{"id": "29027", "revid": "1316653498", "url": "https://en.wikipedia.org/wiki?curid=29027", "title": "Game Gear", "text": "Handheld game console by Sega\nThe is an 8-bit fourth-generation handheld game console released by Sega on October 6, 1990 in Japan, in April 1991 throughout North America and Europe, and in 1992 in Australia. The Game Gear primarily competed with Nintendo's Game Boy, the Atari Lynx, and NEC's TurboExpress. It shares much of its hardware with the Master System, and can play Master System games through the use of an adapter.\nAlthough the Game Gear was rushed to market, it still went on sale more than a year after the Game Boy. With a full-color backlit screen, a landscape format and a more powerful Z80 CPU, Sega positioned the handheld device as technologically superior to the Game Boy. Ultimately, its unique game library and price point gave it an edge over the Atari Lynx and TurboExpress, but its short battery life, large size, lack of original games, and weak support from Sega left the Game Gear unable to surpass the Game Boy, selling 10.62 million units by March 1996. \nThe Game Gear was discontinued in 1997. It was re-released as a budget system by Majesco Entertainment between 2000 and 2002, under license from Sega. \nHistory.\nDeveloped as codename \"Project Mercury\", the Game Gear was launched in Japan on October 6, 1990, in North America and Europe in 1991, and in Australia in 1992. Originally retailing at \u00a5 in Japan, US$ in North America, and \u00a399.99 in the United Kingdom, the Game Gear was developed to compete with the Game Boy, which Nintendo had released in 1989. The decision to make a handheld console was made by Sega's CEO Hayao Nakayama and the name was chosen by newly appointed Sega of America CEO Michael Katz. Both Sega's chairman Isao Okawa and cofounder David Rosen approved of the name. The console had been designed as a portable version of the Master System, with more powerful features than the Game Boy, including a full-color screen instead of monochromatic. According to former Sega console hardware research and development head Hideki Sato, Sega saw the Game Boy's black and white screen as \"a challenge to make our own color handheld system\".\nTo improve upon the design of its competition, Sega modeled the Game Gear with a similar shape to a Genesis controller, intending the curved surfaces and greater length to be more comfortable to hold than the Game Boy. The console's mass was carefully considered from the beginning of the development, aiming for a total mass between that of the Game Boy and the Atari Lynx, another full-color screen competing product. Game Gear can use the Master Gear adaptor to play games from the similar Master System. The original Game Gear pack-in game was \"Columns\", which is similar to \"Tetris\" which was bundled with the Game Boy at launch.\nWith a late start into the handheld console market, Sega rushed to get the Game Gear into stores quickly, having lagged behind Nintendo in sales without a handheld on the market. To simplify development, Sega based the Game Gear hardware on the Master System, with a much larger 4,096 color palette compared to the Master System's 64 colors. Part of the intention was easy conversion of Master System games. The Game Gear's stronger hardware impacted its battery life, running for three to five hours on six AA batteries, falling short of the Game Boy, which could run for more than 30 hours on four AA batteries. Its quick launch in Japan sold 40,000 units in its first two days, 90,000 within a month, and more than 600,000 back orders. According to Sega of America marketing director Robert Botch, \"there is clearly a need for a quality portable system that provides features other systems have failed to deliver. This means easy-to-view, full-color graphics and exciting quality games that appeal to all ages.\"\nRelease and marketing.\nBefore the Game Gear's launch in 1990, the 16-bit Genesis had been successfully marketed as a \"more mature\" option for players, and this was repeated against the Game Boy. Sega's marketing in Japan did not take this approach, instead opting for advertisements with Japanese women featuring the handheld, but Sega's worldwide advertising prominently positioned the Game Gear as the \"cooler\" alternative to the Game Boy.\nIn North America, marketing for the Game Gear included side-by-side comparisons against the Game Boy which likened Game Boy players to the obese and uneducated. Most of these advertisements feature the \"Sega Scream\" with a person yelling the name. One Sega advertisement in early 1994, which contained a dog looking between the two consoles, features the quote, \"If you were color blind and had an IQ of less than 12, then you wouldn't mind which portable you had.\" Such advertising drew criticism from Nintendo, who sought to have protests organized against Sega for insulting disabled people. Sega of America president Tom Kalinske responded that Nintendo \"should spend more time improving their products and marketing rather than working on behind-the-scenes coercive activities\". Ultimately, this debate would have little impact on sales for the Game Gear.\nEurope and Australia were the last regions to receive the Game Gear. Due to delays, some importers paid up to \u00a3200 per system. Upon launch in Europe, video game distributor Virgin Mastertronic unveiled the price as \u00a399.99, positioning it as being more expensive than the Game Boy, but less expensive than the also full-color Atari Lynx. Marketing in the United Kingdom included the slogan, \"To be this good takes Sega\", and advertisements with a biker. In the United Kingdom, the Game Gear had a 16% share of the handheld market in January 1992, increasing to 40% by December 1992.\nDecline.\nSega reduced support for the Game Gear in favor of home consoles. The successful Genesis yielded two major peripherals, the Sega CD and the 32X. The 32-bit Saturn console was launched in 1994. Though selling 10.62 million units by March 1996 (including 1.78 million in Japan), the Game Gear was never able to match the success of its main rival, the Game Boy, with ten times the sales. Sales of the Game Gear were further hurt by Nintendo's release of the smaller Game Boy Pocket, running on two AAA batteries.\nPlans for a 16-bit fifth generation direct successor to the Game Gear were canceled, leaving only the Genesis Nomad, a portable version of the Genesis. Moreover, the Nomad was intended to supplement the Game Gear rather than replace it; in press coverage leading up to the Nomad's release, Sega representatives said the company was not discontinuing the Game Gear in favor of the Nomad, and that \"we believe the two can co-exist\". Though the Nomad had been released in 1995, Sega did not officially end support for the Game Gear until 1996 in Japan, and 1997 worldwide.\nThough the system was originally discontinued in 1997, third-party publisher Majesco Entertainment released a version of the Game Gear at US$, with $ games in 2000 under license from Sega. New games were released, such as a port of \"Super Battletank\". This machine is compatible with all previous Game Gear games, but incompatible with the TV Tuner and some Master System adaptors. The system and its re-released games were sold throughout 2000 and 2001 but were discontinued the following year. Over ten years later, on March 2, 2011, Nintendo announced that its 3DS Virtual Console service on the Nintendo eShop would feature Game Gear games.\nTechnical specifications.\nMuch of the Game Gear's internal hardware is derived from the Master System, as the handheld was designed to be compatible with that system's library of games. It shares the same Zilog Z80 CPU, an 8-bit processor clocked at 3.5MHz, and the Texas Instruments SN76489 sound chip, a programmable sound generator. The chip generated stereo sound, audible using headphones as the device only included a single monaural speaker. The system also contains 8KB of RAM and 16KB of video RAM.\nThe Game Gear measures wide, high, deep, and was designed to be played horizontally. At the center of the device is a color liquid-crystal display that measures diagonally and is able to display up to 32 simultaneous colors from a total palette of 4,096, with a frame rate of about 60Hz with 160\u00d7144 non-square pixels. The screen is backlit for low light using a small cold cathode fluorescent lamp tube. \nThe Game Gear is powered by six AA batteries which provide an approximate battery life of 3 to 5 hours. This was a source of significant criticism from reviewers. In response, Sega released two types of external rechargeable battery packs, intended to lengthen play time and reduce consumer cost. \nAvailable accessories included a TV Tuner with a whip antenna for the cartridge slot, to become a handheld television. Released at \u00a3 (equivalent to US$), the add-on was expensive but unique for collectors and contributed to the system's popularity. The Super Wide Gear magnifies the screen. The Car Gear adapter plugs into cigarette lighters to power the system while traveling, and the Gear to Gear Cable (VS Cable in Japan) establishes a data connection between two Game Gear systems using the same multiplayer game. Master Gear enables the Game Gear to play Master System games.\nGame Gear model variations include several colors, including a blue \"sports\" variation in North America bundled with \"World Series Baseball '95\" or \"The Lion King\". A white version was bundled with a TV tuner. Other versions include a red Coca-Cola theme bundled with \"Coca-Cola Kid\", and the Kids Gear Japan-only variation for children.\nGame library.\nOver 300 total Game Gear games were released, with six titles available at launch. Prices for game cartridges initially ranged from $24.99 to $29.99 in the United States. The casings are molded black plastic with a rounded front to aid in removal. Games include \"Sonic the Hedgehog\", \"The GG Shinobi\", \"Space Harrier\", and \"Land of Illusion Starring Mickey Mouse\", which was considered the best game for the system by \"GamesRadar+\". Later games included entries in franchises that had originated on the successful 16-bit Genesis. Much of the Game Gear's library consists of Master System ports. Because of the landscape orientation of the Game Gear's screen and the similarities to Master System hardware, it was easy for developers to port Master System games to the Game Gear.\nBecause of Nintendo's control over the console video game market, few third-party developers were available to create games for Sega's systems. This contributed to the many ports from Master System. Likewise, because of this, much of the Game Gear library is unique among handhelds, pulling sales away from the Atari Lynx and NEC TurboExpress and helping to establish the Game Gear's market position. However, the Game Boy's library includes over 1000 individual games. Several Game Gear games were released years later on the Nintendo 3DS's Virtual Console service on the Nintendo eShop. The emulator for the Virtual Console releases was handled by M2.\nGame Gear Micro.\nOn June 3, 2020, as part of the company's 60th anniversary, Sega revealed the retroconsole. The Micro was released in Japan on October 6, 2020, through Japanese storefronts in four different versions, varying in color and the game selection, with each containing four separate Game Gear games. Each unit otherwise is the same size, measuring with a display, and is powered by 2 AAA batteries or through a separate USB charger. Each unit also includes a headphone jack. A magnifying accessory modeled after the original system's Big Window accessory was included with preorders. A special version of the device (published by M2 and licensed by Sega) was being shipped with a limited edition of \"Aleste Collection\" in December 2020. This version includes a newly developed Game Gear title \"G.G. Aleste 3\" as well as four other \"Aleste\" titles.\nReception.\nGame Gear surpassed the Atari Lynx and NEC TurboExpress, but lagged far behind the Game Boy in the handheld marketplace. Retrospective reception to the Game Gear is mixed. In 2008, \"GamePro\" listed the Game Gear as 10th on its list of the \"10 Worst-Selling Handhelds of All Time\" and criticized aspects of the implementation of its technology, but also stated that the Game Gear could be considered a commercial success at nearly 11 million units sold. According to \"GamePro\" reviewer Blake Snow, \"Unlike the Game Boy, the Game Gear rocked the landscape holding position, making it less cramped for human beings with two hands to hold. And even though the Game Gear could be considered a success, its bulky frame, relative high price, constant consumption of AA batteries, and a lack of appealing games ultimately kept Sega from releasing a true successor.\" In speaking with \"Famitsu DC\" for its November 1998 issue, Sato stated that the Game Gear achieved \"a respectable chunk of market share\" since overall \"about 14 million systems\" were sold, but that \"Nintendo's Game Boy was such a runaway success, and had gobbled up so much of the market, that our success was still seen as a failure, which I think is a shame.\"\n\"GamesRadar+\" offered some praise for the system and its library, stating: \"With its 8-bit processor and bright color screen, it was basically the Sega Master System in your hands. How many batteries did we suck dry playing Sonic, Madden and Road Rash on the bus or in the car, or in the dark when we were supposed to be sleeping? You couldn't do that on a Game Boy!\" By contrast, \"IGN\" reviewer Levi Buchanan opined that the Game Gear's biggest fault was its game library when compared to the Game Boy, stating: \"the software was completely lacking compared to its chief rival, which was bathed in quality games. It didn't matter that the Game Gear was more powerful. The color screen did not reverse any fortunes. Content and innovation beat out technology, a formula that Nintendo is using right now with the continued ascendance of the DS and Wii.\" Buchanan praised some of the library: \"Some of those Master System tweaks were very good games, and fun is resilient against time.\" \"Retro Gamer\" praised Sega's accomplishment in surviving against the competition of Nintendo in the handheld console market with the Game Gear, noting that \"for all the handhelds that have gone up against the might of Nintendo and ultimately lost out, Sega's Game Gear managed to last the longest, only outdone in sales by the Sony PSP. For its fans, it will remain a piece of classic gaming hardware whose legacy lives on forever.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29028", "revid": "50860895", "url": "https://en.wikipedia.org/wiki?curid=29028", "title": "32X", "text": "Video game console add-on\nThe 32X is an add-on for the Sega Genesis video game console. Codenamed \"Project Mars\", it was designed to expand the power of the Genesis and serve as a transitional console into the 32-bit era until the release of the Sega Saturn. The 32X uses its own ROM cartridges and has its own library of games. It was distributed under the name in Japan and South Korea, Genesis 32X in North America, Mega 32X in Brazil, and Mega Drive 32X in all other regions. \nSega unveiled the 32X at the Consumer Electronics Show in June 1994, and presented it as a low-cost option for 32-bit games. It was developed in response to the Atari Jaguar and concerns that the Saturn would not make it to market by the end of 1994. Though the 32X was conceived as a new, standalone console, at the suggestion of Sega of America executive Joe Miller and his team, it became an add-on for the Genesis which made the console more powerful. The final design contained two 32-bit central processing units and a visual display processor. \nThe 32X failed to attract third-party developers and consumers because of the announcement of the Saturn's simultaneous release in Japan. Sega's efforts to rush the 32X to market cut into time for game development, resulting in a weak library of 40 games that did not fully use the hardware, including Genesis ports. Sega produced 800,000 32X units and sold an estimated 665,000 by the end of 1994, selling the rest at steep discounts until it was discontinued in 1996 as Sega turned its focus to the Saturn. \nThe 32X is considered a commercial failure. Initial reception was positive, highlighting the low price and power expansion to the Genesis. However, later reviews, both contemporary and retrospective, were mostly negative because of its limited game library, poor market timing and its market fragmentation of the Genesis.\nHistory.\nThe Sega Genesis was released in 1988. By early 1994, Sega had started to become concerned about competition from newer, more powerful 32-bit consoles, such as the Atari Jaguar and the 3DO. The Sega CD, a previous add-on for the Genesis, had not met commercial expectations, and the Genesis' successor, the Sega Saturn, would not be fully rolled out worldwide until late 1995. This left a nearly two-year gap that Sega worried would allow its competitors to gain traction. According to former Sega of America CEO Tom Kalinske, in regards to discussing about the longevity of the Genesis, \"Initially, the argument was that we could get another year of life out of the Genesis before we had to introduce the Saturn. Japan disagreed with me on that, so as kind of a stopgap measure, the 32X came up.\"\nDevelopment.\nDuring the Winter Consumer Electronics Show in January 1994, Sega of America research and development head Joe Miller took a phone call in his Las Vegas hotel suite from Sega president Hayao Nakayama, in which Nakayama stressed the importance of coming up with a quick response to the Atari Jaguar. Included on this call were Sega of America producer Scot Bayless, Sega hardware team head Hideki Sato, and Sega of America vice president of technology Marty Franz. One idea mooted by the Japanese team, referred to by former Sega of America producer Michael Latham as \"Genesis 2\", was an entirely new independent console. This would have been a new Genesis model with an upgraded color palette and some limited 3D capabilities thanks to integration of ideas from the development of the Sega Virtua Processor chip.\nAccording to Latham, Miller dismissed an upgraded Genesis as \"just a horrible idea. If all you're going to do is enhance the system, you should make it an add-on. If it's a new system with legitimate new software, great. But if the only thing it does is double the colors...\" Miller said his idea was to leverage the existing Genesis as a way to keep from alienating Sega customers, who would otherwise be required to discard their Genesis systems entirely to play 32-bit games, and to control the cost of the new system in the form of an add-on. From these discussions, the new add-on, codenamed \"Project Mars\", was advanced.\nWith Miller pushing for his American team to create the system, the 32X was designed as a peripheral for the existing Genesis, expanding its power with two 32-bit SuperH-2 processors, the same as those that would be used in the Saturn but with a lower clock speed. The SH-2 had been developed in 1993 as a joint venture between Sega and Japanese electronics company Hitachi. The original design for the 32X add-on, according to Bayless, was created on a cocktail napkin, but Miller denied this. In another account, Bayless claimed that Franz began designing the 32X on a hotel notepad, drawing two SH-2 processors with separate framebuffers. \nAlthough the new unit was a stronger console than originally proposed, it was not compatible with Saturn games. This was justified by Sega's statement that both platforms would run at the same time, and that the 32X would be aimed at players who could not afford the more expensive Saturn. Bayless praised the potential of this system at this point, calling it \"a coder's dream for the day\" with its twin processors and 3D capabilities. Sega of America headed up the development of the 32X, with some assistance from Sato's team in Japan. Shortages of processors due to the same 32-bit chips being used in both the 32X and the Saturn hindered the development of the 32X, as did the language barrier between the teams in Japan and the United States.\nBefore the 32X was launched, the release date of the Saturn was announced for November 1994 in Japan, coinciding with the 32X's target launch date in North America. Sega of America was tasked with marketing the 32X with the Saturn's Japan release occurring simultaneously. Their answer was to describe the 32X a \"transitional device\" between the Genesis and the Saturn; Bayless said this \"just made us look greedy and dumb to consumers\".\nPromotion and release.\nThe unveiling of the 32X to the public came at the Summer Consumer Electronics Show in June 1994 in Chicago. Promoted as the \"poor man's entry into 'next generation' games\", 32X was marketed for its US$159 price point as a less-expensive alternative to the Saturn. However, Sega would not answer as to whether or not a Genesis console equipped with a Sega CD and a 32X would be able to run Saturn software. Trip Hawkins, founder of The 3DO Company, was willing to point out that it would not, stating, \"Everyone knows that 32X is a Band-Aid. It's not a 'next generation system.' It's fairly expensive. It's not particularly high-performance. It's hard to program for, and it's not compatible with the Saturn.\" In response to these comments, Sega executive Richard Brudvik-Lindner pointed out that the 32X would play Genesis games, and had the same system architecture as the Saturn. \nIn August of that year, \"GamePro\" highlighted the advantages of the upcoming add-on in its 32-bit processors and significantly lower price, noting that \"[n]o doubt gotta-get-it-now gamers will spend the big bucks to grab Saturn or PlayStation systems and games from Japan. For the rest of us, however, 32X may well be the system of choice in '94.\" \"Edge\" was more critical, questioning if the 32X was only there to fill in as a stopgap for the Christmas season in the US and Europe, and referred to the Japanese release as a \"PR exercise and quick money maker [rather] than a serious bid to get the machine into every home\". Responding to concerns over the 32X being a stopgap, Kalinske said, \"Saturn will be at a price point that will not make it a massmarket item. In terms of volume and keeping the category exciting, it's Genesis and 32X.\"\nThe 32X was released on November 21, 1994, in North America, in time for the holiday season that year. As announced, it retailed for $159.99 without a pack-in game. Demand among retailers was high, and Sega could not keep up with orders for the new system. Over 1,000,000 orders had been placed for 32X units, but Sega had only managed to ship 600,000 units by January 1995. In the United States, nearly 500,000 units were sold by Christmas 1994, exceeding Sega's initial sales projection. Launching at about the same price as a Genesis console, the price of the 32X was less than half of what the Saturn's price would be at launch. The European release came in November 1994, at a price of \u00a3169.99, and also experienced initial high demand.\nSega promised 12 games available at launch and 50 games due for release in 1995 from third-party developers. Despite Sega's initial promises, only six games were available at its North American launch, including \"Doom\", \"Star Wars Arcade\", \"Virtua Racing Deluxe\", and \"Cosmic Carnage\". Although \"Virtua Racing\" was considered strong, \"Cosmic Carnage\" \"looked and played so poorly that reporters made jokes about it\". Games were available at a retail price of $69.95. Advertising for the system included images of the 32X being connected to a Genesis console to create an \"arcade system\". Japan received the 32X on December 3, 1994, two weeks after the launch of the Saturn in the region. The 32X launched in Brazil in March 1995.\nDecline.\nDespite the lower price console's positioning as an inexpensive entry into 32-bit gaming, Sega had a difficult time convincing third-party developers to create games for the new system. Top developers were already aware of the coming arrival of the Sega Saturn, Nintendo 64, and PlayStation, and did not believe the 32X would be capable of competing with any of those systems. Not wanting to create games for an add-on that was \"a technological dead-end\", many developers decided not to make games for the system. Problems plagued games developed in-house due to the 32X's quick development time. According to Bayless, \"games in the queue were effectively jammed into a box as fast as possible, which meant massive cutting of corners in every conceivable way. Even from the outset, designs of those games were deliberately conservative because of the time crunch. By the time they shipped they were even more conservative; they did nothing to show off what the hardware was capable of.\" Kalinske has said that Sega of America did not receive enough support from Japan in game development. Development kits came out late, leaving little time for game development before the 32X release. According to one developer, the 32X's hardware was significantly slower than the Saturn and lacked the capability for texture mapping.\nJournalists were similarly concerned about Sega's tactic of selling two similar consoles at different prices and attempting to support both, likening Sega's approach to that of General Motors and segmenting the market for its consoles. In order to convince the press that the 32X was a worthwhile console, Sega flew in journalists from all around the country to San Francisco for a party at a local nightclub. The event featured a speech from Kalinske, live music with a local rapper, and 32X games on exhibition. However, the event turned out to be a bust, as journalists attempted to leave the party due to its loud music and unimpressive games on display, only to find that the buses that brought them to the nightclub had just left and would not return until the scheduled end of the party.\nThough the system had a successful launch, demand soon disappeared. Over the first three months of 1995, several of the 32X's third party publishers, including Capcom and Konami, cancelled their 32X projects so that they could focus on producing games for the Saturn and PlayStation. The 32X failed to catch on with the public, and is considered a commercial failure. By 1995, the Genesis had still not proven successful in Japan, where it was known as Mega Drive, and the Saturn was beating the PlayStation, so Sega CEO Hayao Nakayama decided to force Sega of America to focus on the Saturn and cut support for Genesis products, executing a surprise early launch of the Saturn in the early summer of 1995. Sega was supporting five different consoles before this\u2014Saturn, Genesis, Game Gear, Pico, and the Master System\u2014as well as the Sega CD and 32X add-ons. Sales estimates for the 32X stood at 665,000 units at the end of 1994. Despite assurances from Sega that many games would be developed for the system, in early 1996, Sega finally conceded that it had promised too much out of the add-on and decided to discontinue the 32X in order to focus on the Saturn. In September 1995, the retail price for the 32X dropped to $99, and later the remaining inventory was cleared out of stores at $19.95, with 800,000 units sold in total.\nSega Neptune.\nThe Sega Neptune is an unproduced two-in-one Genesis and 32X console which Sega planned to release in winter 1996, with the retail price planned to be under $200. In Sega\u2019s 1995 official product catalog, the system was presented under the name \"Genesis 32X System\", reflecting Sega\u2019s intention to market it as a fully integrated Genesis and 32X platform.\nThe console was featured as early as March 1995, with \"Sega Magazine\" stating that the unit \"shows [Sega's] commitment to the hardware\". The same official catalog listed the system as compatible with the Sega-CD, which logically follows from its design as an integrated platform, meaning that both standard CD titles and CD 32X titles would have operated on the Neptune as well.\nSega cancelled the Neptune in October 1995, expressing concern that releasing another hardware platform would dilute their marketing focus on the Saturn and place a sub-$200 hybrid system uncomfortably close to their 32-bit offering. \"Electronic Gaming Monthly\" later used the Neptune as an April Fools' Day prank in its April 2001 issue, claiming that Sega had discovered a warehouse of unused Neptune units available for US$.\nAlthough often referred to as a prototype, the physical unit shown in promotional contexts was in fact a non-functional mock-up constructed from wood and plastic, used solely to illustrate the intended industrial design of the system. One such mock-up, recognizable by several surface abrasions, has appeared in exhibitions organized by the Videogame History Museum, including events such as the National Videogame Museum, E3, the Game Developers Conference, and the Classic Gaming Expo.\nThe Neptune has remained a subject of interest among enthusiasts, leading to various fan-made recreations incorporating original Genesis and 32X hardware, custom electronic integration, and 3D-printed enclosures intended to approximate the canceled design.\nTechnical aspects and specifications.\nThe 32X can be used only in conjunction with a Genesis system. It is inserted into the system like a standard game cartridge. The add-on requires its own separate power supply, a connection cable linking it to the Genesis, and an additional conversion cable for the original model of the Genesis. As well as playing its own library of cartridges, the 32X is backwards-compatible with Genesis games, and can also be used in conjunction with the Sega CD to play games that use both add-ons. The 32X also came with a spacer so it would fit properly with the second model of the Genesis; an optional spacer was offered for use with the Sega Genesis CDX system, but ultimately never shipped due to risks of electric shock when the 32X and CDX were connected. Installation of the 32X also requires the insertion of two included electromagnetic shield plates into the Genesis' cartridge slot.\nSeated on top of a Genesis, the 32X measures . The 32X contains two Hitachi SH-2 32-bit RISC processors with a clock speed of 23 MHz, which Sega claimed would allow the system to work 40 times faster than a stand-alone Genesis. Its graphics processing unit is capable of producing 32,768 colors and rendering 50,000 polygons per second, which provides a noticeable improvement over the polygon rendering of the Genesis. The 32X also includes 256 kilobytes of random-access memory (RAM), along with 256 kilobytes of video RAM. Sound is supplied through a pulse-width modulation sound source. Input/output is supplied to a television set via a provided A/V cable that supplies composite video and stereo audio, or through an RF modulator. Stereo audio can also be played through headphones via a headphone jack on the attached Genesis.\nGame library.\nThe 32X library consists of 40 games, including six that required both the 32X and Sega CD. Among them were ports of arcade games \"After Burner\", \"Space Harrier\", and \"Star Wars Arcade\", a sidescroller with a hummingbird as a main character in \"Kolibri\", and a 32X-exclusive \"Sonic the Hedgehog\" spinoff, \"Knuckles' Chaotix\". Several of the games released for the 32X are enhanced ports of Genesis games, including \"NFL Quarterback Club\" and \"World Series Baseball '95\". In a retrospective review of the console, \"Star Wars Arcade\" was considered the best game for the 32X by \"IGN\" for its cooperative play, soundtrack, and faithful reproduction of the experiences of \"Star Wars\". In a separate review, \"IGN\"'s Levi Buchanan praised the 32X game \"Shadow Squadron\" as superior to \"Star Wars Arcade\". \"Retro Gamer\" writer Damien McFerran, however, praised \"Virtua Fighter\" as \"the jewel in the 32X's crown\", and \"GamesRadar+\" named \"Knuckles' Chaotix\" as the best game for the system. \"Next Generation\" called \"Virtua Fighter\" \"the colorful wreath on 32X's coffin\", reflecting the consensus among contemporary critics that the game was at once arguably the 32X's best release and a clear harbinger of the platform's imminent discontinuation, since it was inferior to the already-released Saturn version of \"Virtua Fighter Remix\", as well as the forthcoming Saturn release of \"Virtua Fighter 2\". In response to fan inquiries, Sega stated that the 32X architecture was not powerful enough to handle a port of \"Virtua Fighter 2\".\nDespite its 32-bit processing and potential for better graphics and sound than the Genesis, most games did not take advantage of the 32X hardware. \"Doom\" for the 32X received near-perfect reviews, but was later criticized as inferior to versions for the PC and the Atari Jaguar, with missing levels, poor graphics and audio, jerky movement, and windowed gameplay. Franz believes few developers were willing to invest in designing games to work with the 32X's improved audio abilities. One cause was the rush to release games for the 32X launch; former Sega of America executive producer Michael Latham said it took \"a lot of convincing\" to release the 32X launch game \"Cosmic Carnage.\" With \"Doom\", id Software programmer John Carmack had to cut a third of the levels to have the game ready for the 32X launch. Because of time limitations, game designs were intentionally conservative and did not show what the 32X hardware was able to do. Another factor was the architecture of the 32X's dual processors and graphics processor having difficulty accessing RAM, leading to developers choosing to only use one processor for their games. In an interview at the end of 1995, Sega vice president of marketing Mike Ribero insisted that Sega was not abandoning the 32X, but acknowledged that first-party support had been lackluster: \"I won't lie to you, we screwed up with 32X. We overpromised and underdelivered.\"\nReception and legacy.\nInitial reception to the 32X and its games upon the launch of the add-on was positive. Four reviewers from \"Electronic Gaming Monthly\" graded the 32X well in their 1995 Buyer's Guide, highlighting the add-on's enhancements to the Genesis but questioning how long the system would be supported: one reviewer suggested the add-on had a \"bright future\" while another believed it was only meant to last until the release of the Saturn. A reviewer for \"GamePro\" commented that the 32X's multiple input and power cords make it \"as complicated as setting up your VCR\" and noted some performance glitches with the prototype such as freezes and overheating, but expressed confidence that the production models would perform well and gave the add-on their overall approval. \nBy late 1995, feedback to the add-on had soured. In its 1996 Buyer's Guide, \"Electronic Gaming Monthly\"'s four reviewers scored the add-on 3, 3, 3, and 2 out of 10, criticizing the game library and Sega's abandonment of the system in favor of the Saturn. A review in \"Next Generation\" panned the 32X for its weak polygon processing, the tendency of developers to show off its capabilities with garishly colored games, and its apparent function as \"simply a way of grabbing extra 1994 mind and market share while waiting for Saturn\". The review gave it one out of five stars. \"Game Players\" assessed it as so much less powerful than the Saturn and PlayStation that its lower price could not be considered an enticement, and said that the vast majority of its games could have been done just as well on the Super NES. Additionally commenting that both first party and third party software support had been weak, they concluded, \"The lack of support [and] good games, and the release of Saturn make the 32X a system that never was.\"\nRetrospectively, the 32X is widely criticized as having a shallow library with a lack of support and a poor idea in the wake of the release of the Sega Saturn in Japan. \"1UP.com\"'s Jeremy Parish stated that the 32X \"tainted just about everything it touched.\" \"GamesRadar+\" also panned the system, placing it as their ninth-worst console with reviewer Mikel Reparaz criticizing that \"it was a stopgap system that would be thrown under the bus when the Sega Saturn came out six months later, and everyone seemed to know it except for die-hard Sega fans and the company itself.\" \"Retro Gamer'\"s Damien McFerran offered some praise for the power increase of the 32X to offer ports of \"Space Harrier\", \"After Burner\", and \"Virtua Fighter\" that were accurate to the original arcade versions, as well as the add-on's price point, stating, \"If you didn't have deep enough pockets to afford a Saturn, then the 32X was a viable option; it's just a shame that it sold so poorly because the potential was there for true greatness.\" Levi Buchanan, writing for \"IGN\", saw some sense in the move for Sega to create the 32X but criticized its implementation. According to Buchanan, \"I actually thought the 32X was a better idea than the SEGA CD... The 32X, while underpowered, at least advanced the ball. Maybe it only gained a few inches in no small part due to a weak library, but at least the idea was the right one.\"\nIn particular, the console's status as an add-on and poor timing after the announcement of the Saturn has been identified by reviewers as being responsible factors for fracturing the audience for Sega's video game consoles in terms of both developers and consumers. \"Allgame\"'s Scott Alan Marriott states that \"[e]very add-on whittled away at the number of potential buyers and discouraged third-party companies from making the games necessary to boost sales.\" \"GamePro\" criticized the concept of the add-on, noting the expenses involved in purchasing the system. According to reviewer Blake Snow, \"Just how many 16-bit attachments did one need? All in all, if you were one of the unlucky souls who completely bought into Sega's add-on frenzy, you would have spent a whopping $650 for something that weighed about as much as a small dog.\" Writing for \"GamesRadar+\", Reparaz noted that \"developers\u2014not wanting to waste time on a technological dead-end\u2014abandoned the 32X in droves. Gamers quickly followed suit, turning what was once a promising idea into an embarrassing footnote in console history, as well as an object lesson in why console makers shouldn't split their user base with pricey add-ons.\" Reparaz went on to criticize Sega's decision to release the 32X, noting that \"(u)ltimately, the 32X was the product of boneheaded short-sightedness: its existence put Sega into competition with itself once the Saturn rolled out.\" Writing for \"IGN\", Buchanan points out, \"Notice that we haven't seen many add-ons like the 32X since 1994? I think the 32X killed the idea of an add-on like this\u2014a power booster\u2014permanently. And that's a good thing. Because add-ons, if not implemented properly, just splinter an audience.\"\nFormer executives at Sega have mixed opinions of the 32X. Bayless believed firmly that the 32X served as a warning to the video game industry not to risk splintering the market for consoles by creating add-ons, and was critical of the Kinect and PlayStation Move for doing so. Franz placed the 32X's commercial failure on its inability to function without an attached Genesis and lack of a CD drive, despite its compatibility with the Sega CD. Miller remembered the 32X and his vision for the console positively, but conceded that the timing was wrong with the Saturn on the horizon.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29030", "revid": "22041646", "url": "https://en.wikipedia.org/wiki?curid=29030", "title": "SHA", "text": ""}
{"id": "29031", "revid": "9021902", "url": "https://en.wikipedia.org/wiki?curid=29031", "title": "Severan dynasty", "text": "Roman imperial dynasty (ruled 193 to 235)\nThe Severan dynasty, sometimes called the Septimian dynasty, ruled the Roman Empire between 193 and 2351292.\nIt was founded by the emperor Septimius Severus (r.\u2009193\u00a0\u2013\u00a0211)1351 and Julia Domna, his wife, when Septimius emerged victorious from civil war of 193 - 197, which began with the Year of the Five Emperors.\nTheir two sons, Caracalla (r.\u2009192\u00a0\u2013\u00a0217)211 and Geta (r.211)1350, ruled briefly after the death of Septimius.\nIn 217 - 218 there was a short interruption of dynasty's control over the empire by reigns of Macrinus (r.\u2009217\u00a0\u2013\u00a0218)1292 and his son Diadumenian (r.218) before Julia Domna's relatives assumed power by raising her two grandnephews, Elagabalus (r.\u2009218\u00a0\u2013\u00a0222)212 and Severus Alexander (r.\u2009222\u00a0\u2013\u00a0235)212, in succession to the imperial office1292.\nThe dynasty's women, Julia Domna, the mother of Caracalla and Geta, and her sister, Julia Maesa, the mother of Julia Soaemias and Julia Mamaea, mothers of Elagabalus and Severus Alexander respectively, were all powerful \"augustae\".\nThey were also instrumental in securing imperial positions for their male relatives.\nAlthough Septimius Severus restored peace following the upheaval of the late 2nd century, the dynasty's rule was disturbed by unstable family relationships and political instability, especially the rising power of the praetorian prefects170.\nAll this foreshadowed the Crisis of the Third Century195.\nHistory.\nSeptimius Severus (193\u2013211).\nIn April 9 145, Lucius Septimius Severus was born in Leptis Magna1, then in the Roman province of Africa Proconsularis and now in Libya, into a Roman family of equestrian rank, of Libyan-Punic and Italic origin.2-3 He rose through military service to consular rank under the later emperors of the Antonine dynasty.\nIn summer 187 he married a Syrian noblewoman Julia Domna and the marriage produced two boys: Caracalla and Geta.\nJulia Domna also held a prominent political role in government during her husband's reign.\nSeverus was proclaimed emperor in 193 by his legionaries in Noricum3 during the political unrest that followed the death of Commodus97,\nand secured sole rule over the empire in early 197, after defeating Clodius Albinus at the Battle of Lugdunum1256.\nIn late 197 Severus fought a successful war against the Parthians1306, between 208 and 210 he campaigned with success against barbarian incursions in Roman Britain180 and rebuilt Hadrian's Wall. In Rome, his relations with the Senate were poor, but he was popular with the commoners and with his soldiers, whose salary he raised. Starting in 197, his praetorian prefect, Gaius Fulvius Plautianus, was growing in influence, but he would be executed in 205.\nSeptimius died, from natural causes, in early 211 while on campaign in Britain1878.\nDuring his reign, Severus debased the Roman currency several times -- for example upon his accession he decreased the silver purity of the denarius from 81.5% to 78.5%.\nThe Jews experienced more favorable conditions under the Severan dynasty: According to Jerome, both Septimius Severus and Antoninus \"very greatly cherished the Jews.\"135\nSeptimius was succeeded by his sons Caracalla and Geta, whom he had elevated as co-emperors in the years preceding his death21115. The growing hostility between the brothers was initially buffered by Julia Domna's mediation15-6.\nCaracalla (198\u2013217).\nThe eldest son of Severus, born in 188 as Lucius Septimius Bassianus2116.\n\"Caracalla\" was a nickname referring to the Gallic hooded tunic that he habitually wore18.\nIn 195 Severus made him caesar and renamed him to Aurelius Antonius Marcus after Marcus Aurelius2115.\nA while later, in 198, Severus made him augustus2117 while also naming Caracalla's younger brother, Geta, to caesar13507.\nCaracalla hated his brother, and conflict between them culminated in the assassination of the latter in 21121115.\nAfter the murder of his brother, Caracalla tried and gained goodwill of his legionaries with lavish pay raises21116. However, he also purged many of Geta's supporters16.\nDuring his campaigns Caracalla let his mother, Julia Domna, who accompanied her son, to handle many official matters by correspondence and refer to him only major issues17.\nIn 213 he campaigned against the Alamanni, and in 214 he fought with the Danubian Carpi212.\nLater he raised a Macedonian phalanx to emulate Alexander the Great, and marched through Asia and Syria to Alexandria, inviting mockery of many, whom he later executed212.\nDuring his reign he bestowed, for reasons not entirely clear, Roman citizenship to all non-slaves living within the borders of the empire17.\nThe Baths of Caracalla in Rome are the most enduring monument of his rule.\nCaracalla died in April 8 21721119. He was murdered near Carrhae while en route to a campaign against the Partians212, the murder being committed by an evocatus attached to the Praetorian Guard on the order of a Praetorian prefect, the future emperor Macrinus19.\nGeta (209\u2013211).\nThe younger of Severus' two sons, Geta, was born in 1896.\nHe was made caesar in 198 and co-\"augustus\" in 2098 or 2101350 alongside his father and older brother Caracalla1350. Unlike the much more successful joint reign of Marcus Aurelius (r.\u2009161\u00a0\u2013\u00a0180) and his brother Lucius Verus (r.\u2009161\u00a0\u2013\u00a0169) the previous century, relations were hostile between the two Severan brothers211, and soon after their father's death Geta was murdered by his brother Caracalla1350.\nGeta was murdered in their mother's apartments, and died clung to his mother, by order of Caracalla16, who then ruled as sole emperor.\nInterlude: Macrinus (217\u2013218).\nMacrinus was the first Roman emperor who did not come from a senatorial family1039.\nHe was born in 164 at Caesarea in Mauretania, now Cherchell, Algeria.\nThough not related to Severans while also being of just equestrian rank and having been born into a Moorish family201039, he rose through the ranks all the way to being a praetorian prefect under Caracalla1039.\nIn 217 Macrinus became involved in a successful conspiracy to kill Caracalla1039, and soon after the murder trooops saluted Macrinus as 101039.\nHis made peace with the Parthian Empire1039, which involved paying reparations for the damage caused by Caracalla's campaigns1020.\nHis troops considered the terms degrading to the Romans10.\nOne of the reasons for his eventual downfall was his attempt at saving by paying serving soldiers of the Eastern troops by higher pay scales established during the rule of Caracalla while paying the new recruits by lower pay scales from the time of Septimius20101039 -- his troops were not impressed20.\nDue to a continuing threat from Parthia, he kept the rebellious forces in Syria20, where they became one way or the other acquainted with Elagabalus11.\nIn May 218 troops camping near Elesa revolted and hailed Elegabalus as emperor2112.\nAfter months of rebellion and a failed attack on the rebellious troops, Macrinus met the army of Elagabalus near Antioch where he was decisively defeated21141039.\nMacrinus managed to escape with his son to Chalcedon where he was apprehended to be taken back to Antioch, but the guards murdered him en route21.\nDuring his rule Macrinus never entered the city of Rome10.\nElagabalus (218\u2013222).\nElagabalus was born Varius Avitus Bassianus in 203212 and became known later as Marcus Aurelius Antonius212.\nThe name \"Elagabalus\" followed the Latin nomenclature for the Syrian sun god Elagabal, of whom he was a priest11.\nAt the age of 14, in 218, Elagabalus was crowned emperor by Gallic Third Legion9212.\nThere are two different versions how Elagabalus gained the throne.\nIn one version of events, Elagabalus's grandmother, Julia Maesa, Julia Domna's sister and sister-in-law of Septimius Severus, persuaded the Legio III Gallica to rebel against Macrinus212 by claiming that Elagabalus was actually Caracalla's bastard son with one of her daughters11.\nShe also used her enormous wealth to get soldiers swear fealty to Elagabalus.\nHaving succeeded, Maesa and her family were invited to enter the camp, where Elagabalus was clad in imperial purple and crowned as emperor11.\nAnother account of the events tells how Elagabalus was being protected and raised by Gannys, a foster father and lover of his mother, Julia Soaemias11.\nIn this version of events, Gannys dressed young Elagabalus in Caracalla's childhood clothes and smuggled him into the camp at night, where soldiers eventually revolted the next morning11.\nIn any case, he did arrive as emperor in Rome by summer 21918212.\nHistorical sources treat his reign negatively21, but many of his failures can not be affirmed.\nHowever, epigraphical and numismatic evidence shows that Elagabalus did replace Jupiter with Elagabal in late 22018, and he also married a Vestal Virgin called Aquilia Severa212.\nIn addition to these offences to Roman sensibilities, he was also accused of being murderous and bloodthirsty, but executions during his reign appear to be politically motivated instead of being the result of simple bloodlust97.\nMany, if not all, stories about his effeminacy, extravagance, and licentiousness are imaginations of ancient authors122.\nIn 221, seeing that her grandson's outrageous behaviour could mean the loss of power, Julia Maesa persuaded or forced Elagabalus to adopt his cousin, Severus Alexander212, as and his heir37.\nAt the same time he was forced divorce Aquilia in order to marry Annia Faustina, a relative of Marcus Aurelius, only to take Aquila back in a few months before the end of 221212.\nElagabalus also tried on several occasions to murder Alexander, which enraged the troops40212.\nIn 222 Elagabalus was murdered and his corpse thrown into the sewer42. The next day his cousin Alexander was hailed emperor by the troops41-2.\nAlexander Severus (222\u2013235).\nBorn Gessius Bassianus Alexianus in ca. 209212, in 221 Alexander was adopted at by Elagabalus from whence he was called Marcus Aurelius Alexander Caesar2121. The adoption happened at the urging of Julia Maesa212, who was the grandmother of both cousins.\nHis cousin Elagabalus had made several attempts at Alexander's life, which prompted the troops to mutiny, and things came to a head on March 6 when Elagabalus was put to death and Alexander raised to the throne2240-2.\nRuling from the age of 14 under the influence of his mother212, Julia Avita Mamaea, ancient writers presented his reign as an efficient regime like the rule of Septimius Severus22.\nThe rising strength of the Sasanian Empire (r.\u2009226\u00a0\u2013\u00a0651) heralded perhaps the greatest external challenge that Rome faced in the 3rd century; however, in 231 Alexander organised an expedition to Parthia, nominally leading it, and by this did maintain control over the province of Mesopotamia212.\nAlexander's reign ended in early 235 when he was murdered, together with his mother, by his own troops while he was wintering in Germany where he was in order to prosecute a war in Upper Germania213.\nHe was deified in 238 after his memory had been condemned for a few years213.\nThe death of Alexander was the epochal event beginning the troubled Crisis of the Third Century89. His successor was Maximinus Thrax (r.\u2009235\u00a0\u2013\u00a0238), the first in a series of weak emperors, which ended 50 years later with the Tetrarchy instituted in the reign of Diocletian (r.\u2009284\u00a0\u2013\u00a0305).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29032", "revid": "30717234", "url": "https://en.wikipedia.org/wiki?curid=29032", "title": "Sega CD", "text": "Video game console add-on\nThe Sega CD, known as in most regions outside North America and Brazil, is a CD-ROM peripheral and format for the Sega Genesis produced by Sega as part of the fourth generation of video game consoles. Originally released in Japan on December 12, 1991, it came to North America on October 15, 1992, and the rest of the world in 1993. The Sega CD plays CD-based games and adds hardware functionality such as a faster CPU and a custom graphics chip for enhanced sprite scaling and rotation. It can also play audio CDs and CD+G discs.\nSega sought to match the capabilities of the competing PC Engine CD-ROM\u00b2 System, and partnered with JVC to design the Sega CD. Sega refused to consult with their American division until the project was complete, fearful of leaks. The Sega CD was redesigned several times by Sega and was also licensed to third parties, including Pioneer and Aiwa who released home audio products with Sega CD gaming capability. The main benefit of CD technology at the time was greater storage; CDs offered approximately 160 times more space than Genesis/Mega Drive cartridges. This benefit manifested as full-motion video (FMV) games such as the controversial \"Night Trap\".\nThe Sega CD game library features acclaimed games such as \"Sonic CD\", ', ', \"Popful Mail\", and \"Snatcher\", but also many Genesis ports and poorly received FMV games. Only 2.24 million Sega CD units were sold, after which Sega discontinued it to focus on the Sega Saturn. Retrospective reception has been mixed, with praise for some games and functions, but criticism for its lack of deep games and its high price. Sega's poor support for the Sega CD has been criticized as the beginning of the devaluation of its brand.\nHistory.\nBackground.\nReleased in 1988, the Genesis (known as the Mega Drive in most territories outside of North America) was Sega's entry into the fourth generation of video game consoles. In the early 1990s, Sega of America CEO Tom Kalinske helped make the Genesis a success by cutting the price, developing games for the American market with a new American team, continuing aggressive advertising campaigns, and selling \"Sonic the Hedgehog\" with the Genesis as a pack-in game.\nBy the early 1990s, compact discs (CDs) were making headway as a storage medium for music and video games. NEC had been the first to use CD technology in a video game console with their PC Engine CD-ROM\u00b2 System add-on in October 1988 in Japan (launched in North America as the TurboGrafx-CD the following year), which sold 80,000 units in six months. That year, Nintendo announced a partnership with Sony to develop a CD-ROM peripheral for the Super Nintendo Entertainment System (SNES). Commodore International released their CD-based CDTV multimedia system in early 1991, while the CD-i from Philips arrived later that year. According to Nick Thorpe of \"Retro Gamer\", Sega would have received criticism from investors and observers had it not developed a CD-ROM game system.\nDevelopment.\nShortly after the release of the Genesis, Sega's Consumer Products Research and Development Labs, led by manager Tomio Takami, were tasked with creating a CD-ROM add-on. It was originally intended to equal the capabilities of the TurboGrafx-CD, but with twice as much random-access memory (RAM). In addition to relatively short loading times, Takami's team planned to implement hardware scaling and rotation similar to that of Sega's arcade games, which required a dedicated digital signal processor. A custom graphics chip would implement these features, alongside an additional sound chip manufactured by Ricoh. According to Kalinske, Sega was ambitious about what CD-ROM technology would do for video games, with its potential for \"movie graphics\", \"rock and roll concert sound\" and 3D animation. \nHowever, two major changes were made towards the end of development that dramatically raised the price of the add-on. Because the Genesis' Motorola 68000 CPU was too slow to handle the Sega CD's new graphical capabilities, an additional 68000 CPU was incorporated. This second CPU has a clock speed of 12.5\u00a0MHz, faster than the 7.67\u00a0MHz CPU in the Genesis. Responding to rumors that NEC planned a memory upgrade to bring the TurboGrafx-CD RAM from 0.5\u00a0Mbit to between 2 and 4\u00a0Mbit, Sega increased the Sega CD's available RAM from 1 to 6.5\u00a0Mbit. This proved to be a technical challenge, since the Sega CD's RAM access speed was initially too slow to run programs effectively, and the developers had to focus on increasing the speed. The estimated cost of the device rose to US$370, but market research convinced Sega executives that consumers would be willing to pay more for a state-of-the-art machine. Sega partnered with JVC, which had been working with Warner New Media to develop a CD player under the CD+G standard.\nSega of America was not informed of the project details until mid-1991. Despite being provided with preliminary technical documents earlier in the year, the American division was not given a functioning unit to test. According to former executive producer Michael Latham: \"When you work at a multinational company, there are things that go well and there are things that don't. They didn't want to send us working Sega CD units. They wanted to send us dummies and not send us the working CD units until the last minute because they were concerned about what we would do with it and if it would leak out. It was very frustrating.\" \nLatham and Sega of America vice president of licensing Shinobu Toyoda assembled a functioning Sega CD by acquiring a ROM for the system and installing it in a dummy unit. The American staff were frustrated by the Sega CD's construction. Former senior producer Scot Bayless said: \"[It] was designed with a cheap, consumer-grade audio CD drive, not a CD-ROM. Quite late in the run-up to launch, the quality assurance teams started running into severe problems with many of the units\u2014and when I say severe, I mean units literally bursting into flames. We worked around the clock, trying to catch the failure in-progress, and after about a week we finally realized what was happening.\" He said the problems were caused by certain games excessively seeking to different tracks on the disc (as opposed to continuously playing / streaming), leading to overheating of the motors which repositioned the laser head assembly.\nLaunch.\nAs early as 1990, magazines were covering a CD-ROM expansion for the Genesis. Sega announced the release of the Mega-CD in Japan for late 1991, and North America (as the Sega CD) in 1992. It was unveiled to the public at the 1991 Tokyo Toy Show, to positive reception from critics, and at the Consumer Electronic Show in Chicago in mid-1991. It was released in Japan on December 12, 1991, initially retailing at JP\u00a549,800. Though the Mega-CD sold quickly, the small install base of the Mega Drive in Japan meant that sales declined rapidly. Within its first three months, the Mega-CD sold 200,000 units, but only sold an additional 200,000 over the next three years. Third-party game development suffered because Sega took a long time to release software development kits. Other factors affecting sales included the high launch price of the Mega-CD in Japan and only two games available at launch, with only five published by Sega within the first year.\nOn October 15, 1992, the Mega-CD was released in North America as the Sega CD, with a retail price of US$299. Advertising included one of Sega's slogans, \"Welcome to the Next Level\". Though only 50,000 units were available at launch due to production problems, the Sega CD sold over 200,000 units by the end of 1992 and 300,000 by July 1993. As part of Sega's sales, Blockbuster purchased Sega CD units for rental in their stores. Sega of America emphasized that the Sega CD's additional storage space allowed for full-motion video (FMV), with Digital Pictures becoming an important partner. After the initial competition between Sega and Nintendo to develop a CD-based add-on, Nintendo canceled development of a CD add-on for the SNES after having partnered with Sony and then Philips to develop one.\nThe Mega-CD was launched in Europe in April 1993, starting with the United Kingdom on April 2, 1993, at a price of \u00a3269.99. The European version was packaged with \"Sol-Feace\" and \"Cobra Command\" in a two-disc set, along with a compilation CD of five Mega Drive games. Only 70,000 units were initially available in the UK, but 60,000 units were sold by August 1993. The Mega-CD was released in Australia in March 1993. Brazilian toy company Tectoy released the Sega CD in Brazil in October 1993, retaining the North American name despite the use of the name Mega Drive for the base console there.\nSega released a second model, the Sega CD 2 (Mega-CD 2), on April 23, 1993, in Japan. It was released in North America several months later at a price of US$229, bundled with one of the bestselling Sega CD games, \"Sewer Shark\". Designed to bring down the manufacturing costs of the Sega CD, the newer model is smaller and does not use a motorized disc tray. A limited number of games were developed that used the Sega CD and another Genesis add-on, the 32X, released in November 1994.\n\"Night Trap\" controversy.\nOn December 9, 1993, the United States Congress began hearings on video game violence and the marketing of violent video games to children. The Sega CD game \"Night Trap\", an FMV adventure game by Digital Pictures, was at the center of debate. \"Night Trap\" had been brought to the attention of United States Senator Joe Lieberman, who said: \"It ends with this attack scene on this woman in lingerie, in her bathroom. I know that the creator of the game said it was all meant to be a satire of \"Dracula\"; nonetheless, I thought it sent out the wrong message.\" Lieberman's research concluded that the average video game player was between seven and twelve years old, and that video game publishers were marketing violence to children.\nIn the United Kingdom, \"Night Trap\" was discussed in Parliament. Former Sega Europe development director Mike Brogan noted that \"Night Trap\" brought Sega publicity, and helped reinforce Sega's image as an \"edgy company with attitude\". Despite the increased sales, Sega recalled \"Night Trap\" and rereleased it with revisions in 1994. Following the congressional hearings, Sega and other video game manufacturers came together in 1994 to establish a unified rating system under the Entertainment Software Rating Board.\nDecline.\nBy the end of 1993, sales of the Sega CD had stalled in Japan and were slowing in North America. In Europe, sales of Mega-CD games were outpaced by games for the Amiga CD32. Newer CD-based consoles such as the 3DO Interactive Multiplayer rendered the Sega CD technically obsolete, reducing public interest. In late 1993, less than a year after the Sega CD had launched in North America and Europe, the media reported that Sega was no longer accepting in-house development proposals for the Mega-CD in Japan. By 1994, 1.5 million units had been sold in the United States and 415,000 in Western Europe. Kalinske blamed the Sega CD's high price for limiting its potential market; Sega attempted to add value in the US and the UK by bundling more games, with some packages including up to five games. \nIn early 1995, Sega shifted its focus to the Sega Saturn and discontinued advertising for Genesis hardware, including the Sega CD. Sega discontinued the Sega CD in the first quarter of 1996, saying that it needed to concentrate on fewer platforms and that the Sega CD could not compete due to its high price and outdated single-speed drive. According to Thorpe, the Sega CD only reached a more popular price point in 1995, by which time customers were willing to wait for newer consoles. The last scheduled Sega CD games, ports of \"Myst\" and \"Brain Dead 13\", were cancelled. 2.24 million Sega CD units were sold worldwide.\nTechnical specifications.\nThe Sega CD can only be used in conjunction with a Genesis system, attaching through an expansion slot on the side of the main console. It requires its own power supply. A core feature of the Sega CD is the increase in data storage by its games being CD-ROMs; whereas ROM cartridges of the day typically contained 8 to 16 megabits of data, a CD-ROM disc can hold more than 640 megabytes of data, more than 320 times the storage of a Genesis cartridge. This increase in storage allows the Sega CD to play FMV games. In addition to playing its own library of games in CD-ROM format, the Sega CD can also play compact discs and karaoke CD+G discs, and can be used in conjunction with the 32X to play 32-bit games that use both add-ons. The second model, also known as the Sega CD 2, includes a steel joining plate to be screwed into the bottom of the Genesis and an extension spacer to work with the original Genesis model.\nThe main CPU of the Sega CD is a 12.5\u00a0MHz 16-bit Motorola 68000 processor, which runs 5\u00a0MHz faster than the Genesis processor. It contains 1\u00a0Mbit of boot ROM, allocated for the CD game BIOS, CD player software, and compatibility with CD+G discs. 6.5\u00a0Mbit of RAM is allocated to data for programs, pictures, and sounds; 128\u00a0Kbit to CD-ROM data cache memory; and an additional 64\u00a0Kbit is allocated as the backup memory. Additional backup memory in the form of a 1\u00a0Mbit Backup RAM Cartridge was also available as a separate purchase, released near the end of the system's life. The graphics chip is a custom ASIC, and can perform similarly to the SNES's Mode 7, but with the ability to handle more objects at the same time. Audio is supplied through the Ricoh RF5C164, and two RCA pin jacks allow the Sega CD to output stereophonic sound separate from the Genesis. Combining stereo sound from a Genesis to either version of the Sega CD requires a cable between the Genesis's headphone jack and an input jack on the back of the CD unit. This is not required for the second model of the Genesis. Sega released an additional accessory to be used with the Sega CD for karaoke, including a microphone input and various sound controls.\nModels.\nSeveral models of the Sega CD were released. The original model used a front-loading motorized disc tray and sat underneath the Genesis. The second model was redesigned to sit next to the Genesis and featured a top-loading disc tray. Sega also released the Genesis CDX (Multi-Mega in Europe), a combined Genesis and Sega CD, with additional functionality as a portable CD player.\nThree additional system models were created by other electronics companies. Working with Sega, JVC released the Wondermega, a combination of the Genesis and Sega CD with high-quality audio, on April 1, 1992, in Japan. The Wondermega was redesigned by JVC and released as the X'Eye in North America in September 1994. Its high price kept it out of the hands of average consumers. Another console, the LaserActive by Pioneer Corporation, can play Genesis and Sega CD games if equipped with the Mega-LD attachment developed by Sega. The LaserActive was positioned to compete with the 3DO Interactive Multiplayer, but the combined system and Mega-LD pack retailed at too expensive a price for most consumers. Aiwa released the CSD-GM1, a combination Mega Drive and Mega CD unit built into a boombox. The CSD-GM1 was released in Japan in 1994.\nGames.\nThe Sega CD supports a library of more than 200 games created by Sega and third-party publishers. Six Sega CD games were also released in versions that used both the Sega CD and 32X add-ons. \nWell regarded Sega CD games include \"Sonic CD\", ', ', \"Popful Mail\", and \"Snatcher\", as well as the controversial \"Night Trap\". Although Sega created \"Streets of Rage\" for the Genesis to compete against the SNES port of the arcade hit \"Final Fight\", the Sega CD received an enhanced version of \"Final Fight\" that has been praised for its greater faithfulness to the arcade original. \"\" was noted for its impressive use of the Sega CD hardware as well as its violent content. In particular, \"Sonic CD\" garnered acclaim for its graphics and time travel gameplay, which improved upon the traditional \"Sonic\" formula. The Sega CD also received enhanced ports of Genesis games including \"Batman Returns\" and \"Ecco the Dolphin\".\nThe Sega CD library includes several FMV games, such as \"Night Trap, Dragon's Lair\" and \"Space Ace\". FMV quality was substandard on the Sega CD due to poor video compression software and limited color palette, and the concept never caught on with the public. According to Digital Pictures founder Tom Zito, the Sega CD's limited color palette created \"a horrible grainy look\". Likewise, most Genesis ports for the Sega CD featured additional FMV sequences, extra levels, and enhanced audio, but were otherwise identical to their Genesis release. The video quality in these sequences has been criticized as comparable to an old VHS tape.\nGiven a large number of FMV games and Genesis ports, the Sega CD's game library has been criticized for its lack of depth. Kalinske felt this was a valid criticism, and that while it was useful for releasing collections of games, \"just doing cartridge games on a CD-ROM was not a step forward\". According to Thorpe, the Sega CD's games did not display enough advancement to justify the console price for most consumers. He felt that FMV games, targeted toward more casual players, were not enough to satisfy hardcore players.\nReception and legacy.\nNear the time of its release, the Sega CD was awarded Best New Peripheral of 1992 by \"Electronic Gaming Monthly\". Four separate reviews scored the add-on 8, 9, 8, and 8 out of 10; reviewers cited its upgrades to the Genesis as well as its high-quality and expanding library of games. In 1995, four \"Electronic Gaming Monthly\" reviewers scored it 5 out of 10, citing its limited game library and substandard video quality. \"GamePro\" cited the same problems, noting that many games were simple ports of cartridge games with minimal enhancements; \"GamePro\" concluded that the Sega CD was merely \"a big memory device with CD sound\" rather than a meaningful upgrade. They gave it a \"thumbs sideways\" and recommended that Genesis fans buy an SNES before considering a Sega CD. In a special Game Machine Cross Review in May 1995, \"Famicom Ts\u016bshin\" scored the Japanese Mega-CD 2 17 out of 40.\nRetrospective reception of the Sega CD has been mixed, praising certain games but criticizing its value for money and limited upgrades over Genesis. According to \"GamePro,\" the Sega CD is the seventh-lowest-selling console; reviewer Blake Snow wrote: \"The problem was threefold: the device was expensive at $299, it arrived late in the 16-bit life cycle, and it didn't do much (if anything) to enhance the gameplay experience.\" However, Snow felt that the Sega CD had the greatest \"Sonic\" game in \"Sonic CD\". \"IGN\"'s Levi Buchanan criticized Sega's implementation of CD technology, arguing that it offered no new gameplay concepts. Jeremy Parish of \"USgamer\" wrote that Sega was not the only company of the period to \"muddy its waters\" with a CD add-on, and highlighted some \"gems\" for the system, but that \"the benefits offered by the Sega CD had to be balanced against the fact that the add-on more than doubled the price (and complexity) of the [Genesis].\" In a separate article for \"1Up.com\", Parish praised the Sega CD's expansion of value to the Genesis. Writing for \"Retro Gamer\", Damien McFerran cited various reasons for the Sega CD's limited sales, including its price, lack of significant enhancement to the Genesis, and the fact that it was not a standalone console. \"Retro Gamer\" writer Aaron Birch, defended the Sega CD as \"ahead of its time\" and said that game developers had failed to meet the potential of CD technology.\nSega's poor support for the Sega CD has been criticized as the first step in the devaluation of the Sega brand. Writing for \"IGN\", Buchanan said the Sega CD, released without a strong library of games, \"looked like a strange, desperate move\u2014something designed to nab some ink but without any real, thought-out strategy. Genesis owners that invested in the add-on were sorely disappointed, which undoubtedly helped sour the non-diehards on the brand.\" In \"GamePro\", Snow wrote that the Sega CD was the first of several poorly supported Sega systems, which damaged the value of the brand and ultimately led to Sega's exit from the hardware market. Thorpe wrote that, while it was possible for Sega to have brushed off the Sega CD's failure, the failure of the Sega CD and the 32X together damaged faith in Sega's support for its platforms.\nFormer Sega of America senior producer Scot Bayless attributes the unsuccessful market to a lack of direction from Sega with the add-on. According to Bayless, \"It was a fundamental paradigm shift with almost no thought given to consequences. I honestly don't think anyone at Sega asked the most important question: 'Why?' There's a rule I developed during my time as an engineer in the military aviation business: never fall in love with your tech. I think that's where the Mega-CD went off the rails. The whole company fell in love with the idea without ever really asking how it would affect the games you made.\" Sega of America producer Michael Latham said he \"loved\" the Sega CD, and that it had been damaged by an abundance of \"Hollywood interactive film games\" instead of using it to make \"just plain great video games\". Former Sega Europe president Nick Alexander said: \"The Mega CD was interesting but probably misconceived and was seen very much as the interim product it was.\" Kalinske said that the Sega CD had been an important learning experience for Sega for programming for discs, and that it was not a mistake but not \"as dramatically different as it needed to be\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29033", "revid": "42783819", "url": "https://en.wikipedia.org/wiki?curid=29033", "title": "Sega Pico", "text": "Educational video game console\nThe Sega Pico, also known as is an educational video game console by Sega Toys. The Pico was released in June 1993 in Japan and November 1994 in North America and Europe. Sales in South Korea and China began in 1995 and 2002 respectively. \nMarketed as \"edutainment\", the main focus of the Pico was educational video games for children between 3 and 7 years old. Releases for the Pico were focused on education for children and included titles supported by licensed franchised animated characters, including Sega's own \"Sonic the Hedgehog\" series.\nThough the Pico was sold continuously in Japan through the release of the Beena, in North America and Europe the Pico was less successful and was discontinued in early 1998, later being re-released by Majesco Entertainment. Overall, Sega claims sales of 3.4 million Pico consoles and 11.2 million game cartridges, and over 350,000 Beena consoles and 800,000 cartridges. It was succeeded by the Advanced Pico Beena, released in Japan in 2005. The ePico, the successor to the Pico and Beena, was also released in Japan in 2024.\nDesign and software.\nPowered by the same hardware used in the Sega Genesis, the physical shape of the Pico was designed to appear similar to a laptop. Included in the Pico is a stylus called the \"Magic Pen\", and a pad to draw on. Controlling the games for the system is accomplished either by using the Magic Pen like a mouse, or by pressing the directional buttons on the console. The Pico does not include a screen, and instead must be connected to a monitor through the composite video output. Touching the pen to the pad allows drawing, or moving/animating a character on the screen.\nCartridges for the system were referred to as \"Storyware\", and took the form of picture books with a cartridge slot on the bottom. The Pico changes the television display and the set of tasks for the player to accomplish each time a page is turned. Sound, including voices and music, also accompanied every page. Games for the Pico focused on education, including subjects such as music, counting, spelling, reading, matching, and coloring. Titles included licensed animated characters from various franchises, such as \"Disney's The Lion King: Adventures at Pride Rock\" and \"A Year at Pooh Corner\". Sega also released titles including their mascot, Sonic the Hedgehog, including \"Sonic Gameworld\" and \"Tails and the Music Maker\".\nAccording to former Sega console hardware research and development head Hideki Sato, the development of the Sega Pico was possible due to the company's past work on the My Card cartridges developed for the SG-1000, as well as on drawing tablets. The sensor technology used in the pad came from that developed for the 1987 arcade game \"World Derby\", while its CPU and graphics chip came from the Genesis. The Pico excludes the Genesis's sound coprocessor and FM sound chip, the Zilog Z80 and Yamaha YM2612 respectively, leaving only the Texas Instruments SN76489 PSG integrated onto the console's graphics chip as the main sound generator alongside the addition of an NEC \u03bcPD7759 ADPCM chip that was borrowed from Sega's arcade system boards of the time such as the System 16B and System C2.\nHistory.\nAt a price of \u00a5, the Pico was released in Japan in June 1993. In North America, Sega unveiled the Pico at the 1994 American International Toy Fair, showcasing its drawing and display abilities ahead of its release in November. The console was advertised at a price of approximately US$160, but was eventually released at a price of US$. \"Storyware\" cartridges sold for . The Pico's slogan was \"The computer that thinks it's a toy.\" The Sega Pico won a few awards, including the \"National Parenting Seal of Approval\", a \"Platinum Seal Award\", and a gold medal from the \"National Association of Parenting Publications Awards\".\nAfter a lack of success, Sega discontinued the Pico in North America in early 1998. Later, in August 1999, a remake of the Pico made by Majesco Entertainment was released in North America at a price of US$, with Storyware titles selling at US$. The Pico would later be released in China in 2002, priced at CN\u00a5.\nIn early 1995, Sega of America reported that it had sold 400,000 units in North America. In 2000, Sega claimed that the Pico had sold units. As of April 2005, Sega claims that Pico consoles and software cartridges had been sold worldwide. The Pico was recognized in 1995 by being listed on Dr. Toy's 100 Best Products, as well as being listed in \"Child\" as one of the best computer games available. According to Joseph Szadkowski of \"The Washington Times\", \"Pico has enough power to be a serious learning aid that teaches counting, spelling, matching, problem-solving, memory, logic, hand/eye coordination and important, basic computer skills.\" Former Sega of America vice president of product development Joe Miller claims that he named his dog after the system because of his passion for the console. By contrast, Steven L. Kent claims that Sega of Japan CEO Hayao Nakayama watched the Pico \"utterly fail\" in North America.\nYamaha Copera.\nIn December 1993, Yamaha released the Copera in Japan at a price of \u00a5. The Copera is an enhanced variant of the Pico designed for musical education, with additional sound hardware such as an 18-channel Yamaha FM sound chip based on the OPL3 and a four-channel PCM audio chip, stereo audio output, a microphone input, and two MIDI ports. It is compatible with all Pico software, as well as dedicated software making use of the enhanced hardware known as 'Mixt Books', which are not compatible with regular Pico hardware.\nAdvanced Pico Beena.\nThe Advanced Pico Beena, also known simply as Beena or BeenaLite, is an educational console system targeted at young children sold by Sega Toys, released in 2005 in Japan. It is the successor to the Pico, and marketed around the \"learn while playing\" concept. According to Sega Toys, the focus of the Advanced Pico Beena is on learning in a new social environment, and is listed as their upper-end product. Topics listed as being educational focuses for the Beena include intellectual, moral, physical, dietary, and safety education. The name of the console was chosen to sound like the first syllables of \"Be Natural\".\nCompared to the Pico, Beena adds several functions. Beena can be played without a television, and supports multiplayer via a separately sold additional Magic Pen. The console also supports data saving. Playtime can be limited by settings in the system. Some games for the Beena offer adaptive difficulty, becoming more difficult to play based on the skill level of the player. The Beena Lite, a more affordable version of the console, was released on July 17, 2008. As of 2010, Sega estimated that 4.1 million Beena consoles had been sold, along with 20 million game cartridges.\nIn 2014, Sega launched the educational mobile app Telebeena that could be paired with a (Sharp) smart TV.\nePico.\nThe ePico is an educational console system targeted at young children sold by Sega Fave, released on October 10, 2024 in Japan. It is the successor to the Advanced Pico Beena.\nThe ePico is similar in nature to the Cocopad (the Japanese version of the LeapPad) and requires special picture book software to function, as with the Pico and Beena among others, however it is not compatible with Pico, Beena, or Cocopad/LeapPad software. The ePico also uses a special mat that allows it to be used without relying on the stylus (also called Magic Pen), and has an additional function that is planned to be developed for the \"ePico Enthusiasm Report,\" a personal page for parents that will report on what their child is interested in using the \"multiple intelligences theory\" developed at Harvard University.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29034", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=29034", "title": "Sega VR", "text": "Video console peripheral\nThe Sega VR is an unreleased virtual reality headset developed by Sega in the early 1990s. Planned as an add-on peripheral for the Sega Genesis and only publicly showcased at a number of trade shows and expositions, its release was postponed and later cancelled outright after Sega ran into development issues. At least four in-progress games for the hardware were in development before its cancellation.\nThe project was largely driven by Sega of America; a more successful, separate, and officially released attempt at a virtual reality headset, the Mega Visor Display, was overseen by Sega's Japanese amusement divisions and United Kingdom-based collaborators Virtuality, and would be used in the VR-1 theme park ride and the \"Dennou Senki Net Merc\" arcade game. The similarly titled VR-1 is not to be confused with the Sega VR.\nFeatures.\nThe Sega VR's design was based on an IDEO virtual reality head-mounted display containing LCD screens in the visor and stereo headphones. The headset tracking solution was developed by a small electronics company called Ono-Sendai that had been experimenting with VR headsets. The method employed was only capable of tracking two degrees of freedom but was very inexpensive, costing only around $1 per unit, making it affordable for the consumer market. The device used a magnetometer to detect azimuth relative to the Earth's magnetic field and an optical sensor measuring the refraction of light at the boundary of a gas and fluid to detect tilt.\nDevelopment.\nSega of America, flush with funds from the success of its Mega Drive/Genesis, announced the peripheral in 1991. It was later seen in 1993 at the Consumer Electronics Show (CES) in Chicago, where it was demonstrated by Alan Hunter and appeared close to a finished product. The event stated that the headset was planned to use the Genesis hardware and would be released in late 1993 at US$ with four confirmed launch games and the possibility of a port of arcade game \"Virtua Racing\". Sega later announced release was slated for early 1994, according to \"Electronic Games\".\nThe Sega VR headset was never released to the general public and it vanished from release schedules in 1994. There are conflicting reports as to why the product was cancelled. Sega officially claimed to have terminated the project because the virtual reality effect was \"too realistic\", so users might move while wearing the headset and injure themselves. However, Tom Kalinske, then president and CEO of Sega of America, stated that the system would not be released due to reports of it inducing motion sickness and severe headaches in users. Mark Pesce, who worked on the Sega VR project, says a SRI International conducted research on the product and warned Sega of the \"hazards of prolonged use\".\nGames.\nOnly four original games are known to have been in development.\nSega also announced a port of Sega AM2's hit 1992 arcade game \"Virtua Racing\" as a launch game for the device, though it is not known how far this reached in development.\nLegacy.\nFollowing the cancellation of the Sega VR, a few further attempts were made by Sega to develop virtual reality technology. A similar peripheral was reportedly made, but never seen, for the Saturn.\nWhile Sega of America undertook development on the Sega VR, Sega of Japan endeavoured to create their own virtual reality project. Sega entered into an agreement to collaborate with the pioneering Virtuality Group on a VR arcade project in 1993. Following this the two companies entered into negotiations to build a new headset by combining their previous development assets in the field of VR.\nThe result of the agreement was the Mega Visor Display, publicly released for the first time in July 1994 as part of the VR-1 attraction installed at Sega's flagship Joypolis indoor theme parks in Japan, as well as SegaWorld London and Sega World Sydney. Alongside the attraction, the MVD was praised in reviews at the time for its advancements in ergonomic design and graphical output, and was supposedly not fully matched in performance until the 2010s.\nA second project to utilize the Mega Visor Display, the \"Dennou Senki Net Merc\" arcade game, was later demonstrated at Japan's 1995 AOU (Amusement Operators Union) show, using the Sega Model 1 arcade system board to produce its 3D graphics. \"Net Merc\" subsequently received much more muted reception, with the game's flat-shaded graphics compared unfavourably to the Sega Model 2's textured-filtered graphics when showcased.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29035", "revid": "18438347", "url": "https://en.wikipedia.org/wiki?curid=29035", "title": "Sega Saturn", "text": "Home video game console\nThe is a home video game console developed by Sega and released on November 22, 1994, in Japan, May 11, 1995, in North America, and July 8, 1995, in Europe. Part of the fifth generation of video game consoles, it is the successor to the successful Genesis. The Saturn has a dual-CPU architecture and eight processors. Its games are in CD-ROM format, including several ports of arcade games and original games.\nDevelopment of the Saturn began in 1992, the same year Sega's groundbreaking 3D Model 1 arcade hardware debuted. The Saturn was designed around a new CPU from the Japanese electronics company Hitachi. Another video display processor was added in early 1994 to better compete with the 3D graphics of Sony's forthcoming PlayStation.\nThe Saturn was initially successful in Japan but not in the United States, where it was hindered by a surprise May 1995 launch, four months before its scheduled release date. After the debut of the Nintendo 64 in late 1996, the Saturn rapidly lost market share in the US, where it was discontinued in 1998. The Saturn is considered a commercial failure; this was affected by the cancellation of \"Sonic X-treme\", planned as the first 3D entry in Sega's popular \"Sonic the Hedgehog\" series. The Saturn was succeeded in 1998 by the Dreamcast, having sold 9.26 million units sold worldwide, most in Japan.\nThe Saturn has several well-regarded games, including \"Nights into Dreams\", the \"Panzer Dragoon\" series, and the \"Virtua Fighter\" series, although much of its library was confined to the Japanese market where the system fared better than it did in the West. The Saturn's reception is mixed due to its complex hardware design and limited third-party support; Sega's management has been criticized for its decisions during the Saturn's development and discontinuation.\nHistory.\nBackground.\nIn the early 1990s, Sega had success with the Genesis (known as the Mega Drive in most countries outside of North America), backed by aggressive advertising campaigns and the popularity of its \"Sonic the Hedgehog\" series. Sega also had success with arcade games; in 1992 and 1993, the new Sega Model 1 arcade system board showcased Sega AM2's \"Virtua Racing\" and \"Virtua Fighter\" (the first 3D fighting game), crucial to popularizing 3D polygonal graphics. The Model 1 was expensive, so several alternatives helped bring Sega's newest arcade games to Genesis, such as the Virtua Processor chip used for \"Virtua Racing\", and the 32X add-on.\nDevelopment.\nDevelopment of the Saturn was supervised by Hideki Sato, Sega's director and deputy general manager of research and development. According to project manager Hideki Okamura, the project codenamed Saturn started over two years before its announcement at the Tokyo Toy Show in June 1994. It was developed by the same team that developed the System 32 arcade board. Sato regrets that he did not go with the Model 1 arcade hardware as a base, as he was too concerned of leaving all the developers behind that were focused on sprites rather than 3D, which were the majority of developers.\nIn 1993, Sega and the Japanese electronics company Hitachi formed a joint venture to develop a new CPU for the Saturn, which resulted in the creation of the \"SuperH RISC Engine\" (or SH-2) later that year. The Saturn was designed around a dual-SH2 configuration. According to Kazuhiro Hamada, Sega's section chief for Saturn development during the system's conception, \"the SH-2 was chosen for reasons of cost and efficiency. The chip has a calculation system similar to a DSP [digital signal processor], but we realized that a single CPU would not be enough to calculate a 3D world.\" Although the Saturn's design was largely finished before the end of 1993, reports in early 1994 of the technical capabilities of Sony's upcoming PlayStation console prompted Sega to include another video display processor (VDP) to improve 2D performance and 3D texture mapping. Sega considered making CD-ROM-based and cartridge-only versions of the Saturn, but discarded the idea due to concerns over the lower quality and higher price of cartridge games.\nAccording to president Tom Kalinske, Sega of America \"fought against the architecture of Saturn for quite some time\". Seeking an alternative graphics chip for the Saturn, Kalinske attempted to broker a deal with Silicon Graphics, but Sega of Japan rejected the proposal. Silicon Graphics subsequently collaborated with Nintendo on the Nintendo 64. Kalinske, Sony Electronic Publishing's Olaf Olafsson, and Sony America's Micky Schulhof had discussed development of a joint \"Sega/Sony hardware system\", which never materialized due to Sega's desire to create hardware for both 2D and 3D visuals and Sony's competing notion of focusing on 3D technology. Publicly, Kalinske defended the Saturn's design: \"Our people feel that they need the multiprocessing to be able to bring to the home what we're doing next year in the arcades.\"\nIn 1993, Sega restructured its internal studios in preparation for the Saturn's launch. To ensure high-quality 3D games would be available early in the Saturn's life, and to create a more energetic working environment, developers from Sega's arcade division were asked to create console games. New teams, such as the \"Panzer Dragoon\" developer Team Andromeda, were formed during this time. In early 1994, the Sega Titan Video arcade system was announced as an arcade counterpart to the Saturn. In April 1994, Acclaim Entertainment announced it would be the first American publisher to produce software for the Titan.\nIn January 1994, Sega began to develop the 32X add-on for the Genesis, as a less expensive entry into the 32-bit era. The 32X was approved by Sega CEO Hayao Nakayama and widely supported by Sega of America employees. According to the former Sega of America producer Scot Bayless, Nakayama was worried that the Saturn would not be available until after 1994 and that the recently released Atari Jaguar would reduce Sega's hardware sales. As a result, Nakayama ordered his engineers to have the system ready for launch by the end of the year. The 32X would not be compatible with the Saturn, but Sega executive Richard Brudvik-Lindner pointed out that the 32X would play Genesis games, and had the same system architecture as the Saturn. This was justified by Sega's statement that both platforms would run at the same time, and that the 32X would be aimed at players who could not afford the more expensive Saturn. According to Sega of America research and development head Joe Miller, the 32X familiarized development teams with the dual SH-2 architecture also used in the Saturn. Because the machines share many parts and were prepared to launch around the same time, tensions emerged between Sega of America and Sega of Japan when the Saturn was given priority.\nLaunch.\nSega released the Saturn in Japan on November 22, 1994, at a price of \u00a544,800 (equivalent to at the time). \"Virtua Fighter\", a faithful port of the popular arcade game, sold at a nearly one-to-one ratio with the Saturn console at launch and was crucial to the system's early success in Japan. Though Sega had wanted to launch with \"Clockwork Knight\" and \"Panzer Dragoon\", the only other first-party game available at launch was \"Wan Chai Connection\". Boosted by the popularity of \"Virtua Fighter\", Sega's initial shipment of 200,000 Saturn units sold out on the first day. Sega waited until the December 3 launch of the PlayStation to ship more units; when both were sold side by side, the Saturn proved more popular.\nMeanwhile, Sega released the 32X on November 21, 1994, in North America, December 3, 1994, in Japan, and January 1995 in PAL territories, at less than half of the Saturn's launch price. After the holiday season, however, interest in the 32X rapidly declined. Half a million Saturn units were sold in Japan by the end of 1994 (compared to 300,000 PlayStation units), and sales exceeded 1\u00a0million within the following six months. There were conflicting reports that the PlayStation had a higher sell-through rate, and the system gradually began to overtake the Saturn in sales during 1995. Sony attracted many third-party developers to the PlayStation with a liberal $10 licensing fee, excellent development tools, and the introduction of a 7- to 10-day order system that allowed publishers to meet demand more efficiently than the 10- to 12-week lead times for cartridges that had previously been standard in the Japanese video game industry.\nIn March 1995, Sega of America CEO Tom Kalinske announced the Saturn's launch in the U.S. on \"Saturnday\" (Saturday), September 2, 1995.&lt;ref name=\"Saturnday/1:1\"&gt;&lt;/ref&gt; However, Sega of Japan mandated an early launch to give the Saturn an advantage over the PlayStation. At the first Electronic Entertainment Expo (E3) in Los Angeles on May 11, 1995, Kalinske gave a keynote presentation in which he revealed the release price of $ (including a copy of \"Virtua Fighter\"), and described the features of the console. Kalinske also revealed that, due to \"high consumer demand\", Sega had already shipped 30,000 Saturns to Toys \"R\" Us, Babbage's, Electronics Boutique, and Software Etc. for immediate release. The announcement upset retailers who were not informed of the surprise release, including Best Buy and Walmart; KB Toys, which was not part of the early launch, responded by refusing to carry the Saturn and its games. Sony subsequently unveiled the retail price for the PlayStation; Olaf Olafsson, the head of Sony Computer Entertainment America (SCEA), summoned Steve Race to the stage, who uttered \"$299\", and then walked away to applause. The Saturn's release in Europe also came before the previously announced North American date, on July 8, 1995, at \u00a3399.99. European retailers and press did not have time to promote the system or its games, harming sales. The PlayStation launched in Europe on September 29, 1995; by November, it had already outsold the Saturn by a factor of three in the United Kingdom, where Sony had allocated \u00a320\u00a0million of marketing during the holiday season compared to Sega's \u00a34\u00a0million.\nThe Saturn's U.S. launch was accompanied by a reported $50\u00a0million advertising campaign including coverage in publications such as \"Wired\" and \"Playboy\". Early advertising for the system was targeted at a more mature, adult audience than the Genesis ads. The early rescheduling yielded only six launch games (all published by Sega) because most third-party games were scheduled around the original launch date. \"Virtua Fighter\"'s relative lack of popularity in the West, combined with a release schedule of only two games between the surprise launch and September 1995, prevented Sega from capitalizing on the Saturn's early timing. Within two days of its North American launch on September 9, 1995, the PlayStation, backed by a large marketing campaign, had more units sold than the Saturn had in the five months following its surprise launch, with almost all of the initial shipment of 100,000 units being sold in advance, and the rest selling out across the U.S.\nA high-quality port of the Namco arcade game \"Ridge Racer\" contributed to the PlayStation's early success, and garnered favorable media in comparison to the Saturn version of Sega's \"Daytona USA\", which was considered inferior to its arcade counterpart. Namco, a longtime arcade competitor with Sega, also unveiled the Namco System 11 arcade board, based on raw PlayStation hardware. Although the System 11 is technically inferior to Sega's Model 2 arcade board, its lower price made it attractive to smaller arcades. Following a 1994 acquisition of Sega developers, Namco released \"Tekken\" for the System 11 and PlayStation. Directed by former \"Virtua Fighter\" designer Seiichi Ishii, \"Tekken\" was intended to be fundamentally similar, with the addition of detailed textures and twice the frame rate. \"Tekken\" surpassed \"Virtua Fighter\" in popularity due to its superior graphics and nearly arcade-perfect console port, becoming the first million-selling PlayStation game.\nOn October 2, Sega announced a Saturn price reduction to $299. High-quality Saturn ports of the Sega Model 2 arcade hits \"Sega Rally Championship\", \"Virtua Cop\", and \"Virtua Fighter 2\" (running at 60 frames per second at a high resolution) were available by the end of the year and were generally regarded as superior to competitors on the PlayStation. Notwithstanding a subsequent increase in Saturn sales during the 1995 holiday season, the games were not enough to reverse the PlayStation's decisive lead. By 1996, the PlayStation had a considerably larger library than the Saturn, although Sega hoped to generate interest with upcoming exclusives such as \"Nights into Dreams\". An informal survey of retailers showed that the Saturn and PlayStation sold in roughly equal numbers during the first quarter of 1996. Within its first year, the PlayStation secured over 20% of the entire U.S. video game market. On the first day of the May 1996 E3 show, Sony announced a PlayStation price reduction to $199, a reaction to the release of the Model 2 Saturn in Japan at a price roughly equivalent to $199. On the second day, Sega announced it would match this price, though Saturn hardware was more expensive to manufacture.\nChanges at Sega.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nI thought the world of [Hayao] Nakayama because of his love of software. We spoke about building a new hardware platform that I would be very, very involved with, shape the direction of this platform, and hire a new team of people and restructure Sega. That, to me, was a great opportunity.\n\u2014Bernie Stolar on joining Sega of America\nAfter the launch of the PlayStation and Saturn, sales of 16-bit games and consoles continued to account for 64% of the video game market in 1995. Sega underestimated the continued popularity of the Genesis, and did not have the inventory to meet demand. Sega was able to capture 43% of the dollar share of the U.S. video game market and sell more than 2\u00a0million Genesis units in 1995, but Kalinske estimated that \"we could have sold another 300,000 Genesis systems in the November/December timeframe.\" Nakayama's decision to focus on the Saturn over the Genesis, based on the systems' relative performance in Japan, has been cited as the major contributing factor in this miscalculation.\nDue to long-standing disagreements with Sega of Japan, Kalinske lost interest in his work as CEO of Sega of America. By early 1996, rumors were circulating that Kalinske planned to leave Sega, and a July 13 article in the press reported speculation that Sega of Japan was planning significant changes to Sega of America's management. On July 16, 1996, Sega announced that Kalinske would leave Sega after September 30, and that Shoichiro Irimajiri had been appointed chairman and CEO of Sega of America. A former Honda executive, Irimajiri had been involved with Sega of America since joining Sega in 1993. Sega also announced that David Rosen and Nakayama had resigned from their positions as chairman and co-chairman of Sega of America, though both remained with the company. Bernie Stolar, a former executive at Sony Computer Entertainment of America, was named Sega of America's executive vice president in charge of product development and third-party relations. Stolar, who had arranged a six-month PlayStation exclusivity deal for \"Mortal Kombat 3\" and helped build close relations with Electronic Arts while at Sony, was perceived as a major asset by Sega officials. Finally, Sega of America made plans to expand its PC software business.\nStolar was not supportive of the Saturn, deciding it was poorly designed, and publicly announced at E3 1997 that \"the Saturn is not our future\". Though Stolar had \"no interest in lying to people\" about the Saturn's prospects, he continued to emphasize quality games for the system, and later said that \"we tried to wind it down as cleanly as we could for the consumer\". At Sony, Stolar had opposed the localization of Japanese games that he decided would not represent PlayStation well in North America, and advocated a similar policy for the Saturn, although he later sought to distance himself from his actions. These changes were accompanied by a softer image that Sega was beginning to portray in its advertising, including removing the \"Sega!\" scream and holding press events for the education industry. Marketing for the Saturn in Japan also changed with the introduction of Segata Sanshiro (played by Hiroshi Fujioka), a character in a series of TV advertisements starting in 1997; the character eventually starred in a Saturn game.\nTemporarily abandoning arcade development, Sega AM2 head Yu Suzuki began developing several Saturn-exclusive games, including a role-playing game in the \"Virtua Fighter\" series. Initially conceived as an obscure prototype, \"The Old Man and the Peach Tree\", and intended to address the flaws of contemporary Japanese RPGs (such as poor non-player character artificial intelligence routines), \"Virtua Fighter RPG\" evolved into a planned 11-part, 45-hour \"revenge epic in the tradition of Chinese cinema\", which Suzuki hoped would become the Saturn's killer app. The game was eventually released as \"Shenmue\" for the Saturn's successor, the Dreamcast.\nCancellation of \"Sonic X-treme\".\nAs Sonic Team was working on \"Nights into Dreams\", Sega tasked the U.S.-based Sega Technical Institute (STI) with developing the first fully 3D entry in its popular \"Sonic the Hedgehog\" series. The game, \"Sonic X-treme\", was moved to the Saturn after several prototypes for other hardware (including the 32X) were discarded. It featured a fisheye lens camera system that rotated levels with Sonic's movement. After Nakayama ordered the game be reworked around the engine created for its boss battles, the developers were forced to work between 16 and 20 hours a day to meet their December 1996 deadline. Weeks of development were wasted after Stolar rescinded STI's access to Sonic Team's \"Nights into Dreams\" engine following an ultimatum by \"Nights\" programmer Yuji Naka. After programmer Ofer Alon quit and designers Chris Senn and Chris Coffin became ill, \"Sonic X-Treme\" was cancelled in early 1997. Sonic Team started work on an original 3D \"Sonic\" game for the Saturn, but development shifted to the Dreamcast as \"Sonic Adventure\". STI was disbanded in 1996 as a result of changes in management at Sega of America.\nJournalists and fans have speculated about the impact a completed \"X-treme\" might have had on the market. David Houghton of \"GamesRadar\" described the prospect of \"a good 3D \"Sonic\" game\" on the Saturn as \"a 'What if...' situation on a par with the dinosaurs not becoming extinct\". \"IGN\"'s Travis Fahs called \"X-treme\" \"the turning point not only for Sega's mascot and their 32-bit console, but for the entire company [and] an empty vessel for Sega's ambitions and the hopes of their fans\". Dave Zdyrko, who operated a prominent Saturn fan website during the system's lifespan, said: \"I don't know if [\"X-treme\"] could've saved the Saturn, but\u00a0[...] \"Sonic\" helped make the Genesis and it made absolutely no sense why there wasn't a great new \"Sonic\" title ready at or near the launch of the [Saturn].\" In a 2007 retrospective, producer Mike Wallis maintained that \"X-treme\" \"definitely would have been competitive\" with Nintendo's \"Super Mario 64\". \"Next Generation\" reported in late 1996 that \"X-treme\" would have harmed Sega's reputation if it did not compare well to contemporary competition. Naka said he had been relieved by the cancellation, because the game was not promising.\nDecline.\nFrom 1993 to early 1996, although Sega's revenue declined as part of an industry-wide slowdown, the company retained control of 38% of the U.S. video game market (compared to Nintendo's 30% and Sony's 24%). Eight hundred thousand PlayStation units were sold in the U.S. by the end of 1995, compared to 400,000 Saturn units. In part due to an aggressive price war, the PlayStation outsold the Saturn by two to one in 1996, and Sega's 16-bit sales declined markedly. By the end of 1996, the PlayStation had 2.9\u00a0million units sold in the U.S., more than twice the 1.2\u00a0million Saturn units sold. The Christmas 1996 \"Three Free\" pack, which bundled the Saturn with \"Daytona USA\", \"Virtua Fighter 2\", and \"Virtua Cop\", drove sales dramatically and ensured the Saturn remained a competitor into 1997.\nHowever, the Saturn failed to take the lead. After the launch of the Nintendo 64 in 1996, sales of the Saturn and its games were sharply reduced, and the PlayStation outsold the Saturn by three-to-one in the U.S. in 1997. The 1997 release of \"Final Fantasy VII\" significantly increased the PlayStation's popularity in Japan. The game helped push PlayStation sales ahead of the Saturn in Japan, after the PlayStation and Saturn had been very close in Japan prior to the game's release. As of August 1997, Sony controlled 47% of the console market, Nintendo 40%, and Sega only 12%. Neither price cuts nor high-profile game releases proved helpful. Reflecting decreased demand for the system, worldwide Saturn shipments during March to September 1997 declined from 2.35\u00a0million to 600,000 versus the same period in 1996; shipments in North America declined from 800,000 to 50,000. Due to the Saturn's poor performance in North America, 60 of Sega of America's 200 employees were laid off in late 1997.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nI thought the Saturn was a mistake as far as hardware was concerned. The games were obviously terrific, but the hardware just wasn't there.\n\u2014Bernie Stolar, former president of Sega of America, assessed the Saturn in 2009.\nAs a result of Sega's deteriorating financial situation, Nakayama resigned as president in January 1998 in favor of Irimajiri. Stolar subsequently acceded to president of Sega of America. Following five years of generally declining profits, in the fiscal year ending March 31, 1998, Sega suffered its first parent and consolidated financial losses since its 1988 listing on the Tokyo Stock Exchange. Due to a 54.8% decline in consumer product sales (including a 75.4% decline overseas), the company reported a net loss of \u00a543.3\u00a0billion ($) and a consolidated net loss of \u00a535.6\u00a0billion ($).\nShortly before announcing its financial losses, Sega announced that it was discontinuing the Saturn in North America to prepare for the launch of its successor. Only 7 Saturn games were released in North America in 1998 (\"Magic Knight Rayearth\" is the final official release), compared to 119 in 1996. The Saturn lasted longer in Japan, with Irimajiri announcing in early 1998 that Sega would continue supporting the Saturn in Japan after its successor was released. Between June 1996 and August 1998, a further 1,103,468 consoles and 29,685,781 games were sold in Japan, giving the Saturn a Japanese attach rate of 16.71 games per console, the highest of that generation. As of February 1997, the attach rate was four games per console worldwide.\nRumors about the upcoming Dreamcast, spread mainly by Sega, were leaked to the public before the last Saturn games were released. The Dreamcast was released on November 27, 1998, in Japan and on September 9, 1999, in North America. The decision to abandon the Saturn effectively left the Western market without Sega games for over one year. Sega suffered an additional \u00a542.881\u00a0billion consolidated net loss in the fiscal year ending March 1999 and announced plans to eliminate 1,000 jobs, nearly a quarter of its workforce.\nWorldwide Saturn sales include at least the following amounts in each territory: 5.75\u00a0million in Japan (surpassing Genesis sales of 3.58\u00a0million there), 1.8\u00a0million in the United States, 1\u00a0million in Europe, and 530,000 elsewhere. With lifetime sales of 9.26\u00a0million units, the Saturn is considered a commercial failure, although its install base in Japan, where it did better than the West, surpassed the Nintendo 64's 5.54\u00a0million, where it became Sega's highest-selling home console. The Saturn ultimately shipped more than 6 million units in Japan. Lack of distribution has been cited as a significant factor of the Saturn's failure, because the system's surprise launch had damaged Sega's reputation with key retailers. Conversely, Nintendo's long delay in releasing a 3D console and damage to Sega's reputation caused by poorly supported Genesis add-ons are considered major factors allowing Sony's establishment in the video game market.\nTechnical specifications.\nFeaturing eight processors, the Saturn's central processing units are two Hitachi SH-2 microprocessors clocked at 28.6\u00a0MHz and capable of 56 MIPS. It uses a Motorola 68EC000 running at 11.3\u00a0MHz as a sound controller; a custom sound processor with an integrated Yamaha FH1 DSP running at 22.6\u00a0MHz capable of up to 32 sound channels with both FM synthesis and 16-bit 44.1\u00a0kHz pulse-code modulation; and two video display processors: the VDP1 (which handles sprites and polygons) and the VDP2 (which handles backgrounds). Its double-speed CD-ROM drive is controlled by a dedicated Hitachi SH-1 processor to reduce load time. The System Control Unit (SCU), which controls all buses and functions as a co-processor of the main SH-2 CPU, has an internal DSP running at 14.3\u00a0MHz. It features a cartridge slot that allows memory expansion, 16\u00a0Mbit of work random-access memory (RAM), 12\u00a0Mbit of video RAM, 4\u00a0Mbit of RAM for sound functions, 4\u00a0Mbit of CD buffer RAM and 256\u00a0Kbit (32\u00a0KB) of battery backup RAM. Its RCA video output displays at resolutions from 320\u00d7224 to 704\u00d7224 pixels, with up to 16.78 million colors. The Saturn measures . It was packaged with an instruction manual, control pad, stereo AV cable, and 100\u00a0V AC power supply consuming approximately 15\u00a0W.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n One very fast central processor would be preferable. I don't think all programmers have the ability to program two CPUs\u2014most can only get about one-and-a-half times the speed you can get from one SH-2. I think that only 1 in 100 programmers are good enough to get this kind of speed [double] out of the Saturn.\n \u2014Yu Suzuki reflecting on Saturn \"Virtua Fighter\" development\nThe Saturn had technically impressive hardware at the time of its release, but its complexity made harnessing this power difficult for developers accustomed to conventional programming. The greatest disadvantage was that both CPUs shared the same bus and were unable to access system memory at the same time. Making full use of the 4\u00a0KB of cache memory in each CPU was critical to maintaining performance. For example, \"Virtua Fighter\" used one CPU for each character, while \"Nights\" used one CPU for 3D environments and the other for 2D objects. The Visual Display Processor 2 (VDP2), which can generate and manipulate backgrounds, has also been cited as one of the system's most important features.\nThe Saturn's design elicited mixed commentary among game developers and journalists. Developers quoted by \"Next Generation\" in December 1995 described the Saturn as \"a real coder's machine [for] those who love to get their teeth into assembly and really hack the hardware [with] more flexibility [and] more calculating power than the PlayStation\". The sound board was widely praised. Lobotomy Software programmer Ezra Dreisbach described the Saturn as significantly slower than the PlayStation, whereas Kenji Eno of WARP observed little difference. In particular, Dreisbach criticized the Saturn's use of quadrilaterals as its basic geometric primitive, in contrast to the triangles rendered by the PlayStation and the Nintendo 64. Ken Humphries of Time Warner Interactive remarked that compared to the PlayStation, the Saturn was worse at generating polygons but better at sprites. Third-party development was initially hindered by the lack of useful software libraries and development tools, requiring developers to use assembly language. During early Saturn development, programming in assembly had a speed increase of two to five times above higher-level languages such as C.\nSega responded to complaints about the difficulty of programming for the Saturn by writing new graphics libraries which were claimed to make development easier. Sega of America purchased a United Kingdom-based development firm, Cross Products, to produce the Saturn's development system. Treasure CEO Masato Maegawa stated that the Nintendo 64 was more difficult to develop for than the Saturn. Traveller's Tales founder Jon Burton said that though the PlayStation was easier \"to get started on\u00a0[...] you quickly reach [its] limits\", whereas the Saturn's \"complicated [hardware could] improve the speed and look of a game when all used together correctly\". A major criticism was the Saturn's use of 2D sprites to generate polygons and simulate 3D space. The PlayStation has a different design, based entirely on 3D triangle-based polygonal rendering, with no direct 2D support. As a result, several analysts described the Saturn as an \"essentially\" 2D system. For example, Steven L. Kent stated: \"Although Nintendo and Sony had true 3D game machines, Sega had a 2D console that did a good job with 3D objects but wasn't optimized for 3D environments.\" The Saturn hardware is extremely difficult to emulate.\nSeveral Saturn models were produced in Japan. An updated model in a recolored light gray (officially white) was released at \u00a520,000 to reduce the system's cost and raise its appeal among women and younger children. Two models were released by third parties: Hitachi released the Hi-Saturn (a smaller model equipped with a car navigation function), and JVC released the V-Saturn. Saturn controllers have various complementary color schemes. The system also supports several accessories. A wireless controller powered by AA batteries uses infrared signal to connect. Designed to work with \"Nights\", the Saturn 3D Pad includes both a control pad and an analog stick for directional input. Sega also released several versions of arcade sticks as peripherals, including the Virtua Stick, the Virtua Stick Pro, the Mission Analog Stick, and the Twin Stick. Sega created a light gun peripheral, the Virtua Gun, for shooting games such as \"Virtua Cop\", and the Arcade Racer, a wheel for racing games. The Play Cable connects two Saturn consoles for multiplayer gaming across two screens, and a multitap connects up to six players to the same console. One console with two multitaps can support up to 12 players. Other accessories include RAM expansion cartridges, keyboard, mouse, floppy disk drive, and movie card.\nLike the Genesis, the Saturn had an Internet-based gaming service. The Sega NetLink is a 28.8k modem for the cartridge slot for direct dial multiplayer games \"Daytona USA\", \"Duke Nukem 3D\", \"Saturn Bomberman\", \"Sega Rally\", and \"\". In Japan, a pay-to-play service was used. It can be used for web browsing, email, and online chat. Because the NetLink was released before the keyboard, Sega produced a series of CDs containing hundreds of website addresses so that Saturn owners could browse with the joypad. In 1995, Sega announced a variant of the Saturn featuring a built-in NetLink modem codenamed Pluto, but it was never released.\nSega developed a Saturn-based arcade board, the Sega ST-V (or Titan), intended as an affordable alternative to Sega's Model 2 arcade board and as a testing ground for upcoming Saturn software. The Titan was criticized for its comparatively weak performance compared to the Sega Model 2 arcade system by Yu Suzuki, and it was overproduced by Sega's arcade division. Because Sega already had the \"Die Hard\" license, members of Sega AM1 working at the Sega Technical Institute developed \"Die Hard Arcade\" for the Titan to clear excess inventory. \"Die Hard\" became the most successful Sega arcade game produced in the United States at that point. Other games released for the Titan include \"\" and \"Virtua Fighter Kids\".\nGame library.\nMuch of the Saturn's library comprises Sega's arcade ports, including \"Daytona USA\", \"The House of the Dead\", \"Last Bronx\", \"Sega Rally Championship\", the \"Virtua Cop\" series, the \"Virtua Fighter\" series, and \"Virtual-On\". Ports of 2D Capcom fighting games including \"Darkstalkers 3\", \"Marvel Super Heroes vs. Street Fighter\", and \"Street Fighter Alpha 3\" were noted for their faithfulness to their arcade originals. \"Fighters Megamix\", developed by Sega AM2 for the Saturn rather than arcades, combined characters from \"Fighting Vipers\" and \"Virtua Fighter\" to positive reviews. \nHighly rated Saturn exclusives include \"Panzer Dragoon Saga\", \"Dragon Force\", \"Guardian Heroes\", \"Nights\", \"Panzer Dragoon II Zwei\", and \"Shining Force III\". PlayStation games such as \"\", \"Resident Evil\", and \"Wipeout 2097\" received Saturn ports with mixed results. The first-person shooter \"PowerSlave\" featured some of the most impressive 3D graphics on the Saturn, leading Sega to contract its developers, Lobotomy Software, to produce ports of \"Duke Nukem 3D\" and \"Quake\". While Electronic Arts's limited support for the Saturn and Sega's failure to develop a football game for late 1995 gave Sony the lead in the sports genre, Sega Sports published Saturn sports games including the well-regarded \"World Series Baseball\" and \"Sega Worldwide Soccer\" series.\nDue to the cancellation of \"Sonic X-treme\", the Saturn lacks an exclusive \"Sonic the Hedgehog\" platformer. Instead, it received a graphically enhanced port of the Genesis game \"Sonic 3D Blast\", as well as the compilation \"Sonic Jam\" and the racing game \"Sonic R\". The main character of the platformer \"Bug!\" was seen as a potential mascot for the Saturn, but failed to catch on as the \"Sonic\" series had. Instead, Sonic Team developed the score attack game \"Nights into Dreams\", considered one of the most important Saturn games. The gameplay involves steering the imp-like protagonist Nights, as it flies on a mostly 2D plane across surreal stages. Although it lacked the fully 3D environments of Nintendo's \"Super Mario 64\", the emphasis by \"Nights\" on unfettered movement and graceful acrobatic techniques showcased the intuitive potential of analog control. Sonic Team's next game, \"Burning Rangers\", a fully 3D action-adventure game involving a team of outer-space firefighters, garnered praise for its transparency effects and distinctive art direction, but was released in limited quantities late in the Saturn's lifespan and criticized for its short length.\nMany well-regarded Saturn games were exclusive to Japan, such the \"Sakura Wars\" series. Co-developed by Sega and Red Entertainment, \"Sakura Wars\" mixes elements of tactical RPGs, anime cutscenes, and visual novels. \"Sakura Wars\" and \"Grandia\" helped popularize the Saturn in Japan, but never had a Western release due to Sega of America's policy of not localizing RPGs and other Japanese games that might have damaged the Saturn's reputation in North America. Some games that launched on Saturn, such as \"Dead or Alive\", \"Grandia\", and \"\" were only released on the PlayStation in the West. Working Designs localized several Japanese Saturn games before a public feud between Sega of America's Bernie Stolar and Working Designs president Victor Ireland resulted in the company switching their support to the PlayStation. According to the review aggregator GameRankings, \"Panzer Dragoon Saga\" is the most acclaimed Saturn game; it was praised for its cinematic presentation, evocative plot, and unique battle system. However, Sega released fewer than 20,000 retail copies in North America in what \"IGN\"'s Levi Buchanan characterized as an example of the Saturn's \"ignominious send-off\" in the region. Similarly, only the first of three installments of \"Shining Force III\" was released outside Japan. The Saturn's library was criticised for its lack of sequels to high-profile Sega Genesis franchises, with Sega of Japan's cancellation of a planned third installment in Sega of America's popular \"Eternal Champions\" series cited as a significant source of controversy.\nLater ports of Saturn games including \"Guardian Heroes\", \"Nights Into Dreams\", and \"\" continued to garner positive reviews. Partly due to rarity, Saturn games such as \"Panzer Dragoon Saga\" and \"Radiant Silvergun\" are noted for their cult following. Due to the Saturn's commercial failure and hardware limitations, games such as \"Resident Evil 2\", \"Shenmue\", \"Sonic Adventure\", and \"Virtua Fighter 3\" were cancelled and moved to the Dreamcast.\nReception and legacy.\nAt the time of the Saturn's release, \"Famicom Ts\u016bshin\" awarded it 24 out of 40, higher than the PlayStation's 19 out of 40. In June 1995, Dennis Lynch of the \"Chicago Tribune\" and Albert Kim of \"Entertainment Weekly\" praised the Saturn as the most advanced console available; Lynch praised the double-speed CD-ROM drive and \"intense surround-sound capabilities\" and Kim cited \"Panzer Dragoon\" as a \"lyrical and exhilarating epic\" demonstrating the ability of new technology to \"transform\" the industry. In December 1995, \"Next Generation\" gave the Saturn three and a half stars out of five, highlighting Sega's marketing and arcade background as strengths but the system's complexity as a weakness. Four critics in \"Electronic Gaming Monthly\"'s December 1996 \"Buyer's Guide\" rated the Saturn 8, 6, 7, and 8 out of 10 and the PlayStation 9, 10, 9, and 9. By December 1998, \"EGM\"'s reviews were more mixed, with reviewers citing the lack of games as a major problem. According to \"EGM\" reviewer Crispin Boyer, \"the Saturn is the only system that can thrill me one month and totally disappoint me the next\".\nRetrospective feedback of the Saturn is mixed, but generally praises its game library. According to Greg Sewart of 1UP.com, \"the Saturn will go down in history as one of the most troubled, and greatest, systems of all time\". In 2009, IGN named the Saturn the 18th-best console of all time, praising its unique game library. According to the reviewers, \"While the Saturn ended up losing the popularity contest to both Sony and Nintendo\u00a0[...] \"Nights into Dreams\", the \"Virtua Fighter\" and \"Panzer Dragoon\" series are all examples of exclusive titles that made the console a fan favorite.\" \"Edge\" noted that \"hardened loyalists continue to reminisce about the console that brought forth games like \"Burning Rangers\", \"Guardian Heroes\", \"Dragon Force\" and \"Panzer Dragoon Saga\"\". In 2015, \"The Guardian\"'s Keith Stuart wrote that \"the Saturn has perhaps the strongest line-up of 2D shooters and fighting games in console history\".\n\"Retro Gamer\"'s Damien McFerran wrote: \"Even today, despite the widespread availability of sequels and re-releases on other formats, the Sega Saturn is still a worthwhile investment for those who appreciate the unique gameplay styles of the companies that supported it.\" IGN's Adam Redsell wrote \"[Sega's] devil-may-care attitude towards game development in the Saturn and Dreamcast eras is something that we simply do not see outside of the indie scene today.\" Necrosoft Games director Brandon Sheffield said that \"the Saturn was a landing point for games that were too 'adult' in content for other systems, as it was the only one that allowed an 18+ rating for content in Japan\u00a0[...] some games, like \"Enemy Zero\" used it to take body horror to new levels, an important step toward the expansion of games and who they served.\" Sewart praised the Saturn's first-party games as \"Sega's shining moment as a game developer\", with Sonic Team demonstrating its creative range and AM2 producing numerous technically impressive arcade ports. He also commented on the many Japan-exclusive Saturn releases, which he connected with a subsequent boom in the game import market. IGN's Travis Fahs was critical of the Saturn library's lack of \"fresh ideas\" and \"precious few high-profile franchises\", in contrast to what he described as Sega's more creative Dreamcast output.\nSega has been criticized for its management of the Saturn. McFerran said its management staff had \"fallen out of touch with both the demands of the market and the industry\". Stolar has also been criticized; according to Fahs, \"Stolar's decision to abandon the Saturn made him a villain to many Sega fans, but\u00a0[...] it was better to regroup than to enter the next fight battered and bruised. Dreamcast would be Stolar's redemption.\" Stolar defended his decision, saying, \"I felt Saturn was hurting the company more than helping it. That was a battle that we weren't going to win.\" Sheffield said that the Saturn's quadrilaterals undermined third-party support, but because \"nVidia invested in quads\" at the same time, there had been \"a remote possibility\" they could have \"become the standard instead of triangles [...] if somehow, magically, the Saturn were the most popular console of that era.\" Speaking more positively, former Working Designs president Victor Ireland described the Saturn as \"the start of the future of console gaming\" because it \"got the better developers thinking and designing with parallel-processing architecture in mind for the first time\". In GamesRadar, Justin Towell wrote that the Saturn's 3D Pad \"set the template for every successful controller that followed, with analog shoulder triggers and left thumbstick\u00a0[...] I don't see any three-pronged controllers around the office these days.\"\nDouglass C. Perry of Gamasutra noted that, from its surprise launch to its ultimate failure, the Saturn \"soured many gamers on Sega products\". Sewart and IGN's Levi Buchanan cited the failure of the Saturn as the major reason for Sega's downfall as a hardware manufacturer, but USgamer's Jeremy Parish described it as \"more a symptom\u00a0[...] than a cause\" of the decline, which began with add-ons for the Genesis that fragmented the market and continued with Sega of America's and Sega of Japan's competing designs for the Dreamcast. Sheffield portrayed Sega's mistakes with the Saturn as emblematic of the broader then-decline of the Japanese gaming industry: \"They thought they were invincible, and that structure and hierarchy were necessary for their survival, but more flexibility, and a greater participation with the West could have saved them.\" According to Stuart, Sega \"didn't see\u00a0[...] the roots of a prevailing trend, away from arcade conversions and traditional role-playing adventures and toward a much wider console development community with fresh ideas about gameplay and structure\". Pulp365 reviews editor Matt Paprocki concluded that \"the Saturn is a relic, but an important one, which represents the harshness of progress and what it can leave in its wake\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29036", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=29036", "title": "Dreamcast", "text": "Sega video game console\nThe is the final home video game console manufactured by Sega. It was released in Japan on November 27, 1998, in North America on September 9, 1999, in Europe on October 14, 1999 and in Australia on November 30, 1999. It was the first sixth-generation video game console, preceding Sony's PlayStation 2, Nintendo's GameCube, and Microsoft's Xbox. The Dreamcast's discontinuation in 2001 ended Sega's 18 years in the console market.\nA team led by Hideki Sato began developing the Dreamcast in 1997. In contrast to the expensive hardware of the unsuccessful Saturn, the Dreamcast was designed to reduce costs with off-the-shelf components, including a Hitachi SH-4 CPU and an NEC PowerVR2 GPU. Sega used the GD-ROM disc format to avoid the expense of DVD licensing. To speed game development, the console could run a custom version of Windows CE for easier PC game porting and shared hardware with Sega's NAOMI system board, enabling authentic arcade game conversions. The Dreamcast was the first console to include a built-in modular modem for internet access and online play.\nThough its Japanese release was beset by supply problems, the Dreamcast had a successful US launch backed by a large marketing campaign. However, sales steadily declined as Sony built anticipation for the PlayStation 2. Dreamcast sales did not meet Sega's expectations, and attempts to renew interest through price cuts caused significant financial losses. After a change in leadership, Sega discontinued the Dreamcast on March 31, 2001, withdrew from the console business, and restructured itself as a third-party developer. A total of 9.13 million Dreamcast units were sold worldwide and over 600 games were produced. Its bestselling game, \"Sonic Adventure\" (1998)\u2014the first 3D game in Sega's \"Sonic the Hedgehog\" series\u2014sold 2.5 million copies.\nThe Dreamcast's commercial failure has been attributed to several factors, including competition from the PlayStation 2, limited third-party support, and the earlier failures of the 32X and Saturn having tarnished Sega's reputation. In retrospect, reviewers have celebrated the Dreamcast as one of the greatest consoles. It is considered ahead of its time for pioneering concepts such as online play and downloadable content. Many Dreamcast games are regarded as innovative, including \"Sonic Adventure\", \"Crazy Taxi\" (1999), \"Shenmue\" (1999), \"Jet Set Radio\" (2000), and \"Phantasy Star Online\" (2000). The Dreamcast remains popular in the video game homebrew community, which has developed private servers to preserve its online functions and unofficial Dreamcast software.\nHistory.\nBackground.\nIn 1988, Sega released the Genesis (known as the Mega Drive in most countries outside North America), in the fourth generation of video game consoles. It became the most successful Sega console ever, at 30.75 million units sold. Its successor, the Saturn, was released in Japan in 1994. The Saturn is CD-ROM-based and has 2D and 3D graphics, but its complex dual-CPU architecture was more difficult to program than its chief competitor, the Sony PlayStation. Although the Saturn debuted before the PlayStation in Japan and the United States, its surprise US launch, four months ahead of schedule, was limited to four retailers due to a lack of supply, which \"aggravated\" other retailers. Developers also found it easier to program for the Playstation, which caused a loss of support from these game developers. Losses on the Saturn contributed to financial problems for Sega, whose revenue had declined between 1992 and 1995 as part of an industry-wide slowdown.\nSega announced that Shoichiro Irimajiri would replace Tom Kalinske as chairman and CEO of Sega of America, while Bernie Stolar, a former executive at Sony Computer Entertainment of America, became Sega of America's executive vice president in charge of product development and third-party relations. After the 1996 launch of the Nintendo 64, sales of the Saturn and its software fell sharply. As of August 1997, Sony controlled 47 percent of the console market, Nintendo controlled 40 percent, and Sega controlled only 12 percent; neither price cuts nor high-profile games helped the Saturn. &lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nI thought the Saturn was a mistake as far as hardware was concerned. The games were obviously terrific, but the hardware just wasn't there.\n\u2014Bernie Stolar, former president of Sega of America, in 2009\nHayao Nakayama resigned as president of Sega in January 1998 in favor of Irimajiri, and Stolar acceded to become CEO and president of Sega of America. Following five years of generally declining profits, in the fiscal year ending March 31, 1998, Sega suffered its first parent and consolidated financial losses since its 1988 listing on the Tokyo Stock Exchange, reporting a consolidated net loss of \u00a5 (US$). Shortly before announcing its financial losses, Sega announced the discontinuation of the Saturn in North America to prepare for the launch of its successor. This effectively left the Western market without Sega games for more than a year. Rumors about the upcoming Dreamcast\u2014spread mainly by Sega\u2014leaked to the public before the last Saturn games were released.\nDevelopment.\nAs early as 1995, reports surfaced that Sega would collaborate with Lockheed Martin, The 3DO Company, Matsushita or Alliance Semiconductor to create a new graphics processing unit, which conflicting accounts said would be used for a 64-bit \"Saturn 2\" or an add-on peripheral. Dreamcast development was unrelated. Considering the Saturn's poor performance, Irimajiri looked beyond Sega's internal hardware development division to create a new console. In 1997, he enlisted IBM's Tatsuo Yamamoto to lead an eleven-person team to work on a secret project in the United States with the codename Blackbelt. Accounts vary on how an internal team led by Hideki Sato also began development on Dreamcast hardware; one account specifies that Sega tasked both teams, and another suggests that Sato was bothered by Irimajiri's choice to begin development externally and had his team start work. Sato and his group chose the Hitachi SH-4 processor architecture and the VideoLogic PowerVR2 graphics processor, manufactured by NEC, in the production of the mainboard. Initially known as Whitebelt, the project was later codenamed Dural, after the metallic female fighter from Sega's \"Virtua Fighter\" series.\nYamamoto's group opted to use 3dfx Voodoo 2 and Voodoo Banshee graphics processors alongside a Motorola PowerPC 603e central processing unit (CPU), but Sega management later asked them to also use the SH-4 chip. Both processors have been described as \"off-the-shelf\" components. According to Charles Bellfield, the former Sega of America vice president of communications and former NEC brand manager, presentations of games using the NEC solution showcased the performance and low cost delivered by the SH-4 and PowerVR architecture. He said that Sega's relationship with NEC, a Japanese company, likely also influenced the decision to use its hardware rather than the architecture developed in America. Stolar felt the US 3dfx version should have been used, but that \"Japan wanted the Japanese version, and Japan won\". As a result, 3dfx filed a lawsuit against Sega and NEC claiming breach of contract, which was settled out of court.\nThe choice to use the PowerVR architecture concerned Electronic Arts (EA), a longtime developer for Sega consoles. EA had invested in 3dfx but was unfamiliar with the selected architecture, which was reportedly less powerful. According to Shiro Hagiwara (a general manager at Sega's hardware division) and Ian Oliver (the managing director of the Sega subsidiary Cross Products), the SH-4 was chosen while still in development, following lengthy deliberation, as the only processor that \"could adapt to deliver the 3D geometry calculation performance necessary\". By February 1998, Sega had renamed the project Katana, after the Japanese sword, although certain hardware specifications such as random access memory (RAM) were not finalized.\nKnowing the Saturn had been set back by its high production costs and complex hardware, Sega took a different approach with the Dreamcast. Like previous Sega consoles, the Dreamcast was designed around intelligent subsystems working in parallel, but the selections of hardware were closer to personal computers than video game consoles, reducing cost. It also enabled software development to begin before any development kits had been completed, as Sega informed developers that any game developed with a Pentium II 200 in mind would run on the console. According to Damien McFerran, \"the motherboard was a masterpiece of clean, uncluttered design and compatibility\".\nThe Chinese economist and future Sega.com CEO Brad Huang convinced the Sega chairman, Isao Okawa, to include a modem with every Dreamcast under opposition from Okawa's staff over the additional US$ cost per unit. To account for rapid changes in home data delivery, Sega designed the modem to be modular.\nSega selected the GD-ROM (Gigabyte Disc) media format. Jointly developed by Sega and Yamaha, the GD-ROM could be mass-produced at a similar price to a normal CD-ROM, avoiding the greater expense of newer DVD-ROM technology.\nMicrosoft developed a custom Dreamcast version of Windows CE with DirectX API and dynamic-link libraries, making it easy to port PC games to the platform, although programmers would ultimately favor Sega's development tools over those from Microsoft. A member of the Project Katana team speaking anonymously predicted this would be the case, speculating developers would prefer the greater performance possibilities offered by the Sega OS to the more user-friendly interface of the Microsoft OS. In late 1997, there were reports about the rumored system, then codenamed Dural, and that it had been demonstrated to a number of game developers.\nThe Dreamcast was finally revealed on May 21, 1998 in Tokyo. Sega held a public competition to name its new system and considered over 5,000 different entries before choosing \"Dreamcast\"\u2014a portmanteau of \"dream\" and \"broadcast\". According to Katsutoshi Eguchi, Japanese game developer Kenji Eno submitted the name and created the Dreamcast's spiral logo, but this has not been officially confirmed by Sega. Former Sega executive Kunihisa Ueno confirmed in his biography that a branding agency called Interbrand created the logo for the console, with Kenji Eno volunteering to name the console. Eno was paid for his involvement and signed a NDA to prevent his involvement from going public.\nThe Dreamcast's startup sound was composed by the Japanese musician Ryuichi Sakamoto. Because the Saturn had tarnished its reputation, Sega planned to remove its name from the console and establish a new gaming brand similar to Sony's PlayStation, but Irimajiri's management team decided to retain it. Sega spent on hardware development, on software development, and US$ on worldwide promotion\u2014a sum which Irimajiri, a former Honda executive, humorously likened to the investments required to design new automobiles.\nLaunch.\nJapan.\nDespite a 75 percent drop in half-year profits just before the Japanese launch, Sega was confident about the Dreamcast. It drew significant interest and many pre-orders. However, Sega could not achieve its shipping goals for the Japanese Dreamcast launch due to a shortage of PowerVR chipsets caused by a high failure rate in the manufacturing process. As more than half of its limited stock had been pre-ordered, Sega stopped pre-orders in Japan. On November 27, 1998, the Dreamcast launched in Japan at a price of \u00a5, and the stock sold out by the end of the day. However, of the four games available at launch, only one\u2014a port of \"Virtua Fighter 3\", the most successful arcade game Sega ever released in Japan\u2014sold well. Sega estimated that an additional Dreamcast units could have been sold with sufficient supply.\nSega had announced that \"Sonic Adventure\", the next game starring its mascot, Sonic the Hedgehog, would launch with the Dreamcast and promoted it with a large-scale public demonstration at the Tokyo Kokusai Forum Hall, but it and \"Sega Rally Championship 2\" were delayed. They arrived within the following weeks, but sales continued to be slower than expected. Irimajiri hoped to sell over one million Dreamcast units in Japan by February 1999, but sold fewer than 900,000, undermining Sega's attempts to build an installed base sufficient to protect the Dreamcast after the arrival of competition from other manufacturers. There were reports of disappointed Japanese consumers returning their Dreamcasts and using the refund to purchase additional PlayStation software. \"Seaman\", released in July 1999, became the Dreamcast's first major hit in Japan. Prior to the Western launch, Sega reduced the price of the Dreamcast to \u00a5, effectively making it unprofitable but increasing sales. The reduction and the release of Namco's \"Soulcalibur\" helped Sega gain 17 percent on its shares.\nNorth America.\nBefore the Dreamcast's release, Sega was dealt a blow when Electronic Arts, the largest third-party video game publisher at the time, announced it would not develop games for the system. EA's chief creative officer Bing Gordon said that Sega had \"flip-flopped\" on the hardware configuration, that EA developers did not want to work on it, and that Sega \"was not acting like a competent hardware company\". Gordon also said that Sega could not afford to give them the \"kind of license that EA has had over the last five years\". According to Stolar, president of EA at the time, Larry Probst, wanted exclusive rights as the only sports brand on Dreamcast, which Stolar could not accept due to Sega's recent US$ purchase of the sports game developer Visual Concepts. While EA's \"Madden NFL\" series had established brand power, Stolar regarded Visual Concepts' \"NFL 2K\" as superior and would provide \"a breakthrough experience\" to launch the Dreamcast. While none of EA's popular sports games were released for the Dreamcast, \"Sega Sports\" titles developed mainly by Visual Concepts helped to fill that void.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n Let's take the conservative estimate of 250,000 Dreamcast units at presale\u2014that's a quarter of a million units at $. We'll have a ratio of 1.5 or two games for every Dreamcast unit sold. That's half a million units of software. We think we'll be .5 to one on VMUs and peripheral items such as extra controllers and what have you. This could be a 24-hour period. What has ever sold in the first 24 hours?\n \u2014Peter Moore, speaking to \"Electronic Gaming Monthly\" about the then-upcoming launch of the Dreamcast\nWorking closely with Midway Games (which developed four North American launch games for the system) and taking advantage of the ten months following the Dreamcast's release in Japan, Sega of America worked to ensure a more successful US launch with a minimum of 15 launch games. With lingering bitterness over the Saturn's early release, Stolar repaired relations with major US retailers, with whom Sega presold 300,000 Dreamcast units. In addition, a pre-launch promotion enabled consumers to rent Dreamcasts from Hollywood Video starting on July 14. Sega of America's senior vice president of marketing Peter Moore, a fan of the attitude previously associated with Sega's brand, worked with Foote, Cone &amp; Belding and Access Communications to develop the \"It's Thinking\" campaign of 15-second television commercials, which emphasized the Dreamcast's hardware power. According to Moore: \"We needed to create something that would really intrigue consumers, somewhat apologize for the past, but invoke [\"sic\"] all the things we loved about Sega, primarily from the Genesis days.\" On August 11, Sega of America confirmed that Stolar had been fired, leaving Moore to direct the launch.\nThe Dreamcast launched in North America on September 9, 1999, at a price of $, which Sega's marketing dubbed \"9/9/99 for $\". Nineteen launch games were available in the US. Sega set a new sales record by selling more than 225,132 Dreamcast units in 24 hours, earning $ in what Moore called \"the biggest 24 hours in entertainment retail history\". Within two weeks, US Dreamcast sales exceeded 500,000 units. By Christmas, Sega held 31 percent of the North American video game market share. Significant launch games included \"Sonic Adventure\", the arcade fighting game \"Soulcalibur\", and Visual Concepts' football simulation \"NFL 2K\". On November 4, Sega announced it had sold over one million Dreamcast units in North America. The launch was marred by a glitch at one of Sega's manufacturing plants, which produced defective GD-ROMs.\nEurope.\nSega released the Dreamcast in Europe on October 14, 1999, at a price of \u00a3200. By November 24, 400,000 consoles had been sold in Europe. By Christmas of 1999, Sega of Europe had sold 500,000 units, six months ahead of schedule. The price was dropped to \u00a3149.99 from September 8, 2000, with sales at around 800,000 in Europe at this point. Announcing the drop, Jean-Fran\u00e7ois Cecillon, CEO of Sega Europe, commented: \"There are 'X' amount of core gamers in Europe; the early adopters. We have reached 80 or 90 per cent of them now and the market is screaming for a price reduction. We have to acknowledge these things and go with the market\". Sales did not continue at this pace, and by October 2000, Sega had sold only about one million units in Europe. As part of Sega's promotions of the Dreamcast in Europe, it sponsored four European football clubs: Arsenal (England), Saint-\u00c9tienne (France), Sampdoria (Italy), and Deportivo de La Coru\u00f1a (Spain).\nAustralia and New Zealand.\nThrough the regional distributor Ozisoft, the Dreamcast went on sale in Australia and New Zealand on November 30, 1999, at a price of A$. The launch was planned for September, but was delayed due to problems with Internet compatibility and launch game availability, then delayed again from the revised date of October 25 for various reasons. There were severe problems at launch; besides a severe shortage of the consoles, only six of the thirty planned launch games were available for purchase on day one with no first-party software included, and additional peripherals were not available in stores.\nThe Ozisoft representative Steve O'Leary, in a statement released the day of launch, explained that the Australian Customs Service had impounded virtually all the supplied launch software, including demo discs, due to insufficient labeling of their country of origin; Ozisoft had received them only two days before launch, resulting in few games that were catalogued and prepared for shipment in time. O'Leary also said that the Dreamcast's high demand in other markets had reduced the number of peripherals allotted to the region. Further complicating matters was the lack of an internet disc due to localization problems, and delays in securing an ISP contract, which was done through Telstra the day before launch. The online component was not ready until March 2000, at which point Ozisoft sent the necessary software to users who had sent in a filled-out reply paid card included with the console. The poor launch, combined with a lack of advertising and a high price point, produced lackluster sales in Australia; two large retail chains reported a combined total of 13 console sales over the first few days after launch.\nCompetition.\nThough the Dreamcast launch was successful, Sony held 60 percent of the overall video game market share in North America with the PlayStation at the end of 1999. On March 2, 1999, Sony revealed the first details of the PlayStation 2 (PS2), which Ken Kutaragi said would allow video games to convey unprecedented emotions. Sony estimated the PS2 could render 7.5 million to 16 million polygons per second, whereas independent estimates ranged from 3 million to 20 million, compared to Sega's estimates of more than 3 million to 6 million for the Dreamcast. The PS2 would also use the DVD-ROM format, which could hold substantially more data than the Dreamcast's GD-ROM, and would be backwards-compatible with hundreds of popular PlayStation games. Sony's specifications appeared to render the Dreamcast obsolete months before its US launch, although reports later emerged that the PS2 was not as powerful as expected and difficult to develop on. The same year, Nintendo announced that its next console, the GameCube, would meet or exceed anything on the market, and Microsoft began development of its own console, the Xbox.\nUS Dreamcast sales\u2014which exceeded 1.5 million by the end of 1999\u2014began to decline as early as January 2000. Poor Japanese sales contributed to Sega's \u00a542.88 billion ($404 million) consolidated net loss in the fiscal year ending March 2000, which followed a loss of \u00a542.881 billion the previous year and marked Sega's third consecutive annual loss. Although Sega's overall sales for the term increased 27.4%, and Dreamcast sales in North America and Europe greatly exceeded expectations, this coincided with a decrease in profitability due to the investments required to launch the Dreamcast in Western markets and poor software sales in Japan. At the same time, increasingly poor market conditions reduced the profitability of Sega's Japanese arcade business, prompting Sega to close 246 locations.\nMoore became the president and chief operating officer of Sega of America on May 8, 2000. He and Sega's developers focused on the US market to prepare for the upcoming launch of the PS2. To that end, Sega of America launched its own internet service provider, Sega.com, led by CEO Brad Huang. On September 7, 2000, Sega.com launched SegaNet, the Dreamcast's internet gaming service, at a subscription price of $21.95 per month. Although Sega had previously released only one Dreamcast game in the US that featured online multiplayer, \"ChuChu Rocket!\", the launch of SegaNet combined with the release of \"NFL 2K1\", with a robust online component, was intended to increase demand for the Dreamcast in the US market. The service later supported games including \"Bomberman Online\", \"Quake III Arena\", and \"Unreal Tournament\". The September 7 launch coincided with a new advertising campaign to promote SegaNet, including advertising on the MTV Video Music Awards that day, which Sega sponsored for the second consecutive year. Sega employed aggressive pricing strategies around online gaming; in Japan, every Dreamcast sold included a free year of internet access, which Okawa personally paid for. Prior to the launch of SegaNet, Sega had already offered a $200 rebate to any Dreamcast owner who purchased two years of internet access from Sega.com. To increase SegaNet's appeal in the US, Sega dropped the price of the Dreamcast to $ (compared to the PS2's US launch price of $) and offered a rebate for the full $ price of a Dreamcast, and a free Dreamcast keyboard, with every 18-month SegaNet subscription.\nDecline.\nMoore said that the Dreamcast would need to sell 5 million units in the US by the end of 2000 to remain a viable platform; Sega fell short of this goal, with some 3 million units sold. Moreover, Sega's attempts to spur increased Dreamcast sales through lower prices and cash rebates caused escalating financial losses. Instead of an expected profit, for the six months ending September 2000, Sega posted a \u00a5 ($) loss, with a projected year-end loss of \u00a5. This estimate more than doubled to \u00a5, and in March 2001, Sega posted a consolidated net loss of \u00a5 ($). While the PS2's October 26 US launch was marred by shortages, this did not benefit the Dreamcast as much as expected; many consumers continued to wait for a PS2, while the PSone, a remodeled version of the original PlayStation, became the bestselling console in the US at the start of the 2000 holiday season. According to Moore, \"The PlayStation 2 effect that we were relying upon did not work for us... People will hang on for as long as possible... What effectively happened is the PlayStation 2 lack of availability froze the marketplace.\" Eventually, Sony and Nintendo held 50 and 35 percent of the US video game market, while Sega held only 15 percent. According to Bellfield, Dreamcast software sold at an 8-to-1 ratio with the hardware, but the small install base meant this did not produce enough revenue to keep it viable. During the course of 2000, the PlayStation had sold five times more than Dreamcast despite being five year old hardware.&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nWe had a tremendous 18 months. Dreamcast was on fire - we really thought that we could do it. But then we had a target from Japan that said we had to make x hundreds of millions of dollars by the holiday season and shift x millions of units of hardware, otherwise, we just couldn't sustain the business. Somehow I got to make that call, not the Japanese. I had to fire a lot of people; it was not a pleasant day. So on January 31st 2001 we said Sega is leaving hardware. We were selling 50,000 units a day, then 60,000, then 100,000, but it was just not going to be enough to get the critical mass to take on the launch of PS2. It was a big stakes game. Sega had the option of pouring in more money and going bankrupt and they decided they wanted to live to fight another day.\n\u2014Peter Moore, on the Dreamcast's discontinuation\nOn May 22, 2000, Okawa replaced Irimajiri as president of Sega. Okawa had long advocated that Sega abandon the console business. His sentiments were not unique; Sega co-founder David Rosen had \"always felt it was a bit of a folly for them to be limiting their potential to Sega hardware\", and Stolar had suggested Sega should have sold their company to Microsoft. In September 2000, in a meeting with Sega's Japanese executives and the heads of the company's major Japanese game development studios, Moore and Bellfield recommended that Sega abandon its console business and focus on software, prompting the studio heads to walk out.\nAmid speculation and rumors, Sega executives denied to the media that it would leave the console hardware business. Nevertheless, on January 31, 2001, Sega announced the discontinuation of the Dreamcast after March 31 and the restructuring of the company as a \"platform-agnostic\" third-party developer, although with continued Dreamcast software support for some time. Sega also announced a price reduction to $ to eliminate its unsold inventory, which was estimated at 930,000 units as of April 2001. After a further reduction to $79, the Dreamcast was cleared out of stores at $. The final Dreamcast unit manufactured was autographed by the heads of all nine of Sega's internal game development studios, plus the heads of Visual Concepts and Sega's sound studio Wave Master, and given away with all 55 first-party Dreamcast games through a competition organized by \"GamePro\". Okawa, who had previously loaned Sega $ in 1999, died on March 16, 2001; shortly before his death, he forgave Sega's debts to him and returned his $ worth of Sega and CSK stock, helping Sega survive the transition to third-party development. As part of this restructuring, nearly one third of Sega's Tokyo workforce was laid off in 2001.\nAftermath and reaction.\n9.13 million Dreamcast units were sold worldwide. Despite the discontinuation of Dreamcast hardware, Sega continued to support the system and had stated that more than 30 new titles were confirmed for release for the remainder of 2001. In the United States, official game releases continued until the end of the first half of 2002. Sega continued to repair Dreamcast units until September 2007. Many hardware developers that worked on the Dreamcast also joined pachinko and pachislot company Sammy Corporation, who soon merged with Sega. Hideki Sato pushed for leftover Dreamcast parts being used as displays in the machines that Sammy develops, including the very successful \"Fist of the North Star\" pachinko machines. \nAfter five consecutive years of financial losses, Sega finally posted a profit for the fiscal year ending March 2003.\nThe announcement of Sega's exit from hardware was met with enthusiasm. According to \"IGN\"'s Travis Fahs, \"Sega was a creatively fertile company with a rapidly expanding stable of properties to draw from. It seemed like they were in a perfect position to start a new life as a developer/publisher.\" Former Working Designs president Victor Ireland wrote, \"It's actually a good thing\u00a0... because now Sega will survive, doing what they do best: software.\" The staff of \"Newsweek\" wrote that \"from \"Sonic\" to \"Shenmue\", Sega's programmers have produced some of the most engaging experiences in the history of interactive media\u00a0... Unshackled by a struggling console platform, this platoon of world-class software developers can do what they do best for any machine on the market.\" \"Game Informer\", commenting on Sega's tendency to produce under-appreciated cult classics, wrote: \"Let us rejoice in the fact that Sega is making games equally among the current console crop, so that history will not repeat itself.\"\nTechnical specifications.\nHardware.\nThe Dreamcast measures and weighs . Its main CPU is a two-way 360 MIPS superscalar Hitachi SH-4 32-bit RISC, clocked at 200\u00a0MHz with an 8 kB instruction cache and 16\u00a0kB data cache and a 128-bit graphics-oriented floating-point unit delivering 1.4 GFLOPS. Its 100\u00a0MHz NEC PowerVR2 rendering engine, integrated with the ASIC, can draw more than 3 million polygons per second and use deferred shading. Sega estimated the Dreamcast's theoretical rendering capability at 7 million raw polygons per second, or 6 million with textures and lighting, but noted that \"game logic and physics reduce peak graphic performance\".\nGraphical hardware effects include trilinear filtering, gouraud shading, z-buffering, spatial anti-aliasing, per-pixel translucency sorting and bump mapping. The Dreamcast can output approximately 16.77 million colors simultaneously and displays interlaced or progressive scan video at 640\u00a0\u00d7\u00a0480 video resolution. Its 67\u00a0MHz Yamaha AICA sound processor, with a 32-bit ARM7 RISC CPU core, can generate 64 voices with PCM or ADPCM, providing ten times the performance of the Saturn's sound system. The Dreamcast has 16 MB main RAM, along with an additional 8\u00a0MB of RAM for graphic textures and 2\u00a0MB of RAM for sound. It reads media using a 12\u00d7 speed Yamaha GD-ROM drive. In addition to Windows CE, the Dreamcast supports several Sega and middleware application programming interfaces.\nThe Dreamcast can supply video through several accessories including A/V cables, RF modulator connectors S-Video cables and SCART. A VGA adapter allows Dreamcast to connect on computer displays or enhanced-definition television sets in 480p.\nModels.\nSega constructed numerous Dreamcast models, most of which were exclusive to Japan. The R7, a refurbished Dreamcast, was originally used as a network console in Japanese pachinko parlors. Another model, the Divers 2000 CX-1, is shaped similarly to Sonic's head and includes a television and software for teleconferencing. A \"Hello Kitty\" version, limited to 2000 units, was targeted at female gamers in Japan. Special editions were created for \"Seaman\" and \"\". Color variations were sold through the Dreamcast Direct service in Japan. Toyota also offered special Dreamcast units at 160 of its dealers in Japan. In North America, a limited edition black Dreamcast was released with a Sega Sports logo on the lid, which included matching Sega Sports-branded black controllers and two games.\nControllers and accessories.\nThe Dreamcast has four ports for controller inputs, and was sold with one controller. The controller is based on the Saturn 3D controller and includes an analog stick, a D-pad, four action buttons, start button and two analog triggers. It received mostly negative reviews from critics; \"Edge\" described it as \"an ugly evolution of Saturn's 3D controller\", and was called \"[not] that great\" by \"1Up.com\"'s Sam Kennedy and \"lame\" by \"Game Informer\"'s Andy McNamara. \"IGN\" wrote that \"unlike most controllers, Sega's pad forces the user's hands into an uncomfortable parallel position\". Both the analog joystick and triggers uniquely used Hall effect sensors, which requires less calibration and leads to fewer issues with joystick drift.\nVarious third-party controllers, from companies such as Mad Catz, include additional buttons and other features; third parties also manufactured arcade-style joysticks for fighting games, such as Agetech's Arcade Stick and Interact's Alloy Arcade Stick. Mad Catz and Agetec created racing wheels for racing games. Sega did not release its official light guns in the US, but some third party light guns were available. The Dreamcast supports a Sega fishing \"reel and rod\" motion controller and a keyboard for text entry. Although it was designed for fishing games such as \"Sega Bass Fishing\", \"Soulcalibur\" is playable with the fishing controller, which translates vertical and horizontal movements into on-screen swordplay; \"IGN\" cited it as a predecessor to the Wii Remote. The Japanese Dreamcast port of Sega's \"Cyber Troopers Virtual-On Oratorio Tangram\" supported a \"Twin Sticks\" peripheral, but its American publisher, Activision, opted not to release it in the US. The Dreamcast can connect to SNK's Neo Geo Pocket Color, predating Nintendo's GameCube \u2013 Game Boy Advance link cable.\nIn most regions, the Dreamcast includes a removable modem for online connectivity, which is modular for future upgrades. In Brazil, due to the high price of the console, the modem was sold separately. The original Japanese model and all PAL models have a transfer rate of 33.6\u00a0kbit/s, and consoles sold in the US and in Japan after September 9, 1999, feature a 56\u00a0kbit/s dial-up modem. Broadband service was enabled through the later release of a broadband accessory in 2000 in Japan, and early 2001 in the US.\nSega also produced the Dreameye, a digital camera that could be connected to the Dreamcast and used to exchange pictures and participate in video chat over the internet. Sega hoped developers would use the Dreameye for future software, as some later did with Sony's similar EyeToy peripheral. In addition, Sega investigated systems that would have allowed users to make telephone calls with the Dreamcast, and discussed with Motorola the development of an internet-enabled cell phone that would use technology from the console to enable quick downloads of games and other data.\nStorage.\nIn contrast to the Sega CD and Sega Saturn, which included internal backup memory, the Dreamcast uses a 128 kbyte memory card, the VMU, for data storage. The VMU features a small LCD screen, audio output from a one-channel PWM sound source, non-volatile memory, a D-pad and four buttons. The VMU can present game information, be used as a minimal handheld gaming device, and connect to certain Sega arcade machines. For example, players use the VMU to call plays in \"NFL 2K\" or raise virtual pets in \"Sonic Adventure\".\nSega officials noted that the VMU could be used \"as a private viewing area, the absence of which has prevented effective implementation of many types of games in the past\". After a VMU slot was incorporated into the controller's design, Sega's engineers found many additional uses for it, so a second slot was added. It is generally for vibration packs providing force feedback, such as Sega's \"Jump Pack\" and Performance's \"Tremor Pack\"; it can be used for peripherals including a microphone, enabling voice control and player communication. Various third-party cards provide storage, and some contain the LCD screen addition. Iomega announced a Dreamcast-compatible zip drive storing up to 100 MB on removable discs, but it was never released.\nSoftware.\nGame library.\nThe Dreamcast library consists of over 600 games across all regions, in GD-ROM format. It uses regional lockout, only playing games released within its predetermined region; however, this is circumventable via modchip installation, boot discs, or cheat discs such as Datel's Action Replay. In Japan, the Dreamcast was launched with \"Virtua Fighter 3tb\", \"Pen Pen TriIcelon\", \"Godzilla Generations\", and \"July\". In North America, it launched with 19 games, including the highly anticipated \"Sonic Adventure\", \"Soulcalibur\", and \"NFL 2K\". In Europe, it was planned to launch with 10 games; this increased to 15 after the launch was delayed. Licensed Dreamcast games were released until mid-2002 in the US. Some indie developers continued to release games, such as 2007's \"Last Hope\", developed by the German studio NG:Dev.Team.\nFirst-party games.\nIn what has been called \"a brief moment of remarkable creativity\", in 2000, Sega restructured its arcade and console development teams into nine semi-autonomous studios headed by their top designers. Studios included United Game Artists (UGA), Hitmaker, Smilebit, Overworks, WOW Entertainment, Amusement Vision, Sega Rosso, Wave Master, and Sonic Team, while Sega AM2 had been taken over earlier in the year by CSK Research Institute and became independent in 2001 as SEGA-AM2 Co., Ltd. Sega's design studios were encouraged to experiment and benefited from a relatively lax approval process. This resulted in games such as UGA's \"Rez\", an attempt to simulate synaesthesia in the form of a rail shooter; Wow's \"The Typing of the Dead\", a version of \"The House of the Dead 2\" remade into a touch typing trainer; and Hitmaker's \"Segagaga\", a Japan-exclusive role-playing game in which players are tasked with preventing Sega from going out of business.\nSonic Team's \"Sonic Adventure\", the first fully 3D platform game starring Sega's mascot Sonic the Hedgehog, was considered the \"centerpiece\" of the Dreamcast launch. At 2.5 million copies, it is the best-selling Dreamcast game. Sonic Team also developed the Dreamcast's first online game\u2014\"ChuChu Rocket!\"\u2014which was praised for its addictive puzzle gameplay and \"frantic\" multiplayer matches, and the critically successful music game \"Samba de Amigo\", which was noted for its expensive maracas peripheral and colorful aesthetic. Sonic Team's \"Phantasy Star Online\", the first online console RPG, is considered a landmark game for refining and simplifying \"Diablo\"'s style of gameplay to appeal to console audiences.\nUGA created the music game \"Space Channel 5\" for a female casual audience; players help a female outer-space news reporter, Ulala, fight aliens with \"groove energy\" by dancing. Hitmaker's arcade ports include \"Crazy Taxi\", an open-world arcade racing game known for its addictive gameplay with more than one million copies sold; and \"Virtua Tennis\", which revitalized the tennis game genre. Smilebit's \"Jet Set Radio\", in which players control a Tokyo gang of rebellious inline skaters, is cited as a major example of Sega's commitment to original concepts during the Dreamcast's lifespan. \"Jet Set Radio\" also popularized cel shaded graphics, though it failed to meet Sega's sales expectations. The role-playing game \"Skies of Arcadia\", developed by Overworks and produced by Rieko Kodama, was acclaimed for its surreal Jules Verne-inspired fantasy world of floating islands and sky pirates, charming protagonists, exciting airship battles and memorable plot.\nAM2 developed what Sega hoped would be the Dreamcast's killer app, \"Shenmue\", a \"revenge epic in the tradition of Chinese cinema\", with a level of detail considered unprecedented for a video game. Incorporating a simulated day-and-night cycle with variable weather, non-player characters with regular schedules, the ability to pick up and examine detailed objects, and introducing the quick-time event in its modern form, \"Shenmue\" went over budget and was rumored to have cost Sega over $50 million. According to Moore, \"Shenmue\" sold \"extremely well\", but had no chance of making a profit due to the Dreamcast's limited installed base.\nVisual Concepts' \"NFL 2K\" football series and its \"NBA 2K\" basketball series were critically acclaimed. \"NFL 2K\" was considered an outstanding launch game for its high-quality visuals and \"insightful, context-friendly, and, yes, even funny commentary\", while \"NFL 2K1\" featured groundbreaking online multiplayer earlier than its chief competitor, EA's \"Madden NFL\" series. \"Madden\" and \"2K\" continued to compete on other platforms through 2004, with the \"2K\" series introducing innovations such as a first person perspective new to the genre, and eventually launching \"ESPN NFL 2K5\" at the aggressively low price point of $19.95 until EA signed an exclusive agreement with the National Football League, effectively putting every other pro-football game out of business. After Sega sold Visual Concepts for $24 million in 2005, the \"NBA 2K\" series continued with publisher Take-Two Interactive. During the Dreamcast's lifespan, Visual Concepts also collaborated with the \"Sonic the Hedgehog\" level designer Hirokazu Yasuhara on the action-adventure game \"Floigan Bros.\" and developed the action game \"Ooga Booga\".\nPorts and third-party games.\nBefore the launch of the Dreamcast in Japan, Sega announced its NAOMI arcade board, a cheaper alternative to the Sega Model 3. NAOMI shares the same technology as the Dreamcast, with twice as much system, video, and audio memory and a 160\u00a0MB flash ROM board in place of a GD-ROM drive, allowing nearly identical home conversions of arcade games. Games were ported from NAOMI to the Dreamcast by several leading Japanese arcade companies, including Capcom and Namco. The Dreamcast also used parts similar to those found in personal computers with Pentium II and III processors, allowing a handful of ports of PC games.\nTo appeal to the European market, Sega formed a French affiliate, No Clich\u00e9, which developed games such as \"Toy Commander\". Sega Europe also approached Bizarre Creations to develop the racing game \"Metropolis Street Racer\". Although Acclaim, SNK, Ubisoft, Midway, Activision, Infogrames, and Capcom supported the Dreamcast during its first year, third-party support proved difficult to obtain due to the failure of the Sega Saturn and the profitability of publishing for the PlayStation. Namco's \"Soulcalibur\", for example, was released for the Dreamcast because of the relative unpopularity of the \"Soul\" series at the time; Namco's more successful \"Tekken\" franchise was associated with the PlayStation console and PlayStation-based arcade boards. Capcom produced a number of fighting games for the Dreamcast, including the \"Power Stone\" series, and a temporarily exclusive entry in the popular \"Resident Evil\" series, '. The Dreamcast is known for several shoot 'em ups, most notably Treasure's \"Bangai-O\" and \"Ikaruga\". Sega also revived franchises from the Genesis era, such as Appaloosa Interactive's '.\nNetwork services.\nDricas was an Internet service for Dreamcast consoles in Japan. The service launched the week of October 28, 1998, with its feature set expanded in the weeks preceding the Dreamcast's launch in Japan on November 27, 1998. Much of its infrastructure was developed by ISAO Corporation, which was spun-off from Sega on November 26, 1999. Its accompanying web browser, Dream Passport, provided the ability to connect via dial-up, browse the internet, receive and send e-mail, and chat with other users. Dricas persisted until March 7, 2000, when the service was consolidated into ISAO's multi-platform online service, isao.net. Isao.net maintained online services and game servers for the Dreamcast until Sega ceased operation of the online servers for \"Phantasy Star Online\", along with its GameCube port, on March 31, 2007.\nSegaNet was an Internet service for dial-up-based online gaming on the Dreamcast in the United States. The service was created by Sega in collaboration with GTE through its GTE Internetworking division, later renamed Genuity. Sega announced a partnership with AT&amp;T on August 4, 1999, making the AT&amp;T WorldNet service the preferred ISP for Dreamcast in the United States, and an agreement making Excite@Home as the exclusive portal partner for SegaNet. Microsoft participated somewhat in the development of the service, but they terminated their relationship with Sega just a few months before its launch over differences in its direction. SegaNet launched on September 7, 2000, and originally offered a rebate for a free Dreamcast and keyboard with a two-year contract. Because of the Dreamcast's discontinuation, Sega announced they would discontinue the service on July 20, 2001, less than 11 months after launch. Online support for Dreamcast games via SegaNet continued until 2003.\nDreamarena was a free dial-up-based online gaming service provided for Dreamcast consoles in Europe, launching with the debut of the Dreamcast in Europe on October 14, 1999. The service was created and operated for Sega Europe by a partnership between ICL, BT and various ISPs. The service was accessed via the DreamKey browser, which was also built into some games such as \"Sonic Adventure 2\". After the discontinuation of the Dreamcast, Sega closed Dreamarena on February 28, 2002.\nReception and legacy.\nIn December 1999, \"Next Generation\" rated the Dreamcast four out of five, writing: \"If you want the most powerful system available now, showcasing the best graphics at a reasonable price, this system is for you.\" However, \"Next Generation\" gave its future prognosis three out of five, noting that Sony and Nintendo were both due to release more powerful consoles. At the beginning of 2000, five \"Electronic Gaming Monthly\" reviewers scored the Dreamcast 8.5, 8.5, 8.5, 8.0, and 9.0 out of 10. In 2001, the \"Electronic Gaming Monthly\" reviewers scored it 9.0, 9.0, 9.0, 9.0, and 9.5 out of 10. \"BusinessWeek\" named the Dreamcast one of the best products of 1999.\nReasons cited for the failure of the Dreamcast include consumer excitement for the PS2; a lack of support from EA and Squaresoft, the most popular third parties in the US and Japan respectively; disagreement among executives over Sega's future, and Okawa's lack of commitment to the product; Sega's lack of advertising money, with Bellfield doubting that Sega spent even \"half\" the $100 million it had pledged to promote the Dreamcast in the US; that the market was not ready for online gaming; Sega's focus on \"hardcore\" gamers over mainstream consumers; poor timing; and damage to Sega's reputation caused by its several poorly supported previous platforms. In \"GamePro\", Blake Snow wrote of \"the much beloved [Dreamcast] launched years ahead of the competition but ultimately struggled to shed the negative reputation [Sega] had gained during the Saturn, Sega 32X, and Sega CD days. As a result, casual gamers and jaded third-party developers doubted Sega's ability to deliver.\"\n\"Eurogamer\"'s Dan Whitehead noted that consumers' \"wait-and-see\" approach, and the lack of support from EA, were symptoms rather the cause of Sega's decline. He concluded that \"Sega's misadventures during the 1990s had left both gamers and publishers wary of any new platform bearing its name\". According to \"1Up.com\"'s Jeremy Parish, it would be intellectually dishonest to blame Sony for \"killing the Dreamcast by overselling the PS2\", as Sega's lack of support for previous consoles had made customers hesitant to purchase Dreamcasts.\nIn 2009, \"IGN\" named the Dreamcast the eighth-greatest video game console, praising its software and innovations, including its online play. In 2010, \"PC Magazine\"'s Jeffrey L. Wilson named the Dreamcast the greatest console and said that it was \"gone too soon\". In 2013, \"Edge\" named the Dreamcast the tenth-best console of the last 20 years, highlighting innovations including in-game voice chat, downloadable content, and second-screen technology through the use of VMUs. \"Edge\" wrote that \"Sega's console was undoubtedly ahead of its time, and it suffered at retail for that reason... [b]ut its influence can still be felt today.\" Dan Whitehead of \"Eurogamer\" likened the Dreamcast to \"a small, square, white plastic JFK. A progressive force in some ways, perhaps misguided in others, but nevertheless a promising life cut tragically short by dark shadowy forces, spawning complex conspiracy theories that endure to this day.\" He wrote that its short lifespan \"may have sealed its reputation as one of the greatest consoles ever\", as \"nothing builds a cult like a tragic demise\". According to \"IGN\"'s Travis Fahs, \"Many hardware manufacturers have come and gone, but it's unlikely any will go out with half as much class as Sega.\"&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nIf ever a system deserved to succeed, it was Dreamcast. Dreamcast has a hell of a library. It's dying now, 18 months old, with a larger library than the 5-year-old Nintendo 64. It's a better library than the Nintendo 64. Dreamcast was a wonderful system.\n \u2014Journalist Steven L. Kent, March 2001.\nThe Dreamcast's game library was celebrated. In January 2000, three months after the Dreamcast's North American launch, \"Electronic Gaming Monthly\" wrote that \"with triple-A stuff like \"Soul Calibur\", \"NBA 2K\", and soon \"Crazy Taxi\" to kick around, we figure you're happy you took the 128-bit plunge\". In a retrospective, \"PC Magazine\"'s Jeffrey L. Wilson referred to Dreamcast's \"killer library\" and said that Sega's creative influence and visual innovation had been at its peak. The staff of \"Edge\" agreed with this assessment of Dreamcast games, including Sega's arcade conversions, stating that the system \"delivered the first games that could meaningfully be described as arcade perfect\". Damien McFerran of \"Retro Gamer\" praised Dreamcast's NAOMI arcade ports, and wrote: \"The thrill of playing \"Crazy Taxi\" in the arcade knowing full well that a pixel-perfect conversion (and not some cut-down port) was set to arrive on the Dreamcast is an experience gamers are unlikely to witness again.\"\nNick Montfort and Mia Consalvo, writing in \"Loading... The Journal of the Canadian Game Studies Association\", argued that \"the Dreamcast hosted a remarkable amount of video game development that went beyond the odd and unusual and is interesting when considered as avant-garde\u00a0... It is hard to imagine a commercial console game expressing strong resistance to the commodity perspective and to the view that game production is commerce. But even when it comes to resisting commercialization, it is arguable that Dreamcast games came closer to expressing this attitude than any other console games have.\" \"1Up.com\"'s Jeremy Parish favorably compared Sega's Dreamcast output, which included some of \"the most varied, creative, and fun [games] the company had ever produced\", with its \"enervated\" status as a third-party. Fahs noted, \"The Dreamcast's life was fleeting, but it was saturated with memorable titles, most of which were completely new properties.\" According to author Steven L. Kent, \"From \"Sonic Adventure\" and \"Shenmue\" to \"Space Channel 5\" and \"Seaman\", Dreamcast delivered and delivered and delivered.\"\nSome journalists have compared the demise of the Dreamcast with changing trends in the video game industry. In \"1001 Video Games You Must Play Before You Die\", Duncan Harris wrote: \"One of the reasons that older gamers mourned the loss of the Dreamcast was that it signaled the demise of arcade gaming culture\u00a0... Sega's console gave hope that things were not about to change for the worse and that the tenets of fast fun and bright, attractive graphics were not about to sink into a brown and green bog of realistic war games.\" Jeremy Parish, writing for \"USgamer\", contrasted the Dreamcast's diverse library with the \"suffocating sense of conservatism\" that pervaded the gaming industry in the following decade. According to Sega's head of product implementation, Tadashi Takezaki, the Dreamcast would have been Sega's last video game console no matter how it sold because of the changes in the market and the rise of PCs. He praised the Dreamcast for its features, saying in 2013, \"The seeds we sowed with the Dreamcast are finally bearing fruit at this point in time. In some ways, we were going by the seat of our pants, but it was part of the Sega credo at the time \u2014 if it's fun, then go for it.\"\nThe Dreamcast remains popular in the video game homebrew community. By 2014, unlicensed Dreamcast games formatted for MIL-CD, a multimedia-enhanced format developed by Sega and supported by the Dreamcast, continued to be released. After Sega shut down the official Dreamcast servers, hobbyists developed private servers to allow games such as \"Phantasy Star Online\" to continue being played online. Hobbyists have restored online functions for 40 Dreamcast games as of 2025.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29037", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=29037", "title": "Sega NOMAD", "text": ""}
{"id": "29038", "revid": "9092818", "url": "https://en.wikipedia.org/wiki?curid=29038", "title": "SEGA", "text": ""}
{"id": "29039", "revid": "1319099780", "url": "https://en.wikipedia.org/wiki?curid=29039", "title": "SH3 domain", "text": "Small protein domain found in some kinases and GTPases\nThe SRC Homology 3 Domain (or SH3 domain) is a small protein domain of about 60 amino acid residues. Initially, SH3 was described as a conserved sequence in the viral adaptor protein v-Crk. This domain is also present in the molecules of phospholipase and several cytoplasmic tyrosine kinases such as Abl and Src. It has also been identified in several other protein families such as: PI3 Kinase, Ras GTPase-activating protein, CDC24 and cdc25. SH3 domains are found in proteins of signaling pathways regulating the cytoskeleton, the Ras protein, and the Src kinase and many others. The SH3 proteins interact with adaptor proteins and tyrosine kinases. Interacting with tyrosine kinases, SH3 proteins usually bind far away from the active site. Approximately 300 SH3 domains are found in proteins encoded in the human genome. In addition to that, the SH3 domain was responsible for controlling protein-protein interactions in the signal transduction pathways and regulating the interactions of proteins involved in the cytoplasmic signaling.\nStructure.\nThe SH3 domain has a characteristic beta-barrel fold that consists of five or six \u03b2-strands arranged as two tightly packed anti-parallel \u03b2 sheets. The linker regions may contain short helices. The SH3-type fold is an ancient fold found in eukaryotes as well as prokaryotes.\nPeptide binding.\nThe classical SH3 domain is usually found in proteins that interact with other proteins and mediate assembly of specific protein complexes, typically via binding to proline-rich peptides in their respective binding partner. Classical SH3 domains are restricted in humans to intracellular proteins, although the small human MIA family of extracellular proteins also contain a domain with an SH3-like fold.\nMany SH3-binding epitopes of proteins have a consensus sequence that can be represented as a regular expression or Short linear motif:\n -X-P-p-X-P-\n 1 2 3 4 5\nwith 1 and 4 being aliphatic amino acids, 2 and 5 always and 3 sometimes being proline. The sequence binds to the hydrophobic pocket of the SH3 domain. More recently, SH3 domains that bind to a core consensus motif R-x-x-K have been described. Examples are the C-terminal SH3 domains of adaptor proteins like Grb2 and Mona (a.k.a. Gads, Grap2, Grf40, GrpL etc.). Other SH3 binding motifs have emerged and are still emerging in the course of various molecular studies, highlighting the versatility of this domain.\nSH3 interactomes.\nSH3 domain-mediated protein-protein interaction networks, \"i.e.\", SH3 interactomes, revealed that worm SH3 interactome resembles the analogous yeast network because it is significantly enriched for proteins with roles in endocytosis. Nevertheless, orthologous SH3 domain-mediated interactions are highly rewired between worm and yeast."}
{"id": "29040", "revid": "84591", "url": "https://en.wikipedia.org/wiki?curid=29040", "title": "Generalized Stokes theorem", "text": "Statement about integration on manifolds\nIn vector calculus and differential geometry the generalized Stokes theorem (sometimes with apostrophe as Stokes' theorem or Stokes's theorem), also called the Stokes\u2013Cartan theorem, is a statement about the integration of differential forms on manifolds, which both simplifies and generalizes several theorems from vector calculus. In particular, the fundamental theorem of calculus is the special case where the manifold is a line segment, Green\u2019s theorem and Stokes' theorem are the cases of a surface in formula_1 or &amp;NoBreak;&amp;NoBreak;, and the divergence theorem is the case of a volume in &amp;NoBreak;&amp;NoBreak;. Hence, the theorem is sometimes referred to as the fundamental theorem of multivariate calculus.\nStokes' theorem says that the integral of a differential form formula_2 over the boundary formula_3 of some orientable manifold formula_4 is equal to the integral of its exterior derivative formula_5 over the whole of &amp;NoBreak;&amp;NoBreak;, i.e.,\nformula_6\nStokes' theorem was formulated in its modern form by \u00c9lie Cartan in 1945, following earlier work on the generalization of the theorems of vector calculus by Vito Volterra, \u00c9douard Goursat, and Henri Poincar\u00e9.\nThis modern form of Stokes' theorem is a vast generalization of a classical result that Lord Kelvin communicated to George Stokes in a letter dated July 2, 1850. Stokes set the theorem as a question on the 1854 Smith's Prize exam, which led to the result bearing his name. It was first published by Hermann Hankel in 1861. This classical case relates the surface integral of the curl of a vector field formula_7 over a surface (that is, the flux of &amp;NoBreak;}&amp;NoBreak;) in Euclidean three-space to the line integral of the vector field over the surface boundary.\nIntroduction.\nThe second fundamental theorem of calculus states that the integral of a function formula_8 over the interval formula_9 can be calculated by finding an antiderivative formula_10 of &amp;NoBreak;&amp;NoBreak;:\nformula_11\nStokes' theorem is a vast generalization of this theorem in the following sense. \nIn even simpler terms, one can consider the points as boundaries of curves, that is as 0-dimensional boundaries of 1-dimensional manifolds. So, just as one can find the value of an integral (&amp;NoBreak;&amp;NoBreak;) over a 1-dimensional manifold (&amp;NoBreak;&amp;NoBreak;) by considering the anti-derivative (&amp;NoBreak;&amp;NoBreak;) at the 0-dimensional boundaries (&amp;NoBreak;}&amp;NoBreak;), one can generalize the fundamental theorem of calculus, with a few additional caveats, to deal with the value of integrals (&amp;NoBreak;&amp;NoBreak;) over &amp;NoBreak;&amp;NoBreak;-dimensional manifolds (&amp;NoBreak;&amp;NoBreak;) by considering the antiderivative (&amp;NoBreak;&amp;NoBreak;) at the &amp;NoBreak;&amp;NoBreak;-dimensional boundaries (&amp;NoBreak;&amp;NoBreak;) of the manifold.\nSo the fundamental theorem reads:\nformula_25\nFormulation for smooth manifolds with boundary.\nLet formula_4 be an oriented smooth manifold of dimension formula_27 with boundary and let formula_28 be a smooth &amp;NoBreak;&amp;NoBreak;-differential form that is compactly supported on &amp;NoBreak;&amp;NoBreak;. First, suppose that formula_28 is compactly supported in the domain of a single, oriented coordinate chart &amp;NoBreak;}&amp;NoBreak;. In this case, we define the integral of formula_28 over formula_4 as\nformula_32\ni.e., via the pullback of formula_28 to &amp;NoBreak;&amp;NoBreak;.\nMore generally, the integral of formula_28 over formula_4 is defined as follows: Let formula_36 be a partition of unity associated with a locally finite cover formula_37 of (consistently oriented) coordinate charts, then define the integral\nformula_38\nwhere each term in the sum is evaluated by pulling back to formula_39 as described above. This quantity is well-defined; that is, it does not depend on the choice of the coordinate charts, nor the partition of unity.\nThe generalized Stokes theorem reads:\n&lt;templatestyles src=\"Math_theorem/styles.css\" /&gt;\nTheorem\u00a0(\"Stokes\u2013Cartan\")\u2014 Let formula_2 be a smooth &amp;NoBreak;&amp;NoBreak;-form with compact support on an oriented, &amp;NoBreak;&amp;NoBreak;-dimensional manifold-with-boundary &amp;NoBreak;&amp;NoBreak;, where formula_41 is given the induced orientation. Then formula_42\nHere formula_43 is the exterior derivative, which is defined using the manifold structure only. The right-hand side is sometimes written as formula_44 to stress the fact that the &amp;NoBreak;&amp;NoBreak;-manifold formula_3 has no boundary. (This fact is also an implication of Stokes' theorem, since for a given smooth &amp;NoBreak;&amp;NoBreak;-dimensional manifold &amp;NoBreak;&amp;NoBreak;, application of the theorem twice gives formula_46 for any &amp;NoBreak;&amp;NoBreak;-form &amp;NoBreak;&amp;NoBreak;, which implies that &amp;NoBreak;&amp;NoBreak;.) The right-hand side of the equation is often used to formulate integral laws; the left-hand side then leads to equivalent differential formulations (see below).\nThe theorem is often used in situations where formula_4 is an embedded oriented submanifold of some bigger manifold, often &amp;NoBreak;&amp;NoBreak;, on which the form formula_2 is defined.\nTopological preliminaries; integration over chains.\nLet M be a smooth manifold. A (smooth) singular k-simplex in M is defined as a smooth map from the standard simplex in R\"k\" to M. The group \"C\"\"k\"(\"M\", Z) of singular k-chains on M is defined to be the free abelian group on the set of singular k-simplices in M. These groups, together with the boundary map, \u2202, define a chain complex. The corresponding homology (resp. cohomology) group is isomorphic to the usual singular homology group \"H\"\"k\"(\"M\", Z) (resp. the singular cohomology group \"H\"\"k\"(\"M\", Z)), defined using continuous rather than smooth simplices in M.\nOn the other hand, the differential forms, with exterior derivative, d, as the connecting map, form a cochain complex, which defines the de Rham cohomology groups &amp;NoBreak;&amp;NoBreak;.\nDifferential k-forms can be integrated over a k-simplex in a natural way, by pulling back to R\"k\". Extending by linearity allows one to integrate over chains. This gives a linear map from the space of k-forms to the kth group of singular cochains, \"Ck\"(\"M\", Z), the linear functionals on \"Ck\"(\"M\", Z). In other words, a k-form \u03c9 defines a functional\nformula_49\non the k-chains. Stokes' theorem says that this is a chain map from de Rham cohomology to singular cohomology with real coefficients; the exterior derivative, d, behaves like the \"dual\" of \u2202 on forms. This gives a homomorphism from de Rham cohomology to singular cohomology. On the level of forms, this means:\nDe Rham's theorem shows that this homomorphism is in fact an isomorphism. So the converse to 1 and 2 above hold true. In other words, if {\"ci\"} are cycles generating the kth homology group, then for any corresponding real numbers, {\"ai\"}, there exist a closed form, \u03c9, such that\nformula_50\nand this form is unique up to exact forms.\nStokes' theorem on smooth manifolds can be derived from Stokes' theorem for chains in smooth manifolds, and vice versa. Formally stated, the latter reads:\n&lt;templatestyles src=\"Math_theorem/styles.css\" /&gt;\nTheorem\u00a0(\"Stokes' theorem for chains\")\u2014If c is a smooth k-chain in a smooth manifold M, and \u03c9 is a smooth (\"k\" \u2212 1)-form on M, then\nformula_51\nUnderlying principle.\nTo simplify these topological arguments, it is worthwhile to examine the underlying principle by considering an example for \"d\" = 2 dimensions. The essential idea can be understood by the diagram on the left, which shows that, in an oriented tiling of a manifold, the interior paths are traversed in opposite directions; their contributions to the path integral thus cancel each other pairwise. As a consequence, only the contribution from the boundary remains. It thus suffices to prove Stokes' theorem for sufficiently fine tilings (or, equivalently, simplices), which usually is not difficult.\nClassical vector analysis example.\nLet formula_52 be a piecewise smooth Jordan plane curve. The Jordan curve theorem implies that formula_53 divides formula_1 into two components, a compact one and another that is non-compact. Let formula_55 denote the compact part that is bounded by formula_53 and suppose formula_57 is smooth, with &amp;NoBreak;&amp;NoBreak;. If formula_58 is the space curve defined by &amp;NoBreak;&amp;NoBreak; and formula_7 is a smooth vector field on &amp;NoBreak;&amp;NoBreak;, then:\nformula_60\nThis classical statement is a special case of the general formulation after making an identification of vector field with a 1-form and its curl with a two form through \nformula_61\nformula_62\nGeneralization to rough sets.\nThe formulation above, in which formula_4 is a smooth manifold with boundary, does not suffice in many applications. For example, if the domain of integration is defined as the plane region between two x-coordinates and the graphs of two functions, it will often happen that the domain has corners. In such a case, the corner points mean that formula_4 is not a smooth manifold with boundary, and so the statement of Stokes' theorem given above does not apply. Nevertheless, it is possible to check that the conclusion of Stokes' theorem is still true. This is because formula_4 and its boundary are well-behaved away from a small set of points (a measure zero set).\nA version of Stokes' theorem that allows for roughness was proved by Hassler Whitney. Assume that formula_55 is a connected bounded open subset of &amp;NoBreak;&amp;NoBreak;. Call formula_55 a \"&lt;dfn &gt;standard domain&lt;/dfn&gt;\" if it satisfies the following property: there exists a subset formula_68 of &amp;NoBreak;&amp;NoBreak;, open in &amp;NoBreak;&amp;NoBreak;, whose complement in formula_69 has Hausdorff &amp;NoBreak;&amp;NoBreak;-measure zero; and such that every point of formula_68 has a \"&lt;dfn &gt;generalized normal vector&lt;/dfn&gt;\". This is a vector formula_71 such that, if a coordinate system is chosen so that formula_71 is the first basis vector, then, in an open neighborhood around &amp;NoBreak;&amp;NoBreak;, there exists a smooth function formula_73 such that formula_68 is the graph formula_75 and formula_55 is the region &amp;NoBreak;}&amp;NoBreak;. Whitney remarks that the boundary of a standard domain is the union of a set of zero Hausdorff &amp;NoBreak;&amp;NoBreak;-measure and a finite or countable union of smooth &amp;NoBreak;&amp;NoBreak;-manifolds, each of which has the domain on only one side. He then proves that if formula_55 is a standard domain in &amp;NoBreak;&amp;NoBreak;, formula_2 is an &amp;NoBreak;&amp;NoBreak;-form which is defined, continuous, and bounded on &amp;NoBreak;&amp;NoBreak;, smooth on &amp;NoBreak;&amp;NoBreak;, integrable on &amp;NoBreak;&amp;NoBreak;, and such that formula_5 is integrable on &amp;NoBreak;&amp;NoBreak;, then Stokes' theorem holds, that is,\nformula_80\nThe study of measure-theoretic properties of rough sets leads to geometric measure theory. Even more general versions of Stokes' theorem have been proved by Federer and by Harrison.\nSpecial cases.\nThe general form of the Stokes theorem using differential forms is more powerful and easier to use than the special cases. The traditional versions can be formulated using Cartesian coordinates without the machinery of differential geometry, and thus are more accessible. Further, they are older and their names are more familiar as a result. The traditional forms are often considered more convenient by practicing scientists and engineers but the non-naturalness of the traditional formulation becomes apparent when using other coordinate systems, even familiar ones like spherical or cylindrical coordinates. There is potential for confusion in the way names are applied, and the use of dual formulations.\nClassical (vector calculus) case.\nThis is a (dualized) &amp;NoBreak;&amp;NoBreak;-dimensional case, for a 1-form (dualized because it is a statement about vector fields). This special case is often just referred to as \"Stokes' theorem\" in many introductory university vector calculus courses and is used in physics and engineering. It is also sometimes known as the curl theorem.\nThe classical Stokes' theorem relates the surface integral of the curl of a vector field over a surface formula_81 in Euclidean three-space to the line integral of the vector field over its boundary. It is a special case of the general Stokes theorem (with &amp;NoBreak;&amp;NoBreak;) once we identify a vector field with a 1-form using the metric on Euclidean 3-space. The curve of the line integral, &amp;NoBreak;&amp;NoBreak;, must have positive orientation, meaning that formula_82 points counterclockwise when the surface normal, &amp;NoBreak;&amp;NoBreak;, points toward the viewer.\nOne consequence of this theorem is that the field lines of a vector field with zero curl cannot be closed contours. The formula can be rewritten as:\n&lt;templatestyles src=\"Math_theorem/styles.css\" /&gt;\nTheorem\u2014 Suppose formula_83 is defined in a region with smooth surface formula_81 and has continuous first-order partial derivatives. Then\nformula_85\nwhere formula_86 and formula_87 are the components of &amp;NoBreak;}&amp;NoBreak;, and formula_82 is the boundary of the region &amp;NoBreak;&amp;NoBreak;.\nGreen's theorem.\nGreen's theorem is immediately recognizable as the third integrand of both sides in the integral in terms of P, Q, and R cited above.\nIn electromagnetism.\nTwo of the four Maxwell equations involve curls of 3-D vector fields, and their differential and integral forms are related by the special 3-dimensional (vector calculus) case of Stokes' theorem. Caution must be taken to avoid cases with moving boundaries: the partial time derivatives are intended to exclude such cases. If moving boundaries are included, interchange of integration and differentiation introduces terms related to boundary motion not included in the results below (see Differentiation under the integral sign):\n&lt;templatestyles src=\"Template:vertical align rows/styles.css\" /&gt;\nThe above listed subset of Maxwell's equations are valid for electromagnetic fields expressed in SI units. In other systems of units, such as CGS or Gaussian units, the scaling factors for the terms differ. For example, in Gaussian units, Faraday's law of induction and Amp\u00e8re's law take the forms:\nformula_89\nrespectively, where c is the speed of light in vacuum.\nDivergence theorem.\nLikewise, the divergence theorem\nformula_90\nis a special case if we identify a vector field with the &amp;NoBreak;&amp;NoBreak;-form obtained by contracting the vector field with the Euclidean volume form. An application of this is the case formula_91 where formula_92 is an arbitrary constant vector. Working out the divergence of the product gives\nformula_93\nSince this holds for all formula_92 we find\nformula_95\nVolume integral of gradient of scalar field.\nLet formula_96 be a scalar field. Then\nformula_97\nwhere formula_98 is the normal vector to the surface formula_41 at a given point.\nProof:\nLet formula_92 be a vector. Then\nformula_101\nSince this holds for any formula_92 (in particular, for every basis vector), the result follows.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29042", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=29042", "title": "Superfetation", "text": "Simultaneous presence of multiple stages of developing offspring in one animal\nSuperfetation (also spelled superfoetation \u2013 see fetus) is the simultaneous occurrence of more than one stage of developing offspring in the same animal. This phenomenon is extremely rare in humans, with only 10 confirmed cases.\nIn mammals, it manifests as the formation of an embryo from a subsequent menstrual cycle, while another embryo or fetus is already present in the uterus. When two separate instances of fertilization occur during the same menstrual cycle, it is known as superfecundation.\nHumans.\nWhile proposed cases of superfetation have been reported in humans, the existence of this phenomenon in humans has been deemed unlikely. Better explanations include differential growth between twins due to various reasons, such as twin-to-twin transfusion syndrome. Artificially-induced superfetation has been demonstrated, although only up to a short period after insemination.\nA 2008 French study found evidence to suggest that superfetation is a reality for humans, but that it is so rare that there have been fewer than 10 recorded cases in the world.\nIn 2017, it was reported that an American woman who had agreed to act as a surrogate for a Chinese couple bore two babies, who were initially believed to be twins. Before the adoptive parents could return home to China, however, it was discovered that one of the babies was, in fact, the biological son of the surrogate. Doctors confirmed that the birth-mother had become pregnant with her and her partner's child, roughly three weeks after becoming pregnant with the Chinese couple's child.\nResearch has found that 10% of women release two eggs in a cycle, but both eggs are released at the end of the same \"wave\" of folliculogenesis, which does not support the theory of superfetation in humans.\nIn 2017, a woman in \u0130zmir, Turkey, became pregnant with two babies conceived about a month apart and she gave birth to both on 7 October 2017. According to the news report this event has officially been registered in global medical records as the 12th superfetation case. \nIn September 2020, a woman in Wiltshire, England, gave birth to fraternal twins, who were conceived three weeks apart.\nOther animals.\nSuperfetation is normal for some species of poeciliid fish and has been clearly demonstrated for the European brown hare.\nIn domestic cats, superfecundation is common, but superfetation never has been definitively proven to occur.\nAnimals that have been claimed to be subject to superfetation include rodents (mice and rats), rabbits, horses, sheep, marsupials (kangaroos and sugar gliders), felines, and primates (humans).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29043", "revid": "1289561556", "url": "https://en.wikipedia.org/wiki?curid=29043", "title": "Steenbeck", "text": "Flatbed film editor manufacturer\nSteenbeck was a company that manufactured flatbed editors. Steenbeck is a brand name that has become synonymous with a type of flatbed film editing suite which is usable with both 16 mm and 35 mm optical sound and magnetic sound film.\nThe Steenbeck company was founded in 1931 by Wilhelm Steenbeck in Hamburg, Germany. Since then, Steenbeck editing tables have become ubiquitous in the film editing community and have seen significant use in television production. In total, more than 25,000 machines are in operation around the world. The company relocated to Venray, Netherlands, in September 2003, and went out of business in 2024.https://www.faillissementsdossier.nl/en/bankruptcy/1841457/steenbeck-b-v.aspx\nDespite the move away from physical film stock \u2013 much editing is now based on digital media \u2013 devices such as the Lightworks non-linear film editing controller and archives still use the Steenbeck for controlling the process. The Steenbeck's lower light levels and controllable speed make it a preferred piece of equipment for film archives (such as the Library of Congress's motion picture collection) and restoration facilities as prints can be quickly and easily inspected with less risk of damage compared with a movie projector. Because there is no intermittent movement, the image is created through a rotating prism which scans the frames. Steenbeck machines were known to be exceptionally easy on film stock, due to their use of soft-edged nylon rollers."}
{"id": "29044", "revid": "4293477", "url": "https://en.wikipedia.org/wiki?curid=29044", "title": "Sexual relations", "text": ""}
{"id": "29045", "revid": "57939", "url": "https://en.wikipedia.org/wiki?curid=29045", "title": "Speciesism", "text": "Philosophical term on species treatment\nSpeciesism () is a term used in philosophy regarding the treatment of individuals of different species. The term has several different definitions. Some specifically define speciesism as discrimination or unjustified treatment based on an individual's species membership, while others define it as differential treatment without regard to whether the treatment is justified or not. Richard D. Ryder, who coined the term, defined it as \"a prejudice or attitude of bias in favour of the interests of members of one's own species and against those of members of other species\". Speciesism results in the belief that humans have the right to use non-human animals in exploitative ways which is pervasive in the modern society. Studies from 2015 and 2019 suggest that people who support animal exploitation also tend to have intersectional bias that encapsulates and endorses racist, sexist, and other prejudicial views, which furthers the beliefs in human supremacy and group dominance to justify systems of inequality and oppression.\nAs a term, speciesism first appeared during a protest against animal experimentation in 1970. Philosophers and animal rights advocates state that speciesism plays a role in the animal\u2013industrial complex, including in the practice of factory farming, animal slaughter, blood sports (such as bullfighting, cockfighting and rodeos), the taking of animals' fur and skin, and experimentation on animals, as well as the refusal to help animals suffering in the wild due to natural processes, and the categorization of certain animals as alien, non-naturalized, feral and invasive giving then the justification to their killing or culling based on these classifications.\nNotable proponents of the concept include Peter Singer, Oscar Horta, Steven M. Wise, Gary L. Francione, Melanie Joy, David Nibert, Steven Best, and Ingrid Newkirk. Among academics, the ethics, morality, and concept of speciesism has been the subject of substantial philosophical debate. Carl Cohen, Nel Noddings, Bernard Williams, Peter Staudenmaier, Christopher Grau, Douglas Maclean, Roger Scruton, Thomas Wells, and Robert Nozick have criticized the term or elements of it.\nHistory.\nPreceding ideas.\nEarly perspectives on animal sensation and kinship.\nBuffon, a French naturalist, writing in \"Histoire Naturelle\" in 1753, questioned whether it could be doubted that animals \"whose organization is similar to ours, must experience similar sensations\", and that \"those sensations must be proportioned to the activity and perfection of their senses\". Despite these assertions, he also maintained that there exists a gap between humans and other animals. In the poem \"Po\u00e8me sur le d\u00e9sastre de Lisbonne\", Voltaire described a kinship between sentient beings, humans and animals alike, writing: \"All sentient things, born by the same stern law, / Suffer like me, and like me also die.\"\nJeremy Bentham.\nJeremy Bentham has been identified as an early Western philosopher to advocate for animals' equal consideration within a comprehensive, secular moral framework. He argued that species membership is morally irrelevant and that any being capable of suffering has intrinsic value. In his 1789 book \"An Introduction to the Principles of Morals and Legislation\", he wrote:\nThe day may come, when the rest of the animal creation may acquire those rights which never could have been withheld from them but by the hand of tyranny. ... [T]he question is not, Can they reason? nor, Can they talk? but, Can they suffer?\nBentham also supported animal welfare laws. At the same time, he accepted the killing and use of animals, provided that what he regarded as unnecessary cruelty was avoided.\nLewis Gompertz.\nIn his 1824 work \"Moral Inquiries on the Situation of Man and of Brutes\", English writer and early animal rights advocate Lewis Gompertz argued for egalitarianism, extending it to nonhuman animals. He stated that humans and animals have highly similar feelings and sensations, noting that experiences such as hunger, desire, fear and anger affect both in similar ways. Gompertz also pointed to shared physiological characteristics between humans and animals, suggesting a similarity in sensation. He criticized human use of animals, drawing attention to what he saw as a disregard for their feelings, needs and desires.\nCharles Darwin.\nEnglish naturalist Charles Darwin, writing in his notebook in 1838, observed that humans tend to regard themselves as masterpieces produced by a deity, but recorded his own view that it was \"truer to consider him created from animals\". In his 1871 book \"The Descent of Man\", Darwin argued:\nThere is no fundamental difference between man and the higher mammals in their mental faculties ... [t]he difference in mind between man and the higher animals, great as it is, certainly is one of degree and not of kind. We have seen that the senses and intuitions, the various emotions and faculties, such as love, memory, attention, curiosity, imitation, reason, etc., of which man boasts, may be found in an incipient, or even sometimes in a well-developed condition, in the lower animals.\nLewis H. Morgan.\nIn 1843 Lewis H. Morgan published \"\" in \"The Knickerbocker\", where he used anecdotes such as dogs returning to surgeons, beavers building dams, ants storing grain and marmots posting lookouts to argue that animals display memory, foresight and reasoning. He rejected appeals to \"instinct\" as an explanation, suggesting instead that humans and other species share a common mental principle differing only in degree, and he questioned claims of human moral superiority while criticizing practices such as hunting for sport and killing animals for food. He developed these arguments in 1857 in an unpublished paper, \"Animal Psychology\", read to the Pundit Club in Rochester, New York, which again rejected instinct and attributed animal behavior to perception, memory, reflection, volition and reason. Morgan also speculated that animals might possess moral capacities and immortal souls, and he placed species on a \"scale of gradation\" of intelligence while remaining a creationist. Although little noticed at the time, the essay has been described in later scholarship as an unusually early critique of instinct within American comparative psychology.\nArthur Schopenhauer.\nGerman philosopher Arthur Schopenhauer criticized anthropocentrism as, in his view, a fundamental defect of Christianity and Judaism. He argued that these religions contributed to the suffering of sentient beings by separating humans from other animals and encouraging their treatment as mere things. By contrast, Schopenhauer praised Brahmanism and Buddhism for their focus on kinship between humans and other animals and for their teaching about a connection between them through metempsychosis.\nSecular and utilitarian animal advocacy.\nAccording to historian Chien-Hui Li, some secularist thinkers in the late 19th and early 20th centuries argued for animals on utilitarian grounds and on the basis of evolutionary kinship, linking their views to a broader critique of Christian doctrines about suffering and social order. These secularists sought a morality independent of religious authority. Some initially supported vivisection for human benefit but later questioned its necessity. Figures such as G. W. Foote argued for broader utility, focusing on long-term moral principles rather than immediate gains. Drawing on evolutionary theories, they described common origins and similarities between humans and animals and argued that morality should extend to animals as beings capable of experiencing pain and pleasure. They rejected the idea of a theological gulf separating humans from animals and used contemporary scientific theories to support various proposals for animal rights and welfare.\nBritish writer and animal rights advocate Henry S. Salt, in his 1892 book \"Animals' Rights\", argued that for humans to do justice to other animals they must look beyond the conception of a \"great gulf\" between them, claiming instead that people should recognize the \"common bond of humanity that unites all living beings in one universal brotherhood\".\nEdward Payson Evans, an American scholar and animal rights advocate, criticized anthropocentric psychology and ethics in his 1897 work \"Evolutional Ethics and Animal Psychology\". He argued that such views treat humans as fundamentally different from other sentient beings, and he denied that this distinction removes all moral obligations toward animals. Evans held that Darwin's theory of evolution implies moral duties not only toward enslaved humans but also toward nonhuman animals. He asserted that beyond kind treatment, animals need enforceable rights to protect them from cruelty. Evans contended that recognizing kinship between humans and other sentient beings would make it impossible, in his view, to mistreat them.\nAn 1898 article in \"The Zoophilist\", titled \"Anthropocentric Ethics\", argued that some early civilizations, prior to Christianity, regarded tenderness and mercy toward sentient beings as a moral requirement. It discussed Zarathustra, Buddha and early Greek philosophers, who practiced vegetarianism, as exemplifying this outlook. The article claimed that this understanding of human\u2013animal kinship persisted into early Christianity but was challenged by figures such as Origen, who saw animals as mere automata for human use. It concluded that the relationship between animal psychology and evolutionary ethics was gaining scientific and moral attention and could no longer be ignored.\nIn 1895, American zoologist, philosopher and animal rights advocate J. Howard Moore described vegetarianism as the ethical result of recognizing the evolutionary kinship of all creatures, connecting his position with Darwin's insights. He criticized what he called the \"pre-Darwinian delusion\" that nonhuman animals were created for human use. In his 1899 book \"Better-World Philosophy\", Moore argued that human ethics were still anthropocentric, having developed to include various human groups but not animals. He proposed \"zoocentricism\" as a further development, extending ethical concern to the entire sentient universe. In his 1906 book \"The Universal Kinship\", Moore criticized what he described as a \"provincialist\" attitude leading to animal mistreatment, comparing it to denying ethical relations among human groups. He rejected what he saw as a human-centric perspective and urged consideration of the standpoint of animal victims. Moore concluded that the Golden Rule should apply to all sentient beings, advocating equal ethical consideration for animals and humans:\n[D]o as you would be done by, and \"not\" to the dark man and the white woman alone, but to the sorrel horse and the gray squirrel as well; \"not\" to creatures of your own anatomy only, but to \"all\" creatures.\nCoining of the term.\nThe term \"speciesism\", and the argument that it is a prejudice, first appeared in 1970 in a privately printed pamphlet written by British psychologist Richard D. Ryder. Ryder was a member of a group of academics in Oxford, England, the nascent animal rights community, now known as the Oxford Group. One of the group's activities was distributing pamphlets about areas of concern; the pamphlet titled \"Speciesism\" was written to protest against animal experimentation. The term was intended by its proponents to create a rhetorical and categorical link to racism and sexism.\nRyder stated in the pamphlet that \"[s]ince Darwin, scientists have agreed that there is no 'magical' essential difference between humans and other animals, biologically-speaking. Why then do we make an almost total distinction morally? If all organisms are on one physical continuum, then we should also be on the same moral continuum.\" He wrote that, at that time in the United Kingdom, 5,000,000 animals were being used each year in experiments, and that attempting to gain benefits for our own species through the mistreatment of others was \"just 'speciesism' and as such it is a selfish emotional argument rather than a reasoned one\". Ryder used the term again in an essay, \"Experiments on Animals\", in \"Animals, Men and Morals\" (1971), a collection of essays on animal rights edited by philosophy graduate students Stanley and Roslind Godlovitch and John Harris, who were also members of the Oxford Group. Ryder wrote:\nIn as much as both \"race\" and \"species\" are vague terms used in the classification of living creatures according, largely, to physical appearance, an analogy can be made between them. Discrimination on grounds of race, although most universally condoned two centuries ago, is now widely condemned. Similarly, it may come to pass that enlightened minds may one day abhor \"speciesism\" as much as they now detest \"racism\". The illogicality in both forms of prejudice is of an identical sort. If it is accepted as morally wrong to deliberately inflict suffering upon innocent human creatures, then it is only logical to also regard it as wrong to inflict suffering on innocent individuals of other species.\u00a0... The time has come to act upon this logic.\nSpread of the idea.\nThe term was popularized by the Australian philosopher Peter Singer in his book \"Animal Liberation\" (1975). Singer had known Ryder from his own time as a graduate philosophy student at Oxford. He credited Ryder with having coined the term and used it in the title of his book's fifth chapter: \"Man's Dominion ... \"a short history of speciesism\"\", defining it as \"a prejudice or attitude of bias in favour of the interests of members of one's own species and against those of members of other species\":\nRacists violate the principle of equality by giving greater weight to the interests of members of their own race when there is a clash between their interests and the interests of those of another race. Sexists violate the principle of equality by favouring the interests of their own sex. Similarly, speciesists allow the interests of their own species to override the greater interests of members of other species. The pattern is identical in each case.\nSinger stated from a preference-utilitarian perspective, writing that speciesism violates the principle of equal consideration of interests, the idea based on Jeremy Bentham's principle: \"each to count for one, and none for more than one\". Singer stated that, although there may be differences between humans and nonhumans, they share the capacity to suffer, and we must give equal consideration to that suffering. Any position that allows similar cases to be treated in a dissimilar fashion fails to qualify as an acceptable moral theory. The term caught on; Singer wrote that it was an awkward word but that he could not think of a better one. It became an entry in the \"Oxford English Dictionary\" in 1985, defined as \"discrimination against or exploitation of animal species by human beings, based on an assumption of mankind's superiority.\" In 1994 the \"Oxford Dictionary of Philosophy\" offered a wider definition: \"By analogy with racism and sexism, the improper stance of refusing respect to the lives, dignity, or needs of animals of other than the human species.\"\nAnti-speciesism movement.\nThe French-language journal \"Cahiers antisp\u00e9cistes\" (\"Antispeciesist notebooks\") was founded in 1991, by David Olivier, Yves Bonnardel and Fran\u00e7oise Blanchon, who were the first French activists to speak out against speciesism. The aim of the journal was to disseminate anti-speciesist ideas in France and to encourage debate on the topic of animal ethics, specifically on the difference between animal liberation and ecology. Estela D\u00edaz and Oscar Horta assert that in Spanish-speaking countries, unlike English-speaking countries, anti-speciesism has become the dominant approach for animal advocacy. In Italy, the contemporary anti-speciesist movement has two main approaches: one that takes a strong, radical stance against the dominant societal norms represented by authors such as Adriano Fragano, author of the \"Antispeciesist Manifesto\", and another that aligns more with mainstream, neoliberal views.\nIn the 21st century, animal rights groups such as the Farm Animal Rights Movement and People for the Ethical Treatment of Animals have attempted to popularize the concept by promoting a World Day Against Speciesism on 5 June. The World Day for the End of Speciesism (WoDES) is a similar annual observance held at the end of August. The WoDES has been held annually since 2015.\nSocial psychology and relationship with other prejudices.\nScholars including philosopher Peter Singer and botanist Brent Mishler have argued that speciesism is analogous to racism, the belief that some human races are superior to others.\nIn the 2019 book \"Why We Love and Exploit Animals\", Kristof Dhont, Gordon Hodson, Ana C. Leite, and Alina Salmen reveal the psychological connections between speciesism and other prejudices such as racism and sexism. Marjetka Gole\u017e Kau\u010di\u010d connects racism and speciesism saying that discriminations based on race and species are strongly interrelated, with human rights providing the legal ground for the development of the animal rights. Kau\u010di\u010d further argues that racism and speciesism are further connected to issues of freedom, both collective and individual.\nIn one study, 242 participants responded to questions on the Speciesism Scale, and those who scored higher on this scale scored higher on racism, sexism, and homophobia scales. Other studies suggest that those who support animal exploitation also tend to endorse racist and sexist views, furthering the beliefs in human supremacy and group dominance in order to justify systems of inequality and oppression. It is suggested that the connection rests in the ideology of social dominance.\nPsychologists have also considered examining speciesism as a specific psychological construct or attitude (as opposed to speciesism as a philosophy), which was achieved using a specifically designed Likert scale. Studies have found that speciesism is a stable construct that differs amongst personalities and correlates with other variables. For example, speciesism has been found to have a weak positive correlation with homophobia and right-wing authoritarianism, as well as slightly stronger correlations with political conservatism, racism and system justification. Moderate positive correlations were found with social dominance orientation and sexism. Social dominance orientation was theorised to be underpinning most of the correlations; controlling for social dominance orientation reduces all correlations substantially and renders many statistically insignificant. Speciesism likewise predicts levels of prosociality toward animals and behavioural food choices.\nThose who state that speciesism is unfair to individuals of nonhuman species have often invoked mammals and chickens in the context of research or farming. There is not yet a clear definition or line agreed upon by a significant segment of the movement as to which species are to be treated equally with humans or in some ways additionally protected: mammals, birds, reptiles, arthropods, insects, bacteria, etc. This question is all the more complex since a study by Miralles et al. (2019) has brought to light the evolutionary component of human empathic and compassionate reactions and the influence of anthropomorphic mechanisms in our affective relationship with the living world as a whole: the more an organism is evolutionarily distant from us, the less we recognize ourselves in it and the less we are moved by its fate.\nSome researchers have suggested that since speciesism could be considered, in terms of social psychology, a prejudice (defined as \"any attitude, emotion, or behaviour toward members of a group, which directly or indirectly implies some negativity or antipathy toward that group\"), then laypeople may be aware of a connection between it and other forms of \"traditional\" prejudice. Research suggests laypeople do indeed tend to infer similar personality traits and beliefs from a speciesist that they would from a racist, sexist or homophobe. However, it is not clear if there is a link between speciesism and non-traditional forms of prejudice such as negative attitudes towards the overweight or towards Christians.\nPsychological studies have furthermore argued that people tend to \"morally value individuals of certain species less than others even when beliefs about intelligence and sentience are accounted for\". One study identified that there are age-related differences in moral views of animal worth, with children holding less speciesist beliefs than adults; the authors argue that such findings indicate that the development of speciesist beliefs is socially constructed over an individual's lifetime.\nRelationship with the animal\u2013industrial complex.\nPiers Beirne considers speciesism as the ideological anchor of the intersecting networks of the animal\u2013industrial complex, such as factory farms, vivisection, hunting and fishing, zoos and aquaria, and wildlife trade. Amy Fitzgerald and Nik Taylor argue that the animal-industrial complex is both a consequence and cause of speciesism, which according to them is a form of discrimination similar to racism or sexism. They also argue that the obfuscation of meat's animal origins is a critical part of the animal\u2013industrial complex under capitalist and neoliberal regimes. Speciesism results in the belief that humans have the right to use non-human animals, which is pervasive in the modern society.\nSociologist David Nibert states,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The profound cultural devaluation of other animals that permits the violence that underlies the animal industrial complex is produced by far-reaching speciesist socialization. For instance, the system of primary and secondary education under the capitalist system largely indoctrinates young people into the dominant societal beliefs and values, including a great deal of procapitalist and speciesist ideology. The devalued status of other animals is deeply ingrained; animals appear in schools merely as caged \"pets\", as dissection and vivisection subjects, and as lunch. On television and in movies, the unworthiness of other animals is evidenced by their virtual invisibility; when they do appear, they generally are marginalized, vilified, or objectified. Not surprisingly, these and numerous other sources of speciesism are so ideologically profound that those who raise compelling moral objections to animal oppression largely are dismissed, if not ridiculed.\nSome scholars have argued that all kinds of animal production are rooted in speciesism, reducing animals to mere economic resources. Built on the production and slaughter of animals, the animal\u2013industrial complex is perceived as the materialization of the institution of speciesism, with speciesism becoming \"a mode of production\". In his 2011 book \"Critical Theory and Animal Liberation\", J. Sanbonmatsu argues that speciesism is not ignorance or the absence of a moral code towards animals, but is a mode of production and material system imbricated with capitalism.\nArguments in favor.\nPhilosopher Carl Cohen stated in 1986: \"Speciesism is not merely plausible; it is essential for right conduct, because those who will not make the morally relevant distinctions among species are almost certain, in consequence, to misapprehend their true obligations.\" Cohen writes that racism and sexism are wrong because there are no relevant differences between the sexes or races. Between people and animals, he states, there are significant differences; his view is that animals do not qualify for Kantian personhood, and as such have no rights.\nNel Noddings, the American feminist, has criticized Singer's concept of speciesism for being simplistic, and for failing to take into account the context of species preference, as concepts of racism and sexism have taken into account the context of discrimination against humans. Peter Staudenmaier has stated that comparisons between speciesism and racism or sexism are trivializing:\nThe central analogy to the civil rights movement and the women's movement is trivializing and ahistorical. Both of those social movements were initiated and driven by members of the dispossessed and excluded groups themselves, not by benevolent men or white people acting on their behalf. Both movements were built precisely around the idea of reclaiming and reasserting a shared humanity in the face of a society that had deprived it and denied it. No civil rights activist or feminist ever argued, \"We're sentient beings too!\" They argued, \"We're fully human too!\" Animal liberation doctrine, far from extending this humanist impulse, directly undermines it.\nA similar argument was made by Bernard Williams, who observed that a difference between speciesism versus racism and sexism is that racists and sexists deny any input from those of a different race or sex when it comes to questioning how they should be treated. Conversely, when it comes to how animals should be treated by humans, Williams observed that it is only possible for humans to discuss that question. Williams observed that being a human being is often used as an argument against discrimination on the grounds of race or sex, whereas racism and sexism are seldom deployed to counter discrimination.\nWilliams also stated in favour of speciesism (which he termed 'humanism'), arguing that \"Why are fancy properties which are grouped under the label of personhood \"morally relevant\" to issues of destroying a certain kind of animal, while the property of being a human being is not?\" Williams states that to respond by arguing that it is because these are properties considered valuable by human beings does not undermine speciesism as humans also consider human beings to be valuable, thus justifying speciesism. Williams then states that the only way to resolve this would be by arguing that these properties are \"simply better\" but in that case, one would need to justify why these properties are better if not because of human attachment to them. Christopher Grau supported Williams, arguing that if one used properties like rationality, sentience and moral agency as criteria for moral status as an alternative to species-based moral status, then it would need to be shown why these particular properties are to be used instead of others; there must be something that gives them special status. Grau states that to claim these are simply better properties would require the existence of an impartial observer, an \"enchanted picture of the universe\", to state them to be so. Thus, Grau states that such properties have no greater justification as criteria for moral status than being a member of a species does. Grau also states that even if such an impartial perspective existed, it still would not necessarily be against speciesism, since it is entirely possible that there could be reasons given by an impartial observer for humans to care about humanity. Grau then further observes that if an impartial observer existed and valued only minimalizing suffering, it would likely be overcome with horror at the suffering of all individuals and would rather have humanity annihilate the planet than allow it to continue. Grau thus concludes that those endorsing the idea of deriving values from an impartial observer do not seem to have seriously considered the conclusions of such an idea.\nDouglas Maclean agreed that Singer raised important questions and challenges, particularly with his argument from marginal cases. However, Maclean questioned if different species can be fitted with human morality, observing that animals were generally held exempt from morality; Maclean notes that most people would try to stop a man kidnapping and killing a woman but would regard a hawk capturing and killing a marmot with awe and criticise anyone who tried to intervene. Maclean thus suggests that morality only makes sense under human relations, with the further one gets from it, the less it can be applied.\nThe British philosopher Roger Scruton regards the emergence of the animal rights and anti-speciesism movement as \"the strangest cultural shift within the liberal worldview\", because the idea of rights and responsibilities is, he states, distinctive to the human condition, and it makes no sense to spread them beyond our own species. Scruton argues that if animals have rights, then they also have duties, which animals would routinely violate, such as by breaking laws or killing other animals. He accuses anti-speciesism advocates of \"pre-scientific\" anthropomorphism, attributing traits to animals that are, he says, Beatrix Potter-like, where \"only man is vile\". It is, he states, a fantasy, a world of escape.\nThomas Wells states that Singer's call for ending animal suffering would justify simply exterminating every animal on the planet in order to prevent the numerous ways in which they suffer, as they could no longer feel any pain. Wells also stated that by focusing on the suffering humans inflict on animals and ignoring suffering animals inflict upon themselves or that inflicted by nature, Singer is creating a hierarchy where some suffering is more important than others, despite claiming to be committed to equality of suffering. Wells also states that the capacity to suffer, Singer's criteria for moral status, is one of degree rather than absolute categories; Wells observes that Singer denies moral status to plants on the grounds they cannot subjectively feel anything (even though they react to stimuli), yet Wells alleges there is no indication that nonhuman animals feel pain and suffering the way humans do.\nRobert Nozick notes that if species membership is irrelevant, then this would mean that endangered animals have no special claim.\nThe Rev. John Tuohey, founder of the Providence Center for Health Care Ethics, writes that the logic behind the anti-speciesism critique is flawed, and that, although the animal rights movement in the United States has been influential in slowing animal experimentation, and in some cases halting particular studies, no one has offered a compelling argument for species equality.\nArguments against.\nMoral community, argument from marginal cases.\nPaola Cavalieri writes that the current humanist paradigm is that only human beings are members of the moral community and that all are worthy of equal protection. Species membership, she writes, is \"ipso facto\" moral membership. The paradigm has an inclusive side (all human beings deserve equal protection) and an exclusive one (only human beings have that status).\nNonhumans do possess some moral status in many societies, but it generally extends only to protection against what Cavalieri calls \"wanton cruelty\". Anti-speciesists state that the extension of moral membership to all humanity, regardless of individual properties such as intelligence, while denying it to nonhumans, also regardless of individual properties, is internally inconsistent. According to the argument from marginal cases, if infants, the senile, the comatose, and the cognitively disabled (marginal-case human beings) have a certain moral status, then nonhuman animals must be awarded that status too since there is no morally relevant ability that the marginal-case humans have that nonhumans lack.\nAmerican legal scholar Steven M. Wise states that speciesism is a bias as arbitrary as any other. He cites the philosopher R.G. Frey (1941\u20132012), a leading animal rights critic, who wrote in 1983 that, if forced to choose between abandoning experiments on animals and allowing experiments on \"marginal-case\" humans, he would choose the latter, \"not because I begin a monster and end up choosing the monstrous, but because I cannot think of anything at all compelling that cedes all human life of any quality greater value than animal life of any quality.\"\n\"Discontinuous mind\".\nRichard Dawkins, the evolutionary biologist, wrote against speciesism in \"The Blind Watchmaker\" (1986), \"The Great Ape Project\" (1993), and \"The God Delusion\" (2006), elucidating the connection with evolutionary theory. He compares former racist attitudes and assumptions to their present-day speciesist counterparts. In the chapter \"The one true tree of life\" in \"The Blind Watchmaker\", he states that it is not only zoological taxonomy that is saved from awkward ambiguity by the extinction of intermediate forms but also human ethics and law. Dawkins states that what he calls the \"discontinuous mind\" is ubiquitous, dividing the world into units that reflect nothing but our use of language, and animals into discontinuous species:\nThe director of a zoo is entitled to \"put down\" a chimpanzee that is surplus to requirements, while any suggestion that he might \"put down\" a redundant keeper or ticket-seller would be greeted with howls of incredulous outrage. The chimpanzee is the property of the zoo. Humans are nowadays not supposed to be anybody's property, yet the rationale for discriminating against chimpanzees is seldom spelled out, and I doubt if there is a defensible rationale at all. Such is the breathtaking speciesism of our Christian-inspired attitudes, the abortion of a single human zygote (most of them are destined to be spontaneously aborted anyway) can arouse more moral solicitude and righteous indignation than the vivisection of any number of intelligent adult chimpanzees!\u00a0... The only reason we can be comfortable with such a double standard is that the intermediates between humans and chimps are all dead.\nDawkins elaborated in a discussion with Singer at The Center for Inquiry in 2007 when asked whether he continues to eat meat: \"It's a little bit like the position which many people would have held a couple of hundred years ago over slavery. Where lots of people felt morally uneasy about slavery but went along with it because the whole economy of the South depended upon slavery.\"\nCentrality of consciousness.\n\"Libertarian extension\" is the idea that the intrinsic value of nature can be extended beyond sentient beings. This seeks to apply the principle of individual rights not only to all animals but also to objects without a nervous system such as trees, plants, and rocks. Ryder rejects this argument, writing that \"value cannot exist in the absence of consciousness or potential consciousness. Thus, rocks and rivers and houses have no interests and no rights of their own. This does not mean, of course, that they are not of value to us, and to many other [beings who experience pain], including those who need them as habitats and who would suffer without them.\"\nComparisons to the Holocaust.\nDavid Sztybel states in his paper, \"Can the Treatment of Animals Be Compared to the Holocaust?\" (2006), that the racism of the Nazis is comparable to the speciesism inherent in eating meat or using animal by-products, particularly those produced on factory farms. Y. Michael Barilan, an Israeli physician, states that speciesism is not the same thing as Nazi racism, because the latter extolled the abuser and condemned the weaker and the abused. He describes speciesism as the recognition of rights on the basis of group membership, rather than solely on the basis of moral considerations.\nLaw and policy.\nLaw.\nThe first major statute addressing animal protection in the United States, titled \"An Act for the More Effectual Prevention of Cruelty to Animals\", was enacted in 1867. It provided the right to incriminate and enforce protection with regards to animal cruelty. The act, which has since been revised to suit modern cases state by state, originally addressed such things as animal neglect, abandonment, torture, fighting, transport, impound standards and licensing standards. Although an animal rights movement had already started as early as the late 1800s, some of the laws that would shape the way animals would be treated as industry grew, were enacted around the same time that Richard Ryder was bringing the notion of Speciesism to the conversation. Legislation was being proposed and passed in the U.S. that would reshape animal welfare in industry and science. Bills such as Humane Slaughter Act, which was created to alleviate some of the suffering felt by livestock during slaughter, was passed in 1958. Later the Animal Welfare Act of 1966, passed by the 89th United States Congress and signed into law by President Lyndon B. Johnson, was designed to put much stricter regulations and supervisions on the handling of animals used in laboratory experimentation and exhibition but has since been amended and expanded. These groundbreaking laws foreshadowed and influenced the shifting attitudes toward nonhuman animals in their rights to humane treatment which Richard D. Ryder and Peter Singer would later popularize in the 1970s and 1980s.\nGreat ape personhood.\nGreat ape personhood is the idea that the attributes of non-human great apes are such that their sentience and personhood should be recognized by the law, rather than simply protecting them as a group under animal cruelty legislation. Awarding personhood to nonhuman primates would require that their individual interests be taken into account.\nFilms and television series with themes around speciesism.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29047", "revid": "11677590", "url": "https://en.wikipedia.org/wiki?curid=29047", "title": "Steelman language requirements", "text": ""}
{"id": "29048", "revid": "18731412", "url": "https://en.wikipedia.org/wiki?curid=29048", "title": "Single-sideband modulation", "text": "Electronic method of transmitting information with a carrier wave\nIn radio communications, single-sideband modulation (SSB) or single-sideband suppressed-carrier modulation (SSB-SC) is a type of signal modulation used to transmit information, such as an audio signal, by radio waves. A refinement of amplitude modulation, it uses transmitter power and bandwidth more efficiently. Amplitude modulation produces an output signal the bandwidth of which is twice the maximum frequency of the original baseband signal. Single-sideband modulation avoids this bandwidth increase, and the power wasted on a carrier, at the cost of increased device complexity and more difficult tuning at the receiver.\nBasic concept.\nRadio transmitters work by mixing a radio frequency (RF) signal of a specific frequency, the carrier wave, with the audio signal to be broadcast. In AM transmitters this mixing usually takes place in the final RF amplifier (high level modulation). It is less common and much less efficient to do the mixing at low power and then amplify it in a linear amplifier. Either method produces a set of frequencies with a strong signal at the carrier frequency and with weaker signals at frequencies extending above and below the carrier frequency by the maximum frequency of the input signal. Thus the resulting signal has a spectrum whose bandwidth is twice the maximum frequency of the original input audio signal.\nSSB takes advantage of the fact that the entire original signal is encoded in each of these \"sidebands\". Since a good receiver can extract the complete original signal from either the upper or lower sideband, it is not essential or efficient to transmit both sidebands plus the carrier - the full AM signal will occupy double the bandwidth of the original baseband signal, and transmitted RF power will be wasted in producing the carrier and redundant sideband. There are several methods for eliminating the carrier and one sideband from the transmitted signal. Producing this single sideband signal can be done at high level in the final amplifier stage as with AM\nbut it is usually produced at a low power level and linearly amplified. The lower efficiency of linear amplification partially offsets the power advantage gained by eliminating the carrier and one sideband. Nevertheless, SSB transmissions use the available amplifier energy considerably more efficiently, providing longer-range transmission for the same power output. In addition, the occupied spectrum is less than half that of a full carrier AM signal.\nSSB reception requires frequency stability and selectivity well beyond that of inexpensive AM receivers which is why broadcasters have seldom used it. In point-to-point communications, where expensive receivers are in common use already, they can successfully be adjusted to receive whichever sideband is being transmitted.\nHistory.\nThe first U.S. patent application for SSB modulation was filed on December 1, 1915, by John Renshaw Carson. The U.S. Navy experimented with SSB over its radio circuits before World War I. SSB first entered commercial service on January 7, 1927, on the longwave transatlantic public radiotelephone circuit between New York and London. The high power SSB transmitters were located at Rocky Point, New York, and Rugby, England. The receivers were in very quiet locations in Houlton, Maine, and Cupar, Scotland.\nSSB was also used over long-distance telephone lines, as part of a technique known as frequency-division multiplexing (FDM). FDM was pioneered by telephone companies in the 1930s. With this technology, many simultaneous voice channels could be transmitted on a single physical circuit, for example in L-carrier. With SSB, channels could be spaced (usually) only 4,000\u00a0Hz apart, while offering a speech bandwidth of nominally 300\u00a0Hz to 3,400\u00a0Hz.\nAmateur radio operators began serious experimentation with SSB after World War II. The Strategic Air Command established SSB as the radio standard for its aircraft in 1957. It has become a de facto standard for long-distance voice radio transmissions since then.\nMathematical formulation.\nSingle-sideband has the mathematical form of quadrature amplitude modulation (QAM) in the special case where one of the baseband waveforms is derived from the other, instead of being independent messages:\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nwhere formula_1 is the message (real-valued), formula_2 is its Hilbert transform, and formula_3 is the radio carrier frequency.\nTo understand this formula, we may express formula_4 as the real part of a complex-valued function, with no loss of information:\nformula_5\nwhere formula_6 represents the imaginary unit.\u00a0 formula_7 is the analytic representation of formula_8\u00a0 which means that it comprises only the positive-frequency components of formula_4:\nformula_10\nwhere formula_11 and formula_12 are the respective Fourier transforms of formula_7 and formula_14\u00a0 Therefore, the frequency-translated function formula_15 contains only one side of formula_16\u00a0 Since it also has only positive-frequency components, its inverse Fourier transform is the analytic representation of formula_17\nformula_18\nand again the real part of this expression causes no loss of information.\u00a0 With Euler's formula to expand \u00a0formula_19\u00a0 we obtain Eq.1:\nformula_20\nCoherent demodulation of formula_21 to recover formula_4 is the same as AM: multiply by formula_23\u00a0 and lowpass to remove the \"double-frequency\" components around frequency formula_24. If the demodulating carrier is not in the correct phase (cosine phase here), then the demodulated signal will be some linear combination of formula_4 and formula_26, which is usually acceptable in voice communications (if the demodulation carrier frequency is not quite right, the phase will be drifting cyclically, which again is usually acceptable in voice communications if the frequency error is small enough, and amateur radio operators are sometimes tolerant of even larger frequency errors that cause unnatural-sounding pitch shifting effects).\nLower sideband.\nformula_4 can also be recovered as the real part of the complex-conjugate, formula_28 which represents the negative frequency portion of formula_16 When formula_3 is large enough that formula_31 has no negative frequencies, the product formula_32 is another analytic signal, whose real part is the actual \"lower-sideband\" transmission:\nformula_33\nThe sum of the two sideband signals is:\nformula_34\nwhich is the classic model of suppressed-carrier double sideband AM.\nPractical implementations.\nBandpass filtering.\nOne method of producing an SSB signal is to remove one of the sidebands via filtering, leaving only either the upper sideband (USB), the sideband with the higher frequency, or less commonly the lower sideband (LSB), the sideband with the lower frequency. Most often, the carrier is reduced or removed entirely (suppressed), being referred to in full as single sideband suppressed carrier (SSBSC). Assuming both sidebands are symmetric, which is the case for a normal AM signal, no information is lost in the process. Since the final RF amplification is now concentrated in a single sideband, the effective power output is greater than in normal AM (the carrier and redundant sideband account for well over half of the power output of an AM transmitter). Though SSB uses substantially less bandwidth and power, it cannot be demodulated by a simple envelope detector like standard AM.\nHartley modulator.\nAn alternate method of generation known as a Hartley modulator, named after R. V. L. Hartley, uses phasing to suppress the unwanted sideband. To generate an SSB signal with this method, two versions of the original signal are generated, mutually 90\u00b0 out of phase for any single frequency within the operating bandwidth. Each one of these signals then modulates carrier waves (of one frequency) that are also 90\u00b0 out of phase with each other. By either adding or subtracting the resulting signals, a lower or upper sideband signal results. A benefit of this approach is to allow an analytical expression for SSB signals, which can be used to understand effects such as synchronous detection of SSB.\nShifting the baseband signal 90\u00b0 out of phase cannot be done simply by delaying it, as it contains a large range of frequencies. In analog circuits, a wideband 90-degree phase-difference network is used. The method was popular in the days of vacuum tube radios, but later gained a bad reputation due to poorly adjusted commercial implementations. Modulation using this method is again gaining popularity in the homebrew and DSP fields. \nThis method, utilizing the Hilbert transform to phase shift the baseband audio, can be done at low cost with digital circuitry.\nWeaver modulator.\nAnother variation, the Weaver modulator, initially used only six resistors and six capacitors to generate equal amplitude signals with a 90\u00b0 phase difference over the passband, as with the Hilbert Transformer. He later showed a method using low pass filters combined with four heterodyne operations.\nIn Weaver's method, the band of interest is first translated to be centered at zero, conceptually by modulating a complex exponential formula_35 with frequency in the middle of the voiceband, but implemented by a quadrature pair of sine and cosine modulators at that frequency (e.g. 2\u00a0kHz). This complex signal or pair of real signals is then lowpass filtered to remove the undesired sideband that is not centered at zero. Then, the single-sideband complex signal centered at zero is upconverted to a real signal, by another pair of quadrature mixers, to the desired center frequency.\nFull, reduced, and suppressed-carrier SSB.\nConventional amplitude-modulated signals can be considered wasteful of power and bandwidth because they contain a carrier signal and two identical sidebands. Therefore, SSB transmitters are generally designed to minimize the amplitude of the carrier signal. When the carrier is removed from the transmitted signal, it is called \"suppressed-carrier SSB\".\nHowever, in order for a receiver to reproduce the transmitted audio without distortion, it must be tuned to exactly the same frequency as the transmitter. Since this is difficult to achieve in practice, SSB transmissions can sound unnatural, and if the error in frequency is great enough, it can cause poor intelligibility. In order to correct this, a small amount of the original carrier signal can be transmitted so that receivers with the necessary circuitry to synchronize with the transmitted carrier can correctly demodulate the audio. This mode of transmission is called reduced-carrier single-sideband.\nIn other cases, it may be desirable to maintain some degree of compatibility with simple AM receivers, while still reducing the signal's bandwidth. This can be accomplished by transmitting single-sideband with a normal or slightly reduced carrier. This mode is called \"compatible (or full-carrier) SSB\" or \"amplitude modulation equivalent (AME)\". In typical AME systems, harmonic distortion can reach 25%, and intermodulation distortion can be much higher than normal, but minimizing distortion in receivers with envelope detectors is generally considered less important than allowing them to produce intelligible audio.\nA second, and perhaps more correct, definition of \"compatible single sideband\" (CSSB) refers to a form of amplitude and phase modulation in which the carrier is transmitted along with a series of sidebands that are predominantly above or below the carrier term. Since phase modulation is present in the generation of the signal, energy is removed from the carrier term and redistributed into the sideband structure similar to that which occurs in analog frequency modulation. The signals feeding the phase modulator and the envelope modulator are further phase-shifted by 90\u00b0 with respect to each other. This places the information terms in quadrature with each other; the Hilbert transform of information to be transmitted is utilized to cause constructive addition of one sideband and cancellation of the opposite primary sideband. Since phase modulation is employed, higher-order terms are also generated. Several methods have been employed to reduce the impact (amplitude) of most of these higher-order terms. In one system, the phase-modulated term is actually the log of the value of the carrier level plus the phase-shifted audio/information term. This produces an ideal CSSB signal, where at low modulation levels only a first-order term on one side of the carrier is predominant. As the modulation level is increased, the carrier level is reduced while a second-order term increases substantially in amplitude. At the point of 100% envelope modulation, 6\u00a0dB of power is removed from the carrier term, and the second-order term is identical in amplitude to carrier term. The first-order sideband has increased in level until it is now at the same level as the formerly unmodulated carrier. At the point of 100% modulation, the spectrum appears identical to a normal double-sideband AM transmission, with the center term (now the primary audio term) at a 0\u00a0dB reference level, and both terms on either side of the primary sideband at \u22126\u00a0dB. The difference is that what appears to be the carrier has shifted by the audio-frequency term towards the \"sideband in use\". At levels below 100% modulation, the sideband structure appears quite asymmetric. When voice is conveyed by a CSSB source of this type, low-frequency components are dominant, while higher-frequency terms are lower by as much as 20\u00a0dB at 3\u00a0kHz. The result is that the signal occupies approximately 1/2 the normal bandwidth of a full-carrier, DSB signal. There is one catch: the audio term utilized to phase-modulate the carrier is generated based on a log function that is biased by the carrier level. At negative 100% modulation, the term is driven to zero (0), and the modulator becomes undefined. Strict modulation control must be employed to maintain stability of the system and avoid splatter. This system is of Russian origin and was described in the late 1950s. It is uncertain whether it was ever deployed.\nA second series of approaches was designed and patented by Leonard R. Kahn. The various Kahn systems removed the hard limit imposed by the use of the strict log function in the generation of the signal. Earlier Kahn systems utilized various methods to reduce the second-order term through the insertion of a predistortion component. One example of this method was also used to generate one of the Kahn independent-sideband (ISB) AM stereo signals. It was known as the STR-77 exciter method, having been introduced in 1977. Later, the system was further improved by use of an arcsine-based modulator that included a 1-0.52E term in the denominator of the arcsin generator equation. E represents the envelope term; roughly half the modulation term applied to the envelope modulator is utilized to reduce the second-order term of the arcsin \"phase\"-modulated path; thus reducing the second-order term in the undesired sideband. A multi-loop modulator/demodulator feedback approach was used to generate an accurate arcsin signal. This approach was introduced in 1984 and became known as the STR-84 method. It was sold by Kahn Research Laboratories; later, Kahn Communications, Inc. of NY. An additional audio processing device further improved the sideband structure by selectively applying pre-emphasis to the modulating signals. Since the envelope of all the signals described remains an exact copy of the information applied to the modulator, it can be demodulated without distortion by an envelope detector such as a simple diode. In a practical receiver, some distortion may be present, usually at a low level (in AM broadcast, always below 5%), due to sharp filtering and nonlinear group delay in the IF filters of the receiver, which act to truncate the compatibility sideband \u2013 those terms that are not the result of a linear process of simply envelope modulating the signal as would be the case in full-carrier DSB-AM \u2013 and rotation of phase of these compatibility terms such that they no longer cancel the quadrature distortion term caused by a first-order SSB term along with the carrier. The small amount of distortion caused by this effect is generally quite low and acceptable.\nThe Kahn CSSB method was also briefly used by Airphone as the modulation method employed for early consumer telephone calls that could be placed from an aircraft to ground. This was quickly supplanted by digital modulation methods to achieve even greater spectral efficiency.\nWhile CSSB is seldom used today in the AM/MW broadcast bands worldwide, some amateur radio operators still experiment with it.\nDemodulation.\nThe front end of an SSB receiver is similar to that of an AM or FM receiver, consisting of a superheterodyne RF front end that produces a frequency-shifted version of the radio frequency (RF) signal within a standard intermediate frequency (IF) band.\nTo recover the original signal from the IF SSB signal, the single sideband must be frequency-shifted down to its original range of baseband frequencies, by using a product detector which mixes it with the output of a beat frequency oscillator (BFO). In other words, it is just another stage of heterodyning. For this to work, the BFO frequency must be exactly adjusted. \nIf the BFO frequency is off, the output signal will be frequency-shifted (up or down), making speech sound strange and \"Donald Duck\"-like, or unintelligible.\nFor audio communications, there is a common agreement about the BFO oscillator shift of 1.7\u00a0kHz. A voice signal is sensitive to about 50\u00a0Hz shift, with up to 100\u00a0Hz still bearable. Some receivers use a carrier recovery system, which attempts to automatically lock on to the exact IF frequency. The carrier recovery doesn't solve the frequency shift. It gives better S/N ratio on the detector output.\nAs an example, consider an IF SSB signal centered at frequency formula_36 = 45000\u00a0Hz. The baseband frequency it needs to be shifted to is formula_37 = 2000\u00a0Hz. The BFO output waveform is formula_38. When the signal is multiplied by (aka \"heterodyned with\") the BFO waveform, it shifts the signal to \u00a0formula_39,\u00a0\"and\" to\u00a0formula_40, which is known as the \"beat frequency\" or \"image frequency\". The objective is to choose an formula_41 that results in \u00a0formula_42 = 2000\u00a0Hz. (The unwanted components at formula_43 can be removed by a lowpass filter; for which an output transducer or the human ear may serve).\nThere are two choices for formula_41: 43000\u00a0Hz and 47000\u00a0Hz, called \"low-side\" and \"high-side\" injection. With high-side injection, the spectral components that were distributed around 45000\u00a0Hz will be distributed around 2000\u00a0Hz in the reverse order, also known as an inverted spectrum. That is in fact desirable when the IF spectrum is also inverted, because the BFO inversion restores the proper relationships. One reason for that is when the IF spectrum is the output of an inverting stage in the receiver. Another reason is when the SSB signal is actually a lower sideband, instead of an upper sideband. But if both reasons are true, then the IF spectrum is not inverted, and the non-inverting BFO (43000\u00a0Hz) should be used.\nIf formula_45 is off by a small amount, then the beat frequency is not exactly formula_37, which can lead to the speech distortion mentioned earlier.\nSSB as a speech-scrambling technique.\nSSB techniques can also be adapted to frequency-shift and frequency-invert baseband waveforms (voice inversion). This voice scrambling method was made by running the audio of one side band modulated audio sample through its opposite (e.g. running an LSB modulated audio sample through a radio running USB modulation). \nThese effects were used, in conjunction with other filtering techniques, during World War II as a simple method for speech encryption. Radiotelephone conversations between the US and Britain were intercepted and \"decrypted\" by the Germans; they included some early conversations between Franklin D. Roosevelt and Churchill. In fact, the signals could be understood directly by trained operators. Largely to allow secure communications between Roosevelt and Churchill, the SIGSALY system of digital encryption was devised.\nToday, such simple inversion-based speech encryption techniques are easily decrypted using simple techniques and are no longer regarded as secure.\nVestigial sideband (VSB).\nLimitation of single-sideband modulation being used for voice signals and not available for video/TV signals leads to the usage of vestigial sideband. A vestigial sideband (in radio communication) is a sideband that has been only partly cut off or suppressed. \nTelevision broadcasts (in analog video formats) use this method if the video is transmitted in AM, due to the large bandwidth used. It may also be used in digital transmission, such as the ATSC standardized 8VSB.\nThe broadcast or transport channel for TV in countries that use NTSC or ATSC has a bandwidth of 6\u00a0MHz. To conserve bandwidth, SSB would be desirable, but the video signal has significant low-frequency content (average brightness) and has rectangular synchronising pulses. The engineering compromise is vestigial-sideband transmission. In vestigial sideband, the full upper sideband of bandwidth W2 = 4.0\u00a0MHz is transmitted, but only W1 = 0.75\u00a0MHz of the lower sideband is transmitted, along with a carrier. The carrier frequency is 1.25\u00a0MHz above the lower edge of the 6\u00a0MHz wide channel. This effectively makes the system AM at low modulation frequencies and SSB at high modulation frequencies. The absence of the lower sideband components at high frequencies must be compensated for, and this is done in the IF amplifier.\nFrequencies for LSB and USB in amateur radio voice communication.\nWhen single-sideband is used in amateur radio voice communications, it is common practice that for frequencies below 10\u00a0MHz, lower sideband (LSB) is used and for frequencies of 10\u00a0MHz and above, upper sideband (USB) is used. For example, on the 40 m band, voice communications often take place around 7.100\u00a0MHz using LSB mode. On the 20 m band at 14.200\u00a0MHz, USB mode would be used.\nAn exception to this rule applies to the five discrete amateur channels on the 60-meter band (near 5.3\u00a0MHz) where FCC rules specifically require USB.\nExtended single sideband (eSSB).\nExtended single sideband is any J3E (SSB-SC) mode that exceeds the audio bandwidth of standard or traditional 2.9\u00a0kHz SSB J3E modes (ITU 2K90J3E) to support higher-quality sound. \nAmplitude-companded single-sideband modulation (ACSSB).\nAmplitude-companded single sideband (ACSSB) is a narrowband modulation method using a single sideband with a pilot tone, allowing an expander in the receiver to restore the amplitude that was severely compressed by the transmitter. It offers improved effective range over standard SSB modulation while simultaneously retaining backwards compatibility with standard SSB radios. ACSSB also offers reduced bandwidth and improved range for a given power level compared with narrow band FM modulation.\nControlled-envelope single-sideband modulation (CESSB).\nThe generation of standard SSB modulation results in large envelope overshoots well above the average envelope level for a sinusoidal tone (even when the audio signal is peak-limited). The standard SSB envelope peaks are due to truncation of the spectrum and nonlinear phase distortion from the approximation errors of the practical implementation of the required Hilbert transform. It was recently shown that suitable overshoot compensation (so-called controlled-envelope single-sideband modulation or CESSB) achieves about 3.8\u00a0dB of peak reduction for speech transmission. This results in an effective average power increase of about 140%.\nAlthough the generation of the CESSB signal can be integrated into the SSB modulator, it is feasible to separate the generation of the CESSB signal (e.g. in form of an external speech preprocessor) from a standard SSB radio. This requires that the standard SSB radio's modulator be linear-phase and have a sufficient bandwidth to pass the CESSB signal. If a standard SSB modulator meets these requirements, then the envelope control by the CESSB process is preserved.\nITU designations.\nIn 1982, the International Telecommunication Union (ITU) designated the types of amplitude modulation:"}
{"id": "29049", "revid": "45032371", "url": "https://en.wikipedia.org/wiki?curid=29049", "title": "SSB", "text": "SSB may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "29050", "revid": "19158033", "url": "https://en.wikipedia.org/wiki?curid=29050", "title": "Szlachta", "text": "Noble class in the Kingdom of Poland and the Grand Duchy of Lithuania\nThe szlachta (; ; lit.\u2009'nobility') , the nobles, were the noble estate of the realm in the Kingdom of Poland, the Grand Duchy of Lithuania, and the Polish\u2013Lithuanian Commonwealth. It was the dominating social class in the Kingdom of Poland and the Polish-Lithuanian Commonwealth, which was exercising political rights and power. Szlachta as a class differed substantially from the feudal nobility of Western Europe. The estate was officially abolished in 1921 by the March Constitution.\nThe origins of the \"szlachta\" are obscure and the subject of several theories. The \"szlachta\" secured substantial and increasing political power and rights throughout its history, beginning with the reign of King Casimir III the Great between 1333 and 1370 in the Kingdom of Poland until the decline and end of the Polish\u2013Lithuanian Commonwealth in the late 18th century. Apart from providing officers for the army, its chief civic obligations included electing the monarch and filling honorary and advisory roles at court that would later evolve into the upper legislative chamber, the Senate. The \"szlachta\" electorate also took part in the government of the Commonwealth via the lower legislative chamber of the Sejm (bicameral national parliament), composed of representatives elected at local \"sejmiks\" (local \"szlachta\" assemblies). Sejmiks performed various governmental functions at local levels, such as appointing officials and overseeing judicial and financial governance, including tax-raising. The \"szlachta\" assumed various governing positions, including \"voivode\", \"marshal of voivodeship\", castellan, and \"starosta\".\nIn 1413, following a series of tentative personal unions between the Grand Duchy of Lithuania and the Crown of the Kingdom of Poland, the existing Lithuanian and Ruthenian nobilities formally joined the \"szlachta\". As the Polish\u2013Lithuanian Commonwealth (1569\u20131795) evolved and expanded territorially after the Union of Lublin, its membership grew to include the leaders of Ducal Prussia and Livonia. Over time, membership in the \"szlachta\" grew to encompass around 8% to 15% of Polish-Lithuanian society, which made the membership an electorate that was several times larger than most noble classes in other countries; by contrast, nobles in Italy and France encompassed 1% during the early modern period.\nDespite often enormous differences in wealth and political influence, few distinctions in law existed between the great magnates and lesser \"szlachta\". The juridic principle of \"szlachta\" equality existed because \"szlachta\" land titles were allodial, not feudal, involving no requirement of feudal service to a liege Lord. Unlike absolute monarchs who eventually took reign in most other European countries, the Polish king was not an autocrat and not the szlachta's overlord. During the three successive Partitions of Poland between 1772 and 1795, most of the \"szlachta\" began to lose legal privileges and social status, while \"szlachta\" elites became part of the nobilities of the three partitioning powers.\nHistory.\nEtymology.\nIn Polish, a nobleman is called a \"\"szlachcic\" and a noblewoman a \"szlachcianka\"\".\nThe Polish term \"szlachta\" derived from the Old High German word \"slahta\". In modern German \"Geschlecht\" \u2013 which originally came from the Proto-Germanic *\"slagiz\", \"blow\", \"strike\", and shares the Anglo-Saxon root for \"slaughter\", or the verb \"to slug\" \u2013 means \"breeding\" or \"gender\".\n17th-century Poles assumed \"szlachta\" came from the German \"schlachten\", \"to slaughter\" or \"to butcher\", and was therefore related to the German word for battle, \"Schlacht\". Some early Polish historians thought the term might have derived from the name of the legendary proto-Polish chief, Lech, mentioned in Polish and Czech writings. The szlachta traced their descent from Lech, who allegedly founded the Polish kingdom in about the fifth century.\nThe Polish term \"szlachta\" designated the formalized, hereditary aristocracy of the Polish\u2013Lithuanian Commonwealth, which constituted the nation itself, and ruled without competition. In official Latin documents of the old Commonwealth, the hereditary szlachta were referred to as \"nobilitas\" from the Latin term. Until the second half of the 19th century, the Polish term \"obywatel\" (which now means \"citizen\") could be used as a synonym for szlachta landlords.\nToday the word \"szlachta\" simply translates as \"nobility\". In its broadest sense, it can also denote some non-hereditary honorary knighthoods and baronial titles granted by other European monarchs, including the Holy See. Occasionally, 19th-century landowners of commoner descent were referred to as \"szlachta\" by courtesy or error, when they owned manorial estates, but were not in fact noble by birth. \"Szlachta\" also denotes the Ruthenian and Lithuanian nobility from before the old Commonwealth.\nIn the past, a misconception sometimes led to the mistranslation of \"szlachta\" as \"gentry\" rather than \"nobility\". This mistaken practice began due to the inferior economic status of many \"szlachta\" members compared to that of the nobility in other European countries (see also Estates of the Realm \"regarding wealth and nobility\"). The \"szlachta\" included those rich and powerful enough to be great magnates down to the impoverished with an aristocratic lineage, but with no land, no castle, no money, no village, and no subject peasants. Historian M.Ross wrote in 1835: \"At least 60,000 families belong to this class, of which, however, only about 100 are wealthy; all the rest are poor.\"\nA few exceptionally wealthy and powerful szlachta members constituted the \"magnateria\" and were known as magnates (magnates of Poland and Lithuania).\nComposition.\nAdam Zamoyski argues that the szlachta were not exactly the same as the European nobility nor a gentry, as the szlachta fundamentally differed in law, rights, political power, origin, and composition from the feudal nobility of Western Europe. The szlachta did not rank below the king, as the szlachta's relationship to the Polish king was not feudal. The szlachta stood as equals before the king. The king was not an autocrat, nor the szlachta's overlord, as szlachta land was in allodium, not feudal tenure. Feudal dependence upon a Polish king did not exist for the szlachta and earlier in history some high-ranking szlachta (magnates) descending from past tribal dynasties regarded themselves as co-proprietors of Piast realms and constantly sought to undermine Piast authority.\nIn 1459 Ostror\u00f3g presented a memorandum to the Sejm (parliament), submitting palatines, or Voivodes of the Polish\u2013Lithuanian Commonwealth, receive the title of prince. Sons of a prince were to receive titles of counts and barons. Castellans of the Polish\u2013Lithuanian Commonwealth were to receive the title of count. This attempt to introduce the hierarchy of noble titles common for European feudal systems for szlachta was rejected.\nThe fact the szlachta were equal before the king and deliberately opposed becoming a feudal nobility became a matter of law embedded as a constitutional principle of equality. The republicanism of ancient Rome was the szlachta's ideal. Poland was known as the Most Serene Republic of Poland, Serenissima Res Publica Poloniae. The szlachta, not as a feudal nobility or gentry, but as an electorate, and an aristocracy and warrior caste, with no feudal dependence on a king, exercised supreme political power over that republic and elected kings as servants of a republic the szlachta regarded as the embodiment of their rights.\nOver time, numerically most \"lesser\" szlachta became poorer, or were poorer than, their few rich peers with the same political status and status in law, and many \"lesser\" szlachta were worse off than commoners with land. They were called \"szlachta zagrodowa\", that is, \"farm nobility\", from \"zagroda\", a farm, often little different from a peasant's dwelling, sometimes referred to as \"drobna szlachta\", \"petty nobles\" or yet, \"szlachta okoliczna\", meaning \"local\". Particularly impoverished szlachta families were often forced to become tenants of their wealthier peers. They were described as \"szlachta czynszowa\", or \"tenant nobles\" who paid rent. See \"Szlachta categories\" for more.\nOrigins.\nPoland.\nThe origins of the szlachta, while ancient, have always been considered obscure. As a result, its members often referred to it as \"odwieczna\" (perennial). Two popular historical theories about its origins have been put forward by its members and early historians and chroniclers. The first theory involved a presumed descent from the ancient Iranian tribe known as Sarmatians, who in the 2nd century AD, occupied lands in Eastern Europe, and the Middle East. The second theory involved a presumed szlachta descent from Japheth, one of Noah's sons. By contrast, the peasantry were said to be the offspring of another son of Noah, Ham \u2014 and hence subject to bondage under the Curse of Ham. The Jews were considered the offspring of Shem. Other fanciful theories included its foundation by Julius Caesar, Alexander the Great, or regional leaders who had not mixed their bloodlines with those of 'slaves, prisoners, or aliens'.\nAnother theory describes its derivation from a non-Slavic warrior class, forming a distinct element known as the Lechici/Lekhi (\"Lechit\u00f3w\") within the ancient Polonic tribal groupings (Indo-European caste systems). Similar to Nazi racial ideology, which dictated the Polish elite were largely Nordic (the szlachta Boreyko coat of arms heralds a swastika), this hypothesis states this upper class was not of Slavonic extraction and was of a different origin than the Slavonic peasants () over which they ruled.\nIn old Poland, there were two nations \u2013 szlachta and peasants. The szlachta were differentiated from the rural population. In harshly stratified and elitist Polish society, the szlachta's sense of distinction led to practices that in later periods would be characterized as racism. Wac\u0142aw Potocki, herbu \u015areniawa (1621\u20131696), proclaimed \"by nature\" are \"chained to the land and plow,\" that even an educated peasant would always remain a peasant, because \"it is impossible to transform a dog into a lynx.\" The szlachta were noble in the Aryan (see \"Alans\") sense -- \"noble\" in contrast to the people over whom they ruled after coming into contact with them.\nThe szlachta traced their descent from Lech/Lekh, who allegedly founded the Polish kingdom in about the fifth century. Lechia was the name of Poland in antiquity, and the szlachta's own name for themselves was Lechici/Lekhi. Richard Holt Hutton argued an exact counterpart of szlachta society was the system of tenure of southern India\u2014an aristocracy of equality\u2014settled as conquerors among a separate race. Some elements of the Polish state paralleled the Roman Empire in that full rights of citizenship were limited to the szlachta. According to British historian Alexander Bruce Boswell, the 16th-century szlachta ideal was a Greek polis\u2014a body of citizens, a small merchant class, and a multitude of laborers. The laborers consisted of peasants in serfdom. The szlachta had the exclusive right to enter the clergy until the time of the three partitions of Poland\u2013Lithuania, and the szlachta and clergy believed they were genetically superior to peasants. The szlachta regarded peasants as a lower species. Quoting Bishop of Pozna\u0144, Wawrzyniec Go\u015blicki, herbu Grzyma\u0142a (between 1530 and 1540\u20131607):\n\"The kingdome of Polonia doth also consist of the said three sortes, that is, the king, nobility and people. But it is to be noted, that this word people includeth only knights and gentlemen. ... The gentlemen of Polonia doe represent the popular state, for in them consisteth a great part of the government, and they are as a Seminarie from whence Councellors and Kinges are taken.\"\nMilitary caste and aristocracy.\nThe social status of szlachta is compared with caste, a military caste, similar to castes in Hindu society. In the year 1244, Boles\u0142aw, Duke of Masovia, identified members of the knights' clan as members of a \"genealogia:\"\n\"I received my good servitors [Raciborz and Albert] from the land of [Great] Poland, and from the clan [\"genealogia\"] called Jelito, with my well-disposed knowledge [i.e., consent and encouragement] and the cry [\"vocitatio\"], [that is], the \"god\u0142o,\" [by the name of] \"Nagody,\" and I established them in the said land of mine, Masovia, [on the military tenure described elsewhere in the charter].\"\nThe documentation regarding Raciborz and Albert's tenure is the earliest surviving of the use of the clan name and cry defining the honorable status of Polish knights. The names of knightly \"genealogiae\" only came to be associated with heraldic devices later in the Middle Ages and in the early modern period. The Polish clan name and cry ritualized the \"ius militare,\" i.e., the power to command an army; and they had been used sometime before 1244 to define knightly status. .\n\"In Poland, the Radwanice were noted relatively early (1274) as the descendants of Radwan, a knight [more properly a \"rycerz\" from the German \"ritter\"] active a few decades earlier. ...\"\nEscutcheons and hereditary coats of arms with eminent privileges attached is an honor derived from the ancient Germans. Where Germans did not inhabit, and where German customs were unknown, no such thing existed. The usage of heraldry in Poland was brought in by knights arriving from Silesia, Lusatia, Meissen, and Bohemia. Migrations from here were the most frequent, and the time period was the thirteenth and fourteenth centuries. However, unlike other European chivalry, coats of arms were associated with Polish knights' clans' (\"genealogiae\") names and war cries (\"god\u0142o\"), where heraldic devices came to be held in common by entire clans, fighting in regiments. .\nAround the 14th century, there was little difference between knights and the \"szlachta\" in Poland. Members of the szlachta had the personal obligation to defend the country (\"pospolite ruszenie\"), thereby becoming within the kingdom a military caste and aristocracy with political power and extensive rights secured. Inclusion in the warrior caste was almost exclusively based on inheritance.\nConcerning the early Polish tribes, geography contributed to long-standing traditions. The Polish tribes were internalized and organized around a unifying religious cult, governed by the \"wiec\", an assembly of free tribesmen. Later, when safety required power to be consolidated, an elected prince was chosen to govern. The election privilege was usually limited to elites.\nThe tribes were ruled by clans () consisting of people related by blood or marriage and theoretically descending from a common ancestor, giving the r\u00f3d/clan a highly developed sense of solidarity. (See \"gens\".) The \"starosta\" (or \"starszyna\") had judicial and military power over the r\u00f3d/clan, although this power was often exercised with an assembly of elders. Strongholds called \"gr\u03ccd\" were built where the religious cult was powerful, where trials were conducted, and where clans gathered in the face of danger. The \"opole\" was the territory occupied by a single tribe. The family unit of a tribe is called the \"rodzina\", while a collection of tribes is a .\nMieszko I of Poland (c. 935 \u2013 25 May 992) established an elite knightly retinue from within his army, which he depended upon for success in uniting the Lekhitic tribes and preserving the unity of his state. Documented proof exists of Mieszko I's successors utilizing such a retinue, as well.\nAnother group of knights were granted land in allodium, not feudal tenure, by the prince, allowing them the economic ability to serve the prince militarily. A Polish warrior belonging to the military caste living at the time prior to the 15th century was referred to as a \"rycerz\", very roughly equivalent to the English \"knight\", the critical difference being the status of \"rycerz\" was almost strictly hereditary; the group of all such warriors was known as the \"rycerstwo\". Representing the wealthier families of Poland and itinerant knights from abroad seeking their fortunes, this other group of rycerstwo, which became the szlachta (\"szlachta\" becomes the proper term for Polish aristocracy beginning about the 15th century), gradually formed apart from Mieszko I's and his successors' elite retinues. This rycerstwo/aristocracy secured more rights granting them favored status. They were absolved from particular burdens and obligations under ducal law, resulting in the belief only rycerstwo (those combining military prowess with high/aristocratic birth) could serve as officials in state administration.\nSelect rycerstwo were distinguished above the other rycerstwo, because they descended from past tribal dynasties, or because early Piasts' endowments made them select beneficiaries. These rycerstwo of great wealth were called \"mo\u017cni\" (\"the powerful ones\"). They had the same political status and status in law as the rycerstwo from which they all originated and to which they would return were their wealth lost. \nThe Period of Division (1138\u20131314), which included nearly 200 years of fragmentation and which stemmed from Boles\u0142aw III's division of Poland among his sons, was the genesis of the political structure where the powerful landowning szlachta (\"mo\u017cni\", both ecclesiastical and lay), whose land was in allodium, not feudal tenure, were economically elevated above the rycerstwo they originated from. The prior political structure was one of Polish tribes united into the historic Polish nation under a state ruled by the Piast dynasty, this dynasty appearing circa 850 A.D.\nSome \"mo\u017cni\" descending from past tribal dynasties regarded themselves as co-proprietors of Piast realms, even though the Piasts attempted to deprive them of their independence. These \"mo\u017cni\" constantly sought to undermine princely authority. In Gall Anonym's chronicle, there is noted the nobility's alarm when the Palatine Sieciech \"elevated those of a lower class over those who were noble born\" entrusting them with state offices. \nLithuania.\nIn Lithuania Propria and in Samogitia, prior to the creation of the Kingdom of Lithuania by Mindaugas, nobles were called \"die beste leuten\" in German sources. In Lithuanian, nobles were named \"ponai\". The higher nobility were named \"kunigai\" or \"kunigaik\u0161\u010diai\" (dukes) \u2014 a loanword from Scandinavian \"konung\". They were the established local leaders and warlords. During the development of the state, they gradually became subordinated to higher dukes, and later to the King of Lithuania. Because of Lithuanian expansion into the lands of Ruthenia in the middle of the 14th century, a new term for nobility appeared \u2014 \"bajorai\", from Ruthenian \"\u0431\u043e\u044f\u0440\u0435\". This word is used to this day in Lithuania to refer to nobility in general, including those from abroad.\nAfter the Union of Horod\u0142o, the Lithuanian nobility acquired equal status with its Polish counterparts. Over time they became increasingly Polonized, although they did preserve their national consciousness, and in most cases recognition of their Lithuanian family roots. In the 16th century, some of the Lithuanian nobility claimed that they were descended from the Romans, and that the Lithuanian language was derived from Latin. This led to a conundrum: Polish nobility claimed its own ancestry from Sarmatian tribes, but Sarmatians were considered enemies of the Romans. Thus, a new Roman-Sarmatian theory was created. Strong cultural ties with Polish nobility led to a new term for Lithuanian nobility appearing in the 16th century \u2014 \"\u0161l\u0117kta\", a direct loanword from Polish \"szlachta\". Recently, Lithuanian linguists advocated dropping the usage of this Polish loanword.\nThe process of Polonization took place over a lengthy period. At first only the leading members of the nobility were involved. Gradually the wider population became affected. Major effects on the lesser Lithuanian nobility occurred after various sanctions were imposed by the Russian Empire, such as removing \"Lithuania\" from the names of the \"Gubernyas\" shortly after the November Uprising. After the January Uprising the sanctions went further, and Russian officials began to intensify Russification, and banned the printing of books in Lithuanian.\nRuthenia.\nAfter the principalities of Halych and Volhynia became integrated with the Grand Duchy, Ruthenia's nobility gradually rendered loyalty to the multilingual and cultural melting pot that was the Grand Duchy of Lithuania. Many noble Ruthenian families intermarried with Lithuanians.\nThe rights of Orthodox nobles were nominally equal to those enjoyed by the Polish and Lithuanian nobility, but they were put under cultural pressure to convert to Catholicism. It was a policy that was greatly eased in 1596 by the Union of Brest. See, for example, the careers of Senator Adam Kisiel and Jerzy Franciszek Kulczycki.\nOrigins of szlachta surnames.\nThe Proto-Slavic suffix \"-\u044csk\u044a\" means \"characteristic of\", \"typical of\".\nThis suffix exists in Polish as \"-ski\" (feminine: \"-ska\"). It's attached to surnames derived from a person's occupation, characteristics, patronymic surnames, or toponymic surnames (from a person's place of residence, birth or family origin).\n In antiquity, the szlachta used topographic surnames to identify themselves. The expression \"z\" (meaning \"from\" sometimes \"at\") plus the name of one's patrimony or estate (dominion) carried the same prestige as \"de\" in French names such as \"de Ch\u00e2tellerault\", and \"von\" or \"zu\" in German names such as \"von Weizs\u00e4cker\" or \"zu Rhein\". For example, the family name of counts Litwiccy (Litwicki) was formed with the patronymic suffix -ic from the ethnic name Litwa, i.e. Lithuania, 'nation of Lithuanians'. It refers to the early modern empire of Central Europe, the Polish-Lithuanian Commonwealth (1569\u20131648). In Polish \"z D\u0105br\u00f3wki\" and \"D\u0105browski\" mean the same thing: \"of, from D\u0105br\u00f3wka.\" More precisely, \"z D\u0105br\u00f3wki\" means owning the patrimony or estate D\u0105br\u00f3wka, not necessarily originating from. Almost all the surnames of genuine Polish szlachta can be traced back to a patrimony or locality, despite time scattering most families far from their original home. John of Zamo\u015b\u0107 called himself John Zamoyski, Stephen of Potok called himself Potocki.\nAt least since the 17th century the surnames/cognomens of szlachta families became fixed and were inherited by following generations, remaining in that form until today. Prior to that time, a member of the family would simply use his Christian name (e.g., Jakub, Jan, Miko\u0142aj, etc.), and the name of the coat of arms common to all members of his clan. A member of the family would be identified as, for example, \"Jakub z D\u0105br\u00f3wki\", herbu Radwan, (Jacob to/at D\u0105br\u00f3wki of the knights' clan Radwan coat of arms), or \"Jakub z D\u0105br\u00f3wki, \u017b\u0105d\u0142o (cognomen) (later a przydomek/nickname/agnomen), herbu Radwan\" (Jacob to/at [owning] D\u0105br\u00f3wki with the distinguishing name \u017b\u0105d\u0142o of the knights' clan Radwan coat of arms), or \"Jakub \u017b\u0105d\u0142o, herbu Radwan\".\nThe Polish state paralleled the Roman Empire in that full rights of citizenship were limited to the szlachta. The szlachta in Poland, where Latin was written and spoken far and wide, used the Roman naming convention of the tria nomina (praenomen, nomen, and cognomen) to distinguish Polish citizens/szlachta from the peasantry and foreigners, hence why multiple surnames are associated with many Polish coat of arms.\nExample \u2013 Jakub: Radwan \u017b\u0105d\u0142o-D\u0105browski (sometimes Jakub: Radwan D\u0105browski-\u017b\u0105d\u0142o)\nPraenomen\nJakub\nNomen (nomen gentile\u2014name of the gens/ or knights' clan):\nRadwan\nCognomen (name of the family branch/sept within the Radwan gens):\nFor example\u2014Braniecki, D\u0105browski, Czcikowski, Dostojewski, G\u00f3rski, Nicki, Zebrzydowski, etc.\nAgnomen (nickname, Polish przydomek):\n\u017b\u0105d\u0142o (prior to the 17th century, was a cognomen)\nBartosz Paprocki gives an example of the Ro\u015bciszewski family taking different surnames from the names of various patrimonies or estates they owned. The branch of the Ro\u015bciszewski family that settled in Chrapunia became the Chrapunski family, the branch of the Ro\u015bciszewski family that settled in Strykwina became the Strykwinski family, and the branch of the Ro\u015bciszewski family that settled in Borkow became known as the Borkowski family. Each family shared a common ancestor and belonged to the same knights' clan, so they bore the same coat of arms as the Ro\u015bciszewski family.\nEach knights' clan/gens/r\u00f3d had its coat of arms, and there were only a limited number. Almost without exception, there were no family coat of arms. Each coat of arms bore a name, the clan's call word. In most instances, the coat of arms belonged to many families within the clan. The Polish state paralleled the Roman Empire, and the szlachta had a different origin and structure in law than Western Europe's feudal nobility. The clan/gens/r\u00f3d system survived the whole of Polish history.\nHeraldry.\nCoats of arms were very important to the szlachta. Its heraldic system evolved together with neighbouring states in Central Europe, while differing in many ways from the heraldry of other European countries. Polish Knighthood had its counterparts, links and roots in Bohemia, e.g. Poraj coat of arms and in Germany, e.g. Junosza coat of arms.\nFamilies who had a common origin would also share a coat of arms. They would also share their crest with families adopted into the clan. Sometimes unrelated families would be falsely attributed to a clan on the basis of similarity of crests. Some noble families inaccurately claimed clan membership. The number of coats of arms in this system was comparatively low and did not exceed 200 in the late Middle Ages. There were 40,000 in the late 18th century.\nAt the Union of Horod\u0142o, forty-seven families of Catholic Lithuanian lords and boyars were adopted by Polish szlachta families and allowed to use Polish coats of arms.\nHeritability.\nThe tradition of differentiating between a coat of arms and a lozenge granted to women, did not develop in Poland. By the 17th century, invariably, men and women inherited a coat of arms from their father. When mixed marriages developed after the partitions, that is between commoners and members of the nobility, as a courtesy, children could claim a coat of arms from their distaff side, but this was only tolerated and could not be passed on to the next generation. The brisure was rarely used. All children would inherit the coat of arms and title of their father. This partly accounts for the relatively large proportion of Polish families who had claim to a coat of arms by the 18th century. Another factor was the arrival of titled foreign settlers, especially from the German lands and the Habsburg Empire.\nIllegitimate children could adopt the mother's surname and title by the consent of the mother's father, but would sometimes be adopted and raised by the natural father's family, thereby acquiring the father's surname, though not the title or arms.\nEnnoblement.\nKingdom of Poland.\nThe number of lawfully granted ennoblements (naturalization) after the 15th century was minimal.\nIn the Kingdom of Poland and later in the Polish\u2013Lithuanian Commonwealth, ennoblement (\"nobilitacja\") may be equated with an individual given legal status as a \"szlachcic\" member of the Polish nobility. Initially, this privilege could be granted by the monarch, but from 1641 onward, this right was reserved for the sejm. Most often the individual being ennobled would join an existing noble szlachta clan and assume the undifferentiated coat of arms of that clan.\nAccording to heraldic sources, the total number of lawful ennoblements issued between the 14th century and the mid-18th century is estimated at 800. This is an average of only about two ennoblements per year, or only 0.000,000,14 \u2013 0.000,001 of the historical population. Compare: historical demography of Poland. Charles-Joseph, 7th Prince of Ligne, when trying to obtain Polish noble status, supposedly said in 1784, \"It is easier to become a duke in Germany, than to be counted among Polish nobles.\"\nThe close of the late 18th century (see below) was a period in which a definite increase in the number of ennoblements can be noted. This can most readily be explained in terms of the ongoing decline and eventual collapse of the Commonwealth and the resulting need for soldiers and other military leaders (see: Partitions of Poland, King Stanis\u0142aw August Poniatowski).\nEstimated number of ennoblements.\nAccording to heraldic sources 1,600 is the total estimated number of all lawful ennoblements throughout the history of Kingdom of Poland and Polish\u2013Lithuanian Commonwealth from the 14th century onward (half of which were performed in the final years of the late 18th century).\nTypes of ennoblement:\nGrand Duchy of Lithuania.\nIn the late 14th century, in the Grand Duchy of Lithuania, Vytautas the Great reformed the Grand Duchy's army: instead of calling all men to arms, he created forces comprising professional warriors\u2014\"bajorai\" (\"nobles\"; see the cognate \"boyar\"). As there were not enough nobles, Vytautas trained suitable men, relieving them of labor on the land and of other duties; for their military service to the Grand Duke, they were granted land that was worked by hired men (veldams). The newly formed noble families generally took up, as their family names, the Lithuanian pagan given names of their ennobled ancestors; this was the case with the Go\u0161tautai, Radvilos, Astikai, K\u0119sgailos and others. These families were granted their coats of arms under the Union of Horodlo (1413).\nIn 1506, King Sigismund I the Old confirmed the position of the Lithuanian Council of Lords in state politics and limited entry into the nobility.\nPrivileges.\nSpecific rights of the szlachta included:\nSignificant legislative changes in the status of the szlachta, as defined by Robert Bideleux and Ian Jeffries, consist of its 1374 exemption from the land tax, a 1425 guarantee against the 'arbitrary arrests and/or seizure of property' of its members, a 1454 requirement that military forces and new taxes be approved by provincial Sejms, and statutes issued between 1496 and 1611 that prescribed the rights of commoners.\nReal and false nobles.\nNobles were born into a noble family, or adopted into a noble clan by an act of the King (this was abolished in 1633). The rarest way of achieving szlachta status was through ennoblement (naturalization) by a king or Sejm for reasons such as bravery in combat, service to the state, etc. There were claims some nobles were, in fact, usurpers who were commoners that moved to another part of the country and falsely claimed noble status. In the first half of the 16th century, hundreds of such \"false nobles\" were denounced by Hieronim Nekanda Trepka (1550\u20131630) in his \"Liber generationis plebeanorum (Liber chamorum)\", or \"Book of Plebeian Genealogy (Ham's Book)\". Peasants were considered descendants of Ham, the son of Noah subject to bondage under the Curse of Ham. The law forbade commoners holding landed estates and promised such estates as a reward to denouncers. Trepka was himself an impoverished nobleman who lived a town dweller's life and documented hundreds of such false claims hoping to take over one of the usurped estates. He does not seem to have succeeded in his quest despite his employment as the king's secretary. Many sejms issued decrees over the centuries in an attempt to resolve this issue, but with little success. It is unknown what percentage of the Polish nobility came from the 'lower orders' of society, but there are historians who claim nobles of such base origins formed a 'significant' element of the szlachta.\nSelf-promotion and aggrandizement were not confined to commoners. Often, members of the lower szlachta sought further ennoblement from foreign, therefore less verifiable, sources. That is, they might acquire by legitimate means or otherwise, such as by purchase, one of a selection of foreign titles ranging from Baron, Marchese, Freiherr to Comte, all readily translatable into the Polish \"Hrabia\". Alternatively, they would simply appropriate a title by conferring it upon themselves. An example of this is cited in the case of the last descendant of the Ciechanowiecki family, who managed to restore a genuinely old Comital title, but whose actual origins are shrouded in 18th-century mystery.\nAccretion of sovereignty to the szlachta.\nThe szlachta secured many rights not secured to the nobility of other countries. Over time, each new monarch ceded to them further privileges. Those privileges became the basis of the \"Golden Liberty\" in the Polish\u2013Lithuanian Commonwealth. Despite having a king, Poland was considered the 'nobility's Commonwealth' because Royal elections in Poland were in the hands of members of a hereditary class. Poland was therefore the domain of this class, and not that of the king or the ruling dynasty. This arose in part because of the extinction of male heirs in the original royal dynasties: first, the Piasts, then the Jagiellons. As a result, the nobility took it upon itself to choose \"the Polish king\" from among the dynasties' matrilinial descendants.\nPoland's successive kings granted privileges to the nobility upon their election to the throne \u2013 the privileges having been specified in the king-elect's Pacta conventa \u2013 and at other times, in exchange for \"ad hoc\" leave to raise an extraordinary tax or a \"pospolite ruszenie\", a military call up. Poland's nobility thus accumulated a growing array of privileges and immunities.\nIn 1355 in Buda King Casimir III the Great issued the first country-wide privilege for the nobility, in exchange for their agreeing that if Casimir had no male heirs, the throne would pass to his nephew, Louis I of Hungary. Casimir further decreed that the nobility would no longer be subject to 'extraordinary' taxes or have to use their own funds for foreign military expeditions. Casimir also promised that when the royal court toured, the king and the court would cover all expenses, instead of requiring facilities to be provided by the local nobility.\nPrivilege of Koszyce and others.\nIn 1374 King Louis of Hungary approved the Privilege of Koszyce (\"przywilej koszycki\") to guarantee the Polish throne for his daughter, Jadwiga. He broadened the definition of membership of the nobility and exempted the entire class from all but one tax (\"\u0142anowy\") a limit of 2 groszes per \"\u0142an\" of land, Old Polish units of measurement. In addition, the King's right to raise taxes was effectively abolished: no new taxes would be levied without the agreement of the nobility. Henceforth, district offices were also reserved exclusively for local nobility, as the Privilege of Koszyce forbade the king to grant official posts and major Polish castles to foreign knights. Finally, the privilege obliged the king to pay indemnities to nobles injured or taken captive during a war outside Polish borders.\nIn 1422 King W\u0142adys\u0142aw II Jagie\u0142\u0142o was constrained by the Privilege of Czerwi\u0144sk (\"przywilej czerwi\u0144ski\"), which established the inviolability of nobles' property. Their estates could not be confiscated except upon the verdict of a court. It also made him cede some jurisdiction over fiscal policy to the Royal Council, later, the Senate of Poland, including the right to mint coinage.\nIn 1430, with the Privileges of Jedlnia, confirmed at Krak\u00f3w in 1433, Polish: \"przywileje jedlne\u0144sko-krakowskie\", based partially on his earlier Brze\u015b\u0107 Kujawski privilege (25 April 1425), King W\u0142adys\u0142aw II Jagie\u0142\u0142o granted the nobility a guarantee against arbitrary arrest, similar to the English Magna Carta's habeas corpus, known from its own Latin name as \"neminem captivabimus nisi jure victum\". Henceforth, no member of the nobility could be imprisoned without a warrant from a court of justice. The king could neither punish nor imprison any noble on a whim. King W\u0142adys\u0142aw's \"quid pro quo\" for the easement was the nobles' guarantee that the throne would be inherited by one of his sons, who would be bound to honour the privileges granted earlier to the nobility. On 2 May 1447 the same king issued the \"Wilno Pact, or Wilno Privilege\", which gave the Lithuanian boyars the same rights as those already secured by the Polish \"szlachta\".\nIn 1454, King Casimir IV granted the Nieszawa Statutes \u2013 Polish: \"statuty cerkwicko-nieszawskie\", clarifying the legal basis of voivodship sejmiks \u2013 local parliaments. The king could promulgate new laws, raise taxes, or call for a mass military call up \"pospolite ruszenie\", only with the consent of the sejmiks, and the nobility were protected from judicial abuses. The Nieszawa Statutes also curbed the power of the magnates, as the Sejm, the national parliament, had the right to elect many officials, including judges, voivods and castellans. These privileges were demanded by the \"szlachta\" in exchange for their participation in the Thirteen Years' War.\nFirst Royal Election.\nThe first \"free election\" (Polish: \"wolna elekcja\") of a king took place in 1492. In fact, some earlier Polish kings had been elected with help from assemblies such as those that put Casimir II on the throne, thereby setting a precedent for free elections. Only senators voted in the 1492 free election, which was won by John I Albert. For the duration of the Jagiellonian Dynasty, only members of that royal family were considered for election. Later, there would be no restrictions on the choice of candidates.\nIn 1493 the Sejm, began meeting every two years at Piotrk\u00f3w. It comprised two chambers:\nThe numbers of senators and deputies later increased.\nOn 26 April 1496 King John I Albert granted the Privilege of Piotrk\u00f3w. The Statutes of Piotrk\u00f3w increased the nobility's feudal power over serfs. It bound the peasant to the land, and only one son though not the eldest, was permitted to leave the village. Townsfolk \"mieszcza\u0144stwo\" were prohibited from owning land. Positions in the Church hierarchy were restricted to nobles.\nOn 23 October 1501, the Polish\u2013Lithuanian union was reformed by the Union of Mielnik. It was there that the tradition of a coronation Sejm was founded. Here again, the lesser nobility, lesser in wealth only \u2013 not in rank \u2013 attempted to reduce the power of the Magnates with a law that made them impeachable before the Senate for malfeasance. However, the Act of Mielnik of 25 October did more to strengthen the Magnate-dominated Senate of Poland than the lesser nobility. Nobles as a whole were given the right to disobey the King or his representatives \u2014 \"non praestanda oboedientia\", and to form confederations, armed opposition against the king or state officials if the nobles found that the law or their legitimate privileges were being infringed.\nOn 3 May 1505 King Alexander I Jagiellon granted the Act of \"Nihil novi nisi commune consensu\" \u2013 \"I accept nothing new except by common consent\". This forbade the king to pass new laws without the consent of the representatives of the nobility in the assembled Sejm, thus greatly strengthening the nobility's powers. Essentially, this act marked the transfer of legislative power from the king to the Sejm. It also marks the beginning of the First Rzeczpospolita, the period of a \"szlachta\"-run \"Commonwealth\".\nIn 1520 the Act of Bydgoszcz granted the Sejm the right to convene every four years, with or without the king's permission. At about that time the \"Executionist Movement\", seeking to oversee law enforcement, began to take shape. Its members sought to curb the power of the Magnates at the Sejm and to strengthen the power of the monarch. In 1562 at the Sejm in Piotrk\u00f3w they forced the Magnates to return many leased crown lands to the king, and the king to create a standing army wojsko kwarciane. One of the most famous members of this movement was Jan Zamoyski.\nEnd of the Jagiellonian dynasty.\nUntil the death of Sigismund II Augustus, the last king of the Jagiellonian dynasty, all monarchs had to be elected from within the royal family. However, from 1573, practically any Polish noble or foreigner of royal blood could potentially become a Polish\u2013Lithuanian monarch. Every newly elected king was supposed to sign two documents: the \"Pacta conventa\", the king's \"pre-election pact\", and the \"Henrican articles\", named after the first freely elected king, Henry of Valois. The latter document was a virtual \"Polish constitution\" and contained the basic laws of the Commonwealth:\nIn 1578 king, Stefan Batory, created the Crown Tribunal to reduce the enormous pressure on the Royal Court. This placed much of the monarch's juridical power in the hands of the elected szlachta deputies, further strengthening the nobility as a class. In 1581 the Crown Tribunal was joined by a counterpart in Lithuania, the Lithuanian Tribunal.\nMagnate oligarchy.\nFor many centuries, wealthy and powerful members of the szlachta sought to gain legal privileges over their peers. In 1459 Ostror\u00f3g presented a memorandum to the Sejm (parliament), submitting palatines, or Voivodes of the Polish\u2013Lithuanian Commonwealth, receive the title of prince. Sons of the prince were to receive titles of counts and barons. Castellans of the Polish\u2013Lithuanian Commonwealth were to receive the title of count. All these submissions were rejected.\nFew szlachta were wealthy enough to be known as Magnates, \"karmazyni\", the \"Crimsons\" \u2013 from the crimson colour of their boots. A true Magnate had to be able to trace his ancestry for many generations and own at least 20 villages or estates. He also had to hold high office in the Commonwealth.. Thus, out of about one million szlachta, only 200\u2013300 persons could be classed as Magnates with country-wide possessions and influence. Of these some 30\u201340 were considered as having significant impact on Poland's politics. Magnates often received gifts from monarchs, which greatly increased their wealth. Although such gifts were only temporary leases, often the Magnates never returned them. This gave rise in the 16th century, to a self-policing trend by the szlachta, known as the \"ruch egzekucji praw\" \u2014 movement for the enforcement of the law \u2013 against usurping Magnates to force them to return leased lands back to their rightful owner, the monarch.\nOne of the most important victories of the Magnates was the late 16th century right to create \"Ordynacjas\", similar to Fee tails under English law, which ensured that a family which gained landed wealth could more easily preserve it. The \"Ordynacjas\" that belonged to families such as the Radziwi\u0142\u0142, Zamoyski, Potocki or Lubomirskis often rivalled the estates of the king and were important power bases for them.\nThe difference between the \"magnateria\" and the rest of the szlachta was primarily one of wealth and life-style, as both belonged to the same legally defined class being members of the same clans. Consequently, any power wrested from the king by the magnates was consequently trickled down to the entirety of the szlachta. This often meant the rest of the szlachta tended to cooperate with the magnates rather than struggle against them.\nSzlachta loss of influence.\n The notion of the szlachta's accrued sovereignty ended in 1795 with the final Partitions of Poland, and until 1918 their legal status was dependent on the policies of the Russian Empire, the Kingdom of Prussia or the Habsburg monarchy.\nIn the 1840s Nicholas I reduced 64,000 of lesser szlachta to a particular commoner status known as \"odnodvortsy\" (literally \"single-householders\"). Despite this, 62.8% of all Russia's nobles were Polish szlachta in 1858 and still 46.1% in 1897.\nSerfdom was abolished in Russian Poland on 19 February 1864. It was deliberately enacted with the aim of ruining the szlachta. Only in the Russian Partition did peasants pay the market price for land redemption, the average for the rest of the Russian Empire was 34% above the market rates. All land taken from Polish peasants since 1846 was to be returned to them without redemption payments. The ex-serfs could only sell land to other peasants, not szlachta. 90% of the ex-serfs in the empire who actually gained land after 1861 lived in the 8 western provinces. Along with Romania, Polish landless or domestic serfs were the only ones to be given land after serfdom was abolished. All this was to punish the szlachta's role in the uprisings of 1830 and 1863.\nBy 1864 80% of szlachta were \"d\u00e9class\u00e9\" \u2013 downward social mobility. One quarter of petty nobles were worse off than the average serf. While 48.9% of the land in Russian Poland was in peasant hands, nobles still held onto 46%.\nIn the Second Polish Republic the privileges of the nobility were legally abolished by the March Constitution in 1921 and as such not reinstated by any succeeding Polish law.\nCulture.\nSarmatism.\nThe \"szlachta\"'s prevalent ideology, especially in the 17th and 18th centuries, was manifested in its adoption of \"Sarmatism\", a word derived from the legend that its origins reached back to the ancient tribe of an Iranic people, the Sarmatians. This nostalgic belief system embracing chivalry and courtliness became an important part of \"szlachta\" culture and affected all aspects of their lives. It was popularized by poets who exalted traditional village life, peace and pacifism. It was also manifested in oriental-style apparel, the \"\u017cupan\", \"kontusz\", \"sukmana\", \"pas kontuszowy\", \"delia\" and made the scimitar-like \"szabla\" a near-obligatory item of everyday \"szlachta\" apparel. Sarmatism served to integrate a nobility of disparate provenance, as it sought to create a sense of national unity and pride in the szlachta's \"Golden Liberty\" \"z\u0142ota wolno\u015b\u0107\". It was marked furthermore by a linguistic affectation among the \"szlachta\" of mixing Polish and Latin vocabulary, producing a form of Polish Dog Latin peppered with \"macaronisms\" in everyday conversation.\nGastronomy.\nThe szlachta, no less than the rest of the population, placed a particular accent on food. It was at the centre of courtly and estate entertaining and in good times, at the heart of village life. During the Age of Enlightenment, King Stanislaw August Poniatowski emulated the French Salons by holding his famed Thursday Lunches for intellectuals and artists, drawn chiefly from the szlachta. His \"Wednesday Lunches\" were gatherings for policy makers in science, education and politics.\nThere was a tradition, particularly in Mazovia, kept until the 20th century, of estate owners laying on a festive banquet at the completion of harvest for their staff, known as \"Do\u017cynki\", as a way of expressing an acknowledgment of their work. It was equivalent to a harvest festival. Polish food varied according to region, as elsewhere in Europe, and was influenced by settlers, especially Jewish cuisine, and occupying armies.\nHunting.\nOne of the favourite szlachta pastimes was hunting (\"\u0142owiectwo\"). Before the formation of Poland as a state, hunting was accessible to everyone. With the introduction of rulers and rules, big game, generically \"zwierzyna\": Aurochs, bison, deer and boar became the preserve of kings and princes on penalty of poachers' death. From the 13th century on the king would appoint a high-ranking courtier to the role of Master of the Hunt, \"\u0141owczy\". In time, the penalties for poaching were commuted to fines and from around the 14th century, landowners acquired the right to hunt on their land. Small game, foxes, hare, badger and stoat etc. were 'fair game' to all comers. Hunting became one of the most popular social activities of the szlachta until the partitions, when different sets of restrictions in the three territories were introduced. This was with a view to curbing social interaction among the subject Poles. Over the centuries, at least two breeds of specialist hounds were bred in Poland. One was the Polish Hunting Dog, the \"brach\". The other was the Ogar Polski. Count Xavier Branicki was so nostalgic about Polish hunting, that when he settled in France in the mid 19th century, and restored his estate at the Chateau de Montresor, he ordered a brace of Ogar Polski hounds from the Polish breeder and \"szlachcic\", Piotr Orda.\nWomen as purveyors of culture.\nHigh-born women in Polish\u2013Lithuanian Commonwealth exerted political and cultural influence throughout history in their own country and abroad, as queens, princesses and the wives or widows of magnates. Their cultural activities came into sharper relief in the 18th century with their hosting of salons in the French manner. They went on to publish as translators and writers and as facilitators of educational and social projects.\nNotable women members of the szlachta who exerted political and/or cultural influence include:\nDemographics and stratification.\nThe szlachta differed in many respects from the nobility in other countries. The most important difference was that, while in most European countries the nobility lost power as the ruler strove for absolute monarchy, in the Polish\u2013Lithuanian Commonwealth a reverse process occurred: the nobility actually gained power at the expense of the king, and enabled the political system to evolve into an oligarchy.\nSzlachta members were also proportionately more numerous than their equivalents in all other European countries, constituting 6\u201312% of the entire population.&lt;templatestyles src=\"Citation/styles.css\"/&gt;[a] By contrast, nobles in other European countries, except for Spain, amounted to a mere 1\u20133%. Most of the szlachta were \"minor nobles\" or smallholders. In Lithuania the minor nobility made up to 3/4 of the total szlachta population. By the mid-16th century the szlachta class consisted of at least 500,000 persons (some 25,000 families). Polish historian Tadeusz Korzon carried out an estimation of the social structure of Poland based on the documents of 1770\u20131780s, such as tax registers, partial censuses, etc. His estimate for the number of \"szlachta\" was 725,000 of total population 8.8 million. For comparison with other social classes, Christian clergy counted 50,000, Christian \"mieszcza\u0144stwo\" (burghers) counted 500,000, peasants of various categories (\"w\u0142o\u015bcianie\"): 6.4 million, Jews (the fast growing group), e.g., 750,000 in 1764 and 900,000 in 1790. Korzon counted Armenians, Tatars, Greeks, and Russian \"raskolniks\" as separate social groups, totaling 250,000-300,000.\nThe proportion of nobles in the population varied across regions. In the 16th century, the highest proportion of nobles lived in the P\u0142ock Voivodeship (24,6%) and in Podlachia (26,7%), while Galicia had numerically the largest szlachta population. In districts, such as Wizna and \u0141om\u017ca, the szlachta constituted nearly half of the population. Regions with the lowest percentage of nobles were the Krak\u00f3w Voivodeship with (1,7%), Royal Prussia with (3%) and the Sieradz Voivodeship with 4,6%. Before the Union of Lublin, inequality among nobles in terms of wealth and power was far greater in the Grand Duchy of Lithuania than in the Polish Kingdom. The further south and east one went, the more the territory was dominated by magnate families and other nobles. In the Lithuanian and Ruthenian palatinates, poor nobles were more likely to rent smallholdings from magnates than to own land themselves.\nIt has been said that the ruling elites were the only socio-political milieu to whom a sense of national consciousness could be attributed. All szlachta members, irrespective of their cultural/ethnic background, were regarded as belonging to a single \"political nation\" within the Commonwealth. Arguably, a common culture, the Catholic religion and the Polish language were seen as the main unifying factors in the dual state. Prior to the Partitions there was said to have been no Polish national identity as such. Only szlachta members, irrespective of their ethnicity or culture of origin, were considered as \"Poles\".\nDespite Polonisation in Lithuania and Ruthenia in the 17th-18th centuries, a large part of the lower szlachta managed to retain their cultural identity in various ways. Due to poverty most of the local szlachta had never had access to formal education nor to Polish language teaching and hence could not be expected to self-identify as \"Poles\". It was common even for wealthy and in practice Polonised szlachta members still to refer to themselves as Lithuanian, \"Litwin\" or Ruthenian, \"Rusyn\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Although born a Lithuanian and a Lithuanian I shall die, I must use the Polish idiom in my homeland.\u2014\u200a\nAccording to Polish estimates from the 1930s, 300,000 members of the common nobles \"s\" \"zlachta zagrodowa\" \u2013 inhabited the subcarpathian region of the Second Polish Republic out of 800,000 in the whole country. 90% of them were Ukrainian-speaking and 80% were Ukrainian Greek Catholics. In other parts of Ukraine with a significant szlachta population, such as the Bar or the Ovruch regions, the situation was similar despite Russification and earlier Polonization. As an example:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;... The first official records of the Chopovsky family, as clan members of the Korwin coat of arms, date back to mid-XVII century. As the Chopovsky family multiplied, by 1861 they were already 3063 souls of both sexes. They were considered szlachta members, but neither their way of life nor their clothing distinguished them from the neighbouring peasants, except that they were more prosperous and possessed more of their own land [...]. When Uniates began joining the Orthodox church in 1839 - The Russian government liquidated the Uniate church after the Polotsk Convocation - 43 souls of both sexes switched to the Roman faith, while the rest of the Chopovsky (86%) returned to Orthodoxy. The Heraldic Office of the Russian Senate declined to certify the Chopovsky family's noble status, but the land remained theirs. The exception were the Prokopenko-Chopovsky branch of the family who were received into the Russian nobility in 1858,\nHowever the era of sovereign rule by the szlachta ended earlier than in other countries, excluding France, in 1795 (see Partitions of Poland). Since then their legitimacy and fate depended on the legislation and policies of the Russian Empire, Kingdom of Prussia and Habsburg monarchy. Their privileges became increasingly limited, and were ultimately dissolved by the March Constitution of Poland in 1921.\nThere were a number of avenues to upward social mobility and the attainment of nobility. The szlachta was not rigidly exclusive or closed as a class, but according to heraldic sources, the total number of legal ennoblements issued between the 14th and mid-18th century, is estimated at 800. This is an average of about two ennoblements per year.\nAccording to two English journalists Richard Holt Hutton and Walter Bagehot writing on the subject in 1864,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The condition of the country at the present day shows that the population consisted of two different peoples, between whom there was an impassable barrier. There is the Sliachta, or caste of nobles (the descendants of Lekh), on the one hand, and the serfs or peasantry, who constitute the bulk of the population, on the other.\nand\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;... the Statute of 1633 completed the slavery of the other classes, by proclaiming the principle that 'the air enslaves the man,' in virtue of which every peasant who had lived for a year upon the estate of a noble was held to be his property. Nowhere in history - nowhere in the world - do we ever see a homogeneous nation organise itself in a form like that which has prevailed from the earliest times in Poland. But where there has been an intrusion of a dominant people, or settlers, who have not fused into the original population, there we find an exact counterpart of Polish society: the dominant settlers establishing themselves as an upper caste, all politically equal among themselves, and holding the lands (or, more frequently, simply drawing the rents) of the country.\nSociologist and historian, Jerzy Ryszard Szacki said in this context,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;... the Polish nobility was a closed group (apart from a few exceptions, many of which were contrary to the law), in which membership was inherited.\nOthers assert the szlachta were not a social class, but a caste, among them, historian Adam Zamoyski,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;A more apt analogy might perhaps be made with the Rajputs of northern India. ... unlike any other gentry in Europe, the szlachta was not limited by nor did it depend for its status on either wealth, or land, or royal writ. It was defined by its function, that of a warrior caste.\nJerzy Szacki continues,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;While Aleksander \u015awi\u0119tochowski wrote: 'If from the deeds of the Polish nobility we took away excesses and the exclusiveness of caste, ...'.\nLow-born individuals, including townsfolk \"mieszczanie\", peasants \"ch\u0142opi\", but not Jews \"\u017bydzi\", could and did rise to official ennoblement in Commonwealth society, although Charles-Joseph, 7th Prince of Ligne, while trying to obtain Polish noble status, is supposed to have said in 1784,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It is easier to become a duke in Germany, than to be counted among Polish nobles.\nAccording to heraldic sources 1,600 is the total estimated number of all legal ennoblements throughout the history of Kingdom of Poland and Polish\u2013Lithuanian Commonwealth from the 14th century onward, half of which were enacted in the final years of the late 18th century. Hutton and Bagehot,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;... for the barrier of exclusion was partly thrown down in the last days of the monarchy ...\nEach \"szlachcic\" was said to hold enormous potential influence over the country's politics, far greater than that enjoyed by the citizens of modern democratic countries. Between 1652 and 1791, any nobleman could potentially nullify all the proceedings of a given \"sejm\" or \"sejmik\" by exercising his individual right of \"liberum veto\" \u2013 Latin for \"I do not allow\" \u2013 except in the case of a confederated sejm or confederated sejmik.\nIn old Poland, a nobleman could only marry a noblewoman, as intermarriage between \"castes\" was fraught with difficulties (endogamy); but, children of a legitimate marriage followed the condition of the father, never the mother, therefore, only the father transmitted his nobility to his children. See \"patrilineality\". A noble woman married to a commoner could not transmit her nobility to her husband and their children. Any individual could attain ennoblement (\"\") for special services to the state. A foreign noble might be naturalized as a Polish noble through the mechanism called the \"Indygenat\", certified by the king. Later, from 1641, it could only be done by a general sejm. By the eighteenth century all these trends contributed to the great increase in the proportion of szlachta in the total population.\nIn theory all szlachta members were social equals and were formally legal peers. Those who held civic appointments were more privileged but their roles were not hereditary. Those who held honorary appointments were superior in the hierarchy but these positions were only granted for a lifetime. Some tenancies became hereditary and went with both privilege and title. Nobles who were not direct Lessees of the Crown but held land from other lords were only peers \"de iure\". The poorest enjoyed the same rights as the wealthiest magnate. The exceptions were a few symbolically privileged families such as the Radziwi\u0142\u0142, Lubomirski and Czartoryski, who held honorary aristocratic titles bestowed by foreign courts and recognised in Poland which granted them use of titles such as \"Prince\" or \"Count\". See also The Princely Houses of Poland. All other szlachta simply addressed each other by their given name or as \"Brother, Sir\" \"Panie bracie\" or the feminine equivalent. The other forms of address would be \"Illustrious and Magnificent Lord\", \"Magnificent Lord\", \"Generous Lord\" or \"Noble Lord\" in descending order, or simply \"His/Her Grace Lord/Lady\".\nThe notion that all Polish nobles were social equals, regardless of their financial status or offices held, is enshrined in a traditional Polish adage:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nrenderable in English:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nor, preserving the Polish original's rhyme scheme:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nSzlachta categories.\nThe nobility were divided by wealth into:\nPolish landed gentry \u2013 \"ziemianie\", or \"ziemia\u0144stwo\" \u2013 was a social class of landowners with manorial estates. The vast majority were \"szlachta\", including lesser nobility, and owned at least part of a village. Since titular manorial lordships were also open to burgers of certain privileged cities with royal charters, not all landed gentry had hereditary noble status. The term \"ziemia\u0144stwo\" was also applied to wealthier landed peasants. Magnates, as owners of vast lands, generally were considered a separate social class.\nLandless \"szlachta\" were sometimes excluded from taking part in \"sejmiks\". Its political rights were removed altogether by the Constitution of 3 May 1791. The purpose of the move was to eliminate the purchases of \"szlachta-go\u0142ota\" voices in sejmiks by magnates to use them, e.g., in voting or in executing \"liberum veto\".\n\"P\u00f3\u0142panek\" (\"half-lord\"); also podpanek/pidpanek (\"sub-lord\") in Podolia and Ukrainian accent \u2013 a derogatory term for a petty \"szlachcic\" pretending to be wealthy.\nIn the Russian Partition of Poland, Tsar Nicholas I signed a ukase on 19 October 1831, titled \"On the Division and Disposition of Nobility in the Western Governorates\", which required those claiming noble status to provide evidence to the Russian Office of Heraldry. The result was a drastic decrease in the number of petty \"szlachta\", who were demoted into estates of the realm required to pay taxes.\nExplanatory notes.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n\"a.\"&lt;templatestyles src=\"Citation/styles.css\"/&gt;^ Estimates of the proportion of szlachta vary widely: 10\u201312% of the total population of historic Polish\u2013Lithuanian Commonwealth, around 8% of the total population in 1791 (up from 6.6% in the 16th century) or 6\u20138%.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29052", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=29052", "title": "Scissors, Paper, Stone", "text": ""}
{"id": "29053", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=29053", "title": "Small Computer Systems Interface", "text": ""}
{"id": "29054", "revid": "38101398", "url": "https://en.wikipedia.org/wiki?curid=29054", "title": "Syntactic sugar", "text": "Programming language syntax designed for ease of use\nIn computer science, syntactic sugar is syntax within a programming language that is designed to make things easier to read or to express. It makes the language \"sweeter\" for human use: things can be expressed more clearly, more concisely, or in an alternative style that some may prefer. Syntactic sugar is usually a shorthand for a common operation that could also be expressed in an alternate, more verbose, form: The programmer has a choice of whether to use the shorter form or the longer form, but will usually use the shorter form since it is shorter and easier to type and read.\nFor example, in the Python programming language it's possible to get a list element at a given index using the syntax codice_1, but this is frequently shortened to codice_2 which could be considered simpler and easier to read, despite having identical behavior. Similarly, codice_3 is frequently shortened to codice_4.\nA construct in a language is syntactic sugar if it can be removed from the language without any effect on what the language can do: functionality and expressive power will remain the same.\nLanguage processors, including compilers and static analyzers, often expand sugared constructs into their more verbose equivalents before processing, a process sometimes called \"desugaring\".\nOrigins.\nThe term \"syntactic sugar\" was coined by Peter J. Landin in 1964 to describe the surface syntax of a simple ALGOL-like programming language which was defined semantically in terms of the applicative expressions of lambda calculus, centered on lexically replacing \u03bb with \"where\".\nLater programming languages, such as CLU, ML and Scheme, extended the term to refer to syntax within a language which could be defined in terms of a language core of essential constructs; the convenient, higher-level features could be \"desugared\" and decomposed into that subset. This is, in fact, the usual mathematical practice of building up from primitives.\nBuilding on Landin's distinction between essential language constructs and syntactic sugar, in 1991, Matthias Felleisen proposed a codification of \"expressive power\" to align with \"widely held beliefs\" in the literature. He defined \"more expressive\" to mean that without the language constructs in question, a program would have to be completely reorganized.\nCriticism.\nSome programmers feel that these syntax usability features are either unimportant or outright frivolous. Notably, special syntactic forms make a language less uniform and its specification more complex, and may cause problems as programs become large and complex. This view is particularly widespread in the Lisp community, as Lisp has very simple and regular syntax, and the surface syntax can easily be modified.\nFor example, Alan Perlis once quipped in \"Epigrams on Programming\", in a reference to bracket-delimited languages, that \"Syntactic sugar causes cancer of the semi-colons\".\nDerivative terms.\nSyntactic salt.\nThe metaphor has been extended by coining the term \"syntactic salt\", which indicates a feature designed to make it harder to write bad code. Specifically, syntactic salt is a hoop that programmers must jump through just to prove that they know what is going on, rather than to express a program action.\nIn C#, when hiding an inherited class member, a compiler warning is issued unless the codice_42 keyword is used to specify that the hiding is intentional. To avoid potential bugs owing to the similarity of the switch statement syntax with that of C or C++, C# requires a codice_43 for each non-empty codice_44 label of a codice_45 (unless codice_46, codice_47, or codice_48 is used) even though it does not allow implicit \"fall-through\". (Using codice_46 and specifying the subsequent label produces a C/C++-like \"fall-through\".)\nSyntactic salt may defeat its purpose by making the code unreadable and thus worsen its quality\u00a0\u2013 in extreme cases, the essential part of the code may be shorter than the overhead introduced to satisfy language requirements.\nAn alternative to syntactic salt is generating compiler warnings when there is high probability that the code is a result of a mistake\u00a0\u2013 a practice common in modern C/C++ compilers.\nSyntactic saccharin.\nOther extensions are \"syntactic saccharin\" and \"syntactic syrup\", meaning gratuitous syntax that does not make programming any easier.\nSugared types.\nData types with core syntactic support are said to be \"sugared types\". Common examples include quote-delimited strings, curly braces for object and record types, and square brackets for arrays.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "29056", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=29056", "title": "Sonic the Hedgehog (character)", "text": "Video game character\n is a character created by the Japanese game designers Yuji Naka and Naoto Ohshima. He is the star of the \"Sonic the Hedgehog\" franchise and the mascot of the Japanese video game company Sega. Sonic is an anthropomorphic blue hedgehog who can run at supersonic speed. He races through levels, collecting rings and avoiding obstacles, as he seeks to defeat his archenemy, Doctor Eggman. He is accompanied by supporting characters, such as his sidekick Miles \"Tails\" Prower, romantic interest Amy Rose, and friendly rival Knuckles the Echidna.\nSonic made a cameo appearance in the arcade game \"Rad Mobile\" (1990) before starring in \"Sonic the Hedgehog\", a platform game for the Sega Genesis, in 1991. Sega sought a mascot to compete with Nintendo's Mario, and Ohshima designed Sonic based on a prototype programmed by Naka. Sonic's design was influenced by a variety of sources, including Felix the Cat, Mickey Mouse, Michael Jackson, and Santa Claus; his pigmentation was chosen to match Sega's cobalt blue logo. Yuji Uekawa redesigned Sonic for \"Sonic Adventure\" (1998) to suit the franchise's transition to 3D computer graphics, with a more mature look designed to appeal to older players.\n\"Sonic\" media characterizes Sonic as an impatient, snarky drifter and daredevil who despises injustice. He frequently battles Eggman, a mad scientist who seeks to steal the mystical Chaos Emeralds and take over the world. Sonic can curl into a ball to attack enemies and use the Chaos Emeralds to become invulnerable. He has appeared in over 100 video games, in addition to guest appearances in other Sega franchises and in crossover games such as Nintendo's \"Super Smash Bros.\" series. Jun'ichi Kanemaru voices Sonic in Japan, while his English voice has been provided by Ryan Drummond, Jason Griffith, and Roger Craig Smith.\nSonic is one of the most famous video game characters in history and an established pop culture icon. He is widely considered one of the greatest video game characters and his popularity inspired a wave of imitators. His likeness has been featured in merchandise and Sega sponsorships. The \"Sonic\" series is one of the bestselling video game franchises and was one of the key reasons for Sega's success during the 16-bit era in the 1990s. Sonic has been adapted in comics, animations, and films, including a live-action film franchise distributed by Paramount Pictures in which he is voiced by Ben Schwartz.\nHistory.\nWhile Sega was seeking a flagship series to compete with Nintendo's Mario series, several character designs were submitted by its research and development department. Many results came forth from their experiments with character design, including an armadillo, a dog, a Theodore Roosevelt look-alike in pajamas (who would later be the basis of Doctor Eggman's design), and a rabbit (who would use its extendable ears to collect objects, an aspect later incorporated in \"Ristar\"). Naoto Ohshima took some of these internal designs with him on a trip to New York City and sought feedback by asking random passersby at Central Park their opinions; of the designs, the spiky teal hedgehog, initially codenamed , led this informal poll, followed by Eggman and the dog character. Ohshima felt that people selected it because it \"transcends race and gender and things like that\". On return to Japan, Ohshima pitched this to the department, and the hedgehog was ultimately selected as the new mascot.\nThe detailed design of Sonic was aimed to be something that could be easily drawn by children and be familiar, as well as exhibit a \"cool\" attitude, representative of the United States at the time. Sonic's blue pigmentation was chosen to match Sega's cobalt blue logo, and his shoes evolved from a design inspired by both Santa Claus and Michael Jackson's boots with the addition of the color red, which was inspired by the contrast of those colors on Jackson's 1987 album \"Bad\"; his personality was based on then-Governor of Arkansas and later President of the United States Bill Clinton's \"Get it done\" attitude. To help sell the idea to Sega's higher-ups, Ohshima pitched the concept framed by a fictional fighter pilot that had earned the name \"Hedgehog\" due to his spiky hair, and had decorated his plane with images of Sonic. When this pilot retired, he married a children's book author, who wrote stories about the Sonic character, the first which became the plot for the first \"Sonic\" game; Ohshima stated that this influence can be seen in the logo of the game, which features Sonic in a pilot's wing emblem.\nThe origins of \"Sonic\" can be traced farther back to a draft created by Naoto \u014cshima in 1989, which years later turned into Sonic. Yuji Naka implemented the idea of a character running inside loops with an algorithm that allowed a sprite to move smoothly on a curve by determining its position with a dot matrix. This concept was subsequently fleshed out by designer Hirokazu Yasuhara.\nSonic was created without the ability to swim because of a mistaken assumption by Yuji Naka that all hedgehogs could not do so. A group of fifteen people started working on the first \"Sonic the Hedgehog\" game, and renamed themselves Sonic Team. The game's soundtrack was composed by Masato Nakamura of the band Dreams Come True. Sega sponsored the group's \"Wonder 3\" tour, painting Sonic on the tour bus, distributing pamphlets advertising the game, and having footage of the game broadcast above stage prior to its release. The original concepts gave Sonic fangs and put him in a band with a human girlfriend named Madonna. However, a team from Sega of America, led by Madeline Schroeder, who calls herself \"Sonic's mother\", \"softened\" the character up for an American audience by removing those elements. This sparked a heated issue with Sonic Team. Naka later admitted that it was probably for the best.\nSonic's appearance varies greatly depending on the medium and the style in which he is drawn. In the video games, Sonic's original design by Ohshima was short and round, with short quills, a round body, and no visible irises. Artwork featuring this design and drawn by Akira Watanabe was displayed on the package artwork for \"Sonic the Hedgehog\". Sonic's proportions would change for the release of \"Sonic the Hedgehog 2\" on the Mega Drive; Sonic's head to height ratio was changed from 1:2 to 1:2.5. For the 1998 release of \"Sonic Adventure\", Sonic was redesigned by Yuji Uekawa as a character with longer legs and a less spherical body, longer and more drooping quills, and green-colored irises. For the 2006 game, Sonic was redesigned to make him look adult-like and taller to appeal to the next generation players. This was also done because Sonic would interact with humans more often and his design was supposed to fit. An alternative \"Werehog\" form was introduced in \"Sonic Unleashed\", placing more emphasis on Sonic's melee skills rather than speed. Although Tetsu Katano acknowledged the large negative fan response to the Werehog, he believes it could return in a future game.\nBob Raffei, CEO of \"Sonic Boom\" developer Big Red Button, stated that \"Sonic Boom\"'s Sonic is \"very different... both in tone and art direction.\" That version has blue-furred arms, more quills, and wears a brown neckerchief around his neck and athletic sports tape on his wrists and shoes.\nVoice portrayal.\nSonic originally had a few voice samples in \"Sonic CD\", with designer Masato Nishimura providing the voice. Sonic's first true voice actor was Takeshi Kusao for the arcade game \"SegaSonic the Hedgehog\", with Junichi Kanemaru continually voicing the role beginning with the release of \"Sonic Adventure\". Kanemaru also voices Sonic in \"Sonic X\", \"Sonic Boom\", and the Japanese dub of the \"Wreck-It Ralph\" films. In \"Sonic Unleashed\", Sonic was voiced by Tomokazu Seki while in Werehog form. Jaleel White voiced the character in the DiC animated series \"Adventures of Sonic the Hedgehog\", \"Sonic SatAM\", and \"Sonic Underground\". Sam Vincent provided his singing voice in the latter DiC cartoon.\nStarting with \"Sonic Adventure\", Sonic was voiced in English by Ryan Drummond. Drummond was replaced by Jason Griffith starting from \"Sonic X\", with Griffith voicing Sonic within the games starting with \"Shadow The Hedgehog\" in 2005. Griffith was replaced by Roger Craig Smith, starting with \"Sonic Free Riders\" and \"Sonic Colors\". Smith announced on his Twitter account on January 29, 2021, that he would no longer voice Sonic, with his departure confirmed by Sega the same day. On May 26, 2021, Smith and Sega confirmed that he was voicing Sonic once again. Ben Schwartz voiced Sonic in the 2020 feature film and its 2022 and 2024 sequels. Canadian actor Deven Mack voices Sonic in the \"Sonic Prime\" animated series.\nAppearances.\nVideo games.\nSonic's first shown appearance in a video game was in the 1990 arcade racing game \"Rad Mobile\", as a decorative ornament hanging from a rearview mirror. This was followed by an unlicensed appearance in \"The Adventures of Quik &amp; Silva\" as a villain. Sonic's first playable appearance was in the platform game \"Sonic the Hedgehog\" for the Sega Mega Drive/Genesis, which also introduced his nemesis Dr. Robotnik. His two-tailed fox friend Tails joined him in the game's 1992 sequel, \"Sonic the Hedgehog 2\". When all the Chaos Emeralds have been collected, Sonic can transform into Super Sonic by collecting 50 rings. Super Sonic is nearly invincible, runs faster, and jumps farther, but loses one ring per second and reverts to normal when his rings are depleted. \"Sonic CD\", released in 1993, introduced Sonic's self-appointed girlfriend Amy Rose and recurring robotic doppelg\u00e4nger Metal Sonic as Sonic traveled through time to ensure a good future for the world. \"Sonic 3\" and its direct sequel \"Sonic &amp; Knuckles\", both released in 1994, saw Sonic and Tails battle Robotnik again, with the additional threat of Knuckles, who is tricked by Robotnik into thinking Sonic is a threat. \"\" (2010\u20132012) continues where the story of \"Sonic 3\" left off, reducing Sonic to the only playable character and releasing in episodic installments. The second episode sees the return of both Tails as Sonic's sidekick and Metal Sonic as a recurring enemy.\nOther two-dimensional platformers starring Sonic include \"Sonic Chaos\" (1993), \"Sonic Triple Trouble\" (1994), \"Sonic Blast\" (1996), \"Sonic the Hedgehog Pocket Adventure\" (1999), \"Sonic Advance\" (2001), \"Sonic Advance 2\" (2002), \"Sonic Advance 3\" (2004), \"Sonic Rush\" (2005), \"Sonic Rush Adventure\" (2007), \"Sonic Colors\" (2010), and \"Sonic Generations\" (2011), all in which were released for handheld consoles.\n\"Sonic Adventure\" (1998) was Sonic Team's return to the character for a major game. It featured Sonic returning from vacation to find the city of Station Square under attack by a new foe named Chaos, under the control of Dr. Robotnik (now known as Dr. Eggman). It was also the first Sonic game to feature a complete voice-over. \"Sonic Adventure 2\" (2001) placed Sonic on-the-run from the military (G.U.N.) after being mistaken for Shadow the Hedgehog. \"Sonic Heroes\" (2003) featured Sonic teaming up with Tails and Knuckles, along with other character teams like Team Rose and Chaotix, against the newly rebuilt Metal Sonic, who had betrayed his master with intentions of world domination. \"Sonic the Hedgehog\" (2006) features Sonic in the city of water, \"Soleanna\", where he must rescue Princess Elise from Dr. Eggman while trying to avoid a new threat to his own life, Silver the Hedgehog. He is the only playable character in \"Sonic Unleashed\" (2008), in which he unwillingly gains a new personality, \"Sonic the Werehog\", the result of Sonic being fused with Dark Gaia's power. He gains strength and flexibility in exchange for his speed, and new friends including a strange creature named Chip who helps him along the way. In \"Sonic Colors\" (2010), Eggman tries to harness the energy of alien beings known as \"Wisps\" for a mind-control beam. \"Sonic Generations\" (2011) features two playable incarnations of Sonic: the younger \"classic\" Sonic, whose gameplay is presented in a style reminiscent of the Mega Drive/Genesis games, and present-day \"modern\" Sonic, who uses the gameplay style present in \"Unleashed\" and \"Colors\", going through stages from past games to save their friends. \"Sonic Generations\" features various theme songs including modern and retro versions that are able to be selected from throughout Sonic's twenty-year history. In April 2013, Sega announced that \"Sonic Lost World\" would launch in October 2013 for the Wii U and Nintendo 3DS.\n\"Sonic and the Secret Rings\" (2007) features Sonic in the storybook world of \"One Thousand and One Nights\". A sequel, \"Sonic and the Black Knight\" (2009), continued the storybook theme, this time taking place within the realm of the Arthurian legend.\nSonic has also been featured in other games of many genres other than 2D and 3D platform games. These include \"Sonic Spinball\", \"Sonic Labyrinth\" (1995), the racing games \"Sonic Drift\" (1994), \"Sonic Drift 2\" (1995), \"Sonic R\" (1996), \"Sonic Riders\" (2006), \"Sonic Rivals\" (2006), \"Sonic Rivals 2\" (2007), ' (2008), and \"Sonic Free Riders\" (2010), the fighting games \"Sonic the Fighters\" (1996) and \"Sonic Battle\" (2003), the mobile game \"Sonic Jump\" (2005), and the role-playing video game ' (2008). Critics and fans have occasionally questioned why Sonic uses vehicles in several of the racing games, given his latent speed; however, it has been explained by Sega and in some official \"Sonic\" media that he does so in order to compete fairly with others in races.\nVideo games such as \"Dr. Robotnik's Mean Bean Machine\" (1993), \"Knuckles' Chaotix\" (1995), \"Tails' Skypatrol\" (1995), \"Tails Adventure\" (1995), and \"Shadow the Hedgehog\" (2005) starred supporting characters of the \"Sonic\" series, although Sonic himself cameos in most of them.\nCameos and crossovers.\nSonic makes cameos in various other games, such as \"Billy Hatcher and the Giant Egg\" as a power-up, in the main hallway in \"Phantasy Star Universe\", and in the 2008 remake of \"Samba de Amigo\". He is also a playable character in \"Christmas NiGHTS into Dreams\". Nintendo, Sega's former rival, references Sonic in \"\", by showing Sonic's shoes next to a trash can that reads \"No Hopers\" on the Cranky's Video Game Heroes screen.\nSonic has appeared in several crossover games, including playable appearances in \"Super Smash Bros. Brawl\" (2008), \"Super Smash Bros. for Nintendo 3DS and Wii U\" (2014), and \"Super Smash Bros. Ultimate\" (2018), \"Lego Dimensions\" (2015), and ' (2021). He appears in the crossover party game series \"Mario &amp; Sonic at the Olympic Games\" and is also a playable character in all three \"Sega Superstars\" games. An official Sonic the Hedgehog skin is available in the platformer battle royale game \"Fall Guys\". Sonic appears as a playable character in \"Puyo Puyo Tetris 2\" via free update. An official Sonic the Hedgehog world with skins are available with DLC in \"Minecraft\". He is also appears as an unlockable playable character in ', \"Super Monkey Ball Banana Mania\" and \"Super Monkey Ball Banana Rumble\".\nAnimation.\nThe first three animated series featuring Sonic were created by the international company DiC. The first of these series, \"Adventures of Sonic the Hedgehog\", premiered in 1993, and depicts Sonic and his friend Tails opposing Doctor Ivo Robotnik and his robots on the planet Mobius. Another animated series premiering the same year, simply titled \"Sonic the Hedgehog\", depicts Sonic and a group of rebels aiming to defeat Robotnik in a futuristic version of Mobius. The third animated series, \"Sonic Underground\", premiered in 1999, and features Sonic as the protagonist alongside his siblings Sonia and Manic.\nIn 1996, a two-part OVA, \"Sonic the Hedgehog,\" was released in Japan. For the American release, the two episodes combined and released as \"Sonic the Hedgehog: The Movie\" by ADV Films. A new series, \"Sonic X,\" began airing in 2003. The 78-episode anime series detailed Sonic's struggle to protect the Chaos Emeralds from Eggman and new villains. Featuring a cross-world and interstellar journey, \"Sonic X\" depicted Sonic and his human friend Chris Thorndyke in quests to save the world. \"Sonic: Night of the Werehog\" is a short film produced by Sega's VE Animation Studio, released to coincide with the release of \"Sonic Unleashed\". In the film, Sonic and Chip enter a haunted house, and must deal with two ghosts trying to scare them in attempt to win the heart of the girl ghost. Sonic also makes multiple cameo appearances in the Disney films, \"Wreck-It Ralph\" (2012) and its sequel \"Ralph Breaks the Internet\" (2018).\nIn October 2013, Sega announced a CGI animated series, \"Sonic Boom\". The show ran for 104 11-minute episodes between 2014 and 2017 on Cartoon Network in the U.S. and the UK, and Canal J and Gulli in France. Sonic makes several appearances in 2014 anime \"Hi-sCoool! SeHa Girls\" and guest-stars in the \"OK K.O.! Let's Be Heroes\" episode \"Let's Meet Sonic\".\nIn February 2021, \"Sonic Prime\" was announced by Netflix with a 2022 release window, though the series' development was initially revealed in a deleted tweet in December 2020. The show is primarily for children ages six to eleven, as well as longtime fans of the franchise. In October 2022, Netflix set its release for December. In the series, after recklessly breaking the Paradox Prism which breaks the entire universe and creates several alternative dimensions and versions of his friends, Sonic desperately seeks to restore them and embarks on a mission to find the shards of the Prism and fix it.\nLive-action films.\nOn June 10, 2014, a film based on the \"Sonic\" series was announced. Simply known as \"Sonic the Hedgehog\", it was produced by Neal Moritz on his Original Film banner alongside Takeshi Ito and Mie Onishi, with Toby Ascher as executive producer. The film was written by Pat Casey and Josh Miller and produced as a joint venture between Paramount Pictures and Marza Animation Planet. The film is a live-action and CGI hybrid. The movie was filmed in 2018, with a release date initially set for November 8, 2019. Upon the release of the film's first trailer in late April 2019, however, Sonic's appearance was heavily criticized, leading to the director, Jeff Fowler, to announce a redesign of him, pushing back the release date to February 14, 2020. The second trailer for the film was released on November 12, 2019, featuring the redesign, which drew in a far more positive response from both fans and critics alike. In the first film, it centers on Sonic, born with supersonic speed powers and abilities, who befriends the sheriff named Tom Wachowski, to stop the villainous Dr. Robotnik who plots to have Sonic's speed powers for world domination. Particular issues with his design included his teeth and legs. According to Paramount marketing president Marc Weinstock, the negative reaction to the original design resulted in a change to how video game adaptations are handled at the company. A sequel, \"Sonic the Hedgehog 2\", was released on April 8, 2022, and it centers on Sonic and Tails on a race to prevent Robotnik and Knuckles from getting the hands on the Master Emerald.\nThe original design of Sonic from the first movie's initial trailer appears in \"\", voiced by Tim Robinson. Named \"Ugly Sonic\", he is portrayed as a washed up actor looking to make a comeback after he was kicked off the film.\nSonic briefly appears as a player's avatar in the 2018 film \"Ready Player One\".\nPrint media.\nSonic's first comic appearance was in a promotional comic printed in \"Disney Adventures\" magazine (and also given away as a free pull-out with a copy of \"Mean Machines\" magazine), which established a backstory for the character involving the origin of his color and abilities and the transformation of kindly scientist Dr. Ovi Kintobor into the evil Dr. Ivo Robotnik. Numerous British publications, including \"Sega handbook\" \"Stay Sonic\" (1993), four novels published by Virgin Books (1993\u20131994) and the comic book \"Sonic the Comic\" (1993\u20132001), published by Fleetway Publications/Egmont Publishing, used this premise as their basis.\nThe American comics published by Archie Comics, \"Sonic the Hedgehog\" (1993\u20132017), \"Sonic X\" (2005\u20132008), and \"Sonic Universe\" (2009\u20132017) are based on the settings established by earlier animated TV series, the ABC \"SatAM\" cartoon, the \"Sonic X\" anime, and an expansion to the series, respectively. The former series is currently the second longest-running licensed comic series in the history of American comic books, second only to Marvel's Conan series (first issue released in 1970).\nIn France two comic books named \"Sonic Adventures\" were published by Sir\u00e8ne in 1994. \"Guinness World Records\" recognized Sonic comic as the longest-running comic based on a game. Archie Comics also released a twelve part crossover with Mega Man beginning in 2013. The Archie comics were later succeeded by a new comic series by IDW Publishing in 2018, which is currently ongoing.\nSonic has also been featured in two different manga. One series was simply called \"Sonic the Hedgehog\", and featured a story about a normal hedgehog boy named Nicky who can change into Sonic. The other series was a compilation of short stories and was separated into two volumes, the first being called \"Dash and Spin\", and the other called \"Super Fast Sonic!!\".\nIn 2025, Sonic was featured in the crossover miniseries \"DC X Sonic the Hedgehog\", in which he and his friends team up with the Justice League to stop Darkseid from harnessing the Chaos Emeralds and using their power to conquer the multiverse. primarily pairs up with the Flash, although they initially and typically debated on whose of them is the fastest.\nCharacteristics.\nAccording to various official materials from Sega, Sonic is described as a character who is \"like the wind\": a drifter who lives as he wants, and makes life a series of events and adventures. Sonic hates oppression and staunchly defends freedom. Although he is mostly quick-witted and easygoing, he has a short temper and is often impatient with slower things. Sonic is a habitual daredevil hedgehog who is honest, loyal to friends, keeps his promises, and dislikes tears. He took the young Tails under his wing like a little brother, and is uninterested in marital proposals from Amy Rose. In times of crisis, he focuses intensely on the challenge, as if his personality had undergone an astonishing change.\nSonic's greatest strength is his running speed, being known in the game's universe as the world's fastest hedgehog. Many of his abilities are variations on the tendency for hedgehogs to roll into tight balls for protection with the addition of spinning his body. Since his introduction in 1991's \"Sonic the Hedgehog\", Sonic's primary offensive maneuver is the basic \"Spin Attack\" (or \"Sonic Spin Attack\"). Later games in the series expanded on this basic attack and two of these enhancements have become mainstays of his: the Spin Dash which was introduced in \"Sonic the Hedgehog 2\" and involves Sonic spinning on the spot before blasting off at full speed, and the Homing Attack, officially introduced in \"Sonic Adventure\", in which Sonic dashes toward a target in midair. Sonic's only weakness is that he cannot swim, sinking like a rock if plunged to a deep body of water. The reason for this is because Yuji Naka had a misunderstanding about hedgehogs not being able to swim. The only exception is that he can swim in the Sonic the Hedgehog Adventure Gamebooks. When the seven Chaos Emeralds are collected and used, Sonic transforms into , a faster, stronger and invulnerable version of himself that can fly. In Super Sonic form, Sonic's irises turn red and his body becomes golden.\nReception and legacy.\nAs Sega's mascot and one of the key reasons for the company's success during the 16-bit era of video game consoles, Sonic is one of the most famous video game characters in the world. In 1993, Sonic became the first video game character to have a balloon in Macy's Thanksgiving Day Parade. In 1996, Sonic was also the first video game character to be seen in a Rose Parade. Sonic was one of the three game characters inducted on the inaugural Walk of Game class in 2005, along with former rivals Mario and Link (both from Nintendo). One of a class of genes involved in fruit fly embryonic development, called hedgehog genes, has been named \"sonic hedgehog\" after him.\nOn the other hand, Sonic's apparent romantic relationship with Princess Elise in the 2006 video game resulted in major criticism. Sonic's characterization and relationship with Eggman in \"Sonic Boom\" earned a positive response by Patrick Lee of \"The A.V. Club\" and Emily Ashby of Common Sense Media.\nSonic has also been used as a symbol for Sega's various sponsorships. Between 1993 and 1997, Sega sponsored the JEF United Ichihara Chiba football team, during which period Sonic appeared in the team's uniform. During the 1993 Formula One championship, Sega sponsored the Williams Grand Prix team, which won the Constructors' Championship that year, as well as the team's lead driver, Alain Prost, winning the Drivers' Championship. Sonic was featured in the cars, helmets, and their rivals McLaren used to paint a squashed hedgehog after winning races over Williams. The 1993 European Grand Prix featured a Sonic balloon and Sonic billboards. In 1992, according to Sega of America marketing director Al Nilsen, Sonic was found to be more recognizable than Mickey Mouse in the six-to eleven-year-old demographic, based on the character's respective Q Scores, although this claim could not be confirmed by Q Score developer Marketing Evaluations, Inc.\nNintendo Power listed Sonic as their sixth favorite hero, stating that while he was originally Mario's nemesis, he seems at home on Nintendo platforms. They added that he has remained as one of gaming's greatest icons. In 2004, the character won a Golden Joystick Award for \"The Sun Ultimate Gaming Hero\". The character's popularity declined in the mid-1990s, and Sonic failed to place in \"Electronic Gaming Monthly\"'s Coolest Mascot of 1996 in either the editors' or readers' picks, being beaten out by not only competitors Mario and Crash Bandicoot, but Sega's own Nights; however, in a 2008 poll of 500 people, Sonic was voted the most popular video game character in the UK with a 24% vote while his old rival Mario came second with 21% of the vote. Later that year, Sonic was ranked as the most iconic video game character in an MSN rankings list. In 2011, \"Empire\" ranked him as the 14th greatest video game character. And he was voted 10th out of the top 50 video game characters of all time in \"Guinness World Records\" 2011 Gamers' Edition. Sonic ranked ninth on GameDaily's Top 10 Smash Bros characters list. GameDaily also listed his \"next-generation stumble\" in their list of video game characters' worst moments, using his relationship with a human female as one of the worst parts of it. In 2024, a poll conducted by BAFTA with around 4,000 respondents named Sonic the Hedgehog as the fourth most iconic video-game character of all time, only behind Lara Croft, Mario and Agent 47.\nKen Balough, Sega's former associate brand manager, said that Sonic's appeal endured because the character is \"a gaming legend, first and foremost\" who originated \"from a series of games that defined a generation in gaming history, and his iconic personality was the epitome of speed in the early '90s, pushing the limits of what gamers knew and expected from high-speed action and platforming games.\"\nA Japanese team developing the Radio &amp; Plasma Wave Investigation (RPWI) instrumentation for the \"Jupiter Icy Moons Explorer\" spacecraft, launched by ESA and Airbus in 2022, was able to gain Sega's approval to use Sonic as the mascot for the device. Specifically, Sonic appears on the logo of the RPWI in his classic design, the rendition being a redraw of how Sonic appears on the Japanese and PAL box art for \"Sonic the Hedgehog\".\nAn Internet meme called \"Sanic\" has been used based on a poorly drawn Sonic; typically, the meme uses one of Sonic's catchphrases but with poor grammar. Sega's official Sonic Twitter account has made numerous references to it, and it appeared in official downloadable content for \"Sonic Forces\" on in-game shirts. The meme also appears as a drawing in the theatrical film.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29059", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=29059", "title": "Saturated hydrocarbon", "text": ""}
{"id": "29061", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=29061", "title": "Suffix morpheme", "text": ""}
{"id": "29062", "revid": "24279709", "url": "https://en.wikipedia.org/wiki?curid=29062", "title": "Supreme Soviet of the Soviet Union", "text": "Highest organ of state authority of the Soviet Union\nThe Supreme Soviet of the Union of Soviet Socialist Republics (SSUSSR) was the highest organ of state authority of the Soviet Union from 1936 to 1991. Based on the principle of unified power, it was the only branch of government in the Soviet state, and headed the unified state apparatus.\nPrior to 1936, the Congress of Soviets was the highest organ of state authority. During 1989\u20131991 a similar, but not identical organ acted as the highest organ of state authority. The Supreme Soviet appointed the Council of Ministers, the Supreme Court, and the Procurator General of the Soviet Union as well as elected the Presidium which served as the Soviet Union's collective head of state under both the 1936 and 1977 Soviet Constitutions.\nBy the Soviet constitutions of 1936 and 1977, the Supreme Soviet was defined as the highest organ of state power in the Soviet Union and was imbued with great lawmaking powers. In practice, however, it was a rubber stamp parliament which did little more than ratify decisions already made by the Soviet Union's executive organs and the Communist Party of the Soviet Union (CPSU) \u2013 always by unanimous consent \u2013 and listen to the General Secretary's speeches. This was in accordance with the Stalinist CPSU's principle of democratic centralism and became the norm for other Communist legislatures.\nHistory.\nHighest legislative body of the Soviet Union (1938\u20131991)\nThe Supreme Soviet of the Soviet Union (, \"Verkhovny Sovet SSSR\") was the highest legislative body in the Soviet Union from 1938 to 1991. It succeeded the Congress of Soviets of the Soviet Union and functioned as the nominal supreme organ of state power according to the 1936 Soviet Constitution.\nStructure.\nThe Supreme Soviet replaced the Congress of Soviets in 1938 and was theoretically the highest authority in the USSR. In practice, however, it usually rubber-stamped decisions made by the Communist Party and its Politburo.\nOriginally, it was composed of two chambers of equal legislative power:\nAlthough the Supreme Soviet was formally the highest organ of state power, real authority rested with the Communist Party until Mikhail Gorbachev's reforms in the late 1980s. Under perestroika, it became a somewhat genuine parliamentary body after the creation of the Congress of People's Deputies of the Soviet Union in 1989, from which the Supreme Soviet was elected as a smaller working legislature.\nThe last session of the Supreme Soviet was held in December 1991, shortly before the formal dissolution of the USSR.\nPowers.\nThe Supreme Soviet had authority to:\nSessions were generally short, held twice a year, with most legislative work done by standing commissions or the Presidium.\nPresidium.\nBetween sessions, its powers were exercised by the Presidium of the Supreme Soviet, which could issue decrees (\"ukazy\") with the force of law, subject to later approval.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nStructure.\nThe Supreme Soviet was composed of two chambers, each with equal legislative powers:\nUnder the 1936 Constitution, the Supreme Soviet was elected for a four-year term, and the Soviet of the Union had one deputy for every 300,000 people. This was changed by the 1977 constitution; the term was extended to five years, and the number of seats in the Soviet of the Union was changed to be the same as the Soviet of Nationalities, regardless of the population size.\nThe Supreme Soviet convened twice a year, usually for less than a week. For the rest of the year, the Presidium performed its ordinary functions. Often, the CPSU bypassed the Supreme Soviet altogether and had major laws enacted as Presidium decrees. Nominally, if such decrees were not ratified by the Supreme Soviet at its next session, they were considered revoked. In practice, however, the principle of democratic centralism rendered the process of ratifying Presidium decrees a mere formality. In some cases, even this formality was not observed.\nAfter 1989 it consisted of 542 deputies (divided into two 271 chambers) decreased from a previous 1,500. The meetings of the highest organ of state authority were also more frequent, from six to eight months a year. In September 1991, after the August Coup, it was reorganised into the Soviet (council) of Republics and the Soviet of The Union, which would jointly amend the Soviet Constitution, admit new states, hear out the President of the Soviet Union on important home and foreign policy issues, approve the union budget, declare war and conclude peace. The Soviet of Republics would consist of 20 deputies from each union republic, plus one deputy to represent each autonomous region of each republic, delegated by the republics' legislatures. Russia was an exception with 52 deputies. The Soviet of the Union consisted of deputies apportioned by the existing quotas.\nIn 1989, its powers were:\nActs by the Supreme Soviet entered into force after signature by the President and publication.\nBetween 1938 and February 1990, more than 50 years, only 80 laws were passed by the Supreme Soviet, less than 1% of total legislative acts.\nSupreme Soviets of the republics.\nBeside the Supreme Soviet of the Soviet Union, each of its constituting union republics and each autonomous republic had a supreme soviet. These supreme soviets also had presidiums, but all consisted of only one chamber. After the dissolution of the Soviet Union, some soviets of the succeeded independent republics simply changed their name to their more historic name or to emphasise their importance as a national parliament, while others changed to double-chamber assemblies.\nSupreme soviets of the union republics.\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Soviet Republics dissolved before the dissolution of the Soviet Union\n&lt;templatestyles src=\"Legend/styles.css\" /&gt;\u00a0\u00a0Parliaments not formally recognized by some countries such as the Western Bloc \nSupreme soviets of the autonomouss republics.\nList of known autonomous republics councils:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29064", "revid": "3736169", "url": "https://en.wikipedia.org/wiki?curid=29064", "title": "Slave (disambiguation)", "text": "A slave is an individual held in forced servitude.\nSlave or slaves may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "29065", "revid": "29463730", "url": "https://en.wikipedia.org/wiki?curid=29065", "title": "Slaves", "text": ""}
{"id": "29067", "revid": "23242057", "url": "https://en.wikipedia.org/wiki?curid=29067", "title": "Satyr", "text": "Male nature spirit with horse or goat features found in Greek mythology\nIn Greek mythology, a satyr (, ), also known as a silenus or silenos ( ), and sileni (plural), is a male nature spirit with ears and a tail resembling those of a horse, as well as a permanent, exaggerated erection. Early artistic representations sometimes include horse-like legs, but, by the sixth century BC, they were more often represented with human legs. Comically hideous, they have mane-like hair, bestial faces, and snub noses and they always are shown naked. Satyrs were characterized by their ribaldry and were known as lovers of wine, music, dancing, and women. They were companions of the god Dionysus and were believed to inhabit remote locales, such as woodlands, mountains, and pastures. They often attempted to seduce or rape nymphs and mortal women alike, usually with little success. They are sometimes shown masturbating or engaging in bestiality.\nIn classical Athens, satyrs made up the chorus in a genre of play known as a \"satyr play\", which was a parody of tragedy and known for its bawdy and obscene humor. The only complete surviving play of this genre is \"Cyclops\" by Euripides, although a significant portion of Sophocles's \"Ichneutae\" has also survived. In mythology, the satyr Marsyas is said to have challenged the god Apollo to a musical contest and been flayed alive for his hubris. Although superficially ridiculous, satyrs were also thought to possess useful knowledge, if they could be coaxed into revealing it. The satyr Silenus was the tutor of the young Dionysus, and a story from Ionia told of a \"silenos\" who gave sound advice when captured.\nOver the course of Greek history, satyrs gradually became portrayed as more human and less bestial. They also began to acquire goat-like characteristics in some depictions as a result of conflation with the Pans, plural forms of the god Pan with the legs and horns of goats. The Romans identified satyrs with their native nature spirits, fauns. Eventually the distinction between the two was lost entirely. Since the Renaissance, satyrs have been most often represented with the legs and horns of goats. Representations of satyrs cavorting with nymphs have been common in western art, with many famous artists creating works on the theme. Since the beginning of the twentieth century, satyrs have generally lost much of their characteristic obscenity, becoming more tame and domestic figures. They commonly appear in works of fantasy and children's literature, in which they are most often referred to as \"fauns\".\nTerminology.\nThe etymology of the term \"satyr\" () is unclear, and several different etymologies have been proposed for it, including a possible Pre-Greek origin. Some scholars have linked the second part of name to the root of the Greek word , meaning 'wild animal'. This proposal may be supported by the fact that at one point Euripides refers to satyrs as . Another proposed etymology derives the name from an ancient Peloponnesian word meaning 'the full ones', alluding to their permanent state of sexual arousal. Eric Partridge suggested that the name may be related to the root , meaning 'to sow', which has also been proposed as the root of the name of the Roman god Saturn. Satyrs are usually indistinguishable from , whose iconography is virtually identical. According to \"Brewer's Dictionary of Phrase and Fable\", the name 'satyr' is sometimes derogatorily applied to a \"brutish or lustful man\". The term satyriasis refers to a medical condition in males characterized by excessive sexual desire. It is the male equivalent of nymphomania.\nOrigin hypotheses.\nIndo-European.\nAccording to classicist Martin Litchfield West, satyrs and silenoi in Greek mythology are similar to a number of other entities appearing in other Indo-European mythologies, indicating that they probably go back, in some vague form, to Proto-Indo-European mythology. Like satyrs, these other Indo-European nature spirits are often human-animal hybrids, frequently bearing specifically equine or asinine features. Human-animal hybrids known as Ki\u1e43puru\u1e63as or Ki\u1e43naras are mentioned in the , an Indian epic poem written in Sanskrit. According to Augustine of Hippo (354\u2013430 AD) and others, the ancient Celts believed in \"dusii\", which were hairy demons believed to occasionally take human form and seduce mortal women. Later figures in Celtic folklore, including the Irish , the Scottish and , and the Manx , are part human and part goat. The lexicographer Hesychius of Alexandria (fifth or sixth century AD) records that the Illyrians believed in satyr-like creatures called \"Deuadai\". The Slavic \"leshy\" also bears similarities to satyrs, since he is described as being covered in hair and having \"goat's horns, ears, feet, and long clawlike fingernails.\"\nLike satyrs, these similar creatures in other Indo-European mythologies are often also tricksters, mischief-makers, and dancers. The \"leshy\" was believed to trick travelers into losing their way. The Armenian Pay(n) were a group of male spirits said to dance in the woods. In Germanic mythology, elves were also said to dance in woodland clearings and leave behind fairy rings. They were also thought to play pranks, steal horses, tie knots in people's hair, and steal children and replace them with changelings. West notes that satyrs, elves, and other nature spirits of this variety are a \"motley crew\" and that it is difficult to reconstruct a prototype behind them. Nonetheless, he concludes that \"we can recognize recurrent traits\" and that they can probably be traced back to the Proto-Indo-Europeans in some form.\nNear Eastern.\nOn the other hand, a number of commentators have noted that satyrs are also similar to beings in the beliefs of ancient Near Eastern cultures. Various demons of the desert are mentioned in ancient Near Eastern texts, although the iconography of these beings is poorly-attested. Beings possibly similar to satyrs called are mentioned several times in the Hebrew Bible. was the standard Hebrew word for 'he-goat', but it could also apparently sometimes refer to demons in the forms of goats. They were evidently subjects of veneration, because Leviticus 17:7 forbids Israelites from making sacrificial offerings to them and 2 Chronicles 11:15 mentions that a special cult was established for the of Jeroboam I. Like satyrs, they were associated with desolate places and with some variety of dancing. Isaiah 13:21 predicts, in Karen L. Edwards's translation: \"But \"wild animals\" [] will lie down there, and its houses will be full of \"howling creatures\" []; there ostriches will live, and there \"goat-demons\" [] will dance.\" Similarly, Isaiah 34:14 declares: \"\"Wildcats\" [] shall meet with \"hyenas\" [], \"goat-demons\" [] shall call to each other; there too \"Lilith\" [] shall repose and find a place to rest.\" were understood by at least some ancient commentators to be goat-like demons of the wilderness. In the Latin Vulgate translation of the Old Testament, is translated as , which also means 'hairy'. Jerome, the translator of the Vulgate, equated these figures with satyrs. Both satyrs and have also been compared to the jinn of Pre-Islamic Arabia, who were envisioned as hairy demons in the forms of animals who could sometimes change into other forms, including human-like ones.\nIn archaic and classical Greece.\nPhysical appearance.\nIn archaic and classical Greek art, satyrs are shown with the ears and tails of horses. They walk upright on two legs, like human beings. They are usually shown with bestial faces, snub noses, and manelike hair. They are often bearded and balding. Like other Greek nature spirits, satyrs are always depicted nude. Sometimes they also have the legs of horses, but, in ancient art, including both vase paintings and in sculptures, satyrs are most often represented with human legs and feet.\nSatyrs' genitals are always depicted as either erect or at least extremely large. Their erect phalli represent their association with wine and women, which were the two major aspects of their god Dionysus's domain. In some cases, satyrs are portrayed as very human-like, lacking manes or tails. As time progressed, this became the general trend, with satyrs losing aspects of their original bestial appearance over the course of Greek history and gradually becoming more and more human. In the most common depictions, satyrs are shown drinking wine, dancing, playing flutes, chasing nymphs, or consorting with Dionysus. They are also frequently shown masturbating or copulating with animals. In scenes from ceramic paintings depicting satyrs engaging in orgies, satyrs standing by and watching are often shown masturbating.\nBehavior.\nOne of the earliest written sources for satyrs is the \"Catalogue of Women\", which is attributed to the Boeotian poet Hesiod. Here satyrs are born alongside the nymphs and Kouretes and are described as \"good-for-nothing, prankster Satyrs\". Satyrs were widely seen as mischief-makers who routinely played tricks on people and interfered with their personal property. They had insatiable sexual appetites and often sought to seduce or ravish both nymphs and mortal women alike, though these attempts were not always successful. Satyrs almost always appear in artwork alongside female companions of some variety. These female companions may be clothed or nude, but the satyrs always treat them as mere sexual objects. A single elderly satyr named Silenus was believed to have been the tutor of Dionysus on Mount Nysa. After Dionysus grew to maturity, Silenus became one of his most devout followers, remaining perpetually drunk.\nThis image was reflected in the classical Athenian satyr play. Satyr plays were a genre of plays defined by the fact that their choruses were invariably made up of satyrs. These satyrs are always led by Silenus, who is their \"father\". According to Carl A. Shaw, the chorus of satyrs in a satyr play were \"always trying to get a laugh with their animalistic, playfully rowdy, and, above all, sexual behavior.\" The satyrs play an important role in driving the plot of the production, without any of them actually being the lead role, which was always reserved for a god or tragic hero. Many satyr plays are named for the activity in which the chorus of satyrs engage during the production, such as , , and . Like tragedies, but unlike comedies, satyr plays were set in the distant past and dealt with mythological subjects. The third or second-century BC philosopher Demetrius of Phalerum famously characterized the satiric genre in his treatise \"De Elocutione\" as the middle ground between tragedy and comedy: a \"playful tragedy\" ().\nThe only complete extant satyr play is Euripides's \"Cyclops\", which is a burlesque of a scene from the eighth-century BC epic poem, the \"Odyssey\", in which Odysseus is captured by the Cyclops Polyphemus in a cave. In the play, Polyphemus has captured a tribe of satyrs led by Silenus, who is described as their \"Father\", and forced them to work for him as his slaves. After Polyphemus captures Odysseus, Silenus attempts to play Odysseus and Polyphemus off each other for his own benefit, primarily by tricking them into giving him wine. As in the original scene, Odysseus manages to blind Polyphemus and escape. Approximately 450 lines, most of which are fragmentary, have survived of Sophocles's satyr play \"Ichneutae\" (\"Tracking Satyrs\"). In the surviving portion of the play, the chorus of satyrs are described as \"lying on the ground like hedgehogs in a bush, or like a monkey bending over to fart at someone.\" The character Cyllene scolds them: \"All you [satyrs] do you do for the sake of fun!... Cease to expand your smooth phallus with delight. You should not make silly jokes and chatter, so that the gods will make you shed tears to make me laugh.\"\nIn Dionysius I of Syracuse's fragmentary satyr play \"Limos\" (\"Starvation\"), Silenus attempts to give the hero Heracles an enema. A number of vase paintings depict scenes from satyr plays, including the Pronomos Vase, which depicts the entire cast of a victorious satyr play, dressed in costume, wearing shaggy leggings, erect phalli, and horse tails. The genre's reputation for crude humor is alluded to in other texts as well. In Aristophanes's comedy \"Thesmophoriazusae\", the tragic poet Agathon declares that a dramatist must be able to adopt the \"personae\" of his characters in order to successfully portray them on stage. In lines 157\u2013158, Euripides's unnamed relative retorts: \"Well, let me know when you're writing satyr plays; I'll get behind you with my hard-on and show you how.\" This is the only extant reference to the genre of satyr plays from a work of ancient Greek comedy and, according to Shaw, it effectively characterizes satyr plays as \"a genre of 'hard-ons.'\"\nIn spite of their bawdy behavior, however, satyrs were still revered as semi-divine beings and companions of the god Dionysus. They were thought to possess their own kind of wisdom that was useful to humans if they could be convinced to share it. In Plato's \"Symposium\", Alcibiades praises Socrates by comparing him to the famous satyr Marsyas. He resembles him physically, since he is balding and has a snub-nose, but Alcibiades contends that he resembles him mentally as well, because he is \"insulting and abusive\", in possession of irresistible charm, \"erotically inclined to beautiful people\", and \"acts as if he knows nothing\". Alcibiades concludes that Socrates's role as a philosopher is similar to that of the paternal satyr Silenus, because, at first, his questions seem ridiculous and laughable, but, upon closer inspection, they are revealed to be filled with much wisdom. One story, mentioned by Herodotus in his \"Histories\" and in a fragment by Aristotle, recounts that King Midas once captured a silenus, who provided him with wise philosophical advice.\nMythology.\nAccording to classicist William Hansen, although satyrs were popular in classical art, they rarely appear in surviving mythological accounts. Different classical sources present conflicting accounts of satyrs' origins. According to a fragment from the Hesiodic \"Catalogue of Women\", satyrs are sons of the five granddaughters of Phoroneus and therefore siblings of the Oreads and the Kouretes. The satyr Marsyas, however, is described by mythographers as the son of either Olympos or Oiagros. Hansen observes that \"there may be more than one way to produce a satyr, as there is to produce a Cyclops or a centaur.\" The classical Greeks recognized that satyrs obviously could not self-reproduce since there were no female satyrs, but they seem to have been unsure whether satyrs were mortal or immortal.\nRather than appearing \"en masse\" as in satyr-plays, when satyrs appear in myths it is usually in the form of a single, famous character. The comic playwright Melanippides of Melos (c. 480\u2013430 BC) tells the story in his lost comedy \"Marsyas\" of how, after inventing the \"aulos\", the goddess Athena looked in the mirror while she was playing it. She saw how blowing into it puffed up her cheeks and made her look silly, so she threw the aulos away and cursed it so that whoever picked it up would meet an awful death. The aulos was picked up by the satyr Marsyas, who challenged Apollo to a musical contest. They both agreed beforehand that whoever won would be allowed to do whatever he wanted to the loser. Marsyas played the aulos and Apollo played the lyre. Apollo turned his lyre upside-down and played it. He asked Marsyas to do the same with his instrument. Since he could not, Apollo was deemed to victor. Apollo hung Marsyas from a pine tree and flayed him alive to punish him for his hubris in daring to challenge one of the gods. Later, this story became accepted as canonical and the Athenian sculptor Myron created a group of bronze sculptures based on it, which was installed before the western front of the Parthenon in around 440 BC. Surviving retellings of the legend are found in the \"Library\" of Pseudo-Apollodorus, Pausanias's \"Guide to Greece\", and the \"Fabulae\" of Pseudo-Hyginus.\nIn a myth referenced in multiple classical texts, including the \"Bibliotheke\" of Pseudo-Apollodorus and the \"Fabulae\" of Pseudo-Hyginus, a satyr from Argos once attempted to rape the nymph Amymone, but she called to the god Poseidon for help and he launched his trident at the satyr, knocking him to the ground. This myth may have originated from Aeschylus's lost satyr play \"Amymone\". Scenes of one or more satyrs chasing Amymone became a common trope in Greek vase paintings starting in the late fifth century BC. One of the earliest depictions of the scene comes from a bell krater in the style of the Peleus Painter from Syracuse (PEM 10, pl. 155) and another from a bell krater in the style of the Dinos Painter from Vienna (DM 7).\nAccording to one account, Satyrus was one of the many sons of Dionysus and the Bithynian nymph Nicaea, born after Dionysus tricked Nicaea into getting drunk and raped her as she lay unconscious.\nList of Satyrs.\nMany names of the satyrs that appear in Nonnos' Dionysiaca are heavily assumed to have been coined by the author, and are nothing more than plot devices with no mythological significance. Four names listed in the epic, when translated, are merely adjectives associated to the character (\"Pastoral\", \"Cult-association\", \"Tall-horn\", and \"Mountain-dweller\").\nThe names of the satyrs according to various vase paintings were: Babacchos, Briacchos, Dithyrambos, Demon, Dromis, Echon, Hedyoinos (\"Sweet Wine\"), Hybris (\"Insolence\"), Hedymeles, (\"Sweet Song\"), Komos (\"Revelry\"), Kissos (\"Ivy\"), Molkos, Oinos, Oreimachos, Simos (\"Snub-nose\"), Terpon and Tyrbas (\"Rout\").\nLater antiquity.\nHellenistic Era.\nThe iconography of satyrs was gradually conflated with that of the Pans, plural forms of the god Pan, who were regularly depicted with the legs and horns of a goat. By the Hellenistic Period (323\u201331 BC), satyrs were beginning to sometimes be shown with goat-like features. Meanwhile, both satyrs and Pans also continued to be shown as more human and less bestial. Scenes of satyrs and centaurs were very popular during the Hellenistic Period. They often appear dancing or playing the aulos. The maenads that often accompany satyrs in Archaic and Classical representations are often replaced in Hellenistic portrayals with wood nymphs.\nArtists also began to widely represent scenes of nymphs repelling the unwanted advances of amorous satyrs. Scenes of this variety were used to express the dark, beastly side of human sexuality at a remove by attributing that sexuality to satyrs, who were part human and part animal. In this way, satyrs became vehicles of a metaphor for a phenomenon extending far beyond the original narrative purposes in which they had served during earlier periods of Greek history. Some variants on this theme represent a satyr being rebuffed by a hermaphrodite, who, from the satyr's perspective, appears to be a beautiful, young girl. These sculptures may have been intended as kind of sophisticated erotic joke.\nThe Athenian sculptor Praxiteles's statue \"Pouring Satyr\" represented the eponymous satyr as very human-like. The satyr was shown as very young, in line with Praxiteles's frequent agenda of representing deities and other figures as adolescents. This tendency is also attested in the descriptions of his sculptures of Dionysus and the Archer Eros written in the third or fourth century AD by the art critic Callistratus. The original statue is widely assumed to have depicted the satyr in the act of pouring an \"oinochoe\" over his head into a cup, probably a \"kantharos\". Antonio Corso describes the satyr in this sculpture as a \"gentle youth\" and \"a precious and gentle being\" with \"soft and velvety\" skin. The only hints at his \"feral nature\" were his ears, which were slightly pointed, and his small tail.\nThe shape of the sculpture was an S-shape, shown in three-quarter view. The satyr had short, boyish locks, derived from those of earlier Greek athletic sculpture. Although the original statue has been lost, a representation of the pouring satyr appears in a late classical relief sculpture from Athens and twenty-nine alleged \"copies\" of the statue from the time of the Roman Empire have also survived. Olga Palagia and J. J. Pollitt argue that, although the \"Pouring Satyr\" is widely accepted as a genuine work of Praxiteles, it may not have been a single work at all and the supposed \"copies\" of it may merely be Roman sculptures repeating the traditional Greek motif of pouring wine at \"symposia\".\nAncient Rome.\nThe Romans identified satyrs with their own nature spirits, fauns. Although generally similar to satyrs, fauns differed in that they were usually seen as \"shy, woodland creatures\" rather than the drunk and boisterous satyrs of the classical Greeks. Also, fauns generally lacked the association Greek satyrs had with secret wisdom. Unlike classical Greek satyrs, fauns were unambiguously goat-like; they had the upper bodies of men, but the legs, hooves, tail, and horns of goats. The first-century BC Roman poet Lucretius mentions in his lengthy poem \"De rerum natura\" that people of his time believed in \"goat-legged\" (\"capripedes\") satyrs, along with nymphs who lived in the mountains and fauns who played rustic music on stringed instruments and pipes.\nIn Roman-era depictions, satyrs and fauns are both often associated with music and depicted playing the Pan pipes or \"syrinx\". The poet Virgil, who flourished during the early years of the Roman Empire, recounts a story in his sixth \"Eclogue\" about two boys who tied up the satyr Silenus while he was in a drunken stupor and forced him to sing them a song about the beginning of the universe. The first-century AD Roman poet Ovid makes Jupiter, the king of the gods, express worry that the viciousness of humans will leave fauns, nymphs, and satyrs without a place to live, so he gives them a home in the forests, woodlands, and mountains, where they will be safe. Ovid also retells the story of Marsyas's hubris. He describes a musical contest between Marsyas, playing the aulos, and the god Apollo, playing the lyre. Marsyas loses and Apollo flays him as punishment.\nThe Roman naturalist and encyclopedist Pliny the Elder conflated satyrs with gibbons, which he describes using the word \"satyrus\", a Latinized form of the Greek \"satyros\". He characterizes them as \"a savage and wild people; distinct voice and speech they have none, but in steed thereof, they keep a horrible gnashing and hideous noise: rough they are and hairie all over their bodies, eies they have red like the houlets [owls] and toothed they be like dogs.\"\nThe second-century Greek Middle Platonist philosopher Plutarch records a legendary incident in his \"Life of Sulla\", in which the soldiers of the Roman general Sulla are reported to have captured a satyr sleeping during a military campaign in Greece in 89 BC. Sulla's men brought the satyr to him and he attempted to interrogate it, but it spoke only in an unintelligible sound: a cross between the neighing of a horse and the bleating of a goat. The second-century Greek travel writer Pausanias reports having seen the tombs of deceased silenoi in Judaea and at Pergamon. Based on these sites, Pausanias concludes that silenoi must be mortal.\nThe third-century Greek biographer Philostratus records a legend in his \"Life of Apollonius of Tyana\" of how the ghost of an Aethiopian satyr was deeply enamored with the women from the local village and had killed two of them. Then, the philosopher Apollonius of Tyana set a trap for it with wine, knowing that, after drinking it, the ghost-satyr would fall asleep forever. The wine diminished from the container before the onlookers' eyes, but the ghost-satyr himself remained invisible. Once all the wine had vanished, the ghost-satyr fell asleep and never bothered the villagers again. Amira El-Zein notes similarities between this story and later Arabic accounts of jinn. The treatise \"Saturnalia\" by the fifth-century AD Roman poet Macrobius connects both the word \"satyr\" and the name \"Saturn\" to the Greek word for \"penis\". Macrobius explains that this is on account of satyrs' sexual lewdness. Macrobius also equates Dionysus and Apollo as the same deity and states that a festival in honor of Bacchus is held every year atop Mount Parnassus, at which many satyrs are often seen.\nAfter antiquity.\nMiddle Ages.\nStarting in late antiquity, Christian writers began to portray satyrs and fauns as dark, evil, and demonic. Jerome (c. 347 \u2013 420 AD) described them as symbols of Satan on account of their lasciviousness. Despite this, however, satyrs were sometimes clearly distinguished from demons and sometimes even portrayed as noble. Because Christians believed that the distinction between humans and animals was spiritual rather than physical, it was thought that even a satyr could attain salvation. Isidore of Seville (c. 560 \u2013 636) records an anecdote later recounted in the \"Golden Legend\", that Anthony the Great encountered a satyr in the desert who asked to pray with him to their common God. During the Early Middle Ages, features and characteristics of satyrs and the god Pan, who resembled a satyr, became absorbed into traditional Christian iconography of Satan.\nMedieval storytellers in Western Europe also frequently conflated satyrs with wild men. Both satyrs and wild men were conceived as part human and part animal and both were believed to possess unrestrained sexual appetites. Stories of wild men during the Middle Ages often had an erotic tone and were primarily told orally by peasants, since the clergy officially disapproved of them. In this form, satyrs are sometimes described and represented in medieval bestiaries, where a satyr is often shown dressed in an animal skin, carrying a club and a serpent. In the \"Aberdeen Bestiary\", the \"Ashmole Bestiary\", and MS Harley 3244, a satyr is shown as a nude man holding a wand resembling a jester's club and leaning back, crossing his legs. Satyrs are sometimes juxtaposed with apes, which are characterized as \"physically disgusting and akin to the Devil\". In other cases, satyrs are usually shown nude, with enlarged phalli to emphasize their sexual nature. In the Second-Family Bestiary, the name \"satyr\" is used as the name of a species of ape, which is described as having a \"very agreeable face, restless, however, in its twitching movements.\"\nRenaissance.\nDuring the Renaissance, satyrs and fauns began to reappear in works of European art. During the Renaissance, no distinction was made between satyrs and fauns and both were usually given human and goat-like features in whatever proportion the artist deemed appropriate. A goat-legged satyr appears at the base of Michelangelo's statue \"Bacchus\" (1497). Renaissance satyrs still sometimes appear in scenes of drunken revelry like those from antiquity, but they also sometimes appear in family scenes, alongside female and infant or child satyrs. This trend towards more familial, domestic satyrs may have resulted from conflation with wild men, who, especially in Renaissance depictions from Germany, were often portrayed as living relatively peaceful lives with their families in the wilderness. The most famous representation of a domestic satyr is Albrecht D\u00fcrer's 1505 engraving \"The Satyr's Family\", which has been widely reproduced and imitated. This popular portrayal of satyrs and wild men may have also helped give rise to the later European concept of the noble savage.\nSatyrs occupied a paradoxical, liminal space in Renaissance art, not only because they were part human and part beast, but also because they were both antique and natural. They were of classical origin, but had an iconographical canon of their own very different from the standard representations of gods and heroes. They could be used to embody what Stephen J. Campbell calls a \"monstrous double\" of the category in which human beings often placed themselves. It is in this aspect that satyrs appear in Jacopo de' Barbari's c. 1495 series of prints depicting satyrs and naked men in combat and in Piero di Cosimo's \"Stories of Primitive Man\", inspired by Lucretius. Satyrs became seen as \"pre-human\", embodying all the traits of savagery and barbarism associated with animals, but in human-like bodies. Satyrs also became used to question early modern humanism in ways which some scholars have seen as similar to present-day posthumanism, as in Titian's \"Flaying of Marsyas\" (c. 1570\u20131576). \"The Flaying of Marysas\" depicts the scene from Ovid's \"Metamorphoses\" in which the satyr Marysas is flayed alive. According to Campbell, the people performing the flaying are shown calmly absorbed in their task, while Marsyas himself even displays \"an unlikely patience\". The painting reflects a broad continuum between the divine and the bestial.\nEarly modern period.\nIn the 1560 Geneva Bible, the word in both of the instances in Isaiah is translated into English as 'satyr'. The 1611 King James Version follows this translation and likewise renders as 'satyr'. Edwards states that the King James Version's translation of this phrase and others like it was intended to reduce the strangeness and unfamiliarity of the creatures described in the original Hebrew text by rendering them as names of familiar entities. Edmund Spenser refers to a group of woodland creatures as Satyrs in his epic poem \"The Faerie Queene\". In Canto VI, Una is wandering through the forest when she stumbles upon a \"troupe of Fauns and Satyrs far away Within the wood were dancing in a round.\" Although Satyrs are often negatively characterized in Greek and Roman mythology, the Satyrs in this poem are docile, helpful creatures. This is evident by the way they help protect Una from Sansloy. Sylvanus, the leader, and the rest of the Satyrs become enamored by Una's beauty and begin to worship her as if she is a deity. However, the Satyrs prove to be simple-minded creatures because they begin to worship the donkey she was riding.\nIn the seventeenth century, satyrs became identified with great apes. In 1699, the English anatomist Edward Tyson (1651\u20131708) published an account of his dissection of a creature which scholars have now identified as chimpanzee. In this account, Tyson argued that stories of satyrs, wild men, and other hybrid mythological creatures had all originated from the misidentification of apes or monkeys. The French materialist philosopher Julien Offray de La Mettrie (1709\u20131751) included a section titled \"On savage men, called Satyrs\" in his \"Oeuvres philosophiques\", in which he describes great apes, identifying them with both satyrs and wild men. Many early accounts of the orangutan describe the males as being sexually aggressive towards human women and towards females of its own species, much like classical Greek satyrs. The first scientific name given to this ape was \"Simia satyrus\".\nRelationships between satyrs and nymphs of this period are often portrayed as consensual. This trend is exemplified by the 1623 painting \"Satyr and Nymph\" by Gerard van Honthorst, which depicts a satisfied satyr and nymph lasciviously fondling each other after engaging in obviously consensual sex. Both are smiling and the nymph is showing her teeth, a sign commonly used by painters of the era to signify that the woman in question is of loose morals. The satyr's tongue is visible as the nymph playfully tugs on his goat beard and he strokes her chin. Even during this period, however, depictions of satyrs uncovering sleeping nymphs are still common, indicating that their traditional associations with rape and sexual violence had not been forgotten.\nNineteenth century.\nDuring the nineteenth century, satyrs and nymphs came to often function as a means of representing sexuality without offending Victorian moral sensibilities. In the novel \"The Marble Faun\" (1860) by the American author Nathaniel Hawthorne, the Italian count Donatello is described as bearing a remarkable resemblance to one of Praxiteles's marble satyr statues. Like the satyrs of Greek legend, Donatello has a carefree nature. His association with satyrs is further cemented by his intense sexual attraction to the American woman Miriam.\nSatyrs and nymphs provided a classical pretext which allowed sexual depictions of them to be seen as objects of high art rather than mere pornography. The French emperor Napoleon III awarded the Academic painter Alexandre Cabanel the Legion of Honour, partly on account of his painting \"Nymph Abducted by a Faun\". In 1873, another French Academicist William-Adolphe Bouguereau painted \"Nymphs and Satyr\", which depicts four nude nymphs dancing around \"an unusually submissive satyr\", gently coaxing him into the water of a nearby stream. This painting was bought that same year by an American named John Wolfe, who displayed it publicly in a prominent location in the bar at the Hoffman House, a hotel he owned on Madison Square and Broadway. Despite its risqu\u00e9 subject, many women came to the bar to view the painting. The painting was soon mass reproduced on ceramic tiles, porcelain plates, and other luxury items in the United States.\nIn 1876, St\u00e9phane Mallarm\u00e9 wrote \"The Afternoon of a Faun\", a first-person narrative poem about a faun who attempts to kiss two beautiful nymphs while they are sleeping together. He accidentally wakes them up. Startled, they transform into white water birds and fly away, leaving the faun to play his pan pipes alone. Claude Debussy composed a symphonic poem \"Pr\u00e9lude \u00e0 l'apr\u00e8s-midi d'un faune\" (\"Prelude to the Afternoon of a Faun\"), which was first performed in 1894.The late nineteenth-century German Existentialist philosopher Friedrich Nietzsche was either unaware of or chose to ignore the fact that, in all the earliest representations, satyrs are depicted as horse-like. He accordingly defined a satyr as a \"bearded\" creature \"who derived his name and attributes from the goat.\" Nietzsche excluded the horse-like satyrs of Greek tradition from his consideration entirely and argued that tragedy had originated from a chorus of men dressed up as satyrs or goats (\"tragoi\"). Thus, Nietzsche held that tragedy had begun as a Dionysian activity. Nietzsche's rejection of the early evidence for horse-like satyrs was a mistake his critics severely excoriated him for. Nonetheless, he was the first modern scholar to recognize the full importance of satyrs in Greek culture and tradition, as Dionysian symbols of humanity's close ties to the animal kingdom. Like the Greeks, Nietzsche envisioned satyrs as essentially humans stripped down to their most basic and bestial instincts.\nTwentieth and twenty-first centuries.\nIn 1908, the French painter Henri Matisse produced his own \"Nymph and Satyr\" painting, in which the animal nature of the satyr is drastically minimized. The satyr is given human legs, but is exceptionally hairy. The seduction element is removed altogether; the satyr simply extends his arms towards the nymph, who lies on the ground, defeated. Penny Florence writes that the \"generic scene displays little sensuality\" and that the main factor distinguishing it is its tone, because \"[i]t does not seem convincing as a rape, despite the nymph's reluctance.\" In 1912, Vaslav Nijinsky choreographed Debussy's symphonic poem \"Prelude to the Afternoon of a Faun\" as a ballet and danced in it as the lead role of the faun. The choreography of the ballet and Nijinsky's performance were both highly erotic and sexually charged, causing widespread scandal among upper-class Parisians. In the 1980 biographical film \"Nijinsky\", directed by Herbert Ross, Nijinsky, who is played by George de la Pe\u00f1a, is portrayed as actually masturbating on stage in front of the entire live audience during the climax of the dance.\nThe 1917 Italian silent film \"Il Fauno\", directed by Febo Mari, is about a statue of a faun who comes to life and falls in love with a female model. Fauns appear in the animated dramatization of Ludwig van Beethoven's Symphony No. 6 (1808) in the 1940 Disney animated film \"Fantasia\". Their goat-legs are portrayed as brightly colored, but their hooves are black. They play the Pan pipes and, like traditional satyrs and fauns, are portrayed as mischievous. One young faun plays hide-and-seek with a unicorn and imitates a statue of a faun atop a pedestal. Though the fauns are not portrayed as overtly sexual, they do assist the Cupids in pairing the centaurs into couples. A drunken Bacchus appears in the same scene.\nA faun named Mr. Tumnus appears in the classic juvenile fantasy novel \"The Lion, the Witch and the Wardrobe\" (1950) by C. S. Lewis. Mr. Tumnus has goat legs and horns, but also a tail long enough for him to carry it draped over his arm to prevent it from dragging in the snow. He is a domesticated figure who lacks the bawdiness and hypersexuality that characterized classical satyrs and fauns. Instead, Mr. Tumnus wears a scarf and carries an umbrella and lives in a cozy cave with a bookshelf with works such as \"The Life and Letters of Silenus\", \"Nymphs and their Ways\", and \"Is Man a Myth?\".\nThe satyr has appeared in all five editions of the \"Dungeons &amp; Dragons\" role-playing game, having been introduced in 1976 in the earliest edition, in Supplement IV: \"Gods, Demi-Gods &amp; Heroes\" (1976), then in the first edition of the Monster Manual (1977), where it is described as a sylvan woodland inhabitant primarily interested in sport such as frolicking, piping, and chasing wood nymphs. The life history of satyrs was further detailed in \"Dragon\" No. 155 (March 1990), in \"The Ecology of the Satyr\". The satyr was later detailed as a playable character race in \"The Complete Book of Humanoids\" (1993), and is later presented as a playable character race again in ' (1995). The satyr appears in the Monster Manual for the 3.0 edition. \"Savage Species\" (2003) presented the satyr as both a race and a playable class. The satyr appears in the revised Monster Manual for version 3.5 and also appears in the Monster Manual for the 4th edition, and as a playable character race in the \"Heroes of the Feywild\" sourcebook (2011).\nMatthew Barney's art video \"Drawing Restraint 7\" (1993) includes two satyrs wrestling in the backseat of a moving limousine. A satyr named Grover Underwood appears in the young adult fantasy novel \"The Lightning Thief\" (2005) by American author Rick Riordan, as well as in subsequent novels in the series \"Percy Jackson &amp; the Olympians\". Though consistently referred to as a \"satyr\", Grover is described as having goat legs, pointed ears, and horns. Grover is not portrayed with the sexually obscene traits that characterized classical Greek satyrs. Instead, he is the loyal protector to the main character Percy Jackson, who is the son of a mortal woman and the god Poseidon.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "29068", "revid": "10289486", "url": "https://en.wikipedia.org/wiki?curid=29068", "title": "Sturgeon-class submarine", "text": "Class of fast attack nuclear submarine by US Navy\nThe \"Sturgeon\" class (known colloquially in naval circles as the 637 class) was a class of thirty-seven nuclear-powered fast attack submarines (SSN) in service with the United States Navy from the 1960s until 2004. They were the \"workhorses\" of the Navy's attack submarine fleet throughout much of the Cold War. The boats were phased out in the 1990s and early 21st century, as their successors, the , followed by the and -class boats, entered service.\nDesign.\nThe \"Sturgeon\"s were essentially lengthened and improved variants of the \"Thresher/Permit\" class that directly preceded them. The five-compartment arrangement of the \"Permit\"s was retained, including the bow compartment, operations compartment, reactor compartment, auxiliary machinery room no. 2, and the engine room. The extra length was in the operations compartment, including longer torpedo racks to accommodate additional Mark 37 torpedoes, the most advanced in service at the time of the class's design in the late 1950s. The class was redesigned to SUBSAFE requirements concurrently with the construction of the first units, with seawater, main ballast, and other systems modified for improved safety. The biggest difference was the much larger sail, which permitted a second periscope and additional intelligence-gathering masts, and which reduced the risk of the submarine broaching the surface in heavy seas. The fairwater planes mounted on the sail could rotate 90\u00a0degrees, allowing the submarine to surface through thin ice. Because the S5W reactor was used (the same as in the \"Skipjack\"s and \"Thresher/Permit\"s), the sail was enlarged (increasing drag), and the displacement was increased, the \"Sturgeon\"s' top speed was , 2\u00a0knots slower than the \"Thresher/Permit\"s.\nThe last nine \"Sturgeon\"s were lengthened to provide more space for electronic equipment and habitability. The extra space also helped facilitate the use of dry deck shelters first deployed in 1982.\nThe class received mid-life upgrades in the 1980s, including the BQQ-5 sonar suite with a retractable towed array, Mk 117 torpedo fire control equipment, and other electronics upgrades.\nArmament.\nThe \"Sturgeon\"-class boats were equipped to carry the Harpoon missile, the Tomahawk cruise missile, the UUM-44 SUBROC, the Mark 67 SLMM and Mark 60 CAPTOR mines, and the MK-48 and ADCAP torpedoes. Torpedo tubes were located amidships to accommodate the bow-mounted sonar. The bow covering the sonar sphere was made from steel or glass reinforced plastic (GRP), both varieties having been produced both booted and not booted. Booted domes are covered with a half-inch layer of rubber. The GRP domes improved the bow sonar sphere performance; though for intelligence gathering missions, the towed-array sonar was normally used as it was much more sensitive.\nNoise reduction.\nSeveral \"Sturgeon\" boats and related submarines were modifications of the original designs to test ways to reduce noise.\nVariants.\nBeginning with , units of this class had a longer hull, giving them more living and working space than previous submarines. received an additional hull extension containing cable tapping equipment that brought her total length to . A number of the long hull \"Sturgeon\"-class SSNs, including \"Parche\", \"L. Mendel Rivers\", and \"Richard B. Russell\" were involved in top-secret reconnaissance missions, including cable tap operations in the Barents and Okhotsk seas. \"Parche\" received nine Presidential Unit Citations for successful missions.\nA total of seven boats were modified to carry the SEAL Dry Deck Shelter (DDS). The DDS is a submersible launch hangar with a lockout chamber attached to the ship's midships weapons shipping hatch, facilitating the use of SEAL Delivery Vehicles. DDS-equipped boats were tasked with the covert insertion of special forces.\nBoats in class.\nFrom \"Register of Ships of the US Navy, 1775-1990\".\nShort hull.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nLong hull.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDerivatives.\nOne other Navy vessel was based on the \"Sturgeon\" hull, but was modified for experimental reasons:\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29069", "revid": "50528310", "url": "https://en.wikipedia.org/wiki?curid=29069", "title": "Seawolf-class submarine", "text": "Class of US nuclear attack submarines\nThe \"Seawolf\" class is a class of nuclear-powered, fast attack submarines (SSN) in service with the United States Navy. The class was the intended successor to the , and design work began in 1983. A fleet of 29 submarines was to be built over a ten-year period, but that was reduced to 12 submarines. The end of the Cold War and budget constraints led to the cancellation of any further additions to the fleet in 1995, leaving the \"Seawolf\" class limited to just three boats. This, in turn, led to the design of the smaller . The \"Seawolf\" class cost about $3\u00a0billion per unit ($3.5\u00a0billion for ), making it the most expensive United States Navy fast attack submarine and second most expensive submarine ever, after the French nuclear-powered ballistic missile submarines.\nDesign.\nThe \"Seawolf\" design was intended to combat the threat of advanced Soviet ballistic missile submarines such as the , and attack submarines such as the in a deep-ocean environment. \"Seawolf\"-class hulls are constructed from HY-100 steel, which is stronger than the HY-80 steel employed in previous classes, in order to withstand water pressure at greater depths.\n\"Seawolf\"-class submarines are larger, faster, and significantly quieter than previous \"Los Angeles\"-class submarines; they also carry more weapons and have twice as many torpedo tubes. The boats are able to carry up to 50 UGM-109 Tomahawk cruise missiles for attacking land and sea surface targets. The boats also have extensive equipment to allow shallow water operations. The class uses the more advanced ARCI Modified AN/BSY-2 combat system, which includes a larger spherical sonar array, a wide aperture array (WAA), and a new towed-array sonar. Each boat is powered by a single S6W nuclear reactor, delivering to a low-noise pump-jet.\nAs a result of their advanced design, however, \"Seawolf\"-class submarines were much more expensive. The projected cost for 12 submarines of this class was $33.6\u00a0billion, but construction was stopped at three boats when the Cold War ended.\nVariants.\n is roughly longer than the other two boats of her class because it has an additional central section known as the Multi-Mission Platform (MMP), which allows launch and recovery of remotely operated underwater vehicles (ROV) and Navy SEALs. The MMP may also be used as an underwater splicing chamber for tapping of undersea fiber optic cables. This role was formerly filled by the now decommissioned . \"Jimmy Carter\" was modified for this role by General Dynamics Electric Boat at a cost of $887\u00a0million.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29071", "revid": "21860424", "url": "https://en.wikipedia.org/wiki?curid=29071", "title": "SunOS", "text": "Operating system from Sun Microsystems\nSunOS is a Unix-branded operating system developed by Sun Microsystems for their workstation and server computer systems from 1982 until the mid-1990s. The \"SunOS\" name is usually only used to refer to versions 1.0 to 4.1.4, which were based on BSD, while versions 5.0 and later are based on UNIX System V Release 4 and are marketed under the brand name \"Solaris\".\nHistory.\nSunOS\u00a01 only supported the Sun-2 series systems, including Sun-1 systems upgraded with Sun-2 (68010) CPU boards. SunOS\u00a02 supported Sun-2 and Sun-3 (68020) series systems. SunOS\u00a04 supported Sun-2 (until release 4.0.3), Sun-3 (until 4.1.1), Sun386i (4.0, 4.0.1 and 4.0.2 only) and Sun-4 (SPARC) architectures. Although SunOS\u00a04 was intended to be the first release to fully support Sun's new SPARC processor, there was also a SunOS\u00a03.2 release with preliminary support for Sun-4 systems.\nSunOS 4.1.2 introduced support for Sun's first sun4m-architecture multiprocessor machines (the SPARCserver 600MP series); since it had only a single lock for the kernel, only one CPU at a time could execute in the kernel.\nThe last release of SunOS\u00a04 was 4.1.4 (Solaris 1.1.2) in 1994. The sun4, sun4c and sun4m architectures were supported in 4.1.4; sun4d was not supported.\nSun continued to ship SunOS 4.1.3 and 4.1.4 until December 27, 1998; they were supported until September 30, 2003.\n\"SunOS\" and \"Solaris\".\nIn 1987, AT&amp;T Corporation and Sun announced that they were collaborating on a project to merge the most popular Unix flavors on the market at that time: BSD (including many of the features then unique to SunOS), System V, and Xenix. This would become System V Release 4 (SVR4).\nOn September 4, 1991, Sun announced that its next major OS release would switch from its BSD-derived source base to one based on SVR4. Although the internal designation of this release would be \"SunOS\u00a05\", from this point Sun began using the marketing name \"Solaris\". The justification for this new \"overbrand\" was that it encompassed not only SunOS, but also the OpenWindows desktop environment and Open Network Computing (ONC) functionality.\nEven though the new SVR4-based OS was not expected to ship in volume until the following year, Sun immediately began using the new \"Solaris\" name to refer to the currently shipping SunOS 4 release (also including OpenWindows). Thus SunOS 4.1.1 was rebranded \"Solaris\u00a01.0\"; SunOS 5.0 would be considered a part of Solaris\u00a02.0. SunOS\u00a04.1.\"x\" micro versions continued to be released through 1994, and each of these was also given a \"Solaris 1.\"x equivalent name. In practice, these were often still referred to by customers and even Sun personnel by their SunOS release names. Matching the version numbers was not straightforward:\nToday, SunOS\u00a05 is universally known as \"Solaris\", although the \"SunOS\" name is still visible within the OS itself\u00a0\u2013 in the startup banner, the output of the uname command, and man page footers, among other places.\nMatching a SunOS\u00a05.x release to its corresponding Solaris marketing name is simple: each Solaris release name includes its corresponding SunOS\u00a05 minor version number. For example, Solaris\u00a02.4 incorporated SunOS\u00a05.4. There is one small twist: after Solaris\u00a02.6, the \"2.\" was dropped from the Solaris name and the SunOS minor number appears by itself. The latest Solaris release is named \"Solaris 11\" and incorporates SunOS\u00a05.11.\nUser interface.\nBeginning with SunOS 1.0, the Sun Window System provided a GUI called Suntools, layered on top of lower-level windowing and bitmap libraries; this was renamed SunView in SunOS 3.0. Sun then developed a novel window system called NeWS that used and extended the PostScript language and graphics model. In 1989, Sun released OpenWindows, an OPEN LOOK-compliant X11-based environment which also supported SunView and NeWS applications. This became the default SunOS GUI in SunOS\u00a04.1.1.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29072", "revid": "6383155", "url": "https://en.wikipedia.org/wiki?curid=29072", "title": "SANS Institute", "text": "American security company\nThe SANS Institute (officially the Escal Institute of Advanced Technologies) is a private U.S. for-profit company founded in 1989 that specializes in information security, cybersecurity training, and selling certificates. Topics available for training include cyber and network defenses, penetration testing, incident response, digital forensics, and auditing. The information security courses are developed through a consensus process involving administrators, security managers, and information security professionals. The courses cover security fundamentals and technical aspects of information security. The institute has been recognized for its training programs and certification programs. Per 2021, SANS is the world\u2019s largest cybersecurity research and training organization. SANS is an acronym for SysAdmin, Audit, Network, and Security.\nPrograms.\nSANS sponsors several community resources including the Internet Storm Center, an internet monitoring system operated by volunteer security practitioners that provides analysis of emerging threats and has been recognized for identifying novel attack patterns. The SANS Reading Room maintains an extensive archive of information security research documents that serves as a key resource for security professionals. SANS also co-founded the Center for Internet Security and provides cybersecurity news through various digital publications.\nSANS offers news and analysis through Twitter feeds and e-mail newsletters. Additionally, there is a weekly news and vulnerability digest available to subscribers.\nTraining.\nWhen originally organized in 1989, SANS training events functioned like traditional technical conferences showcasing technical presentations. By the mid-1990s, SANS offered events which combined training with tradeshows. Beginning in 2006, SANS offered asynchronous online training (SANS OnDemand) and a virtual, synchronous classroom format (SANS vLive). Free webcasts and email newsletters (@Risk, Newsbites, Ouch!) have been developed in conjunction with security vendors. The actual content behind SANS training courses and training events remains \"vendor-agnostic\". Vendors cannot pay to offer their own official SANS course, although they can teach a SANS \"hosted\" event via sponsorship.\nSANS training has evolved from traditional technical conferences to include asynchronous online training and virtual classrooms. The organization maintains a vendor-agnostic approach to content development. In 1999, SANS formed the Global Information Assurance Certification (GIAC) program, which provides certifications that are consistently ranked among the most valuable in the cybersecurity industry. The institute also developed NetWars, a cyberattack simulation platform used by U.S. military organizations including the Air Force and Army.\nIt has developed and operates \"NetWars\", a suite of interactive learning tools for simulating scenarios such as cyberattacks. NetWars is in use by the US Air Force and the US Army.\nFaculty.\nThe majority of SANS faculty are not SANS employees, but industry professionals and experts in the field of information security. The faculty is organized into six different levels: Mentors, Community, Certified Instructors, Principal Instructors, Senior Instructors, and Fellows.\nSANS Technology Institute.\nAs of 2006[ [update]], SANS established the SANS Technology Institute, an accredited college based on SANS training and GIAC certifications. On November 21, 2013, SANS Technology Institute was granted regional accreditation by the Middle States Commission on Higher Education.\nSANS Technology Institute focuses exclusively on cybersecurity, offering a Master of Science degree program in Information Security Engineering (MSISE), five post-baccalaureate certificate programs (Penetration Testing &amp; Ethical Hacking, Incident Response, Industrial Control Systems, Cyber Defense Operations, and Cybersecurity Engineering (Core), and an upper-division undergraduate certificate program (Applied Cybersecurity). SANS later launched a bachelor's degree program in Applied Cybersecurity as well.\nSANS continues to offer free security content via the SANS Technology Institute Leadership Lab and IT/Security related leadership information.\nCourses and certifications.\nSANS offers more than 85 cybersecurity courses covering topics such as penetration testing, incident response, cloud security, and digital forensics. The curriculum includes both technical training and security leadership education. GIAC certifications validate skills in specific security domains and are widely recognized for their rigor and relevance to current security challenges.\nGlobal impact and recognition.\nSANS maintains significant influence on international cybersecurity practices. The institute's curriculum aligns with the U.S. National Institute of Standards and Technology (NIST) NICE Cybersecurity Workforce Framework, and its training content addresses the core cybersecurity threats and priorities identified in official European Union cybersecurity frameworks. The organization has been cited as a key solution to addressing the global cybersecurity skills gap, with its training programs helping to alleviate workforce shortages worldwide.\nCriticism and controversy.\nThe SANS Institute has faced criticism regarding the high cost of its training programs and certifications, with public debates about their return on investment for individual professionals. The ethical nature of some course content has also been questioned. For instance, courses covering \"active defense\" and \"hack back\" techniques have been noted to sit in a legal and ethical grey area. In a notable incident that challenged the institute's security posture, SANS confirmed a 2020 data breach that compromised the personal information of thousands of users.\nAwards programs.\nSANS acknowledges the contributions made by exceptional information security professionals, through its annual awards programs.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29074", "revid": "1320117629", "url": "https://en.wikipedia.org/wiki?curid=29074", "title": "Sun Myung Moon", "text": "Korean religious leader (1920\u20132012)\nSun Myung Moon (Korean:\u00a0; Hanja:\u00a0; born Moon Yong-myeong; 6 January 1920 \u2013 3 September 2012) was a Korean religious leader, also known for his business ventures and support for conservative political causes. A messiah claimant, he was the founder of the Unification Church, whose members consider him and his wife, Hak Ja Han, to be their \"True Parents\", and of its widely noted \"Blessing\" or mass wedding ceremonies. The author of the Unification Church's religious scripture, the \"Divine Principle\", was an anti-communist and an advocate for Korean reunification, for which he was recognized by the governments of both North and South Korea. Businesses he promoted included News World Communications, an international news media corporation known for its American subsidiary \"The Washington Times\", and Tongil Group, a South Korean business group (chaebol), as well as other related organizations.\nMoon was born in what is now North Korea. When he was a child, his family converted to Christianity. In the 1940s and 1950s, he was imprisoned multiple times by the North and South Korean governments during his early new religious ministries, formally founding the Holy Spirit Association for the Unification of World Christianity, simply known as the Unification Church, in Seoul, South Korea, in 1954.\nIn 1971, Moon moved to the United States and became well known after giving a series of public speeches on his beliefs. In the 1982 case \"United States v. Sun Myung Moon\", he was found guilty of willfully filing false federal income tax returns and sentenced to 18 months in federal prison. His case generated protests from clergy and civil libertarians, who said that the trial was biased against him.\nMany of Moon's followers were very dedicated and were often referred to in popular parlance as \"Moonies\". His wedding ceremonies drew criticism, specifically after members of other churches took part, including the excommunicated Roman Catholic archbishop Emmanuel Milingo. Moon was also criticized for his relationships with political and religious figures, including US presidents Richard Nixon, George H. W. Bush, and George W. Bush; Soviet president Mikhail Gorbachev; North Korean president Kim Il Sung; and Nation of Islam leader Louis Farrakhan.\nEarly life.\nSun Myung Moon was born Yong Myung Moon on 6 January 1920 in modern-day North P'y\u014fng'an Province, North Korea, at a time when Korea was under Japanese rule. He was the second son in a farming family of thirteen children, eight of whom survived. Moon's family followed Confucianist beliefs until he was around 10 years old. Then they converted to Christianity and joined the Presbyterian Church. Moon claims that he experienced a religious vision of Jesus at age 16 that laid out his life's mission.\nIn 1941, Moon began studying electrical engineering at Waseda University in Japan. During this time, he cooperated with Communist Party members in the Korean independence movement against the Empire of Japan. In 1943, he returned to Seoul and, in 1944, married his first wife, Sun-kil Choi (; \u5d14\u5148\u5409; \"Choe Seon-gil\"). They had a son, Sung Jin Moon (; \u6587\u8056\u9032; \"Mun Seong-jin\"). In the 1940s, Sun Myung Moon attended a church led by Kim Baek-moon, who influentially taught that he had been given by Jesus the mission to spread the message of a \"new Israel\" throughout the world. Around this time, Moon changed his given name to Sun Myung in an effort to quell the increased resentment of other Christians against him, as he gradually began gathering his own group of followers.\nFollowing World War II, Korea was divided (South and North) along the 38th parallel into two trusteeships: the United States and the Soviet Union. Pyongyang (the eventual capital of North Korea) was the center of Christian activity in Korea until 1945. From the late 1940s, hundreds of Korean Christian religious figures were killed or disappeared in concentration camps, including Francis Hong Yong-ho, Catholic bishop of Pyongyang, and all monks of Tokwon Abbey. When Moon started his own movement (an early version of the Unification Church) in Pyongyang in 1946, the Soviet-controlled North Korean government imprisoned and, he claims, tortured him. Sources vary on the motivation behind his arrest: religious persecution, or a charge of espionage or polygamy. His religious practices during this time may have included unorthodox sexual rituals with multiple women, a claim the Unification Church denies and some scholars have doubted.\nArrested again in 1948, he was sentenced to five years at Hungnam labor camp, though in 1950, during the Korean War, he was liberated by United Nations troops and allegedly traveled by foot to Busan, (South) Korea. Moon emerged from his years in the labor camp as a staunch anti-communist. His teachings viewed the Cold War between capitalism and communism as the final conflict between God and Satan, with divided Korea as its primary front line.\nIn the 1950s, after years of being separated from his wife and child before reuniting, Moon and Choi divorced. Moon moved to Seoul once again and, continuing his ministry, was arrested two more times: once on suspicion of religious orgies and once for draft evasion; both charges were overturned.\nIn 1954, Moon formally founded the Holy Spirit Association for the Unification of World Christianity in Seoul and fathered an illegitimate child (who died in 1969). In the 1950s, Moon quickly drew young acolytes who helped to build the foundations of Unification-affiliated business and cultural organizations. In his new church, he preached a conservative, family-oriented value system and his interpretation of the Bible. A follower whose family joined Moon's movement in the early 1950s claims that she and Moon engaged in various religious sexual rituals, including with several other women, and that she remained Moon's mistress (through his second marriage) until 1964, bearing Moon another son, in secret, in 1965.\nSecond marriage and Blessing ceremonies.\nMarriage to Hak Ja Han.\nMoon married his second wife, Hak Ja Han (who was 17 at the time) on 11 April 1960, soon after Moon turned 40 years old, in a ceremony called the Holy Marriage. Han is called \"Mother\" or \"True Mother\". She and Moon together are referred to as the \"True Parents\" by members of the Unification Church and their family as the \"True Family\".\nBlessing ceremonies.\nAlthough they initially lived communally, his followers gradually returned to the traditional Christian family form (monogamy). Blessing ceremonies have attracted attention in the press and in the public imagination, often being labeled \"mass weddings\". People who have never met, from completely different countries, were married by the Messiah of the Unification Church by \"matching\". They were informed that a certain person, specially chosen for him/her by the Messiah, would become their husband/wife. Some of them did not see their future partner until the day of the \"marriage\". Public mass blessing ceremonies followed. Some couples are already married, and those that are engaged are later legally married according to the laws of their own countries. Meant to highlight the church's emphasis on traditional morality, they brought Moon both fame and controversy.\n36 couples participated in the first ceremony in 1961 for members of the early church in Seoul. The ceremonies continued to grow in scale; over 2,000 couples participated in the 1982 one at New York's Madison Square Garden, the first outside South Korea. In 1992, about 30,000 couples took part in a ceremony and a record 360,000 couples in Seoul took part three years later.\nMoon said that he matched couples from differing races and nationalities because of his belief that all of humanity should be united: \"International and intercultural marriages are the quickest way to bring about an ideal world of peace. People should marry across national and cultural boundaries with people from countries they consider to be their enemies so that the world of peace can come that much more quickly.\"\nEstablishing beliefs of the Unification movement.\nMoon said that when he was 16 years old, Jesus appeared to him, anointing him to carry out his unfinished work by becoming a parent to all of humanity. The \"Divine Principle\u200a\", or \"Exposition of the Divine Principle\" (Korean:\u00a0; Hanja:\u00a0; RR:\u00a0), is the main theological textbook of the Unification movement. It was co-written by Moon and early disciple Hyo Won Eu and first published in 1966. A translation entitled \"Divine Principle\" was published in English in 1973. The book lays out the core of Unification theology and is held to have the status of scripture by believers. Following the format of systematic theology, it includes (1)\u00a0God's purpose in creating human beings, (2)\u00a0the fall of man, and (3)\u00a0restoration\u2014the process through history by which God is working to remove the ill effects of the fall and restore humanity back to the relationship and position that God originally intended.\nGod is viewed as the creator, whose nature combines both masculinity and femininity, and is the source of all truth, beauty, and goodness. Human beings and the universe reflect God's personality, nature, and purpose. \"Give-and-take action\" (reciprocal interaction) and \"subject and object position\" (initiator and responder) are \"key interpretive concepts\", and the self is designed to be God's object. The purpose of human existence is to return joy to God. The \"four-position foundation\" (Origin, Subject, Object, and Union) is another important and interpretive concept and explains in part the emphasis on the family.\nMoon taught that Jesus was divine but not God; he was supposed to be the second Adam who would create a perfect family by joining with the ideal wife and creating a pure family that would have begun humanity's liberation from its sinful condition. When Jesus was crucified before marrying, he redeemed mankind spiritually but not physically. That task was left to the \"True Parents\"\u2014Moon and Han\u2014who would link married couples and their families to God.\nMove to United States.\nIn 1971, Moon moved to the United States, which he had first visited in 1965, and eventually settled into a 35-room mansion on an estate in Irvington, New York. He remained a citizen of South Korea, where he maintained a residence. In 1972, Moon founded the International Conference on the Unity of the Sciences, a series of scientific conferences. The first conference had 20 participants, while the largest conference in Seoul, in 1982, had 808 participants from over 100 countries. Participants included Nobel laureates John Eccles (Physiology or Medicine 1963, who chaired the 1976 conference)\nand Eugene Wigner (Physics 1963).\nIn 1974, Moon asked church members in the United States to support President Richard Nixon during the Watergate scandal, when Nixon was being pressured to resign his office. Church members prayed and fasted in support of Nixon for three days in front of the United States Capitol under the motto: \"Forgive, Love and Unite.\" On 1 February 1974, Nixon publicly thanked them for their support and officially received Moon. This brought the church into widespread public and media attention.\nIn the 1970s, Moon, who had seldom before spoken to the general public, gave a series of public speeches to audiences in the United States, Japan, and South Korea. The largest was a rally in 1975 against North Korean aggression in Seoul and a speech at an event organized by the Unification Church in Washington, D.C.\n\"United States v. Sun Myung Moon\".\nIn 1982, following an IRS investigation, Moon was convicted in the United States of conspiracy and tax evasion by filing incorrect federal income tax returns totaling less than $. He refused to stay in Korea and returned to the United States. His conviction was upheld on appeal in a split decision. Moon was given an 18-month sentence and a $ fine. He served 13 months of the sentence at the Federal Correctional Institution, Danbury, before being released on good behavior to a halfway house.\nThe case was the center of national freedom of religion and free speech debates. Prof. Laurence H. Tribe of the Harvard University Law School argued that the trial by jury had \"doomed (Moon) to conviction based on religious prejudice.\" The American Baptist Churches in the USA, the National Council of Churches, the National Black Catholic Clergy Caucus, and the Southern Christian Leadership Conference filed briefs in support of Moon. Many notable clergy, including Jerry Falwell and Joseph Lowery, signed petitions protesting the government's case and spoke publicly in defense of Moon. Carlton Sherwood, in his book , stated that the conviction of Reverend Moon was viewed by Protestant pastors as a humiliation of religious liberty.\nAfter his prison sentence, Moon began calling himself humanity's Messiah and officially conferred the title of \"Messiah\" on himself in 1992.\n\"The Washington Times\".\nIn 1982, \"The Washington Times\" was founded by News World Communications, an international media conglomerate associated with Moon, which also owned newspapers in South Korea, Japan, and South America, as well as the news agency United Press International. The political views of \"The Washington Times\" have often been described as conservative. The \"Times\" was read by many Washington, DC insiders, including Ronald Reagan. By 2002, Moon had invested roughly $ to support the \"Times\", which he called \"the instrument in spreading the truth about God to the world.\"\nTwenty-first century events.\nIn 2000, Moon sponsored a United Nations conference that proposed the formation of \"a religious assembly, or council of religious representatives, within the structure of the United Nations.\"\nIn 2003, Moon sponsored the first Peace Cup international club soccer tournament. The Los Angeles Galaxy, which competes in Major League Soccer, played in South Korea in the Peace Cup. During the event, Pel\u00e9, widely regarded as the best soccer player of all time and former Brazilian Sports Minister, met with Moon.\nIn 2009, Moon's autobiography, \"As a Peace-Loving Global Citizen\" (), was published by Gimm-Young Publishers in South Korea. The book became a best-seller in Korea and Japan.\nBy 2010, Moon had given much of the responsibility for the Family Federation for World Peace and Unification religious and business activities to his children, who were then in their 30s and 40s. In 2012, the South Korean press reported that Moon traveled worldwide in his private jet, which cost $.\nIllness and death.\nOn 14 August 2012, after suffering from pneumonia earlier in the month, Moon was admitted to Saint Mary's Hospital at The Catholic University of Korea in Seoul. On 15 August 2012, he was reported to be gravely ill and was put on a ventilator at the intensive care unit of St. Mary's. On 31 August 2012, Moon was transferred to a church-owned hospital near his home in Gapyeong, northeast of Seoul, after suffering multiple organ failure. Moon died on the morning of 3 September 2012 (1:54\u00a0am KST) at the age of 92.\nA two-week mourning period was conducted in honor of him. On 15 September, after a funeral service attended by tens of thousands of Unification Church followers, Moon was buried at a church-owned mansion in Gapyeong.\nActivities and interests.\nPolitics.\nIn 1964, Moon founded the Korean Culture and Freedom Foundation, which promoted the interests of South Korea and sponsored Radio Free Asia. Former US Presidents Harry S Truman, Dwight D. Eisenhower, and Richard Nixon were honorary presidents or directors at various times.\nIn 1972, Moon offered predictions on the decline of communism, based on the teachings of the \"Divine Principle\": \"After 7,000 biblical years\u20146,000 years of restoration history plus the millennium, the time of completion\u2014communism will fall in its 70th year. Here is the meaning of the year 1978. Communism, begun in 1917, could maintain itself for approximately 60 years and reach its peak. So 1978 is the borderline and afterward, communism will decline; in the 70th year, it will be altogether ruined. This is true. Therefore, now is the time for people who are studying communism to abandon it.\"\nIn 1980, Moon asked church members to found CAUSA International as an anti-communist educational organization, based in New York. In the 1980s, it was active in 21 countries. In the United States, it sponsored educational conferences for Christian leaders as well as seminars and conferences for Senate staffers and other activists. In 1986, it produced the anti-communist documentary film \"Nicaragua Was Our Home\". CAUSA supported the Nicaraguan Contras.\nIn August 1985, the Professors World Peace Academy, an organization founded by Moon, sponsored a conference in Geneva to debate the theme \"The situation in the world after the fall of the communist empire.\" In April 1990, Moon visited the Soviet Union and met with President Mikhail Gorbachev. Moon expressed support for the political and economic transformations underway in the Soviet Union. At the same time, the Unification Church was expanding into formerly communist nations. After the dissolution of the Soviet Union in 1991, some American conservatives criticized Moon for his softening of his previous anti-communist stance.\nIn 1991, Moon met with Kim Il Sung, then North Korean president, to discuss ways to achieve peace on the Korean peninsula, as well as on international relations, tourism, etc. In 1994, Moon was officially invited to the funeral of Kim Il Sung in spite of the absence of diplomatic relations between North Korea and South Korea. Moon and his church are known for their efforts to promote Korean unification.\nIn 2003, Korean Unification Church members started a political party in South Korea. It was named \"The Party for God, Peace, Unification, and Home.\" In its inauguration declaration, the new party said it would focus on preparing for Korean reunification by educating the public about God and peace. Moon was a member of the Honorary Committee of the Unification Ministry of the Republic of Korea. In 2012, Moon was posthumously awarded North Korea's National Reunification Prize.\nIn 2005, Sun Myung Moon and his wife, Hak Ja Han Moon, founded the Universal Peace Federation (UPF), an NGO in Special Consultative Status with the United Nations Economic and Social Council (ECOSOC). \"We support and promote the work of the United Nations and the achievement of the Sustainable Development Goals.\"\nMoon's projects have been lobbied in the National Congress of Brazil by Brazilian MPs. Moon has held dialogues between members of the Israeli Knesset and the Palestinian Parliament as part of his Middle East Peace Initiatives.\nBusiness.\nTongil Group is a South Korean business group (chaebol \"Tongil\" is Korean for \"unification\"; the name of the Unification Church in Korean is \"Tongilgyo\") founded in 1963 by Moon as a nonprofit organization to provide revenue for the church. Its core focus was manufacturing, but in the 1970s and 1980s, it expanded by founding or acquiring businesses in pharmaceuticals, tourism, and publishing. Among Tongil Group's chief holdings are: The Ilwha Company, which produces ginseng and related products; Ilshin Stone, building materials; and Tongil Heavy Industries, machine parts, including hardware for the South Korean military.\nNews World Communications is an international news media corporation founded by Moon in 1976. It owns United Press International, \"World and I\", \"Tiempos del Mundo\" (Latin America), \"The Segye Ilbo\" (South Korea), \"The Sekai Nippo\" (Japan), the \"Zambezi Times\" (South Africa), and \"The Middle East Times\" (Egypt). Until 2008, it published the Washington, D.C.-based newsmagazine \"Insight on the News\". Until 2010, it owned \"The Washington Times\". On 2 November 2010, Sun Myung Moon and a group of former \"Times\" editors purchased the \"Times\" from News World.\nIn 1982, Moon sponsored the film \"Inchon\", a historical drama about the Battle of Inchon during the Korean War. It was not successful critically or financially and was criticized for its unfair treatment of the North Korean government.\nIn 1989, Moon founded Seongnam Ilhwa Chunma, the second most successful soccer club in South Korea, having won a record 7 league titles, 2 FA Cups, 3 League Cups, and 2 AFC Champions League titles. Seongnam's record was beaten by Jeonbuk Hyundai Motors in 2020.\nThe church is the largest owner of US sushi restaurants, and in the Kodiak region of Alaska is the area's largest employer. The church founded the first currently operating automobile manufacturing plant in North Korea, Pyeonghwa Motors, and is the second largest exporter of Korean goods.\nIn 2011, construction of the $ Yeosu Expo Hotel was completed; the hotel is located at the Moon-owned Ocean Resort in Yeosu, the venue of Expo 2012. The opening ceremony was attended by the governor of the province. Another one, the Ocean Hotel, was completed in February 2012. Moon-owned Yeongpyeong Resort, Ocean Resort, and Pineridge Resort were scheduled to host Expo 2012, the 2018 Winter Olympics, and Formula 1. Moon also managed the FIFA-accredited Peace Cup. The FIFA itself has funded more than $ for the Peace Cup since 2003.\nRace relations.\nMoon took a strong stance against racism and racial discrimination. In 1974, he urged Unification Church members to support an African-American president of the United States: \"We have had enough of white presidents. So, let's this time elect a president from the Negro race. What will you do if I say so? There's no question there. We must never forget that we are brothers and sisters in a huge human family. In any level of community, we must become like a family.\"\nIn 1981, he said that he himself was a victim of racial prejudice in the United States (concerning his prosecution on tax charges in United States v. Sun Myung Moon), saying: \"I would not be standing here today if my skin were white or my religion was Presbyterian. I am here today only because my skin is yellow and my religion is the Unification Church. The ugliest things in this beautiful country of America are religious bigotry and racism.\"\nSeveral African American organizations and individuals spoke out in defense of Moon at this time, including the National Black Catholic Clergy Caucus, the Southern Christian Leadership Conference, the National Conference of Black Mayors, and Joseph Lowery, who was then the head of the Southern Christian Leadership Conference.\nIn a later controversy over the use of the word \"Moonie\" (which was said to be offensive) by the American news media, Moon's position was supported by civil rights activists Ralph Abernathy and James Bevel.\nIn 2000, Moon and Nation of Islam leader Louis Farrakhan got together to sponsor the Million Family March, a rally in Washington, D.C. to celebrate family unity and racial and religious harmony as well as to address other issues, including abortion, capital punishment, health care, education, welfare, Social Security reform, substance abuse prevention, and overhaul of the World Bank and International Monetary Fund. In his keynote speech, Farrakhan called for racial harmony.\nDance.\nIn 1962, Moon and other church members founded the Little Angels Children's Folk Ballet of Korea, a children's dance troupe that presents traditional Korean folk dances. He said that this was to project a positive image of South Korea to the world. In 1984, Moon founded the $ Universal Ballet project, with Soviet-born Oleg Vinogradov as its art director and Moon's daughter-in-law Julia as its prima ballerina. It was described by \"The New York Times\" as the top ballet company in Asia. In 1989, Moon founded Universal Ballet Academy, which later changed its name to Kirov Academy of Ballet, in Washington, D.C.\nSeafood and shipbuilding.\nThe Unification Church owns True World Foods, which controls a major portion of the sushi trade in the US. True World Foods' parent company is the corporate conglomerate True World Group, which operates restaurants and markets.\nThe Unification Church's into the seafood industry began at the direction of Moon, who ordered an expansion into \"the oceanic providence.\" In 1976 and 1977, the Unification Church invested nearly a million dollars into the American seafood industry. Moon delivered a speech in 1980 entitled \"The Way of Tuna\", in which he claimed that \"After we build the boats, we catch the fish and process them for the market, and then have a distribution network. This is not just on the drawing board; I have already done it\" and declared himself the \"king of the ocean.\" He also suggested that they could get around the recently imposed 200-nautical-mile exclusive economic zone by marrying American and Japanese members, allowing the Japanese ones to become American citizens, because once married, \"we are not foreigners; therefore Japanese brothers, particularly those matched to Americans, are becoming ... leaders for fishing and distribution.\" He also declared that \"Gloucester is almost a Moonie town now!\"\nLater in 1980, Moon gave a sermon in which he said, \"This ocean business is really reserved for Unification Church. How much income would this business generate? Roughly speaking, enough money to buy the entire world. That's true! It has unlimited potential.\" In 1986, he advised his followers to open a thousand restaurants in America.\nThe Unification Church owns Master Marine (a shipbuilding and fishing company in Alabama) and International Seafood of Kodiak, Alaska. In 2011, Master Marine opened a factory in Las Vegas, Nevada, to manufacture a 27-foot pleasure boat designed by Moon.\nHonorary degrees and other recognition.\nMoon held honorary degrees from more than ten universities and colleges worldwide, at least one of which, the University of Bridgeport, received significant funding from his organizations. He was a member of the Honorary Committee of the Unification Ministry of South Korea. In 1985, he and his wife received Doctor of Divinity degrees from Shaw University.\nIn 2004, Moon was honored as the Messiah at an event in the Dirksen Senate Office Building, Washington, D.C. This attracted much public attention and was criticized by \"The New York Times\" and \"The Washington Post\" as a possible violation of the principle of separation of church and state in the United States. Some of the political figures who had attended the event later told reporters that they had been misled as to its nature.\nSeveral months after his death, an award named after him and his wife (the Sunhak Peace Prize) was proposed, inheriting his will to \"recognize and empower innovations in human development, conflict resolution, and ecological conservation.\" Its laureates receive a certificate, a medal, and $.\nMoon was posthumously awarded North Korea's National Reunification Prize in 2012 and a meritorious award by K-League. On the first anniversary of Moon's death, North Korean leader Kim Jong Un expressed condolences to Han and the family, saying: \"Kim Jong Un prayed for the repose of Moon, who worked hard for national concord, prosperity and reunification and world peace.\"\nIn 2013, Zimbabwean Prime Minister Morgan Tsvangirai stated: \"I remain greatly inspired by people like Reverend Dr. Sun Myung Moon, whose work and life across continents continue to impact positively on the lives of millions of others in the world.\"\nIn 2021, president Donald Trump praised Moon in an event linked to the Unification Church. Previously, such events held by Unification Church, named Rally of Hope, gathered speakers from the Trump Administration: e.g., former Vice President Mike Pence, former Secretary of State Mike Pompeo, and advisor Paula White.\nCriticism.\nMoon's claim to be the Messiah and the Second Coming of Christ has been rejected by most Jewish and Christian scholars. The \"Divine Principle\" was labeled as heretical by Protestant churches in South Korea, including Moon's own Presbyterian Church. In the United States, it was rejected by ecumenical organizations as being non-Christian. Protestant commentators have also criticized Moon's teachings as being contrary to the Protestant doctrine of salvation by faith alone. In their influential book \"The Kingdom of the Cults\" (first published in 1965), Walter Ralston Martin and Ravi K. Zacharias disagreed with the \"Divine Principle\" on the issues of the divinity of Christ, the virgin birth of Jesus, Moon's belief that Jesus should have married, the necessity of the crucifixion of Jesus, a literal resurrection of Jesus, as well as a literal second coming of Jesus. Commentators have criticized the \"Divine Principle\" for saying that the First World War, the Second World War, the Holocaust, and the Cold War served as indemnity conditions to prepare the world for the establishment of the Kingdom of God.\nDuring the Cold War, Moon was criticized by both the mainstream media and the alternative media for his anti-communist activism, which many said could lead to World War III and a nuclear holocaust. Moon's anti-communist activities received financial support from controversial Japanese millionaire and activist Ry\u014dichi Sasakawa. In 1977, the Subcommittee on International Organizations of the Committee on International Relations of the United States House of Representatives, while investigating the Koreagate scandal, found that the South Korean National Intelligence Service (KCIA) had worked with the Unification Church to gain political influence within the United States, with some members working as volunteers in Congressional offices. Together, they founded the Korean Cultural Freedom Foundation, a nonprofit organization that undertook public diplomacy for the Republic of Korea. The committee also investigated possible KCIA influence on Moon's campaign in support of Richard Nixon. \nAfter the dissolution of the Soviet Union in 1991, some American conservatives criticized Moon for his softening of his previous anti-communist stance.\nIn the 1990s, when Moon began to offer the Unification marriage blessing ceremony to members of other churches and religions, he was criticized for creating possible confusion. In 1998, journalist Peter Maass, writing for \"The New Yorker\", reported that some Unification members were dismayed and also grumbled when Moon extended the Blessing to non-members, who had not gone through the same course that members had. In 2001, Moon came into conflict with the Roman Catholic Church when 71-year-old Catholic archbishop Emmanuel Milingo and Maria Sung, a 43-year-old Korean acupuncturist, married in a blessing ceremony, presided over by Moon and his wife. Following his marriage, the archbishop was called to the Vatican by Pope John Paul II, where he was asked not to see his wife anymore and to move to a Capuchin monastery. Sung went on a hunger strike to protest their separation. This attracted much media attention. Milingo is now an advocate of the removal of the requirement for celibacy by priests in the Catholic Church. He is the founder of the Married Priests Now! advocacy group.\nIn 1998, the Egyptian newspaper \"Al-Ahram\" criticized Moon's possible relationship with Israeli Prime Minister Benjamin Netanyahu and wrote that \"The Washington Times\" editorial policy was \"rabidly anti-Arab, anti-Muslim and pro-Israel.\"\nIn 2000, Moon was criticized, including by some members of his church, for his support of controversial Nation of Islam leader Louis Farrakhan's Million Family March. Moon was also criticized for his relationship with controversial Jewish scholar Richard L. Rubenstein, an advocate of the \"death of God theology\" of the 1960s. Rubenstein was a defender of the Unification Church and served on its advisory council, and on the board of directors of \"The Washington Times\", a church-owned newspaper. In the 1990s, he served as president of the University of Bridgeport, which was then affiliated with the church.\nIn 2003, George D. Chryssides of the University of Wolverhampton criticized Moon for introducing doctrines that tended to divide the Christian church rather than uniting it, which was his stated purpose in founding the Unification movement (originally named the Holy Spirit Association for the Unification of World Christianity). In his 2009 autobiography, Moon himself wrote that he did not originally intend on founding a separate denomination.\nMoon opposed homosexuality and compared gay people to \"dirty dung-eating dogs\". He said that \"gays will be eliminated\" in a \"purge on God's orders\". \nIn 2009, Moon's support for the Japan-Korea Undersea Tunnel was criticized in Japan and South Korea as a possible threat to both nations' interests and national identities.\nOther criticisms include Moon's apparent neglect of his wife, Hak Ja Han, and his appointments of their children and their spouses to leadership positions in the church and related businesses, including their daughter In Jin Moon to the presidency of the Unification Church of the United States against the wishes of some church members; his support of conservatives within the government of South Korea; his assignment of movement members and resources to business projects and political activism, including \"The Washington Times\"; as well as the relationship between the Unification Church and Islam, especially following the September 11 attacks in New York City.\nViews of Moon by his followers.\nThe \"Divine Principle\" itself says about Moon: \"With the fullness of time, God has sent one person to this earth to resolve the fundamental problems of human life and the universe. His name is Sun Myung Moon. For several decades he wandered through the spirit world so vast as to be beyond imagining. He trod a bloody path of suffering in search of the truth, passing through tribulations that God alone remembers. Since he understood that no one can find the ultimate truth to save humanity without first passing through the bitterest of trials, he fought alone against millions of devils, both in the spiritual and physical worlds, and triumphed over them all. Through intimate spiritual communion with God and by meeting with Jesus and many saints in Paradise, he brought to light all the secrets of Heaven.\"\nIn 1978, Rodney Sawatsky wrote in an article in \"Theology Today\": \"Why trust Rev. Moon's dreams and visions of the new age and his role in it, we ask? Most converts actually have had minimal contact with him. Frederick Sontag (Sun Myung Moon and the Unification Church, Abingdon, 1977), in his interviews with Moon, appears to have found a pleasant but not overwhelming personality. Charisma, as traditionally understood, seems hardly applicable here. Rather, Moon provides a model. He suffered valiantly, he knows confidently, he prays assuredly, and he lives lovingly, say his followers. The Divine Principle is not an unrealizable ideal; it is incarnate in a man, it lives, it is imitable. His truth is experienced to be their truth. His explanation of the universe becomes their understanding of themselves and the world in which they live.\"\nIn 1980, sociologist Irving Louis Horowitz commented: \"The Reverend Moon is a fundamentalist with a vengeance. He has a belief system that admits of no boundaries or limits, an all-embracing truth. His writings exhibit a holistic concern for the person, society, nature, and all things embraced by the human vision. In this sense the concept underwriting the Unification Church is apt, for its primary drive and appeal is unity, urging a paradigm of the essence in an overly complicated world of existence. It is a ready-made doctrine for impatient young people and all those for whom the pursuit of the complex has become a tiresome and fruitless venture.\"\nIn 1998, investigative journalist Peter Maass wrote in an article in \"The New Yorker\": \"There are, certainly, differing degrees of devotion among Moon's followers; the fact that they bow at the right moment or shout \"Mansei!\" in unison doesn't mean they believe everything Moon says, or do precisely what he commands. Even on important issues, like Moon's claiming to be the messiah, there are church members whom I met, including a close aide to Moon, who demur. A religious leader whom they respect and whose theology they believe, yes; the messiah, perhaps not.\"\nIn his 2004 book \"The New Religious Movement Experience in America\", Eugene V. Gallagher wrote: \"The \"Divine Principle's\" analysis of the Fall sets the stage for the mission of Rev. Moon, who in the last days brings a revelation that offers humankind the chance to return to an Edenic state. The account in the \"Divine Principle\" offers Unificationists a comprehensive context for understanding human suffering.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29076", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=29076", "title": "Sun Myung Moon/imprisonment", "text": ""}
{"id": "29077", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=29077", "title": "Sun Myung Moon/tax case", "text": ""}
{"id": "29079", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=29079", "title": "Statute of frauds", "text": "Type of statute specifying that certain contracts must be in writing\nA statute of frauds is a form of statute requiring that certain kinds of contracts be memorialized in writing, signed by the party against whom they are to be enforced, with sufficient content to evidence the contract.\nTerminology.\nThe term \"statute of frauds\" comes from the Statute of Frauds, an act of the Parliament of England (29 Chas. 2 c. 3) passed in 1677 (authored by Lord Nottingham assisted by Sir Matthew Hale, Sir Francis North and Sir Leoline Jenkins and passed by the Cavalier Parliament), the long title of which is: An Act for Prevention of Frauds and Perjuries. \nMany common law jurisdictions have made similar statutory provisions, while a number of civil law jurisdictions have equivalent legislation incorporated into their civil codes. The original English statute itself may still be in effect in a number of Canadian provinces, depending on the constitutional or reception statute of English law, and any subsequent legislative developments.\nApplication.\nThe statute of frauds typically requires a signed writing in the following circumstances:\n* Contracts in consideration of marriage. This provision covers prenuptial agreements.\n* Contracts that cannot be performed within one year. However, contracts of indefinite duration do not fall under the statute of frauds regardless of how long the performance actually takes.\n* Contracts for the transfer of an interest in land. This applies not only to a contract to sell land but also to any other contract in which land or an interest in it is disposed, such as the grant of a mortgage or an easement.\n* Contracts by the executor of a will to pay a debt of the estate with his own money.\n* Contracts in which one party becomes a surety (acts as guarantor) for another party's debt or other obligation.\n* Contracts for the sale of goods totaling $500.00 or more.\nIn an action for specific performance of a contract to convey land, the agreement must be in writing to satisfy the statute of frauds. The statute is satisfied if the contract to convey is evidenced by a writing or writings containing the essential terms of a purchase and sale agreement and signed by the party against whom the contract is to be enforced. If there is no written agreement, a court of equity can specifically enforce an oral agreement to convey only if the part performance doctrine is satisfied. In most jurisdictions, part performance is proven when the purchaser pays the purchase price, has possession of the land and makes improvements on the land, all with the permission of the seller. No jurisdiction is satisfied by payment of the purchase price alone.\nUnder common law, the statute of frauds also applies to contract modifications. For example, in an oral agreement for the lease of a car for nine months, immediately after taking possession, the lessor then decides that he really likes the car and makes an oral offer to the lessee to extend the term of the lease by an additional six months. Although neither agreement alone comes under the statute of frauds, the oral extension modifies the original contract to make it a fifteen-month lease (nine months plus the additional six), thereby bringing it under the statute as the contract now exceeds twelve months in duration. In theory, the same principle works in reverse as well, such that an agreement to reduce a lease from fifteen months to nine months would not require a writing. However, many jurisdictions have enacted statutes that require a writing for such situations.\nRaising the defense.\nA defendant in a contract case who wants to use the statute of frauds as a defense must raise it as an affirmative defense in a timely manner. The burden of proving that a written contract exists comes into play only when a statute of frauds defense is raised by the defendant.\nExceptions.\nAn agreement may be enforced even if it does not comply with the statute of frauds in the following situations:\n* A statute of frauds defense may also be affected by a showing of part performance by proving the existence of one of two different conditions. If the parties have taken action in reliance on the agreement, as in the case \"Riley v. Capital Airlines, Inc.\", the court held that part performance does not take an executory portion of a contract out of the statute of frauds. Each performance constitutes a contract that falls outside the Statute of Frauds and was enforceable to the extent it is executed. However, the unexecuted portion of the contract falls within the Statute of Frauds and is unenforceable. As a result, only the executed portion of the contract can be recovered, and the doctrine of part performance does not remove the contract from the statute. On the other hand, the court, in \"Schwedes v. Romain\", held that partial performance and grounds for estoppel can make the contract effective.\n* Promissory estoppel can be applied in many but not all jurisdictions when the charging party detrimentally relies on the otherwise unenforceable contract. In England and Wales, the circumstances where promissory estoppel may be used to overcome the statute are limited, and some jurisdictions deny this possibility altogether.\n* The \"main purpose rule\" as it relates to guarantee or suretyship type contracts: where the promisor's promise to answer for the debt of another is made mainly for the promisor's own economic advantage, then it is a primary promise, and enforceable even without a writing.\n* Easements by implication: easements, which are agreements that permit the use of real estate by someone who has no property interest in the land, may be created by operation of law rather than by written instrument. This may happen where, for example, a piece of land is partitioned between owners and pre-existing utilities routes or access paths that would otherwise be trespassory over one of the plots is reasonably necessary for enjoyment of the other plot. In such case, the pre-existing use must be apparent and continuous at the time of the partition for an easement to be created by implication. The implied easement constitutes an interest in land that does not require a writing to be enforceable.\nBy jurisdiction.\nCanada.\nThe Statute of Frauds recites that it was enacted for the \". . . prevention of many fraudulent practices which are commonly endeavored to be upheld by perjury . . .\". The mischief arising from claimants asserting oral agreements was to be avoided by requiring that certain contracts be evidenced by \"some memorandum or note thereof . . . in writing and signed by the party to be charged therewith . . .\". Contracts respecting land \"created by livery and seisen only or by parole\" would not be enforced absent such a writing.\nIt quickly became apparent to the common law judges that the Statute might itself become an instrument of fraud (or at least injustice) if it was strictly enforced with respect to contracts that were wholly or partly performed.\nThe courts developed the concept of \"part performance\" as an exception. If a contract concerning land was partly performed, that could displace the need for a note or memorandum in writing signed by the party to be charged.\nIt was one thing to create an exception that displaced the need for a memorandum in writing, but something else to completely nullify the Statute's operation. The thrust of the Statute was that contracts concerning land could not be proved by parol evidence alone. Thus, part performance might be an exception, but it could not, in effect, mean that the underlying contract could be proven by parol evidence. In developing the \"part performance\" exception, a balancing of the competing considerations was required. An important factor in the case law became that the part performance must be \"unequivocally\" related to the alleged contract.\nIreland.\nThe Statute of Frauds, sub-titled \"An Act for Prevention of Frauds and Perjuries\", was passed in 1695 in Ireland. The statute took effect \"from and after the feast day of the nativity of St. John Baptist [24 June], which shall be in the year of our Lord one thousand six hundred ninety-six\", and is one of the few pre-Independence laws that survived the Statute Law Revision (Pre-1922) Act 2005 and the Statute Law Revision Act 2007. It remains largely in force today.\nSome effects of the law have been softened by equity, for example the requirement that all contracts for sale of land be evidenced in writing can be circumvented by reliance on the doctrine of part performance.\nUnited Kingdom.\nEngland and Wales.\nThe Statute of Frauds, dating from 1677, was largely repealed in England and Wales by the Law Reform (Enforcement of Contracts) Act 1954 (2 &amp; 3 Eliz. 2. c. 34). The only provision of it extant is part of Section\u00a04 which means that contracts of guarantee (surety for another's debt) are unenforceable unless evidenced in writing. This requirement is clarified by section 3 of the Mercantile Law Amendment Act 1856 (19 &amp; 20 Vict. c. 97), dated 29 July 1856, which provides that the consideration for the guarantee need not appear in writing or require any necessary inference from a written document.\nSection 6 of the Statute of Frauds Amendment Act 1828 (9 Geo. 4. c .14) (commonly known as Lord Tenterden's Act) was enacted to prevent Section 4 being circumvented by bringing an action against a verbal guarantor for the tort of deceit (the tort in \"Freeman v. Palsey\"). A common summary of the law is \"a verbal guarantee (for a debt) isn't worth the paper it is written on\".\nProvisions in section 4 as to formalities for contracts for the sale of land were repealed by Schedule 7 to the Law of Property Act 1925 (15 &amp; 16 Geo. 5. c. 20), however the requirement that contracts for the sale of land be evidenced in writing was maintained by section 40 of that Act, subsequently replaced by section 2 of the Law of Property (Miscellaneous Provisions) Act 1989 (c. 34).\nScotland.\nSection 6 of the Mercantile Law Amendment Act Scotland 1856 was derived from those parts of section 4 of the Statute of Frauds (1677) which relate to contracts of guarantee and from section 6 of the Statute of Frauds Amendment Act 1828.\nIt was repealed on 1 August 1995 by the Requirements of Writing (Scotland) Act 1995, sections 14(2) and Schedule 5 (with ss. 9(3)(5)(7), 13, 14(3)).\nUnited States.\nIn the United States, for contracts for the sale of goods that fall under the Uniform Commercial Code, additional exceptions may apply:\n* Admission of the existence of a contract by the defendant under oath. However, the contract would only exist for the quantity of goods that were admitted. For instance, if the contract was for 100 televisions but the seller admitted in court that it was for 70 televisions, then the contract would exist only for 70 televisions and not the original 100. \n* Merchant confirmation rule. If one merchant sends a writing sufficient to satisfy the statute of frauds to another merchant and the receiving merchant has reason to know of the contents of the sent confirmation and does not object to the confirmation within 10 days, the confirmation is good to satisfy the statute as to both parties, even if the confirmation was not signed by the party to be charged.\n* The goods were specially manufactured for the buyer and the seller either 1) began manufacturing them, or 2) entered into a third party contract for their manufacture, and the manufacturer cannot without undue burden sell the goods to another person in the seller's ordinary course of business: for example, T-shirts with a Little League baseball team logo or wall-to-wall carpeting for an odd-sized room.\nState laws.\nEvery state has a statute that requires certain types of contracts to be in writing and signed by the party to be charged. The most common requirements are for contracts that involve the sale or transfer of land, and contracts that cannot be completed within one year. When the statute of frauds applies, a typical statute requires that the writing commemorating the agreement identify the contracting parties, recite the subject matter of the contract so that it is reasonably identifiable, and include the important terms and conditions of agreement.\nThe statute of frauds in various states comes in three types:\nColorado.\nColorado has a number of different statutes of frauds applicable to different areas of law.\nTexas.\nIn addition to the statute of frauds as conventionally defined, the State of Texas has two rules that govern the litigation process, each of which also has the character of a statute of frauds. One is a rule of general applicability and requires agreements between counsel (or a party, if self-represented) to be in writing to be enforceable. Tex. R. Civ. P. 11.\nAgreements under Texas Rule of Civil Procedure 11 are called \"Rule 11 Agreements\" and may either concern settlement or any procedural aspect, such as an agreement regarding scheduling, continuances of trial settings, or discovery matters. The rule has existed since 1840 and has contained the filing requirement since 1877. The number designation can cause confusion to non-Texas attorneys because the federal rule 11 is the sanctions rule, whose state-court counterpart has the number designation 13 under the Texas Rules of Civil Procedure (TRCP).\nThe other rule that is in the nature of a statute of frauds governs fee agreements with clients when the attorney is to be compensated based on the outcome of the case. The Texas Government Code requires that \"[a] contingent fee contract for legal services must be in writing and signed by the attorney and client.\" TEX. GOV'T CODE ANN. \u00a7 82.065(a).\nThe classic example is a contingent fee contract in a personal injury case that provides for the claimant's lawyer to receive a certain percentage of the settlement amount (or of the amount awarded by judgment) net of litigation costs, with the percentages typically staggered and increasing based on whether a settlement was obtained before lawsuit is filed, after a lawsuit was filed but before trial, or whether a judgment favorable to the client was obtained through trial. The other scenario is a contingency fee contract based on cost savings achieved (for a client who is a defendant sued for a money judgment) or based on other specified litigation objectives. In those cases, the client will not recover any money from his opponent in the lawsuit, and will have to pay his attorney from his or her own funds in accordance with the terms of the agreement, once the matter is concluded favorably. When the client does not pay, some attorneys then sue the client on the contingency fee contract, or in quantum meruit in the alternative. See, e.g., Shamoun &amp; Norman, LLP v. Hill, 483 S.W.3d 767 (Tex. App.-Dallas 2016), reversed on other grounds by Hill v. Shamoun &amp; Norman, LLP, No. 16-0107 (Tex. April 13, 2018). The attorney-vs-client fee-dispute issue generally does not arise in personal injury cases because the settlement funds from the settling party or judgment-debtor are disbursed through the attorney of the party entitled to them, net of costs and the contingency fee component.\nUniform Commercial Code.\nIn addition to general statutes of frauds, under Article 2 of the Uniform Commercial Code (UCC), every state except Louisiana has adopted an additional statute of frauds that relates to the sale of goods. Pursuant to the UCC, contracts for the sale of goods where the price equals $500 or more fall under the statute of frauds, with the exceptions for professional merchants performing their normal business transactions, and for any custom-made items designed for one specific buyer.\nThe application of the statute of frauds to dealings between merchants has been modified by provisions of the UCC. There is a \"catch-all\" provision in the UCC for personal property not covered by any other specific law, stating that a contract for the sale of such property where the purchase price exceeds $500 is not enforceable unless memorialized by a signed writing. The most recent UCC revision increases the triggering point for the UCC Statute of Frauds to $5,000, but states have been slow to amend their versions of the statute to increase the trigger point.\nFor purposes of the UCC, a defendant who admits the existence of the contract in his pleadings, under oath in a deposition or affidavit, or at trial, may not use the statute of frauds as a defense. However, a statute of frauds defense may still be available under a state's general statute.\nWith respect to securities transactions, the Uniform Commercial Code has abrogated the statute of frauds. The drafters of the most recent revision commented that \"with the increasing use of electronic means of communication, the statute of frauds is unsuited to the realities of the securities business.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29080", "revid": "37878", "url": "https://en.wikipedia.org/wiki?curid=29080", "title": "SI Unit", "text": ""}
{"id": "29081", "revid": "40071619", "url": "https://en.wikipedia.org/wiki?curid=29081", "title": "Sovereign immunity", "text": "Legal doctrine\nSovereign immunity, or crown immunity, is a legal doctrine whereby a sovereign or state cannot commit a legal wrong and is immune from civil suit or criminal prosecution, strictly speaking in modern texts in its own courts. State immunity is a similar, stronger doctrine, that applies to foreign courts.\nHistory.\nSovereign immunity is the original forebear of state immunity based on the classical concept of sovereignty in the sense that a sovereign could not be subjected without his or her approval to the jurisdiction of another. In constitutional monarchies, the sovereign is the historical origin of the authority which creates the courts. Thus the courts had no power to compel the sovereign to be bound by them as they were created by the sovereign for the protection of his or her subjects. This rule was commonly expressed by the popular legal maxim \"rex non potest peccare\", meaning \"the king can do no wrong\".\nForms.\nThere are two forms of sovereign immunity:\nImmunity from suit means that neither a sovereign/head of state in person nor any \"in absentia\" or representative form (nor to a lesser extent the state) can be a defendant or subject of court proceedings, nor in most equivalent forums such as under arbitration awards and tribunal awards/damages.\nImmunity from enforcement means that even if a person succeeds in any way against their sovereign or state, they and the judgment may find themselves without means of enforcement. Separation of powers or natural justice coupled with a political status other than a totalitarian state dictates there be broad exceptions to immunity such as statutes which expressly bind the state (a prime example being constitutional laws) and judicial review.\nWaiver.\nSovereign immunity of a state entity may be waived. A state entity may waive its immunity by:\nBy country.\nAustralia.\nThere is no automatic Crown immunity in Australia, and the Australian Constitution does not establish a state of unfettered immunity of the Crown in respect of the states and the Commonwealth. The Constitution of Australia establishes matters on which the states and the Commonwealth legislate independently of each other; in practice this means the states legislate on some things and the Commonwealth legislates on others. In some circumstances, this can create ambiguity as to the applicability of legislation where there is no clearly established Crown immunity. The Australian Constitution does however, in s. 109, declare that, \"When a law of a State is inconsistent with a law of the Commonwealth, the latter shall prevail, and the former shall, to the extent of the inconsistency, be invalid.\" Based on this, depending on the context of application and whether a particular statute infringes on the executive powers of the state or the Commonwealth the Crown may or may not be immune from any particular statute.\nMany Acts passed in Australia, both at the state and at the federal level, contain a section declaring whether the Act binds the Crown, and, if so, in what respect:\nWhile there is no ambiguity about the first aspect of this declaration about binding the Crown with respect to the state in question, there have been several cases about the interpretation of the second aspect extending it to the Crown in its other capacities. Rulings by the High Court of Australia on specific matters of conflict between the application of states laws on Commonwealth agencies have provided the interpretation that the Crown in all of its other capacities includes the Commonwealth, therefore if a state Act contains this text then the Act may bind the Commonwealth, subject to the s. 109 test of inconsistency.\nA landmark case which set a precedent for challenging broad Crown immunity and established tests for the applicability of state laws on the Commonwealth was \"Henderson v Defence Housing Authority\" in 1997. This case involved the arbitration of a dispute between Mr. Henderson and the Defence Housing Authority (DHA). Mr. Henderson owned a house which the DHA had leased to provide housing to members of the Australian Defence Force (ADF). Under the NSW \"Residential Tenancies Act 1997\", Mr. Henderson sought orders from the Residential Tenancies Tribunal to enter the premises for the purposes of conducting inspections. In response, DHA claimed that as a Commonwealth agency the legislation of NSW did not apply to it and further sought writs of prohibition attempting to restrain Mr. Henderson from pursuing the matter further. Up until this point the Commonwealth and its agencies claimed an unfettered immunity from state legislation and had used s. 109 to justify this position, specifically that the NSW Act was in conflict with the Act which created the DHA and s. 109 of the constitution applied. Mr. Henderson took the case to the High Court and a panel of seven justices to arbitrate the matter. By a majority decision of six to one the court ruled that the DHA was bound by the NSW Act on the basis that the NSW Act did not limit, deny or restrict the activities of the DHA but sought to regulate them, an important distinction which was further explained in the rulings of several of the justices. It was ruled that the NSW Act was one of general application and therefore the Crown (in respect of the Commonwealth) could not be immune from it, citing other cases in which the same ruling had been made and that it was contrary to the rule of law. As a result of this case, the Commonwealth cannot claim a broad constitutional immunity from state legislation.\nIn practice, three tests have been developed to determine whether a state law applies to the Commonwealth and vice versa:\nIf these three tests are satisfied, then the Act binds the Crown in respect of the Commonwealth. In Australia, there is no clear automatic Crown immunity or lack of it; as such there is a rebuttable presumption that the Crown is not bound by a statute, as noted in \"Bropho v State of Western Australia\". The Crown's immunity may also apply to other parties in certain circumstances, as held in \"Australian Competition and Consumer Commission v Baxter Healthcare\".\nBelgium.\nArticle 88 of the Constitution of Belgium states: \"The King's person is inviolable; his ministers are accountable.\"\nBhutan.\nAccording to the constitution of Bhutan, the monarch is not answerable in a court of law for his or her actions.\nCanada.\nCanada inherited the common law version of Crown immunity from British law. However, over time, the scope of Crown immunity has been steadily reduced by statute law. As of 1994, section 14 of Alberta's Interpretation Act states, \"no enactment is binding on His Majesty or affects His Majesty or His Majesty's rights or prerogatives in any manner, unless the enactment expressly states that it binds His Majesty.\" However, in more recent times \"all Canadian provinces\u00a0... and the federal government (the Crown Liability Act) have now rectified this anomaly by passing legislation which leaves the Crown liable in tort as a normal person would be. Thus, the tort liability of the government is a relatively new development in Canada, statute-based, and is not a fruit of common law.\"\nSince 1918, it has been held that provincial legislatures cannot bind the federal Crown, as Charles Fitzpatrick noted in \"Gauthier v The King\": \"Provincial legislation cannot [i.e., of its own force] take away or abridge any privilege of the Crown in right of the Dominion.\"\nIt has also been a constitutional convention that the Crown in right of each province is immune from the jurisdiction of the courts in other provinces. However, this is now in question.\nLieutenant governors do not enjoy the same immunity as the sovereign in matters not relating to the powers of the office. In 2013, the Supreme Court refused to hear the request of former Lieutenant Governor of Quebec Lise Thibault to have charges against her dropped. She was being prosecuted by the Attorney General of Quebec for misappropriation of public funds, but invoked royal immunity on the basis that \"the Queen can do no wrong\". As per convention, the court did not disclose its reasons for not considering the matter. Thibault later petitioned the Court of Quebec for the same motives. Judge St-Cyr again rejected her demand, noting that constitutional law does not grant a lieutenant governor the same benefits as the monarch and that, in her case, royal immunity would only apply to actions involving official state functions, not personal ones. She was eventually found guilty and sentenced to 18 months in jail, but was granted conditional release after serving six months.\nChina.\nChina has consistently claimed that a basic principle of international law is for states and their property to have absolute sovereign immunity. China objects to restrictive sovereign immunity. It is held that a state can waive its immunity by voluntarily stating so, but that should a government intervene in a suit (e.g. to make protests), it should not be viewed as waiver of immunity. Chinese state-owned companies considered instrumental to the state have claimed sovereign immunity in lawsuits brought against them in foreign courts before. China's view is that sovereign immunity is a lawful right and interest that their enterprises are entitled to protect. Some examples of Chinese state-owned companies that have claimed sovereign immunity in foreign lawsuits are the Aviation Industry Corporation of China (AVIC) and China National Building Material.\nIn 2023, China's national legislature \u2013 the Standing Committee of the National People's Congress \u2013 passed the Foreign State Immunity Law, which changed China's sovereign immunity regime to a restrictive one.\nHong Kong.\nIn 2011, the Hong Kong Court of Final Appeal ruled that absolute sovereign immunity applies in Hong Kong, as the Court found that Hong Kong, as a Special Administrative Region of China, could not have policies on state immunity that were inconsistent with China. The ruling was an outcome of the \"Democratic Republic of the Congo v FG Hemisphere Associates\" case in 2011. \nIn 2023, China's national legislature \u2013 the Standing Committee of the National People's Congress \u2013 passed the Foreign State Immunity Law, which changed China's sovereign immunity regime to a restrictive one. In accordance with the Hong Kong Court of Final Appeal's decision in \"Congo\" and the NPCSC's corresponding interpretation of the Basic Law in 2011, the new national law applies in Hong Kong, even though it has yet to be formally applied to Hong Kong through Annex III of the Basic Law. As such, restrictive immunity applies in Hong Kong.\n\"Democratic Republic of the Congo v FG Hemisphere Associates\" (2011).\nThe Democratic Republic of the Congo and its state-owned electricity company (SNEL) defaulted on payments of a debt owed to an energy company, Energoinvest. During arbitration, Energoinvest was awarded damages against the Congolese government and SNEL. This was reassigned by Energoinvest to FG Hemisphere Associates LLC.\nFG Hemisphere subsequently learned that the Congolese government entered into a separate joint venture with Chinese companies later, in which the Congolese government would be paid US$221 million in mining entry fees. As a result, FG Hemisphere applied to collect these fees in order to enforce the earlier arbitral award. The Congolese government asserted sovereign immunity in the legal proceedings. This was eventually brought to the Hong Kong Court of Final Appeal, when the Congolese government fought to overturn an earlier Court of Appeal decision which had ruled that:\nThe Hong Kong Court of Final Appeal ruled 3:2 that the Congolese government had not waived its immunity in the Hong Kong courts, and that as a Special Administrative Region of China, Hong Kong could not have policies on state immunity that were inconsistent with China's. Therefore, the doctrine of sovereign immunity applied in Hong Kong should be absolute, and may be invoked when jurisdiction is sought in the foreign court in relation to an application to enforce a foreign judgment or arbitral award, or when execution is sought against assets in the foreign state. This means that sovereign states are absolutely immune to the jurisdiction of Hong Kong courts, including in commercial claims, unless the state waives its immunity. In order to waive immunity, there must be express, unequivocal submission to the jurisdiction of the Hong Kong courts \"in the face of the court\". Claimants should establish that the state party has waived their entitlement to immunity at the relevant stage, before proceedings can occur in court.\nDenmark.\nArticle 13 of the Constitution of Denmark states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nAccordingly, the monarch cannot be sued in his or her personal capacity. On the other hand, this immunity from lawsuits does not extend to the state as such and article 63 explicitly authorises the courts to judge the executive authority: \"The courts of justice shall be empowered to decide any question relating to the scope of the executive's authority; though any person wishing to question such authority shall not, by taking the case to the courts of justice, avoid temporary compliance with orders given by the executive authority.\" Furthermore, no other member of the royal family can be prosecuted for any crime under Article 25 of the old absolutist constitution Lex Regia (The King's Law), currently still valid, which states: \"They shall answer to no magistrate judges, but their first and last Judge shall be the King, or to whom He to that decrees.\"\nFinland.\nThe President of Finland has immunity from prosecution according to Article 113 of the Constitution, which applies to their official activities. If the president is suspected of treason or a crime against humanity in the course of their official duties, the parliament can, with a &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3\u20444 majority, decide to bring charges to the national court. The president cannot be charged for other crimes committed in the performance of their duties, but may remain accountable for acts committed outside of their office in the same way as other citizens.\nHoly See.\nThe Holy See, the jurisdiction of the Catholic Church of which the pope is head (often referred to by metonymy as the Vatican or Vatican City State, a distinct entity), claims sovereign immunity for the pope, supported by many international agreements.\nIceland.\nAccording to article 11 of the Constitution of Iceland the president can only be held accountable and be prosecuted with the consent of parliament.\nIndia.\nAccording to Article 361 of the Constitution of India no legal action in the court of law can be taken against President of India and the governors of states of India as long as that person is holding either office. However, they can be impeached and then sued for their actions.\nIreland.\nIn \"Byrne v. Ireland\", the Supreme Court of Ireland declared that sovereign immunity had not survived the creation of the Irish Free State in 1922, and that accordingly the state could be sued for and held vicariously liable for the acts and omissions of its servants and agents.\nItaly.\nAccording to the Constitution, a President of the Italian Republic is not accountable, and is not responsible for any act of their office, unless they have committed high treason or attempted to subvert the Constitution, as stated in Article 90:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The President of the Republic is not responsible for the actions performed in the exercise of his functions, except in the cases of high treason or attempt against the Constitution. In such cases, he may be impeached by Parliament in joint session, with an absolute majority of its members.\nThe Italian Penal Code makes it a criminal offence to insult the honor and prestige of the President (Art. 278), and until 2006 it was an offence to publicly give the President responsibility for actions of the Government (Art. 279 \u2013 abrogated).\nJapan.\nArticle 17 of the Constitution of Japan states: \"Every person may sue for redress as provided by law from the State or a public entity, in case he has suffered damage through illegal act of any public official.\" The was made according to this article. Officials who commit torts themselves are not liable, although the State or a public entity has the right to obtain reimbursement from the officers if there is intent or gross negligence on the part of them. The Administrative Litigation Act enables the people to file lawsuits involving the government of Japan.\nOn November 20, 1989, the Supreme Court ruled that it does not have judicial power over the Emperor because he is \"the symbol of the State and of the unity of the people\".\nMalaysia.\nIn Malaysia, a amendment to the constitution in 1993 during the premiership of Mahathir Mohamad abolished royal immunity from prosecution, allowing both the king and state rulers to be tried in a Special Court. This was previously impossible because every ruler of Malaysia was stated to be protected from being brought to court due to their royal status.\nNetherlands.\nSince 1848, article 42 of the Dutch constitution states: \"The king is immune from prosecution; the ministers are responsible\".\nNigeria.\nSection 308 of the Nigerian constitution of 1999 provides immunity from court proceedings, i.e., proceedings that will compel their attendance in favour of elected executive officers, namely the President and his vice and the governors of the states and the deputies. This immunity extends to acts done in their official capacities so that they are not responsible for acts done on behalf of the state. However, this immunity does not extend to acts done in abuse of the powers of their office of which they are liable upon the expiration of their tenure. It is important to note that the judiciary has absolute immunity for actions decisions taken in their official capacity.\nNorway.\nArticle 5 of the Constitution of Norway states: \"The King's person is sacred; he cannot be censured or accused. The responsibility\nrests with his Council.\"\nAccordingly, the monarch cannot be prosecuted or sued in his or her personal capacity, but this immunity does not extend to the state as such. Neither does immunity extend to the monarch in his capacity as an owner or stakeholder in real property, or as an employer, provided that the suit does not allege personal responsibility for the monarch.\nPhilippines.\nArticle XVI, Section 3 of the 1987 Constitution currently in force states: \"The State may not be sued without its consent.\"\nSpain.\nThe Spanish monarch is personally immune from prosecution for acts committed by government ministers in his or her name, according to Title II, Section 56, Subsection 3 of the Spanish Constitution of 1978.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe constitution did not state whether a monarch who abdicated retains legal immunity, prior to the abdication of Juan Carlos I in 2014, but the government was planning to make changes to allow this. Legislation was passed, although unlike his previous immunity, the new legislation did not completely shield Juan Carlos, who was obliged to answer to the Supreme Court in a similar type of protection afforded to many high-ranking civil servants and politicians in Spain. The legislation stipulated that all outstanding legal matters relating to the former king be suspended and passed \"immediately\" to the Supreme Court.\nSri Lanka.\nBy the Constitution of Sri Lanka, a sitting president of Sri Lanka has sovereign immunity.\nSweden.\nChapter 5, Article 8 of the Swedish Constitution states: \"The King or Queen who is Head of State cannot be prosecuted for his or her actions. Nor can a Regent be prosecuted for his or her actions as Head of State.\" This only concerns the monarch as a private person, since they do not appoint the government nor do any public officials act in their name. It does not concern other members of the Swedish royal family, except in such cases as they are exercising the office of regent when the monarch is unable to serve. It is a disputed matter among Swedish constitutional lawyers whether the article also implies that the monarch is immune from lawsuits in civil cases which do not involve prosecution.\nSingapore.\nIn Singapore, state immunities are codified in the http:// , which closely resembles the United Kingdom's State Immunity Act 1978. Singapore's State Immunity Act has phrases identical to that of Section 9 of United Kingdom's State Immunity Act, and does not allow a foreign state, which has agreed to submit a dispute to arbitration, to claim jurisdictional immunity in judicial proceedings relating to the agreed arbitration, i.e. \"where a State has agreed in writing to submit a dispute which has arisen, or may arise, to arbitration, the state is not immune as respects proceedings in the courts in Singapore which relate to the arbitration\".\nThe President of Singapore does to a certain extent have sovereign immunity subjected to clause 22K(4).\nUnited Kingdom.\nImmunity in proceedings.\nHistorically, the general rule in the United Kingdom has been that the Crown has never been liable to be prosecuted or proceeded against in either criminal or civil cases. The only means by which civil proceedings could be brought were:\nThe position was drastically altered by the Crown Proceedings Act 1947 which made the Crown (when acting as the government) liable as of right in proceedings where it was previously only liable by virtue of a grant of a fiat. With limited exceptions, this had the effect of allowing proceedings for tort and contract to be brought against the Crown. Proceedings to bring writs of mandamus and prohibition were always available against ministers, because their actions derive from the royal prerogative.\nCriminal proceedings are still prohibited from being brought against His Majesty's Government unless expressly permitted by the Crown Proceedings Act.\nAs the Crown Proceedings Act only affected the law in respect of acts carried on by or on behalf of the British government, the monarch remains personally immune from criminal and civil actions. However, civil proceedings can, in theory, still be brought using the two original mechanisms outlined above \u2013 by petition of right or by suit against the Attorney General for a declaration.\nOther immunities.\nThe monarch is immune to arrest in all cases; members of the royal household are immune from arrest in civil proceedings. No arrest can be made \"in the monarch's presence\", or within the \"verges\" of a royal palace. When a royal palace is used as a residence (regardless of whether the monarch is actually living there at the time), judicial processes cannot be executed within that palace.\nThe monarch's goods cannot be taken under a writ of execution, nor can distress be levied on land in his/her possession. Chattels owned by the Crown, but present on another's land, cannot be taken in execution or for distress. The Crown is not subject to foreclosure.\nAs of 2022, there were more than 160 laws granting express immunity to the monarch or his/her property in some respects. For instance, employees of the monarchy cannot pursue anti-discrimination complaints such as those under the Equality Act 2010. The monarchy is exempt from numerous other workers' rights, health and safety, or pensions laws. Government employees such as environmental inspectors are banned from entering the monarch's property without his/her permission. The monarch is also exempt from numerous taxes, although Queen Elizabeth II did pay some taxes voluntarily. Some of the odder exceptions for the monarch are included in laws against private persons setting off nuclear explosions, or regulating the sale of alcohol after midnight.\nUnited States.\nIn United States law, state, federal, and tribal governments generally enjoy immunity from lawsuits. Local governments typically enjoy immunity from some forms of suit, particularly in tort.\nIn the US, sovereign immunity falls into two categories:\nIn some situations, sovereign immunity may have been waived by law, for example allowing lawsuits to enforce constitutional rights (such as requiring compensation for seized property) or specific legal requirements (like government projects that must perform environmental studies). This permits lawsuits against the government as a legal person, or against specific government officials in their official capacity (meaning they are not personally liable, but they are named in lawsuits, and the next occupant of the office would inherit the lawsuit).\nGovernment employees as individuals may be covered by either type, depending on their function. Police generally enjoy qualified immunity; judicial immunity is a specific form of absolute immunity that applies to judges. \nFederal sovereign immunity.\nThe federal government of the United States has sovereign immunity and may not be sued anywhere in the United States unless it has waived its immunity or consented to suit. The United States has waived sovereign immunity to a limited extent, mainly through the Federal Tort Claims Act, which waives the immunity if a tortious act of a federal employee causes damage, and the Tucker Act, which waives the immunity over claims arising out of contracts to which the federal government is a party. As a sovereign, the United States is immune from suit unless it unequivocally consents to being sued. The United States Supreme Court in \"Price v. United States and Osage Indians\" observed: \"It is an axiom of our jurisprudence. The government is not liable to suit unless it consents thereto, and its liability in suit cannot be extended beyond the plain language of the statute authorizing it.\"\nState sovereign immunity.\nIn \"Hans v. Louisiana\" (1890), the Supreme Court of the United States held that the Eleventh Amendment (1795) re-affirms that states possess sovereign immunity and are therefore generally immune from being sued in federal court without their consent. In later cases, the Supreme Court has strengthened state sovereign immunity considerably. In \"Blatchford v. Native Village of Noatak\" (1991), the court explained that\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;we have understood the Eleventh Amendment to stand not so much for what it says, but for the presupposition of our constitutional structure which it confirms: that the States entered the federal system with their sovereignty intact; that the judicial authority in Article III is limited by this sovereignty, . . . and that a State will therefore not be subject to suit in federal court unless it has consented to suit, either expressly or in the \"plan of the convention.\"\nIn \"Alden v. Maine\" (1999), the Court explained that while it has \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;sometimes referred to the States' immunity from suit as \"Eleventh Amendment immunity\"[,] [that] phrase is [a] convenient shorthand but something of a misnomer, for the sovereign immunity of the States neither derives from, nor is limited by, the terms of the Eleventh Amendment. Rather, as the Constitution's structure, its history, and the authoritative interpretations by this Court make clear, the States' immunity from suit is a fundamental aspect of the sovereignty which the States enjoyed before the ratification of the Constitution, and which they retain today (either literally or by virtue of their admission into the Union upon an equal footing with the other States) except as altered by the plan of the Convention or certain constitutional Amendments.\nWriting for the Court in \"Alden\", Justice Anthony Kennedy argued that in view of this, and given the limited nature of congressional power delegated by the original unamended Constitution, the court could not \"conclude that the specific Article I powers delegated to Congress necessarily include, by virtue of the Necessary and Proper Clause or otherwise, the incidental authority to subject the States to private suits as a means of achieving objectives otherwise within the scope of the enumerated powers.\"\nHowever, other cases have determined that a \"consequence of [the] Court's recognition of preratification sovereignty as the source of immunity from suit is that only States and arms of the State possess immunity from suits authorized by federal law\". Thus, cities and municipalities lack sovereign immunity. Counties are not generally considered to have sovereign immunity, even when they \"exercise a 'slice of state power,'\" nor are school districts.\nAdditionally, Congress can abrogate state sovereign immunity when it acts pursuant to powers delegated to it by any amendments ratified after the Eleventh Amendment. The abrogation doctrine, established by the Supreme Court in \"Fitzpatrick v. Bitzer\" (1976), is most often implicated in cases that involve Section 5 of the Fourteenth Amendment, which explicitly allows Congress to enforce its guarantees on the states.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29082", "revid": "45853341", "url": "https://en.wikipedia.org/wiki?curid=29082", "title": "Social geography", "text": "Branch of human geography\nSocial geography is the branch of human geography that is interested in the relationships between society and space, and is most closely related to social theory in general and sociology in particular, dealing with the relation of social phenomena and its spatial components. Though the term itself has a tradition of more than 100 years, there is no consensus on its explicit content. In 1968, Anne Buttimer noted that \"[w]ith some notable exceptions, (...) social geography can be considered a field created and cultivated by a number of individual scholars rather than an academic tradition built up within particular schools\". Since then, despite some calls for convergence centred on the structure and agency debate, its methodological, theoretical and topical diversity has spread even more, leading to numerous definitions of social geography and, therefore, contemporary scholars of the discipline identifying a great variety of different \"social geographies\". However, as Benno Werlen remarked, these different perceptions are nothing else than different answers to the same two (sets of) questions, which refer to the spatial constitution of society on the one hand, and to the spatial expression of social processes on the other.\nThe different conceptions of social geography have also been overlapping with other sub-fields of geography and, to a lesser extent, sociology. When the term emerged within the Anglo-American tradition during the 1960s, it was basically applied as a synonym for the search for patterns in the distribution of social groups, thus being closely connected to urban geography and urban sociology. In the 1970s, the focus of debate within American human geography lay on political economic processes (though there also was a considerable number of accounts for a phenomenological perspective on social geography), while in the 1990s, geographical thought was heavily influenced by the \"cultural turn\". Both times, as Neil Smith noted, these approaches \"claimed authority over the 'social'\". In the American tradition, the concept of cultural geography has a much more distinguished history than social geography, and encompasses research areas that would be conceptualized as \"social\" elsewhere. In contrast, within some continental European traditions, social geography was and still is considered an approach to human geography rather than a sub-discipline, or even as identical to human geography in general.\nHistory.\nBefore World War II.\nThe term \"social geography\" (or rather \"g\u00e9ographie sociale\") originates from France, where it was used both by geographer \u00c9lis\u00e9e Reclus and by sociologists of the Le Play School, perhaps independently from each other. In fact, the first proven occurrence of the term derives from a review of Reclus' \"Nouvelle g\u00e9ographie universelle\" from 1884, written by Paul de Rousiers, a member of the Le Play School. Reclus himself used the expression in several letters, the first one dating from 1895, and in his last work \"L'Homme et la terre\" from 1905. The first person to employ the term as part of a publication's title was Edmond Demolins, another member of the Le Play School, whose article \"G\u00e9ographie sociale de la France\" was published in 1896 and 1897. After the death of Reclus as well as the main proponents of Le Play's ideas, and with \u00c9mile Durkheim turning away from his early concept of social morphology, Paul Vidal de la Blache, who noted that geography \"is a science of places and not a science of men\", remained the most influential figure of French geography. One of his students, Camille Vallaux, wrote the two-volume book \"G\u00e9ographie sociale\", published in 1908 and 1911. Jean Brunhes, one of Vidal's most influential disciples, included a level of (spatial) interactions among groups into his fourfold structure of human geography. Until the Second World War, no more theoretical framework for social geography was developed, though, leading to a concentration on rather descriptive rural and regional geography. However, Vidal's works were influential for the historical Annales School, who also shared the rural bias with the contemporary geographers, and Durkheim's concept of social morphology was later developed and set in connection with social geography by sociologists Marcel Mauss and Maurice Halbwachs.\nThe first person in the Anglo-American tradition to use the term \"social geography\" was George Wilson Hoke, whose paper \"The Study of Social Geography\" was published in 1907, yet there is no indication it had any academic impact. Le Play's work, however, was taken up in Britain by Patrick Geddes and Andrew John Herbertson. Percy M. Roxby, a former student of Herbertson, in 1930 identified social geography as one of human geography's four main branches. By contrast, the American academic geography of that time was dominated by the Berkeley School of Cultural Geography led by Carl O. Sauer, while the spatial distribution of social groups was already studied by the Chicago School of Sociology. Harlan H. Barrows, a geographer at the University of Chicago, nevertheless regarded social geography as one of the three major divisions of geography.\nAnother pre-war concept that combined elements of sociology and geography was the one established by Dutch sociologist Sebald Rudolf Steinmetz and his Amsterdam School of Sociography. However, it lacked a definitive subject, being a combination of geography and ethnography created as the more concrete counterpart to the rather theoretical sociology. In contrast, the Utrecht School of Social geography, which emerged in the early 1930s, sought to study the relationship between social groups and their living spaces.\nPost-war period.\nContinental Europe.\nIn the German-language geography, this focus on the connection between social groups and the landscape was further developed by Hans Bobek and Wolfgang Hartke after the Second World War. For Bobek, groups of \"Lebensformen\" (patterns of life)\u2014influenced by social factors\u2014that formed the landscape, were at the center of his social geographical analysis. In a similar approach, Hartke considered the landscape a source for indices or traces of certain social groups' behaviour. The best-known example of this perspective was the concept of \"Sozialbrache\" (social-fallow), i.e. the abandoning of tillage as an indicator for occupational shifts away from agriculture.\nThough the French \"G\u00e9ographie Sociale\" had been a great influence especially on Hartke's ideas, no such distinct school of thought formed within the French human geography. Nonetheless, Albert Demangeon paved the way for a number of more systematic conceptualizations of the field with his (posthumously published) notion that social groups ought to be within the center of human geographical analysis. That task was carried out by Pierre George and Maximilien Sorre, among others. Then a Marxist, George's stance was dominated by a socio-economic rationale, but without the structuralist interpretations found in the works of some the French sociologists of the time. However, it was another French Marxist, the sociologist Henri Lefebvre, who introduced the concept of the (social) production of space. He had written on that and related topics since the 1930s, but fully expounded it in \"La Production de L'Espace\" as late as 1974. Sorre developed a schema of society related to the ecological idea of habitat, which was applied to an urban context by the sociologist Paul-Henry Chombart de Lauwe. For the Dutch geographer Christiaan van Paassen, the world consisted of socio-spatial entities of different scales formed by what he referred to as a \"syn-ecological complex\", an idea influenced by existentialism.\nA more analytical ecological approach on human geography was the one developed by Edgar Kant in his native Estonia in the 1930s and later at Lund University, which he called \"anthropo-ecology\". His awareness of the temporal dimension of social life would lead to the formation of time geography through the works of Torsten H\u00e4gerstrand and Sven Godlund.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29083", "revid": "19569748", "url": "https://en.wikipedia.org/wiki?curid=29083", "title": "Segway", "text": "Two-wheeled, self-balancing personal vehicle\nA Segway is a two-wheeled, self-balancing personal transporter device invented by Dean Kamen. The name is a registered trademark of Segway Inc. It was brought to market in 2001 as the Segway HT, and then subsequently as the Segway PT. \"HT\" is an initialism for \"human transporter\" and \"PT\" for \"personal transporter.\"\nNinebot, a Beijing-based transportation robotics startup rival, acquired Segway Inc. in April 2015, broadening the company to include other transportation devices. In June 2020, it was announced that it would no longer make the Segway PT.\nHistory.\nIndependent company.\nThe Segway PT, referred to during development and initial marketing as the Segway HT, was developed from the self-balancing iBOT wheelchair which was initially developed at University of Plymouth, in conjunction with BAE Systems and Sumitomo Precision Products. The first patent of human transporter was filed in 1994 and granted in 1997, followed by others, including one submitted in June 1999 and granted in October 2001.\nPrior to its introduction, a news report about a proposal for a book about the invention, development, and financing of the Segway PT led to speculation about the device and its importance. John Doerr speculated that it would be more important than the Internet. \"South Park\" devoted an episode to making fun of the hype before the product was released. Steve Jobs was quoted as saying that it was \"as big a deal as the PC\", (he later expressed a negative opinion, saying that it \"sucked\", presumably referring to \"the design\" \u2013 but also referred to the (presumably high) price point, asking, \"You're \"sure\" your market is upscale consumers for transportation?\") The device was unveiled on 3 December 2001, following months of public speculation, in Bryant Park, New York City, on the ABC News morning program \"Good Morning America\", with the first units delivered to customers in early 2002.\nThe original Segway PT models featured three speed settings: , with faster turning, and . Steering of early versions was controlled using a twist grip that varied the speeds of the two motors. The range of the p-Series was on a fully charged nickel metal hydride (NiMH) battery with a recharge time of four to six hours. In September 2003, the Segway PT was recalled, because if users ignored repeated low-battery warnings on the PTs, it could ultimately lead them to fall.\nIn August 2006, Segway Inc. discontinued all previous models and introduced the i2 and x2 products, which were steered by leaning the handlebars to the right or left, had a maximum speed of from a pair of Brushless DC electric motors with regenerative braking and a range of up to , depending on terrain, riding style, and state of the batteries. Recharging took eight to ten hours. The i2 and x2 also introduced the wireless InfoKey which could show mileage and a trip odometer, and put the vehicle into security mode, which locked the wheels and set off an alarm if it was moved, and could also be used to turn on the PT from up to away.\nSegway Inc. was acquired by British businessman Jimi Heselden from its U.S. inventor Dean Kamen in December 2009. A year later, Heselden died after he \"plunged into the River Wharfe while riding a rugged country version\" of Segway PT.\nVersions of the product prior to 2011 included (in order of release):\nIn March 2014, Segway Inc. announced third generation designs, including the i2 SE and x2 SE sport, new LeanSteer frame and powerbase designs, with integrated lighting.\nSubsidiary of Ninebot.\nNinebot, a Beijing-based transportation robotics startup and a rival of Segway Inc., acquired Segway Inc. in April 2015, having raised $80M from Xiaomi and Sequoia Capital. The acquisition came months after the U.S. International Trade Commission agreed to investigate Segway Inc.'s claim that Ninebot and other companies were infringing on its patents and copyrights. Segway Inc. requested the blocking of imports of competing scooters into the United States.\nIn June 2016, Segway Inc. launched the Segway miniPRO, a smaller self-balancing scooter.\nEnd of production.\nOnly 140,000 units were sold during the lifetime of the product, and in the later years the Segway PT only made up 1.5% of total company profit. Factors contributing to the end of production include the price (US$5,000 at launch), and the learning curve in learning to balance on a Segway PT which has led to notable accidents involving Usain Bolt, George W. Bush, Ellen DeGeneres, Ian Healy, and Segway Inc. previous owner Jimi Heselden. While the Segway has remained popular for security and tourism, electric scooters have been more popular for personal mobility.\nUTVs.\nIn February 2022, Segway entered the UTV (Utility Terrain Vehicle) market.\nProducts.\nAt the end of production in 2020, Segway Inc. was selling these five self-balancing scooters:\nATV: AT5 S, AT5 L, AT6 S, AT6 L&lt;br&gt;UTV: UT10, UT10 Crew&lt;br&gt;SSV (SxS): SX10 - E, SX10 - X, SX10 - WIDE, SX20 - TURBO, SX20 - HYBRID\nTechnology.\nThe dynamics of the Segway PT are similar to a classic control problem, the inverted pendulum. It uses brushless DC electric motors in each wheel powered by lithium-ion batteries with balance achieved using tilt sensors, and gyroscopic sensors developed by BAE Systems' Advanced Technology Centre.\nUsage.\nThe special police forces trained to protect the public during the 2008 Summer Olympics used the Segway for mobility.\nIn 2011, the Segway i2 was being marketed to the emergency medical services community.\nIn 2018, the police of Stockholm adopted Segway i2 as a transportation method for the patrollers of the old town.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29084", "revid": "29463730", "url": "https://en.wikipedia.org/wiki?curid=29084", "title": "Slayers", "text": "Japanese light novel series and its franchise\n&lt;/table&gt;\n is a Japanese light novel series written by Hajime Kanzaka and illustrated by Rui Araizumi. The novels have been serialized in \"Dragon Magazine\" since 1989, before being published into individual volumes. They follow the adventures of teenage sorceress Lina Inverse and her companions as they journey through their world. Using powerful magic and swordsmanship they battle overreaching wizards, demons seeking to destroy the world, and an occasional hapless gang of bandits.\n\"Slayers\" inspired several spin-off novel series and has been adapted into numerous manga titles, anime television series, anime films, OVA series, role-playing video games, and other media. Including the spin-off series and digital copies, the novels have sold over 22 million copies. The anime series is considered to be one of the most popular of the 1990s.\nPlot.\nSetting.\nIn the \"Slayers\" universe, the ultimate being is the Lord of Nightmares, the creator of at least four parallel worlds. An artifact known as the Claire Bible contains information about the Lord of Nightmares' task to regain its \"true form\", which is only attainable by destroying these worlds and returning them to the chaos (sea of darkness) that it itself is. For unexplained reasons, though, the Lord of Nightmares has not acted upon this desire by itself so far. On each of these worlds are gods (\"shinzoku\", lit. \"godly race\") and demons (\"mazoku\", lit. \"demon race\"), fighting without end. Should the gods win the war in a world, that world will be at peace. Should the monsters win, the world will be destroyed and returned to the Sea of Chaos.\nIn the world where the \"Slayers\" takes place, Flare Dragon Ceifeed and the Ruby-Eye Shabranigdu are, respectively, the supreme god and demon. Long ago, their war ended more or less in a stalemate, when Ceifeed was able to split Shabranigdu's existence into seven pieces in order to prevent him from coming back to life, then seal them within human souls. As the souls are reincarnated, the individual fragments would wear down until Shabranigdu himself would be destroyed. However, Ceifeed was so exhausted by this that he himself sank into the Sea of Chaos, leaving behind four parts of himself in the world. A millennium before the events in \"Slayers\", one of Ruby-Eye's fragments (which was sealed in the body of Lei Magnus, a very powerful sorcerer) revived and began the against one of the parts of Ceifeed, the Water Dragon King, also known as Aqualord Ragradia. Ultimately, the piece of Shabranigdu won, but Aqualord, using the last remnants of her power, sealed him into a block of magical ice within the Kataart Mountains. Nevertheless, Shabranigdu's lieutenants remained at liberty, sealing a part of the world within a magical barrier, through which only demons could pass.\nThere are four types of magic within the \"Slayers\" universe: Black, White, Shamanistic, and Holy. Black magic spells, such as the famous Dragon Slave, call directly on the powers of the demons and are capable of causing enormous damage. White magic spells are of an obscure origin and are used for healing or protection. Shamanistic magic is focused on manipulation and alteration of the basic elements of the natural world (earth, wind, fire, water and spirit) and contains spells for both offense and convenience, such as Lei Wing, Fireball, or Elemekia Lance. Holy magic uses the power of the gods, but the aforementioned barrier made its usage impossible for anyone inside before the death of the demon Hellmaster Phibrizzo. As a rule, demons can only be harmed by astral shamanistic magic, holy magic, or black magic which draws power from another demon with greater might than the target.\nAbove all other magic, however, are the immensely destructive spells drawing power from the Lord of Nightmares. The two spells of this class are the Ragna Blade, capable of cutting through any obstacle or being, and the Giga Slave, which can kill any opponent, but which could also destroy the world itself if the spell is miscast. Some have claimed that these terrible spells, drawing their power directly from the Lord of Nightmares, constitute a fifth form of magic: Chaos magic.\nStory.\nThe protagonist of \"Slayers\" is Lina Inverse, a teenage wandering genius sorceress with many nicknames and much infamy attached to her that she refuses to acknowledge. Lina narrates (within the novels) the history of her various adventures, ranging from whimsical and silly to dramatic to even outright world-threatening crises, in which she becomes involved along with her traveling companions everywhere she goes.\nProduction.\nThe first \"Slayers\" light novel was written by Hajime Kanzaka for entrance into Fujimi Fantasia Bunko's first annual Fantasia Ch\u014dhen Sh\u014dsetsu Awards in 1989. After it won, the new author was asked to create a follow-up. Kanzaka initially thought this was an impossible task as the characters had already defeated the Dark Lord. He called the second book a turning point for him and said it was initially very difficult to write. However, as soon as he added the \"spike-wolves and stuff\", from his love of y\u014dkai and kaiju, the \"words just flew off the page\". Kanzaka set the second book in a city so that Lina could not solve the story by simply casting one big spell. He said that this taught him how using circumstances and setting could change the \"flavor\" of a story. The author also said that the second book is intentionally \"heavier\" than the first.\nKanzaka described his writing process as like trying to put together puzzle pieces that have been scattered about, figuring stuff out as he goes instead of following an outline written beforehand. As a new author, he said he was not good at submitting plot summaries to his supervisor, who wanted them before he started writing. When the supervisor passively accepted the plot summary of the third \"Slayers\" novel, but was then ecstatic with the finished book, he stopped asking for plot summaries. Kanzaka assumed that he had finally realized that the finished story was always going to widely diverge from the initial summary. The first three books were written as the author thought up stories, but volume four on tell a grander epic. Because the first novel was written as a one-off before evolving into a series, there are some inconsistencies with the later installments. A few of these inconsistencies were corrected in the 2008 reprints.\nKanzaka stated the reason Zelgadis and Amelia do not appear in \"part 2\" is because of the plot point concerning a character's death. Although he speculated he could have written around the healing spells, it would have taken a lot of extra steps to get there and dragged everything out a lot longer than necessary. In the afterward of the fifteenth novel, the original final installment of the series, Kanzaka said he wanted to end the story in an open-ended way in order to allow readers to imagine what happens next to Lina and Gourry. He also described the \"Slayers\" video games, television shows, and comics as \"parallel part 3 stories\".\nKanzaka makes references to people and events not depicted in the novels, such as Lina's older sister and Gourry Gabriev's first visit to Sairaag, which he referred to as \"flavor\" to stimulate the reader's imagination and clarified that they are not foreshadowing. He explained that the fictional world would feel smaller if everything that appears in the story is explained; something he learned from a teacher's comment in design school. Although some of these he has not even thought about, like Gourry's visit to Sairaag, others he has created a backstory to, such as Lina's sister. Zuma's backstory was omitted because the novels are told from Lina's first-person perspective, but Kanzaka gave some of the material to the staff of \"Slayers Revolution\" so it could be included in the anime.\nMedia.\nLight novels.\n\"Slayers\" began serialization in \"Dragon Magazine\" in 1989 as a short story series written by Hajime Kanzaka and with artwork by Rui Araizumi. The chapters were then published as light novels under the Fujimi Fantasia Bunko imprint across 15 volumes from January 17, 1990 to May 10, 2000. Although the original story ended with the 15th volume in 2000, Kanzaka began a new arc 18 years later in the May 2018 issue of \"Dragon Magazine\", which was published in March 2018, to celebrate the magazine and Fujimi Fantasia Bunko's 30th anniversary. He described it as \"kind of a reunion\" and said he had not decided to relaunch the series yet. Volume 16 was published on October 20, 2018. A third story arc began in the November 2019 issue of the magazine, released in September 2019. The author described this as \"Rather than an official history, the third arc is going to be more like one of the possibilities, a parallel existence to the TRY TV anime and the Water Dragon King manga, I guess.\" Volume 17 was published on October 19, 2019.\nOn September 7, 2004, Tokyopop began publishing the novels in English, ending with the release of volume 8 on January 2, 2008. On July 3, 2020, J-Novel Club announced their rescue license of the series at Anime Expo Lite. They first release the novels digitally, with the first chapter uploaded to their website that day. Their physical release of \"Slayers\" began in July 2021 and is a 3-1 hardcover omnibus edition based on Japan's 2008 revised edition that featured new illustrations and covers.\nManga.\nBetween July 26, 2008 and March 2009, a new manga series entitled was serialised in Kadokawa Shoten's \"Kerokero Ace\". The series was written by Yoshijir\u014d Muramatsu and illustrated Shin Sasaki, and set in a technological world instead of a fantasy world.\nIn July 1998, Central Park Media announced they had licensed the manga for distribution in North America. On June 15, 1999, \"Slayers: Medieval Mayhem\" was released. The four-volume series \"Slayers Special\" was published between October 12, 2002, and June 25, 2003. A seven-volume series \"Super-Explosive Demon Story\" followed between July 9, 2002 and December 1, 2004. Finally, \"Slayers Premium\" was published in North America on July 5, 2005.\nAnime television series.\nThe self-titled first season of the anime adapts volumes 1 and 3 of the light novels. \nThe second season, \"Slayers Next\", adapts volumes 2, 4, 5, 7, and 8 of the light novels.\nThe third season, \"Slayers Try\", is an original story. \nHowever, a fourth season, \"Slayers AGAIN\", was rumored following the success of \"Try\", but early scheduling conflicts caused interest in the project to dissipate.\nA fourth anime series, \"Slayers Revolution\", premiered in Japan on July 2, 2008. Megumi Hayashibara, the voice actress for main character Lina Inverse, performed both the opening and ending theme songs. The new plot is told across two 13-episode arcs and follows an original storyline that has subplots based on events in the novels, with series director Takashi Watanabe and production studio J.C.Staff reprising their duties from the three original TV series. A fifth \"Slayers\" series titled \"Slayers Evolution-R\" is the second 13-episode arc of \"Slayers Revolution\" and was aired on AT-X starting on January 12, 2009 in Japan.\nCentral Park Media licensed and distributed the anime in North America under the Software Sculptors label on VHS and Laserdisc between 1996 and 1998, collected in eight volumes. It was a commercial success for Central Park, which led them to license \"Slayers Next\" and \"Slayers Try\"; \"Next\" was first shipped from April 1999 in a similar format; a box set of the first four volumes was released in July of that same year, and a box set of the second four volumes in October. \"Slayers Try\" was released later in 2000. The first three seasons were subsequently re-released on DVD (in season box sets). Months before Central Park's license for the anime properties expired, Funimation Entertainment was able to obtain the license and it aired as part of the new owner's programming block on CoLours TV, as well as the Funimation Channel. The first bilingual DVD box set after Funimation's rescue of the license was released on August 21, 2007, retaining the Software Sculptors-produced English dub. A boxset of \"Slayers\", \"Next\" and \"Try\" was released by Funimation on August 4, 2009.\nFox Kids won the rights to broadcast \"Slayers\" but eventually did not air the anime since it would be too heavy to edit it for content. The first North American television broadcast of \"The Slayers\" was February 17, 2002 on the International Channel. In 2009, MVM Films began releasing the series in the United Kingdom on a monthly basis. The first series was released on four DVDs between January 5, and April 6, 2009. The first volume of \"Slayers Next\" was released on May 11, 2009. Episodes have also been made available on the streaming video sites Hulu, YouTube, Crackle, Anime News Network, Netflix, and Funimation's website.\nFunimation licensed both \"Slayers Revolution\" and \"Slayers Evolution-R\" for American release; the episodes in Japanese with English subtitles were uploaded to YouTube, as well as Funimation's website in July 2009. Funimation contracted NYAV Post to produce the English version of the series, with dialogue being recorded in both New York City and Los Angeles. NYAV Post was able to reunite most of the original Central Park Media main character cast for the new season. However, Michael Sinterniklaas replaced David Moo as Xellos. Other notable characters, such as Sylphiel, Prince Phil, and Naga the Serpent were also recast with new voice actors. Funimation released the first \"Slayers Revolution\" boxset on March 16, 2010. Funimation released the first four English-dubbed episodes of \"Slayers Revolution\" to YouTube on January 19, 2010. They have also uploaded the first two English-dubbed episodes of \"Evolution-R\" to YouTube and released \"Evolution-R\" on DVD in June 2010. Funimation released both \"Slayers Revolution\" and \"Evolution-R\" on Blu-ray on October 26, 2010. Both \"Revolution\" and \"Evolution-R\" made their North American television debut when they began airing on the Funimation Channel on September 6, 2010.\nOriginal video animations.\nIn North America, \"Slayers Special\" was initially sold as two separate titles, \"Slayers: Dragon Slave\" and \"Slayers: Explosion Array\" on VHS by licensee ADV Films. All three episodes were later compiled into \"Slayers: The Book of Spells\", shipped on November 21, 2000.\nFilms.\nMost of the films were produced by J.C.Staff and licensed for home video release in North America by ADV Films. \"Slayers Premium\" was animated by Hal Film Maker.\nGames.\nRole-playing games.\nThe series was adapted for two role-playing games (RPGs):\nCollectible card game.\nA collectible card game (CCG), \"Slayers Fight\" (\u30b9\u30ec\u30a4\u30e4\u30fc\u30ba\u3075\u3041\u3044\u3068), was developed by ORG and published by Kadokawa Shoten between 1999 and 2001.\nVideo games.\nA series of five \"Slayers\" role-playing video games were released exclusively in Japan between 1994 and 1998. Two different 16-bit games titled simply \"Slayers\" (including the one for the Super Famicom) were released in 1994. Three 32-bit / CD-ROM games followed in the late 1990s: \"Slayers Royal\" in 1997 and \"Slayers Royal 2\" and \"Slayers Wonderful\" in 1998. In addition, Lina and other \"Slayers\" main characters have been featured in several other video games in crossover and guest appearances, in particular in mobile games since the late 2010s.\nReception.\nIncluding the spin-off series, the \"Slayers\" novels had 18 million copies in print by 2015. This number had grown to over 20million copies by 2018. In January 2025, it was announced that the franchise had sold over 22 million copies, including digital sales. Writing in 2020, Iyane Agossah from DualShockers opined \"Slayers\" \"is still rarely equaled 30 years later, with an incredible mix of comedy and tragedy, an intricate amount of world-building, great story developments and iconic characters.\"\nOf the various media which make up the \"Slayers\" franchise, the anime has by far reached the largest audience and is considered to be one of the most popular series of the 1990s, both in Japan and abroad. As it is a parody of the high fantasy genre, the series' driving force lies in comic scenarios alluding to other specific anime, or more general genre tropes and clich\u00e9s. Its focus on humor and entertainment and \"old school\" anime feel make it a nostalgic classic to many. According to Anime News Network's Daryl Surat, 1996 was the best year of \"Slayers\" anime with the releases of \"Next\" and \"Return\". \"Slayers Next\" took the third place as the overall best anime of 1996 in the Anime Grand Prix '97 awards (in addition to winning in the category best female character), while the next year's series \"Slayers Try\" placed second but technically also third (the first place was a tie between the films \"Mononoke Hime\" and \"The End of Evangelion\") in 1998.\n\"Slayers\" was sometimes compared with \"Record of Lodoss War\", another hit Japanese fantasy franchise that began around the same time. In \"Anime Essentials: Every Thing a Fan Needs to Know\", Gilles Poitras wrote: \"More humorous and less serious looking than the characters in the \"Lodoss War\" series, the stars of \"Slayers\" provide action and laughs.\" In ', Helen McCarthy similarly called it \"the antidote to the deadly serious \"Record of Lodoss War\", with a cynical cast modeled on argumentative role-players. (...) Ridiculing its own shortcomings, \"Slayers\" has successfully kept a strong following that watches for what some might call biting satire, and others bad workmen blaming their tools.\" Joseph Luster of \"Otaku USA\" called it \"the very definition of an all-encompassing media franchise. (...) \"Slayers\" certainly has that in its memorable lineup, and they'll likely cast some sort of spell on you, regardless of age.\" Paul Thomas Chapman from the same magazine voiced a more reserved opinion on the \"franchise whose remarkable longevity and popularity is matched only by its remarkable averageness,\" especially regarding various aspects of the TV series, to which nevertheless he returned for \"light entertainment\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29085", "revid": "1519900", "url": "https://en.wikipedia.org/wiki?curid=29085", "title": "Submarine recycling", "text": ""}
{"id": "29086", "revid": "26074453", "url": "https://en.wikipedia.org/wiki?curid=29086", "title": "Sansad", "text": "Sansad or Sangsad is the word for \"Assembly\", association, council or \"Parliament\" in several Indo-Aryan languages, derived from a Sanskrit root. It may also mean:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "29087", "revid": "46914511", "url": "https://en.wikipedia.org/wiki?curid=29087", "title": "Security through obscurity", "text": "Reliance on design or implementation secrecy for security\nIn security engineering, security through obscurity is the practice of concealing the details or mechanisms of a system to enhance its security. This approach relies on the principle of hiding something in plain sight, akin to a magician's sleight of hand or the use of camouflage. It diverges from traditional security methods, such as physical locks, and is more about obscuring information or characteristics to deter potential threats. Examples of this practice include disguising sensitive information within commonplace items, like a piece of paper in a book, or altering digital footprints, such as spoofing a web browser's version number. While not a standalone solution, security through obscurity can complement other security measures in certain scenarios.\nObscurity in the context of security engineering is the notion that information can be protected, to a certain extent, when it is difficult to access or comprehend. This concept hinges on the principle of making the details or workings of a system less visible or understandable, thereby reducing the likelihood of unauthorized access or manipulation. \nSecurity by obscurity alone is discouraged and not recommended by standards bodies.\nHistory.\nAn early opponent of security through obscurity was the locksmith Alfred Charles Hobbs, who in 1851 demonstrated to the public how state-of-the-art locks could be picked. In response to concerns that exposing security flaws in the design of locks could make them more vulnerable to criminals, he said: \"Rogues are very keen in their profession, and know already much more than we can teach them.\"\nThere is scant formal literature on the issue of security through obscurity. Books on security engineering cite Kerckhoffs' doctrine from 1883 if they cite anything at all. For example, in a discussion about secrecy and openness in nuclear command and control:\n[T]he benefits of reducing the likelihood of an accidental war were considered to outweigh the possible benefits of secrecy. This is a modern reincarnation of Kerckhoffs' doctrine, first put forward in the nineteenth century, that the security of a system should depend on its key, not on its design remaining obscure.\nPeter Swire has written about the trade-off between the notion that \"security through obscurity is an illusion\" and the military notion that \"loose lips sink ships\", as well as on how competition affects the incentives to disclose.\nThere are conflicting stories about the origin of this term. Fans of MIT's Incompatible Timesharing System (ITS) say it was coined in opposition to Multics users down the hall, for whom security was far more an issue than on ITS. Within the ITS culture, the term referred, self-mockingly, to the poor coverage of the documentation and obscurity of many commands, and to the attitude that by the time a tourist figured out how to make trouble he'd generally got over the urge to make it, because he felt part of the community. One instance of deliberate security through obscurity on ITS has been noted: the command to allow patching the running ITS system (altmode altmode control-R) echoed as codice_1. Typing Alt Alt Control-D set a flag that would prevent patching the system even if the user later got it right.\nIn January 2020, NPR reported that Democratic Party officials in Iowa declined to share information regarding the security of its caucus app, to \"make sure we are not relaying information that could be used against us.\" Cybersecurity experts replied that \"to withhold the technical details of its app doesn't do much to protect the system.\"\nCriticism.\nSecurity by obscurity alone is discouraged and not recommended by standards bodies. The National Institute of Standards and Technology (NIST) in the United States recommends against this practice: \"System security should not depend on the secrecy of the implementation or its components.\" The Common Weakness Enumeration project lists \"Reliance on Security Through Obscurity\" as CWE-656.\nA large number of telecommunication and digital rights management cryptosystems use security through obscurity, but have ultimately been broken. These include components of GSM, GMR encryption, GPRS encryption, a number of RFID encryption schemes, and most recently Terrestrial Trunked Radio (TETRA).\nOne of the largest proponents of security through obscurity commonly seen today is anti-malware software. What typically occurs with this single point of failure, however, is an arms race of attackers finding novel ways to avoid detection and defenders coming up with increasingly contrived but secret signatures to flag on.\nThe technique stands in contrast with security by design and open security, although many real-world projects include elements of all strategies.\nObscurity in architecture vs. technique.\nKnowledge of how the system is built differs from concealment and camouflage. The effectiveness of obscurity in operations security depends on whether the obscurity lives on top of other good security practices, or if it is being used alone. When used as an independent layer, obscurity is considered a valid security tool.\nIn recent years, more advanced versions of \"security through obscurity\" have gained support as a methodology in cybersecurity through Moving Target Defense and cyber deception. NIST's cyber resiliency framework, 800-160 Volume 2, recommends the usage of security through obscurity as a complementary part of a resilient and secure computing environment.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29089", "revid": "51066825", "url": "https://en.wikipedia.org/wiki?curid=29089", "title": "Snuff film", "text": "Film showing real murders\nA snuff film, snuff movie, or snuff video is a type of film, oftentimes defined as being produced for profit or financial gain, that shows scenes of actual homicide.\nThe concept of snuff films became known to the general public during the 1970s, when an urban legend alleged that a clandestine industry was producing such films for profit. The rumor was amplified in 1976 by the release of a film called \"Snuff\", which capitalized on the legend through a disingenuous marketing campaign. However, that film, like others on the topic, relied on special effects to simulate murder. According to the fact-checking website \"Snopes\", there has never been a verified example of a genuine commercially produced snuff film. Videos of actual murders (such as beheading videos) have been made available to the public, generally through the Internet. However, those videos have been made and broadcast by the murderers either for their own gratification or for propaganda purposes, and not for financial gain and thus do not qualify, according to one author, as a \"snuff film\". \nIn 2025, \"Vice\" magazine published an article documenting what they described as the first legitimate snuff video, titled \"The Vietnamese Butcher\". According to the report, the video has been sold since February 2025 on the dark web and through Telegram channels, indicating its commercial distribution. There is strong evidence that the murder victim was a willing participant with the awareness of the intention to monetize the film.\nDefinitions.\nA snuff film is a movie in a purported genre of films in which a person is actually murdered, though some variations of the definition may include films that show people committing suicide. According to existing definitions, snuff films can be pornographic and are made for financial gain but are supposedly \"circulated amongst a jaded few for the purpose of entertainment\". The \"Collins English Dictionary\" defines a \"snuff movie\" as \"a pornographic film in which an unsuspecting actress or actor is murdered at the climax of the film\"; the \"Cambridge Dictionary\" defines it more broadly as \"a violent film that shows a real murder\".\nHorror film magazine \"Fangoria\" defined snuff movies as \"films in which a person is killed on camera. The death is premeditated, with the purpose of being filmed in order to make money. Often times, there is a sexual aspect to the murder, either on film (as in, a porn scene that ends horribly) or that the final project is used for sexual gratification.\" Films featuring deaths that are authentic but accidental \"are not considered snuff because the deaths were not planned. Other death on video, such as terrorists beheading victims, are done to fulfill an ideology, not to earn money.\"\n\"Snuff\" industry myth.\nSome filmed records of executions and deaths in war exist, but in those cases the death was not specifically staged for financial gain or entertainment. There have been a number of \"amateur-made\" snuff films available on the Internet. However, such videos are produced by the murderers to make an impact on an audience or for their own satisfaction, and not for financial profit. Some specialized websites show videos of actual killings for profit, as their shock value will attract an audience; but these websites are not operated by the perpetrators of the murders.\nAccording to \"Snopes\", the idea of an actual snuff film \"industry\" clandestinely producing such \"entertainment\" for monetary gain is preposterous because \"capturing a murder on film would be foolhardy at best. Only the most deranged would consider preserving for a jury a perfect video record of a crime they could go to the executioner for. Even if the murderer stays completely out of the camera's way, too much of who the killer is, how the murder was carried out, and where it took place would be part of such a film, and these details would quickly lead police to the right door. Though someone whose mania has caused them to lose touch with reality might skip over this point, those who are supposedly in the business for the money would be all too aware of this. It doesn't make sense to flirt with the electric chair for the profits derived from a video.\"\nFurthermore, \"Fangoria\" has also described the very concept as a \"myth\" and \"a scare tactic, dreamt up by the media to terrify the public.\"\nHistory of the concept.\nOrigins of the urban legend.\nThe noun \"snuff\" originally meant the part of a candle wick that has already burned; the verb \"snuff\" meant to cut this off, and by extension to extinguish or kill. The word has been used in this sense in English slang for hundreds of years. It was defined in 1874 as a \"term very common among the lower orders of London, meaning to die from disease or accident\".\nFilm studies professor Boaz Hagin argues that the concept of films showing actual murders originated decades earlier than is commonly believed, at least as early as 1907. That year, Polish-French writer Guillaume Apollinaire published the short story \"A Good Film\" about newsreel photojournalists who stage and film a murder due to public fascination with crime news; in the story, the public believes the murder is real but police determine that the crime was faked. Hagin also proposes that the film \"Network\" (1976) contains an explicit (fictional) snuff film depiction when television news executives orchestrate the on-air murder of a news anchor to boost ratings.\nAccording to film critic Geoffrey O'Brien, \"whether or not commercially distributed 'snuff' movies actually exist, the possibility of such movies is implicit in the stock B-movie motif of the mad artist killing his models, as in \"A Bucket of Blood\" (1959), \"Color Me Blood Red\" (1965), or \"Decoy for Terror\" (1967) also known as \"Playgirl Killer\".\" Likewise, the protagonist of \"Peeping Tom\" (1960) films the murders he commits, though he does so as part of his mania and not for financial gain: a 1979 article in \"The New York Times\" described the character's activity as making \"private 'snuff' films\".\nThe first known use of the term \"snuff movie\" is in a 1971 book by Ed Sanders, \"The Family: The Story of Charles Manson's Dune Buggy Attack Battalion\". This book included the interview of an anonymous one-time member of Charles Manson's \"Family\", who claimed that the group once made such a film in California, by recording the murder of a woman. However, the interviewee later added that he had not watched the film himself and had just heard rumors of its existence. In later editions of the book, Sanders clarified that no films depicting real murders or murder victims had been found.\nDuring the first half of the 1970s, urban legends started to allege that snuff films were being produced in South America for commercial gain, and circulated clandestinely in the United States.\n\"Snuff\" controversy (1976).\nThe idea of movies showing actual murders for profit became more widely known in 1976 with the release of the exploitation film \"Snuff\". This low-budget horror film, loosely based on the Manson murders and originally titled \"Slaughter\", was shot in Argentina by Michael and Roberta Findlay. The film's distribution rights were bought by Allan Shackleton, who eventually found the picture unfit for release and shelved it. Several years later, Shackleton read about snuff films being imported from South America and decided to cash in on the rumor as an attempt to recoup his investment in \"Slaughter\".\nShackleton retitled \"Slaughter\" to \"Snuff\" and released it with a new ending that purported to depict an actual murder committed on a film set. \"Snuff\"'s promotional material suggested, without stating outright, that the film featured the real murder of a woman, which amounted to false advertising. The film's slogan read: \"The film that could only be made in South America... where life is CHEAP\". Shackleton put out false newspaper clippings that reported a citizens group's crusading against the film, and hired people to act as protesters to picket screenings.\nShackleton's efforts succeeded in generating a media frenzy about the film: real feminist and citizens groups eventually started protesting the movie and picketing theaters. As a result, New York District Attorney Robert M. Morgenthau investigated the picture, establishing that it was a hoax. The controversy nevertheless made the film financially profitable.\nRumors related to serial killers and other controversies.\nIn subsequent years, more urban legends emerged about snuff movies. Notably, multiple serial killers were rumored to have produced snuff films: however, no such videos were proven to exist. Henry Lee Lucas and his accomplice Ottis Toole claimed to have filmed their crimes, but both men were \"pathological liars\" and the purported films were never found. Charles Ng and Leonard Lake videotaped their interactions with some of their future victims, but not the murders. Lawrence Bittaker and Roy Norris made an audio recording of their encounter with one victim, though not of her death. Likewise, Paul Bernardo and Karla Homolka made videos of Bernardo sexually abusing two victims, but did not film the murders. In all those cases, the recordings were not intended for public consumption and were used as evidence during the murderers' trials.\nOver the years, several films were suspected of being \"snuff movies\", though none of these accusations turned out to be true. A similar controversy concerned the filming of the video for the 1989 song \"Down in It\" by Nine Inch Nails, in which Trent Reznor acted in a scene which ended with the implication that Reznor's character had fallen off a building and died. To film the scene, a camera was tied to a balloon with ropes. Minutes after filming started, the ropes snapped and the balloons and camera flew away, eventually landing on a farmer's field in Michigan. The farmer later handed it to the FBI, who began investigating whether the footage was a snuff film portraying a person committing suicide. The FBI identified Reznor and the investigation ended when it was confirmed that Reznor was alive and the footage was not related to crime.\nAround 2018, a conspiracy theory called \"Frazzledrip\", related to Pizzagate and QAnon, purported the existence of a snuff video where Hillary Clinton and her aide Huma Abedin murdered a young girl as part of a Satanic ritual. \nPotential first case of a legitimate snuff film.\nIn late July 2025, a gore video of what is now referred to as \"The Vietnamese Butcher\" began circulating on Telegram and other encrypted messaging apps. It was eventually leaked to public knowledge through gore sites and other platforms with an extended version, bringing into the light what is described as potentially the first authentic snuff film by Vice News.\nThere are 11 video clips and 98 images of the event have been made available on dark web and on Telegram to buy as a pack since at least February, 2025. Videos and images of the film have also been shared around various social media apps and shock sites.\nThe film itself involved a willing male participant who had a sexual desire of being beheaded, and later pleasuring himself before being beheaded with a meat cleaver by a man wearing a plastic Guy Fawkes mask. A montage shows body parts stacked up, intestines separated, followed by images of some kind of food containing an unidentified meat. The end of the film plays a slide show showing the perpetrator with his face partially concealed with a blue surgical mask, holding the victim's severed head via a selfie, as well as multiple other angles and shots of the victim's severed body parts.\nThe participant and victim in the film is theorized to be Nguy\u1ec5n Xu\u00e2n \u0110\u1ea1t (10 March 1989 \u2013 25 January 2025), a Vietnamese male who had multiple Facebook accounts showing and expressing his sexual desire to be beheaded. Internet users have been trying to find information on the killer. Other similar cases have started to surface on the Chinese messaging app Baidu Tieba, with footage featuring butchered Asian men.\nIn late November 2025, Internet users traced the leaked information to a suspect, eventually leading to a police investigation at an alleged crime scene inside a market-surveillance workplace in L\u1ea1ng S\u01a1n province.\nInternet age.\nThe advent of the Internet, by allowing anyone to broadcast self-made videos to an international audience, also changed the means of production of films that may be categorized as \"snuff\". There have been several cases of murders being filmed by their perpetrators and later finding their way online. These include videos made by Mexican cartels or jihadist groups, at least one of the videos shot by the Dnepropetrovsk maniacs in mid-2000s Ukraine, the video shot by Luka Magnotta from Montreal in 2012, the video shot by Vester Lee Flanagan II in 2015, as well as cases of livestreamed murders, including videos made by mass shooters.\nAuthor Steve Lillebuen, who wrote a book on the Magnotta case, commented that social media had created a new trend in crime where killers who crave an audience can become \"online broadcasters\" by showing their crimes to the world.\n\"Fangoria\" commented that Magnotta's 2012 video, which showed him mutilating the corpse of his victim, was the closest thing in existence to an actual snuff movie, especially as Magnotta had done some crude editing and used a song as a soundtrack, which amounted to minimal production values. However, it did not show the murder itself and was originally published to attract attention and not for monetary gain. The charges of which Magnotta was found guilty included \"publishing obscene materials\". In 2016, the owner of Bestgore.com, the website that originally hosted Magnotta's video, pleaded guilty to an obscenity charge and was sentenced to a six-month conditional sentence, half of which was served under house arrest.\nIn 2025, it was reported that Wagner Group members were sharing graphic videos of their war crimes via Telegram, sometimes even behind paywalls, prompting calls for an ICC investigation.\nA confidential legal brief submitted to the International Criminal Court (ICC) by UC Berkeley legal experts asserts that Wagner has been distributing highly graphic videos\u2014involving mutilation, torture, and even scenes implying cannibalism\u2014on Telegram channels tied to their network. These videos were shared explicitly to terrorize civilians and dehumanize victims in Mali, Burkina Faso, and Niger.\nThe Telegram channel White Uncles in Africa, believed to be managed by current or former Wagner operatives, has reposted such atrocity content. Experts argue that even sharing these videos may itself be a war crime, constituting a violation of human dignity under the Rome Statute.\nOn July 7, 2025, the Israeli state arms manufacturer and exporter Rafael Advanced Defense Systems made a social media posting on X that promoted their Spike Firefly miniature loitering munition using a video of an attack on a lone man who was walking out in the open in the middle of a street.\nIn fiction.\nSince the concept became familiar to the general public, snuff films being made for profit or entertainment have been used as a core plot element or at least mentioned in numerous works of fiction, including the 1979 films \"Hardcore\" and \"Bloodline\", and Bret Easton Ellis's 1985 novel \"Less than Zero\". The making or discovery of one or several snuff films is the premise of various horror, thriller or crime films, such as \"Last House on Dead End Street\" (1977), \"Videodrome\" (1983), \"Tesis\" (1996), \"8mm\" (1999), \"Vacancy\" (2007), \"Snuff 102\" (2007), \"A Serbian Film\" (2010), \"Sinister\" (2012), \"The Counselor\" (2013), ' (2023), and the episode \"The Devil of Christmas\" (2016) in the black comedy series \"Inside No. 9\". The 2003 video game \"Manhunt\" sees the main character being forced to participate in a series of snuff films to guarantee his freedom. The 2005 video game ' features a mission titled \"Snuff\", where the main character kills a few gangsters while unknowingly being filmed for a snuff movie by a third party, which may be a reference to \"Manhunt\". Also, pretend snuff porn is sometimes filmed as a fetish.\nSeveral horror films such as \"Cannibal Holocaust\" (1980) and \"August Underground\" (2001) have depicted \"snuff movie\" situations, coupled with found footage aesthetics used as a narrative device. Though some of these films have generated controversy as to their nature and content, none were, nor have officially purported to be, actual snuff movies.\nFalse snuff films.\n\"Faces of Death\".\nThe 1978 pseudo-documentary film \"Faces of Death\", which spawned several sequels, is one of the films most commonly associated with the \"snuff movie\" concept, even though it was not produced by murderers nor clandestinely distributed. Purporting to be an educational film about death, it mixed footage of actual deadly accidents, suicides, autopsies, or executions, with \"outright fake scenes\" obtained with the help of special effects.\nThe \"Guinea Pig\" films.\nThe first two films in the Japanese \"Guinea Pig\" series, ' and ' (both released in 1985) are designed to look like snuff films; the video is grainy and unsteady, as if recorded by amateurs, and extensive practical and special effects are used to imitate such features as internal organs and graphic wounds. The sixth film in the series, \"Mermaid in a Manhole\" (1988), allegedly served as an inspiration for Japanese serial killer Tsutomu Miyazaki, who murdered several preschool girls in the late 1980s.\nIn 1991, actor Charlie Sheen became convinced that \"Flower of Flesh and Blood\" depicted an actual homicide and contacted the FBI. The FBI initiated an investigation but closed it after the series' producers released a \"making of\" film demonstrating the special effects used to simulate the murders.\n\"Cannibal Holocaust\".\nThe Italian director Ruggero Deodato was charged after rumors that the depictions of the killing of the main actors in his film \"Cannibal Holocaust\" (1980) were real. He was able to clear himself of the charges after the actors made an appearance in court and on television.\nOther than graphic gore, the film contains several scenes of sexual violence and the genuine deaths of six animals onscreen and one off screen, issues which find \"Cannibal Holocaust\" in the midst of controversy to this day. It has also been claimed that \"Cannibal Holocaust\" is banned in over 50 countries, although this has never been verified. In 2006, \"Entertainment Weekly\" magazine named \"Cannibal Holocaust\" as the 20th most controversial film of all time.\n\"August Underground\" trilogy.\nThis trilogy of horror films, which depict graphic tortures and murders, is shot as if it were amateur footage made by a serial killer and his accomplices. In 2005, director and lead actor Fred Vogel, who was traveling with copies of the first two films to attend a horror film festival in Canada, was arrested by Canadian customs pending charges of transporting obscene materials into the country. The charges were eventually dropped after Vogel had spent ten hours in custody.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29090", "revid": "46855107", "url": "https://en.wikipedia.org/wiki?curid=29090", "title": "Software testing", "text": "Checking software against a standard\nSoftware testing is the act of checking whether software meets its intended objectives and satisfies expectations.\nSoftware testing can provide objective, independent information about the quality of software and the risk of its failure to a user or sponsor or any other stakeholder.\nSoftware testing can determine the correctness of software for specific scenarios but cannot determine correctness for all scenarios. It cannot find all bugs.\nBased on the criteria for measuring correctness from an oracle, software testing employs principles and mechanisms that might recognize a problem. Examples of oracles include specifications, contracts, comparable products, past versions of the same product, inferences about intended or expected purpose, user or customer expectations, relevant standards, and applicable laws.\nSoftware testing can be functional or non-functional in nature.\nSoftware testing is often dynamic in nature; running the software to verify actual output matches expected. It can also be static in nature; reviewing code and its associated documentation.\nSoftware testing is often used to answer the question: Does the software do what it is supposed to do and what it needs to do?\nInformation learned from software testing may be used to improve the process by which software is developed.\nA commonly suggested approach to automated testing is the \"test pyramid,\" wherein most of the tests are unit tests, followed by a smaller set of integration tests and finally a few end-to-end (e2e) tests.\nEconomics.\nA study conducted by NIST in 2002 reported that software bugs cost the U.S. economy $59.5 billion annually. More than a third of this cost could be avoided if better software testing was performed.\nOutsourcing software testing because of costs is very common, with China, the Philippines, and India being preferred destinations.\nHistory.\nGlenford J. Myers initially introduced the separation of debugging from testing in 1979. Although his attention was on breakage testing (\"A successful test case is one that detects an as-yet undiscovered error.\"), it illustrated the desire of the software engineering community to separate fundamental development activities, such as debugging, from that of verification.\nSoftware testing typically includes handling software bugs \u2013 a defect in the code that causes an undesirable result. Bugs generally slow testing progress and involve programmer assistance to debug and fix.\nNot all defects cause a failure. For example, a defect in dead code will not be considered a failure.\nA defect that does not cause failure at one point in time may lead to failure later due to environmental changes. Examples of environment change include running on new computer hardware, changes in data, and interacting with different software.\nGoals.\nSoftware testing is typically goal driven.\nFinding bugs.\nSoftware testing typically includes handling software bugs \u2013 a defect in the code that causes an undesirable result. Bugs generally slow testing progress and involve programmer assistance to debug and fix.\nNot all defects cause a failure. For example, a defect in dead code will not be considered a failure.\nA defect that does not cause failure at one point in time may lead to failure later due to environmental changes. Examples of environment change include running on new computer hardware, changes in data, and interacting with different software.\nA single defect may result in multiple failure symptoms.\nEnsuring requirements are satisfied.\nSoftware testing may involve a Requirements gap \u2013 omission from the design for a requirement. Requirement gaps can often be non-functional requirements such as testability, scalability, maintainability, performance, and security.\nCode coverage.\nA fundamental limitation of software testing is that testing under \"all\" combinations of inputs and preconditions (initial state) is not feasible, even with a simple product. \nDefects that manifest in unusual conditions are difficult to find in testing. Also, non-functional dimensions of quality (how it is supposed to \"be\" versus what it is supposed to \"do\") \u2013 usability, scalability, performance, compatibility, and reliability \u2013 can be subjective; something that constitutes sufficient value to one person may not to another.\nAlthough testing for every possible input is not feasible, testing can use combinatorics to maximize coverage while minimizing tests.\nCategories.\nTesting can be categorized many ways.\nLevels.\nSoftware testing can be categorized into levels based on how much of the software system is the focus of a test.\nStatic, dynamic, and passive testing.\nThere are many approaches to software testing. Reviews, walkthroughs, or inspections are referred to as static testing, whereas executing programmed code with a given set of test cases is referred to as dynamic testing.\nStatic testing is often implicit, like proofreading, plus when programming tools/text editors check source code structure or compilers (pre-compilers) check syntax and data flow as static program analysis. Dynamic testing takes place when the program itself is run. Dynamic testing may begin before the program is 100% complete in order to test particular sections of code and are applied to discrete functions or modules. Typical techniques for these are either using stubs/drivers or execution from a debugger environment.\nStatic testing involves verification, whereas dynamic testing also involves validation.\nPassive testing means verifying the system's behavior without any interaction with the software product. Contrary to active testing, testers do not provide any test data but look at system logs and traces. They mine for patterns and specific behavior in order to make some kind of decisions. This is related to offline runtime verification and log analysis.\nPreset testing vs adaptive testing.\nThe type of testing strategy to be performed depends on whether the tests to be applied to the IUT should be decided before the testing plan starts to be executed (preset testing) or whether each input to be applied to the IUT can be dynamically dependent on the outputs obtained during the application of the previous tests (adaptive testing).\nBlack/white box.\nSoftware testing can often be divided into white-box and black-box. These two approaches are used to describe the point of view that the tester takes when designing test cases. A hybrid approach called grey-box that includes aspects of both boxes may also be applied to software testing methodology.\nWhite-box testing.\nWhite-box testing (also known as clear box testing, glass box testing, transparent box testing, and structural testing) verifies the internal structures or workings of a program, as opposed to the functionality exposed to the end-user. In white-box testing, an internal perspective of the system (the source code), as well as programming skills are used to design test cases. The tester chooses inputs to exercise paths through the code and determines the appropriate outputs. This is analogous to testing nodes in a circuit, e.g., in-circuit testing (ICT).\nWhile white-box testing can be applied at the unit, integration, and system levels of the software testing process, it is usually done at the unit level. It can test paths within a unit, paths between units during integration, and between subsystems during a system\u2013level test. Though this method of test design can uncover many errors or problems, it might not detect unimplemented parts of the specification or missing requirements.\nTechniques used in white-box testing include:\nCode coverage tools can evaluate the completeness of a test suite that was created with any method, including black-box testing. This allows the software team to examine parts of a system that are rarely tested and ensures that the most important function points have been tested. Code coverage as a software metric can be reported as a percentage for:\n* \"Function coverage\", which reports on functions executed\n* \"Statement coverage\", which reports on the number of lines executed to complete the test\n* \"Decision coverage\", which reports on whether both the True and the False branch of a given test has been executed\n100% statement coverage ensures that all code paths or branches (in terms of control flow) are executed at least once. This is helpful in ensuring correct functionality, but not sufficient since the same code may process different inputs correctly or incorrectly.\nBlack-box testing.\nBlack-box testing (also known as functional testing) describes designing test cases without knowledge of the implementation, without reading the source code. The testers are only aware of what the software is supposed to do, not how it does it. Black-box testing methods include: equivalence partitioning, boundary value analysis, all-pairs testing, state transition tables, decision table testing, fuzz testing, model-based testing, use case testing, exploratory testing, and specification-based testing.\nSpecification-based testing aims to test the functionality of software according to the applicable requirements. This level of testing usually requires thorough test cases to be provided to the tester, who then can simply verify that for a given input, the output value (or behavior), either \"is\" or \"is not\" the same as the expected value specified in the test case. Test cases are built around specifications and requirements, i.e., what the application is supposed to do. It uses external descriptions of the software, including specifications, requirements, and designs, to derive test cases. These tests can be functional or non-functional, though usually functional. Specification-based testing may be necessary to assure correct functionality, but it is insufficient to guard against complex or high-risk situations.\nBlack box testing can be used to any level of testing although usually not at the unit level.\nComponent interface testing\nComponent interface testing is a variation of black-box testing, with the focus on the data values beyond just the related actions of a subsystem component. The practice of component interface testing can be used to check the handling of data passed between various units, or subsystem components, beyond full integration testing between those units. The data being passed can be considered as \"message packets\" and the range or data types can be checked for data generated from one unit and tested for validity before being passed into another unit. One option for interface testing is to keep a separate log file of data items being passed, often with a timestamp logged to allow analysis of thousands of cases of data passed between units for days or weeks. Tests can include checking the handling of some extreme data values while other interface variables are passed as normal values. Unusual data values in an interface can help explain unexpected performance in the next unit.\nVisual testing.\nThe aim of visual testing is to provide developers with the ability to examine what was happening at the point of software failure by presenting the data in such a way that the developer can easily find the information he or she requires, and the information is expressed clearly.\nAt the core of visual testing is the idea that showing someone a problem (or a test failure), rather than just describing it, greatly increases clarity and understanding. Visual testing, therefore, requires the recording of the entire test process \u2013 capturing everything that occurs on the test system in video format. Output videos are supplemented by real-time tester input via picture-in-a-picture webcam and audio commentary from microphones.\nVisual testing provides a number of advantages. The quality of communication is increased drastically because testers can show the problem (and the events leading up to it) to the developer as opposed to just describing it, and the need to replicate test failures will cease to exist in many cases. The developer will have all the evidence he or she requires of a test failure and can instead focus on the cause of the fault and how it should be fixed.\nAd hoc testing and exploratory testing are important methodologies for checking software integrity because they require less preparation time to implement, while the important bugs can be found quickly. In ad hoc testing, where testing takes place in an improvised impromptu way, the ability of the tester(s) to base testing off documented methods and then improvise variations of those tests can result in a more rigorous examination of defect fixes. However, unless strict documentation of the procedures is maintained, one of the limits of ad hoc testing is lack of repeatability.\nGrey-box testing.\nGrey-box testing (American spelling: gray-box testing) involves using knowledge of internal data structures and algorithms for purposes of designing tests while executing those tests at the user, or black-box level. The tester will often have access to both \"the source code and the executable binary.\" Grey-box testing may also include reverse engineering (using dynamic code analysis) to determine, for instance, boundary values or error messages. Manipulating input data and formatting output do not qualify as grey-box, as the input and output are clearly outside of the \"black box\" that we are calling the system under test. This distinction is particularly important when conducting integration testing between two modules of code written by two different developers, where only the interfaces are exposed for the test.\nBy knowing the underlying concepts of how the software works, the tester makes better-informed testing choices while testing the software from outside. Typically, a grey-box tester will be permitted to set up an isolated testing environment with activities, such as seeding a database. The tester can observe the state of the product being tested after performing certain actions such as executing SQL statements against the database and then executing queries to ensure that the expected changes have been reflected. Grey-box testing implements intelligent test scenarios based on limited information. This will particularly apply to data type handling, exception handling, and so on.\nWith the concept of grey-box testing, this \"arbitrary distinction\" between black- and white-box testing has faded somewhat.\nCompatibility testing.\nA common cause of software failure (real or perceived) is a lack of its compatibility with other application software, operating systems (or operating system versions, old or new), or target environments that differ greatly from the original (such as a terminal or GUI application intended to be run on the desktop now being required to become a Web application, which must render in a Web browser). For example, in the case of a lack of backward compatibility, this can occur because the programmers develop and test software only on the latest version of the target environment, which not all users may be running. This results in the unintended consequence that the latest work may not function on earlier versions of the target environment, or on older hardware that earlier versions of the target environment were capable of using. Sometimes such issues can be fixed by proactively abstracting operating system functionality into a separate program module or library.\nSmoke and sanity testing.\nSanity testing determines whether it is reasonable to proceed with further testing.\nSmoke testing consists of minimal attempts to operate the software, designed to determine whether there are any basic problems that will prevent it from working at all. Such tests can be used as build verification test.\nRegression testing.\nRegression testing focuses on finding defects after a major code change has occurred. Specifically, it seeks to uncover software regressions, as degraded or lost features, including old bugs that have come back. Such regressions occur whenever software functionality that was previously working correctly, stops working as intended. Typically, regressions occur as an unintended consequence of program changes, when the newly developed part of the software collides with the previously existing code. Regression testing is typically the largest test effort in commercial software development, due to checking numerous details in prior software features, and even new software can be developed while using some old test cases to test parts of the new design to ensure prior functionality is still supported.\nCommon methods of regression testing include re-running previous sets of test cases and checking whether previously fixed faults have re-emerged. The depth of testing depends on the phase in the release process and the risk of the added features. They can either be complete, for changes added late in the release or deemed to be risky, or be very shallow, consisting of positive tests on each feature, if the changes are early in the release or deemed to be of low risk.\nAcceptance testing.\nAcceptance testing is system-level testing to ensure the software meets customer expectations.\nAcceptance testing may be performed as part of the hand-off process between any two phases of development.\nTests are frequently grouped into these levels by where they are performed in the software development process, or by the level of specificity of the test.\nSometimes, UAT is performed by the customer, in their environment and on their own hardware.\nOAT is used to conduct operational readiness (pre-release) of a product, service or system as part of a quality management system. OAT is a common type of non-functional software testing, used mainly in software development and software maintenance projects. This type of testing focuses on the operational readiness of the system to be supported, or to become part of the production environment. Hence, it is also known as operational readiness testing (ORT) or operations readiness and assurance (OR&amp;A) testing. Functional testing within OAT is limited to those tests that are required to verify the \"non-functional\" aspects of the system.\nIn addition, the software testing should ensure that the portability of the system, as well as working as expected, does not also damage or partially corrupt its operating environment or cause other processes within that environment to become inoperative.\nContractual acceptance testing is performed based on the contract's acceptance criteria defined during the agreement of the contract, while regulatory acceptance testing is performed based on the relevant regulations to the software product. Both of these two tests can be performed by users or independent testers. Regulation acceptance testing sometimes involves the regulatory agencies auditing the test results.\nAlpha testing.\nAlpha testing is simulated or actual operational testing by potential users/customers or an independent test team at the developers' site. Alpha testing is often employed for off-the-shelf software as a form of internal acceptance testing before the software goes to beta testing.\nBeta testing.\nBeta testing comes after alpha testing and can be considered a form of external user acceptance testing. Versions of the software, known as beta versions, are released to a limited audience outside of the programming team known as beta testers. The software is released to groups of people so that further testing can ensure the product has few faults or bugs. Beta versions can be made available to the open public to increase the feedback field to a maximal number of future users and to deliver value earlier, for an extended or even indefinite period of time (perpetual beta).\nFunctional vs non-functional testing.\nFunctional testing refers to activities that verify a specific action or function of the code. These are usually found in the code requirements documentation, although some development methodologies work from use cases or user stories. Functional tests tend to answer the question of \"can the user do this\" or \"does this particular feature work.\"\nNon-functional testing refers to aspects of the software that may not be related to a specific function or user action, such as scalability or other performance, behavior under certain constraints, or security. Testing will determine the breaking point, the point at which extremes of scalability or performance leads to unstable execution. Non-functional requirements tend to be those that reflect the quality of the product, particularly in the context of the suitability perspective of its users.\nContinuous testing.\nContinuous testing is the process of executing automated tests as part of the software delivery pipeline to obtain immediate feedback on the business risks associated with a software release candidate. Continuous testing includes the validation of both functional requirements and non-functional requirements; the scope of testing extends from validating bottom-up requirements or user stories to assessing the system requirements associated with overarching business goals.\nDestructive testing.\nDestructive testing attempts to cause the software or a sub-system to fail. It verifies that the software functions properly even when it receives invalid or unexpected inputs, thereby establishing the robustness of input validation and error-management routines. Software fault injection, in the form of fuzzing, is an example of failure testing. Various commercial non-functional testing tools are linked from the software fault injection page; there are also numerous open-source and free software tools available that perform destructive testing.\nSoftware performance testing.\nPerformance testing is generally executed to determine how a system or sub-system performs in terms of responsiveness and stability under a particular workload. It can also serve to investigate, measure, validate or verify other quality attributes of the system, such as scalability, reliability and resource usage.\n\"Load testing\" is primarily concerned with testing that the system can continue to operate under a specific load, whether that be large quantities of data or a large number of users. This is generally referred to as software scalability. The related load testing activity of when performed as a non-functional activity is often referred to as \"endurance testing\". \"Volume testing\" is a way to test software functions even when certain components (for example a file or database) increase radically in size. \"Stress testing\" is a way to test reliability under unexpected or rare workloads. \"Stability testing\" (often referred to as load or endurance testing) checks to see if the software can continuously function well in or above an acceptable period.\nThere is little agreement on what the specific goals of performance testing are. The terms load testing, performance testing, scalability testing, and volume testing, are often used interchangeably.\nReal-time software systems have strict timing constraints. To test if timing constraints are met, real-time testing is used.\nUsability testing.\nUsability testing is to check if the user interface is easy to use and understand. It is concerned mainly with the use of the application. This is not a kind of testing that can be automated; actual human users are needed, being monitored by skilled UI designers. Usability testing can use structured models to check how well an interface works. The Stanton, Theofanos, and Joshi (2015) model looks at user experience, and the Al-Sharafat and Qadoumi (2016) model is for expert evaluation, helping to assess usability in digital applications.\nAccessibility testing.\nAccessibility testing is done to ensure that the software is accessible to persons with disabilities. Some of the common web accessibility tests are\nSecurity testing.\nSecurity testing is essential for software that processes confidential data to prevent system intrusion by hackers.\nThe International Organization for Standardization (ISO) defines this as a \"type of testing conducted to evaluate the degree to which a test item, and associated data and information, are protected so that unauthorised persons or systems cannot use, read or modify them, and authorized persons or systems are not denied access to them.\"\nInternationalization and localization.\nTesting for internationalization and localization validates that the software can be used with different languages and geographic regions. The process of pseudolocalization is used to test the ability of an application to be translated to another language, and make it easier to identify when the localization process may introduce new bugs into the product.\nGlobalization testing verifies that the software is adapted for a new culture, such as different currencies or time zones.\nActual translation to human languages must be tested, too. Possible localization and globalization failures include:\nDevelopment testing.\nDevelopment testing is a software development process that involves the synchronized application of a broad spectrum of defect prevention and detection strategies in order to reduce software development risks, time, and costs. It is performed by the software developer or engineer during the construction phase of the software development lifecycle. Development testing aims to eliminate construction errors before code is promoted to other testing; this strategy is intended to increase the quality of the resulting software as well as the efficiency of the overall development process.\nDepending on the organization's expectations for software development, development testing might include static code analysis, data flow analysis, metrics analysis, peer code reviews, unit testing, code coverage analysis, traceability, and other software testing practices.\nA/B testing.\nA/B testing is a method of running a controlled experiment to determine if a proposed change is more effective than the current approach. Customers are routed to either a current version (control) of a feature, or to a modified version (treatment) and data is collected to determine which version is better at achieving the desired outcome.\nConcurrent testing.\nConcurrent or concurrency testing assesses the behaviour and performance of software and systems that use concurrent computing, generally under normal usage conditions. Typical problems this type of testing will expose are deadlocks, race conditions and problems with shared memory/resource handling.\nConformance testing or type testing.\nIn software testing, conformance testing verifies that a product performs according to its specified standards. Compilers, for instance, are extensively tested to determine whether they meet the recognized standard for that language.\nOutput comparison testing.\nCreating a display expected output, whether as data comparison of text or screenshots of the UI, is sometimes called snapshot testing or Golden Master Testing unlike many other forms of testing, this cannot detect failures automatically and instead requires that a human evaluate the output for inconsistencies.\nProperty testing.\nProperty testing is a testing technique where, instead of asserting that specific inputs produce specific expected outputs, the practitioner randomly generates many inputs, runs the program on all of them, and asserts the truth of some \"property\" that should be true for every pair of input and output. For example, every output from a serialization function should be accepted by the corresponding deserialization function, and every output from a sort function should be a monotonically increasing list containing exactly the same elements as its input.\nProperty testing libraries allow the user to control the strategy by which random inputs are constructed, to ensure coverage of degenerate cases, or inputs featuring specific patterns that are needed to fully exercise aspects of the implementation under test.\nProperty testing is also sometimes known as \"generative testing\" or \"QuickCheck testing\" since it was introduced and popularized by the Haskell library QuickCheck.\nMetamorphic testing.\nMetamorphic testing (MT) is a property-based software testing technique, which can be an effective approach for addressing the test oracle problem and test case generation problem. The test oracle problem is the difficulty of determining the expected outcomes of selected test cases or to determine whether the actual outputs agree with the expected outcomes.\nVCR testing.\nVCR testing, also known as \"playback testing\" or \"record/replay\" testing, is a testing technique for increasing the reliability and speed of regression tests that involve a component that is slow or unreliable to communicate with, often a third-party API outside of the tester's control. It involves making a recording (\"cassette\") of the system's interactions with the external component, and then replaying the recorded interactions as a substitute for communicating with the external system on subsequent runs of the test.\nThe technique was popularized in web development by the Ruby library https://.\nContract Testing.\nContract testing, not to be confused with the aforementioned legally-motivated contractual acceptance testing, is a methodology consisting of testing the intergration point between any two software services by checking if the requests and responses sent between each conform to a shared set of expectations commonly referred to as a contract. It is often used in the context of distributed systems, service-oriented software architectures, and microservices.\nTeamwork.\nRoles.\nIn an organization, testers may be in a separate team from the rest of the software development team or they may be integrated into one team. Software testing can also be performed by non-dedicated software testers.\nIn the 1980s, the term \"software tester\" started to be used to denote a separate profession.\nNotable software testing roles and titles include: \"test manager\", \"test lead\", \"test analyst\", \"test designer\", \"tester\", \"automation developer\", and \"test administrator\".\nProcesses.\nOrganizations that develop software, perform testing differently, but there are common patterns.\nWaterfall development.\nIn waterfall development, testing is generally performed after the code is completed, but before the product is shipped to the customer. This practice often results in the testing phase being used as a project buffer to compensate for project delays, thereby compromising the time devoted to testing.\nSome contend that the waterfall process allows for testing to start when the development project starts and to be a continuous process until the project finishes.\nAgile development.\nAgile software development commonly involves testing while the code is being written and organizing teams with both programmers and testers and with team members performing both programming and testing.\nOne agile practice, test-driven software development (TDD), is a way of unit testing such that unit-level testing is performed while writing the product code. Test code is updated as new features are added and failure conditions are discovered (bugs fixed). Commonly, the unit test code is maintained with the project code, integrated in the build process, and run on each build and as part of regression testing. Goals of this continuous integration is to support development and reduce defects.\nEven in organizations that separate teams by programming and testing functions, many often have the programmers perform unit testing.\nSample process.\nThe sample below is common for waterfall development. The same activities are commonly found in other development models, but might be described differently.\nQuality.\nSoftware verification and validation.\nSoftware testing is used in association with verification and validation:\nThe terms verification and validation are commonly used interchangeably in the industry; it is also common to see these two terms defined with contradictory definitions. According to the \"IEEE Standard Glossary of Software Engineering Terminology\":\n Verification is the process of evaluating a system or component to determine whether the products of a given development phase satisfy the conditions imposed at the start of that phase.\n Validation is the process of evaluating a system or component during or at the end of the development process to determine whether it satisfies specified requirements.\nAnd, according to the ISO 9000 standard:\n Verification is confirmation by examination and through provision of objective evidence that specified requirements have been fulfilled.\n Validation is confirmation by examination and through provision of objective evidence that the requirements for a specific intended use or application have been fulfilled.\nThe contradiction is caused by the use of the concepts of requirements and specified requirements but with different meanings.\nIn the case of IEEE standards, the specified requirements, mentioned in the definition of validation, are the set of problems, needs and wants of the stakeholders that the software must solve and satisfy. Such requirements are documented in a Software Requirements Specification (SRS). And, the products mentioned in the definition of verification, are the output artifacts of every phase of the software development process. These products are, in fact, specifications such as Architectural Design Specification, Detailed Design Specification, etc. The SRS is also a specification, but it cannot be verified (at least not in the sense used here, more on this subject below).\nBut, for the ISO 9000, the specified requirements are the set of specifications, as just mentioned above, that must be verified. A specification, as previously explained, is the product of a software development process phase that receives another specification as input. A specification is verified successfully when it correctly implements its input specification. All the specifications can be verified except the SRS because it is the first one (it can be validated, though). Examples: The Design Specification must implement the SRS; and, the Construction phase artifacts must implement the Design Specification.\nSo, when these words are defined in common terms, the apparent contradiction disappears.\nBoth the SRS and the software must be validated. The SRS can be validated statically by consulting with the stakeholders. Nevertheless, running some partial implementation of the software or a prototype of any kind (dynamic testing) and obtaining positive feedback from them, can further increase the certainty that the SRS is correctly formulated. On the other hand, the software, as a final and running product (not its artifacts and documents, including the source code) must be validated dynamically with the stakeholders by executing the software and having them to try it.\nSome might argue that, for SRS, the input is the words of stakeholders and, therefore, SRS validation is the same as SRS verification. Thinking this way is not advisable as it only causes more confusion. It is better to think of verification as a process involving a formal and technical input document.\nSoftware quality assurance.\nIn some organizations, software testing is part of a software quality assurance (SQA) process. In SQA, software process specialists and auditors are concerned with the software development process rather than just the artifacts such as documentation, code and systems. They examine and change the software engineering process itself to reduce the number of faults that end up in the delivered software: the so-called defect rate. What constitutes an acceptable defect rate depends on the nature of the software; a flight simulator video game would have much higher defect tolerance than software for an actual airplane. Although there are close links with SQA, testing departments often exist independently, and there may be no SQA function in some companies.\nSoftware testing is an activity to investigate software under test in order to provide quality-related information to stakeholders. By contrast, QA (quality assurance) is the implementation of policies and procedures intended to prevent defects from reaching customers.\nMeasures.\nQuality measures include such topics as correctness, completeness, security and ISO/IEC 9126 requirements such as capability, reliability, efficiency, portability, maintainability, compatibility, and usability.\nThere are a number of frequently used software metrics, or measures, which are used to assist in determining the state of the software or the adequacy of the testing.\nArtifacts.\nA software testing process can produce several artifacts. The actual artifacts produced are a factor of the software development model used, stakeholder and organisational needs.\nTest plan.\nA test plan is a document detailing the approach that will be taken for intended test activities. The plan may include aspects such as objectives, scope, processes and procedures, personnel requirements, and contingency plans. The test plan could come in the form of a single plan that includes all test types (like an acceptance or system test plan) and planning considerations, or it may be issued as a master test plan that provides an overview of more than one detailed test plan (a plan of a plan). A test plan can be, in some cases, part of a wide \"test strategy\" which documents overall testing approaches, which may itself be a master test plan or even a separate artifact.\nTest case.\nA test case normally consists of a unique identifier, requirement references from a design specification, preconditions, events, a series of steps (also known as actions) to follow, input, output, expected result, and the actual result. Clinically defined, a test case is an input and an expected result. This can be as terse as \"for condition x your derived result is y\", although normally test cases describe in more detail the input scenario and what results might be expected. It can occasionally be a series of steps (but often steps are contained in a separate test procedure that can be exercised against multiple test cases, as a matter of economy) but with one expected result or expected outcome. The optional fields are a test case ID, test step, or order of execution number, related requirement(s), depth, test category, author, and check boxes for whether the test is automatable and has been automated. Larger test cases may also contain prerequisite states or steps, and descriptions. A test case should also contain a place for the actual result. These steps can be stored in a word processor document, spreadsheet, database, or other common repositories. In a database system, you may also be able to see past test results, who generated the results, and what system configuration was used to generate those results. These past results would usually be stored in a separate table.\nTest script.\nA test script is a procedure or programming code that replicates user actions. Initially, the term was derived from the product of work created by automated regression test tools. A test case will be a baseline to create test scripts using a tool or a program.\nTest fixture or test data.\nIn most cases, multiple sets of values or data are used to test the same functionality of a particular feature. All the test values and changeable environmental components are collected in separate files and stored as test data. It is also useful to provide this data to the client and with the product or a project. There are techniques to generate Test data.\nTest harness.\nThe software, tools, samples of data input and output, and configurations are all referred to collectively as a test harness.\nTest run.\nA test run is a collection of test cases or test suites that the user is executing and comparing the expected with the actual results. Once complete, a report or all executed tests may be generated.\nCertifications.\nSeveral certification programs exist to support the professional aspirations of software testers and quality assurance specialists. A few practitioners argue that the testing field is not ready for certification, as mentioned in the controversy section.\nControversy.\nSome of the major software testing controversies include:\nIt is commonly believed that the earlier a defect is found, the cheaper it is to fix it. The following table shows the cost of fixing the defect depending on the stage it was found. For example, if a problem in the requirements is found only post-release, then it would cost 10\u2013100 times more to fix than if it had already been found by the requirements review. With the advent of modern continuous deployment practices and cloud-based services, the cost of re-deployment and maintenance may lessen over time.\nThe data from which this table is extrapolated is scant. Laurent Bossavit says in his analysis:\nThe \"smaller projects\" curve turns out to be from only two teams of first-year students, a sample size so small that extrapolating to \"smaller projects in general\" is totally indefensible. The GTE study does not explain its data, other than to say it came from two projects, one large and one small. The paper cited for the Bell Labs \"Safeguard\" project specifically disclaims having collected the fine-grained data that Boehm's data points suggest. The IBM study (Fagan's paper) contains claims that seem to contradict Boehm's graph and no numerical results that clearly correspond to his data points.\nBoehm doesn't even cite a paper for the TRW data, except when writing for \"Making Software\" in 2010, and there he cited the original 1976 article. There exists a large study conducted at TRW at the right time for Boehm to cite it, but that paper doesn't contain the sort of data that would support Boehm's claims.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29091", "revid": "64883", "url": "https://en.wikipedia.org/wiki?curid=29091", "title": "Ship-Submarine Recycling Program", "text": "US Navy process to dispose of decommissioned nuclear vessels\nThe Ship-Submarine Recycling Program (SRP) is the process that the United States Navy uses to dispose of decommissioned nuclear vessels. SRP takes place only at the Puget Sound Naval Shipyard (PSNS) in Bremerton, Washington, but the preparations can begin elsewhere.\nProgram overview.\nDefueling and decommissioning.\nBefore SRP can begin, the vessel's nuclear fuel must be removed, and defueling usually coincides with decommissioning. Until the fuel is removed, the vessel is referred to as \"USS \"Name\",\" but afterward, the \"USS\" prefix is dropped and it is referred to as \"ex-\"Name\".\" Reusable equipment is removed at the same time as the fuel.\nSpent fuel storage.\nSpent nuclear fuel is shipped by rail to the Naval Reactor Facility in the Idaho National Laboratory (INL), located northwest of Idaho Falls, Idaho, where it is stored in special canisters.\nHull salvage.\nAt PSNS, the SRP proper begins. The salvage workers cut the submarine into three or four pieces: the aft section, the reactor compartment, the missile compartment if one exists, and the forward section. Missile compartments are dismantled according to the provisions of the Strategic Arms Reductions Treaty.\nUntil 1991, the forward and aft sections of the submarines were rejoined and placed in floating storage. Various proposals for disposal of those hulls were considered, including sinking them at sea, but none proved economically practical. Some submarines built prior to the 1978 banning of polychlorinated biphenyl products (PCBs) had the chemicals on board, which are considered hazardous materials by the Environmental Protection Agency and United States Coast Guard, requiring their removal. Since then, and to help reduce costs, the remaining submarine sections are recycled, returning reusable materials to production. In the process of submarine recycling, all hazardous and toxic wastes are identified and removed, and reusable equipment is removed and put into inventory. Scrap metals and all other materials are sold to private companies or reused. The overall process is not profitable, but does provide some cost relief. Disposal of submarines by the SRP costs the Navy US$25\u201350 million per submarine.\nReactor vessel disposal.\nOnce the de-fueled reactor compartment is removed, it is sealed at both ends and shipped by barge and multiple-wheel high-capacity trailers to the Department of Energy's Hanford Nuclear Reservation in Washington state, where they are currently, , kept in open dry storage and slated to be eventually buried. Russian submarine reactor compartments are stored in similar fashion at Sayda-Guba (Sayda Bay) in northwestern Russia and Chazhma Bay near Vladivostok. The burial trenches have been evaluated to be secure for at least 600 years before the first pinhole penetration of some lead containment areas of the reactor compartment packages occurs, and several thousand years before leakage becomes possible. \nPrior disposal methods.\nIn 1959 the US Navy removed a nuclear reactor from the submarine and replaced it with a new type. The removed reactor was scuttled in the Atlantic Ocean, east of Delaware, at a depth of .\nIn 1972, the London Dumping Convention restricted ocean disposal of radioactive waste and in 1993, ocean disposal of radioactive waste was completely banned. The US Navy began a study on scrapping nuclear submarines; two years later shallow land burial of reactor compartments was selected as the most suitable option.\nIn 1990, was the first US nuclear-powered submarine to be scrapped.\nFuture salvage work.\nBy the end of 2005, 195 nuclear submarines had been ordered or built in the US (including the NR-1 Deep Submergence Craft and , but none of the later ). The last of the regular attack boats, , was decommissioned in 2001, and , a highly modified \"Sturgeon\", was decommissioned in 2004. The last of the initial \"41 for Freedom\" fleet ballistic missile (FBM) submarines, , was decommissioned in 2002. Decommissioning of the boats began in 1995 with . Additionally, a handful of nuclear-powered cruisers have entered the program, and their dismantling is ongoing. The first aircraft carrier due for decommissioning that would enter the SRP is planned to be , which was withdrawn in 2013. Unlike the disposal of other nuclear powered surface ships, all of which have been recycled at the Puget Sound Naval Shipyard and Intermediate Maintenance Facility, the Navy is looking at other, commercial or private sector options for \"Enterprise\" in an effort to reduce both the cost of the work and the time taken to dismantle such a large vessel, as well as negating the difficulty of towing the hulk all the way from Newport News, where it is stored, to Puget Sound. \"Enterprise\" will be used as the pilot project to look at the disposal of nuclear-powered aircraft carriers, with the lessons learned from the ship's eventual scrapping to be incorporated into the plans for the upcoming disposal of the first \"Nimitz\"-class ships. To this end, in 2024, the US Navy established the CVN Inactivation and Disposal Program Office, under the oversight of the Program Executive Office, Aircraft Carriers.\nIn December 2020, it was announced that a further nine \"Los Angeles\"-class attack submarines, two guided missile submarines, and the aircraft carrier would be decommissioned and enter the recycling program by 2026. However, in November 2023, a further announcement was made that, owing to delays in both the construction of ships of the and the Refueling and Complex Overhaul work on the existing \"Nimitz\" class ships, the US Navy was looking to extend the service life of \"Nimitz\" beyond 2026, and , which was planned to decommission in 2027.\nHulls waiting or already processed by the recycling program are listed below.\nLists of vessels by type.\nAircraft carriers.\nIn September 2023, it was announced that, once any remaining radioactive and hazardous material had been removed, ex-\"Enterprise\" would be broken up at a commercial shipyard. In May 2025, a consortium consisting of NorthStar Maritime Dismantlement Services and Modern American Recycling and Radiological Services won the contract to dispose of ex-\"Enterprise\", with the work to be undertaken at a breaker's yard in Mobile, Alabama, and completed by November 2029. As of November\u00a02025[ [update]], the hull remains stored at Hampton Roads.\nCruisers.\n\u2020 A dagger after a completion date indicates that portions of the hull were preserved as memorials. See the individual articles for details.\n(note) ex-\"Long Beach\" has been partially dismantled and remains moored in Puget Sound Naval Shipyard in 2018.\nAttack submarines.\nSome of these submarines (the \"George Washington\" class) were fleet ballistic missile boats for the vast majority of their careers. However, they were briefly converted to SSNs before decommissioning and arrival at PSNS, and so are listed under that designation here. The nuclear-powered research submersible \"NR-1\" is also included in this list.\n\u2020 A dagger after a completion date indicates that portions of the hull were preserved as memorials. See the individual articles for details.\n\u2021 Date given for ex-\"Parche\" is official date used to secure FY2004 funding; work did not begin until 19 October.\n (SSN-701) is currently undergoing conversion to a moored training ship at Norfolk Naval Shipyard. (SSN-711) will be converted after decommissioning.\nBallistic missile submarines.\nSome of these submarines (the \"Lafayette\" class) were fleet ballistic missile boats for the vast majority of their careers. However, they were converted to SSNs for use as moored training platforms and are not currently scheduled for recycling.\n\u2020 A dagger after a completion date indicates that portions of the hull were preserved as memorials. See the individual articles for details.\nBecause the program is underway, this list is almost certainly incomplete.\nNote for ships marked with refit:\n\"Sam Rayburn\" (SSBN-635) was converted into a training platform \u2013 Moored Training Ship (MTS-635). \"Sam Rayburn\" arrived for conversion on 1 February 1986, and on 29 July 1989 the first moored training ship achieved initial criticality. Modifications included special mooring arrangements including a mechanism to absorb power generated by the main propulsion shaft. \"Daniel Webster\" (SSBN-626) was converted to the second Moored Training Ship (MTS-2 / MTS-626) in 1993. The Moored Training Ship Site is located at Naval Weapons Station Charleston in Goose Creek, South Carolina. \"Sam Rayburn\" is scheduled to operate as an MTS until 2014 while undergoing shipyard availabilities at four-year intervals.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29092", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=29092", "title": "States of matter", "text": ""}
{"id": "29095", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=29095", "title": "Situational Dynamics", "text": ""}
{"id": "29096", "revid": "869314", "url": "https://en.wikipedia.org/wiki?curid=29096", "title": "Social Psychology", "text": ""}
{"id": "29098", "revid": "4904587", "url": "https://en.wikipedia.org/wiki?curid=29098", "title": "Shaolin Monastery", "text": "Chan Buddhist temple in Dengfeng, China\nShaolin Monastery (), also known as Shaolin Temple, is a monastic Mahayana Buddhist institution recognized as the birthplace of Chan Buddhism and the cradle of Shaolin kung fu. It is located at the foot of Wuru Peak of the Songshan mountain range in Dengfeng county, Zhengzhou prefecture, in Henan province, China. The name reflects its location in the ancient grove () of Mount Shaoshi, in the hinterland of the Songshan mountains. Mount Song occupied a prominent position among Chinese sacred mountains as early as the 1st century BC, when it was proclaimed one of the Five Holy Peaks (). It is located some southeast of Luoyang, the former capital of the Northern Wei Dynasty (386\u2013534), and southwest of Zhengzhou, the modern capital of Henan Province.\nAs the first Shaolin abbot, Butuo Buddhabhadra devoted himself to translating Buddhist scriptures and preaching doctrines to hundreds of his followers. According to legend, Bodhidharma, the 28th patriarch of Mahayana Buddhism in India, arrived at the Shaolin Temple in 527. He spent nine years meditating in a cave of the Wuru Peak and initiated the Chinese Chan tradition at the Shaolin Temple. Thereafter, Bodhidharma was honored as the first patriarch of Chan Buddhism.\nThe Temple's historical architectural complex, standing out for its great aesthetic value and its profound cultural connotations, has been inscribed in the UNESCO World Heritage List. Apart from its contribution to the development of Chinese Buddhism, as well as for its historical, cultural, and artistic heritage, the temple is famous for its martial arts tradition. Shaolin monks have been devoted to research, creation, and continuous development and perfecting of Shaolin Kung Fu.\nThe main pillars of Shaolin culture are Chan Buddhism (), martial arts (), Buddhist art (), and traditional Chinese medicine (). This cultural heritage, still constituting the daily temple life, is representative of Chinese civilization. A large number of prominent people, eminent monks, Buddhist disciples, and many others visit the temple for pilgrimage and cultural exchanges. In addition, owing to the work of official Shaolin overseas cultural centers and foreign disciples, Shaolin culture has spread around the world as a distinctive symbol of Chinese culture and a means of foreign cultural exchange.\nHistory.\nNorthern Wei and Northern Zhou dynasties.\nBatuo, also referred to in the Chinese sources as Fotuo and in Sanskrit as Buddhabhadra, had enjoyed the sponsorship of the Emperor Xiaowen of Northern Wei since arriving in Pingcheng via the Silk Road, around the year 490. Yang Xuanzhi, in the \"Record of the Buddhist Monasteries of Luoyang\" (AD 547), and Li Xian, in the \"Ming Yitongzhi\" (1461), concur with Daoxuan's location and attribution. The \"Jiaqing Chongxiu Yitongzhi\" (1843) specifies that this monastery, located in the province of Henan, was built in the twentieth year of the \"Taihe\" era of the Northern Wei dynasty, that is, the monastery was built in AD 495.\nThanks to Batuo, Shaolin became an important center for the study and translation of original Buddhist scriptures. It also became a place of gathering for esteemed Buddhist masters. Historical sources on the early origins of Shaolin kung fu show that at this time, martial arts practice existed in the temple. Batuo's teaching was continued by his two disciples, Sengchou (, 480\u2013560) and Huiguang (, 487\u2013536).\nIn the first year of the Yongping era (506), Indian monks Lenamoti (, in Sanskrit: \"Ratnamati\") and Putiliuzhi (, in Sanskrit: \"Bodhiruci\") came to Shaolin to set up a scripture translation hall. Together with Huiguang, they translated master Shiqin's (; in Sanskrit: \"Vasubandhu\") commentary on the Ten Stages Sutra (Sanskrit: \"Da\u015babh\u016bmika S\u016btra\"; simplified Chinese: ), an early, influential Mahayana Buddhist scripture. After that, Huiguang promoted the Vinaya in Four Parts (; Sanskrit: \"Dharmagupta-Vinaya\"), which formed the theoretical basis of the Luzong () School of Buddhism, formed during the Tang Dynasty by Dao Xuan (596\u2013667).\nIn the third year of the Xiaochang era (527) of Emperor Xiaoming of Northern Wei, Bodhidharma (), the 28th patriarch of Mahayana Buddhism in India, came to the Shaolin Temple. The Indian arrived as a Chan Buddhist missionary and traveled for decades throughout China before settling on Mount Song in the 520s. Bodhidharma's teachings were primarily based on the Lankavatara Sutra, which contains the conversation between Gautama Buddha and Bodhisattva Mahamatti, who is considered the first patriarch of the Chan tradition.\nUsing the teachings of Batuo and his disciples as a foundation, Bodhidharma introduced Chan Buddhism, and the Shaolin Temple community gradually grew to become the center of Chinese Chan Buddhism. Bodhidharma's teaching was transmitted to his disciple Huike, who, the legend says, cut off his arm to show his determination and devotion to the teachings of his master. Huike was forced to leave the temple during the persecution of Buddhism and Daoism (574\u2013580) by Emperor Wu of Northern Zhou. In 580, Emperor Jing of Northern Zhou restored the temple and renamed it Zhi'ao Temple ().\nThe idea that Bodhidharma founded martial arts at the Shaolin Temple was spread in the 20th century. However, martial arts historians have shown this legend stems from a 17th-century qigong manual known as the \"Yijin Jing\". The oldest available copy was published in 1827. The composition of the text itself has been dated to 1624. Even then, the association of Bodhidharma with martial arts only became widespread as a result of the 1904\u20131907 serialization of the novel \"The Travels of Lao Ts'an\" in \"Illustrated Fiction Magazine\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;One of the most recently invented and familiar of the Shaolin historical narratives is a story that claims that the Indian monk Bodhidharma, the supposed founder of Chinese Chan (Zen) Buddhism, introduced boxing into the monastery as a form of exercise around a.d. 525. This story first appeared in a popular novel, \"The Travels of Lao T'san\", published as a series in a literary magazine in 1907. This story was quickly picked up by others and spread rapidly through publication in a popular contemporary boxing manual, Secrets of Shaolin Boxing Methods, and the first Chinese physical culture history published in 1919. As a result, it has enjoyed vast oral circulation and is one of the most \"sacred\" of the narratives shared within Chinese and Chinese-derived martial arts. That this story is clearly a twentieth-century invention is confirmed by writings going back at least 250 years earlier, which mention both Bodhidharma and martial arts but make no connection between the two.\nOther scholars see an earlier connection between Da Mo and the Shaolin Monastery. The monk and his disciples are said to have lived at a spot about a mile from the Shaolin Temple that is now a small nunnery.\nIn the 6th century, around AD 547, The Record of the Buddhist Monasteries says Da Mo visited the area near Mount Song. In AD 645, The Continuation of the Biographies of Eminent Monks describes him as being active in the Mount Song region. Around AD 710, Da Mo is identified specifically with the Shaolin Temple (Precious Record of Dharma's Transmission or Chuanfa Baoji) and writes of his sitting facing a wall in meditation for many years. It also speaks of Huike's many trials in his efforts to receive instruction from Da Mo. In the 11th century (1004), a work embellishes the Da Mo legends with great detail. A stele inscription at the Shaolin Monastery dated to 728 AD reveals Da Mo residing on Mount Song. Another stele from AD 798 speaks of Huike seeking instruction from Da Mo. Another engraving, dated to 1209, depicts the barefoot saint holding a shoe, according to the ancient legend of Da Mo. A plethora of 13th- and 14th-century steles feature Da Mo in various roles. One 13th-century image shows him riding a fragile stalk across the Yangtze River. In 1125, a special temple was constructed in his honor at the Shaolin Monastery.\nSui, Tang, Wu Zhou, and Song dynasties.\nEmperor Wen of Sui, who was a Buddhist himself, returned the temple's original name and offered to its community 100 hectares of land. Shaolin thus became a large temple with hundreds of hectares of fertile land and large properties. It was once again the center of Chan Buddhism, with eminent monks from all over China visiting regularly.\nAt the end of the Sui dynasty, the Shaolin Temple, with its huge monastery properties, became the target of thieves and bandits. The monks organized forces within their community to protect the temple and fight against the intruders. At the beginning of the Tang dynasty, thirteen Shaolin monks helped Li Shimin, the future second emperor of the Tang dynasty, in his fight against Wang Shichong. They captured Shichong's nephew Wang Renze, whose army was stationed in the Cypress Valley. In 626, Li Shimin, later known as Emperor Taizong, sent an official letter of gratitude to the Shaolin community for the help they provided in his fight against Shichong and thus the establishment of the Tang dynasty.\nAccording to legend, Emperor Taizong granted the Shaolin Temple extra land and a special \"imperial dispensation\" to consume meat and alcohol during the Tang dynasty. If true, this would have made Shaolin the only temple in China that did not prohibit alcohol. Regardless of historical veracity, these rituals are not practiced today. This legend is not corroborated in any period documents, such as the Shaolin Stele, erected in AD 728. The stele does not list any such imperial dispensation as reward for the monks' assistance during the campaign against Wang Shichong; only land and a water mill are granted. The Tang dynasty also established several Shaolin branch monasteries throughout the country and formulated policies for Shaolin monks and soldiers to assist local governments and regular military troops. The Shaolin Temple also became a place where emperors and high officials would come for temporary reclusion. Emperor Gaozong of Tang and Empress Wu Zetian often visited the temple for good luck and made large donations. Empress Wu also paid several visits to the temple to discuss Chan philosophy with high monk Tan Zong. During the Tang and Song dynasties, the Shaolin Temple was extremely prosperous. It had more than 14,000 acres of land, 540 acres of temple grounds, more than 5,000 rooms, and over 2,000 monks. The Chan Buddhist School, founded by Bodhidharma, flourished during the Tang dynasty and was the largest Buddhist school of that time.\nInformation about the first century of the Northern Song dynasty is scarce. The rulers of Song supported the development of Buddhism, and Chan established itself as dominant over other Buddhist schools. Around 1093, Chan master Baoen () promoted the Caodong School in the Shaolin Temple and achieved what is known in Buddhist history as \"revolutionary turn into Chan\". This meant that the Shaolin Temple officially became a Chan Buddhist Temple, while up to that point it was a L\u01dcz\u014dng temple specialized in Vinaya, with a Chan Hall.\nYuan, Ming, and Qing dynasties.\nAt the beginning of the Yuan dynasty, Emperor Shizu of Yuan installed the monk Xueting Fuyu (, 1203\u20131275) as the abbot of Shaolin and put him in charge of all the temples in the Mount Song area. During this period, the abbot undertook important construction work, including the building of the Bell Tower and the Drum Tower. He also introduced the generational lineage system of the Shaolin disciples through a 70-character poem\u2014each character in line corresponding to the name of the next generation of disciples. In 1260, Fuyu was honored with the title of the Divine Buddhist Master, and in 1312, posthumously named Duke of Jin () by the Yuan emperor.\nThe fall of the Yuan dynasty and the establishment of the Ming dynasty brought much unrest, in which the temple community needed to defend itself from rebels and bandits. During the Red Turban Rebellion in the 14th century, bandits ransacked the monastery for its real or supposed valuables, destroying much of the temple and driving the monks away. The monastery was likely abandoned from 1351 or 1356 (the most likely dates for the attack) to at least 1359, when government troops retook Henan. The events of this period would later figure heavily in 16th-century legends of the temple's patron saint Vajrapani, with the story being changed to claim a victory for the monks, rather than a defeat.\nWith the establishment of the Ming dynasty in the mid-14th century, Shaolin recovered, and a large part of the monastic community that had fled during the Red Turban attacks returned. At the beginning of the Ming dynasty, the government did not advocate martial arts. During the reign of the Jiajing Emperor, Japanese pirates harassed China's coastal areas, and generals Yu Dayou and Qi Jiguang led their troops against the pirates. During his stay in Fujian, Qi Jiguang convened martial artists from all over China, including local Shaolin monks, to develop a set of boxing and staff fighting techniques to be used against Japanese pirates. Owing to the monks' merits in fighting against the Japanese, the government renovated the temple on a large scale, and Shaolin enjoyed certain privileges, such as food tax exemption, granted by the government. Afterward, Shaolin monks were recruited by the Ming government at least six times to participate in wars. Due to their outstanding contribution to Chinese military success, the imperial court built monuments and buildings for the Shaolin Temple on numerous occasions. This also contributed to the establishment of the legitimacy of Shaolin kung fu in the national martial arts community. During the Ming Dynasty (in the mid-16th century), Shaolin reached its apogee and held its position as the central place of the Caodong School of Chan Buddhism.\nIn 1641, rebel forces led by Li Zicheng sacked the monastery due to the monks' support of the Ming dynasty and the possible threat they posed to the rebels. This effectively destroyed the temple's fighting force. The temple fell into ruin and was home to only a few monks until the early 18th century, when the government of the Qing dynasty patronized and restored it.\nDuring the Qing dynasty, Shaolin Temple was favored by Qing emperors. In the 43rd year of the Kangxi Emperor's reign (1704), the emperor gifted a tablet to the temple, with the characters () engraved on it in his calligraphy (originally hung in the Heavenly King Hall and later moved by the Mountain Gate). In the 13th year of the Yongzheng Emperor's reign (1735), important reconstructions were financed by the court, including the rebuilding of the gate and the Thousand Buddha's Hall. In the 15th year of his rule (1750), the Qianlong Emperor personally visited Shaolin Temple, stayed at the abbot's room overnight, and wrote poems and tablet inscriptions.\nA well-known story of the temple from this period is that it was destroyed by the Qing government for supposed anti-Qing activities. Variously said to have taken place in 1647 under the Shunzhi Emperor, in 1674, 1677, or 1714 under the Kangxi Emperor, or in 1728 or 1732 under the Yongzheng Emperor, this destruction is also supposed to have helped spread Shaolin martial arts throughout China by means of the five fugitive monks. Some accounts claim that a supposed southern Shaolin Temple was destroyed instead of, or in addition to, the temple in Henan: Ju Ke, in the \"Qing bai lei chao\" (1917), locates this temple in Fujian. These stories commonly appear in legendary or popular accounts of martial history and in \"wuxia\" fiction.\nWhile these latter accounts are popular among martial artists and often serve as origin stories for various martial arts styles, they are viewed by scholars as fictional. The accounts are known through often inconsistent 19th-century secret society histories and popular literature, and also appear to draw on both Fujianese folklore and popular narratives, such as the classical novel \"Water Margin\". Modern scholarly attention to the tales is mainly concerned with their role as folklore.\nRepublic of China.\nIn the early days of the Republic of China, the Shaolin Temple was repeatedly hit by wars. In 1912, monk Yunsong Henglin from the Dengfeng County Monks Association was elected by the local government as the head of the Shaolin Militia (Shaolin Guarding Corps). He organized the guards and trained them in combat skills to maintain local order. In the autumn of 1920, famine and drought hit Henan province, which led to thieves surging throughout the area and endangering the local community. Henglin led the militia to fight the bandits on different occasions, thus enabling dozens of villages in the temple's surroundings to live and work in peace.\nIn the late 1920s, Shaolin monks became embroiled in the warlords' feuds that swept the plains of northern China. They sided with General Fan Zhongxiu (1888\u20131930), who had studied martial arts at Shaolin Temple as a child, against Shi Yousan (1891\u20131940). Fan was defeated and, in the spring of 1928, Yousan's troops entered Dengfeng and Shaolin Temple, which served as Fan Zongxiu's headquarters. On 15 March, Feng Yuxiang's subordinate Shi Yousan set fire to the monastery, destroying some of its ancient towers and halls. The flames partially damaged the \"Shaolin Monastery Stele\" (which recorded the politically astute choice made by other Shaolin clerics fifteen hundred years earlier), the Dharma Hall, the Heavenly King Hall, Daxiongbao Hall, Bell Tower, Drum Tower, Sixth Ancestor Hall, Chan Hall, and other buildings, causing the death of several monks. A large number of cultural relics and 5,480 volumes of Buddhist scriptures were destroyed in the fire.\nJapan's activities in Manchuria in the early 1930s made the National Government very worried. The military then launched a strong patriotic movement to defend the country and resist the enemy. The Nanjing Central Martial Arts Center and Wushu Institute, together with other martial arts institutions, were established around the country as part of this movement. The government also organized martial arts events such as \"Martial arts returning to Shaolin\". This particular event served to encourage people to remember the importance of patriotism by celebrating the contribution of Shaolin martial arts to the country's defense from foreign invasion on numerous occasions throughout history.\nPeople's Republic of China.\nSince the founding of the People's Republic of China in 1949, the state officially became atheist, with roughly half of the population identifying as nonreligious or atheist. Some state-monitored religions and practices were allowed, while others, like Tibetan Buddhism, were persecuted after the takeover of Tibet by the Chinese military in 1959.\nDuring the Cultural Revolution, the monks of Shaolin Temple were forced to return to secular life, Buddha statues were destroyed, and temple properties were invaded. After this period ended, the Shaolin Temple was repaired and rebuilt. The buildings and other material heritage that were destroyed, including the Daxiongbao Hall and the stone portraying \"Bodhidharma facing the wall\", were reconstructed according to their originals. Others, such as the ancient martial arts training ground, the Pagoda Forest, and some stone carvings that survived, remain in their original state. In December 1996, Chuzu Temple and Shaolin Temple Pagoda Forest (No. 4-89) were listed as national key cultural relic protection units. The Shaolin Temple leadership aimed for its historical architectural complex to become a United Nations World Heritage site in order to obtain annual funding for maintenance and development from the UN. After repeated submissions, their application was finally accepted by the 34th World Heritage Committee on 1 August 2010. UNESCO reviewed and approved eight sites and eleven architectural complexes, including Shaolin's Resident Hall, Pagoda Forest, and Chuzu Temple as World Cultural Heritage.\nIn 1994, the temple registered its name as a trademark. In the late 2000s, Shi Yongxin began authorizing Shaolin branches outside of mainland China in what has been called a franchise scheme. The branches are run by current and former monks and allow dispersion of Shaolin culture and study of Shaolin kung fu around the world. As of January 2011, Yongxin and the temple operated over forty companies in cities across the world, including London and Berlin, which have purchased land and property.\nIn 2018, for the first time in its 1,500-year history, the Shaolin Monastery raised the national flag of China as part of a \"patriotism drive\" under the new National Religious Affairs Administration, a part of the United Front Work Department of the Chinese Communist Party (CCP), which \"oversees propaganda efforts as well as relations with the global Chinese diaspora\". Senior theology lecturer Sze Chi Chan of Hong Kong Baptist University interpreted this move as CCP general secretary Xi Jinping making an example of the Shaolin Monastery to send a message to other temples and the Chinese Catholic Church.\nGovernance.\nThe monastery was historically led by an abbot. However, Communist restrictions on religious expression and independence have changed this ancient system. The monastery is currently led by a committee composed primarily of government officials. The treasurer is appointed by the government, and as such, the abbot has little control over monastery finances. The monastery splits its profits with Dengfeng: the municipality takes two-thirds of the profits, and the monastery retains one-third.\nAbbots.\nBatuo (\u8dcb\u9640), Buddhabhadra 495 CE\nShi Yongxin (\u91cb\u6c38\u4fe1), 1999\u20132025\nShi Yinle (\u91ca\u5ef6\u4e50), appointed 29 July 2025\nShaolin culture.\nHeritage culture.\nThe Shaolin Temple has developed numerous complementary cultural aspects that permeate and mutually reinforce each other and are inseparable when it comes to presenting the temple's material and intangible cultural heritage. The most prominent aspects are those of Chan (), martial arts (), traditional medicine (), and art (). Shaolin culture is rooted in Mahayana Buddhism, while the practice of Chan is its nucleus, and finally, the martial arts, traditional medicine, and art are its manifestations. Thanks to the efforts of the abbot Shi Yongxin, the monastic community, and the temple's disciples from all over the world, Shaolin culture continues to grow. During its historical development, Shaolin culture has also integrated the essential values of Confucianism and Taoism.\nThe contemporary temple establishment offers to all interested individuals and groups, regardless of cultural, social, and religious values, the chance to experience Shaolin culture through the Shaolin cultural exchange program. This program offers an introduction to Chan meditation, Shaolin kung fu, Chan medicine, calligraphy, art, archery, etc. Chan practice is supposed to help the individual in attaining calm and patience necessary for living optimistically, meaningfully, wisely, and with compassion. Ways of practicing Chan are numerous, and they range from everyday activities such as eating, drinking, walking, or sleeping, to specialized practices such as meditation, martial arts, and calligraphy.\nShaolin kung fu is manifested through a system of different skills that are based on attack and defense movements with the form () as its unit. One form is a combination of different movements. The structure of movements is founded on ancient Chinese medical knowledge, which is compatible with the laws of body movement. Within the temple, the forms are taught with a focus on integration of the principles of complementarity and opposition. This means that Shaolin kung fu integrates dynamic and static components, yin and yang, hardness and softness, etc.\nThe Shaolin community invests great effort in safeguarding, developing, and innovating its heritage. Following the ancient Chinese principle of harmony between heaven and humans, temple masters work on the development of the most natural body movement in order to achieve the full potential of human expression.\nShaolin has developed activities related to the international promotion of its cultural heritage. In 2012, the first international Shaolin cultural festival was organized in Germany, followed by festivals in the US and England. Official Shaolin cultural centers exist in numerous countries in Europe, the US, Canada, and Russia. Every year, the temple hosts more than thirty international events to promote cultural exchange.\nInternational promotion of Shaolin cultural heritage.\nThe Shaolin Temple is an important religious and cultural institution, both in China and internationally. Since the founding of the People's Republic of China, and especially since the 1970s, cultural exchanges between Shaolin Temple and the rest of the world have continuously improved in terms of content, scale, frequency, and scope. The temple has been visited by European and American dancers, martial artists, NBA players, Hollywood movie stars, and also renowned monks from traditional Buddhist countries such as Myanmar, Thailand, Cambodia, Nepal, and Sri Lanka. Also, many political leaders, such as Swedish King Carl XVI Gustaf, British Queen Elizabeth II, Spanish King Juan Carlos I, Australia's former prime minister John Howard, South Africa former president Nelson Mandela, Russian president Vladimir Putin, former US secretary of state Henry Kissinger, and Taiwanese politician James Soong have met with the temple's abbot.\nThere are more than forty overseas cultural institutions established by the temple's leadership and its disciples in dozens of countries around the world. Shaolin monks come to the centers to teach Buddhist classics, martial arts, meditation, etc. Another way of promoting Shaolin's intangible cultural heritage in the world is through Shaolin Cultural Festivals, the first of which was held in North America. These festivals and similar events convey the spiritual connotation of Chinese culture and Eastern values to societies internationally.\nMyths of Shaolin.\nAsian monks are typically portrayed in Western culture as being knowledgeable, at peace, as well as spiritual individuals. Additionally, they are depicted as wise mystics who offer spiritual advice. This stereotype's beginnings can be traced to the 19th century, when Western explorers and missionaries first started to come into contact with Buddhist monks in Asia. The monks were typically romanticized as otherworldly, enigmatic individuals who had achieved a profound spiritual perception of reality. Despite being a poor oversimplification of the variety of beliefs, practices, and experiences among Buddhist monks, the stereotype has persisted. Jane Iwamura calls this phenomenon \"virtual Orientalism\" and states that it \"declares an independence from the real but also co-opts or colonizes the real\".\nArchitectural complex of Shaolin Temple.\nProtection of the site.\nThe original Shaolin Temple was burned to the ground in 1928 by Shi Yousan, a renegade nationalist warlord. The monks were either killed or deported. The ground lay more or less abandoned, and under CCP chairman Mao Zedong's Cultural Revolution, it suffered additional damage. However, in 1982, six years after Mao's death in 1976, the Law on the Protection of Cultural Heritage of the People's Republic of China was passed.\nThe Songshan Scenic Area, established that year, came to include the Shaolin Temple Scenic Spot. \"Scenic areas\" were created by the 1982 law as protected regions valuable to the public for their natural or cultural assets. The Songshan Scenic Area covers the mountains around Denfeng. In 1990, the Ministry of Construction and Tongji University proposed that scenic areas be divided into subregions called \"Scenic Spots\". When this measure was passed by the state council (central government), the \"Songshan National Scenic Area\" (SNSA) acquired the \"Shaolin Temple Scenic Spot\" (STSS), consisting of the Shaosi side of the Scenic Area. Though named after the famous monastery in the south of the spot, it also included the north, where the government established a kung fu academy, the largest in China. The scenic spot consists of the entire park.\nThe government promptly allocated funds for the reconstruction of the monastery as a tourist site. They were to rebuild nine halls, restore ten, and construct eight new ones. However, all documentation on the temple had been destroyed. Already familiar with the type of structure, the architects interviewed elders who had been at the monastery before 1928 for details.\nThe task became greater than simply restoring the monastery of 1928. That monastery was the end point of a long line of development, which included reconstruction after some twenty or more previous destructions, and variations in size from twenty monks during the Tang dynasty (619\u2013907) to more than 1,800 monks living in 5,000 rooms during the Yuan dynasty (1271\u20131368). No single configuration representative of the entire span of the monastery was apparent. Multiple possibilities existed, and deliberations about what to restore were complex and prolonged. By 1998, the government of Dengfeng had reconstructed or restored fourteen architectural items, mostly buildings.\nBy 2010, it was obvious that management decisions were beyond merely the government. A new management was created that year to operate a joint venture between the government, a private company from Hong Kong, and the abbot of a newly constituted body of monks. They were empowered to maintain a balance between historical authenticity and tourist sustainability.\nUNESCO was not far behind this change in management technique. It took an interest and was invited to participate. In 2010, several ancient sites around Dengfeng were united into a single UNESCO World Heritage Site, with eight distinct scenic spots. The Shaolin Scenic spot contained three of the WHS components, collectively called the \"architectural complex\". By this, the International Council on Monuments and Sites (ICOMOS) of UNESCO designated three ancient sites: the Shaolin Temple compound, assigned the name \"Kernel Compound\"; its cemetery, the Pagoda Forest; and its subsidiary, the Chuzu Temple.\nAccess to the site.\nThe Shaolin Temple Scenic Spot is located approximately in the middle of Mount Song, an E\u2013W trending massif on the right bank of the Yellow River. The massif is terminated by Luoyang on the west side and Zhengzhou on the east. The straight-line distance from Luoyang to Shaolin is about ; from Zhengzhou, about . Either city is a popular starting point for a bus or automobile tour to the site.\nMount Song is divided by an extensive valley on its south-central side, where much of Dengfeng is located. The mountains around the valley, forming an upside-down U, have been defined as the Songshan Scenic Area. The pass over the U is located directly north of the valley. On the western side is the Shaolin Scenic Spot, accessed by China National Highway 207 (G207), which winds over the pass from the direction of Luoyang and runs past the scenic spot, before descending into the valley and joining other roads leading to Zhengzhou. The north entrance of the scenic spot adjoins G207.\nThe North Gate is an entirely new complex built to facilitate the arrival and departure of visitors along the main point of entry, Highway G207. The local highway representing G207 in this case is East Ring Road, Dengfeng. The Shaolin bus stop is at the minimum of the southward-curving highway, at .\nTopography.\nThe temple's inside area is , or . The buildings are arranged in three lengthwise strips. It has seven main halls on the central axis and seven other halls around, with several yards around the halls. These halls are primarily museums containing Buddhist artifacts. Memorials and monuments are scattered freely around the place, as are ancient ginkgo trees.\nThe architecture below follows the World Heritage Site (WHS) arrangement.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29102", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=29102", "title": "Sycorax (disambiguation)", "text": "Sycorax is a character mentioned though not seen in William Shakespeare's play \"The Tempest\".\nSycorax may also refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "29103", "revid": "39949103", "url": "https://en.wikipedia.org/wiki?curid=29103", "title": "Seymour Cray", "text": "American supercomputer architect (1925\u20131996)\nSeymour Roger Cray (September 28, 1925\u00a0\u2013 October 5, 1996) was an American electrical engineer and supercomputer architect who designed a series of computers that were the fastest in the world for decades, and founded Cray Research, which built many of these machines. Called \"the father of supercomputing\", Cray has been credited with creating the supercomputer industry. Joel S. Birnbaum, then chief technology officer of Hewlett-Packard, said of him: \"It seems impossible to exaggerate the effect he had on the industry; many of the things that high performance computers now do routinely were at the farthest edge of credibility when Seymour envisioned them.\" Larry Smarr, then director of the National Center for Supercomputing Applications at the University of Illinois said that Cray is \"the Thomas Edison of the supercomputing industry.\"\nEarly life.\nCray was born in 1925 in Chippewa Falls, Wisconsin, to Seymour R. and Lillian Cray. His father was a civil engineer who fostered Cray's interest in science and engineering. As early as the age of ten he was able to build a device out of Erector Set components that converted punched paper tape into Morse code signals. The basement of the family home was given over to the young Cray as a \"laboratory\".\nCray graduated from Chippewa Falls High School in 1943 before being drafted for World War II as a radio operator. He saw action in Europe, and then moved to the Pacific theatre where he worked on breaking Japanese naval codes. On his return to the United States he earned a B.Sc. in electrical engineering at the University of Minnesota, graduating in 1949, followed by a M.Sc. in applied mathematics in 1951.\nCareer.\nEngineering Research Associates.\nIn 1950, Cray joined Engineering Research Associates (ERA) in Saint Paul, Minnesota. ERA had formed out of a former United States Navy laboratory that had built codebreaking machines, a tradition ERA carried on when such work was available. ERA was introduced to computer technology during one such effort, but in other times had worked on a wide variety of basic engineering as well.\nCray quickly came to be regarded as an expert on digital computer technology, especially following his design work on the ERA 1103, the first commercially successful scientific computer. He remained at ERA when it was bought by Remington Rand and then Sperry Corporation in the early 1950s. At the newly formed Sperry Rand, ERA became the scientific computing arm of their UNIVAC division.\nControl Data Corporation.\nCray, along with William Norris, later became dissatisfied with ERA, then spun off as Sperry Rand. In 1957, they founded a new company, Control Data Corporation.\nBy 1960 he had completed the design of the CDC 1604, an improved low-cost ERA 1103 that had impressive performance for its price. Even as the CDC 1604 was starting to ship to customers in 1960, Cray had already moved on to designing other computers. He first worked on the design of an upgraded version (the CDC 3000 series), but company management wanted these machines targeted toward \"business and commercial\" data processing for average customers. Cray did not enjoy working on such \"mundane\" machines, constrained to design for low-cost construction, so CDC could sell many of them. His desire was to \"produce the largest [fastest] computer in the world\". So after some basic design work on the CDC 3000 series, he turned that over to others and went on to work on the CDC 6600. Nonetheless, several special features of the 6600 first started to appear in the 3000 series.\nAlthough in terms of hardware the 6600 was not on the leading edge, Cray invested considerable effort into the design of the machine in an attempt to enable it to run as fast as possible. Unlike most high-end projects, Cray realized that there was considerably more to performance than simple processor speed, that I/O bandwidth had to be maximized as well in order to avoid \"starving\" the processor of data to crunch. He later noted, \"Anyone can build a fast CPU. The trick is to build a fast system.\"\nThe 6600 was the first commercial supercomputer, outperforming everything then available by a wide margin. While expensive, for those that needed the fastest computer available there was nothing else on the market that could compete. When other companies (namely IBM) attempted to create machines with similar performance, they stumbled (IBM 7030 Stretch). In the 6600, Cray had solved the critical design problem of \"imprecise interrupts\", which was largely responsible for IBM's failure. He did this by replacing I/O interrupts with a polled request issued by one of ten so-called peripheral processors, which were built-in mini-computers that did all transfers in and out of the 6600's central memory. The following CDC 7600 even improved the speed advantage by a factor of five.\nIn 1963, in a \"Business Week\" article announcing the CDC 6600, Seymour Cray clearly expressed an idea that is often misattributed to Herb Grosch as so-called Grosch's law:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Computers should obey a square law\u00a0\u2014 when the price doubles, you should get at least four times as much speed.\u2014\u200a\nCDC's Chippewa Falls laboratory.\nDuring this period Cray had become increasingly annoyed at what he saw as interference from CDC management. Cray always demanded an absolutely quiet work environment with a minimum of management overhead, but as the company grew he found himself constantly interrupted by middle managers who\u00a0\u2013 according to Cray\u00a0\u2013 did little but gawk and use him as a sales tool by introducing him to prospective customers.\nCray decided that in order to continue development he would have to move from St. Paul, far enough that it would be too long a drive for a \"quick visit\" and long-distance telephone charges would be just enough to deter most calls, yet close enough that real visits or board meetings could be attended without too much difficulty. After some debate, Norris backed him and set up a new laboratory on land Cray owned in his hometown of Chippewa Falls. Part of the reason for the move may also have to do with Cray's worries about an impending nuclear war, which he felt made the Twin Cities a serious safety concern. His house, built a few hundred yards from the new CDC laboratory, included a huge bomb shelter.\nThe new Chippewa Lab was set up during the middle of the 6600 project, although it does not seem to have delayed the project. After the 6600 shipped, the successor CDC 7600 system was the next product to be developed in Chippewa Falls, offering peak computational speeds of ten times the 6600. The failed follow-on to the 7600, the CDC 8600, was the project that finally ended his run of successes at CDC in 1972.\nAlthough the 6600 and 7600 had been huge successes in the end, both projects had almost bankrupted the company while they were being designed. The 8600 was running into similar difficulties and Cray eventually decided that the only solution was to start over fresh. This time Norris was not willing to take the risk, and another project within the company, the CDC STAR-100, seemed to be progressing more smoothly. Norris said he was willing to keep the project alive at a low level until the STAR was delivered, at which point full funding could be put into the 8600. Cray was unwilling to work under these conditions and left the company.\nCray Research.\nThe split was fairly amicable, and when he started Cray Research in a new laboratory on the same Chippewa property a year later, Norris invested $250,000 in start-up money. Like CDC's organization, Cray R&amp;D was based in Chippewa Falls and business headquarters were in Minneapolis. Unlike CDC, Cray's manufacturing was also in Chippewa Falls.\nAt first there was some question as to what exactly the new company should do. It did not seem that there would be any way for them to afford to develop a new computer, given that the now-large CDC had been unable to support more than one. When the President in charge of financing traveled to Wall Street to look for seed money, he was surprised to find that Cray's reputation was very well known. Far from struggling for some role to play in the market, Cray would find the financial world more than willing to provide all the money needed to develop a new machine.\nAfter several years of development, their first product was released in 1976 as the Cray-1. As with earlier Cray designs, the Cray-1 made sure that the \"entire\" computer was fast, as opposed to just the processor. When it was released it easily beat almost every machine in terms of speed, including the STAR-100 that had beaten the 8600 for funding. The only machine able to perform on the same sort of level was the ILLIAC IV, a specialized one-off machine that rarely operated near its maximum performance, except on very specific tasks. In general, the Cray-1 beat anything on the market by a wide margin.\nSerial number 001 was \"lent\" to Los Alamos National Laboratory in 1976, and that summer the first full system was sold to the National Center for Atmospheric Research (NCAR) for $8.8 million. The company's early estimates had suggested that they might sell a dozen such machines, based on sales of similar machines from the CDC era, so the price was set accordingly. Eventually, well over 80 Cray-1s were sold, the company was a huge success financially, and Cray's innovations with super computers won him the nickname \"The Wizard of Chippewa Falls\".\nFollow-up success was not as easy. While he worked on the Cray-2, other teams delivered the two-processor Cray X-MP, which was another huge success and later the four-processor X-MP. When the Cray-2 was finally released after six years of development it was only marginally faster than the X-MP, largely due to very fast and large main memory, and thus it sold in much smaller numbers. The Cray-2 ran at 250\u00a0MHz with a very deep pipeline, making it harder to write code than for the shorter-pipe X-MP.\nAs the Cray-3 project started, he found himself once again being \"bothered\" too much with day-to-day tasks. In order to concentrate on design, Cray left the CEO position of Cray Research in 1980 to become an independent contractor. In 1988, he moved the Cray-3 project from Chippewa Falls to a laboratory in Colorado Springs, Colorado.\nIn 1989, Cray was faced with a repeat of history when the Cray-3 started to run into difficulties. An upgrade of the X-MP using high-speed memory from the Cray-2 was under development and seemed to be making real progress, and once again management was faced with two projects and limited budgets. They eventually decided to take the safer route, releasing the new design as the Cray Y-MP.\nCray Computer Corporation.\n&lt;templatestyles src=\"Plain image with caption/styles.css\"/&gt; \nLogo of Cray Computer Corporation \nCray decided to spin off the Colorado Springs laboratory to form Cray Computer Corporation. This new entity took the Cray-3 project with them.\nThe 500\u00a0MHz Cray-3 proved to be Cray's second major failure. In order to provide the tenfold increase in performance that he always demanded of his newest machines, Cray decided that the machine would have to be built using gallium arsenide semiconductors. In the past Cray had always avoided using anything even near the state of the art, preferring to use well-known solutions and designing a fast machine based on them. In this case, Cray was developing every part of the machine, even the chips inside it.\nNevertheless, the team were able to get the machine working and delivered their first example to NCAR on 24 May 1993.\nThe machine was still essentially a prototype, and the company was using the installation to debug the design. By this time a number of massively parallel machines were coming into the market at price/performance ratios the Cray-3 could not touch. Cray responded through \"brute force\", starting design of the Cray-4, which would run at 1\u00a0GHz and outpower these machines, regardless of price.\nIn 1995 there had been no further sales of the Cray-3, and the ending of the Cold War made it unlikely anyone would buy enough Cray-4s to offer a return on the development funds. The company ran out of money and filed for Chapter 11 bankruptcy 24 March 1995.\nSRC Computers.\nCray had always resisted the massively parallel solution to high-speed computing, offering a variety of reasons that it would never work as well as one very fast processor. He famously quipped \"If you were plowing a field, which would you rather use: two strong oxen or 1024 chickens?\" By the mid-1990s, this argument was becoming increasingly difficult to justify, and modern compiler technology made developing programs on such machines not much more difficult than their simpler counterparts.\nCray set up a new company, SRC Computers, and started the design of his own massively parallel machine. The new design concentrated on communications and memory performance, the bottleneck that hampered many parallel designs. Design had just started when Cray was killed in a car accident. SRC Computers carried on development and specialized in reconfigurable computing.\nTechnical approaches.\nCray frequently cited two important aspects to his design philosophy: remove heat, and ensure that all signals that are supposed to arrive somewhere at the same time do indeed arrive at the same time.\nHis computers were equipped with built-in cooling systems, extending ultimately to coolant channels cast into the mainframes and thermally coupled to metal plates within the circuit boards, and to systems immersed in coolants. In a story he told about himself, he realized early in his career that he should interlock the computers with the cooling systems so that the computers would not operate unless the cooling systems were operational. It did not originally occur to him to interlock in the other direction until a customer reported that localized power outages had shut down their computer, but left the cooling system running\u00a0\u2014 so they arrived in the morning to find the machine encased in ice.\nCray addressed the problem of skew by ensuring that every signal path in his later computers was the same electrical length, so that values that were to be acted upon at a particular time were indeed all valid values. When required, he would run the traces back and forth on the circuit boards until the desired length was achieved, and he employed Maxwell's equations in design of the boards to ensure that any radio frequency effects which altered the signal velocity and hence the electrical path length were accounted for.\nWhen asked what kind of CAD tools he used to design computers, Cray said that he liked pads of 8&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442\u2033 \u00d7 11\u2033 \"faintly-ruled &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444-inch quadrille\" paper.\nList of computers.\nCray was involved in the design of the following computers:\nPersonal life.\nCray married Verene Voll in 1947. They had known each other since childhood. She was the daughter of a Methodist minister, as was Cray's mother, and Verene worked as a nutritionist. They had three children. Cray and Voll divorced around 1978. He later married Geri M. Harrand. Cray was the grandfather of Andrew Cray, an LGBTQ rights activist.\nCray avoided publicity. There are a number of unusual tales about his life away from work, termed \"Rollwagenisms\", from then-CEO of Cray Research, John A. Rollwagen. Cray enjoyed skiing, windsurfing, tennis, and other sports. Another favorite pastime was digging a tunnel under his home; he attributed the secret of his success to \"visits by elves\" while he worked in the tunnel: \"While I'm digging in the tunnel, the elves will often come to me with solutions to my problem.\"\nOne story has it that when Cray was asked by management to provide detailed one-year and five-year plans for his next machine, he simply wrote, \"Five-year goal: Build the biggest computer in the world. One year goal: One-fifth of the above.\" And another time, when expected to write a multi-page detailed status report for the company executives, Cray's two-sentence report read: \"Activity is progressing satisfactorily as outlined under the June plan. There have been no significant changes or deviations from the June plan.\"\nCray was mortally wounded in a rollover accident caused by a reckless driver while Cray was merging his Jeep Cherokee onto Interstate 25, near the Air Force Academy in Colorado. Cray died of his injuries on October 5, 1996, two weeks after the accident and one week after his 71st birthday.\nPosthumous.\nThe IEEE Computer Society's Seymour Cray Computer Engineering Award, established in late 1997, recognizes innovative contributions to high performance computing systems exemplifying Cray's creative spirit.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29105", "revid": "36961620", "url": "https://en.wikipedia.org/wiki?curid=29105", "title": "Signature block", "text": "Type of personalized block\nA signature block (often abbreviated as signature, sig block, sig file, .sig, dot sig, siggy, or just sig) is a personalized block of text automatically appended at the bottom of an email message, Usenet article, or forum post.\nEmail and Usenet.\nAn email signature is a block of text appended to the end of an email message often containing the sender's name, address, phone number, disclaimer or other contact information.\n\"Traditional\" internet cultural .sig practices assume the use of monospaced ASCII text because they pre-date MIME and the use of HTML in email. In this tradition, it is common practice for a signature block to consist of one or more lines containing some brief information on the author of the message such as phone number and email address, URLs for sites owned or favoured by the author\u2014but also often a quotation (occasionally automatically generated by such tools as fortune), or an ASCII art picture. \nAmong some groups of people it has been common to include .\n |\\_/| **************************** (\\_/)\n / @ @ \\ * \"Purrrfectly pleasant\" * (='.'=)\n ( &gt; \u00ba &lt; ) * Poppy Prinz * (\")_(\")\n `\u00bbx\u00ab\u00b4 * (pprinz@example.com) *\n / O \\ ****************************\n\"Example of a signature block using ASCII art.\"\nMost email clients, including Mozilla Thunderbird, Opera Mail, Microsoft Outlook, Outlook Express, and Eudora, can be configured to automatically append an email signature with each new message. A shortened form of a signature block (sometimes called a \"signature line\"), only including one's name, often with some distinguishing prefix, can be used to simply indicate the end of a post or response. Most email servers can be configured to append email signatures to all outgoing mail as well.\nEmail signature generator.\nAn email signature generator is an app or an online web app that allows users to create a designed email signature using a pre-made template (with no need for HTML coding skills).\nSignatures in Usenet postings.\nSignature blocks are also used in the Usenet discussion system.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a\nEmail signatures in business.\nBusinesses often automatically append signature blocks to messages\u2014or have policies mandating a certain style. Generally they resemble standard business cards in their content\u2014and often in their presentation\u2014with company logos and sometimes even the exact appearance of a business card. In some cases, a vCard is automatically attached.\nIn addition to these standard items, email disclaimers of various sorts are often automatically appended. These are typically couched in legal jargon, but it is unclear what weight they have in law, and they are routinely lampooned.\nBusiness emails may also use some signature block elements mandated by local laws:\nWhile criticized by some as overly bureaucratic, these regulations only extend existing laws for paper business correspondence to email.\nStandard delimiter.\nThe Usenet news system standards say that a signature block is conventionally delimited from the body of the message by a single line consisting of exactly two hyphens, followed by a space, followed by the end of line (i.e., in C-notation: codice_1). This latter prescription goes by many names, including \u201cdash dash space\u201d, \"sig dashes\", \"signature cut line\", \"sig-marker\", \"sig separator\" and \"signature delimiter\". It allows software to automatically mark or remove the sig block as the receiver desires.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a\nMost Usenet clients (including, for example, Mozilla Thunderbird) will recognize the signature block delimiter in a news article and will cut off the signature below it when inserting a quote of the original message into the composition window for a reply. Although the Usenet standards strictly apply only to Usenet news articles, this same delimiter convention is widely used in email messages as well, and email clients (such as K-9, Opera Mail, and Gmail commonly use it for recognition and special handling of signatures in email.\nInternet forums.\nOn web forums, the rules are often less strict on how a signature block is formatted, as Web browsers typically are not operated within the same constraints as text interface applications. Users will typically define their signature as part of their profile. Depending on the board's capabilities, signatures may range from a simple line or two of text to an elaborately constructed HTML piece. Images are often allowed as well, including dynamically updated images usually hosted remotely and modified by a server-side script. In some cases avatars or hackergotchis take over some of the role of signatures.\nFidoNet.\nWith FidoNet, echomail and netmail software would often add an origin line at the end of a message. This would indicate the FidoNet address and name of the originating system (not the user). The user posting the message would generally not have any control over the origin line. However, single-line taglines, added under user control, would often contain a humorous or witty saying. Multi-line user signature blocks were rare.\nHowever, a tearline standard for FidoNet was included in FTS-0004 and clarified in FSC-0068 as three dashes optionally followed by a space optionally followed by text."}
{"id": "29106", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=29106", "title": "Sig block", "text": ""}
{"id": "29107", "revid": "40347300", "url": "https://en.wikipedia.org/wiki?curid=29107", "title": "Semantics", "text": "Study of meaning in language\nSemantics is the study of linguistic meaning. It examines what meaning is, how words get their meaning, and how the meaning of a complex expression depends on its parts. Part of this process involves the distinction between sense and reference. Sense is given by the ideas and concepts associated with an expression while reference is the object to which an expression points. Semantics contrasts with syntax, which studies the rules that dictate how to create grammatically correct sentences, and pragmatics, which investigates how people use language in communication. Semantics, together with syntactics and pragmatics, is a part of semiotics.\nLexical semantics is the branch of semantics that studies word meaning. It examines whether words have one or several meanings and in what lexical relations they stand to one another. Phrasal semantics studies the meaning of sentences by exploring the phenomenon of compositionality or how new meanings can be created by arranging words. Formal semantics relies on logic and mathematics to provide precise frameworks of the relation between language and meaning. Cognitive semantics examines meaning from a psychological perspective and assumes a close relation between language ability and the conceptual structures used to understand the world. Other branches of semantics include conceptual semantics, computational semantics, and cultural semantics.\nTheories of meaning are general explanations of the nature of meaning and how expressions are endowed with it. According to referential theories, the meaning of an expression is the part of reality to which it points. Ideational theories identify meaning with mental states like the ideas that an expression evokes in the minds of language users. According to causal theories, meaning is determined by causes and effects, which behaviorist semantics analyzes in terms of stimulus and response. Further theories of meaning include truth-conditional semantics, verificationist theories, the use theory, and inferentialist semantics.\nThe study of semantic phenomena began during antiquity but was not recognized as an independent field of inquiry until the 19th century. Semantics is relevant to the fields of formal logic, computer science, and psychology.\nDefinition and related fields.\nSemantics is the study of meaning in languages. It is a systematic inquiry that examines what linguistic meaning is and how it arises. It investigates how expressions are built up from different layers of constituents, like morphemes, words, clauses, sentences, and texts, and how the meanings of the constituents affect one another. Semantics can focus on a specific language, like English, but in its widest sense, it investigates meaning structures relevant to all languages. As a descriptive discipline, it aims to determine how meaning works without prescribing what meaning people should associate with particular expressions. Some of its key questions are \"How do the meanings of words combine to create the meanings of sentences?\", \"How do meanings relate to the minds of language users, and to the things words refer to?\", and \"What is the connection between what a word means, and the contexts in which it is used?\". The main disciplines engaged in semantics are linguistics, semiotics, and philosophy. Besides its meaning as a field of inquiry, semantics can also refer to theories within this field, like truth-conditional semantics, and to the meaning of particular expressions, like the semantics of the word \"fairy\".\nAs a field of inquiry, semantics has both an internal and an external side. The internal side is interested in the connection between words and the mental phenomena they evoke, like ideas and conceptual representations. The external side examines how words refer to objects in the world and under what conditions a sentence is true.\nMany related disciplines investigate language and meaning. Semantics contrasts with other subfields of linguistics focused on distinct aspects of language. Phonology studies the different types of sounds used in languages and how sounds are connected to form words while syntax examines the rules that dictate how to arrange words to create sentences. These divisions are reflected in the fact that it is possible to master some aspects of a language while lacking others, like when a person knows how to pronounce a word without knowing its meaning. As a subfield of semiotics, semantics has a more narrow focus on meaning in language while semiotics studies both linguistic and non-linguistic signs. Semiotics investigates additional topics like the meaning of non-verbal communication, conventional symbols, and natural signs independent of human interaction. Examples include nodding to signal agreement, stripes on a uniform signifying rank, and the presence of vultures indicating a nearby animal carcass.\nSemantics further contrasts with pragmatics, which is interested in how people use language in communication. An expression like \"That's what I'm talking about\" can mean many things depending on who says it and in what situation. Semantics is interested in the possible meanings of expressions: what they can and cannot mean in general. In this regard, it is sometimes defined as the study of context-independent meaning. Pragmatics examines which of these possible meanings is relevant in a particular case. In contrast to semantics, it is interested in actual performance rather than in the general linguistic competence underlying this performance. This includes the topic of additional meaning that can be inferred even though it is not literally expressed, like what it means if a speaker remains silent on a certain topic. A closely related distinction by the semiotician Charles W. Morris holds that semantics studies the relation between words and the world, pragmatics examines the relation between words and users, and syntax focuses on the relation between different words.\nSemantics is related to etymology, which studies how words and their meanings changed in the course of history. Another connected field is hermeneutics, which is the art or science of interpretation and is concerned with the right methodology of interpreting text in general and scripture in particular. Metasemantics examines the metaphysical foundations of meaning and aims to explain where it comes from or how it arises.\nThe word \"semantics\" originated from the Ancient Greek adjective ', meaning 'relating to signs', which is a derivative of ', the noun for 'sign'. It was initially used for medical symptoms and only later acquired its wider meaning regarding any type of sign, including linguistic signs. The word \"semantics\" entered the English language from the French term \"\", which the linguist Michel Br\u00e9al first introduced at the end of the 19th century.\nBasic concepts.\nMeaning.\nSemantics studies meaning in language, which is limited to the meaning of linguistic expressions. It concerns how signs are interpreted and what information they contain. An example is the meaning of words provided in dictionary definitions by giving synonymous expressions or paraphrases, like defining the meaning of the term \"ram\" as \"adult male sheep\". There are many forms of non-linguistic meaning that are not examined by semantics. Actions and policies can have meaning in relation to the goal they serve. Fields like religion and spirituality are interested in the meaning of life, which is about finding a purpose in life or the significance of existence in general.\nLinguistic meaning can be analyzed on different levels. Word meaning is studied by lexical semantics and investigates the denotation of individual words. It is often related to concepts of entities, like how the word \"dog\" is associated with the concept of the four-legged domestic animal. Sentence meaning falls into the field of phrasal semantics and concerns the denotation of full sentences. It usually expresses a concept applying to a type of situation, as in the sentence \"the dog has ruined my blue skirt\". The meaning of a sentence is often referred to as a proposition. Different sentences can express the same proposition, like the English sentence \"the tree is green\" and the German sentence . Utterance meaning is studied by pragmatics and is about the meaning of an expression on a particular occasion. Sentence meaning and utterance meaning come apart in cases where expressions are used in a non-literal way, as is often the case with irony.\nSemantics is primarily interested in the public meaning that expressions have, like the meaning found in general dictionary definitions. Speaker meaning, by contrast, is the private or subjective meaning that individuals associate with expressions. It can diverge from the literal meaning, like when a person associates the word \"needle\" with pain or drugs.\nSense and reference.\nMeaning is often analyzed in terms of sense and reference, also referred to as intension and extension or connotation and denotation. The referent of an expression is the object to which the expression points. The sense of an expression is the way in which it refers to that object or how the object is interpreted. For example, the expressions \"morning star\" and \"evening star\" refer to the same planet, just like the expressions \"2 + 2\" and \"3 + 1\" refer to the same number. The meanings of these expressions differ not on the level of reference but on the level of sense. Sense is sometimes understood as a mental phenomenon that helps people identify the objects to which an expression refers. Some semanticists focus primarily on sense or primarily on reference in their analysis of meaning. To grasp the full meaning of an expression, it is usually necessary to understand both to what entities in the world it refers and how it describes them.\nThe distinction between sense and reference can explain identity statements, which can be used to show how two expressions with a different sense have the same referent. For instance, the sentence \"the morning star is the evening star\" is informative and people can learn something from it. The sentence \"the morning star is the morning star\", by contrast, is an uninformative tautology since the expressions are identical not only on the level of reference but also on the level of sense.\nCompositionality.\nCompositionality is a key aspect of how languages construct meaning. It is the idea that the meaning of a complex expression is a function of the meanings of its parts. It is possible to understand the meaning of the sentence \"Zuzana owns a dog\" by understanding what the words \"Zuzana\", \"owns\", \"a\" and \"dog\" mean and how they are combined. In this regard, the meaning of complex expressions like sentences is different from word meaning since it is normally not possible to deduce what a word means by looking at its letters and one needs to consult a dictionary instead.\nCompositionality is often used to explain how people can formulate and understand an almost infinite number of meanings even though the amount of words and cognitive resources is finite. Many sentences that people read are sentences that they have never seen before and they are nonetheless able to understand them.\nWhen interpreted in a strong sense, the principle of compositionality states that the meaning of a complex expression is not just affected by its parts and how they are combined but fully determined this way. It is controversial whether this claim is correct or whether additional aspects influence meaning. For example, context may affect the meaning of expressions; idioms like \"kick the bucket\" carry figurative or non-literal meanings that are not directly reducible to the meanings of their parts.\nTruth and truth conditions.\nTruth is a property of statements that accurately present the world and true statements are in accord with reality. Whether a statement is true usually depends on the relation between the statement and the rest of the world. The truth conditions of a statement are the way the world needs to be for the statement to be true. For example, it belongs to the truth conditions of the sentence \"it is raining outside\" that raindrops are falling from the sky. The sentence is true if it is used in a situation in which the truth conditions are fulfilled, i.e., if there is actually rain outside.\nTruth conditions play a central role in semantics and some theories rely exclusively on truth conditions to analyze meaning. To understand a statement usually implies that one has an idea about the conditions under which it would be true. This can happen even if one does not know whether the conditions are fulfilled.\nSemiotic triangle.\nThe semiotic triangle, also called the triangle of meaning, is a model used to explain the relation between language, language users, and the world, represented in the model as \"Symbol\", \"Thought or Reference\", and \"Referent\". The symbol is a linguistic signifier, either in its spoken or written form. The central idea of the model is that there is no direct relation between a linguistic expression and what it refers to, as was assumed by earlier dyadic models. This is expressed in the diagram by the dotted line between symbol and referent.\nThe model holds instead that the relation between the two is mediated through a third component. For example, the term \"apple\" stands for a type of fruit but there is no direct connection between this string of letters and the corresponding physical object. The relation is only established indirectly through the mind of the language user. When they see the symbol, it evokes a mental image or a concept, which establishes the connection to the physical object. This process is only possible if the language user learned the meaning of the symbol before. The meaning of a specific symbol is governed by the conventions of a particular language. The same symbol may refer to one object in one language, to another object in a different language, and to no object in another language.\nOthers.\nMany other concepts are used to describe semantic phenomena. The semantic role of an expression is the function it fulfills in a sentence. In the sentence \"the boy kicked the ball\", the boy has the role of the agent who performs an action. The ball is the theme or patient of this action as something that does not act itself but is involved in or affected by the action. The same entity can be both agent and patient, like when someone cuts themselves. An entity has the semantic role of an instrument if it is used to perform the action, for instance, when cutting something with a knife then the knife is the instrument. For some sentences, no action is described but an experience takes place, like when a girl sees a bird. In this case, the girl has the role of the experiencer. Other common semantic roles are location, source, goal, beneficiary, and stimulus.\nLexical relations describe how words stand to one another. Two words are synonyms if they share the same or a very similar meaning, like \"car\" and \"automobile\" or \"buy\" and \"purchase\". Antonyms have opposite meanings, such as the contrast between \"alive\" and \"dead\" or \"fast\" and \"slow\". One term is a hyponym of another term if the meaning of the first term is included in the meaning of the second term. For example, ant is a hyponym of insect. A prototype is a hyponym that has characteristic features of the type it belongs to. A robin is a prototype of a bird but a penguin is not. Two words with the same pronunciation are homophones like \"flour\" and \"flower\", while two words with the same spelling are homonyms, like a bank of a river in contrast to a bank as a financial institution. Hyponymy is closely related to meronymy, which describes the relation between part and whole. For instance, \"wheel\" is a meronym of \"car\". An expression is ambiguous if it has more than one possible meaning. In some cases, it is possible to disambiguate them to discern the intended meaning. The term \"polysemy\" is used if the different meanings are closely related to one another, like the meanings of the word \"head\", which can refer to the topmost part of the human body or the top-ranking person in an organization.\nThe meaning of words can often be subdivided into meaning components called semantic features. The word \"horse\" has the semantic feature \"animate\" but lacks the semantic feature \"human\". It may not always be possible to fully reconstruct the meaning of a word by identifying all its semantic features.\nA semantic or lexical field is a group of words that are all related to the same activity or subject. For instance, the semantic field of cooking includes words like \"bake\", \"boil\", \"spice\", and \"pan\".\nThe context of an expression refers to the situation or circumstances in which it is used and includes time, location, speaker, and audience. It also encompasses other passages in a text that come before and after it. Context affects the meaning of various expressions, like the deictic expression \"here\" and the anaphoric expression \"she\".\nA syntactic environment is extensional or transparent if it is always possible to exchange expressions with the same reference without affecting the truth value of the sentence. For example, the environment of the sentence \"the number 8 is even\" is extensional because replacing the expression \"the number 8\" with \"the number of planets in the Solar System\" does not change its truth value. For intensional or opaque contexts, this type of substitution is not always possible. For instance, the embedded clause in \"Paco believes that the number 8 is even\" is intensional since Paco may not know that the number of planets in the solar system is 8.\nSemanticists commonly distinguish the language they study, called object language, from the language they use to express their findings, called metalanguage. When a professor uses Japanese to teach their student how to interpret the language of first-order logic then the language of first-order logic is the object language and Japanese is the metalanguage. The same language may occupy the role of object language and metalanguage at the same time. This is the case in monolingual English dictionaries, in which both the entry term belonging to the object language and the definition text belonging to the metalanguage are taken from the English language.\nBranches.\nLexical semantics.\nLexical semantics is the sub-field of semantics that studies word meaning. It examines semantic aspects of individual words and the vocabulary as a whole. This includes the study of lexical relations between words, such as whether two terms are synonyms or antonyms. Lexical semantics categorizes words based on semantic features they share and groups them into semantic fields unified by a common subject. This information is used to create taxonomies to organize lexical knowledge, for example, by distinguishing between physical and abstract entities and subdividing physical entities into stuff and individuated entities. Further topics of interest are polysemy, ambiguity, and vagueness.\nLexical semantics is sometimes divided into two complementary approaches: semasiology and onomasiology. Semasiology starts from words and examines what their meaning is. It is interested in whether words have one or several meanings and how those meanings are related to one another. Instead of going from word to meaning, onomasiology goes from meaning to word. It starts with a concept and examines what names this concept has or how it can be expressed in a particular language.\nSome semanticists also include the study of lexical units other than words in the field of lexical semantics. Compound expressions like \"being under the weather\" have a non-literal meaning that acts as a unit and is not a direct function of its parts. Another topic concerns the meaning of morphemes that make up words, for instance, how negative prefixes like \"in-\" and \"dis-\" affect the meaning of the words they are part of, as in \"inanimate\" and \"dishonest\".\nPhrasal semantics.\nPhrasal semantics studies the meaning of sentences. It relies on the principle of compositionality to explore how the meaning of complex expressions arises from the combination of their parts. The different parts can be analyzed as subject, predicate, or argument. The subject of a sentence usually refers to a specific entity while the predicate describes a feature of the subject or an event in which the subject participates. Arguments provide additional information to complete the predicate. For example, in the sentence \"Mary hit the ball\", \"Mary\" is the subject, \"hit\" is the predicate, and \"the ball\" is an argument. A more fine-grained categorization distinguishes between different semantic roles of words, such as agent, patient, theme, location, source, and goal.\nVerbs usually function as predicates and often help to establish connections between different expressions to form a more complex meaning structure. In the expression \"Beethoven likes Schubert\", the verb \"like\" connects a liker to the object of their liking. Other sentence parts modify meaning rather than form new connections. For instance, the adjective \"red\" modifies the color of another entity in the expression \"red car\". A further compositional device is variable binding, which is used to determine the reference of a term. For example, the last part of the expression \"the woman who likes Beethoven\" specifies which woman is meant. Parse trees can be used to show the underlying hierarchy employed to combine the different parts. Various grammatical devices, like the gerund form, also contribute to meaning and are studied by grammatical semantics.\nFormal semantics.\nFormal semantics uses formal tools from logic and mathematics to analyze meaning in natural languages. It aims to develop precise logical formalisms to clarify the relation between expressions and their denotation. One of its key tasks is to provide frameworks of how language represents the world, for example, using ontological models to show how linguistic expressions map to the entities of that model. A common idea is that words refer to individual objects or groups of objects while sentences relate to events and states. Sentences are mapped to a truth value based on whether their description of the world is in correspondence with its ontological model.\nFormal semantics further examines how to use formal mechanisms to represent linguistic phenomena such as quantification, intensionality, noun phrases, plurals, mass terms, tense, and modality. Montague semantics is an early and influential theory in formal semantics that provides a detailed analysis of how the English language can be represented using mathematical logic. It relies on higher-order logic, lambda calculus, and type theory to show how meaning is created through the combination of expressions belonging to different syntactic categories.\nDynamic semantics is a subfield of formal semantics that focuses on how information grows over time. According to it, \"meaning is context change potential\": the meaning of a sentence is not given by the information it contains but by the information change it brings about relative to a context.\nCognitive semantics.\nCognitive semantics studies the problem of meaning from a psychological perspective or how the mind of the language user affects meaning. As a subdiscipline of cognitive linguistics, it sees language as a wide cognitive ability that is closely related to the conceptual structures used to understand and represent the world. Cognitive semanticists do not draw a sharp distinction between linguistic knowledge and knowledge of the world and see them instead as interrelated phenomena. They study how the interaction between language and human cognition affects the conceptual organization in very general domains like space, time, causation, and action. The contrast between profile and base is sometimes used to articulate the underlying knowledge structure. The profile of a linguistic expression is the aspect of the knowledge structure that it brings to the foreground while the base is the background that provides the context of this aspect without being at the center of attention. For example, the profile of the word \"hypotenuse\" is a straight line while the base is a right-angled triangle of which the hypotenuse forms a part.\nCognitive semantics further compares the conceptual patterns and linguistic typologies across languages and considers to what extent the cognitive conceptual structures of humans are universal or relative to their linguistic background. Another research topic concerns the psychological processes involved in the application of grammar. Other investigated phenomena include categorization, which is understood as a cognitive heuristic to avoid information overload by regarding different entities in the same way, and embodiment, which concerns how the language user's bodily experience affects the meaning of expressions.\nFrame semantics is an important subfield of cognitive semantics. Its central idea is that the meaning of terms cannot be understood in isolation from each other but needs to be analyzed on the background of the conceptual structures they depend on. These structures are made explicit in terms of semantic frames. For example, words like bride, groom, and honeymoon evoke in the mind the frame of marriage.\nOthers.\nConceptual semantics shares with cognitive semantics the idea of studying linguistic meaning from a psychological perspective by examining how humans conceptualize and experience the world. It holds that meaning is not about the objects to which expressions refer but about the cognitive structure of human concepts that connect thought, perception, and action. Conceptual semantics differs from cognitive semantics by introducing a strict distinction between meaning and syntax and by relying on various formal devices to explore the relation between meaning and cognition.\nComputational semantics examines how the meaning of natural language expressions can be represented and processed on computers. It often relies on the insights of formal semantics and applies them to problems that can be computationally solved. Some of its key problems include computing the meaning of complex expressions by analyzing their parts, handling ambiguity, vagueness, and context-dependence, and using the extracted information in automatic reasoning. It forms part of computational linguistics, artificial intelligence, and cognitive science. Its applications include machine learning and machine translation.\nCultural semantics studies the relation between linguistic meaning and culture. It compares conceptual structures in different languages and is interested in how meanings evolve and change because of cultural phenomena associated with politics, religion, and customs. For example, address practices encode cultural values and social hierarchies, as in the difference of politeness of expressions like ' and ' in Spanish or ' and ' in German in contrast to English, which lacks these distinctions and uses the pronoun \"you\" in either case. Closely related fields are intercultural semantics, cross-cultural semantics, and comparative semantics.\nPragmatic semantics studies how the meaning of an expression is shaped by the situation in which it is used. It is based on the idea that communicative meaning is usually context-sensitive and depends on who participates in the exchange, what information they share, and what their intentions and background assumptions are. It focuses on communicative actions, of which linguistic expressions only form one part. Some theorists include these topics within the scope of semantics while others consider them part of the distinct discipline of pragmatics.\nTheories of meaning.\nTheories of meaning explain what meaning is, what meaning an expression has, and how the relation between expression and meaning is established.\nReferential.\nReferential theories state that the meaning of an expression is the entity to which it points. The meaning of singular terms like names is the individual to which they refer. For example, the meaning of the name \"George Washington\" is the person with this name. General terms refer not to a single entity but to the set of objects to which this term applies. In this regard, the meaning of the term \"cat\" is the set of all cats. Similarly, verbs usually refer to classes of actions or events and adjectives refer to properties of individuals and events.\nSimple referential theories face problems for meaningful expressions that have no clear referent. Names like \"Pegasus\" and \"Santa Claus\" have meaning even though they do not point to existing entities. Other difficulties concern cases in which different expressions are about the same entity. For instance, the expressions \"Roger Bannister\" and \"the first man to run a four-minute mile\" refer to the same person but do not mean exactly the same thing. This is particularly relevant when talking about beliefs since a person may understand both expressions without knowing that they point to the same entity. A further problem is given by expressions whose meaning depends on the context, like the deictic terms \"here\" and \"I\".\nTo avoid these problems, referential theories often introduce additional devices. Some identify meaning not directly with objects but with functions that point to objects. This additional level has the advantage of taking the context of an expression into account since the same expression may point to one object in one context and to another object in a different context. For example, the reference of the word \"here\" depends on the location in which it is used. A closely related approach is possible world semantics, which allows expressions to refer not only to entities in the actual world but also to entities in other possible worlds. According to this view, expressions like \"the first man to run a four-minute mile\" refer to different persons in different worlds. This view can also be used to analyze sentences that talk about what is possible or what is necessary: possibility is what is true in some possible worlds while necessity is what is true in all possible worlds.\nIdeational.\nIdeational theories, also called mentalist theories, are not primarily interested in the reference of expressions and instead explain meaning in terms of the mental states of language users. One historically influential approach articulated by John Locke holds that expressions stand for ideas in the speaker's mind. According to this view, the meaning of the word \"dog\" is the idea that people have of dogs. Language is seen as a medium used to transfer ideas from the speaker to the audience. After having learned the same meaning of signs, the speaker can produce a sign that corresponds to the idea in their mind and the perception of this sign evokes the same idea in the mind of the audience.\nA closely related theory focuses not directly on ideas but on intentions. This view is particularly associated with Paul Grice, who observed that people usually communicate to cause some reaction in their audience. He held that the meaning of an expression is given by the intended reaction. This means that communication is not just about decoding what the speaker literally said but requires an understanding of their intention or why they said it. For example, telling someone looking for petrol that \"there is a garage around the corner\" has the meaning that petrol can be obtained there because of the speaker's intention to help. This goes beyond the literal meaning, which has no explicit connection to petrol.\nCausal.\nCausal theories hold that the meaning of an expression depends on the causes and effects it has. According to behaviorist semantics, also referred to as stimulus-response theory, the meaning of an expression is given by the situation that prompts the speaker to use it and the response it provokes in the audience. For instance, the meaning of yelling \"Fire!\" is given by the presence of an uncontrolled fire and attempts to control it or seek safety. Behaviorist semantics relies on the idea that learning a language consists in adopting behavioral patterns in the form of stimulus-response pairs. One of its key motivations is to avoid private mental entities and define meaning instead in terms of publicly observable language behavior.\nAnother causal theory focuses on the meaning of names and holds that a naming event is required to establish the link between name and named entity. This naming event acts as a form of baptism that establishes the first link of a causal chain in which all subsequent uses of the name participate. According to this view, the name \"Plato\" refers to an ancient Greek philosopher because, at some point, he was originally named this way and people kept using this name to refer to him. This view was originally formulated by Saul Kripke to apply to names only but has been extended to cover other types of speech as well.\nOthers.\nTruth-conditional semantics analyzes the meaning of sentences in terms of their truth conditions. According to this view, to understand a sentence means to know what the world needs to be like for the sentence to be true. Truth conditions can themselves be expressed through possible worlds. For example, the sentence \"Hillary Clinton won the 2016 American presidential election\" is false in the actual world but there are some possible worlds in which it is true. The extension of a sentence can be interpreted as its truth value while its intension is the set of all possible worlds in which it is true. Truth-conditional semantics is closely related to verificationist theories, which introduce the additional idea that there should be some kind of verification procedure to assess whether a sentence is true. They state that the meaning of a sentence consists in the method to verify it or in the circumstances that justify it. For instance, scientific claims often make predictions, which can be used to confirm or disconfirm them using observation. According to verificationism, sentences that can neither be verified nor falsified are meaningless.\nThe use theory states that the meaning of an expression is given by the way it is utilized. This view was first introduced by Ludwig Wittgenstein, who understood language as a collection of language games. The meaning of expressions depends on how they are used inside a game and the same expression may have different meanings in different games. Some versions of this theory identify meaning directly with patterns of regular use. Others focus on social norms and conventions by additionally taking into account whether a certain use is considered appropriate in a given society.\nInferentialist semantics, also called conceptual role semantics, holds that the meaning of an expression is given by the role it plays in the premises and conclusions of good inferences. For example, one can infer from \"x is a male sibling\" that \"x is a brother\" and one can infer from \"x is a brother\" that \"x has parents\". According to inferentialist semantics, the meaning of the word \"brother\" is determined by these and all similar inferences that can be drawn.\nHistory.\nSemantics was established as an independent field of inquiry in the 19th century but the study of semantic phenomena began as early as the ancient period as part of philosophy and logic. In ancient Greece, Plato (427\u2013347 BCE) explored the relation between names and things in his dialogue \"Cratylus\". It considers the positions of naturalism, which holds that things have their name by nature, and conventionalism, which states that names are related to their referents by customs and conventions among language users. The book \"On Interpretation\" by Aristotle (384\u2013322 BCE) introduced various conceptual distinctions that greatly influenced subsequent works in semantics. He developed an early form of the semantic triangle by holding that spoken and written words evoke mental concepts, which refer to external things by resembling them. For him, mental concepts are the same for all humans, unlike the conventional words they associate with those concepts. The Stoics incorporated many of the insights of their predecessors to develop a complex theory of language through the perspective of logic. They discerned different kinds of words by their semantic and syntactic roles, such as the contrast between names, common nouns, and verbs. They also discussed the difference between statements, commands, and prohibitions.\nIn ancient India, the orthodox school of Nyaya held that all names refer to real objects. It explored how words lead to an understanding of the thing meant and what consequence this relation has to the creation of knowledge. Philosophers of the orthodox school of M\u012bm\u0101\u1e43s\u0101 discussed the relation between the meanings of individual words and full sentences while considering which one is more basic. The book \"V\u0101kyapad\u012bya\" by Bhart\u1e5bhari (4th\u20135th century CE) distinguished between different types of words and considered how they can carry different meanings depending on how they are used. In ancient China, the Mohists argued that names play a key role in making distinctions to guide moral behavior. They inspired the School of Names, which explored the relation between names and entities while examining how names are required to identify and judge entities.\nIn the Middle Ages, Augustine of Hippo (354\u2013430) developed a general conception of signs as entities that stand for other entities and convey them to the intellect. He was the first to introduce the distinction between natural and linguistic signs as different types belonging to a common genus. Boethius (480\u2013528) wrote a translation of and various comments on Aristotle's book \"On Interpretation\", which popularized its main ideas and inspired reflections on semantic phenomena in the scholastic tradition. An innovation in the semantics of Peter Abelard (1079\u20131142) was his interest in propositions or the meaning of sentences in contrast to the focus on the meaning of individual words by many of his predecessors. He further explored the nature of universals, which he understood as mere semantic phenomena of common names caused by mental abstractions that do not refer to any entities. In the Arabic tradition, Ibn Faris (920\u20131004) identified meaning with the intention of the speaker while Abu Mansur al-Azhari (895\u2013980) held that meaning resides directly in speech and needs to be extracted through interpretation.\nAn important topic towards the end of the Middle Ages was the distinction between categorematic and syncategorematic terms. Categorematic terms have an independent meaning and refer to some part of reality, like \"horse\" and \"Socrates\". Syncategorematic terms lack independent meaning and fulfill other semantic functions, such as modifying or quantifying the meaning of other expressions, like the words \"some\", \"not\", and \"necessarily\". An early version of the causal theory of meaning was proposed by Roger Bacon (c. 1219/20 \u2013 c. 1292), who held that things get names similar to how people get names through some kind of initial baptism. His ideas inspired the tradition of the speculative grammarians, who proposed that there are certain universal structures found in all languages. They arrived at this conclusion by drawing an analogy between the modes of signification on the level of language, the modes of understanding on the level of mind, and the modes of being on the level of reality.\nIn the early modern period, Thomas Hobbes (1588\u20131679) distinguished between marks, which people use privately to recall their own thoughts, and signs, which are used publicly to communicate their ideas to others. In their \"Port-Royal Logic\", Antoine Arnauld (1612\u20131694) and Pierre Nicole (1625\u20131695) developed an early precursor of the distinction between intension and extension. The \"Essay Concerning Human Understanding\" by John Locke (1632\u20131704) presented an influential version of the ideational theory of meaning, according to which words stand for ideas and help people communicate by transferring ideas from one mind to another. Gottfried Wilhelm Leibniz (1646\u20131716) understood language as the mirror of thought and tried to conceive the outlines of a universal formal language to express scientific and philosophical truths. This attempt inspired theorists Christian Wolff (1679\u20131754), Georg Bernhard Bilfinger (1693\u20131750), and Johann Heinrich Lambert (1728\u20131777) to develop the idea of a general science of sign systems. \u00c9tienne Bonnot de Condillac (1715\u20131780) accepted and further developed Leibniz's idea of the linguistic nature of thought. Against Locke, he held that language is involved in the creation of ideas and is not merely a medium to communicate them.\nIn the 19th century, semantics emerged and solidified as an independent field of inquiry. Christian Karl Reisig (1792\u20131829) is sometimes credited as the father of semantics since he clarified its concept and scope while also making various contributions to its key ideas. Michel Br\u00e9al (1832\u20131915) followed him in providing a broad conception of the field, for which he coined the French term \"\". John Stuart Mill (1806\u20131873) gave great importance to the role of names to refer to things. He distinguished between the connotation and denotation of names and held that propositions are formed by combining names. Charles Sanders Peirce (1839\u20131914) conceived semiotics as a general theory of signs with several subdisciplines, which were later identified by Charles W. Morris (1901\u20131979) as syntactics, semantics, and pragmatics. In his pragmatist approach to semantics, Peirce held that the meaning of conceptions consists in the entirety of their practical consequences. The philosophy of Gottlob Frege (1848\u20131925) contributed to semantics on many different levels. Frege first introduced the distinction between sense and reference, and his development of predicate logic and the principle of compositionality formed the foundation of many subsequent developments in formal semantics. Edmund Husserl (1859\u20131938) explored meaning from a phenomenological perspective by considering the mental acts that endow expressions with meaning. He held that meaning always implies reference to an object and expressions that lack a referent, like \"green is or\", are meaningless.\nIn the 20th century, Alfred Tarski (1901\u20131983) defined truth in formal languages through his semantic theory of truth, which was influential in the development of truth-conditional semantics by Donald Davidson (1917\u20132003). Tarski's student Richard Montague (1930\u20131971) formulated a complex formal framework of the semantics of the English language, which was responsible for establishing formal semantics as a major area of research. According to structural semantics, which was inspired by the structuralist philosophy of Ferdinand de Saussure (1857\u20131913), language is a complex network of structural relations and the meanings of words are not fixed individually but depend on their position within this network. The theory of general semantics was developed by Alfred Korzybski (1879\u20131950) as an inquiry into how language represents reality and affects human thought. The contributions of George Lakoff (1941\u2013present) and Ronald Langacker (1942\u2013present) provided the foundation of cognitive semantics. Charles J. Fillmore (1929\u20132014) developed frame semantics as a major approach in this area. The closely related field of conceptual semantics was inaugurated by Ray Jackendoff (1945\u2013present).\nIn various disciplines.\nLogic.\nLogicians study correct reasoning and often develop formal languages to express arguments and assess their correctness. One part of this process is to provide a semantics for a formal language to precisely define what its terms mean. A semantics of a formal language is a set of rules, usually expressed as a mathematical function, that assigns meanings to formal language expressions. For example, the language of first-order logic uses lowercase letters for individual constants and uppercase letters for predicates. To express the sentence \"Bertie is a dog\", the formula formula_1 can be used where formula_2 is an individual constant for Bertie and formula_3 is a predicate for dog. Classical model-theoretic semantics assigns meaning to these terms by defining an interpretation function that maps individual constants to specific objects and predicates to sets of objects or tuples. The function maps formula_2 to Bertie and formula_3 to the set of all dogs. This way, it is possible to calculate the truth value of the sentence: it is true if Bertie is a member of the set of dogs and false otherwise.\nFormal logic aims to determine whether arguments are deductively valid, that is, whether the premises entail the conclusion. Entailment can be defined in terms of syntax or in terms of semantics. Syntactic entailment, expressed with the symbol formula_6, relies on rules of inference, which can be understood as procedures to transform premises and arrive at a conclusion. These procedures only take the logical form of the premises on the level of syntax into account and ignore what meaning they express. Semantic entailment, expressed with the symbol formula_7, looks at the meaning of the premises, in particular, at their truth value. A conclusion follows semantically from a set of premises if the truth of the premises ensures the truth of the conclusion, that is, if any semantic interpretation function that assigns the premises the value \"true\" also assigns the conclusion the value \"true\".\nComputer science.\nIn computer science, the semantics of a program is how it behaves when a computer runs it. Semantics contrasts with syntax, which is the particular form in which instructions are expressed. The same behavior can usually be described with different forms of syntax. In JavaScript, this is the case for the commands codice_1 and codice_2, which are syntactically different expressions to increase the value of the variable \"i\" by one. This difference is also reflected in different programming languages since they rely on different syntax but can usually be employed to create programs with the same behavior on the semantic level.\nStatic semantics focuses on semantic aspects that affect the compilation of a program. In particular, it is concerned with detecting errors of syntactically correct programs, such as type errors, which arise when an operation receives an incompatible data type. This is the case, for instance, if a function performing a numerical calculation is given a string instead of a number as an argument. Dynamic semantics focuses on the run time behavior of programs, that is, what happens during the execution of instructions. The main approaches to dynamic semantics are denotational, axiomatic, and operational semantics. Denotational semantics relies on mathematical formalisms to describe the effects of each element of the code. Axiomatic semantics uses deductive logic to analyze which conditions must be in place before and after the execution of a program. Operational semantics interprets the execution of a program as a series of steps, each involving the transition from one state to another state.\nPsychology.\nPsychological semantics examines psychological aspects of meaning. It is concerned with how meaning is represented on a cognitive level and what mental processes are involved in understanding and producing language. It further investigates how meaning interacts with other mental processes, such as the relation between language and perceptual experience. Other issues concern how people learn new words and relate them to familiar things and concepts, how they infer the meaning of compound expressions they have never heard before, how they resolve ambiguous expressions, and how semantic illusions lead them to misinterpret sentences.\nOne key topic is semantic memory, which is a form of general knowledge of meaning that includes the knowledge of language, concepts, and facts. It contrasts with episodic memory, which records events that a person experienced in their life. The comprehension of language relies on semantic memory and the information it carries about word meanings. According to a common view, word meanings are stored and processed in relation to their semantic features. The feature comparison model states that sentences like \"a robin is a bird\" are assessed on a psychological level by comparing the semantic features of the word \"robin\" with the semantic features of the word \"bird\". The assessment process is fast if their semantic features are similar, which is the case if the example is a prototype of the general category. For atypical examples, as in the sentence \"a penguin is a bird\", there is less overlap in the semantic features and the psychological process is significantly slower.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "29109", "revid": "4842600", "url": "https://en.wikipedia.org/wiki?curid=29109", "title": "Semantic network", "text": "Knowledge base that represents semantic relations between concepts in a network\nA semantic network, or frame network is a knowledge base that represents semantic relations between concepts in a network. This is often used as a form of knowledge representation. It is a directed or undirected graph consisting of vertices, which represent concepts, and edges, which represent semantic relations between concepts, mapping or connecting semantic fields. A semantic network may be instantiated as, for example, a graph database or a concept map. Typical standardized semantic networks are expressed as semantic triples.\nSemantic networks are used in natural language processing applications such as semantic parsing and word-sense disambiguation. Semantic networks can also be used as a method to analyze large texts and identify the main themes and topics (e.g., of social media posts), to reveal biases (e.g., in news coverage), or even to map an entire research field.\nHistory.\nExamples of the use of semantic networks in logic, directed acyclic graphs as a mnemonic tool, dates back centuries. The earliest documented use being the Greek philosopher Porphyry's commentary on Aristotle's categories in the third century AD.\nIn computing history, \"Semantic Nets\" for the propositional calculus were first implemented for computers by Richard H. Richens of the Cambridge Language Research Unit in 1956 as an \"interlingua\" for machine translation of natural languages. Although the importance of this work and the CLRU was only belatedly realized.\nSemantic networks were also independently implemented by Robert F. Simmons and Sheldon Klein, using the first order predicate calculus as a base, after being inspired by a demonstration of Victor Yngve. The \"line of research was originated by the first President of the Association [Association for Computational Linguistics], Victor Yngve, who in 1960 had published descriptions of algorithms for using a phrase structure grammar to generate syntactically well-formed nonsense sentences. Sheldon Klein and I about 1962-1964 were fascinated by the technique and generalized it to a method for controlling the sense of what was generated by respecting the semantic dependencies of words as they occurred in text.\" Other researchers, most notably M. Ross Quillian and others at System Development Corporation helped contribute to their work in the early 1960s as part of the SYNTHEX project. It's from these publications at SDC that most modern derivatives of the term \"semantic network\" cite as their background. Later prominent works were done by Allan M. Collins and Quillian (e.g., Collins and Quillian; Collins and Loftus Quillian). Still later in 2006, Hermann Helbig fully described MultiNet.\nIn the late 1980s, two Netherlands universities, Groningen and Twente, jointly began a project called \"Knowledge Graphs\", which are semantic networks but with the added constraint that edges are restricted to be from a limited set of possible relations, to facilitate algebras on the graph. In the subsequent decades, the distinction between semantic networks and knowledge graphs was blurred. In 2012, Google gave their knowledge graph the name Knowledge Graph.\nThe Semantic Link Network was systematically studied as a social semantics networking method. Its basic model consists of semantic nodes, semantic links between nodes, and a semantic space that defines the semantics of nodes and links and reasoning rules on semantic links. The systematic theory and model was published in 2004. This research direction can trace to the definition of inheritance rules for efficient model retrieval in 1998 and the Active Document Framework ADF. Since 2003, research has developed toward social semantic networking. This work is a systematic innovation at the age of the World Wide Web and global social networking rather than an application or simple extension of the Semantic Net (Network). Its purpose and scope are different from that of the Semantic Net (or network). The rules for reasoning and evolution and automatic discovery of implicit links play an important role in the Semantic Link Network. Recently it has been developed to support Cyber-Physical-Social Intelligence. It was used for creating a general summarization method. The self-organised Semantic Link Network was integrated with a multi-dimensional category space to form a semantic space to support advanced applications with multi-dimensional abstractions and self-organised semantic links It has been verified that Semantic Link Network play an important role in understanding and representation through text summarisation applications. Semantic Link Network has been extended from cyberspace to cyber-physical-social space. Competition relation and symbiosis relation as well as their roles in evolving society were studied in the emerging topic: Cyber-Physical-Social Intelligence\nMore specialized forms of semantic networks has been created for specific use. For example, in 2008, Fawsy Bendeck's PhD thesis formalized the Semantic Similarity Network (SSN) that contains specialized relationships and propagation algorithms to simplify the semantic similarity representation and calculations.\nBasics of semantic networks.\nA semantic network is used when one has knowledge that is best understood as a set of concepts that are related to one another.\nMost semantic networks are cognitively based. They also consist of arcs and nodes which can be organized into a taxonomic hierarchy. Semantic networks contributed ideas of spreading activation, inheritance, and nodes as proto-objects.\nExamples.\nIn Lisp.\nThe following code shows an example of a semantic network in the Lisp programming language using an association list.\n(setq *database*\n'((canary (is-a bird)\n (color yellow)\n (size small))\n (penguin (is-a bird)\n (movement swim))\n (bird (is-a vertebrate)\n (has-part wings)\n (reproduction egg-laying))))\nTo extract all the information about the \"canary\" type, one would use the codice_1 function with a key of \"canary\".\nWordNet.\nAn example of a semantic network is WordNet, a lexical database of English. It groups English words into sets of synonyms called synsets, provides short, general definitions, and records the various semantic relations between these synonym sets. Some of the most common semantic relations defined are meronymy (A is a meronym of B if A is part of B), holonymy (B is a holonym of A if B contains A), hyponymy (or troponymy) (A is subordinate of B; A is kind of B), hypernymy (A is superordinate of B), synonymy (A denotes the same as B) and antonymy (A denotes the opposite of B).\nWordNet properties have been studied from a network theory perspective and compared to other semantic networks created from Roget's Thesaurus and word association tasks. From this perspective the three of them are a small world structure.\nOther examples.\nIt is also possible to represent logical descriptions using semantic networks such as the existential graphs of Charles Sanders Peirce or the related conceptual graphs of John F. Sowa. These have expressive power equal to or exceeding standard first-order predicate logic. Unlike WordNet or other lexical or browsing networks, semantic networks using these representations can be used for reliable automated logical deduction. Some automated reasoners exploit the graph-theoretic features of the networks during processing.\nOther examples of semantic networks are Gellish models. Gellish English with its Gellish English dictionary, is a formal language that is defined as a network of relations between concepts and names of concepts. Gellish English is a formal subset of natural English, just as Gellish Dutch is a formal subset of Dutch, whereas multiple languages share the same concepts. Other Gellish networks consist of knowledge models and information models that are expressed in the Gellish language. A Gellish network is a network of (binary) relations between things. Each relation in the network is an expression of a fact that is classified by a relation type. Each relation type itself is a concept that is defined in the Gellish language dictionary. Each related thing is either a concept or an individual thing that is classified by a concept. The definitions of concepts are created in the form of definition models (definition networks) that together form a Gellish Dictionary. A Gellish network can be documented in a Gellish database and is computer interpretable.\nSciCrunch is a collaboratively edited knowledge base for scientific resources. It provides unambiguous identifiers (Research Resource IDentifiers or RRIDs) for software, lab tools etc. and it also provides options to create links between RRIDs and from communities.\nAnother example of semantic networks, based on category theory, is ologs. Here each type is an object, representing a set of things, and each arrow is a morphism, representing a function. Commutative diagrams also are prescribed to constrain the semantics.\nIn the social sciences people sometimes use the term semantic network to refer to co-occurrence networks. \nSoftware tools.\nThere are also elaborate types of semantic networks connected with corresponding sets of software tools used for lexical knowledge engineering, like the Semantic Network Processing System (SNePS) of Stuart C. Shapiro or the MultiNet paradigm of Hermann Helbig, especially suited for the semantic representation of natural language expressions and used in several NLP applications.\nSemantic networks are used in specialized information retrieval tasks, such as plagiarism detection. They provide information on hierarchical relations in order to employ semantic compression to reduce language diversity and enable the system to match word meanings, independently from sets of words used.\nThe Knowledge Graph proposed by Google in 2012 is actually an application of semantic network in search engine.\nModeling multi-relational data like semantic networks in low-dimensional spaces through forms of embedding has benefits in expressing entity relationships as well as extracting relations from mediums like text. There are many approaches to learning these embeddings, notably using Bayesian clustering frameworks or energy-based frameworks, and more recently, TransE (NIPS 2013). Applications of embedding knowledge base data include Social network analysis and Relationship extraction.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29110", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=29110", "title": "Social Dynamics", "text": ""}
{"id": "29113", "revid": "13079754", "url": "https://en.wikipedia.org/wiki?curid=29113", "title": "Stockholm Bloodbath", "text": "1520 trial and executions\nThe Stockholm Bloodbath () was a trial that led to a series of executions in Stockholm between 7 and 9 November 1520. The event is also known as the Stockholm massacre. The events occurred after the coronation of Christian II as the new king of Sweden, when guests in the crowning party were invited to a meeting at Tre Kronor castle. Archbishop Gustav Trolle, demanding economic compensation for things such as the demolition of Almarest\u00e4ket's fortress, questioned whether the former Swedish regent Sten Sture the Younger and his supporters had been guilty of heresy. \nSupported by canon law, nearly 100 people were executed in the days following the meeting despite promises of amnesty. Among those killed were many people from the aristocracy who had been supporting the Sture party in the previous years. Thereafter King Christian II became known in Sweden as (\"Christian [the] Tyrant\").\nBackground.\nPolitical factions in Sweden.\nThe Stockholm Bloodbath was a consequence of conflict between Swedish pro-unionists (in favour of the Kalmar Union, then dominated by Denmark) and anti-unionists (supporters of Swedish independence), and also between the anti-unionists and the Danish aristocracy, which in other aspects was opposed to King Christian. The anti-unionist party was headed by Sten Sture the Younger, and the pro-unionist party by the Archbishop Gustavus Trolle.\nMilitary interventions of King Christian.\nKing Christian, who had already taken measures to isolate Sweden politically, intervened to help Archbishop Trolle, who was under siege in his fortress at St\u00e4ket. However, he was defeated by Sture and his peasant soldiers at Vedila, and forced to return to Denmark. A second attempt to bring Sweden back under his control in 1518 was also countered by Sture's victory at Br\u00e4nnkyrka. Eventually, a third attempt made in 1520 with a large army of French, German and Scottish mercenaries proved successful.\nSture was mortally wounded at the Battle of Bogesund on 19 January 1520. The Danish army, unopposed, was approaching Uppsala, where the members of the Swedish Riksdag of the Estates had already assembled. The senators agreed to render homage to Christian, on condition that he give a full amnesty for past actions and a guarantee that Sweden should be ruled according to Swedish laws and customs. A convention to this effect was confirmed by the king and the Danish Privy Council on 31 March. Sture's widow, Lady Kristina, was still resisting in Stockholm with support from the peasants of central Sweden, and defeated the Danes at Balunds\u00e5s on 19 March. Eventually, her forces were defeated at Uppsala () on Good Friday, 6 April.\nIn May, the Danish fleet, led by King Christian, arrived and Stockholm was attacked by land and sea. Lady Kristina resisted for four months longer, and in the beginning of autumn Kristina's forces began winning. The inhabitants of Stockholm had a large supply of food and fared relatively well. Christian realized that his stockpile was dwindling and that it would doom his army to maintain the siege throughout the winter. With the help of Bishop Mattias, Hemming Gadh and other Swedes of high stature, Christian sent a proposal for retreat that was very advantageous for the Swedes. During a meeting on what is thought to be Beckholmen, outside of Djurg\u00e5rden, Christian swore that all acts against him would be forgotten, and gave pardon to several named persons (including Gustav Vasa, who had escaped from Denmark, where he had been held hostage). Lady Kristina would be given H\u00f6rningsholm and all M\u00f6rk\u00f6n as a fief, and was also promised Tavastehus (H\u00e4meenlinna) in Finland. When this had been written down on paper, the mayor of the city delivered the keys to the city on S\u00f6dermalm and Christian held his grand entry. Shortly after, he sailed back to Denmark, to return in October for his coronation.\nMassacre.\nOn 4 November, Christian was anointed by Gustavus Trolle in Storkyrkan Cathedral and took the usual oath to rule the kingdom through native-born Swedes only. A banquet was held for the next three days. Lots of wine and beer was drunk and jokes were cracked between Danes and Swedes.\nOn the evening of 7 November, Christian summoned many Swedish leaders to a private conference at the palace. At dusk on 8 November, Danish soldiers, with lanterns and torches, entered a great hall of the royal palace and imprisoned several noble guests. Later in the evening, even more of the king's guests were imprisoned. All these people had previously been marked down on Archbishop Trolle's proscription list.\nThe following day, 9 November, a council, headed by Archbishop Trolle, sentenced the proscribed to death for being heretics; the main point of accusation was their having united in a pact to depose Trolle a few years earlier. However, many of them were also leading men of the Sture party and thus potential opponents of the Danish kings. At noon, the anti-unionist bishops of Skara and Str\u00e4ngn\u00e4s were led out into the great square and beheaded. Fourteen noblemen, three burgomasters, fourteen town councillors and about twenty common citizens of Stockholm were then hanged or beheaded.\nThe executions continued throughout the following day (10 November). According to the chief executioner, J\u00f6rgen Homuth, 82 people were executed. It has been claimed that Christian also took revenge on Sten Sture's body, having it dug up and burnt, as well as the body of his child. Sture's widow Lady Kristina and many other noblewomen were taken as prisoners to Denmark.\nAftermath.\nChristian justified the massacre in a proclamation to the Swedish people as a measure necessary to avoid a papal interdict, but, when apologising to the Pope for the decapitation of the bishops, he blamed his troops for performing unauthorised acts of vengeance.\nGustav Vasa was a son of Erik Johansson, one of the victims of the executions. Vasa, upon hearing of the massacre, travelled north to the province of Dalarna to seek support for a new revolt. The population, informed of what had happened, rallied to his side. They were ultimately able to defeat Christian's forces in the Swedish War of Liberation. The massacre became the catalyst that permanently separated Sweden from Denmark.\nLater reception and propaganda.\nThe Stockholm Bloodbath precipitated a lengthy hostility towards Danes in Sweden, and from then on the two nations were almost continuously hostile toward each other. These hostilities, developing into a struggle for hegemony in the Scandinavian and North German area, lasted for nearly three hundred years. Memory of the Bloodbath served to let Swedes depict themselves (and often, actually regard themselves) as the wronged and aggrieved party, even when they were the ones who eventually took the political and military lead, such as the conquest and annexation of Scania until the Treaty of Roskilde in 1658.\nChristian the Tyrant and spurious \"Christian the Good\".\nThe event earned Christian II the nickname of \"Kristian Tyrann\" (\"Christian [the] Tyrant\") in Sweden, which is retained in the present day. It is a common misconception in Sweden that King Christian II is given the contrary byname (\"Christian the Good\") in Denmark, but this is apocryphal.\nAccording to Danish historians, no bynames have been given to Christian II in Danish historical tradition. In an interview with Gunnar Richardson in 1979, Danish historian Mikael Venge, author of the article about Christian II in \"Dansk Biografisk Leksikon \"said: \"I think you ought to protest the next time the Swedish radio claims anything so utterly unfounded that could be understood as if the Danes approved of the Stockholm bloodbath.\" Despite this, even today, tourist guides in Stockholm spice up their guiding of the Old Town (Gamla Stan) with the news about Christian II's \"rehabilitation\" back in Denmark.\nIn fiction.\nThe Stockholm Bloodbath has been depicted in several pieces of fiction:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29115", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=29115", "title": "Schrodingers equation", "text": ""}
{"id": "29117", "revid": "17631563", "url": "https://en.wikipedia.org/wiki?curid=29117", "title": "Sexual practices", "text": ""}
{"id": "29121", "revid": "473822", "url": "https://en.wikipedia.org/wiki?curid=29121", "title": "SSL", "text": "SSL may refer to:&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "29122", "revid": "1398", "url": "https://en.wikipedia.org/wiki?curid=29122", "title": "Signals intelligence", "text": "Intelligence-gathering by interception of signals\nSignals intelligence (SIGINT) is the act and field of intelligence-gathering by interception of \"signals\", whether communications between people (communications intelligence\u2014abbreviated to COMINT) or from electronic signals not directly used in communication (electronic intelligence\u2014abbreviated to ELINT). As classified and sensitive information is usually encrypted, signals intelligence may necessarily involve cryptanalysis (to decipher the messages). Traffic analysis\u2014the study of who is signaling to whom and in what quantity\u2014is also used to integrate information, and it may complement cryptanalysis.\nHistory.\nOrigins.\nElectronic interceptions appeared as early as 1900, during the Boer War of 1899\u20131902. The British Royal Navy had installed wireless sets produced by Marconi on board their ships in the late 1890s, and the British Army used some limited wireless signalling. The Boers captured some wireless sets and used them to make vital transmissions. Since the British were the only people transmitting at the time, the British did not need special interpretation of the signals that they were.\nThe birth of signals intelligence in a modern sense dates from the Russo-Japanese War of 1904\u20131905. As the Russian fleet prepared for conflict with Japan in 1904, the British ship HMS \"Diana\" stationed in the Suez Canal intercepted Russian naval wireless signals being sent out for the mobilization of the fleet, for the first time in history.\nDevelopment in World War I.\nOver the course of the First World War, a new method of signals intelligence reached maturity. Russia's failure to properly protect its communications fatally compromised the Russian Army's advance early in World War I and led to their disastrous defeat by the Germans under Ludendorff and Hindenburg at the Battle of Tannenberg. In 1918, French intercept personnel captured a message written in the new ADFGVX cipher, which was cryptanalyzed by Georges Painvin. This gave the Allies advance warning of the German 1918 Spring Offensive.\nThe British in particular, built up great expertise in the newly emerging field of signals intelligence and codebreaking (synonymous with cryptanalysis). On the declaration of war, Britain cut all German undersea cables. This forced the Germans to communicate exclusively via either (A) a telegraph line that connected through the British network and thus could be tapped; or (B) through radio which the British could then intercept. Rear Admiral Henry Oliver appointed Sir Alfred Ewing to establish an interception and decryption service at the Admiralty; Room 40. An interception service known as 'Y' service, together with the post office and Marconi stations, grew rapidly to the point where the British could intercept almost all official German messages.\nThe German fleet was in the habit each day of wirelessing the exact position of each ship and giving regular position reports when at sea. It was possible to build up a precise picture of the normal operation of the High Seas Fleet, to infer from the routes they chose where defensive minefields had been placed and where it was safe for ships to operate. Whenever a change to the normal pattern was seen, it immediately signalled that some operation was about to take place, and a warning could be given. Detailed information about submarine movements was also available.\nThe use of radio-receiving equipment to pinpoint the location of any single transmitter was also developed during the war. Captain H.J. Round, working for Marconi, began carrying out experiments with direction-finding radio equipment for the army in France in 1915. By May 1915, the Admiralty was able to track German submarines crossing the North Sea. Some of these stations also acted as 'Y' stations to collect German messages, but a new section was created within Room 40 to plot the positions of ships from the directional reports.\nRoom 40 played an important role in several naval engagements during the war, notably in detecting major German sorties into the North Sea. The battle of Dogger Bank was won in no small part due to the intercepts that allowed the Navy to position its ships in the right place. It played a vital role in subsequent naval clashes, including at the Battle of Jutland as the British fleet was sent out to intercept them. The direction-finding capability allowed for the tracking and location of German ships, submarines, and Zeppelins. The system was so successful that by the end of the war, over 80 million words, comprising the totality of German wireless transmission over the course of the war, had been intercepted by the operators of the Y-stations and decrypted. However, its most astonishing success was in decrypting the Zimmermann Telegram, a telegram from the German Foreign Office sent via Washington to its ambassador Heinrich von Eckardt in Mexico.\nPostwar consolidation.\nWith the importance of interception and decryption firmly established by the wartime experience, countries established permanent agencies dedicated to this task in the interwar period. In 1919, the British Cabinet's Secret Service Committee, chaired by Lord Curzon, recommended that a peace-time codebreaking agency should be created. The Government Code and Cypher School (GC&amp;CS) was the first peace-time codebreaking agency, with a public function \"to advise as to the security of codes and cyphers used by all Government departments and to assist in their provision\", but also with a secret directive to \"study the methods of cypher communications used by foreign powers\". GC&amp;CS officially formed on 1 November 1919, and produced its first decrypt on 19 October. By 1940, GC&amp;CS was working on the diplomatic codes and ciphers of 26 countries, tackling over 150 diplomatic cryptosystems.\nThe US Cipher Bureau was established in 1919 and achieved some success at the Washington Naval Conference in 1921, through cryptanalysis by Herbert Yardley. Secretary of War Henry L. Stimson closed the US Cipher Bureau in 1929 with the words \"Gentlemen do not read each other's mail.\"\nWorld War II.\nThe use of SIGINT had even greater implications during World War II. The combined effort of intercepts and cryptanalysis for the whole of the British forces in World War II came under the code name \"Ultra\", managed from Government Code and Cypher School at Bletchley Park. Properly used, the German Enigma and Lorenz ciphers should have been virtually unbreakable, but flaws in German cryptographic procedures, and poor discipline among the personnel carrying them out, created vulnerabilities which made Bletchley's attacks feasible.\nBletchley's work was essential to defeating the U-boats in the Battle of the Atlantic, and to the British naval victories in the Battle of Cape Matapan and the Battle of North Cape. In 1941, Ultra exerted a powerful effect on the North African desert campaign against German forces under General Erwin Rommel. General Sir Claude Auchinleck wrote that were it not for Ultra, \"Rommel would have certainly got through to Cairo\". Ultra decrypts featured prominently in the story of Operation SALAM, L\u00e1szl\u00f3 Alm\u00e1sy's mission across the desert behind Allied lines in 1942. Prior to the Normandy landings on D-Day in June 1944, the Allies knew the locations of all but two of Germany's fifty-eight Western Front divisions.\nWinston Churchill was reported to have told King George VI: \"It is thanks to the secret weapon of General Menzies, put into use on all the fronts, that we won the war!\" Supreme Allied Commander, Dwight D. Eisenhower, at the end of the war, described Ultra as having been \"decisive\" to Allied victory. Official historian of British Intelligence in World War II Sir Harry Hinsley argued that Ultra shortened the war \"by not less than two years and probably by four years\"; and that, in the absence of Ultra, it is uncertain how the war would have ended.\nAt a lower level, German cryptanalysis, direction finding, and traffic analysis were vital to Rommel's early successes in the Western Desert Campaign until British forces tightened their communications discipline and Australian raiders destroyed his principal SIGINT Company.\nTechnical definitions.\nThe United States Department of Defense has defined the term \"signals intelligence\" as:\nBeing a broad field, SIGINT has many sub-disciplines. The two main ones are communications intelligence (COMINT) and electronic intelligence (ELINT).\nDisciplines shared across the branches.\nTargeting.\nA collection system has to know to look for a particular signal. \"System\", in this context, has several nuances. Targeting is the process of developing \"collection requirements\":\n\"1. An intelligence need considered in the allocation of intelligence resources. Within the Department of Defense, these collection requirements fulfill the essential elements of information and other intelligence needs of a commander, or an agency.\n\"2. An established intelligence need, validated against the appropriate allocation of intelligence resources (as a requirement) to fulfill the essential elements of information and other intelligence needs of an intelligence consumer.\"\nNeed for multiple, coordinated receivers.\nFirst, atmospheric conditions, sunspots, the target's transmission schedule and antenna characteristics, and other factors create uncertainty that a given signal intercept sensor will be able to \"hear\" the signal of interest, even with a geographically fixed target and an opponent making no attempt to evade interception. Basic countermeasures against interception include frequent changing of radio frequency, polarization, and other transmission characteristics. An intercept aircraft could not get off the ground if it had to carry antennas and receivers for every possible frequency and signal type to deal with such countermeasures.\nSecond, locating the transmitter's position is usually part of SIGINT. Triangulation and more sophisticated radio location techniques, such as time of arrival methods, require multiple receiving points at different locations. These receivers send location-relevant information to a central point, or perhaps to a distributed system in which all participate, such that the information can be correlated and a location computed.\nIntercept management.\nModern SIGINT systems, therefore, have substantial communications among intercept platforms. Even if some platforms are clandestine, there is still a broadcast of information telling them where and how to look for signals. A United States targeting system under development in the late 1990s, PSTS, constantly sends out information that helps the interceptors properly aim their antennas and tune their receivers. Larger intercept aircraft, such as the EP-3 or RC-135, have the on-board capability to do some target analysis and planning, but others, such as the RC-12 GUARDRAIL, are completely under ground direction. GUARDRAIL aircraft are fairly small and usually work in units of three to cover a tactical SIGINT requirement, whereas the larger aircraft tend to be assigned strategic/national missions.\nBefore the detailed process of targeting begins, someone has to decide there is a value in collecting information about something. While it would be possible to direct signals intelligence collection at a major sports event, the systems would capture a great deal of noise, news signals, and perhaps announcements in the stadium. If, however, an anti-terrorist organization believed that a small group would be trying to coordinate their efforts using short-range unlicensed radios at the event, SIGINT targeting of radios of that type would be reasonable. Targeting would not know where in the stadium the radios might be located or the exact frequency they are using; those are the functions of subsequent steps such as signal detection and direction finding.\nOnce the decision to target is made, the various interception points need to cooperate, since resources are limited.\nKnowing what interception equipment to use becomes easier when a target country buys its radars and radios from known manufacturers, or is given them as military aid. National intelligence services keep libraries of devices manufactured by their own country and others, and then use a variety of techniques to learn what equipment is acquired by a given country.\nKnowledge of physics and electronic engineering further narrows the problem of what types of equipment might be in use. An intelligence aircraft flying well outside the borders of another country will listen for long-range search radars, not short-range fire control radars that would be used by a mobile air defense. Soldiers scouting the front lines of another army know that the other side will be using radios that must be portable and not have huge antennas.\nSignal detection.\nEven if a signal is human communications (e.g., a radio), the intelligence collection specialists have to know it exists. If the targeting function described above learns that a country has a radar that operates in a certain frequency range, the first step is to use a sensitive receiver, with one or more antennas that listen in every direction, to find an area where such a radar is operating. Once the radar is known to be in the area, the next step is to find its location.\nIf operators know the probable frequencies of transmissions of interest, they may use a set of receivers, preset to the frequencies of interest. These are the frequency (horizontal axis) versus power (vertical axis) produced at the transmitter, before any filtering of signals that do not add to the information being transmitted. Received energy on a particular frequency may start a recorder, and alert a human to listen to the signals if they are intelligible (i.e., COMINT). If the frequency is not known, the operators may look for power on primary or sideband frequencies using a spectrum analyzer. Information from the spectrum analyzer is then used to tune receivers to signals of interest. For example, in this simplified spectrum, the actual information is at 800\u00a0kHz and 1.2\u00a0MHz.\nReal-world transmitters and receivers usually are directional. In the figure to the left, assume that each display is connected to a spectrum analyzer connected to a directional antenna aimed in the indicated direction.\nCountermeasures to interception.\nSpread-spectrum communications is an electronic counter-countermeasures (ECCM) technique to defeat looking for particular frequencies. Spectrum analysis can be used in a different ECCM way to identify frequencies not being jammed or not in use.\nDirection-finding.\nThe earliest, and still common, means of direction finding is to use directional antennas as goniometers, so that a line can be drawn from the receiver through the position of the signal of interest. (See HF/DF.) Knowing the compass bearing, from a single point, to the transmitter does not locate it. Where the bearings from multiple points, using goniometry, are plotted on a map, the transmitter will be located at the point where the bearings intersect. This is the simplest case; a target may try to confuse listeners by having multiple transmitters, giving the same signal from different locations, switching on and off in a pattern known to their user but apparently random to the listener.\nIndividual directional antennas have to be manually or automatically turned to find the signal direction, which may be too slow when the signal is of short duration. One alternative is the Wullenweber array technique. In this method, several concentric rings of antenna elements simultaneously receive the signal, so that the best bearing will ideally be clearly on a single antenna or a small set. Wullenweber arrays for high-frequency signals are enormous, referred to as \"elephant cages\" by their users.\nA more advance approach is Amplitude comparison. An alternative to tunable directional antennas or large omnidirectional arrays such as the Wullenweber is to measure the time of arrival of the signal at multiple points, using GPS or a similar method to have precise time synchronization. Receivers can be on ground stations, ships, aircraft, or satellites, giving great flexibility. \nA more accurate approach is Interferometer. \nModern anti-radiation missiles can home in on and attack transmitters; military antennas are rarely a safe distance from the user of the transmitter.\nTraffic analysis.\nWhen locations are known, usage patterns may emerge, from which inferences may be drawn. Traffic analysis is the discipline of drawing patterns from information flow among a set of senders and receivers, whether those senders and receivers are designated by location determined through direction finding, by addressee and sender identifications in the message, or even MASINT techniques for \"fingerprinting\" transmitters or operators. Message content other than the sender and receiver is not necessary to do traffic analysis, although more information can be helpful.\nFor example, if a certain type of radio is known to be used only by tank units, even if the position is not precisely determined by direction finding, it may be assumed that a tank unit is in the general area of the signal. The owner of the transmitter can assume someone is listening, so might set up tank radios in an area where he wants the other side to believe he has actual tanks. As part of Operation Quicksilver, part of the deception plan for the invasion of Europe at the Battle of Normandy, radio transmissions simulated the headquarters and subordinate units of the fictitious First United States Army Group (FUSAG), commanded by George S. Patton, to make the German defense think that the main invasion was to come at another location. In like manner, fake radio transmissions from Japanese aircraft carriers, before the Battle of Pearl Harbor, were made from Japanese local waters, while the attacking ships moved under strict radio silence.\nTraffic analysis need not focus on human communications. For example, a sequence of a radar signal, followed by an exchange of targeting data and a confirmation, followed by observation of artillery fire, may identify an automated counterbattery fire system. A radio signal that triggers navigational beacons could be a radio landing aid for an airstrip or helicopter pad that is intended to be low-profile.\nPatterns do emerge. A radio signal with certain characteristics, originating from a fixed headquarters, may strongly suggest that a particular unit will soon move out of its regular base. The contents of the message need not be known to infer the movement.\nThere is an art as well as science of traffic analysis. Expert analysts develop a sense for what is real and what is deceptive. Harry Kidder, for example, was one of the star cryptanalysts of World War II, a star hidden behind the secret curtain of SIGINT.\nElectronic order of battle.\nGenerating an electronic order of battle (EOB) requires identifying SIGINT emitters in an area of interest, determining their geographic location or range of mobility, characterizing their signals, and, where possible, determining their role in the broader organizational order of battle. EOB covers both COMINT and ELINT. The Defense Intelligence Agency maintains an EOB by location. The Joint Spectrum Center (JSC) of the Defense Information Systems Agency supplements this location database with five more technical databases:\n# FRRS: Frequency Resource Record System\n# BEI: Background Environment Information\n# SCS: Spectrum Certification System\n# EC/S: Equipment Characteristics/Space\n# TACDB: platform lists, sorted by nomenclature, which contain links to the C-E equipment complement of each platform, with links to the parametric data for each piece of equipment, military unit lists and their subordinate units with equipment used by each unit.\nFor example, several voice transmitters might be identified as the command net (i.e., top commander and direct reports) in a tank battalion or tank-heavy task force. Another set of transmitters might identify the logistic net for that same unit. An inventory of ELINT sources might identify the medium- and long-range counter-artillery radars in a given area.\nSignals intelligence units will identify changes in the EOB, which might indicate enemy unit movement, changes in command relationships, and increases or decreases in capability.\nUsing the COMINT gathering method enables the intelligence officer to produce an electronic order of battle by traffic analysis and content analysis among several enemy units. For example, if the following messages were intercepted:\n# U1 to U2, requesting permission to proceed to checkpoint X.\n# U2 to U1, approved. please report at arrival.\n# (20 minutes later) U1 to U2, all vehicles have arrived to checkpoint X.\nThis sequence shows that there are two units in the battlefield, unit 1 is mobile, while unit 2 is in a higher hierarchical level, perhaps a command post. One can also understand that unit 1 moved from one point to another which are distant from each 20 minutes with a vehicle. If these are regular reports over a period of time, they might reveal a patrol pattern. Direction-finding and radio frequency MASINT could help confirm that the traffic is not deception.\nThe EOB buildup process is divided as following:\n* Signal separation\n* Measurements optimization\n* Data fusion\n* Networks build-up\nSeparation of the intercepted spectrum and the signals intercepted from each sensor must take place in an extremely small period of time, in order to separate the different signals to different transmitters in the battlefield. The complexity of the separation process depends on the complexity of the transmission methods (e.g., hopping or time-division multiple access (TDMA)).\nBy gathering and clustering data from each sensor, the measurements of the direction of signals can be optimized and get much more accurate than the basic measurements of a standard direction finding sensor. By calculating larger samples of the sensor's output data in near real-time, together with historical information of signals, better results are achieved.\nData fusion correlates data samples from different frequencies from the same sensor, \"same\" being confirmed by direction finding or radiofrequency MASINT. If an emitter is mobile, direction finding, other than discovering a repetitive pattern of movement, is of limited value in determining if a sensor is unique. MASINT then becomes more informative, as individual transmitters and antennas may have unique side lobes, unintentional radiation, pulse timing, etc.\nNetwork build-up, or analysis of emitters (communication transmitters) in a target region over a sufficient period of time, enables creation of the communications flows of a battlefield.\nCommunications intelligence.\nCOMINT (communications intelligence) is a sub-category of signals intelligence that engages in dealing with messages or voice information derived from the interception of foreign communications. COMINT is commonly referred to as SIGINT, which can cause confusion when talking about the broader intelligence disciplines. The US Joint Chiefs of Staff defines it as \"Technical information and intelligence derived from foreign communications by other than the intended recipients\".\nCOMINT, which is defined to be communications among people, will reveal some or all of the following:\nVoice interception.\nA basic COMINT technique is to listen for voice communications, usually over radio but possibly \"leaking\" from telephones or from wiretaps. If the voice communications are encrypted, traffic analysis may still give information.\nIn the Second World War, for security the United States used Native American volunteer communicators known as code talkers, who used languages such as Navajo, Comanche and Choctaw, which would be understood by few people, even in the U.S. Even within these uncommon languages, the code talkers used specialized codes, so a \"butterfly\" might be a specific Japanese aircraft. British forces made limited use of Welsh speakers for the same reason.\nWhile modern electronic encryption does away with the need for armies to use obscure languages, it is likely that some groups might use rare dialects that few outside their ethnic group would understand.\nText interception.\nMorse code interception was once very important, but Morse code telegraphy is now obsolete in the western world, although possibly used by special operations forces. Such forces, however, now have portable cryptographic equipment.\nSpecialists scan radio frequencies for character sequences (e.g., electronic mail) and fax.\nSignaling channel interception.\nA given digital communications link can carry thousands or millions of voice communications, especially in developed countries. Without addressing the legality of such actions, the problem of identifying which channel contains which conversation becomes much simpler when the first thing intercepted is the \"signaling channel\" that carries information to set up telephone calls. In civilian and many military use, this channel will carry messages in Signaling System 7 protocols.\nRetrospective analysis of telephone calls can be made from Call detail record (CDR) used for billing the calls.\nMonitoring friendly communications.\nMore a part of communications security than true intelligence collection, SIGINT units still may have the responsibility of monitoring one's own communications or other electronic emissions, to avoid providing intelligence to the enemy. For example, a security monitor may hear an individual transmitting inappropriate information over an unencrypted radio network, or simply one that is not authorized for the type of information being given. If immediately calling attention to the violation would not create an even greater security risk, the monitor will call out one of the BEADWINDOW codes used by Australia, Canada, New Zealand, the United Kingdom, the United States, and other nations working under their procedures. Standard BEADWINDOW codes (e.g., \"BEADWINDOW 2\") include:\nIn WWII, for example, the Japanese Navy, by poor practice, identified a key person's movement over a low-security cryptosystem. This made possible Operation Vengeance, the interception and death of the Combined Fleet commander, Admiral Isoroku Yamamoto.\nElectronic signals intelligence.\nElectronic signals intelligence (ELINT) refers to intelligence-gathering by use of electronic sensors. Its primary focus lies on non-communications signals intelligence. The Joint Chiefs of Staff define it as \"Technical and geolocation intelligence derived from foreign noncommunications electromagnetic radiations emanating from sources other than nuclear detonations or radioactive sources.\"\nSignal identification is performed by analyzing the collected parameters of a specific signal, and either matching it to known criteria, or recording it as a possible new emitter. ELINT data are usually highly classified, and are protected as such.\nThe data gathered are typically pertinent to the electronics of an opponent's defense network, especially the electronic parts such as radars, surface-to-air missile systems, aircraft, etc. ELINT can be used to detect ships and aircraft by their radar and other electromagnetic radiation; commanders have to make choices between not using radar (EMCON), intermittently using it, or using it and expecting to avoid defenses. ELINT can be collected from ground stations near the opponent's territory, ships off their coast, aircraft near or in their airspace, or by satellite.\nComplementary relationship to COMINT.\nCombining other sources of information and ELINT allows traffic analysis to be performed on electronic emissions which contain human encoded messages. The method of analysis differs from SIGINT in that any human encoded message which is in the electronic transmission is not analyzed during ELINT. What is of interest is the type of electronic transmission and its location. For example, during the Battle of the Atlantic in World War II, Ultra COMINT was not always available because Bletchley Park was not always able to read the U-boat Enigma traffic. But high-frequency direction finding (\"huff-duff\") was still able to detect U-boats by analysis of radio transmissions and the positions through triangulation from the direction located by two or more huff-duff systems. The Admiralty was able to use this information to plot courses which took convoys away from high concentrations of U-boats.\nOther ELINT disciplines include intercepting and analyzing enemy weapons control signals, or the identification, friend or foe responses from transponders in aircraft used to distinguish enemy craft from friendly ones.\nRole in air warfare.\nA very common area of ELINT is intercepting radars and learning their locations and operating procedures. Attacking forces may be able to avoid the coverage of certain radars, or, knowing their characteristics, electronic warfare units may jam radars or send them deceptive signals. Confusing a radar electronically is called a \"soft kill\", but military units will also send specialized missiles at radars, or bomb them, to get a \"hard kill\". Some modern air-to-air missiles also have radar homing guidance systems, particularly for use against large airborne radars.\nKnowing where each surface-to-air missile and anti-aircraft artillery system is and its type means that air raids can be plotted to avoid the most heavily defended areas and to fly on a flight profile which will give the aircraft the best chance of evading ground fire and fighter patrols. It also allows for the jamming or spoofing of the enemy's defense network (see electronic warfare). Good electronic intelligence can be very important to stealth operations; stealth aircraft are not totally undetectable and need to know which areas to avoid. Similarly, conventional aircraft need to know where fixed or semi-mobile air defense systems are so that they can shut them down or fly around them.\nELINT and ESM.\nElectronic support measures (ESM) or electronic surveillance measures are ELINT techniques using various \"electronic surveillance systems\", but the term is used in the specific context of tactical warfare. ESM give the information needed for electronic attack (EA) such as jamming, or directional bearings (compass angle) to a target in \"signals intercept\" such as in the huff-duff radio direction finding (RDF) systems so critically important during the World War II Battle of the Atlantic. After WWII, the RDF, originally applied only in communications, was broadened into systems to also take in ELINT from radar bandwidths and lower frequency communications systems, giving birth to a family of NATO ESM systems, such as the shipboard US AN/WLR-1\u2014AN/WLR-6 systems and comparable airborne units. EA is also called electronic counter-measures (ECM). ESM provides information needed for electronic counter-counter measures (ECCM), such as understanding a spoofing or jamming mode so one can change one's radar characteristics to avoid them.\nELINT for meaconing.\nMeaconing is the combined intelligence and electronic warfare of learning the characteristics of enemy navigation aids, such as radio beacons, and retransmitting them with incorrect information.\nForeign instrumentation signals intelligence.\nFISINT (Foreign instrumentation signals intelligence) is a sub-category of SIGINT, monitoring primarily non-human communication. Foreign instrumentation signals include (but not limited to) telemetry (TELINT), tracking systems, and video data links. TELINT is an important part of national means of technical verification for arms control.\nCounter-ELINT.\nStill at the research level are techniques that can only be described as , which would be part of a SEAD campaign. It may be informative to compare and contrast counter-ELINT with ECCM.\nSIGINT and MASINT comparison.\nSignals intelligence and measurement and signature intelligence (MASINT) are closely, and sometimes confusingly, related.\nThe signals intelligence disciplines of communications and electronic intelligence focus on the information in those signals themselves, as with COMINT detecting the speech in a voice communication or ELINT measuring the frequency, pulse repetition rate, and other characteristics of a radar.\nMASINT also works with collected signals, but is more of an analysis discipline. There are, however, unique MASINT sensors, typically working in different regions or domains of the electromagnetic spectrum, such as infrared or magnetic fields. While NSA and other agencies have MASINT groups, the Central MASINT Office is in the Defense Intelligence Agency (DIA).\nWhere COMINT and ELINT focus on the intentionally transmitted part of the signal, MASINT focuses on unintentionally transmitted information. For example, a given radar antenna will have sidelobes emanating from a direction other than that in which the main antenna is aimed. The RADINT (radar intelligence) discipline involves learning to recognize a radar both by its primary signal, captured by ELINT, and its sidelobes, perhaps captured by the main ELINT sensor, or, more likely, a sensor aimed at the sides of the radio antenna.\nMASINT associated with COMINT might involve the detection of common background sounds expected with human voice communications. For example, if a given radio signal comes from a radio used in a tank, if the interceptor does not hear engine noise or higher voice frequency than the voice modulation usually uses, even though the voice conversation is meaningful, MASINT might suggest it is a deception, not coming from a real tank.\nSee HF/DF for a discussion of SIGINT-captured information with a MASINT flavor, such as determining the frequency to which a \"receiver\" is tuned, from detecting the frequency of the beat frequency oscillator of the superheterodyne receiver.\nLegality.\nSince the invention of the radio, the international consensus has been that the radio-waves are no one's property, and thus the interception itself is not illegal. There can, however, be national laws on who is allowed to collect, store, and process radio traffic, and for what purposes. Monitoring traffic in cables (i.e. telephone and Internet) is far more controversial, since it most of the time requires physical access to the cable and thereby violating ownership and expected privacy.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29123", "revid": "3736169", "url": "https://en.wikipedia.org/wiki?curid=29123", "title": "Semantic Web", "text": "Extension of the Web to facilitate data exchange\nThe Semantic Web, sometimes known as Web 3.0, is an extension of the World Wide Web through standards set by the World Wide Web Consortium (W3C). The goal of the Semantic Web is to make Internet data machine-readable.\nTo enable the encoding of semantics with the data, technologies such as Resource Description Framework (RDF) and Web Ontology Language (OWL) are used. These technologies are used to formally represent metadata. For example, ontology can describe concepts, relationships between entities, and categories of things. These embedded semantics offer significant advantages such as reasoning over data and operating with heterogeneous data sources.\nThese standards promote common data formats and exchange protocols on the Web, fundamentally the RDF. According to the W3C, \"The Semantic Web provides a common framework that allows data to be shared and reused across application, enterprise, and community boundaries.\" The Semantic Web is therefore regarded as an integrator across different content and information applications and systems.\nHistory.\nThe term was coined by Tim Berners-Lee for a web of data (or data web) that can be processed by machines\u2014that is, one in which much of the meaning is machine-readable. While its critics have questioned its feasibility, proponents argue that applications in library and information science, industry, biology and human sciences research have already proven the validity of the original concept.\nBerners-Lee originally expressed his vision of the Semantic Web in 1999 as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I have a dream for the Web [in which computers] become capable of analyzing all the data on the Web\u00a0\u2013 the content, links, and transactions between people and computers. A \"Semantic Web\", which makes this possible, has yet to emerge, but when it does, the day-to-day mechanisms of trade, bureaucracy and our daily lives will be handled by machines talking to machines. The \"intelligent agents\" people have touted for ages will finally materialize.\nThe 2001 \"Scientific American\" article by Berners-Lee, Hendler, and Lassila described an expected evolution of the existing Web to a Semantic Web. In 2006, Berners-Lee and colleagues stated that: \"This simple idea\u2026remains largely unrealized\".\nIn 2013, more than four million Web domains (out of roughly 250 million total) contained Semantic Web markup.\nExample.\nIn the following example, the text \"Paul Schuster was born in Dresden\" on a website will be annotated, connecting a person with their place of birth. The following HTML fragment shows how a small graph is being described, in RDFa-syntax using a schema.org vocabulary and a Wikidata ID:\n&lt;div vocab=\"https://schema.org/\" typeof=\"Person\"&gt;\n &lt;span property=\"name\"&gt;Paul Schuster&lt;/span&gt; was born in\n &lt;span property=\"birthPlace\" typeof=\"Place\" href=\"https://www.wikidata.org/entity/Q1731\"&gt;\n &lt;span property=\"name\"&gt;Dresden&lt;/span&gt;.\n &lt;/span&gt;\n&lt;/div&gt;\nThe example defines the following five triples (shown in Turtle syntax). Each triple represents one edge in the resulting graph: the first element of the triple (the \"subject\") is the name of the node where the edge starts, the second element (the \"predicate\") the type of the edge, and the last and third element (the \"object\") either the name of the node where the edge ends or a literal value (e.g. a text, a number, etc.).\n _:a &lt;https://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;https://schema.org/Person&gt; .\n _:a &lt;https://schema.org/name&gt; \"Paul Schuster\" .\n _:a &lt;https://schema.org/birthPlace&gt; &lt;https://www.wikidata.org/entity/Q1731&gt; .\n &lt;https://www.wikidata.org/entity/Q1731&gt; &lt;https://schema.org/itemtype&gt; &lt;https://schema.org/Place&gt; .\n &lt;https://www.wikidata.org/entity/Q1731&gt; &lt;https://schema.org/name&gt; \"Dresden\" .\nThe triples result in the graph shown in the given figure.\nOne of the advantages of using Uniform Resource Identifiers (URIs) is that they can be dereferenced using the HTTP protocol. According to the so-called Linked Open Data principles, such a dereferenced URI should result in a document that offers further data about the given URI. In this example, all URIs, both for edges and nodes (e.g. , , ) can be dereferenced and will result in further RDF graphs, describing the URI, e.g. that Dresden is a city in Germany, or that a person, in the sense of that URI, can be fictional.\nThe second graph shows the previous example, but now enriched with a few of the triples from the documents that result from dereferencing (green edge) and (blue edges).\nAdditionally to the edges given in the involved documents explicitly, edges can be automatically inferred: the triple\n _:a &lt;https://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://schema.org/Person&gt; .\nfrom the original RDFa fragment and the triple\n &lt;https://schema.org/Person&gt; &lt;http://www.w3.org/2002/07/owl#equivalentClass&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\nfrom the document at (green edge in the figure) allow to infer the following triple, given OWL semantics (red dashed line in the second Figure):\n _:a &lt;https://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://xmlns.com/foaf/0.1/Person&gt; .\nBackground.\nThe concept of the semantic network model was formed in the early 1960s by researchers such as the cognitive scientist Allan M. Collins, linguist Ross Quillian and psychologist Elizabeth F. Loftus as a form to represent semantically structured knowledge. When applied in the context of the modern internet, it extends the network of hyperlinked human-readable web pages by inserting machine-readable metadata about pages and how they are related to each other. This enables automated agents to access the Web more intelligently and perform more tasks on behalf of users. The term \"Semantic Web\" was coined by Tim Berners-Lee, the inventor of the World Wide Web and director of the World Wide Web Consortium (\"W3C\"), which oversees the development of proposed Semantic Web standards. He defines the Semantic Web as \"a web of data that can be processed directly and indirectly by machines\".\nMany of the technologies proposed by the W3C already existed before they were positioned under the W3C umbrella. These are used in various contexts, particularly those dealing with information that encompasses a limited and defined domain, and where sharing data is a common necessity, such as scientific research or data exchange among businesses. In addition, other technologies with similar goals have emerged, such as microformats.\nLimitations of HTML.\nMany files on a typical computer can be loosely divided into either human-readable documents, or machine-readable data. Examples of human-readable document files are mail messages, reports, and brochures. Examples of machine-readable data files are calendars, address books, playlists, and spreadsheets, which are presented to a user using an application program that lets the files be viewed, searched, and combined.\nCurrently, the World Wide Web is based mainly on documents written in Hypertext Markup Language (HTML), a markup convention that is used for coding a body of text interspersed with multimedia objects such as images and interactive forms. Metadata tags provide a method by which computers can categorize the content of web pages. In the examples below, the field names \"keywords\", \"description\" and \"author\" are assigned values such as \"computing\", and \"cheap widgets for sale\" and \"John Doe\".\n&lt;meta name=\"keywords\" content=\"computing, computer studies, computer\" /&gt;\n&lt;meta name=\"description\" content=\"Cheap widgets for sale\" /&gt;\n&lt;meta name=\"author\" content=\"John Doe\" /&gt;\nBecause of this metadata tagging and categorization, other computer systems that want to access and share this data can easily identify the relevant values.\nWith HTML and a tool to render it (perhaps web browser software, perhaps another user agent), one can create and present a page that lists items for sale. The HTML of this catalog page can make simple, document-level assertions such as \"this document's title is 'Widget Superstore'\", but there is no capability within the HTML itself to assert unambiguously that, for example, item number X586172 is an Acme Gizmo with a retail price of \u20ac199, or that it is a consumer product. Rather, HTML can only say that the span of text \"X586172\" is something that should be positioned near \"Acme Gizmo\" and \"\u20ac199\", etc. There is no way to say \"this is a catalog\" or even to establish that \"Acme Gizmo\" is a kind of title or that \"\u20ac199\" is a price. There is also no way to express that these pieces of information are bound together in describing a discrete item, distinct from other items perhaps listed on the page.\nSemantic HTML refers to the traditional HTML practice of markup following intention, rather than specifying layout details directly. For example, the use of codice_1 denoting \"emphasis\" rather than codice_1, which specifies italics. Layout details are left up to the browser, in combination with Cascading Style Sheets. But this practice falls short of specifying the semantics of objects such as items for sale or prices.\nMicroformats extend HTML syntax to create machine-readable semantic markup about objects including people, organizations, events and products. Similar initiatives include RDFa, Microdata and Schema.org.\nSemantic Web solutions.\nThe Semantic Web takes the solution further. It involves publishing in languages specifically designed for data: Resource Description Framework (RDF), Web Ontology Language (OWL), and Extensible Markup Language (XML). HTML describes documents and the links between them. RDF, OWL, and XML, by contrast, can describe arbitrary things such as people, meetings, or airplane parts.\nThese technologies are combined in order to provide descriptions that supplement or replace the content of Web documents. Thus, content may manifest itself as descriptive data stored in Web-accessible databases, or as markup within documents (particularly, in Extensible HTML (XHTML) interspersed with XML, or, more often, purely in XML, with layout or rendering cues stored separately). The machine-readable descriptions enable content managers to add meaning to the content, i.e., to describe the structure of the knowledge we have about that content. In this way, a machine can process knowledge itself, instead of text, using processes similar to human deductive reasoning and inference, thereby obtaining more meaningful results and helping computers to perform automated information gathering and research.\nAn example of a tag that would be used in a non-semantic web page:\n&lt;item&gt;blog&lt;/item&gt;\nEncoding similar information in a semantic web page might look like this:\n&lt;item rdf:about=\"https://example.org/semantic-web/\"&gt;Semantic Web&lt;/item&gt;\nTim Berners-Lee calls the resulting network of Linked Data the Giant Global Graph, in contrast to the HTML-based World Wide Web. Berners-Lee posits that if the past was document sharing, the future is data sharing. His answer to the question of \"how\" provides three points of instruction. One, a URL should point to the data. Two, anyone accessing the URL should get data back. Three, relationships in the data should point to additional URLs with data.\nTags and identifiers.\nTags, including hierarchical categories and tags that are collaboratively added and maintained (e.g. with folksonomies) can be considered part of, of potential use to or a step towards the semantic Web vision.\nUnique identifiers, including hierarchical categories and collaboratively added ones, analysis tools and metadata, including tags, can be used to create forms of semantic webs \u2013 webs that are to a certain degree semantic. In particular, such has been used for structuring scientific research i.a. by research topics and scientific fields by the projects OpenAlex, Wikidata and Scholia which are under development and provide APIs, Web-pages, feeds and graphs for various semantic queries.\nWeb 3.0.\nTim Berners-Lee has described the Semantic Web as a component of Web 3.0.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;People keep asking what Web 3.0 is. I think maybe when you've got an overlay of scalable vector graphics \u2013 everything rippling and folding and looking misty\u00a0\u2013 on Web 2.0 and access to a semantic Web integrated across a huge space of data, you'll have access to an unbelievable data resource \u2026\u2014\u200a\n\"Semantic Web\" is sometimes used as a synonym for \"Web 3.0\", though the definition of each term varies.\nBeyond Web 3.0.\nThe next generation of the Web is often termed Web 4.0, but its definition is not clear. According to some sources, it is a Web that involves artificial intelligence, the internet of things, pervasive computing, ubiquitous computing and the Web of Things among other concepts. According to the European Union, Web 4.0 is \"the expected fourth generation of the World Wide Web. Using advanced artificial and ambient intelligence, the internet of things, trusted blockchain transactions, virtual worlds and XR capabilities, digital and real objects and environments are fully integrated and communicate with each other, enabling truly intuitive, immersive experiences, seamlessly blending the physical and digital worlds\".\nChallenges.\nSome of the challenges for the Semantic Web include vastness, vagueness, uncertainty, inconsistency, and deceit. Automated reasoning systems will have to deal with all of these issues in order to deliver on the promise of the Semantic Web.\nThis list of challenges is illustrative rather than exhaustive, and it focuses on the challenges to the \"unifying logic\" and \"proof\" layers of the Semantic Web. The World Wide Web Consortium (W3C) Incubator Group for Uncertainty Reasoning for the World Wide Web (URW3-XG) final report lumps these problems together under the single heading of \"uncertainty\". Many of the techniques mentioned here will require extensions to the Web Ontology Language (OWL) for example to annotate conditional probabilities. This is an area of active research.\nStandards.\nStandardization for Semantic Web in the context of Web 3.0 is under the care of W3C.\nComponents.\nThe term \"Semantic Web\" is often used more specifically to refer to the formats and technologies that enable it. The collection, structuring and recovery of linked data are enabled by technologies that provide a formal description of concepts, terms, and relationships within a given knowledge domain. These technologies are specified as W3C standards and include:\nThe Semantic Web Stack illustrates the architecture of the Semantic Web. The functions and relationships of the components can be summarized as follows:\nCurrent state of standardization.\nWell-established standards:\nNot yet fully realized:\nApplications.\nThe intent is to enhance the usability and usefulness of the Web and its interconnected resources by creating semantic web services, such as:\nSuch services could be useful to public search engines, or could be used for knowledge management within an organization. Business applications include:\nIn a corporation, there is a closed group of users and the management is able to enforce company guidelines like the adoption of specific ontologies and use of semantic annotation. Compared to the public Semantic Web there are lesser requirements on scalability and the information circulating within a company can be more trusted in general; privacy is less of an issue outside of handling of customer data.\nSkeptical reactions.\nPractical feasibility.\nCritics question the basic feasibility of a complete or even partial fulfillment of the Semantic Web, pointing out both difficulties in setting it up and a lack of general-purpose usefulness that prevents the required effort from being invested. In a 2003 paper, Marshall and Shipman point out the cognitive overhead inherent in formalizing knowledge, compared to the authoring of traditional web hypertext:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;While learning the basics of HTML is relatively straightforward, learning a knowledge representation language or tool requires the author to learn about the representation's methods of abstraction and their effect on reasoning. For example, understanding the class-instance relationship, or the superclass-subclass relationship, is more than understanding that one concept is a \"type of\" another concept. [...] These abstractions are taught to computer scientists generally and knowledge engineers specifically but do not match the similar natural language meaning of being a \"type of\" something. Effective use of such a formal representation requires the author to become a skilled knowledge engineer in addition to any other skills required by the domain. [...] Once one has learned a formal representation language, it is still often much more effort to express ideas in that representation than in a less formal representation [...]. Indeed, this is a form of programming based on the declaration of semantic data and requires an understanding of how reasoning algorithms will interpret the authored structures.\nAccording to Marshall and Shipman, the tacit and changing nature of much knowledge adds to the knowledge engineering problem, and limits the Semantic Web's applicability to specific domains. A further issue that they point out are domain- or organization-specific ways to express knowledge, which must be solved through community agreement rather than only technical means. As it turns out, specialized communities and organizations for intra-company projects have tended to adopt semantic web technologies greater than peripheral and less-specialized communities. The practical constraints toward adoption have appeared less challenging where domain and scope is more limited than that of the general public and the World-Wide Web.\nFinally, Marshall and Shipman see pragmatic problems in the idea of (Knowledge Navigator-style) intelligent agents working in the largely manually curated Semantic Web:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In situations in which user needs are known and distributed information resources are well described, this approach can be highly effective; in situations that are not foreseen and that bring together an unanticipated array of information resources, the Google approach is more robust. Furthermore, the Semantic Web relies on inference chains that are more brittle; a missing element of the chain results in a failure to perform the desired action, while the human can supply missing pieces in a more Google-like approach. [...] cost-benefit tradeoffs can work in favor of specially-created Semantic Web metadata directed at weaving together sensible well-structured domain-specific information resources; close attention to user/customer needs will drive these federations if they are to be successful.\nCory Doctorow's critique (\"metacrap\") is from the perspective of human behavior and personal preferences. For example, people may include spurious metadata into Web pages in an attempt to mislead Semantic Web engines that naively assume the metadata's veracity. This phenomenon was well known with metatags that fooled the Altavista ranking algorithm into elevating the ranking of certain Web pages: the Google indexing engine specifically looks for such attempts at manipulation. Peter G\u00e4rdenfors and Timo Honkela point out that logic-based semantic web technologies cover only a fraction of the relevant phenomena related to semantics.\nCensorship and privacy.\nEnthusiasm about the semantic web could be tempered by concerns regarding censorship and privacy. For instance, text-analyzing techniques can now be easily bypassed by using other words, metaphors for instance, or by using images in place of words. An advanced implementation of the semantic web would make it much easier for governments to control the viewing and creation of online information, as this information would be much easier for an automated content-blocking machine to understand. In addition, the issue has also been raised that, with the use of FOAF files and geolocation meta-data, there would be very little anonymity associated with the authorship of articles on things such as a personal blog. Some of these concerns were addressed in the \"Policy Aware Web\" project and is an active research and development topic.\nDoubling output formats.\nAnother criticism of the semantic web is that it would be much more time-consuming to create and publish content because there would need to be two formats for one piece of data: one for human viewing and one for machines. However, many web applications in development are addressing this issue by creating a machine-readable format upon the publishing of data or the request of a machine for such data. The development of microformats has been one reaction to this kind of criticism. Another argument in defense of the feasibility of semantic web is the likely falling price of human intelligence tasks in digital labor markets, such as Amazon's Mechanical Turk.\nSpecifications such as eRDF and RDFa allow arbitrary RDF data to be embedded in HTML pages. The GRDDL (Gleaning Resource Descriptions from Dialects of Language) mechanism allows existing material (including microformats) to be automatically interpreted as RDF, so publishers only need to use a single format, such as HTML.\nResearch activities on corporate applications.\nThe first research group explicitly focusing on the Corporate Semantic Web was the ACACIA team at INRIA-Sophia-Antipolis, founded in 2002. Results of their work include the RDF(S) based Corese search engine, and the application of semantic web technology in the realm of distributed artificial intelligence for knowledge management (e.g. ontologies and multi-agent systems for corporate semantic Web) and E-learning.\nSince 2008, the Corporate Semantic Web research group, located at the Free University of Berlin, focuses on building blocks: Corporate Semantic Search, Corporate Semantic Collaboration, and Corporate Ontology Engineering.\nOntology engineering research includes the question of how to involve non-expert users in creating ontologies and semantically annotated content and for extracting explicit knowledge from the interaction of users within enterprises.\nFuture of applications.\nTim O'Reilly, who coined the term Web 2.0, proposed a long-term vision of the Semantic Web as a web of data, where sophisticated applications are navigating and manipulating it. The data web transforms the World Wide Web from a distributed file system into a distributed database.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29124", "revid": "10289486", "url": "https://en.wikipedia.org/wiki?curid=29124", "title": "Soviet submarine K-219", "text": "A Project 667A Navaga-class ballistic missile submarine\nK-219 was a Project 667A \"Navaga\"-class ballistic missile submarine (NATO reporting name Yankee I) of the Soviet Navy. It carried 16 R-27U liquid-fuel missiles powered by UDMH with nitrogen tetroxide (NTO). \"K-219\" was involved in what has become one of the most controversial submarine incidents during the Cold War on 3 October 1986. The 15-year-old vessel, which was on an otherwise routine Cold War nuclear deterrence patrol in the North Atlantic northeast of Bermuda, suffered an explosion and fire in a missile tube. While underway, a submerged seal in a missile hatch cover failed, allowing high-pressure seawater to enter the missile tube and owing to the pressure differential ruptured the missile fuel tanks, allowing the missile's liquid fuel to mix and ultimately combust. Though there was no official announcement, the Soviet Union claimed the leak was caused by a collision with the submarine .\nAlthough \"Augusta\" was operating within the area, both the United States Navy and the commander of \"K-219\", Captain Second Rank Igor Britanov, deny that a collision took place.\nThe incident was novelized in the book \"Hostile Waters\", which reconstructed the incident from descriptions by the survivors, ships' logs, the official investigations, and participants both ashore and afloat from the Soviet and the American sides.\nExplosion.\nShortly after 0530 Moscow time, seawater leaking into silo six of \"K-219\" reacted with missile fuel, producing chlorine and nitrogen dioxide gases and sufficient heat to explosively decompose additional fuming nitric acid to produce more nitrogen dioxide gas. \"K-219\" weapons officer Alexander Petrachkov attempted to deal with this by disengaging the hatch cover and venting the missile tube to the sea. Shortly after 0532, an explosion occurred in the silo. \"K-219\" had previously experienced a similar event; one of her missile tubes was already disabled and welded shut, having been permanently sealed after an explosion caused by reaction between seawater leaking into the silo and missile fuel residue.\nAn article in \"Undersea Warfare\" by Captain First Rank, Igor Kurdin, Russian Navy \u2013 \"K-219\"'s previous XO (executive officer) \u2013 and Lieutenant Commander Wayne Grasdock, USN described the explosion occurrence as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;At 0514, the BCh-2 officer and the hold machinist/engineer in compartment IV (the forward missile compartment) discovered water dripping from under the plug of missile tube No. 6 (the third tube from the bow on the port side). During precompression of the plug, the drips turned into a stream. The BCh-2 officer reported water in missile tube No. 6, and at 0525, the captain ordered an ascent to a safe depth () while a pump was started in an attempt to dry out missile tube No. 6. At 0532, brown clouds of oxidant began issuing from under the missile-tube plug, and the BCh-2 officer declared an accident alert in the compartment and reported the situation to the GKP (main control post). Although personnel assigned to other compartments left the space, nine people remained in compartment IV. The captain declared an accident alert. It took the crew no more than one minute to carry out initial damage control measures, which included hermetically sealing all compartments. Five minutes later, at 0538, an explosion occurred in missile tube No. 6.\nTwo sailors were killed outright in the explosion, and a third died soon afterward from toxic gas poisoning. Through a breach in the hull, the vessel immediately started taking on seawater, quickly sinking from its original depth of to eventually reaching a depth of over . Sealing all of the compartments and full engagement of the seawater pumps in the stricken compartments enabled the depth to be stabilized.\nUp to 25 sailors were trapped in a sealed section, and it was only after a conference with his incident specialists that the captain allowed the chief engineer to open the hatch and save the 25 lives. It could be seen from instruments that although the nuclear reactor should have automatically been shut down, it was not. Lt. Nikolai Belikov, one of the reactor control officers, entered the reactor compartment but ran out of oxygen after turning just one of the four rod assemblies on the first reactor, forcing him to evacuate. Belikov then reentered with twenty-year-old enlisted seaman Sergei Preminin as support, shutting down the remaining three rod assemblies. However, they were forced to evacuate again due to heat and exhaustion, leaving the four assembly rods from the second reactor still active. Despite his exhaustion, Preminin then volunteered to single-handedly shut down the second reactor by following the instructions of the chief engineer. Working with a full-face gas mask, he succeeded, averting any potential meltdown. However, when Preminin tried to exit the reactor compartment, he found that the door would not open. A large fire had developed within the compartment, raising the pressure inside compared to that outside. The resulting pressure difference trapped Preminin inside the reactor compartment, where he eventually died of asphyxiation. For his actions, Sergei Preminin was posthumously awarded the title \"Hero of the Russian Federation.\"\nIn a nuclear safe condition, and with sufficient stability to allow it to surface, Captain Britanov surfaced \"K-219\" on battery power alone. He was then ordered to have the ship towed by a Soviet freighter back to her home port of Gadzhiyevo, away. Although a towline was attached, towing attempts were unsuccessful, and after subsequent poison gas leaks into the final aft compartments and against orders, Britanov ordered the crew to evacuate onto the towing ship, but remained aboard \"K-219\" himself.\nDispleased with Britanov's inability to repair his submarine and continue his patrol, Moscow ordered Valery Pshenichny, \"K-219\"'s security officer, to assume command, transfer the surviving crew back to the submarine, and return to duty. Before those orders could be carried out the flooding reached a point beyond recovery and on 6 October 1986 \"K-219\" sank to the bottom of the Hatteras Abyssal Plain at a depth of about . Britanov abandoned ship shortly before the sinking. \"K-219\"'s full complement of nuclear weapons was lost along with the vessel.\nAftermath.\nPreminin was posthumously awarded the Order of the Red Star for his bravery in securing the reactors. Britanov was charged with negligence, sabotage, and treason. He was never imprisoned, but waited for his trial in Sverdlovsk. On 30 May 1987, Defense Minister Sergey Sokolov was dismissed as a result of the Mathias Rust incident two days earlier, and replaced by Dmitry Yazov; the charges against Britanov were subsequently dismissed.\nIn popular culture.\nIn 1997, the British BBC television film \"Hostile Waters\", co-produced with HBO and starring Rutger Hauer, Martin Sheen, and Max von Sydow, was released in the United States by Warner Bros. It was based on the book by the same name, which claimed to describe the loss of \"K-219\". In 2001, Captain Britanov filed suit, claiming Warner Bros. did not seek or get his permission to use his story or his character, and that the film did not portray the events accurately and made him look incompetent. After three years of hearing, the court ruled in Britanov's favor. Russian media reported that the filmmaker paid a settlement totaling under $100,000.\nAfter the release of the movie, the U.S. Navy issued the following statement regarding both the book and the movie:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The United States Navy normally does not comment on submarine operations, but in the [\"sic\"] case, because the scenario is so outrageous, the Navy is compelled to respond. The United States Navy categorically denies that any U.S. submarine collided with the Soviet Yankee-class submarine K-219 or that the Navy had anything to do with the cause of the casualty that resulted in the loss of the Soviet Yankee-class submarine.\nAn article on the U.S. Navy's website posted by Captain 1st Rank (Ret.) Igor Kurdin (former XO of \"K-219\") and Lieutenant Commander Wayne Grasdock denied any collision between \"K-219\" and \"Augusta\". Captain Britanov also denies a collision, and he has stated that he was not asked to be a guest speaker at Russian functions, because he refuses to follow the Russian government's interpretation of the \"K-219\" incident.\nIn a BBC interview recorded in February 2013, Admiral of the Fleet Vladimir Chernavin, the Commander-in-Chief of the Soviet Navy at the time of the \"K-219\" incident, says the accident was caused by a malfunction in a missile tube, and makes no mention of a collision with an American submarine. The interview was conducted for the BBC2 series \"The Silent War\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29125", "revid": "10289486", "url": "https://en.wikipedia.org/wiki?curid=29125", "title": "Soviet submarine K-8", "text": "November-class submarine\nK-8 was a of the Soviet Northern Fleet that sank in the Bay of Biscay with her nuclear weapons on board on April 12, 1970. A fire on April 8 had disabled the submarine and it was being towed in rough seas. Fifty-two crewmen were killed attempting the salvage of the submarine when it sank.\nAccidents.\n1960 loss of coolant.\nOn 13 October 1960, while operating in the Barents Sea, \"K-8\" suffered a ruptured steam generator tube, causing a loss-of-coolant accident. While the crew jury-rigged a system to supply emergency cooling water to the reactor, preventing a reactor core meltdown, large amounts of radioactive gas leaked out which contaminated the entire vessel. The gas radiation levels could not be determined because instrumentation could not measure such large scales. Three of the crew suffered visible radiation injuries, and many crewmen were exposed to doses of up to 1.8\u20132 Sv (180\u2013200 rem).\n1970 Bay of Biscay fire.\nDuring the large-scale \"Ocean-70\" naval exercise, \"K-8\" suffered fires in two compartments simultaneously on 8 April 1970. Due to short circuits that took place in III and VII compartments simultaneously at a depth of , a fire spread through the air-conditioning system. Both nuclear reactors were shut down.\nThe captain ordered his entire crew to abandon ship but was countermanded once a towing vessel arrived. Fifty-two crewmen, including the commander, Captain 2nd Rank Vsevolod Bessonov, re-boarded the surfaced submarine that was to be towed. This was the first loss of a Soviet nuclear-powered submarine, which sank in rough seas as it was being towed in the Bay of Biscay of the North Atlantic Ocean. Eight sailors had already died due to certain compartments being locked to prevent further flooding as well as the spread of the fire as soon as it was detected. All hands on board died due to carbon monoxide poisoning and the flooding of the surfaced submarine during 80 hours of damage control in stormy conditions. Seventy-three crewmen survived. \"K-8\" sank with four nuclear torpedoes out of total 24 on board to a depth of approximately northwest of Spain.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29126", "revid": "50548049", "url": "https://en.wikipedia.org/wiki?curid=29126", "title": "Soviet submarine K-19", "text": "Ballistic missile submarine\nK-19 was the first submarine of the Project 658 (Russian: \u043f\u0440\u043e\u0435\u043a\u0442-658, lit. \"Projekt-658\") class (NATO reporting name ), the first generation of Soviet nuclear submarines equipped with nuclear ballistic missiles, specifically the R-13 SLBM. The boat was hastily built by the Soviets in response to United States' developments in nuclear submarines as part of the arms race. Before it was launched, 10 civilian workers and a sailor died due to accidents and fires. After \"K-19\" was commissioned, the boat had multiple breakdowns and accidents, several of which threatened to sink the submarine.\nOn its initial voyage on 4 July 1961, \"K-19\" suffered a complete loss of coolant to one of its two reactors. A backup system included in the design was not installed, so the captain ordered members of the engineering crew to find a solution to avoid a nuclear meltdown. Sacrificing their own lives, the engineering crew jury-rigged a secondary coolant system and kept the reactor from a meltdown. Twenty-two crew members died during the following two years. The submarine experienced several other accidents, including two fires and a collision. The series of accidents inspired crew members to nickname the submarine \"Hiroshima\".\nHistory.\nBackground.\nIn the late 1950s, the leaders of the Soviet Union were determined to catch up with the United States and began to build a nuclear submarine fleet. In practice, this meant that speed was prioritized over safety in the construction of vessels, which were then rushed through sea trials so they could be put into service. \"K-19\" suffered from poor workmanship and was accident-prone from the beginning. Many Soviet naval officers felt that the ships were not fit for combat, but fearing reprisals from above, no action was taken to prevent them from sailing. The crews aboard the first nuclear submarines of the Soviet fleet were provided with a very high quality standard of food including smoked fish, sausages, fine chocolates, and cheeses, unlike the standard fare given to the crews of other naval vessels.\nConstruction deaths.\n\"K-19\" was ordered by the Soviet Navy on 16 October 1957. Her keel was laid on 17 October 1958 at the naval yard in Severodvinsk. Several workers died building the submarine: two workers were killed when a fire broke out, and later six women gluing rubber lining to a water cistern were fatally poisoned by inhaling fumes. While missiles were being loaded, an electrician was crushed to death by a missile-tube cover, and an engineer fell between two compartments and died.\nGains unlucky reputation.\nThe boat was launched and named on 8 April 1959. Breaking with tradition, a man (Captain 3rd Rank V. V. Panov of the 5th Urgent Unit) instead of a woman was chosen to smash the ceremonial champagne bottle across the ship's stern. The bottle failed to break, instead sliding along the screws (propellers) and bouncing off the rubber-coated hull. This is traditionally viewed among sea crews as a sign that the ship is unlucky. Captain 1st Rank Nikolai Vladimirovich Zateyev was the first commander of the submarine. Vasily Arkhipov, who would later prevent the Cuban Missile Crisis from turning into nuclear war, was appointed as executive officer.\nEarly problems.\nIn January 1960, confusion among the crew during a watch change led to improper operation of the reactor and a reactor-control rod was bent. The damage required the reactor to be dismantled for repairs. The officers on duty were removed and Captain Panov was demoted.\nThe submarine's ensign was hoisted for the first time on 12 July 1960. The vessel underwent sea trials from 13 through 17 July 1960 and again from 12 August through 8 November 1960, travelling . The ship was considered completed on 12 November 1960. After surfacing from a full-power run, the crew discovered that most of the hull's rubber coating had detached, and the entire surface of the boat had to be re-coated.\nDuring a test dive to the maximum depth of , flooding was reported in the reactor compartment, and Captain Zateyev ordered the submarine to immediately surface, where the boat heeled over on her port side due to the water she had taken on. It was later determined that during construction the workers had failed to replace a gasket. In October 1960, the galley crew disposed of wood from equipment crates through the galley's waste system, clogging it. This led to flooding of the ninth compartment, which filled one third full of water. In December 1960, a loss of coolant was caused by failure of the main circuit pump. Specialists called from Severodvinsk managed to complete repairs at sea within a week.\nThe boat was commissioned on 30 April 1961. The submarine had a total of 139 men aboard, including missile men, reactor officers, torpedo men, doctors, cooks, stewards, and several observing officers who were not part of the standard crew.\nNuclear accident.\nOn 4 July 1961, under the command of Captain First Rank Nikolai Vladimirovich Zateyev, \"K-19\" was conducting exercises in the North Atlantic off the south-east coast of Greenland. At 04:15 local time the pressure in the starboard nuclear reactor's cooling system dropped to zero. The reactor department crew found a major leak in the reactor coolant system, causing the coolant pumps to fail. The boat could not contact Moscow and request assistance because a separate accident had damaged the long-range radio system. The control rods were automatically inserted by the emergency SCRAM system, but the reactor temperature rose uncontrollably. Decay heat from fission products produced during normal operation eventually heated the reactor to .\nMaking a drastic decision, Zateyev ordered the engineering section to fabricate a new coolant system by cutting off an air vent valve and welding a water-supply pipe to it. This required men to work in high radiation for extended periods. The jury-rigged cooling water system successfully reduced the temperature in the reactor.\nThe accident released radioactive steam containing fission products that were drawn into the ship's ventilation system and spread to other compartments of the ship. The entire crew was irradiated as was most of the ship and some of the ballistic missiles on board. All seven members of the engineering crew and their divisional officer died of radiation exposure within the next month. Fifteen more sailors died within the next two years.\nInstead of continuing on the mission's planned route, the captain decided to head south to meet diesel-powered submarines expected to be there. Worries about a potential crew mutiny prompted Zateyev to have all small arms thrown overboard except for five pistols distributed to his most trusted officers. A diesel submarine, , picked up \"K-19\"'s low-power distress transmissions and joined up with it.\nAmerican warships nearby had also heard the transmission and offered to help, but Zateyev, afraid of giving away Soviet military secrets to the West, refused and sailed to meet \"S-270\". He evacuated the crew and had the boat towed to its home base.\nOver the next two years, repair crews removed and replaced the damaged reactors. The repair process contaminated the nearby environment, in a zone within , and the repair crew. The Soviet Navy dumped the original radioactive compartment into the Kara Sea. \"K-19\" returned to the fleet with the nickname \"Hiroshima\".\nAccording to the government's official explanation of the disaster, the repair crews found that the catastrophe had been caused by a faulty welding incident during initial construction. They discovered that during installation of the primary cooling system piping, a welder had failed to cover exposed pipe surfaces with asbestos drop cloths (required to protect piping systems from accidental exposure to welding sparks), due to the cramped working space. A drop from a welding electrode fell on an unprotected surface, producing an invisible crack. This crack was subject to prolonged and intensive pressure (over ), compromising the pipe's integrity and finally causing it to fail.\nOthers disputed this conclusion. Retired Rear-Admiral Nikolai Mormul asserted that when the reactor was first started ashore, the construction crew had not attached a pressure gauge to the primary cooling circuit. Before anyone realized there was a problem, the cooling pipes were subjected to a pressure of 400 atmospheres, double the acceptable limit.\nOn 1 February 2006, former President of the Soviet Union Mikhail Gorbachev proposed in a letter to the Norwegian Nobel Committee that the crew of \"K-19\" be nominated for a Nobel Peace Prize for their actions on 4 July 1961.\nDeceased crew members.\nSeveral crew members received fatal doses of radiation during repairs on the reserve coolant system of Reactor #8. Eight died between one and three weeks after the accident from severe radiation sickness. A person who receives a dose of 4 to 5 Sv (about 400\u2013500 rem) over a short period has a 50% chance of dying within 30 days.\nFourteen other crew members died within two years. Many other crew members also received radiation doses exceeding permissible levels. They underwent medical treatment during the following year. Many others experienced chest pains, numbness, cancer, and kidney failure. Their treatment was devised by Professor Z. Volynskiy and included bone marrow transplantation and blood transfusion. It saved, among others, Chief Lieutenant Mikhail Krasichkov and Captain 3rd class Vladimir Yenin, who had received doses of radiation that were otherwise considered deadly. For reasons of secrecy, the official diagnosis was not \"radiation sickness\" but \"astheno-vegetative syndrome\", a mental disorder.\nCrew members decorated.\nOn 6 August 1961, 26 members of the crew were decorated for courage and valor shown during the accident.\nLater operational history.\nOn 14 December 1961, the boat was fully upgraded to the Hotel II (\"658\u043c\") variant, which included upgrading to R-21 missiles, which had twice the effective range of the earlier missiles.\nCollision.\nAt 07:13 on 15 November 1969, \"K-19\" collided with the attack submarine in the Barents Sea at a depth of . She was able to surface using an emergency main ballast tank blow. The impact completely destroyed the bow sonar systems and mangled the covers of the forward torpedo tubes. \"K-19\" was able to return to port where the boat was repaired and returned to the fleet. \"Gato\" was relatively undamaged and continued her patrol.\nFires.\nOn 24 February 1972, a fire broke out while the submarine was at a depth of , some from Newfoundland, Canada. The boat surfaced and the crew was evacuated to surface warships except for 12 men trapped in the aft torpedo room. Towing was delayed by a gale, and rescuers could not reach the aft torpedo room because of conditions in the engine room. The fire killed 28 sailors aboard \"K-19\" and two others who died after they were transferred to rescue ships. Investigators determined that the fire was caused by a hydraulic fluid leak onto a hot filter.\nThe rescue operation lasted more than 40 days and involved over 30 ships. From 15 June through 5 November 1972, \"K-19\" was repaired and put back into service.\nOn 15 November 1972, another fire broke out in compartment 6, but it was put out by the chemical fire-extinguisher system and there were no casualties.\nReclassification.\nOn 25 July 1977, \"K-19\" was reclassified in the large submarine class, and on 26 July 1979, she was reclassified as a communications submarine and given the symbol KS-19 (\u041a\u0421-19). \nOn 15 August 1982, an electrical short circuit resulted in severe burns to two sailors; one, V. A. Kravchuk, died five days later.\nOn 28 November 1985, the ship was upgraded to the 658s (658\u0441) variant.\nDecommissioning and fate.\nOn 19 April 1990 the submarine was decommissioned, and was transferred in 1994 to the naval repair yard at Polyarny. In March 2002, she was towed to the Nerpa Shipyard, Snezhnogorsk, Murmansk, to be scrapped.\nIn 2006, a section of \"K-19\" was purchased by Vladimir Romanov, who once served on the submarine as a conscript, with the intention of \"Turning it into a Moscow-based meeting place to build links between submarine veterans from Russia and other countries.\" In 2023, \"The Athletic\" reported that Romanov had refurbished the submarine to serve as his place of residence in Nikul'skaya, described as a village in northwestern Russia.\nTheatre and film.\nIn 1969 writer Vasily Aksyonov wrote a play about the nuclear incident.\nThe movie \"\" (2002), starring Harrison Ford and Liam Neeson, is based on the story of the \"K-19\"'s first disaster. The original crew of the submarine were allowed to read the script and had complaints, which led to several changes in the script. The production company attempted in March 2002 to secure access to the boat as a set for its production, but the Russian Navy declined. The nickname \"The Widowmaker\" in the film's title is fictional; the submarine did not gain a nickname until the nuclear accident on 4 July 1961, when she was called \"Hiroshima\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29127", "revid": "49924652", "url": "https://en.wikipedia.org/wiki?curid=29127", "title": "Seleucid dynasty", "text": "Royal family of the Seleucid Empire\nThe Seleucid dynasty or the Seleucidae (; , \"\", \"descendants of Seleucus\") was a Macedonian Greek royal family, which ruled the Seleucid Empire based in West Asia during the Hellenistic period. It was founded by Seleucus I Nicator, a general and successor of Alexander the Great, after the division of the Macedonian Empire as a result of the Wars of the Successors (\"Diadochi\"). \nThrough its history, the Seleucid dominion included large parts of the Near East, as well as of the Asian territory of the earlier Achaemenid Persian Empire. A major center of Hellenistic culture, it attracted a large number of immigrants from Greece who, encouraged by the Seleucids, formed a dominant political elite under the ruling dynasty. After the death of Seleucus I, his successors maintained the empire's strength establishing it as a Greek power in West Asia; the empire reached its height under emperor Antiochus III. From the mid-second century BC, after its defeat at the hands of the resurgent Parthian Empire, the polity entered a state of instability with slow territorial losses and internecine civil wars. The Seleucids, now reduced to a rump state occupying a small part of Syria succumbed to the Rome's annexation of their territory in 64 BC under Pompey the Great.\nHistory.\nBackground.\nSeleucus (c. 358 \u2013 281 BC) served as an officer of Alexander the Great, commanding the elite infantry corps in the Macedonian army: the \"Shield-bearers\" (, \"Hypaspistai\"), later known as the \"Silvershields\" (, \"Argyraspides\"). After the death of Alexander in 323 BC, the Partition of Triparadisus assigned Seleucus as satrap of Babylon in 321 BC. Antigonus, the satrap of much of Asia Minor, forced Seleucus to flee from Babylon, but, supported by Ptolemy, the Satrap of Egypt, Seleucus returned in 312 BC. Seleucus' later conquests included Persia and Media. He agreed to a peace treaty with the Indian King Chandragupta Maurya (reigned 324-297 BC). Seleucus defeated Antigonus in the Battle of Ipsus in 301 BC and Lysimachus (King of Thrace, Macedon and Asia Minor) in the battle of Corupedium (near Sardis) in 281 BC. Ptolemy Ceraunus assassinated Seleucus later in the same year. Seleucus' eldest son Antiochus I succeeded him as ruler of the Seleucid territories in 281 BC."}
{"id": "29128", "revid": "51048735", "url": "https://en.wikipedia.org/wiki?curid=29128", "title": "Super Bowl I", "text": "1967 National Football League championship game\nThe first AFL\u2013NFL World Championship Game (known retroactively as Super BowlI and referred to in contemporaneous reports, including the game's radio broadcast, as the Super Bowl) was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles, California. The National Football League (NFL) champion Green Bay Packers defeated the American Football League (AFL) champion Kansas City Chiefs by the score of 35\u201310.\nComing into the game, billed by some as the \"supergame\", considerable animosity existed between the AFL and NFL, thus the teams representing the two rival leagues (the Chiefs and Packers, respectively) felt additional pressure to win. The Chiefs posted an 11\u20132\u20131 record during the regular season, and defeated the Buffalo Bills 31\u20137 in the AFL Championship Game. The Packers finished the regular season at 12\u20132 and defeated the Dallas Cowboys 34\u201327 in the NFL Championship Game. Many sportswriters and fans believed any team in the older NFL was vastly superior to any club in the upstart AFL, and so expected the Packers would blow out the Chiefs.\nThe first half of Super Bowl I was competitive, as the Chiefs outgained the Packers in total yards, 181\u2013164, and kept pace with the Packers by posting a 14\u201310 score at halftime. Early in the third quarter, Packers safety Willie Wood intercepted a pass and returned it 50 yards to the 5-yard line. The turnover sparked the Packers to score 21 unanswered points in the second half. Packers quarterback Bart Starr, who completed 16 of 23 passes for 250 yards and two touchdowns, with one interception, was named MVP.\nAs NBC and CBS had held the rights to nationally televise AFL and NFL games, respectively, it was decided that both networks were allowed to televise the game. The game remains the only Super Bowl to have been simulcast in the United States by two of the then-\"Big Three\" broadcast companies. Several recent Super Bowls have been simultaneously broadcast on network television as well as cable and streaming platforms.\nBackground.\nOrigins.\nWhen the NFL began its 41st season in 1960, it had a new and unwanted rival: the American Football League. The NFL had successfully fended off several other rival leagues in the past, and so the older league initially ignored the new upstart and its eight teams, figuring it would be made up of nothing but NFL rejects, and that fans were unlikely to prefer it to the NFL. But unlike the NFL's prior rivals, the AFL survived and prospered, in part by signing \"NFL rejects\" who turned out to be highly talented players the older league had badly misjudged. Soon the NFL and AFL found themselves locked in a massive bidding war for the top free agents and prospects coming out of college. Originally, there was a tacit agreement between the two not to raid each other by signing players who were already under contract with a team from an opposing league. This policy broke down in early 1966 when the NFL's New York Giants signed Pete Gogolak, a placekicker who was under contract with the AFL's Buffalo Bills. The AFL owners considered this an \"act of war\" and immediately struck back, signing several contracted NFL players, including eight of their top quarterbacks.\nEventually, the NFL had enough and started negotiations with the AFL in an attempt to resolve the issue. As a result of the negotiations, the leagues signed a merger agreement on June 9, 1966. Among the details, both leagues agreed to share a common draft to end the bidding war for the top college players, as well as merge into a single league after the 1969 season. In addition, an \"AFL\u2013NFL World Championship Game\" was established, in which the AFL and NFL champions would play against each other in a game at the end of the season to determine which league had the best team.\nLos Angeles wasn't awarded the game until December 1, less than seven weeks before the kickoff; likewise, the date of the game was not set until December 13. Since the AFL Championship Game originally was scheduled for Monday, December 26, and the NFL Championship Game for Sunday, January1, the \"new\" championship game was suggested to be played Sunday, January 8. An unprecedented TV doubleheader was held on January 1, with the AFL Championship Game telecast from Buffalo on NBC and the NFL Championship Game telecast from Dallas on CBS three hours later.\nComing into this \"first\" game, considerable animosity still existed between the two rival leagues, with both of them putting pressure on their respective champions to trounce the other and prove each league's dominance in professional football. Still, many sportswriters and fans believed the game was a mismatch, and any team from the long-established NFL was far superior to the best team from the upstart AFL.\nThe players' shares were $15,000 each for the winning team and $7,500 each for the losing team. This was in addition to the league championship money earned two weeks earlier: the Packers' shares were $8,600 each and the Chiefs' were $5,308 each.\nKansas City Chiefs.\nThe Chiefs entered the game after an 11\u20132\u20131 regular season and a decisive 31\u20137 road win over the defending AFL champion Buffalo Bills in the AFL championship game on New Year's Day.\nThe Chiefs' high-powered offense led the AFL in points scored (448) and total rushing yards (2,274). Their trio of running backs, Mike Garrett (801 yards), Bert Coan (521 yards), and Curtis McClinton (540 yards) all ranked among the top-ten rushers in the AFL. Quarterback Len Dawson was the top-rated passer in the AFL, completing 159 of 284 (56%) of his passes for 2,527 yards and 26 touchdowns. Wide receiver Otis Taylor provided the team with a great deep threat by recording 58 receptions for 1,297 yards and eight touchdowns. Receiver Chris Burford added 58 receptions for 758 yards and eight touchdowns, and tight end Fred Arbanas, who had 22 catches for 305 yards and four touchdowns, was one of six Chiefs offensive players who were named to the All-AFL team. The Chiefs' offensive line was led by tackle Jim Tyrer, who had been selected to the AFL Pro Bowl for the 5th time in his career.\nThe Chiefs also had a strong defense, with All-AFL players Jerry Mays and Buck Buchanan anchoring their line. Linebacker Bobby Bell, who was also named to the All-AFL team, was great at run stopping and pass coverage. The strongest part of their defense, though, was their secondary, led by All-AFL safeties Johnny Robinson and Bobby Hunt, who each recorded 10 interceptions, and Fred Williamson, who recorded four. Their head coach was Hank Stram.\nGreen Bay Packers.\nThe Packers were an NFL dynasty, turning around what had been a losing team just eight years earlier. The team had posted an NFL-worst 1\u201310\u20131 record in 1958 before head coach Vince Lombardi was hired in January 1959. \"Their offense was like a conga dance\", one sportswriter quipped. \"1, 2, 3and kick.\"\nLombardi was determined to build a winning team. During the preseason, he signed Fred \"Fuzzy\" Thurston, who had been cut from three other teams, but ended up becoming an All-Pro left guard for the Packers. Lombardi also made a big trade with the Cleveland Browns that brought three players to the team who would become cornerstones of the defense: linemen Henry Jordan, Willie Davis, and Bill Quinlan.\nLombardi's hard work paid off, and the Packers improved to a 7\u20135 regular-season record in 1959. They surprised the league during the following year by making it to the 1960 NFL Championship Game. Although the Packers lost, 17\u201313, to the Philadelphia Eagles, they had sent a clear message that they were no longer losers. The Packers went on to win NFL Championships in 1961, 1962, 1965, and 1966.\nPackers veteran quarterback Bart Starr was the top-rated quarterback in the NFL for 1966, and won the NFL Most Valuable Player Award, completing 156 of 251 (62.2%) passes for 2,257 yards (9.0 per attempt), 14 touchdowns, and only three interceptions. His top targets were wide receivers Boyd Dowler and Carroll Dale, who combined for 63 receptions for 1,336 yards. Fullback Jim Taylor was the team's top rusher with 705 yards, adding four touchdowns, and caught 41 passes for 331 yards and two touchdowns. (Before the season, Taylor had informed the team that instead of returning to the Packers in 1967, he would play out his option and sign with the expansion New Orleans Saints. Lombardi, infuriated at what he considered to be Taylor's disloyalty, refused to speak to Taylor the entire season.) The team's starting halfback, Paul Hornung, was injured early in the season and replaced by running back Elijah Pitts, who gained 857 all-purpose yards. The Packers' offensive line was also a big reason for the team's success, led by All-Pro guards Jerry Kramer, and Fuzzy Thurston, and tackle Forrest Gregg.\nThe Packers also had an excellent defense that displayed their talent in the NFL championship game, stopping the Dallas Cowboys on four consecutive plays starting from the Packers' 2-yard line on the final drive to win the game. Lionel Aldridge had replaced Quinlan, but Jordan and Davis still anchored the defensive line; linebacker Ray Nitschke excelled at run stopping and pass coverage, while the secondary was led by Herb Adderley and Willie Wood. Wood was another example of how Lombardi found talent nobody else could see. Wood had been a quarterback in college and was not drafted by an NFL team. When Wood joined the Packers in 1960, he was converted to a free safety and went on to make the All-Pro team nine times in his 12-year career.\nPregame news and notes.\nMany people considered it fitting that the Chiefs and the Packers would be the teams to play in the first-ever AFL\u2013NFL World Championship Game. Chiefs owner Lamar Hunt had founded the AFL, while the Packers were widely considered one of the best teams in NFL history (even if they could not claim to be founding members of their league, as the Packers joined the NFL in 1921, a year after the league's formation). Lombardi was under intense pressure from the entire NFL to make sure the Packers not only won the game but preferably won big to demonstrate the superiority of the NFL. CBS announcer Frank Gifford, who interviewed Lombardi before the game, said Lombardi was so nervous, \"he held onto my arm and he was shaking like a leaf. It was incredible.\" The Chiefs saw this game as an opportunity to show they were good enough to play against any NFL team. One player who was looking forward to competing in this game was Len Dawson, who had spent three years as a backup in the NFL before joining the Chiefs. However, the Chiefs were also nervous. Linebacker E. J. Holub said, \"the Chiefs were scared to death. Guys in the tunnel were throwing up.\"\nIn the week before the game, Chiefs cornerback Fred \"The Hammer\" Williamson garnered considerable publicity by boasting he would use his \"hammer\" \u2013 forearm blows to the head \u2013 to destroy the Packers' receivers, stating, \"Two hammers to (Boyd) Dowler, one to (Carroll) Dale should be enough.\"\nThe Packers practiced at UC Santa Barbara, and the Chiefs at Veterans Field in Long Beach.\nThe temperature was mild with clear skies. \nThe two teams played with their respective footballs from each league; the Chiefs' offense used the AFL ball, the slightly narrower and longer J5V by Spalding, and the Packers played with the NFL ball, \"The Duke\" by Wilson.\nThe AFL's two-point conversion rule was not in force; the NFL added the two-point conversion in 1994 and it was first used in the Super Bowl (XXIX) that season, in January 1995.\nThis was the only Super Bowl where the numeric yard markers were five yards apart, rather than ten as is customary today. In\u00a01972, marking yard lines ending in\u00a0\"5\" was disallowed in the NFL in order to standardize field markings. It was also the last professional gridiron game ever played with double-support goalposts. The\u00a0\"slingshot\" goalpost, with a single support, had made its debut a few weeks before Super Bowl I in the 1966 CFL playoffs. It became standard across all three professional leagues then operating in 1967.\nTickets for this game were priced at twelve, ten, and six dollars, which was equivalent to $109, $90, and $55 in 2023 when adjusted for inflation.\nBroadcasting.\nAt the time, NBC held the rights to nationally televise AFL games while CBS had the rights to broadcast NFL games. Both networks were allowed to cover the game, each using its own announcers. Ray Scott (doing play-by-play for the first half), Jack Whitaker (doing play-by-play for the second half) and Frank Gifford provided commentary on CBS, while Curt Gowdy and Paul Christman were on NBC. This is the only Super Bowl that Curt Gowdy called for NBC where the NFL or NFC team won (the AFL/AFC teams won the others, even though the Baltimore Colts and Pittsburgh Steelers were part of the old NFL before moving to the AFC following the AFL\u2013NFL merger).\nHowever, during the week preceding the game, tensions flared between the staff of the two networks (longtime arch-rivals in American broadcasting), who each wanted to win the rating war, to the point where a fence was built between the CBS and NBC trucks. In addition, Rozelle decreed that NBC would not be able to use its cameramen and technical personnel, instead forcing it to use the feed provided by CBS, since the Coliseum was home to the NFL's Rams.\nThis game remains the only Super Bowl to have been broadcast in the United States by two of the \"Big Three\" broadcast companies. It was the only NFL game to be carried nationally on more than one broadcaster until the same two networks (as well as NFL Network and various local ABC and MyNetworkTV affiliates) carried a game between the New England Patriots and the New York Giants on December 29, 2007, and it was the only Super Bowl to simulcast on multiple American networks until Super Bowl LVIII was broadcast on CBS and its sister network Nickelodeon in February 2024.\nSuper BowlI was the only Super Bowl that was not a sellout, despite the television blackout in Los Angeles (at the time, the local blackout was required even at a neutral site and even if the stadium did sell out), shutting out the vast Los Angeles market and network-owned stations KNXT (Channel 2, CBS; now KCBS-TV) and KNBC (Channel 4, NBC). Of the 94,000-seat capacity in the Coliseum, 33,000 went unsold. Days before the game, local newspapers printed editorials about what they viewed as an exorbitant ticket price of ), and wrote stories about how viewers could pull in the game from stations in surrounding markets such as Bakersfield, Santa Barbara and San Diego.\nRatings.\nCBS received a 22.6 rating and a market share of 43 for its broadcast, which was seen by 26.75 million people. NBC received an 18.5 rating and a market share of 36 for its broadcast, which was seen by 24.43 million people. Combined, the game received a market share of 79 and reached 51.18 million viewers.\nLost recording.\nAll known broadcast tapes of the game in its entirety were subsequently wiped by both NBC and CBS to save costs, a common practice in the television industry at the time, as videotapes were very expensive (one half-hour tape cost around $300 at the time, equivalent to $ in 2024 dollars). Additionally, it was not foreseen how big the game was going to become. This has prevented studies comparing each network's respective telecast.\nFor many years, only two small samples of the telecasts were known to have survived, showing Max McGee's opening touchdown and Jim Taylor's touchdown run. Both were shown in 1991 on HBO's \"Play by Play: A History of Sports Television\" and on the Super Bowl XXV pregame show. In January 2011, a partial recording of the CBS telecast was reported to have been found in a Pennsylvania attic and restored by the Paley Center for Media in New York. The two-inch color videotape is the most complete version of the broadcast yet discovered, missing only the halftime show and most of the third quarter. The NFL owns the broadcast copyright and has blocked its sale or distribution. After remaining anonymous and communicating with the media only through his lawyer since the recording's discovery, the owner of the recording, Troy Haupt, came forward to \"The New York Times\" in 2016 to tell his side of the story. The Paley Center has restored and digitized the footage and showed the recording to the public for the first time on February 10, 2024, as part of an exhibit, being staged in partnership with the NFL and the Pro Football Hall of Fame, on the history of the Super Bowl called \"Beyond the Big Game\".\nNFL Films had a camera crew present, and retains a substantial amount of film footage in its archives, some of which have been released in its film productions. One such presentation was the \"NFL's Greatest Games\" episode about this Super Bowl, entitled \"The Spectacle of a Sport\" (also the title of the Super BowlI highlight film).\nOn January 11, 2016, the NFL announced that \"in an exhaustive process that took months to complete, NFL Films searched its enormous archives of footage and were able to locate all 145 plays from Super BowlI from more than a couple of dozen disparate sources. Once all the plays were located, NFL Films was able to put the plays in order and stitch them together while fully restoring, re-mastering, and color-correcting the footage. Finally, audio from the NBC Sports radio broadcast featuring announcers Jim Simpson and George Ratterman was layered on top of the footage to complete the broadcast. The final result represents the only known video footage of the entire action from Super BowlI.\" It then announced that NFL Network would broadcast the newly pieced together footage in its entirety on January 15, 2016\u2014the 49th anniversary of the contest. This footage was nearly all on film with the exception of several player introductions and a post-game locker room chat between Pat Summerall and Pete Rozelle.\nOn June 25, 2025, missing episode hunter Ray Langstone spotted a 29-minute Avco Cartrivision release of highlights on eBay and announced this on the Missing Episodes Forum.\nCeremonies and entertainment.\nThe Los Angeles Ramettes, majorettes who had performed at all Rams home games, entertained during pregame festivities and after each quarter. Also during the pregame, the University of Arizona marching band created a physical outline of the continental United States at the center of the field, with the famed Anaheim High School drill team placing banners of each NFL and AFL team at each team's geographical location.\nThe postgame trophy presentation ceremony was handled by CBS' Pat Summerall and NBC's George Ratterman. Summerall and Ratterman were forced to share a single microphone.\nHalftime show.\nThe halftime show was produced by Tommy Walker, and featured trumpeter Al Hirt, the marching bands from the University of Arizona and Grambling College, the Ana-Hi-Steppers (more information below), 300 pigeons, 10,000 balloons and a flying demonstration by the hydrogen-peroxide-propelled Bell Rocket Air Men. In addition, the halftime featured a local high school drill team, the Ana-Hi-Steppers from Anaheim High School. The team joined the two university marching bands to form an outline of a United States map. Their transportation to and from the game was by school bus. This team was chosen due to their connection to Tommy Walker, whose children attended Anaheim High School. He had seen the Ana-Hi-Steppers perform and chose them over nationally famous drill teams since he only had three weeks to cast and produce the show.\nDuring the halftime show the Chief's QB, Len Dawson, was photographed by a Life Magazine photographer, while he was resting in a chair on the sidelines, calming inhaling on a cigarette, with a bottle of Fresca between his feet.\nGame summary.\nBalls from both leagues were used \u2013 when the Chiefs were on offense, the official AFL football (Spalding J5V) was used, and when the Packers were on offense, the official NFL ball (Wilson's \"The Duke\") was used. Even the officiating crew was a combination of AFL and NFL referees, with the NFL's Norm Schachter as the head referee.\nFirst quarter.\nAfter the teams traded punts on their first possessions, the Packers drove 80 yards in six plays. The drive was highlighted by quarterback Bart Starr's passes to tight end Marv Fleming for 11 yards, to running back Elijah Pitts for 22 yards on a scramble, and to wide receiver Carroll Dale for 12 yards. The drive ended with Starr's 37-yard touchdown pass to wide receiver Max McGee, who had replaced re-injured starter Boyd Dowler earlier in the drive, giving Green Bay an early 7\u20130 lead. (Dowler had injured his shoulder two weeks prior after scoring a third-quarter touchdown; Cowboys safety Mike Gaechter had upended him several steps after scoring and he landed awkwardly.) McGee slipped past Chiefs cornerback Willie Mitchell, made a one-handed catch at the 23-yard line, and then went the distance for the touchdown. (McGee had also caught a touchdown pass after replacing an injured Dowler in the NFL championship game). On their ensuing drive, Kansas City moved the ball to Green Bay's 33-yard line, during which quarterback Len Dawson completed an 18-yard pass to tight end Fred Arbanas and running back Mike Garrett rushed for 9 yards, but kicker Mike Mercer missed a 40-yard field goal attempt wide left. The Packers picked up 3 yards on the next play to end the first quarter.\nSecond quarter.\nKansas City forced a three-and-out to start the second quarter, then got on the board with a six-play, 66-yard scoring drive, featuring passes by Dawson to Garrett for 15 yards, and to wide receiver Otis Taylor for 31 yards, which set up 1st-and-goal for the Chiefs at the Packers' 7-yard line. Dawson then threw a 7-yard touchdown pass to fullback Curtis McClinton to tie the game, 7\u20137. But the Packers responded with a 73-yard scoring drive on their next possession, which was again highlighted by Starr's key passes. On the third play of the drive, Starr appeared to complete a 64-yard touchdown pass to Dale, but this was nullified by a false start penalty against Green Bay. As the drive continued, however, Starr converted four straight third downs; he hit McGee for 10 yards on 3rd-and-6, then Dale for 15 on 3rd-and-10, then Fleming for 11 on 3rd-and-5, and then Pitts for 10 on 3rd-and-7 to set up fullback Jim Taylor's 14-yard touchdown run with the team's famed Packers sweep play. Taylor's rushing touchdown was the first in Super Bowl history.\nOn the first play of the Chiefs' next drive, defensive end Lionel Aldridge and defensive tackle Henry Jordan shared a sack on Dawson for an 8-yard loss, but he followed it up with four consecutive completions for 58 yards, including a 27-yard pass to wide receiver Chris Burford. This set up Mercer's 31-yard field goal to cut the Chiefs' deficit to 14\u201310 at the end of the half.\nAt halftime, the Chiefs appeared to have a chance to win. Many people watching the game were surprised at how close the score was and how well the AFL's champions were playing. Kansas City outgained Green Bay in total yards, 181\u2013164, and had 11 first downs compared to the Packers' nine. The Chiefs were exuberant at halftime. Hank Stram said later, \"I honestly thought we would come back and win it.\" The Packers were disappointed with the quality of their play in the first half. \"The coach was \"concerned\"\", said defensive end Willie Davis later. Lombardi told them the game plan was sound, but that they had to tweak some things and execute better.\nThird quarter.\nOn their first drive of the second half, the Chiefs advanced to their 49-yard line with a chance to take their first lead of the game. But on a third-down pass play, a heavy blitz by linebackers Dave Robinson and Lee Roy Caffey collapsed the Chief's pocket. Robinson, Jordan, and Aldridge converged on Dawson, who threw weakly toward Arbanas. The wobbly pass was intercepted by safety Willie Wood, who raced 50 yards to Kansas City's 5-yard line before being dragged down from behind by Garrett. This was \"the biggest play of the game,\" wrote Starr later. The Packers capitalized on the turnover on the next play with a 5-yard touchdown run by Pitts to increase their lead to 21\u201310. Stram agreed that it was the critical point of the game. The Packers' defense then held the Chief scoreless for the rest of the game, allowing them to cross midfield only once, and for just one play. The Chiefs were forced to deviate from their game plan, and that hurt them. The Kansas City offense totaled only 12 yards in the third quarter, and Dawson was held to five of 12 second-half pass completions for 59 yards.\nMeanwhile, Green Bay forced Kansas City to punt from their two-yard line after sacking Dawson twice and got the ball back with good field position on their own 44-yard line (despite a clipping penalty on the punt return). McGee subsequently caught three passes for 40 yards on a 56-yard drive. Taylor ran for one first down, Starr hit McGee for 16 yards on 3rd-and-11, and a third-down sweep with Taylor carrying gained 8 yards and a first down at the Kansas City 13. The drive ended with Starr's 13-yard touchdown pass to McGee on a post pattern, giving Green Bay a 28\u201310 lead.\nFourth quarter.\nAfter two punts by Kansas City and an interception at their own 11-yard line by Chiefs cornerback Willie Mitchell, midway through the fourth quarter, Starr completed a 25-yard pass to Dale and a 37-yard strike to McGee, moving the ball to the Chiefs' 18-yard line. Six plays later, Pitts scored his second touchdown of the game on a 1-yard run to close out the scoring, giving the Packers the 35\u201310 win. Also, in the fourth quarter, Chiefs defensive back Fred Williamson, who had boasted about his \"hammer\" before the game, was knocked out when his head collided with Packers running back Donny Anderson's knee, and then suffered a broken arm when Chiefs linebacker Sherrill Headrick fell on him. Williamson had three tackles for the game.\nPackers halfback Paul Hornung was the only Packer to not see any action. Lombardi had asked him in the fourth quarter if he wanted to go in, but Hornung declined, not wanting to aggravate a pinched nerve in his neck. McGee, who caught only four passes for 91 yards and one touchdown during the season, finished Super BowlI with seven receptions for 138 yards and two touchdowns. After the game was over, a reporter asked Vince Lombardi if he thought Kansas City was a good team. Lombardi responded that though the Chiefs were an excellent, well-coached club, he thought several NFL teams such as Dallas were better.\nBox score.\nSuper Bowl I: Green Bay Packers 35, Kansas City Chiefs 10\n\"at Los Angeles Memorial Coliseum, Los Angeles, California\nFinal statistics.\nSources: http://, https://, https://\nStatistical comparison.\nNote: According to NBC Radio announcer Jim Simpson's report at halftime of the game, Kansas City led 11\u20139 in first downs at halftime, 181\u2013164 in total yards, and 142\u2013113 in passing yards (Green Bay led 51\u201339 in rushing yards). Bart Starr completed eight of 13 with no interceptions, while Len Dawson was 11 of 15 with no interceptions. Green Bay led 14\u201310 at halftime. Green Bay had the ball five times, although only for a minute or so on the last possession; they punted on their first possession, scored a touchdown on their second, punted on their third, scored a touchdown on their fourth, and had the ball when the half ended on their fifth. Kansas City had the ball four times \u2013 punting on their first possession, driving to a missed field goal on their second possession, scoring a touchdown on their third, and kicking a field goal on their fourth.\nThis means, in the second half, Green Bay led 12\u20136 in first downs, 197\u201358 in total yards, 115\u201325 in passing yards, and 82\u201333 in rushing yards (the Packers won the second half, 21\u20130). Starr and his late-game replacement, Zeke Bratkowski, were eight for 11 with one interception; Dawson and his late-game replacement, Pete Beathard, were just six for 17, also with one interception. Each team had the ball seven times in the second half, although Green Bay's first possession was just one play and their seventh possession was abbreviated because the game ended. Green Bay scored a touchdown on their first (one play) possession, punted on their second, scored a touchdown on their third, was intercepted at Kansas City's 15-yard line on their fourth (just Starr's fourth interception of the year), scored a touchdown on their fifth, punted on their sixth, and had the ball when the game ended on their seventh possession. Kansas City was intercepted on their first possession \u2013 Wood's return to the five set up Pitts' touchdown which made the score 21\u201310 \u2013 and then punted on each of their next six possessions.\nIndividual statistics.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n1Completions/attempts\n2Carries\n3Long gain\n4Receptions\n5Times targeted\nRecords established.\nBecause this was the first Super Bowl, a new record was set in every category. All categories are listed in the 2016 NFL Fact book. The following records were set in Super BowlI, according to the official NFL.com boxscore and the Pro-Football-Reference.com game summary. Some records have to meet NFL minimum number of attempts to be recognized. The minimums are shown (in parentheses).\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nTurnovers are defined as the number of times losing the ball on interceptions and fumbles.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nStarting lineups.\nSource:\n&lt;mark style=\"color:black;background:#FFCC00\"&gt;Hall of Fame \u2021&lt;/mark&gt;\nOfficials.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nSource:\nNote: A six-official system was used by the NFL from 1965 through the 1977 season.\nSince officials from the NFL and AFL wore different uniform designs, a \"neutral\" uniform was designed for this game. These uniforms had the familiar black and white stripes, but the sleeves were all black with the official's uniform number. This design was also worn in Super Bowl II, but was discontinued after that game when AFL officials began wearing uniforms identical to those of the NFL during the 1968 season, in anticipation of the AFL\u2013NFL merger in 1970.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29129", "revid": "36941121", "url": "https://en.wikipedia.org/wiki?curid=29129", "title": "Super Bowl II", "text": "1968 Edition of the Super Bowl\nThe second AFL\u2013NFL World Championship Game (known retroactively as Super Bowl II) was an American football game played on January 14, 1968, at the Orange Bowl in Miami, Florida. The National Football League (NFL)'s defending champion Green Bay Packers defeated American Football League (AFL) champion Oakland Raiders by the score of 33\u201314. This game and the following year's are the only two Super Bowls played in the same stadium in consecutive seasons.\nComing into the game, much like during the first Super Bowl, many sports writers and fans believed that any team in the NFL was vastly superior to any club in the AFL. The Packers, the defending champions, posted a 9\u20134\u20131 record during the 1967 NFL season before defeating the Los Angeles Rams 28\u20137 in the first round of the playoffs, then outlasted the Dallas Cowboys 21\u201317 in the frigid NFL Championship Game (popularly known as the \"Ice Bowl\"). The Raiders finished the regular season at 13\u20131, then defeated the Houston Oilers 40\u20137 in the AFL Championship Game.\nAs expected, the Packers dominated the Raiders throughout the majority of Super Bowl II. The Raiders could only score two touchdown passes from quarterback Daryle Lamonica. Meanwhile, Packers kicker Don Chandler made four field goals, including three in the first half, while cornerback Herb Adderley had a 60-yard interception return for a touchdown that put the game away. Packers quarterback Bart Starr was named the MVP for the second straight time, becoming the first back-to-back Super Bowl MVP for his 13 of 24 passes for 202 yards and one touchdown.\nThe Packers won their third consecutive World Championship, the second such occasion in NFL history (the 1929\u201331 Green Bay Packers did it first). The 1965\u201367 Packers became the first and only team to win three consecutive championship games, as there were no NFL playoff games from 1920 to 1932. No NFL team has accomplished this feat since.\nBackground.\nHost selection process.\nThe NFL awarded Super Bowl II to Miami on May 25, 1967, at the owners meetings in New York City. It\u00a0marked the first of eleven Super Bowls in the Miami area (as of 2022), and the first of two consecutive (II and III). A total of five cities were considered to host the second edition: Miami, Los Angeles (Coliseum), Houston (Astrodome), Dallas (Cotton Bowl), and New Orleans (Tulane Stadium). After lackluster attendance for Super Bowl I at the Coliseum, Los Angeles was eliminated by the owners. The Miami Orange Bowl was selected for the game, based on weather, hotel accommodations, capacity, and the stadium's previous experience in hosting the Playoff Bowl. The local Orange Bowl committee had even once (unsuccessfully) lobbied to host the NFL Championship Game, which was not normally a neutral field contest. Furthermore, NFL Commissioner Pete Rozelle opined that it was \"helpful to move the game around a little\", and not play it in the same city every year. Playing the game in an AFL town also established a precedent for maintaining competitive balance between the two leagues. The city's contingent, led by mayor Robert King High, Joe Robbie, and others, would have just under eight months to prepare for the event.\nGreen Bay Packers.\nThe Packers advanced to their second straight AFL\u2013NFL World Championship Game, but had a much more difficult time than in the previous season. Both of their starting running backs from the previous year, future Pro Football Hall of Famers Paul Hornung and Jim Taylor, had left the team. Their replacements, Elijah Pitts and Jim Grabowski, both went down with season-ending injuries, forcing Green Bay coach Vince Lombardi to use second-year reserve running back Donny Anderson and rookie Travis Williams. Fullbacks Chuck Mercein and Ben Wilson, who were signed as free agents after being discarded by many other teams, were also used to help compensate for the loss of Hornung and Taylor. Meanwhile, the team's 33-year-old veteran quarterback Bart Starr had missed 4 games during the season with injuries, and finished the season with nearly twice as many interceptions (17) as touchdown passes (9).\nThe team's deep threat was provided by veteran receivers Carroll Dale, who recorded 35 receptions for 738 yards (a 21.1 average), and 5 touchdowns; and Pro Bowler Boyd Dowler, who had 54 catches for 846 yards and 4 touchdowns. The Packers still had the superb blocking of guard Jerry Kramer, Fred Thurston and Forrest Gregg. Grabowski was the team's leading rusher with 466 yards, while Wilson had 453. Anderson had 733 yards from scrimmage and 9 total touchdowns, while also gaining another 324 yards returning kicks. On special teams, Williams returned 18 kickoffs for 749 yards and an NFL record 4 touchdowns, giving him a whopping 41.1 yards per return average. The team ranked just 9th out of 16 NFL teams in scoring with 332 points.\nThe Packers defense, however, allowed only 209 points, the 3rd best in the NFL. Even this figure was misleading, since Green Bay had yielded only 131 points in the first 11 games (when they clinched their division), the lowest total in professional football. Three members of Green Bay's secondary, the strongest aspect of their defense, were named to the Pro Bowl: Willie Wood, Herb Adderley, and Bob Jeter. The Packers also had a superb defensive line led by Henry Jordan and Willie Davis. Behind them, the Packers linebacking corps was led by Ray Nitschke.\nThe Packers won the NFL's Central Division with a 9\u20134\u20131 regular season record, clinching the division in the 11th week of the season. During the last three weeks, the Packers gave up an uncharacteristic total of 78 points, after having yielded only about a dozen points per game in their first 11 contests. In the playoffs, Green Bay returned to its dominant form, blowing away their first playoff opponent, the Los Angeles Rams, in the Western Conference Championship Game, 28\u20137. The next week, Green Bay then came from behind to defeat the Dallas Cowboys in the NFL championship game for the second year in a row, in one of the most famous games in NFL lore: The Ice Bowl.\nOakland Raiders.\nThe Raiders, led by head coach John Rauch, had stormed to the top of the AFL with a 13\u20131 regular season record, the best record in AFL history (their only defeat was an October 7 loss to the New York Jets, 27\u201314), and went on to crush the Houston Oilers, 40\u20137, in the AFL Championship game. They had led all AFL and NFL teams in scoring with 468 points. Starting quarterback Daryle Lamonica had thrown for 3,228 yards and an AFL-best 30 touchdown passes.\nThe offensive line was anchored by center Jim Otto and rookie guard Gene Upshaw, along with AFL All-Stars Harry Schuh and Wayne Hawkins. Wide receiver Fred Biletnikoff led the team with 40 receptions for 876 yards, an average of 21.3 yards per catch. On the other side of the field, tight end Billy Cannon caught 32 passes for 629 yards and scored 10 touchdowns. In the backfield, the Raiders had three running backs, Clem Daniels, Hewritt Dixon, and Pete Banaszak, who carried the ball equally and combined for 1,510 yards and 10 touchdowns. On special teams, defensive back Rodger Bird led the AFL with 612 punt return yards and added another 148 yards returning kickoffs.\nThe main strength of the Raiders was their defense, nicknamed \"The 11 Angry Men\". The defensive line was anchored by AFL All-Stars Tom Keating and Ben Davidson, a former Packer who played on Green Bay's 1961 championship team. Davidson was an extremely effective pass rusher who had demonstrated his aggressiveness in a regular season game against the New York Jets by breaking the jaw of Jets quarterback Joe Namath while sacking him. Behind them, All AFL linebacker Dan Conners excelled at blitzing and pass coverage, recording 3 interceptions. The Raiders also had two All AFL defensive backs: Willie Brown, who led the team with 7 interceptions, and Kent McCloughan, who had 2 interceptions. Safety Warren Powers recorded 6 interceptions, returning them for 154 yards and 2 touchdowns.\nSuper Bowl pregame news and notes.\nDespite Oakland's accomplishments, and expert consensus that this was the weakest of all the Packer NFL championship teams, Green Bay was a 14-point favorite to win the Super Bowl. Like the previous year, most fans and sports writers believed that the top NFL teams were superior to the best AFL teams.\nThus, most of the drama and discussions surrounding the game focused not on which team would win, but on the rumors that Lombardi might retire from coaching after the game. The game also proved to be the final one for Packers wide receiver Max McGee, one of the heroes of Super Bowl I, and place kicker Don Chandler.\nThis was the first Super Bowl to use the \"tuning fork\" or \"slingshot\" goalposts (with one supporting post instead of two) invented by Jim Trimble and Joel Rottman; they had made their debut at the start of the season for both the AFL and NFL, and first appeared at the pro level in Canada.\nBroadcasting.\nThe game was televised in the United States by CBS. This was the first of seventeen Super Bowls in which the game was rotated annually between CBS and NBC. Ray Scott handled the play-by-play duties, and was joined by color commentators Pat Summerall and Jack Kemp in the broadcast booth. Kemp was the first Super Bowl commentator who was still an active player (with Buffalo of the AFL) at the time of the broadcast. The CBS telecast of this game is considered lost; all that survives are in-game photos, most of which were shown in the January 8, 1969, edition of \"Sports Illustrated\". Not even NFL Films, the league's official filmmaker, has a copy of the full game available; however, they do have game footage that they used for their game highlight film. Super Bowl II was aired exclusively by CBS and was long believed to have been erased, but it was later found that the entire telecast fully exists and rests in the vaults of NFL Films.\nWhile the Orange Bowl was sold out for the game, the NFL's unconditional blackout rules in place then prevented the live telecast from being shown in the Miami area.\nDuring the latter part of the second quarter, and again for three minutes of halftime, almost 80 percent of the country (with the exceptions of New York City, Cleveland, Philadelphia and much of the Northeast) lost the video feed of the CBS broadcast. CBS, who had paid $2.5 million for broadcast rights, blamed the glitch on a breakdown in AT&amp;T cable lines.\n39.12 million people in the US watched the game on television, resulting in a rating of 36.8 and a market share of 68. The overnight Arbitron rating was 43.\nCeremonies and entertainment.\nThe pregame ceremonies featured two giant figures, one dressed as a Packers player and the other dressed as a Raiders player. They appeared on opposite ends of the field and then faced each other near the 50-yard line.\nThe Grambling College Tiger Marching Band performed the national anthem as well as during the halftime show. The band was part of the halftime show of Super Bowl I the previous year.\nGame summary.\nFirst quarter.\nThe game kicked off at 3:05\u00a0p.m. EST. On Oakland's first offensive play, Green Bay linebacker Ray Nitschke shot through a gap and upended fullback Hewritt Dixon by himself in what was one of Nitschke's signature plays of his entire career. The hit was so vicious, it prompted Jerry Green, a \"Detroit News\" columnist sitting in the press box with fellow journalists, to say in a deadpan, that the game was \"over\". After forcing the Raiders to punt, the Packers scored with kicker Don Chandler's 39-yard field goal after marching 34 yards on their first drive of the game, giving Green Bay an early 3-0 lead. The Raiders picked up three first downs on their second drive, which included a pass interference penalty called on Nitschke, but they could not reach field goal range and were forced to punt back to the Packers. Green Bay started their next drive from their own 3-yard line. On their third play quarterback Bart Starr completed a 17-yard pass to wide receiver Carroll Dale and four plays later rushed for 14 yards while escaping a sack by defensive end Ben Davidson and defensive tackle Tom Keating. The Packers also elected to convert 4th-and-inches at the Raiders' 35-yard line, and fullback Ben Wilson picked up 5 yards and the fifth first down of the drive to end the quarter.\nSecond quarter.\nDespite Green Bay's excellent field position, their drive stalled at the 13-yard line, forcing them to settle for a 20-yard field goal by Chandler to take a 6\u20130 lead. Less than two minutes later after forcing an Oakland three-and-out, the Packers took the ball on their own 38-yard line. Raiders cornerback Kent McCloughan jammed Packers wide receiver Boyd Dowler at the line of scrimmage, but then allowed him to head downfield, thinking that a safety would pick him up. However, McCloughan and safety Howie Williams were both influenced by the Packer running backs who were executing a \"flood\" pattern, with halfback Travis Williams and Wilson running pass routes to the same side as Dowler. Dowler ran a quick post and was wide open down the middle. He grabbed Starr's pass well behind linebacker Dan Conners, and safety Rodger Bird could not get over quickly enough. Dowler outran the defense to score on a 62-yard touchdown reception, increasing the Packers' lead to 13\u20130. Green Bay became the first team in a Super Bowl to score on its first three possessions on offense.\nAfter being completely dominated until this point, the Raiders offense finally struck back on their next possession, advancing 79 yards in 9 plays, and scoring on a 23-yard touchdown pass from quarterback Daryle Lamonica to wide receiver Bill Miller, cutting the Raiders' deficit to 13\u20137. The score seemed to fire up the Raiders' defense, and they forced the Packers to punt on their next drive. Bird gave the Raiders great field position with a 12-yard return to Green Bay's 40-yard line, but Oakland could only gain 1 yard with their next three plays and came up empty when kicker/backup quarterback George Blanda's 46-yard field goal attempt fell short of the goal posts. Oakland's defense again forced Green Bay to punt after three plays on the ensuing drive, but this time after calling for a fair catch, Bird fumbled punter/running back Donny Anderson's twisting, left-footed kick, and Packers tight end Dick Capp recovered the ball. After two incomplete passes, Starr threw a 9-yard completion to Dowler (despite a heavy rush from defensive end Ike Lassiter) to set up Chandler's third field goal from the 43 as time expired in the first half, giving the Packers a 16\u20137 lead.\nAt halftime, Packers guard Jerry Kramer said to his teammates (referring to Lombardi), \"Let's play the last 30 minutes for the old man.\"\nThird quarter.\nAny chance the Raiders might have had to make a comeback seemed to completely vanish in the second half. The Packers had the ball three times in the third quarter, and held it for all but two and a half minutes. On the Packers' second drive of the half starting at their own 17, Wilson ripped up the middle for 14 yards on a draw play. Anderson picked up 8 yards on a sweep, and Wilson carried to within inches of the first down. Starr then pulled one of his favorite plays on third down and short yardage, faking to Wilson and completing a 35-yard pass to wide receiver Max McGee who had slipped past three Raiders at the line of scrimmage. This was McGee's only reception of the game, and the final one of his career. Starr then hit Dale on a sideline route at the Oakland 13. Starr overthrew Anderson wide open in the end zone, but on the next play he rolled out to the right and threw back to Anderson who was tackled at the 2-yard line by linebacker Gus Otto. The next play was a broken play, as Anderson thought he saw daylight to the right but ran into Starr. The Packers were not rattled, and Anderson's 2-yard touchdown run increased Green Bay's lead to 23\u20137.\nPackers guard Jerry Kramer must have taken to heart his plea to play the second half for Coach Lombardi. On this drive, game films show him blowing Conners out of Wilson's path on the draw play, then flattening Conners again on Anderson's scoring run.\nAgain the Green Bay defense forced Oakland to go three-and-out, and the Raiders punted. The Packers drove from their own 39-yard line to the Raiders' 24 and increased their lead to 26\u20137 as Chandler kicked his fourth field goal of the game (which hit the crossbar from 31 yards out and bounced over).\nFourth quarter.\nOn the Raiders' first play of the fourth quarter, Lamonica completed a pass to running back Pete Banaszak, but safety Tom Brown forced a fumble on Banaszak, which was recovered and returned to the Raiders' 37-yard line by linebacker Dave Robinson. On the next play, however, Starr was knocked out of the game when he jammed the thumb on his throwing hand after getting sacked for an 11-yard loss by Davidson. Starr was replaced by Zeke Bratkowski, who was then sacked on his only pass attempt. The Packers could not get back to the original line of scrimmage after the sack, forcing them to punt it back to the Raiders. However, the Packers cemented the game when cornerback Herb Adderley intercepted a pass intended for wide receiver Fred Biletnikoff and returned it 60 yards for a touchdown, making the score 33\u20137 in favor of Green Bay. Adderley laid back as Biletnikoff ran a curl route, then dashed in front of him to snare the ball and scored with the help of a crushing downfield block by defensive tackle Ron Kostelnik.\nOakland did manage to score on their next drive after the turnover with a second 23-yard touchdown pass from Lamonica to Miller, set up by Banaszak's 41-yard reception on the previous play. But all the Raiders' second touchdown did was make the final score look remotely more respectable, 33\u201314.\nAt the end of the game, coach Lombardi was carried off the field by his victorious Packers in one of the more memorable images of early Super Bowl history. It was in fact Lombardi's last game as Packer coach and his ninth consecutive playoff victory.\nOakland's Bill Miller was the top receiver of the game with 5 receptions for 84 yards and 2 touchdowns. Green Bay fullback Ben Wilson was the leading rusher of the game with 62 yards despite missing most of the fourth quarter while looking for a lost contact lens on the sidelines. Don Chandler ended his Packer career in style with 4 field goals. Lamonica, the game's leading passer, finished with 15 out of 34 pass completions for 208 yards, 2 touchdowns, and 1 interception. Bart Starr completed 13 of 24 (with a couple of dropped passes) for 202 yards and one touchdown; his passer rating for the game was 96.2 to Lamonica's 71.7. The Packers outgained the Raiders in rushing yardage 160 to 107, led in time of possession by 35:54 to 24:06, had no turnovers, and only one penalty. Packer guard Jerry Kramer later recalled the mental mistakes his team made in the game, which only highlights the impossibly high standards held by Lombardi's team. As previously mentioned, this was Lombardi's last game as Green Bay head coach and this was also the final game for Green Bay Packer players Max McGee, Fuzzy Thurston, and Don Chandler.\nBox score.\nSuper Bowl II: Green Bay Packers 33, Oakland Raiders 14\n\"at Miami Orange Bowl, Miami, Florida\nFinal statistics.\nSources:\"The NFL's Official Encyclopedic History of Professional Football\", (1973), p.\u00a0139, Macmillan Publishing Co. New York, NY, LCCN 73-3862, http://, https://, https://\nIndividual statistics.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n1Completions/attempts\n2Carries\n3Long gain\n4Receptions\n5Times targeted\nRecords set.\nThe following records were set or tied in Super Bowl II, according to the official NFL.com boxscore and the ProFootball reference.com game summary. Some records have to meet NFL minimum number of attempts to be recognized. The minimums are shown (in parentheses).\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nTurnovers are defined as the number of times losing the ball on interceptions and fumbles.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nStarting lineups.\nSource:\n&lt;mark style=\"color:black;background:#FFCC00\"&gt;Hall of Fame\u2021&lt;/mark&gt;\nOfficials.\nAlternates\n\"Note: A seven-official system was not used until 1978\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29130", "revid": "36941121", "url": "https://en.wikipedia.org/wiki?curid=29130", "title": "Super Bowl IV", "text": "Fourth AFL\u2013NFL Championship Game\nSuper Bowl IV was an American football game played on January 11, 1970, at Tulane Stadium in New Orleans, Louisiana. It was the fourth and final AFL\u2013NFL World Championship Game in professional football prior to the AFL\u2013NFL merger taking effect the following season. The American Football League (AFL) champion Kansas City Chiefs defeated the National Football League (NFL) champion Minnesota Vikings by the score of\u00a023\u20137. This victory by the AFL squared the Super Bowl series with the NFL at two games apiece as the two leagues merged after the game.\nDespite the AFL's New York Jets winning the previous season's Super Bowl, many sports writers and fans thought it was a fluke and continued to believe that the NFL was still superior to the AFL, and thus fully expected the Vikings to defeat the Chiefs; the Vikings entered the Super Bowl as 13\u00bd point favorites. The Vikings posted a 12\u20132 record in 1969, then defeated the Los Angeles Rams 23\u201320 for the Western Conference title, and the Cleveland Browns 27\u20137 in the NFL Championship Game. The Chiefs, who previously appeared in the first Super Bowl, finished the regular season at 11\u20133; they continued with two road wins in the AFL playoffs, dethroning the New York Jets 13\u20136, and then taking down division rival Oakland Raiders 17\u20137 in the final AFL title game.\nUnder wet conditions, the Chiefs defense dominated Super Bowl IV by limiting the Vikings' offense to only 67 rushing yards, forcing three interceptions, and recovering two fumbles. The Chiefs' Len Dawson became the fourth consecutive winning quarterback to be named Super Bowl MVP. He completed 12 of 17 passes for 142 yards and one touchdown, with one interception. Dawson also recorded three rushing attempts for 11 yards.\nSuper Bowl IV is also notable for NFL Films miking up the Chiefs' Hank Stram during the game, the first time that a head coach had worn a microphone during a Super Bowl.\nBackground.\nHost selection process.\nThe NFL awarded Super Bowl IV to New Orleans on March 19, 1969, at the owners' meetings held in Palm Springs, California. It marked the first of eleven (as of 2024) Super Bowls to be held in New Orleans. Two cites were in consideration for the game, Miami being the other. After two consecutive Super Bowls played at the Miami Orange Bowl (II and III), owners by a roughly three-quarters vote, opted out of giving Miami the game for a third straight year. Some owners felt that since an AFL town had hosted the game two years in a row, that an NFL town should get another turn to balance out the hosting duties. New Orleans mayor Victor H. Schiro was joined by George W. Healy Jr. (editor of the \"Times-Picayune\") and Al Hirt. They highlighted the superior seating capacity (80,982) of Tulane Stadium, as well as the local accommodations. Healy and Miami mayor Stephen P. Clark became locked in a debate during a press conference while the deliberation and voting was going on behind closed doors.\nMinnesota Vikings.\nThe Minnesota Vikings, led by head coach Bud Grant, entered the game with an NFL best 12\u20132 regular season record, leading the older league in total points scored (379) and fewest points allowed (133). They had scored 50 or greater points in three different games. They lost their first and last games of the season, but in between had 12 straight victories, the longest single-season winning streak in 35 years. The Vikings broke the previous record of 11 consecutive wins set by the 1964 Colts. Their defense, considered the most intimidating in the NFL, was anchored by a defensive line nicknamed the \"Purple People Eaters\", consisting of defensive tackles Gary Larsen and Alan Page, and defensive ends Carl Eller and Jim Marshall. The secondary was led by Bobby Bryant (8 interceptions, 97 return yards), Earsell Mackbee (6 interceptions, 100 return yards), and Paul Krause (5 interceptions, 82 return yards, 1 touchdown).\nOn offense, quarterback Joe Kapp was known for his superb leadership and his running ability, both throwing on the run and running for extra yards. And when Kapp did take off and run, instead of sliding when he was about to be tackled like most quarterbacks, he lowered his shoulder and went right at the tackler. This style of play earned him the nickname \"Indestructible\". In the NFL Championship Game against the Cleveland Browns, he collided with linebacker Jim Houston while running for a first down, and Houston had to be helped off the field after the play ended. Also, Kapp was known for being an extremely unselfish leader: when he was voted the Vikings Most Valuable Player, he turned the award down and said that every player on the team was equally valuable: \"There is no one most valuable Viking. There are 40 most valuable Vikings.\"\nRunning back Dave Osborn was the team's top rusher with 643 yards and seven touchdowns. He also caught 22 passes for 236 yards and another touchdown. In the passing game, Pro Bowl wide receiver Gene Washington averaged 21.1 yards per catch by recording 821 yards and nine touchdowns from 39 receptions. Wide receiver John Henderson caught 34 passes for 553 yards and 5 touchdowns. The Vikings' offensive line was anchored by Pro Bowlers Grady Alderman and Mick Tingelhoff.\nBy winning the 1969 NFL Championship, the Vikings became the last possessors of the Ed Thorp Memorial Trophy. The trophy was thought to have been lost by the Vikings following the merger, but it was found at the Green Bay Packers Hall of Fame in 2015.\nKansas City Chiefs.\nMeanwhile, it seemed that the Chiefs, led by head coach Hank Stram, and especially quarterback Len Dawson, were jinxed throughout the year. In the second game of the regular season, Dawson suffered a knee injury that kept him from playing the next six games. Then in the following week, second-string quarterback Jacky Lee went down for the season with a broken ankle in a loss to the Cincinnati Bengals. However, third-string quarterback Mike Livingston engineered five wins of the next six starts, with Dawson coming off the bench in the second half of the sixth to clinch the win. The Chiefs (11\u20133) managed to finish in second place behind the Oakland Raiders (12\u20131\u20131) in the AFL's Western Division, after suffering a tough 10\u20136 loss to Oakland in the final game of the regular season. After that game, many sports writers and fans heavily criticized the team and Dawson for the poor play calling (Dawson called between 80 and 90 percent of the plays during the season).\nAfter a 34\u201316 road win over the New York Jets on November 16, the Chiefs clinched a playoff spot at 9\u20131 with four games remaining. Wanting to set itself up more like the NFL right before the merger, the AFL expanded its 1969 playoffs to four teams, with the second place teams from each division traveling to play the first place teams from the other division (Western champion vs. Eastern runner-up, and vice versa). As a result of the new playoff format, many critics thought the Chiefs entered the playoffs through a \"back-door\" as the runner-up in the Western division. However, Dawson silenced the critics and led Kansas City to a strong finish with two road wins in the playoffs, defeating the defending champion Jets 13\u20136, and the Raiders (who had beaten them 41\u20136 in the previous year's postseason and won seven of the last eight meetings, including twice in the 1969 season) 17\u20137 in the AFL Championship Game. This essentially made the Chiefs the first wild card team to play in the Super Bowl. (Dawson said he thought both the Jets and the Raiders could have beaten the Vikings.)\nStill, many people felt that Dawson's level of play in the AFL was not comparable to the NFL. Dawson himself had spent five seasons in the NFL as a backup before going to the AFL and becoming one of its top quarterbacks. \"The AFL saved my career,\" said Dawson. In his 8 AFL seasons, he had thrown more touchdown passes (182) than any other professional football quarterback during that time. But because many still viewed the AFL as being inferior to the NFL, his records were not considered significant. Dawson's first chance to prove himself against an NFL team ended in failure, with his Chiefs losing 35\u201310 to the Green Bay Packers in Super Bowl I, reinforcing the notion that his success was only due to playing in the \"inferior league\".\nOffensively, the Chiefs employed innovative formations and strategies designed by Stram to disrupt the timing and positioning of the defense. Besides Dawson, the Chiefs main offensive weapon was running back Mike Garrett (1965 Heisman Trophy winner), who rushed for 732 yards and 6 touchdowns. He also recorded 43 receptions for 432 yards and another 2 touchdowns. Running back Robert Holmes had 612 rushing yards, 266 receiving yards, and 5 touchdowns. Running back Warren McVea rushed for 500 yards and 7 touchdowns, while adding another 318 yards returning kickoffs. In the passing game, wide receiver Otis Taylor caught 41 passes for 696 yards and 7 touchdowns. The offensive line was anchored by AFL All-Stars Ed Budde and Jim Tyrer. According to Len Dawson, placekicker Jan Stenerud and punter Jerrel Wilson were the best kickers in football. The offensive line was led by tackle Jim Tyrer, who was selected to his 6th AFL pro bowl.\nThe Chiefs defense led the AFL in fewest points allowed (177), as all 11 players started all 14 games. Like the Vikings, the Chiefs also had an outstanding defensive line, which was led by defensive tackles Buck Buchanan and Curley Culp, and defensive ends Jerry Mays and Aaron Brown. The Chiefs also had AFL All-Star linebacker Willie Lanier, who recorded 4 interceptions and 1 fumble recovery during the season. The Kansas City secondary was led by defensive backs Emmitt Thomas (9 interceptions for 146 return yards and a touchdown), Jim Kearney (5 interceptions for 154 return yards and a touchdown) and Johnny Robinson (8 interceptions for 158 return yards). Six members of the Chiefs' defense have been inducted into the Hall of Fame: Culp, Buchanan, Lanier, Thomas, Bobby Bell, and Johnny Robinson.\nKansas City's defense had shown their talent in the AFL title game when they defeated the Raiders. Raiders quarterback Daryle Lamonica had completed 13 of 17 passes for 276 yards and a record setting 6 touchdowns in a 56\u20137 divisional rout of the Houston Oilers in their previous game, and had shredded the Chiefs with 347 yards and 5 touchdowns in their 41\u20136 win in the previous season's playoffs. But in the 1969 AFL Championship Game, the Chiefs defense held him to just 15 of 39 completions and intercepted him 3 times in the fourth quarter.\nPlayoffs.\nKansas City advanced to the Super Bowl with wins over the two previous AFL champions. First they defeated the New York Jets in a defensive struggle 13\u20136, with Dawson's 61-yard completion to Taylor setting up the game winning score on his 19-yard touchdown pass to Gloster Richardson. Kansas City held New York to just 234 yards and forced 4 turnovers.\nThe Chiefs then faced the Raiders, who took a 7\u20130 lead over them in the first quarter, but that was their only score of the game. Meanwhile, Dawson's 41-yard completion to Frank Pitts in the second quarter set up a 1-yard touchdown run by Wendell Hayes. Then in the third quarter, Emmitt Thomas' clutch interception in the end zone and Dawson's long completion to Taylor sparked a 95-yard drive that ended with a touchdown run by Robert Holmes. Kansas City went into the fourth quarter with a 14\u20137 lead, and held on for the win by forcing four turnovers (3 interceptions and a turnover on downs) in the final period.\nMeanwhile, the ninth-year Vikings recorded their first postseason win in franchise history by defeating the Los Angeles Rams 23\u201320. Though the Rams held the lead for most of the time in regulation, Kapp led a touchdown drive to give the team a 21\u201320 fourth quarter lead. Eller made a key play to preserve the lead, sacking Rams quarterback (and 1969 NFL MVP) Roman Gabriel in the end zone for a safety and Alan Page intercepted a pass with thirty seconds remaining.\nThen Minnesota quickly demolished the Cleveland Browns in the NFL championship game, jumping to a 24\u20130 halftime lead and going on to win 27\u20137. The Vikings offense gained 381 yards without turning the ball over, with Kapp passing for 169 yards and a touchdown, while Osborn rushed for 108 yards and Washington gained 125 yards on just 3 receptions.\nSuper Bowl pregame news and notes.\nMany sportswriters and fans expected that the Vikings would easily defeat the Chiefs. Although the AFL's New York Jets won Super Bowl III at the end of the previous season, many were convinced that it was a fluke. They continued to believe that all of the NFL teams were far and away superior to all of the AFL teams. And regardless of the differences among the leagues, the Vikings simply appeared to be a superior team. Minnesota had the NFL's best record and outscored their opponents by 246 points, while Kansas City had not even won their own division. The Chiefs also had played only five games in the regular season against teams who finished with winning records, and eight against teams who finished with losing records, while the Vikings played seven against teams with winning records and seven against teams with losing records. Including playoffs, Minnesota had not lost a game against a winning team.\nSuper Bowl IV provided another chance to show that Dawson belonged at the same level with all of the great NFL quarterbacks. But five days before the Super Bowl, news leaked that his name had been linked to a Detroit federal gambling investigation. Although Dawson was eventually cleared of any charges, the controversy added to the pressure he was already under while preparing for the game, causing him to lose sleep and concentration. \"It was, beyond a doubt, the toughest week of my life,\" said Dawson.\nBud Grant became the first Super Bowl coach not to wear a tie. His counterpart, Hank Stram, wore a three-piece suit, with a red vest and a blazer with the Chiefs' helmet logo emblazoned on the breast pocket.\nAll seats for the game were priced at $15; the previous year's prices were $12, $8 and $6. The attendance mark of 80,562 is the highest of the first four pre-merger Super Bowl games played.\nBroadcasting.\nAmerican television.\nSuper Bowl IV was broadcast in the United States by CBS with play-by-play announcer Jack Buck (his only Super Bowl on television) and color commentator Pat Summerall, with Frank Gifford and Jack Whitaker reporting from the winning and losing locker rooms, respectively. After the season, Summerall was transferred to work alongside Ray Scott, whose broadcast partner Paul Christman died on March 2, 1970. This was the last Super Bowl that Gifford worked for CBS, as he left following the 1970 season to become the play-by-play announcer for Monday Night Football. Gifford did not work another Super Bowl until Super Bowl XIX, the first Super Bowl to air on ABC. \nWhile the game was a sellout, the NFL's unconditional blackout rules prohibited the live telecast from being shown in the New Orleans area. \nCBS erased the videotape a few days after the game, as the network had done following the broadcasts of Super Bowl I and II. Videotape was expensive and television networks did not believe that old games were worth saving. For many years, the only known extant recording of the broadcast was one sourced from the CBC archives. The network and its French-language counterpart T\u00e9l\u00e9vision de Radio-Canada carried the broadcast, and it was saved because of Vikings coach Bud Grant's history in the CFL and the close proximity of Minnesota to Canada. CBC transferred the footage to black-and-white film using the kinescope process soon after the original broadcast, enabling reuse of the videotape. However, a color videotape of the first three quarters and a portion of the fourth quarter, including the pregame show and original commercials, was discovered in 2023 and is publicly available.\n44.27 million people in the U.S. watched the game on television, resulting in a rating of 39.4 and a market share of 69.\nHank Stram and NFL Films.\nThe night before the game, Ed Sabol of NFL Films met with Hank Stram and convinced him to wear a hidden microphone during the game so that Stram's comments could be recorded for the NFL Films Super Bowl IV film. This was the first time that a head coach had worn a microphone during a Super Bowl, although Stram had done so during the regular season in a home game against the Boston Patriots. Sabol and Stram agreed that the microphone would be kept secret. Sabol had his top sound man Jack Newman, who had also wired Vince Lombardi in a previous playoff game, conceal the microphone on Stram and monitor the sound throughout. However, some Chiefs players noticed that Stram's demeanor deviated from his normal form during the game, ostensibly because he was aware of the microphone. Linebacker Willie Lanier commented that \"Hank seemed somewhat more animated\", quarterback Len Dawson \"wondered why he was being so joyous and chattering all the time\" and halfback Mike Garrett recalled that Stram \"was in rare form and pretty glib\".\nStram's awareness of the microphone likely resulted in a direct impact on the game itself. Dawson later recalled that \"I thought there was something wrong with Hank\" because Stram selected the Chiefs' offensive play calls during the game and communicated them directly to Dawson, while Dawson had routinely called his own plays during the season.\nBecause of Stram's colorful soundbites throughout the film, it ranks among the most popular and well-known of all official Super Bowl highlight films, despite the fact that the game was a mostly one-sided affair. Notable excerpts include the following:\nGame summary.\nChiefs head coach Hank Stram, who was also the team's offensive coordinator, devised an effective game plan against the Vikings. He knew Minnesota's secondary was able to play very far off receivers because Viking defensive ends Carl Eller and Jim Marshall knocked down short passes or put pressure on the quarterback. Stram decided to double-team Marshall and Eller; most of quarterback Len Dawson's completions were short passes, and neither Marshall nor Eller knocked down any passes. Stram also concluded that the Vikings' aggressiveness on defense also made them susceptible to trap plays; Mike Garrett's rushing touchdown came on a trap play. On offense, the Vikings' inside running game depended on center Mick Tingelhoff blocking linebackers. Stram put 285-pound Buck Buchanan or 295-pound Curley Culp nose to nose in front of Tingelhoff, who weighed only 235 pounds. To Minnesota's credit, the NFL used the so-called light \"greyhound\" centers while the AFL used big centers. It was a mismatch that disrupted the Vikings' running game; it also kept quarterback Joe Kapp from moving outside the pocket. Left defensive end Jerry Mays said of the odd line formation, \"...we never played it that much before. Minnesota's recognition was destroyed.\" Wrote Dawson, \"It was obvious that their offense had never seen a defense like ours.\" Minnesota rushed for only two first downs.\nFirst quarter.\nThe Vikings began the game by receiving the opening kickoff and marching from their own 20-yard line to the Kansas City 39-yard line with quarterback Joe Kapp completing his first two passes for 36 yards. Kapp's next pass was also a completion, but running back Bill Brown was slowed by linebacker Bobby Bell, then brought down by defensive end Jerry Mays for a 1-yard loss to make it third down, on which Kapp failed to connect with tight end John Beasley. Minnesota rushed for only 6 yards on the drive and chose to punt. The Chiefs then drove 42 yards in eight plays. Included was a 20-yard reception by wide receiver Frank Pitts after Vikings cornerback Ed Sharockman gambled trying to make an interception. Kansas City then scored on placekicker Jan Stenerud's Super Bowl record 48-yard field goal. This record stood for 24 years until broken by Steve Christie in Super Bowl XXVIII. (According to Dawson, the Vikings were shocked that the Chiefs attempted a 48-yard field goal. Stenerud was among the first soccer-style placekickers in professional football. The others included brothers Charlie and Pete Gogolak. The soccer-style placekickers used the instep of the foot while the conventional professional football placekickers kicked straight on with their toes. \"Stenerud was a major factor,\" Dawson said.) Minnesota then managed to reach midfield on their next drive, which was even aided by a roughing the kicker penalty on Chiefs linebacker Bob Stein during a punt from their own 25-yard line, but could not get in scoring position and were forced to punt again.\nOn the first play of the Chiefs' ensuing drive, Dawson threw a 20-yard completion to Pitts, followed by a 9-yard pass to wide receiver Otis Taylor, to get to midfield before the end of the quarter.\nSecond quarter.\nFour plays later, on the first play of the second quarter, a pass interference penalty on Sharockman nullified Dawson's third down incompletion and gave Kansas City a new set of downs at the Minnesota 31-yard line. However, on 3rd-and-4 at the 25-yard line, Vikings cornerback Earsell Mackbee broke up a deep pass intended for Taylor, forcing the Chiefs to settle for a 32-yard field goal by Stenerud, increasing their lead to 6\u20130.\nOn the second play of Minnesota's next drive, Chiefs cornerback Jim Marsalis forced a fumble on wide receiver John Henderson, who caught a 16-yard reception, and safety Johnny Robinson recovered the ball at the Vikings' 46-yard line. But defensive tackle Alan Page tackled running back Mike Garrett for a 1-yard loss, and then safety Paul Krause intercepted Dawson's pass to Taylor at the 7-yard line on the next play, turning the ball back over to the Vikings.\nHowever, the Vikings also could not take advantage of the turnover. Kapp's two incompletions and a delay of game penalty forced Minnesota to punt from their own 5-yard line. The Chiefs then took over at the Viking 44-yard line after punter/backup quarterback Bob Lee's kick traveled 39 yards. A 19-yard run by Pitts on an end around play fooled the overaggressive, over-pursuing Viking defense to set up Stenerud's 25-yard field goal, increasing Kansas City's lead to 9\u20130.\nOn the ensuing kickoff, Vikings safety/kick returner Charlie West fumbled the ball, and Chiefs center Remi Prudhomme recovered it at the Minnesota 19-yard line. (\"That was a key, key play,\" said Dawson.) Defensive end Jim Marshall sacked Dawson for an 8-yard loss on the first play of the drive; however, a 13-yard run on a draw play by running back Wendell Hayes and a 10-yard reception by Taylor gave the Chiefs a first down at the Vikings' 4-yard line. Three plays later, Garrett's 5-yard touchdown run on a trap draw play named 65 Toss Power Trap (although the play did not involve a toss), aided by pulling guard Mo Moorman's block on Page that cleared a huge hole, gave Kansas City a 16\u20130 lead.\nWest returned the ensuing kickoff 27 yards to the 32-yard line. On the first play of the drive, Kapp completed a 27-yard pass to Henderson to advance the ball to the Kansas City 41-yard line. However, on the next three plays, Kapp threw two incompletions and was sacked by Chief defensive tackle Buck Buchanan for an 8-yard loss. On fourth down, Vikings kicker Fred Cox's 56-yard field goal attempt fell way short of the goal posts and was caught and returned to the Chiefs' 24-yard line by kick returner Warren McVea. Kansas City could not get the ball past midfield, so they punted it back to Minnesota to end the half. For the first half, Minnesota rushed for only 24 yards and failed to convert any of five third downs. On nine first down plays, the Vikings rushed six times and gained only 12 yards.\nTo this point in the combined history of NFL and AFL championship games, including the first three Super Bowls, no team had lost a game when holding a lead of more than 10 points, no matter what time of the game it was. The Chiefs, when they were the Dallas Texans in their last game before they became the Chiefs, lost a 17\u20130 lead in the 1962 AFL Championship Game, but managed to defeat the Houston Oilers 20\u201317 in the second overtime. No team would lose such a lead and also lose the game until Super Bowl LI.\nThird quarter.\nIn the third quarter, the Vikings managed to build momentum. After the Chiefs punted on their opening possession, Minnesota drove 69 yards in 10 plays, during which they made their first third down conversion of the game. Kapp completed four consecutive passes for 47 yards, including a 15-yard pass to tight end John Beasley. Kapp also rushed for 7 yards. The Vikings' drive ended with fullback Dave Osborn's 4-yard touchdown run, reducing their deficit to 16\u20137. However, the Chiefs responded on their next possession with a six-play, 82-yard drive. Pitts picked up a key first down with a 7-yard left-to-right run on a reverse play. Then right after a 15-yard personal foul penalty against the Vikings, Dawson threw a short pass to Taylor, who caught the ball at the Minnesota 41-yard line, broke tackles by Mackbee and safety Karl Kassulke, took off down the sideline and scored the clinching touchdown on a 46-yard play, making the score 23\u20137. The Vikings reached their own 47 on their next possession to end the quarter.\nFourth quarter.\nThe Vikings were demoralized after the game-breaking touchdown and the Chiefs' defense continued to shut them down in the fourth quarter, forcing three interceptions on three Minnesota possessions to clinch the 23\u20137 victory. The defeat was total for the Vikings, as even Kapp had to be helped off the field in the fourth quarter after getting strip-sacked by Chiefs defensive end Aaron Brown. Gary Cuozzo filled in for Kapp for the rest of the game. Fittingly, the Vikings' final play was an interception Cuozzo threw to cornerback Emmitt Thomas.\nKansas City running back and future University of Southern California Athletic Director Mike Garrett, the 1965 Heisman Trophy recipient, was the top rusher of the game, recording 11 carries for 39 yards and a touchdown. He also caught two passes for 25 yards and returned a kickoff for 18 yards. Taylor was the Chiefs' leading receiver with six catches for 81 yards and a touchdown. Kapp finished the game with 16 of 25 completions for 183 yards, with two costly interceptions. Henderson was the top receiver of the game with seven catches for 111 yards. The Chiefs defense completely shut down Minnesota's vaunted rushing attack. In the NFL championship game, Osborn had rushed for 108 yards while Kapp rushed for 57. In Super Bowl IV, however, the two rushed for a combined total of 24 yards. In addition, Kansas City's secondary held Minnesota All Pro receiver Gene Washington to one reception for 9 yards.\nReferring to the Vikings' three interceptions, three fumbles, and six penalties, Kassulke said, \"We made more mental mistakes in one game than we did in one season.\" Kapp never played again for the Vikings, as he played out the option of his contract and signed with the Boston Patriots for the 1970 season.\nKansas City is, as of 2024[ [update]], the only team in the Super Bowl era to win the title without allowing as much as 10 points in any postseason game.\nBox score.\nSuper Bowl IV: Kansas City Chiefs 23, Minnesota Vikings 7\n\"at Tulane Stadium, New Orleans, Louisiana\nFinal statistics.\nSources:\"The NFL's Official Encyclopedic History of Professional Football\", (1973), p.\u00a0144, Macmillan Publishing Co. New York, NY, LCCN 73-3862, http://, http://, https://, https://, https://\nIndividual leaders.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n1Completions/attempts\n2Carries\n3Long gain\n4Receptions\n5Times targeted\nRecords set.\nThe following records were set or tied in Super Bowl IV, according to the official NFL.com boxscore and the ProFootball reference.com game summary. Some records have to meet NFL minimum number of attempts to be recognized. The minimums are shown (in parentheses).\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nStarting lineups.\n&lt;mark style=\"color:black;background:#FFCC00\"&gt;Hall of Fame\u2021&lt;/mark&gt;\nSource:\nPlayers' shares.\nAs with the previous three Super Bowls, the players' shares were $15,000 each for the winning team and $7,500 each for the losing team. This was in addition to the league championship money earned a week earlier, approximately $8,000 each.\nOfficials.\nThis was the first Super Bowl for all six officials, and the only one for McDonough, Kessel and Schleibaum. \n\"Note: A seven-official system was not used until 1978\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29131", "revid": "46866511", "url": "https://en.wikipedia.org/wiki?curid=29131", "title": "Super Bowl V", "text": "1971 Edition of the Super Bowl\nSuper Bowl V was an American football game played between the American Football Conference (AFC) champion Baltimore Colts and the National Football Conference (NFC) champion Dallas Cowboys to determine the National Football League (NFL) champion for the 1970 season. It was the fifth edition of the Super Bowl and the first modern-era NFL championship game. The Colts defeated the Cowboys by the score of 16\u201313 on a field goal with 5 seconds left in the game. The game was played on January 17, 1971, at the Orange Bowl in Miami, Florida, and was the first Super Bowl game played on artificial turf; specifically, the game was played on a Poly-Turf surface.\nThe game was the first Super Bowl played after the completion of the AFL\u2013NFL merger. Beginning with this game and continuing to the present day, the Super Bowl has served as the NFL's championship game, with the winner of the AFC Championship Game and the winner of the NFC Championship Game facing off in the culmination of the NFL playoffs. As per the merger agreement, all 26 AFL and NFL teams were divided into two conferences with 13 teams in each. Along with the Colts, the Cleveland Browns and Pittsburgh Steelers agreed to join the ten AFL teams to form the AFC; the remaining 13 NFL teams formed the NFC. This explains why the Colts represented the NFL in Super Bowl III, but the AFC for Super Bowl V. Baltimore advanced to Super Bowl V after posting an 11\u20132\u20131 regular season record. Meanwhile, the Cowboys were making their first Super Bowl appearance after posting a 10\u20134 regular season record.\nThe game is often referred to as the \"Blunder Bowl,\" \"Blooper Bowl,\" or \"Stupor Bowl\" due to it being marred with poor play, a blocked PAT, missed opportunities, penalties, turnovers, and officiating miscues. The two teams combined for a Super Bowl record 11 turnovers, with five solely in the fourth quarter. The Colts' seven turnovers remain the most committed by a Super Bowl champion. Dallas also set a Super Bowl record with 10 penalties, costing them 133 yards. It was finally settled when Colts rookie kicker Jim O'Brien made a 32-yard field goal with five seconds left in regulation time, then a Super Bowl record for least time in the lead for a champion. Baltimore overcame a 13\u20136 deficit after three quarters and the loss of its starting quarterback Johnny Unitas to an injury in the second quarter. To date, the game is the only Super Bowl in which the Most Valuable Player Award was given to a member of the losing team: Cowboys' linebacker Chuck Howley, the first non-quarterback to win the award, after making two interceptions (sacks and tackles were not yet recorded).\nDue to its blunders, the game is often regarded among the worst Super Bowls played, but is also recognized as the title the Colts needed after losing Super Bowl III.\nBackground.\nHost selection process.\nThe NFL awarded Super Bowl V to Miami on March 17, 1970, at the owners' meeting held in Honolulu. It marked the third Super Bowl to be played in the Orange Bowl. Three cities submitted bids: Miami, New Orleans, and Los Angeles (Coliseum). A potential bid by Pasadena (Rose Bowl) failed to materialize, and Houston (Astrodome) dropped out due to scheduling conflicts with conventions.\nBaltimore Colts.\nThe Colts were an unspectacular but well-balanced veteran team, led by 37-year-old star quarterback Johnny Unitas. He had regained his starting spot on the team in 1969 upon recovering from an injury that led him to miss the majority of the 1968 season. Unitas played inconsistently during the 1970 regular season; he threw for 2,213 yards, but recorded more interceptions than touchdowns. He also had injury problems, missing two regular season games and giving Earl Morrall more significant playing time. Morrall put up better statistics (792 yards, 9 touchdowns, 4 interceptions, and a 97.6 passer rating), but head coach Don McCafferty decided to start Unitas for the playoffs. (According to Jim O'Brien, Morrall was just as good as Unitas in the players' opinion.)\nIn addition, Baltimore had three solid weapons in the passing game: wide receivers Eddie Hinton and Roy Jefferson, and future Hall of Fame tight end John Mackey combined for 119 receptions, 1,917 yards, and 15 touchdowns. In the backfield, running back Norm Bulaich was the team's top rusher with 426 yards and 3 touchdowns, while also catching 11 passes for another 123 yards.\nThe Colts' main strength was their defense. Pro Bowl defensive tackle Bubba Smith anchored the line. Behind him, the Colts had two outstanding linebackers: Pro Bowler Mike Curtis, who recorded 5 interceptions, and Ted Hendricks. In the secondary, Pro Bowl safety Jerry Logan recorded 6 interceptions for 92 return yards and 2 touchdowns, while safety Rick Volk had 4 interceptions for 61 return yards.\nDon Klosterman, formerly with San Diego, Kansas City, and Houston in the AFL, became the Colts' general manager in 1970. Future Colts GM Ernie Accorsi was the public relations director.\nBaltimore finished the regular season winning the AFC East with an 11\u20132\u20131 record, the best in the AFC. Only the Minnesota Vikings had a better record among all NFL teams at 12\u20132.\nDallas Cowboys.\nThe Cowboys overcame many obstacles during the regular season. Running back Calvin Hill, the team's second leading rusher with 577 yards and four touchdowns, was lost for the year after suffering a leg injury late in the regular season. And wide receiver Bob Hayes was benched by head coach Tom Landry for poor performances on several occasions.\nMost significantly, the Cowboys had a quarterback controversy between Craig Morton and Roger Staubach; the two alternated as starters during the regular season. Landry eventually settled on Morton for most of the latter half of the season, because he felt less confident that Staubach would follow his game plan (Landry called all of Morton's plays). Also, Morton had done extremely well in the regular season, throwing for 1,819 yards and 15 touchdowns, with only seven interceptions, earning him a passer rating of 89.8. In contrast, Staubach, although a noted scrambler and able to salvage broken plays effectively, threw for 542 yards, and only two touchdowns with eight interceptions, giving him a 42.9 rating.\nHayes was the main deep threat on the team, catching 34 passes for 889 yards (a 26.1 yards per catch average) and ten touchdowns, while also rushing four times for 34 yards and another touchdown, and adding another 116 yards returning punts. On the other side of the field, wide receiver Lance Rentzel (who would be deactivated for the last few weeks of the season and postseason following an indecent exposure charge; being replaced in the starting lineup by Reggie Rucker) recorded 28 receptions for 556 yards and 5 touchdowns.\nHowever, the main strength on the Cowboys offense was their running game. Rookie running back Duane Thomas rushed 151 times for 803 yards (a 5.1 yards per carry average) and five touchdowns, while adding another 416 yards returning kickoffs. Fullback Walt Garrison, who replaced the injured Hill, provided Thomas with excellent blocking and rushed for 507 yards and three touchdowns. Garrison was also a good receiver out of the backfield, catching 21 passes for 205 yards and 2 touchdowns. Up front, Pro Bowl guard John Niland and Hall of Famer Rayfield Wright anchored the offensive line.\nLike the Colts, the Cowboys' main strength was their defense. Nicknamed the \"Doomsday Defense\", they allowed just one touchdown in their last six games prior to the Super Bowl. Their line was anchored by Hall of Fame defensive tackle Bob Lilly. Behind him, linebackers Lee Roy Jordan, Dave Edwards, and Hall of Famer Chuck Howley excelled at stopping the run and pass coverage. The Cowboys had an outstanding secondary, led by the Hall of Fame tandem of Mel Renfro and Herb Adderley, who combined for seven interceptions. Dallas also had two rookie safeties: Hall of Famer Cliff Harris and Charlie Waters, who led the team with five interceptions, while Harris recorded two.\nDallas finished the regular season winning the NFC East with a 10\u20134 record, winning their final five regular season games to overcome the St. Louis Cardinals (who lost their final three games and fell to third place in the final standings) and New York Giants (who lost their finale 31\u20133 to the Los Angeles Rams; a Giants victory would have given New York the NFC East title based upon a better division record and forced a coin toss between the Cowboys and Detroit Lions for the wild card playoff spot).\nPlayoffs.\nIn the playoffs, Dallas defeated Detroit 5\u20130 in sunny weather at the Cotton Bowl, with a field goal and a safety. Later, the Cowboys overcame the San Francisco 49ers in the NFC championship game, 17\u201310, aided by Thomas' 143 rushing yards, along with interceptions by Renfro and Jordan late in the third quarter that were both converted into touchdowns.\nMeanwhile, the Colts advanced to the Super Bowl by beating the Cincinnati Bengals 17\u20130 and the Oakland Raiders 27\u201317 in the playoffs at Memorial Stadium.\nSuper Bowl pregame news and notes.\nFor the Colts, Super Bowl V represented a chance to redeem themselves for their humiliating loss to the New York Jets in Super Bowl III. Volk commented, \"Going to the game a second time took away some of the awe. I think we were able to focus better. There was no way we were going to let ourselves get beat again.\" Further pressure was on the Colts as the Baltimore Orioles achieved redemption four months earlier by beating the Cincinnati Reds in the World Series after falling to the New York Mets a year earlier.\nMeanwhile, the game was a chance for the Cowboys to lose their nickname of \"next year's champions\" and their reputation of \"not being able to win the big games\". In the past five seasons, Dallas had won more games, 52 of 68, than any other professional football team, but they had yet to win a league title. The Cowboys had chances to go to the first two Super Bowls, but narrowly lost to the Green Bay Packers in both the 1966 and 1967 NFL Championship games. In the 1966 title game, the Cowboys failed to score a potential tying touchdown on four attempts starting from the Packers two-yard line on the game's final drive. Then in the 1967 title game (the \"Ice Bowl\"), the Cowboys lost because they allowed the Packers to score a touchdown with sixteen seconds left in the game.\nAs the designated home team, Dallas was forced to wear its blue jerseys for the Super Bowl under rules in place at the time, which did not allow the home team its choice of jersey color, unlike the regular season and playoff games leading up to the Super Bowl. Dallas had not worn its blue jerseys at home since 1963, as Cowboys general manager Tex Schramm opted to have the team wear white at home in order to present fans with a consistent look. The Cowboys wore their blue jerseys twice during the 1970 season, losing 20\u20137 at St. Louis in week three and winning 6\u20132 at Cleveland in week 13. The designated home team was first allowed its choice of jersey color for Super Bowl XIII, allowing the Cowboys to wear white vs. the Pittsburgh Steelers.\nGambling establishments had the Colts as 2 \u00bd point favorites and projected 36 total points scored.\nVice President Spiro Agnew, a Colts fan since the team began playing in Baltimore in 1953, attended the game. Agnew was Governor of Maryland prior to his election as Richard Nixon's running mate in 1968. Nixon himself was a huge football fan and had a vacation home in Key Biscayne, approximately ten miles from the Orange Bowl.\nAlso in attendance was boxing great Muhammad Ali, who signed autographs for many young fans. Ali was in south Florida training for his March 8 heavyweight championship fight vs. Joe Frazier in New York City.\nKickoff for this game was at 2:00 pm, making it the earliest starting time in the Eastern Time Zone in Super Bowl history, and one of only three Super Bowls to start in the morning for viewers in the Pacific Time Zone (the others were Super Bowl VI in New Orleans and Super Bowl X in Miami).\nBroadcasting.\nThe game was broadcast in the United States by NBC with play-by-play announcer Curt Gowdy, color commentator Kyle Rote, and sideline reporter Bill Enis.\nAlthough the Orange Bowl was sold out for the event, unconditional blackout rules in the NFL in the era prohibited the live telecast from being shown in the Miami area. The blackout was challenged in Miami-Dade District Court by attorney Ellis Rubin, and although the judge denied Rubin's request since he felt he did not have the power to overrule the NFL, he agreed with Rubin's argument that the blackout rule was unnecessary for the Super Bowl. The game was also the first Super Bowl to be carried live in the state of Alaska, thanks to NBC's then-parent company RCA acquiring the Alaska Communications System from the United States Air Force.\nThe video of the complete original broadcast, up until Chuck Howley's second interception, the first play of the fourth quarter, exists; however, the rest of the fourth quarter is missing from network vaults. The complete audio, including the post-game, does exist. Broadcast excerpts of the crucial fourth-quarter plays, recovered from the Canadian feed of NBC's original, also exist and circulate among collectors. (Two different NFL Films game compilations also cover the fourth-quarter plays, in part.)\n46.04 million people in the US watched the game on television, resulting in a rating of 39.9 and a market share of 75.\nEntertainment.\nThe bands from Southern University and Southeast Missouri State College performed before the game, while trumpeter Tommy Loy played the national anthem. Loy also played the anthem before every Cowboys' home game from the mid-1960s until the late-1980s. The Southeast Missouri State Golden Eagle Band was featured during the halftime show along with singer Anita Bryant.\nThe game had one of the first planned jet fly-bys. The fly-by, which was supposed to happen right at the end of the national anthem, ended up coming 5 minutes after the anthem had ended.\nThis was the third consecutive (and final) Super Bowl to feature the Vince Lombardi Trophy on the 50-yard line. Originally the trophy was supposed to be painted gray, but the league changed it to silver which led to problems washing it out of the poly turf surface.\nHalftime show.\nThe Super Bowl V halftime show was headlined by the Southeast Missouri State Marching Band, with Anita Bryant as a guest. Up with People were also included as performers.\nThis was the third time that the Southeast Missouri State Marching Band had performed at the Miami Orange Bowl (venue of Super Bowl V), having previously performed during the halftime of the 1965 and 1969 Orange Bowl games. The band was directed by LeRoy Mason. During their stay in Miami for the game, the band was accommodated at the McAllister Hotel.\nDuring the roughly 13-minute performance, floats representing each of the league's 26 teams were utilized. Members of two high school bands were utilized to form a geographic outline of the United States.\nIn the performance, Bryant, standing on a float, sang, \"Battle Hymn of the Republic\". The arrangement of this song was created by her musical director Charles Bird, and had been created for the band to accompany her. It had been adapted from a previous recording Bryant had done of the tune.\nGame summary.\nFirst quarter.\nThe first three possessions of Super Bowl V ended quietly with each team punting after a three-and-out. Then, after a facemask penalty on Dallas during a punt back to Baltimore for the second time, the Colts started their second drive on their own 47-yard line, but on the first play, Cowboys linebacker Chuck Howley intercepted a pass from Colts quarterback Johnny Unitas and returned it 22 yards to the Colts' 46-yard line, the first of 11 combined turnovers committed by both teams. The Cowboys failed to take advantage of the turnover, with a 15-yard holding penalty 10 yards behind the line of scrimmage pushing them back to a 3rd-and-33 situation. Fullback Walt Garrison could only gain 11 yards on the next play, forcing Dallas to punt. However, Colts punt returner/cornerback Ron Gardin fumbled the return, and the loose ball was recovered by Cowboys safety Cliff Harris at the Colts' 9-yard line. Baltimore managed to keep Dallas out of the end zone, forcing them to settle for kicker Mike Clark's 14-yard field goal to establish a 3\u20130 lead.\nAfter a Colts punt, which they failed to keep from reaching the end zone, Cowboys quarterback Craig Morton completed a 14-yard pass to running back Dan Reeves, followed by a 41-yard pass to wide receiver Bob Hayes (Morton's longest pass of the game) to reach the Colts' 12-yard line, with a roughing the passer penalty on Colts defensive tackle Fred Miller adding 6 yards (half the distance to the goal), but Dallas was denied the end zone by the Baltimore defense for a second time. Linebacker Ted Hendricks deflected Morton's pass on first down, and running back Duane Thomas was tackled for a 1-yard loss on second down by cornerback Jim Duncan.\nSecond quarter.\nAt the start of the second quarter, Morton was flagged for intentional grounding on third down while trying to avoid a sack by defensive tackle Billy Ray Smith, pushing the Cowboys back to the 22-yard line and forcing them to settle for Clark's 30-yard field goal, stretching the score to 6\u20130.\nOn their next possession, the Colts offense got a break. After two straight incompletions to open the drive, Unitas uncorked a pass to wide receiver Eddie Hinton that was both high and behind the receiver. The ball ricocheted off Hinton's hands, was tipped by Cowboys cornerback Mel Renfro, then landed in the arms of tight end John Mackey, who sprinted 75 yards for a touchdown, the final one of Mackey's career. The Cowboys subsequently blocked kicker Jim O'Brien's extra point attempt to keep the score tied at 6\u20136, with O'Brien later saying that he was \"awfully nervous\" and hesitated a second too long before kicking it.\nAfter the next three possessions ended in punts, Cowboys linebacker Lee Roy Jordan forced a fumble on Unitas, and defensive tackle Jethro Pugh recovered the loose ball at the Baltimore 28. Dallas capitalized on the turnover in three plays; Thomas rushed for 4 yards, then Morton completed a 17-yard pass to Reeves, followed by a 7-yard touchdown pass to Thomas to establish a 13\u20136 lead. The Colts reached the Cowboys' 37 on their next drive, but turned the ball over yet again, with Unitas unleashing a fluttering interception to Renfro while taking a fierce hit by defensive end George Andrie. Unitas was knocked out of the game permanently on the play with a rib injury and was replaced by Earl Morrall, who was widely blamed for the Colts' loss to the New York Jets in Super Bowl III. The Cowboys, starting from their own 15, were unable to score any points off the turnover. An offensive pass interference penalty on Hayes forced Dallas to punt. Starting from their own 48-yard line, the Colts offense, now led by Morrall, began to gain momentum. Morrall completed a 26-yard pass to Hinton, followed by a 21-yard pass to wide receiver Roy Jefferson. A personal foul penalty on Jordan put the ball on the Dallas 2-yard line with less than two minutes remaining in the half and giving Baltimore a chance to tie the game. However, the Cowboys defense stiffened. Colts running back Norm Bulaich was stuffed on three consecutive rushing attempts from inside the 2-yard line. The Colts elected to convert fourth down, but Morrall threw a pass intended for tight end Tom Mitchell that fell incomplete, turning the ball over on downs and maintaining Dallas' 13\u20136 lead to end the half.\nThird quarter.\nThe second half was a parade of turnovers, sloppy plays, penalties, and missed opportunities. Baltimore's defense also held Dallas' offense scoreless for the rest of the game.\nDuncan fumbled the opening kickoff while running into Cowboys running back Claxton Welch, and Dallas recovered the ball at Baltimore's 31. Then the Cowboys drove to the Colts' 2-yard line with the chance to take a two-score lead, but linebacker Mike Curtis punched the ball loose from Thomas before he could cross the goal line, and the Colts took over at their own 1 as Duncan was credited with the recovery\u2013-a controversial call because when the resulting pile-up was sorted out, Dallas center Dave Manders was seen holding the ball. The energized Colts then drove to the Cowboys' 44-yard line, with Morrall completing a 26-yard pass to wide receiver Sam Havrilak, but came up empty when O'Brien's 52-yard field goal attempt fell short of the goal posts. However, instead of attempting to return the missed field goal, Renfro allowed it to bounce inside the Cowboys' own 1-yard line where it was downed by Colts center Tom Goode (NFL rules prior to 1974 allowed a field goal that fell short of the goal posts to be downed just like a punt; that rule is still in effect in high school football). \"I thought it would carry into the end zone\", Renfro explained after the game.\nDallas, backed up to their own end zone, punted after a three-and-out. The Colts would have received the ball inside Dallas territory following the punt, but a clipping penalty on Baltimore running back Jack Maitland pushed the Colts back to their own 39 to begin the drive. Two plays later, however, Morrall completed a 45-yard pass to running back Tom Nowatzke to reach the Cowboys' 15-yard line.\nFourth quarter.\nHowever, three plays later, on the first play of the fourth quarter, Morrall threw an interception to Howley in the end zone to preserve the Cowboys' 13\u20136 lead.\nAfter forcing the Cowboys to punt, the Colts regained the ball on their own 18-yard line, still trailing 13\u20136. Aided by a pass interference penalty on Dallas safety Charlie Waters and a 23-yard pass from Morrall to Jefferson, the Colts advanced into Dallas territory. A second pass interference penalty, which was called on defensive back Cornell Green, gave the Colts a first down at the Dallas 39-yard-line. An 8-yard run by Nowatzke moved the ball to the 31-yard line. The Colts then attempted to fool the Cowboys with a flea-flicker, resulting in one of the oddest plays in Super Bowl history. Havrilak took a handoff and ran right, intending to lateral the ball back to Morrall, but Pugh stormed into the backfield and prevented him from doing so. Havrilak (who played quarterback at Bucknell University) then threw a pass intended for Mackey, but it was caught instead by Hinton, who promptly took off for the end zone. However, Green stripped Hinton from behind at the 11, and the loose ball bounced wildly into the end zone, evading recovery attempts by six different players until it was eventually pushed through the back of the end zone for a touchback, thus returning the ball to the Cowboys at their 20.\nThree plays after the turnover, Morton threw a pass that was deflected by Garrison and intercepted by Colts safety Rick Volk, who returned the ball 30 yards to the Cowboys' 3-yard line before being tackled by wide receiver Reggie Rucker (Morrall later referred to that play as the play of the game). Two plays later, Nowatzke scored on a 2-yard touchdown run, tying the game at 13\u201313. (O'Brien says he was much calmer and more confident on this extra point than on the first one, which was blocked.)\nThe next two possessions ended in traded punts, with the Cowboys eventually taking over in excellent field position at the Colts 48-yard line with less than two minutes left in the game.\nOn the second play of this potential game-winning drive, a 15-yard holding penalty on Cowboys offensive tackle Ralph Neely on the Dallas 42-yard line, which was a spot foul, pushed the Cowboys all the way back to their own 27-yard line (the NFL did not reduce the penalty for offensive holding to 10 yards until 1974). Then, on 2nd-and-35, Morton threw a pass that slipped through the hands of Reeves and bounced for an interception into the arms of Mike Curtis, who then returned the ball 13 yards to the Cowboys' 28-yard line.\nTwo plays later, with nine seconds left in the game, O'Brien kicked the go ahead 32-yard field goal, giving Baltimore their first lead of the game, 16\u201313. O'Brien says he was \"on automatic\" and was so calm and concentrating so hard that he didn't hear anything and saw only the ball. After the field goal, in an enduring image, Cowboys defensive tackle Bob Lilly took off his helmet and hurled it through the air in disgust.\nThe Cowboys received the ball again on their own 40 with one second remaining after O'Brien's ensuing squib kick, but Morton's pass to Hayes was intercepted by safety Jerry Logan at the Baltimore 29, and the Colts were victorious.\nPostscript.\nMorrall was the top passer of the game, with 7 out of 15 completions for 147 yards, with 1 interception. Before being knocked out of the game, Unitas completed 3 out of 9 passes for 88 yards and a touchdown, with 2 interceptions. Morton completed more passes than Morrall and Unitas combined (12), but finished the game with 118 fewer passing yards (127), and was intercepted 3 times (all in the fourth quarter). Mackey was the top receiver of the game with 2 receptions for 80 yards and a touchdown. Nowatzke was the Colts' leading rusher with 33 yards and a touchdown, while also catching a pass for 47 yards. Dallas running back Walt Garrison was the leading rusher of the game with 65 rushing yards, and added 19 yards on 2 pass receptions.\nReferencing the numerous turnovers, Morrall said, \"It really was a physical game. I mean, people were flying into one another out there.\" \"It was really a hard-hitting game,\" wrote O'Brien. \"It wasn't just guys dropping the ball. They fumbled because they got the snot knocked out of them.\" Said Tom Landry:\nI haven't been around many games where the players hit harder. Sometimes people watch a game and see turnovers and they talk about how sloppy the play was. The mistakes in that game weren't invented, at least not by the people who made them. Most were forced.\n\"We figured we could win if our offense didn't put us into too many holes\", said 35-year-old Colts lineman Billy Ray Smith, who was playing in his last NFL game, \"Let me put it this way, they didn't put us into any holes we couldn't get out of\".\nColts defensive end Bubba Smith would later refuse to wear his Super Bowl V ring because of the \"sloppy\" play. In a similar action, Cowboys linebacker Chuck Howley was named the Super Bowl MVP, despite being on the losing team, but Howley initially refused to accept the award because he stated that it was meaningless to him since his team lost. He reluctantly accepted the honor since it included the awarding of a brand-new station wagon that he decided to use as a gift for his wife. During the game, Howley recorded two tackles and two interceptions, one of which he returned for 22 yards.\nDon McCafferty became the first rookie head coach to win a Super Bowl. The feat was not repeated until George Seifert led the San Francisco 49ers to victory in Super Bowl XXIV. McCafferty was also the first Super Bowl-winning coach who did not wear coat and tie, opting for a short-sleeved T-shirt with a mock turtleneck.\nThis Super Bowl would also start a trend with the team that lost the game would come back the next year and win it. Dallas lost this game but they would come back and win it all the next year in Super Bowl VI while their opponents, the Miami Dolphins, lost that game, and would go on to win Super Bowl VII the following season.\nTwo rule changes that were adopted before the 1974 season were: \nThese would have reduced the severity of the two Dallas offensive holding penalties in Super Bowl V.\nThis was the first and only Super Bowl where the Trophy presentation was done by somebody other than the commissioner, in this case, Marie Lombardi the wife of recently deceased coach Vince Lombardi. Super Bowl V also marked the debut of the newly renamed Vince Lombardi Trophy. Vince Lombardi died on September 3, 1970 and was to enter his 2nd season as the Washington Redskins head coach.\nBox score.\nSuper Bowl V: Baltimore Colts 16, Dallas Cowboys 13\n\"at Orange Bowl, Miami, Florida\nFinal statistics.\nSources:\"The NFL's Official Encyclopedic History of Professional Football\", (1973), p.\u00a0149, Macmillan Publishing Co. New York, NY, LCCN 73-3862, http://, https://, https://\nIndividual statistics.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n1Completions/attempts\n2Carries\n3Long gain\n4Receptions\n5Times targeted\nRecords set.\nThe following records were set or tied in Super Bowl V, according to the official NFL.com boxscore, the 2016 NFL Record &amp; Fact Book and the ProFootball reference.com game summary. Some records have to meet a required minimum number of attempts in order to be recognized. The minimums are shown (in parentheses).\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nTurnovers are defined as the number of times losing the ball on interceptions and fumbles.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nStarting lineups.\nSource:\n&lt;mark style=\"color:black;background:#FFCC00\"&gt;Hall of Fame\u2021&lt;/mark&gt;\nOfficials.\n\"Note: A seven-official system was not used until 1978, also back judge and field swapped titles in 1998.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29132", "revid": "44273096", "url": "https://en.wikipedia.org/wiki?curid=29132", "title": "Super Bowl VI", "text": "1972 Edition of the Super Bowl\nSuper Bowl VI was an American football game between the National Football Conference (NFC) champion Dallas Cowboys and the American Football Conference (AFC) champion Miami Dolphins to decide the National Football League (NFL) champion for the 1971 season. The Cowboys defeated the Dolphins by the score of 24\u20133, to win their first Super Bowl, which was the first professional sports championship ever won by a Texas-based team. The game was played on January 16, 1972, at Tulane Stadium in New Orleans, Louisiana, the second time the Super Bowl was played in that city. Despite the southerly location, it was unseasonably cold at the time, with the kickoff air temperature of making this the coldest Super Bowl played.\nDallas, in its second Super Bowl appearance, entered the game with a reputation of not being able to win big playoff games such as Super Bowl V and the 1966 and 1967 NFL Championship Games prior to the 1970 AFL\u2013NFL merger. They posted an 11\u20133 record during the 1971 regular season before defeating the Minnesota Vikings and the San Francisco 49ers in the playoffs. The Dolphins were making their first Super Bowl appearance after building a 10\u20133\u20131 regular season record, including eight consecutive wins, and posting postseason victories over the Kansas City Chiefs and the Baltimore Colts.\nThe Cowboys dominated Super Bowl VI, setting Super Bowl records for the most rushing yards (252), the most first downs (23), and the fewest points allowed (3). They were also the first NFL or NFC team to win the Super Bowl since the Green Bay Packers in Super Bowl II. For the next 47 years, they would be the only team to prevent their opponent from scoring a touchdown in the Super Bowl, a feat matched by the 2018 New England Patriots in Super Bowl LIII and again by the 2020 Tampa Bay Buccaneers in Super Bowl LV. The game was close in the first half, with the Cowboys only leading 10\u20133 at halftime. But Dallas opened the third quarter with a 71-yard, 8-play touchdown drive, and then Dallas linebacker Chuck Howley's 41-yard interception return in the fourth quarter set up another score. This was the first Super Bowl where the winning team outscored the losing team in all four quarters. Cowboys quarterback Roger Staubach, who completed 12 out of 18 passes for 119 yards, threw 2 touchdown passes, and rushed 5 times for 18 yards, was named the Super Bowl's Most Valuable Player.\nThis was the last Super Bowl to be blacked out in the TV market in which the game was played. Under the NFL's unconditional blackout rules at the time, the Super Bowl could not be broadcast locally even if the local team did not advance to the Super Bowl, and it was a sellout. The following year, the league changed their rules to allow games to be broadcast in the local market if sold out 72 hours in advance. It was the last Super Bowl played with the hashmarks (also called the inbound lines) set at 40 feet apart (20 yards from the sidelines), and the last NFL game overall; the next season, they were brought in to 18&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 feet, the width of the goalposts, where they remain.\nBackground.\nHost selection process.\nThe NFL awarded Super Bowl VI to New Orleans on March 23, 1971, at the owners meetings held in Palm Beach, Florida. Six cities submitted bids: Miami, Dallas, Jacksonville, New Orleans, Los Angeles, and Houston. It took fourteen ballots to finally select a winner. Miami and Dallas emerged as the heavy favorites. After thirteen deadlocked votes, support for both Dallas and Miami eroded after owners including Al Davis and Billy Sullivan noted that the Cowboys and Dolphins both were both favorites to reach the Super Bowl. They argued against a team having a potential competitive advantage of a home game for the Super Bowl. Owners compromised on the 14th vote and selected New Orleans. City representatives, namely those from Miami, argued that future votes involve awarding multiple Super Bowl sites at the same meeting. They also floated the idea of rotating the host city between AFC and NFC cities annually. This would provide the hosts with greater preparation time, and prevent them from having to prepare bids every year. The idea to vote on multiple Super Bowls was implemented the following year, but the AFC/NFC rotation was never implemented.\nDallas Cowboys.\nThe Cowboys entered the season still having the reputation of \"not being able to win the big games\" and \"next year's champion\". The Super Bowl V loss added more fuel to that widely held view. As in the previous season, Dallas had a quarterback controversy as Staubach and Craig Morton alternated as starting quarterback (in a loss to the Bears in game 7, Morton and Staubach alternated \"plays\"). The Cowboys were 4\u20133 at the season midpoint, including a 24\u201314 loss to the New Orleans Saints at Tulane Stadium. But after head coach Tom Landry settled on Staubach, the Cowboys won their last seven regular season games to finish with an 11\u20133 record.\nStaubach finished the regular season as the NFL's top rated passer (101.8) by throwing for 1,882 yards, 15 touchdowns, and only 4 interceptions. He was also a terrific rusher, gaining 343 yards and 2 touchdowns on 41 carries. Dallas also had an outstanding trio of running backs, Walt Garrison, Duane Thomas, and Calvin Hill, who rushed for a combined total of 1,690 yards and 14 touchdowns during the season. Garrison led the team in receptions during the season (40). (Thomas, upset that the Cowboys would not renegotiate his contract after his excellent rookie year, had stopped talking to the press and to almost everyone on the team). Wide Receivers Bob Hayes and Lance Alworth also provided a deep threat, catching a combined total of 69 passes for 1,327 yards and 10 touchdowns. The offensive line, anchored by all-pro tackle Rayfield Wright, Pro Bowlers John Niland and Ralph Neely, and future Hall of Famer Forrest Gregg, was also a primary reason for their success on offense. Neely had broken his leg in November in a dirt-bike accident, and was replaced first by Gregg and then by Tony Liscio, who came out of retirement.\nThe Dallas defense (nicknamed the \"Doomsday Defense\") had given up only one touchdown in the last 14 quarters prior to the Super Bowl. Their defensive line was anchored by Pro Bowl defensive tackle Bob Lilly, who excelled at pressuring quarterbacks and breaking up running plays. Dallas also had an outstanding trio of linebackers: Pro Bowler Chuck Howley, who recorded 5 interceptions and returned them for 122 yards; Dave Edwards 2 interceptions; and Lee Roy Jordan, who recorded 2 interceptions. The Cowboys secondary was led by 2 future Hall of Fame cornerbacks Herb Adderley (6 interceptions for 182 return yards) and Mel Renfro (4 interceptions for 11 yards). Safeties Cliff Harris and Pro Bowler Cornell Green combined for 4 interceptions. Harris added 29 kickoff returns for 823 yards, an average of 28.4 yards per return (3rd in the NFL). They were also helped out by weak side linebacker D.D. Lewis.\nMiami Dolphins.\nThe Dolphins, who advanced to the Super Bowl just five years after their founding in 1966, were based primarily around their league-leading running attack, led by running backs Larry Csonka and Jim Kiick. Csonka rushed for 1,051 yards, averaging over five yards per carry, and scored seven touchdowns. Versatile Jim Kiick rushed for 738 yards and three touchdowns, and was second on the Dolphins in receiving with 40 receptions for 338 yards. They fumbled once (by Kiick) between the two of them during the regular season. But Miami also had a threatening passing game. Quarterback Bob Griese, the AFC's leading passer and most valuable player, put up an impressive performance during the season, completing 145 passes for 2,089 yards and 19 touchdowns with only 9 interceptions. Griese's major weapon was wide receiver Paul Warfield, who caught 43 passes for 996 yards (a 23.2 yards per catch average) and a league-leading 11 touchdowns. The Dolphins also had an excellent offensive line to open up holes for their running backs and protect Griese on pass plays, led by future Hall of Fame guard Larry Little.\nMiami's defense was a major reason why the team built a 10\u20133\u20131 regular season record, including eight consecutive wins. Future Hall of Fame linebacker Nick Buoniconti was a major force reading and stopping plays, while safety Jake Scott recorded 7 interceptions and led the NFL in punt return yards with 318.\nPlayoffs.\nBefore this season, the Dolphins had never won a playoff game in franchise history, but they surprised the entire NFL by advancing to the Super Bowl with wins against the two previous Super Bowl champions. The Dolphins became the first of the four teams which had commenced play in the NFL or AFL after the start of the Super Bowl era to contest so much as a title game, let alone earn a berth in the world championship game.\nFirst Miami defeated the Kansas City Chiefs (winners of Super Bowl IV), 27\u201324, in the longest game in NFL history with kicker Garo Yepremian's game-winning field goal after 22 minutes and 40 seconds of overtime play in the final Chiefs game at Municipal Stadium. Later, Miami shut out the defending Super Bowl champion Baltimore Colts, 21\u20130, in the AFC Championship Game, with safety Dick Anderson intercepting 3 passes from Colts quarterback Johnny Unitas and returning one of them for a 62-yard touchdown.\nMeanwhile, the Cowboys marched to the Super Bowl with playoff wins over the Minnesota Vikings, 20\u201312 in the NFC Divisional Playoffs, and the San Francisco 49ers, 14\u20133 in the NFC Championship Game, giving up only one touchdown in the two games.\nSuper Bowl pregame news and notes.\nSoon after the Dolphins' win in the AFC Championship Game, Shula received a phone call at his home from President Richard Nixon at 1:30 in the morning. Nixon had a play he thought would work, a particular pass to Warfield. (That particular play, which was called late in the first quarter, was broken up by Mel Renfro.)\nWhen asked about the Dolphins' defensive team prior to Super Bowl VI, Landry said that he could not recall any of the players' names, but they were a big concern to him. Over the years this remark has been regarded as the origin of the nickname \"No-Name Defense\". However, it was Miami defensive coordinator Bill Arnsparger who had originally given his squad the nickname after the Dolphins had beaten the Baltimore Colts in the AFC Championship.\nAccording to Tom Landry, the Cowboys were very confident. \"When they talked among themselves they said there was no way they were going to lose that game.\"\nThe Cowboys used the New Orleans Saints' practice facility in Metairie as its training headquarters for the game. The Dolphins split their practices between Tulane Stadium and Tad Gormley Stadium in New Orleans' City Park. Dallas' team hotel was the Hilton across from New Orleans International Airport in Kenner, and Miami lodged at the Fontainebleau Motor Hotel in New Orleans' Mid-City neighborhood.\nOn Media Day, Duane Thomas refused to answer any questions and sat silently until his required time was up. Roger Staubach surmises that Duane Thomas would have been named MVP if he had cooperated with the press prior to the game. In the Cowboys' locker room after the game, flustered CBS reporter Tom Brookshier asked Duane Thomas a long-winded question, the gist of which was \"You're fast, aren't you?\" Thomas, who had shunned the press all season, simply said \"Evidently.\" Thomas became the first player to score touchdowns in back-to-back Super Bowls, having a receiving touchdown in Super Bowl V.\nDolphins safety Jake Scott entered Super Bowl VI with a broken left hand. He broke his right wrist during the game but never came out. With both hands in casts for three months, he said \"When I go to the bathroom, that's when I find out who my real friends are.\"\nThis was the first Super Bowl to match two teams which played its home games on artificial turf. Both of the Cowboys' home stadiums of 1971, the Cotton Bowl and Texas Stadium, had turf, as did the Dolphins' Orange Bowl (specifically Poly-Turf). The previous year, the Cowboys became the first team to play its home games on turf to make it to a Super Bowl.\nIt was hoped the Louisiana Superdome would be ready in time for the 1972 NFL season (had construction stayed on schedule, it is likely this game would have been played elsewhere, with either Super Bowl VII or Super Bowl VIII awarded to New Orleans). However, wrangling between labor unions and Louisiana politicians, led by Governor John McKeithen, led to a lengthy delay in construction, and groundbreaking did not take place until August 11, 1971, five months before this game. The Superdome was not completed until August 1975, forcing Super Bowl IX to be moved to Tulane Stadium. That Super Bowl proved to be the final NFL game in the stadium, which was demolished in late 1979.\nThe night before the game, Joe Frazier successfully defended his heavyweight boxing championship with a fourth-round knockout of Terry Daniels (at the time of the fight, a student at Dallas' Southern Methodist University) at the Rivergate Convention Center (now Caesar's Palace New Orleans), which was one mile south of the construction site for the Superdome on Poydras Street. The next day, the Rivergate hosted a closed-circuit television broadcast of the game, charging $10 per person.\nThe temperature at kickoff was a sunny and windy , making this the coldest Super Bowl to date.\nThis was the final Super Bowl where both teams' head coaches (Landry of the Cowboys, Shula of the Dolphins) wore suits.\nBroadcasting.\nThe game was broadcast in the United States by CBS with play-by-play announcer Ray Scott and color commentator Pat Summerall. Jack Whitaker hosted the pregame show, and Tom Brookshier conducted locker room interviews post-game. \nAlthough Tulane Stadium was sold out for the game, unconditional blackout rules in the NFL prohibited the live telecast from being shown in the New Orleans area. This was the last Super Bowl to be blacked out in the TV market in which the game was played (the NFL allowed WWL to air the game on tape delay at midnight). The game was not blacked out in Baton Rouge, which was blacked out during Saints home games. The following year, the NFL allowed Super Bowl VII to be televised live in the host city (Los Angeles) when all tickets were sold. In 1973, the league changed its blackout policy to allow any game to be broadcast in the home team's market if sold out 72 hours in advance. The blackout rule has been suspended since 2015.\nThis game was featured in the movie \"Where the Buffalo Roam\" where the protagonist character Hunter S. Thompson is sent to cover the game by \"Rolling Stone\" magazine, although the host site set in the movie is Los Angeles Memorial Coliseum (site of Super Bowl VII), not Tulane Stadium.\nExcept for a portion of the Cowboys first scoring drive and the Dolphins only scoring drive (both drives ended with field goals), the complete original broadcast exists.\nIn popular culture.\nThis game was featured in the movie \"Where the Buffalo Roam\" where the protagonist character Hunter S. Thompson is sent to cover the game by \"Rolling Stone\" magazine, although the host site set in the movie is Los Angeles Memorial Coliseum (site of Super Bowl VII), not Tulane Stadium.\nEntertainment.\nThe Tyler Junior College Apache Belles drill team performed during the pregame and halftime festivities. Later, the U.S. Air Force Academy Chorale sang the national anthem. This was followed by an eight-plane flyover of F-4 Phantoms from Eglin Air Force Base, which featured a plane in the missing man formation.\nDespite being the second Super Bowl after the AFL\u2013NFL merger, Super Bowl VI was the first one to have the NFL logo painted at the 50-yard line. The NFL would do this for all but one Super Bowl after this until Super Bowl XXXI (the exception was Super Bowl XXV, when the Super Bowl logo was painted at midfield instead).\nHalftime show.\nThe Super Bowl VI halftime show was themed as a \"Salute to Louis Armstrong\" (Armstrong, a New Orleans native, died in July 1971). Headlining the show were jazz singer Ella Fitzgerald, actress and singer Carol Channing, trumpeter Al Hirt and the U.S. Marine Corps Drill Team. Also performing were the Onward Brass Band with Danny Barker, and young Leroy Jones as \"Little Louis Armstrong\".\nFitzgerald was the first Black woman to sing in a Super Bowl halftime show. She is also considered to be the first jazz artist featured in such a manner in a Super Bowl halftime show.\nThis was the second of three Super Bowl halftime shows in which Al Hirt was a headlining performer. Hirt, a minority shareholder of the New Orleans Saints, had previously been among the headlining performers in the halftime shows of Super Bowl I, and would subsequently be a headlining performer in the halftime show of Super Bowl XII. Also returning to the Super Bowl halftime stage was Carol Channing, who had previously been a performer in the halftime show of Super Bowl IV.\nIn the show, the Onward Brass Band performed \"High Society\" and accompanied Carol Channing in performing \"Hello, Dolly!\". Al Hirt accompanied Ella Fitzgerald in performing \"Mack the Knife\".\nGame summary.\nAccording to Roger Staubach, the Cowboys' game plan was to neutralize the Dolphins' key offensive and defensive players\u2014Paul Warfield and Nick Buoniconti. Warfield was double-teamed by Green and Renfro. \"They pretty much shut him down\", wrote Staubach. Since the running game was the key to the Cowboys' offense, they wanted to take the quick-reacting Buoniconti out of each play. Two linemen, usually Niland and center Dave Manders, were assigned to block Buoniconti. Combined with counterplays and the excellent cutback running of Thomas, this tactic proved very successful. Buoniconti sustained a concussion which he suffered from throughout the second half, during which he did not keep track of the score, thinking it was still 10\u20133 when it had become 24\u20133.\nMiami's defense was designed to stop Staubach's scrambling. According to Staubach, although his scrambling was shut down this did not work to the Dolphins' benefit because it opened things up for the other backs.\nFirst quarter.\nMiami won the coin toss and elected to receive. Neither team could mount a drive on their first possessions. On the first play of the Dolphins' second possession, fullback Larry Csonka, on his first carry of the game, gained 12 yards on a sweep aided by a big block by guard Larry Little on cornerback Herb Adderley. It would be his longest gain of the day. On the next play, Csonka fumbled a handoff from quarterback Bob Griese, his first fumble of the season, and it was recovered by linebacker Chuck Howley at the Cowboys' 48-yard line. A pair of runs for 18 total yards by fullback Walt Garrison put Dallas within field goal range, but on the next play, defensive tackle Bob Heinz and defensive end Jim Riley shared a sack on quarterback Roger Staubach for a 12-yard loss. However, Staubach found Bob Hayes open for an 18-yard pass and completed an 11-yard pass to running back Duane Thomas to bring up 1st-and-goal at Miami's 7-yard line. The Dolphins' defense managed to keep the Cowboys out of the end zone, forcing them to settle for kicker Mike Clark's 9-yard field goal to give the Cowboys a 3\u20130 lead.\nOn the third play of the Dolphins' next possession at their own 38-yard line, Griese was sacked by Cowboys defensive tackle Bob Lilly for a Super Bowl record 29-yard loss, which still stands as the longest negative play from scrimmage in Super Bowl history.\nSecond quarter.\nTo start the second quarter, Dolphins punter Larry Seiple punted the ball from Miami's own end zone, which was caught at the Dallas 45 by Hayes. The Cowboys could not get past the Miami 40, so they punted it back to the Dolphins. Miami drove to the Cowboys' 42-yard line with the aid of a 20-yard reception by wide receiver Howard Twilley, but the drive stalled and ended with no points after kicker Garo Yepremian missed a 49-yard field goal attempt.\nAfter an exchange of punts, starting with 6:15 left in the half, Dallas drove 76 yards in 10 plays, including a 21-yard reception on 3rd-and-9 by wide receiver Lance Alworth and running back Calvin Hill's three carries for 25 yards. The drive ended with Staubach's 7-yard touchdown pass to Alworth to increase Dallas' lead to 10\u20130 (Alworth would refer to the receptions that he made on the scoring drive as \"The two most important catches of his career\"). Miami started the ensuing drive at their own 31-yard line with just 1:15 left in the half, and Griese completed three consecutive passes, two to wide receiver Paul Warfield and one to running back Jim Kiick, for 44 total yards to reach the Dallas 24-yard line. Despite their excellent field position, the Dolphins could not reach the end zone and had to settle for Yepremian's 31-yard field goal to cut their deficit to 10\u20133 going into halftime.\nThird quarter.\nThe Cowboys shut out the Dolphins in the second half, preventing any chance of a Miami comeback. Dallas reasoned that Miami would make adjustments to stop the Cowboys' inside running game which had been so successful in the first half. So the Cowboys decided to run outside. The Cowboys opened the third quarter with a 71-yard, 8-play scoring drive, which included a 12-yard reception by Hill, four runs by Thomas for 37 yards, and a 16-yard run by Hayes. Thomas ended the drive with his 3-yard touchdown run to increase Dallas' lead to 17\u20133. This seemed to fire up the Cowboys' defense, who managed to prevent the Dolphins' offense from getting a single first down in the entire third quarter. The farthest advance Miami had in the third quarter was to their own 42-yard line as Griese and the offense were, as Dolphins coach Don Shula put it, \"destroyed.\" Three possessions later, on an incomplete pass on third down, Dolphins safety Jake Scott hit Staubach on a blitz that shook him up with under two minutes remaining in the period, but Staubach returned in the fourth.\nFourth quarter.\nMiami managed to advance to midfield early in the final period, opening the fourth quarter with their first third down conversion of the game. Howley ended the drive, however, by intercepting a pass from Griese intended for Kiick. After returning the ball 41 yards, Howley tripped and fell at the Dolphins' 9-yard line with no one near him. He then got up and spiked the ball out of frustration for not scoring a touchdown. But three plays later, Dallas capitalized on the turnover with Staubach's 7-yard touchdown pass to tight end Mike Ditka, increasing their lead to 24\u20133 with 12 minutes left in the game.\nMiami began their next possession at their own 23-yard line and mounted only their third sustained drive of the game, reaching the Dallas 16-yard line in six plays, which included a 16-yard reception by Csonka and two receptions by tight end Marv Fleming for 37 yards. However, when Miami reached the Dallas 16, Griese fumbled the snap, and defensive end Larry Cole recovered it at the 20-yard line. The Cowboys then mounted an 11-play drive to the Miami 1-yard line which featured a 22-yard reception by Ditka, an 18-yard run by Garrison, and a 4th-and-1 conversion by running back Dan Reeves on a fake field goal attempt at the Miami 20-yard line, which was followed by a 17-yard run by Ditka to set up 1st-and-goal at the Miami 1-yard line (the victory formation, where the quarterback kneels to run down the clock, was not introduced in the NFL until late in the 1978 season following the Miracle at the Meadowlands). On the next play, however, Hill fumbled the ball while attempting to dive into the end zone, and the ball was recovered at the 4-yard line by Dolphins defensive tackle Manny Fernandez with just under two minutes left. Miami, now playing for pride, ran four meaningless plays and reached their own 26-yard line to end the game.\nAftermath.\nStaubach became the first quarterback of a winning team in the Super Bowl to play the entire game. Wrote Staubach, \"I can say that I don't think I ever felt any better as an athlete than how I felt after that game...\" Nick Buoniconti wrote, \"I was knocked senseless...The Cowboys seemed to be moving so much faster than we were...We were overmatched psychologically as well as physically.\" Jim Kiick said, \"Dallas wasn't that much better, but football is momentum. We lost it in the first quarter when we fumbled and they scored, and we never got it back.\" Said the Dolphins' Howard Twilley:\nIt's so hard to figure. We went in confident. We really thought we'd win and win handily. Something happened, though, during the week. I guess it was that week. The week has its own momentum, like nothing we'd been in before...[Shula] said we'd been embarrassed. He said we didn't even compete...That's the sickest feeling I've ever had.\nSaid Cornell Green, \"The difference between the Dolphins and Cowboys was that the Dolphins were just happy to be in the game and the Cowboys came to win the game.\".\nGriese completed the same amount of passes as Staubach (12), and threw for 15 more yards (134), but threw no touchdown passes and was intercepted once. Csonka and Kiick were held to just 80 combined rushing yards (40 yards each), scored no touchdowns, and lost 1 fumble on 19 carries. Warfield was the game's leading receiver, but was limited to just 4 receptions for 39 yards. Thomas was the top rusher of the game with 19 carries for 95 yards and a touchdown. He also caught 3 passes for 17 yards. Dallas running back Walt Garrison added 74 rushing yards and caught 2 passes for 11 yards.\nThe Dallas Cowboys became the first team to win the Super Bowl after losing it the previous year. The Miami Dolphins would duplicate this feat the following season by winning Super Bowl VII. This would be the only game the Dolphins would lose in 1972, going undefeated the next season prior to their Super Bowl VII win. Miami's 3 points scored set a Super Bowl record in scoring futility, which was tied by the Los Angeles Rams in Super Bowl LIII in 2019. The Kansas City Chiefs also failed to score a touchdown in their 31\u20139 loss to the Tampa Bay Buccaneers in Super Bowl LV in February 2021.\nBox score.\nSuper Bowl VI: Dallas Cowboys 24, Miami Dolphins 3\n\"at Tulane Stadium, New Orleans, Louisiana\nFinal statistics.\nSources:\"The NFL's Official Encyclopedic History of Professional Football\", (1973), p.\u00a0153, Macmillan Publishing Co. New York, LCCN 73-3862, http://, https://, https://, http://\nIndividual statistics.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n1Completions/attempts\n2Carries\n3Long gain\n4Receptions\n5Times targeted\nRecords set.\nThe following records were set or tied in Super Bowl VI, according to the official NFL.com boxscore and the ProFootball reference.com game summary. Some records have to meet NFL minimum number of attempts to be recognized. The minimums are shown (in parentheses).\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nTurnovers are defined as the number of times losing the ball on interceptions and fumbles.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nStarting lineups.\nSource:\n&lt;mark style=\"color:black;background:#FFCC00\"&gt;Hall of Fame \u2021&lt;/mark&gt;\nOfficials.\n&lt;br&gt;\nAll on-field officials except Vandenberg were on the crew for Super Bowl XII, the first Super Bowl at the Superdome. \n&lt;br&gt;\nBernie Ulman was the referee for Super Bowl IX, the last professional football game played at Tulane Stadium. \n&lt;br&gt;\n\"Note: A seven-official system was not used until the 1978 season\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29133", "revid": "38104346", "url": "https://en.wikipedia.org/wiki?curid=29133", "title": "Super Bowl VII", "text": "1973 Edition of the Super Bowl\nSuper Bowl VII was an American football game between the American Football Conference (AFC) champion Miami Dolphins and the National Football Conference (NFC) champion Washington Redskins to decide the National Football League (NFL) champion for the 1972 season. The Dolphins defeated the Redskins by the score of 14\u20137, winning their first Super Bowl, and became the first and still the only team in modern NFL history to complete a perfect undefeated season. They also remain the only Super Bowl champion to win despite having been shut out in the second half of the game. This was the first professional sports championship ever won by a Florida-based team. The game was played on January 14, 1973, at the Los Angeles Memorial Coliseum in Los Angeles, the second time the Super Bowl was played in that city. At kickoff, the temperature was , making the game the warmest Super Bowl.\nThis was the Dolphins' second Super Bowl appearance; they had lost Super Bowl VI to Dallas the previous year. The Dolphins posted an undefeated 14\u20130 regular season record before defeating the Cleveland Browns and Pittsburgh Steelers in the playoffs. The Redskins were making what would be the first of five Super Bowl appearances in a 20-year period, after posting an 11\u20133 regular season record and playoff victories over the Green Bay Packers and Dallas Cowboys. Despite being undefeated, the Dolphins were actually one-point underdogs, largely based on the weakness of their regular season schedule (and losing the previous Super Bowl).\nSuper Bowl VII was largely dominated by the Dolphins, and is the second-lowest-scoring Super Bowl to date with a total of only 21 points (three touchdowns and three extra points), behind only the 13\u20133 score of Super Bowl LIII. The only real drama occurred during the final minutes of the game, in what was later known as \"Garo's Gaffe\". Miami attempted to cap their 17\u20130 perfect season with a 17\u20130 shutout by means of a 42-yard field goal by Garo Yepremian, but instead the game and the season was jeopardized when his kick was blocked. Instead of falling on the loose ball, the Dolphins kicker picked it up, attempted a forward pass, but batted it in the air, and Redskins cornerback Mike Bass (who was Yepremian's former teammate on the Detroit Lions years earlier) caught it and returned it 49 yards for a touchdown. This remains the longest period in a Super Bowl for one team to be shut out, as Washington was held scoreless until 2:07 remained in the fourth quarter. Because of the turnover and score, what was a Miami-dominated game became close, and the Dolphins had to stop Washington's final drive for the tying touchdown as time expired.\nDolphins safety Jake Scott was named Most Valuable Player. He recorded two interceptions for 63 return yards, including a 55-yard return from the end zone during the fourth quarter. Scott became the second defensive player in Super Bowl history (after linebacker Chuck Howley in Super Bowl V) to earn a Super Bowl MVP award.\nBackground.\nHost selection process.\nThe NFL awarded Super Bowl VII to Los Angeles on March 21, 1972, at the owners' meetings held in Honolulu. For the first time, multiple Super Bowl sites were selected at a single meeting, as hosts for both VII and VIII were named. Five cities, Los Angeles, Houston, Miami, Dallas, and New Orleans, prepared serious bids, while San Francisco (Stanford Stadium) withdrew from the running a week prior to the vote. After nine deadlocked votes, Bud Adams recommended awarding two consecutive sites. This compromise mirrored an idea brought up in 1971 by representatives from Miami. Los Angeles won on the ninth ballot, while second place Houston was named the host for VIII. In order to accommodate the game, the Pro Bowl was shifted from Los Angeles Memorial Coliseum to Texas Stadium for 1973.\nMiami Dolphins.\nThe Dolphins went undefeated during the season, despite losing their starting quarterback. In the fifth game of the regular season, starter Bob Griese suffered a fractured right leg and dislocated ankle. In his place, 38-year-old Earl Morrall, a 17-year veteran, led Miami to victory in their nine remaining regular season games, and was the 1972 NFL Comeback Player of the Year. Morrall had previously played for Dolphins head coach Don Shula when they were both with the Baltimore Colts, where Morrall backed up quarterback Johnny Unitas and started in Super Bowl III.\nBut Miami also had the same core group of young players who had helped the team advance to the previous year's Super Bowl VI. (The only Dolphins starter in Super Bowl VII over the age of 30 was 32-year-old Nick Buoniconti.) The Dolphins still had a powerful running attack, spearheaded by running backs Larry Csonka, Jim Kiick and Eugene \"Mercury\" Morris. (Morris, who in previous seasons had been used primarily as a kick returner, took over the starting halfback position from Kiick, who had been the starter the previous four years. However, the more-experienced Kiick would start in Super Bowl VII.) Csonka, who had the best season of his career, led the team with 1,117 yards and six touchdowns. Kiick contributed 521 yards and five touchdowns, and also caught 21 passes for 147 yards and another touchdown. Morris, a breakaway runner, rushed for exactly 1,000 yards, caught 15 passes for 168 yards, added another 334 yards returning kickoffs, and scored a league-leading 12 rushing touchdowns. Overall, Miami set a record with 2,960 total rushing yards during the regular season, and became the first team ever to have two players rush for 1,000 yards in one season. Miami led the NFL in points scored (385). Since 1972, only six other teams have had two 1,000 yard rushers in the same backfield, but the Dolphins are the only one of those seven to make it to and win the Super Bowl.\nReceiver Paul Warfield once again provided the run-based Dolphins with an effective deep-threat option, catching 29 passes for 606 yards, an average of 20.9 yards per catch. Miami's offensive line, led by undrafted future Hall of Famers Jim Langer and Larry Little, was also a key factor in the Dolphins' offensive production. Miami's \"No-Name Defense\" (a nickname inspired by Dallas Cowboys head coach Tom Landry when he could not recall the names of any Dolphins defenders just before Super Bowl VI), led by future Hall of Fame linebacker Nick Buoniconti, allowed the fewest points in the league during the regular season (171), and ranked second in the NFL with 26 interceptions. Safety Jake Scott recorded five interceptions, while Lloyd Mumphord had four picks and safety Dick Anderson had three interceptions and led the NFL with five fumble recoveries. Because of injuries to defensive linemen (at the beginning of the season the Dolphins were down to four healthy players at the position), defensive coordinator Bill Arnsparger created what he called the \"53\" defense, in which the versatile Bob Matheson (number 53) would be used as either a defensive end in the standard 4\u20133 defense or as a fourth linebacker in a 3\u20134 defense, with Manny Fernandez at nose tackle. As a linebacker, Matheson would either rush or drop back into coverage. Said Nick Buoniconti, \"Teams would be totally confused.\" Linebacker Doug Swift was also a playmaker with three interceptions and a fumble recovery.\nThe Dolphins' undefeated, untied regular season was the third in NFL history, and the first of the post-merger era. The previous two teams to do so, the 1934 and 1942 Chicago Bears, both lost the NFL Championship game. Later, the 2007 New England Patriots became the 4th team to complete an undefeated and untied regular season, but lost to the New York Giants in Super Bowl XLII. The Cleveland Browns also completed a perfect season in 1948, including a league championship, while part of the All-America Football Conference (AAFC), but until April 1, 2025 this feat was recognized only by the Pro Football Hall of Fame, since the NFL did not officially recognize any AAFC records.\nWashington Redskins.\nFollowing the death of Redskins head coach Vince Lombardi 17 days prior to the start of the 1970 season, Washington finished 6\u20138 under interim coach Bill Austin. Shortly after the conclusion of the 1970 season, the Redskins hired George Allen as their head coach, hoping he could turn the team's fortunes around. Allen's philosophy was that veteran players win games, so immediately after taking over the team, he traded away most of the younger team members and draft choices for older, more established players. His motto was \"The future is now.\" Washington quickly became the oldest team in the NFL and earned the nickname \"The Over-the-Hill Gang.\" The average age of starters was 31 years old. However, Allen's strategy turned the Redskins around, as the team improved to a 9\u20134\u20131 record in 1971, and finished the 1972 season with an NFC-best 11\u20133 record.\nWashington was led by 33-year-old quarterback Billy Kilmer, who completed 120 out of 225 passes for 1,648 yards and a league-leading 19 touchdowns during the regular season, with only 11 interceptions, giving him an NFL-best 84.8 passer rating. Kilmer had started the first three games of the season, was replaced in Game 4 by 38-year-old Sonny Jurgensen, then replaced Jurgensen when he was lost for the season with an Achilles tendon injury. The Redskins' powerful rushing attack featured two backs. Larry Brown gained 1,216 yards (first in the NFC and second in the NFL, behind only O. J. Simpson's 1,251 rushing yards) on 285 carries during the regular season, caught 32 passes for 473 yards and scored 12 touchdowns, earning him both the NFL Most Valuable Player Award and the NFL Offensive Player of the Year Award. Charley Harraway ran for 567 yards on 148 carries. Future Hall of Fame wide receiver Charley Taylor and wide receiver Roy Jefferson provided the team with a solid deep threat, combining for 84 receptions, 1,223 receiving yards and 10 touchdowns. Veteran tight end Jerry Smith added 21 receptions for 353 yards and 7 touchdowns.\nWashington also had a solid defense led by linebacker Chris Hanburger (four interceptions, 98 return yards, one touchdown) and cornerbacks Pat Fischer (four interceptions, 61 return yards) and Mike Bass (three interceptions, 53 return yards)\nPlayoffs.\nMorrall led the Dolphins to a 20\u201314 playoff win over the Cleveland Browns. However, Griese started the second half of the AFC Championship Game to help rally the Dolphins to a 21\u201317 victory over the Pittsburgh Steelers. A fake punt by Miami's Larry Seiple made the difference.\nMeanwhile, the Redskins advanced to the Super Bowl without having allowed a touchdown in either their 16\u20133 playoff win over the Green Bay Packers or their crushing 26\u20133 NFC Championship Game victory over the Cowboys, the defending Super Bowl champions.\nSuper Bowl pregame news and notes.\nMuch of the pregame hype surrounded the chances of the Dolphins completing a perfect, undefeated season, as well as their quarterback controversy between Griese and Morrall. Griese was eventually picked to start the Super Bowl because Shula felt more comfortable with Morrall as the backup just in case Griese was ineffective following his recent inactivity. Miami was also strongly motivated to win the Super Bowl after having been humiliated by the Dallas Cowboys in Super Bowl VI. Wrote Nick Buoniconti, \"There was no way we were going to lose the Super Bowl; there was no way.\" Head coach Don Shula, loser of Super Bowls III and VI, was also determined to win. Although Shula was relaxed and charming when dealing with the press, it was all an act; Dolphins players described him as \"neurotic\" and \"absolutely crazy.\" He was also sick during Super Bowl week with the flu, which he kept secret.\nStill, many favored the Redskins to win the game because of their group of \"Over the Hill Gang\" veterans, and because Miami had what some considered an easy schedule (only two opponents, Kansas City and the New York Giants, posted winning records, and both of those teams were 8\u20136). This is reflected in the regular season standings where Miami ended the regular season 7 games in front of the Buffalo Bills in the AFC East while Washington barely won the NFC East winning the division over the Dallas Cowboys by one game. and had struggled in the playoffs. In the playoffs, Miami trailed in the second half of both contests needing a 4th quarter comeback against the Browns in the Divisional round and a quarterback change in the AFC Championship against the Steelers. Washington easily beat their playoff opponents holding both to a field goal.\nAllen had a reputation for spying on opponents. A school overlooked the Rams facility that the NFL designated as the Dolphins practice field, so the Dolphins found a more secure field at a local community college. Dolphins employees inspected the trees every day for spies.\nMiami cornerback Tim Foley, a future broadcaster who was injured and would not play in Super Bowl VII, was writing daily stories for a Miami newspaper and interviewed George Allen and his players, provoking charges from Allen that Foley was actually spying for Shula.\nAllen was extremely uptight and prickly dealing with the press Super Bowl week, and accused the press of ruining his team's preparation. Allen pushed the team so hard in practices that the players joked among themselves that they should have left Allen in Washington.\nDuring practice the day before Super Bowl VII, the Dolphins' 5'7\" 150-pound kicker, Garo Yepremian, relaxed by throwing 30-yard passes to Dave Shula, Don Shula's son. During the pregame warmups, he consistently kicked low line drives and couldn't figure out why.\nThis was the first Super Bowl in which neither coach wore a tie. Shula wore a coat and tie for Super Bowl VI, but wore a white short-sleeved polo shirt for this game, as did Allen. For Super Bowl VIII, Shula would wear a sport coat, but with a shirt underneath that was similar to the one he wore in Super Bowl VII. This was the warmest Super Bowl on record with a kickoff temperature of .\nThe American flag in the east end of the Coliseum flew at half-mast in memory of former President Harry S. Truman, who died December 26, 1972. Richard Nixon declared the traditional 30-day mourning period following the death of a president later that day.\nBroadcasting.\nThe game was broadcast in the United States by NBC with play-by-play announcer Curt Gowdy, color commentator Al DeRogatis and sideline reporter Bill Enis; who also covered the Trophy presentation, with other contributors including Kyle Rote. This was Enis' final Super Bowl telecast before his death on December 14, 1973, as well as Rote's last Super Bowl before leaving broadcasting and DeRogatis' first Super Bowl as lead color commentator (and only Super Bowl as the solo analyst).\nThis was the first Super Bowl to be televised live in the city in which it was being played, via NBC's flagship station in Los Angeles, KNBC (Channel 4). Despite unconditional blackout rules in the NFL that normally would have prohibited the live telecast from being shown locally, the NFL allowed the game to be telecast in the Los Angeles area on an experimental basis when all tickets for the game were sold. The league then changed its blackout rules the following season to allow any game sold out at least 72 hours in advance to be televised in the host market. No subsequent Super Bowl has ever been blacked out under this rule, as all have been sold out (owing to its status as the marquee event on the NFL schedule, meaning that tickets sell out quickly).\nBecause of Super Bowl VII, NBC was forced to delay its broadcast of Elvis Presley's \"Aloha from Hawaii\" concert, which took place the same day and was intended to be broadcast around the world live. NBC eventually re-edited the concert and aired it later that April.\nThis game is featured on \"NFL's Greatest Games\" under the title \"17\u20130\".\nEntertainment.\nThe pregame show was a tribute to Apollo 17, the sixth and last mission to land on the Moon and the final one of Project Apollo. The show featured the Michigan Marching Band and the crew of Apollo 17 who exactly one month earlier had been the final humans to date to leave the Moon. The Apollo 17 crew also recited the final Pledge of Allegiance in Super Bowl history.\nLater, the Little Angels of Chicago's Angels Church from Chicago performed the national anthem.\nHalftime show.\nThe halftime show, featured Woody Herman and the Michigan Marching Band along with The Citrus College Singers and Andy Williams, was titled \"Happiness Is\". The show was produced by Tommy Walker.\nSetlist.\nPartial setlist:\nGame summary.\nAccording to Shula, the Dolphins' priority on defense was to stop Larry Brown and force Billy Kilmer to pass. Buoniconti looked at Washington's offensive formation on each play and shifted the defense so it was strongest where he felt Brown would run. This strategy proved successful. Washington's offensive line also had trouble handling Dolphins' defensive tackle/nose tackle Manny Fernandez, who was very quick. \"He beat their center Len Hauss like a drum\", wrote Buoniconti. Miami's defenders had also drilled in maintaining precise pursuit angles on sweeps to prevent the cut-back running that Duane Thomas had used to destroy the Dolphins in Super Bowl VI.\nWashington's priority on defense was to disrupt Miami's ball-control offense by stopping Larry Csonka. They also intended to shut down Paul Warfield by double-covering him.\nWith a game-time kickoff temperature of , this is the warmest Super Bowl to date. It came the year after the coldest game in Super Bowl VI which registered a temperature at kickoff of .\nFirst quarter.\nAs they did in Super Bowl VI, Miami won the toss and elected to receive. Most of the first quarter was a defensive battle with each team punting on their first two possessions. The Dolphins would, however, get two key breaks. Offensive tackle Howard Kindig appeared to fumble the snap on their first punt from the Miami 27 and lose the ball to Washington linebacker Harold McLinton, but McLinton was called for slapping at the ball while it was being snapped, for a 5-yard penalty. On the replay of the down, Miami punter Larry Seiple got the kick away safely. Later, after stopping the Redskins for the second time, Dolphins safety Jake Scott did not call for a fair catch, as he had not been told to do so by safety Dick Anderson. Scott fumbled the ball while taking a hit by Redskins cornerback Ted Vactor, but Anderson made the recovery. Miami then started this drive on their own 37-yard line with 2:55 left in the first quarter. Running back Jim Kiick started out the drive with two carries for 11 yards. Then quarterback Bob Griese completed an 18-yard pass to wide receiver Paul Warfield to reach the Washington 34-yard line. After two more running plays, Griese threw a 28-yard touchdown pass (his longest completion of the game) to wide receiver Howard Twilley for his only catch of the game. Twilley fooled cornerback Pat Fischer by faking a route to the inside, then broke to the outside and caught the ball at the 5-yard line, dragging Fischer with him into the end zone. \"Griese read us real good all day\", said Fischer. Kicker Garo Yepremian's extra point gave the Dolphins a 7\u20130 lead with one second remaining in the period. (Yepremian noticed that the kick was too low, just like his practice kicks).\nSecond quarter.\nOn the third play of the Redskins' ensuing drive, Scott intercepted Redskins quarterback Billy Kilmer's pass down the middle intended for wide receiver Charley Taylor and returned it 8 yards to the Washington 47-yard line. However, a 15-yard ineligible player downfield penalty on the Dolphins nullified Greise's 20-yard pass to tight end Marv Fleming on the first play after the turnover, and the Dolphins were forced to punt after a three-and-out.\nAfter the Redskins were forced to punt again, Miami reached the 47-yard line with a 13-yard run by fullback Larry Csonka and an 8-yard run by Kiick. But on the next play, Griese's 47-yard touchdown pass to Warfield was nullified by an illegal formation penalty on Miami's offensive line. On third down, Redskins defensive tackle Diron Talbert sacked Griese for a 6-yard loss and the Dolphins had to punt.\nThe Redskins then advanced from their own 17-yard line to the Miami 48-yard line (their first incursion into Miami territory) with less than two minutes left in the half. But on 3rd-and-3, Dolphins linebacker Nick Buoniconti intercepted a pass by Kilmer at the Miami 41-yard line and returned it 31 yards to the Washington 28-yard line. From there, Kiick and Csonka each ran once for three yards, and then Griese completed a 19-yard pass (his sixth completion in six attempts) to tight end Jim Mandich, who made a diving catch at the 2-yard line. Two plays later, Kiick scored on a 1-yard touchdown run with a block by Csonka, guard Larry Little, and offensive tackle Norm Evans with just 18 seconds left in the half, giving the Dolphins a lead of 14\u20130 before halftime (once again, Yepremian noticed his extra point kick was too low).\nMiami's defense dominated the Redskins in the first half, limiting Washington to 49 yards rushing, 23 yards passing, and four first downs.\nThird quarter.\nThe Redskins had more success moving the ball in the second half. They took the second half kickoff and advanced across midfield for only the second time in the game, driving from their own 29-yard line to Miami's 17-yard line in a seven-play drive that featured just two runs. On first down at Miami's 17-yard line, Kilmer threw to Taylor, who was open at the 2-yard line, but Taylor stumbled right before the ball arrived and the ball glanced off his fingertips. After a second-down screen pass to fullback Charley Harraway fell incomplete, Dolphins defensive tackle Manny Fernandez sacked Kilmer on third down for a loss of 8 yards, and Washington's drive ended with no points after kicker Curt Knight's ensuing 32-yard field goal attempt sailed wide right. \"That was an obvious turning point\", said Allen. Three possessions later, the Dolphins drove 78 yards to Washington's 5-yard line, featuring a 49-yard run by Csonka, the second-longest run in Super Bowl history at the time. However, Redskins safety Brig Owens intercepted a pass intended for Fleming in the end zone for a touchback.\nFourth quarter.\nEarly in the fourth quarter, Washington threatened to score by mounting their most impressive drive of the game, driving 79 yards from their own 11 to Miami's 10-yard line in twelve plays. On second down at the Miami 10-yard line, Kilmer threw to Smith, who was wide open in the end zone, but the ball hit the crossbar of the goalpost and fell incomplete. Then on third down, Scott intercepted Kilmer's pass to Taylor in the end zone and returned it 55 yards to the Redskins 48-yard line.\nMiami moved the ball to the Washington 34-yard line on their ensuing drive. Leading 14\u20130 on 4th-and-4, Shula could have tried for a conversion, but thought \"What a hell of a way to remember this game\" if they could end a perfect 17\u20130 season with a 17\u20130 Super Bowl final score. He called on Yepremian to attempt a 42-yard field goal in what is now remembered as one of the most famous blunders in NFL lore: \"Garo's Gaffe\". As had been the case all day, Yepremian's kick was too low, and it was blocked by defensive tackle Bill Brundige. The ball bounced to Yepremian's right and he reached it before holder Earl Morrall. But instead of falling on the ball, Yepremian picked it up and, with Brundige bearing down on him, made a frantic attempt to pass the ball to Csonka, who blocked on field goals. Unfortunately for Miami, the ball slipped out of his hands and went straight up in the air. Yepremian attempted to bat the ball out of bounds, but instead batted it back up into the air, and it went right into the arms of cornerback Mike Bass, who returned the fumble 49 yards for a touchdown, the first fumble recovery returned for a touchdown in Super Bowl history, to make the score 14\u20137 with 2:07 left in the game.\nWashington did not try an onside kick following the touchdown, but instead kicked deep. The Redskins were forced to use up all of their timeouts on the Dolphins' ensuing five-play possession, but did force Miami to punt (nearly blocking the punt) from their own 36-yard line with 1:14 remaining in the game, giving themselves a chance to drive for the tying touchdown and force overtime for the first time in Super Bowl history. However, Miami's defense forced two incompletions and a 4-yard loss on a swing pass, and then defensive ends Vern Den Herder and Bill Stanfill sacked Kilmer for a 9-yard loss on fourth down, sealing the Dolphins' victory. Following the ball being spotted on the change of possession, the clock was started, as per the rule which existed at the time, and no more plays were run before time expired in the game. Beginning the following season with a new rule change, the clock would not start until the snap following all changes of possession.\nGriese finished the game having completed 8 out of 11 passes for 88 yards and a touchdown, with one interception. Csonka was the game's leading rusher with 15 carries for 112 yards. Kiick had 38 rushing yards, two receptions for six yards, and a touchdown. Morris had 34 rushing yards. Manny Fernandez had 11 solo tackles and six assists. Kilmer completed six more passes than Griese but finished the game with just 16 more total passing yards and was intercepted three times. Said Kilmer, \"I wasn't sharp at all. Good as their defense is, I still should have thrown better.\" Washington's Larry Brown rushed for 72 yards on 22 carries and also had five receptions for 26 yards. Redskins receiver Roy Jefferson was the top receiver of the game, with five catches for 50 yards. Washington amassed almost as many total yards (228) as Miami (253), and actually more first downs (16 to Miami's 12) and more time of possession (32:31 to 27:29). As of 2023, this game is the only Super Bowl where the team with the advantage in time of possession did not score any offensive points.\nDelayed White House visit.\nThe Dolphins never made the traditional post-game visit to the White House due to the Watergate scandal, but in August 2013 finally made the trip at the behest of Barack Obama, minus Manny Fernandez, Jim Langer, and Bob Kuechenberg, who did not attend due to their opposition to the Obama administration. Garo Yepremian was a longtime Republican supporter and friend of former Florida Governor Jeb Bush but made the trip anyway and had an amusing exchange with President Obama over his long-ago bumble in the game.\nBox score.\nSuper Bowl VII: Miami Dolphins 14, Washington Redskins 7\n\"at Los Angeles Memorial Coliseum, Los Angeles, California\nFinal statistics.\nSources:\"The NFL's Official Encyclopedic History of Professional Football\", (1973), p.\u00a0153, Macmillan Publishing Co. New York, LCCN 73-3862, http://, https://, https://\nIndividual statistics.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n1Completions/attempts\n2Carries\n3Long gain\n4Receptions\n5Times targeted\nRecords set.\nThe following records were set or tied in Super Bowl VII, according to the official NFL.com boxscore and the ProFootball reference.com game summary. Some records have to meet NFL minimum number of attempts to be recognized. The minimums are shown (in parentheses).\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nStarting lineups.\nSource:\n&lt;mark style=\"color:black;background:#FFCC00\"&gt;Hall of Fame\u2021&lt;/mark&gt;\nOfficials.\n\"Note: A seven-official system was not used until 1978. Back judge and field judge swapped titles prior to the 1998 NFL season.\"\nSuper Bowl postgame news.\nAs Shula was being carried off the field after the end of the game, a kid who shook his hand stripped off his watch. Shula got down, chased after the kid, and retrieved his watch.\nManny Fernandez was a strong contender for MVP. Wrote Nick Buoniconti, \"It was the game of his life\u2013in fact, it was the most dominant game by a defensive lineman in the history of the game, and he would never be given much credit for it. They should have given out two game balls and made Manny Fernandez the co-MVP with Jake Scott.\" Larry Csonka also said he thought Fernandez should have been the MVP. The MVP was selected by Dick Schaap, the editor of \"SPORT\" magazine. Schaap admitted later that he had been out late the previous night, struggled to watch the defense-dominated game, and was not aware that Fernandez had 17 tackles.\nWhen Garo Yepremian went back to the Dolphins' sideline after his botched field goal attempt, Nick Buoniconti told him that if they lost he would \"Hang you up by one of your ties.\" Yepremian would joke to reporters after the game, \"This is the first time the goat of the game is in the winner's locker room.\" But Yepremian would be so traumatized by his botched attempt that he had to be helped from the post-game party by his brother because of a stress-induced stabbing pain down his right side. Depressed, he spent two weeks in seclusion until he was cheered up by a letter, apparently from Shula, praising him for his contributions to the team and urging him to ignore criticism. Yepremian kept the letter and mentioned it to Shula in 2000, but Shula had no knowledge of it. They concluded the letter was actually written by Shula's wife Dorothy, who died from breast cancer in 1991. She had signed her husband's name to it. Nevertheless, \"Garo's Gaffe\" made Yepremian famous and led to a lucrative windfall of speaking engagements and endorsements. \"It's been a blessing\", said Yepremian, who died in 2015.\nThe same teams met 10 years later in Super Bowl XVII, which was also played in the Los Angeles area, at the Rose Bowl in Pasadena. The Redskins won that game, 27\u201317. Two starters from Miami's undefeated team, guard Bob Kuechenberg and defensive end Vern Den Herder, were still active during the strike-shortened 1982 season. The Redskins had no players remaining from Super Bowl VII on their Super Bowl XVII roster. The last member of the 1972 Redskins still active with the franchise, offensive tackle Terry Hermeling, retired after the 1980 season.\nRedskins linebacker and defensive captain Jack Pardee retired immediately following this game, ending a 16-year career. He coached the Chicago Bears for three seasons (1975\u201377) before succeeding Allen as Redskins coach in 1978. Pardee was fired following a 6\u201310 campaign in 1980 and was replaced by Joe Gibbs, who led the Redskins to three Super Bowl championships (XVII, XXII, XXVI) and 171 victories to earn induction into the Pro Football Hall of Fame. After coaching the Houston Gamblers of the United States Football League in 1984 and '85, Pardee coached at the University of Houston (1987\u201389) and the Houston Oilers (1990\u201394).\nThe Miami Dolphins became the second team to win the Super Bowl after losing it the previous year. They were the last team to do so until the New England Patriots in Super Bowl LIII.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences and notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "29134", "revid": "48535054", "url": "https://en.wikipedia.org/wiki?curid=29134", "title": "Super Bowl VIII", "text": "1974 edition of the Super Bowl\nSuper Bowl VIII was an American football game between the National Football Conference (NFC) champion Minnesota Vikings and the American Football Conference (AFC) champion Miami Dolphins to decide the National Football League (NFL) champion for the 1973 season. The Dolphins defeated the Vikings by the score of 24\u20137 to win their second consecutive Super Bowl, the first team to do so since the Green Bay Packers in Super Bowls I and II, and the first AFL/AFC team to do so.\nThe game was played on January 13, 1974, at Rice Stadium in Houston, Texas. This was the first time the Super Bowl venue was not home to that of an NFL franchise. At the time, the Astrodome seated just over 50,000, and was considered too small to host a Super Bowl. This was also the first Super Bowl not to be held in either the Los Angeles, Miami or New Orleans areas. It was also the last Super Bowl, and penultimate game overall (the 1974 Pro Bowl in Kansas City played the next week was the last) to feature goal posts at the front of the end zone (they were moved to the endline, in the back of the end zone, the next season).\nThis was the Dolphins' third consecutive Super Bowl appearance. They posted a 12\u20132 record during the regular season, then defeated the Cincinnati Bengals and the Oakland Raiders in the playoffs. The Vikings were making their second Super Bowl appearance after also finishing the regular season with a 12\u20132 record, and posting postseason victories over the Washington Redskins and the Dallas Cowboys.\nSuper Bowl VIII was largely dominated by the Dolphins, who scored 24 unanswered points during the first three quarters, including two touchdowns on their first two drives. Minnesota's best chance to threaten Miami occurred with less than a minute left in the first half, but Vikings running back Oscar Reed fumbled the ball away at the Dolphins' 6-yard line, and his team was unable to overcome Miami's lead in the second half. Dolphins fullback Larry Csonka became the first running back to be named Super Bowl MVP; both his 145 rushing yards and his 33 carries were Super Bowl records. Csonka broke the previous record for yards rushing (121) and carries (30) set by Matt Snell (who was also a fullback) in Super Bowl III.\nBackground.\nHost selection process.\nThe NFL awarded Super Bowl VIII to Houston on March 21, 1972, at the owners' meetings held in Honolulu. For the first time, multiple Super Bowl sites were selected at a single meeting, as hosts for both VII and VIII were named. Houston became the first Super Bowl host city provided with more than one year to prepare for the game, and lead time has grown substantially in succeeding years. Five cities, Los Angeles, Houston, Miami, Dallas, and New Orleans, prepared serious bids, while San Francisco (Stanford Stadium) withdrew from the running a week prior to the vote. After nine deadlocked votes, Bud Adams recommended awarding two consecutive sites. This compromise mirrored an idea brought up in 1971 by representatives from Miami. Los Angeles won on the ninth ballot and was named host of VII, while second place Houston was named the host for VIII.\nMiami Dolphins.\nAlthough the Dolphins were unable to match their 17\u20130 perfect season of 1972, many sports writers, fans, and Dolphins players themselves felt that the 1973 team was better. While the 1972 team faced no competition in the regular season that had a record of better than 8-6 and/or .500, the 1973 team played against a much tougher schedule that included games against the Oakland Raiders, Pittsburgh Steelers, and Dallas Cowboys (all playoff teams), plus two games against a resurgent Bills squad that featured 2,000-yard rusher O. J. Simpson, and a Cleveland Browns team that finished over .500. Miami finished with a 12\u20132 regular season, including their opening game victory over the defending 1972 NFC West champions, the San Francisco 49ers that tied an NFL record with eighteen consecutive wins. The Dolphins' streak ended in week two with a 12\u20137 loss to the Raiders in Berkeley, California.\nJust like the two previous seasons, Miami's offense relied primarily on its rushing attack. Fullback Larry Csonka recorded his third consecutive 1,000-rushing-yard season (1,003 yards), while running back Mercury Morris rushed for 954 yards and scored 10 touchdowns. Running back Jim Kiick was also a key contributor, rushing for 257 yards and catching 27 passes for 208 yards. Quarterback Bob Griese, the AFC's second-leading passer, completed only 116 passes for 1,422 yards, but threw more than twice as many touchdown passes (17) as interceptions (8), and earned an 84.3 passer rating. He became the first quarterback to start three Super Bowls and is joined by Jim Kelly and Tom Brady as the only quarterbacks to start at least three consecutive Super Bowls. Wide receiver Paul Warfield remained the main deep threat on the team, catching 29 passes for 514 yards and 11 touchdowns. Marlin Briscoe added 30 receptions for 447 yards and 2 scores. The offensive line was strong, once again led by center Jim Langer and right guard Larry Little. Griese, Csonka, Warfield, Langer, Nick Buoniconti and Little would all eventually be elected to the Pro Football Hall of Fame. Bobby Beathard was also elected to the Pro Football Hall of Fame.\nMiami's \"No Name Defense\" continued to dominate their opponents. Future Hall of Fame linebacker Nick Buoniconti recovered three fumbles and returned one for a touchdown. Safety Dick Anderson led the team with eight interceptions, which he returned for 163 yards and two touchdowns on route to winning NFL Defensive Player of the Year. And safety Jake Scott, the previous season's Super Bowl MVP, had four interceptions and 71 return yards. The Dolphins were still using their \"53\" defense devised at the beginning of the 1971 season, in which Bob Matheson (#53) would be brought in as a fourth linebacker in a 3\u20134 defense, with Manny Fernandez at nose tackle. Matheson could either rush the passer or drop back into coverage.\nMinnesota Vikings.\nThe Vikings also finished the regular season with a 12\u20132 record, winning their first nine games before a 20\u201314 loss on \"Monday Night Football\" to the Atlanta Falcons. The Vikings' other loss was a 27\u20130 shutout in Week 12 to the eventual AFC Central Division Champion Cincinnati Bengals, whom the Dolphins defeated in the AFC divisional playoffs.\nMinnesota's offense was led by 13-year veteran quarterback Fran Tarkenton. During the regular season, Tarkenton completed 61.7 percent of his passes for 2,113 yards, 15 touchdowns and just seven interceptions. He also rushed for 202 yards and another touchdown. The team's primary deep threat was Pro Bowl wide receiver John Gilliam, who caught 42 passes for 907 yards, an average of 21.6 yards per catch, and scored eight touchdowns. Tight end Stu Voigt was also a key element of the passing game, with 23 receptions for 318 yards and two touchdowns.\nThe Vikings' main rushing weapon was NFL Rookie of the Year running back Chuck Foreman, who rushed for 801 yards, caught 37 passes for 362 yards and scored six touchdowns. The Vikings had four other significant running backs \u2013 Dave Osborn, Bill Brown, Oscar Reed and future actor Ed Marinaro \u2013 who combined for 1,469 rushing/receiving yards and 11 touchdowns. The Vikings' offensive line was also very talented, led by right tackle Ron Yary and six-time Pro Bowl center Mick Tingelhoff.\nThe Minnesota defense ranked second in the league in fewest points allowed (168) and was again anchored by a defensive line nicknamed the \"Purple People Eaters\", consisting of defensive tackles Gary Larsen and Alan Page, and defensive ends Jim Marshall and Carl Eller. Behind them, Pro Bowl linebacker Jeff Siemon had 2 interceptions and 2 fumble recoveries. Cornerback Bobby Bryant (seven interceptions, 105 return yards, one touchdown) and safety Paul Krause (four interceptions) led the defensive secondary.\nPlayoffs.\nThe Vikings earned their second appearance in the Super Bowl after defeating the wild card Washington Redskins, 27\u201320, and the NFC East champion Dallas Cowboys, 27\u201310, in the playoffs. Meanwhile, the Dolphins defeated the AFC Central champion Cincinnati Bengals 34\u201316 in the divisional round, and the AFC West Champion Oakland Raiders, 27\u201310 for the AFC Championship. The Dolphins were the first team to appear in three consecutive Super Bowls. Just as in the regular season, Miami relied primarily on their run game in the playoffs, racking up 241 rushing yards against Cincinnati and 266 vs the Raiders. The ground game was particularly crucial against Oakland, as it enabled them to win despite completing just 3 of 6 passes for 34 yards in the game.\nSuper Bowl notes.\nThis was the first Super Bowl in which a former AFL franchise was the favorite. The 1970 AFC champion Baltimore Colts had been the favorite in Super Bowl V, but they were an original NFL franchise prior the 1970 merger. Despite Miami being favored, \"Sports Illustrated\" predicted a Dolphin loss for the third consecutive year.\nThis was also the first Super Bowl played in a stadium that was not the current home to an NFL or AFL team, as no team had called Rice Stadium home since the Houston Oilers moved into the Astrodome in 1968. At that time, the Astrodome seated just over 50,000 for football, and was considered too small to host the Super Bowl. It was also the first Super Bowl game played on the then-popular AstroTurf artificial playing surface, not surprising since Houston's Astrodome was the first facility to install AstroTurf in 1966. (Super Bowl V and Super Bowl VI, the first two Super Bowls played on artificial turf were played the competing Poly-Turf brand.) Indeed, a city in the state of Texas overall would not host another Super Bowl for exactly 30 years until Super Bowl XXXVIII (also in Houston, at what was then Reliant Stadium).\nThe Vikings complained about their practice facilities at Houston ISD's Delmar Stadium, a 20-minute bus ride from their hotel. They said the locker room was cramped, uncarpeted, had no lockers and that most of the shower heads (which was later discovered that birds had nested there) did not work. The practice field had no blocking sleds. \"I don't think our players have seen anything like this since junior high school\", said Vikings head coach Bud Grant. The Dolphins, meanwhile, trained at the Oilers' facility, since they were an AFC team like Miami.\nHaving already become the first NFC Central team to even reach the NFC Championship Game, the Vikings became the first non-East Division team from either conference to play in a post-merger Super Bowl.\nThere were reports of dissension among the Dolphins arising from owner Joe Robbie's decision to allow married players to bring their wives at the club's expense. The single players were reportedly angry that they could not bring their girlfriends, mothers or sisters.\nVikings defensive tackle Alan Page and Dolphins left guard Bob Kuechenberg were former teammates at the University of Notre Dame, including participating in the Game of the Century seven years earlier. Kuechenberg, who would be blocking Page in the game, had sustained a broken arm in a game against the Colts and wore a cast while playing in the Super Bowl. Paul Warfield entered the game with a well-publicized hamstring injury to his left leg.\nOn television before the game, New York Jets quarterback Joe Namath said, \"If Miami gets the kickoff and scores on the opening drive, the game is over.\". Indeed, the Dolphins became the first team to score a touchdown after receiving the game's opening kickoff.\nThe Dolphins, who were designated as the home team, were obligated by a now-defunct policy to wear their aqua jerseys despite having normally worn white jerseys for home games (though Miami wore aqua for its final two regular-season home games vs. the Pittsburgh Steelers and Detroit Lions). Also, the Dolphins wore two slightly different helmet decals; some had the decal that the team had previously used in the 1967 season (Bob Griese's rookie year) and would permanently adopt in 1974 (mostly linemen; with the mascot dolphin leaping through the sun), while others had the decal used in 1966 and again from 1968 to 1973 (with the mascot dolphin halfway through the sun).\nFamed \"Gonzo\" writer Hunter S. Thompson covered the game for \"Rolling Stone\" magazine, and his exploits in Houston are legendary.\nThis was the only Super Bowl in which the game ball had white stripes. At the time, the league permitted striped footballs for night games, late afternoon games, indoor games, and other special situations. The\u00a0NFL ended the use after the 1975 season, as the stripes were slippery and made the ball more difficult to throw.\nHead linesman Leo Miles was the first African-American to officiate in a Super Bowl.\nBroadcasting.\nThe game was televised in the United States by CBS with play-by-play announcer Ray Scott and color commentators Pat Summerall and Bart Starr. This was Scott's final telecast for CBS. Midway through the following season Summerall would take Scott's place as the network's lead play-by-play announcer, holding that position through 1993, when CBS lost rights to the NFC television package to Fox.\nThis is the earliest surviving Super Bowl where the complete original broadcast exists on videotape. Earlier Super Bowls (such as III, V, VI, and VII) had most of the action preserved on videotape but had a portion of the game missing. All Super Bowls from here on out would be preserved in their entirety.\nEntertainment.\nThe Longhorn Band from the University of Texas at Austin performed during the pregame festivities. Later, country music singer Charley Pride sang \"America the Beautiful\" and the national anthem. This game marked the first time that \"America the Beautiful\" was performed before a Super Bowl game.\nThe halftime show also featured the Longhorn Band, along with Judy Mallett, Miss Texas 1973, playing the fiddle, in a tribute to American music titled \"A Musical America\".\nThe pre-game party was held on the floor of the Astrodome the night before the game. It was attended by the players, the coaches, media, and celebrities. Entertainment was provided by The La France Sisters and Charley Pride.\nGame summary.\nThe Dolphins' game plan on offense was to use misdirection, negative-influence traps, and cross-blocking to exploit the Minnesota defense's excellent pursuit. (The Kansas City Chiefs had used similar tactics against the same Vikings defensive line in Super Bowl IV). Wrote Jim Langer, \"All this was successful right away. We kept ripping huge holes into their defense and Csonka kept picking up good yardage, especially to the right. We'd hear Alan [Page] cussing because those negative-influence plays were just driving him nuts. He didn't know what the hell to do.\" On defense, the Dolphins' goal was to neutralize Chuck Foreman by using cat-quick Manny Fernandez at nose tackle and to make passing difficult for Tarkenton by knocking down his receivers and double-teaming John Gilliam. They were also depending on defensive ends Bill Stanfill and Vern Den Herder to contain Tarkenton's scrambling. Coach Don Shula wrote, \"In the case of Tarkenton we wanted to hem him in. In the case of Page, Eller and company, we wanted to try to turn their aggressiveness to our advantage. We decided to emphasize negative influence by misdirection and cross blocking, trying to make the Vikings Front Four commit to the influence of the play and then actually running it elsewhere. The Vikings responded as we anticipated. Then later in the game we found that the Vikings started hesitating, reducing their charge. When they did that, we beat them with straight blocking.\"\nFirst quarter.\nAs they had in the two previous Super Bowls, the Dolphins won the coin toss and elected to receive. The Dolphins dominated the Vikings right from the beginning, scoring touchdowns on two 10-play drives in the first quarter. Said center Jim Langer, \"It was obvious from the beginning that our offense could overpower their defense.\" The two drives were very similar, both containing 8 rushes, 2 passes (both of which were complete), one third-down conversion, and four first downs picked up, while Miami did not get penalized. First, Dolphins safety Jake Scott gave his team good field position by returning the opening kickoff 31 yards to the Miami 38-yard line. Then running back Mercury Morris ran right for four yards, fullback Larry Csonka crashed through the middle for two, and quarterback Bob Griese completed a 13-yard pass to tight end Jim Mandich to advance the ball to the Vikings 43-yard line. Csonka then ran on second down for 16 yards (his longest run of the game), then Griese completed a 6-yard pass to wide receiver Marlin Briscoe to the 21-yard line. Three more running plays, two by Csonka and one by Morris, moved the ball to the Vikings 5-yard line. Csonka then finished the drive with a 5-yard touchdown run.\nMinnesota's offense started well on the first play with a five-yard run by Chuck Foreman. But the Dolphins were already leading, with Tarkenton behind before running any play, and now Miami's No-Name Defense responded when Foreman ran again and was stopped for no gain. It seemed predictable when Tarkenton's first pass had Foreman as the target, and Manny Fernandez made the stop one yard short of the first down. After three plays and out, punter Mike Eischeid's kick went only 34 yards. Scott fumbled the return, but quickly recovered the ball at the Miami 44, giving the Dolphins better field position than the opening drive. The Dolphins then went 56 yards in 10 plays (aided with three runs by Csonka for a total of 28 yards, and Griese's 13-yard pass to Briscoe) to score on running back Jim Kiick's 1-yard touchdown run (his only touchdown of the season) to extend their lead to 14\u20130.\nBy the time the first quarter ended, Miami had run 20 plays for 118 yards and eight first downs, and scored touchdowns on their first two possessions, with Csonka carrying eight times for 64 yards and Griese completing all four of his passes for 40 yards. Meanwhile, the Miami defense held the Minnesota offense to only 25 yards, six plays from scrimmage, and one first down. The Vikings advanced only as far as their own 27-yard line. The Dolphins set the record which still stands for the largest Super Bowl lead (14 points) at the end of the first quarter. It has since been tied by the Oakland Raiders against the Philadelphia Eagles in Super Bowl XV (led 14\u20130) and the Green Bay Packers against the Pittsburgh Steelers in Super Bowl XLV (led 14\u20130).\nSecond quarter.\nThe situation never got much better for the Vikings the rest of the game. After the first three possessions of the second period ended in punts, Miami mounted a seven-play drive starting from their own 34-yard line. On the first play of the drive, Minnesota linebacker Wally Hilgenberg was flagged for a 15-yard personal foul penalty, putting the ball at the Vikings' 49-yard line. On the previous series, Hilgenberg had thrown an elbow through Csonka's facemask, cutting Csonka above the eye, but had not been penalized. Later in the drive, Morris ran for 10 yards on 3rd-and-inches from the Minnesota 40-yard line to allow Miami to get into field goal range. The drive stalled at the Minnesota 20, forcing Miami to settle for kicker Garo Yepremian's 28-yard field goal to increase their lead to 17\u20130 midway through the quarter. \nThe Vikings then had their best opportunity to score in the first half on their ensuing drive. Starting at their own 20-yard line, Minnesota marched to the Miami 15-yard line in nine plays, aided by quarterback Fran Tarkenton's two completions to tight end Stu Voigt for 31 yards and wide receiver John Gilliam's 30-yard reception on 3rd-and-9 (the longest play of the game). Tarkenton's 8-yard run on first down then advanced the ball to the Miami 7, but on the next two plays, Vikings running back Oscar Reed gained only 1 yard on two rushes, bringing up a 4th-and-1 with less than a minute left in the half. Instead of kicking a field goal, Minnesota attempted to convert the fourth down with another running play by Reed, but Reed was stripped of the ball by linebacker Nick Buoniconti before he could pick up the first down, turning the ball back over to the Dolphins to end the half. About the decision to run with Reed on three straight plays, Grant defended the decision since the Vikings twice had converted in the NFC title game against Dallas. \"If it's less than a yard, we go for it\", he said. \"We feel we have the plays to make it.\" The Dolphins, however, made the stop where the Cowboys had not.\nLanger wrote that at halftime, \"We definitely knew that this game was over.\"\nThird quarter.\nGilliam returned the second half kickoff 65 yards, but this was nullified by a clipping penalty on Voigt, moving the ball back to the Minnesota 11-yard line. Two plays later, Tarkenton was sacked for a 6-yard loss by Miami defensive tackle Manny Fernandez, forcing Minnesota to punt from their own 7-yard line. Scott then returned the punt 12 yards to the Minnesota 43-yard line.\nMiami's first possession of the half led to a 43-yard, eight-play scoring drive. The key play was Griese's 27-yard pass to wide receiver Paul Warfield on 3rd-and-5 to the Minnesota 11-yard line. It was Griese's last pass of the game, his only pass of the second half and just the seventh overall, and only Warfield's second, and last, catch of the game. (Because of his hamstring injury, Warfield had earlier been limping through primarily decoy routes.) On 3rd-and-4 from the Minnesota 5, cornerback Bobby Bryant sacked Morris for an 8-yard loss, but a defensive holding penalty on Hilgenberg gave Miami a new set of downs at the 8. Two plays later, Csonka scored on a 2-yard touchdown run, increasing the Dolphins' lead to 24\u20130 with nine minutes left in the period. On the scoring play, Griese forgot the snap count at the line of scrimmage. He asked Csonka, who said \"two.\" Kiick said, \"No, it's one.\" Griese chose to believe Csonka, which was a mistake; it was \"one.\" Griese bobbled the ball slightly, but still managed to get it to Csonka.\nAfter an exchange of punts, Minnesota got the ball back at their 43-yard line after Larry Seiple's kick went just 24 yards.\nFourth quarter.\nThe Vikings got on the board with a 10-play, 57-yard drive, with Tarkenton completing 5 passes for 43 yards, including a 15-yarder to Voigt on 3rd-and-8, and finished the drive himself with a 4-yard touchdown run, cutting Minnesota's deficit to 24\u20137. This was the first rushing touchdown by a quarterback in Super Bowl history.\nMinnesota recovered the ensuing onside kick, but an offside penalty on the Vikings nullified the play, and they subsequently kicked deep. Miami went three-and-out, but Seiple boomed a 57-yard punt and Minnesota got the ball back at their own 3-yard line. Eight plays later, the Vikings reached the Miami 32-yard line, aided by the only penalty charged to Miami in the game (4 yards for pass interference on cornerback Tim Foley) and a 27-yard reception by running back Ed Marinaro. But after two incomplete passes, Tarkenton's pass intended for wide receiver Jim Lash was intercepted by Dolphins cornerback Curtis Johnson at the goal line and returned to Miami's 10 with 6:24 left in the game. Csonka and Kiick were the ball carriers on all 12 remaining plays. The Dolphins picked up two first downs by rush and two by penalty on Vikings defensive tackle Alan Page in running out the clock. With less than four minutes left in the game, a frustrated Page delivered a late hit on Griese, and was assessed a personal foul penalty. Two plays later, both Page and Dolphins guard Bob Kuechenberg were given offsetting personal fouls after getting into a scuffle with each other. Page finished venting out his frustration by committing an offside penalty, while Miami advanced to the Minnesota 29 to run out the clock and claim their second consecutive Super Bowl title.\nWrote Langer, \"We just hit the Vikings defense so hard and so fast that they didn't know what hit them. Alan Page later said he knew we would dominate them after only the first couple of plays.\"\nGriese finished the game with just six out of seven pass completions for 73 yards. Miami's seven pass attempts were the fewest ever thrown by a team in the Super Bowl. The Dolphins rushed for 196 yards, did not have any turnovers, and were not penalized in the first 52 minutes. Tarkenton set what was then a Super Bowl record for completions, 18 out of 28 for 182 yards, with one interception, and rushed for 17 yards and a touchdown. Reed was the leading rusher for the Vikings, but with just 32 yards. Voigt was the top receiver of the game with three catches for 46 yards. The Vikings' lethargic performance in this game was very similar to their performance in their loss to the Kansas City Chiefs in Super Bowl IV, as a single touchdown was the only scoring play for the Vikings in both Super Bowls.\nBox score.\nSuper Bowl VIII: Miami Dolphins 24, Minnesota Vikings 7\n\"at Rice Stadium, Houston, Texas\nFinal statistics.\nSources: http://, https://, https://\nIndividual statistics.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\n1Completions/attempts\n2Carries\n3Long gain\n4Receptions\n5Times targeted\nRecords set.\nThe following records were set or tied in Super Bowl VIII, according to the official NFL.com boxscore and the ProFootball reference.com game summary. Some records have to meet NFL minimum number of attempts to be recognized. The minimums are shown (in parentheses).\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nTurnovers are defined as the number of times losing the ball on interceptions and fumbles.\n&lt;templatestyles src=\"Col-float/styles.css\" /&gt;\nSuper Bowl postgame news and notes.\nIn the Dolphins' locker room after the game, Csonka was asked about his battered face. Without naming Hilgenberg, he said, \"It was a cheap shot, but an honest cheap shot. He came right at me and threw an elbow right through my mask. I could see the game meant something to him.\"\nWith their 32\u20132 record over two years, the still-young Dolphins appeared to have established a dynasty. In 1974, however, their offense was hurt by injuries to Csonka and the offensive line, and the defense was hurt by the departure of defensive coordinator Bill Arnsparger who became the New York Giants head coach. The Dolphins finished 11\u20133 but lost a dramatic playoff game (\"The Sea of Hands\") to the Oakland Raiders. In 1975 Csonka, Kiick, and Warfield left to join the World Football League. The Dolphins would not win another playoff game until 1982, and they have not won a Super Bowl since. They would appear in but lose two more, XVII and XIX.\nJim Langer ended his career with the Vikings in 1981, allowing him to play for his hometown franchise. Langer lost his starting center job in 1980 to Dwight Stephenson, who like Langer is a member of the Hall of Fame.\nStarting lineups.\nSource:\n&lt;mark style=\"color:black;background:#FFCC00\"&gt;Hall of Fame\u2021&lt;/mark&gt;\nOfficials.\n\"Note: A seven-official system was not used until the 1978 season.\"\nLeo Miles was the first African-American to officiate in a Super Bowl.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
