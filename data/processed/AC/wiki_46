{"id": "24780", "revid": "51006953", "url": "https://en.wikipedia.org/wiki?curid=24780", "title": "Five precepts", "text": "Basic code of ethics for Buddhist lay people\nThe five precepts (; ) or five rules of training (; ) is the most important system of morality for Buddhist lay people. They constitute the basic code of ethics to be respected by lay followers of Buddhism. The precepts are commitments to abstain from killing living beings, stealing, sexual misconduct, lying and intoxication. Within the Buddhist doctrine, they are meant to develop mind and character to make progress on the path to enlightenment. They are sometimes referred to as the \u015ar\u0101vakay\u0101na precepts in the Mah\u0101y\u0101na tradition, contrasting them with the \"bodhisattva\" precepts. The five precepts form the basis of several parts of Buddhist doctrine, both lay and monastic. With regard to their fundamental role in Buddhist ethics, they have been compared with the Ten Commandments in Abrahamic religions or the ethical codes of Confucianism. The precepts have been connected with utilitarianist, deontological and virtue approaches to ethics, though by 2017, such categorization by western terminology had mostly been abandoned by scholars. The precepts have been compared with human rights because of their universal nature, and some scholars argue they can complement the concept of human rights.\nThe five precepts were common to the religious milieu of 6th-century BCE India, but the Buddha's focus on awareness through the fifth precept was unique. As shown in Early Buddhist Texts, the precepts grew to be more important, and finally became a condition for membership of the Buddhist religion. When Buddhism spread to different places and people, the role of the precepts began to vary. In countries where Buddhism had to compete with other religions, such as China, the ritual of undertaking the five precepts developed into an initiation ceremony to become a Buddhist layperson. On the other hand, in countries with little competition from other religions, such as Thailand, the ceremony has had little relation to the rite of becoming Buddhist, as many people are presumed Buddhist from birth.\nUndertaking and upholding the five precepts is based on the principle of non-harming (P\u0101li and ). The Pali Canon recommends one to compare oneself with others, and on the basis of that, not to hurt others. Compassion and a belief in karmic retribution form the foundation of the precepts. Undertaking the five precepts is part of regular lay devotional practice, both at home and at the local temple. However, the extent to which people keep them differs per region and time. People keep them with an intention to develop themselves, but also out of fear of a bad rebirth.\nIn modern times, traditional Buddhist countries have seen revival movements to promote the five precepts. As for the West, the precepts play a major role in Buddhist organizations. They have also been integrated into mindfulness training programs, though many mindfulness specialists do not support this because of the precepts' religious import. Lastly, many conflict prevention programs make use of the precepts.\nRole in Buddhist doctrine.\nBuddhist scriptures explain the five precepts as the minimal standard of Buddhist morality. It is the most important system of morality in Buddhism, together with the monastic rules. \"\u015a\u012bla\" (Sanskrit; ) is used to refer to Buddhist precepts, including the five. But the word also refers to the virtue and morality which lies at the foundation of the spiritual path to enlightenment, which is the first of the three forms of training on the path. Thus, the precepts are rules or guidelines to develop mind and character to make progress on the path to enlightenment. The five precepts are part of the right speech, action and livelihood aspects of the Noble Eightfold Path, the core teaching of Buddhism. Moreover, the practice of the five precepts and other parts of \"\u015b\u012bla\" are described as forms of merit-making, means to create good karma. The five precepts have been described as social values that bring harmony to society, and breaches of the precepts described as antithetical to a harmonious society. On a similar note, in Buddhist texts, the ideal, righteous society is one in which people keep the five precepts.\nComparing different parts of Buddhist doctrine, the five precepts form the basis of the eight precepts, which are lay precepts stricter than the five precepts, similar to monastic precepts. Secondly, the five precepts form the first half of the ten or eleven precepts for a person aiming to become a Buddha (\"bodhisattva\"), as mentioned in the \"Brahmajala S\u016btra\" of the Mah\u0101y\u0101na tradition. Contrasting these precepts with the five precepts, the latter were commonly referred to by Mah\u0101y\u0101nists as the \"\u015br\u0101vakay\u0101na\" precepts, or the precepts of those aiming to become enlightened disciples (; ) of a Buddha, but not Buddhas themselves. The ten\u2013eleven \"bodhisattva\" precepts presuppose the five precepts, and are partly based on them. The five precepts are also partly found in the teaching called the ten good courses of action, referred to in Therav\u0101da () and Tibetan Buddhism (; Wylie: \"dge ba bcu\"). Finally, the first four of the five precepts are very similar to the most fundamental rules of monastic discipline (), and may have influenced their development.\nIn conclusion, the five precepts lie at the foundation of all Buddhist practice, and in that respect, can be compared with the Ten Commandments in Christianity and Judaism or the ethical codes of Confucianism.\nHistory.\nThe five precepts were part of Early Buddhism and are common to nearly all schools of Buddhism. In Early Buddhism, the five precepts were regarded as an ethic of restraint, to restrain unwholesome tendencies and thereby purify one's being to attain enlightenment. The five precepts were based on the \"pa\u00f1ca\u015b\u012bla\", prohibitions for pre-Buddhist Brahmanic priests, which were adopted in many Indic religions around 6th century BCE. The first four Buddhist precepts were nearly identical to these \"pa\u00f1ca\u015b\u012bla\", but the fifth precept, the prohibition on intoxication, was new in Buddhism: the Buddha's emphasis on awareness () was unique.\nIn some schools of ancient Indic Buddhism, Buddhist devotees could choose to adhere to only a number of precepts, instead of the complete five. The schools that would survive in later periods, however, that is Therav\u0101da and Mah\u0101y\u0101na Buddhism, were both ambiguous about this practice. Some early Mah\u0101y\u0101na texts allow it, but some do not; Therav\u0101da texts do not discuss such selective practice at all.\nThe prohibition on killing had motivated early Buddhists to form a stance against animal sacrifice, a common religious ritual practice in ancient India. According to the P\u0101li Canon, however, early Buddhists did not adopt a vegetarian lifestyle.\nIn Early Buddhist Texts, the role of the five precepts gradually develops. First of all, the precepts are combined with a declaration of faith in the Triple Gem (the Buddha, his teaching and the monastic community). Next, the precepts develop to become the foundation of lay practice. The precepts are seen as a preliminary condition for the higher development of the mind. At a third stage in the texts, the precepts are actually mentioned together with the triple gem, as though they are part of it. Lastly, the precepts, together with the triple gem, become a required condition for the practice of Buddhism, as laypeople have to undergo a formal initiation to become a member of the Buddhist religion. When Buddhism spread to different places and people, the role of the precepts began to vary. In countries in which Buddhism was adopted as the main religion without much competition from other religious disciplines, such as Thailand, the relation between the initiation of a layperson and the five precepts has been virtually non-existent. In such countries, the taking of the precepts has become a sort of ritual cleansing ceremony. People are presumed Buddhist from birth without much of an initiation. The precepts are often committed to by new followers as part of their installment, yet this is not very pronounced. However, in some countries like China, where Buddhism was not the only religion, the precepts became an ordination ceremony to initiate laypeople into the Buddhist religion.\nIn China, the five precepts were introduced in the first centuries CE, both in their \"\u015br\u0101vakay\u0101na\" and \"bodhisattva\" formats. During this time, it was particularly Buddhist teachers who promoted abstinence from alcohol (the fifth precept), since Daoism and other thought systems emphasized moderation rather than full abstinence. Chinese Buddhists interpreted the fifth precept strictly, even more so than in Indic Buddhism. For example, the monk Daoshi (c. 600\u2013683) dedicated large sections of his encyclopedic writings to abstinence from alcohol. However, in some parts of China, such as Dunhuang, considerable evidence has been found of alcohol consumption among both lay people and monastics. Later, from the 8th century onward, strict attitudes of abstinence led to a development of a distinct tea culture among Chinese monastics and lay intellectuals, in which tea gatherings replaced gatherings with alcoholic beverages, and were advocated as such. These strict attitudes were formed partly because of the religious writings, but may also have been affected by the bloody An Lushan Rebellion of 775, which had a sobering effect on 8th-century Chinese society. When the five precepts were integrated in Chinese society, they were associated and connected with karma, Chinese cosmology and medicine, a Daoist worldview, and Confucian virtue ethics.\nCeremonies.\nIn P\u0101li tradition.\nIn the Therav\u0101da tradition, the precepts are recited in a standardized fashion, using P\u0101li language. In Thailand, a leading lay person will normally request the monk to administer the precepts by reciting the following three times:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Venerables, we request the five precepts and the three refuges [i.e. the triple gem] for the sake of observing them, one by one, separately\". ()\nAfter this, the monk administering the precepts will recite a reverential line of text to introduce the ceremony, after which he guides the lay people in declaring that they take their refuge in the three refuges or triple gem.\nHe then continues with reciting the five precepts:\nAfter the lay people have repeated the five precepts after the monk, the monk will close the ceremony reciting:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"These five precepts lead with good behavior to bliss, with good behavior to wealth and success, they lead with good behavior to happiness, therefore purify behavior.\" ()\nIn other textual traditions.\nThe format of the ceremony for taking the precepts occurs several times in the Chinese Buddhist Canon, in slightly different forms.\nOne formula of the precepts can be found in the \"Treatise on Taking Refuge and the Precepts\" ():\nSimilarly, in the M\u016bla-Sarv\u0101stiv\u0101da texts used in Tibetan Buddhism, the precepts are formulated such that one takes the precepts upon oneself for one's entire lifespan, following the examples of the enlightened disciples of the Buddha (\"arahant\").\nPrinciples.\nThe five precepts can be found in many places in the Early Buddhist Texts. The precepts are regarded as means to building good character, or as an expression of such character. The P\u0101li Canon describes them as means to avoid harm to oneself and others. It further describes them as gifts toward oneself and others. Moreover, the texts say that people who uphold them will be confident in any gathering of people, will have wealth and a good reputation, and will die a peaceful death, reborn in heaven or as a human being. On the other hand, living a life in violation of the precepts is believed to lead to rebirth in an unhappy destination. They are understood as principles that define a person as human in body and mind.\nThe precepts are normative rules, but are formulated and understood as \"undertakings\" rather than commandments enforced by a moral authority, according to the voluntary and gradualist standards of Buddhist ethics. They are forms of restraint formulated in negative terms, but are also accompanied by virtues and positive behaviors, which are cultivated through the practice of the precepts. The most important of these virtues is non-harming (P\u0101li and ), which underlies all of the five precepts. Precisely, the texts say that one should keep the precepts, adhering to the principle of comparing oneself with others:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"For a state that is not pleasant or delightful to me must be so to him also; and a state that is not pleasing or delightful to me, how could I inflict that upon another?\"\nIn other words, all living beings are alike in that they want to be happy and not suffer. Comparing oneself with others, one should therefore not hurt others as one would not want to be hurt. Ethicist Pinit Ratanakul argues that the compassion which motivates upholding the precepts comes from an understanding that all living beings are equal and of a nature that they are 'not-self' (). Another aspect that is fundamental to this is the belief in karmic retribution.\nIn the upholding or violation of the precepts, intention is crucial. In the P\u0101li scriptures, an example is mentioned of a person stealing an animal only to set it free, which was not seen as an offense of theft. In the P\u0101li commentaries, a precept is understood to be violated when the person violating it finds the object of the transgression (e.g. things to be stolen), is aware of the violation, has the intention to violate it, does actually act on that intention, and does so successfully.\nUpholding the precepts is sometimes distinguished in three levels: to uphold them without having formally undertaken them; to uphold them formally, willing to sacrifice one's own life for it; and finally, to spontaneously uphold them. The latter refers to the \"arahant\", who is understood to be morally incapable of violating the first four precepts. A layperson who upholds the precepts is described in the texts as a \"jewel among laymen\". On the other hand, the most serious violations of the precepts are the five actions of immediate retribution, which are believed to lead the perpetrator to an unavoidable rebirth in hell. These consist of injuring a Buddha, killing an \"arahant\", killing one's father or mother, and causing the monastic community to have a schism.\nPractice in general.\nLay followers often undertake these training rules in the same ceremony as they take the refuges. Monks administer the precepts to the laypeople, which creates an additional psychological effect. Buddhist lay people may recite the precepts regularly at home, and before an important ceremony at the temple to prepare the mind for the ceremony.\nThe five precepts are at the core of Buddhist morality. In field studies in some countries like Sri Lanka, villagers describe them as the core of the religion. Anthropologist Barend Terwiel found in his fieldwork that most Thai villagers knew the precepts by heart, and many, especially the elderly, could explain the implications of the precepts following traditional interpretations.\nHowever, Buddhists vary in how strict they follow them. Devotees who have just started keeping the precepts will typically have to exercise considerable restraint. When they become used to the precepts, they start to embody them more naturally. Researchers doing field studies in traditional Buddhist societies have found that the five precepts are generally considered demanding and challenging. For example, anthropologist Stanley Tambiah found in his field studies that strict observance of the precepts had \"little positive interest for the villager ... not because he devalues them but because they are not normally open to him\". Observing precepts was seen to be mostly the role of a monk or an elderly lay person. More recently, in a 1997 survey in Thailand, only 13.8% of the respondents indicated they adhered to the five precepts in their daily lives, with the fourth and fifth precept least likely to be adhered to. Yet, people do consider the precepts worth striving for, and do uphold them out of fear of bad karma and being reborn in hell, or because they believe in that the Buddha issued these rules, and that they therefore should be maintained. Anthropologist Melford Spiro found that Burmese Buddhists mostly upheld the precepts to avoid bad karma, as opposed to expecting to gain good karma. Scholar of religion Winston King observed from his field studies that the moral principles of Burmese Buddhists were based on personal self-developmental motives rather than other-regarding motives. Scholar of religion Richard Jones concludes that the moral motives of Buddhists in adhering to the precepts are based on the idea that renouncing self-service, ironically, serves oneself.\nIn East Asian Buddhism, the precepts are intrinsically connected with the initiation as a Buddhist lay person. Early Chinese translations such as the \"Up\u0101saka-\u015bila S\u016btra\" hold that the precepts should only be ritually transmitted by a monastic. The texts describe that in the ritual the power of the Buddhas and \"bodhisattvas\" is transmitted, and helps the initiate to keep the precepts. This \"lay ordination\" ritual usually occurs after a stay in a temple, and often after a monastic ordination (); has taken place. The ordained lay person is then given a religious name. The restrictions that apply are similar to a monastic ordination, such as permission from parents.\nIn the Therav\u0101da tradition, the precepts are usually taken \"each separately\" (), to indicate that if one precept should be broken, the other precepts are still intact. In very solemn occasions, or for very pious devotees, the precepts may be taken as a group rather than each separately. This does not mean, however, that only some of the precepts can be undertaken; they are always committed to as a complete set. In East Asian Buddhism, however, the vow of taking the precepts is considered a solemn matter, and it is not uncommon for lay people to undertake only the precepts that they are confident they can keep. The act of taking a vow to keep the precepts is what makes it karmically effective: Spiro found that someone who did not violate the precepts, but did not have any intention to keep them either, was not believed to accrue any religious merit. On the other hand, when people took a vow to keep the precepts, and then broke them afterwards, the negative karma was considered larger than in the case no vow was taken to keep the precepts.\nSeveral modern teachers such as Thich Nhat Hanh and Sulak Sivaraksa have written about the five precepts in a wider scope, with regard to social and institutional relations. In these perspectives, mass production of weapons or spreading untruth through media and education also violates the precepts. On a similar note, human rights organizations in Southeast Asia have attempted to advocate respect for human rights by referring to the five precepts as guiding principles.\nFirst precept.\nTextual analysis.\nThe first precept prohibits the taking of life of a sentient being. It is violated when someone intentionally and successfully kills such a sentient being, having understood it to be sentient and using effort in the process. Causing injury goes against the spirit of the precept, but does, technically speaking, not violate it. The first precept includes taking the lives of animals, even small insects. However, it has also been pointed out that the seriousness of taking life depends on the size, intelligence, benefits done and the spiritual attainments of that living being. Killing a large animal is worse than killing a small animal (also because it costs more effort); killing a spiritually accomplished master is regarded as more severe than the killing of another \"more average\" human being; and killing a human being is more severe than the killing of an animal. But all killing is condemned. Virtues that accompany this precept are respect for dignity of life, kindness and compassion, the latter expressed as \"trembling for the welfare of others\". A positive behavior that goes together with this precept is protecting living beings. Positive virtues like sympathy and respect for other living beings in this regard are based on a belief in the cycle of rebirth\u2014that all living beings must be born and reborn. The concept of the fundamental Buddha nature of all human beings also underlies the first precept.\nThe description of the first precept can be interpreted as a prohibition of capital punishment. Suicide is also seen as part of the prohibition. Moreover, abortion (of a sentient being) goes against the precept, since in an act of abortion, the criteria for violation are all met. In Buddhism, human life is understood to start at conception. A prohibition of abortion is mentioned explicitly in the monastic precepts, and several Buddhist tales warn of the harmful karmic consequences of abortion. Bioethicist Damien Keown argues that Early Buddhist Texts do not allow for exceptions with regard to abortion, as they consist of a \"consistent' (i.e. exceptionless) pro-life position\". Keown further proposes that a middle way approach to the five precepts is logically hard to defend. Asian studies scholar Giulio Agostini argues, however, that Buddhist commentators in India from the 4th century onward thought abortion did not break the precepts under certain circumstances.\nOrdering another person to kill is also included in this precept, therefore requesting or administering euthanasia can be considered a violation of the precept, as well as advising another person to commit abortion. With regard to euthanasia and assisted suicide, Keown quotes the P\u0101li \"D\u012bgha Nik\u0101ya\" that says a person upholding the first precept \"does not kill a living being, does not cause a living being to be killed, does not approve of the killing of a living being\". Keown argues that in Buddhist ethics, regardless of motives, death can never be the aim of one's actions.\nInterpretations of how Buddhist texts regard warfare are varied, but in general Buddhist doctrine is considered to oppose all warfare. In many \"J\u0101taka\" tales, such as that of Prince Temiya, as well as some historical documents, the virtue of non-violence is taken as an opposition to all war, both offensive and defensive. At the same time, though, the Buddha is often shown not to explicitly oppose war in his conversations with political figures. Buddhologist Andr\u00e9 Bareau points out that the Buddha was reserved in his involvement of the details of administrative policy, and concentrated on the moral and spiritual development of his disciples instead. He may have believed such involvement to be futile, or detrimental to Buddhism. Nevertheless, at least one disciple of the Buddha is mentioned in the texts who refrained from retaliating his enemies because of the Buddha, that is King Pasenadi (). The texts are ambiguous in explaining his motives though. In some later Mah\u0101y\u0101na texts, such as in the writings of Asa\u1e45ga, examples are mentioned of people who kill those who persecute Buddhists. In these examples, killing is justified by the authors because protecting Buddhism was seen as more important than keeping the precepts. Another example that is often cited is that of King Du\u1e6d\u1e6dhag\u0101ma\u1e47\u012b, who is mentioned in the post-canonical P\u0101li Mah\u0101va\u1e43sa chronicle. In the chronicle, the king is saddened with the loss of life after a war, but comforted by a Buddhist monk, who states that nearly everyone who was killed did not uphold the precepts anyway. Buddhist studies scholar Lambert Schmithausen argues that in many of these cases Buddhist teachings like that of emptiness were misused to further an agenda of war or other violence.\nIn practice.\nField studies in Cambodia and Burma have shown that many Buddhists considered the first precept the most important, or the most blamable. In some traditional communities, such as in Kandal Province in pre-war Cambodia, as well as Burma in the 1980s, it was uncommon for Buddhists to slaughter animals, to the extent that meat had to be bought from non-Buddhists. In his field studies in Thailand in the 1960s, Terwiel found that villagers did tend to kill insects, but were reluctant and self-conflicted with regard to killing larger animals. In Spiro's field studies, however, Burmese villagers were highly reluctant even to kill insects.\nEarly Buddhists did not adopt a vegetarian lifestyle. Indeed, in several P\u0101li texts vegetarianism is described as irrelevant in the spiritual purification of the mind. There are prohibitions on certain types of meat, however, especially those which are condemned by society. The idea of abstaining from killing animal life has also led to a prohibition on professions that involve trade in flesh or living beings, but not to a full prohibition of all agriculture that involves cattle. In modern times, referring to the law of supply and demand or other principles, some Therav\u0101din Buddhists have attempted to promote vegetarianism as part of the five precepts. For example, the Thai Santi Asoke movement practices vegetarianism.\nFurthermore, among some schools of Buddhism, there has been some debate with regard to a principle in the monastic discipline. This principle states that a Buddhist monk cannot accept meat if it comes from animals that were specifically slaughtered for the monks to eat. Some teachers have interpreted this to mean that when the recipient has no knowledge on whether the animal has been killed for him, he cannot accept the food either. Similarly, there has been debate as to whether laypeople should be vegetarian when adhering to the five precepts. Though vegetarianism among Therav\u0101dins is generally uncommon, it has been practiced much in East Asian countries, as some Mah\u0101y\u0101na texts, such as the \"Mah\u0101paranirvana S\u016btra\" and the \"La\u1e45k\u0101vat\u0101ra S\u016btra\", condemn the eating of meat. Nevertheless, even among Mah\u0101y\u0101na Buddhists\u2014and East Asian Buddhists\u2014there is disagreement on whether vegetarianism should be practiced. In the \"La\u1e45k\u0101vat\u0101ra S\u016btra\", biological, social and hygienic reasons are given for a vegetarian diet; however, historically, a major factor in the development of a vegetarian lifestyle among Mah\u0101y\u0101na communities may have been that Mah\u0101y\u0101na monastics cultivated their own crops for food, rather than living from alms. Already from the 4th century CE, Chinese writer Xi Chao understood the five precepts to include vegetarianism.\nApart from trade in flesh or living beings, there are also other professions considered undesirable. Vietnamese teacher Thich Nhat Hanh gives a list of examples, such as working in the arms industry, the military, police, producing or selling poison or drugs such as alcohol and tobacco.\nIn general, the first precept has been interpreted by Buddhists as a call for non-violence and pacifism. But there have been some exceptions of people who did not interpret the first precept as an opposition to war. For example, in the twentieth century, some Japanese Zen teachers wrote in support of violence in war, and some of them argued this should be seen as a means to uphold the first precept. There is some debate and controversy surrounding the problem whether a person can commit suicide, such as self-immolation, to reduce other people's suffering in the long run, such as in protest to improve a political situation in a country. Teachers like the Dalai Lama and Shengyan have rejected forms of protest like self-immolation, as well as other acts of self-harming or fasting as forms of protest.\nAlthough capital punishment goes against the first precept, as of 2001, many countries in Asia still maintained the death penalty, including Sri Lanka, Thailand, China and Taiwan. In some Buddhist countries, such as Sri Lanka and Thailand, capital punishment was applied during some periods, while during other periods no capital punishment was used at all. In other countries with Buddhism, like China and Taiwan, Buddhism, or any religion for that matter, has had no influence in policy decisions of the government. Countries with Buddhism that have abolished capital punishment include Cambodia and Hong Kong.\nIn general, Buddhist traditions oppose abortion. In many countries with Buddhist traditions such as Thailand, Taiwan, Korea and Japan, however, abortion is a widespread practice, whether legal or not. Many people in these countries consider abortion immoral, but also think it should be less prohibited. Ethicist Roy W. Perrett, following Ratanakul, argues that this field research data does not so much indicate hypocrisy, but rather points at a \"Middle Way\" in applying Buddhist doctrine to solve a moral dilemma. Buddhists tend to take \"both sides\" on the pro-life\u2013pro-choice debate, being against the taking of life of a fetus in principle, but also believing in compassion toward mothers. Similar attitudes may explain the Japanese \"mizuko kuy\u014d\" ceremony, a Buddhist memorial service for aborted children, which has led to a debate in Japanese society concerning abortion, and finally brought the Japanese to a consensus that abortion should not be taken lightly, though it should be legalized. This position, held by Japanese Buddhists, takes the middle ground between the Japanese neo-Shinto \"pro-life\" position, and the liberationist, \"pro-choice\" arguments. Keown points out, however, that this compromise does not mean a Buddhist Middle Way between two extremes, but rather incorporates two opposite perspectives. In Thailand, women who wish to have abortion usually do so in the early stages of pregnancy, because they believe the karmic consequences are less then. Having had abortion, Thai women usually make merits to compensate for the negative karma.\nSecond precept.\nTextual analysis.\nThe second precept prohibits theft, and involves the intention to steal what one perceives as not belonging to oneself (\"what is not given\") and acting successfully upon that intention. The severity of the act of theft is judged by the worth of the owner and the worth of that which is stolen. Underhand dealings, fraud, cheating and forgery are also included in this precept. Accompanying virtues are generosity, renunciation, and right livelihood, and a positive behavior is the protection of other people's property.\nIn practice.\nThe second precept includes different ways of stealing and fraud. Borrowing without permission is sometimes included, as well as gambling. Psychologist Vanchai Ariyabuddhiphongs did studies in the 2000s and 2010s in Thailand and discovered that people who did not adhere to the five precepts more often tended to believe that money was the most important goal in life, and would more often pay bribes than people who did adhere to the precepts. On the other hand, people who observed the five precepts regarded themselves as wealthier and happier than people who did not observe the precepts.\nProfessions that are seen to violate the second precept include working in the gambling industry or marketing products that are not actually required for the customer.\nThird precept.\nTextual analysis.\nThe third precept condemns sexual misconduct. This has been interpreted in classical texts to include any form of sexual misconduct, which would therefore include inappropriate touching and speech, with a married or engaged person, fornication, rape, incest, sex with a minor (under 18 years, or a person \"protected by any relative\"), and sex with a prostitute. In later texts, details such as intercourse at an inappropriate time or inappropriate place are also counted as breaches of the third precept. Masturbation goes against the spirit of the precept, because of wrongful fantasy. As a manner of uncelibacy, it is not prohibited for laypeople.\nThe third precept is explained as preventing profound spiritual damage to oneself and others. The transgression is regarded as more severe if the other person is a good person. Virtues that go hand-in-hand with the third precept are contentment, especially with one's partner, and recognition and respect for faithfulness in a marriage, and respect for the sexual nature of oneself and others.\nIn practice.\nThe third precept is interpreted as avoiding harm to another by using sexuality in the wrong way. This means not engaging with inappropriate partners, but also respecting one's personal commitment to a relationship. In some traditions, the precept also condemns adultery with a person whose spouse agrees with the act, since the nature of the act itself is condemned. Furthermore, flirting with a married person may also be regarded as a violation. Though prostitution is discouraged in the third precept, it is usually not actively prohibited by Buddhist teachers. With regard to applications of the principles of the third precept, the precept, or any Buddhist principle for that matter, is usually not connected with a stance against contraception. In traditional Buddhist societies such as Sri Lanka, pre-marital sex is considered to violate the precept, though this is not always adhered to by people who already intend to marry.\nIn the interpretation of modern teachers, the precept includes any person in a sexual or a dependent relationship, for example as someone's child, with another person, as they define the precept by terms such as \"sexual responsibility\" and \"long-term commitment\". Some modern teachers include masturbation as a violation of the precept, others include certain professions, such as those that involve sexual exploitation, prostitution or pornography, and professions that promote unhealthy sexual behavior, such as in the entertainment industry.\nFourth precept.\nTextual analysis.\nThe fourth precept involves falsehood spoken or committed to by action. Avoiding other forms of wrong speech are also considered part of this precept, consisting of malicious speech, harsh speech and gossip. A breach of the precept is considered more serious if the falsehood is motivated by an ulterior motive (rather than, for example, \"a small white lie\"). The accompanying virtue is being honest and dependable, and involves honesty in work, truthfulness to others, loyalty to superiors and gratitude to benefactors. In Buddhist texts, this precept is considered second in importance to the first precept, because a lying person is regarded to have no shame, and therefore capable of many wrongs. Untruthfulness is not only to be avoided because it harms others, but also because it goes against the Buddhist ideal of finding the truth.\nIn practice.\nThe fourth precept includes avoidance of lying and harmful speech. Some modern teachers such as Thich Nhat Hanh interpret this to include avoiding spreading false news and uncertain information. Work that involves data manipulation, false advertising or online scams can also be regarded as violations. Terwiel reports that among Thai Buddhists, the fourth precept is also seen to be broken when people insinuate, exaggerate or speak abusively or deceitfully.\nFifth precept.\nTextual analysis.\nThe fifth precept prohibits intoxication through alcohol, drugs or other means, and its virtues are mindfulness and responsibility, applied to food, work, behavior, and with regard to the nature of life. Awareness, meditation and heedfulness can also be included here. Medieval P\u0101li commentator Buddhaghosa writes that whereas violating the first four precepts may be more or less blamable depending on the person or animal affected, the fifth precept is always \"greatly blamable\", as it hinders one from understanding the Buddha's teaching and may lead one to \"madness\". In ancient China, Daoshi described alcohol as the \"doorway to laxity and idleness\" and as a cause of suffering. Nevertheless, he did describe certain cases when drinking was considered less of a problem, such as in the case of a queen distracting the king by alcohol to prevent him from murder. However, Daoshi was generally strict in his interpretations: for example, he allowed medicinal use of alcohol only in extreme cases. Early Chinese translations of the Tripitaka describe negative consequences for people breaking the fifth precept, for themselves and their families. The Chinese translation of the \"Up\u0101sika\u015bila S\u016btra\", as well as the P\u0101li version of the Sig\u0101lov\u0101da Sutta, speak of ill consequences such as loss of wealth, ill health, a bad reputation and \"stupidity\", concluding in a rebirth in hell. The \"D\u012brgh\u0101gama\" adds to that that alcohol leads to quarreling, negative states of mind and damage to one's intelligence. The Mah\u0101y\u0101na \"Brahmaj\u0101la S\u016btra\" describes the dangers of alcohol in very strong terms, including the selling of alcohol. Similar arguments against alcohol can be found in N\u0101g\u0101rjuna's writings. The strict interpretation of prohibition of alcohol consumption can be supported by the \"Up\u0101li S\u016btra\"'s statement that a disciple of the Buddha should not drink any alcohol, \"even a drop on the point of a blade of grass\". However, in the writing of some Abhidharma commentators, consumption was condemned depending on the intention with which alcohol was consumed. An example of an intention which was not condemned is taking alcohol in a small amount as a form of medicine.\nIn practice.\nThe fifth precept is regarded as important, because drinking alcohol is condemned for the sluggishness and lack of self-control it leads to, which might lead to breaking the other precepts. In Spiro's field studies, violating the fifth precept was seen as the worst of all the five precepts by half of the monks interviewed, citing the harmful consequences. Nevertheless, in practice it is often disregarded by lay people. In Thailand, drinking alcohol is fairly common, even drunkenness. Among Tibetans, drinking beer is common, though this is only slightly alcoholic. Medicinal use of alcohol is generally not frowned upon, and in some countries like Thailand and Laos, smoking is usually not regarded as a violation of the precept. Thai and Laotian monks have been known to smoke, though monks who have received more training are less likely to smoke. On a similar note, as of 2000, no Buddhist country prohibited the sale or consumption of alcohol, though in Sri Lanka Buddhist revivalists unsuccessfully attempted to get a full prohibition passed in 1956. Moreover, pre-Communist Tibet used to prohibit smoking in some areas of the capital. Monks were prohibited from smoking, and the import of tobacco was banned.\nThich Nhat Hanh also includes mindful consumption in this precept, which consists of unhealthy food, unhealthy entertainment and unhealthy conversations, among others.\nPresent trends.\nIn modern times, adherence to the precepts among Buddhists is less strict than it traditionally was. This is especially true for the third precept. For example, in Cambodia in the 1990s and 2000s, standards with regard to sexual restraint were greatly relaxed. Some Buddhist movements and communities have tried to go against the modern trend of less strict adherence to the precepts. In Cambodia, a millenarian movement led by Chan Yipon promoted the revival of the five precepts. And in the 2010s, the Supreme Sangha Council in Thailand ran a nationwide program called \"The Villages Practicing the Five Precepts\", aiming to encourage keeping the precepts, with an extensive classification and reward system.\nIn many Western Buddhist organizations, the five precepts play a major role in developing ethical guidelines. Furthermore, Buddhist teachers such as Philip Kapleau, Thich Nhat Hanh and Robert Aitken have promoted mindful consumption in the West, based on the five precepts. In another development in the West, some scholars working in the field of mindfulness training have proposed that the five precepts be introduced as a component in such trainings. Specifically, to prevent organizations from using mindfulness training to further an economical agenda with harmful results to its employees, the economy or the environment, the precepts could be used as a standardized ethical framework. As of 2015, several training programs made explicit use of the five precepts as secular, ethical guidelines. However, many mindfulness training specialists consider it problematic to teach the five precepts as part of training programs in secular contexts because of their religious origins and import.\nPeace studies scholar Theresa Der-lan Yeh notes that the five precepts address physical, economical, familial and verbal aspects of interaction, and remarks that many conflict prevention programs in schools and communities have integrated the five precepts in their curriculum. On a similar note, peace studies founder Johan Galtung describes the five precepts as the \"basic contribution of Buddhism in the creation of peace\".\nTheory of ethics.\nStudying lay and monastic ethical practice in traditional Buddhist societies, Spiro argued ethical guidelines such as the five precepts are adhered to as a means to a higher end, that is, a better rebirth or enlightenment. He therefore concluded that Buddhist ethical principles like the five precepts are similar to Western utilitarianism. Keown, however, has argued that the five precepts are regarded as rules that cannot be violated, and therefore may indicate a deontological perspective in Buddhist ethics. On the other hand, Keown has also suggested that Aristotle's virtue ethics could apply to Buddhist ethics, since the precepts are considered good in themselves, and mutually dependent on other aspects of the Buddhist path of practice. Philosopher Christopher Gowans disagrees that Buddhist ethics are deontological, arguing that virtue and consequences are also important in Buddhist ethics. Gowans argues that there is no moral theory in Buddhist ethics that covers all conceivable situations such as when two precepts may be in conflict, but is rather characterized by \"a commitment to and nontheoretical grasp of the basic Buddhist moral values\". As of 2017, many scholars of Buddhism no longer think it is useful to try to fit Buddhist ethics into a Western philosophical category.\nComparison with human rights.\nKeown has argued that the five precepts are very similar to human rights, with regard to subject matter and with regard to their universal nature. Other scholars, as well as Buddhist writers and human rights advocates, have drawn similar comparisons. For example, the following comparisons are drawn:\nKeown describes the relationship between Buddhist precepts and human rights as \"look[ing] both ways along the juridical relationship, both to what one is due to do, and to what is due to one\". On a similar note, Cambodian human rights advocates have argued that for human rights to be fully implemented in society, the strengthening of individual morality must also be addressed. Buddhist monk and scholar Phra Payutto sees the Human Rights Declaration as an unfolding and detailing of the principles that are found in the five precepts, in which a sense of ownership is given to the individual, to make legitimate claims on one's rights. He believes that human rights should be seen as a part of human development, in which one develops from moral discipline (), to concentration () and finally wisdom (). He does not believe, however, that human rights are natural rights, but rather human conventions. Buddhism scholar Somparn Promta disagrees with him. He argues that human beings do have natural rights from a Buddhist perspective, and refers to the \"att\u016bpan\u0101yika-dhamma\", a teaching in which the Buddha prescribes a kind of Golden Rule of comparing oneself with others &lt;templatestyles src=\"Crossreference/styles.css\" /&gt;. From this discourse, Promta concludes that the Buddha has laid down the five precepts in order to protect individual rights such as right of life and property: human rights are implicit within the five precepts. Academic Buntham Phunsap argues, however, that though human rights are useful in culturally pluralistic societies, they are in fact not required when society is entirely based on the five precepts. Phunsap therefore does not see human rights as part of Buddhist doctrine.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24781", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=24781", "title": "Paper, Scissors, Rock", "text": ""}
{"id": "24782", "revid": "4637213", "url": "https://en.wikipedia.org/wiki?curid=24782", "title": "Pente", "text": "Abstract strategy board game\nPente is an abstract strategy board game for two or more players, created in 1977 by Gary Gabrel. A member of the m,n,k game family, Pente stands out for its custodial capture mechanic, which allows players to \"sandwich\" pairs of stones and capture them by flanking them on either side. This changes the overall tactical assessments players face when compared to pure placement m,n,k games such as Gomoku.\nRules.\nPente is played on a 19x19 grid of intersections similar to a Go board. Players alternate placing stones of their color on empty intersections, with White always assuming the opening move. The goal of the game is to either align five or more stones of the same color in a row in any vertical, horizontal or diagonal direction or to make five captures.\nStones are captured by custodial capture (flanking an adjacent pair of an opponent's stones directly on either side with your own stones). Captures consist of exactly two stones; flanking a single stone or three or more stones does not result in a capture. As an example, if the stones are \u26ab\u26aa\u26aa\u2581 and Black places their stone so it becomes \u26ab\u26aa\u26aa\u26ab, then White's pair is removed from the board, leaving \u26ab\u2581\u2581\u26ab.\nA stone may legally be placed on any empty intersection, even if it forms a pair between two enemy stones. If the stones are placed \u26ab\u26aa\u2581\u26ab, then White may place their stone so it becomes \u26ab\u26aa\u26aa\u26ab. The pair is not captured in this case.\nA player wins if they capture ten or more stones.\nHistory.\nInvention.\nGary Gabrel invented Pente while working as a dishwasher at Hideaway Pizza, in Stillwater, Oklahoma. He took the job while in college at Oklahoma State University to pay room and board, and would play games there with his coworkers, such as Go, Checkers, and the Gomoku family of games. The latter in particular stood out to him, and he noted that it had all the qualities necessary to make a great product. Gabrel, taking the features that appealed to him, used them to invent Pente, increasing the board size, reducing the complexity, and speeding up the game to \"fit the western lifestyle.\"\nNinuki-Renju, the variant from the Gomoku family of games most similar to Pente, is played on the intersections of a 15x15 board with black and white stones. It allows captures of pairs like Pente but has complex opening rules and first player restrictions, such as requiring exactly five stones in a row to win, and restricting the first player from forming open double threes.\nHoping to secure publisher backing, Gabrel sent his new ruleset to ten different companies but was rejected by all of them. Gabrel describes the experience of approaching prospective partners:\nI went to the very few acquaintances I had, but they all rejected my propositions because they didn't understand the premise of the game, and they didn't have any respect for me as a prospective professional. \nHe continued looking for a partner who had both experience and the funds to launch his product, and found someone listed in the phone book as an \"inventor\". The man already had a project to which he was committed but agreed to help Gabrel. Together they applied for a copyright and had two hundred copies of the game made. Looking for a name, they settled on \"Pente\" (\u03c0\u03ad\u03bd\u03c4\u03b5), from the Greek word for \"five\", a reference to the win conditions of getting five in a row or making five captures. They avoided an \"oriental\"-sounding name despite the inspiration from Go and Gomoku, because according to Gabrel, feelings about the Vietnam War were still \"running high.\"\nIn 1978, Gabrel, now a manager, intended to quit his job at Hideaway Pizza and devote his time exclusively to Pente, but his partner expressed doubts, saying \"the world wasn't ready for Pente.\" Gabrel's bank rejected his request for a loan several times. He eventually secured a small loan from a different bank and borrowed money from his family, using it to buy out his partner and make a down payment on a GMC van to travel around selling copies of the game.\nHe traveled across the Southwest, staying a few days each in towns and cities in the area, selling and teaching Pente to gift-store owners, club owners, and reporters. The money gained in each town was usually enough to allow him to continue for a few weeks at a time. Through 1978 and the first half of 1979, Gabrel sold around five thousand Pente sets, with the game being played in several popular clubs in Oklahoma City. Gabrel himself was featured in newspapers across the state.\nPente Games Inc..\nWhile successful, by the second half of 1979, Gabrel was worried that he would not be able to secure the financing needed to take advantage of the growth opportunities that Pente's popularity was making possible.\nHe decided to incorporate his Pente business as Pente Games Inc. and secured financing from Dr. Lee Centraccos and his wife, Cookie Centraccos, both of whom had previous experience in the restaurant industry and cable television, and agreed to give Gabrel cash and a $100,000 line of credit in return for twenty percent of the equity in Pente games, a share of the profit, and a position on the company's board of directors.\nWith funding secured, Pente Games Inc. and Gabrel pursued what they called \"the backgammon example\", which involved promoting Pente as a fashionable and prestigious game and selling it for seventeen dollars to support its upscale image. Their target demographic was eighteen- to thirty-five\u2013year-old young professionals who were \"upscale and fashion conscious.\" They avoided mass merchandisers to avoid both the complexities of going through buyers in different parts of the country and competing with Monopoly and Risk on the shelves, targeting local and regional gift and department stores instead.\nTo save money, Gabrel packaged Pente in roll-up vinyl tubes instead of boxes, which made stocking the games on standard shelving more difficult for stores but also stood out visually and distinguished the game from other products on the market.\nIn the fall of 1979, Pente was picked up by John A. Brown, an Oklahoma department store, and sold twenty thousand sets during the Christmas season. In its first full year in business, Pente Games Inc. sold one hundred thousand sets, and by the end of the second year had sold three hundred thousand.\nBy 1983, Pente had become popular enough that it was being called \"the backgammon of the '80s\" and President Ronald Reagan and Hugh Hefner were both said to own sets.\nIn 1983, an article in the Soviet gaming magazine \"\u0418\u0433\u0440\u0430 \u0438 \u043b\u043e\u0433\u0438\u043a\u0430\" (Game and Logic) claimed a variant of Pente had independently emerged among mathematics students at Leningrad State University. This version, called \u201cPyatka\u201d (\u041f\u044f\u0442\u043a\u0430, \u201clittle five\u201d), supposedly featured a modified rule where captures could only occur diagonally, and players had to complete both a five-in-a-row and three successful captures to win. No other references to this variant are known and some researchers believe the story was a satirical fabrication aimed at Western abstract games.\nSale to Parker Brothers.\nOn July 2, 1983, Gary Gabrel sold Pente to Parker Brothers for an undisclosed sum. He was adamant that the sale would be the best thing possible for Pente and had assurances from Parker Brothers that the gameplay would not change and that they would continue to fund tournaments and promote the game. The hope was that Pente would move from being a popular new game to the status of a \"true classic\".\nDespite promises to continue to promote Pente as heavily as Gabrel and Pente Games Inc. had, the year after the purchase of Pente, Parker Brothers failed to hold the 1984 championship tournament.\nPresent.\nCurrently, Pente is a registered trademark of Hasbro for strategy-game equipment. While Hasbro ceased distribution of Pente in 1993, it later licensed the name to Winning Moves Games USA, a classic games publisher that resurrected the game in 2004. The 2004 version includes four extra stones, called power stones, that can be played in the Pente Plus version.\nProfessional play.\nThe now-defunct United States Pente Association was formed in 1982 to \"further the communication of Pente players throughout the world\" and \"assist the growth of Pente enjoyment.\" It organized in-person tournaments, held postal tournaments through the mail, kept an up-to-date list of player ratings, and released a quarterly newsletter discussing Pente news, problems, and games, among other things.\nPente tournament play is governed in Poland by Polskie Stowarzyszenie Gomoku Renju i Pente (the Polish Association of Gomoku, Renju, and Pente) jointly with Gomoku and Renju.\nFirst player advantage.\nPente, much like Gomoku, is known to favor the first player. The Pro Tournament Rule, proposed by Tom Braunlich, was adopted for standard tournament play as an attempt to mitigate this advantage and bring the win ratio at high-level play closer to around fifty percent, as is roughly the case in casual play. Analysis of approximately seven hundred fifty thousand games played online at Pente.org bears this out, demonstrating a bias of about fifty-three percent across all games and skill levels.\nFurther analysis showed that when timeouts are excluded and games are filtered out if either player's rating is below 1800 Elo, the first player advantage (FPA) increases from about 53% to about 58%. When the results are filtered to exclude games where the players ratings are below 2000 and then 2200 the FPA increases again to 59% and then 60%, respectively.\nRollie Tesh, the 1983 world champion, argued in an interview in 1984 that the Professional Pente (Pro Pente) tournament rule was not an effective solution and suggested either adopting mitigation rules from professional Renju tournaments, such as move restrictions on the first player known as forbidden moves, or adopting Keryo Pente.\nTournament Gomoku currently uses what is called the swap2 opening, where a player places three stones (two black and one white) on any of the intersections of the board. The second player can then either choose to play as white and place the fourth stone, swap colors and control the black stones, or put two more stones (one black and one white) and pass the choice of which color to play as to their opponent.\nWhen analyzing tournament data for Gomoku using identical opening rules to Pro Pente, an FPA around sixty-seven percent was calculated. When swap2 was adopted for tournament play, analysis of tournament games showed an FPA drop to about fifty-two percent.\nIn light of this, the same swap2 opening was adopted for Pente on vint.ee, Board Game Arena, and Pente.org, online gaming websites, as an attempt to mitigate FPA in high-level play.\nVariants.\nGameplay.\nKeryo.\nKeryo-Pente was proposed in 1983 by World Pente Champion Rollie Tesh as a way to balance tournament play. The first Keryo Pente tournament took place on June 16, 1984. Keryo-Pente is similar to Pente, changing only the capture rules. As in Pente, if one places five or more stones in a row in any direction, horizontally, vertically, or diagonally, that player wins the game. One may capture pairs like Pente, and in addition may capture three stones in a row by the same custodial capture method. If one captures fifteen or more stones, that player wins the game.\nRollie Tesh believed, in comparison to the first player advantage mitigation rules used by Renju and Gomoku, such as overlines and double restrictions, that Keryo Pente was a more interesting proposal. Keryo Pente mitigates the FPA by \"giving the defender more tactical chances . . . the attacker has to be more careful in his play; in regular Pente, the attack often is too easy, as if the attack plays itself.\"\nPoof.\nPoof Pente was invented by Pente player Tom Cooley. In normal Pente, when a player places a stone on an empty intersection and creates a pair flanked on either side by the opponent's stones, no capture occurs. In Poof Pente, this is not the case. Any time a pair is flanked between two of the opponent's stones, capture occurs. So, if a line of stones is arranged \u26ab\u26aa\u2581\u26ab and White places their stone so that it creates a line of \u26ab\u26aa\u26aa\u26ab, the white pair is removed from play and counted towards capture, leaving \u26ab\u2581\u2581\u26ab. All other rules are the same as in Pente.\nBoat.\nBoat Pente is a variant of Pente invented by Jay E. Hoff in the 1980s. It differs from regular Pente in how it deals with win conditions involving the creation of a Pente (five stones of one color in a row). If a Pente is made, the game continues if the opponent is able to capture a pair across the Pente. This allows the defending player to either win through capture or by forming their own Pente. However, if the defender does not win through their capture, then the attacking player can recreate the pente and win unless another capture across the pente is made. All other rules are the same as in Pente.\nNinuki-Renju.\nNinuki Renju is a predecessor to Pente and one of Gabrel's inspirations for Pente. The winner is the player either to make a perfect five in a row, or to capture five pairs of the opponent's stones. As in Pente, a pair of stones of the same color may be captured by the opponent with custodial capture (sandwiching a line of two stones lengthwise). It differs from Pente in black moving first and its use of a 15x15 board and rule restrictions on the first player, such as the rule of three and three or winning through overlines. The rule of three and three forbids the creation of two lines of three stones at the same time without an opponent's stone blocking on one side of either line. An overline refers to lines longer than five in a row. In Pente, this is counted as a win, while in Ninuki-Renju, it is not. Finally, Ninuki-Renju also allows the game to continue after a player has formed a row of five stones if their opponent can capture a pair across the line, the same as in Boat Pente.\nMultiplayer.\nMultiplayer Pente can be played with pairs of two players acting as partners, or with multiple independent players each controlling different colored stones. When capturing, the pairs \"sandwiched\" between two stones can be of any color, but the capturing stones must be the same color.\nTournament rules.\nPro is currently the most widely used tournament rule. It restricts the first and second move of the first player, in that the first stone must be placed in the center of the board and the second stone must be placed at least three intersections away from the first stone, leaving two empty intersections in between the two stones. The tournament rule was created by Tom Braunlich to reduce the advantage held by the first player.\nSwap, also known as D-Pente, or DK-Pente if applied to Keryo Pente, is a tournament rule variant that replaces the Pro rule with a version of the pie rule. It is a modified version of the opening rule proposed in the 1983 \"Pente Newsletter\" that attempts to mitigate first-player advantage more effectively than the Pro rule by allowing for a greater variety of openings. The first player places two white stones and two black stones anywhere on the board. The second player then chooses which color to play. Play proceeds from there as normal with white moving first again. The Swap opening rule is available for online play on Pente.org after being implemented at the suggestion of Pente player Don Banks.\nSwap2, borrowed from professional Gomoku, is a modification of the Swap rule. It seeks to limit the tentative first player's ability to offer known (to them) Swap openings that may be unclear to the tentative second player seeing it for the first time.\nThe first player places three stones on the board, two white and one black. The second player then has these options:\nBecause the tentative first player doesn't know where the tentative second player will place the additional stones if they take option 2 or 3, the swap2 opening protocol limits excessive studying of a line by only one of the players. Swap2 Pente is available for online play on Vint.ee and Board Game Arena.\nStrategy and tactics.\nInitiative.\nInitiative is a fundamental concept for winning Pente. Initiative is the ability to make a threat or move without having to respond to an opponent's play, while forcing them to respond to yours. A player with initiative essentially controls the state of the board and will eventually win if the other player isn't able to take it back and begin forming their own threats.\nBasic shapes.\nCertain basic shapes are fundamental to skillful Pente play. The most important are stretch twos, open trias, stretch trias, and open tesseras.\nA pair is a group of two stones directly adjacent. Pairs are the basis of Pente's capture rules and the only pattern in standard Pente susceptible to capture. Pairs are therefore very weak and vulnerable formations. Beginners are often told outright to simply avoid forming them in a game if they can due to their vulnerabilities. They can, however, be used to great advantage by intermediate and advanced players due to their ability to threaten to form open trias and their use in advanced tactics such as the wedge formation.\nA stretch two is a pattern with stones placed near each other with an empty space in between. Stretch Twos are an important skill to learn for beginners. They offer two main benefits for a player. They can threaten to form a line of three stones, an open tria, if unbound on either side by enemy stones, and they stop the player from forming a pair. A pair is vulnerable to capture by the opponent and therefore a liability to player that formed it. If the opponent places a stone adjacent to either side of the pair the defending player must now either sacrifice the pair to capture and play elsewhere, create a threat in another location that cannot be ignored by the enemy, or to protect it by extending it immediately and lose initiative.\nAn open tria is a line of three stones that are not bound on either side of the line by an opponent's stones. Open trias are powerful because they threaten to form an open tessera on the next turn if the opponent does not respond to block the tria. Open tesseras are the most powerful shape in Pente, short of the eponymous and winning \"pente\" pattern of five stones in a row. An open tria allows the player who placed it to create initiative for themselves because of how it forces the opponent to move to respond. The ability to form many open trias each turn forces the other player to respond and allows the placing player to form a powerful board presence with many options for attack, while the defending generally has to place stones in many locations all over the board that are disconnected and not immediately helpful for forming pentes and other powerful patterns.\nA stretch tria is a shape formed by a single stone placed in line with a pair of stones and a single empty space between them. The stretch tria is vulnerable to counter because an opponent can place a stone between the single stone and the pair and threaten capture. It is powerful, however, because it threatens to form a tessera, and if unbound on either side forces the opponent to respond in a similar way to open tria, creating initiative and allowing play elsewhere on the board without the opponent interfering. The stretch tria can be a very powerful tool when used in conjunction with other stretch trias. A vertical stretch tria with the pair at the top and the single stone at the bottom can be combined with another stretch tria in a diagonal or horizontal line so that both stretch trias share the same single stone. If an opponent tries to stop one of them, then the very next turn, the player who formed the stretch tria can extend the other and turn it into a tessera. If the tessera is unbound the position is likely a winning one.\nAn open tessera is a line of four stones in any direction without any of the opponent's stones on either side. If the open tessera is not cut across with certain captures that dismantle it, it cannot be stopped from forming a pente and winning the game for the player who formed it. The reason for this is that if an opponent tries to place a stone on either of the sides, the attacking player can simply place a stone at the opposite end and form a pente.\nAdvanced shapes.\nAdvanced Pente play often utilizes more complicated shapes built from basic shapes in order to achieve initiative and positional advantage. Among the most common are the I, L, h, X, and H shapes along with the 4x3 pattern, the 5x3 pattern, and the Hat.\nThe I shape is a stretch two unbound on either side and with the space to expand to an L shape in at least one of the applicable directions. The l shape, like the stretch two, protects your two stones from being captured as a pair, and has the ability to threaten to become an open tria or an L shape. It is the weakest of the \"letter\" shapes and is largely valuable for its potential rather than its strength as a pattern.\nThe L shape, pictured left, builds off the I shape by forming another split two using one of the stones from the I shape and forming an L shape. The L shape is protected from capture because of its utilization of stretch twos, but it also has more potential for threats than the I shape. The I shape can be blocked from forming an open tria by placing a stone in between it, however if the opponent tries to do the same with the L shape, then the player who formed can immediately use the stretch two not blocked to form an open tria in two different ways forcing the opponent to respond.\nA play that creates an open tria in the middle of the L shape forms the h shape. The h shape is powerful because when it has been formed the opponent must immediately respond to the open tria threat. This begins actively using the potential for threats that began with the I shape and gives the first player initiative. From the h shape a player can immediately form three other open trias. One of the open trias available forms the X shape. If the opponent fails to stop this from happening they will lose the game by allowing the attacking player to form an unstoppable open tessera.\nThe x shape continues the momentum given to it by the h shape. The x shape allows the player to choose from upwards of four open tria threats, but more importantly gives the player enough initiative to form the H shape.\nThe H shape is the most powerful of the advanced letter shapes. When done in the correct order the H allows the player who made it to end the sequence of letters in a double open three, at least one of which will end in an open tessera. The H shape is made by choosing two of the four open tria threats available to the player in the X formation. If an open tria is made on opposite ends of the X shape so that a pattern resembling a capital H is formed, then the middle of the H creates an open tria at the same time one of the ends does. The opponent cannot block both so one of them can be formed into an open tessera.\nThe 4x3 triangle is a triangle made of three stones. Two are spaced 4 intersections wide with two empty spaces in between with a third stone placed two intersections away from one of the stones with an empty space in between. This creates two perpendicular \"potential\" lines. The 4x3 triangle is powerful because it allows you to form an open tria, forcing the opponent to respond, and then form a stretch tria immediately after. Eventually, when played correctly it allows you to form an H shape along with its potential for a double tria threat.\nThe 5x3 Triangle, much like the 4x3 triangle, is a triangle formed by three stones. One side of the triangle is 5 intersections long while the other two sides are 3 intersections in length. The triangle makes use of two stretch twos that allows the player to form an open tria threat even if the opponent attempts to place a stone in between one of the two stretch twos. Rollie Tesh, the 1983 World Champion, argues that, while powerful, it is easier to see for advanced players and therefore easier to counter than several of the other triangle attack patterns that can be used.\nThe hat is a scalene triangle formed by three stones that allows the player to form a stretch tria and then immediately after an open tria, forcing the opponent to respond. Once the open tria is formed, the player can make an X shape and proceed to making an H shape, sacrificing the pair made by its stretch tria in the process.\nCaptures.\nIn addition to shapes that provide strong positional advantage, there are several tactics that take advantage of Pente's capture mechanics. Notable among these tactics are the wedge and extension.\nThe wedge is the use of a pair to block a stretch two. Players will often place stretch twos near an existing line. If the owner of the original line attempts to block the stretch two by placing a stone in-between, they're forced to create a vulnerable pair to do so. The wedge takes advantage of this common protection tactic and flips it on its head setting up the wedge maneuver so that if the player who created the stretch two attacks the pair, the player who initiated the wedge can place a stone to immediately counter by capturing a different pair elsewhere on the board.\nExtension\nExtension is a tactic used to force captures. Rather than extending a bound tria into a tessera to force the opponent to respond by blocking it, it is sometimes beneficial to \"extend\" the tria into what's called a \"stretch\" tessera. A stretch tessera is a line of three stones of one color broken by an empty space followed by another stone of the same color. If the opponent doesn't block or dismantle the stretch tessera, then the player who formed it can create a pente on the next turn. Extension into a stretch tessera is used because of how stones are aligned to the side of the line. If an opponent's stone is lined up so that when another of their stones is placed in the empty space to block, and it forms a pair, this pair can then be captured. Stretch trias can be utilized for this tactic as well so long as they're unbound and threaten to form an open tessera.\nNotation.\nThere are two notation systems developed for Pente.\nUSPA.\nThe older notation system was used by the USPA for its newsletters and documentation of tournament games. The notation system was based on an xy 2 dimensional grid used in mathematics. The center of the board was notated as \"0\". Points on the board were measured based on their distance and direction from the center. The four cardinal directions were notated as L, R, U, D for Left, Right, Up, Down, while the number of spaces in any of the directions were notated by a number signifying the empty intersections away from \"0.\" A stone two intersections right and seven intersections up would be recorded as R2U7. If a stone was on the same vertical or horizontal axis as the center point, then the \"0\" would be left off of the notation. A stone two intersections up from center and zero intersections left or right would be notated simply as U2. Capture moves were notated by placing an asterisk following the notation for the stone's location. For organization, moves were recorded as sets with white's ply on the left and black's ply on the right, and numbered in ascending order according to when they happened in the game.\nModern.\nThe newer system is notated similarly to the algebraic notation system used in chess, where horizontal values are notated by letters and vertical values are notated by numbers. In Pente this means the board is notated A through T moving left to right and 1 through 19 moving upwards. The center point is notated as \"K10.\" This form of notation is used for online play on Pente.org, Brainking.com, iggamecenter and Vint.ee.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24783", "revid": "524544", "url": "https://en.wikipedia.org/wiki?curid=24783", "title": "Pompatus", "text": "Nonce word\nPompatus (or Pompitus) () is a nonce word coined by Steve Miller in his hit single \"The Joker\" (1973).\nEtymology.\nThe word is probably a corruption of\u2014or imagined variation on\u2014the word \"puppetutes\", which was itself a coinage, originated by Vernon Green at the age of 14. Green included the word \"puppetutes\" in the lyrics of doo-wop song \"The Letter\" (1954), as performed by him and The Medallions. \"The Letter\" also included another original coinage, \"pismotality\". Presumably in homage to the Medallions' song, Steve Miller used the nonce words \"epismetology\" and \"pompatus\" in the lyrics of two of his other songs, \"Enter Maurice\" and \"The Conversation\", one of which is, like \"The Letter\", in spoken-word style.\nThe appealing oddness of the phrase \"the pompatus of love\" garnered a lot of attention, and inspired its use by others. For example, as the title of a 1996 film starring Jon Cryer.\nLyrics.\nThe lyrics of \"The Joker\" include the quatrain:\nSome people call me the space cowboy.\nYeah! Some call me the gangster of love.\nSome people call me Maurice,\n'Cause I speak of the pompatus of love.\nEach line references a track on a previous Miller album: \"Space Cowboy\" on \"Brave New World\" (1969); \"Gangster of Love\" on \"Sailor\" (1968); and \"Enter Maurice\" on \"Recall the Beginning...A Journey from Eden\" (1972), which includes the lines:\n My dearest darling, come closer to Maurice\n so I can whisper sweet words of epismetology\n in your ear and speak to you of the pompatus of love.\nAlthough Miller claims he invented the words \"epismetology\" (a metathesis of the word epistemology) and \"pompatus\", both are variants of words which Miller most likely heard in a song by Vernon Green called \"The Letter,\" which was recorded by the Los Angeles doo-wop group The Medallions in 1954.\nGreen's \"The Letter\" as performed by the Medallions had the lines:\n Oh my darling, let me whisper\n sweet words of \"pizmotality\"\n and discuss the \"puppetutes\" of love.\nGreen describes the lyrics as a description of his dream woman. \"\"Pizmotality\" described words of such secrecy that they could only be spoken to the one you loved\", Green explained. He coined the term \"puppetutes\" \"to mean a secret paper-doll fantasy figure who would be my everything and bear my children\".\nIn 2019, Miller appeared on \"The Tonight Show Starring Jimmy Fallon\" and explained that the word \"pompatus\" came from \"an old doo-wop song\" that included a term he misunderstood as \"pompatus\", and said that for years he did not know what it meant whenever someone asked him about it.\n\"Pompatus\" in pop culture.\nBecause of its peculiarity, the word \"pompatus\" has secured a niche in 20th century pop culture. Wolfman Jack frequently referenced the phrase and there is a sound clip of him using the line within the song \"Clap for the Wolfman\" by The Guess Who. \"The Pompatus of Love\", a 1996 film starring Jon Cryer, featured four men discussing a number of assorted themes, including attempts to determine the meaning of the phrase. Jon Cryer was also a writer of the film, and describes finding out the meaning of the phrase during a phone call with Vernon Green in his autobiography \"So That Happened\" in chapter 22, page 217. \nHumor columnist Dave Barry frequently refers to the song line as a source of comedic value, particularly in his 1997 book \"Dave Barry's Book of Bad Songs\". 'Pompatus' is used by Michael Ondaatje in his 2001 book \"Anil's Ghost\". Stephen King uses the word in his 2006 novel \"Lisey's Story\". Tim Dorsey uses the word in his 2010 novel, \"Gator a-Go-Go\". It was the subject of the October 9, 2011 \"Over the Hedge\" comic strip.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24785", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=24785", "title": "Prefix morpheme", "text": ""}
{"id": "24786", "revid": "13420", "url": "https://en.wikipedia.org/wiki?curid=24786", "title": "Polaris ballistic missile", "text": ""}
{"id": "24787", "revid": "46866511", "url": "https://en.wikipedia.org/wiki?curid=24787", "title": "UGM-27 Polaris", "text": "The UGM-27 Polaris missile was a two-stage solid-fueled nuclear-armed submarine-launched ballistic missile (SLBM). As the United States Navy's first SLBM, it served from 1961 to 1980.\nIn the mid-1950s the Navy was involved in the Jupiter missile project with the U.S. Army, and had influenced the design by making it squat so it would fit in submarines. However, they had concerns about the use of liquid fuel rockets on board ships, and some consideration was given to a solid fuel version, Jupiter S. In 1956, during an anti-submarine study known as Project Nobska, Edward Teller suggested that very small hydrogen bomb warheads were possible. A crash program to develop a missile suitable for carrying such warheads began as Polaris, launching its first shot less than four years later, in February 1960.\nAs the Polaris missile was fired underwater from a moving platform, it was essentially invulnerable to counterattack. This led the Navy to suggest, starting around 1959, that they be given the entire nuclear deterrent role. This led to new infighting between the Navy and the U.S. Air Force, the latter responding by developing the counterforce concept that argued for the strategic bomber and ICBM as key elements in flexible response. Polaris formed the backbone of the U.S. Navy's nuclear force aboard a number of custom-designed submarines. In 1963, the Polaris Sales Agreement led to the Royal Navy taking over the United Kingdom's nuclear role, and while some tests were carried out by the Italian Navy, this did not lead to use.\nThe Polaris missile was gradually replaced on 31 of the 41 original SSBNs in the U.S. Navy by the MIRV-capable Poseidon missile beginning in 1972. During the 1980s, these missiles were replaced on 12 of these submarines by the Trident I missile. The 10 - and SSBNs retained Polaris A-3 until 1980 because their missile tubes were not large enough to accommodate Poseidon. With beginning sea trials in 1980, these submarines were disarmed and redesignated as attack submarines to avoid exceeding the SALT II strategic arms treaty limits.\nThe Polaris missile program's complexity led to the development of new project management techniques, including the Program Evaluation and Review Technique (PERT) to replace the simpler Gantt chart methodology.\nHistory and development.\nThe Polaris missile replaced an earlier plan to create a submarine-based missile force based on a derivative of the U.S. Army Jupiter Intermediate-range ballistic missile. Chief of Naval Operations Admiral Arleigh Burke appointed Rear Admiral W. F. \"Red\" Raborn as head of a Special Project Office to develop Jupiter for the Navy in late 1955. The Jupiter missile's large diameter was a product of the need to keep the length short enough to fit in a reasonably-sized submarine. At the seminal Project Nobska conference in 1956, with Admiral Burke present, nuclear physicist Edward Teller stated that a physically small one-megaton warhead could be produced for Polaris within a few years, and this prompted Burke to leave the Jupiter program and concentrate on Polaris in December of that year. Polaris was spearheaded by the Special Project Office's Missile Branch under Rear Admiral Roderick Osgood Middleton,&lt;ref name=\"https://\"&gt;&lt;/ref&gt; and is still under the Special Project Office. Admiral Burke later was instrumental in determining the size of the Polaris submarine force, suggesting that 40\u201345 submarines with 16 missiles each would be sufficient. Eventually, the number of Polaris submarines was fixed at 41.\nThe was the first submarine capable of deploying U.S. developed submarine-launched ballistic missiles (SLBM). The responsibility of the development of SLBMs was given to the Navy and the Army. The Air Force was charged with developing a land-based intermediate range ballistic missile (IRBM), while an IRBM which could be launched by land or by sea was tasked to the Navy and Army. The Navy Special Projects (SP) office was at the head of the project. It was led by Rear Admiral William Raborn.\nOn September 13, 1955, James R. Killian, head of a special committee organized by President Eisenhower, recommended that both the Army and Navy come together under a program aimed at developing an intermediate-range ballistic missile (IRBM). The missile, later known as Jupiter, would be developed under the Joint Army-Navy Ballistic Missile Committee approved by Secretary of Defense Charles E. Wilson in early November of that year. The first IRBM boasted a liquid-fueled design. Liquid fuel is compatible with aircraft; it was considered less compatible with submarines in the West, even though in the Soviet Navy liquid-fuelled SLBMs, none of which used cryogenic components, were in overwhelming majority, and R-29RMU2 is still in service with the Russian Navy As of 2021[ [update]] (it's expected to be phased out after 2030). Solid fuels, on the other hand, make logistics and storage simpler and are safer. Not only was the Jupiter a liquid fuel design, it was also very large; even after it was designed for solid fuel, it was still a whopping 160,000 pounds. A smaller, new design would weigh much less, estimated at 30,000 pounds. The Navy would rather develop a smaller, more easily manipulated design. Edward Teller was one of the scientists encouraging the progress of smaller rockets. He argued that the technology needed to be discovered, rather than apply technology that is already created. Raborn was also convinced he could develop smaller rockets. He sent officers to make independent estimates of size to determine the plausibility of a small missile; while none of the officers could agree on a size, their findings were encouraging nonetheless.\nProject Nobska.\nThe U.S. Navy began work on nuclear-powered submarines in 1946. They launched the first one, the USS Nautilus in 1954. Nuclear powered submarines were the least vulnerable to a first strike from the Soviet Union. The next question that led to further development was what kind of arms the nuclear-powered submarines should be equipped with. In the summer of 1956, the navy sponsored a study by the National Academy of Sciences on anti-submarine warfare at Nobska Point in Woods Hole, Massachusetts, known as Project NOBSKA. The navy's intention was to have a new missile developed that would be lighter than existing missiles and cover a range up to fifteen hundred miles. A problem that needed to be solved was that this design would not be able to carry the desired one-megaton thermonuclear warhead.\nThis study brought Edward Teller from the recently formed nuclear weapons laboratory at Livermore and J. Carson Mark, representing the Los Alamos nuclear weapons laboratory. Teller was already known as a nuclear salesman, but this became the first instance where there was a big betting battle where he outbid his Los Alamos counterpart. The two knew each other well: Mark was named head of the theoretical division of Los Alamos in 1947, a job that was originally offered for Teller. Mark was a cautious physicist and no match for Teller in a bidding war.\nAt the NOBSKA summer study, Edward Teller made his famous contribution to the FBM program. Teller offered to develop a lightweight warhead of one-megaton strength within five years. He suggested that nuclear-armed torpedoes could be substituted for conventional ones to provide a new anti-submarine weapon. Livermore received the project. When Teller returned to Livermore, people were astonished by the boldness of Teller's promise. It seemed inconceivable with the current size of nuclear warheads, and Teller was challenged to support his assertion. He pointed out the trend in warhead technology, which indicated reduced weight to yield ratios in each succeeding generation. When Teller was questioned about the application of this to the FBM program, he asked, \u2018Why use a 1958 warhead in a 1965 weapon system?\u2019\nMark disagreed with Teller's prediction that the desired one-megaton warhead could be made to fit the missile envelope within the timescale envisioned. Instead, Mark suggested that half a megaton would be more realistic and he quoted a higher price and a longer deadline. This simply confirmed the validity of Teller's prediction in the Navy's eyes. Whether the warhead was half or one megaton mattered little so long as it fitted the missile and would be ready by the deadline. Almost four decades later, Teller said, referring to Mark's performance, that it was \u201can occasion when I was happy about the other person being bashful.\u201d\nWhen the Atomic Energy Commission backed up Teller's estimate in early September, Admiral Burke and the Navy Secretariat decided to support SPO in heavily pushing for the new missile, now named Polaris by Admiral Raborn.\nThere is a contention that the Navy's \"Jupiter\" missile program was unrelated to the Army program. The Navy also expressed an interest in Jupiter as an SLBM, but left the collaboration to work on their Polaris. At first, the newly assembled SPO team had the problem of making the large, liquid-fuel Jupiter IRBM work properly. Jupiter retained the short, squat shape intended to fit in naval submarines. Its sheer size and volatility of its fuel made it very unsuited to submarine launching and was only slightly more attractive for deployment on ships. The missile continued to be developed by the Army's German team in collaboration with their main contractor, Chrysler Corporation. SPO's responsibility was to develop a sea-launching platform with necessary fire control and stabilization systems for that very purpose. The original schedule was to have a ship-based IRBM system ready for operation evaluation by January 1, 1960, and a submarine-based one by January 1, 1965.\nHowever, the Navy was deeply dissatisfied with the liquid fuel IRBM. The first concern was that the cryogenic liquid fuel was not only extremely dangerous to handle, but launch-preparations were also very time-consuming. Second, an argument was made that liquid-fueled rockets gave relatively low initial acceleration, which is disadvantageous in launching a missile from a moving platform in certain sea states. By mid-July 1956, the Secretary of Defense's Scientific Advisory Committee had recommended that a solid-propellant missile program be fully instigated but not using the unsuitable Jupiter payload and guidance system.\nBy October 1956, a study group comprising key figures from Navy, industry and academic organizations considered various design parameters of the Polaris system and trade-offs between different sub-sections. The estimate that a 30,000-pound missile could deliver a suitable warhead over 1500 nautical miles was endorsed. With this optimistic assessment, the Navy now decided to scrap the Jupiter program altogether and sought out the Department of Defense to back a separate Navy missile.\nA huge surfaced submarine would carry four \"Jupiter\" missiles, which would be carried and launched horizontally. This was probably the never-built SSM-N-2 Triton program. However, a history of the Army's Jupiter program states that the Navy was involved in the Army program, but withdrew at an early stage.\nOriginally, the Navy favored cruise missile systems in a strategic role, such as the Regulus missile deployed on the earlier and a few other submarines, but a major drawback of these early cruise missile launch systems (and the Jupiter proposals) was the need to surface, and remain surfaced for some time, to launch. Submarines were very vulnerable to attack during launch, and a fully or partially fueled missile on deck was a serious hazard. The difficulty of preparing a launch in rough weather was another major drawback for these designs, but rough sea conditions did not unduly affect Polaris' submerged launches.\nIt quickly became apparent that solid-fueled ballistic missiles had advantages over cruise missiles in range and accuracy, and could be launched from a submerged submarine, improving submarine survivability.\nThe prime contractor for all three versions of Polaris was Lockheed Missiles and Space Company (now Lockheed Martin).\nThe Polaris program started development in 1956. , the first U.S. missile submarine, successfully launched the first Polaris missile from a submerged submarine on July 20, 1960. The A-2 version of the Polaris missile was essentially an upgraded A-1, and it entered service in late 1961. It was fitted on a total of 13 submarines and served until June 1974. Ongoing problems with the W-47 warhead, especially with its mechanical arming and safing equipment, led to large numbers of the missiles being recalled for modifications, and the U.S. Navy sought a replacement with either a larger yield or equivalent destructive power. The result was the W-58 warhead used in a \"cluster\" of three warheads for the Polaris A-3, the final model of the Polaris missile.\nOne of the initial problems the Navy faced in creating an SLBM was that the sea moves, while a launch platform on land does not. Waves and swells rocking the boat or submarine, as well as possible flexing of the ship's hull, had to be taken into account to properly aim the missile.\nThe Polaris development was kept on a tight schedule and the only influence that changed this was the USSR's launching of Sputnik on October 4, 1957. This caused many working on the project to want to accelerate development. The launch of a second Russian satellite and pressing public and government opinions caused Secretary Wilson to move the project along more quickly.\nThe Navy favored an underwater launch of an IRBM, although the project began with an above-water launch goal. They decided to continue the development of an underwater launch, and developed two ideas for this launch: wet and dry. Dry launch meant encasing the missile in a shell that would peel away when the missile reached the water's surface. Wet launch meant shooting the missile through the water without a casing. While the Navy was in favor of a wet launch, they developed both methods as a failsafe. They did this with the development of gas and air propulsion of the missile out of the submerged tube as well.\nThe first Polaris missile tests were given the names \u201cAX-#\u201d and later renamed \u201cA1X-#\u201d. Testing of the missiles occurred:\nIt was in between these two tests that the inertial guidance system was developed and implemented for testing.\nGuidance.\nAt the time that the Polaris project went live, submarine navigation systems accuracy was adequate for existing weapons systems. Initially, developers of Polaris were set to utilize the existing 'Stable Platform' configuration of the inertial guidance system. Created at the MIT Instrumentation Laboratory, this Ships Inertial Navigation System (SINS) was supplied to the Navy in 1954. The developers of Polaris encountered many issues from the outset of the project, including the outdated technology of the gyroscopes they would be implementing.\nThis 'Stable Platform' configuration did not account for the change in gravitational fields that the submarine would experience while it was in motion, nor did it account for the ever-altering position of the Earth. This problem raised many concerns, as this would make it nearly impossible for navigational readouts to remain accurate and reliable. A submarine equipped with ballistic missiles was of little to no use if operators had no way to direct them. The Polaris developers then turned to a guidance system that had been abandoned by the U.S. Air Force, the XN6 Autonavigator. Developed by the Autonetics Division of North American Aviation for the U.S. Air Force Navaho, the XN6 was a system designed for air-breathing cruise missiles, but by 1958 had proved useful for installment on submarines.\nA predecessor to the GPS satellite navigation system, the Transit system (later called NAVSAT), was developed because the submarines needed to know their position at launch in order for the missiles to hit their targets. Two American physicists at Johns Hopkins's Applied Physics Laboratory (APL), William Guier and George Weiffenbach, began this work in 1958. A computer small enough to fit through a submarine hatch was developed in 1958, the AN/UYK-1. It was used to interpret the Transit satellite data and send guidance information to the Polaris, which had its own guidance computer made with ultra miniaturized electronics, very advanced for its time, because there wasn't much room in a Polaris\u2014there were 16 on each submarine. The Ship's Inertial Navigation System (SINS) was developed earlier to provide a continuous dead reckoning update of the submarine's position between position fixes via other methods, such as LORAN. This was especially important in the first few years of Polaris, because Transit was not operational until 1964. By 1965 microchips similar to the Texas Instruments units made for the Minuteman II were being purchased by the Navy for the Polaris. The Minuteman guidance systems each required 2000 of these, so the Polaris guidance system may have used a similar number. To keep the price under control, the design was standardized and shared with Westinghouse Electric Company and RCA. In 1962, the price for each Minuteman chip was $50. The price dropped to $2 in 1968.\nPolaris A-3.\nThis missile replaced the earlier A-1 and A-2 models in the U.S. Navy, and also equipped the British Polaris force. The A-3 had a range extended to and a new weapon bay housing three Mk 2 re-entry vehicles (ReB or Re-Entry Body in U.S. Navy and British usage); and the new W-58 warhead of 200\u00a0kt yield. This arrangement was originally described as a \"cluster warhead\" but was replaced with the term Multiple Re-Entry Vehicle (MRV). The three warheads, also known as \"bomblets\", were spread out in a \"shotgun\" like pattern above a single target and were not independently targetable (such as a MIRV missile is). The three warheads were stated to be equivalent in destructive power to a single one-megaton warhead due to their spread out pattern on the target. The first Polaris submarine outfitted with MRV A-3's was the USS \"Daniel Webster\" in 1964. Later the Polaris A-3 missiles (but not the ReBs) were also given limited hardening to protect the missile electronics against nuclear electromagnetic pulse effects while in the boost phase. This was known as the A-3T (\"Topsy\") and was the final production model.\nPolaris A-1.\nThe initial test model of the Polaris was referred to as the AX series and made its maiden flight from Cape Canaveral on September 24, 1958. The missile failed to perform its pitch and roll maneuver and instead just flew straight up, however the flight was considered a partial success (at that time, \"partial success\" was used for any missile test that returned usable data). The next flight on October 15 failed spectacularly when the second stage ignited on the pad and took off by itself. Range Safety blew up the errant rocket while the first stage sat on the pad and burned. The third and fourth tests (December 30 and January 9) had problems due to overheating in the boattail section. This necessitated adding extra shielding and insulation to wiring and other components. When the final AX flight was conducted a year after the program began, 17 Polaris missiles had been flown of which five met all of their test objectives.\nThe first operational version, the Polaris A-1, had a range of and a single Mk 1 re-entry vehicle, carrying a single W-47-Y1 600\u00a0kt nuclear warhead, with an inertial guidance system which provided a circular error probable (CEP) of . The two-stage solid propellant missile had a length of , a body diameter of , and a launch weight of .\n was the first fleet ballistic missile submarine (SSBN in U.S. naval terminology) and she and all other Polaris submarines carried 16 missiles. Forty more SSBNs were launched in 1960 to 1966.\nWork on its W47 nuclear warhead began in 1957 at the facility that is now called the Lawrence Livermore National Laboratory by a team headed by John Foster and Harold Brown. The Navy accepted delivery of the first 16 warheads in July 1960. On May 6, 1962, a Polaris A-2 missile with a live W47 warhead was tested in the \"Frigate Bird\" test of Operation Dominic by in the central Pacific Ocean, the only American test of a live strategic nuclear missile.\nThe two stages were both steered by thrust vectoring. Inertial navigation guided the missile to about a 900\u00a0m (3,000-foot) CEP, insufficient for use against hardened targets. They were mostly useful for attacking dispersed military surface targets (airfields or radar sites), clearing a pathway for heavy bombers, although in the general public perception Polaris was a strategic second-strike retaliatory weapon.\nAfter Polaris.\nTo meet the need for greater accuracy over the longer ranges the Lockheed designers included a reentry vehicle concept, improved guidance, fire control, and navigation systems to achieve their goals. To obtain the major gains in performance of the Polaris A3 in comparison to early models, there were many improvements, including propellants and material used in the construction of the burn chambers. The later versions (the A-2, A-3, and B-3) were larger, weighed more, and had longer ranges than the A-1. The range increase was most important: The A-2 range was , the A-3 , and the B-3 . The A-3 featured multiple re-entry vehicles (MRVs) which spread the warheads about a common target, and the B-3 was to have penetration aids to counter Soviet Anti-Ballistic Missile defenses.\nThe U.S. Navy began to replace Polaris with Poseidon in 1972. The B-3 missile evolved into the C-3 Poseidon missile, which abandoned the decoy concept in favor of using the C3's greater throw-weight for larger numbers (10\u201314) of new hardened high-re-entry-speed reentry vehicles that could overwhelm Soviet defenses by sheer weight of numbers, and its high speed after re-entry. This turned out to be a less than reliable system and soon after both systems were replaced by the Trident. A proposed Undersea Long-Range Missile System (ULMS) program outlined a long-term plan which proposed the development of a longer-range missile designated as ULMS II, which was to achieve twice the range of the existing Poseidon (ULMS I) missile. In addition to a longer-range missile, a larger submarine (Ohio-class) was proposed to replace the submarines currently being used with Poseidon. The ULMS II missile system was designed to be retrofitted to the existing SSBNs, while also being fitted to the proposed Ohio-class submarine.\nIn May 1972, the term ULMS II was replaced with Trident. The Trident was to be a larger, higher-performance missile with a range capacity greater than 6000 miles. Under the agreement, the United Kingdom paid an additional 5% of their total procurement cost of 2.5 billion dollars to the U.S. government as a research and development contribution.\nIn 2002, the United States Navy announced plans to extend the life of the submarines and the D5 missiles to the year 2040. This requires a D5 Life Extension Program (D5LEP), which is currently underway. The main aim is to replace obsolete components at minimal cost by using commercial off the shelf (COTS) hardware; all the while maintaining the demonstrated performance of the existing Trident II missiles.\nSTARS.\nSTARS, the Strategic Target System program, is a BMDO program managed by the U. S. Army Space and Strategic Defense Command (SSDC). It began in 1985 in response to concerns that the supply of surplus Minuteman I boosters used to launch targets and other experiments on intercontinental ballistic missile flight trajectories in support of the Strategic Defense Initiative would be depleted by 1988. SSDC tasked Sandia National Laboratories, a Department of Energy laboratory, to develop an alternative launch vehicle using surplus Polaris boosters. The Sandia National Laboratories developed two STARS booster configurations: STARS I and STARS II.\nSTARS I consisted of refurbished Polaris first and second stages and a\ncommercially procured Orbis I third stage. It can deploy single or multiple payloads, but the multiple payloads cannot be deployed in a manner that simulates the operation of a post-boost vehicle. To meet this specific need, Sandia developed an Operations and Deployment\nExperiments Simulator (ODES), which functions as a PBV. When ODES was added to STARS I, the configuration became known as STARS II. The development phase of the STARS program was completed in 1994, and BMDO provided about $192.1 million for this effort. The operational phase began in 1995. The first STARS I flight, a hardware check-out flight, was launched in February 1993, and the second flight, a STARS I reentry vehicle experiment, was launched in August 1993.\nThe third flight, a STARS II development mission, was launched in July 1994, with all three flights considered to be successful by BMDO. The Secretary of Defense conducted a comprehensive review in 1993 of the nation's defense strategy, which drastically reduced the number of STARS launches required to support National Missile Defense (NMD)2 and BMDO funding. Due to the launch and budget reductions, the STARS office developed a draft long-range plan for the STARS program. The study examined three options:\nWhen the STARS program was started in 1985 it was perceived that there would be four launches per year. Because of the large number of anticipated launches and an unknown defect rate for surplus Polaris motors, the STARS office acquired 117 first-stage and 102 second-stage surplus motors. As of December 1994, seven first-stage and five second-stage refurbished motors were available for future launches. BMDO is currently evaluating STARS as a potential long-range system for launching targets for development tests of future Theater Missile Defense 3 systems. STARS I was first launched in 1993, and from 2004 onwards has served as the standard booster for trials of the Ground-Based Interceptor.\nBritish Polaris.\nFrom the early days of the Polaris program, American senators and naval officers suggested that the United Kingdom might use Polaris. In 1957 Chief of Naval Operations Arleigh Burke and First Sea Lord Louis Mountbatten began corresponding on the project. After the cancellations of the Blue Streak and Skybolt missiles in the 1960s, under the 1962 Nassau Agreement that emerged from meetings between Harold Macmillan and John F. Kennedy, the United States would supply Britain with Polaris missiles, launch tubes, ReBs, and the fire-control systems. Britain would make its own warheads and initially proposed to build five ballistic missile submarines, later reduced to four by the incoming Labour government of Harold Wilson, with 16 missiles to be carried on each boat. The Nassau Agreement also featured very specific wording. The intention of wording the agreement in this manner was to make it intentionally opaque. The sale of the Polaris was malleable in how an individual country could interpret it due to the diction choices taken in the Nassau Agreement. For the United States of America, the wording allowed for the sale to fall under the scope of NATO's deterrence powers. On the other hand, for the British, the sale could be viewed as a solely British deterrent. The Polaris Sales Agreement was signed on April 6, 1963.\nIn return, the British agreed to assign control over their Polaris missile targeting to the SACEUR (Supreme Allied Commander, Europe), with the provision that in a national emergency when unsupported by the NATO allies, the targeting, permission to fire, and firing of those Polaris missiles would reside with the British national authorities. Nevertheless, the consent of the British Prime Minister is and has always been required for the use of British nuclear weapons, including SLBMs.\nThe operational control of the Polaris submarines was assigned to another NATO Supreme Commander, the SACLANT (Supreme Allied Commander, Atlantic), who is based near Norfolk, Virginia, although the SACLANT routinely delegated control of the missiles to his deputy commander in the Eastern Atlantic area, COMEASTLANT, who was always a British admiral.\nPolaris was the largest project in the Royal Navy's peacetime history. Although in 1964 the new Labour government considered cancelling Polaris and turning the submarines into conventionally armed hunter-killers, it continued the program as Polaris gave Britain a global nuclear capacity\u2014perhaps east of Suez\u2014at a cost \u00a3150 million less than that of the V bomber force. By adopting many established, American, methodologies and components Polaris was finished on time and within budget. On 15 February 1968, , the lead ship of her class, became the first British vessel to fire a Polaris. All Royal Navy SSBNs have been based at Faslane, only a few miles from Holy Loch. Although one submarine of the four was always in a shipyard undergoing a refit, recent declassifications of archived files disclose that the Royal Navy deployed four boatloads of reentry vehicles and warheads, plus spare warheads for the Polaris A3T, retaining a limited ability to re-arm and put to sea the submarine that was in refit. When replaced by the Chevaline warhead, the sum total of deployed RVs and warheads was reduced to three boatloads.\nChevaline.\nThe original U.S. Navy Polaris had not been designed to penetrate anti-ballistic missile (ABM) defenses, but the Royal Navy had to ensure that its small Polaris force operating alone, and often with only one submarine on deterrent patrol, could penetrate the ABM screen around Moscow. Britain's submarines featured the Polaris A3TK missiles, a modification to the model of the Polaris used by the U.S. from 1968 to 1972. Similar concerns were present in the U.S. as well, resulting in a new American defense program.\nThe program became known as Antelope, and its purpose was to alter the Polaris. Various aspects of the Polaris, such as increasing deployment efficiency and creating ways to improve the penetrative power were specific items considered in the tests conducted during the Antelope program. The British's uncertainty with their missiles led to the examination of the Antelope program. The assessments of Antelope occurred at Aldermaston. Evidence from the evaluation of Antelope led to the British decision to undertake their program following that of the United States.\nThe result was a programme called \"Chevaline\" that added multiple decoys, chaff, and other defensive countermeasures. Its existence was only revealed in 1980, partly because of the cost overruns of the project, which had almost quadrupled the original estimate given when the project was finally approved in January 1975. The program also ran into trouble when dealing with the British Labour Party. Their Chief Scientific Adviser, Solly Zuckerman, believed that Britain no longer needed new designs for nuclear weapons and no more nuclear warhead tests would be necessary. Though the Labour Party provided a clear platform on nuclear weapons, the Chevaline program found supporters. One such individual who supported modification to the Polaris was the Secretary of State for Defence, Denis Healey.\nDespite the approval of the program, the expenses caused hurdles that augmented the time it took for the system to come to fruition. The cost of the project led to Britain's disbanding the program in 1977. The system became operational in mid-1982 on , and the last British SSBN submarine was equipped with it in mid-1987. Chevaline was withdrawn from service in 1996.\nThough Britain adopted the Antelope program methods, no input on the design came from the United States. Aldermaston was solely responsible for the Chevaline warheads.\nReplacement.\nThe British did not ask to extend the Polaris Sales Agreement to cover the Polaris successor Poseidon due to its cost. The Ministry of Defence upgraded its nuclear missiles to the longer-ranged Trident after much political wrangling within the Callaghan Labour Party government over its cost and whether it was necessary. The outgoing Prime Minister James Callaghan made his government's papers on Trident available to Margaret Thatcher's new incoming Conservative Party government, which took the decision to acquire the Trident C4 missile.\nA subsequent decision to upgrade the missile purchase to the even larger, longer-ranged Trident D5 missile was possibly taken to ensure that there was missile commonality between the U.S. Navy and the Royal Navy, which was considerably important when the Royal Navy Trident submarines were also to use the Naval Submarine Base Kings Bay.\nEven though the U.S. Navy initially deployed the Trident C4 missile in the original set of its \"Ohio\"-class submarines, it was always planned to upgrade all of these submarines to the larger and longer-ranged Trident D5 missile\u2014and that eventually, all of the C4 missiles would be eliminated from the U.S. Navy. This change-over has been completely carried out, and no Trident C4 missiles remain in service.\nThe Polaris missile remained in Royal Navy service long after it had been completely retired and scrapped by the U.S. Navy in 1980\u20131981. Consequently, many spare parts and repair facilities for the Polaris that were located in the U.S. ceased to be available (such as at Lockheed, which had moved on first to the Poseidon and then to the Trident missile).\nItaly.\nDuring its reconstruction program in 1957\u20131961, the was fitted with four Polaris missile launchers located in the aft part of the ship. The Italian usage of Polaris missiles was partially the result of the Kennedy administration. Prior to 1961, Italy and Turkey were equipped with Jupiter missiles. Three factors were instrumental in the movement away from the Jupiter project in Italy and Turkey: the president's view of the project, new understanding about weapons systems and the diminished necessity of the Jupiter missile. The Joint Congressional Committee report on Atomic Energy accentuated the three previous factors in Italy's decision to switch to the Polaris missiles.Successful tests held in 1961\u20131962 induced the United States to study a NATO Multilateral Nuclear Force (MLF), consisting of 25 international surface vessels from the US, United Kingdom, France, Italy, and West Germany, equipped with 200 Polaris nuclear missiles, enabling European allies to participate in the management of the NATO nuclear deterrent.\nThe report advocated a change from the outdated Jupiter missiles, already housed by the Italians, to the newer missile, Polaris. The report resulted in Secretary of State Dean Rusk and assistant Secretary of Defense Paul Nitze discussing the possibility of changing the warheads in the Mediterranean. The Italians were not swayed by the American's interest in modernizing their warheads. However, after the Cuban Missile Crisis, Kennedy met the Italian leader Amintore Fanfani in Washington. Fanfani conceded and went along with Kennedy's Polaris plan, despite the Italians hoping to stick with the Jupiter missile.\nThe MLF plan, as well as the Italian Polaris Program, were abandoned, both for political reasons (in consequence of the Cuban Missile Crisis) and the initial operational availability of the first SSBN , which was capable of launching SLBMs while submerged, a solution preferable to surface-launched missiles.\nItaly developed a new domestic version of the missile, the SLBM-designated Alfa. That program was cancelled in 1975 after Italy ratified the Nuclear Non-Proliferation Treaty, with the final launch of the third prototype in 1976.\nTwo Italian Navy cruisers, commissioned in 1963\u20131964, were \"fitted for but not with\" two Polaris missile launchers per ship. All four launchers were built but never installed, and were stored at the La Spezia naval facility.\nThe , launched in 1969, was also \"fitted for but not with\" four Polaris missile launchers. During refit periods in 1980\u20131983, these facilities were removed and used for other weapons and systems.\nReferences.\nNotes\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography"}
{"id": "24788", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=24788", "title": "UGM-73 Poseidon", "text": "The UGM-73 Poseidon missile was the second US Navy nuclear-armed submarine-launched ballistic missile (SLBM) system, powered by a two-stage solid-fuel rocket. It succeeded the UGM-27 Polaris beginning in 1972, bringing major advances in warheads and accuracy. It was followed by Trident I in 1979, and Trident II in 1990.\nDevelopment.\nA development study for a longer range version of the Polaris missile\u2014achieved by enlarging it to the maximum possible size allowed by existing launch tubes\u2014started in 1963. Tests had already shown that Polaris missiles could be operated without problems in launch tubes that had their fiberglass liners and locating rings removed.\nThe project was given the title Polaris B3 in November, but the missile was eventually named Poseidon C3 to emphasize the technical advances over its predecessor. The C3 was the only version of the missile produced, and it was also given the designation UGM-73A.\nSlightly longer and considerably wider and heavier than Polaris A3, Poseidon had the same range, greater payload capacity, improved accuracy, and multiple independently targetable reentry vehicle (MIRV) capability. MIRV capacity has been given as up to either ten or fourteen W68 thermonuclear warheads contained in Mark 3 reentry vehicles to multiple targets.\nAs with Polaris, starting a rocket motor when the missile was still in the submarine was considered very dangerous. Therefore, the missile was ejected from its launch tube using high pressure steam produced by a solid-fueled boiler. The main rocket motor ignited automatically when the missile had risen approximately above the submarine.\nThe first test launch took place on 16 August 1968, the first successful at-sea launch was from a surface ship, the (from July 1 to December 16, 1969), earning the ship the Meritorious Unit Commendation, and the first test launch from a submarine took place on the on 3 August 1970. The weapon officially entered service on 31 March 1971. It eventually equipped 31 -, -, and -class submarines.\nThe Royal Navy also considered adopting Poseidon in the 1970s as an upgrade to its Polaris A3T boats, and like the US this would have kept the existing hulls. Although the Navy's favoured option, the British government instead adopted Chevaline, a two warhead MRV system with decoys, on the existing Polaris airframes and later moved to the Trident D5 in new boats.\nBeginning in 1979, 12 Poseidon-equipped SSBNs were refitted with Trident I. By 1992, the Soviet Union had collapsed, 12 Ohio-class submarines had been commissioned, and the START I treaty had gone into effect, so the 31 older Poseidon- and Trident I-armed SSBNs were disarmed, withdrawing Poseidon from service.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24789", "revid": "27233032", "url": "https://en.wikipedia.org/wiki?curid=24789", "title": "Portuguese", "text": "Portuguese may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "24793", "revid": "1588193", "url": "https://en.wikipedia.org/wiki?curid=24793", "title": "POTS", "text": "POTS or Pots may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "24795", "revid": "13370122", "url": "https://en.wikipedia.org/wiki?curid=24795", "title": "Private (rank)", "text": "Lowest enlisted rank in many armed forces\nA private is a soldier, usually with the lowest rank in many armies. Soldiers with the rank of private may be conscripts or they may be professional (career) soldiers.\nThe term derives from the term \"private soldier\". \"Private\" comes from the Latin word \"privus\" or perhaps \"privo\" that meant an individual person and later an individual without an office.\nAsia.\nIndonesia.\nIn Indonesia, this rank is referred to as \"Prajurit\" (lit.\u2009'soldier'), which is the lowest rank in the Indonesian National Armed Forces. In the Indonesian Army, Indonesian Marine Corps, and Indonesian Air Force, \"Private\" has three levels, which are: Private Second Class (\"Prajurit Dua\"), Private First Class (\"Prajurit Satu\"), and Chief Private (\"Prajurit Kepala\"). After this rank, the next promotion is to Corporal.\nPeople's Republic of China.\nIn the People's Liberation Army of the People's Republic of China, Privates and Privates First Class are typically conscripted soldiers serving for a two-year period; conscripts who volunteer to continue beyond this period may become professional soldiers: \"After the end of induction training, conscripts are awarded the rank of private; in their second year they become privates first class. At the end of two years, conscripts may be demobilized or, if they volunteer, they may be selected to become NCOs. They can also attend a military academy to become officers after passing a test. In effect, the two-year conscription period is a probation period.\"\nPhilippines.\nIn the Armed Forces of the Philippines, the rank of Private is the lowest enlisted personnel rank. It is currently being used by the Philippine Army and the Philippine Marine Corps. It stands below the rank of Private first class. It is equivalent to the Airman of the Air Force and the Apprentice Seaman of the Navy and Coast Guard.\nSingapore.\nOnce recruits complete their Basic Military Training (BMT) or Basic Rescue Training (BRT), they attain the rank of private (PTE). Privates do not wear ranks on their rank holder. PTEs who performed well are promoted to the rank of Lance Corporal (LCP). The PFC rank is rarely awarded today by the Singapore Armed Forces. All private enlistees can be promoted directly to lance corporal should they meet the minimum qualifying requirements, conduct appraisal and work performance. Recruits who did not complete BMT but completed two years of National Service will be promoted to private.\nCommonwealth.\nAustralia.\nIn the Australian Army, a soldier of private rank wears no insignia. Like its British Army counterpart, the Australian Army rank of private (PTE) has other titles, depending on the corps and specification of that service member.\nThe following alternative ranks are available for privates in the Australian Army:\nNew Zealand.\nIn the New Zealand Army, a soldier of private rank wears no insignia. Like its British Army counterpart, the New Zealand Army rank of private (PTE) has other titles, depending on the corps and specification of that service member.\nThe following alternative ranks are available for privates in the New Zealand Army:\nCanada.\nIn the Canadian Army, the term private refers to the two lowest non-commissioned member ranks.\nThe lowest rank is Private (Recruit). Canadian Army recruits hold this rank upon enrolment until they complete the requirements of the next rank, a holder of this rank wears a blank rank insignia that reads \"Canada\" because they are technically considered to generically belong to the Canadian Armed Forces rather than a specific regiment.\nThe next rank is Private (Basic), is equivalent to a NATO OR-1, and a holder of this rank still wears blank rank insignia and a blank rank legend with the abbreviation of their regiment at the bottom. Canadian Army recruits hold this rank upon completion of Basic training until they complete the requirements of the next rank.\nThe rank of Private (Trained), equivalent to a NATO OR-2, is achieved following successful completion of the applicable trades training (QL3/DP1) and 30 months of service. A holder of this rank wears rank insignia consisting of a single chevron.\nThe equivalent ranks in the Royal Canadian Navy are Sailor 1st Class (for Private (Basic)), and Sailor 2nd Class (for Private (Trained)).\nThe equivalent ranks in the Royal Canadian Air Force are Aviator (Basic), and Aviator (Trained)\nCanadian Army Privates (Trained) may be known by other titles, depending on their personnel branch and their regiment's tradition:\nSouth Africa.\nIn the South African Army the lowest enlisted rank is Private. Privates do not wear insignia on their uniforms. In the different corps it is known with different titles.\nUnited Kingdom.\nIn the British Army, a private (Pte) equates to both OR-1 and OR-2 on the NATO scale, although there is no difference in rank. Privates wear no insignia. Many regiments and corps use other distinctive and descriptive names instead of private, some of these ranks have been used for centuries; others are less than 100 years old. In the contemporary British Armed Forces, the army rank of private is broadly equivalent to able seaman in the Royal Navy, aircraftman, leading aircraftman and senior aircraftman in the Royal Air Force, and marine (Mne) or bandsman, as appropriate equivalent rank in the Royal Marines. In the Boys' Brigade the rank of private is used when a boy moves from the junior section to the company section.\nDistinctive equivalents for private include:\nRoyal Marines.\nIn the Corps of Royal Marines, the rank structure follows that of British infantry regiments with the exception that the Royal Marines equivalent of private is Marine (Mne).\nDuring the course of the First World War, some Royal Marines also took the rank of Sapper, this was usually found as part of the Royal Marine Divisional Engineers of the Royal Naval Division.\nEurope.\nBelgium.\nUpon enlistment to the Belgian army, one is given the rank of (Dutch) or (French), whether one wishes to be a volunteer, non-commissioned officer or officer. Subsequent rank depends on the branch of the service: for example, at the Royal Military Academy (for officer training) one is soon promoted to the rank of (Dutch) or (French) i.e. \"corporal\". The insignia is a simple black mark or the simplified version of the Royal Military Academy's coat of arms for candidate officers.\nFinland.\nThe Finnish equivalent rank is \"sotamies\" (literally \"war man\"), although since 1973 this has been purely a paper term as all infantry troopers were renamed as \"j\u00e4\u00e4k\u00e4ri\" troops, previously reserved only to mobile light infantry. As in the British army, the various branches use different names:\nIn the Finnish Air Force, the basic rank is \"lentosotamies\" (\"airman\"). In the Finnish Navy, the basic rank is \"matruusi\" (\"seaman\") or \"tykkimies\" (\"artilleryman\") in the marine infantry.\nSpecial corps troopers may be referred by their function or unit, such as \"kaartinj\u00e4\u00e4k\u00e4ri\" (Guards jaeger), \"panssarij\u00e4\u00e4k\u00e4ri\" (armored jaeger), \"laskuvarjoj\u00e4\u00e4k\u00e4ri\" (paratroop jaeger), \"rajaj\u00e4\u00e4k\u00e4ri\" (border jaeger) or \"rannikkoj\u00e4\u00e4k\u00e4ri\" (coastal jaeger).\nFrance.\nIn the French army, \"soldat de seconde classe\" is the lowest military rank. This rank is also referred to as \"recrue\" (\"recruit\").\nHungary.\nThe name of the lowest rank in the Hungarian army (\"Magyar Honv\u00e9ds\u00e9g\") is the \"honv\u00e9d\" which means \"homeland defender\". The word is also used informally for a soldier in general of any rank (i.e. \"our \"honv\u00e9ds\"\" or an officer referred as a \"honv\u00e9dtiszt\", \"honv\u00e9d\" officer). This is because Hungarian military traditions are strictly defensive, despite the Hungarian army participating in offensives on foreign soil in both world wars. The word \"honv\u00e9d\" has been in use since the Hungarian Revolution of 1848. The term is not used for soldiers of foreign armies: a foreign soldier with no rank is called \"k\u00f6zleg\u00e9ny\", literally \"common lad\" or \"common man\".\nIreland.\nPrivate (Pte) (\"saighdi\u00far singil\" in Irish), is the lowest enlisted rank in the Irish Army. Soldiers enlist as recruits then undergo a basic course of instruction. There are three grades of private in the army. After basic training the soldier is upgraded (rather than promoted) from recruit to private 2 star (Pte 2*) (\"saighdi\u00far singil, 2 r\u00e9alta\"). After more corps-specific training (usually lasting eight weeks) the soldier is upgraded to private 3 star (Pte 3*) (\"saighdi\u00far singil, 3 r\u00e9alta\"). All are usually just addressed as \"private\", although before being upgraded, recruits may be addressed as \"recruit\".\nIn corps units, the rank designation changes. In the artillery, the rank is known as gunner (Gnr), but usually only after the completion of a gunners' course, and in the cavalry it is known as trooper (Tpr). Communications and Information Services privates are known as signalman or signalwoman. Medical orderlies are sometimes referred to as medic, although this can apply to privates and corporals.\nItaly.\nIn the Italian Army is the lowest military rank. This rank is also referred to as (meaning recruit).\n is the generic term for private. But in many specialized corps this term is never used, as a more specific, corp related, term is preferred. For instance the lowest rank in Alpine troops is , and the lowest rank in the artillery is . In the air force this is ranked as and in the navy as . While in the infantry is ranked as and in the mechanized infantry is ranked as .\nNetherlands.\nIn the Royal Netherlands Army, the \"Landmacht\", the equivalent ranks are \"soldaat\" (soldier), similar to the original French, with different classes:\nDepending on where the \"soldaat\" serves, he may be deemed a \"kanonnier\" (gunner in the artillery), \"huzaar\" (hussar in the cavalry) or \"fuselier\" (rifleman in the rifles) as well as \"commando\", \"jager\" (hunter) or \"rijder\" (rider). A \"soldaat\" can be promoted to \"korporaal\" (corporal).\nRomania.\nSoldat (\"soldier\") is the lowest rank in the Romanian Land Forces, equivalent to the rank of private. It is the equivalent of jandarm () in the Romanian Gendarmerie.\nIn day-to-day usage, the term \"soldat\" denotes every man or woman enrolled in the Romanian Armed Forces, irrespective of their actual rank or branch in which they activate.\nRussia.\nThe beginning of military service in the Armed Forces of Russia for citizens who are not in the reserve of the Russian Armed Forces, called up for military service, is considered to be the day of assignment of the military rank - Private (Sailor).\nThe word \"guards\" is added before the military rank of a serviceman serving in a guards military unit, on a guards ship.\nThe words \"justice\" or \"medical service\" are added to the military rank of a serviceman or citizen in the reserve, who has a military registration speciality in a legal or medical profile, respectively.\nThe words \"reserve\" or \"retired\" are added to the military rank of a citizen in the reserve or retired, respectively.\nIn the category of military personnel of the ship composition of the Russian Navy, the rank of private corresponds to the ship military rank of sailor.\nStudents of military schools are called \"cadets\". During their training, they are awarded the military ranks of private or sailor, and in the event of successful completion of a military educational institution, they are immediately awarded the officer rank of junior lieutenant or lieutenant, depending on the school.\nUnited States.\nUnited States Army.\nIn the United States Army, private is used for the two lowest enlisted ranks, just below private first class (E-3) or PFC. The lowest rank is \"private (E-1)\" or PV1, sometimes referred to as \"recruit\", but this rank can also be held by some soldiers after punishment through the Uniform Code of Military Justice, or by soldiers punished under the UCMJ as a demotion until they are discharged. A PV1 wears no uniform rank insignia; since the advent of the Army Combat Uniform (ACU), the slang term \"fuzzy\" has come into vogue, referring to the blank velcro patch area on the ACU where the rank would normally be placed.\nThe single \"stripe\" rank insignia of private was originally the insignia of a private first class (Grade 6) beginning in 1921, prior to that there was no insignia at all for privates. In May of 1968, the Army created the current PFC rank and the single stripe moved to E-2. \nThe second rank, \"private (E-2)\" or PV2, wears a single chevron, known colloquially as \"mosquito wings\". In pay tables, the rank is listed as \"private second class.\" Advancement to PV2 is automatic after six months' time in service, but may be shortened to four months by a waiver. A person who has earned the Eagle Scout award or the Gold Award or has completed at least two years of JROTC may enlist at any time at the rank of PV2. The third rank is private first class or \"PFC\", which is designated by an arc or \"rocker\" under the chevron. The term of address \"Private\" may be properly applied to any Army soldier E-1 (PV1) to E-3 (PFC). The abbreviation \"Pvt\" may be used whenever the specific grade of private is immaterial (such as in tables of organization and equipment).\nUnited States Marine Corps.\nIn the United States Marine Corps, \"private\" (Pvt) refers only to the lowest enlisted rank, also known as a \"boot\", just below private first class. A Marine Corps private wears no insignia on their uniform and is sometimes described as having a \"slick sleeve\" for this reason. Most new, non-officer marines (a.k.a. \"boots\" or \"non-rates\") begin their military career as privates. In the Marine Corps, privates are addressed as \"Private\" to differentiate them from Private First Class Marines who are often called PFCs.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24797", "revid": "47732363", "url": "https://en.wikipedia.org/wiki?curid=24797", "title": "Proclus", "text": "5th-century Greek Neoplatonist philosopher\nProclus Lycius (; 8 February 412\u00a0\u2013 17 April 485), called Proclus the Successor (, ), was a Greek Neoplatonist philosopher, one of the last major classical philosophers of late antiquity. He set forth one of the most elaborate and fully developed systems of Neoplatonism and, through later interpreters and translators, exerted an influence on Byzantine philosophy, early Islamic philosophy, scholastic philosophy, and German idealism, especially G. W. F. Hegel, who called Proclus's \"Platonic Theology\" \"the true turning point or transition from ancient to modern times, from ancient philosophy to Christianity.\"\nBiography.\nThe primary source for the life of Proclus is the eulogy \"Proclus\", \"or On Happiness\" that was written for him upon his death by his successor, Marinus. Marinus's biography set out to prove that Proclus reached the peak of virtue and attained eudaimonia. There are also a few details about the time in which he lived in the similarly structured \"Life of Isidore\" written by the philosopher Damascius in the following century.\nAccording to Marinus, Proclus was born in 412\u00a0AD in Constantinople to a family of high social status from Lycia, and raised in Xanthus. He studied rhetoric, philosophy and mathematics in Alexandria, with the intent of pursuing a judicial position like his father. Before completing his studies, he returned to Constantinople when his rector, his principal instructor (one Leonas), had business there. Proclus became a successful practicing lawyer. However, the experience of the practice of law made Proclus realize that he truly preferred philosophy. He returned to Alexandria, and began determinedly studying the works of Aristotle under Olympiodorus the Elder. He also began studying mathematics during this period as well with a teacher named Heron (no relation to Hero of Alexandria, who was also known as Heron). As a gifted student, he eventually became dissatisfied with the level of philosophical instruction available in Alexandria, and went to Athens, philosophical center of the day, in 431 to study at the Neoplatonic successor of the New Academy, where he was taught by Plutarch of Athens (not to be confused with Plutarch of Chaeronea), Syrianus, and Asclepigenia; he succeeded Syrianus as head of the Academy in 437, and would in turn be succeeded on his death by Marinus of Neapolis. He lived in Athens as a vegetarian bachelor, prosperous and generous to his friends, until the end of his life, except for a one-year exile, to avoid pressure from Christian authorities. Marinus reports that he was writing seven hundred lines each day.\nPhilosophy.\nOne challenge with determining Proclus' specific doctrines is that the Neoplatonists of his time did not consider themselves innovators; they believed themselves to be the transmitters of the correct interpretations of Plato himself. Although the neoplatonic doctrines are much different from the doctrines in Plato's dialogues, it's often difficult to distinguish between different Neoplatonic thinkers and determine what is original to each one. For Proclus, this is largely only possible with Plotinus, the only other Neoplatonic writer for whom a significant amount of writings survive.\nProclus, like Plotinus and many of the other Neoplatonists, agreed on the three hypostases of Neoplatonism: The One (hen), The Intellect (nous) and The Soul (psyche), and wrote a commentary on the Enneads, of which only fragments survive. At other times he criticizes Plotinus' views, such as the prime mover. Unlike Plotinus, Proclus also did not hold that matter was evil, an idea that caused contradictions in the system of Plotinus. It is difficult to determine what, if anything, is different between the doctrines of Proclus and Syrianus: for the latter, only a commentary on Aristotle's Metaphysics survives, and Proclus never criticizes his teacher in any of his preserved writings.\nThe particular characteristic of Proclus's system is his elaboration of a level of individual ones, called \"henads\", between the One which is before being and intelligible divinity. The henads exist \"superabundantly\", also beyond being, but they stand at the head of chains of causation (\"seirai\") and in some manner give to these chains their particular character. He identifies them with the Greek gods, so one henad might be Apollo and be the cause of all things apollonian, while another might be Helios and be the cause of all \"sunny\" things. Each henad participates in every other henad, according to its character. What appears to be multiplicity is not multiplicity at all, because any henad may rightly be considered the center of the polycentric system. According to Proclus, philosophy is the activity which can liberate the soul from a subjection to bodily passions, remind it of its origin in Soul, Intellect, and the One, and prepare it not only to ascend to the higher levels while still in this life, but to avoid falling immediately back into a new body after death. Because the soul's attention, while inhabiting a body, is turned so far away from its origin in the intelligible world, Proclus thinks that we need to make use of bodily reminders of our spiritual origin. In this he agrees with the doctrines of theurgy put forward by Iamblichus. Theurgy is possible because the powers of the gods (the \"henads\") extend through their series of causation even down to the material world. And by certain power-laden words, acts, and objects, the soul can be drawn back up the series, so to speak. Proclus himself was a devotee of many of the religions in Athens, considering that the power of the gods could be present in these various approaches.\nWorks.\nCommentaries on Plato.\nThe majority of Proclus's works are commentaries on dialogues of Plato (\"Alcibiades\", \"Cratylus\", \"Parmenides\", \"Republic\", \"Timaeus\"). In these commentaries, he presents his own philosophical system as a faithful interpretation of Plato, and in this he did not differ from other Neoplatonists, as he considered that \"nothing in Plato's corpus is unintended or there by chance\", that \"Plato's writings were divinely inspired\" (\u1f41 \u03b8\u03b5\u1fd6\u03bf\u03c2 \u03a0\u03bb\u03ac\u03c4\u03c9\u03bd \"ho theios Platon\"\u2014the divine Plato, inspired by the gods), that \"the formal structure and the content of Platonic texts imitated those of the universe\", and therefore that they spoke often of things under a veil, hiding the truth from the philosophically uninitiated. Proclus was however a close reader of Plato, and quite often makes very astute points about his Platonic sources.\nCommentary on Timaeus.\nIn his commentary on Plato's \"Timaeus\" Proclus explains the role the Soul as a principle has in mediating the Forms in Intellect to the body of the material world as a whole. The Soul is constructed through certain proportions, described mathematically in the \"Timaeus\", which allow it to make Body as a divided image of its own arithmetical and geometrical ideas.\nSystematic works.\nIn addition to his commentaries, Proclus wrote two major systematic works. The \"Elements of Theology\" (\u03a3\u03c4\u03bf\u03b9\u03c7\u03b5\u03af\u03c9\u03c3\u03b9\u03c2 \u03b8\u03b5\u03bf\u03bb\u03bf\u03b3\u03b9\u03ba\u03ae) consists of 211 propositions, each followed by a proof, beginning from the existence of the One (divine Unity) and ending with the descent of individual souls into the material world. The \"Platonic Theology\" (\u03a0\u03b5\u03c1\u1f76 \u03c4\u1fc6\u03c2 \u03ba\u03b1\u03c4\u1f70 \u03a0\u03bb\u03ac\u03c4\u03c9\u03bd\u03b1 \u03b8\u03b5\u03bf\u03bb\u03bf\u03b3\u03af\u03b1\u03c2) is a systematization of material from Platonic dialogues, showing from them the characteristics of the divine orders, the part of the universe which is closest to the One.\nWe also have three essays, extant only in Latin translation: \"Ten doubts concerning providence\" (); \"On providence and fate\" (); \"On the existence of evils\" (\"\").\nOther works.\nCommentary on Euclid's Elements.\nProclus, the scholiast to Euclid, knew Eudemus of Rhodes' \"History of Geometry\" well, and gave a short sketch of the early history of geometry, which appeared to be founded on the older, lost book of Eudemus. The passage has been referred to as \"the Eudemian summary\", and determines some approximate dates, which otherwise might have remained unknown. The influential commentary on the first book of Euclid's \"Elements\" is one of the most valuable sources regarding the history of ancient mathematics, and its Platonic account of the status of mathematical objects was influential.\nIn this work, Proclus also listed the first mathematicians associated with Plato: a mature set of mathematicians (Leodamas of Thasos, Archytas of Taras, and Theaetetus), a second set of younger mathematicians (Neoclides, Eudoxus of Cnidus), and a third yet younger set (Amyntas, Menaechmus and his brother Dinostratus, Theudius of Magnesia, Hermotimus of Colophon and Philip of Opus). Some of these mathematicians were influential in arranging the \"Elements\" that Euclid later published.\nTheology of Plato.\nProclus authored a theology of Plato, which is text concerned with the divine hierarchies and their complex ramifications.\nOthers.\nA commentary on the \"Works and Days\" of Hesiod (incomplete); some scholia on Homer.\nLost works.\nA number of his Platonic commentaries are lost. In addition to the Alcibiades, the Cratylus, the Timaeus, and the Parmenides, he also wrote commentaries on the remainder of the dialogues in the Neoplatonic curriculum. He also wrote a commentary on the Organon, as well as prolegomena to both Plato and Aristotle.\nLegacy.\nProclus exerted a great deal of influence on Medieval philosophy, though largely indirectly, through the works of the commentator Pseudo-Dionysius the Areopagite. This late-5th- or early-6th-century Christian Greek author wrote under the pseudonym Dionysius the Areopagite, the figure converted by St. Paul in Athens. Because of this pseudonym, his writings were taken to have almost apostolic authority. He is an original Christian writer, and in his works can be found a great number of Proclus's metaphysical principles.\nAnother important source for the influence of Proclus on the Middle Ages is Boethius's \"Consolation of Philosophy\", which has a number of Proclus principles and motifs. The central poem of Book III is a summary of Proclus's \"Commentary on the Timaeus\", and Book V contains the important principle of Proclus that things are known not according to their own nature, but according to the character of the knowing subject.\nA summary of Proclus's \"Elements of Theology\" circulated under the name \"Liber de Causis\" (\"Book of Causes\"). This book is of uncertain origin, but circulated in the Arabic world as a work of Aristotle, and was translated into Latin as such. It had great authority because of its supposed Aristotelian origin, and it was only when Proclus's \"Elements\" were translated into Latin that Thomas Aquinas realised its true origin. Proclus's works also exercised an influence during the Renaissance through figures such as Nicholas of Cusa and Marsilio Ficino. The most significant early scholar of Proclus in the English-speaking world was Thomas Taylor, who produced English translations of most of his works.\nThe crater Proclus on the Moon is named after him.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\nProclus's works in Translation.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nThe \"Liber de Causis\" (Book of Causes) is not a work by Proclus, but a summary of his work the \"Elements of Theology\", likely written by an Arabic interpreter.\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nMonographs\nCollections\nBibliographic resources"}
{"id": "24799", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=24799", "title": "Production team", "text": "A production team is the group of technical staff who produce a play, television show, recording, or film. Generally the term refers to all individuals responsible for the technical aspects of creating of a particular product, regardless of where in the process their expertise is required, or how long they are involved in the project. For example, in a theatrical performance, the production team includes not only the running crew, but also the theatrical producer, designers and theatre direction.\nA production company in filmmaking is composed of a film crew and a television crew in video production.\nIn music, the term \"production team\" typically refers to a group of individuals filling the role of \"record producer\" usually reserved for one individual. Some examples of musical production teams include Matmos and D-Influence."}
{"id": "24801", "revid": "753665", "url": "https://en.wikipedia.org/wiki?curid=24801", "title": "Pinconning cheese", "text": "Type of semi-hard cheese\nPinconning cheese is an aged semi-hard whole cow's milk, Colby-style cheese named after Pinconning, Michigan. It is made and distributed by a number of different companies including Pinconning Cheese Company and Wilson's (Horn) Cheese Shoppe in Pinconning, Michigan, and Williams Cheese in nearby Linwood, Michigan. \nIt is available as cheese curds and in mild or aged many years, to sharpness levels of medium mild, medium sharp, sharp, extra sharp, and super sharp (10 plus years old). Its hardness and texture change, and sharpness increases with aging. Pinconning cheese's flavor and texture are rich, creamy, and open. It is an unusual and different experience from eating traditional Colby cheese. It is often used as a replacement for Cheddar and Colby in dishes such as macaroni and souffl\u00e9s.\"\nIn 2020, production was .\nIt was developed and first produced by Daniel Horn in 1915 on a farm at the northeast corner of Mount Forest and Mackinaw Roads. \nThe product is still based on the original family recipe and made and produced by companies related to the originator.\nPinconning was chosen as the 'Cheese Capital of Michigan' based on Pinconning cheese.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24802", "revid": "41833184", "url": "https://en.wikipedia.org/wiki?curid=24802", "title": "Papacy", "text": ""}
{"id": "24805", "revid": "11096", "url": "https://en.wikipedia.org/wiki?curid=24805", "title": "Prophet", "text": "Intermediary between humanity and the divine\nIn religion, a prophet or prophetess is an individual who is regarded as being in contact with a divine being and is said to speak on behalf of that being, serving as an intermediary with humanity by delivering messages or teachings from the supernatural source to other people. The message that the prophet conveys is called a prophecy.\nProphethood has existed in many cultures and religions throughout history, including Mesopotamian religion, Zoroastrianism, Judaism, Christianity, Manichaeism, Islam, the Bah\u00e1\u02bc\u00ed Faith, and Thelema.\nEtymology.\nThe English word \"prophet\" is the transliteration of a compound Greek word derived from \"pro\" (before/toward) and \"phesein\" (to tell); thus, a \u03c0\u03c1\u03bf\u03c6\u03ae\u03c4\u03b7\u03c2 (\"proph\u1e17t\u0113s\") is someone who conveys messages from the divine to humans, including occasionally foretelling future events. In a different interpretation, it means advocate or speaker. It is used to translate the Hebrew word \u05e0\u05b8\u05d1\u05b4\u05d9\u05d0 (\"n\u0101v\u00ee\") in the Septuagint and the Arabic word \u0646\u0628\u064a (\"nab\u012b\"). W.F. Albright points to the Akkadian Nabu for the origin of these Hebrew (\u05e0\u05b8\u05d1\u05b4\u05d9\u05d0 (\"n\u0101v\u00ee\") and the Arabic \u0646\u0628\u064a (\"nab\u012b\") words.\nThe Akkadian \"nab\u00fb\" means \"announcer\" or \"authorised person\", derived from the Semitic root n-b-y or nb\u02be. It is cognate with , , and , all meaning 'prophet'.\nIn Hebrew, the word \u05e0\u05b8\u05d1\u05b4\u05d9\u05d0 (\"n\u0101v\u00ee\"), \"spokesperson\", traditionally translates as \"prophet\". The second subdivision of the Tanakh, Nevi'im, is devoted to the Hebrew prophets. The meaning of \"navi\" is perhaps described in Deuteronomy 18:18, where God said, \"...and I will put My words in his mouth, and he shall speak unto them all that I shall command him.\" Thus, a \"navi\" was thought to be the \"mouth\" of God. A Jewish tradition was that the root nun-bet-alef (\"navi\") is based on the two-letter root nun-bet which denotes hollowness or openness; to receive transcendental wisdom, one must make oneself \"open\".\nMesopotamian origins.\nBefore the advent of Zoroastrianism and the prophetic tradition established by Zoroaster, various ancient civilizations had individuals who served as intermediaries between humanity and the divine. In ancient Sumer, for instance, figures such as the \"ensi\" or \"lugal\" fulfilled roles akin to prophets, offering guidance and interpreting divine will through rituals, omens, and prayers. The \"ensi\" was considered a representative of the city-state's patron deity. The functions of a would include certain ceremonial and cultic activities, arbitration in border disputes, and military defence against external enemies. The \"ensis\" of Lagash would sometimes refer to the city's patron deity, Ningirsu, as their (\"master\"). All of the above is connected to the possibly priestly or sacral character of the titles \"ensi\" and especially \"en\" (the latter term continuing to designate priests in subsequent times).\nThese prophets, while lacking the systematic theological framework found in later traditions, laid the groundwork for the concept of prophethood by demonstrating a connection with the divine and providing spiritual leadership within their communities. Despite the absence of codified scripture or organized religious institutions, these pre-Zoroastrian prophetic figures played a crucial role in shaping early religious thought and practices, paving the way for the structured prophetic tradition that emerged with Zoroaster and subsequent religious traditions.\nZoroastrianism.\nZoroastrianism holds a significant position in shaping the concept of prophets and prophecy. Founded by the revered figure Zoroaster (or Zarathustra) in ancient Persia around the 6th century BCE, Zoroastrianism introduced fundamental ideas that profoundly influenced subsequent religious and philosophical traditions, particularly in its portrayal of prophetic figures.\nAt the heart of Zoroastrian belief lies the concept of a singular supreme deity, Ahura Mazda, engaged in an eternal struggle against the forces of darkness and chaos, embodied by Angra Mainyu. Zoroaster, as the primary prophet of this faith, received divine revelations and visions from Ahura Mazda, which formed the basis of the Avesta, the sacred scripture of Zoroastrianism.\nZoroaster's role as a prophet established a template for future religious leaders and visionaries. He articulated monotheistic principles, ethical dualism, and the idea of a cosmic battle between good and evil, influencing not only the religious landscape of ancient Persia but also later traditions such as Judaism, Christianity, Islam, and Thelema.\nThe legacy of Zoroastrianism in shaping the understanding of prophets is profound. Zoroaster's direct communication with the divine, his role as a mediator between humanity and the divine will, and his teachings about moral righteousness laid the groundwork for the concept of prophethood as it evolved in subsequent religious traditions.\nInfluence from Zoroastrian thought can be seen in the characterization of prophets as individuals chosen by a single supreme deity to convey divine messages, guide communities, and uphold moral principles. The structured prophetic tradition established by Zoroaster set a precedent for future prophets, shaping how societies perceive and interact with visionary figures throughout history.\nWhile other ancient civilizations may have had individuals who served similar functions, Zoroastrianism's systematic approach to prophecy and its enduring influence on subsequent religious thought solidified its place in history as a foundational example of prophetic tradition, enriching humanity's understanding of the divine and the role of prophets in conveying its will.\nJudaism.\nSome examples of prophets in the Tanakh include Abraham, Moses, Miriam, Isaiah, Samuel, Ezekiel, Malachi, and Job. Moses is considered the most important prophet in Judaism. On one occasion during the Exodus journey, \"the spirit which was upon Moses\" was passed to seventy elders, who were also able to prophesy for one time only, but mostly they could not prophesy again. Moses expressed the hope that \"all the LORD's people\" could be prophets. In addition to writing and speaking messages from God, Israelite or Judean \"nevi'im\" (\"spokespersons\", \"prophets\") often acted out prophetic parables in their life. For example, in order to contrast the people's disobedience with the obedience of the Rechabites, God has Jeremiah invite the Rechabites to drink wine, in disobedience to their ancestor's command. The Rechabites refuse, for which God commends them. Other prophetic parables acted out by Jeremiah include burying a linen belt so that it gets ruined to illustrate how God intends to ruin Judah's pride. Likewise, Jeremiah buys a clay jar and smashes it in the Valley of Ben Hinnom in front of elders and priests to illustrate that God will smash the nation of Judah and the city of Judah beyond repair. God instructs Jeremiah to make a yoke from wood and leather straps and to put it on his own neck to demonstrate how God will put the nation under the yoke of Nebuchadnezzar, king of Babylon. In a similar way, the prophet Isaiah had to walk stripped and barefoot for three years to illustrate the coming captivity, and the prophet Ezekiel had to lie on his side for 390 days and to eat measured food to illustrate the coming siege.\nProphetic assignment is usually portrayed as rigorous and exacting in the Hebrew Bible, and prophets were often the target of persecution and opposition. God's personal prediction for Jeremiah, \"And they shall fight against thee; but they shall not prevail against thee,\" was performed many times in the biblical narrative as Jeremiah warned of destruction of those who continued to refuse repentance and accept more moderate consequences. In return for his adherence to God's discipline and speaking God's words, Jeremiah was attacked by his own brothers, beaten and put into the stocks by a priest and false prophet, imprisoned by the king, threatened with death, thrown into a cistern by Judah's officials, and opposed by a false prophet. Likewise, Isaiah was told by his hearers who rejected his message, \"Leave the way! Get off the path! Let us hear no more about the Holy One of Israel!\" The life of Moses being threatened by Pharaoh is another example.\nAccording to I Samuel 9:9, the old name for navi is \"ro'eh\", \u05e8\u05b9\u05d0\u05b6\u05d4, which literally means \"seer\". That could document an ancient shift, from viewing prophets as seers for hire to viewing them as moral teachers. L. C. Allen (1971) comments that in the First Temple Era, there were essentially seer-priests belonging to a guild, who performed divination, rituals, and sacrifices, and were scribes; and beside these were canonical prophets, who did none of these things (and condemned divination), but came to deliver a message. The seer-priests were usually attached to a local shrine or temple, such as Shiloh, and initiated others into that priesthood, acting as a mystical craft-guild with apprentices and recruitment. Canonical prophets were not organised this way.\nJewish tradition - unlike Christian and Islamic practice - does not regard Daniel as a prophet.\nA Jewish tradition suggests that there were twice as many prophets as the number which left Egypt, which would make 1,200,000 prophets. The Talmud recognizes 48 male prophets who bequeathed permanent messages to humankind. According to the Talmud, there were also seven women counted as prophetesses whose message bears relevance for all generations: Sarah, Miriam, Devorah, Hannah (mother of the prophet Samuel), Abigail (a wife of King David), Huldah (from the time of Jeremiah), and Esther. The Talmudic and Biblical commentator Rashi points out that Rebecca, Rachel, and Leah were also prophets.\nIsaiah 8:3-4 refers to Isaiah's wife, who bore his son Maher-shalal-hash-baz as \"the prophetess\"; she is not referred to elsewhere.\nProphets in the Tanakh are not always Jews;\nnote for example the non-Jewish prophet Balaam in Numbers 22. According to the Talmud, Obadiah is said to have been a convert to Judaism.\nThe last \"nevi'im\" mentioned in the Jewish Bible are Haggai, Zechariah, and Malachi, all of whom lived at the end of the 70-year Babylonian exile of c. 586 to 539 BCE. The Talmud (Sanhedrin 11a) states that Haggai, Zachariah, and Malachi were the last prophets, and later times have known only the \"Bath Kol\" (\u05d1\u05ea \u05e7\u05d5\u05dc, lit. \"daughter of a voice\", \"voice of God\").\nChristianity.\nTraditional definitions.\nIn Christianity, a prophet (or seer) is one inspired by God through the Holy Spirit to deliver a message. This includes Jewish prophets active before the church began and the prophets active in the Christian church. Some Christian denominations limit a prophet's message to words intended only for active members of a congregation, excluding social or political messages. However, the Bible has several occasions in which prophets were called to deliver social or political messages. The reception of a message is termed revelation and the delivery of the message is termed prophecy.\nThe term \"prophet\" applies to those who receive public or private revelation. Public revelation, in Catholicism, is part of the Deposit of faith, the revelation of which was completed by Jesus; whereas private revelation does not add to the Deposit. The term \"deposit of faith\" refers to the entirety of Jesus Christ's revelation, and is passed to successive generations through scripture and the traditions of the church.\nThe Bible applies the appellation 'false prophet' to anyone who preaches a Gospel contrary to that delivered to the apostles and recorded in Sacred Scripture. One Old Testament text in Deuteronomy contains a warning against those who prophesy events which do not come to pass and says they should be put to death. Elsewhere a false prophet may be someone who is purposely trying to deceive, is delusional, under the influence of Satan or is speaking from his own spirit.\nCatholicism.\nSix of the Minor Prophets are commemorated in December. Each encouraged people to return to God, to repent of past sins, and to recognize God's presence even in their difficulties.\n\"Jesus Christ is the one whom the Father anointed with the Holy Spirit and established as priest, prophet, and king. The whole People of God participates in these three offices of Christ and bears the responsibilities for mission and service that flow from them.\" The laity act prophetically when they speak the truth, and live the Gospel by example before their families, neighbors, and co-workers. The Old Testament prophets defended the poor and powerless \"and inspire Catholic Social Teaching on the preferential option for the poor, workers\u2019 rights, and justice and peace.\"\nOngoing prophecy.\nChristians who believe that the Holy Spirit continues to give spiritual gifts to Christians are known as continuationists. These charismata may include prophecy, tongues, miraculous healing ability, and discernment (Matthew 12:32 KJV \"Whosoever speaketh a word against the Son of Man, it shall be forgiven him: but whosoever speaketh against the Holy Ghost, it shall not be forgiven him, neither in this world, neither in the world to come.\"). Cessationists believe that these gifts were given only in New Testament times and that they ceased after the last apostle died.\nThe last prophet of the Old Covenant before the arrival of Jesus is John the Baptist. New Testament passages that explicitly discuss prophets existing after the death and resurrection of Christ include Revelation 11:10, Matthew 10:40\u201341 and 23:34, John 13:20 and 15:20 and Acts 11:25\u201330, 13:1 and 15:32.\nThe \"Didache\" gives extensive instruction in how to distinguish between true and false prophets, as well as commands regarding tithes to prophets in the church. Irenaeus, wrote of 2nd-century believers with the gift of prophecy, while Justin Martyr argued in his \"Dialogue with Trypho\" that prophets were not found among the Jews in his time, but that the church had prophets. \"The Shepherd of Hermas\" describes revelation in a vision regarding the proper operation of prophecy in the church. Eusebius mentions that Quadratus and Ammia of Philadelphia were both prominent prophets following the age of the Twelve Apostles. Tertullian, writing of the church meetings of the Montanists (to whom he belonged), described in detail the practice of prophecy in the 2nd-century church.\nA number of later Christian saints were said to have powers of prophecy, such as Columba of Iona (521\u2013597), Saint Malachy (1094\u20131148) or Padre Pio (1887\u20131968). Marian apparitions like those at Fatima in 1917 or at Kibeho in Rwanda in the 1980s often included prophetic predictions regarding the future of the world as well as of the local areas they occurred in.\nProphetic movements in particular can be traced throughout the Christian Church's history, expressing themselves in (for example) Montanism, Novatianism, Donatism, Franciscanism, Anabaptism, Camisard enthusiasm, Puritanism, Quakerism, Quietism, Lutheranism and Radical Pietism. Modern Pentecostals and Charismatics, members of movements which together comprised approximately 584 million people as of 2011[ [update]], believe in the contemporary function of the gift of prophecy, and some in these movements, especially those within the Apostolic-Prophetic Movement, allow for idea that God may continue to gift the church with some individuals who are prophets.\nSome Christian sects recognize the existence of \"modern-day\" prophets. One such denomination is the Church of Jesus Christ of Latter-day Saints, which teaches that God still communicates with humankind through prophecy.\nLatter Day Saint movement.\nJoseph Smith, who established the Church of Christ in 1830, is considered a prophet by members of the Latter Day Saint movement, of which the Church of Jesus Christ of Latter-day Saints (LDS Church) is the largest denomination. Additionally, many churches within the movement believe in a succession of modern prophets (accepted by Latter Day Saints as \"prophets, seers, and revelators\") since the time of Joseph Smith, Dallin H. Oaks is the current Prophet and President of the Church of Jesus Christ of Latter-day Saints.\nAdventism.\nBaptist preacher William Miller is credited with beginning the mid-19th century North American religious movement now known as Adventism. He announced a Second Coming, resulting in the Great Disappointment.\nSeventh-day Adventist.\nThe Seventh-day Adventist Church, which was established in 1863, believes that Ellen G. White, one of the church's founders, was given the spiritual gift of prophecy.\nBranch Davidians.\nThe Branch Davidians are a religious cult which was founded in 1959 by Benjamin Roden as an offshoot of the Seventh-Day Adventist Church. David Koresh, who died in the Waco Siege in 1993, called himself their final prophet and \"the Son of God, the Lamb\" in 1983.\nManichaeism.\nMani (, c.\u2009April AD\u00a0216\u20132 March AD\u00a0274 or 26 February AD\u00a0277) was an Iranian prophet and the founder of Manichaeism, a religion most prevalent in late antiquity.\nMani was born in or near Seleucia-Ctesiphon (south of modern Baghdad) in Mesopotamia, at the time part of the Parthian Empire. Seven of his major works were written in Syriac, and the eighth, dedicated to the Sasanian emperor Shapur I, was written in Middle Persian. He died in Gundeshapur.\nManichaeism teaches an elaborate dualistic cosmology describing the struggle between a good, spiritual world of light, and an evil, material world of darkness. Through an ongoing process that takes place in human history, light is gradually removed from the world of matter and returned to the world of light, whence it came. Mani's teaching was intended to \"combine\", succeed, and surpass the teachings of Christianity, Zoroastrianism, Buddhism, Marcionism, Hellenistic and Rabbinic Judaism, Gnostic movements, Ancient Greek religion, Babylonian and other Mesopotamian religions, and mystery cults. It reveres Mani as the final prophet after Zoroaster, the Gautama Buddha and Jesus Christ.\nManichaeism was quickly successful and spread far through Aramaic-speaking regions. It thrived between the third and seventh centuries, and at its height was one of the most widespread religions in the world. Manichaean churches and scriptures existed as far east as the Han dynasty and as far west as the Roman Empire. It was briefly the main rival to early Christianity in the competition to replace classical polytheism before the spread of Islam. Under the Roman Dominate, Manichaeism was persecuted by the Roman state and was eventually stamped out in the Roman Empire. While most of Manichaeism's original writings have been lost, numerous translations and fragmentary texts have survived.\nManichaeism has survived longer in the east than it did in the west. Although it was thought to have finally faded away after the 14th century in South China, contemporary to the decline of the Church of the East in Ming China, there is a growing corpus of evidence that shows Manichaeism persists in some areas of China, especially in Fujian, where numerous Manichaean relics have been discovered over time. The currently known sects are notably secretive and protective of their belief system, in an effort to remain undetected. This stems from fears relating to persecution and suppression during various periods of Chinese history.\nIslam.\nThe Quran identifies a number of men as \"Prophets of Islam\" ( \"nab\u012b\"; pl. \"anbiy\u0101\u02be\"). Muslims believe such individuals were assigned a special mission by God to guide humanity. Besides Muhammad, this includes prophets such as Abraham (\"Ibr\u0101h\u012bm\"), Moses (\"M\u016bs\u0101\") and Jesus (\"\u02bf\u012as\u0101\").\nAlthough only twenty-five prophets are mentioned by name in the Quran, a hadith (no. 21257 in \"Musnad Ahmad ibn Hanbal\") mentions that there were (more or less) 124,000 prophets in total throughout history. Other traditions place the number of prophets at 224,000. The Quran says that God has sent a prophet to every group of people throughout time and that Muhammad is the last of the prophets, sent for the whole of humankind. The message of all the prophets is believed to be the same. In Islam, all prophetic messengers are prophets (such as Adam, Noah, Abraham, Moses, Jesus, and Muhammad) though not all prophets are prophetic messengers. The primary distinction is that a prophet is required to demonstrate God's law through his actions, character, and behavior without necessarily calling people to follow him, while a prophetic messenger is required to pronounce God's law (i.e. revelation) and call his people to submit and follow him. Muhammad is distinguished from the rest of the prophetic messengers and prophets in that God commissioned him to be the prophetic messenger to all of humankind. Many of these prophets are also found in the texts of Judaism (The Torah, the Prophets, and the Writings) and Christianity.\nMuslims often refer to Muhammad as \"the Prophet\", in the form of a noun. Jesus is the result of a virgin birth in Islam as in Christianity, and is regarded as a prophet.\nAlthough it offers many incidents from the lives of many prophets, the Quran focuses with special narrative and rhetorical emphasis on the careers of the first four of these five major prophets.\nOf all the figures before Muhammad, the significance of Jesus in Islam is reflected in his being mentioned in the Quran in 93 verses with various titles attached such as \"Son of Mary\" and other relational terms, mentioned directly and indirectly, over 187 times. He is thus the most mentioned person in the Quran by reference; 25 times by the name Isa, third-person 48 times, first-person 35 times, and the rest as titles and attributes. Moses (\"Musa\") and Abraham (\"Ibrahim\") are also referred to frequently in the Quran. As for the fifth, the Quran is frequently addressed directly to Muhammad, and it often discusses situations encountered by him. Direct use of his name in the text, however, is rare. Rarer still is the mention of Muhammad's contemporaries.\nSeveral prominent exponents of the Fatimid Ismaili Imams explained that throughout history there have been six enunciators () who brought the exoteric () revelation to humans, namely: Adam, Noah, Abraham, Moses, Jesus and Muhammad. They speak of a seventh enunciator (), the Resurrector (Qa\u2019im), who will unveil the esoteric () meaning of all the previous revelations. He is believed to be the pinnacle and purpose of creation. The enunciators (sing. ) who are the Prophets and the Imams in their respective times, are the highest hierarch (). The enunciators () signal the beginning of a new age () in humankind, whereas the Imams unveil and present the esoteric () meaning of the revelation to the people. These individuals are both known as the \u2018Lord of the Age\u2019 () or the \u2018Lord of the Time\u2019 (). Through them, one can know God, and their invitation to humans to recognize God is called the invitation ().\nAccording to Shia Islam, all Prophets and Imams are infallible and the belief in their abstinence from intentional and unintentional sins is a part of the creed. Thus, it is accordingly believed that they are the examples to be followed and that they act as they preach. This belief includes some \u02beAwliy\u0101\u02be such as Lady Fatima and Lady Mary.\nAhmadiyya.\nDuring his lifetime, Mirz\u0101 Ghul\u0101m A\u1e25mad said that he was a prophet of God and became the founder of the Ahmadiyya Movement in Islam, which embodied the \"Mahd\u012b\" of Islam and fulfilled the messianic prophecies regarding the coming of a savior to various other religious traditions, including Christianity and Hinduism.\nFollowers of the Ahmadiyya Movement in Islam believe that Mirz\u0101 Ghul\u0101m A\u1e25mad was a prophet of God, who is said to be a fulfillment of the various Islamic prophecies regarding the second advent of Jesus (\"\u02bf\u012as\u0101\") before the end of time.\nAhmadi thought emphasizes the belief that Islam is the final dispensation for humanity as revealed to Muhammad and the necessity of restoring it to its true intent and pristine form, which had been lost through the centuries. Its adherents consider Ahmad to have appeared as the Mahdi\u2014bearing the qualities of Jesus in accordance with their reading of scriptural prophecies\u2014to revitalize Islam and set in motion its moral system that would bring about lasting peace. They believe that upon divine guidance he purged Islam of foreign accretions in belief and practice by championing what is, in their view, Islam's original precepts as practised by Muhammad and the early Muslim community. Ahmadis thus view themselves as leading the propagation and renaissance of Islam.\nDruze faith.\nIn the Druze faith, seven spokesmen or prophets are considered and revered as messengers or intermediaries between God and mankind. These prophets include Adam, Noah, Abraham, Moses, Jesus, Muhammad and Muhammad ibn Isma'il. Each of them was sent in a different period of history to preach the message of God.\nThe Druze believe that each spokesman or prophet (\"natiq\") has a \"foundation\" or \"guardian\" who is responsible for the esoteric, interpretative law, while the spokesman or prophet himself presents the apparent, obligatory law. The first prophet was Adam, whose foundation was Seth, although Adam did not have a mandate to introduce a law. Noah followed with a new law, superseding Adam's teachings, and his foundation was Shem. Then came Abraham, with Ishmael as his foundation, and Moses, whose foundation was Joshua son of Nun after Aaron's death. Jesus followed, with Simon Peter as his foundation, and finally, Muhammad, with Ali ibn Abi Talib as his foundation. The last figure is Abd Allah al-Mahdi Billah, the founder of the Fatimid Caliphate, whose foundation was al-Qaddah. With Hamza ibn Ali, the prophet of al-Hakim, a new era began, introducing a new law called the \"Law of Tawhid\" (Unification) or the \"Third Path,\" which superseded all previous laws. Hamza ibn Ali was assisted by four boundaries mentioned in their tradition.\nBah\u00e1\u02bc\u00ed Faith.\nThe Bah\u00e1\u02bc\u00ed Faith refers to what are commonly called prophets as \"Manifestations of God\" who are directly linked with the concept of progressive revelation. Bah\u00e1\u02bc\u00eds believe that the will of God is expressed at all times and in many ways, including through a series of divine messengers referred to as \"Manifestations of God\" or \"divine educators\". In expressing God's intent, these Manifestations are seen to establish religion in the world. Thus they are seen as an intermediary between God and humanity.\nThe Manifestations of God are not seen as incarnations of God, and are also not seen as ordinary mortals. Instead, the Bah\u00e1\u02bc\u00ed concept of the Manifestation of God emphasizes simultaneously the humanity of that intermediary and the divinity in the way they show forth the will, knowledge and attributes of God; thus they have both human and divine stations.\nIn addition to the Manifestations of God, there are also minor prophets. While the Manifestations of God, or major prophets, are compared to the Sun (which produces its own heat and light), minor prophets are compared to the Moon (which receives its light from the sun). Moses, for example, is taught as having been a Manifestation of God and his brother Aaron a minor prophet. Moses spoke on behalf of God, and Aaron spoke on behalf of Moses (Exodus 4:14\u201317). Other Jewish prophets are considered minor prophets, as they are considered to have come in the shadow of the dispensation of Moses to develop and consolidate the process he set in motion.\nNative Americans.\nThe Great Peacemaker (sometimes referred to as \"Deganawida\" or \"Dekanawida\") co-founded the Haudenosaunee league in pre-Columbian times. In retrospect, his prophecy of the boy seer could appear to refer to the conflict between natives and Europeans (white serpent).\nFrom 1805 until the Battle of Tippecanoe that falsified his predictions in 1811, the \"Shawnee prophet\" Tenskwatawa led an Indian alliance to stop Europeans from taking more and more land going west. He reported visions he had. He is said to have accurately predicted a solar eclipse. His brother Tecumseh re-established the alliance for Tecumseh's War, that ended with the latter's death in 1813. Tecumseh fought together with British forces that, in the area of the Great Lakes, occupied essentially today's territory of Canada.\nFrancis the Prophet, influenced by Tecumseh and Tenskwatawa, was a leader of the Red Stick faction of the Creek Indians. He traveled to England in 1815 as a representative of the \"four Indian nations\" in an unsuccessful attempt to get Great Britain to help them resist the expansionism of the white settlers.\n20 years later (1832), Wabokieshiek, the \"Winnebago Prophet\", after whom Prophetstown has been named, (also called \"White Cloud\") said that British forces would support the Indians in the Black Hawk War against the United States as 20 years earlier (based on \"visions\"). They did not, and he was no longer considered a \"prophet\".\nIn 1869, the Paiute Wodziwob founded the Ghost Dance movement. The dance rituals were an occasion to announce his visions of an earthquake that would swallow the whites. He seems to have died in 1872.\nThe Northern Paiute Wovoka said he had a vision during the solar eclipse of January 1, 1889, that the Paiute dead would come back and the whites would vanish from America, provided the natives performed Ghost Dances. This idea spread among other Native American peoples. The government were worried about a rebellion and sent troops, which lead to the death of Sitting Bull and to the Wounded Knee massacre in 1890.\nThelema.\nAleister Crowley (1875\u20131947) was an English occultist, philosopher, ceremonial magician, poet, painter, novelist and mountaineer. He founded the religion of Thelema, identifying himself as the prophet entrusted with guiding humanity into the \u00c6on of Horus in the early 20th century. A prolific writer, he published widely over the course of his life.\nAccording to Crowley's later statements, on 8 April he heard a disembodied voice identifying itself as that of Aiwass, the messenger of Horus, or Hoor-Paar-Kraat. Crowley said that he wrote down everything the voice told him over the course of the next three days, and titled it \"Liber AL vel Legis\" or \"The Book of the Law\". The book proclaimed that humanity was entering a new Aeon, and that Crowley would serve as its prophet. It stated that a supreme moral law was to be introduced in this Aeon, \"Do what thou wilt shall be the whole of the Law,\" and that people should learn to live in tune with their Will. This book, and the philosophy that it espoused, became the cornerstone of Crowley's religion, Thelema.\nIn 1924, Crowley traveled to Tunisia for a magical retreat in Nefta, where he also wrote \"To Man\" (1924), a declaration of his own status as a prophet entrusted with bringing Thelema to humanity. Crowley believed that the twentieth century marked humanity's entry to the Aeon of Horus, a new era in which humans would take increasing control of their destiny. He believed that this Aeon follows on from the Aeon of Osiris, in which paternalistic religions like Christianity, Islam, and Buddhism dominated the world, and that this in turn had followed the Aeon of Isis, which was maternalistic and dominated by goddess worship. He believed that Thelema was the proper religion of the Aeon of Horus, and also deemed himself to be the prophet of this new Aeon.\nThelema revolves around the idea that human beings each have their own True Will that they should discover and pursue, and that this exists in harmony with the Cosmic Will that pervades the universe. Crowley referred to this process of searching and discovery of one's True Will to be \"the Great Work\" or the attaining of the \"knowledge and conversation of the Holy Guardian Angel\". His favoured method of doing so was through the performance of the Abramelin operation, a ceremonial magic ritual obtained from a 17th-century grimoire. The moral code of \"Do What Thou Wilt\" is believed by Thelemites to be the religion's ethical law, although the historian of religion Marco Pasi noted that this was not anarchistic or libertarian in structure, as Crowley saw individuals as part of a wider societal organism.\nSecular usage.\nThe designation of \"Victorian prophet\" has been used in reference to cultural critics of the era, such as Thomas Carlyle and John Ruskin.\nCommentators who suggest escalating crisis are often called \"prophets of doom.\"\nScientists analyzing data to forecast future events can also be considered prophets in a secular sense. In 2020, Ann Druyan stated that, \"The only prophets that I\u2019m really impressed by are the climate scientists of the past seventy years.\" She included her late husband, Carl Sagan, among the modern-day prophets, with the disclaimer that \"[a] lot of the things that he speculated about haven\u2019t turned out to be true, but all those people are human. They were just using their knowledge and their intelligence to make good guesses.\"\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24807", "revid": "4842600", "url": "https://en.wikipedia.org/wiki?curid=24807", "title": "Pleading", "text": "In law, statement of a party's claims to another party's claims in a civil action\nIn law as practiced in countries that follow the English models, a pleading is a formal written statement of one party's claims or defenses in response to another party's complaint(s) in a civil action. The parties' pleadings in a case define the issues to be adjudicated in the action.\nThe Civil Procedure Rules (CPR) govern pleading in England and Wales.\nFederal Rules of Civil Procedure govern pleading in United States federal courts. Each state in the United States has its own statutes and rules that govern pleading in the courts of that state.\nExamples.\nUnder the Federal Rules of Civil Procedure a \"complaint\" is the first pleading in American law filed by a plaintiff which initiates a lawsuit. A complaint sets forth the relevant allegations of fact that give rise to one or more legal causes of action along with a prayer for relief and sometimes a statement of damages claimed (an ad quod damnum clause). In some situations, a complaint is called a \"petition\", in which case the party filing it is called the petitioner and the other party is the respondent. In equity, sometimes called chancery, the initial pleading may be called either a \"petition\" or a \"bill of complaint in chancery\".\nIn England and Wales, the first pleading is a Claim Form, issued under either Part 7 or Part 8 of the Civil Procedure Rules, which sets out the nature of the action and the relief sought, and may give brief particulars of the claim. The Claimant also has the option, under Practice Direction 7A.61 to serve Particulars of Claim (a document setting out the allegations which found the cause of action) within 14 days of the issue of the Claim Form.\nWhen used in civil proceedings in England and Wales, the term \"complaint\" refers to the mechanism by which civil proceedings are instituted in the magistrates' court and may be either written or oral.\nA \"demurrer\" is a pleading (usually filed by a defendant) which objects to the legal sufficiency of the opponent's pleading (usually a complaint) and demands that the court rule immediately about whether the pleading is legally adequate before the party must plead on the merits in response. Since the demurrer procedure required an immediate ruling as does a motion, many common law jurisdictions therefore narrowed the concept of pleadings to be framing the issues in a case. Pleadings are not motions in and of themselves, and courts replaced the demurrer mechanism with the motion to dismiss for failure to state a cause of action or the application to strike out particulars of claim.\nAn \"answer\" is a pleading filed by a defendant which admits or denies the specific allegations set forth in a complaint and constitutes a general appearance by a defendant. In England and Wales, the equivalent pleading is called a Defence.\nA defendant may also file a cross-complaint against another defendant named by the plaintiff and may also file a \"third-party complaint\" bring other parties into a case by the process of impleader.\nA defendant may file a \"counter-claim\" to raise a cause of action to defend, reduce or set off the claim of the plaintiff.\nSystems.\nCommon law.\nCommon law pleading was the system of civil procedure used in England, which early on developed a strong emphasis on the form of action rather than the cause of action (as a result of the Provisions of Oxford, which severely limited the evolution of the common law writ system). The emphasis was on procedure over substance.\nLaw and equity evolved as separate judicial systems, each with its own procedures and remedies. Because the types of claims eligible for consideration was capped early during the development of the English legal system, claims that might have been acceptable to the courts' evolving sense of justice often did not match up perfectly with any of the established forms of action. Lawyers had to engage in great ingenuity to shoehorn their clients' claims into existing forms of action. The result was that at common law, pleadings were stuffed full of awkward legal fictions that had little to do with the actual \"real-world\" facts of the case. The placeholder name John Doe (still commonly used in American pleading to name unknown parties) is a remnant of this period.\nIn its final form in the 19th century, common law pleading was terribly complex and slow by modern standards. The parties would normally go through several rounds of pleadings before the parties were deemed to have clearly stated their controversy, so that the case was \"at issue\" and could proceed to trial. A case would begin with a complaint in which the plaintiff alleged the facts entitling him to relief, then the defendant would file any one of a variety of pleas as an answer, followed by a replication from the plaintiff, a rejoinder from the defendant, a surrejoinder from the plaintiff, a rebutter from the defendant, and a surrebutter from the plaintiff. At each stage, a party could file a demurrer to the other's pleading (essentially a request that the court immediately rule on whether the pleading was legally adequate before they had to file a pleading in response) or simply file another pleading in response.\nGenerally, a plea could be dilatory or peremptory. There were three kinds of dilatory plea: to the jurisdiction, in suspension, or in abatement. The first challenged the court's jurisdiction, the second asked the court to stay the action, and the third asked the court to dismiss the action without prejudice to the other side's right to bring the claims in another action or another court. A peremptory plea had only one kind: a plea in bar. A party making a plea in bar could either traverse the other side's pleading (i.e., deny all or some of the facts pleaded) or confess and avoid it (i.e., admit the facts pleaded but plead new ones that would dispel their effect). A traverse could be general (deny everything) or specific. Either side could plead imparlance in order to get more time to plead on the merits. Once the case was at issue, the defendant could reopen the pleadings in order to plead a newly discovered defense (and start the whole sequence again) by filing a plea puis darrein.\nThe result of all this complexity was that to ascertain what was \"at issue\" in a case, a stranger to the case (i.e., such as a newly appointed judge) would have to sift through a huge pile of pleadings to figure out what had happened to the original averments of the complaint and whether there was anything left to be actually adjudicated by the court.\nCode.\nCode pleading was first introduced in 1850 in New York and in 1851 in California, and eventually spread to 26 other states. Code pleading sought to abolish the distinction between law and equity. It unified civil procedure for all types of actions as much as possible. The focus shifted from pleading the right form of action (that is, the right procedure) to pleading the right cause of action (that is, a substantive right to be enforced by the law).\nCode pleading stripped out most of the legal fictions that had encrusted common law pleading by requiring parties to plead \"ultimate facts.\" This means that to plead a cause of action, the pleader has to plead each element and also allege specific facts which, if proven with evidence at trial, would constitute proof of that element. Failure to provide such detail could lead to dismissal of the case if the defendant successfully demurred to the complaint on the basis that it merely stated \"legal conclusions\" or \"evidentiary facts.\"\nCode pleading also drastically shortened the pleading process. Most of the old common law pleadings were abolished. From now on, a case required only a complaint and an answer, with an optional cross-complaint and cross-answer, and with the demurrer kept as the standard attack on improper pleadings. Instead of piling layers and layers of pleadings and averments on top of each other, a pleading that was attacked by demurrer would either be completely superseded by an amended pleading or would proceed immediately \"at issue\" as to the validly pleaded parts. This meant that to determine what the parties were currently fighting about, a stranger to a case would no longer have to read the entire case file from scratch, but could (in theory) look \"only\" at the most recent version of the complaint filed by the plaintiff, the defendant's most recent answer to that complaint, and any court orders on demurrers to either pleading.\nCode pleading was criticized because many lawyers felt that it was too difficult to fully research all the facts needed to bring a complaint \"before\" one had even initiated the action, and thus meritorious plaintiffs could not bring their complaints in time before the statute of limitations expired. Code pleading has also been criticized as promoting \"hypertechnical reading of legal papers\".\nNotice.\nNotice pleading is the dominant form of pleading used in the United States today. In 1938, the Federal Rules of Civil Procedure were adopted to govern civil procedure in United States federal courts. One goal of the Federal Rules of Civil Procedure was to relax the strict rules of code pleading. However, each state also has its own rules of civil procedure, which may require different, looser, or stricter rules in state court.\nFact.\nLouisiana, a state that derives its legal tradition from the Spanish and French civil law (as opposed to English common law), employs a system of fact pleading wherein it is only necessary to plead the facts that give rise to a cause of action. It is not necessary even for the petitioner to identify the cause of action being pleaded. However, mere conclusory allegations such as \"the defendant was negligent\" are not, by themselves, sufficient to sustain a cause of action.\nOther states, including Connecticut and New Jersey, are also fact-pleading jurisdictions. Illinois, for example, requires that a complaint \"must assert a legally recognized cause of action and it must plead facts which bring the particular case within that cause of action.\"\nAlternative.\nIn alternative pleading, legal fiction is employed to permit a party to argue two mutually exclusive possibilities, for example, submitting an injury complaint alleging that the harm to the plaintiff caused by the defendant was so outrageous that it must have either been intended as a malicious attack or, if not, must have been due to gross negligence.\nLinguistic.\n\"pleaded\" vs \"pled\".\nThe use of \"pleaded\" versus \"pled\" as the past tense version of \"pleading\" has been a subject of controversy among many of those that practice law. \"Pled\" is almost never used in Australian publications, while being somewhat common in American, British, and Canadian publications. In a 2010 search of the Westlaw legal database, \"pled\" is used in a narrow majority of cases over \"pleaded\". The AP stylebook and \"The Chicago Manual of Style\" call for \"pleaded\", and a Westlaw search shows the US Supreme Court has used pleaded in over 3,000 opinions and pled in only 26.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24808", "revid": "11005874", "url": "https://en.wikipedia.org/wiki?curid=24808", "title": "Personal Communications Service", "text": "Type of cellular mobile phone service\nA personal communications service (PCS) is set of communications capabilities that provide a combination of terminal mobility, personal mobility, and service profile management. This class of services comprises several types of wireless voice or wireless data communications systems, typically incorporating digital technology, providing services similar to advanced cellular mobile or paging services. In addition, PCS can also be used to provide other wireless communications services, including services that allow people to place and receive communications while away from their home or office, as well as wireless communications to homes, office buildings and other fixed locations. Described in more commercial terms, PCS is a generation of wireless cellular-phone technology, that combines a range of features and services surpassing those available in analogue- and first-generation (2G) digital-cellular phone systems, providing a user with an all-in-one wireless phone, paging, messaging, and data service.\nThe International Telecommunication Union (ITU) describes personal communications services as a component of the IMT-2000 (3G) standard. PCS and the IMT-2000 standard of which PCS is a part do not specify a particular air interface and channel access method. Wireless service providers may deploy equipment using any of several air interface and channel access methods, as long as the network meets the service description for technical characteristics described in the standard.\nIn ITU Region 2, PCS are provided in the '1900\u00a0MHz' band (specifically 1850\u20131995\u00a0MHz). This frequency band was designated by the United States Federal Communications Commission (FCC) and Industry Canada to be used for new wireless services to alleviate capacity caps inherent in the original Advanced Mobile Phone System (AMPS) and Digital AMPS (D-AMPS) cellular networks in the '850\u00a0MHz' band (specifically 814\u2013894\u00a0MHz). Only Region 2 has a PCS band.\nPCS network in the United States.\nIn the United States, Sprint PCS was the first company to build and operate a PCS network, launching service in November 1995 under the \"Sprint Spectrum\" brand in the Baltimore-Washington metropolitan area. Sprint originally built the network using GSM radio interface equipment. Sprint PCS later selected CDMA as the radio interface for its nationwide network, and built a parallel CDMA network in the Baltimore-Washington area, launching service in 1997. Sprint operated the two networks in parallel until finishing a migration of its area customers to the CDMA network.\nAfter completing the customer migration, Sprint PCS sold the GSM radio interface network equipment to Omnipoint Communications in January 2000. \nOmnipoint was later purchased by VoiceStream Wireless which subsequently became T-Mobile US.\nIn August 2022, T-Mobile US announced dead-zone cell phone coverage across the US using \"midband\" (1900 MHz) PCS spectrum and Starlink Gen2 satellite cell coverage, to begin testing in 2023. Using this satellite and midband spectrum, T-Mobile plans to be able to connect by satellite to common mobile devices, unlike previous generations of satellite phones which used specialized Earth-bound radios to connect to geosynchronous satellites with characteristic long lag time in communications.\nRest of the world.\nITU Regions 1 and 3 (Eurasia, Africa) does not have a PCS band. The comparable technology in the context of GSM is GSM-1800, also known as \"Digital Cellular System\" (DCS). GSM-1800 launched in Hong Kong in 1997. It can form dual band service with GSM at 900MHz. This frequency was inherited into UMTS, LTE, and 5G NR.\nKorea, which has never used GSM, runs CDMA on 1800 MHz. See CDMA frequency bands.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24809", "revid": "1588193", "url": "https://en.wikipedia.org/wiki?curid=24809", "title": "PCS", "text": "PCS may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "24811", "revid": "45478263", "url": "https://en.wikipedia.org/wiki?curid=24811", "title": "Puck", "text": "Puck may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "24812", "revid": "9092818", "url": "https://en.wikipedia.org/wiki?curid=24812", "title": "Personal attack", "text": ""}
{"id": "24813", "revid": "914515179", "url": "https://en.wikipedia.org/wiki?curid=24813", "title": "Portia (Shakespeare)", "text": ""}
{"id": "24814", "revid": "7787635", "url": "https://en.wikipedia.org/wiki?curid=24814", "title": "Priesthood", "text": ""}
{"id": "24815", "revid": "525927", "url": "https://en.wikipedia.org/wiki?curid=24815", "title": "Polaris Sales Agreement", "text": "Treaty between the United States and the United Kingdom\nThe Polaris Sales Agreement was a treaty between the United States and the United Kingdom which began the UK Polaris programme. The agreement was signed on 6 April 1963. It formally arranged the terms and conditions under which the Polaris missile system was provided to the United Kingdom.\nThe United Kingdom had been planning to buy the air-launched Skybolt missile to extend the operational life of the British V bombers, but the United States decided to cancel the Skybolt program in 1962 as it no longer needed the missile. The crisis created by the cancellation prompted an emergency meeting between the president of the United States, John F. Kennedy, and the prime minister of the United Kingdom, Harold Macmillan, which resulted in the Nassau Agreement, under which the United States agreed to provide Polaris missiles to the United Kingdom instead.\nThe Polaris Sales Agreement provided for the implementation of the Nassau Agreement. The United States would supply the United Kingdom with Polaris missiles, launch tubes, and the fire control system. The United Kingdom would manufacture the warheads and submarines. In return, the US was given certain assurances by the United Kingdom regarding the use of the missile, but not a veto on the use of British nuclear weapons. The British Polaris ballistic missile submarines were built on time and under budget, and came to be seen as a credible deterrent.\nAlong with the 1958 US\u2013UK Mutual Defence Agreement, the Polaris Sales Agreement became a pillar of the nuclear Special Relationship between Britain and the United States. The agreement was amended in 1982 to provide for the sale of the Trident missile system.\nBackground.\nDuring the early part of the Second World War, Britain had a nuclear weapons project, codenamed Tube Alloys. In August 1943, the prime minister of the United Kingdom, Winston Churchill and the president of the United States, Franklin Roosevelt, signed the Quebec Agreement, which merged Tube Alloys with the American Manhattan Project. The British government trusted that the United States would continue to share nuclear technology, which it regarded as a joint discovery, but the 1946 McMahon Act ended cooperation. Fearing a resurgence of United States isolationism, and Britain losing its great power status, the British government restarted its own development effort, now codenamed High Explosive Research. The first British atomic bomb was tested in Operation Hurricane on 3 October 1952. The subsequent British development of the hydrogen bomb, and a favourable international relations climate created by the Sputnik crisis, led to the McMahon Act being amended in 1958, and the restoration of the nuclear Special Relationship in the form of the 1958 US\u2013UK Mutual Defence Agreement (MDA), which allowed Britain to acquire nuclear weapons systems from the United States.\nBritain's nuclear weapons armament was initially based on free-fall bombs delivered by the V bombers of the Royal Air Force (RAF), but the possibility of the crewed bomber becoming obsolete by the late 1960s due to improvements in anti-aircraft defences was foreseen. In 1953, work began on a medium-range ballistic missile (MRBM) called Blue Streak, but by 1958, there were concerns about the vulnerability of this liquid-propellant-missile to a pre-emptive nuclear strike. To extend the effectiveness and operational life of the V bombers, an air-launched, rocket-propelled standoff missile called Blue Steel was developed, but it was anticipated that the air defences of the Soviet Union would improve to the extent that V bombers might still find it difficult to attack their targets. A solution appeared to be the American Skybolt missile, which combined the range of Blue Streak with the mobile basing of the Blue Steel, and was small enough that two could be carried on an Avro Vulcan bomber.\nAn institutional challenge to Skybolt came from the United States Navy, which was developing a submarine-launched ballistic missile (SLBM), the UGM-27 Polaris. The US Chief of Naval Operations, Admiral Arleigh Burke, kept the First Sea Lord, Lord Mountbatten, apprised of its development. By moving the deterrent out to sea, Polaris offered the prospect of a deterrent that was invulnerable to a first strike, and reduced the risk of a nuclear strike on the British Isles. The British Nuclear Deterrent Study Group (BNDSG) produced a study that argued that SLBM technology was as yet unproven, that Polaris would be expensive, and that given the time it would take to build the boats, it could not be deployed before the early 1970s. The Cabinet Defence Committee therefore approved the acquisition of Skybolt in February 1960. The prime minister, Harold Macmillan, met with the president, Dwight D. Eisenhower, in March 1960, and secured permission to buy Skybolt. In return, the Americans could base the US Navy's Polaris ballistic missile submarines in the Holy Loch in Scotland. The financial arrangement was particularly favourable to Britain, as the US was charging only the unit cost of Skybolt, absorbing all the research and development costs. With this agreement in hand, the cancellation of Blue Streak was announced in the House of Commons on 13 April 1960.\nThe subsequent American decision to cancel Skybolt created a political crisis in the UK, and an emergency meeting between Macmillan and President John F. Kennedy was called in Nassau, Bahamas. Macmillan rejected the US offers of paying half the cost of developing Skybolt, and of supplying the AGM-28 Hound Dog missile instead. This brought options down to Polaris, but the Americans would only supply it on condition that it be used as part of a proposed Multilateral Force (MLF). Kennedy ultimately relented, and agreed to supply Britain with Polaris missiles, while \"the Prime Minister made it clear that except where Her Majesty's Government may decide that supreme national interests are at stake, these British forces will be used for the purposes of international defence of the Western Alliance in all circumstances.\" A joint statement to this effect, the Nassau Agreement, was issued on 21 December 1962.\nNegotiations.\nWith the Nassau Agreement in hand, it remained to work out the details. Vice Admiral Michael Le Fanu had a meeting with the United States secretary of defense, Robert S. McNamara, on 21 December 1962, the final day of the Nassau conference. He found McNamara eager to help, and enthusiastic about the idea of Polaris costing as little as possible. The first issue identified was how many Polaris boats should be built. While the Vulcans to carry Skybolt were already in service, the submarines to carry Polaris were not, and there was no provision in the defence budget for them. Some naval officers feared that their construction would adversely impact the hunter-killer submarine programme. The First Sea Lord, Admiral of the Fleet Sir Caspar John, denounced the \"millstone of Polaris hung around our necks\" as \"potential wreckers of the real navy\".\nThe number of missiles required was based on substituting for Skybolt. To achieve the same capability, the BNDSG calculated that this would require eight Polaris submarines, each of which would have 16 missiles, for a total of 128 missiles, with 128 one-megaton warheads. It was subsequently decided to halve this, based on the decision that the ability to destroy twenty Soviet cities would have nearly as great a deterrent effect as the ability to destroy forty. The Admiralty considered the possibility of hybrid submarines that could operate as hunter-killers while carrying eight Polaris missiles, but McNamara noted that this would be inefficient, as twice as many submarines would need to be on station to maintain the deterrent, and cautioned that the effect of tinkering with the US Navy's 16-missile layout was unpredictable. The Treasury costed a four-boat Polaris fleet at \u00a3314 million by 1972/73. A Cabinet Defence Committee meeting on 23 January 1963 approved the plan for four boats, with Thorneycroft noting that four boats would be cheaper and faster to build.\nA mission led by Sir Solly Zuckerman, the chief scientific adviser to the Ministry of Defence, left for the United States to discuss Polaris on 8 January 1963. It included the vice chief of the Naval Staff, Vice Admiral Sir Varyl Begg; the deputy secretary of the Admiralty, James Mackay; Rear Admiral Hugh Mackenzie; and physicist Sir Robert Cockburn and F. J. Doggett from the Ministry of Aviation. That the involvement of the Ministry of Aviation might be a complicating factor was foreseen, but it had experience with nuclear weapons development. Mackenzie had been the Flag Officer Submarines until 31 December 1962, when Le Fanu had appointed him the chief Polaris executive (CPE). As such, he was directly answerable to Le Fanu as Controller of the Navy. His CPE staff was divided between London and Foxhill, near Bath, Somerset, where Royal Navy had its ship design, logistics and weapons groups. It was intended as a counterpart to the United States Navy Special Projects Office (SPO), with whom it would have to deal.\nThe principal finding of the Zuckerman mission was that the Americans had developed a new version of the Polaris missile, the A3. With a range extended of , it had a new weapons bay housing three re-entry vehicles (REBs or Re-Entry Bodies in US Navy parlance) and a new W58 warhead to penetrate improved Soviet anti-missile defences expected to become available around 1970. A decision was therefore required on whether to purchase the old A2 missile or the new A3. The Zuckerman mission came out in favour of the new A3 missile, although it was still under development and not expected to enter service until August 1964, as the deterrent would remain credible for much longer. The decision was endorsed by the First Lord of the Admiralty, Lord Carrington, in May 1963, and was officially made by Thorneycroft on 10 June 1963.\nThe choice of the A3 created a problem for the Atomic Weapons Research Establishment (AWRE) at Aldermaston, for the Skybolt warhead that had recently been tested in the Tendrac nuclear test at the Nevada Test Site in the United States would require a redesigned Re-Entry System (RES) in order to be fitted to a Polaris missile, at an estimated cost of between \u00a330 million and \u00a340 million. The alternative was to make a British copy of the W58. While the AWRE was familiar with the W47 warhead used in the A2, it knew nothing of the W58. A presidential determination was required to release information on the W58 under the MDA, but with this in hand, a mission led by John Challens, the chief of warhead development at the AWRE, visited the Lawrence Livermore Laboratory from 22 to 24 January 1963, and was shown details of the W58.\nThe Zuckerman mission found the SPO helpful and forthcoming, but there was one major shock. The British were expected to contribute to the research and development costs of the A3, backdated to 1 January 1963. These were expected to top $700 million by 1968. Skybolt had been offered to the UK at unit cost, with the US absorbing the research and development costs, but no such agreement had been reached at Nassau for Polaris. Thorneycroft baulked at the prospect of paying research and development costs, but McNamara pointed out that the United States Congress would not stand for an agreement that placed all the burden on the United States. Macmillan instructed the British Ambassador to the United States, Sir David Ormsby-Gore, to inform Kennedy that Britain was not willing to commit to an open-ended sharing of research and development costs, but, as a compromise, would pay an additional five per cent for each missile. He asked that Kennedy be informed that a breakdown of the Nassau Agreement would likely cause the fall of his government. Ormsby-Gore met with Kennedy that very day, and while Kennedy noted that the five per cent offer \"was not the most generous offer he had ever heard of\", he accepted it. McNamara, certain that the United States was being ripped off, calculated the five per cent on top of not just the missiles, but their fire control and navigation systems as well, adding around \u00a32 million to the bill. On Ormsby-Gore's advice, this formulation was accepted.\nAn American mission now visited the United Kingdom. This was led by Paul H. Nitze, the Assistant Secretary of Defense for International Security Affairs, and included Walt W. Rostow, the Director of Policy Planning at the State Department, and Admiral Ignatius J. Galantin, the head of the SPO. The Americans had ideas about how the programme should be organised. They foresaw the UK Polaris programme having project officers from both countries, with a Joint Steering Task Group that met regularly to provide advice. This was accepted, and would become part of the final agreement. However, a follow-up British mission under Leslie Williams, the Director General Atomic Weapons at the Ministry of Aviation, whose members included Challens and Rear Admiral Frederick Dossor, was given a letter by the SPO with a list of subjects that were off limits. These included penetration aids, which were held to be outside the scope of the Nassau Agreement.\nOne remaining obstacle in the path of the programme was how it would be integrated with the MLF. The British response to the MLF concept \"ranged from unenthusiastic to hostile throughout the military establishment and in the two principal political parties\". Apart from anything else, it was estimated to cost as much as \u00a3100 million over ten years. Nonetheless, the Foreign Office argued that Britain must support the MLF. The Nassau Agreement had invigorated the MLF effort in the United States. Kennedy appointed Livingston T. Merchant to negotiate the MLF with the European governments, which he did in February and March 1963. While reaffirming support for those parts of the Nassau Agreement concerning the MLF, the British were successful in getting them omitted from the Polaris Sales Agreement.\nThe British team completed drafting the agreement in March 1963, and copies were circulated for discussion. The contracts for their construction were announced that month. The Polaris boats would be the largest submarines built in Britain up to that time, and would be built by Vickers Armstrong Shipbuilders in Barrow-in-Furness and Cammell Laird in Birkenhead. For similar reasons to the US Navy, the Royal Navy decided to base the boats at Faslane, on the Gareloch, not far from the US Navy's base on the Holy Loch. The drawback of the site was that it isolated the Polaris boats from the rest of the navy. The Polaris Sales Agreement was signed in Washington, D.C., on 6 April 1963 by Ormsby-Gore and Dean Rusk, the United States Secretary of State.\nOutcome.\nThe two liaison officers were appointed in April; Captain Peter la Niece became the Royal Navy project officer in Washington, D.C., while Captain Phil Rollings became the US Navy project officer in London. The Joint Steering Task Group held its first meeting in Washington on 26 June 1963. The shipbuilding programme would prove to be a remarkable achievement, with the four submarines built on time and within the budget. The first boat, was launched in September 1966, and commenced its first deterrent patrol in June 1968. The annual running costs of the Polaris boats came to around two per cent of the defence budget, and they came to be seen as a credible deterrent that enhanced Britain's international status. Along with the more celebrated 1958 US\u2013UK Mutual Defence Agreement, the Polaris Sales Agreement became a pillar of the nuclear Special Relationship between Britain and the United States.\nTrident.\nThe Polaris Sales Agreement provided an established framework for negotiations over missiles and re-entry systems. The legal agreement took the form of amending the Polaris Sales Agreement through an exchange of notes between the two governments so that \"Polaris\" in the original now also covered the purchase of Trident. There were also some amendments to the classified annexes of the Polaris Sales Agreement to delete the exclusion of penetrating aids. Under the Polaris Sales Agreement, the United Kingdom paid a five per cent levy on the cost of equipment supplied in recognition of US research and development costs already incurred. For Trident, a payment of $116 million was substituted. The United Kingdom procured the Trident system from America and fitted them to their own submarines, which had only 16 missile tubes like Polaris rather than the 24 in the American . The first , , entered operational service in December 1994, by which time the Cold War had ended.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24818", "revid": "48794015", "url": "https://en.wikipedia.org/wiki?curid=24818", "title": "Proto-Indo-Europeans", "text": "Postulated prehistoric ethnolinguistic group\nThe Proto-Indo-Europeans are a postulated prehistoric ethnolinguistic group of Eurasia who spoke Proto-Indo-European (PIE), the reconstructed common ancestor of the Indo-European language family.\nKnowledge of them comes chiefly from that linguistic reconstruction, along with material evidence from archaeology and archaeogenetics. The Proto-Indo-Europeans likely lived during the Late Neolithic period (6400 to 3500 BC). Mainstream scholars place them in the Pontic\u2013Caspian steppe across Eurasia (this steppe extends from northeastern Bulgaria and southeastern Romania, through Moldova, and southern and eastern Ukraine, through the Northern Caucasus of southern Russia, and into the Lower Volga region of western Kazakhstan, adjacent to the Kazakh steppe to the east, both forming part of the larger Eurasian Steppe). Some archaeologists would extend the time depth of PIE to the Middle Neolithic period (5500 to 4500 BC)[] or even the Early Neolithic period (7500 to 5500 BC) and suggest alternative origin hypotheses.\nBy the early second millennium BC, descendants of the Proto-Indo-Europeans had reached far and wide across Eurasia, including Anatolia (Hittites), the Aegean (the linguistic ancestors of Mycenaean Greece), the north of Europe (Corded Ware culture), the edges of Central Asia (Yamnaya culture), and southern Siberia (Afanasievo culture).\nDefinition.\nIn the words of philologist Martin L. West, \"If there was an Indo-European language, it follows that there was a people who spoke it: not a people in the sense of a nation, for they may never have formed a political unity, and not a people in any racial sense, for they may have been as genetically mixed as any modern population defined by language. If our language is a descendant of theirs, that does not make them 'our ancestors', any more than the ancient Romans are the ancestors of the French, the Romanians, and the Brazilians. The Indo-Europeans were a people in the sense of a linguistic community. We should probably think of them as a loose network of clans and tribes, inhabiting a coherent territory of limited size.\"\nWhile \"Proto-Indo-Europeans\" is used in scholarship to designate the group of speakers associated with the reconstructed proto-language and culture, the term \"Indo-Europeans\" may refer to any historical people that speak an Indo-European language.\nCulture.\nUsing linguistic reconstruction from old Indo-European languages such as Latin and Sanskrit, hypothetical features of the Proto-Indo-European language are deduced. Assuming that these linguistic features reflect culture and environment of the Proto-Indo-Europeans, the following cultural and environmental traits are widely proposed:\nA 2016 phylogenetic analysis of Indo-European folktales posits that one folktale, \"The Smith and the Devil\", can be reconstructed to the Proto-Indo-European period. This story, found in contemporary Indo-European folktales from Scandinavia to India, describes a blacksmith who offers his soul to a malevolent being (commonly a devil in modern versions of the tale) in exchange for the ability to weld any kind of materials together. The blacksmith then uses his new ability to stick the devil to an immovable object (often a tree), thus avoiding his end of the bargain. According to the authors, the reconstruction of this folktale to PIE implies that the Proto-Indo-Europeans had metallurgy, which in turn \"suggests a plausible context for the cultural evolution of a tale about a cunning smith who attains a superhuman level of mastery over his craft\".\nHistory of research.\nResearchers have made many attempts to identify particular prehistoric cultures with the Proto-Indo-European-speaking peoples, but all of such theories remain speculative.\nThe scholars of the 1800s who first tackled the question of the Indo-Europeans' original homeland (also called \"Urheimat\", from German), had essentially only linguistic evidence. They attempted a rough localization by reconstructing the names of plants and animals (importantly the beech and the salmon) as well as the culture and technology (a Bronze Age culture that was centered upon animal husbandry and having domesticated the horse). The scholarly opinions became basically divided between a European hypothesis, which posited a migration from Europe to Asia, and an Asian hypothesis, which posited that the migration took place in the opposite direction.\nIn the early 1900s, the question became associated with the expansion of a supposed \"Aryan race\", a now-discredited theory that was promoted during the expansion of European empires and the rise of \"scientific racism\". The question remains contentious within some flavours of ethnic nationalism (see also Indigenous Aryans).\nThere was a series of major advances in the 1970s due to the convergence of several factors. First, the radiocarbon dating method (invented in 1949) was now cheap enough to be applied on a mass scale. Through dendrochronology (tree-ring dating), pre-historians could calibrate radiocarbon dates with much more accuracy. And finally, before the 1970s, parts of eastern Europe and central Asia had been off-limits to Western scholars, while non-Western archaeologists did not have access to publication in Western peer-reviewed journals. The pioneering work of Marija Gimbutas, assisted by Colin Renfrew, at least partly addressed this problem by organizing expeditions and arranging for more academic collaboration between Western and non-Western scholars.\nThe Kurgan hypothesis, which is the most widely held theory as of 2017, depends upon linguistic and archaeological evidence, but is not universally accepted. It posits that the PIEs originated in the Pontic\u2013Caspian steppe during the Chalcolithic age. A minority of scholars prefer the Anatolian hypothesis, which posits an origin in Anatolia during the Neolithic age. Other theories (Armenian hypothesis, Out of India theory, paleolithic continuity theory, and Balkan hypothesis) have only marginal scholarly support.\nIn regard to terminology, in the 19th and early 20th centuries, the term \"Aryan\" was used to refer to the Proto-Indo-Europeans and their descendants. However, \"Aryan\" more properly applies to the Indo-Iranians, the Indo-European branch that settled parts of the Middle East and South Asia, as only Indic and Iranian languages explicitly affirm the term as a self-designation referring to the entirety of their people, whereas the same Proto-Indo-European root (*aryo-) is the basis for Greek and Germanic word forms which seem only to denote the ruling elite of Proto-Indo-European (PIE) society. In fact, the most accessible evidence available confirms only the existence of a common, but vague, socio-cultural designation of \"nobility\" associated with PIE society, such that Greek socio-cultural lexicon and Germanic proper names derived from this root remain insufficient to determine whether the concept was limited to the designation of an exclusive, socio-political elite, or whether it could possibly have been applied in the most inclusive sense to an inherent and ancestral \"noble\" quality which allegedly characterized all ethnic members of PIE society. Only the latter could have served as a true and universal self-designation for the Proto-Indo-European people.\nBy the early 1900s, the term \"aryan\" had come to be widely used in a racial sense, in which it referred to a hypothesized white, blond, and blue-eyed superior race. The dictator Adolf Hitler called this race the \"master race\" (\"Herrenrasse\"), and, in its name, led massive pogroms in Europe. Subsequently, the term \"Aryan\" as a general term for Indo-Europeans has been largely abandoned by scholars (though the term \"Indo-Aryan\" is still used to refer to the branch that settled in Southern Asia).\nUrheimat hypotheses.\nAccording to some archaeologists, PIE speakers cannot be assumed to have been a single, identifiable people or tribe, but were a group of loosely related populations that were ancestral to the later, still partially prehistoric, Bronze Age Indo-Europeans. This is believed especially by those archaeologists who posit an original homeland of vast extent and immense time depth. However, this belief is not shared by most linguists, because proto-languages, like all languages before modern transport and communication, occupied small geographical areas over a limited time span, and were spoken by a set of close-knit communities\u2013 a tribe in the broad sense.\nResearchers have put forward a great variety of proposed locations for the first speakers of Proto-Indo-European. Few of these hypotheses have survived scrutiny by academic specialists in Indo-European studies sufficiently well to be included in modern academic debate.\nPontic-Caspian steppe hypothesis.\nThe Kurgan (or Steppe) hypothesis was first formulated by Otto Schrader (1883) and V. Gordon Childe (1926), and was later systematized by Marija Gimbutas from 1956 onwards. The name originates from the \"kurgans\" (burial mounds) of the Eurasian steppes. The hypothesis suggests that the Indo-Europeans, a patriarchal, patrilinear, and nomadic culture of the Pontic\u2013Caspian steppe (which is now part northeastern Bulgaria and southeastern Romania, through Moldova, and southern and eastern Ukraine, through the northern Caucasus of southern Russia, and into the lower Volga region of western Kazakhstan), expanded into the area through several waves of migration during the 3rd millennium BCE, coinciding with the taming of the horse. Leaving archaeological signs of their presence (see Corded Ware culture), they subjugated the supposedly peaceful, egalitarian, and matrilinear European neolithic farmers of Gimbutas' Old Europe. A modified form of this theory, by J. P. Mallory, which dates the migrations to an earlier time (to around 3500 BCE), and puts less insistence upon their violent or quasi-military nature, remains the most widely accepted theory of the Proto-Indo-European expansion.\nArmenian highland hypothesis.\nThe Armenian hypothesis, based on the glottalic theory, suggests that the Proto-Indo-European language was spoken during the 4th millennium BC in the Armenian Highland. This Indo-Hittite model does not include the Anatolian languages in its scenario. The phonological peculiarities of PIE proposed in the glottalic theory would be best preserved in the Armenian language and the Germanic languages, the former assuming the role of the dialect which remained \"in situ\", implied to be particularly archaic in spite of its late attestation. Proto-Greek would be practically equivalent to Mycenean Greek and would date to the 17th century BC, closely associating Greek migration to Greece with the Indo-Aryan migration to India at about the same time (viz., Indo-European expansion at the transition to the Late Bronze Age, including the possibility of Indo-European Kassites). The Armenian hypothesis argues for the latest possible date of Proto-Indo-European (\"sans\" Anatolian), a full millennium later than the mainstream Kurgan hypothesis. In this, it figures as an opposite to the Anatolian hypothesis, in spite of the geographical proximity of the respective \"Urheimaten\" suggested, diverging from the time-frame suggested there by a full three millennia.\nAnatolian hypothesis.\nThe Anatolian hypothesis, notably advocated by Colin Renfrew from the 1980s onwards, proposes that the Indo-European languages spread peacefully into Europe from Anatolia from around 7000 BC with the Neolithic Revolution's advance of farming (\"wave of advance\"). The culture of the Indo-Europeans as inferred by linguistic reconstruction raises difficulties for this theory, since early neolithic cultures lacked the horse, the wheel, and metal \u2013 terms for all of which are securely reconstructed for Proto-Indo-European. Renfrew dismisses this argument, comparing such reconstructions to a theory that the presence of the word \"caf\u00e9\" in all modern Romance languages implies that the ancient Romans had caf\u00e9s too.\nAnother argument, made by proponents of the steppe Urheimat (such as David Anthony) against Renfrew, points to the fact that ancient Anatolia is known to have been inhabited in the 2nd millennium BC by non-Indo-European-speaking peoples, namely the Hattians (perhaps North Caucasian-speaking), the Chalybes (language unknown), and the Hurrians (Hurro-Urartian).\nFollowing the publication of several studies on ancient DNA in 2015, Colin Renfrew subsequently acknowledged the important role of migrations of populations speaking one or several Indo-European languages from the Pontic\u2013Caspian steppe towards Northwestern Europe, noting that the DNA evidence from ancient skeletons \"had completely rejuvenated Marija Gimbutas' kurgan hypothesis.\"\nGenetics.\nArchaeogenetics has allowed the use of genetic analysis to trace migration patterns.\nKurgan/Steppe hypothesis.\nThe Kurgan hypothesis, or steppe theory, is the most widely accepted proposal to identify the Proto-Indo-European homeland from which the Indo-European languages spread out throughout Europe and parts of Asia. It postulates that the people of a Kurgan culture in the Pontic steppe north of the Black Sea were the most likely speakers of the Proto-Indo-European language (PIE). The term is derived from the Russian (), meaning 'tumulus' or 'burial mound'.\nR1a and R1b.\nAccording to three autosomal DNA studies, haplogroups R1b and R1a, now the most common in Europe (R1a is also very common in South Asia) would have expanded from the Pontic steppes, along with the Indo-European languages; they also detected an autosomal component present in modern Europeans which was not present in Neolithic Europeans, which would have been introduced with paternal lineages R1b and R1a, as well as Indo-European languages. Studies which analysed ancient human remains in Ireland and Portugal suggest that R1b was introduced in these places along with autosomal DNA from the Pontic steppes.\nR1a and R1a1a.\nThe subclade R1a1a (R-M17 or R-M198) is most commonly associated with Indo-European speakers. Data so far collected indicate that there are two widely separated areas of high frequency:\nThe historical and prehistoric possible reasons for this are the subject of on-going discussion and attention amongst population geneticists and genetic genealogists, and are considered to be of potential interest to linguists and archaeologists also.\nA large study in 2014 by Underhill et al., using 16,244 individuals from over 126 populations from across Eurasia, concluded there was compelling evidence that R1a-M420 originated in the vicinity of Iran. The mutations that characterize haplogroup R1a occurred around 10,000 years BP. Its defining mutation (M17) occurred about 10,000 to 14,000 years ago. Pamjav et al. (2012) believe that R1a originated and initially diversified either within the Eurasian Steppes or in the Middle East and Caucasus region.\nOrnella Semino et al. propose a postglacial (Holocene) spread of the R1a1 haplogroup from north of the Black Sea during the time of the Late Glacial Maximum, which was subsequently magnified by the expansion of the Kurgan culture into Europe and eastward.\nYamnaya culture.\nAccording to Jones et al. (2015) and , autosomal tests indicate that the Yamnaya-people were the result of admixture between \"Eastern Hunter-Gatherers\" from eastern Europe (EHG) and \"Caucasus hunter-gatherers\" (CHG).\nEach of those two populations contributed about half the Yamnaya DNA. According to co-author Dr. Andrea Manica of the University of Cambridge: \n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The question of where the Yamnaya come from has been something of a mystery up to now [...] we can now answer that, as we've found that their genetic make-up is a mix of Eastern European hunter-gatherers and a population from this pocket of Caucasus hunter-gatherers who weathered much of the last Ice Age in apparent isolation.\nAll Yamnaya individuals sampled by Haak et al. (2015) belonged to the Y-haplogroup R1b.\nBased on these findings and by equating the people of the Yamnaya culture with the Proto-Indo-Europeans, David W. Anthony (2019) suggests that the Proto-Indo-European language formed mainly from a base of languages spoken by Eastern European hunter-gathers with influences from languages of northern Caucasus hunter-gatherers, in addition to a possible later influence from the language of the Maikop culture to the south (which is hypothesized to have belonged to the North Caucasian family) in the later neolithic or Bronze Age involving little genetic impact.\nEastern European hunter-gatherers.\nAccording to , \"Eastern European hunter-gatherers\" who inhabited Russia were a distinctive population of hunter-gatherers with high affinity to a ~24,000-year-old Siberian from the Mal'ta-Buret' culture, or other, closely related Ancient North Eurasian (ANE) people from Siberia and to the Western Hunter-Gatherers (WHG). Remains of the \"Eastern European hunter-gatherers\" have been found in Mesolithic or early Neolithic sites in Karelia and Samara Oblast, Russia, and put under analysis. Three such hunter-gathering individuals of the male sex have had their DNA results published. Each was found to belong to a different Y-DNA haplogroup: R1a, R1b, and J. R1b is also the most common Y-DNA haplogroup found among both the Yamnaya and modern-day Western Europeans. R1a is more common in Eastern Europeans and in the northern parts of the Indian subcontinent.\nNear East population.\nThe Near East population were most likely hunter-gatherers from the Caucasus (CHG) c.q. Iran Chalcolithic related people with a major CHG-component.\nJones et al. (2015) analyzed genomes from males from western Georgia, in the Caucasus, from the Late Upper Palaeolithic (13,300 years old) and the Mesolithic (9,700 years old). These two males carried Y-DNA haplogroups J* and J2a. The researchers found that these Caucasus hunters were probably the source of the farmer-like DNA in the Yamnaya, as the Caucasians were distantly related to the Middle Eastern people who introduced farming in Europe. Their genomes showed that a continued mixture of the Caucasians with Middle Eastern took place up to 25,000 years ago, when the coldest period in the last Ice Age started.\nAccording to Lazaridis et al. (2016), \"a population related to the people of the Iran Chalcolithic contributed ~43% of the ancestry of early Bronze Age populations of the steppe.\"; and these Iranian Chalcolithic people were a mixture of \"the Neolithic people of western Iran, the Levant, and Caucasus Hunter Gatherers.\" They also note that farming spread in two places in the Near East, namely the Levant and Iran, from where it spread, Iranian people spreading to the steppe and south Asia.\nNorthern and Central Europe.\n studied DNA from 94 skeletons from Europe and Russia aged between 3,000 and 8,000 years old. They concluded that about 4,500 years ago there was a major influx into Europe of Yamnaya culture people originating from the Pontic\u2013Caspian steppe north of the Black Sea and that the DNA of copper-age Europeans matched that of the Yamnaya.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The four Corded Ware people could trace an astonishing three-quarters of their ancestry to the Yamnaya, according to the paper. That suggests a massive migration of Yamnaya people from their steppe homeland into Eastern Europe about 4500 years ago when the Corded Ware culture began, perhaps carrying an early form of Indo-European language.\nBronze Age Greeks.\nA 2017 archaeogenetics study of Mycenaean and Minoan remains published in the journal \"Nature\" concluded that the Mycenaean Greeks were genetically closely related with the Minoans but unlike the Minoans also had a 13\u201318% genetic contribution from Bronze Age steppe populations.\nAnatolian hypothesis.\nLuigi Luca Cavalli-Sforza and Alberto Piazza argue that Renfrew and Gimbutas reinforce rather than contradict each other. states that \"It is clear that, genetically speaking, peoples of the Kurgan steppe descended at least in part from people of the Middle Eastern Neolithic who immigrated there from Turkey.\" state that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;if the expansions began at 9,500 years ago from Anatolia and at 6,000 years ago from the Yamnaya culture region, then a 3,500-year period elapsed during their migration to the Volga-Don region from Anatolia, probably through the Balkans. There a completely new, mostly pastoral culture developed under the stimulus of an environment unfavourable to standard agriculture, but offering new attractive possibilities. Our hypothesis is, therefore, that Indo-European languages derived from a secondary expansion from the Yamnaya culture region after the Neolithic farmers, possibly coming from Anatolia and settled there, developing pastoral nomadism.\nSpencer Wells suggests in a 2001 study that the origin, distribution and age of the R1a1 haplotype points to an ancient migration, possibly corresponding to the spread by the Kurgan people in their expansion across the Eurasian steppe around 3000 BC.\nAbout his old teacher Cavalli-Sforza's proposal, states that \"there is nothing to contradict this model, although the genetic patterns do not provide clear support either\", and instead argues that the evidence is much stronger for Gimbutas' model:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;While we see substantial genetic and archaeological evidence for an Indo-European migration originating in the southern Russian steppes, there is little evidence for a similarly massive Indo-European migration from the Middle East to Europe. One possibility is that, as a much earlier migration (8,000 years old, as opposed to 4,000), the genetic signals carried by Indo-European-speaking farmers may simply have dispersed over the years. There is clearly \"some\" genetic evidence for migration from the Middle East, as Cavalli-Sforza and his colleagues showed, but the signal is not strong enough for us to trace the distribution of Neolithic languages throughout the entirety of Indo-European-speaking Europe.\nIranian/Armenian hypothesis.\nDavid Reich (2018), noting the presence of some Indo-European languages (such as Hittite) in parts of ancient Anatolia, argues that \"the most likely location of the population that first spoke an Indo-European language was south of the Caucasus Mountains, perhaps in present-day Iran or Armenia, because ancient DNA from people who lived there matches what we would expect for a source population both for the Yamnaya and for ancient Anatolians.\" Yet, Reich also notes that \"...the evidence here is circumstantial as no ancient DNA from the Hittites themselves has yet been published.\" Kristian Kristiansen, in an interview with \"Der Spiegel\" in May 2018, stated that the Yamnaya culture may have had a predecessor at the Caucasus, where \"proto-proto-Indo-European\" was spoken.\nRecent DNA-research has led to renewed suggestions of a Caucasian homeland for the 'proto-Indo-Europeans'. According to Kroonen et al. (2018) and Damgaard et al. (2018), ancient Anatolia \"show no indication of a large-scale intrusion of a steppe population.\" They further note that this lends support to the Indo-Hittite hypothesis, according to which both proto-Anatolian and proto-Indo-European split-off from a common mother language \"no later than the 4th millennium BCE.\" states that \"the Armenian plateau hypothesis gains in plausibility\" since the Yamnaya partly descended from a Near Eastern population, which resembles present-day Armenians.\"\nWang et al. (2018) note that the Caucasus served as a corridor for gene flow between the steppe and cultures south of the Caucasus during the Eneolithic and the Bronze Age, stating that this \"opens up the possibility of a homeland of PIE south of the Caucasus.\" However, Wang et al. also comment that the most recent genetic evidence supports an expansion of proto-Indo-Europeans through the steppe, noting: \"but the latest ancient DNA results from South Asia also lend weight to a spread of Indo-European languages \"via the steppe belt. The spread of some or all of the proto-Indo-European branches would have been possible via the North Caucasus and Pontic region and from there, along with pastoralist expansions, to the heart of Europe. This scenario finds support from the well attested and now widely documented 'steppe ancestry' in European populations, the postulate of increasingly patrilinear societies in the wake of these expansions (exemplified by R1a/R1b), as attested in the latest study on the Bell Beaker phenomenon.\"\nDavid W. Anthony in a 2019 analysis, criticizes the \"southern\" or \"Armenian\" hypothesis (addressing Reich, Kristiansen, and Wang). Among his reasons being: that the Yamnaya lack evidence of genetic influence from the Bronze Age or late neolithic Caucasus (deriving instead from an earlier mixture of Eastern European hunter-gatherers and Caucasus hunter-gatherers) and have paternal lineages that seem to derive from the hunter-gatherers of the Eastern European Steppe rather than the Caucasus, as well as a scarcity in the Yamnaya of the Anatolian Farmer admixture that had become common and substantial in the Caucasus around 5,000 BC. Anthony instead suggests a genetic and linguistic origin of proto-Indo-Europeans (the Yamnaya) in the Eastern European steppe north of the Caucasus, from a mixture of these two groups (EHG and CHG). He suggests that the roots of Proto-Indo-European (\"archaic\" or proto-proto-Indo-European) were in the steppe rather than the south and that PIE formed mainly from a base of languages spoken by Eastern European hunter-gathers with some influences from languages of Caucasus hunter-gatherers.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24820", "revid": "30021739", "url": "https://en.wikipedia.org/wiki?curid=24820", "title": "Peter Mark Roget", "text": "British physician, philologist (1779\u20131869)\nPeter Mark Roget ( ; 18 January 1779 \u2013 12 September 1869) was a British physician, natural theologian, lexicographer, and founding secretary of The Portico Library. He is best known for publishing, in 1852, the \"Thesaurus of English Words and Phrases\", a classified collection of related words (thesaurus). In 1824, he read a paper to the Royal Society about a peculiar optical illusion which is often (falsely) regarded as the origin of the ancient persistence of vision theory that was later commonly, yet incorrectly, used to explain apparent motion in film and animation.\nEarly life.\nPeter Mark Roget was born in Broad Street, Soho, London, the son of Jean (John) Roget (1751\u20131783), a Genevan cleric born to French parents, and Catherine \"Kitty\" Romilly, the sister of British politician, abolitionist, and legal reformer Sir Samuel Romilly. His parents were French Huguenots. Following his father's death, the family moved to Edinburgh in 1783 where Roget later studied medicine at the University of Edinburgh, graduating in 1798, with a thesis titled \"De chemicae affinitatis legibus\" (\"On the Laws of Chemical Affinity\"). Samuel Romilly, who took on the role of surrogate father to Roget and supported his nephew's education, also introduced him into Whig social circles.\nRoget then attended lectures at London medical schools. Living in Clifton, Bristol, from 1798 to 1799, he knew Thomas Beddoes and Humphry Davy and frequented the Pneumatic Institute.\nNot making a quick start to a medical career, in 1802 Roget took a position as a tutor to the sons of John Leigh Philips, with whom he began a Grand Tour during the Peace of Amiens, travelling with a friend, Lovell Edgeworth, son of Richard Lovell Edgeworth. When the Peace abruptly ended he was detained as a prisoner in Geneva. He was able to bring his pupils back to England in late 1803, but Edgeworth was held in captivity until Napoleon fell on 6 April 1814.\nMedical career.\nWith the help of Samuel Romilly, Roget became a private physician to William Petty, 1st Marquess of Lansdowne, who died in 1805. He then succeeded Thomas Percival at Manchester Infirmary and began to lecture on physiology. He moved to London in 1808 and in 1809 became a licentiate of the Royal College of Physicians. After an extended period of dispensary work and lecturing, in particular, at the Russell Institution and Royal Institution, he joined the staff of the Queen Charlotte Hospital in 1817. He also lectured at the London Institution and the Windmill Street School.\nIn 1823 Roget and Peter Mere Latham were brought in to investigate disease at Millbank Penitentiary. In 1828 Roget, with William Thomas Brande and Thomas Telford, submitted a report on London's water supply. In 1834 he became the first Fullerian Professor of Physiology at the Royal Institution. One of those who helped found the University of London in 1837, he was an examiner in physiology there. He gave up medical practice in 1840.\nThesaurus.\nRoget retired from professional life in 1840, and by 1846 was working on the book that perpetuates his memory today. It has been claimed that Roget struggled with depression for most of his life, and that the thesaurus arose partly from an effort to battle it. A biographer stated that his obsession with list-making as a coping mechanism was well established by the time Roget was eight years old. In 1805, he began to maintain a notebook classification scheme for words, organized by meaning. During this period he also moved to Manchester, where he became the first secretary of the Portico Library.\nThe catalogue of words was first printed in 1852, titled \"Thesaurus of English Words and Phrases Classified and Arranged so as to Facilitate the Expression of Ideas and Assist in Literary Composition\". During Roget's lifetime, the work had twenty-eight printings. After his death, it was revised and expanded by his son, John Lewis Roget (1828\u20131908), and later by John's son, the engineer Samuel Romilly Roget (1875\u20131953). Roget's private library was put up for auction in 1870 at Sotheby's and its catalogue has been analysed.\nOther interests.\nRoget was elected to membership of the Manchester Literary and Philosophical Society on 25January 1805 and as a Fellow of the Royal Society in 1815, in recognition of a paper on a slide rule with a loglog scale. He was a secretary of the Society from 1827 to 1848. On 9 December 1824, Roget presented a paper on a peculiar optical illusion to the \"Philosophical Transactions\", which was published in 1825, as \"Explanation of an optical deception in the appearance of the spokes of a wheel when seen through vertical apertures.\" The paper was noted by Michael Faraday and by Joseph Plateau, who both mentioned it in their articles that presented new illusions with apparent motion. It has often been heralded as the basis for the persistence of vision theory, which has for a long time been falsely regarded as the principle causing the perception of motion in animation and film. In 1834, Roget claimed to have invented \"the Phantasmascope or Phenakistoscope\" in the spring of 1831, a few years before Plateau introduced that first stroboscopic animation device.\nOne of the promoters of the Medical and Chirurgical Society of London, of which he was the President in 1829, and which later became the Royal Society of Medicine, Roget was also a founder of the Society for the Diffusion of Useful Knowledge, writing a series of popular manuals for it. He wrote numerous papers on physiology and health, among them the fifth \"Bridgewater Treatise\", \"Animal and Vegetable Physiology considered with reference to Natural Theology\" (1834), and articles for the \"Encyclop\u00e6dia Britannica\". He was hostile to phrenology, writing against it in a \"Britannica\" supplement in 1818 and devoting a two-volume work to it in 1838.\nA chess player, in an article in the \"London and Edinburgh Philosophical Magazine\" Roget solved the general open knight's tour problem. He composed chess problems and designed an inexpensive pocket chessboard.\nPersonal life.\nIn 1818 Roget was called to the home of Samuel Romilly following the death of his wife, Lady Romilly. Samuel Romilly, Roget's uncle and surrogate father, then committed suicide by cutting his throat, dying in Roget's presence.\nFamily.\nIn 1824 Roget married Mary Taylor, the daughter of Jonathan Hobson. They had a son, John Lewis (1828\u20131908), and a daughter, Kate.\nLater life.\nIn later life Roget became deaf and was cared for by his daughter, Kate. He died aged 90 while on holiday in West Malvern, Worcestershire and was laid to rest in St. James Church cemetery, West Malvern. There is a memorial to him at his local parish church of St Mary on Paddington Green Church.\nIn literature.\nCanadian writer Keath Fraser published a story, \"Roget's Thesaurus\", in 1982, which is narrated in Roget's voice. He has Roget speak on his wife's death, from cancer.\nRoget also appears in Shelagh Stephenson's \"An Experiment with an Air Pump\", set in 1799, as the only historical character. The play is set in the fictional household of Joseph Fenwick, and Roget is one of Fenwick's assistants.\nA picture-book biography of Roget entitled \"The Right Word: Roget and His Thesaurus\" was published by Eerdmans Books in 2014. It was named a Caldecott Honor book for excellence in illustration and won the Sibert Medal for excellence in children's nonfiction.\nMartin Luther King, Jr. cites \"Roget\u2019s Thesaurus\" in the context of racism:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u201dEven semantics have conspired to make that which is black seem ugly and degrading. In Roget\u2019s Thesaurus there are some 120 synonyms for \u201cblackness\u201d and at least 60 of them are offensive\u2014such words as \u201cblot,\u201d \u201csoot,\u201d \u201cgrime,\u201d \u201cdevil\u201d and \u201cfoul.\u201d There are some 134 synonyms for \u201cwhiteness,\u201d and all are favorable, expressed in such words as \u201cpurity,\u201d \u201ccleanliness,\u201d \u201cchastity\u201d and \u201cinnocence.\u201d\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24822", "revid": "14383484", "url": "https://en.wikipedia.org/wiki?curid=24822", "title": "Playstation", "text": ""}
{"id": "24823", "revid": "39732090", "url": "https://en.wikipedia.org/wiki?curid=24823", "title": "Pterodactylus", "text": "Genus of pterodactyloid pterosaur from the Late Jurassic\nPterodactylus (from 'winged finger') is a genus of extinct pterosaurs. It is thought to contain only a single species, Pterodactylus antiquus, which was the first pterosaur to be named and identified as a flying reptile and one of the first prehistoric reptiles to ever be discovered.\nFossil remains of \"Pterodactylus\" have primarily been found in the Solnhofen limestone of Bavaria, Germany, which dates from the Late Jurassic period (Tithonian stage), about 150.8 to 148.5 million years ago. More fragmentary remains of \"Pterodactylus\" have tentatively been identified from elsewhere in Europe and in Africa.\n\"Pterodactylus\" was a generalist carnivore that probably fed on a variety of invertebrates and vertebrates. Like all pterosaurs, \"Pterodactylus\" had wings formed by a skin and muscle membrane stretching from its elongated fourth finger to its hind limbs. It was supported internally by collagen fibres and externally by keratinous ridges. \"Pterodactylus\" was a small pterosaur compared to other famous genera such as \"Pteranodon\" and \"Quetzalcoatlus\", and it also lived earlier, during the Late Jurassic period, while both \"Pteranodon\" and \"Quetzalcoatlus\" lived during the Late Cretaceous. \"Pterodactylus\" lived alongside other small pterosaurs such as the well-known \"Rhamphorhynchus\", as well as other genera such as \"Scaphognathus\", \"Anurognathus\" and \"Ctenochasma\". \"Pterodactylus\" is classified as an early-branching member of the ctenochasmatid lineage, within the pterosaur clade Pterodactyloidea.\nDiscovery and history.\nThe type specimen of the animal now known as \"Pterodactylus antiquus\" was the first pterosaur fossil ever to be identified. The first \"Pterodactylus\" specimen was described by the Italian scientist in 1784, based on a fossil skeleton that had been unearthed from the Solnhofen limestone of Bavaria. Collini was the curator of the , or nature cabinet of curiosities (a precursor to the modern concept of the natural history museum), in the palace of Charles Theodore, Elector of Bavaria at Mannheim. The specimen had been given to the collection by Count around 1780, having been recovered from a lithographic limestone quarry in . The actual date of the specimen's discovery and entry into the collection is unknown however, and it was not mentioned in a catalogue of the collection taken in 1767, so it must have been acquired at some point between that date and its 1784 description by Collini. This makes it potentially the earliest documented pterosaur find; the \"Pester Exemplar\" of the genus \"Aurorazhdarcho\" was described in 1779 and possibly discovered earlier than the Mannheim specimen, but it was at first considered to be a fossilized crustacean, and it was not until 1856 that this species was properly described as a pterosaur by German paleontologist .\nIn his first description of the Mannheim specimen, Collini did not conclude that it was a flying animal. In fact, Collini could not fathom what kind of animal it might have been, rejecting affinities with the birds or the bats. He speculated that it may have been a sea creature, not for any anatomical reason, but because he thought the ocean depths were more likely to have housed unknown types of animals. The idea that pterosaurs were aquatic animals persisted among a minority of scientists as late as 1830, when the German zoologist Johann Georg Wagler published a text on \"amphibians\" which included an illustration of \"Pterodactylus\" using its wings as flippers. Wagler went so far as to classify \"Pterodactylus\", along with other aquatic vertebrates (namely plesiosaurs, ichthyosaurs, and monotremes), in the class Gryphi, between birds and mammals.\nThe German/French scientist Johann Hermann was the one who first stated that \"Pterodactylus\" used its long fourth finger to support a wing membrane. Back in March 1800, Hermann alerted the prominent French scientist Georges Cuvier to the existence of Collini's fossil, believing that it had been captured by the invading forces of the French Consulate and sent to collections in Paris (and perhaps to Cuvier himself) as war booty; at the time special French political commissars systematically seized art treasures and objects of scientific interest. Hermann sent Cuvier a letter containing his own interpretation of the specimen (though he had not examined it personally), which he believed to be a mammal, including the first known life restoration of a pterosaur. Hermann restored the animal with wing membranes extending from the long fourth finger to the ankle and a covering of fur (neither wing membranes nor fur had been preserved in the specimen). Hermann also added a membrane between the neck and wrist, as is the condition in bats. Cuvier agreed with this interpretation, and at Hermann's suggestion, Cuvier became the first to publish these ideas in December 1800 in a very short description. However, contrary to Hermann, Cuvier was convinced the animal was a reptile. The specimen had not in fact been seized by the French. Rather, in 1802, following the death of Charles Theodore, it was brought to Munich, where Baron Johann Paul Carl von Moll had obtained a general exemption of confiscation for the Bavarian collections. Cuvier asked von Moll to study the fossil but was informed it could not be found. In 1809 Cuvier published a somewhat longer description, in which he named the animal \"Petro-Dactyle\", this was a typographical error however, and was later corrected by him to \"Pt\u00e9ro-Dactyle\". He also refuted a hypothesis by Johann Friedrich Blumenbach that it would have been a shore bird. Cuvier remarked: \"It is not possible to doubt that the long finger served to support a membrane that, by lengthening the anterior extremity of this animal, formed a good wing.\"\nContrary to von Moll's report, the fossil was not missing; it was being studied by Samuel Thomas von S\u00f6mmerring, who gave a public lecture about it on December 27, 1810. In January 1811, von S\u00f6mmerring wrote a letter to Cuvier deploring the fact that he had only recently been informed of Cuvier's request for information. His lecture was published in 1812, and in it von S\u00f6mmerring named the species Ornithocephalus antiquus. The animal was described as being both a bat, and a form in between mammals and birds, i.e. not intermediate in descent but in \"affinity\" or archetype. Cuvier disagreed, and the same year in his \"Ossemens fossiles\" provided a lengthy description in which he restated that the animal was a reptile. It was not until 1817 that a second specimen of \"Pterodactylus\" came to light, again from Solnhofen. This tiny specimen was that year described by von S\u00f6mmerring as \"Ornithocephalus brevirostris\", named for its short snout, now understood to be a juvenile character. He provided a restoration of the skeleton, the first one published for any pterosaur. This restoration was very inaccurate, von S\u00f6mmerring mistaking the long metacarpals for the bones of the lower arm, the lower arm for the humerus, this upper arm for the breast bone and this sternum again for the shoulder blades. S\u00f6mmerring did not change his opinion that these forms were bats and this \"bat model\" for interpreting pterosaurs would remain influential long after a consensus had been reached around 1860 that they were reptiles. The standard assumptions were that pterosaurs were quadrupedal, clumsy on the ground, furred, warmblooded and had a wing membrane reaching the ankle. Some of these elements have been confirmed, some refuted by modern research, while others remain disputed.\nIn 1815, the generic name \"Pt\u00e9ro-Dactyle\" was latinized to \"Pterodactylus\" by Constantine Samuel Rafinesque. Unaware of Rafinesque's publication however, Cuvier himself in 1819 latinized the name \"Pt\u00e9ro-Dactyle\" again to \"Pterodactylus\", but the specific name he then gave, \"longirostris\", has to give precedence to von S\u00f6mmerring's \"antiquus\". In 1888, English naturalist Richard Lydekker designated \"Pterodactylus antiquus\" as the type species of \"Pterodactylus\", and considered \"Ornithocephalus antiquus\" a synonym. He also designated specimen BSP AS.I.739 as the holotype of the genus.\nDescription.\n\"Pterodactylus\" is known from over 30 fossil specimens, and though most belong to juveniles, many preserve complete skeletons. \"Pterodactylus antiquus\" was a relatively small pterosaur, with an estimated adult wingspan of about , based on the only known adult specimen, which is represented by an isolated skull. Other \"species\" were once thought to have been smaller. However, these smaller specimens have been shown to represent juveniles of \"Pterodactylus\", as well as its contemporary relatives including \"Ctenochasma\", \"Germanodactylus\", \"Aurorazhdarcho\", \"Gnathosaurus\", and hypothetically \"Aerodactylus\" if this genus is truly valid.\nThe skulls of adult \"Pterodactylus\" were long and thin, with about 90 narrow and conical teeth. The teeth extended back from the tips of both jaws, and became smaller farther away from the jaw tips. This was unlike the ones seen in most relatives, where teeth were absent in the upper jaw tip and were relatively uniform in size. The teeth of \"Pterodactylus\" also extended farther back into the jaw compared to close relatives, and some were present below the front of the \"nasoantorbital fenestra\", which is the largest opening in the skull. Another autapomorphy that \"Pterodactylus\" has is that the skull and jaws were straight, which are unlike the upwardly curved jaws seen in the related ctenochasmatids.\n\"Pterodactylus\", like related pterosaurs, had a crest on its skull composed mainly of soft tissues. In adult \"Pterodactylus\", this crest extended between the back edge of the antorbital fenestra and the back of the skull. In at least one specimen, the crest had a short bony base, also seen in related pterosaurs like \"Germanodactylus\". Solid crests have only been found on large, fully adult specimens of \"Pterodactylus\", indicating that this was a display structure that became larger and more well developed as individuals reached maturity. In 2013, pterosaur researcher S. Christopher Bennett noted that other authors claimed that the soft tissue crest of \"Pterodactylus\" extended backward behind the skull; Bennett himself, however, didn't find any evidence for the crest extending past the back of the skull. Two specimens of \"P. antiquus\" (the holotype specimen BSP AS I 739 and the incomplete skull BMMS 7, the largest known skull of \"P. antiquus\") have a low bony crest on their skulls; in BMMS 7 it is 47.5\u00a0mm long (1.87 inches, more or less 24% of the estimated total length of its skull) and has a maximum height of 0.9\u00a0mm (0.035 inches) above the orbit. Several specimens previously referred to \"P. antiquus\" preserved evidence of the soft tissue extensions of these crests, including an \"occipital lappet\", a flexible, tab-like structure extending from the back of the skull. Most of these specimens have been reclassified in the related species \"Aerodactylus scolopaciceps\", which may however be nothing more than a junior synonym. Even if \"Aerodactylus\" were valid, at least one specimen with these features is still considered to belong to \"Pterodactylus\", BSP 1929 I 18, which has an occipital lappet similar to the proposed \"Aerodactylus\" definition, and also possesses a small triangular soft tissue crest with the peak of the crest positioned above the eyes.\nPaleobiology.\nLife history.\nLike other pterosaurs (most notably \"Rhamphorhynchus\"), \"Pterodactylus\" specimens can vary considerably based on age or level of maturity. Both the proportions of the limb bones, size and shape of the skull, and size and number of teeth changed as the animals grew. Historically, this has led to various growth stages (including growth stages of related pterosaurs) being mistaken for new species of \"Pterodactylus\". Several detailed studies using various methods to measure growth curves among known specimens have suggested that there is actually only one valid species of \"Pterodactylus\", \"P. antiquus\".\nThe youngest immature specimens of \"Pterodactylus antiquus\" (alternately interpreted as young specimens of the distinct species \"P. kochi\") have a small number of teeth, as few as 15 in some, and the teeth have a relatively broad base. The teeth of other \"P. antiquus\" specimens are both narrower and more numerous (up to 90 teeth are present in several specimens).\n\"Pterodactylus\" specimens can be divided into two distinct year classes. In the first year class, the skulls are only in length. The second year class is characterized by skulls of around long, but are still immature however. These first two size groups were once classified as juveniles and adults of the species \"P. kochi\", until further study showed that even the supposed \"adults\" were immature, and possibly belong to a distinct genus. A third year class is represented by specimens of the \"traditional\" \"P. antiquus\", as well as a few isolated, large specimens once assigned to \"P. kochi\" that overlap \"P. antiquus\" in size. However, all specimens in this third year class also show sign of immaturity. Fully mature \"Pterodactylus\" specimens remain unknown, or may have been mistakenly classified as a different genus.\nGrowth and breeding seasons.\nThe distinct year classes of \"Pterodactylus antiquus\" specimens show that this species, like the contemporary \"Rhamphorhynchus muensteri\", likely bred seasonally and grew consistently during its lifetime. A new generation of 1st year class \"P. antiquus\" would have been produced seasonally, and reached 2nd-year size by the time the next generation hatched, creating distinct 'clumps' of similarly-sized and aged individuals in the fossil record. The smallest size class probably consisted of individuals that had just begun to fly and were less than one year old. The second year class represents individuals one to two years old, and the rare third year class is composed of specimens over two years old. This growth pattern is similar to modern crocodilians, rather than the rapid growth of modern birds.\nDaily activity patterns.\nComparisons between the scleral rings of \"Pterodactylus antiquus\" and modern birds and reptiles suggest that it may have been diurnal. This may also indicate niche partitioning with contemporary pterosaurs inferred to be nocturnal, such as \"Ctenochasma\" and \"Rhamphorhynchus\".\nDiet.\nBased on the shape, size, and arrangement of its teeth, \"Pterodactylus\" has long been recognized as a carnivore specializing in small animals. A 2020 study of pterosaur tooth wear supported the hypothesis that \"Pterodactylus\" preyed mainly on invertebrates and had a generalist feeding strategy, indicated by a relatively high bite force.\nPaleoecology.\nSpecimens of \"Pterodactylus\" have been found mainly in the Solnhofen limestone (geologically known as the Altm\u00fchltal Formation) of Bavaria, Germany. The main composition of this formation is fine-grained limestone that originated mainly from the nearby towns Solnhofen and Eichst\u00e4tt, which is formed by mud silt deposits. The Solnhofen Limestone is a diverse Lagerst\u00e4tte that contains a wide range of different creatures, including highly detailed fossilized imprints of soft bodied organisms such as jellyfishes. Abundant specimens of pterosaurs similar to \"Pterodactylus\" were also found within the formation, these include the rhamphorhynchids \"Rhamphorhynchus\" and \"Scaphognathus\", several gallodactylids such as \"Aerodactylus\", \"Ardeadactylus\", \"Aurorazhdarcho\" and \"Cycnorhamphus\", the ctenochasmatids \"Ctenochasma\" and \"Gnathosaurus\", the anurognathid \"Anurognathus\", the germanodactylid \"Germanodactylus\", as well as the basal euctenochasmatian \"Diopecephalus\". Fossil remains of the dinosaurs \"Archaeopteryx\" and \"Compsognathus\" were also found within the limestone, these specimens were related to early evolution of feathers, since they were some of the only ones that had them during the Jurassic period. Various lizard remains were also found alongside those of \"Pterodactylus\", with several specimens assigned to \"Ardeosaurus\", \"Bavarisaurus\" and \"Eichstaettisaurus\". Crocodylomorph specimens were widely distributed within the fossil site, most were assigned to the metriorhynchid genera \"Cricosaurus\", \"Dakosaurus\", \"Geosaurus\" and \"Rhacheosaurus\". These genera are colloquially called as marine or sea crocodiles due to their similar built. The turtle genera \"Eurysternum\" and \"Paleomedusa\" were also found within the formation. Fossils of the ichthyosaur \"Aegirosaurus\" also appeared to be present in the site, as well as fish remains, with many specimens assigned to ray-finned fishes such as the halecomorphs \"Lepidotes\", \"Propterus\", \"Gyrodus\", \"Mesturus\", \"Proscinetes\", \"Caturus\", \"Ophiopsis\" and \"Ophiopsiella\", the pachycormids \"Asthenocormus\", \"Hypsocormus\" and \"Orthocormus\", as well as the aspidorhynchid \"Aspidorhynchus\", and the ichthyodectid \"Thrissops\".\nClassification.\nInitial classifications for \"Pterodactylus\" started when paleontologist Hermann von Meyer used the name Pterodactyli to contain \"Pterodactylus\" and other pterosaurs known at the time. This was emended to the family Pterodactylidae by Prince Charles Lucien Bonaparte in 1838. However, this group has more recently been given several competing definitions.\nBeginning in 2014, researchers Steven Vidovic and David Martill constructed an analysis in which several pterosaurs traditionally thought of as archaeopterodactyloids closely related to the ctenochasmatoids may have been more closely related to the more advanced dsungaripteroids, or in some cases, fall outside both groups. Their conclusion was published in 2017, in which they placed \"Pterodactylus\" as a basal member of the suborder Pterodactyloidea.\nAs illustrated below, the results of a different topology are based on a phylogenetic analysis made by Longrich, Martill, and Andres in 2018. Unlike the previous results above, they placed \"Pterodactylus\" within the clade Euctenochasmatia, resulting in a more derived position.\nFormerly assigned species.\nNumerous species have been assigned to \"Pterodactylus\" in the years since its discovery. In the first half of the 19th century any new pterosaur species would be named \"Pterodactylus\", which thus became a \"wastebasket taxon\". Even after clearly different forms had later been given their own generic name, new species would be created from the very productive sites, throughout Europe and North America, often based on only slightly different material.\nThe earliest reassignments of pterosaur species to \"Pterodactylus\" started in 1825, with the description of \"Rhamphorhynchus\"; fossil collector Georg Graf zu M\u00fcnster alerted the German paleontologist Samuel Thomas von S\u00f6mmerring about several distinct fossil specimens, S\u00f6mmerring thought that they belonged to an ancient bird. Further fossil preparations had uncovered teeth, to which Graf zu M\u00fcnster created a skull cast. He later sent the cast to Professor Georg August Goldfuss, who recognized it as a pterosaur, specifically a species of \"Pterodactylus\". At the time however, most paleontologists incorrectly consider the genus \"Ornithocephalus\" (lit.\u2009'bird-head') to be the valid name for \"Pterodactylus\", and therefore the specimen found was named as \"Ornithocephalus M\u00fcnsteri\", which was first mentioned by Graf zu M\u00fcnster himself. Another specimen was found and described by Graf zu M\u00fcnster in 1839, he assigned this specimen to a new separate species called \"Ornithocephalus longicaudus\"; the specific name means 'long tail', in reference to the animal's tail size. German paleontologist Hermann von Meyer in 1845 officially emended that the genus \"Pterodactylus\" had priority over \"Ornithocephalus\", so he reassigned the species \"O. m\u00fcnsteri\" and \"O. longicaudus\" into \"Pterodactylus m\u00fcnsteri\" and \"Pterodactylus longicaudus\". In 1846, von Meyer created the new species \"Pterodactylus gemmingi\" based on long-tailed remains; the specific name honors the fossil collector Carl Eming von Gemming. Later, in 1847, von Meyer finally erected the generic name \"Rhamphorhynchus\" (lit.\u2009'beak snout') due to the distinctively long tails seen in the specimens found, which are much longer than those seen in \"Pterodactylus\". He assigned the species \"P. longicaudus\" as the type species of \"Rhamphorhynchus\", which resulted in a new combination called \"Rhamphorhynchus longicaudus\". The species \"R. m\u00fcnsteri\" was later changed to \"R. muensteri\" by Lydekker in 1888, due to the ICZN rule that prohibits non-standard Latin characters, such as \"\u00fc\", in scientific names.\nBeginning in 1846, many pterosaur specimens were found near the village of Burham in Kent, England by British paleontologists James Scott Bowerbank and Sir Richard Owen. Bowerbank had assigned fossil remains to two new species; the first was named in 1846 as \"Pterodactylus giganteus\"; the specific name means 'the gigantic one' in Latin, in reference to the large size of the remains, and the second species was named in 1851 as \"Pterodactylus cuvieri\", in honor of the French scientist Georges Cuvier. Later in 1851, Owen named and described new pterosaur specimens that have been found yet again in England. He assigned these specimens to a new species called \"Pterodactylus compressirostris\". In 1914 however, paleontologist Reginald Hooley redescribed \"P. compressirostris\", to which he erected the genus \"Lonchodectes\" (lit.\u2009'lance biter'), and therefore made \"P. compressirostris\" the type species, and created the new combination \"L. compressirostris\". In a 2013 review, \"P. giganteus\" and \"P. cuvieri\" were reassigned to new genera; \"P. giganteus\" was reassigned to a genus called \"Lonchodraco\" ('lance dragon'), which resulted in a new combination called \"L. giganteus\", and \"P. cuvieri\" was reassigned to the new genus \"Cimoliopterus\" ('chalk wing'), creating \"C. cuvieri\". Back in 1859, Owen had found remains the front part of a snout in the Cambridge Greensand, and assigned it into the species \"Pterodactylus segwickii\"; in honor of Adam Sedgwick, a British geologist. This species however, was reassigned to the genus \"Camposipterus\" in 2013, therefore creating the new combination \"Camposipterus segwickii\". Later, in 1861, Owen had uncovered multiple distinctively looking fossil remains yet again in the Cambridge Greensand, these were assigned to a new species named \"Pterodactylus simus\", though the British paleontologist Harry Govier Seeley had created a separate generic name called \"Ornithocheirus\", and reassigned \"P. simus\" as the type species, which created the combination \"Ornithocheirus simus\". Between the years 1869 and 1870, Seeley had reassigned many pterosaur species into \"Ornithocheirus\", while also creating several new species. Many of these species however, are now reclassified to other genera, or considered . In 1874, further specimens were found in England, again by Owen, these ones were assigned to a new species called \"Pterodactylus sagittirostris\", this species however, was reassigned to the genus \"Lonchodectes\" in 1914 by Hooley, which resulted in an \"L. sagittirostris\". This conclusion was revised by Rigal \"et al.\" in 2017, who disagreed with Hooley's reassignment, and therefore created the genus \"Serradraco\", which afterwards resulted in a new combination called \"S. sagittirostris\".\nAssigning new pterosaur species to \"Pterodactylus\" was not only common in Europe, but also in North America; paleontologists such as Othniel Charles Marsh in 1871 for example, described several toothless pterosaur specimens, which were accompanied by teeth that belonged to the fish \"Xiphactinus\", which Marsh assumed that these teeth belonged to the pterosaur specimens he found, since all pterosaurs discovered at the time had teeth. He then assigned these specimens to a new species called \"Pterodactylus oweni\", but this was changed to \"Pterodactylus occidentalis\" because \"P. oweni\" was found to have been preoccupied by a pterosaur species described with the same name back in 1864 by Seeley. In 1872, American paleontologist Edward Drinker Cope also found various pterosaur specimens in North America, he assigned these to two new species known as \"Ornithochirus umbrosus\" and \"Ornithochirus harpyia\", Cope attempted to assign the specimens he found to the genus \"Ornithocheirus\", but misspelled forgetting the 'e'. In 1875 however, Cope reassigned the species \"O. umbrosus\" and \"O. harpyia\" into \"Pterodactylus umbrosus\" and \"Pterodactylus harpyia\", though these species had been considered ever since. Paleontologist Samuel Wendell Williston unearthed the first skull of the pterosaur, and found that the animal was toothless, this made Marsh create the genus \"Pteranodon\" (lit.\u2009'toothless wing'), and therefore reassigned all the American pterosaur species, including the ones that he named, from \"Pterodactylus\" to \"Pteranodon\".\nLater, in the 1980s, subsequent revisions by Peter Wellnhofer had reduced the number of recognized species to about half a dozen. Many species assigned to \"Pterodactylus\" had been based on juvenile specimens, and subsequently been recognized as immature individuals of other species or genera. By the 1990s it was understood that this was even true for part of the remaining species. \"P. elegans\", for example, was found by numerous studies to be an immature \"Ctenochasma\". Another species of \"Pterodactylus\" originally based on small, immature specimens was \"P. micronyx\". However, it has been difficult to determine exactly of what genus and species \"P. micronyx\" might be the juvenile form. St\u00e9phane Jouve, Christopher Bennett and others had once suggested that it probably belonged either to \"Gnathosaurus subulatus\" or one of the species belonging to \"Ctenochasma\". After additional research in 2013, Bennett assigned it to the genus \"Aurorazhdarcho\", though a subsequent review by this researcher again proposed synonymy of \"P. micronyx\" with \"Gnathosaurus\". Another species with a complex history is \"P. longicollum\", named by von Meyer in 1854, based on a large specimen with a long neck and fewer teeth. Many researchers, including David Unwin, have found \"P. longicollum\" to be distinct from \"P. kochi\" and \"P. antiquus\". Unwin found \"P. longicollum\" to be closer to \"Germanodactylus\" and therefore requiring a new genus name. It has sometimes been placed in the genus \"Diopecephalus\" because Harry Govier Seeley based this genus partly on the \"P. longicollum\" material. However, it was shown by Bennett that the type specimen later designated for \"Diopecephalus\" was a fossil belonging to \"P. kochi\", and no longer thought to be separate from \"Pterodactylus\". \"Diopecephalus\" is therefore a synonym of \"Pterodactylus\", and as such is unavailable for use as a new genus for \"\"P.\" longicollum\". \"\"P.\" longicollum\" was eventually made the type species of a separate genus \"Ardeadactylus\".\nControversial species.\nThe only well-known and well-supported species left by the first decades of the 21st century were \"P. antiquus\" and \"P. kochi\". However, most studies between 1995 and 2010 found little reason to separate even these two species, and treated them as synonymous. More recent studies of pterosaur relationships have found anurognathids and pterodactyloids to be sister groups, which would limit the more inclusive group Caelidracones to just two clades. In 1996, Bennett suggested that the differences between specimens of \"P. kochi\" and \"P. antiquus\" could be explained by differences in age, with \"P. kochi\" (including specimens alternately classified in the species \"P. scolopaciceps\") representing an immature growth stage of \"P. antiquus\". In a 2004 paper, Jouve used a different method of analysis and recovered the same result, showing that the \"distinctive\" features of \"P. kochi\" were age-related, and using mathematical comparison to show that the two forms are different growth stages of the same species. An additional review of the specimens published in 2013 demonstrated that some of the supposed differences between \"P. kochi\" and \"P. antiquus\" were due to measurement errors, further supporting their synonymy.\nBy the 2010s, a large body of research had been developed based on the idea that \"P. kochi\" and \"P. scolopaciceps\" were early growth stages of \"P. antiquus\". However, in 2014, two scientists began publishing research that challenged this paradigm. Steven Vidovic and David Martill concluded that differences between specimens of \"P. kochi\", \"P. scolopaciceps\", and \"P. antiquus\", such as different lengths of neck vertebrae, thinner or thicker teeth, more rounded skulls, and how far the teeth extended back in the jaws, were significant enough to separate them into three distinct species. Vidovic and Martill also performed a phylogenetic analysis which treated all relevant specimens as distinct units, and found that the \"P. kochi\" type specimen did not form a natural group with that of \"P. antiquus\". They concluded that the genus \"Diopecephalus\" could be returned to use to distinguish \"\"P\". kochi\" from \"P. antiquus\". They named the new genus \"Aerodactylus\" for \"P. scolopaciceps\" as well. So, what Bennett considered early growth stages of one species, Vidovic and Martill considered representatives of new species.\nIn 2017, Bennett challenged this hypothesis, he claimed that while Vidovic and Martill had identified real differences between these three groups of specimens, they had not provided any rationale that the differences were enough to distinguish them as species, rather than just individual variation, growth changes, or simply due to crushing and distortion during the fossilization process. Bennett pointed in particular to the data used to distinguish \"Aerodactylus\", which was so different from the data for related species, it might be due to an unnatural assemblage of specimens. As a result, Bennett continued to consider \"Diopecephalus\" and \"Aerodactylus\" simply as year-classes of immature \"Pterodactylus antiquus\".\nList of species.\nDuring its over-200-year history, the various species of \"Pterodactylus\" have gone through a number of changes in classification and thus have acquired a large number of synonyms. Additionally, a number of species assigned to \"Pterodactylus\" are based on poor remains that have proven difficult to assign to one species or another and are therefore considered (lit.\u2009'doubtful names'). The following list includes names that were used to identify new pterosaur species that now have been reclassified, or until recently thought to be pertaining to \"Pterodactylus\" proper, and names based on other material that has as yet not been assigned to other genera. This list also includes species that are ('naked names'), which are species that were not published formally. Species that are ('forgotten names') are the ones that have been disused, and species that are ('rejected names') are the ones that have been rejected because a more preferable name had been accepted instead.\nCultural significance.\n\"Pterodactylus\" is regarded as one of the most iconic prehistoric creatures, with multiple appearances in books, movies, as well as television series and several videogames. The informal name \"pterodactyl\" is sometimes used to refer to any kind of animal belonging to the order Pterosauria, though most of the time to \"Pterodactylus\" itself and the distantly-related \"Pteranodon\", the most well-known members of the group. The popular aspect of \"Pterodactylus\" consists of an elongated head crest, and potentially large wings. Studies of \"Pterodactylus\", however, conclude that it may even lack a bony cranial crest, though several analysis have proven that \"Pterodactylus\" may in fact have a crest made up of soft tissue instead of bone.\nAnother appearance of \"Pterodactylus\"-like creatures is in J. R. R. Tolkien's Middle-earth legendarium. In this novel, the Nazg\u00fbl, introduced as the Black Riders, are nine characters who rode flying monsters that looked similarly built to \"Pterodactylus\". Christopher Tolkien, the son of the author, described the flying monsters as \"Nazg\u00fbl-birds\"; his father described the appearance of the steeds as somewhat \"pterodactylic\", and acknowledged that these were obviously \"new mythology\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24824", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=24824", "title": "Pterosaur", "text": "Flying reptiles of the extinct clade or order Pterosauria\nPterosaurs are an extinct clade of flying reptiles in the order Pterosauria. They existed during most of the Mesozoic: from the Late Triassic to the end of the Cretaceous (228\u00a0million to 66\u00a0million years ago). Pterosaurs are the earliest vertebrates known to have evolved powered flight. Their wings were formed by a membrane of skin, muscle, and other tissues stretching from the ankles to a dramatically lengthened fourth finger.\nTraditionally, pterosaurs were divided into two major types. Basal pterosaurs (also called non-pterodactyloid pterosaurs or 'rhamphorhynchoids') were smaller animals, up to two meter wingspan, with fully toothed jaws and, typically, long tails. Their wide wing membranes probably included and connected the hindlimbs. On the ground, they would have had an awkward sprawling posture due to short metacarpals, but the anatomy of their joints and strong claws would have made them effective climbers, and some may have lived in trees. Basal pterosaurs were insectivores, piscivores or predators of small land vertebrates. Later pterosaurs (pterodactyloids) evolved many sizes, shapes, and lifestyles. Pterodactyloids had narrower wings with free hindlimbs, highly reduced tails, and long necks with large heads. On the ground, they walked well on all four limbs due to long metacarpals with an upright posture, standing plantigrade on the hind feet and folding the wing finger upward to walk on the metacarpals with the three smaller fingers of the hand pointing to the rear. They could take off from the ground, and fossil trackways show that at least some species were able to run, wade, and/or swim. Their jaws had horny beaks, and some groups lacked teeth. Some groups developed elaborate head crests with sexual dimorphism. Since 2010 it is understood that many species, the basal Monofenestrata, were intermediate in build, combining an advanced long skull with long tails.\nPterosaurs sported coats of hair-like filaments known as pycnofibers, which covered their bodies and parts of their wings. Pycnofibers grew in several forms, from simple filaments to branching down feathers. These may be homologous to the down feathers found on both avian and some non-avian dinosaurs, suggesting that early feathers evolved in the common ancestor of pterosaurs and dinosaurs, possibly as insulation. They were warm-blooded (endothermic), active animals. The respiratory system had efficient unidirectional \"flow-through\" breathing using air sacs, which hollowed out their bones to an extreme extent. Pterosaurs spanned a wide range of adult sizes, from the very small anurognathids to the largest known flying creatures, including \"Quetzalcoatlus\" and \"Hatzegopteryx\", which reached wingspans of at least nine metres. The combination of endothermy, a good oxygen supply and strong muscles made pterosaurs powerful and capable flyers.\nPterosaurs are often referred to by popular media or the general public as \"flying dinosaurs\", but dinosaurs are defined as the descendants of the last common ancestor of the Saurischia and Ornithischia, which excludes the pterosaurs. Pterosaurs are nonetheless more closely related to birds and other dinosaurs than to crocodiles or any other living reptile, though they are not bird ancestors. Pterosaurs are also colloquially referred to as pterodactyls, particularly in fiction and journalism. However, technically, \"pterodactyl\" may refer to members of the genus \"Pterodactylus\", and more broadly to members of the suborder Pterodactyloidea of the pterosaurs.\nPterosaurs had a variety of lifestyles. Traditionally seen as fish-eaters, the group is now understood to have also included hunters of land animals, insectivores, fruit eaters and even predators of other pterosaurs. They reproduced by eggs, some fossils of which have been discovered.\nAnatomy.\nThe anatomy of pterosaurs was highly modified from their reptilian ancestors by the adaptation to flight. Pterosaur bones were hollow and air-filled, like those of birds. This provided a higher muscle attachment surface for a given skeletal weight. The bone walls were often paper-thin. They had a large and keeled breastbone for flight muscles and an enlarged brain able to coordinate complex flying behaviour. Pterosaur skeletons often show considerable fusion. In the skull, the sutures between elements disappeared. In some later pterosaurs, the backbone over the shoulders fused into a structure known as a notarium, which served to stiffen the torso during flight, and provide a stable support for the shoulder blade. Likewise, the sacral vertebrae could form a single synsacrum while the pelvic bones fused also.\nSize.\nPterosaurs were highly diverse in size, and some were the largest flying organisms in earth's history. Early pterosaurs of the Triassic and Jurassic periods were typically small animals with wingspans only up to , while most Cretaceous pterosaurs were larger. Some isolated specimens indicate exceptions to this rule, and the divisions of size across time may be a partial result of an incomplete fossil record. Anurognathids may have been the smallest pterosaurs, with wingspans of as small as , though the age of these individuals remains uncertain. The largest pterosaurs were members of Azhdarchidae such as \"Hatzegopteryx\" and \"Quetzalcoatlus\", which could attain estimated wingspans of and weights of .\nSkull.\nPterosaurs have large skulls compared to other flying vertebrates, the birds and bats. Later pterosaurs had very elongated skulls, sometimes longer than the whole torso. Many bones were fused in adults. The skulls were pierced by multiple large holes: the bony nostrils, eye sockets, the antorbital fenestrae in the snout side and two temporal fenestrae on each rear side. Monofenestratan pterosaurs fused the nasal and antorbital fenestra into a single large nasantorbital fenestra. The back of the head was at first vertical in orientation, but rotated to nearly horizontal later in evolution of some groups. The paired lower jaws were fused at the front into an elongated mandibular symphysis. The lower jaws of the earliest pterosaurs were pierced at the rear by a mandibular fenestra, but this was lost in later species.\nThe snout or the back of the skull often sported an upward projecting crest, sometimes of enormous size. The lower jaws could likewise feature a downward projecting keel. These crests could be expanded in size and shape with soft tissues. Some crests entirely lacked a bone core, with their presence only known from exceptionally well preserved specimens.\nEarly pterosaurs were heterodont, with multiple tooth types. Later pterosaurs were homodont, having a single tooth form, often elongated and conical, throughout the skull. The teeth were replaced continuously throughout life. Between species, the dentition varied considerably. Fish eaters often had longer teeth in an expansion of the jaw tips. Filter feeders could have a sieve of up to a thousand teeth. Some later pterosaur groups were entirely toothless, featuring a horny beak similar to that of birds. Most species had some keratinized beak tissue, though never in the same snout section as the teeth.\nNeck and torso.\nThe vertebral column of pterosaurs had up to seventy vertebrae. Later pterosaurs have unique structures at the sides of the vertebrae, called exapophyses, and the concave fronts may possess a midline prong, the hypapophysis. Pterosaur necks were typically long, deep, and straight, and in pterodactyloids was longer than the torso. The number of neck vertebrae is always seven, or nine if one includes two trunk vertebrae. Pterodactyloids have lost all neck ribs. The neck was deep and well-muscled.\nThe torso was short and compact. Up to seven front back vertebrae and ribs can be fused into a rigid structure known as a notarium. \nThe shoulder girdle was strong and well-muscled, with the upper shoulder blade and connected lower coracoid fused in later species into a single scapulocoracoid. The top of this structure fitted to the notarium, while the lower end connected to the breastbone, forming a rigid closed loop, better to withstand the forces of flapping flight. The shoulder joint was saddle-shaped allowing considerable movement to the wing. It faced obliquely sideways and upwards. \nThe breastbone was wide with a shallow keel, via sternal ribs attached to the dorsal ribs. Behind it, belly ribs (gastralia) covered the entire belly. To the front, a long pointy structure termed the cristospina jutted obliquely upwards. The thorax was deepest at the rear of the breastbone. There were no (inter)clavicles.\nThe pelvis of pterosaurs was of moderate size compared to the body as a whole. Often the three pelvic bones were fused. The sacrum had up to ten sacral vertebrae, sometimes connected by a bar in a similar fashion to the notarium. The ilium was long and low, its front and rear blades projecting horizontally beyond the edges of the lower pelvic bones. Despite this length, the rod-like form of these processes indicates that the hindlimb muscles attached to them were limited in strength. Then, in side view narrow, pubic bone fused with the broad ischium into an ischiopubic blade. Sometimes, the blades of both sides were also fused, closing the pelvis from below and forming the pelvic canal. The hip joint was not perforated and allowed considerable mobility to the leg. It was directed obliquely upwards, preventing a perfectly vertical position of the leg. The front of the pubic bones articulated with a unique structure, the paired prepubic bones. Together these formed a cusp covering the rear belly, between the pelvis and the belly ribs. The vertical mobility of this element suggests a function in breathing, compensating the relative rigidity of the chest cavity.\nWings.\nWing membranes.\nThe primary wing membranes attached to the extremely long fourth fingers, probably extending to the ankles. The profile of the trailing edge is uncertain. The membranes were not leathery flaps composed of skin but highly complex dynamic structures suited to serve an active flight style. They were strengthened by closely spaced fibers called \"actinofibrils\", in three distinct layers in the wing, in a crisscross pattern superimposed on one another. They had a stiffening or strengthening function. Also a thin layer of muscle, fibrous tissue, and a unique, complex circulatory system of looping blood vessels was present. This combination may have allowed the animal to adjust the wing slackness and camber to control lift.\nThe wing membrane is divided into three parts. The \"propatagium\" (\"fore membrane\"), was the forward-most part of the wing and attached between the wrist and shoulder, creating the \"leading edge\" during flight. The \"brachiopatagium\" (\"arm membrane\") stretched from the fourth finger to the hindlimb. Finally, a membrane that stretched between the legs, possibly incorporated the tail, called the uropatagium. It might only have connected the legs, rendering it a cruropatagium. Early pterosaurs perhaps had a broader uro/cruropatagium stretching between their long fifth toes; pterodactyloids, lacking such toes, only had membranes running along the legs. Fossils of the rhamphorhynchoid \"Sordes\", the anurognathid \"Jeholopterus\", suggest that the wing membrane did attach to the hindlimbs. However, pterosaur limb proportions show that there was considerable variation in wing-plans.\nWing bones.\nThe arm bones supported and extended the wing. The humerus or upper arm bone is short but powerful. It has a large deltopectoral crest, to which the major flight muscles are attached. The humerus is hollow or pneumatised inside, reinforced by bone struts. The long bones of the lower arm, the ulna and radius, are much longer than the humerus. A bone unique to pterosaurs, the pteroid, supported the propatagium between the wrist and shoulder. The pterosaur wrist consists of two inner and four outer carpals. Two inner and three outer carpals are fused together into \"syncarpals\". The remaining outer carpal bears a deep concave fovea within which the pteroid articulates, according to Wilkinson.\nIn derived pterodactyloids metacarpals I-III are small and do not connect to the carpus, instead hanging in contact with the fourth metacarpal. In that case the fourth metacarpal has been enormously elongated, typically equalling or exceeding the length of the long bones of the lower arm. The fifth metacarpal had been lost. The first to third fingers are much smaller than the fourth, the \"wingfinger\", and contain two, three and four phalanges respectively. The smaller fingers are clawed. The wingfinger accounts for about half or more of the total wing length. It normally consists of four phalanges. Their relative lengths vary among species, allowing to distinguish related forms. The fourth phalanx is usually the shortest. It lacks a claw and has been lost completely by nyctosaurids. It is curved to behind, resulting in a rounded wing tip, which reduces induced drag. The wingfinger is also bent somewhat downwards. Standing, pterosaurs rested on their metacarpals, with the outer wing folded to behind. The \"anterior\" sides of the metacarpals were then rotated to the rear. This would point the smaller fingers obliquely to behind. According to Bennett, this would imply that the wingfinger, able to describe the largest arc of any wing element, up to 175\u00b0, was not folded by flexion but by an extreme extension. The wing was automatically folded when the elbow was bowed.\nHindlimbs.\nThe hindlimbs of pterosaurs were strongly built, yet relative to their wingspans smaller than those of birds. They were long in comparison to the torso length. The thighbone was rather straight, with the head making only a small angle with the shaft. This implies that the legs were not held vertically below the body but were somewhat sprawling. The shinbone was often fused with the upper ankle bones into a tibiotarsus that was longer than the thighbone. It could attain a vertical position when walking. The calf bone tended to be slender, especially at its lower end that in advanced forms did not reach the ankle, sometimes reducing total length to a third. Typically, it was fused to the shinbone. The ankle was a simple, \"mesotarsal\", hinge. The, rather long and slender, metatarsus was always splayed to some degree. The foot was plantigrade, meaning that during the walking cycle the sole of the metatarsus was pressed onto the soil.\nThe first to fourth toes were long. They had two, three, four and five phalanges respectively. Often the third toe was longest; sometimes the fourth. Flat joints indicate a limited mobility. These toes were clawed but the claws were smaller than the hand claws. There was a clear difference between early pterosaurs and advanced species regarding the form of the fifth digit. Originally, the fifth metatarsal was robust and not very shortened. It was connected to the ankle in a higher position than the other metatarsals. It bore a long, and often curved, mobile clawless fifth toe consisting of two phalanges. It's thought that these toes support the uropatagium (or cruropatagium). As the fifth toes were on the outside of the feet, such a configuration would only have been possible if these rotated their fronts outwards in flight. Such a rotation could be caused by an abduction of the thighbone, meaning that the legs would be spread. This would also turn the feet into a vertical position. In more advanced pterosaurs, the fifth metatarsal was much reduced and the fifth toe, if present, little more than a stub.\nTail.\nThe tail, a continuation of the vertebral column, was slender, incapable of powering the hindlimb. Early species had long tails of up to fifty vertebrae, stiffened by elongated zygapophyses and chevrons. They acted as rudders, ending at the rear in a vertical vane. In pterodactyloids, the tails were short and flexible, with as few as ten vertebrae.\nPycnofibers.\nAll pterosaurs had hair-like filaments known as pycnofibers on the head and torso. Pycnofibres were unique structures similar to mammalian hair, an example of convergent evolution, and pterosaur pelts might have been comparable in density those of mammals Skin patches show small round non-overlapping scales on the soles of the hands and feet, but these were absent from the rest of the body. The pycnofibers show that pterosaurs were warm-blooded, providing insulation to prevent heat-loss.\nRemains of two small Jurassic-age pterosaurs from Inner Mongolia, China, demonstrated that some pterosaurs had a wide array of pycnofiber shapes and structures, as opposed to the homogeneous structures that had previously documented. Some of these had frayed ends, very similar in structure to certain feather types known from birds or other dinosaurs. A well preserved fossil of \"Tupandactylus\" was found to have pigment cells with similar forms to those seen in modern birds, more complex in organization than those previously known from other pterosaurs. This specimen also suggest the presence of Stage IIIa feathers, further indication of more complex filament structures in pterosaurs. Supporting a model of common ancestry with the filaments of birds, the authors termed these structures as pterosaur feathers rather than pycnofibres. This common origin had been suggested before, but remains controversial.\nHistory of discovery.\nFirst finds.\nPterosaur fossils are very rare, due to their light bone construction. Complete skeletons can generally only be found in geological layers with exceptional preservation conditions, the so-called \"Lagerst\u00e4tten\". The pieces from one such \"Lagerst\u00e4tte\", the Late Jurassic Solnhofen Limestone in Bavaria, became much sought after by rich collectors. In 1784, Italian naturalist Cosimo Alessandro Collini was the first scientist to describe a pterosaur fossil. At that time the concepts of evolution and extinction were imperfectly developed. The bizarre build of the pterosaur was shocking, as it could not clearly be assigned to any existing animal group. The discovery of pterosaurs would thus play an important role in the progress of modern paleontology and geology. Scientific opinion at the time was that if such creatures were still alive, only the sea was a credible habitat; Collini suggested it might be a swimming animal that used its long front limbs as paddles. A few scientists continued to support the aquatic interpretation even until 1830, when German zoologist Johann Georg Wagler suggested that \"Pterodactylus\" used its wings as flippers and was affiliated with Ichthyosauria and Plesiosauria.\nIn 1800, Johann Hermann first suggested that it represented a flying creature in a letter to Georges Cuvier. Cuvier agreed in 1801, understanding it was an extinct flying reptile. In 1809, he coined the name \"Pt\u00e9ro-Dactyle\", \"wing-finger\". This was in 1815 Latinised to \"Pterodactylus\". At first most species were assigned to this genus and ultimately \"pterodactyl\" was popularly and incorrectly applied to all members of Pterosauria. Today, paleontologists limit the term to the genus \"Pterodactylus\" or members of the Pterodactyloidea.\nIn 1812 and 1817, Samuel Thomas von Soemmerring redescribed the original specimen and an additional one. He saw them as affiliated to birds and bats. Although he was mistaken in this, his \"bat model\" would be influential during the 19th century. In 1843, Edward Newman thought pterosaurs were flying marsupials. Ironically, as the \"bat model\" depicted pterosaurs as warm-blooded and furred, it would turn out to be more correct in certain aspects than Cuvier's \"reptile model\" in the long run. In 1834, Johann Jakob Kaup named an order \"Pterosaurii\" to contain the \"Pterodactylii\" (\"Pterodactylus)\" and suggested it probably consisted of several genera. Kaup has often been mentioned as the author of the name Pterosauria. The first to actually use the spelling Pteroauria was in 1841/1842 Richard Owen, referring \"Pterodactylus cuvieri\" (\"Cimoliopterus\"), \"Pterodactylus giganteus\" (\"Lonchodraco\"), \"Pterodactylus compressirostris\" (\"Lonchodectes\") and \"Pterodactylus micronyx\" (\"Dimorphodon)\" to the order. Brian Andres and Timothy Myers have pointed out that Owen's description of Pterosauria as \"reptiles that achieved flight by modification of their pectoral extremity\" would be useful as a modern apomorphy-based clade definition.\nExpanding research.\nIn 1828, Mary Anning found in England the first pterosaur genus outside Germany, named as \"Dimorphodon\" by Richard Owen, also the first non-pterodactyloid pterosaur known. Later in the century, the Early Cretaceous Cambridge Greensand produced thousands of pterosaur fossils, that however, were of poor quality, consisting mostly of strongly eroded fragments. Nevertheless, based on these, numerous genera and species would be named. Many were described by Harry Govier Seeley, at the time the main English expert on the subject, who also wrote the first pterosaur book, \"Ornithosauria\", and in 1901 the first popular book, \"Dragons of the Air\". Seeley thought that pterosaurs were warm-blooded and dynamic creatures, closely related to birds. Earlier, the evolutionist St. George Jackson Mivart had suggested pterosaurs were the direct ancestors of birds. Owen opposed the views of both men, seeing pterosaurs as cold-blooded \"true\" reptiles.\nIn the US, Othniel Charles Marsh in 1870 discovered \"Pteranodon\" in the Niobrara Chalk, then the largest known pterosaur, the first toothless one and the first from America. These layers too rendered thousands of fossils, also including relatively complete skeletons that were three-dimensionally preserved instead of being strongly compressed as with the Solnhofen specimens. This led to a much better understanding of many anatomical details, such as the hollow nature of the bones.\nMeanwhile, finds from the Solnhofen had continued, accounting for the majority of complete high-quality specimens discovered. They allowed to identify most new basal taxa, such as \"Rhamphorhynchus\", \"Scaphognathus\" and \"Dorygnathus\". This material gave birth to a German school of pterosaur research, which saw flying reptiles as the warm-blooded, furry and active Mesozoic counterparts of modern bats and birds. In 1882, Marsh and Karl Alfred Zittel published studies about the wing membranes of specimens of \"Rhamphorhynchus\". German studies continued well into the 1930s, describing new species such as \"Anurognathus\". In 1927, Ferdinand Broili discovered hair follicles in pterosaur skin, and paleoneurologist Tilly Edinger determined that the brains of pterosaurs more resembled those of birds than modern cold-blooded reptiles.\nIn contrast, English and American paleontologists by the middle of the twentieth century largely lost interest in pterosaurs. They saw them as failed evolutionary experiments, cold-blooded and scaly, that hardly could fly, the larger species only able to glide, being forced to climb trees or throw themselves from cliffs to achieve a take-off. In 1914, for the first-time pterosaur aerodynamics were quantitatively analysed, by Ernest Hanbury Hankin and David Meredith Seares Watson, but they interpreted \"Pteranodon\" as a pure glider. Little research was done on the group during the 1940s and 1950s.\nPterosaur renaissance.\nThe situation for dinosaurs was comparable. From the 1960s onwards, a dinosaur renaissance took place, a quick increase in the number of studies and critical ideas, influenced by the discovery of additional fossils of \"Deinonychus\", whose spectacular traits refuted what had become entrenched orthodoxy. In 1970, likewise the description of the furry pterosaur \"Sordes\" began what Robert Bakker named a renaissance of pterosaurs. Kevin Padian especially propagated the new views, publishing a series of studies depicting pterosaurs as warm-blooded, active and running animals. This coincided with a revival of the German school through the work of Peter Wellnhofer, who in 1970s laid the foundations of modern pterosaur science. In 1978, he published the first pterosaur textbook, the \"Handbuch der Pal\u00e4oherptologie, Teil 19: Pterosauria\", and in 1991 the second ever popular science pterosaur book, the \"Encyclopedia of Pterosaurs\".\nThis development accelerated through the exploitation of two new \"Lagerst\u00e4tten\". During the 1970s, the Early Cretaceous Santana Formation in Brazil began to produce chalk nodules that, though often limited in size and the completeness of the fossils they contained, perfectly preserved three-dimensional pterosaur skeletal parts. German and Dutch institutes bought such nodules from fossil poachers and prepared them in Europe, allowing their scientists to describe many new species and revealing a whole new fauna. Soon, Brazilian researchers, among them Alexander Kellner, intercepted the trade and named even more species.\nEven more productive was the Early Cretaceous Chinese Jehol Biota of Liaoning that since the 1990s has brought forth hundreds of exquisitely preserved two-dimensional fossils, often showing soft tissue remains. Chinese researchers such as L\u00fc Junchang have again named many new taxa. As discoveries also increased in other parts of the world, a sudden surge in the total of named genera took place. By 2009, when they had increased to about ninety, this growth showed no sign of levelling-off. In 2013, M.P. Witton indicated that the number of discovered pterosaur species had risen to 130. Over ninety percent of known taxa has been named during the \"renaissance\". Many of these were from groups the existence of which had been unknown. Advances in computing power enabled researchers to determine their complex relationships through the quantitative method of cladistics. New and old fossils yielded much more information when subjected to modern ultraviolet light or roentgen photography, or CAT-scans. Insights from other fields of biology were applied to the data obtained. All this resulted in a substantial progress in pterosaur research, rendering older accounts in popular science books completely outdated.\nIn 2017 a fossil from a 170-million-year-old pterosaur, later named as the species \"Dearc sgiathanach\" in 2022, was discovered on the Isle of Skye in Scotland. The National Museum of Scotland claims that it is the largest of its kind ever discovered from the Jurassic period, and it has been described as the world's best-preserved skeleton of a pterosaur.\nEvolution and extinction.\nOrigins.\nBecause pterosaur anatomy has been so heavily modified for flight, and immediate transitional fossil predecessors have not so far been described, the ancestry of pterosaurs is not fully understood. The oldest known pterosaurs were already fully adapted to a flying lifestyle. Since Seeley, it was recognised that pterosaurs were likely to have had their origin in the \"archosaurs\", what today would be called the Archosauromorpha. In the 1980s, early cladistic analyses found that they were Avemetatarsalians (archosaurs closer to dinosaurs than to crocodilians). As this would make them also rather close relatives of the dinosaurs, these results were seen by Kevin Padian as confirming his interpretation of pterosaurs as bipedal warm-blooded animals. Because these early analyses were based on a limited number of taxa and characters, their results were inherently uncertain.\nSeveral influential researchers who rejected Padian's conclusions offered alternative hypotheses. David Unwin proposed an ancestry among the basal Archosauromorpha, specifically long-necked forms (\"protorosaurs\") such as tanystropheids. A placement among basal archosauriforms like \"Euparkeria\" was also suggested. Basal archosauromorps such as these seemed to be good candidates for close pterosaur relatives due to their long-limbed anatomy; especially notable is \"Sharovipteryx\", which possessed skin membranes on its hindlimbs likely used for gliding. A 1999 study by Michael Benton reinforced that pterosaurs were avemetatarsalians closely related to \"Scleromochlus,\" and named the group Ornithodira to encompass pterosaurs and dinosaurs\".\" In 1996, research S. Christopher Bennett published an analysis finding pterosaurs to be protorosaurs or closely related to them after removing characteristics of the hindlimb from his analysis, to test the possibility of locomotion-based convergent evolution between pterosaurs and dinosaurs. A 2007 reply by Dave Hone and Michael Benton could not reproduce this result, finding pterosaurs to be closely related to dinosaurs even without hindlimb characters. They concluded that, although more basal pterosauromorphs are needed to clarify their relationships, current evidence indicates that pterosaurs are avemetatarsalians, as either the sister group of \"Scleromochlus\" or a branch between the latter and \"Lagosuchus\". \nA 2011 archosaur-focused phylogenetic analysis by Sterling Nesbitt benefited from far more data and found strong support for pterosaurs being avemetatarsalians, though \"Scleromochlus\" was not included due to its poor preservation. A 2016 archosauromorph-focused study by Martin Ezcurra included various proposed pterosaur relatives, yet also found pterosaurs to be closer to dinosaurs and unrelated to more basal taxa. Working from his 1996 analysis, Bennett published a 2020 study on \"Scleromochlus\" which argued that both \"Scleromochlus\" and pterosaurs were non-archosaur archosauromorphs, albeit not particularly closely related to each other. By contrast, a later 2020 study proposed that lagerpetid archosaurs were the sister clade to pterosauria. This was based on newly described fossil skulls and forelimbs showing various anatomical similarities with pterosaurs and reconstructions of lagerpetid brains and sensory systems based on CT scans also showing neuroanatomical similarities with pterosaurs. The results of the latter study were subsequently supported by an independent analysis of early pterosauromorph interrelationships.\nA related problem is the origin of pterosaur flight. Like with birds, hypotheses can be ordered into two main varieties: \"ground up\" or \"tree down\". Climbing a tree would cause height and gravity to provide both the energy and a strong selection pressure for incipient flight, as a fall could kill a climbing animal. Rupert Wild in 1983 proposed a hypothetical \"propterosaurus\": a lizard-like arboreal animal developing a membrane between its limbs, first to safely parachute and then, gradually elongating the fourth finger, to glide. However, subsequent cladistic results did not fit this model well. Neither protorosaurs nor ornithodirans are biologically equivalent to lizards. Furthermore, the transition between gliding and flapping flight is not well-understood. More recent studies on basal pterosaur hindlimb morphology seem to vindicate a connection to \"Scleromochlus\". Like this archosaur, basal pterosaur lineages have plantigrade hindlimbs that show adaptations for saltation.\nAt least one study found that the early Triassic ichnofossil \"Prorotodactylus\" is anatomically similar to that of early pterosaurs.\nExtinction.\nIt was once assumed that competition with early bird species resulted in the extinction of many of the pterosaurs. It was thought that by the end of the Cretaceous, only very large species of pterosaurs were present. The smaller species were presumed to have become extinct, their niche filled by birds. However, pterosaur decline (if actually occurring) seems unrelated to bird diversity, as ecological overlap between the two groups appears to be minimal. In fact, at least some avian niches were reclaimed by pterosaurs prior to the Cretaceous\u2013Paleogene extinction event. It seems that this K-Pg extinction event at the end of the Cretaceous, which wiped out all non-avian dinosaurs and many other animals, was the direct cause of the extinction of the pterosaurs.\nSmall-sized pterosaur species apparently were present in the Csehb\u00e1nya Formation, indicating a higher diversity of Late Cretaceous pterosaurs than previously accounted for. The recent findings of a small cat-sized adult azhdarchid further indicate that small pterosaurs from the Late Cretaceous might actually have simply been rarely preserved in the fossil record, helped by the fact that there is a strong bias against terrestrial small sized vertebrates such as juvenile dinosaurs, and that their diversity might actually have been much larger than previously thought.\nA 2021 study showcases that niches previously occupied by small pterosaurs were increasingly occupied by the juvenile stages of larger species in the Late Cretaceous. Rather than being outcompeted by birds, pterosaurs essentially specialized a trend already occurring in previous eras of the Mesozoic.\nClassification and phylogeny.\nIn phylogenetic taxonomy, the clade Pterosauria has usually been defined as node-based and anchored to several extensively studied taxa as well as those thought to be primitive. One 2003 study defined Pterosauria as \"The most recent common ancestor of the Anurognathidae, \"Preondactylus\" and \"Quetzalcoatlus\" and all their descendants.\" However, these types of definition would inevitably leave any related species that are slightly more primitive out of the Pterosauria. To remedy this, a new definition was proposed that would anchor the name not to any particular species but to an anatomical feature, the presence of an enlarged fourth finger that supports a wing membrane. This apomorphy-based definition was adopted by the PhyloCode in 2020 as \"[T]he clade characterized by the apomorphy fourth manual digit hypertrophied to support a wing membrane, as inherited by \"Pterodactylus\" (originally \"Ornithocephalus\") \"antiquus\" (S\u00f6mmerring 1812)\". A broader clade, Pterosauromorpha, has been defined as all ornithodirans more closely related to pterosaurs than to dinosaurs.\nThe internal classification of pterosaurs has historically been difficult, because there were many gaps in the fossil record. Starting from the 21st century, new discoveries are now filling in these gaps and giving a better picture of the evolution of pterosaurs. Traditionally, they were organized into two suborders: the Rhamphorhynchoidea, a \"primitive\" group of long-tailed pterosaurs, and the Pterodactyloidea, \"advanced\" pterosaurs with short tails. However, this traditional division has been largely abandoned. Rhamphorhynchoidea is a paraphyletic (unnatural) group, since the pterodactyloids evolved directly from them and not from a common ancestor, so, with the increasing use of cladistics, it has fallen out of favor among most scientists.\nWithin pterosaurs, several smaller clades have been named. The clade Novialoidea was named by paleontologist Alexander Wilhelm Armin Kellner in 2003 as a node-based taxon consisting of the last common ancestor of \"Campylognathoides\", \"Quetzalcoatlus\" and all its descendants. This name was derived from Latin \"novus\" \"new\", and \"ala\", \"wing\", in reference to the wing synapomorphies that the members of the clade possess.\nPaleontologist David Unwin in 2003 had named the group Lonchognatha in the same issue of the journal that published Novialoidea (Geological Society of London, Special Publications 217) and defined it as \"Eudimorphodon ranzii\", \"Rhamphorhynchus muensteri\", their most recent common ancestor and all its descendants (as a node-based taxon). Under Unwin's and Kellner's phylogenetic analyses (where \"Eudimorphodon\" and \"Campylognathoides\" form a group that is basal to both \"Rhamphorhynchus\" and \"Quetzalcoatlus\"), Novialoidea is materially identical to Lonchognatha. However, other analyses find Lonchognatha to be a separate concept (Andres \"et al.\", 2010), or synonymous with the Pterosauria (Andres, 2010).\nThe precise relationships between pterosaurs is still unsettled. Many studies of pterosaur relationships in the past have included limited data and were highly contradictory. However, newer studies using larger data sets are beginning to make things clearer. The cladogram (family tree) below follows a phylogenetic analysis presented by Longrich, Martill and Andres in 2018, with clade names after Andres \"et al.\" (2014).\nThe position of the clade Anurognathidae (\"Anurognathus, Jeholopterus, Vesperopterylus\") is debated. Anurognathids were highly specialized, small flyers with shortened jaws and a wide gape. Some had large eyes suggesting nocturnal or crepuscular habits, mouth bristles, and feet adapted for clinging. Parallel adaptations are seen in birds and bats that prey on insects in flight.\nPaleobiology.\nFlight.\nThe mechanics of pterosaur flight are not completely understood or modeled at this time.\nKatsufumi Sato, a Japanese scientist, did calculations using modern birds and concluded that it was impossible for a pterosaur to stay aloft. In the book \"Posture, Locomotion, and Paleoecology of Pterosaurs\" it is theorized that they were able to fly due to the oxygen-rich, dense atmosphere of the Late Cretaceous period. However, both Sato and the authors of \"Posture, Locomotion, and Paleoecology of Pterosaurs\" based their research on the now-outdated theories of pterosaurs being seabird-like, and the size limit does not apply to terrestrial pterosaurs, such as azhdarchids and tapejarids. Furthermore, Darren Naish concluded that atmospheric differences between the present and the Mesozoic were not needed for the giant size of pterosaurs.\nAnother issue that has been difficult to understand is how they took off. Earlier suggestions were that pterosaurs were largely cold-blooded gliding animals, deriving warmth from the environment like modern lizards, rather than burning calories. In this case, it was unclear how the larger ones of enormous size, with an inefficient cold-blooded metabolism, could manage a bird-like takeoff strategy, using only the hind limbs to generate thrust for getting airborne. Later research shows them instead as being warm-blooded and having powerful flight muscles, and using the flight muscles for walking as quadrupeds. Mark Witton of the University of Portsmouth and Mike Habib of Johns Hopkins University suggested that pterosaurs used a vaulting mechanism to obtain flight. The tremendous power of their winged forelimbs would enable them to take off with ease. Once aloft, pterosaurs could reach speeds of up to and travel thousands of kilometres.\nIn 1985, the Smithsonian Institution commissioned aeronautical engineer Paul MacCready to build a half-scale working model of \"Quetzalcoatlus northropi\". The replica was launched with a ground-based winch. It flew several times in 1986 and was filmed as part of the Smithsonian's IMAX film \"On the Wing\".\nLarge-headed species are thought to have forwardly swept their wings in order to better balance.\nAir sacs and respiration.\nA 2009 study showed that pterosaurs had a lung-and-air-sac system and a precisely controlled skeletal breathing pump, which supports a flow-through pulmonary ventilation model in pterosaurs, analogous to that of birds. The presence of a subcutaneous air sac system in at least some pterodactyloids would have further reduced the density of the living animal. Like modern crocodilians, pterosaurs appeared to have had a hepatic piston, seeing as their shoulder-pectoral girdles were too inflexible to move the sternum as in birds, and they possessed strong gastralia. Thus, their respiratory system had characteristics comparable to both modern archosaur clades.\nNervous system.\nAn X-ray study of pterosaur brain cavities revealed that the animals (\"Rhamphorhynchus muensteri\" and \"Anhanguera santanae\") had massive flocculi. The flocculus is a brain region that integrates signals from joints, muscles, skin and balance organs. The pterosaurs' flocculi occupied 7.5% of the animals' total brain mass, more than in any other vertebrate. Birds have unusually large flocculi compared with other animals, but these only occupy between 1 and 2% of total brain mass.\nThe flocculus sends out neural signals that produce small, automatic movements in the eye muscles. These keep the image on an animal's retina steady. Pterosaurs may have had such a large flocculus because of their large wing size, which would mean that there was a great deal more sensory information to process. The low relative mass of the flocculi in birds is also a result of birds having a much larger brain overall; though this has been considered an indication that pterosaurs lived in a structurally simpler environment or had less complex behaviour compared to birds, recent studies of crocodilians and other reptiles show that it is common for sauropsids to achieve high intelligence levels with small brains. Studies on the endocast of \"Allkaruen\" show that brain evolution in pterodactyloids was a modular process.\nTerrestrial locomotion.\nPterosaurs' hip sockets are oriented facing slightly upwards, and the head of the femur (thigh bone) is only moderately inward facing, suggesting that pterosaurs had an erect stance. It would have been possible to lift the thigh into a horizontal position during flight, as gliding lizards do.\nThere was considerable debate whether pterosaurs ambulated as quadrupeds or as bipeds. In the 1980s, paleontologist Kevin Padian suggested that smaller pterosaurs with longer hindlimbs, such as \"Dimorphodon\", might have walked or even run bipedally, in addition to flying, like road runners. However, a large number of pterosaur trackways were later found with a distinctive four-toed hind foot and three-toed front foot; these are the unmistakable prints of pterosaurs walking on all fours.\nFossil footprints show that pterosaurs stood with the entire foot in contact with the ground (plantigrade), in a manner similar to many mammals like humans and bears. Footprints from azhdarchids and several unidentified species show that pterosaurs walked with an erect posture with their four limbs held almost vertically beneath the body, an energy-efficient stance used by most modern birds and mammals, rather than the sprawled limbs of modern reptiles. Indeed, erect-limbs may be omnipresent in pterosaurs.\nThough traditionally depicted as ungainly and awkward when on the ground, the anatomy of some pterosaurs (particularly pterodactyloids) suggests that they were competent walkers and runners. Early pterosaurs have long been considered particularly cumbersome locomotors due to the presence of large cruropatagia, but they too appear to have been generally efficient on the ground.\nThe forelimb bones of azhdarchids and ornithocheirids were unusually long compared to other pterosaurs, and, in azhdarchids, the bones of the arm and hand (metacarpals) were particularly elongated. Furthermore, as a whole, azhdarchid front limbs were proportioned similarly to fast-running ungulate mammals. Their hind limbs, on the other hand, were not built for speed, but they were long compared with most pterosaurs, and allowed for a long stride length. While azhdarchid pterosaurs probably could not run, they would have been relatively fast and energy efficient.\nThe relative size of the hands and feet in pterosaurs (by comparison with modern animals such as birds) may indicate the type of lifestyle pterosaurs led on the ground. Azhdarchid pterosaurs had relatively small feet compared to their body size and leg length, with foot length only about 25\u201330% the length of the lower leg. This suggests that azhdarchids were better adapted to walking on dry, relatively solid ground. \"Pteranodon\" had slightly larger feet (47% the length of the tibia), while filter-feeding pterosaurs like the ctenochasmatoids had very large feet (69% of tibial length in \"Pterodactylus\", 84% in \"Pterodaustro\"), adapted to walking in soft muddy soil, similar to modern wading birds. Though clearly forelimb-based launchers, basal pterosaurs have hindlimbs well adapted for hopping, suggesting a connection with archosaurs such as \"Scleromochlus\".\nSwimming.\nTracks made by ctenochasmatoids indicate that these pterosaurs swam using their hindlimbs. In general, these have large hindfeet and long torsos, indicating that they were probably more adapted for swimming than other pterosaurs. Pteranodontians conversely have several speciations in their humeri interpreted to have been suggestive of a water-based version of the typical quadrupedal launch, and several like boreopterids must have foraged while swimming, as they seem incapable of frigatebird-like aerial hawking. These adaptations are also seen in terrestrial pterosaurs like azhdarchids, which presumably still needed to launch from water in case they found themselves in it. The nyctosaurid \"Alcione\" may display adaptations for wing-propelled diving like modern gannets and tropicbirds.\nDiet and feeding habits.\nTraditionally, almost all pterosaurs were seen as surface-feeding piscivores or fish-eaters, a view that still dominates popular science. Today, many pterosaurs groups are thought to have been terrestrial carnivores, omnivores or insectivores.\nEarly-on it was recognised that the small Anurognathidae were nocturnal, aerial insectivores. With highly flexible joints on the wing finger, a broad, triangular wing shape, large eyes and short tail, these pterosaurs were likely analogous to nightjars or extant insectivorous bats, being capable of high manoeuvrability at relatively low speeds.\nInterpretations of the habits of basal groups have changed profoundly. \"Dimorphodon\", envisioned as a puffin analogue in the past, is indicated by its jaw structure, gait, and poor flight capabilities, as a terrestrial/semiarboreal predator of small mammals, squamates, and large insects. Its robust dentition caused \"Campylognathoides\" to be seen as a generalist or a terrestrial predator of small vertebrates, but the highly robust humerus and high-aspect wing morphology, suggest it may have been capable of grabbing prey on the wing; a later study indicates it was teuthophagous based on squid findings within its gut. The small insectivorous \"Carniadactylus\" and the larger \"Eudimorphodon\" were highly aerial animals and fast, agile flyers with long robust wings. \"Eudimorphodon\" has been found with fish remains in its stomach, but its dentition suggests an opportunistic diet. Slender-winged \"Austriadactylus\" and \"Caviramus\" were likely terrestrial/semiarboreal generalists. \"Caviramus\" likely had a strong bite force, indicating an adaptation towards hard food items that might have been chewed in view of the tooth wear.\nSome Rhamphorhynchidae, such as \"Rhamphorhynchus\" itself or \"Dorygnathus\", were fish-eaters with long, slender wings, needle-like dentition and long, thin jaws. \"Sericipterus\", \"Scaphognathus\" and \"Harpactognathus\" had more robust jaws and teeth (which were ziphodont, dagger-shaped, in \" Sericipterus\"), and shorter, broader wings. These were either terrestrial/aerial predators of vertebrates or corvid-like generalists. Wukongopteridae like \"Darwinopterus\" were first considered aerial predators. Lacking a robust jaw structure or powerful flying muscles, they are now seen as arboreal or semiterrestrial insectivores. \"Darwinopterus robustidens\", in particular, seems to have been a beetle specialist.\nAmong pterodactyloids, a greater variation in diet is present. Pteranodontia contained many piscivorous taxa, such as the Ornithocheirae, Boreopteridae, Pteranodontidae and Nyctosauridae. Niche partitioning caused ornithocheirans and the later nyctosaurids to be aerial dip-feeders like today's frigatebirds (with the exception of the plunge-diving adapted \"Alcione elainus\"), while boreopterids were freshwater diving animals similar to cormorants, and pteranodonts pelagic plunge-divers akin to boobies and gannets. An analysis of \"Lonchodraco\" found clusters of foramina at the tip of its beak; birds with similarly numerous foramina have sensitive beaks used to feel for food, so \"Lonchodraco\" may have used its beak to feel for fish or invertebrates in shallow water. The istiodactylids were likely primarily scavengers. Archaeopterodactyloidea obtained food in coastal or freshwater habitats. \"Germanodactylus\" and \"Pterodactylus\" were piscivores, while the Ctenochasmatidae were suspension feeders, using their numerous fine teeth to filter small organisms from shallow water. \"Pterodaustro\" was adapted for flamingo-like filter-feeding.\nIn contrast, Azhdarchoidea mostly were terrestrial pterosaurs. Tapejaridae were arboreal omnivores, likely supplementing seeds and fruits with small insects and vertebrates. Gut contents consisting of phytoliths from various plants in a specimen of the tapejarid \"Sinopterus\" constitute the first evidence of herbivory in a pterosaur. Dsungaripteridae were specialist molluscivores, using their powerful jaws to crush the shells of molluscs and crustaceans. Thalassodromidae were likely terrestrial carnivores. \"Thalassodromeus\" itself was named after a fishing method known as \"skim-feeding\", later understood to be biomechanically impossible. Perhaps it pursued relatively large prey, in view of its reinforced jaw joints and relatively high bite force. Azhdarchidae are now understood to be terrestrial predators akin to ground hornbills or some storks, eating any prey item they could swallow whole. \"Hatzegopteryx\" was a robustly built predator of relatively large prey, including medium-sized dinosaurs. \"Alanqa\" may have been a specialist molluscivore.\nA 2021 study reconstructed the adductor musculature of skulls from pterodactyloids, estimating the bite force and potential dietary habits of nine selected species. The study corroborated the view of pteranodontids, nyctosaurids and anhanuerids as piscivores based on them being relatively weak but fast biters, and suggest that \"Tropeognathus mesembrinus\" was specialised in consuming relatively large prey compared to \"Anhanguera\". \"Dsungaripterus\" was corroborated as a durophage, with \"Thalassodromeus\" proposed to share this feeding habit based on high estimated bite force quotients (BFQ) and absolute bite force values. \"Tapejara wellnhoferi\" was corroborated as a specialised consumer of hard plant material with a relatively high BFQ and high mechanical advantage, and \"Caupedactylus ybaka\" and \"Tupuxuara leonardii\" were proposed to be ground-feeding generalists with intermediate bite force values and less specialised jaws.\nNatural predators.\nPterosaurs are known to have been eaten by theropods. In the 1 July 2004 edition of \"Nature\", paleontologist \u00c9ric Buffetaut discusses an Early Cretaceous fossil of three cervical vertebrae of a pterosaur with the broken tooth of a spinosaur, most likely \"Irritator\", embedded in it. The vertebrae are known not to have been eaten and exposed to digestion, as the joints are still articulated. Fossils of \"Pteranodon\" have been found with tooth marks from sharks such as \"Squalicorax\", and a fossil with tooth marks from the \"Toolebuc formation\" has been interpreted as being attacked or scavenged by an ichthyosaur (most likely \"Platypterygius\").\nReproduction and life history.\nWhile very little is known about pterosaur reproduction, it is believed that, similar to all dinosaurs, all pterosaurs reproduced by laying eggs, though such findings are very rare. The first known pterosaur eggs were found in the quarries of Liaoning, the same place that yielded feathered dinosaurs, and in Loma del Pterodaustro (Lagarcito Formation, Argentina). The eggs from Liaoning were squashed flat with no signs of cracking, so evidently the eggs had leathery shells, as in modern lizards. The egg from the Lagarcito Formation was laid by a \"Pterodaustro\", a pterosaur known by abundant material. This was supported by the description of an additional pterosaur egg belonging to the genus \"Darwinopterus\", described in 2011, which also had a leathery shell and, also like modern reptiles but unlike birds, was fairly small compared to the size of the mother. In 2014 five unflattened eggs from the species \"Hamipterus tianshanensis\" were found in an Early Cretaceous deposit in northwest China. Examination of the shells by scanning electron microscopy showed the presence of a thin calcareous eggshell layer with a membrane underneath. A study of pterosaur eggshell structure and chemistry published in 2007 indicated that it is likely pterosaurs buried their eggs, like modern crocodiles and turtles. Egg-burying would have been beneficial to the early evolution of pterosaurs, as it allows for more weight-reducing adaptations, but this method of reproduction would also have put limits on the variety of environments pterosaurs could live in and may have disadvantaged them when they began to face ecological competition from birds.\nA \"Darwinopterus\" specimen showcases that at least some pterosaurs had a pair of functional ovaries, as opposed to the single functional ovary in birds, dismissing the reduction of functional ovaries as a requirement for powered flight.\nWing membranes preserved in pterosaur embryos are well developed, suggesting that pterosaurs were ready to fly soon after birth. However, tomography scans of fossilised \"Hamipterus\" eggs suggests that the young pterosaurs had well-developed thigh bones for walking, but weak chests for flight. It is unknown if this holds true for other pterosaurs. Fossils of pterosaurs only a few days to a week old (called \"flaplings\") have been found, representing several pterosaur families, including pterodactylids, rhamphorhinchids, ctenochasmatids and azhdarchids. All preserved bones that show a relatively high degree of hardening (\"ossification\") for their age, and wing proportions similar to adults. In fact, many pterosaur flaplings have been considered adults and placed in separate species in the past. Additionally, flaplings are normally found in the same sediments as adults and juveniles of the same species, such as the \"Pterodactylus\" and \"Rhamphorhynchus\" flaplings found in the Solnhofen limestone of Germany, and \"Pterodaustro\" flaplings from Argentina. All are found in deep aquatic environment far from shore.\nFor the majority of pterosaur species, it is not known whether they practiced any form of parental care, but their ability to fly as soon as they emerged from the egg and the numerous flaplings found in environments far from nests and alongside adults has led most researchers, including Christopher Bennett and David Unwin, to conclude that the young were dependent on their parents for a relatively short period of time, during a period of rapid growth while the wings grew long enough to fly, and then left the nest to fend for themselves, possibly within days of hatching. Alternatively, they may have used stored yolk products for nourishment during their first few days of life, as in modern reptiles, rather than depend on parents for food. Fossilised \"Hamipterus\" nests were shown preserving many male and female pterosaurs together with their eggs in a manner to a similar to that of modern seabird colonies. Due to how underdeveloped the chests of the hatchlings were for flying, it was suggested that \"Hamipterus\" may have practiced some form of parental care. However, this study has since been criticised. Most evidence currently leans towards pterosaur hatchlings being superprecocial, similar to that of megapode birds, which fly after hatching without the need of parental care. A further study compares evidence for superprecociality and \"late term flight\" and overwhelmingly suggests that most if not all pterosaurs were capable of flight soon after hatching. A later study suggested that while smaller-bodied pterosaurs were most likely superprecocial or precocial, owing to the consistent or decreasing wing aspect ratio during growth, certain large-bodied pterosaurs, such as \"Pteranodon\" showed possible evidence of their young being altricial, due to the fast rate the limb bones closest to the body grew compared to any other element of their skeleton after hatching. Other factors mentioned were the limits of soft shelled eggs and the size of the pelvic opening of large female pterosaurs.\nGrowth rates of pterosaurs once they hatched varied across different groups. In earlier, long-tailed pterosaurs (\"rhamphorhynchoids\"), such as \"Rhamphorhynchus\", the average growth rate during the first year of life was 130% to 173%, slightly faster than the growth rate of alligators. Growth in these species slowed after sexual maturity, and it would have taken more than three years for \"Rhamphorhynchus\" to attain maximum size. In contrast, the later pterodactyloid pterosaurs, such as \"Pteranodon\", grew to adult size within the first year of life. Additionally, pterodactyloids had \"determinate growth\", meaning that the animals reached a fixed maximum adult size and stopped growing.\nA 2021 study indicates that pterosaur juveniles of larger species increasingly took the roles previously occupied by adult small pterosaurs.\nDaily activity patterns.\nComparisons between the scleral rings of pterosaurs and modern birds and reptiles have been used to infer daily activity patterns of pterosaurs. The pterosaur genera \"Pterodactylus\", \"Scaphognathus\", and \"Tupuxuara\" have been inferred to be diurnal, \"Ctenochasma\", \"Pterodaustro\", and \"Rhamphorhynchus\" have been inferred to be nocturnal, and \"Tapejara\" has been inferred to be cathemeral, being active throughout the day for short intervals. As a result, the possibly fish-eating \"Ctenochasma\" and \"Rhamphorhynchus\" may have had similar activity patterns to modern nocturnal seabirds, and the filter-feeding \"Pterodaustro\" may have had similar activity patterns to modern anseriform birds that feed at night. The differences between activity patterns of the Solnhofen pterosaurs \"Ctenochasma\", \"Rhamphorhynchus\", \"Scaphognathus\", and \"Pterodactylus\" may also indicate niche partitioning between these genera.\nCultural significance.\nPterosaurs have been a staple of popular culture for as long as their cousins the dinosaurs, though they are usually not featured as prominently in films, literature or other art. While the depiction of dinosaurs in popular media has changed radically in response to advances in paleontology, a mainly outdated picture of pterosaurs has persisted since the mid-20th century.\nThe vague generic term \"pterodactyl\" is often used for these creatures. The animals depicted in fiction and pop culture frequently represent either \"Pteranodon\" or (non-pterodactyloid) \"Rhamphorhynchus\", or a fictionalized hybrid of the two. Many children's toys and cartoons feature \"pterodactyls\" with \"Pteranodon\"-like crests and long, \"Rhamphorhynchus\"-like tails and teeth, a combination that never existed in nature. However, at least one pterosaur \"did\" have both the \"Pteranodon\"-like crest and teeth: \"Ludodactylus\", whose name means \"toy finger\" for its resemblance to old, inaccurate children's toys. Pterosaurs have sometimes been incorrectly identified as (the ancestors of) birds, though birds are theropod dinosaurs and not descendants of pterosaurs.\nPterosaurs were used in fiction in Sir Arthur Conan Doyle's 1912 novel \"The Lost World\" and its 1925 film adaptation. They appeared in a number of films and television programs since, including the 1933 film \"King Kong\", and 1966's \"One Million Years B.C.\" In the latter, animator Ray Harryhausen had to add inaccurate bat-like wing fingers to his stop motion models in order to keep the membranes from falling apart, though this particular error was common in art even before the film was made. Rodan, a fictional giant monster (or \"kaiju\") which first appeared in the 1956 film \"Rodan\", is portrayed as an enormous irradiated species of \"Pteranodon\". Rodan has appeared in multiple Japanese \"Godzilla\" films released during the 1960s, 1970s, 1990s, and 2000s, and also appeared in the 2019 American-produced film \"\".\n The Fell Beasts of J.R.R. Tolkien's \"Lord of the Rings\" are often understood as \"pterosaur-like\", although Tolkien himself did deny they were actual pterosaurs.\nAfter the 1960s, pterosaurs remained mostly absent from notable American film appearances until 2001's \"Jurassic Park III\". Paleontologist Dave Hone noted that the pterosaurs in this film had not been significantly updated to reflect modern research. Errors persisting were teeth while toothless \"Pteranodon\" was intended to be depicted, nesting behavior that was known to be inaccurate by 2001, and leathery wings, rather than the taut membranes of muscle fiber required for pterosaur flight. Petrie from \"The Land Before Time\" (1988), is a notable example from an animated film.\nIn most media appearances, pterosaurs are depicted as piscivores, not reflecting their full dietary variation. They are also often shown as aerial predators similar to birds of prey, grasping human victims with talons on their feet. However, only the small anurognathid \"Vesperopterylus\" and small wukongopterid \"Kunpengopterus\" are known to possess prehensile feet and hands respectively; all other known pterosaurs have flat, plantigrade feet with no opposable toes, and the feet are generally proportionally small, at least in the case of the Pteranodontia.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24825", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=24825", "title": "Pteranodon", "text": "Genus of pterosaur of the Late Cretaceous\nPteranodon (; from 'wing' and 'toothless') is a genus of pterosaur that included some of the largest known flying reptiles, with \"P. longiceps\" having a wingspan of over . They lived during the late Cretaceous geological period of North America in present-day Kansas, Nebraska, Wyoming, South Dakota and Alabama. More fossil specimens of \"Pteranodon\" have been found than any other pterosaur, with about 1,200 specimens known to science, many of them well preserved with nearly complete skulls and articulated skeletons. It was an important part of the animal community in the Western Interior Seaway.\nWhen the first fossils of \"Pteranodon\" were found, they were assigned to toothed pterosaur genera, such as \"Ornithocheirus\" and \"Pterodactylus\". In 1876, Othniel Charles Marsh recognised it as a genus of its own, making particular note of its complete lack of teeth, which at the time was unique among pterosaurs. Over the decades, multiple species would be assigned to \"Pteranodon\", though today, only two are recognised: \"P. longiceps\", the type species, and \"P. sternbergi\". A third species, \"P. maiseyi\", may also exist. Some researchers have suggested the latter two as a genus of their own, \"Geosternbergia\", though this is the subject of some debate. Another genus split from \"Pteranodon\", \"Dawndraco\", may be synonymous with \"Geosternbergia\" if that genus is valid, or with \"Pteranodon\" if it is not.\n\"Pteranodon\" is part of the family Pteranodontidae, part of the clade Pteranodontia, which also includes nyctosaurids. Pteranodontians form a larger clade, Pteranodontoidea, alongside ornithocheiromorphs, and that clade falls under the suborder Pterodactyloidea. While not dinosaurs, pterosaurs such as \"Pteranodon\" form a clade closely related to dinosaurs as both fall within the clade Avemetatarsalia.\nMale and female \"Pteranodon\" differed in size and crest shape. Males attained wingspans of ; females were smaller, averaging . The crests of males were far larger than those of females. In \"P. longiceps\", they were long and backswept, whereas in \"P. sternbergi\", they were tall and upright. Females also had wider pelvises than males.\nDiscovery and history.\nFirst fossils.\n\"Pteranodon\" was the first pterosaur found outside of Europe. Its fossils first were found by Othniel Charles Marsh in 1871, in the Late Cretaceous Smoky Hill Chalk deposits of western Kansas. These chalk beds were deposited at the bottom of what was once the Western Interior Seaway, a large shallow sea over what now is the midsection of the North American continent. These first specimens, YPM 1160 and YPM 1161, consisted of partial wing bones, as well as a tooth from the prehistoric fish \"Xiphactinus\", which Marsh mistakenly believed to belong to this new pterosaur (all known pterosaurs up to that point had teeth). In 1871, Marsh named the find \"Pterodactylus oweni\", assigning it to the well-known (but much smaller) European genus \"Pterodactylus\". Marsh also collected more wing bones of the large pterosaur in 1871. Realizing that the name he had chosen had already been used for Harry Seeley's European pterosaur species \"Pterodactylus oweni\" in 1864, Marsh renamed his giant North American pterosaur \"Pterodactylus occidentalis\", meaning \"Western wing finger,\" in his 1872 description of the new specimen. He named two additional species, based on size differences: \"Pterodactylus ingens\" (the largest specimen so far), and \"Pterodactylus velox\" (the smallest).\nMeanwhile, Marsh's rival Edward Drinker Cope had unearthed several specimens of the large North American pterosaur. Based on these specimens, Cope named two new species, Ornithochirus umbrosus and \"Ornithochirus harpyia\", in an attempt to assign them to the large European genus \"Ornithocheirus\", though he misspelled the name (forgetting the 'e'). Cope's paper naming his species was published in 1872, just five days after Marsh's paper. This resulted in a dispute, fought in the published literature, over whose names had priority in what obviously were the same species. Cope conceded in 1875 that Marsh's names did have priority over his, but maintained that \"Pterodactylus umbrosus\" was a distinct species (but not genus) from any that Marsh had named previously. Re-evaluation by later scientists has supported Marsh's case, refuting Cope's assertion that \"P. umbrosus\" represented a larger, distinct species.\nA toothless pterosaur.\nWhile the first \"Pteranodon\" wing bones were collected by Marsh and Cope in the early 1870s, the first \"Pteranodon\" skull was found on May 2, 1876, along the Smoky Hill River in Wallace County (now Logan County), Kansas, USA, by Samuel Wendell Williston, a fossil collector working for Marsh. A second, smaller skull soon was discovered as well. These skulls showed that the North American pterosaurs were different from any European species, in that they lacked teeth and had bony crests on their skulls. Marsh recognized this major difference, describing the specimens as \"distinguished from all previously known genera of the order Pterosauria by the entire absence of teeth.\" Marsh recognized that this characteristic warranted a new genus, and he coined the name \"Pteranodon\" (\"wing without tooth\") in 1876. Marsh reclassified all the previously named North American species from \"Pterodactylus\" to \"Pteranodon\". He considered the smaller skull to belong to \"Pteranodon occidentalis\", based on its size. Marsh classified the larger skull, YPM 1117, in the new species \"Pteranodon longiceps\", which he thought to be a medium-sized species in between the small \"P. occidentalis\" and the large \"P. ingens\". Marsh also named several additional species: Pteranodon comptus and \"Pteranodon nanus\" were named for fragmentary skeletons of small individuals, while \"Pteranodon gracilis\" was based on a wing bone that he mistook for a pelvic bone. He soon realized his mistake, and re-classified that specimen again into a separate genus, which he named \"Nyctosaurus\". \"P. nanus\" was also later recognized as a \"Nyctosaurus\" specimen.\nIn 1892, Samuel Williston examined the question of \"Pteranodon\" classification. He noticed that, in 1871, Seeley had mentioned the existence of a partial set of toothless pterosaur jaws from the Cambridge Greensand of England, which he named \"Ornithostoma\". Because the primary characteristic Marsh had used to separate \"Pteranodon\" from other pterosaurs was its lack of teeth, Williston concluded that \"Ornithostoma\" must be considered the senior synonym of \"Pteranodon\". However, in 1901, Pleininger pointed out that \"Ornithostoma\" had never been scientifically described or even assigned a species name until Williston's work, and therefore had been a \"nomen nudum\" and could not beat out \"Pteranodon\" for naming priority. Williston accepted this conclusion and went back to calling the genus \"Pteranodon\". However, both Williston and Pleininger were incorrect, because unnoticed by both of them was the fact that, in 1891, Seeley himself had finally described and properly named \"Ornithostoma\", assigning it to the species \"O. sedgwicki\". In the 2010s, more research on the identity of \"Ornithostoma\" showed that it was probably not \"Pteranodon\" or even a close relative, but may in fact have been an azhdarchoid, a different type of toothless pterosaur.\nRevising species.\nWilliston was also the first scientist to critically evaluate all of the \"Pteranodon\" species classified by Cope and Marsh. He agreed with most of Marsh's classification, with a few exceptions. First, he did not believe that \"P. ingens\" and \"P. umbrosus\" could be considered synonyms, which even Cope had come to believe. He considered both \"P. velox\" and \"P. longiceps\" to be dubious; the first was based on non-diagnostic fragments, and the second, though known from a complete skull, probably belonged to one of the other, previously-named species. In 1903, Williston revisited the question of \"Pteranodon\" classification, and revised his earlier conclusion that there were seven species down to just three. He considered both \"P. comptus\" and \"P. nanus\" to be specimens of \"Nyctosaurus\", and divided the others into small (\"P. velox\"), medium (\"P. occidentalis\"), and large species (\"P. ingens\"), based primarily on the shape of their upper arm bones. He thought \"P. longiceps\", the only one known from a skull, could be a synonym of either \"P. velox\" or \"P. occidentalis\", based on its size.\nIn 1910, Eaton became the first scientist to publish a more detailed description of the entire \"Pteranodon\" skeleton, as it was known at the time. He used his findings to revise the classification of the genus once again based on a better understanding of the differences in pteranodont anatomy. Eaton conducted experiments using clay models of bones to help determine the effects of crushing and flattening on the shapes of the arm bones Williston had used in his own classification. Eaton found that most of the differences in bone shapes could be easily explained by the pressures of fossilization, and concluded that no \"Pteranodon\" skeletons had any significant differences from each other besides their size. Therefore, Eaton was left to decide his classification scheme based on differences in the skulls alone, which he assigned to species just as Marsh did, by their size. In the end, Eaton recognized only three valid species: \"P. occidentalis\", \"P. ingens\", and \"P. longiceps\".\nThe discovery of specimens with upright crests, classified by Harksen in 1966 as the new species \"Pteranodon sternbergi\", complicated the situation even further. prompting another revision of the genus by Halsey W. Miller in 1972. Because it was impossible to determine crest shape for all of the species based on headless skeletons, Miller concluded that all \"Pteranodon\" species except the two based on skulls (\"P. longiceps\" and \"P. sternbergi\") must be considered \"nomena dubia\" and abandoned. The skull Eaton thought belonged to \"P. ingens\" was placed in the new species \"Pteranodon marshi\", and the skull Eaton assigned to \"P. occidentalis\" was re-named \"Pteranodon eatoni\". Miller also recognized another species based on a skull with a crest similar to that of \"P. sternbergi\"; Miller named this \"Pteranodon walkeri\". To help bring order to this tangle of names, Miller created three subgenera. \"P. marshi\" and \"P. longiceps\" were placed in the subgenus \"Longicepia\", though this was later changed to simply \"Pteranodon\" due to the rules of priority. \"P. sternbergi\" and \"P. walkeri\", the upright-crested species, were given the subgenus \"Sternbergia\", which was later changed to \"Geosternbergia\" because \"Sternbergia\" was preoccupied. Finally, Miller named the subgenus \"Occidentalia\" for \"P. eatoni\", the skull formerly associated with \"P. occidentalis\". Miller further expanded the concept of \"Pteranodon\" to include \"Nyctosaurus\" as a fourth subgenus. Miller considered these to be an evolutionary progression, with the primitive \"Nyctosaurus\", at the time thought to be crestless, giving rise to small-crested \"Occidentalia\", which in turn gave rise to long-crested \"Pteranodon\", finally leading to tall-crested \"Geosternbergia\". However, Miller made several mistakes in his study concerning which specimens Marsh had assigned to which species, and most scientists disregarded his work on the subject in their later research. In 1984, Robert Milton Schoch published another revision that essentially returned to Marsh's original classification scheme, most notably sinking \"P. longiceps\" as a synonym of \"P. ingens\".\nRecognizing variation.\nIn the late 1980s and early 1990s, S. Christopher Bennett published several major papers reviewing the anatomy, taxonomy and life history of \"Pteranodon\". In 1992, he published a paper discussing sexual dimorphism and its role in individual variation among \"Pteranodon\" fossils, a follow-up of a 1987 paper he authored on the same subject. In the 1992 paper, he referred only to two species, \"P. longiceps\" and \"P. sternbergi\". Two years later, he published a paper fully revising its taxonomy, wherein he concluded that only \"P. longiceps\" and \"P. sternbergi\" were valid species. \"P. marshi\" and \"P. walkeri\" were regarded as junior synonyms of \"P. longiceps\", and \"P. eatoni\" as a junior synonym of \"P. stenbergi\". The remainder were either rendered \"nomina dubia\" or placed in Nyctosaurus\".\"\nDescription.\nBody size and sexual dimorphism.\nAdult male \"Pteranodon\" were among the largest pterosaurs, and were the largest flying animals known until the late 20th century, when the giant azhdarchid pterosaurs were discovered. The wingspan of an average adult male \"Pteranodon\" was . Adult females were much smaller, averaging in wingspan. A large specimen of \"Pteranodon longiceps\", USNM 50130, is estimated to have a wingspan of , body length of and body mass of . Even larger specimens had wingspans of . Size aside, females were distinguished by their short, rounded head crests and wide pelvic canals, whereas males had narrow hips and very large head crests, likely serving a display function.\nMethods used to estimate the mass of large male \"Pteranodon\" specimens (those with wingspans of about 7 meters) have been notoriously unreliable, producing a wide range of estimates. In a review of pterosaur size estimates published in 2010, Mark Witton and Michael Habib argued that the largest estimate of is much too high and an upper limit of is more realistic. Witton and Habib considered the methods used by researchers who obtained smaller mass estimates equally flawed. Most have been produced by scaling modern animals such as bats and birds up to \"Pteranodon\" size, despite the fact that pterosaurs have vastly different body proportions and soft tissue anatomy from any living animal.\nSkull and beak.\nUnlike earlier pterosaurs, such as \"Rhamphorhynchus\" and \"Pterodactylus\", \"Pteranodon\" had toothless beaks, similar to those of birds. \"Pteranodon\" beaks were made of solid, bony margins that projected from the base of the jaws. The beaks were long, slender, and ended in thin, sharp points. The upper jaw, which was longer than the lower jaw, was curved upward; while this normally has been attributed only to the upward-curving beak, one specimen (UALVP 24238) has a curvature corresponding with the beak widening towards the tip. While the tip of the beak is not known in this specimen, the level of curvature suggests it would have been extremely long. The unique form of the beak in this specimen led Alexander Kellner to assign it to a distinct genus, \"Dawndraco\", in 2010.\nThe most distinctive characteristic of \"Pteranodon\" is its cranial crest. These crests consisted of skull bones (frontals) projecting upward and backward from the skull. The size and shape of these crests varied due to a number of factors, including age, sex, and species. Male \"Pteranodon sternbergi\", the older species of the two described to date, had a more vertical crest with a broad forward projection, while their descendants, \"Pteranodon longiceps\", evolved a narrower, more backward-projecting crest. Females of both species were smaller and bore small, rounded crests. The crests were probably mainly display structures, though they may have had other functions as well.\nPostcranial skeleton.\nThe neural spines of \"Pteranodon\"'s vertebrae were narrow. Like many pterosaurs and birds, it possessed a notarium, a fused mass comprising the first six dorsal vertebrae. Similarly, the first few ribs were fused. The pelvic bones were fused to the synsacrum, a mass of vertebrae that included at least two dorsal vertebrae, the sacral vertebrae, and the first caudal vertebra. The sacrals were strengthened by bony ligaments. Beyond the synsacrum, the tail was relatively short, and the last few vertebrae were fused into a bony rod. The entire length of the tail was about 3.5% as long as the wingspan, or up to in the largest males. \n\"Pteranodon\"'s scapulae were oriented in such a way that each one braces the other, due to their fusion with the coracoids, providing increased integrity during flight. The humeri were extremely robust, with large, curved deltopectoral crests. The radius and ulna were similarly robust. The first three metacarpals were very slender, and their respective digits sported short, curved unguals (claws). \"Pteranodon\"'s hind feet had four metatarsals, which were tipped with less curved claws.\nPaleobiology.\nFlight.\nThe wing shape of \"Pteranodon\" suggests that it would have flown rather like a modern-day albatross. This is based on the fact that \"Pteranodon\" had a high aspect ratio (wingspan to chord length) similar to that of the albatross \u2014 9:1 for \"Pteranodon\", compared to 8:1 for an albatross. Albatrosses spend long stretches of time at sea fishing, and use a flight pattern called \"dynamic soaring\" which exploits the vertical gradient of wind speed near the ocean surface to travel long distances without flapping, and without the aid of thermals (which do not occur over the open ocean the same way they do over land). While most of a \"Pteranodon\" flight would have depended on soaring, like long-winged seabirds, it probably required an occasional active, rapid burst of flapping, and studies of \"Pteranodon\" wing loading (the strength of the wings vs. the weight of the body) indicate that they were capable of substantial flapping flight, contrary to some earlier suggestions that they were so big they could only glide. However, a more recent study suggests that it relied on thermal soaring, unlike modern seabirds but much like modern continental flyers and the extinct \"Pelagornis\".\nLike other pterosaurs, \"Pteranodon\" probably took off from a standing, quadrupedal position. Using their long forelimbs for leverage, they would have vaulted themselves into the air in a rapid leap. Almost all of the energy would have been generated by the forelimbs. The upstroke of the wings would have occurred when the animal cleared the ground followed by a rapid down-stroke to generate additional lift and complete the launch into the air. It is possible that \"Pteranodon\" could have achieved this from the water, as well as on land, which has been speculated for various other such as the distantly related \"Anhanguera\".\nLocomotion.\nHistorically, terrestrial locomotion in \"Pteranodon\", as in pterosaurs overall, has been the subject of debate, chiefly the matter of whether or not they were bipedal or quadrupedal. The earliest model of \"Pteranodon\" locomotion, put forward by Cherrie D. Bramwell and G. R. Whitfield, suggested that they were utterly incapable of walking or standing. Instead, they suggested that it moved on land by pushing itself around, and that it took off by perching on cliffsides and allowing the wind to take it. Subsequent works largely revolved around more conventional methods of locomotion, such as bipedalism and various kinds of quadrupedalism. In 2004, Sankar Chatterjee and R. J. Templin proposed a dual system, wherein pterosaurs walked quadrupedally most of the time, but opted for a bipedal takeoff. The latter, however, is unlikely. Trackways suggest that pterosaurs like \"Pteranodon\" were quadrupedal.\nDiet.\nThe diet of \"Pteranodon\" is known to have included fish; fossilized fish bones have been found in the stomach area of one \"Pteranodon\", and a fossilized fish bolus has been found between the jaws of another \"Pteranodon\", specimen AMNH 5098. Numerous other specimens also preserve fragments of fish scales and vertebrae near the torso, indicating that fish made up a majority of the diet of \"Pteranodon\" (though they may also have taken invertebrates).\nTraditionally, most researchers have suggested that \"Pteranodon\" would have taken fish by dipping their beaks into the water while in low, soaring flight. However, this was probably based on the assumption that the animals could not take off from the water surface. It is more likely that \"Pteranodon\" could take off from the water, and would have dipped for fish while swimming rather than while flying. Even a small, female \"Pteranodon\" could have reached a depth of at least with its long bill and neck while floating on the surface, and they may have reached even greater depths by plunge-diving into the water from the air like some modern long-winged seabirds. In 1994, Bennett noted that the head, neck, and shoulders of \"Pteranodon\" were as heavily built as diving birds, and suggested that they could dive by folding back their wings like the modern gannet.\nCrest function.\n\"Pteranodon\" was notable for its skull crest, though the function of this crest has been a subject of debate. Most explanations have focused on the blade-like, backward pointed crest of male \"P. longiceps\", however, and ignored the wide range of variation across age and sex. The fact that the crests vary so much rules out most practical functions other than for use in mating displays. Therefore, display was probably the main function of the crest, and any other functions were secondary.\nScientific interpretations of the crest's function began in 1910, when George Francis Eaton proposed two possibilities: an aerodynamic counterbalance and a muscle attachment point. He suggested that the crest might have anchored large, long jaw muscles, but admitted that this function alone could not explain the large size of some crests. Bennett (1992) agreed with Eaton's own assessment that the crest was too large and variable to have been a muscle attachment site. Eaton had suggested that a secondary function of the crest might have been as a counterbalance against the long beak, reducing the need for heavy neck muscles to control the orientation of the head. Wind tunnel tests showed that the crest did function as an effective counterbalance to a degree, but Bennett noted that, again, the hypothesis focuses only on the long crests of male \"P. longiceps\", not on the larger crests of \"P. sternbergi\" and very small crests that existed among the females. Bennett found that the crests of females had no counterbalancing effect, and that the crests of male \"P. sternbergi\" would, by themselves, have a negative effect on the balance of the head. In fact, side to side movement of the crests would have required more, not less, neck musculature to control balance.\nIn 1943, Dominik von Kripp suggested that the crest may have served as a rudder, an idea embraced by several later researchers. One researcher, Ross S. Stein, even suggested that the crest may have supported a membrane of skin connecting the backward-pointing crest to the neck and back, increasing its surface area and effectiveness as a rudder. The rudder hypothesis, again, does not take into account females nor \"P. sternbergi\", which had an upward-pointing, not backward-pointing crest. Bennett also found that, even in its capacity as a rudder, the crest would not provide nearly so much directional force as simply maneuvering the wings. The suggestion that the crest was an air brake, and that the animals would turn their heads to the side in order to slow down, suffers from a similar problem. Additionally, the rudder and air brake hypotheses do not explain why such large variation exists in crest size even among adults.\nAlexander Kellner suggested that the large crests of the pterosaur \"Tapejara\", as well as other species, might be used for heat exchange, allowing these pterosaurs to absorb or shed heat and regulate body temperature, which also would account for the correlation between crest size and body size. There is no evidence of extra blood vessels in the crest for this purpose, however, and the large, membranous wings filled with blood vessels would have served that purpose much more effectively.\nWith these hypotheses ruled out, the best-supported hypothesis for crest function seems to be as a sexual display. This is consistent with the size variation seen in fossil specimens, where females and juveniles have small crests and males large, elaborate, variable crests.\nSexual variation.\nAdult \"Pteranodon\" specimens may be divided into two distinct size classes, small and large, with the large size class being about one and a half times larger than the small class, and the small class being twice as common as the large class. Both size classes lived alongside each other, and while researchers had previously suggested that they represent different species, Christopher Bennett showed that the differences between them are consistent with the concept that they represent females and males, and that \"Pteranodon\" species were sexually dimorphic. Skulls from the larger size class preserve large, upward and backward pointing crests, while the crests of the smaller size class are small and triangular. Some larger skulls also show evidence of a second crest that extended long and low, toward the tip of the beak, which is not seen in smaller specimens.\nThe gender of the different size classes was determined, not from the skulls, but from the pelvic bones. Contrary to what may be expected, the smaller size class had disproportionately large and wide-set pelvic bones. Bennett interpreted this as indicating a more spacious birth canal, through which eggs would pass. He concluded that the small size class with small, triangular crests represent females, and the larger, large-crested specimens represent males. The overall size and crest size also corresponds to age. Immature specimens are known from both females and males, and immature males often have small crests similar to adult females. Therefore, it seems that the large crests only developed in males when they reached their large, adult size, making the sex of immature specimens difficult to establish from partial remains.\nThe fact that females appear to have outnumbered males two to one suggests that, as with modern animals with size-related sexual dimorphism, such as sea lions and other pinnipeds, \"Pteranodon\" might have been polygynous, with a few males competing for association with groups consisting of large numbers of females. Similar to modern pinnipeds, \"Pteranodon\" may have competed to establish territory on rocky, offshore rookeries, with the largest, and largest-crested, males gaining the most territory and having more success mating with females. The crests of male \"Pteranodon\" would not have been used in competition, but rather as \"visual dominance-rank symbols\", with display rituals taking the place of physical competition with other males. If this hypothesis is correct, it also is likely that male \"Pteranodon\" played little to no part in rearing the young; such a behavior is not found in the males of modern polygynous animals who father many offspring at the same time.\nPaleoecology.\nSpecimens assigned to \"Pteranodon\" have been found in both the Smoky Hill Chalk deposits of the Niobrara Formation, and the slightly younger Sharon Springs deposits of the Pierre Shale Formation. When \"Pteranodon\" was alive, this area was covered by a large inland sea, known as the Western Interior Seaway. Famous for fossils collected since 1870, these formations extend from as far south as Kansas in the United States to Manitoba in Canada. However, \"Pteranodon\" specimens (or any pterosaur specimens) have only been found in the southern half of the formation, in Kansas, Wyoming, and South Dakota. Despite the fact that numerous fossils have been found in the contemporary parts of the formation in Canada, no pterosaur specimens have ever been found there. This strongly suggests that the natural geographic range of \"Pteranodon\" covered only the southern part of the Niobrara, and that its habitat did not extend farther north than South Dakota.\nSome very fragmentary fossils belonging to pteranodontian pterosaurs, and possibly \"Pteranodon\" itself, have also been found on the Gulf Coast and East Coast of the United States. For example, some bone fragments from the Mooreville Formation of Alabama and the Merchantville Formation of Delaware may have come from \"Pteranodon\", though they are too incomplete to make a definite identification. Some remains from Japan have also been tentatively attributed to \"Pteranodon\", but their distance from its known Western Interior Seaway habitat makes this identification unlikely.\n\"Pteranodon longiceps\" would have shared the sky with the giant-crested pterosaur \"Nyctosaurus\". Compared to \"P. longiceps\", which was a very common species, \"Nyctosaurus\" was rare, making up only 3% of pterosaur fossils from the formation. Also less common was the early toothed bird, \"Ichthyornis\". Below the surface, the sea was populated primarily by invertebrates such as ammonites and squid. Vertebrate life, apart from basal fish, included sea turtles, such as \"Toxochelys\", the plesiosaurs \"Elasmosaurus\" and \"Styxosaurus\", and the flightless diving bird \"Parahesperornis\". Mosasaurs were the most common marine reptiles, with genera including \"Clidastes\", \"Mosasaurus\" and \"Tylosaurus\". At least some of these marine reptiles are known to have fed on \"Pteranodon\". Barnum Brown, in 1904, reported plesiosaur stomach contents containing \"pterodactyl\" bones, most likely from \"Pteranodon\". Fossils from terrestrial dinosaurs also have been found in the Niobrara Chalk, suggesting that animals who died on shore must have been washed out to sea (one specimen of a hadrosaur appears to have been scavenged by a shark).\nIt is likely that, as in other polygynous animals (in which males compete for association with harems of females), \"Pteranodon\" lived primarily on offshore rookeries, where they could nest away from land-based predators and feed far from shore; most \"Pteranodon\" fossils are found in locations which at the time, were hundreds of kilometres from the coastline.\nClassification.\nTimespan and evolution.\n\"Pteranodon\" fossils are known primarily from the Niobrara Formation of the central United States. Broadly defined, \"Pteranodon\" existed for more than four million years, during the Santonian stage of the Cretaceous period. The genus is present in most layers of the Niobrara Formation except for the upper two; in 2003, Kenneth Carpenter surveyed the distribution and dating of fossils in this formation, demonstrating that \"Pteranodon sternbergi\" existed there from 88 to 85 million years ago, while \"P. longiceps\" existed between 86 and 84.5 million years ago. A possible third species, which Kellner named \"Geosternbergia maiseyi\" in 2010, is known from the Sharon Springs member of the Pierre Shale Formation in Kansas, Wyoming, and South Dakota, dating to between 81.5 and 80.5 million years ago. Fossils of \"P. longiceps\" have been found in layers dating to 80-78.25 million years ago.\nIn the early 1990s, Bennett noted that the two major morphs of pteranodont present in the Niobrara Formation were precisely separated in time with little, if any, overlap. Due to this, and to their gross overall similarity, he suggested that they probably represent chronospecies within a single evolutionary lineage lasting about 4 million years. In other words, only one species of \"Pteranodon\" would have been present at any one time, and \"P. sternbergi\" (or \"Geosternbergia\") in all likelihood was the direct ancestor species of \"P. longiceps\".\nValid species.\nMany researchers consider there to be at least two species of \"Pteranodon\". However, aside from the differences between males and females described above, the post-cranial skeletons of \"Pteranodon\" show little to no variation between species or specimens, and the bodies and wings of all pteranodonts were essentially identical.\nTwo species of \"Pteranodon\" are traditionally recognized as valid: \"Pteranodon longiceps\", the type species, and \"Pteranodon sternbergi\". The species differ only in the shape of the crest in adult males (described above), and possibly in the angle of certain skull bones. Because well-preserved \"Pteranodon\" skull fossils are extremely rare, researchers use stratigraphy (i.e. which rock layer of the geologic formation a fossil is found in) to determine species identity in most cases.\n\"Pteranodon sternbergi\" is the only known species of \"Pteranodon\" with an upright crest. The lower jaw of \"P. sternbergi\" was long. It was collected by George F. Sternberg in 1952 and described by John Christian Harksen in 1966, from the lower portion of the Niobrara Formation. It was older than \"P. longiceps\" and is considered by Bennett to be the direct ancestor of the later species.\nBecause fossils identifiable as \"P. sternbergi\" are found exclusively in the lower layers of the Niobrara Formation, and \"P. longiceps\" fossils exclusively in the upper layers, a fossil lacking the skull can be identified based on its position in the geologic column (though for many early fossil finds, precise data about its location was not recorded, rendering many fossils unidentifiable).\nBelow is a cladogram showing the phylogenetic placement of this genus within Pteranodontia from Andres and Myers (2013).\nAlternative classifications.\nDue to the subtle variations between specimens of pteranodontid from the Niobrara Formation, most researchers have assigned all of them to the single genus \"Pteranodon\", in at least two species (\"P. longiceps\" and \"P. sternbergi\") distinguished mainly by the shape of the crest. However, the classification of these two forms has varied from researcher to researcher. In 1972, Halsey Wilkinson Miller published a paper arguing that the various forms of \"Pteranodon\" were different enough to be placed in distinct subgenera. He named these \"Pteranodon (Occidentalia) occidentalis\" (for the now-disused species \"P. occidentalis\") and \"Pteranodon (Sternbergia) sternbergi\". However, the name \"Sternbergia\" was preoccupied, and in 1978 Miller re-named the species \"Pteranodon (Geosternbergia) sternbergi\", and named a third subgenus/species combination for \"P. longiceps\", as \"Pteranodon (Longicepia) longiceps\". Most prominent pterosaur researchers of the late 20th century however, including S. Christopher Bennett and Peter Wellnhofer, did not adopt these subgeneric names, and continued to place all pteranodont species into the single genus \"Pteranodon\".\nIn 2010, pterosaur researcher Alexander Kellner revisited H.W. Miller's classification. Kellner followed Miller's opinion that the differences between the \"Pteranodon\" species were great enough to place them into different genera. He placed \"P. sternbergi\" into the genus named by Miller, \"Geosternbergia\", along with the Pierre Shale skull specimen which Bennett had previously considered to be a large male \"P. longiceps\". Kellner argued that this specimen's crest, though incompletely preserved, was most similar to \"Geosternbergia\". Because the specimen was millions of years younger than any known \"Geosternbergia\", he assigned it to the new species \"Geosternbergia maiseyi\". Numerous other pteranodont specimens are known from the same formation and time period, and Kellner suggested they may belong to the same species as \"G. maiseyi\", but because they lack skulls, he could not confidently identify them. However, both species previously referred to \"Geosternbergia\" were separately included as those of \"Pteranodon\" (\"P. sternbergi\" and \"P. maiseyi\") based on phylogenetic analysis in 2024.\nDisused species.\nA number of additional species of \"Pteranodon\" have been named since the 1870s, although most now are considered to be junior synonyms of two or three valid species. The best-supported is the type species, \"P. longiceps\", based on the well-preserved specimen including the first-known skull found by S. W. Williston. This individual had a wingspan of . Other valid species include the possibly larger \"P. sternbergi\", with a wingspan originally estimated at . \"P. oweni\" (\"P. occidentalis\"), \"P. velox\", \"P. umbrosus\", \"P. harpyia\", and \"P. comptus\" are considered to be \"nomina dubia\" by Bennett (1994) and others who question their validity. All probably are synonymous with the more well-known species.\nBecause the key distinguishing characteristic Marsh noted for \"Pteranodon\" was its lack of teeth, any toothless pterosaur jaw fragment, wherever it was found in the world, tended to be attributed to \"Pteranodon\" during the late nineteenth and early twentieth centuries. This resulted in a plethora of species and a great deal of confusion. The name became a wastebasket taxon, rather like the dinosaur \"Megalosaurus\", to label any pterosaur remains that could not be distinguished other than by the absence of teeth. Species (often dubious ones now known to be based on sexual variation or juvenile characters) have been reclassified a number of times, and several subgenera have in the 1970s been erected by Halsey Wilkinson Miller to hold them in various combinations, further confusing the taxonomy (subgenera include \"Longicepia\", \"Occidentalia\", and \"Geosternbergia\"). Notable authors who have discussed the various aspects of \"Pteranodon\" include Bennett, Padian, Unwin, Kellner, and Wellnhofer. Two species, \"P. oregonensis\" and \"P. orientalis\", are not pteranodontids and have been renamed \"Bennettazhia oregonensis\" and \"Bogolubovia orientalis\" respectively.\nList of species and synonyms.\nStatus of names listed below follow a survey by Bennett, 1994 unless otherwise noted.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24826", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=24826", "title": "Passive voice", "text": "Grammatical construction\nA passive voice construction is a grammatical voice construction that is found in many languages. In a clause with passive voice, the grammatical subject expresses the \"theme\" or \"patient\" of the main verb \u2013 that is, the person or thing that undergoes the action or has its state changed. This contrasts with active voice, in which the subject has the agent role. For example, in the passive sentence \"The tree was pulled down\", the subject (\"the tree\") denotes the patient rather than the agent of the action. In contrast, the sentences \"Someone pulled down the tree\" and \"The tree is down\" are active sentences.\nTypically, in passive clauses, what is usually expressed by the object (or sometimes another argument) of the verb is now expressed by the subject, while what is usually expressed by the subject is either omitted or is indicated by some adjunct of the clause. Thus, turning an active sense of a verb into a passive sense is a valence-decreasing process (\"detransitivizing process\"), because it syntactically turns a transitive sense into an intransitive sense. This is not always the case; for example in Japanese a passive-voice construction does not necessarily decrease valence.\nMany languages have both an active and a passive voice; this allows for greater flexibility in sentence construction, as either the semantic agent or patient may take the syntactic role of subject. The use of passive voice allows speakers to organize stretches of discourse by placing figures other than the agent in subject position. This may be done to foreground the patient, recipient, or other thematic role; it may also be useful when the semantic patient is the topic of on-going discussion. The passive voice may also be used to avoid specifying the agent of an action.\nPassive marking.\nDifferent languages use various grammatical forms to indicate passive voice.\nIn some languages, passive voice is indicated by verb conjugation, specific forms of the verb. Examples of languages that indicate voice through conjugation include Greek, Latin, and North Germanic languages such as Swedish.\nNorwegian (Nynorsk) and Icelandic have a similar system, but the usage of the passive is more restricted. The passive forms in Nynorsk are restricted to being accompanied by an auxiliary verb, which is not the case in Swedish and Danish.\nNynorsk uses \"\u00e5 verte\" or \"\u00e5 bli\" + past participle for passive voice, and Swedish and Danish use the passive suffix \"-s\" and Icelandic uses \"a\u00f0 ver\u00f0a\" or \"a\u00f0 vera\" + past participle or \"-st\" suffix for middle voice. \nIn Latin, the agent of a passive sentence (if indicated) is expressed using a noun in the ablative case, in this case (the ablative of ). Different languages use different methods for expressing the agent in passive clauses. In Swedish, the agent can be expressed by means of a prepositional phrase with the preposition (equivalent here to the English \"by\").\nThe Austronesian language Kimaragang Dusun also indicates passive voice by verb conjugation using the infix, .\nOther languages, including English, express the passive voice periphrastically, using an auxiliary verb.\nIn English.\nEnglish, like some other languages, uses a periphrastic passive. Rather than conjugating directly for voice, English uses the past participle form of the verb plus an auxiliary verb, either \"be\" or \"get\" (called linking verbs in traditional grammar), to indicate passive voice.\nIf the agent is mentioned, it usually appears in a prepositional phrase introduced by the preposition \"by\".\nThe subject of the passive voice usually corresponds to the direct object of the corresponding active-voice formulation (as in the above examples), but English also allows passive constructions in which the subject corresponds to an indirect object or preposition complement:\nIn sentences of the second type, a stranded preposition is left. This is called the \"prepositional passive\" or \"pseudo-passive\" (although the latter term can also be used with other meanings).\nThe active voice is the dominant voice used in English. Many commentators, notably George Orwell in his essay \"Politics and the English Language\" and Strunk &amp; White in \"The Elements of Style\", have urged minimizing use of the passive voice, but this is almost always based on these commentators' misunderstanding of what the passive voice is. Contrary to common critiques, the passive voice has important uses, with virtually all writers using the passive voice (including Orwell and Strunk &amp; White).\nThere is general agreement that the passive voice is useful for emphasis or when the receiver of the action is more important than the actor.\n\"Merriam\u2013Webster's Dictionary of English Usage\" refers to three statistical studies of passive versus active sentences in various periodicals, stating: \"the highest incidence of passive constructions was 13 percent. Orwell runs to a little over 20 percent in \"Politics and the English Language\". Clearly he found the construction useful in spite of his advice to avoid it as much as possible\".\nDefining \"passive\".\nIn the field of linguistics, the term \"passive\" is applied to a wide range of grammatical structures. Linguists therefore find it difficult to define the term in a way that makes sense across all human languages. The canonical passive in European languages has the following properties:\nThe problem arises with non-European languages. Many constructions in these languages share at least one property with the canonical European passive, but not all. While it seems justified to call these constructions \"passive\" when comparing them to European languages' passive constructions, as a whole the passives of the world's languages do not share a single common feature.\nR. M. W. Dixon has defined four criteria for determining whether a construction is a passive:\nDixon acknowledges that this excludes some constructions labeled as \"passive\" by some linguists.\nAdversative passive.\nIn some languages, including several Southeast Asian languages, the passive voice is sometimes used to indicate that an action or event was unpleasant or undesirable. This so-called \"adversative passive\" works like the ordinary passive voice in terms of syntactic structure\u2014that is, a theme or instrument acts as subject. In addition, the construction indicates adversative affect, suggesting that someone was negatively affected.\nIn Japanese, for example, the adversative passive (also called indirect passive) indicates adversative affect. The indirect or adversative passive has the same form as the direct passive. Unlike the direct passive, the indirect passive may be used with intransitive verbs.\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\nYup'ik, from the Eskimo\u2013Aleut family, has two different suffixes that can indicate passive, \"-cir-\" and \"-ma-\". The morpheme \"-cir-\" has an adversative meaning. If an agent is included in a passive sentence with the \"-cir\" passive, the noun is usually in the allative (oblique) case.\n&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\nStative and dynamic passive.\nIn some languages, for example English, there is often a similarity between clauses expressing an action or event in the passive voice and clauses expressing a state. For example, the string of words \"The dog is fed\" can have the following two different meanings:\nThe additions in parentheses \"force\" the same string of words to clearly show only one of their two possible grammatical functions and the related meaning. In the first sentence, the combination of the auxiliary verb \"is\" and the past participle \"fed\" is a regular example of the construction of the passive voice in English. In the second sentence, \"is\" can however be interpreted as an ordinary copula and the past participle as an adjective.\nSentences of the second type are called \"false passives\" by some linguists, who feel that such sentences are simply confused with the passive voice due to their outward similarity. Other linguists consider the second type to be a different kind of passive \u2013 a \"stative passive\" (rarely called \"statal\", \"static\", or \"resultative passive\"), in contrast to the \"dynamic\" or \"eventive\" passive illustrated by the first sentence. Some languages express or can express these different meanings using different constructions.\nThe difference between dynamic and stative passives is more evident in languages such as German that use different words or constructions for the two. In German, the auxiliary verb marks static passive (German: , rarely , in referring to German also called or ), while marks the dynamic passive ( or , rarely , in referring to German also called or or simply or ).\nThe English string of words \"the lawn is mown\" has two possible meanings corresponding to the example \"the dog is fed\" above. It can be used in the following two different senses:\nGerman uses two different grammatical constructions for these sentences:\nFurther examples and explanations:\nA number of German verbs such as (\"cover\"), (\"fill\"), and (\"separate\"), when used as stative verbs, usually only form static passives.\n- (\"Snow covers the ground\", active)\n- (\"The ground is covered with snow\", static)\n- rare, poetic: (\"The ground is being covered with snow\", dynamic)\n- but not: * (The English equivalent would be equally incorrect: *\"The street is being covered with rubble.\") \n- correct: (\"The street is covered with rubble.\")\nIn English, the passive voice expressed with the auxiliary verb \"get\" rather than \"be\" (\"get-passive\") expresses a dynamic rather than a static meaning. But when the auxiliary verb \"be\" is used, the main verb can have either a dynamic or static meaning as shown below (including copies of some examples from above):\nThe dog \"gets fed\" twice a day. (dynamic)\nThe dog \"is fed\" (twice a day). (dynamic)\nThe dog \"is fed\" (so we can leave now). (stative)\nThe couple \"got married\" last spring. (dynamic)\nThe marriage \"was celebrated\" last spring. (dynamic)\nIt \"is agreed\" that laws were invented for the safety of citizens. (stative)\nVerbs that typically express static meaning can show dynamic meaning when used in the passive formed with \"get\", for example \"be known\" (static) vs. \"get known\" (dynamic):\nZoltan \"is known\" for hosting big parties. (static)\nGet your foot in the door, \"get known\". (dynamic)\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24828", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=24828", "title": "Pesistratus", "text": ""}
{"id": "24829", "revid": "50439069", "url": "https://en.wikipedia.org/wiki?curid=24829", "title": "Primitive recursive function", "text": "Function computable with bounded loops\nIn computability theory, a primitive recursive function is, roughly speaking, a function that can be computed by a computer program whose loops are all \"for\" loops (that is, an upper bound of the number of iterations of every loop is fixed before entering the loop). Primitive recursive functions form a strict subset of those general recursive functions that are also total functions.\nThe importance of primitive recursive functions lies in the fact that most computable functions that are studied in number theory (and more generally in mathematics) are primitive recursive. For example, addition and division, the factorial and exponential function, and the function which returns the \"n\"th prime are all primitive recursive. In fact, for showing that a computable function is primitive recursive, it suffices to show that its time complexity is bounded above by a primitive recursive function of the input size. It is hence not particularly easy to devise a computable function that is \"not\" primitive recursive; some examples are shown in section below.\nThe set of primitive recursive functions is known as PR in computational complexity theory.\nDefinition.\nA primitive recursive function takes a fixed number of arguments, each a natural number (nonnegative integer: {0, 1, 2, ...}), and returns a natural number. If it takes \"n\" arguments it is called \"n\"-ary.\nThe basic primitive recursive functions are given by these axioms:\nMore complex primitive recursive functions can be obtained by applying the operations given by these axioms:\nformula_12\n\"Interpretation:\"\nThe function formula_13 acts as a for-loop from formula_14 up to the value of its first argument. The rest of the arguments for formula_13, denoted here with formula_16, are a set of initial conditions for the for-loop which may be used by it during calculations but which are immutable by it. The functions formula_17 and formula_18 on the right-hand side of the equations that define formula_13 represent the body of the loop, which performs calculations. The function formula_17 is used only once to perform initial calculations. Calculations for subsequent steps of the loop are performed by formula_18. The first parameter of formula_18 is fed the \"current\" value of the for-loop's index. The second parameter of formula_18 is fed the result of the for-loop's previous calculations, from previous steps. The rest of the parameters for formula_18 are those immutable initial conditions for the for-loop mentioned earlier. They may be used by formula_18 to perform calculations but they will not themselves be altered by formula_18.\nThe primitive recursive functions are the basic functions and those obtained from the basic functions by applying these operations a finite number of times.\nPrimitive-recursiveness of vector-valued functions.\nA (vector-valued) function formula_27 is primitive recursive if it can be written as\nformula_28\nwhere each component formula_29 is a (scalar-valued) primitive recursive function.\nExamples.\nAddition.\nA definition of the 2-ary function formula_30, to compute the sum of its arguments, can be obtained using the primitive recursion operator formula_8. To this end, the well-known equations \nformula_32\nare \"rephrased in primitive recursive function terminology\": In the definition of formula_33, the first equation suggests to choose formula_34 to obtain formula_35; the second equation suggests to choose formula_36 to obtain formula_37. Therefore, the addition function can be defined as formula_38. As a computation example,\nformula_39\nDoubling.\nGiven formula_30, the 1-ary function formula_41 doubles its argument, formula_42.\nMultiplication.\nIn a similar way as addition, multiplication can be defined by formula_43. This reproduces the well-known multiplication equations: \nformula_44 \nand \nformula_45\nPredecessor.\nThe predecessor function acts as the \"opposite\" of the successor function and is recursively defined by the rules formula_46 and formula_47. A primitive recursive definition is formula_48. As a computation example,\nformula_49\nTruncated subtraction.\nThe limited subtraction function (also called \"monus\", and denoted \"formula_50\") is definable from the predecessor function. It satisfies the equations \nformula_51\nSince the recursion runs over the second argument, we begin with a primitive recursive definition of the reversed subtraction, formula_52. Its recursion then runs over the first argument, so its primitive recursive definition can be obtained, similar to addition, as formula_53. To get rid of the reversed argument order, then define formula_54. As a computation example,\nformula_55\nConverting predicates to numeric functions.\nIn some settings it is natural to consider primitive recursive functions that take as inputs tuples that mix numbers with truth values (that is formula_56 for true and formula_13 for false), or that produce truth values as outputs. This can be accomplished by identifying the truth values with numbers in any fixed manner. For example, it is common to identify the truth value formula_56 with the number formula_59 and the truth value formula_13 with the number formula_14. Once this identification has been made, the characteristic function of a set formula_62, which always returns formula_59 or formula_14, can be viewed as a predicate that tells whether a number is in the set formula_62. Such an identification of predicates with numeric functions will be assumed for the remainder of this article.\nPredicate \"Is zero\".\nAs an example for a primitive recursive predicate, the 1-ary function formula_66 shall be defined such that formula_67 if formula_68, and \nformula_69, otherwise. This can be achieved by defining formula_70. Then, formula_71 and e.g. formula_72.\nPredicate \"Less or equal\".\nUsing the property formula_73, the 2-ary function formula_74 can be defined by formula_75. Then formula_76 if formula_77, and formula_78, otherwise. As a computation example,\nformula_79\nPredicate \"Greater or equal\".\nOnce a definition of formula_74 is obtained, the converse predicate can be defined as formula_81. Then, formula_82 is true (more precisely: has value 1) if, and only if, formula_83.\nIf-then-else.\nThe 3-ary if-then-else operator known from programming languages can be defined by formula_84. Then, for arbitrary formula_85,\nformula_86\nand \nformula_87.\nThat is, formula_88 returns the then-part, formula_89, if the if-part, formula_85, is true, and the else-part, formula_91, otherwise.\nJunctors.\nBased on the formula_92 function, it is easy to define logical junctors. For example, defining formula_93, one obtains formula_94, that is, formula_95 is true if, and only if, both formula_85 and formula_89 are true (logical conjunction of formula_85 and formula_89).\nSimilarly, formula_100 and formula_101 lead to appropriate definitions of disjunction and negation: formula_102 and formula_103.\nEquality predicate.\nUsing the above functions formula_74, formula_105 and formula_106, the definition formula_107 implements the equality predicate. In fact, formula_108 is true if, and only if, formula_85 equals formula_89.\nSimilarly, the definition formula_111 implements the predicate \"less-than\", and formula_112 implements \"greater-than\".\nOther operations on natural numbers.\nExponentiation and primality testing are primitive recursive. Given primitive recursive functions formula_113, formula_13, formula_17, and formula_18, a function that returns the value of formula_17 when formula_118 and the value of formula_18 otherwise is primitive recursive.\nOperations on integers and rational numbers.\nBy using G\u00f6del numberings, the primitive recursive functions can be extended to operate on other objects such as integers and rational numbers. If integers are encoded by G\u00f6del numbers in a standard way, the arithmetic operations including addition, subtraction, and multiplication are all primitive recursive. Similarly, if the rationals are represented by G\u00f6del numbers then the field operations are all primitive recursive.\nSome common primitive recursive functions.\nThe following examples and definitions are from . Many appear with proofs. Most also appear with similar names, either as proofs or as examples, in they add the logarithm lo(x, y) or lg(x, y) depending on the exact derivation.\nIn the following the mark \" ' \", e.g. a', is the primitive mark meaning \"the successor of\", usually thought of as \" +1\", e.g. a +1 =def a'. The functions 16\u201320 and #G are of particular interest with respect to converting primitive recursive predicates to, and extracting them from, their \"arithmetical\" form expressed as G\u00f6del numbers.\n# Addition: a+b\n# Multiplication: a\u00d7b\n# Exponentiation: ab\n# Factorial a! : 0! = 1, a'! = a!\u00d7a'\n# pred(a): (Predecessor or decrement): If a &gt; 0 then a\u22121 else 0\n# Proper subtraction a \u2238 b: If a \u2265 b then a\u2212b else 0\n# Minimum(a1, ... an)\n# Maximum(a1, ... an)\n# Absolute difference: | a\u2212b | =def (a \u2238 b) + (b \u2238 a)\n# ~sg(a): NOT[signum(a)]: If a=0 then 1 else 0\n# sg(a): signum(a): If a=0 then 0 else 1\n# a | b: (a divides b): If b=k\u00d7a for some k then 0 else 1\n# Remainder(a, b): the leftover if b does not divide a \"evenly\". Also called MOD(a, b)\n# a = b: sg | a \u2212 b | (Kleene's convention was to represent \"true\" by 0 and \"false\" by 1; presently, especially in computers, the most common convention is the reverse, namely to represent \"true\" by 1 and \"false\" by 0, which amounts to changing sg into ~sg here and in the next item)\n# a &lt; b: sg( a' \u2238 b )\n# Pr(a): a is a prime number Pr(a) =def a&gt;1 &amp; NOT(Exists c)1&lt;c [ c|a ]\n# pi: the i+1th prime number\n# (a)i: exponent of pi in a: the unique x such that pix|a &amp; NOT(pix'|a)\n# lh(a): the \"length\" or number of non-vanishing exponents in a\n# lo(a, b): (logarithm of a to base b): If a, b &gt; 1 then the greatest x such that bx | a else 0\n \"In the following, the abbreviation x =def x1, ... xn; subscripts may be applied if the meaning requires.\"\n* NOT_Q(x) .\n* Q OR R: Q(x) V R(x),\n* Q AND R: Q(x) &amp; R(x),\n* Q IMPLIES R: Q(x) \u2192 R(x)\n* Q is equivalent to R: Q(x) \u2261 R(x)\n* (Ey)y&lt;z R(x, y) where (Ey)y&lt;z denotes \"there exists at least one y that is less than z such that\"\n* (y)y&lt;z R(x, y) where (y)y&lt;z denotes \"for all y less than z it is true that\"\n* \u03bcyy&lt;z R(x, y). The operator \u03bcyy&lt;z R(x, y) is a \"bounded\" form of the so-called minimization- or mu-operator: Defined as \"the least value of y less than z such that R(x, y) is true; or z if there is no such value.\"\n \u03c6(x) =\n* \u03c61(x) if Q1(x) is true,\n* \u03c6m(x) if Qm(x) is true\n* \u03c6m+1(x) otherwise\n \u03c6(y,x) = \u03c7(y, COURSE-\u03c6(y; x2, ... xn ), x2, ... xn then \u03c6 is primitive recursive in \u03c7. The value COURSE-\u03c6(y; x2 to n ) of the course-of-values function encodes the sequence of values \u03c6(0,x2 to n), ..., \u03c6(y-1,x2 to n) of the original function.\nRelationship to recursive functions.\nThe broader class of partial recursive functions is defined by introducing an unbounded search operator. The use of this operator may result in a partial function, that is, a relation which has \"at most\" one value for each argument, but which may \"fail\" to have a value at some arguments (see domain). An equivalent definition states that a partial recursive function is one that can be computed by a Turing machine. A total recursive function is a partial recursive function that is defined for every input.\nEvery primitive recursive function is total recursive, but not all total recursive functions are primitive recursive. The Ackermann function \"A\"(\"m\",\"n\") is a well-known example of a total recursive function (in fact, provable total), that is not primitive recursive. There is a characterization of the primitive recursive functions as a subset of the total recursive functions using the Ackermann function. This characterization states that a function is primitive recursive if and only if there is a natural number \"m\" such that the function can be computed by a Turing machine that always halts within A(\"m\",\"n\") or fewer steps, where \"n\" is the sum of the arguments of the primitive recursive function.\nAn important property of the primitive recursive functions is that they are a recursively enumerable subset of the set of all total recursive functions (which is not itself recursively enumerable). This means that there is a single recursive function \"f\"(\"m\",\"n\") that enumerates the primitive recursive functions, namely:\n\"f\" can be explicitly constructed by iteratively repeating all possible ways of creating primitive recursive functions. Thus, it is provably total. One can use a diagonalization argument to show that \"f\" is not recursive primitive in itself: had it been such, so would be \"h\"(\"n\") = \"f\"(\"n\",\"n\")+1. But if this equals some primitive recursive function, there is an \"m\" such that \"h\"(\"n\") = \"f\"(\"m\",\"n\") for all \"n\", and then \"h\"(\"m\") = \"f\"(\"m\",\"m\"), leading to contradiction.\nHowever, the set of primitive recursive functions is not the \"largest\" recursively enumerable subset of the set of all total recursive functions. For example, the set of provably total functions (in Peano arithmetic) is also recursively enumerable, as one can enumerate all the proofs of the theory. While all primitive recursive functions are provably total, the converse is not true.\nLimitations.\nPrimitive recursive functions tend to correspond very closely with our intuition of what a computable function must be. Certainly the initial functions are intuitively computable (in their very simplicity), and the two operations by which one can create new primitive recursive functions are also very straightforward. However, the set of primitive recursive functions does not include every possible total computable function\u2014this can be seen with a variant of Cantor's diagonal argument. This argument provides a total computable function that is not primitive recursive. A sketch of the proof is as follows:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;The primitive recursive functions of one argument (i.e., unary functions) can be computably enumerated. This enumeration uses the definitions of the primitive recursive functions (which are essentially just expressions with the composition and primitive recursion operations as operators and the basic primitive recursive functions as atoms), and can be assumed to contain every definition once, even though a same \"function\" will occur many times on the list (since many definitions define the same function; indeed simply composing by the identity function generates infinitely many definitions of any one primitive recursive function). This means that the formula_120-th definition of a primitive recursive function in this enumeration can be effectively determined from formula_120. Indeed if one uses some G\u00f6del numbering to encode definitions as numbers, then this formula_120-th definition in the list is computed by a primitive recursive function of formula_120. Let formula_124 denote the unary primitive recursive function given by this definition.\nNow define the \"evaluator function\" formula_125 with two arguments, by formula_126. Clearly formula_125 is total and computable, since one can effectively determine the definition of formula_128, and being a primitive recursive function formula_128 is itself total and computable, so formula_130 is always defined and effectively computable. However a diagonal argument will show that the function formula_125 of two arguments is not primitive recursive.\nSuppose formula_125 were primitive recursive, then the unary function formula_17 defined by formula_134 would also be primitive recursive, as it is defined by composition from the successor function and formula_125. But then formula_17 occurs in the enumeration, so there is some number formula_120 such that formula_138. But now formula_139 gives a contradiction.\nThis argument can be applied to any class of computable (total) functions that can be enumerated in this way, as explained in the article Machine that always halts. Note however that the \"partial\" computable functions (those that need not be defined for all arguments) can be explicitly enumerated, for instance by enumerating Turing machine encodings.\nOther examples of total recursive but not primitive recursive functions are known:\nVariants.\nConstant functions.\nInstead of formula_140,\nalternative definitions use just one 0-ary \"zero function\" formula_141 as a primitive function that always returns zero, and build the constant functions from the zero function, the successor function and the composition operator.\nIterative functions.\nRobinson considered various restrictions of the recursion rule. One is the so-called \"iteration rule\" where the function \"h\" does not have access to the parameters \"xi\" (in this case, we may assume without loss of generality that the function \"g\" is just the identity, as the general case can be obtained by substitution):\nformula_142\nHe proved that the class of all primitive recursive functions can still be obtained in this way.\nPure recursion.\nAnother restriction considered by Robinson is \"pure recursion\", where \"h\" does not have access to the induction variable \"y\":\nformula_143\nGladstone proved that this rule is enough to generate all primitive recursive functions. Gladstone improved this so that even the combination of these two restrictions, i.e., the \"pure iteration\" rule below, is enough:\nformula_144\nFurther improvements are possible: Severin prove that even the pure iteration rule \"without parameters\", namely\nformula_145\nsuffices to generate all unary primitive recursive functions if we extend the set of initial functions with truncated subtraction \"x \u2238 y\". We get \"all\" primitive recursive functions if we additionally include + as an initial function.\nAdditional primitive recursive forms.\nSome additional forms of recursion also define functions that are in fact\nprimitive recursive. Definitions in these forms may be easier to find or\nmore natural for reading or writing. Course-of-values recursion defines primitive recursive functions. Some forms of mutual recursion also define primitive recursive functions.\nThe functions that can be programmed in the LOOP programming language are exactly the primitive recursive functions. This gives a different characterization of the power of these functions. The main limitation of the LOOP language, compared to a Turing-complete language, is that in the LOOP language the number of times that each loop will run is specified before the loop begins to run.\nComputer language definition.\nAn example of a primitive recursive programming language is one that contains basic arithmetic operators (e.g. + and \u2212, or ADD and SUBTRACT), conditionals and comparison (IF-THEN, EQUALS, LESS-THAN), and bounded loops, such as the basic for loop, where there is a known or calculable upper bound to all loops (FOR i FROM 1 TO n, with neither i nor n modifiable by the loop body). No control structures of greater generality, such as while loops or IF-THEN plus GOTO, are admitted in a primitive recursive language.\nThe LOOP language, introduced in a 1967 paper by Albert R. Meyer and Dennis M. Ritchie, is such a language. Its computing power coincides with the primitive recursive functions. A variant of the LOOP language is Douglas Hofstadter's BlooP in \"G\u00f6del, Escher, Bach\". Adding unbounded loops (WHILE, GOTO) makes the language general recursive and Turing-complete, as are all real-world computer programming languages.\nThe definition of primitive recursive functions implies that their computation halts on every input (after a finite number of steps). On the other hand, the halting problem is undecidable for general recursive functions.\nFinitism and consistency results.\nThe primitive recursive functions are closely related to mathematical finitism, and are used in several contexts in mathematical logic where a particularly constructive system is desired. Primitive recursive arithmetic (PRA), a formal axiom system for the natural numbers and the primitive recursive functions on them, is often used for this purpose.\nPRA is much weaker than Peano arithmetic, which is not a finitistic system. Nevertheless, many results in number theory and in proof theory can be proved in PRA. For example, G\u00f6del's incompleteness theorem can be formalized into PRA, giving the following theorem:\nIf \"T\" is a theory of arithmetic satisfying certain hypotheses, with G\u00f6del sentence \"G\"\"T\", then PRA proves the implication Con(\"T\")\u2192\"G\"\"T\".\nSimilarly, many of the syntactic results in proof theory can be proved in PRA, which implies that there are primitive recursive functions that carry out the corresponding syntactic transformations of proofs.\nIn proof theory and set theory, there is an interest in finitistic consistency proofs, that is, consistency proofs that themselves are finitistically acceptable. Such a proof establishes that the consistency of a theory \"T\" implies the consistency of a theory \"S\" by producing a primitive recursive function that can transform any proof of an inconsistency from \"S\" into a proof of an inconsistency from \"T\". One sufficient condition for a consistency proof to be finitistic is the ability to formalize it in PRA. For example, many consistency results in set theory that are obtained by forcing can be recast as syntactic proofs that can be formalized in PRA.\nHistory.\nRecursive definitions had been used more or less formally in mathematics before, but the construction of primitive recursion is traced back to Richard Dedekind's theorem 126 of his \"Was sind und was sollen die Zahlen?\" (1888). This work was the first to give a proof that a certain recursive construction defines a unique function.\nPrimitive recursive arithmetic was first proposed by Thoralf Skolem in 1923.\nThe current terminology was coined by R\u00f3zsa P\u00e9ter (1934) after Ackermann had proved in 1928 that the function which today is named after him was not primitive recursive, an event which prompted the need to rename what until then were simply called recursive functions.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24830", "revid": "87355", "url": "https://en.wikipedia.org/wiki?curid=24830", "title": "Peisistratus (disambiguation)", "text": "Peisistratus was a tyrant of Athens, Greece, three different times between 561 and 528 BC.\nPeisistratus, Peisistratos or Pisistratus may also refer to:\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about people with the same name. "}
{"id": "24833", "revid": "635492", "url": "https://en.wikipedia.org/wiki?curid=24833", "title": "Prime Minister of Japan", "text": "Head of government of Japan\nThe is the head of government of Japan. The prime minister chairs the Cabinet of Japan and has the ability to select and dismiss its ministers of state. The prime minister also serves as the commander-in-chief of the Japan Self Defence Forces. The incumbent[ [update]] prime minister, Sanae Takaichi, took office on 21 October 2025; she is the first woman to serve as either president of the Liberal Democratic Party or prime minister.\nThe National Diet (parliament) nominates the prime minister from among its members (typically from among the members of the House of Representatives). They are then formally appointed by the emperor. The prime minister must retain the confidence of the House of Representatives to remain in office. The prime minister lives and works at the Naikaku S\u014dri Daijin Kantei (Prime Minister's Official Residence) in Nagatach\u014d, Chiyoda, Tokyo, close to the National Diet Building. \nSixty-six people (sixty-five men and one woman) have served as prime minister, the first of whom was It\u014d Hirobumi taking office on 22 December 1885. The longest-serving prime minister was Shinzo Abe, who served over eight years across two non-consecutive terms, and the shortest-serving was Prince Naruhiko Higashikuni, who served fifty-four days.\nDesignation.\nAbbreviations.\nIn Japanese, due to the special nature of the work of the head of government, the prime minister's titles vary depending on context, sometimes demonstrating their role. Since the inception of the cabinet system, the prime minister is known in Japanese as \"Naikaku S\u014dri-Daijin\" (\u5185\u95a3\u7dcf\u7406\u5927\u81e3) whenever they are referred to as the head of the Cabinet. However, this title is usually abbreviated to \"S\u014dri-Daijin\" (\u7dcf\u7406\u5927\u81e3). Other abbreviations include \"S\u014dri\" (\u7dcf\u7406), \"Shush\u014d\" (\u9996\u76f8) or even \"Saish\u014d\" (\u5bb0\u76f8).\nEnglish notation.\nThe official English rendering is 'Prime Minister'. This English translation was informally used as the English translation of 'Grand Minister' before the introduction of the cabinet system. However, this was not the original English translation of 'Prime Minister', and a German translation, 'Minister President of the State', was also used in the past.\nHistory.\nBefore the adoption of the Meiji Constitution, Japan had in practice no written constitution. Originally, a Chinese-inspired legal system known as \"ritsury\u014d\" was enacted in the late Asuka period and early Nara period. It described a government based on an elaborate and rational meritocratic bureaucracy, serving, in theory, under the ultimate authority of the emperor; although in practice, real power was often held elsewhere, such as in the hands of the Fujiwara clan, who intermarried with the imperial family in the Heian period, or by the ruling \"sh\u014dgun\". Theoretically, the last \"ritsury\u014d\" code, the Y\u014dr\u014d Code enacted in 752, was still in force at the time of the Meiji Restoration.\nUnder this system, the was the head of the \"Daij\u014d-kan\" (Department of State), the highest organ of Japan's pre-modern Imperial government during the Heian period and until briefly under the Meiji Constitution with the appointment of Sanj\u014d Sanetomi in 1871. The office was replaced in 1885 with the appointment of It\u014d Hirobumi to the new position of Minister President of State, four years before the enactment of the Meiji Constitution, which mentions neither the Cabinet nor the position of Prime Minister explicitly. It took its current form with the adoption of the Constitution of Japan in 1947.\nTo date, sixty-six people have served in this position. The longest-serving prime minister to date is Shinzo Abe, who served in two non-consecutive terms for 8 years, 267 days: from 26 September 2006 until 26 September 2007, and from 26 December 2012 until 16 September 2020. The shortest-serving prime minister to date is Prince Naruhiko Higashikuni, who served for fifty-four days: from 17 August until 9 October 1945.\nAppointment.\nThe prime minister is nominated by both houses of the Diet, before the conduct of any other business. Each house conducts a ballot under the run-off system. If the two houses choose different individuals, then a joint committee of both houses is appointed to agree on a common nominee. Ultimately, however, if the two houses do not agree, or if the House of Councillors does not make a nomination within 10 days after the House of Representatives vote, the nominee of the House of Representatives is deemed to be that of the Diet. Therefore, the House of Representatives can theoretically ensure the appointment of any prime minister it wants. The nominee is then formally appointed to office and presented with their appointment letter by the emperor at the Tokyo Imperial Palace.\nConventionally, since the prime minister must maintain the confidence of the Diet to stay in office, they are almost always the leader of the majority party in the House of Representatives or the leader of the senior partner in the governing coalition. But there have been three cabinet prime ministers from junior coalition partners (Hitoshi Ashida: 1948, Morihiro Hosokawa: 1993 and Tomiichi Murayama: 1994), a few minority governments (most recently the Hata Cabinet in 1994 and at least numerically the Second Hashimoto Cabinet of 1996 during its first year, but with an extra-cabinet cooperation (\u95a3\u5916\u5354\u529b, \"kakugai ky\u014dryoku\") agreement with two parties, sufficient to ensure safe majorities for most government initiatives), and several cabinets with a majority in the House of Representatives, but without legislative majority of their own (most recently the DPJ-led cabinets, Kan and Noda Cabinets after the 2010 upper house election; cf. \"Nejire Kokkai\"/\"twisted Diets\").\nRole.\nStatutory roles.\nUnlike most of their counterparts in constitutional monarchies, the prime minister is both \"de jure\" and \"de facto\" chief executive. In most other constitutional monarchies, the monarch is at least nominal chief executive, while being bound by convention to act on the advice of the cabinet. In contrast, the Constitution of Japan explicitly vests executive power in the Cabinet, of which the prime minister is the leader; this greatly enhances the prime minister's position compared to prime ministers in other parliamentary democracies. Their countersignature is required for all laws and Cabinet orders. While most ministers in parliamentary democracies have some freedom of action within the bounds of cabinet collective responsibility, the Japanese Cabinet is effectively an extension of the prime minister's authority.\nOfficial office and residence.\nLocated near the Diet building, the Office of the Prime Minister of Japan is called the . The original Kantei served from 1929 until 2002, when a new building was inaugurated to serve as the current Kantei. The old Kantei was then converted into the Official Residence, or . The K\u014dtei lies to the southwest of the Kantei, and is linked by a walkway.\nTravel.\nThe prime minister of Japan travels in a Toyota Century. The Lexus LS 600h L, which served as the prime minister's official car from 2008 to 2019, became a spare/alternative vehicle used by the Prime Minister. \nFor overseas air travel, the Japanese government maintains two Boeing 777, which replaced the Boeing 747-400 also in 2019. The aircraft is also used by the emperor, the members of the imperial family, and other high-ranking officials.\nThey have the radio callsigns Japanese Air Force One and Japanese Air Force Two when operating on official business, and Cygnus One and Cygnus Two when operating outside of official business (e.g., on training flights). The aircraft always fly together on government missions, with one serving as the primary transport and the other serving as a backup with maintenance personnel on board. The aircraft are officially referred to as .\nRetirement honours and emoluments.\nUntil the mid-1930s, the prime minister of Japan was normally granted a hereditary peerage (\"kazoku\") prior to leaving office if they had not already been ennobled. Titles were usually bestowed in the ranks of count, viscount or baron, depending on the relative accomplishments and status of the prime minister. The two highest ranks, marquess and prince, were only bestowed upon highly distinguished statesmen, and were not granted to a prime minister after 1928. The last prime minister who was a peer was Baron Kij\u016br\u014d Shidehara, who served as Prime Minister from October 1945 to May 1946. The peerage was abolished when the Constitution of Japan came into effect in May 1947.\nCertain eminent prime ministers have been awarded the Order of the Chrysanthemum, typically in the degree of Grand Cordon. The highest honour in the Japanese honours system, the Collar of the Order of the Chrysanthemum, has only been conferred upon select prime ministers and eminent statesmen; the last such award to a living prime minister was to Saionji Kinmochi in 1928. More often, the Order of the Chrysanthemum has been a posthumous distinction; both the Collar and Grand Cordon of the order were last awarded posthumously to former prime minister Shinzo Abe in July 2022.\nAfter relinquishing office, the prime minister is normally accorded the second or senior third rank in the court order of precedence, and is usually raised to the senior second rank posthumously. Certain distinguished prime ministers have been posthumously raised to the first rank; the last such award was to Eisaku Sato in 1975. Since the 1920s, following their tenure in office, prime ministers have typically been conferred with the Grand Cordon of the Order of the Paulownia Flowers (until 2003 a special higher class of the Order of the Rising Sun), depending on tenure and eminence. However, honours may be withheld due to misconduct or refusal on the part of the prime minister (for example, Kiichi Miyazawa).\nThe Prime Minister also awards individuals in recognition of their accomplishments in sport, entertainment, and other fields. Some of the awards and commendations offered include the Prime Minister's Award, created by Eisaku Sat\u014d in 1966, and the People's Honour Award, created by Takeo Fukuda in 1977. Additionally, the PM also presents the Prime Minister's Trophy on behalf of the Japan Professional Sports Association and the Monodzukuri Nippon award on behalf of the Japanese Manufacturing Association.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24834", "revid": "18174831", "url": "https://en.wikipedia.org/wiki?curid=24834", "title": "Protein targeting", "text": "Biological mechanism for routing proteins\nProtein targeting or protein sorting is the biological mechanism by which proteins are transported to their appropriate destinations within or outside the cell. Proteins can be targeted to the inner space of an organelle, different intracellular membranes, the plasma membrane, or to the exterior of the cell via secretion. Information contained in the protein itself directs this delivery process. Correct sorting is crucial for the cell; errors or dysfunction in sorting have been linked to multiple diseases.\nHistory.\nIn 1970, G\u00fcnter Blobel conducted experiments on protein translocation across membranes. Blobel, then an assistant professor at Rockefeller University, built upon the work of his colleague George Palade. Palade had previously demonstrated that non-secreted proteins were translated by free ribosomes in the cytosol, while secreted proteins (and target proteins, in general) were translated by ribosomes bound to the endoplasmic reticulum (ER). Candidate explanations at the time postulated a processing difference between free and ER-bound ribosomes, but Blobel hypothesized that protein targeting relied on characteristics inherent to the proteins, rather than a difference in ribosomes. Supporting his hypothesis, Blobel discovered that many proteins have a short amino acid sequence at one end that functions like a postal code specifying an intracellular or extracellular destination. He described these short sequences (generally 13 to 36 amino acids residues) as signal peptides or signal sequences and was awarded the 1999 Nobel prize in Physiology for the same.\nSignal peptides.\nSignal peptides serve as targeting signals, enabling cellular transport machinery to direct proteins to specific intracellular or extracellular locations. While no consensus sequence has been identified for signal peptides, many nonetheless possess a characteristic tripartite structure:\nAfter a protein has reached its destination, the signal peptide is generally cleaved by a signal peptidase. Consequently, most mature proteins do not contain signal peptides. While most signal peptides are found at the N-terminal, in peroxisomes the targeting sequence is located on the C-terminal extension. Unlike signal peptides, signal patches are composed by amino acid residues that are discontinuous in the primary sequence but become functional when folding brings them together on the protein surface. Unlike most signal sequences, signal patches are not cleaved after sorting is complete. In addition to intrinsic signaling sequences, protein modifications like glycosylation can also induce targeting to specific intracellular or extracellular regions.\nProtein translocation.\nSince the translation of mRNA into protein by a ribosome takes place within the cytosol, proteins destined for secretion or a specific organelle must be translocated. This process can occur during translation, known as co-translational translocation, or after translation is complete, known as post-translational translocation.\nCo-translational translocation.\nMost secretory and membrane-bound proteins are co-translationally translocated. Proteins that reside in the endoplasmic reticulum (ER), golgi or endosomes also use the co-translational translocation pathway. This process begins while the protein is being synthesized on the ribosome, when a signal recognition particle (SRP) recognizes an N-terminal signal peptide of the nascent protein. Binding of the SRP temporarily pauses synthesis while the ribosome-protein complex is transferred to an SRP receptor on the ER in eukaryotes, and the plasma membrane in prokaryotes. There, the nascent protein is inserted into the translocon, a membrane-bound protein conducting channel composed of the Sec61 translocation complex in eukaryotes, and the homologous SecYEG complex in prokaryotes. In secretory proteins and type I transmembrane proteins, the signal sequence is immediately cleaved from the nascent polypeptide once it has been translocated into the membrane of the ER (eukaryotes) or plasma membrane (prokaryotes) by signal peptidase. The signal sequence of type II membrane proteins and some polytopic membrane proteins are not cleaved off and therefore are referred to as signal anchor sequences. Within the ER, the protein is first covered by a chaperone protein to protect it from the high concentration of other proteins in the ER, giving it time to fold correctly. Once folded, the protein is modified as needed (for example, by glycosylation), then transported to the Golgi for further processing and goes to its target organelles or is retained in the ER by various ER retention mechanisms.\nThe amino acid chain of transmembrane proteins, which often are transmembrane receptors, passes through a membrane one or several times. These proteins are inserted into the membrane by translocation, until the process is interrupted by a stop-transfer sequence, also called a membrane anchor or signal-anchor sequence. These complex membrane proteins are currently characterized using the same model of targeting that has been developed for secretory proteins. However, many complex multi-transmembrane proteins contain structural aspects that do not fit this model. Seven transmembrane G-protein coupled receptors (which represent about 5% of the genes in humans) mostly do not have an amino-terminal signal sequence. In contrast to secretory proteins, the first transmembrane domain acts as the first signal sequence, which targets them to the ER membrane. This also results in the translocation of the amino terminus of the protein into the ER membrane lumen. This translocation, which has been demonstrated with opsin with in vitro experiments, breaks the usual pattern of \"co-translational\" translocation which has always held for mammalian proteins targeted to the ER. A great deal of the mechanics of transmembrane topology and folding remains to be elucidated.\nPost-translational translocation.\nEven though most secretory proteins are co-translationally translocated, some are translated in the cytosol and later transported to the ER/plasma membrane by a post-translational system. In prokaryotes this process requires certain cofactors such as SecA and SecB and is facilitated by Sec62 and Sec63, two membrane-bound proteins. The Sec63 complex, which is embedded in the ER membrane, causes hydrolysis of ATP, allowing chaperone proteins to bind to an exposed peptide chain and slide the polypeptide into the ER lumen. Once in the lumen the polypeptide chain can be folded properly. This process only occurs in unfolded proteins located in the cytosol.\nIn addition, proteins targeted to other cellular destinations, such as mitochondria, chloroplasts, or peroxisomes, use specialized post-translational pathways. Proteins targeted for the nucleus are also translocated post-translationally through the addition of a nuclear localization sequence (NLS) that promotes passage through the nuclear envelope via nuclear pores.\nSorting of proteins.\nMitochondria.\nWhile some proteins in the mitochondria originate from mitochondrial DNA within the organelle, most mitochondrial proteins are synthesized as cytosolic precursors containing uptake peptide signals. Unfolded proteins bound by cytosolic chaperone hsp70 that are targeted to the mitochondria may be localized to four different areas depending on their sequences. They may be targeted to the mitochondrial matrix, the outer membrane, the intermembrane space, or the inner membrane. Defects in any one or more of these processes has been linked to health and disease.\nMitochondrial matrix.\nProteins destined for the mitochondrial matrix have specific signal sequences at their beginning (N-terminus) that consist of a string of 20 to 50 amino acids. These sequences are designed to interact with receptors that guide the proteins to their correct location inside the mitochondria. The sequences have a unique structure with clusters of water-loving (hydrophilic) and water-avoiding (hydrophobic) amino acids, giving them a dual nature known as amphipathic. These amphipathic sequences typically form a spiral shape (alpha-helix) with the charged amino acids on one side and the hydrophobic ones on the opposite side. This structural feature is essential for the sequence to function correctly in directing proteins to the matrix. If mutations occur that mess with this dual nature, the protein often fails to reach its intended destination, although not all changes to the sequence have this effect. This indicates the importance of the amphipathic property for the protein to be correctly targeted to the mitochondrial matrix.Proteins targeted to the mitochondrial matrix first involves interactions between the matrix targeting sequence located at the N-terminus and the outer membrane import receptor complex TOM20/22. In addition to the docking of internal sequences and cytosolic chaperones to TOM70. Where TOM is an abbreviation for translocase of the outer membrane. Binding of the matrix targeting sequence to the import receptor triggers a handoff of the polypeptide to the general import core (GIP) known as TOM40. The general import core (TOM40) then feeds the polypeptide chain through the intermembrane space and into another translocase complex TIM17/23/44 located on the inner mitochondrial membrane. This is accompanied by the necessary release of the cytosolic chaperones that maintain an unfolded state prior to entering the mitochondria. As the polypeptide enters the matrix, the signal sequence is cleaved by a processing peptidase and the remaining sequences are bound by mitochondrial chaperones to await proper folding and activity. The push and pull of the polypeptide from the cytosol to the intermembrane space and then the matrix is achieved by an electrochemical gradient that is established by the mitochondrion during oxidative phosphorylation. In which a mitochondrion active in metabolism has generated a negative potential inside the matrix and a positive potential in the intermembrane space. It is this negative potential inside the matrix that directs the positively charged regions of the targeting sequence into its desired location.\nMitochondrial inner membrane.\nTargeting of mitochondrial proteins to the inner membrane may follow 3 different pathways depending upon their overall sequences, however, entry from the outer membrane remains the same using the import receptor complex TOM20/22 and TOM40 general import core. The first pathway for proteins targeted to the inner membrane follows the same steps as those designated to the matrix where it contains a matrix targeting sequence that channels the polypeptide to the inner membrane complex containing the previously mentioned translocase complex TIM17/23/44. However, the difference is that the peptides that are designated to the inner membrane and not the matrix contain an upstream sequence called the stop-transfer-anchor sequence. This stop-transfer-anchor sequence is a hydrophobic region that embeds itself into the phospholipid bilayer of the inner membrane and prevents translocation further into the mitochondrion. The second pathway for proteins targeted to the inner membrane follows the matrix localization pathway in its entirety. However, instead of a stop-transfer-anchor sequence, it contains another sequence that interacts with an inner membrane protein called Oxa-1 once inside the matrix that will embed it into the inner membrane. The third pathway for mitochondrial proteins targeted to the inner membrane follow the same entry as the others into the outer membrane, however, this pathway utilizes the translocase complex TIM22/54 assisted by complex TIM9/10 in the intermembrane space to anchor the incoming peptide into the membrane. The peptides for this last pathway do not contain a matrix targeting sequence, but instead contain several internal targeting sequences.\nMitochondrial intermembrane space.\nIf instead the precursor protein is designated to the intermembrane space of the mitochondrion, there are two pathways this may occur depending on the sequences being recognized. The first pathway to the intermembrane space follows the same steps for an inner membrane targeted protein. However, once bound to the inner membrane the C-terminus of the anchored protein is cleaved via a peptidase that liberates the preprotein into the intermembrane space so it can fold into its active state. One of the greatest examples for a protein that follows this pathway is cytochrome b2, that upon being cleaved will interact with a heme cofactor and become active. The second intermembrane space pathway does not utilize any inner membrane complexes and therefor does not contain a matrix targeting signal. Instead, it enters through the general import core TOM40 and is further modified in the intermembrane space to achieve its active conformation. TIM9/10 is an example of a protein that follows this pathway in order to be in the location it needs to be to assist in inner membrane targeting.\nMitochondrial outer membrane.\nOuter membrane targeting simply involves the interaction of precursor proteins with the outer membrane translocase complexes that embeds it into the membrane via internal-targeting sequences that are to form hydrophobic alpha helices or beta barrels that span the phospholipid bilayer. This may occur by two different routes depending on the preprotein internal sequences. If the preprotein contains internal hydrophobic regions capable of forming alpha helices, then the preprotein will utilize the mitochondrial import complex (MIM) and be transferred laterally to the membrane. For preproteins containing hydrophobic internal sequences that correlate to beta-barrel forming proteins, they will be imported from the aforementioned outer membrane complex TOM20/22 to the intermembrane space. In which they will interact with TIM9/10 intermembrane-space protein complex that transfers them to sorting and assembly machinery (SAM) that is present in the outer membrane that laterally displaces the targeted protein as a beta-barrel.\nChloroplasts.\nChloroplasts are similar to mitochondria in that they contain their own DNA for production of some of their components. However, the majority of their proteins are obtained via post-translational translocation and arise from nuclear genes. Proteins may be targeted to several sites of the chloroplast depending on their sequences such as the outer envelope, inner envelope, stroma, thylakoid lumen, or the thylakoid membrane. Proteins are targeted to Thylakoids by mechanisms related to Bacterial Protein Translocation. Proteins targeted to the envelope of chloroplasts usually lack cleavable sorting sequence and are laterally displaced via membrane sorting complexes. General import for the majority of preproteins requires translocation from the cytosol through the Toc and Tic complexes located within the chloroplast envelope. Where Toc is an abbreviation for the translocase of the outer chloroplast envelope and Tic is the translocase of the inner chloroplast envelope. There is a minimum of three proteins that make up the function of the Toc complex. Two of which, referred to as Toc159 and Toc34, are responsible for the docking of stromal import sequences and both contain GTPase activity. The third known as Toc 75, is the actual translocation channel that feeds the recognized preprotein by Toc159/34 into the chloroplast.\nStroma.\nTargeting to the stroma requires the preprotein to have a stromal import sequence that is recognized by the Tic complex of the inner envelope upon being translocated from the outer envelope by the Toc complex. The Tic complex is composed of at least five different Tic proteins that are required to form the translocation channel across the inner envelope. Upon being delivered to the stroma, the stromal import sequence is cleaved off via a signal peptidase. This delivery process to the stroma is currently known to be driven by ATP hydrolysis via stromal HSP chaperones, instead of the transmembrane electrochemical gradient that is established in mitochondria to drive protein import. Further intra-chloroplast sorting depends on additional target sequences such as those designated to the thylakoid membrane or the thylakoid lumen.\nThylakoid lumen.\nIf a protein is to be targeted to the thylakoid lumen, this may occur via four differently known routes that closely resemble bacterial protein transport mechanisms. The route that is taken depends upon the protein delivered to the stroma being in either an unfolded or metal-bound folded state. Both of which will still contain a thylakoid targeting sequence that is also cleaved upon entry to the lumen. While protein import into the stroma is ATP-driven, the pathway for metal-bound proteins in a folded state to the thylakoid lumen has been shown to be driven by a pH gradient.\nThylakoid membrane.\nProteins bound for the membrane of the thylakoid will follow up to four known routes that are illustrated in the corresponding figure shown. They may follow a co-translational insertion route that utilizes stromal ribosomes and the SecY/E transmembrane complex, the SRP-dependent pathway, the spontaneous insertion pathway, or the GET pathway. The last of the three are post-translational pathways originating from nuclear genes and therefor constitute the majority of proteins targeted to the thylakoid membrane. According to recent review articles in the journal of biochemistry and molecular biology, the exact mechanisms are not yet fully understood.\nBoth chloroplasts and mitochondria.\nMany proteins are needed in both mitochondria and chloroplasts. In general the dual-targeting peptide is of intermediate character to the two specific ones. The targeting peptides of these proteins have a high content of basic and hydrophobic amino acids, a low content of negatively charged amino acids. They have a lower content of alanine and a higher content of leucine and phenylalanine. The dual targeted proteins have a more hydrophobic targeting peptide than both mitochondrial and chloroplastic ones. However, it is tedious to predict if a peptide is dual-targeted or not based on its physio-chemical characteristics.\nNucleus.\nThe nucleus of a cell is surrounded by a nuclear envelope consisting of two layers, with the inner layer providing structural support and anchorage for chromosomes and the nuclear lamina. The outer layer is similar to the endoplasmic reticulum (ER) membrane. This envelope contains nuclear pores, which are complex structures made from around 30 different proteins. These pores act as selective gates that control the flow of molecules into and out of the nucleus.\nWhile small molecules can pass through these pores without issue, larger molecules, like RNA and proteins destined for the nucleus, must have specific signals to be allowed through. These signals are known as nuclear localization signals, usually comprising short sequences rich in positively charged amino acids like lysine or arginine.\nProteins called nuclear import receptors recognize these signals and guide the large molecules through the nuclear pores by interacting with the disordered, mesh-like proteins that fill the pore. The process is dynamic, with the receptor moving the molecule through the meshwork until it reaches the nucleus.\nOnce inside, a GTPase enzyme called Ran, which can exist in two different forms (one bound to GTP and the other to GDP), facilitates the release of the cargo inside the nucleus and recycles the receptor back to the cytosol. The energy for this transport comes from the hydrolysis of GTP by Ran. Similarly, nuclear export receptors help move proteins and RNA out of the nucleus using a different signal and also harnessing Ran's energy conversion.\nOverall, the nuclear pore complex works efficiently to transport macromolecules at high speed, allowing proteins to move in their folded state and ribosomal components as complete particles, which is distinct from how proteins are transported into most other organelles.\nEndoplasmic reticulum.\nThe endoplasmic reticulum (ER) plays a key role in protein synthesis and distribution in eukaryotic cells. It's a vast network of membranes where proteins are processed and sorted to various destinations, including the ER itself, the cell surface, and other organelles like the Golgi apparatus, endosomes, and lysosomes. Unlike other organelle-targeted proteins, those headed for the ER start to be transferred across its membrane while they're still being made.\nProtein synthesis and sorting.\nThere are two types of proteins that move to the ER: water-soluble proteins, which completely cross into the ER lumen, and transmembrane proteins, which partly cross and embed themselves within the ER membrane. These proteins find their way to the ER with the help of an ER signal sequence, a short stretch of hydrophobic amino acids.\nProteins entering the ER are synthesized by ribosomes. There are two sets of ribosomes in the cell: those bound to the ER (making it look 'rough') and those floating freely in the cytosol. Both sets are identical but differ in the proteins they synthesize at a given moment. Ribosomes that are making proteins with an ER signal sequence attach to the ER membrane and start the translocation process. This process is energy-efficient because the growing protein chain itself pushes through the ER membrane as it elongates.\nAs the mRNA is translated into a protein, multiple ribosomes may attach to it, creating a structure called a polyribosome. If the mRNA is coding for a protein with an ER signal sequence, the polyribosome attaches to the ER membrane, and the protein begins to enter the ER while it is still being synthesized.\nGuided entry of soluble proteins.\nIn the process of protein synthesis within eukaryotic cells, soluble proteins that are destined for the endoplasmic reticulum (ER) or for secretion out of the cell are guided to the ER by a two-part system. Firstly, a signal-recognition particle (SRP) in the cytosol attaches to the emerging protein's ER signal sequence and the ribosome itself. Secondly, an SRP receptor located in the ER membrane recognizes and binds to the SRP. This interaction temporarily slows down protein synthesis until the SRP and ribs complex binds to the SRP receptor on the ER.\nOnce this binding occurs, the SRP is released, and the ribosome is transferred to a protein translocator in the ER membrane, allowing protein synthesis to continue. The polypeptide chain of the protein is then threaded through a channel in the translocator into the ER lumen. The signal sequence of the protein, typically at the beginning (N-terminus) of the polypeptide chain, plays a dual role. It not only targets the ribosome to the ER but also triggers the opening of the translocator. As the protein is fed through the translocator, the signal sequence stays attached, allowing the rest of the protein to move through as a loop. A signal peptidase inside the ER then cuts off the signal sequence, which is subsequently discarded into the lipid bilayer of the ER membrane and broken down.\nFinally, once the last part of the protein (the C-terminus) passes through the translocator, the entire soluble protein is released into the ER lumen, where it can then fold and undergo further modifications or be transported to its final destination.\nMechanisms of transmembrane protein integration.\nTransmembrane proteins, which are partly integrated into the ER membrane rather than released into the ER lumen, have a complex assembly process. The initial stages are similar to soluble proteins: a signal sequence starts the insertion into the ER membrane. However, this process is interrupted by a stop-transfer sequence\u2014a string of hydrophobic amino acids\u2014which causes the translocator to halt and release the protein laterally into the membrane. This results in a single-pass transmembrane protein with one end inside the ER lumen and the other in the cytosol, and this orientation is permanent.\nSome transmembrane proteins use an internal signal (start-transfer sequence) instead of one at the N-terminus, and unlike the initial signal sequence, this start-transfer sequence isn't removed. It begins the transfer process, which continues until a stop-transfer sequence is encountered, at which point both sequences become anchored in the membrane as alpha-helical segments.\nIn more complex proteins that span the membrane multiple times, additional pairs of start- and stop-transfer sequences are used to weave the protein into the membrane in a fashion akin to a sewing machine. Each pair allows a new segment to cross the membrane and adds to the protein's structure, ensuring it is properly embedded with the correct arrangement of segments inside and outside the ER membrane.\nPeroxisomes.\nPeroxisomes contain a single phospholipid bilayer that surrounds the peroxisomal matrix containing a wide variety of proteins and enzymes that participate in anabolism and catabolism. Peroxisomes are specialized cell organelles that carry out specific oxidative reactions using molecular oxygen. Their primary function is to remove hydrogen atoms from organic molecules, a process that results in the production of hydrogen peroxide (). Within peroxisomes, an enzyme called catalase plays a critical role. It uses the hydrogen peroxide generated in the earlier reaction to oxidize various other substances, including phenols, formic acid, formaldehyde, and alcohol. This is known as the \"peroxidative\" reaction.\nPeroxisomes are particularly important in liver and kidney cells for detoxifying harmful substances that enter the bloodstream. For example, they are responsible for oxidizing about 25% of the ethanol we consume into acetaldehyde. Additionally, catalase within peroxisomes can break down excess hydrogen peroxide into water and oxygen and thus preventing potential damage from the build-up of . Since it contains no internal DNA like that of the mitochondria or chloroplast all peroxisomal proteins are encoded by nuclear genes. To date there are two types of known Peroxisome Targeting Signals (PTS):\nThere are also proteins that possess neither of these signals. Their transport may be based on a so-called \"piggy-back\" mechanism: such proteins associate with PTS1-possessing matrix proteins and are translocated into the peroxisomal matrix together with them.\nIn the case of cytosolic proteins that are produced with the PTS1 C-terminal sequence, its path to the peroxisomal matrix is dependent upon binding to another cytosolic protein called pex5 (peroxin 5). Once bound, pex5 interacts with a peroxisomal membrane protein pex14 to form a complex. When the pex5 protein with bound cargo interacts with the pex14 membrane protein, the complex induces the release of the targeted protein into the matrix. Upon releasing the cargo protein into the matrix, pex5 dissociation from pex14 occurs via ubiquitinylation by a membrane complex comprising pex2, pex12, and pex10 followed by an ATP dependent removal involving the cytosolic protein complex pex1 and pex6. The cycle for pex5 mediated import into the peroxisomal matrix is restored after the ATP dependent removal of ubiquitin and is free to bind with another protein containing a PTS1 sequence. Proteins containing a PTS2 targeting sequence are mediated by a different cytosolic protein but are believed to follow a similar mechanism to that of those containing the PTS1 sequence.\nDiseases.\nProtein transport is defective in the following genetic diseases:\nIn bacteria and archaea.\nAs discussed above (see protein translocation), most prokaryotic membrane-bound and secretory proteins are targeted to the plasma membrane by either a co-translation pathway that uses bacterial SRP or a post-translation pathway that requires SecA and SecB. At the plasma membrane, these two pathways deliver proteins to the SecYEG translocon for translocation. Bacteria may have a single plasma membrane (Gram-positive bacteria), or an inner membrane plus an outer membrane separated by the periplasm (Gram-negative bacteria). Besides the plasma membrane the majority of prokaryotes lack membrane-bound organelles as found in eukaryotes, but they may assemble proteins onto various types of inclusions such as gas vesicles and storage granules.\nGram-negative bacteria.\nIn gram-negative bacteria proteins may be incorporated into the plasma membrane, the outer membrane, the periplasm or secreted into the environment. Systems for secreting proteins across the bacterial outer membrane may be quite complex and play key roles in pathogenesis. These systems may be described as type I secretion, type II secretion, etc.\nGram-positive bacteria.\nIn most gram-positive bacteria, certain proteins are targeted for export across the plasma membrane and subsequent covalent attachment to the bacterial cell wall. A specialized enzyme, sortase, cleaves the target protein at a characteristic recognition site near the protein C-terminus, such as an LPXTG motif (where X can be any amino acid), then transfers the protein onto the cell wall. Several analogous systems are found that likewise feature a signature motif on the extra-cytoplasmic face, a C-terminal transmembrane domain, and cluster of basic residues on the cytosolic face at the protein's extreme C-terminus. The PEP-CTERM/exosortase system, found in many Gram-negative bacteria, seems to be related to extracellular polymeric substance production. The PGF-CTERM/archaeosortase A system in archaea is related to S-layer production. The GlyGly-CTERM/rhombosortase system, found in the Shewanella, Vibrio, and a few other genera, seems involved in the release of proteases, nucleases, and other enzymes.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24837", "revid": "37947689", "url": "https://en.wikipedia.org/wiki?curid=24837", "title": "Pinochle", "text": "Card game\nPinochle (), also called pinocle or penuchle, is a trick-taking ace\u2013ten card game, typically for two to four players and played with a 48-card deck. It is derived from the card game bezique; players score points by trick-taking and also by forming combinations of characters into melds. It is thus considered part of a \"trick-and-meld\" category which also includes the game belote. Each hand is played in three phases: bidding, melds, and tricks. The standard game today is called \"partnership auction pinochle\".\nHistory.\nPinochle is thought to have two possible origins. One is that it is a cousin of Binokel, with both games evolving from the game of bezique. A second alternative is that pinochle actually developed from the Swiss and, later, South German game of Binocle or Binokel, which in turn is a descendant of bezique. \nThe word pinochle has several different potential derivations. It may come from the French word \"binocle\" literally meaning \"two eyes\", or \"eyeglasses\" or \"binoculars\", and was a reference to the mythical notion that the German game of Binocle was invented with a special deck where the Queen of Spades and Jack of Diamonds were pictured in side profile with just one eye each. There are also suggestions that the word pinochle comes from \"bis\" (until) and \"Kn\u00f6chel\" (knuckle) because originally the game ended when a player rapped their knuckles on the table. The term may also be related to the French word \"binage\" for the combination of cards called \"binocle\". This latter pronunciation of the game was adopted by German speakers. \nGerman immigrants brought the game of Binokel to America in the latter quarter of the 19th century, where it was mispronounced and misspelled \"pinochle.\" Pinochle was the favorite card game of American Jewish and Irish immigrants, while Skat was the preferred game of a majority of German immigrants. Auction Pinochle for three players has some similarities with the German game Skat, although the bidding is more similar to that of bid whist.\nDuring the few months when the USA was involved in World War I, the city of Syracuse, New York, outlawed the playing of pinochle in a gesture of anti-German sentiment. It was also temporarily banned in some other US cities as a result of its German heritage, but has since regained popularity.\nDeck.\nA pinochle deck consists of two copies of each of the 9, 10, jack, queen, king, and ace cards of all four suits, for 48 cards per deck. Aces are always considered high. Pinochle follows a nonstandard card ordering. The complete ordering from highest to lowest is A, 10, K, Q, J, 9. The game can also be played using standard ranking with a simple change to scoring.\nOriginally, the deck had to be composed by combining two poker, piquet or euchre decks and removing unneeded cards (a piquet deck does not have the 2\u20136, making it easier to modify, and a euchre deck is exactly half a pinochle deck), but with the game's popularity in the United States in the early 1900s, a single boxed deck with the necessary cards was marketed, and these specialized pinochle decks are now widely available in similar styles to common 52-card counterparts. Variants of pinochle can be played with five, six, eight or more players. These larger variations can combine two pinochle decks called a \"double deck\". The double deck can also be used when playing with four players; hand sizes, average scores and minimum bids are doubled.\nPartnership auction pinochle.\nDealing.\nThe game is played with a deck of 48 cards and four players; one player is the dealer.\nAfter the shuffle, the dealer will offer a cut to the player on their right, then distribute the cards. All the cards are dealt in partnership pinochle. In variations for odd numbers of players like three, a \"widow's hand\" (also called a \"kitty\", \"talon\", or \"stock\") of cards remains. Traditionally, the deal is done clockwise, dealing a packet of three or four cards at a time, starting with the player to the left (the eldest hand) and ending with the dealer. The deal rotates clockwise, so the dealer's left-hand opponent will deal next.\nSome versions include a rule that a player being dealt five nines constitutes a misdeal, and the cards must be redealt. A variation of this stipulates that if someone is dealt five nines, they must also have no aces to constitute a misdeal, or if one has six nines and up to one ace.\nAuction pinochle.\nIn auction pinochle, players bid for the points they predict their hand could earn. The highest bidder earns the right to declare the trump suit. One of the players, usually the player to the left of the dealer, or the dealer themselves, is obligated to open with a first bid. The size of bids is based on the point scale and number of decks used; traditionally, points are in multiples of 10, thus a minimum opening bid might be agreed to be 100 or 250.344 However, many alternate scoring rules drop the unnecessary trailing zero; in that case, bids of 10 and 25, respectively, have the same values. When a player has the turn to bid, the player may either bid or pass.\nA popular variation for four (or three) player pinochle involves dealing a 4 card kitty (3 or 6 cards for three players), with the bid winner taking the kitty and discarding 4 (3 or 6) cards from his hand. The point value of the discards can sometimes be added to the bid winner's total trick count or not, depending on the pre-established rules. In three player games the 6 card kitty can often lead to very competitive and extravagant bidding.\nEach bid must be greater than the previous one, and be a multiple of 10 or 25 (if playing without trailing zeroes, the bid must be one or two greater respectively). When a player passes, they can no longer bid. The auction ends when all subsequent players in rotation have passed after the last bid. The last bid becomes the \"contract\". The player that made this final bid will then declare trump in the suit that is desired. In some house rules, trump cannot be declared in any suit not containing a \"run\", \"marriage\" or \"dix\" meld.\nIn order for the winning bidder to win the hand, the combined total of melding and trick points must be equal to or greater than the winning bid. Thus bidding involves anticipating the points that will be accumulated from melds and from the points accumulated from winning tricks. If the combined score is lower than the bid, then the bidding team or player has been \"set\". This means that the total bid amount is subtracted from the total game score, often accompanied by losing the points scored in meld for that hand as well. This can result in a negative score.\nA related though different style of bidding is for the players to bid individually, and partners' bids are then summed. The winning bid only decides trump; both (or all) teams' bids become their contract, meaning any team can score or be set. This creates a more balanced game.\nPassing cards.\nIn some versions of pinochle, after the bid has been taken and trump declared in a partnership game, the bid winning team exchanges cards. It may be two, three, or four cards, depending on the version of the game. The partner of the bid winner passes first. The objective of the partner is either to add to the total points in meld or to pass trick-winning cards. After receiving the cards, the bid winner examines what will create the strongest hand and then discards an equal number of cards back to their partner. Variations are for the bid winner and partner to exchange the designated number of cards simultaneously, or for no passing to occur.\nMelding.\nMelding consists of displaying specific combinations of cards to all players. Typically this is done by placing the combination of cards face up on the playing surface until all players have had the opportunity to examine them. All players meld after the bid winner shows meld first. The types of melds include \"arounds\", \"marriages\", \"flushes\" and \"pinochles\". These melds are placed under \"headings\" where a card which is melded under a particular heading can be used again under another heading, but cannot be melded again under the same heading.\nThe group melds containing four of the same face cards\u00a0\u2013 ace, king, queen or jack\u00a0\u2013 must include one card from each of the different suits. They are scored as follows:\nThe marriages and flush are the \"sequence melds\":\nA marriage in each suit is worth 240 or 24 total points, which is nothing more than the sum of the marriages, plus kings around and queens around. As a shortcut, this is called a \"roundtable\", \"marriages around\", \"round house\", or a \"round robin\".\nThe pinochle and dix are the \"special melds\".\nIn the most common form of the game (see variations below), any one card may be used in only one meld of each type. Thus, a queen can be used in one marriage with one king, regardless whether the player has the other king of the same suit. However, a queen can be used to score a marriage and a pinochle if the player also has the correct jack.\nAfter the melds are displayed, the points are counted and each player totals their individual meld scores.\nBecause all of these values are multiples of ten, one can arrive at simplified values by removing the trailing zero from each point total. For instance, a pinochle has a simplified score of 4, a double Pinochle would score 30.\nPlaying tricks.\nIn playing cards for tricks, there are strict rules of forced play, which limit a player's ability to strategically retain high cards. The high bidder leads the play with the first card, which can be any card in the contract winner's hand just like basic Whist, although some rules require the first card led to be a trump card. Then there are two variations of following suit depending if you are playing post-1945 or pre-1945 rules.\nAccording to the pre-1945 rules, every player must follow the lead suit if possible. Usually every player must play a winning card against those played so far, if it is possible to do so, even when the current player expects a later player to win the hand with a better card. The only exception is if a player played a trump card when trump was not the suit led. In that case, those following that player may play any card of the lead suit, since they must follow the lead suit but are already losing to the player who played trump. Likewise, if a player cannot follow suit, but has trump, they must play trump. Again, if a player does not have any cards of the lead suit and can play a trump card higher than any other trump played so far, the player must do so, even if the player expects that a later player will beat the card. If another trump has already been played that a player cannot beat, then they can play any trump in their hand, but they still must play a trump card if they can. Only when a player has no cards in suit, and has no trump, can the player choose to play any card in their hand.\nMost books of post-1945 rules say that unless trump is led, there is no requirement to try to win the trick. It is only when trump is led that \"heading\" the trick is mandatory. In pinochle circles and tournaments the post-1945 rules are played about half of the time according to Pagat and Hoyle.\nIf two identical cards are played, the first one outranks the second.\nAfter the first trick, the winner of each trick leads the first card for the next trick, until all the cards are played.\nScoring tricks.\nPoints are scored based on the tricks won in the hand. There are several ways to count up the points for play, but they always add up to 250 points. The last trick is always worth an additional 10 points added to any existing points in the actual trick cards. The classic counting system of pinochle is where aces are worth 11, tens are worth 10, kings are worth four, queens are worth three, jacks are worth two, and nines are worth zero. This method takes longer to count the score at the end of each hand.\nA simpler method is to count aces and tens for 10 points, kings and queens for five points, and jacks and nines are worth zero.\nAn even simpler method has aces, tens, and kings worth 10 (and known as \"counters\"), and everything else zero (\"garbage\"). Since all points are multiples of ten in the third method, most players drop the redundant zero. Aces, tens, and kings won in tricks are worth one point. The meld scoring can also avoid the zero in the tenth place. Melds like 1,000 aces are thus worth 100. The terms \"1,000 aces\", \"800 kings\" and so on are often used, even though the point values are one-tenth.\nGame variations.\nTwo-handed.\nTwo-handed pinochle is the original pinochle game, while partnership, auction, and all other variants are derived from it. It is the game most similar to the original Bezique game, whence pinochle was derived, via the German game of Binokel. The only significant difference in its rules from Bezique is the scoring.\nThe original version of pinochle involves a partial deal of twelve cards to both players in packets of four, leaving a stock of 24 cards. A player can score one meld after each trick won of the first 12 tricks. Melded cards can even be used to win tricks. After each trick, players draw one card from the stock into their hand starting with the trick-winning player. For the last 12 tricks, melds are taken into each player's hand and are no longer announced by the player who wins the trick. The traditional trick-taking rules apply only for these last 12 tricks.\nIn variations of two-handed play, no cards are initially dealt, a distinction from all other variations. Instead, the entire deck is placed face-down on the playing surface between the two players to form the widow. One player begins the hand-building process by drawing the top card of the widow. The player can either keep that card for her or his hand or reject the card. If the player chooses to hold the initial card, the player then draws a second card from the widow, then places it face-down, without looking at it, creating a discard pile. If the player rejects the first card, the card becomes the first card in the discard pile. The second card drawn from the widow must be kept, regardless of whether the player preferred the first card. Players alternate turns in this hand-building process until all cards are chosen.\nWith bidding, the player winning the bid declares trump, then lays all meld face-up on the table. The other player shows her or his melds as well. Meld points are tallied, and players return meld cards to their hands. Some varieties accept a \"round house\", kings and queens of each suit, and earn a bonus 10 points awarding a total of 250 points.\nTrick-taking commences and continues until all held cards have been played. One variation has no \"leading\" requirement for the bid winner or subsequent trick winner to lead a specific card, however the rules of \"following\" are still observed.\nWhen adding counters, cards from each player's discard pile are included in totals for a total of 240 counters per round, plus one counter for winning the final trick. One variation to make it more difficult for the bid-winning player, the discard pile created by drawing cards is used by the non-bidding player to score towards tricks.\nThree-handed.\nIn Three-handed pinochle using a single deck, each player plays for him or herself. The dealer deals 15 cards to each player and three cards to the kitty\u2014a separate pile in the middle.\nAll players review their cards and silently determine their bids. The player to the dealer's left initiates the bidding process. If the player has a meld, he or she is required to open the bidding; otherwise, they may pass or bid. If he or she passes, the obligation to bid passes to the next player, if meld is held. Once a player passes, he or she is out of the auction.\nBidding begins at 20, or as little as 19 if dealer, and increases in multiples of 1. The highest bidder wins the auction and turns up the three-card kitty for all to see. The three widow cards are placed in the bid winner's hand. The bid winner then declares trump and lays down meld. The other two players also lay meld face-up for count. After the appropriate points have been tallied the bid winner must set aside any three cards that have not been melded. This will reduce the bid winner's hand to 15 cards. For all three players, meld is now returned to each respective player's hand, and the round is played. During the round, a player must take at least one trick to \"save one's meld\", even if the trick contains no points; otherwise, no meld points will be counted for that player during that round.\nAfter all tricks are taken, counters are tallied for each player. The three discards by the highest bidder count toward their counter score for the hand, so there is always a total of 25 points for the trick score among the three players. If the highest bidder fails to make their contract by adding meld points and trick points from the play, then their score is negative the amount of the bid for that hand. The meld count is cancelled.\nThe game is won when one player reaches 100 points. It is possible for two or all three players to go over 100 on the same hand. There are three methods of resolving ties:\nRenege.\nAny time a player accidentally misplays during the play portion of the hand, it is called a renege. There are various forms of misplay:\nIf the bidder reneges, they automatically take a double set and the amount of the bid is subtracted from their score. The two opposing players get to count their meld points and the remainder of the hand is thrown in.\nIf either of the two nonbidders misplay, the bidder automatically makes their bid. The bidder gets to score the amount of their bid and meld, the player that misplayed loses all meld and takes a single set, and the third player scores only their meld.\nIf at any point during melding or play it is determined that a non-standard deck is being used, any player may declare a card-fault misdeal. This results in the nullification of the entire hand including all meld and points obtained.\nCutthroat.\nSimilar to three-handed pinochle, cutthroat is a simple modification. The dealer deals the entire deck out (16 cards to each player), in packets of four. The player to the left of the dealer begins the bidding once meld has been silently determined by all players. Play continues normally in terms of scoring and trick taking. The only way to win in cutthroat pinochle, however, is to \"bid and out\", or to have taken the bid and surpassed the predetermined winning score. It is then possible for multiple players to go over the winning score, yet if none has taken a bid and met the resulting contract, a win has not happened and play continues. It is also possible for a person to lose with the high score if they do not take a winning bid.\nFour-handed.\nFour-handed pinochle, or \"partnership pinochle\" is played with two teams of two players each. Partners are seated opposite from each other. Each player is dealt 12 cards. The opening bid is typically 150, but can be a higher agreed on value. All four players may bid. Both the bidder and his partner have their score count towards making the contract. High bidder names trump. There typically is no kitty. With a kitty, the four cards are distributed, one to each player, by the bid winner. Each hand must meld separately. As in the three-handed version, the first player is forced to bid when holding meld. Play is often to 1000 but can increase to 1500 during partnership.\nFive-handed and larger.\nGames with five hands or more typically modify partnership pinochle in a variety of ways. They are generally played with 1 1/2 or doubled decks, with extra dix added or withheld to make an even deal. With an odd number of players, the bidder asks for a desired card in the trump suit, with the first matching player being partner for that hand. Everyone else plays against the team. In larger groups, one or more players can sit out each hand allowing the remaining players to follow the appropriate rules for the respective number of players.\nCheck.\nCheck pinochle is a gambling variant of three-hand. It is the same as to 1000, except that players keep track of \"checks\". If playing for $1 stakes, each check gained means that the other two players owe a dollar. The following events cause a gain or loss of checks.\n Note that checks for meld can be earned either by the bidder or non-bidder. Checks are kept even if the bid is not made.\nDouble-deck.\nToday \"double-deck\" pinochle is a popular form of the game, exclusively played by the National Pinochle Association, the American Pinochle Association, the Cambridge Pinochle Association, and in the \"World Series of Pinochle\".\nDouble-deck pinochle is played with two pinochle decks, without the nines. This makes for an 80 card deck.\nPlay is similar to regular pinochle, except 20 cards are dealt to each person and minimum bid is increased to 500 points. In some variations, bids are made in increments of 10 or more points until 600 is reached, then by 50 points. This version often features \"meld bidding\", a bid made to let a partner know what is in the bidder's hand. The only communication during bidding should be a numerical number or \"pass\", any other way of communicating is called \"talking across the table\" and is forbidden.\nThere are occasionally different meld values for a run and a pinochle; a run being 250 or 150 points, and a pinochle being 150 or 40 points. All other aspects of the game generally remain the same.\nTechnical Misdeal.\nIf a player is dealt 13 or more non-counters and no aces, the player may declare a technical misdeal. This must declared before he or she plays the first trick. A technical misdeal nullifies all points melded for all players. The hand is then re-dealt by the original dealer of that hand.\nTriple-deck, six-handed.\nThis version follows the rules of double-deck pinochle.\nIn triple-deck pinochle six play in two partnerships of three each; each player has an opponent at their right and left. Three pinochle decks with no nines are mixed together, making a pack of 120 cards. Each player is dealt 20 cards, and the rules of double deck pinochle apply, except that the minimum bid is 75, and the last trick is worth 3 points. most of the extra melds made possible by the triple pack do not count extra. i.e. if a player should hold twenty aces, five of each suit, the value would be that of double aces and triple aces combined.\nRacehorse.\nNote that this use of the term \"racehorse\" is inconsistent with the commonly understood meaning of the term when applied to Pinochle. As summarized by Dave LeVasseur: \"Racehorse means that, after the winning bidder has named trump, that player's partner passes cards across the table\"\nPlayed much the same as \"double deck\" but to six hands, the point values are inflated.\nTwo teams are formed, 20 cards are then dealt to each player and four cards are dealt to the blind. Bidding commences with the person immediately to the left of the dealer automatically bidding 500. The winner of the bid includes the blind into their hand, calls trump and melds.\nNote: all runs, double, triple, and quadruple, marriages must be in trump\nThe game continues with the standard rules of play. When the play is over each team adds up their points in the count with kings, 10s, and aces worth ten points, while queens and jacks are worth zero. If a team count plus meld does not equal their bid, they \"go set\". By going set the amount of the bid is subtracted from the team's score and their count is discarded. The other team retains both their meld and their count provided they took at least 10 points in the count.\nEight-player double-deck.\nTwo full decks are dealt between eight players, forming four teams. Team members are spaced so that they are not able to see any other hands. The game is usually played to a score of 5,000 or higher. Other than this, the four-player rules apply, and any variations may also be used. There is an increased possibility that when one team declares trump another team may have an equal number of trump also, which may lead to an interesting game. An optional scoring rule rewards 1,000 points for a quadruple pinochle\u2014four jacks of diamonds and four queens of spades in a meld.\nAlternate end games.\nOne variation on winning allows a team or individual to win instantly from any score by taking all the tricks in a hand. To win in this fashion, the winning player or team must play very skillfully to prevent opposing players from taking even one lowly (even zero-point) trick. This victory is known as \"pinochling\". A player or team can play for this victory even if they are not the highest bidder. \"pinochling\" does not require a bidder to make their bid. They also can play for this victory even if their bid cannot be made with the maximum number of trick points available plus their meld. However, the highest bidding player or team can prevent other players from attempting this if they elect to \"throw in\" the hand before the first card is played.\nAnother version of this, known as \"shooting the moon,\" can be called out by the highest bidder before melding. In this variation, neither team lays their meld down, and the partner of the high bidder does not participate in trick taking. If the high bidder succeeds in taking every trick, they have successfully \"shot the moon,\" and the game is over. If they do not successfully take every trick, this is known as a \"miss,\" and the shooting team immediately loses the game. Yet another variation has a point value of 1000 or 100 for shooting the moon, and an equal negative penalty for missing, and the game continues.\nWhen playing \"bid-out\" rules, a team can win without bidding if their score reaches (and remains above) the agreed-upon game-ending score while their opponents fail to make their bid three times. This is known as a \"slide-out\". Not all versions require the opponents to fail to make their bid three times in order to cross the winning point threshold. \nSome versions have an \"out backwards\" contingency, where if a team goes into the negative equivalent of what the game winning score is, they lose the game.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24838", "revid": "41591971", "url": "https://en.wikipedia.org/wiki?curid=24838", "title": "Peptidoglycan", "text": "Polymer in bacterial cell walls\nPeptidoglycan, murein or mucopeptide is a unique large macromolecule, a polysaccharide, consisting of sugars and amino acids that forms a mesh-like layer (sacculus) that surrounds the bacterial cytoplasmic membrane. The sugar component consists of alternating residues of \u03b2-(1,4) linked \"N\"-acetylglucosamine (NAG) and \"N\"-acetylmuramic acid (NAM). Attached to the \"N\"-acetylmuramic acid is an oligopeptide chain made of three to five amino acids. The peptide chain can be cross-linked to the peptide chain of another strand forming the 3D mesh-like layer. Peptidoglycan serves a structural role in the bacterial cell wall, giving structural strength, as well as counteracting the osmotic pressure of the cytoplasm. This repetitive linking results in a dense peptidoglycan layer which is critical for maintaining cell form and withstanding high osmotic pressures, and it is regularly replaced by peptidoglycan production. Peptidoglycan hydrolysis and synthesis are two processes that must occur in order for cells to grow and multiply, a technique carried out in three stages: clipping of current material, insertion of new material, and re-crosslinking of existing material to new material.\nThe peptidoglycan layer is substantially thicker in gram-positive bacteria (20 to 80 nanometers) than in gram-negative bacteria (7 to 8 nanometers). Depending on pH growth conditions, the peptidoglycan forms around 40 to 90% of the cell wall's dry weight of gram-positive bacteria but only around 10% of gram-negative strains. Thus, presence of high levels of peptidoglycan is the primary determinant of the characterisation of bacteria as gram-positive. In gram-positive strains, it is important in attachment roles and serotyping purposes. For both gram-positive and gram-negative bacteria, particles of approximately 2\u00a0nm can pass through the peptidoglycan.\nIt is difficult to tell whether an organism is gram-positive or gram-negative using a microscope; Gram staining, created by Hans Christian Gram in 1884, is required. The bacteria are stained with the dyes crystal violet and safranin. Gram positive cells are purple after staining, while Gram negative cells stain pink.\nStructure.\nThe peptidoglycan layer within the bacterial cell wall is a crystal lattice structure formed from linear chains of two alternating amino sugars, namely \"N\"-acetylglucosamine (GlcNAc or NAG) and \"N\"-acetylmuramic acid (MurNAc or NAM). The alternating sugars are connected by a \u03b2-(1,4)-glycosidic bond. Each MurNAc is attached to a short (4- to 5-residue) amino acid chain, containing -alanine, -glutamic acid, \"meso\"-diaminopimelic acid, and -alanine in the case of \"Escherichia coli\" (a gram-negative bacterium); or -alanine, -glutamine, -lysine, and -alanine with a 5-glycine interbridge between tetrapeptides in the case of \"Staphylococcus aureus\" (a gram-positive bacterium). Peptidoglycan is one of the most important sources of -amino acids in nature.\nBy enclosing the inner membrane, the peptidoglycan layer protects the cell from lysis caused by the turgor pressure of the cell. When the cell wall grows, it retains its shape throughout its life, so a rod shape will remain a rod shape, and a spherical shape will remain a spherical shape for life. This happens because the freshly added septal material of synthesis transforms into a hemispherical wall for the offspring cells.\nCross-linking between amino acids in different linear amino sugar chains occurs with the help of the enzyme -transpeptidase and results in a 3-dimensional structure that is strong and rigid. The specific amino acid sequence and molecular structure vary with the bacterial species.\nThe different peptidoglycan types of bacterial cell walls and their taxonomic implications have been described. Archaea (domain \"Archaea\") do not contain peptidoglycan (murein). Some Archaea contain pseudopeptidoglycan (pseudomurein, see below).\nPeptidoglycan is involved in binary fission during bacterial cell reproduction. L-form bacteria and mycoplasmas, both lacking peptidoglycan cell walls, do not proliferate by binary fission, but by a budding mechanism.\nIn the course of early evolution, the successive development of boundaries (membranes, walls) protecting first structures of life against their environment must have been essential for the formation of the first cells (cellularisation).\nThe invention of rigid peptidoglycan (murein) cell walls in bacteria (domain \"Bacteria\") was probably the prerequisite for their survival, extensive radiation and colonisation of virtually all habitats of the geosphere and hydrosphere.\nBiosynthesis.\nThe peptidoglycan monomers are synthesized in the cytosol and are then attached to a membrane carrier bactoprenol. Bactoprenol transports peptidoglycan monomers across the cell membrane where they are inserted into the existing peptidoglycan.\nEach of these reactions requires the energy source ATP. This is all referred to as Stage one.\nStage two occurs in the cytoplasmic membrane. It is in the membrane where a lipid carrier called bactoprenol carries peptidoglycan precursors through the cell membrane.\nPseudopeptidoglycan.\nIn some archaea, i.e. members of the Methanobacteriales and in the genus \"Methanopyrus\", pseudopeptidoglycan (pseudomurein) has been found. In pseudopeptidoglycan the sugar residues are \u03b2-(1,3) linked \"N\"-acetylglucosamine and \"N\"-acetyltalosaminuronic acid. This makes the cell walls of such archaea insensitive to lysozyme. The biosynthesis of pseudopeptidoglycan has been described.\nRecognition by immune system.\nPeptidoglycan recognition is an evolutionarily conserved process. The overall structure is similar between bacterial species, but various modifications can increase the diversity. These include modifications of the length of sugar polymers, modifications in the sugar structures, variations in cross-linking or substitutions of amino acids (primarily at the third position). The aim of these modifications is to alter the properties of the cell wall, which plays a vital role in pathogenesis.\nPeptidoglycans can be degraded by several enzymes (lysozyme, glucosaminidase, endopeptidase...), producing immunostimulatory fragments (sometimes called muropeptides) that are critical for mediating host-pathogen interactions. These include muramyl dipeptide (MDP), \"N\"-acetylglucosamine (NAG), or \u03b3-d-glutamyl-meso-diaminopimelic acid (iE-DAP).\nPeptidoglycan from intestinal bacteria (both pathogens and commensals) crosses the intestinal barrier even under physiological conditions. Mechanisms through which peptidoglycan or its fragments enter the host cells can be direct (carrier-independent) or indirect (carrier-dependent), and they are either bacteria-mediated (secretion systems, membrane vesicles) or host cell-mediated (receptor-mediated, peptide transporters). Bacterial secretion systems are protein complexes used for the delivery of virulence factors across the bacterial cell envelope to the exterior environment. Intracellular bacterial pathogens invade eukaryotic cells (which may lead to the formation of phagolysosomes and/or autophagy activation), or bacteria may be engulfed by phagocytes (macrophages, monocytes, neutrophils...). The bacteria-containing phagosome may then fuse with endosomes and lysosomes, leading to degradation of bacteria and generation of polymeric peptidoglycan fragments and muropeptides.\nReceptors.\nInnate immune system senses intact peptidoglycan and peptidoglycan fragments using numerous PRRs (pattern recognition receptors) that are secreted, expressed intracellularly or expressed on the cell surface.\nPeptidoglycan recognition proteins.\nPGLYRPs are conserved from insects to mammals. Mammals produce four secreted soluble peptidoglycan recognition proteins (PGLYRP-1, PGLYRP-2, PGLYRP-3 and PGLYRP-4) that recognize muramyl pentapeptide or tetrapeptide. They can also bind to LPS and other molecules by using binding sites outside of the peptidoglycan-binding groove. After recognition of peptidoglycan, PGLYRPs activate polyphenol oxidase (PPO) molecules, Toll, or immune deficiency (IMD) signalling pathways. That leads to production of antimicrobial peptides (AMPs).\nEach of the mammalian PGLYRPs display unique tissue expression patterns. PGLYRP-1 is mainly expressed in the granules of neutrophils and eosinophils. PGLYRP-3 and 4 are expressed by several tissues such as skin, sweat glands, eyes or the intestinal tract. PGLYRP-1, 3 and 4 form disulphide-linked homodimers and heterodimers essential for their bactericidal activity. Their binding to bacterial cell wall peptidoglycans can induce bacterial cell death by interaction with various bacterial transcriptional regulatory proteins. PGLYRPs are likely to assist in bacterial killing by cooperating with other PRRs to enhance recognition of bacteria by phagocytes.\nPGLYRP-2 is primarily expressed by the liver and secreted into the circulation. Also, its expression can be induced in skin keratinocytes, oral and intestinal epithelial cells. In contrast with the other PGLYRPs, PGLYRP-2 has no direct bactericidal activity. It possesses peptidoglycan amidase activity, it hydrolyses the lactyl-amide bond between the MurNAc and the first amino acid of the stem peptide of peptidoglycan. It is proposed, that the function of PGLYRP-2 is to prevent over-activation of the immune system and inflammation-induced tissue damage in response to NOD2 ligands (see below), as these muropeptides can no longer be recognized by NOD2 upon separation of the peptide component from MurNAc. Growing evidence suggests that peptidoglycan recognition protein family members play a dominant role in the tolerance of intestinal epithelial cells toward the commensal microbiota. It has been demonstrated that expression of PGLYRP-2 and 4 can influence the composition of the intestinal microbiota.\nRecently, it has been discovered, that PGLYRPs (and also NOD-like receptors and peptidoglycan transporters) are highly expressed in the developing mouse brain. PGLYRP-2 and is highly expressed in neurons of several brain regions including the prefrontal cortex, hippocampus, and cerebellum, thus indicating potential direct effects of peptidoglycan on neurons. PGLYRP-2 is highly expressed also in the cerebral cortex of young children, but not in most adult cortical tissues. PGLYRP-1 is also expressed in the brain and continues to be expressed into adulthood.\nNOD-like receptors.\nProbably the most well-known receptors of peptidoglycan are the NOD-like receptors (NLRs), mainly NOD1 and NOD2. The NOD1 receptor is activated after iE-DAP (\u03b3-d-glutamyl-meso-diaminopimelic acid) binding, while NOD2 recognizes MDP (muramyl dipeptide), by their LRR domains. Activation leads to self-oligomerization, resulting in activation of two signalling cascades. One triggers activation of NF-\u03baB (through RIP2, TAK1 and IKK), second leads to MAPK signalling cascade. Activation of these pathways induces production of inflammatory cytokines and chemokines.\nNOD1 is expressed by diverse cell types, including myeloid phagocytes, epithelial cells and neurons. NOD2 is expressed in monocytes and macrophages, epithelial intestinal cells, Paneth cells, dendritic cells, osteoblasts, keratinocytes and other epithelial cell types. As cytosolic sensors, NOD1 and NOD2 must either detect bacteria that enter the cytosol, or peptidoglycan must be degraded to generate fragments that must be transported into the cytosol for these sensors to function.\nRecently, it was demonstrated that NLRP3 is activated by peptidoglycan, through a mechanism that is independent of NOD1 and NOD2. In macrophages, N-acetylglucosamine generated by peptidoglycan degradation was found to inhibit hexokinase activity and induce its release from the mitochondrial membrane. It promotes NLRP3 inflammasome activation through a mechanism triggered by increased mitochondrial membrane permeability.\nNLRP1 is also considered as a cytoplasmic sensor of peptidoglycan. It can sense MDP and promote IL-1 secretion through binding NOD2.\nC-type lectin receptors (CLRs).\nC-type lectins are a diverse superfamily of mainly Ca2+-dependent proteins that bind a variety of carbohydrates (including the glycan skeleton of peptidoglycan), and function as innate immune receptors. CLR proteins that bind to peptidoglycan include mannose binding lectin (MBL), ficolins, Reg3A (regeneration gene family protein 3A), and PTCLec1. In mammals, they initiate the lectin-pathway of the complement cascade.\nToll-like receptors.\nThe role of toll-like receptors (TLRs) in direct recognition of peptidoglycan is controversial. In some studies, has been reported that peptidoglycan is sensed by TLR2. But this TLR2-inducing activity could be due to cell wall lipoproteins and lipoteichoic acids that commonly co-purify with peptidoglycan. Also variation in peptidoglycan structure in bacteria from species to species may contribute to the differing results on this topic.\nAs vaccine or adjuvant.\nPeptidoglycan is immunologically active, which can stimulate immune cells to increase the expression of cytokines and enhance antibody-dependent specific response when combined with vaccine or as adjuvant alone. MDP, which is the basic unit of peptidoglycan, was initially used as the active component of Freund's adjuvant. Peptidoglycan from \"Staphylococcus aureus\" was used as a vaccine to protect mice, showing that after vaccine injection for 40 weeks, the mice survived from \"S. aureus\" challenge at an increased lethal dose.\nInhibition and degradation.\nSome antibacterial drugs such as penicillin interfere with the production of peptidoglycan by binding to bacterial enzymes known as penicillin-binding proteins or -transpeptidases. Penicillin-binding proteins form the bonds between oligopeptide crosslinks in peptidoglycan. For a bacterial cell to reproduce through binary fission, more than a million peptidoglycan subunits (NAM-NAG+oligopeptide) must be attached to existing subunits. Mutations in genes coding for transpeptidases that lead to reduced interactions with an antibiotic are a significant source of emerging antibiotic resistance. Since peptidoglycan is also lacking in L-form bacteria and in mycoplasmas, both are resistant against penicillin.\nOther steps of peptidoglycan synthesis can also be targeted. The topical antibiotic bacitracin targets the utilization of C55-isoprenyl pyrophosphate. Lantibiotics, which include the food preservative nisin, attack lipid II.\nLysozyme, which is found in tears and constitutes part of the body's innate immune system exerts its antibacterial effect by breaking the \u03b2-(1,4)-glycosidic bonds in peptidoglycan (see above). Lysozyme is more effective in acting against gram-positive bacteria, in which the peptidoglycan cell wall is exposed, than against gram-negative bacteria, which have an outer layer of LPS covering the peptidoglycan layer. Several bacterial peptidoglycan modifications can result in resistance to degradation by lysozyme. Susceptibility of bacteria to degradation is also considerably affected by exposure to antibiotics. Exposed bacteria synthesize peptidoglycan that contains shorter sugar chains that are poorly crosslinked and this peptidoglycan is then more easily degraded by lysozyme.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24841", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=24841", "title": "P.A.M. Dirac", "text": ""}
{"id": "24844", "revid": "22879978", "url": "https://en.wikipedia.org/wiki?curid=24844", "title": "PDE", "text": "PDE may refer to:\nOther modes of abbreviation.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "24845", "revid": "50255754", "url": "https://en.wikipedia.org/wiki?curid=24845", "title": "Pope Sixtus IV", "text": "Head of the Catholic Church from 1471 to 1484\nPope Sixtus IV (or Xystus IV, ; born Francesco della Rovere; (21 July 1414\u00a0\u2013 12 August 1484) was head of the Catholic Church and ruler of the Papal States from 9 August 1471 until his death in 1484. His accomplishments as pope included the construction of the Sistine Chapel and the creation of the Vatican Library. A patron of the arts, he brought together the group of artists who ushered the early Renaissance into Rome with the first masterpieces of the city's new artistic age.\nSixtus created the Spanish Inquisition through the Papal bull \"Exigit Sincer\u00e6 Devotionis\" (1478), and annulled the Pontifical decrees of the Council of Constance. He was noted for his nepotism and was personally involved in the infamous Pazzi conspiracy, a plot to remove the Medici family from power in Florence.\nEarly life.\nFrancesco was a member of the Della Rovere family, a son of Leonardo Beltramo di Savona della Rovere and Luchina Monteleoni. He was born in Celle Ligure, a town near Savona.\nAs a young man, Della Rovere joined the Franciscan Order, an unlikely choice for a political career, and his intellectual qualities were revealed while he was studying philosophy and theology at the University of Pavia. He went on to lecture at Padua and many other Italian universities.\nIn 1464, Della Rovere was elected Minister General of the Franciscan order at the age of 50. In 1467, he was appointed Cardinal by Pope Paul\u00a0II with the titular church being the Basilica of San Pietro in Vincoli.\nBefore his papal election, Cardinal della Rovere was renowned for his unworldliness and had written learned treatises, including \"On the Blood of Christ\" and \"On the Power of God\".\nHis reputation for piety was one of the deciding factors that prompted the College of Cardinals to elect him Pope upon the unexpected death of Paul II at the age of fifty-four.\nPapacy.\nUpon being elected Pope, Della Rovere adopted the name Sixtus, which had not been used since the 5th century. One of his first acts was to declare a renewed crusade against the Ottoman Turks in Smyrna. However, after the conquest of Smyrna, the fleet disbanded. Some fruitless attempts were made towards unification with the Greek Church. For the remainder of his pontificate, Sixtus turned to temporal issues and dynastic considerations.\nNepotism.\nSixtus IV sought to strengthen his position by surrounding himself with relatives and friends. In the fresco by Melozzo da Forl\u00ec, he is accompanied by his Della Rovere and Riario nephews, not all of whom were made cardinals; the protonotary apostolic Pietro Riario (on his right), the future Pope Julius II/ Giuliano Della Rovere standing before him; and Girolamo Riario and Giovanni della Rovere, behind the kneeling Platina, author of the first humanist history of the popes.\nHis nephew, Pietro Riario, possibly also benefited from his alleged nepotism. He was successively promoted to be a cardinal, the bishop of Florence, the Patriarch of Constantinople and given some 45 additional benefices. Pietro became one of the richest men in Rome and was entrusted with Pope Sixtus\u00a0IV's foreign policy, in addition to being given an unofficial post as the de facto ruler of Rome. He reportedly spent 200,000 gold ducats on foodstuffs and festivities during two years in office. Pietro died prematurely in 1474. Chroniclers of his life seem to regard his death as unnatural and thus connect his alleged grandiose spending habits and the impression they left on his contemporaries as causal.\nCriticisms of Pietro's meteoric rise were not constrained to the charge of benefiting from nepotism as Sixtus IV's nephew, nor to allegations of possibly having been Sixtus IV's illegitimate son. Indeed, Pietro and his brother Girolamo Riario were alleged to have been lovers of Sixtus IV in polemics against the latter. According to the later published chronicle of the Italian historian Stefano Infessura, \"Diary of the City of Rome\", Sixtus was a \"lover of boys and a sodomite\" () awarding benefices and bishoprics in return for sexual favours and nominating a number of young men as cardinals. Sexualised polemics, in truth concerned with politics and not the sexual lives of their victims, were not uncommon during this time; but as Pfisterer (sic) notes \"the novel flood of accusations of sodomy against a pope\" and \"true flood of corresponding lampoons, reviling poems, and fictional epitaphs\" following his death are at the very least evidence for his contemporaries' opinions about the promotions of these young men.\nThe secular fortunes of the Della Rovere family began when Sixtus invested his nephew Giovanni with the lordship of Senigallia and arranged his marriage to the daughter of Federico III da Montefeltro, duke of Urbino; from that union came a line of Della Rovere dukes of Urbino that lasted until the line expired, in 1631. Six of the thirty-four cardinals that he created were his nephews.\nIn his territorial aggrandizement of the Papal States, his niece's son, Cardinal Raffaele Riario (for whom the Palazzo della Cancelleria was constructed) was suspected of colluding in the failed Pazzi conspiracy of 1478 to assassinate both Lorenzo de' Medici and his brother Giuliano and replace them in Florence with Sixtus IV's other nephew, Girolamo Riario. Francesco Salviati, Archbishop of Pisa and a main organizer of the plot, was hanged on the walls of the Florentine Palazzo della Signoria. Sixtus\u00a0IV replied with an interdict and two years of war with Florence.\nHowever, Infessura had partisan allegiances to the Colonna and so is not considered to be always reliable or impartial. The English churchman and Protestant polemicist John Bale, writing a century later, attributed to Sixtus \"the authorisation to practice sodomy during periods of warm weather\" to the \"Cardinal of Santa Lucia\". This prompted the noted historian of the Catholic Church, Ludwig von Pastor, to issue a firm rebuttal.\nForeign policy.\nSixtus continued a dispute with King Louis XI of France, who upheld the Pragmatic Sanction of Bourges (1438), which held that papal decrees needed royal assent before they could be promulgated in France. That was a cornerstone of the privileges claimed for the Gallican Church and could never be shifted as long as Louis\u00a0XI manoeuvred to replace King Ferdinand I of Naples with a French prince. Louis was thus in conflict with the papacy, and Sixtus could not permit it.\nOn 1 November 1478, Sixtus published the papal bull \"Exigit Sincerae Devotionis Affectus\" through which the Spanish Inquisition was established in the Kingdom of Castile. Sixtus consented under political pressure from Ferdinand of Aragon, who threatened to withhold military support from his kingdom of Sicily. Nevertheless, Sixtus IV quarrelled over protocol and prerogatives of jurisdiction; he was unhappy with the excesses of the Inquisition and condemned the most flagrant abuses in 1482.\nAs a temporal prince who constructed stout fortresses in the Papal States, he encouraged the Venetians to attack Ferrara, which he wished to obtain for another nephew. Ercole I d'Este, Duke of Ferrara, was allied with the Sforzas of Milan, the Medicis of Florence along with the King of Naples, normally a hereditary ally and champion of the papacy. The angered Italian princes allied to force Sixtus IV to make peace to his great annoyance.\nFor refusing to desist from the very hostilities that he himself had instigated and for being a dangerous rival to Della Rovere dynastic ambitions in the Marche, Sixtus placed Venice under interdict in 1483. He also lined the coffers of the state by unscrupulously selling high offices and privileges.\nIn ecclesiastical affairs, Sixtus promoted the dogma of the Immaculate Conception, which had been confirmed at the Council of Basle in 1439, and he designated 8 December as its feastday. In 1476, he issued the apostolic constitution \"Cum Praeexcelsa\", establishing a Mass and Office for the feast. He formally annulled the decrees of the Council of Constance in 1478.\nSlavery.\nThe two papal bulls issued by Pope Nicholas\u00a0V, \"Dum Diversas\" of 1452 and \"Romanus Pontifex\" of 1455, had effectively given the Portuguese the rights to acquire non-Christian slaves along the African Coast by force or trade. Those concessions were confirmed by Sixtus in his own bull, \"Aeterni regis\", of 21 June 1481. Arguably the \"ideology of conquest\" expounded in those texts became the means by which commerce and conversion were facilitated.\nIn November 1476, Isabel and Fernando ordered an investigation into rights of conquest in the Canary Islands, and in the spring of 1478, they sent Juan Rejon with sixty soldiers and thirty cavalry to the Grand Canary, where the natives retreated inland. Sixtus's earlier threats to excommunicate all captains or pirates who enslaved Christians in the bull \"Regimini Gregis\" of 1476 could have been intended to emphasise the need to convert the natives of the Canary Islands and Guinea and establish a clear difference in status between those who had converted and those who resisted. The ecclesiastical penalties were directed towards those who were enslaving the recent converts.\nPrincely patronage.\nAs a civic patron in Rome, even the anti-papal chronicler Stefano Infessura agreed that Sixtus should be admired. The dedicatory inscription in the fresco by Melozzo da Forl\u00ec in the Vatican Palace records: \"You gave your city temples, streets, squares, fortifications, bridges and restored the Acqua Vergine as far as the Trevi...\"\nIn addition to restoring the aqueduct that provided Rome an alternative to the river water, which had made the city famously unhealthy, he restored or rebuilt over 30 of Rome's dilapidated churches such as San Vitale (1475) and Santa Maria del Popolo, and he added seven new ones. The Sistine Chapel was sponsored by Sixtus IV, as was the \"Ponte Sisto\", the Sistine Bridge (the first new bridge across the Tiber since Antiquity), and the building of \"Via Sistina\" (later named \"Borgo Sant'Angelo\"), a road leading from Castel Sant'Angelo to Saint Peter.\nAll of that was done to facilitate the integration of the Vatican Hill and Borgo with the heart of Old Rome. That was part of a broader scheme of urbanization carried out under Sixtus IV, who swept the long-established markets from the Campidoglio in 1477 and decreed in a bull of 1480 the widening of streets and the first post-Roman paving, the removal of porticoes and other post-classical impediments to free public passage.\nAt the beginning of his papacy, in 1471, Sixtus had donated several historically important Roman sculptures that founded a papal collection of art, which would eventually develop into the collections of the Capitoline Museums. He also refounded, enriched and enlarged the Vatican Library. He had Regiomontanus attempt the first sanctioned reorganisation of the Julian calendar and increased the size and prestige of the papal chapel choir, bringing singers and some prominent composers (Gaspar van Weerbeke, Marbrianus de Orto and Bertrandus Vaqueras) to Rome from the north.\nIn addition to being a patron of the arts, Sixtus was a patron of the sciences. Before he became pope, he had spent time at the very liberal and cosmopolitan University of Padua, which maintained considerable independence from the Church and had a very international character.\nAs Pope, he issued a papal bull allowing local bishops to give the bodies of executed criminals and unidentified corpses to physicians and artists for dissection. It was that access to corpses which allowed the anatomist Vesalius, along with Titian's pupil Jan Stephen van Calcar, to complete the revolutionary medical/anatomical text \"De humani corporis fabrica\".\nOther activities.\nConsistories.\nThe Pope created 34 cardinals in eight consistories held during his reign, among them three nephews, one grandnephew and one other relative, thus continuing the practice of nepotism that he and his successors would engage in during this period.\nCanonizations and beatifications.\nSixtus IV named seven new saints, with the most notable being Bonaventure (1482); he also beatified one person, John Buoni (1483).\nUppsala University.\nIn 1477, Sixtus IV issued a papal bull authorizing the creation of Uppsala University \u2013 the first university in Sweden and in the whole of Scandinavia. The choice of this location for the university derived from the fact that the archbishopric of Uppsala had been one of the most important sees in Sweden proper since Christianity first spread to this region in the ninth century, as well as Uppsala being long-standing hub for regional trade. Uppsala's bull, which granted the university its corporate rights, established a number of provisions. Among the most important of these was that the university was officially given the same freedoms and privileges as the University of Bologna. This included the right to establish the four traditional faculties of theology, law (Canon Law and Roman law), medicine, and philosophy, and to award the bachelor's, master's, licentiate, and doctoral degrees. The archbishop of Uppsala was also named as the university's Chancellor, and was charged with maintaining the rights and privileges of the university and its members. This act of Sixtus IV had a profound long-term effect on the society and culture of Sweden, an effect which continues up to the present.\nDeath.\nSixtus IV became ill on 8 August 1484; this illness worsened on 10 August while the pope was attending an event in Rome. He felt unwell that evening and was forced to cancel a meeting he was to hold with his cardinals the following morning. The Pope grew weaker during the night of 11 August and he was unable to sleep. Sixtus IV died the following evening \u2013 12 August.\nThe envoy of the Medici family summed up Sixtus' reign in the announcement to his master, \"Today at 5 o'clock His Holiness Sixtus IV departed this life \u2013 may God forgive him!\"\nPope Sixtus's tomb was destroyed in the Sack of Rome in 1527. Today, his remains, along with the remains of his nephew Pope Julius II (Giuliano della Rovere), are interred in St. Peter's Basilica, in the floor in front of the monument to Pope Clement\u00a0X. A marble tombstone marks the site.\nHis bronze funerary monument, now in the basement Treasury of St. Peter's Basilica, made like a giant casket of goldsmith's work, is by Antonio del Pollaiuolo; it was completed by 1493. The top of the casket is a lifelike depiction of the Pope lying in state. Around the sides are bas-relief panels depicting allegorical female figures representing Grammar, Rhetoric, Arithmetic, Geometry, Music, Painting, Astronomy, Philosophy, and Theology\u2014the classical liberal arts, with the addition of painting and theology. Each figure incorporates the oak tree (\"rovere\" in Italian), symbol of Sixtus IV. The overall program of the panels, their beauty, complex symbolism, classical references and their relative arrangement are compelling and comprehensive illustrations of the Renaissance worldview. None of them actually states how he died.\nCardinals.\nSixtus created an unusually large number of cardinals during his pontificate (23) who were drawn from the roster of the princely houses of Italy, France and Spain, thus ensuring that many of his policies continued after his death:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nPortrayals.\nPope Sixtus is portrayed by Raoul Bova in the second season, and John Lynch in the third season of the TV series \"\".\nPope Sixtus is also portrayed by James Faulkner in all three seasons of the Starz TV series \"Da Vinci's Demons\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24846", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=24846", "title": "Primary pigments", "text": ""}
{"id": "24848", "revid": "754619", "url": "https://en.wikipedia.org/wiki?curid=24848", "title": "Project lifecycle", "text": ""}
{"id": "24849", "revid": "2952402", "url": "https://en.wikipedia.org/wiki?curid=24849", "title": "Panama Canal", "text": "Shipping route across Central America\nThe Panama Canal () is an artificial waterway in Panama that connects the Caribbean Sea with the Pacific Ocean. It cuts across the narrowest point of the Isthmus of Panama, and is a conduit for maritime trade between the Atlantic Ocean and the Pacific Ocean. Locks at each end lift ships up to Gatun Lake, an artificial fresh water lake above sea level, created by damming the Chagres River and Lake Alajuela to reduce the amount of excavation work required for the canal. Locks then lower the ships at the other end. An average of of fresh water is used in a single passing of a ship. The canal is threatened by low water levels during droughts.\nThe Panama Canal shortcut greatly reduces the time for ships to travel between the Atlantic and Pacific oceans, enabling them to avoid the lengthy, hazardous route around the southernmost tip of South America via the Drake Passage, the Strait of Magellan or the Beagle Channel. Its construction was one of the largest and most difficult engineering projects ever undertaken. Since its inauguration on 15 August 1914, the canal has succeeded in shortening maritime communication in time and distance, invigorating maritime and economic transportation by providing a short and relatively inexpensive transit route between the two oceans, decisively influencing global trade patterns, boosting economic growth in developed and developing countries, as well as providing the basic impetus for economic expansion in many remote regions of the world.\nColombia, France, and later the United States controlled the territory surrounding the canal during construction. France began work on the canal in 1881, but stopped in 1889 because of a lack of investors' confidence due to engineering problems and a high worker mortality rate. The US took over the project in 1904 and opened the canal in 1914. The US continued to control the canal and the surrounding Panama Canal Zone until the Torrijos\u2013Carter Treaties provided for its handover to Panama in 1977. After a period of joint American\u2013Panamanian control, the Panamanian government took control in 1999. It is now managed and operated by the Panamanian government-owned Panama Canal Authority.\nThe original locks are wide and allow the passage of Panamax ships. A third, wider lane of locks was constructed between September 2007 and May 2016. The expanded waterway began commercial operation on 26 June 2016. The new locks allow for the transit of larger, Neopanamax ships.\nAnnual traffic has risen from about 1,000 ships in 1914, when the canal opened, to 14,702 vessels in 2008, for a total of 333.7 million Panama Canal/Universal Measurement System (PC/UMS) tons. By 2012, more than 815,000 vessels had passed through the canal. In that year, the top five users of the canal were the United States, China, Chile, Japan, and South Korea. In 2017, it took ships an average of 11.38 hours to pass between the canal's two outer locks. The American Society of Civil Engineers has ranked the Panama Canal one of the Seven Wonders of the Modern World.\nHistory.\nEarly proposals in Panama.\nThe idea of the Panama Canal dates back to 1513, when the Spanish conquistador Vasco N\u00fa\u00f1ez de Balboa (c.1475-1519) first crossed the Isthmus of Panama. He wrote in his journal the possibility of a canal but did not take action. European powers soon noticed the possibility of digging a water passage between the Atlantic and Pacific Oceans across this narrow land bridge between North and South America. The earliest proposal dates to 1534, when the Holy Roman Emperor Charles V ordered a survey for a route through the Americas in order to ease the voyage for ships traveling between Spain and Peru. In 1668, the English physician and philosopher Sir Thomas Browne specifically proposed the Isthmus of Panama as the most convenient place for such a canal.\nThe first attempt to make the isthmus part of a trade route was the ill-fated Darien scheme, launched by the Kingdom of Scotland (1698\u20131700), which was abandoned because of the inhospitable conditions.\nIn 1811, the German naturalist Alexander von Humboldt published an essay on the geography of the Spanish colonies in Central America (https://; translated into English as: https://). In the essay, he considered five possible routes for a canal across Central America, including Panama, but concluded that the most promising location was across Nicaragua, traversing Lake Nicaragua. His recommendations influenced the British to attempt a canal across Nicaragua in 1843. Although this attempt in the end came to nothing, it resulted in the Clayton\u2013Bulwer Treaty (1850) between the United Kingdom and the United States, in which the two nations bound each other to joint control of any canal built in Nicaragua or (by implication) anywhere in Central America.\n In 1846, the Mallarino\u2013Bidlack Treaty, negotiated between the US and New Granada (the predecessor of Colombia), granted the United States transit rights and the right to intervene militarily in the isthmus. In 1848, the discovery of gold in California created a demand for a crossing of Panama as a practical route between the Atlantic and Pacific oceans. This demand was exploited by American businessman William Henry Aspinwall, who ran steamship legs from New York City to Panama, and from Panama to California, with an overland portage through Panama. This route was soon exploited by other businessmen, such as Cornelius Vanderbilt. Between 1850 and 1855, a syndicate founded by Aspinwall built a railroad (now the Panama Canal Railway) from Col\u00f3n on the Caribbean Sea to Panama City. The project cost US$8,000,000 (six times the estimated cost) and between 6,000 and 12,000 of construction workers who succumbed to tropical diseases. The railroad soon became immensely profitable for its owners.\nIn 1870, US President Grant established an Interoceanic Canal Commission, which included Chief of Engineers Brigadier General Andrew A Humphreys as its members. It commissioned several naval officers, including Commander Thomas Oliver Selfridge Jr., to investigate the possible routes suggested by Humboldt for a canal across Central America. The commission decided in favour of Nicaragua, establishing this as the preferred route amongst American policy-makers.\nFrench construction attempts, 1881\u20131899.\nThe French diplomat and entrepreneur Ferdinand de Lesseps and engineer Philippe Bunau-Varilla were the driving forces behind French attempts to construct the Panama Canal (1881\u20131889). De Lesseps had made his reputation by successfully constructing the Suez Canal (1859\u20131869), a route that had soon proved its value in international commerce. After this success, he actively sought new projects. In 1875, de Lesseps was approached by the Soci\u00e9t\u00e9 Civile Internationale du Canal Interoc\u00e9anique par l'isthme du Darien (also known as the \"T\u00fcrr Syndicate\"), a syndicate formed to promote the building of an interoceanic canal across Panama. Its directors were Hungarian freedom fighter Istv\u00e1n T\u00fcrr, financier Jacques de Reinach and T\u00fcrr's brother-in-law Lt. Lucien Bonaparte-Wyse. Between 1876 and 1878, Bonaparte-Wyse and Armand Reclus investigated several potential routes across the isthmus of Panama. Bonaparte-Wyse rode by horseback to Bogot\u00e1, where he obtained a concession from the Colombian government to build a canal across Panama (20 March 1878). The agreement, known as the Wyse Concession, was valid for 99 years and allowed the company to dig a canal and exploit it.\n In May 1879, de Lesseps convened an international congress in Paris to examine the possibilities of a ship canal across Central America. Among the 136 delegates of 26 countries, only 42 were engineers, with the remainder being speculators, politicians, and friends of de Lesseps, who used the congress to promote fundraising for his preferred scheme, which was to build a sea-level canal across Panama, similar in manner to the Suez Canal. De Lesseps won the approval of a majority of the delegates for his plan despite reservations expressed by some who preferred a canal in Nicaragua or who emphasized the likely engineering difficulties and health risks. Following the congress, de Lesseps organized a company to construct the canal (the Compagnie Universelle du Canal Interoc\u00e9anique de Panama). The company bought the Wyse Concession from the T\u00fcrr Syndicate and raised considerable funds from small French investors on the basis of the huge profits generated by the Suez Canal.\nConstruction of the canal began on 1 January 1881, with digging at Culebra beginning on 22 January. A large labor force was assembled, numbering about 40,000 in 1888 (nine-tenths of whom were afro-Caribbean workers from the West Indies). Although the project attracted good, well-paid French engineers, retaining them was difficult due to disease. The death toll from 1881 to 1889 was estimated at over 22,000, of whom as many as 5,000 were French citizens.\n From the beginning, the French canal project faced difficulties. Although the Panama Canal needed to be only 40 percent as long as the Suez Canal, it was much more of an engineering challenge because of the combination of tropical rain forests, debilitating climate, the need for canal locks, and the lack of any ancient route to follow. Beginning with Armand Reclus in 1882, a series of principal engineers resigned in discouragement. The workers were unprepared for the conditions of the rainy season, during which the Chagres River, where the canal started, became a raging torrent, rising up to . Workers had to continually widen the main cut through the mountain at Culebra and reduce the angles of the slopes to minimize landslides into the canal. The dense jungle was alive with venomous snakes, insects, and spiders, but the worst challenges were yellow fever, malaria, and other tropical diseases, which killed thousands of workers; by 1884, the death rate was over 200 per month. Public health measures were ineffective because the role of the mosquito as a disease vector was then unknown. Conditions were downplayed in France to avoid recruitment problems, but the high mortality rate made it difficult to maintain an experienced workforce.\nIn France, de Lesseps kept the investment and supply of workers flowing long after it was obvious that the targets were not being met, but eventually, the money ran out. The French effort went bankrupt in 1889 after reportedly spending US$287,000,000 &amp;lpar;&amp;dollar;\u00a0in &lt;templatestyles src=\"Template:Tooltip/styles.css\" /&gt;); an estimated 22,000 men died from disease and accidents, and the savings of 800,000 investors were lost. Work was suspended on 15 May, and in the ensuing scandal, known as the Panama affair, some of those deemed responsible were prosecuted, including Gustave Eiffel. De Lesseps and his son Charles were found guilty of misappropriation of funds and sentenced to five years' imprisonment. This sentence was later overturned, and the father, at age 88, was never imprisoned.\nIn 1894, a second French company, the Compagnie Nouvelle du Canal de Panama, was created to take over the project. A minimal workforce of a few thousand people was employed primarily to comply with the terms of the Colombian Panama Canal concession, to run the Panama Railroad, and to maintain the existing excavation and equipment in salable condition. The company sought a buyer for these assets, with an asking price of US$109,000,000 &amp;lpar;&amp;dollar;\u00a0in &lt;templatestyles src=\"Template:Tooltip/styles.css\" /&gt;). In the meantime, they continued with enough activity to maintain their franchise. Two lobbyists would become particularly active in later negotiations to sell the interests of the Compagnie Nouvelle. The American lawyer William Nelson Cromwell began looking after the interests of the company in 1894, after first acting for the related Panama Railroad. He would become deeply involved as a lobbyist in the American decisions to continue the canal in Panama, and to support Panamanian independence. The other was Philippe Bunau-Varilla, who, as one of the major subcontractors to the first French company, had been compelled by the receivers to take shares in the Compagnie Nouvelle, and was then named director of engineering in the Compagnie Nouvelle.\nUnited States acquisition.\nIn 1897\u20131899, US President William McKinley (1897\u20131901) tasked two commissions headed by Admiral John Grimes Walker to recommend the best route for a canal across Central America. Although the first commission had been tasked only to consider routes across Nicaragua, William Nelson Cromwell successfully lobbied the Government to broaden the terms of reference to also consider the Panamanian isthmus. The commission issued a confidential preliminary report on 21 November 1901, shortly after Theodore Roosevelt had become president following the assassination of McKinley. The preliminary report favored the Nicaragua route on pricing grounds; although the commissioners noted the technical advantages of the Panama route, they considered its informally quoted price of $109 million to be excessive. The report was leaked to Philippe Bunau-Varilla, who during an emergency shareholders' meeting of the Compagnie Nouvelle amended the price to a formal offer of $40 million, the estimated sale value of the existing Panama assets acceptable to the commissioners. On 10 December, George S. Morison, the most eminent engineer on the commission, wrote a letter to President Roosevelt giving the technical reasons for preferring the Panama route. In January 1902, Roosevelt called the members of the commission into his office individually and asked them to give their own personal evaluations of the best route. Roosevelt then held a closed meeting with the entire commission, where he made it clear that he wanted the offer to take over the Panama route from the Compagnie Nouvelle to be accepted. In late January, the commission issued a final report, unanimously recommending Panama.\n The proposal to purchase the French rights to Panama faced considerable opposition in Congress, since the Nicaragua proposal was preferred by many. The Nicaragua route was championed by Senator John T. Morgan, who grilled members of the Walker Commission on their reasons for recommending Panama. Nonetheless, the proposal to purchase the French rights and property in Panama for $40 million was eventually approved by both Houses of Congress, championed by Senator Mark Hanna. He was supported by the known backing of President Roosevelt for the proposal, and by the lobbying efforts of Cromwell and Bunau-Varilla. In June 1902, the US Senate voted in favor of the Spooner Act to pursue the Panamanian option, provided the necessary rights could be obtained.\nOn 22 January 1903, the Hay\u2013Herr\u00e1n Treaty was signed by United States Secretary of State John M. Hay and Colombian Charg\u00e9 Tom\u00e1s Herr\u00e1n. For $10 million and an annual payment, it would have granted the United States a renewable lease in perpetuity from Colombia on the land proposed for the canal. The treaty was ratified by the US Senate on 14 March 1903, but the Senate of Colombia unanimously rejected the treaty since it had become significantly unpopular in Bogot\u00e1 due to concerns over insufficient compensation, threat to sovereignty, and perpetuity.\n Roosevelt changed tactics, based in part on the Mallarino\u2013Bidlack Treaty of 1846, and actively supported the separation of Panama from Colombia. Shortly after recognizing Panama, he signed a treaty with the new Panamanian government under terms similar to the Hay\u2013Herr\u00e1n Treaty.\nOn 2 November 1903, US warships blocked sea lanes against possible Colombian troop movements en route to put down the Panama rebellion. Panama declared independence on 3 November 1903. The United States quickly recognized the new nation. This happened so quickly that by the time the Colombian government in Bogot\u00e1 launched a response to the Panamanian uprising US troops had already entered the rebelling province. The Colombian troops dispatched to Panama were hastily assembled conscripts with little training. While these conscripts may have been able to defeat the Panamanian rebels, they would not have been able to defeat the US army troops that were supporting the Panamanian rebels. An army of conscripts was the best response the Colombians could muster, as Colombia was recovering from a civil war between Liberals and Conservatives from October 1899, to November 1902, known as the \"Thousand Days War\". The US was fully aware of these conditions and even incorporated them into the planning of the Panama intervention as the US acted as an arbitrator between the two sides. The peace treaty that ended the \"Thousand Days War\" was signed on the USS \"Wisconsin\" on 21 November 1902. While in port, the US also brought engineering teams to Panama with the peace delegation to begin planning the canal's construction before the US had even gained the rights to build the canal. All these factors would result in the Colombians being unable to put down the Panamanian rebellion and expel the United States troops occupying what today is the independent nation of Panama.\nOn 6 November 1903, Philippe Bunau-Varilla, as Panama's ambassador to the United States, signed the Hay\u2013Bunau-Varilla Treaty, granting rights to the United States to build and administer the Panama Canal Zone and its defenses. This treaty gave the US some rights to the canal \"in perpetuity\", but in article 22 limited other rights to a lease period of 99 years. Almost immediately, the treaty was condemned by many Panamanians as an infringement on their country's new national sovereignty. This would later become a contentious diplomatic issue among Colombia, Panama, and the United States.\nPresident Roosevelt famously stated, \"I took the Isthmus, started the canal and then left Congress not to debate the canal, but to debate me.\" Several parties in the United States called this an act of war on Colombia: \"The New York Times\" described the support given by the United States to Bunau-Varilla as an \"act of sordid conquest\". The \"New York Evening Post\" called it a \"vulgar and mercenary venture\". The US maneuvers are often cited as the classic example of US gunboat diplomacy in Latin America, and the best illustration of what Roosevelt meant by the old African adage, \"Speak softly and carry a big stick [and] you will go far.\"\n In 1904, the United States purchased the French equipment and excavations, including the Panama Railroad, for US$40 million, of which $30 million related to excavations completed, primarily in the Culebra Cut, valued at about . The United States also paid the new country of Panama $10 million and a $250,000 payment each following year.\nIn 1921, Colombia and the United States entered into the Thomson\u2013Urrutia Treaty, in which the United States agreed to pay Colombia $25 million: $5 million upon ratification, and four $5 million annual payments, and grant Colombia special privileges in the Canal Zone. In return, Colombia recognized Panama as an independent nation.\nUnited States construction of the Panama canal, 1904\u20131914.\nThe US formally took control of the canal property on 4 May 1904, inheriting from the French a depleted workforce and a vast jumble of buildings, infrastructure, and equipment, much of it in poor condition. A US government commission, the Isthmian Canal Commission (ICC), was established to oversee construction; it was given control of the Panama Canal Zone, over which the United States exercised sovereignty. The commission reported directly to Secretary of War William Howard Taft and was directed to avoid the inefficiency and corruption that had plagued the French 15 years earlier.\nOn 6 May 1904, President Theodore Roosevelt appointed John Findley Wallace, formerly chief engineer and finally general manager of the Illinois Central Railroad, as chief engineer of the Panama Canal Project. Overwhelmed by the disease-plagued country and forced to use often dilapidated French infrastructure and equipment, as well as being frustrated by the overly bureaucratic ICC, Wallace resigned abruptly in June 1905. The ICC brought on a new chairman, Theodore P. Shonts, and a new chief engineer was appointed, John Frank Stevens, a self-educated engineer who had built the Great Northern Railroad. Stevens was not a member of the ICC; he increasingly viewed its bureaucracy as a serious hindrance, bypassing the commission and sending requests and demands directly to the Roosevelt administration in Washington, DC.\nOne of Stevens' first achievements in Panama was in building and rebuilding the housing, cafeterias, hotels, water systems, repair shops, warehouses, and other infrastructure needed by the thousands of incoming workers. Stevens began the recruitment effort to entice thousands of workers from the United States and other areas to come to the Canal Zone to work. Workers from the Caribbean\u00a0\u2013 called \"Afro-Panamanians\"\u00a0\u2013 came in large numbers and many settled permanently. Stevens tried to provide accommodation in which the workers could work and live in reasonable safety and comfort. He also re-established and enlarged the railway, which was to prove crucial in transporting millions of tons of soil from the cut through the mountains to the dam across the Chagres River.\nColonel William C. Gorgas had been appointed chief sanitation officer of the canal construction project in 1904. Gorgas implemented a range of measures to minimize the spread of deadly diseases, particularly yellow fever and malaria, which had recently been shown to be mosquito-borne following the work of Cuban epidemiologist Carlos Finlay, American pathologist Walter Reed and Scottish physician Sir Ronald Ross. Investment was made in extensive sanitation projects, including city water systems, fumigation of buildings, spraying of insect-breeding areas with oil and larvicide, installation of mosquito netting and window screens, and elimination of stagnant water. Despite opposition from the commission (one member said his ideas were barmy), Gorgas persisted, and when Stevens arrived, he threw his weight behind the project. After two years of extensive work, the mosquito-spread diseases were nearly eliminated. Despite the monumental effort, about 5,600 workers died from disease and accidents during the US construction phase of the canal. Of these, the great majority were West Indian laborers, particularly those from Barbados. The number of Americans who died was about 350.\nBesides healthier and far better living conditions for the workers, another benefit given to American citizens working on the Canal was a medal for two years of service. Additional bars were added for each two-year period after that. Designed by Victor D. Brenner and featuring the then-current president they were popularly known as The Roosevelt Medal. A total of 7,189 were ultimately issued, with a few people receiving as many as four bars.\nIn 1905, a US engineering panel was commissioned to review the canal design, which had not been finalized. In January 1906 the panel, in a majority of eight to five, recommended to President Roosevelt a sea-level canal, as had been attempted by the French and temporarily abandoned by them in 1887 for a ten locks system designed by Philippe Bunau-Varilla, and definitively in 1898 for a lock-and-lake canal designed by the Comit\u00e9 Technique of the Compagnie Nouvelle de Canal de Panama as conceptualized by Adolphe Godin de L\u00e9pinay in 1879. But in 1906 Stevens, who had seen the Chagres in full flood, was summoned to Washington; he declared a sea-level approach to be \"an entirely untenable proposition\". He argued in favor of a canal using a lock system to raise and lower ships from a large reservoir above sea level. This would create both the largest dam (Gatun Dam) and the largest human-made lake (Gatun Lake) in the world at that time. The water to refill the locks would be taken from Gatun Lake by opening and closing enormous gates and valves and letting gravity propel the water from the lake. Gatun Lake would connect to the Pacific through the mountains at the Gaillard (Culebra) Cut. Unlike Godin de L\u00e9pinay with the Congr\u00e8s International d'Etudes du Canal Interoc\u00e9anique, Stevens successfully convinced Roosevelt of the necessity and feasibility of this alternative scheme.\nThe construction of a canal with locks required the excavation of more than of material over and above the excavated by the French. As quickly as possible, the Americans replaced or upgraded the old, unusable French equipment with new construction equipment that was designed for a much larger and faster scale of work. Over a hundred railroad-mounted steam shovels were purchased, 77 from Bucyrus-Erie and 25 from the Marion Power Shovel Company. These were joined by enormous steam-powered cranes, giant hydraulic rock crushers, concrete mixers, dredges, and pneumatic power drills, nearly all of which were manufactured by new, extensive machine-building technology developed and built in the United States. The railroad also had to be comprehensively upgraded with heavy-duty, double-tracked rails over most of the line to accommodate new rolling stock. In many places, the new Gatun Lake flooded over the original rail line, and a new line had to be constructed above Gatun Lake's waterline.\nBetween 1912 and 1914 there was a controversy about the tolls for the canal.\nGoethals replaces Stevens as chief engineer, 1907\u20131914.\nIn 1907, Stevens resigned as chief engineer. His replacement, appointed by President Theodore Roosevelt, was US Army Major George Washington Goethals of the US Army Corps of Engineers. Soon to be promoted to lieutenant colonel and later to general, he was a strong, West Point-trained leader and civil engineer with experience in canals (unlike Stevens). Goethals directed the work in Panama to a successful conclusion in 1914, two years ahead of the target date of 10 June 1916.\nGoethals divided the engineering and excavation work into three divisions: Atlantic, Central, and Pacific. The Atlantic Division, under Major William L. Sibert, was responsible for construction of the massive breakwater at the entrance to Bah\u00eda Lim\u00f3n, the Gatun locks, and their approach channel, and the immense Gatun Dam. The Pacific Division, under Sydney B. Williamson (the only civilian member of this high-level team), was similarly responsible for the Pacific breakwater in Panama Bay, the approach channel to the locks, and the Miraflores and Pedro Miguel locks and their associated dams and reservoirs.\nThe Central Division, under Major David du Bose Gaillard of the United States Army Corps of Engineers, was assigned one of the most difficult parts: excavating the Culebra Cut through the continental divide to connect Gatun Lake to the Pacific Panama Canal locks.\nOn 10 October 1913, President Woodrow Wilson sent a signal from the White House by telegraph which triggered the explosion that destroyed the Gamboa Dike. This flooded the Culebra Cut, thereby joining the Atlantic and Pacific oceans via the Panama Canal. \"Alexandre La Valley\" (a floating crane built by Lobnitz &amp; Company and launched in 1887) was the first self-propelled vessel to transit the canal from ocean to ocean. This vessel crossed the canal from the Atlantic in stages during construction, finally reaching the Pacific on 7 January 1914. SS \"Cristobal\" (a cargo and passenger ship built by Maryland Steel, and launched in 1902 as SS \"Tremont\") on 3 August 1914, was the first ship to transit the canal from ocean to ocean.\nThe construction of the canal was completed in 1914, 401 years after Panama was first crossed overland by the Europeans in Vasco N\u00fa\u00f1ez de Balboa's party of conquistadores. The United States spent almost $500 million (roughly equivalent to $ billion in 2024) to finish the project. This was by far the largest American engineering project to date. The canal was formally opened on 15 August 1914, with the passage of the cargo ship .\nThe opening of the Panama Canal in 1914 caused a severe drop in traffic along Chilean ports due to shifts in maritime trade routes, despite the closure of the canal for nearly seven months after a landslide in the Culebra Cut on 18 September 1915. The burgeoning sheep farming business in southern Patagonia suffered a significant setback by the change in trade routes, as did the economy of the Falkland Islands.\nThroughout this time, Ernest \"Red\" Hallen was hired by the Isthmian Canal Commission to document the progress of the work.\nIn 1914, steam shovels from the Panama Canal were purchased and put to use in Chuquicamata copper mine of northern Chile.\nUS control and handover to Panama, 1914\u20131999.\nBy the 1930s, water supply became an issue for the canal, prompting construction of the Madden Dam across the Chagres River above Gatun Lake. Completed in 1935, the dam created Madden Lake (later Lake Alajuela), which provides additional water storage for the canal. In 1939, construction began on a further major improvement: a new set of locks large enough to carry the larger warships that the United States was building at the time and planned to continue building. The work proceeded for several years, and significant excavation was carried out on the new approach channels, but the project was canceled after World War II.\nAfter World War II, US control of the canal and the Canal Zone surrounding it became contentious; relations between Panama and the United States became increasingly tense. Many Panamanians felt that the Zone rightfully belonged to Panama; student protests were met by the fencing-in of the zone and an increased military presence there. Demands for the United States to hand over the canal to Panama increased after the Suez Crisis in 1956, when the United States used financial and diplomatic pressure to force France and the UK to abandon their attempt to retake control of the Suez Canal, previously nationalized by the Nasser regime in Egypt. Panamanian unrest culminated in riots on Martyr's Day, 9 January 1964, when about 20 Panamanians and 3\u20135 US soldiers were killed.\nA decade later, in 1974, negotiations toward a settlement began and resulted in the Torrijos\u2013Carter Treaties. On 7 September 1977, the treaty was signed by President of the United States Jimmy Carter and Omar Torrijos, \"de facto\" leader of Panama. This mobilized the process of granting the Panamanians free control of the canal so long as Panama signed a treaty guaranteeing the permanent neutrality of the canal. The treaty led to full Panamanian control effective at noon on 31 December 1999, and the Panama Canal Authority (ACP) assumed command of the waterway. The Panama Canal remains one of the chief revenue sources for Panama.\nBefore this handover, the government of Panama held an international bid to negotiate a 25-year contract for operation of the container shipping ports located at the canal's Atlantic and Pacific outlets. The contract was not affiliated with the ACP or Panama Canal operations and was won by the firm Hutchison Whampoa, a Hong Kong\u2013based shipping interest owned by Li Ka-shing.\n21st century.\nIn 2015, Hutchison Whampoa merged with Cheung Kong Group and was renamed CK Hutchison Holdings.\nDonald Trump comments and reactions.\nOn 21 December 2024, then US President-elect Donald Trump asserted that the United States should retake control of the Panama Canal from Panama, claiming that the rates Panama was charging American ships were \"exorbitant\" and in violation of the Torrijos\u2013Carter Treaties. The following day, he claimed that the canal was \"falling into the wrong hands\", referring to China. Shortly after Trump's comments, Panamanian president Jos\u00e9 Ra\u00fal Mulino responded, denying that the United States was being unfairly charged or that anyone besides Panama was in full control of the canal, and affirming that the canal was part of the country's \"inalienable patrimony\".\nThough the Hong Kong company Hutchison Port Holdings does have a concession to operate two ports near the ends of the canal \u2013 the Balboa port on the Pacific side and the Crist\u00f3bal port on the Atlantic side \u2013 neither these ports nor the company control access to the canal. Three other ports near the canal's ends are operated by companies from Taiwan and Singapore, and joint venture from the United States and Panama. The government of Panama receives dividends from the Hutchinson concession, but the locks and Marine Traffic Control are run independently by the Panama Canal Authority, and the harbor pilots that guide ships are Panamanian.\nOn 24 December, a protest was held at the US Embassy in Panama City over Trump's threat to take back the Panama Canal. Protesters referred to him as a \"public enemy\" of Panama. On the same day, the Bolivarian Alliance for the Peoples of Our America (ALBA), made up of ten Central and South American countries, denounced Trump's comments and affirmed its support for Panama's \"sovereignty, territorial integrity and self-determination.\"\nIn a 7 January 2025 press conference, Trump vowed to gain control of the Panama Canal. He refused to rule out economic and military action against Panama to seize control of the canal, to secure what he called US \"economic security.\" He reiterated his intent to take back control of the canal in his inaugural address on 20 January.\nOn 5 February, the United States Department of State posted on Twitter that the Panama Canal would no longer be charging United States government vessels to cross. President Mulino called this an \"intolerable\" falsehood, and Secretary of State Marco Rubio (who had departed Panama a few days earlier) had to correct the announcement, saying he \"expects\" Panama to begin doing so in return for the Torrijos\u2013Carter Treaties' guarantee of US military protection in the event of an attack on the canal.\nOn 5 March 2025, the American investment company BlackRock announced that a consortium, including also Global Infrastructure Partners and Terminal Investment Limited, would buy CK Hutchison's 80% holding in Hutchison Port Holdings, which owns ports at either end of the canal. According to \"The New York Times\", the Hong Kong-based Li family felt \"under political pressure to exit the ports business\"; discussions with BlackRock about the Panama Canal had begun only a few weeks prior, coinciding with the beginning of the Trump administration.\nCanal.\nLayout.\n&lt;templatestyles src=\"Routemap/styles.css\"/&gt;\nWhile globally the Atlantic Ocean is east of the isthmus and the Pacific is west, the general direction of the canal passage from the Atlantic to the Pacific is from northwest to southeast, because of the shape of the isthmus at the point the canal occupies. The Bridge of the Americas () at the Pacific side is about a third of a degree east of the Col\u00f3n end on the Atlantic side. Still, in formal nautical communications, the simplified directions \"southbound\" and \"northbound\" are used.\nThe canal consists of artificial lakes, several improved and artificial channels, and three sets of locks. An additional artificial lake, Alajuela Lake (known during the American administration as Madden Lake), acts as a reservoir for the canal. The layout of the canal as seen by a ship passing from the Atlantic to the Pacific is:\nThus, the total length of the canal is . In 2017 it took ships an average of 11.38 hours to pass between the canal's two outer locks.\nGatun Lake.\nCreated in 1913 by damming the Chagres River, the Gatun Lake is a key part of the Panama Canal, providing the millions of liters of water necessary to operate its locks each time a ship passes through. At time of formation, Gatun Lake was the largest human-made lake in the world.\nLock size.\nBecause of the importance of the canal to international trade, many ships are built to the maximum size allowed.\nFor its first century, the width and length of ships that may transit the canal was limited by the Pedro Miguel Locks; their draft by the canal's minimum depth; and their height by the main span of the Bridge of the Americas at Balboa. Ships built to those limits are known as Panamax vessels. A Panamax cargo ship typically has a deadweight tonnage (DWT) of 65,000\u201380,000 tons, but its actual cargo is restricted to about 52,500 tons because of the canal's draft restrictions within the canal. The longest ship ever to transit the canal was the \"San Juan Prospector\" (now \"Marcona Prospector\"), an ore-bulk-oil carrier that is long with a beam of .\nInitially the locks at Gatun were designed to be wide. In 1908, the United States Navy requested that the width be increased to at least to allow the passage of large warships. A compromise was made and the locks were built wide. Each lock is long, with the walls ranging in thickness from at the base to at the top. The central wall between the parallel locks at Gatun is thick and over high. The steel lock gates measure an average of thick, wide, and high.\nPanama Canal pilots were initially unprepared to handle the flight decks of aircraft carriers, which protrude beyond the hull on either side of the ship. When made her first trip through the Gatun Locks in 1928, the ship knocked over all the concrete lamp posts along the canal.\nIn 2016, a decade-long expansion project created larger locks, allowing bigger ships to transit through deeper and wider channels. The allowed dimensions of ships using these locks increased by 25 percent in length, 51 percent in beam, and 26 percent in draft, as defined by Neopanamax metrics.\nTolls.\nAs with a toll road, vessels transiting the canal must pay tolls. Tolls for the canal are set by the Panama Canal Authority and are based on vessel type, size, and the type of cargo.\nFor container ships, the toll is assessed on the ship's capacity expressed in twenty-foot equivalent units (TEUs), one TEU being the size of a standard intermodal shipping container. Effective 1 April 2016, this toll went from US$74 per loaded container to $60 per TEU capacity plus $30 per loaded container for a potential $90 per TEU when the ship is full. A Panamax container ship may carry up to 4,400\u00a0TEU. The toll is calculated differently for passenger ships and for container ships carrying no cargo (\"in ballast\"). As of \u00a0, 2016[ [update]], the ballast rate is US$60, down from US$65.60 per TEU.\nPassenger vessels in excess of 30,000 tons (PC/UMS) pay a rate based on the number of berths, that is, the number of passengers that can be accommodated in permanent beds. Since 1 April 2016, the per-berth charge is $111 for unoccupied berths and $138 for occupied berths in the Panamax locks. Starting in 2007, this fee has greatly increased the tolls for such ships. Passenger vessels of less than 30,000 tons or less than 33 tons per passenger are charged according to the same per-ton schedule as are freighters. Almost all major cruise ships have more than 33 tons per passenger; the rule of thumb for cruise line comfort is generally given as a minimum of 40 tons per passenger.\nMost other types of vessels pay a toll per PC/UMS net ton, in which one \"ton\" is actually a volume of . (The calculation of tonnage for commercial vessels is quite complex.) As of fiscal year 2016[ [update]], this toll is US$5.25 per ton for the first 10,000 tons, US$5.14 per ton for the next 10,000 tons, and US$5.06 per ton thereafter. As with container ships, reduced tolls are charged for freight ships \"in ballast\", $4.19, $4.12, $4.05 respectively.\nIn April 2016, a more complicated toll system was introduced, having the neopanamax locks at a higher rate in some cases, natural gas transport as a new separate category and other changes. In October 2017, there were modified tolls and categories of tolls in effect. Small (less than 125\u00a0ft) vessels up to 583 PC/UMS net tons when carrying passengers or cargo, or up to 735 PC/UMS net tons when in ballast, or up to 1,048 fully loaded displacement tons, are assessed minimum tolls based upon their length overall, according to the following table, from April 2015:\nMorgan Adams of Los Angeles, California, was the first toll received by the US government for the use of the Panama Canal by a pleasure boat. His boat \"Lasata\" passed through the Zone on 14 August 1914. The crossing occurred during a sea voyage from Jacksonville, Florida, to Los Angeles in 1914.\nThe most expensive regular toll for canal passage to date was charged in April 2010, to the cruise ship \"Norwegian Pearl,\" which paid US$375,600. The average toll is around US$54,000. The highest fee for priority passage charged through the Transit Slot Auction System was US$220,300, paid in August 2006, by the Panamax tanker \"Erikoussa\", bypassing a 90-ship queue waiting for the end of maintenance work on the Gatun Locks, and avoiding a seven-day delay. The normal fee would have been US$13,430.\nThe lowest toll ever paid was 36 cents, , by American Richard Halliburton who swam the Panama Canal in 1928.\nIssues leading to expansion.\nEfficiency and maintenance.\nOpponents to the 1977 Torrijos-Carter Treaties feared that efficiency and maintenance would suffer following the US withdrawal from the Panama Canal Zone; however, this has been proven not to be the case. In 2004, it was reported that canal operations, capitalizing on practices developed during the American administration, were improving under Panamanian control. Canal Waters Time (CWT), the average time it takes a vessel to navigate the canal, including waiting time, is a key measure of efficiency; in the first decade of the 2000s, it ranged between 20 and 30 hours, according to the ACP. The accident rate has also not changed appreciably in the past decade, varying between 10 and 30 accidents each year from about 14,000 total annual transits. An official accident is one in which a formal investigation is requested and conducted.\nIncreasing volumes of imports from Asia, which previously landed on US West Coast ports, are now passing through the canal to the American East Coast. In 2007, the total number of ocean-going transits increased from 11,725 in 2003 to 13,233, falling to 12,855 in 2009. The canal's fiscal year runs from October to September. This has been coupled with a steady rise in average ship size and in the numbers of Panamax vessels passing through the canal. The total tonnage carried rose from 227.9 million PC/UMS tons in fiscal year 1999 to a then record high of 312.9 million tons in 2007, and falling to 299.1 million tons in 2009. Tonnage for fiscal 2013, 2014 and 2015 was 320.6, 326.8 and 340.8 million PC/UMS tons, carried on 13,660, 13,481 and 13,874 transits respectively.\nIn the first decade after the transfer to Panamanian control, the Panama Canal Authority (ACP) invested nearly US$1 billion in widening and modernizing the canal, with the aim of increasing capacity by 20 percent. The ACP cites a number of major improvements, including the widening and straightening of the Culebra Cut to reduce restrictions on passing vessels, the deepening of the navigational channel in Gatun Lake to reduce draft restrictions and improve water supply, and the deepening of the Atlantic and Pacific entrances to the canal.\nThis is supported by new equipment, such as a new drill barge and suction dredger, and an increase of the tug boat fleet by 20 percent. Improvements have been made to the canal's operating machinery, including an increased and improved tug locomotive fleet, the replacement of more than of locomotive track, and new lock machinery controls. Improvements have been made to the traffic management system to allow more efficient control over ships in the canal.\nIn December 2010, record-breaking rains caused a 17-hour closure of the canal. This was the first closure since the US invasion of Panama in 1989. The rains also caused an access road to the Centenario Bridge to collapse.\nCapacity.\nThe canal handles more vessel traffic than had ever been envisioned by its builders. In 1934, it was estimated that the maximum capacity of the canal would be around 80 million tons per year. In 2015, canal traffic reached 340.8 million tons of shipping.\nTo improve capacity, a number of improvements have been made to maximize the use of the locking system:\nThese improvements enlarged the capacity from 300 million PCUMS in 2008, to 340 PCUMS in 2012. These improvements were started before the new locks project, and are complementary to it.\nCompetition.\nThe canal faces increasing competition from other quarters. Because canal tolls have risen as ships have become larger, some critics have suggested that the Suez Canal is now a viable alternative for cargo between Asia and the US East Coast. The Panama Canal, however, continues to serve more than 144 of the world's trade routes and the majority of canal traffic comes from the \"all-water route\" from Asia to the US East and Gulf Coasts.\nAn alternative route through Nicaragua and Lake Nicaragua has been proposed. On 15 June 2013, Nicaragua awarded the Hong Kong-based HKND Group a 50-year concession to develop a canal through the country. In February 2018, analysts widely viewed the project as defunct, though the head of the project insisted work was on-going. In April 2018 HKND Group closed its offices, leaving no forwarding address or telephone numbers to be reached.\nThe increasing rate of melting of ice in the Arctic Ocean has led to speculation that the Northwest Passage or Arctic Bridge may become viable for commercial shipping. This route would save on the route from Asia to Europe compared with the Panama Canal, possibly leading to a diversion of some traffic to that route. However, such a route is beset by unresolved territorial issues and would still hold significant problems owing to ice.\nTrade and Economic Impact of the Panama Canal.\nThe Panama Canal has been a vital conduit for global trade since its completion in 1914. By linking the Atlantic Ocean and Pacific Ocean, the canal has significantly reduced maritime travel time and costs, facilitating economic growth and international commerce. Over the past century, the canal has evolved through expansions and policy changes, further strengthening its role in global trade networks.\nExpansion and Increased Trade Capacity.\nThe expansion of the Panama Canal, completed in 2016, allowed for the transit of larger Neopanamax ships, nearly tripling its previous capacity. This development had a profound impact on global trade routes, particularly for container ships, liquefied natural gas (LNG) carriers, and bulk commodities. By accommodating larger vessels, the canal has helped reduce transportation costs for major exporters such as the United States, China, and Japan. Additionally, it has shifted trade dynamics by increasing the viability of East Coast ports in the United States, which have experienced higher traffic as a result of the expansion.\nStrategic Importance in Global Commerce.\nAs one of the world\u2019s most critical maritime chokepoints, the Panama Canal plays a central role in global commerce. Over 5% of world trade passes through the canal annually, with key commodities including grain, petroleum products, and manufactured goods. The canal is particularly essential for trade between Asia and the Americas, serving as a crucial transit route for automobiles, consumer electronics, and raw materials. According to historian Marixa Lasso, the construction of the canal not only altered trade patterns but also erased entire communities and reshaped the economic geography of the region.\nEconomic Impact on Panama and the Region.\nThe economic benefits of the canal extend beyond global trade, significantly impacting the Panamanian economy. The Panama Canal Authority (ACP) generates substantial revenue through tolls and fees, contributing to Panama\u2019s GDP growth and infrastructure development. Since the canal\u2019s transfer from the United States to Panama in 1999, revenues have been reinvested into national development projects, including ports, logistics hubs, and free trade zones. Moreover, the canal's expansion has bolstered employment and stimulated investment in surrounding economic zones.\nChallenges and Future Developments.\nDespite its success, the Panama Canal faces challenges, including climate change, water shortages, and competition from alternative trade routes such as the Arctic shipping lanes and the Suez Canal. Periodic droughts have raised concerns about the canal\u2019s long-term water availability, prompting discussions on sustainable water management solutions. Future investments in technology, such as automated navigation systems, and potential further expansions could enhance the canal\u2019s efficiency and maintain its relevance in global trade.\nWater issues.\nGatun Lake is filled with rainwater, and the lake accumulates excess water during wet months. For the old locks, water is lost to the oceans at a rate of per downward lock movement. The ship's submerged volume is not relevant to this amount of water.\nDuring the dry season, when there is less rainfall, there is also a shortage of water in Gatun Lake.\nAs a signatory to the 2000 United Nations Global Compact and member of the World Business Council for Sustainable Development, the ACP developed an environmentally and socially sustainable program for expansion, which protects the aquatic and terrestrial resources of the canal watershed. The expansion uses three water-saving basins at each new lock, diminishing water loss. It also preserves freshwater resources along the waterway by reusing 60 percent of water from the basins in the locks in each transit.\nThe mean sea level at the Pacific side is about higher than that of the Atlantic side due to differences in ocean conditions such as water density and weather.\nThe 2015\u20132016 fiscal year was one of the driest periods on record, restricting ships passage; 2019 was the fifth driest year for 70 years. Temperature rise has also caused an increase in evaporation. In normal times, 36 ships can transit the canal each day, but in early December 2023, ships were backing up because only 22 ships per day could transit due to low water levels. In January 2024, 24 ships per day were allowed to transit.\nThird set of locks project (expansion).\nAs demand is rising for efficient global shipping of goods, the canal is positioned to be a significant feature of world shipping for the foreseeable future. However, changes in shipping patterns\u00a0\u2013 particularly the increasing numbers of larger-than-Panamax ships\u00a0\u2013 necessitated changes to the canal for it to retain a significant market share. In 2006 it was anticipated that by 2011, 37 percent of the world's container ships would be too large for the present canal, and hence a failure to expand would result in a significant loss of market share. The maximum sustainable capacity of the original canal, given some relatively minor improvement work, was estimated at 340 million PC/UMS tons per year; it was anticipated that this capacity would be reached between 2009 and 2012. Close to 50 percent of transiting vessels were already using the full width of the locks.\nAn enlargement scheme to allow for a greater number of transits and the ability to handle larger ships, similar to the Third Lock Scheme of 1939, had been under consideration for some time, and by 2006 Panama's government canal authority was recommending such a plan. The expansion proposal, with a cost estimate of US$, was expected to double the canal's shipping capacity by allowing both the passage of longer and wider Post-Panamax ships and an increase in overall traffic. This proposal was approved in a national referendum by about 80 percent on 22 October 2006. The canal expansion was built between 2007 and 2016.\nThe expansion plan had two new flights of locks built parallel to, and operated in addition to, the old locks: one east of the existing Gatun locks, and one southwest of the Miraflores locks, each supported by approach channels. Each flight ascends from sea level directly to the level of Gatun Lake; the existing two-stage ascent at Miraflores and Pedro Miguel locks was not replicated. The new lock chambers feature sliding gates, doubled for safety, and are long, wide, and deep. This allows the transit of vessels with a beam of up to , an overall length of up to and a draft of up to , equivalent to a container ship carrying around 12,000 containers, each in length (TEU).\nThe new locks are supported by new approach channels, including a channel at Miraflores from the locks to the Gaillard Cut, skirting Miraflores Lake. Each of these channels is wide, which will require post-Panamax vessels to navigate the channels in one direction at a time. The Gaillard Cut and the channel through Gatun Lake were widened to at least on the straight portions and at least on the bends. The maximum level of Gatun Lake was raised from .\nEach flight of locks is accompanied by nine water reuse basins (three per lock chamber), each basin being about wide, long and deep. These gravity-fed basins allow 60 percent of the water used in each transit to be reused; the new locks consequently use 7 percent less water per transit than each of the existing lock lanes. The deepening of Gatun Lake and the raising of its maximum water level also provide capacity for significantly more water storage. These measures are intended to allow the expanded canal to operate without constructing new reservoirs.\nThe estimated cost of the project is US$. The project was designed to allow for an anticipated growth in traffic from 280 million PC/UMS tons in 2005 to nearly 510 million PC/UMS tons in 2025. The expanded canal will have a maximum sustainable capacity of about 600 million PC/UMS tons per year. Tolls will continue to be calculated based on vessel tonnage, and in some cases depend on the locks used.\nAn article in the February 2007 issue of \"Popular Mechanics\" magazine described the engineering aspects of the expansion project. There is also a follow-up article in the February 2010 issue of \"Popular Mechanics\".\nOn 3 September 2007, thousands of Panamanians stood across from Para\u00edso Hill in Panama to witness a huge initial explosion and launch of the Expansion Program. The first phase of the project was the dry excavations of the wide trench connecting the Gaillard Cut with the Pacific coast, removing 47 million cubic meters of earth and rock. By June 2012, a 30 m reinforced concrete monolith had been completed, the first of 46 such monoliths which will line the new Pacific-side lock walls. By early July 2012, however, it was announced that the canal expansion project had fallen six months behind schedule, leading expectations for the expansion to open in April 2015 rather than October 2014, as originally planned. By September 2014, the new gates were projected to be open for transit at the \"beginning of 2016\".\nIt was announced in July 2009 that the Belgian dredging company Jan De Nul, together with a consortium of contractors consisting of the Spanish Sacyr Vallehermoso, the Italian Impregilo, and the Panamanian company Grupo Cusa, had been awarded the contract to build the six new locks for US$3.1 billion, which was one billion less than the next highest competing bid due to having a concrete budget 71 percent smaller than that of the next bidder and allotted roughly 25 percent less for steel to reinforce that concrete. The contract resulted in $100 million in dredging works over the next few years for the Belgian company and a great deal of work for its construction division. The design of the locks is a carbon copy of the Berendrecht Lock, which is 68 m wide and 500 m long, making it the second largest lock in the world after the Kieldrecht lock in the port of Antwerp, Belgium. Completed in 1989 by the Port of Antwerp, which De Nul helped build, the company still has engineers and specialists who were part of that project.\nIn January 2014, a contract dispute threatened the progress of the project. There was a delay of less than two months however, with work by the consortium members reaching goals by June 2014.\nIn June 2015, flooding of the new locks began: first on the Atlantic side, then on the Pacific; by then, the canal's re-inauguration was slated for April 2016. On 23 March 2016, the expansion inauguration was set for 26 June 2016.\nThe new locks opened for commercial traffic on 26 June 2016, and the first ship to cross the canal using the third set of locks was a modern Neopanamax vessel, the Chinese-owned container ship \"Cosco Shipping Panama\". The original locks, now over 100 years old, allow engineers greater access for maintenance, and are projected to continue operating indefinitely. After the construction of the new locks, in addition to the already existing ones, to date the ship with the largest dimensions transiting the \"Panama Canal new sideway\", had the following dimensions: 366.47 meters in length, 48.23 meters in width and 15 meters draft.\nThe total cost is unknown since the expansion's contractors are seeking at least an additional US$ from the canal authority due to excess expenses.\nEnvironmental and ecological consequences.\nThe Panama Canal, one of the most important chokepoints in global trade, has caused many environmental and ecological problems since it was built and expanded. These problems include deforestation, the spread of invasive species, water and air pollution, and water shortage.\nDeforestation in the Panama Canal drainage basin has been a problem for decades. In 1978, researchers said that \"clearing the forest in the [drainage basin] might kill the canal.\" By 1985, the forested area had dropped to 30%. As of 2000, deforestation from human population growth, land degradation, and erosion continued to harm the ecosystem. Deforestation causes erosion, which raises the bottoms of the Gat\u00fan and Alajuela Lakes and lowers their ability to hold water. These lakes are very important for both canal operations and the local water supply.\nThe Panama Canal has made it easier for invasive species to move between oceans. When the canal was expanded in 2016 with the third set of locks, global trade increased, and so did the spread of invasive species. These species cling to the ship and move from one place to another, something that without the boats they would not have been able to do. One example is the Asian green mussel, first found in Caribbean waters in the late 1990s, which has spread through the canal. These invasive species can harm local ecosystems and compete with native species.\nShips passing through the canal regularly pollute the water. For example, in 1986, a crude oil spill east of the Caribbean entrance to the canal killed plants and invertebrates in the area. The shipping industry also releases emissions of greenhouse gases like carbon dioxide and methane. The Panama Canal, as a chokepoint, has a lot of heavy traffic and delays, which leads to burning more fuel and producing more emissions than needed. These emissions are a major concern because they contribute to climate change and increase environmental problems.\nThe Panama Canal uses a lot of fresh water from the Gat\u00fan Lake, which is Panama City's primary source of potable water. For each ship that passes through, about 200 million liters (52 million gallons) of freshwater are needed. This water use has serious environmental and social impacts. During a drought in 2019, Gat\u00fan Lake's water levels dropped to historic lows because so much water was being used for the canal.\nPlanned Indio River Reservoir.\nIn response to severe drought conditions that significantly impacted the Panama Canal's operations in 2023 and 2024, the Panama Canal Authority (ACP) announced plans to construct a new reservoir on the Indio River. The project aims to augment the canal's water supply and ensure consistent operations amid increasing climate variability.\nThe reservoir, estimated to cost $1.6 billion, will include a dam and hold approximately 1.25 billion cubic meters of water. It is expected to provide water for up to 15 additional daily transits during the dry season and support over half of Panama's population with drinking water.\nThis development followed a Panamanian Supreme Court decision in 2023 that redefined the legal boundaries of the canal\u2019s watershed, enabling water projects like the Indio River reservoir to proceed beyond the traditional limits.\nThe project has also raised social and environmental concerns, as it could displace an estimated 2,000 people and submerge local villages. The ACP has begun public consultations to explore mitigation strategies and compensation plans for affected communities.\nConstruction is expected to begin in 2027 and take approximately six years to complete.\nRoutes competing with the canal.\nNicaragua canal.\nOn 7 July 2014, Wang Jing, chairman of the HK Nicaragua Canal Development Investment Co. Ltd. (HKND Group) advised that a route for Nicaragua's proposed canal had been approved. The construction work was projected by HKND to begin in 2014 and take five years, although there had been little progress before the project's abandonment. The Nicaraguan parliament approved plans for the canal through Nicaragua and according to the deal, the company would have been responsible for operating and maintaining the canal for a 50-year period. By May 2017, no concrete action had been reportedly taken constructing the canal and further doubts were expressed about its financing. In February 2018, analysts widely viewed the project as defunct, though the head of the project insisted work was on-going and HKND retained the legal rights to the concession for the canal as well as side projects. Despite HKND vanishing in April 2018, the Nicaraguan government indicates that it will continue with the dry land expropriations within Nicaragua, under land expropriation Canal Law 840.\nColombia rail link.\nIn 2011, Colombia's then-president Juan Manuel Santos announced a proposal for a railway between Colombia's Pacific and Caribbean coasts. However, in 2015 the director of the Colombia-China Chamber of Commerce said the proposal \"was mentioned in 2011 and subsequently had minimal relevance\".\nNorthwest Passage.\nClimate change has thinned much of the Arctic ice that in the past made this route between the Atlantic and Pacific oceans impassable. Satellite navigation can help monitor location of the ice which remains, further easing transit. A few ships have successfully crossed the previously impossible route since 2000.\nInteroceanic Corridor of the Isthmus of Tehuantepec.\nSince 2019, Mexico has been building a corridor of its own, known as the Interoceanic Corridor of the Isthmus of Tehuantepec (CIIT, by its initials in Spanish), which will use primarily a railway, the \"Tren Interoce\u00e1nico\", to transport cargo and passengers from the Pacific Ocean to the Atlantic. It opened for passenger service on 22 December 2023, and all the works related to it to had begun operation by July 2024. This idea is older than the Panama Canal itself, with the original Tehuantepec Railway, which is being rehabilitated for the CIIT, being inaugurated in 1907 to initial success, but falling out of use due to the Mexican Revolution and the opening of the Panama Canal in 1914. The current Corridor is expected to have certain advantages over the Panama Canal, such as its speed, being able to transport cargo from one ocean to the other in about six hours, and its location, being closer to the United States than Panama, in addition to the creation of ten industrial parks in the Isthmus with various tax benefits to encourage private investment. However, despite being often described as a potential alternative/competitor to the Panama Canal, the ambassador of Panama in Mexico, Alfredo Oranges, and the former director of the CIIT, Rafael Mar\u00edn Mollinedo, have stated that they do not see the CIIT in this way, and that they prefer to see it as a \"complement\" to the Panama Canal, which could relieve the intense traffic the Canal has to cope with. The ambassador even proposed collaborating with the Mexican government to make the Corridor more efficient.\nOther projects.\nIndividuals, companies, and governments have explored the possibility of constructing deep water ports and rail links connecting coasts as a \"dry canal\" in Guatemala, Costa Rica, and El Salvador/Honduras. However, plans to construct these sea-rail-sea links have yet to materialize.\nMaster Key to Panama Canal and Honorary Pilots.\nDuring the last one hundred years, the Panama Canal Authority has granted membership in the \"Esteemed Order of Bearers of the Master Key of the Panama Canal\" and appointed a few \"Honorary Lead Pilots\" to employees, captains and dignitaries. One of the most recent was US Federal Maritime Commissioner Louis Sola, who was awarded for his work for supporting seafarers during the COVID-19 pandemic and previously transiting the canal more than 100 times. On the date of 25 April 2006, was awarded the title of Panama Canal Honorary Pilot the Senior Captain Raffaele Minotauro, an Italian citizen, an Unlimited Oceangoing Shipmaster Senior Grade, of the former Italian governmental navigation company known as the \"Italian Line\". This award was also given to Commodore Ronald Warwick, a British citizen, in 2014, a former Master of the Cunard Liners \"Queen Elizabeth 2\" and RMS \"Queen Mary 2\", who has traversed the Canal more than 50 times.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24850", "revid": "48181213", "url": "https://en.wikipedia.org/wiki?curid=24850", "title": "Political fiction", "text": "Literary genre\nPolitical fiction employs narrative to comment on political events, systems and theories. Works of political fiction, such as political novels, often \"directly criticize an existing society or present an alternative, even fantastic, reality\". The political novel overlaps with the social novel, proletarian novel, and social science fiction.\nPlato's \"Republic\", a Socratic dialogue written around 380 BC, has been one of the world's most influential works of philosophy and political theory, both intellectually and historically. The \"Republic\" is concerned with justice (), the order and character of the just city-state, and the just man. Other influential politically themed works include Thomas More's \"Utopia\" (1516), Jonathan Swift's \"Gulliver's Travels\" (1726), Voltaire's \"Candide\" (1759), and Harriet Beecher Stowe's \"Uncle Tom's Cabin\" (1852).\nPolitical fiction frequently employs satire, often in the utopian and dystopian genres.\nThis includes totalitarian dystopias of the early 20th century such as Jack London's \"The Iron Heel\", Sinclair Lewis' \"It Can't Happen Here\", and George Orwell's \"Nineteen Eighty-Four\".\nPolitical satire.\nThe Greek playwright Aristophanes' plays are known for their political and social satire, particularly in his criticism of the powerful Athenian general, Cleon, in plays such as \"The Knights\". Aristophanes is also notable for the persecution he underwent. Aristophanes' plays turned upon images of filth and disease. His bawdy style was adopted by Greek dramatist-comedian Menander, whose early play, \"Drunkenness\", contains an attack on the politician, Callimedon.\nJonathan Swift's \"A Modest Proposal\" (1729) is an 18th-century Juvenalian satirical essay in which he suggests that the impoverished Irish might ease their economic troubles by selling their children as food for rich gentlemen and ladies. The satirical hyperbole mocks heartless attitudes towards the poor, as well as British policy toward the Irish in general.\nGeorge Orwell's \"Animal Farm\" (1945) is an allegorical and dystopian novella which satirises the Russian Revolution of 1917 and the Soviet Union's Stalinist era. Orwell, a democratic socialist, was a critic of Joseph Stalin and was hostile to Moscow-directed Stalinism\u2014an attitude that had been shaped by his experiences during the Spanish Civil War. The Soviet Union, he believed, had become a brutal dictatorship, built upon a cult of personality and enforced by a reign of terror. Orwell described his \"Animal Farm\" as \"a satirical tale against Stalin\", and in his essay \"Why I Write\" (1946) he wrote that \"Animal Farm\" was the first book in which he tried, with full consciousness of what he was doing, \"to fuse political purpose and artistic purpose into one whole.\"\nOrwell's most famous work, however, is \"Nineteen Eighty-Four\" (published in 1949), many of whose terms and concepts, such as \"Big Brother\", \"doublethink\", \"thoughtcrime\", \"Newspeak\", \"Room 101\", \"telescreen\", \"2 + 2 = 5\", and \"memory hole\", have entered into common use. \"Nineteen Eighty-Four\" popularised the adjective \"Orwellian\", which describes official deception, secret surveillance, and manipulation of recorded history by a totalitarian or authoritarian state.\n16th-century novel.\nThe poet Jan Kochanowski's play \"The Dismissal of the Greek Envoys\" (1578), the first tragedy written in the Polish language, recounts an incident leading up to the Trojan War. Its theme of the responsibilities of statesmanship resonates to the present day.\nThe book \"Utopia\" (1516), written by Sir Thomas More, talk about a story of a different world compared to the one they live in. The character Thomas More is sent by King Henry VIII of England to negotiate the English wool trade. There he meets a man by the name Raphael Hythloday. He is a man that has been to the island on Utopia. He explains to More how their entire philosophy is to find happiness and share everything collectively; in this society, money does not exist, which starkly contrasts with the ascendant commercial empires in Thomas More's Europe.\n18th-century novel.\nThe political comedy \"The Return of the Deputy\" (1790), by Julian Ursyn Niemcewicz\u2014Polish poet, playwright, statesman, and comrade-in-arms of Tadeusz Ko\u015bciuszko\u2014was written in about two weeks' time while Niemcewicz was serving as a deputy to the historic Four-Year Sejm of 1788\u201392. The comedy's premiere in January 1791 was an enormous success, sparking widespread debate, royal communiques, and diplomatic correspondence. As Niemcewicz had hoped, it set the stage for passage of Poland's epochal Constitution of 3 May 1791, which is regarded as Europe's first, and the world's second, modern written national constitution, after the United States Constitution implemented in 1789. The comedy pits proponents against opponents of political reforms: of abolishing the destabilizing free election of Poland's kings; of abolishing the legislatively destructive \"liberum veto\"; of granting greater rights to peasants and townspeople; of curbing the privileges of the mostly self-interested noble class; and of promoting a more active Polish role in international affairs, in the interest of stopping the depredations of Poland's neighbors, Russia, Prussia, and Austria (who will in 1795 complete the dismemberment of the Polish\u2013Lithuanian Commonwealth). Romantic interest is provided by a rivalry between a reformer and a conservative for a young lady's hand\u2014which is won by the proponent of reforms.\n19th-century novel.\nAn early example of the political novel is \"The Betrothed\" (1827) by Alessandro Manzoni, an Italian historical novel. Set in northern Italy in 1628, during the oppressive years of direct Spanish rule, it has been seen sometimes as a veiled attack on the Austrian Empire, which controlled Italy at the time the novel was written. It has been called the most famous and widely read novel in the Italian language.\nIn the 1840s British politician Benjamin Disraeli wrote a trilogy of novels with political themes. With \"Coningsby; or, The New Generation\" (1844), Disraeli, in historian Robert Blake's view, \"infused the novel genre with political sensibility, espousing the belief that England's future as a world power depended not on the complacent old guard, but on youthful, idealistic politicians.\" \"Coningsby\" was followed by \"Sybil; or, The Two Nations\" (1845), another political novel, which was less idealistic and more clear-eyed than \"Coningsby\"; the \"two nations\" of its subtitle referred to the huge economic and social gap between the privileged few and the deprived working classes. The last of Disraeli's political-novel trilogy, \"Tancred; or, The New Crusade\" (1847), promoted the Church of England's role in reviving Britain's flagging spirituality.\nIvan Turgenev wrote \"Fathers and Sons\" (1862) as a response to the growing cultural schism that he saw between Russia's liberals of the 1830s and 1840s, and the growing Russian nihilist movement among their sons. Both the nihilists and the 1830s liberals sought Western-based social change in Russia. Additionally, these two modes of thought were contrasted with the Slavophiles, who believed that Russia's path lay in its traditional spirituality. Turgenev's novel was responsible for popularizing the use of the term \"nihilism\", which became widely used after the novel was published.\nThe Polish writer Boles\u0142aw Prus' novel, \"Pharaoh\" (1895), is set in the Egypt of 1087\u201385 BCE as that country experiences internal stresses and external threats that will culminate in the fall of its Twentieth Dynasty and New Kingdom. The young protagonist Ramses learns that those who would challenge the powers that be are vulnerable to co-option, seduction, subornation, defamation, intimidation, and assassination. Perhaps the chief lesson, belatedly absorbed by Ramses as pharaoh, is the importance, to power, of knowledge. Prus' vision of the fall of an ancient civilization derives some of its power from the author's intimate awareness of the final demise of the Polish\u2013Lithuanian Commonwealth in 1795, a century before he completed \"Pharaoh\". This is a political awareness that Prus shared with his 10-years-junior novelist compatriot, Joseph Conrad, who was an admirer of Prus' writings. \"Pharaoh\" has been translated into 23 languages and adapted as a 1966 Polish feature film. It is also known to have been Joseph Stalin's favourite book.\n20th-century novel.\nJoseph Conrad wrote several novels with political themes: \"Nostromo (1904)\", \"The Secret Agent\" (1907), and\n\"Under Western Eyes\" (1911). \"Nostromo\" (1904) is set amid political upheaval in the fictitious South American country of Costaguana, where a trusted Italian-descended longshoreman, Giovanni Battista Fidanza\u2014the novel's eponymous \"Nostromo\" (Italian for \"our man\")\u2014is instructed by English-descended silver-mine owner Charles Gould to take Gould's silver abroad so that it will not fall into the hands of revolutionaries. The role of politics is paramount in \"The Secret Agent\", as the main character, Verloc, works for a quasi-political organisation. The plot to destroy Greenwich Observatory is in itself anarchistic. Vladimir asserts that the bombing \"must be purely destructive\" and that the anarchists who will be implicated as the architects of the explosion \"should make it clear that [they] are perfectly determined to make a clean sweep of the whole social creation.\" However, the political form of anarchism is ultimately controlled in the novel: the only supposed politically motivated act is orchestrated by a secret government agency. Conrad's third political novel, \"Under Western Eyes\", is connected to Russian history. Its first audience read it against the backdrop of the failed Revolution of 1905 and in the shadow of the movements and impulses that would take shape as the revolutions of 1917. Conrad's earlier novella, \"Heart of Darkness\" (1899), also had political implications, in its depiction of European colonial depredations in Africa, which Conrad witnessed during his employ in the Belgian Congo.\nJohn Steinbeck's novel \"The Grapes of Wrath\" (1939) is a depiction of the plight of the poor. However, some of Steinbeck's contemporaries attacked his social and political views. Bryan Cordyack writes: \"Steinbeck was attacked as a propagandist and a socialist from both the left and the right of the political spectrum. The most fervent of these attacks came from the Associated Farmers of California; they were displeased with the book's depiction of California farmers' attitudes and conduct toward the migrants. They denounced the book as a 'pack of lies' and labeled it 'communist propaganda'\". Some accused Steinbeck of exaggerating camp conditions to make a political point. Steinbeck had visited the camps well before publication of the novel and argued that their inhumane nature destroyed the settlers' spirit.\n\"The Quiet American\" (1955) by English novelist Graham Greene questions the foundations of growing American involvement in Vietnam in the 1950s. The novel has received much attention due to its prediction of the outcome of the Vietnam War and subsequent American foreign policy since the 1950s. Graham Greene portrays a U.S. official named Pyle as so blinded by American exceptionalism that he cannot see the calamities he brings upon the Vietnamese. The book uses Greene's experiences as a war correspondent for \"The Times\" and \"Le Figaro\" in French Indochina in 1951\u201354.\n\"The Gay Place\" (1961) is a set of politically themed novellas with interlocking plots and characters by American author Billy Lee Brammer. Set in an unnamed state identical to Texas, each novella has a different protagonist: Roy Sherwood, a member of the state legislature; Neil Christiansen, the state's junior senator; and Jay McGown, the governor's speech-writer. The governor himself, Arthur Fenstemaker, a master politician (said to have been based on Brammer's mentor Lyndon Johnson) serves as the dominant figure throughout. The book also includes characters based on Brammer, his wife Nadine,\nJohnson's wife Lady Bird, and his brother Sam Houston Johnson. The book has been widely acclaimed one of the best American political novels ever written.\n21st-century novel.\nSince 2000, there has been a surge of Transatlantic migrant literature in French, Spanish, and English, with new narratives about political topics relating to global debt, labor abuses, mass migration, and environmental crises in the Global South. Political fiction by contemporary novelists from the Caribbean, Sub-Saharan Africa, and Latin America directly challenges political leadership, systemic racism, and economical systems.\u00a0Fatou Diome, a Senegalese immigrant living France since the 1990s, writes political fiction about her experiences on France's unwelcoming borders that are dominated by white Christian culture. The work of Guadeloupean author Maryse Cond\u00e9 also tackles colonialism and oppression; her best known titles are \"S\u00e9gou\" (1984) and \"S\u00e9gou II\" (1985). Set in historical Segou (now part of Mali), the novels examine the violent legacies of the slave trade, Islam, Christianity, and colonization (from 1797 to 1860). A bold critic of the presidency of Nicolas Sarkozy, French novelist Marie Ndiayes won the Prix Goncourt for \"Three Strong Women\" (2009) about patriarchal control.\nProletarian novel.\nThe proletarian novel is written by workers, mainly for other workers. It overlaps and sometimes is synonymous with the working-class novel, socialist novel, social-problem novel (also problem novel, sociological novel, or social novel), propaganda or thesis novel, and socialist-realism novel. The intention of the writers of proletarian literature is to lift the workers from the slums by inspiring them to embrace the possibilities of social change or of a political revolution. As such, it is a form of political fiction.\nThe proletarian novel may comment on political events, systems, and theories, and is frequently seen as an instrument to promote social reform or political revolution among the working classes. Proletarian literature is created especially by communist, socialist, and anarchist authors. It is about the lives of the poor, and the period from 1930 to 1945, in particular, produced many such novels. However, proletarian works were also produced before and after those dates. In Britain, the terms \"working-class\" literature, novel, etc., are more generally used.\nSocial novel.\nA closely related type of novel, which frequently has a political dimension, is the social novel \u2013 also known as the \"social-problem\" or \"social-protest\" novel \u2013 a \"work of fiction in which a prevailing social problem, such as gender, race, or class prejudice, is dramatized through its effect on the characters of a novel\". More specific examples of social problems that are addressed in such works include poverty, conditions in factories and mines, the plight of child labor, violence against women, rising criminality, and epidemics caused by overcrowding and poor sanitation in cities.\nCharles Dickens was a fierce critic of the poverty and social stratification of Victorian society. Karl Marx asserted that Dickens \"issued to the world more political and social truths than have been uttered by all the professional politicians, publicists and moralists put together\". On the other hand, George Orwell, in his essay on Dickens, wrote: \"There is no clear sign that he wants the existing order to be overthrown, or that he believes it would make very much difference if it were overthrown. For in reality his target is not so much society as 'human nature'.\"\nDickens's second novel, \"Oliver Twist\" (1839), shocked readers with its images of poverty and crime: it destroyed middle-class polemics about criminals, making any pretence to ignorance about what poverty entailed impossible. Dickens's \"Hard Times\" (1854) is set in a small Midlands industrial town and particularly criticizes the effect of Utilitarianism on the lives of cities' working classes. John Ruskin declared \"Hard Times\" his favourite Dickens work due to its exploration of important social questions. Walter Allen characterised \"Hard Times\" as an unsurpassed \"critique of industrial society\",\nNotable examples.\nOther notable examples are in the main lists, above.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24851", "revid": "48736052", "url": "https://en.wikipedia.org/wiki?curid=24851", "title": "Potato chips", "text": "Thinly sliced potatoes, deep-fried or baked\nPotato chips (North American and Australian English; often just chips) or crisps (British and Irish English) are thin slices of potato (or a thin deposit of potato paste) that have been deep-fried, baked, or air-fried until crunchy. They are commonly served as a snack, side dish, or appetizer. The basic chips are cooked and salted; additional varieties are manufactured using various flavorings and ingredients including herbs, spices, cheeses, other natural flavors, artificial flavors, and additives.\nPotato chips form a large part of the snack food and convenience food market in Western countries. The global potato chip market generated total revenue of US$16.49 billion in 2005. This accounted for 35.5% of the total savory snacks market in that year (which was $46.1 billion overall).\nHistory.\nThe earliest known recipe for potato chips is in the English cook William Kitchiner's book \"The Cook's Oracle\" published in 1817 in London, which was a bestseller in the United Kingdom and the United States. The 1822 edition's recipe for \"Potatoes fried in Slices or Shavings\" reads \"peel large potatoes... cut them in shavings round and round, as you would peel a lemon; dry them well in a clean cloth, and fry them in lard or dripping\". An 1825 British book about French cookery calls them \"Pommes de Terre frites\" (second recipe) and calls for thin slices of potato fried in \"clarified butter or goose dripping\", to be drained once crisp and sprinkled with salt. Early recipes for potato chips in the US are found in Mary Randolph's \"Virginia House-Wife\" (1824) and in N.K.M. Lee's \"Cook's Own Book\" (1832), both of which explicitly cite Kitchiner.\nA legend associates the creation of potato chips with Saratoga Springs, New York, decades later than the first recorded recipe. By the late nineteenth century, a popular version of the story, today known to be untrue, attributed the dish to George Crum, a cook at Moon's Lake House who was trying to appease an unhappy customer on August 24, 1853. The customer kept sending back his French-fried potatoes, complaining that they were too thick, too \"soggy\", or not salted enough. Frustrated, Crum sliced several potatoes extremely thin, fried them to a crisp, and seasoned them with extra salt \u2013 to his surprise, the customer loved them. They soon came to be called \"Saratoga Chips\", a name that persisted into the mid-twentieth century. A version of this story was popularized in a 1973 national advertising campaign by St. Regis Paper Company which manufactured packaging for chips, claiming that Crum's customer was Cornelius Vanderbilt. The story is today known to be a myth, and historians and academics have identified a number of problems with the story: Vanderbilt was in Europe during the alleged encounter, the Moons didn't purchase the Lake House until 1854, and crispy fried potatoes were not unknown to Saratoga in 1853. However, the story remains frequently cited in popular media.\nProduction.\nIn the 20th century, potato chips spread beyond chef-cooked restaurant fare and began to be mass-produced for home consumption. The Dayton, Ohio-based Mikesell's Potato Chip Company, founded in 1910, identifies as the \"oldest potato chip company in the United States\". New Hampshire-based Granite State Potato Chip Factory, founded in 1905 and in operation until 2007, was one of America's first potato chip manufacturers.\nFlavoring.\nIn an idea originated by the Smiths Potato Crisps Company Ltd, formed in 1920, Frank Smith packaged his chips in greaseproof paper bags and attached a twist of salt, and sold them around London. The potato chip remained otherwise unseasoned until the 1950s. After some trial and error, in 1954, Joe \"Spud\" Murphy, the owner of the Irish crisps company Tayto, and his employee Seamus Burke, produced the world's first seasoned chips: cheese &amp; onion. Companies worldwide sought to buy the rights to Tayto's technique. Walkers of Leicester, England, produced cheese &amp; onion the same year. Golden Wonder (Smith's main competitor at the time) also started to produce cheese &amp; onion, and Smith's countered with salt &amp; vinegar (tested first by their north-east England subsidiary Tudor and then launched nationally in 1967), starting a two-decade-long flavor war.\nThe first flavored chips in the United States, barbecue flavor, were being manufactured and sold by 1954. In 1958, Herr's was the first company to introduce barbecue-flavored potato chips in Pennsylvania.\nPackaging.\nIn the 1920s, Laura Scudder, an entrepreneur in Monterey Park, California, started having her workers take home sheets of wax paper to iron into the form of bags, which were filled with chips at her factory the next day. This pioneering method reduced crumbling and kept the chips fresh and crisp longer. This innovation, along with the invention of cellophane, allowed potato chips to become a mass-market product.\nKettle-cooked chips.\nChips were long made in a batch process, where the potato slices are rinsed with cold water to release starch, fried at a low temperature of , and continuously raked to prevent them from sticking together.\nIndustrial advances resulted in a shift to production by a continuous process, running the chips through a vat of hot oil and drying them in a conveyor process.\nSome small producers continued to use a batch process, notably in Maui. In 1980, inspired by the Maui Chip, an entrepreneur started Cape Cod Potato Chips to produce thicker, batch-cooked \"Hawaiian style\" potato chips, which came to be known as kettle-style (US) or hand-cooked (UK) chips and became a premium, \"gourmet\" item. Kettle chips are thicker and the surface starch is not rinsed off, resulting in a style of chip called \"hard-bite\".\nNomenclature.\nLittle consistency exists in the English-speaking world for the name of this food. North American English uses \"chips\", though Canadians may also call French fries, especially thick ones, \"chips\" as well. \"Crisps\" may be used for thin fried or baked products made from potato paste. An example of this type of snack is Pringles, which are marketed as \"potato crisps\" even in the United States.\nIn the United Kingdom and Ireland they are called \"crisps\", whilst \"chips\" refers to french fries (as in \"fish and chips\"). In Australia, some parts of South Africa, New Zealand, India, and the West Indies, especially in Barbados, both forms of potato product are simply known as \"chips\", as are the larger \"home-style\" variety. In the north of New Zealand, they are sometimes affectionately known as \"chippies\"; however, they are marketed as \"chips\" throughout the country. In Australia and New Zealand, a distinction is sometimes made between \"hot chips\" (fried potatoes) and \"chips\" or \"potato chips\". In Bangladesh, they are generally known as \"chip\" or \"chips\", and much less frequently as \"crisps\" (pronounced \"kirisp\") and locally, \"alu bhaja\".\nIn German-speaking countries (Austria, Germany: \"Kartoffelchips\", often shortened to \"Chips\"; Switzerland: \"Pommes Chips\") and in countries of the former Yugoslavia, fried thin potato slices are known as \"chips\" (locally pronounced very similarly to the English pronunciation), with a clear distinction from French fries. In Brazil, \"home-style\" potato chips are known as (\"Portuguese potatoes\") if their sides are relatively smooth and (\"Prussian potatoes\") if their sides show a wafer biscuit-like pattern, whilst American-like industrial uniform potato chips made from a fried potato pur\u00e9e-based dough are known as \"batata chips\" (\"potato chips\"), or just \"chips\".\nHealth concerns.\nMost potato chips contain high levels of sodium, from salt. This has been linked to health issues such as high blood pressure. However, researchers at Queen Mary University of London in 2004 have noted that a small \"bag of ready-salted crisps\" contains less salt than a serving of many breakfast cereals, including \"every brand of cornflakes on sale in the UK\".\nSome potato chip companies have responded to the long-standing concerns by investing in research and development to modify existing recipes and create health-conscious products. PepsiCo research shows that about 80% of salt on chips is not sensed by the tongue before being swallowed. Frito-Lay spent $414 million in 2009 on product development, including development of salt crystals that would reduce the salt content of Lay's potato chips without adversely affecting flavor.\nUnsalted chips are available, e.g. the longstanding British brand Salt 'n' Shake, whose chips are not seasoned but instead include a small salt sachet in the bag for seasoning to taste. Many other popular brands in the United States, such as Frito-Lay, also offer such a product.\nOne health scare related to potato chips focused on acrylamide, which is produced when potatoes are fried or baked at high temperatures. This discovery in 2002 led to international health concerns. Subsequent research has however found that it is not likely that the acrylamides in burnt or well-cooked food cause cancer in humans; Cancer Research UK categorizes the idea that burnt food causes cancer as a \"myth\".\nIn August 2008, California Attorney General Jerry Brown announced a settlement with Frito-Lay, Kettle Foods, and Lance Inc., the makers of Cape Cod Potato Chips, for violating the state's Safe Drinking Water and Toxic Enforcement Act. The state had alleged in 2005 that potato chips from these companies failed to document that they contained high levels of acrylamide, which is listed by California since the 1990s as a carcinogen. These companies paid fines and agreed to reduce acrylamide levels to be under 275 parts per billion. Many potato chip manufacturers attempt to remove burned and thus potentially acrylamide-rich chips before the packaging process. Large scanners are used to eliminate chips worst affected by heat.\nRegional varieties.\nAmericas.\nIn the United States, major regional brands include Jays, Better Made, Old Dutch, Utz and Zapp's. \nIn Canada, regional varieties include all-dressed, dill pickle, and ketchup. Ketchup chips are flavored with tomato, garlic and onions.\nIn Colombia, lemon, chicken, chorizo, and sirloin steak with mushroom sauce flavored potato chips are sold.\nEurope.\nIn the United Kingdom, Walkers makes crisps with popular flavours as Prawn Cocktail, Beef and Onion, Roast Chicken, Smoky Bacon, Worcester Sauce, Pickled Onion, and Tomato Ketchup, and exotic flavors Thai sweet chili, roast pork and creamy mustard sauce, chicken with Italian herbs, Spicy Sriracha, BBQ Pulled Pork, sea salt and cider vinegar, spicy and aromatic curry, turkey and bacon, caramelized onion and sweet balsamic vinegar, Stilton and cranberry. In Ireland, the word \"Tayto\" is synonymous with potato chips after the Tayto brand, and can be used to describe all varieties of chips, including those not produced by Tayto. Hunky Dorys and King are other popular Irish brands.\nIn Germany, Belgium and the Netherlands, salted and sweet paprika chips (sometimes also called \"ungarisch\" (from \"Hungarian\") in Germany) are the two most common and popular types. In Germany, chip producers have introduced additional flavours, such as sour cream and onion, cheese, oriental, or more exotic seasonings like \"Chakalaka\", \"Currywurst\", \"Pommes\" (french fries), and \"Rot-weiss\" (red and white: french fries with tomato ketchup and mayonnaise). In Belgium and the Netherlands, \"Bolognese\" flavoured potato chips are also popular; this flavour was introduced by Belgian chip company Croky.\nIn Russia, the Russkaya Kartoshka brand of chips claim reduced content of oil in their curled (C-shaped, nearly ball-shaped) chips, and offers flavors like grilled salmon, shrimp and \"Kamchatka's crab\", that are unique seafood-themed flavors of potato chips mass-produced in Russia. Lay's offers crab-flavored and no-cream green onion flavored chips as ones made uniquely for Russian market. Lay's \"Iz pechi\" (literally \"from the stove\") line of less-oiled chips also include crab flavor. \"Just Brutal\" brand has pitch-black chips, where the flavors are \"vinegar\" and \"Thai sweet pepper\".\nAsia.\nIn Japan, flavors include norishio (nori and salt), \"consomm\u00e9\", wasabi, soy sauce and butter, garlic, plum, barbecue, pizza, mayonnaise, and black pepper. Chili, scallop with butter, teriyaki, takoyaki, and yakitori chip flavors are also available. Major manufacturers include Calbee and Koikeya. In Hong Kong, the two prominent potato chips are the spicy \"Ethnican\" variety by Calbee, and barbecue by Jack 'n Jill.\nIn Indonesia, potato chips are commonly called \"kripik kentang\" and traditionally fell under the \"kripik\" category. The major brands are Indofood's Chitato (since 1990s) and Lay's (Frito-Lay). In 2014, Japan's Calbee and Indonesia's Wings Food formed Calbeewings, a joint venture and marketed Potabee potato chips offering two flavors: beef BBQ and grilled seaweed. Lay's potato chips sold in Indonesia are available in six flavors: honey butter, sour cream and onion, nori seaweed, beef barbecue, classic salty, and salmon teriyaki flavors. In 2018 Chitato launched three unusual flavors: beef rendang, fried crab golden egg yolk, and mango sticky rice.\nSimilar foods.\nAnother food made from potatoes, notably the Pringles and Lay's Stax brands, is made by extruding or pressing a dough made from dehydrated potato flour into the desired shape before frying. This makes a product that is uniform in size and shape, which allows them to be stacked and packaged in rigid cardboard or plastic canisters. Pringles are officially branded as \"potato crisps\" in the US. Pringles may be termed \"potato chips\" in Britain, to distinguish them from traditional \"crisps\", but do not meet the definition or standard of identity for potato chips. Munchos, another brand that uses the term \"potato crisps\", has deep air pockets in its chips that give it a curved shape, though the chips themselves resemble regular bagged chips.\nAn additional product similar to potato chips exists in the form of \"potato sticks\", also called \"shoestring potatoes\". These are made as extremely thin (2 to 3\u00a0mm) versions of the popular French fry but are fried in the manner of regular salted potato chips. A hickory-smoke-flavored version is popular in Canada, going by the vending machine name \"Hickory Sticks\". Potato sticks are typically packaged in rigid containers, although some manufacturers use flexible pouches, similar to potato chip bags. Potato sticks were originally packed in hermetically sealed steel cans. In the 1960s, manufacturers switched to the less expensive composite canister (similar to the Pringles container). Reckitt Benckiser was a market leader in this category under the Durkee Potato Stix and French's Potato Sticks names but exited the business in 2008. In 2014, French's reentered the market. A larger variant (about 1\u00a0cm thick) made with dehydrated potatoes is marketed as Andy Capp's Pub Fries, using the theme of a long-running British comic strip, which are baked and sold in a variety of flavors. Walkers make a similar product (using the Smiths brand) called \"Chipsticks\" which are sold in ready-salted and salt and vinegar flavors.\nSome companies have also marketed baked potato chips as an alternative with lower fat content. Additionally, some varieties of fat-free chips have been made using artificial, and indigestible, fat substitutes. These became well known in the media when an ingredient many contained, olestra, was linked in some individuals to abdominal discomfort and loose stools.\nMany other products might be called \"crisps\" in Britain, but would not be classed as \"potato chips\" because they are not made with potato or are not chipped (for example, Wotsits, Quavers, Skips, Hula Hoops, and Monster Munch). British restaurant critic Tanya Gold argues that Monster Munch \"is absolutely not a crisp\".\nSweet potato chips are eaten in Korea, New Zealand, and Japan; parsnip, beetroot, and carrot crisps are available in the United Kingdom. India is famous for a large number of localized 'chips shops', selling not only potato chips, but also other varieties such as plantain chips, tapioca chips, yam chips, and even carrot chips. Plantain chips, also known as chifles or tostones, are also sold in the Western Hemisphere from Canada to Chile. In the Philippines, banana chips can be found sold at local stores. In Kenya, chips are made from arrowroot and cassava. In the United Kingdom, Sweden, Finland, and Australia, a new variety of Pringles made from rice was released in 2010 and marketed as lower in fat than its potato counterparts."}
{"id": "24853", "revid": "313197", "url": "https://en.wikipedia.org/wiki?curid=24853", "title": "Political media", "text": ""}
{"id": "24856", "revid": "50327723", "url": "https://en.wikipedia.org/wiki?curid=24856", "title": "Prohibition", "text": "Outlawing of alcohol\nProhibition is the act or practice of forbidding something by law; more particularly the term refers to the banning of the manufacture, storage (whether in barrels or in bottles), transportation, sale, possession, and consumption of alcoholic beverages. The word is also used to refer to a period of time during which such bans are enforced.\nHistory.\nSome kind of limitation on the trade in alcohol can be seen in the Code of Hammurabi (c.\u20091772 BCE) specifically banning the selling of beer for money. It could only be bartered for barley: \"If a beer seller do not receive barley as the price for beer, but if she receive money or make the beer a measure smaller than the barley measure received, they shall throw her into the water.\" A Greek city-state of Eleutherna passed a law against drunkenness in the 6th century BCE, although exceptions were made for religious rituals.\nIn the early twentieth century, much of the impetus for the prohibition movement in the Nordic countries and North America came from moralistic convictions of pietistic Protestants. Prohibition movements in the West coincided with the advent of women's suffrage, with newly empowered women as part of the political process strongly supporting policies that curbed alcohol consumption.\nThe first half of the 20th century saw periods of prohibition of alcoholic beverages in several countries:\nAfter several years, prohibition failed in North America and elsewhere. Rum-running or bootlegging became widespread, and organized crime took control of the distribution of alcohol. Distilleries and breweries in Canada, Mexico and the Caribbean flourished as their products were either consumed by visiting Americans or illegally exported to the United States. Detroit and Chicago became notorious as havens for prohibition dodgers during the time known as the Roaring Twenties \u2013 75% of all alcohol smuggled into the United States crossed the Detroit-Windsor border. Prohibition generally came to an end in the late 1920s or early 1930s in most of North America and Europe, although a few locations continued prohibition for many more years.\nIn some countries where the dominant religion forbids the use of alcohol, the production, sale, and consumption of alcoholic beverages is prohibited or restricted today. For example, in Saudi Arabia and Libya alcohol is banned; in Pakistan and Iran it is illegal with exceptions.\nEffects.\nGenerally, prohibition is not completely effective, and tends to drive the market underground instead. Most countries which have maintained long-standing alcohol bans have predominantly Muslim populations whose religious beliefs forbid them from drinking, but the broad popularity of alcohol has meant prohibition is extremely difficult to enforce in most nations. The vast majority of countries which have at one point fully prohibited alcohol have since reversed it. Both the United States and Soviet Union implemented total bans on alcohol only to repeal them after less than 15 years. \nProhibition worldwide.\nAfrica.\nNigeria.\nIn the British colony of Nigeria, missionary forces demanded prohibition of liquor, which proved highly unpopular. Both Africans and British found illegal supplies such as secret stills, obtaining colonial liquor permits, and smuggling. The experiment began in 1890 and was repealed in 1939.\nSouth Africa.\nDuring the coronavirus outbreak of 2020, alcohol sales, and even the transportation of alcohol outside of one's home, was made illegal. This order came into effect during the nationwide lockdown on 27 March 2020. The purpose of the ban was intended to prevent drunken fights, reduce domestic violence, stop drunk driving, and eliminate the weekend binge-drinking so prevalent across South Africa.\nPolice, medics, and analysts estimate\u2014conservatively\u2014that alcohol is involved in, or responsible for, at least 40% of all emergency hospital admissions. By reducing the number of people within hospitals, and of course within social gatherings, the goal of prohibition was to reduce the rate of transmission, and thus slow the spread of the virus.\nA 2022 study found that the alcohol prohibition reduced injury-induced mortality by at least 14% (a conservative estimate) and sharply reduced violent crime.\nSouth Asia.\nAfghanistan.\nSale of alcohol is illegal in Afghanistan.\nBangladesh.\nIn Bangladesh, alcohol is somewhat prohibited due to its proscription in the Islamic faith. The purchase and consumption is still allowed in the country. The Garo tribe consume a type of rice beer, and Christians in this country drink and purchase wine for their holy communion.\nIndia.\nIn India alcohol is a state subject and individual states can legislate prohibition, but currently most states do not have prohibition and sale/consumption is freely available in 24 out of 29 states. Prohibition is in force in the states of Mizoram, Gujarat, Bihar and Nagaland, parts of Manipur, and the union territory of Lakshadweep. All other States and union territories of India permit the sale of alcohol.\nElection days and certain national holidays such as \"Independence Day\" are meant to be \"dry days\" when liquor sale is not permitted but consumption is allowed. Some Indian states observe dry days on major religious festivals/occasions depending on the popularity of the festival in that region.\nMaldives.\nThe Maldives ban the import of alcohol, x-raying all baggage on arrival. Alcoholic beverages are available only to foreign tourists on resort islands and may not be taken off the resort.\nPakistan.\nPakistan allowed the free sale and consumption of alcohol for three decades from 1947, but restrictions were introduced by Zulfikar Ali Bhutto just weeks before he was removed as prime minister in 1977. Since then, only members of non-Muslim minorities such as Hindus, Christians and Zoroastrians are allowed to apply for alcohol permits. The monthly quota is dependent upon one's income, but is actually about five bottles of liquor or 100 bottles of beer. In a country of 180 million, only about 60 outlets are allowed to sell alcohol. The Murree Brewery in Rawalpindi was once the only legal brewery, but today there are more. The ban officially is enforced by the country's Islamic Ideology Council, but it is not strictly policed. Members of religious minorities, however, often sell their liquor permits to Muslims as part of a continuing black market trade in alcohol.\nSri Lanka.\nIn 1955 Sri Lanka passed a law prohibiting adult women from buying alcohol. In January 2018, Finance Minister Mangala Samaraweera announced that the law would be amended, allowing women to legally consume alcohol and work in venues that sell alcohol. The legalization was overruled by President Maithripala Sirisena several days later.\nWest Asia.\nIran.\nSince the 1979 Islamic Revolution, Muslims are banned from selling and drinking alcohol but some people trade and sell it illegally. Home production by religious minorities (Zoroastrians, Jews, and Christians) is legal.\nKuwait.\nThe consumption, importation and brewing of, and trafficking in liquor is strictly against the law.\nSaudi Arabia.\nThe sale, consumption, importation and brewing of, and trafficking in liquor is strictly against the law.\nYemen.\nAlcohol is banned in Yemen.\nSoutheast Asia.\nBrunei.\nIn Brunei, alcohol consumption and sale is banned in public. Non-Muslims are allowed to purchase a limited amount of alcohol from their point of embarcation overseas for their own private consumption, and non-Muslims who are at least the age of 18 are allowed to bring in not more than two bottles of liquor (about two litres) and twelve cans of beer per person into the country.\nIndonesia.\nAlcohol sales are banned in small shops and convenience stores.\nKorea.\nDuring the Joseon period, laws prohibiting the drinking of alcohol were frequently promulgated when there were major droughts, crop failures, or famines. The purpose of such bans was to appease the wrath of heaven, and to save food and money (since rice was used to make alcohol). A ban was issued almost every year during King Taejong's reign and frequently during the reigns of King Seongjong and King Yeonsangun. It was banned again, in 1758 (the 34th year of King Yeongjo). The bans usually occurred during spring and summer when the droughts were severe.\nMalaysia.\nAlcohol is banned only for Muslims in Malaysia due to its Islamic faith and sharia law. Nevertheless, alcoholic products can easily be found in supermarkets, specialty shops, and convenience stores all over the country. Non-halal restaurants also typically sell alcohol.\nPhilippines.\nThere are only restrictions during elections in the Philippines. Alcohol is prohibited to be sold, furnished, offered, bought, or took the day prior to an election and on the day of an election itself. Hotels and restaurants may secure a prior exemption but even then they are only allowed to serve alcohol to non-Filipino citizens. Private consumption of alcohol hoarded prior to the ban period is tolerated. The Philippine Commission on Elections may opt to extend the liquor ban. In the 2013 elections, there was a proposal that it be extended to five days. This was overturned by the Supreme Court.\nOther than election-related prohibition, alcohol is freely sold to anyone above the legal drinking age.\nThailand.\nAlcohol sales are prohibited during elections from 18:00 the day prior to voting, until the end of the day of voting itself. Alcohol is also prohibited on major Buddhist holy days, and sometimes on royal commemoration days, such as birthdays.\nThailand also enforces time-limited bans on alcohol on a daily basis. Alcohol can only be legally purchased in stores or restaurants between 11:00\u201314:00 and 17:00\u2013midnight. The law is enforced by all major retailers (most notably 7-Eleven) and restaurants, but is frequently ignored by the smaller \"mom and pop\" stores. Hotels and resorts are exempt from the rules.\nThe consumption of alcohol is also banned at any time within 200 meters of a filling station (where sale of alcohol is also illegal), schools, temples or hospitals as well as on board any type of road vehicle regardless of whether it is being consumed by the driver or passenger.\nAt certain times of the year\u2014Thai New Year (Songkran) is an example\u2014the government may also enforce arbitrary bans on the sale and consumption of alcohol in specific public areas where large scale festivities are due to take place and large crowds are expected.\nThailand strictly regulates alcohol advertising, as specified in the Alcoholic Beverage Control Act, B.E. 2551 (2008) (ABCA). Sales of alcohol via \"electronic channels\" (internet) are prohibited.\nEurope.\nCzech Republic.\nOn 14 September 2012, the Government of the Czech Republic banned all sales of alcoholic drinks with more than 20% alcohol. From this date, it was illegal to sell such alcoholic beverages in shops, supermarkets, bars, restaurants, filling stations, e-shops, etc. This measure was taken in response to the wave of methanol poisoning cases resulting in the deaths of 18 people in the Czech Republic. Since the beginning of the \"methanol affair\" the total number of deaths has increased to 25. The ban was to be valid until further notice, though restrictions were eased towards the end of September. The last bans on Czech alcohol with regard to the poisoning cases were lifted on 10 October 2012, when neighbouring Slovakia and Poland allowed its import once again.\nNordic countries.\nThe Nordic countries, with the exception of Denmark, have had a strong temperance movement since the late-1800s, closely linked to the Christian revival movement of the late-nineteenth century, but also to several worker organisations. As an example, in 1910 the temperance organisations in Sweden had some 330,000 members, which was about 6% of a population of 5.5 million. This heavily influenced the decisions of Nordic politicians in the early 20th century.\nIn 1907, the Faroe Islands passed a law prohibiting all sale of alcohol, which was in force until 1992. Very restricted private importation from Denmark was allowed from 1928 onwards.\nIn 1914, Sweden put in place a rationing system, the Bratt System, in force until 1955. A referendum in 1922 rejected an attempt to enforce total prohibition.\nIn 1915, Iceland instituted total prohibition. The ban for wine was lifted in 1922 and spirits in 1935, but beer remained prohibited until 1989 (circumvented by mixing light beer and spirits).\nIn 1916, Norway prohibited distilled beverages, and in 1917 the prohibition was extended to also include fortified wine and beer. The wine and beer ban was lifted in 1923, and in 1927 the ban of distilled beverages was also lifted.\nIn 1919, Finland enacted prohibition, as one of the first acts after independence from the Russian Empire. Four previous attempts to institute prohibition in the early twentieth century had failed due to opposition from the tsar. After a development similar to the one in the United States during its prohibition, with large-scale smuggling and increasing violence and crime rates, public opinion turned against the prohibition, and after a national referendum where 70% voted for a repeal of the law, prohibition was abolished in early 1932.\nToday, all Nordic countries except Denmark continue to have strict controls on the sale of alcohol, which is highly taxed (dutied) to the public. There are government monopolies in place for selling spirits, wine, and stronger beers in Norway (Vinmonopolet), Finland (Alko), Sweden (), Iceland (V\u00ednb\u00fa\u00f0in), and the Faroe Islands (R\u00fasdrekkas\u00f8la Landsins). Bars and restaurants may, however, import alcoholic beverages directly or through other companies.\nGreenland, which is part of the Kingdom of Denmark, does not share its easier controls on the sale of alcohol. Greenland has (like Denmark) sales in food shops, but prices are typically high. Private import when travelling from Denmark is only allowed in small quantities.\nRussian Empire and the Soviet Union.\nIn the Russian Empire, a limited version of a Dry Law was introduced in 1914. It continued through the turmoil of the Russian Revolution of 1917 and the Russian Civil War into the period of Soviet Russia and the Soviet Union until 1925.\nUnited Kingdom.\nAlthough the sale or consumption of commercial alcohol has never been prohibited by law in the United Kingdom, various groups in the UK have campaigned for the prohibition of alcohol; including the Society of Friends (Quakers), The Methodist Church and other non-conformists, as well as temperance movements such as Band of Hope and temperance Chartist movements of the nineteenth century. The village of Bournville traditionally remains a dry town with no pubs due to the founder John Cadbury's Quaker beliefs and wish for it to remain free of alcohol for the workers at his Cadbury's chocolate factory.\nFormed in 1853 and inspired by the Maine law in the United States, the United Kingdom Alliance aimed at promoting a similar law prohibiting the sale of alcohol in the UK. This hard-line group of prohibitionists was opposed by other temperance organisations who preferred moral persuasion to a legal ban. This division in the ranks limited the effectiveness of the temperance movement as a whole. The impotence of legislation in this field was demonstrated when the Sale of Beer Act 1854, which restricted Sunday opening hours, had to be repealed, following widespread rioting. In 1859, a prototype prohibition bill was overwhelmingly defeated in the House of Commons.\nOn 22 March 1917, during the First World War at a crowded meeting in the Queen's Hall in London (chaired by Alfred Booth) many influential people including Agnes Weston spoke, or letters from them were read out, against alcohol consumption, calling for prohibition; General Sir Reginald Hart wrote to the meeting that \"Every experienced officer knew that practically all unhappiness and crime in the Army is due to drink\". At the meeting, Lord Channing said that it was a pity that the whole Cabinet did not follow the example of King George V and Lord Kitchener when in 1914 those two spoke calling for complete prohibition for the duration of the war.\nEdwin Scrymgeour served as Member of Parliament for Dundee between 15 November 1922 and 8 October 1931. He remains the only person to have ever been elected to the House of Commons on a prohibitionist ticket. In 1922, he defeated incumbent Liberal member Winston Churchill; winning the seat for the \nScottish Prohibition Party, which he had founded in 1901, and for which he had stood for election successfully as a Dundee Burgh Councillor in 1905 and unsuccessfully as a parliamentary candidate between 1908 and 1922.\nNorth America.\nCanada.\nIndigenous peoples in Canada were subject to prohibitory alcohol laws under the \"Indian Act\" of 1876. Sections of the \"Indian Act\" regarding liquor were not repealed for over a hundred years, until 1985.\nAn official, but non-binding, federal referendum on prohibition was held in 1898. Prime Minister Wilfrid Laurier's government chose not to introduce a federal bill on prohibition, mindful of the strong antipathy in Quebec. As a result, Canadian prohibition was instead enacted through laws passed by the provinces during the first twenty years of the 20th century, especially during the 1910s. Canada did, however, enact a national prohibition from 1918 to 1920 as a temporary wartime measure. Much of the rum-running during prohibition took place in Windsor, Ontario. The provinces later repealed their prohibition laws, mostly during the 1920s, although some local municipalities remain dry.\nMexico.\nSome communities in the southern Mexican state of Chiapas of are under the control of the libertarian socialist Zapatista Army of National Liberation, and often ban alcohol as part of what was described as \"a collective decision\". This prohibition has been used by many villages as a way to decrease domestic violence and has generally been favored by women. This prohibition, however, is not recognized by federal Mexican law as the Zapatista movement is strongly opposed by the federal government.\nThe sale and purchase of alcohol is prohibited on and the night before certain national holidays, such as \"Natalicio de Benito Ju\u00e1rez\" (birthdate of Benito Ju\u00e1rez) and \"D\u00eda de la Revoluci\u00f3n\", which are meant to be dry nationally. The same \"dry law\" applies to the days before presidential elections every six years.\nUnited States.\nProhibition in the United States focused on the manufacture, transportation, and sale of alcoholic beverages; exceptions were made for medicinal and religious uses. Alcohol consumption was never illegal under federal law. Nationwide Prohibition did not begin in the United States until January 1920, when the Eighteenth Amendment to the U.S. Constitution went into effect. The Eighteenth amendment was ratified in 1919, and was repealed in December 1933 with the ratification of the Twenty-first Amendment.\nConcern over excessive alcohol consumption began during the American colonial era, when fines were imposed for drunken behavior and for selling liquor without a license. In the mid-19th century evangelical Protestants denounced drinking as sinful and demanded the prohibition of the sale of beer, wine and liquor. Apart from Maine, they had limited success until the early 20th century. By the 1840s the temperance movement was actively encouraging individuals to immediately stop drinking. However, the issue of slavery, and then the Civil War, overshadowed the temperance movement until the 1870s.\nProhibition was a major reform movement from the 1870s until the 1920s, when nationwide prohibition went into effect. It was supported by evangelical Protestant churches, especially the Methodists, Baptists, Presbyterians, Disciples of Christ, Congregationalists, Quakers, and Scandinavian Lutherans. Opposition came from Catholics, Episcopalians, and German Lutherans. The Women's Crusade of 1873 and the Woman's Christian Temperance Union (WCTU), founded in 1874, were means through which certain women organized and demanded political action, well before they were granted the vote. The WCTU and the Prohibition Party were major players until the 20th century, when the Anti-Saloon League emerged as the movement's leader. By 1913, 9 states had statewide prohibition and 31 others had local option laws in effect. The League then turned their efforts toward attaining a constitutional amendment and grassroots support for nationwide prohibition. The German American community was the base of the beer industry and became a pariah when the U.S. declared war on Germany in 1917. A new constitutional amendment passed Congress in December 1917 and was ratified by the states in 1919. It prohibited \"the manufacture, sale, or transportation of intoxicating liquors within, the importation thereof into, or the exportation thereof.\" On October 28, 1919, Congress passed the National Prohibition Act, known as the Volstead Act, to implement the new 18th Amendment. After a year's required delay, national prohibition began on January 16, 1920.\nInitially, alcohol consumption nosedived to about 30% of its pre-Prohibition levels, but within a few years, the illicit market grew to roughly two-thirds. Illegal stills flourished in remote rural areas as well as city slums, and large quantities were smuggled from Canada. Bootlegging became a major business activity for organized crime groups, under leaders such as Al Capone in Chicago and Lucky Luciano in New York City.\nProhibition lost support during the Great Depression, from 1929. The repeal movement was initiated and financed by the Association Against the Prohibition Amendment, and Pauline Sabin, a wealthy Republican, founded the Women's Organization for National Prohibition Reform (WONPR). Repeal of Prohibition in the United States was accomplished with the ratification of the Twenty-first Amendment on December 5, 1933. Under its terms, states were allowed to set their own laws for the control of alcohol, although it remains a heavily regulated commodity at the federal level as well, e.g., with federally established standards of identity for alcoholic beverages, federal licensing of distilleries, federal taxation, and a federal Bureau of Alcohol, Tobacco, Firearms and Explosives enforcement agency.\nBetween 1832 and 1953, federal legislation prohibited the sale of alcohol to Native Americans, with very limited success. After 1953, Native American communities and reservations were permitted to pass their own local ordinances governing the sale of alcoholic beverages.\nIn the 21st century, there are still counties and parishes within the United States known as \"dry\", where the sale of alcohol is prohibited or restricted.\nSouth America.\nVenezuela.\nIn Venezuela, twenty-four hours before every election, the government prohibits the sale and distribution of alcoholic beverages throughout the national territory, including the restriction to all dealers, liquor stores, supermarkets, restaurants, wineries, pubs, bars, public entertainment, clubs and any establishment that markets alcoholic beverages.\nThe same is done during Holy Week as a measure to reduce the alarming rate of road traffic accidents during these holidays.\nOceania.\nAustralia.\nThe Australian Capital Territory (then the Federal Capital Territory) was the first jurisdiction in Australia to have prohibition laws. In 1911, King O'Malley, then Minister of Home Affairs, shepherded laws through Parliament preventing new issue or transfer of licences to sell alcohol, to address unruly behaviour among workers building the new capital city. Prohibition was partial, since possession of alcohol purchased outside of the Territory remained legal and the few pubs that had existing licences could continue to operate. The Federal Parliament repealed the laws after residents of the Federal Capital Territory voted for the end of them in a 1928 plebiscite.\nSince then, some state governments and local councils have enacted dry areas. This is where the purchase or consumption of alcohol is only permitted in licensed areas such as liquor stores, clubs, cafes, bars, hotels, restaurants, and also private homes. In public places such as streets, parks, and squares, consumption is not permitted, but carrying bottles that were purchased at licensed venues is allowed. Almost all dry areas are small defined districts within larger urban or rural communities.\nMore recently, alcohol has been prohibited in many remote Indigenous communities. Penalties for transporting alcohol into these \"dry\" communities are severe and can result in confiscation of any vehicles involved; in dry areas within the Northern Territory, all vehicles used to transport alcohol are seized.\nNew Zealand.\nIn New Zealand, prohibition was a moralistic reform movement begun in the mid-1880s by the Protestant evangelical and Nonconformist churches and the Woman's Christian Temperance Union and after 1890 by the Prohibition League. It assumed that individual virtue was all that was needed to carry the colony forward from a pioneering society to a more mature one, but it never achieved its goal of national prohibition. Both the Church of England and the largely Irish Catholic Church rejected prohibition as an intrusion of government into the church's domain, while the growing labor movement saw capitalism rather than alcohol as the enemy.\nReformers hoped that the women's vote, in which New Zealand was a pioneer, would swing the balance, but the women were not as well organized as in other countries. Prohibition had a majority in a national referendum in 1911, but needed a 60% vote to pass. The movement kept trying in the 1920s, losing three more referendums by close votes; it managed to keep in place a 6 pm closing hour for pubs and Sunday closing. The Depression and war years effectively ended the movement, but their 6 p.m. closing hour remained until October 1967 when it was extended to 10 pm.\nFor many years, referendums were held for individual towns or electorates, often coincident with general elections. The ballots determined whether these individual areas would be \"dry\" \u2013 that is, alcohol could not be purchased or consumed in public in these areas. One notable example was the southern city of Invercargill, which was dry from 1907 to 1943. People wanting alcohol usually travelled to places outside the city (such as the nearby township of Lorneville or the town of Winton) to drink in the local pubs or purchase alcohol to take back home. The last bastion of this 'dry' area remains in force in the form of a licensing trust that still to this day governs the sale of liquor in Invercargill. The city does not allow the sale of alcohol (beer and wine included) in supermarkets unlike in the majority of New Zealand, and all form of alcohol regardless of the sort can only be sold in bars and liquor stores.\nProhibition was of limited success in New Zealand as\u2014like in other countries\u2014it led to organised bootlegging. The most famous bootlegged alcohol in New Zealand was that produced in the Hokonui Hills close to the town of Gore (not coincidentally, the nearest large town to Invercargill). Even today, the term \"Hokonui\" conjures up images of illicit whisky to many New Zealanders.\nElections.\nIn many countries in Latin America, the Philippines, Thailand, Turkey, India, and several US states, the sale but not the consumption of alcohol is prohibited before and during elections. In Spanish-speaking countries, this is called a \"Ley Seca\" (dry law).\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24857", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=24857", "title": "Phenothiazine", "text": "Heterocyclic compound containing a ring of four carbon, one nitrogen and one sulfur atom\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nPhenothiazine, abbreviated PTZ, is an organic compound that has the formula S(C6H4)2NH and is related to the thiazine-class of heterocyclic compounds. Derivatives of phenothiazine are highly bioactive and have widespread use.\nThe derivatives chlorpromazine and promethazine revolutionized the fields of psychiatry and allergy treatment, respectively. An earlier derivative, methylene blue, was one of the first antimalarial drugs, and derivatives of phenothiazine are currently under investigation as possible anti-infective drugs. Phenothiazine is a prototypical pharmaceutical lead structure in medicinal chemistry.\nUses.\nPhenothiazine itself is only of theoretical interest, but derivatives of it revolutionized psychiatry, other fields of medicine, and pest management. Other derivatives have been studied for possible use in advanced batteries and fuel cells.\nPhenothiazine-derived drugs.\nIn 1876, methylene blue, a derivative of phenothiazine, was synthesized by Heinrich Caro at BASF. The structure was deduced in 1885 by Heinrich August Bernthsen. Bernthsen synthesized phenothiazine in 1883. In the mid 1880s, Paul Ehrlich began to use methylene blue in his cell staining experiments that led to pioneering discoveries about different cell types. He was awarded a Nobel Prize based in part on that work. He became particularly interested in its use to stain bacteria and parasites such as \"Plasmodiidae\" \u2013 the genus that includes the malaria pathogen \u2013 and found that it could be stained with methylene blue. He thought methylene blue could possibly be used in the treatment of malaria, tested it clinically, and by the 1890s methylene blue was being used for that purpose.\nFor the next several decades, research on derivatives lapsed until phenothiazine itself came to market as an insecticide and deworming drug. In the 1940s, chemists working with Paul Charpentier at Rhone-Poulenc Laboratories in Paris (a precursor company to Sanofi), began making derivatives. This work led to promethazine which had no activity against infective organisms, but did have good antihistamine activity, with a strong sedative effect. It went to market as a drug for allergies and for anesthesia. As of 2012 it was still on the market. At the end of the 1940s the same lab produced chlorpromazine which had an even stronger sedative and soothing effect, and Jean Delay and Pierre Deniker attempted to use it on their psychiatric patients, publishing their results in the early 1950s. The strong effects they found opened the door of the modern field of psychiatry and led to a proliferation of work on phenothiazine derivatives. The systematic research conducted by chemists to explore phenothiazine derivatives and their activity was a pioneering example of medicinal chemistry; phenothiazine is often discussed as a prototypical example of a pharmaceutical lead structure.\nA number of phenothiazines other than methylene blue have been shown to have antimicrobial effects. In particular, thioridazine has been shown to make extensively drug-resistant tuberculosis (XDR-TB) drug-susceptible again and make methicillin-resistant Staphylococcus aureus (MRSA) susceptible to beta-lactam antibiotics. The major reason why thioridazine has not been utilized as an antimicrobial agent is due to adverse effects on the central nervous system and cardiovascular system (particularly QT interval prolongation).\nThe term \"phenothiazines\" describes the largest of the five main classes of antipsychotic drugs. These drugs have antipsychotic and, often, antiemetic properties, although they may also cause severe side effects such as extrapyramidal symptoms (including akathisia and tardive dyskinesia), hyperprolactinaemia, and the rare but potentially fatal neuroleptic malignant syndrome, as well as substantial weight gain. Use of phenothiazines has been associated with antiphospholipid syndrome, but no causal relationship has been established.\nPhenothiazine antipsychotics are classified into three groups that differ with respect to the substituent on nitrogen: the aliphatic compounds (bearing acyclic groups), the \"piperidines\" (bearing piperidine-derived groups), and the piperazine (bearing piperazine-derived substituents).\nNondrug applications.\nThe synthetic dye methylene blue, containing the structure, was described in 1876. Many water-soluble phenothiazine derivatives, such as methylene blue, methylene green, thionine, and others, can be electropolymerized into conductive polymers used as electrocatalysts for NADH oxidation in enzymatic biosensors and biofuel cells.\nPhenothiazine is used as an anaerobic inhibitor for acrylic acid polymerization, often used as an in-process inhibitor during the purification of acrylic acid.\nTrade names.\nLike many commercially significant compounds, phenothiazine has numerous trade names, including AFI-Tiazin, Agrazine, Antiverm, Biverm, Dibenzothiazine, Orimon, Lethelmin, Souframine, Nemazene, Vermitin, Padophene, Fenoverm, Fentiazine, Contaverm, Fenothiazine, Phenovarm, Ieeno, ENT 38, Helmetina, Helmetine, Penthazine, XL-50, Wurm-thional, Phenegic, Phenovis, Phenoxur, and Reconox.\nFormer uses.\nPhenothiazine was formerly used as an insecticide and as a drug to treat infections with parasitic worms (anthelminthic) in livestock and people, but its use for those purposes has been superseded by other chemicals.\nPhenothiazine was introduced by DuPont as an insecticide in 1935. About 3,500,000 pounds were sold in the US in 1944. However, because it was degraded by sunlight and air, it was difficult to determine how much to use in the field, and its use waned in the 1940s with the arrival of new pesticides like DDT that were more durable. As of July 2015 it is not registered for pesticide use in the US, Europe, or Australia.\nAs an anthelminthic.\nIt was introduced as anthelminthic in livestock in 1940 and is considered, with thiabendazole, to be the first modern anthelminthic. The first instances of resistance were noted in 1961. Among anthelmintics, Blizzard et al. 1990 found only paraherquamide to have similar activity to phenothiazine. It is possible that they share the same mode of action. Uses for this purpose in the US are still described but it has \"virtually disappeared from the market.\"\nIn the 1940s it also was introduced as antihelminthic for humans; since it was often given to children, the drug was often sold in chocolate, leading to the popular name, \"worm chocolate.\" Phenothiazine was superseded by other drugs in the 1950s.\nStructure and synthesis.\nThe central C4SN ring is folded in phenothiazines.\nThe compound was originally prepared by Bernthsen in 1883 via the reaction of diphenylamine with sulfur, but more recent syntheses rely on the cyclization of 2-substituted diphenyl sulfides. Few pharmaceutically significant phenothiazines are prepared from phenothiazine, although some of them are.\nPhenothiazines are electron donors, forming charge-transfer salts with many acceptors.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24861", "revid": "30552921", "url": "https://en.wikipedia.org/wiki?curid=24861", "title": "Pale Fire", "text": "1962 novel by Vladimir Nabokov\nPale Fire is a 1962 novel by Vladimir Nabokov. The novel is presented as a 999-line poem titled \"Pale Fire\", written by the fictional poet John Shade, with a foreword, lengthy commentary, and index written by Shade's neighbor and academic colleague, Charles Kinbote. Together these elements form a narrative in which both fictional authors are central characters. Nabokov wrote \"Pale Fire\" in 1960\u201361, after the success of \"Lolita\" had made him financially independent, allowing him to retire from teaching and return to Europe. Nabokov began writing the novel in Nice and completed it in Montreux, Switzerland.\n\"Pale Fire\"'s unusual structure has attracted much attention, and it is often cited as an important example of metafiction, as well as an analog precursor to hypertext fiction, and a poioumenon. It has spawned a wide variety of interpretations and a large body of written criticism, which literary scholar Pekka Tammi estimated in 1995 as more than 80 studies. The Nabokov authority Brian Boyd has called it \"Nabokov's most perfect novel\", and the critic Harold Bloom called it \"the surest demonstration of his own genius ... that remarkable tour de force\".\nNovel structure.\nStarting with the epigraph and table of contents, \"Pale Fire\" is apparently the publication of a 999-line poem in four cantos (\"Pale Fire\") by the fictional John Shade with a foreword, extensive commentary, and index by his self-appointed editor, Charles Kinbote. Kinbote's commentary takes the form of notes to various numbered lines of the poem. Here, as in the rest of his critical apparatus, Kinbote explicates the poem very little. Focusing monomanically on his own concerns, he divulges what proves to be the plot piece by piece, some of which can be connected by following the many cross-references. Espen Aarseth noted that \"Pale Fire\" \"can be read either unicursally, straight through, or multicursally, jumping between the comments and the poem.\" Thus, although the narration is non-linear and multidimensional, the reader can still choose to read the novel in a linear manner without risking misinterpretation.\nThe interaction between Kinbote and Shade takes place in the fictitious small college town and state of New Wye, Appalachia, where they live across a lane from each other from February to July 1959. Kinbote writes his commentary from then to October 1959 in a tourist cabin in the equally fictitious western town and state of Cedarn, Utana. Both authors recount many earlier events, Shade mostly in New Wye and Kinbote in New Wye and in Europe, especially the \"distant northern land\" of Zembla.\nPlot summary.\nShade's poem digressively describes many aspects of his life. Canto 1 includes his early encounters with death and glimpses of what he takes to be the supernatural. Canto 2 is about his family and the apparent suicide of his daughter, Hazel Shade. Canto 3 focuses on Shade's search for knowledge about an afterlife, culminating in a \"faint hope\" in higher powers \"playing a game of worlds\" as indicated by apparent coincidences. Canto 4 offers details on Shade's daily life and creative process, as well as thoughts on his poetry, which he finds to be a means of somehow understanding the universe.\nIn Kinbote's editorial contributions he tells three stories intermixed with each other. One is his own story, notably including what he thinks of as his friendship with Shade. After Shade was murdered, Kinbote acquired the manuscript, including some variants, and has taken it upon himself to oversee the poem's publication, telling readers that it lacks only line 1000. Kinbote's second story deals with King Charles II, \"The Beloved\", the deposed king of Zembla. King Charles escaped imprisonment by Soviet-backed revolutionaries, making use of a secret passage and brave adherents in disguise. Kinbote repeatedly claims that he inspired Shade to write the poem by recounting King Charles's escape to him and that possible allusions to the king, and to Zembla, appear in Shade's poem, especially in rejected drafts. However, no explicit reference to King Charles is to be found in the poem. Kinbote's third story is that of Gradus, an assassin dispatched by the new rulers of Zembla to kill the exiled King Charles. Gradus makes his way from Zembla through Europe and America to New Wye, suffering comic mishaps. In the last note, to the missing line 1000, Kinbote narrates how Gradus killed Shade by mistake.\nTowards the end of the narrative, Kinbote all but states that he is in fact the exiled King Charles, living incognito; however, enough details throughout the story, as well as direct statements of ambiguous sincerity by Kinbote towards the novel's end, suggest that King Charles and Zembla are both fictitious. In the latter interpretation, Kinbote is delusional and has built an elaborate picture of Zembla complete with samples of a constructed language as a by-product of insanity; similarly, Gradus was simply an unhinged man trying to kill Shade, and his backstory as a revolutionary assassin is also made up.\nIn an interview, Nabokov later said that Kinbote killed himself after finishing the book. The critic Michael Wood has stated, \"This is authorial trespassing, and we don't have to pay attention to it\", but Brian Boyd has argued that internal evidence points to Kinbote's suicide. One of Kinbote's annotations to Shade's poem (corresponding to line 493) addresses the subject of suicide at some length.\nExplanation of the title.\nAs Nabokov pointed out himself, the title of John Shade's poem is from Shakespeare's \"Timon of Athens:\" \"The moon's an arrant thief, / And her pale fire she snatches from the sun\" (Act IV, scene 3), a line often taken as a metaphor about creativity and inspiration. Kinbote quotes the passage but does not recognize it, as he says he has access only to an inaccurate Zemblan translation of the play \"in his Timonian cave\", and in a separate note he even rails against the common practice of using quotations as titles.\nSome critics have noted a secondary reference in the book's title to \"Hamlet\", where the Ghost remarks how the glow-worm \"'gins to pale his uneffectual fire\" (Act I, scene 5).\nThe title is first mentioned in the foreword: \"I recall seeing him from my porch, on a brilliant morning, burning a whole stack of [index cards of drafts of the poem] in the pale fire of the incinerator...\".\nReception.\nAccording to Norman Page, \"Pale Fire\" excited as diverse criticism as any of Nabokov's novels. Mary McCarthy's review was extremely laudatory; the Vintage edition excerpts it on the front cover. She tried to explicate hidden references and connections. Dwight Macdonald responded by saying the book was \"unreadable\" and both it and McCarthy's review were as pedantic as Kinbote. Anthony Burgess, like McCarthy, extolled the book, while Alfred Chester condemned it as \"a total wreck\".\nSome other early reviews were less decided, praising the book's satire and comedy but noting its difficulty and finding its subject slight or saying that its artistry offers \"only a kibitzer's pleasure\". Macdonald called the reviews he had seen, other than McCarthy's, \"cautiously unfavorable\". \"Time\"'s 1962 review stated that \"\"Pale Fire\" does not really cohere as a satire; good as it is, the novel in the end seems to be mostly an exercise in agility \u2013 or perhaps in bewilderment\", though this did not prevent the publication from including the book in its 2005 list of the 100 best English-language novels published since 1923.\nThe connection between \"Pale Fire\" and hypertext was stated soon after its publication; in 1969, the information-technology researcher Ted Nelson obtained permission from the novel's publishers to use it for a hypertext demonstration at Brown University. A 2009 paper by Annalisa Volpone also compares \"Pale Fire\" to hypertext.\nThe first Russian translation of the novel, one created by V\u00e9ra Nabokov, its dedicatee, was published in 1983 by Ardis in Ann Arbor, Michigan (Alexei Tsvetkov initially played an important role in this translation).\nAfter Nabokov's reputation was rehabilitated in the Soviet Union (his novels started being published there in 1986 and the first book composed entirely of Nabokov's works was printed in 1988), \"Pale Fire\" was published in 1991 in Sverdlovsk (in Sergei Ilyin's Russian translation).\nIt was ranked 53rd on the list of the Modern Library 100 Best Novels and 1st on the American literary critic Larry McCaffery's \".\"\nInterpretations.\nSome readers concentrate on the apparent story, focusing on traditional aspects of fiction such as the relationship among the characters. In 1997, Brian Boyd published a much-discussed study arguing that the ghost of John Shade influenced Kinbote's contributions. He expanded this essay into a book in which he also argues that, in order to trigger Shade's poem, Hazel Shade's ghost induced Kinbote to recount his Zemblan delusions to Shade.\nSome readers, starting with Mary McCarthy and including Boyd, Nabokov's annotator Alfred Appel, and D. Barton Johnson, see Charles Kinbote as an alter-ego of the insane Professor V. Botkin, to whose delusions John Shade and the rest of the faculty of Wordsmith College generally condescend. Nabokov himself endorsed this reading, stating in an interview in 1962 (the novel's year of publication) that \"Pale Fire\" \"is full of plums that I keep hoping somebody will find. For instance, the nasty commentator is not an ex-King of Zembla nor is he professor Kinbote. He is professor Botkin, or Botkine, a Russian and a madman.\" The novel's intricate structure of teasing cross-references leads readers to this \"plum\". The Index, supposedly created by Kinbote, features an entry for a \"Botkin, V.,\" describing this Botkin as an \"American scholar of Russian descent\"\u2014and referring to a note in the Commentary on line 894 of Shade's poem, in which no such person is directly mentioned but a character suggests that \"Kinbote\" is \"a kind of anagram of Botkin or Botkine\". In this interpretation, \"Gradus\" the murderer is an American named Jack Grey who wanted to kill Judge Goldsworth, whose house \"Pale Fire's\" commentator\u2014whatever his \"true\" name is\u2014is renting. Goldsworth had condemned Grey to an asylum from which he escaped shortly before mistakenly killing Shade, who resembled Goldsworth.\nOther readers see a story quite different from the apparent narrative. \"Shadeans\" maintain that John Shade wrote not only the poem, but the commentary as well, having invented his own death and the character of Kinbote as a literary device. According to Boyd, Andrew Field invented the Shadean theory and Julia Bader expanded it; Boyd himself espoused the theory for a time. In an alternative version of the Shadean theory, Tiffany DeRewal and Matthew Roth argued that Kinbote is not a separate person but is a dissociated, alternative personality of John Shade. (An early reviewer had mentioned that \"a case might be made\" for such a reading.)\n\"Kinboteans\", a decidedly smaller group, believe that Kinbote invented the existence of John Shade. Boyd credits the Kinbotean theory to Page Stegner and adds that most of its adherents are newcomers to the book. Some readers see the book as oscillating undecidably between these alternatives, like the Rubin vase (a drawing that may be two profiles or a goblet).\nThough a minority of commentators believe or at least accept the possibility that Zembla is as \"real\" as New Wye, most assume that Zembla, or at least the operetta-quaint and homosexually gratified palace life enjoyed by Charles Kinbote before he is overthrown, is imaginary in the context of the story. The name \"Zembla\" (taken from \"Nova Zembla\", a former latinization of Novaya Zemlya) may evoke popular fantasy literature about royalty such as \"The Prisoner of Zenda\". As in other Nabokov books, however, the fiction is an exaggerated or comically distorted version of his own life as a son of privilege before the Russian Revolution and an exile afterwards, and the central murder has resemblances (emphasized by Priscilla Meyer) to Nabokov's father's murder by an assassin who was trying to kill someone else.\nStill other readers de-emphasize any sort of \"real story\" and may doubt the existence of such a thing. In the interplay of allusions and thematic links, they find a multifaceted image of English literature, criticism, or glimpses of a higher world and an afterlife.\nAllusions and references.\nThe first two lines of John Shade's 999-line poem, \"Pale Fire\", have become Nabokov's most quoted couplet:\n&lt;poem&gt;I was the shadow of the waxwing slain\nBy the false azure in the window pane&lt;/poem&gt;\nLike many of Nabokov's fictions, \"Pale Fire\" alludes to others of his. \"Hurricane Lolita\" is mentioned, and \"Pnin\" appears as a minor character. There are many resemblances to \"Ultima Thule\" and \"Solus Rex\", two short stories by Nabokov intended to be the first two chapters of a novel in Russian that he never continued. The placename Thule appears in \"Pale Fire\", as does the phrase \"solus rex\" (a chess problem in which one player has no pieces but the king).\nThe book is also full of references to culture, nature, and literature. They include, but are not limited to:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSee also \"The Ambidextrous Universe\", a later book referencing \"Pale Fire\" which in turn triggered a reciprocal response in a subsequent Nabokov novel (\"\", 1969).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24862", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=24862", "title": "Preservative", "text": "Substance designed to prevent decomposition\nA preservative is a substance or a chemical that is added to products such as food products, beverages, pharmaceutical drugs, paints, biological samples, cosmetics, wood, and many other products to prevent decomposition by microbial growth or by undesirable chemical changes. In general, preservation is implemented in two modes, chemical and physical. Chemical preservation entails adding chemical compounds to the product. Physical preservation entails processes such as refrigeration or drying. Preservative food additives reduce the risk of foodborne infections, decrease microbial spoilage, and preserve fresh attributes and nutritional quality. Some physical techniques for food preservation include dehydration, UV-C radiation, freeze-drying, and refrigeration. Chemical preservation and physical preservation techniques are sometimes combined.\nFood preservation.\nPreservatives have been used since prehistoric times. Smoked meat for example has phenols and other chemicals that delay spoilage. The preservation of foods has evolved greatly over the centuries and has been instrumental in increasing food security. The use of preservatives other than traditional oils, salts, paints, etc. in food began in the late 19th century, but was not widespread until the 20th century.\nThe use of food preservatives varies greatly depending on the country. Many developing countries that do not have strong governments to regulate food additives face either harmful levels of preservatives in foods or a complete avoidance of foods that are considered unnatural or foreign. These countries have also proven useful in case studies surrounding chemical preservatives, as they have been only recently introduced. In urban slums of highly populated countries, the knowledge about contents of food tends to be extremely low, despite consumption of these imported foods.\nAntimicrobial preservatives.\nAntimicrobial preservatives prevent degradation by bacteria. This method is the most traditional and ancient type of preserving\u2014ancient methods such as pickling and adding honey prevent microorganism growth by modifying the pH level. The most commonly used antimicrobial preservative is lactic acid. Common antimicrobial preservatives are presented in the table. Nitrates and nitrites are also antimicrobial. The detailed mechanism of these chemical compounds range from inhibiting growth of the bacteria to the inhibition of specific enzymes.\nAntioxidants.\nThe oxidation process spoils most food, especially those with a high fat content. Fats quickly turn rancid when exposed to oxygen. Antioxidants prevent or inhibit the oxidation process. The most common antioxidant additives are ascorbic acid (vitamin C) and ascorbates. Thus, antioxidants are commonly added to oils, cheese, and chips. Other antioxidants include the phenol derivatives BHA, BHT, TBHQ and propyl gallate. These agents suppress the formation of hydroperoxides.\nA variety of agents are added to sequester (deactivate) metal ions that otherwise catalyze the oxidation of fats. Common sequestering agents are disodium EDTA, citric acid (and citrates), tartaric acid, and lecithin.\nNonsynthetic compounds for food preservation.\nCitric and ascorbic acids target enzymes that degrade fruits and vegetables, e.g., mono/polyphenol oxidase which turns surfaces of cut apples and potatoes brown. Ascorbic acid and tocopherol, which are vitamins, are common preservatives. Smoking entails exposing food to a variety of phenols, which are antioxidants. Natural preservatives include rosemary and oregano extract, hops, salt, sugar, vinegar, alcohol, diatomaceous earth and castor oil.\nTraditional preservatives, such as sodium benzoate have raised health concerns in the past. Benzoate was shown in a study to cause hypersensitivity in some asthma sufferers. This has caused reexamination of natural preservatives which occur in vegetables.\nPublic awareness of food preservation.\nPublic awareness of food preservatives is uneven. Americans have a perception that food-borne illnesses happen more often in other countries. This may be true, but the occurrence of illnesses, hospitalizations, and deaths are still high. It is estimated by the Centers for Disease Control (CDC) that each year there are 76 million illnesses, 325,000 hospitalizations, and 5,000 deaths linked to food-borne illness.\nFood suppliers are facing difficulties with regards to the safety and quality of their products as a result of the rising demand for ready-to-eat fresh food products. Artificial preservatives meet some of these challenges by preserving freshness for longer periods of time, but these preservatives can cause negative side-effects as well.\nPreservation of other products.\nWater-based home and personal care products use broad-spectrum preservatives, such as isothiazolinones and formaldehyde releasers, which may cause sensitization, leading to allergic skin.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24863", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=24863", "title": "Pseudomonadota", "text": "Phylum of Gram-negative bacteria\nPseudomonadota (synonym \"Proteobacteria\") is a major phylum of gram-negative bacteria. They include pathogenic and free-living (non-parasitic) genera. The phylum comprises six classes \"Acidithiobacillia, Alphaproteobacteria, Betaproteobacteria, Gammaproteobacteria, Hydrogenophilia\", and \"Zetaproteobacteria.\" The Pseudomonadota are widely diverse, with differences in morphology, metabolic processes, relevance to humans, and ecological influence.\nClassification.\nAmerican microbiologist Carl Woese established this grouping in 1987, calling it informally the \"purple bacteria and their relatives\". The group was later formally named the 'Proteobacteria' after the Greek god Proteus, who was known to assume many forms. In 2021 the International Committee on Systematics of Prokaryotes designated the synonym Pseudomonadota, and renamed many other prokaryotic phyla as well. This renaming of several prokaryote phyla in 2021, including Pseudomonadota, remains controversial among microbiologists, many of whom continue to use the earlier name Proteobacteria, of long standing in the literature. The phylum Pseudomonadota encompasses classes \"Acidithiobacillia, Alphaproteobacteria, Betaproteobacteria, Gammaproteobacteria, Hydrogenophilia\", and \"Zetaproteobacteria.\" The phylum includes a wide variety of pathogenic genera, such as \"Escherichia\", \"Salmonella\", \"Vibrio\", \"Yersinia\", \"Legionella\", and many others. Others are free-living (non-parasitic) and include many of the bacteria responsible for nitrogen fixation.\nPreviously, the Pseudomonadota phylum included two additional classes, namely \"Deltaproteobacteria\" and \"Oligoflexia\". However, further investigation into the phylogeny of these taxa through genomic marker analysis demonstrated their separation from the Pseudomonadota phylum. \"Deltaproteobacteria\" has been identified as a diverse taxonomic unit, leading to a proposal for its reclassification into distinct phyla: \"Desulfobacterota\" (encompassing \"Thermodesulfobacteria\"), \"Myxococcota\", and \"Bdellovibrionota\" (comprising \"Oligoflexia\").\nThe class \"Epsilonproteobacteria\" was additionally identified within the Pseudomonadota phylum. This class is characterized by its significance as chemolithotrophic primary producers and its metabolic prowess in deep-sea hydrothermal vent ecosystems. Noteworthy pathogenic genera within this class include \"Campylobacter, Helicobacter, and Arcobacter\". Analysis of phylogenetic tree topology and genetic markers revealed the direct divergence of \"Epsilonproteobacteria\" from the Pseudomonadota phylum. Limited outgroup data and low bootstrap values support these discoveries. Despite further investigations, consensus has not been reached regarding the monophyletic nature of \"Epsilonproteobacteria\" within Proteobacteria, prompting researchers to propose its taxonomic separation from the phylum. The proposed reclassification of the name \"Epsilonproteobacteria\" is \"Epsilonbacteraeota\", later revised to \"Campylobacterota\" in 2018.\nTaxonomy.\nThe currently accepted taxonomy is based on the List of Prokaryotic names with Standing in Nomenclature (LPSN) and National Center for Biotechnology Information (NCBI).\nThe group Pseudomonadota is defined based on ribosomal RNA (rRNA) sequencing, and are divided into several subclasses. These subclasses were regarded as such for many years, but are now treated as various classes of the phylum. These classes are monophyletic. The genus \"Acidithiobacillus\", part of the Gammaproteobacteria until it was transferred to class Acidithiobacillia in 2013, was previously regarded as paraphyletic to the \"Betaproteobacteria\" according to multigenome alignment studies. In 2017, the Betaproteobacteria was subject to major revisions and the class Hydrogenophilalia was created to contain the order Hydrogenophilales\nPseudomonadota classes with validly published names include some prominent genera: e.g.:\nCharacteristics.\nPseudomonadota are a diverse group. Though some species may stain Gram-positive or Gram-variable in the laboratory, they are nominally Gram-negative. Their unique outer membrane is mainly composed of lipopolysaccharides, which helps differentiate them from the Gram-positive species. Most Pseudomonadota are motile and move using flagella. Many move about using flagella, but some are nonmotile, or rely on bacterial gliding.\nPseudomonadota have a wide variety of metabolism types. Most are facultative or obligate anaerobes, chemolithoautotrophs, and heterotrophs, though numerous exceptions exist. A variety of distantly related genera within the Pseudomonadota obtain their energy from light through conventional photosynthesis or anoxygenic photosynthesis.\nThe Acidithiobacillia contain only sulfur, iron, and uranium-oxidizing autotrophs. The type order is the Acidithiobacillaceae, which includes five different \"Acidithiobacillus\" species used in the mining industry. In particular, these microbes assist with the process of bioleaching, which involves microbes assisting in metal extraction from mining waste that typically extraction methods cannot remove.\nSome Alphaproteobacteria can grow at very low levels of nutrients and have unusual morphology within their life cycles. Some form stalks to help with colonization, and form buds during cell division. Others include agriculturally important bacteria capable of inducing nitrogen fixation in symbiosis with plants. The type order is the Caulobacterales, comprising stalk-forming bacteria such as \"Caulobacter\". The mitochondria of eukaryotes are thought to be descendants of an alphaproteobacterium.\nThe Betaproteobacteria are highly metabolically diverse and contain chemolithoautotrophs, photoautotrophs, and generalist heterotrophs. The type order is the Burkholderiales, comprising an enormous range of metabolic diversity, including opportunistic pathogens. These pathogens are primary for both humans and animals, such as the horse pathogen \"Burkholderia mallei\", and \"Burkholderia cepacia\" which causes respiratory tract infections in people with cystic fibrosis.\nThe Gammaproteobacteria are one of the largest classes in terms of genera, containing approximately 250 validly published names. The type order is the Pseudomonadales, which include the genera \"Pseudomonas\" and the nitrogen-fixing \"Azotobacter\", along with many others. Besides being a well-known pathogenic genus, \"Pseudomonas\" is also capable of biodegradation of certain materials, like cellulose.\nThe Hydrogenophilalia are thermophilic chemoheterotrophs and autotrophs. The bacteria typically use hydrogen gas as an electron donor, but can also use reduced sulfuric compounds. Because of this ability, scientists have begun to use certain species of Hydrogenophilalia to remove sulfides that contaminate industrial wastewater systems. The type order is the Hydrogenophilaceae which contains the genera \"Thiobacillus, Petrobacter, Sulfuricella,\" \"Hydrogenophilus\" and \"Tepidiphilus\". Currently, no members of this class have been identified as pathogenic.\nThe Zetaproteobacteria are the iron-oxidizing neutrophilic chemolithoautotrophs, distributed worldwide in estuaries and marine habitats. This group is so successful in its environment due to their microaerophilic nature. Because they require less oxygen than what is present in the atmosphere, they are able to compete with the abiotic iron(II) oxidation that is already occurring in the environment. The only confirmed type order for this class is the Mariprofundaceae, which does not contain any known pathogenic species.\nTransformation.\nTransformation, a process in which genetic material passes from one bacterium to another, has been reported in at least 30 species of Pseudomonadota distributed in the classes alpha, beta, and gamma. The best-studied Pseudomonadota with respect to natural genetic transformation are the medically important human pathogens \"Neisseria gonorrhoeae\" (class beta), and \"Haemophilus influenzae\" (class gamma). Natural genetic transformation is a sexual process involving DNA transfer from one bacterial cell to another through the intervening medium and the integration of the donor sequence into the recipient genome. In pathogenic Pseudomonadota, transformation appears to serve as a DNA repair process that protects the pathogen's DNA from attack by their host's phagocytic defenses that employ oxidative free radicals.\nHabitat.\nDue to the distinctive nature of each of the six classes of Pseudomonadota, this phylum occupies a multitude of habitats. These include:\nSignificance.\nHuman health.\nStudies have suggested Pseudomonadota as a relevant signature of disease in the human gastrointestinal (GI) tract, by operating as a marker for microbiota instability. The human gut microbiome consists mainly of four phyla: Firmicutes, Bacteroidetes, Actinobacteria, and Pseudomonadota. Microorganism gut colonization is dynamic from birth to death, with stabilization at the first few years of life, to higher diversity in adults, to reduced diversity in the elderly. The gut microbiome conducts processes like nutrient synthesis, chemical metabolism, and the formation of the gut barrier. Additionally, the gut microbiome facilitates host interactions with its surrounding environment through regulation of nutrient absorption and bacterial intake. In 16s rRNA and metagenome sequencing studies, Proteobacteria have been identified as bacteria that prompts endotoxemia (an inflammatory gut response) and metabolic disorders in human GI tracts. Another study by Michail et al. showed a correlation of microbial composition in children with and without nonalcoholic fatty liver disease (NAFLD), wherein patients with NAFLD have a higher abundance of Gammaproteobacteria than patients without the disease.\nClasses Betaproteobacteria and Gammaproteobacteria are prevalent within the human oral cavity, and are markers for good oral health. The oral microbiome consists of 11 habitats, including the tongue dorsum, hard palate, tonsils, throat, saliva, and more. Changes in the oral microbiome are due to endogenous and exogenous factors like host lifestyle, genotype, environment, immune system, and socioeconomic status. Considering diet as a factor, high saturated fatty acid (SAF) content, achieved through poor diet, has been correlated to increased abundance of Betaproteobacteria in the oral cavity.\nEconomic value.\nPseudomonadota bacteria have a symbiotic or mutualistic association with plant roots, an example being in the rhizomes of potato plants. Because of this symbiotic relationship, farmers have the ability to increase their crop yields. Healthier root systems can lead to better nutrient uptake, improved water retention, increased resistance to diseases and pests, and ultimately higher crop yields per acre. Increased agricultural output can spark economic growth, contribute to food security, and lead to job creation in rural areas.\nAs briefly mentioned in previous sections, members of \"Pseudomonadota\" have vast metabolic abilities that allow them to utilize and produce a variety of compounds. Bioleaching, done by various \"Thiobacillus\" species, are a primary example of this. Any iron and sulfur oxidizing species has the potential to uncover metals and low-grade ores that conventional mining techniques were unable to extract. At present, they are most often used for recovering copper and uranium, but researchers are looking to expand this field in the future. The downside of this method is that the bacteria produce acidic byproducts that end up in acid mine drainage. Bioleaching has significant economic promise if it can be controlled and not cause any further harm to the environment.\nEcological impact.\nPseudomonadota are microbes commonly found within soil systems. Microbes play a crucial role in the surrounding ecosystem by performing functions such as nutrient cycling, carbon dioxide fixation, decomposition, and nitrogen fixation. Pseudomonadota can be described as phototrophs, heterotrophs, and lithotrophs. As heterotrophs (examples \"Pseudomonas\" and \"Xanthomonas\") these bacteria are effective in breaking down organic matter, contributing to nutrient cycling. Additionally, photolithotrophs within the phylum are able to perform photosynthesis using sulfide or elemental sulfur as electron donors, which enables them to participate in carbon fixation and oxygen production even in anaerobic conditions. These Pseudomonadota bacteria are also considered copiotrophic organisms, meaning they can be found in environments with high nutrient availability. These environments have ample sources of carbon and other nutrients, environments like fertile soils, compost, and sewage. These copiotrophic bacteria are able to enhance soil health by performing nutrient cycling and waste decomposition.\nBecause this phylum are able to form a symbiotic relationship with plant roots, incorporating Pseudomonadota into agricultural practices aligns with principles of sustainable farming. These bacteria contribute to soil health and fertility, promote natural pest management, and enhance the resilience of crops to environmental stressors.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24864", "revid": "3190204", "url": "https://en.wikipedia.org/wiki?curid=24864", "title": "Professional wrestling", "text": "Form of athletic theater\nProfessional wrestling, often referred to as pro wrestling, or simply, wrestling, is a form of athletic theater centered around mock combat with the premise that its performers are competitive fighters.\nProfessional wrestling gradually developed from competitive catch wrestling in the late 19th century, when wrestlers and promoters began staging matches with predetermined outcomes to exhibit more excitement and draw larger audiences. Over the course of the 20th century, it was increasingly known that professional wrestling was scripted, but the appeal for fans shifted from its competitive element to the entertainment value; wrestlers subsequently responded by incorporating drama, gimmickry, and outlandish stunts into their performances, while maintaining the pretense of engaging in a competitive sport. Eventually, the term \"professional wrestling\" was legally defined as a non-sport by various government regulators because legitimate wrestling was effectively confined to amateur enthusiasts.\nProfessional wrestlers perform as characters and usually maintain what is known in the industry as a gimmick\u2014the persona, style, and traits conveyed by their distinctive attires, ring names, entrance music, and other distinguishable attributes and characteristics. Matches are the primary vehicle for advancing storylines, which typically center on feuds between heroic \"faces\" (also called babyfaces) and villainous \"heels\", although more modern wrestling has increasingly featured morally ambiguous \"tweeners\". A wrestling ring, akin to a boxing ring, serves as the main stage; additional scenes may be recorded for television in backstage areas of the venue, in a format similar to reality television. Performers generally integrate authentic wrestling techniques and fighting styles with choreography, stunts, improvisation, and dramatic conventions designed to maximize audience engagement. Unlike in other forms of entertainment, wrestlers usually remain in character even when they are not performing; this dedication to presenting scripted events as authentic is known as kayfabe.\nProfessional wrestling is performed around the world through various promotions, which are roughly analogous to production companies or sports leagues. Promotions vary considerably in size, scope, and creative approach, ranging from local shows on the independent circuit to internationally broadcast events at major arenas. The largest and most influential promotions are in the United States, Mexico, Japan, and Europe (particularly the United Kingdom, France, and Germany/Austria), which have each developed distinct styles, traditions, and subgenres within professional wrestling. Many professional wrestlers also perform as freelancers and make appearances for different promotions.\nProfessional wrestling has developed its own culture and community, including a unique glossary of terms. It has achieved mainstream success and influence within popular culture; many wrestling phrases, tropes, and concepts are now referenced in everyday language and in film, television, music, and video games. Numerous professional wrestlers have become national or international sports icons with recognition by the wider public, with some finding further fame and success through other endeavours such as acting and music.\nContext.\nIn the United States, authentic wrestling is generally practiced in an amateur context. There is no professional league for competitive wrestling in most Western countries, due to a lack of popularity; one case in point is Real Pro Wrestling, an American professional freestyle wrestling league that dissolved in 2007 after just two seasons.\nIn numerous American states, professional wrestling is legally defined as a non-sport. For instance, the New York athletic commission defines professional wrestling as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Professional wrestling\" means an activity in which participants struggle hand-in-hand primarily for the purpose of providing entertainment to spectators and which does not comprise a \"bona fide\" athletic contest or competition. \"Professional wrestling\" is not a combative sport. Wrestling constituting \"bona fide\" athletic contests and competitions, which may be professional or amateur combative sport, shall not be deemed \"professional wrestling\" under this Part. \"Professional wrestling\" as used in this Part shall not depend on whether the individual wrestlers are paid or have been paid for their performance in a \"professional wrestling\" exhibition. All engagements of \"professional wrestling\" shall be referred to as exhibitions, and not as matches.\u2014\u200a\nIn other countries such as Iran, India, Afghanistan, Turkey, and Egypt, legitimate wrestling enjoys widespread popularity, and the phrase \"professional wrestling\" thus carries a more literal meaning in local parlance. A notable example is India's Pro Wrestling League, which governs authentic competitive wrestling.\nIn the industry's slang, a fixed match is referred to as a \"worked\" match, derived from the slang word for manipulation, as in \"working the crowd\". A \"shoot\" match is a genuine contest where both wrestlers fight to win and are therefore \"straight shooters\", which comes from a carny term for a shooting gallery gun whose sights were not deliberately misaligned.\nHistory in the United States.\nFrom sport to choreography.\nWrestling in the United States blossomed in popularity after the Civil War, with catch wrestling eventually becoming the most popular style. Spectator sports became increasingly popular in the late 19th century due to rising income levels, railroads, mass transit, mass media, and increased urbanization. Before this time, sports were mostly a hobby, but now a star athlete could make a living touring the country and playing before large paying crowds. Many spectators did not enjoy wrestling because of its lengthy, slow nature, however:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"They would go to the mat and stay there for hours and hours, a mass of mute meat. Matches lasted sometimes as long as a third of a day. As practiced by the old school, wrestling was one of the most unexciting spectacles a person could pay money to see: a race between two century plants.\"\u2014\u200a\nThe wrestlers' solution was to stage their matches so that they could present a satisfying spectacle to audiences, and that required both participants to agree in advance who was to be the \"winner\". There were other advantages, also. A real (\"shoot\") match could last hours whereas a staged (\"worked\") match could be made shorter. This was convenient for wrestlers on tour who needed to keep appointments or share venues. This also suited wrestlers who were aging and therefore lacked the stamina for a long fight. Worked matches also carried less risk of injury, which meant shorter recovery. Altogether, worked matches proved more profitable than shoot matches. By the end of the 1800s, nearly all professional wrestling matches were worked.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;American wrestlers are notorious for the amount of faking they do. It is because of this fact that suspicion attaches to so many bouts that the game is not popular here. Nine out of ten bouts, it has been said, are pre-arranged affairs, and it would be no surprise if the ratio of fixed matches to honest ones was really so high.\u2014\u200a\nA major influence on professional wrestling was carnival culture. Wrestlers in the late 19th century worked in carnival shows. For a fee, a visitor could challenge the wrestler to a quick match. If the challenger defeated the champion in a short time frame, usually 15 minutes, they won a prize. To encourage challenges, the carnival operators staged rigged matches in which an accomplice posing as a visitor challenged the champion and won, giving the audience the impression that the champion was easy to beat. This practice taught wrestlers the art of staging matches and fostered a mentality that spectators were marks to be duped. The term \"kayfabe\" comes from carny slang.\nWrestler Lou Thesz recalled that between 1915 and 1920, a series of expos\u00e9s in the newspapers about the integrity of professional wrestling alienated many fans, sending the industry \"into a tailspin\". However, rather than perform more shoot matches, professional wrestlers instead committed themselves wholesale to worked matches and drama.\nCartelization.\nIn the 1910s, promotional cartels for professional wrestling emerged in the East Coast, outside its traditional heartland in the Midwest. These promoters sought to make long-term plans with their wrestlers, and to ensure their more charismatic and crowd-pleasing wrestlers received championships. This also allowed for further suppression of shoot matches, which by this point were largely limited to challenges by independent wrestlers. A challenged wrestler could often claim that the rules of the promotion did not allow for independent challengers. In other cases promotions would respond to challenges with \"policemen\": powerful wrestlers employed not for their charisma or star power but their ability to defeat (and often seriously injure) outside opponents. As the industry trend continued, there were fewer independent wrestlers to make such challenges in the first place.\nDeviations from the agreed choreography, termed double-crosses, in which a wrestler agreed to lose a match but then fought to win, remained a problem in the early cartel days. At times a promoter would even award a victorious double-crosser the title of champion to preserve the facade of competition. However, promoters punished such wrestlers by blacklisting them, making it quite challenging to find work. Double-crossers could also be sued for breach of contract, such as Dick Shikat in 1936. (Notably, witnesses in this trial testified that most of the \"big matches\" and all of the championship bouts were fixed.)\nTransition towards pure entertainment.\nBy the 1930s, with the exception of the occasional double-cross or business dispute, shoot matches were essentially nonexistent. In April 1930, the New York State Athletic Commission decreed that all professional wrestling matches held in the state had to be advertised as exhibitions unless certified as contests by the commission. This requirement did not apply to amateur wrestling, which the commission had no authority over. The Commission did, on very rare occasions, hand out such authorizations, such as for a championship match between Jim Londos and Jim Browning in June 1934.\nSome wrestling fans suspected that professional wrestling was staged, but these few did not care as long as it entertained.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Not the least interesting of all the minor phenomena produced by the current fashion of wrestling is the universal discussion as to the honesty of the matches. And certainly the most interesting phrase of this discussion is the unanimous agreement: \"Who cares if they're fixed or not\u2014the show is good.\"\u2014\u200a\nA sportswriter in 1937 wrote that 98% of the fans believed professional wrestling was \"on the level\".\nIn 1933, wrestling promoter Jack Pfefer divulged the inner workings of the industry with \"New York Daily Mirror\", maintaining no pretense that wrestling was legitimate and sharing planned results just before the matches took place. Other promoters like Jack Curley were furious, and most promoters tried to maintain the facade of \"kayfabe\" as best they could.\nNewspapers tended to eschew coverage of professional wrestling as they learned it was staged. In 1935, \"Toronto Star\" sports editor Lou Marsh was among the first to use the term \"sportive entertainment\" to describe professional wrestling. Eventually promoters resorted to publishing their own magazines in order to attain press coverage and communicate with fans. The first professional wrestling magazine, \"Wrestling As You Like It\", printed its first issue in 1946. These magazines were faithful to \"kayfabe\" and helped sustain the pretense of professional wrestling as a sport.\nBy the late 1950s, professional wrestling had largely completed its shift from sport to theater. In 1989, Vince McMahon\u2014who sought to exempt his promotion, the World Wrestling Federation, from sports licensing fees\u2014testified before the New Jersey State Athletic Control Board that professional wrestling is not a legitimate sport because its matches have predetermined outcomes. New Jersey subsequently deregulated professional wrestling, and the WWF rebranded itself as a \"sports entertainment\" company.\nEvolution in the television age.\nProfessional wrestling's fanbase had traditionally largely consisted of children, the elderly, blue-collar workers, and ethnic minorities. The rise of television in the 1950s brought unprecedented national exposure to a broader audience, as networks were short on content. Professional wrestling enjoyed a period of mainstream popularity that was buoyed by the visual spectacles and showmanship of performers such as Gorgeous George and Buddy Rogers.\nBeginning in the 1960s, however, networks increasingly shifted to more mainstream interests such as baseball, and professional wrestling was dropped from primetime slots, if not altogether; the core audience then shrank back to a profile similar to that of the 1930s. Nevertheless, this period saw some a brief boost in ratings and signs of strength; the American Wrestling Association's (AWA), which had emerged as an independent promotion in 1960, was setting new standards in how professional wrestling was presented on television, while the National Wrestling Alliance (NWA) maintained a strong following in the South.\nHowever, by the 1970s, professional wrestling entered a more pronounced and sustained decline that persisted into the 1980s.\nDevelopment of stylistic conventions.\nIn the early 20th century, the style of wrestling used in professional wrestling matches was catch wrestling. Promoters at the time wanted their matches to look realistic and so preferred to recruit wrestlers with real grappling skills. In his memoir, Lou Thesz recalled that when he started wrestling as a boy in the 1920s, only people trained in legitimate wrestling could see that professional wrestling matches were staged.\nIn the 1920s, a group of wrestlers and promoters known as the Gold Dust Trio introduced moves that have since become staples of the mock combat of professional wrestling, such as body slams, suplexes, punches, finishing moves, and out-of-ring count-outs.\nBy the early 1930s, most wrestlers had adopted personas to generate public interest. These personas could broadly be characterized as either \"faces\" (heroes) or \"heels\" (villains). Native Americans, cowboys, and English aristocrats were staple characters in the 1930s and 1940s. Some wrestlers played different personas depending on the region they were performing in; with the rise of television and thus national exposure, most wrestlers maintained a single persona and narrative.\nWrestlers also often used some sort of gimmick, such as a finishing move, eccentric mannerisms, or out-of-control behavior (in the case of heels). The matches could also have gimmicks, such as wrestlers fighting in mud or piles of tomatoes. The most successful and enduring gimmick to emerge from the 1930s were tag-team matches. Promoters noticed that matches slowed down as the wrestlers in the ring tired, so they gave them partners to relieve them. It also gave heels another way to misbehave by double-teaming.\nTowards the end of the 1930s, faced with declining revenues, promoters chose to focus on grooming charismatic wrestlers with no regard for their skill as they believed it was charisma that drew the crowds, and wrestlers who were both skilled at grappling and charismatic were rarer. Since most of the public by this time knew and accepted that professional wrestling was staged, realism was no longer paramount and a background in authentic wrestling no longer mattered. After this time, matches became more theatrical and any semblance professional wrestling had to catch wrestling faded. The personas of the wrestlers likewise grew more outlandish.\nGorgeous George, who performed throughout the 1940s and 1950s, was the first wrestler whose entrance into the arena was accompanied by a theme song played over the arena's loudspeakers, his being \"Pomp and Circumstance\". He also wore a costume\u2014a robe and hairnet, which he removed after getting in the ring\u2014and had a pre-match ritual where his \"butler\" would spray the ring with perfume. In the 1980s, Vince McMahon made entrance songs, costumes, and rituals standard for his star wrestlers; for instance, McMahon's top star, Hulk Hogan, would entertain the audience by tearing his shirt off before each match.\nEvolution of regional cartels.\nThe first major promoter cartel emerged on the East Coast, although up to that point, wrestling's heartland had been in the Midwest. Notable members of this cartel included Jack Curley, Lou Daro, Paul Bowser and Tom and Tony Packs. The promoters colluded to solve a number of problems that hurt their profits. Firstly, they could force their wrestlers to perform for less money. As the cartel grew, there were fewer independent promoters where independent wrestlers could find work, and many were forced to sign a contract with the cartel to receive steady work. The contracts forbade them from performing at independent venues. A wrestler who refused to play by the cartel's rules was barred from performing at its venues. A second goal of the wrestling cartels was to establish an authority to decide who was the \"world champion\". Before the cartels, there were multiple wrestlers in the US simultaneously calling themselves the \"world champion\", and this sapped public enthusiasm for professional wrestling. Likewise, the cartel could agree on a common set of match rules that the fans could keep track of. The issue over who got to be the champion and who controlled said champion was a major point of contention among the members of wrestling cartels as the champion drew big crowds wherever he performed, and this would occasionally lead to schisms.\nBy 1925, this cartel had divided the country up into territories which were the exclusive domains of specific promoters. This system of territories endured until Vince McMahon drove the fragmented cartels out of the market in the 1980s. This cartel fractured in 1929 after one of its members, Paul Bowser, bribed Ed \"Strangler\" Lewis to lose his championship in a match against Gus Sonnenberg in January 1929. Bowser then broke away to form his own cartel, the Boston-based American Wrestling Association, in September 1930, declaring Sonnenberg as AWA champion. Curley reacted to this move by convincing the National Boxing Association to form the National Wrestling Association, which in turn crowned a champion that Curley put forth: Dick Shikat.\nIn 1948, several promoters from across the country came together to form the National Wrestling Alliance (NWA); Bowser's AWA would join the following year. The NWA recognized one \"world champion\", voted on by its members, but allowed member promoters to crown their own local champions in their territories. If a member poached wrestlers from another member, or held matches in another member's territory, they risked being ejected from the NWA, at which point his territory became fair game for everyone. The NWA would blacklist wrestlers who worked for independent promoters or who publicly criticized an NWA promoter or who did not throw a match on command. If an independent promoter tried to establish himself in a certain area, the NWA would send their star performers to perform for the local NWA promoter to draw the customers away from the independent.\nBy 1956, the NWA controlled 38 promotions in the United States and several more in Canada, Mexico, Australia and New Zealand. The NWA's monopolistic practices became so stifling that independent promotions appealed to the government for help. In October 1956 the U.S. Attorney General's office filed an antitrust lawsuit against the NWA in an Iowa federal district court. The NWA settled with the government: It pledged to stop allocating exclusive territories to its promoters, to stop blacklisting wrestlers who worked for outsider promoters, and to admit any promoter into the Alliance.\nThe NWA would flout many of these promises, but its power was nonetheless weakened by the lawsuit. In 1957, just one year after settlement, the AWA withdrew from the Alliance and renamed itself the Atlantic Athletic Corporation (AAC); the AAC shut down in 1960.\nIn 1958, Omaha promoter and NWA member Joe Dusek recognized Verne Gagne as the world champion without the approval of the NWA. Gagne asked for a match against the recognized NWA champion Pat O'Connor. The NWA refused to honor the request, so Gagne and Minneapolis promoter Wally Karbo established the American Wrestling Association in 1960. This AWA should not be confused with Paul Bowser's AWA, which ceased operations just two months prior. Gagne's AWA operated out of Minnesota. Unlike the NWA, which only allowed faces to be champions, Gagne occasionally allowed heels to win the AWA championship so that they could serve as foils for him.\nConsolidation and renewed growth.\nIn August 1983, the World Wrestling Federation (WWF), a promotion in the northeast, withdrew from the NWA; Vince McMahon then took over as its boss. No longer bound by the territorial pact of the NWA, McMahon began expanding his promotion into the territories of his former NWA peers, now his rivals. By the end of the 1980s, the WWF would become the sole national wrestling promotion in the US. This was in part made possible by the rapid spread of cable television in the 1980s. The national broadcast networks generally regarded professional wrestling as too niche an interest, and had not broadcast any national wrestling shows since the 1950s. The widespread success of the WWF led to the 1980s professional wrestling boom, turning the sport consciously mainstream in society.\nBefore cable TV, a typical American household only received four national channels by antenna, and ten to twelve local channels via UHF broadcasting. Cable television could carry a much larger selection of channels and therefore had room for niche interests. The WWF started with a show called \"All-American Wrestling\" on the USA Network in September 1983. McMahon's TV shows made his wrestlers national celebrities, so when he held matches in a new city, attendance was high because there was a waiting fanbase cultivated in advance by the cable TV shows. The NWA attempted to centralize and create their own national cable television shows to counter McMahon's rogue promotion, but it failed in part because the members of the NWA, protective of their territories, did not wish to be beholden to a central authority. They also did not wish to leave the NWA to compete directly with McMahon, for that would mean their territories would compete against other NWA members. McMahon also had a creative flair for TV that his rivals lacked. For instance, the AWA's TV productions during the 1980s were amateurish, low-budget, and out-of-touch with contemporary culture, which lead to the promotion's closing in 1991.\nIn the spring of 1984, the WWF purchased Georgia Championship Wrestling (GCW), which had been ailing for some time due to financial mismanagement and internal squabbles. In the deal, the WWF acquired the GCW's timeslot on TBS. McMahon agreed to keep showing Georgia wrestling matches in that timeslot, but he was unable to get his staff to Atlanta every Saturday to fulfill this obligation, so McMahon sold GCW and its TBS timeslot to Jim Crockett Promotions (JCP). JCP started informally calling itself World Championship Wrestling (WCW). In 1988, Ted Turner bought JCP and formally renamed it World Championship Wrestling.\nProfessional wrestling experienced a second boom in the late 1990s. During this period, WCW became a credible rival to the WWF (see also Monday Night War), while the WWF's output, coinciding with the rise of \"trash TV\", became increasingly crude. By the turn of the century, WCW suffered from a series of creative missteps that led to its failure and purchase by the WWF. One of WCW's mistakes was the diminished glamor of its World Heavyweight Championship. Between January 2000 and March 2001, the WCW title changed hands eighteen times, which sapped fan enthusiasm, particularly for the climactic pay-per-view matches.\nIndustry conventions.\nProfessional wrestling performances are governed primarily by a script and overarching storyline devised by producers, who often are professional wrestlers themselves. Real-life events, such as a performer's contract status and legitimate injuries, may be incorporated into storylines, and some wrestlers integrate elements of their genuine personalities or background into their performances or personas; for example, Kurt Angle, who performed his fictional persona eponymously, often utilized his genuine Olympic gold medal in wrestling as a defining aspect of his character. The actions of the character in shows are considered fictional and wholly separate from the life of the performer, although some performers will remain in character outside the ring, such as in promotional videos, interviews, and even social media; consequently, the line between real-life and scripted events and personas are often blurred. For example, Maxwell Jacob Friedman is well known for staying in character at all times while in public, going so far as to insult his fans, often to their delight as they are aware of his persona.\nKayfabe.\n\"Kayfabe\" is the term given to the fictional element of professional wrestling. Wrestlers would at all times flatly deny allegations that they fixed their matches, and they often remained in-character in public even when not performing. When in public, wrestlers would sometimes say \"kayfabe\" to each other as a coded signal that there were fans present for whom they needed to be in character. Professional wrestlers in the past strongly believed that if they admitted the truth, their audiences would desert them; accordingly, promotions have often disciplined or punished performers for breaking kayfabe.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Today's performers don't \"protect\" the industry like we did, but that's primarily because they've already exposed it by relying on silly or downright ludicrous characters and gimmicks to gain popularity with the fans. It was different in my day, when our product was presented as an authentic, competitive sport. We protected it because we believed it would collapse if we ever so much as implied publicly that it was something other than what it appeared to be. I'm not sure now the fear was ever justified given the fact that the industry is still in existence today, but the point is no one questioned the need then. \"Protecting the business\" in the face of criticism and skepticism was the first and most important rule a pro wrestler learned. No matter how aggressive or informed the questioner, you never admitted the industry was anything but a competitive sport.\u2014\u200a\nThe first wrestling promoter to publicly admit to routinely fixing matches was Jack Pfefer. In 1933, he started talking about the industry's inner workings to the \"New York Daily Mirror\", resulting in a huge expos\u00e9. The expos\u00e9 neither surprised nor alienated most wrestling fans, although some promoters like Jack Curley were furious and tried to restore the facade of kayfabe as best as they could. In 1989, Vince McMahon testified before the New Jersey government that professional wrestling was not a true sport and therefore should be exempted from sports-related taxes. Many wrestlers and fans resented McMahon for this, but Lou Thesz accepted it as the smart move as it gave the industry more freedom to do as it pleased, and because by that point professional wrestling no longer attempted to appear real.\nThe demise of WCW in 2001 provided some evidence that \"kayfabe\" still mattered to a degree. Vince Russo, the boss of WCW in 2000, completely disregarded \"kayfabe\" by routinely discussing business matters and office politics in public, which alienated fans.\nSports entertainment.\nThe wrestling industry convention of \"kayfabe\" has increasingly been challenged by the modern concept of sports entertainment, which openly acknowledges professional wrestling's predetermined nature and celebrates its roots in both competitive sport and dramatic theater. The term \"sports entertainment\" was coined by World Wrestling Federation chairman Vince McMahon during the 1980s as a marketing term to describe the professional wrestling industry, primarily to potential advertisers; however, precursors date back to at least February 1935, when \"Toronto Star\" sports editor Lou Marsh described professional wrestling as \"sportive entertainment\". In 1989, the WWF used the phrase in a case before the New Jersey Senate to classify professional wrestling as \"sports entertainment\" and thus not subject to regulation like a directly competitive sport.\nIn subsequent years, WWE insisted that its talent use \"sports entertainment\" rather than \"pro wrestling\" to describe its business, to the point that the term was sometimes used in other promotions to generate \"heat\" (fan reaction and engagement). The line between sports entertainment and competitive sports was further blurred in 2023, when WWE merged with the parent company of Ultimate Fighting Championship (UFC), a genuinely competitive mixed martial arts promotion, in what was officially announced as an effort to \"bring together two leading pureplay sports and entertainment companies\" and provide \"significant operating synergies\" between them. The following year, WWE moved away from its insistence on being a sports entertainment company after Vince McMahon's departure from the company, but still uses \"sports entertainment\" in some contexts.\nWhether professional wrestling is a genuine sport often reflects a broader debate as to the nature and qualities of a sport categorically. Some commentators and analysts identify baseline commonalities between professional wrestling and other sports, such as performance entailing \"physical activity governed by a set of rules of customs\" and there still being competition among pro wrestlers with respect to their performances. &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Just because there's a script involved it doesn't take away from the competitive environment of professional wrestling. Ask any former wrestler, read an autobiography on a wrestler or use common sense. There is tremendous competition within the WWE. Not performing to the high standards in the ring? \"You're Fired\". Not getting over with the fans? \"You're Fired.\" Being a nuisance and refusing to be a team player? \"You're fired.\" Don't want to continually train, live the grueling road schedule and establish connections...see where I'm going with all this? While NFL, NBA, NHL, MLB and overseas soccer players (football, I know, I apologize) are getting paid ridiculous contracts (with a lump sum up front, and a lot of the contract guaranteed), professional wrestlers do much more work for a lot less. We can safely take the competition argument out of the discussion. So ultimately, if you can look past the script, then professional wrestling is a sport.\n\u2014 William Gullo, \"Bleacher Report\" (Sep. 6, 2011)Others retort that while professional wrestling is comparable in its physical and athletic requirements\u2014including \"shared values of resilience and excellence\" and similar risks of bodily injury\u2014its scripted nature preempts one of the purported defining characteristics of a sport: genuine competition over the outcome.\nThe ambiguity of professional wrestling as a form of sports entertainment is further heightened by news media, which often cover professional wrestling matches and events as if they were genuine sports; for example, in 2024, \"Forbes\" ranked professional wrestling promotions WWE and All Elite Wrestling (AEW) among the world's \"most valuable combat sports promotions\" alongside bona fide competitive sport organizations UFC, ONE Championship, and Matchroom Boxing.\nPerformance aspects.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I watch championship wrestling from Florida with wrestling commentator Gordon Solie. Is this all \"fake\"? If so, they deserve an Oscar.\u2014\u200a\nProfessional wrestling shows can be considered a form of theater in the round, with the ring, ringside area, and entryway comprising a stage. There is less of a fourth wall than in most theatric performances; like pantomime, audience involvement is expected and encouraged. Attendees are recognized and acknowledged by performers as spectators to the sporting event being portrayed and are encouraged to interact as such; their reactions can dictate how the performance unfolds, leading to a high level of audience participation. Often, individual matches will be part of a longer storyline conflict between \"babyfaces\" (often shortened to just \"faces\") and \"heels\". \"Faces\" (the \"good guys\") are those whose actions are intended to encourage the audience to cheer, while \"heels\" (the \"bad guys\") act to draw the spectators' ire.\nIn pro wrestling matches, performers often execute a series of pre-planned moves and attacks, ranging from grappling and throws found in some traditional forms of wrestling, to more spectacular stunts, sometimes involving props and special effects. Although match outcomes and narratives are predetermined, wrestlers are expected to improvise and weave elements of their character. Attacks are designed to appear dramatic while reducing the risk of serious injury as much as possible; the overall aim is to minimize the actual injurious impact of their moves while maximizing their entertainment value. Shows produced by the largest professional wrestling promotions like WWE are traditionally performed in indoor venues, while flagship events like WrestleMania are sometimes taking place at outdoor venues; these shows are generally video recorded for live or delayed broadcasting. Additionally filmed footage known as \"segments\" or \"promos\" are usually used to accompany the drama in these shows.\nPrior experience in legitimate wrestling is not a requirement for aspiring professional wrestlers but is seen as an advantageous background. Despite its scripted format, several notable performers have had prior experience in legitimate wrestling before transitioning to its theatrical form. A popular performer, Kurt Angle, is the first Olympic gold medalist in professional wrestling history, having won his gold medal at the 1996 Summer Olympic Games in freestyle wrestling. Another prominent performer is Brock Lesnar, a former NCAA Wrestler who won the NCAA Division I National Championship in 2000.\nRules and other dramatic elements.\nProfessional wrestlers nominally compete under rules promulgated by wrestling promotions. However, the rules are not legitimate standards for sporting activity, instead serving as a basis to advance plotlines, similar to the artificial constraints imposed in other fictional universes. Sociologist Thomas S. Henricks has argued the rules serve as a basis for a structuralist moral order, serving to advance plot lines involving charismatic heroes applying an instrumentally rationalist approach to social conflicts.\nProfessional wrestlers do not follow an industry-standard set of rules, unlike most sporting events, which generally have a governing body to regulate competitions. While each promoter can set their own standards, promoters have long understood that fans enjoy professional wrestling more when all matches appear to follow a consistent set of rules. The rules described in this section represent common standards but may not precisely align with the ruleset of any specific promotion.\nStructure of performances.\nMatches are staged between two or more sides (\"corners\"). Each corner may consist of one wrestler, or a team of two or more. Most team matches are nominally governed by tag team rules. Other matches present under the premise of a free-for-alls, with multiple combatants but no teams. In all variants, there can be only one winning team or wrestler.\nMatches generally take place within a wrestling ring, an elevated square canvas mat with posts on each corner. A cloth apron hangs over the edges of the ring. Three horizontal ropes or cables surround the ring, suspended with turnbuckles which are connected to the posts. For safety, the ropes are padded at the turnbuckles and cushioned mats surround the floor outside the ring. Guardrails or a similar barrier enclose this area from the audience. Wrestlers are generally expected to stay within the confines of the ring, though matches sometimes end up moving outside the ring, and even into the audience.\nThe standard method of scoring is the \"fall\", which, is premised as being accomplished by:\nThese are each explained in greater detail below. Pinfalls and submissions must occur within the ring unless stipulated otherwise.\nMost wrestling matches last for a set number of falls, with the first side to achieve the majority number of pinfalls, submissions, or countouts being the kayfabe winner. Historically, the matches went to 3 falls (\"best 2 out of 3\") or 5 falls (\"best 3 out of 5\"). For modern wrestling, the genre convention is 1 fall. These matches have a time limit; if not enough falls are scored by the end of the time limit, the match is presented as draw. Modern matches are generally given a 10- to 30-minute time limit for standard matches; title matches can go for up to one hour. British wrestling matches held under Admiral-Lord Mountevans rules (and similar systems across Europe) consist of a series of rounds \u2013 typically six rounds each lasting three minutes or until a fall or submission is scored, with a thirty-second break between each round and can either be two-out-of-three falls, one fall to a finish (mostly for low-priority warmup matches) or the wrestler with the most falls wins at the end of the final round.\nAn alternative subgenre involves is a match set for a prescribed length of time, with a running tally of falls. The entrant with the most falls at the end of the time limit is declared the winner. This is usually for 20, 30 or 60 minutes, and is commonly called an Iron Man match. This type of match can be modified so that fewer types of falls are allowed.\nIn performances staged with multiple competitors, an elimination system may be used. Any wrestler who has a fall scored against them is forced out of the match, and the match continues until only one remains. It is much more common when more than two wrestlers are involved to simply go one fall, with the one scoring the fall, regardless of who they scored it against, being the winner. In championship matches, this means that, unlike one-on-one matches (where the champion can simply disqualify himself or get himself counted out to retain the title via the Champion's Advantage), the champion does \"not\" have to be pinned or involved in the decision to lose the championship. Heel champions often find advantages, not in Champion's Advantage, but in the use of weapons and outside interference, as these poly-sided matches tend to involve no holds barred rules.\nSome wrestling performances are staged with unique winning conditions, often to allow a thing theoristic plot construction. An example is the ladder match.\nIn the basic ladder match, the premise is wrestlers or teams of wrestlers must climb a ladder to obtain a prize that is hoist above the ring. The key to winning this match is that the wrestler or team of wrestlers must try to incapacitate each other long enough for one wrestler to climb the ladder and secure that prize for their team. As a result, the ladder can be used as a weapon. The prizes include, but are not limited to, any given championship belt (the traditional prize), a document granting the winner the right to a future title shot, or any document that matters to the wrestlers involved in the match (such as one granting the winner a cash prize). Something that is also common in pro wrestling is the cage match which comes with the added rule that victory can be achieved by escaping the cage. Another common specialty match is known as the battle royal. In a battle royal, all the wrestlers enter the ring to the point that there are 20\u201330 wrestlers in the ring at one time. When the match begins, the simple objective is to throw the opponent over the top rope and out of the ring with both feet on the floor to eliminate that opponent. The last wrestler standing is declared the winner. A variant on this type of match is the WWE's Royal Rumble where two wrestlers enter the ring to start the match and other wrestlers follow in 90 second intervals (previously 2 minutes) until 30\u201340 wrestlers have entered the ring. All other rules stay the same.\nAlmost every professional wrestling match features referee, who is the final arbitrator of the fictional rules, which may vary from promotion to promotion. In multi-man lucha libre matches, two referees are used, one inside the ring and one outside.\nDue to the legitimate role that referees play in wrestling of serving as liaison between the bookers backstage and the wrestlers in the ring (the role of being a final arbitrator is merely kayfabe), the referee is present, even in matches that do not at first glance appear to require a referee (such as a ladder match, as it is no holds barred, and the criteria for victory could theoretically be assessed from afar). Although their actions are also frequently scripted for dramatic effect, referees are subject to certain general rules and requirements to maintain the theatrical appearance of unbiased authority. The most basic rule is that an action must be seen by a referee to be declared for a fall or disqualification. This allows for heel characters to gain a scripted advantage by distracting or disabling the referee to perform some ostensibly illegal maneuver on their opponent. Most referees are unnamed and essentially anonymous, though some wrestling promotions, most notably in the present All Elite Wrestling, have made officials known by their names (and there are some cases where fans have called their names during matches).\nSpecial guest referees may be used from time to time; by virtue of their celebrity status, they are often scripted to dispense with the appearance of neutrality and use their influence to unfairly influence the outcome of the match for added dramatic impact. Face special referees will often fight back against hostile heel wrestlers, particularly if the special referee is either a wrestler himself or a famous martial artist (such as Tito Ortiz at the main event at Hard Justice 2005).\nFor dramatic effect, heel referees may assist a heel wrestler. Several common plot devices involve the heel referee assisting the heel wrestler.\nTag rules.\nIn some team matches, there is a fictional premise that only one entrant from each team may be designated as the \"legal\" or \"active\" wrestler at any given moment. Two wrestlers must make physical contact in the corner (typically palm-to-palm) to transfer this legal status. This is known as a \"tag\", with the participants \"tagging out\" and \"tagging in\". Typically, the wrestler who is tagging out has a five count to leave the ring, whereas the one tagging in can enter the ring at any time, resulting in heels legally double-teaming a face.\nThe non-legal wrestlers must remain outside the ring or other legal area at all times (and avoid purposeful contact with the opposing wrestlers) or face reprimand from the referee. In most promotions, the wrestler to be tagged in must be touching the turnbuckle on his corner, or a cloth strap attached to the turnbuckle.\nSome multi-wrestler matches allow for a set number of legal wrestlers; this rule is commonplace in four-way tag team matches, where only two wrestlers are legal in the match, meaning two teams will have both members on the outside at any given time. In these matches, tags can be made between any two teams regardless if they are on the same team or not. As a result of this stipulation, tags between different teams are not usually mutual effort; a non-legal wrestler will usually tag themselves in against the legal wrestler's will. A legal wrestler will only voluntarily tag themselves out to another team if their own partner is incapacitated, or are being held in a submission hold and are closer to another tag team than their own.\nSometimes, poly-sided matches that pit every man for himself will incorporate tagging rules. Outside of kayfabe, this is done to give wrestlers a break from the action (as these matches tend to go on for long periods of time), and to make the action in the ring easier to choreograph. One of the most mainstream examples of this is the Four-Corner match, the most common type of match in the WWE before it was replaced with its equivalent Fatal Four-Way; four wrestlers, each for himself, fight in a match, but only two wrestlers can be in the match at any given time. The other two are positioned in the corner, and tags can be made between any two wrestlers.\nIn a Texas Tornado Tag Team match, all the competitors are legal in the match, and tagging in and out is not necessary. All matches fought under hardcore rules (such as no disqualification, no holds barred, ladder match, etc.) are all contested under \"de facto\" Texas Tornado rules, since the lack of ability of a referee to issue a disqualification renders any tagging requirements moot.\nRegardless of rules of tagging, a wrestler cannot pin his or her own tag team partner, even if it is technically possible from the rules of the match (e.g. Texas Tornado rules, or a three-way tag team match). This is called the \"Outlaw Rule\" because the first team to attempt to use that (in an attempt to unfairly retain their tag team titles) was the New Age Outlaws.\nVictory.\nAlthough scripted and choreographed, wrestling matches are presented as being legitimate athletic competitions decided on one of several possible outcomes.\nPinfall.\nA match's fictional premise may allow a score by pinfall, in which a wrestling performer must pin both their opponent's shoulders against the mat while the referee slaps the mat three times (referred to as a \"three count\"). This is the most common form presented a defeat. The pinned wrestler must also be on their back (if the opponent is lying on their stomach, it usually does not count). A count may be started at any time that a wrestler's shoulders are down (both shoulders touching the mat), back-first and any part of the opponent's body is lying over the wrestler. This often results in pins that can easily be kicked out of, if the defensive wrestler is even slightly conscious. For example, an attacking wrestler who is half-conscious may simply drape an arm over an opponent, or a cocky wrestler may place a foot gently on the opponent's body, prompting a three-count from the referee.\nIn some promotions, there is a premise that certain pinning methods are disallowed, including using the ropes for leverage and hooking the opponent's clothing. As a plot device, disallowed pinning methods can be depicted as a cheating method for heels. Pins such as these are rarely seen by the referee and are often used by heels and on occasion by cheating faces to win matches. Even if it is noticed, storylines rarely result in a disqualification and instead it simply results in nullification of the pin attempt, so the wrestler rarely has anything to lose.\nOccasionally, there are instances where a pinfall is presented as being made where both wrestlers' shoulders were on the mat for the three-count. This situation will most likely lead to a draw, and in some cases a continuation of the match or a future match to determine the winner.\nSubmission.\nTo score by submission, the performer must make their opponent give up, usually by putting them in a submission hold (e.g. figure four leg-lock, arm-lock, sleeper-hold).\nA performer may appear to voluntarily submit by verbally informing the referee (usually used in moves such as the Mexican Surfboard, where all four limbs are incapacitated, making tapping impossible). Since Ken Shamrock popularized it in 1997, a wrestler can indicate a voluntary submission by \"tapping out\", that is, tapping a free hand against the mat or against an opponent. Submission was initially a large factor in professional wrestling, but following the decline of the submission-oriented catch-as-catch-can style from mainstream professional wrestling, the submission largely faded. Despite this, some wrestlers, such as Chris Jericho, Ric Flair, Bret Hart, Kurt Angle, Ken Shamrock, Dean Malenko, Chris Benoit, Bryan Danielson, and Tazz, became famous for their fictional depictions of winning matches via submission. A wrestler with a signature submission technique is portrayed as better at applying the hold, making it more painful or more difficult to get out of than others, or can be falsely credited as inventing the hold (such as when Tazz popularized the kata ha jime judo choke in pro wrestling as the \"Tazzmission\").\nUnder wrestling nominal rules, all contact between the wrestlers must cease if any part of the body is touching or underneath the ropes. As such, many performances will attempt to break submission holds by deliberately grabbing the bottom ropes. This is called a \"rope break\", and it is one of the most common ways to break a submission hold. Most holds leave an arm or leg free, so that the person can tap out if they want. Instead, they use these free limbs to either grab one of the ring ropes or drape their foot across or underneath one. Once this has been accomplished and witnessed by the referee, the referee will demand that the offending wrestler break the hold and start counting to five if the wrestler does not. If the referee reaches the count of five and the wrestler still does not break the hold, they are disqualified.\nIf a manager decides that their wrestler presented as their client should tap out, but cannot convince the wrestler to do so, they may \"throw in the towel\" (by literally taking a gym towel and hurling it into the ring where the referee can see it). This is the same as a submission, as in kayfabe the manager is considered the wrestler's agent and therefore authorized to make formal decisions (such as forfeiting a match) on the client's behalf.\nKnockout.\nSome wrestling performances are presented as resulting in a knockout, mirroring legitimate martial arts and concluding with a technical knockout or technical submission. To determine if a wrestler has passed out in WWE, the referee usually picks up and drops his hand. If it drops to the mat or floor one or three consecutive times without the wrestler having the strength to hold it up, the wrestler is considered to have passed out.\nA performer can also be presented as winning by technical knockout even if he does not resort to submission holds, but still beats the opponent to the point of unconsciousness or to the impossibility to defend himself. To check for a technical knockout in this manner a referee would wave his hand in front of the wrestler's face and, if this produces no reaction of any kind, the referee would award the victory to the other wrestler.\nA wrestler can also request a ten-count from the referee when, under the event's fictional premise, they think an opponent is sufficiently incapacitated to not be able to stand before the count of ten. Except in traditional European promotions where following down on a fallen opponent was prohibited, these knockouts are rarely used or mentioned as logically it makes more sense for a wrestler to actively pin an opponent for three seconds rather than leaving an opponent the chance to stand up before ten. In such European promotions, countouts as described below are treated as a variant of a knockout.\nCountout.\nA performance can be depicted as ending in a countout (alternatively spelled as \"count-out\" or \"count out\"), where wrestler is out of the ring long enough for the referee to count to ten (twenty in some promotions) and thus, under the event's fictional premise, is disqualified. The count is broken and restarted when a wrestler in the ring exits the ring. Playing into this, some wrestlers are depicted as \"milking\" the count by sliding in the ring and immediately sliding back out. As the wrestler was technically inside the ring for a split second before exiting again, it is sufficient to restart the count. This is often referred to by commentators as \"breaking the count\". Heels often use this tactic in order to buy themselves more time to catch their breath, or to attempt to frustrate their babyface opponents.\nIf all the active wrestlers in a match are down inside the ring at the same time, the referee begins a count (usually ten seconds, twenty in Japan). If nobody rises to their feet by the end of the count, the match is ruled a draw. Any participant who stands up in time ends the count for everyone else, while in a Last Man Standing match this form of a countout is the only way that the match can end, so the referee counts when one or more wrestlers are down and one wrestler standing up before the 10-count does not stop the count for another wrestler who is still down.\nIn most major modern promotions, championships are not permitted to change hands via a countout, unless the on-screen authority figure declares otherwise; this rule varies in some promotions, however. In some storylines, heels are presented as taking advantage of this and will intentionally get counted out when facing difficult opponents while defending championships.\nDisqualification.\nDisqualification (sometimes abbreviated as \"DQ\") occurs when a wrestler violates the rules established as part of the performance's fictional premise, thus losing automatically. Although a countout can technically be considered a disqualification (as it is, for all intents and purposes, an automatic loss suffered as a result of violating a match rule), the two concepts are often distinct in wrestling. A no disqualification match can still end by countout (although this is rare). Typically, a match must be declared a \"no holds barred\" match, a \"street fight\" or some other term, in order for both disqualifications and countouts to be waived.\nDisqualification from a match is called when the fictional storyline involves:\nIn the fictional universe of some promotions, not all rule violations result in a disqualification as the referee may be depicted as using his own judgement and is not obligated to stop the match. Usually, the only offenses that the referee will see and immediately disqualify a wrestler for (as opposed to having multiple offenses) are low blows, weapon usage, interference, or assaulting the referee. In WWE, the plot convention is that a referee must see the violation with his own eyes to rule that the match end in a disqualification (simply watching the video tape is usually not enough) and the referee's ruling is almost always final, although \"Dusty finishes\" (named after, and made famous by, Dusty Rhodes) will often result in the referee's decision being overturned. It is not uncommon for the referees themselves to get knocked out during a match, which is commonly referred to by the term \"ref bump\". While the referee remains \"unconscious\", wrestlers are free to violate rules until he is revived or replaced. In some cases, a referee might disqualify a person under the presumption that it was that wrestler who knocked him out; most referee knockouts are arranged to allow a wrestler, usually a heel, to gain an advantage. For example, a wrestler may get whipped into a referee at a slower speed, knocking the ref down for short amount of time; during that interim period, one wrestler may pin his opponent for a three-count and would have won the match but for the referee being down (sometimes, another referee will sprint to the ring from backstage to attempt to make the count, but by then, the other wrestler has had enough time to kick out on his own accord). In most promotions, a championship title cannot normally change hands via disqualification; this rule is explicitly enforced in a title match under special circumstances.\nIn traditional European promotions, severe or persistent infractions of the rules result in a formal caution, called a \"public warning\" in the UK, \"avertissement\" (warning) in France and a soccer-style yellow card in Germany. Three of these will result in disqualification (a red card in Germany). One major North American promotion \u2013 Stampede Wrestling of Calgary \u2013 also used the German card system from the late 1970s onward.\nIf all participants in a match continue to breach the referee's instructions, the staged performance may presented as ending in a double disqualification, where both wrestlers and/or teams (in a tag team match) have been disqualified. The match is essentially nullified and called a draw or in some cases a restart or the same match being held at a pay-per-view or next night's show. Sometimes, in a match to determine the challenger for a heel champion's title, the champion is forced to face both opponents simultaneously for the title. Usually, the double disqualification is caused by the heel wrestler's associates in a match between two face wrestlers to determine his opponent.\nForfeit.\nAlthough extremely rare, some fictional storylines involve a match ending in a forfeit if the opponent is depicted as either not showing up for the match, or showing up but refusing to compete. Although the plot premise is that championship usually cannot change hands except by pinfall or submission, a forfeit victory is enough to crown a new champion. A famous example of this happened on the December 8, 1997, episode of \"Raw is War\", when Stone Cold Steve Austin handed the WWE Intercontinental Championship to The Rock after refusing to defend the title.\nWhen a pay-per-view match is booked and one wrestler is unable to make it for one reason or another, the genre convention is to insert a last-minute replacement rather than award a wrestler a victory by forfeit. Forfeit victories are almost always reserved for when the story the promotion is telling specifically requires such an ending.\nDespite being, statistically, an extremely rare occurrence, Charles Wright is one wrestler whose gimmick was centered around forfeit victories. During the late 1990s, Wright called himself \"The Godfather\" and portrayed the gimmick of a pimp. He often brought multiple women, whom he referred to as \"hos\", to the ring with him, and offered them to his opponents in exchange for their forfeit.\nDraw.\nA professional wrestling match can be depicted as ending in a draw. A draw occurs if both opponents are simultaneously disqualified (e.g. Brock Lesnar vs. The Undertaker at Unforgiven 2002), neither opponent is able to answer a ten-count (e.g. Shawn Michaels vs. Triple H at Royal Rumble 2004), or both opponents simultaneously win the match. The latter can occur if, for example, both wrestlers pin each other (e.g. MJF vs. Adam Cole at All In 2023, before the match was restarted), or one competitor scores a submission victory while the other scores a pinfall victory (e.g. Kurt Angle being pinned while successfully applying the triangle choke to The Undertaker on a 2002 episode of \"SmackDown\"). Traditionally, a championship may not change hands in the event of a draw.\nA variant of the draw is the time-limit draw, where the match does not have a winner by a specified time period; a one-hour draw, which was once common, is known in wrestling circles as a \"Broadway\". In European promotions where wrestling is traditionally timed in rounds, a best of three falls match is stopped and declared a one-fall-each draw if an equalizing pinfall or submission is scored in the final round.\nNo contest.\nA wrestling match may be declared a no contest if, under the fictional storyline, the winning conditions are unable to occur. The storyline may attribute such an outcome to factors such as excessive interference, the loss of referee's control over the match, an injury unrelated to the fictitious storyline, or other fictional circumstances presenting the scheduled match to even begin. A no contest is a state separate and distinct from a draw \u2014 a draw indicates winning conditions were met. Although the terms are sometimes used interchangeably in practice, this usage is technically incorrect.\nOther dramatic elements.\nWhile each wrestling match is ostensibly a competition of athletics and strategy, the goal from a business standpoint is to excite and entertain the audience. Although the competition is staged, dramatic emphasis draws out the most intense reaction. Heightened interest results in higher attendance, increased ticket sales, higher ratings on television broadcasts (greater ad revenue), higher pay-per-view buyrates, and sales of branded merchandise and recorded video footage. All of these contribute to the profit of the promotion company.\nCharacter gimmicks.\nIn Latin America and English-speaking countries, most wrestlers (and other on-stage performers) portray character roles, sometimes with personalities wildly different from their own. These personalities are a gimmick intended to heighten interest in a wrestler without regard to athletic ability. Some can be unrealistic and cartoon-like (such as Doink the Clown), while others carry more verisimilitude (such as Chris Jericho, The Rock, John Cena, Steve Austin, and CM Punk). In lucha libre, many characters wear masks, adopting a secret identity akin to a superhero or a supervillain, a near-sacred tradition.\nAn individual wrestler may use their real name, or a minor variation of it, for much of their career, such as Bret Hart, John Cena and Randy Orton. Others can keep one ring name for their entire career (Shawn Michaels, CM Punk and Ricky Steamboat), or may change from time to time to better suit the demands of the audience or company. Sometimes a character is owned and trademarked by the company, forcing the wrestler to find a new one when he leaves (although a simple typeset change, such as changing Rhyno to Rhino, can get around this), and sometimes a character is owned by the wrestler. Sometimes, a wrestler may change their legal name to obtain ownership of their ring name (Andrew Martin and Warrior). Many wrestlers (such as The Rock and The Undertaker) are strongly identified with their character, even responding to the name in public or between friends. Proper decorum is for wrestlers to refer to each other by their stage names/characters rather than their birth/legal names, unless otherwise introduced. A character can become so popular that it appears in other media (Hulk Hogan and El Santo) or even gives the performer enough visibility to enter politics (Antonio Inoki and Jesse Ventura).\nTypically, matches are staged between a protagonist (historically an audience favorite, known as a babyface, or \"the good guy\") and an antagonist (historically a villain with arrogance, a tendency to break rules, or other unlikable qualities, called a heel, or \"the bad guy\"). In recent years, antiheroes have also become prominent in professional wrestling. There is also a less common role of a \"tweener\", who is neither fully face nor fully heel yet able to play either role effectively (case in point, Samoa Joe during his first run in Impact Wrestling from June 2005 to November 2006).\nAt times, a character may \"turn\", altering their face/heel alignment. This may be an abrupt, surprising event, or it may slowly build over time. It is almost always accomplished with a markable change in behavior. Some turns become defining points in a career, as when Hulk Hogan turned heel after being a top face for over a decade. Others may have no noticeable effect on the character's status. If a character repeatedly switches between face and heel, this lessens the effect of such turns, and may result in apathy from the audience. Big Show is a good example of having more heel and face turns than anyone in WWE history. Sometimes a character's heel turn will become so popular that eventually the audience response will alter the character's heel-face cycle to the point where the heel persona will, in practice, become a face persona, and what was previously the face persona, will turn into the heel persona, such as when Dwayne Johnson first began using \"The Rock\" persona as a heel character, as opposed to his original \"Rocky Maivia\" babyface persona. Another legendary example is Stone Cold Steve Austin, who was originally booked as a heel, with such mannerisms as drinking on the job, using profanity, breaking company property, and even breaking into people's private homes. The fans' response to Austin was so positive that he effectively became one of the most popular antiheroes in professional wrestling. Austin, along with the stable of D-Generation X, Bret Hart and his Hart Foundation, is generally credited with ushering the Attitude Era of WWF programming.\nStory.\nWhile real exhibition matches are now not uncommon, most matches tell a story analogous to an episode of a serial drama: the face will from time to time win (triumph) or from time to time lose (tragedy), and longer story arcs can result from a couple of matches. Since most promotions have a championship title, opposition for the championship is a frequent impetus for stories. For added stakes, anything from a character's own hair to their job can be wagered in a match.\nSome matches are designed to further the story of only one participant. It could be intended to portray an unstoppable force, a lucky underdog, a sore loser, or any other characterization. Sometimes non-wrestling vignettes are shown to enhance a character's image without the need for matches.\nOther stories result from a natural rivalry. Outside of performance, these are referred to as feuds. A feud can exist between any number of participants and can last from a few days to decades. The feud between Ric Flair and Ricky Steamboat lasted from the late 1970s into the early 1990s and allegedly spanned over two thousand matches (although most of those matches were mere dark matches). The career-spanning history between characters Mike Awesome and Masato Tanaka is another example of a long-running feud, as is the case of Steve Austin vs. Vince McMahon, one of the most lucrative feuds in the World Wrestling Federation during 1998 and 1999.\nIn theory, the longer a feud is built up, the more audience interest (aka heat) lasts. The main event of a wrestling show is generally the most heated. Commonly, a heel will hold the upper hand over a face until a final showdown, heightening dramatic tension as the face's fans desire to see them win.\nThroughout the history of professional wrestling, many other elements of media have been utilized in professional wrestling storytelling: pre- and post-match interviews, \"backstage\" skits, positions of authority and worked behind-the-scenes feuds, division rankings (typically the #1-contendership spot), contracts, lotteries, news stories on websites, and in recent years social media.\nAnything that can be used as an element of drama can exist in professional wrestling stories: romantic relationships (including love triangles and marriage), racism, classism, nepotism, favoritism, corporate corruption, family bonds, personal histories, grudges, theft, cheating, assault, betrayal, bribery, seduction, stalking, confidence tricks, extortion, blackmail, substance abuse, self-doubt, self-sacrifice; even kidnapping, sexual fetishism, necrophilia, misogyny, rape and death have been portrayed in wrestling. Some promotions have included supernatural elements such as magic, curses, the undead and Satanic imagery (most notably the Undertaker and his Ministry of Darkness, a stable that regularly performed evil rituals and human sacrifice in Satanic-like worship of a hidden power figure).\nCommentators have become important in communicating the relevance of the characters' actions to the story at hand, filling in past details and pointing out subtle actions that may otherwise go unnoticed.\nPromos.\nA main part of storytelling in wrestling is a promo, short for promotional interview. Promos are performed, or \"cut\" in wrestling jargon, for a variety of reasons, including to heighten interest in a wrestler, or to hype an upcoming match.\nSince the crowd is often too loud or the venue too large for promos to be heard naturally, wrestlers generally use amplification when speaking in the ring. Unlike most stage acting, large and highly visible handheld microphones are typically used and wrestlers frequently speak directly to the audience.\nChampionships.\nProfessional wrestling mimics the structure of title match combat sports. Participants compete for a championship and must defend it after winning it. These titles are represented physically by a title belt that can be worn by the champion. In the case of team wrestling, there is a title belt for each member of the team.\nAlmost all professional wrestling promotions have at least one title, and some have more. Championships are designated by divisions of weight, height, gender, wrestling style and other qualifications.\nTypically, each promotion only recognizes the \"legitimacy\" of their own titles, although cross-promotion does happen. When one promotion absorbs or purchases another, the titles from the defunct promotion may continue to be defended in the new promotion or be decommissioned. Behind the scenes, the bookers in a company will place the title on the most accomplished performer, or those the bookers believe will generate fan interest in terms of event attendance and television viewership. Historically, a world champion was typically a legit shooter/hooker who had the skills to prevent double crosses by shooters who would deviate from the planned finish for personal glory. Lower ranked titles may also be used on the performers who show potential, thus allowing them greater exposure to the audience. Other circumstances may also determine the use of a championship. A combination of a championship's lineage, the caliber of performers as champion, and the frequency and manner of title changes, dictates the audience's perception of the title's quality, significance and reputation.\nA wrestler's championship accomplishments can be central to their career, becoming a measure of their performance ability and drawing power. In general, a wrestler with multiple title reigns or an extended title reign is indicative of a wrestler's ability to maintain audience interest or a wrestler's ability to perform in the ring. As such, the most accomplished or decorated wrestlers tend to be revered as legends due to the amount of title reigns they hold. American wrestler Ric Flair has had multiple world heavyweight championship reigns spanning over three decades. Japanese wrestler \u00daltimo Drag\u00f3n once held and defended a record ten titles simultaneously.\nRing entrance.\nWhile the wrestling matches themselves are the primary focus of professional wrestling, a key dramatic element of the business can be entrances of the wrestlers to the arena and ring. It is typical for a wrestler to get their biggest crowd reaction (or \"pop\") for their ring entrance, rather than for anything they do in the wrestling match itself, especially if former main event stars are returning to a promotion after a long absence.\nAll notable wrestlers now enter the ring accompanied by music, and regularly add other elements to their entrance. The music played during the ring entrance will usually mirror the wrestler's personality. Many wrestlers, particularly in the U.S., have music and lyrics specially written for their ring entrance. While invented long before, the practice of including music with the entrance gained rapid popularity during the 1980s, largely as a result of the huge success of Hulk Hogan and the WWF, and their Rock 'n' Wrestling Connection. When a match is won, the victor's theme music is usually also played in celebration.\nBecause wrestling is predetermined, a wrestler's entrance music will play as they enter the arena, even if they are, in kayfabe, not supposed to be there. For example, in 2012 through 2014, The Shield was a trio of wrestlers who were (in kayfabe) not at the time under contract with WWE (hence their gimmick of entering the ring through the crowd), but they still had entrance music which was played whenever they entered the arena, despite the fact that they were kayfabe invaders.\nWith the introduction of the Titantron entrance screen in 1997, WWF wrestlers also had entrance videos play along with their music.\nOther dramatic elements of a ring entrance can include:\nSpecial ring entrances are also developed for big occasions, most notably the WrestleMania event. For example, WrestleMania III and VI both saw all wrestlers enter the arena on motorized miniature wrestling rings. Live bands are sometimes hired to perform live entrance music at special events. John Cena and Triple H are particularly notable in recent years for their highly theatrical entrances at WrestleMania.\nTraining and qualifications.\nPhysical fitness is considered the minimum requirement for entry in the field, with most professional wrestlers having at least some athletic background or training. Professional wrestlers receive at least some formal training in specialized professional wrestling schools or academies; these institutions can be independent or associated with a specific promotion. Candidates are typically trained and coached by experienced professional wrestlers; training regimens encompass both the athletic and performative aspects of professional wrestling, including physical fitness, choreography, and dramatization. Trainees are often pitted against one another or with their instructors in matches before small crowds to demonstrate and refine their skill in improvisation, mock combat, and stage presence.\nOccupational hazards.\nProfessional wrestling has been characterized by endemic and widespread health risks from its very inception in the 19th century. Although matches have predetermined results, the inherently physical nature of the performances, combined with an emphasis on spectacle and showmanship, results in a high chance of injury and even death. Strikes are often stiff, especially in Japan, and in independent wrestling promotions such as Combat Zone Wrestling. The ring is often made out of timber planks. There have been many brutal accidents, hits and injuries. Injuries are commonly sustained on the shoulders, knees, back, neck, and ribs. Professional wrestler Davey Richards said in 2015, \"We train to take damage, we know we are going to take damage and we accept that.\"\nOccupational hazards have also been attributed to professional wrestling's uniquely ambiguous nature\u2014as neither a true sport nor a formal performing art, yet still some combination of the two\u2014which makes it difficult to regulate; as noted by Claire Warden, Professor of Performance and Physical Culture at Loughborough University, \"Set up a rugby club tomorrow and the Rugby Football Union would soon be knocking on your door to ask about concussion protocol or safeguarding. Set up a wrestling school or promotion and, well, no-one will demand anything.\" Warden also identifies related issues and practices in the industry, such as inadequate health and safety provisions among promotions, lack of unionization or labor representation, and the fact that most professional wrestlers are employed as independent contractors, thereby typically lacking healthcare access while remaining economically precarious.\nSome wrestling performers use steroids and suffer from associated health issues. In 2007, American Congressman Cliff Stearns noted that between 1985 and 2006, 89 performers had died under the age of 50. Chronic traumatic encephalopathy (CTE), a brain disorder often caused by repeated concussions and head injury, may have been a factor in the 2007 double homicide committed by wrestler Chris Benoit. A 2014 study of male professional wrestlers active between 1985 and 2011 found a \"very high premature mortality rate\" compared to the general population; cardiovascular disease was by far the leading cause, while deaths related to drug overdoses and cancer were likewise substantially high, at 122.7 and 6.4 times greater than the general population.\nWrestling performers frequently experience real pain during routine performances. Sociologist R. Tyson Smith attributes wrestlers' willingness to endure occupational injury to the substantivism of their socioeconomic viewpoint: From this viewpoint, Smith argues, wrestlers are willing to accept bodily pain by both practicing denialism and the sociologic embedded desire for authenticity, solidarity, and dominance. These findings are corroborated by the UK-based \"Health and Wellbeing in Professional Wrestling\" project, which interviewed professional wrestlers and identified common risks such as \"downplaying injury to secure that important spot on the card, performing a macho-masculine sense of resilience ... [and] acknowledging that there are always physical risks associated with contact sports.\"\nRegional variations and subgenres.\nThe United States/Canada, northwest Europe (specifically the UK, Germany/Austria and France), Japan, and Mexico are the four largest and most popular markets for professional wrestling and known for their distinctive styles and independent development.\nProfessional wrestling in the U.S., which overlaps into Canada, tends to focus on history building and the establishment of characters and their personalities. There is a story for each match, merging into a narrative arc stretching across successive matches. Stories usually contain characters like faces, heels, and\u2014less often\u2014\"tweeners\" providing character arc. It is a \"triumph\" if the face wins and a \"tragedy\" if the heel wins. American wrestling features intense narrative conflict between faces and heels, with the heels sometimes attacking the faces during TV interviews. The relationship between different characters can also be complex, with sharp and strong personalities providing an element of literary verisimilitude.\nIn Mexico, professional wrestling in Mexico, or Lucha libre, places less emphasis on narrative development. Mexican professional wrestling tradition repeats very usually brutal tactics, specially more aerial holds than professional wrestlers in the U.S. who, more often, rely on power moves and strikes to subdue their opponents. The difference in styles is due to the independent evolution of the sport in Mexico beginning in the 1930s and the fact that wrestlers in the cruiserweight division () are often the most popular wrestlers in Mexican lucha libre. Wrestlers often execute high flying moves characteristic of lucha libre by utilizing the wrestling ring's ropes to catapult themselves towards their opponents, using intricate combinations in rapid-fire succession, and applying complex submission holds. Lucha libre is also known for its tag team wrestling matches, in which the teams are often made up of three members, instead of two as is common in the U.S.\nJapanese professional wrestling (puroresu) also developed distinctively, initially drawing from traditional American style wrestling and becoming an entity in itself. Although matches are predetermined, the psychology and presentation of performances differ markedly: Among the largest promotions, such as New Japan Pro-Wrestling, All Japan Pro Wrestling and Pro Wrestling Noah, professional wrestling is treated as a full contact combat sport that mixes hard hitting martial arts strikes with shoot style submission holds, whilst in the U.S. it is rather more regarded as an entertainment show. Wrestlers incorporate kicks and strikes from martial arts disciplines, and a strong emphasis is placed on submission wrestling, and unlike the use of involved storylines in the U.S., Japanese storylines are not as intricate, with emphasis on the concept of \"fighting spirit\" via displays of physical and mental stamina. Many of Japan's wrestlers including top stars such as Shinya Hashimoto, Riki Ch\u014dsh\u016b and Keiji Mutoh came from a legitimate martial arts background and many Japanese wrestlers in the 1990s began to pursue careers in mixed martial arts organizations such as Pancrase and Shooto which at the time retained the original look of puroresu but were actual competitions. Other companies, such as Michinoku Pro Wrestling and Dragon Gate, wrestle in a style similar to Mexican companies like AAA and CMLL. This is known as \"Lucharesu\".\nMuch of the more serious style of Japanese wrestling derives from wrestling in Europe, particularly traditional British wrestling, which strongly emphasizes pure technical skill (particularly chain sequences of counters/reversals/escapes from holds) and high proportion of clean sportsmanly scientific matches between two \"blue-eyes\" as babyfaces were called there. This spread across mainland Europe (where it was known as \"Catch\" in non-English speaking countries) but in the Mediterranean south it soon died out after an initial flush of popularity, with the major league promotions of Italy and Spain closing in 1965 and 1986 respectively and Greece's annual stadium show last held in 1980 although some low-grade house shows limped on until 1991. This left the UK, France and West Germany/Austria as the three strongholds of European wrestling by the 1980s. In Germany and Austria, wrestling shows\u2014particularly major trophy tournaments in Graz, Hamburg, Bremen, Vienna and other cities featuring visiting wrestlers from around the world\u2014were a key part of the celebrations of various cultural festivals. Champion and promoter Otto Wanz maintained strong links with American promotions, frequently importing U.S. talent and even briefly winning the AWA World Heavyweight Championship in 1982. Meanwhile, in both the UK and France, national television coverage from the 1950s to the late 1980s made household names of top stars. In the UK in the late 1970s and through the 1980s, the dominant Joint Promotions underwent a major boom by rebranding as family entertainment centred around superheavyweight lead blue-eye Big Daddy. Eventually however the sheer lopsided nature of his victories over heels alienated fellow wrestlers and adult fans alike to the point where both groups defected in droves to opposition promoter All Star Wrestling which expanded (taking a share of the final two years of TV coverage) until it eclipsed Joint as dominant promotion, a position it still holds in 2025. During the same period, professional wrestling in France moved to a more acrobatic style of action and colourful gimmick-led presentation, as exemplified by lead babyface Flesh Gordon (Gerard Herv\u00e9) who had learned his craft in 1970s Mexico. By the beginning of the 1990s in all three countries, local styles of wrestling were largely supplanted in mainstream popular culture by the WWF and WCW. While the traditional styles survive at grassroots level they face stiff competition not only from the major American wrestling corporations but also from homegrown \"American style\" promotions conforming to the general pattern of the contemporary U.S. independent wrestling scene.\nWomen's wrestling.\nThe women's division of professional wrestling has maintained a recognized world champion since 1937, when Mildred Burke won the original World Women's title. She then formed the World Women's Wrestling Association in the early 1950s and recognized herself as the first champion, although the championship was vacated upon her retirement in 1956. The NWA ceased to acknowledge Burke as the Women's World champion in 1954 and instead acknowledged June Byers as champion after a controversial finish to a high-profile match between Burke and Byers that year. Upon Byers's retirement in 1964, The Fabulous Moolah, who won a junior heavyweight version of the NWA World Women's Championship (the predecessor to the WWE Women's Championship) in a tournament back in 1958, was recognized by most NWA promoters as champion by default.\nIntergender.\nFor most of its history, men and women rarely worked against each other in professional wrestling, as it was deemed to be unfair and unchivalrous. Andy Kaufman used this to gain notoriety when he created an Intergender Championship and declared it open to any female challenger. This led to a long (worked) feud with Jerry Lawler.\nCathy Davis sued the New York State Athletic Commission (NYSAC) in 1977 because she was denied a boxing license because she was a woman, and the case was decided in her favor later that year, with the judge invalidating New York State rule number 205.15, which stated, \"No woman may be licensed as a boxer or second or licensed to compete in any wrestling exhibition with men.\" In his opinion the judge cited the precedent set by \"Garrett v. New York State Athletic Commission\" (1975), which \"found the regulation invalid under the equal protection clauses of the State and Federal Constitutions\". The NYSAC filed an appeal of the ruling but later dropped it.\nIn the 1980s, mixed tag team matches began to take place, with a male and female on each team and a rule stating that each wrestler could only attack the opponent of the same gender. If a tag was made, the other team had to automatically switch their legal wrestler as well. Despite these restrictions, many mixed tag matches do feature some physical interaction between participants of different genders. For example, a heel may take a cheap shot at the female wrestler of the opposing team to draw a negative crowd reaction. In lucha libre, cheap shots and male-female attacks are not uncommon.\nIntergender singles bouts were first fought on a national level in the 1990s. This began with Luna Vachon, who faced men in Extreme Championship Wrestling (ECW) and WWF. Later, Chyna became the first female to hold a belt that was not exclusive to women when she won the WWF Intercontinental Championship. Intergender wrestling was uncommon in Impact Wrestling. ODB, had participated in intergender matches and once held the Impact Knockouts Tag Team Championship with Eric Young for a record 478 days. Other notable Impact Knockouts that competed in intergender matches include Scarlett Bordeaux; Tessa Blanchard, who became the first woman to win the Impact World Championship; and Jordynne Grace, who became the inaugural Impact Digital Media Championship.\nMidget wrestling.\nMidget wrestling can be traced to professional wrestling's carnival and vaudeville origins. In recent years, the popularity and prevalence of midgets in wrestling has greatly decreased due to wrestling companies depriving midget divisions of storyline or feud. WWE has made a few attempts to enter this market with their \"minis\" in the 1990s and the \"junior's league\" as recent as 2006. It is still a popular form of entertainment in Mexican wrestling, mostly as a \"sideshow\".\nSome wrestlers may have their own specific \"mini me\", like Mascarita Sagrada, Alebrije has Quije, etc. There are also cases in which midgets can become valets for a wrestler, and even get physically involved in matches, like Alushe, who often accompanies Tinieblas, or KeMonito, who is portrayed as Consejo Mundial de Lucha Libre's mascot and is also a valet for Mistico. Dave Finlay was often aided in his matches by a midget known mainly as Hornswoggle while in WWE, who hid under the ring and gave a shillelagh to Finlay to use on his opponent. Finlay also occasionally threw him at his opponents. Hornswoggle was given a run with the WWE Cruiserweight Championship and feuded with D-X in 2009.\nCulture and sociology.\nProfessional wrestling has developed its own unique culture among both spectators and performers. Professional wrestlers have developed a kind of global fraternity, with familial bonds, shared language and passed-down traditions. New performers are expected to \"pay their dues\" for a few years by working in lower-profile promotions and working as ring crew before working their way upward. The permanent rosters of most promotions develop a backstage pecking order, with veterans mediating conflicts and mentoring younger wrestlers. For many decades (and still to a lesser extent today) performers were expected to keep the illusions of wrestling's legitimacy alive even while not performing, essentially acting in character any time they were in public. Some veterans speak of a \"sickness\" among wrestling performers, an inexplicable pull to remain active in the wrestling world despite the devastating effects the job can have on one's life and health.\nFans of professional wrestling likewise have their own subculture, comparable to those of science fiction, video games, or comic books. Like sports fans, many enthusiasts not only attend and view events but take an active interest in backstage occurrences, future storylines, and reasonings behind company decisions; they are catered to by a large and diverse industry of newsletters written by journalists with insider ties to the wrestling industry. Known in the subculture as \"rags\" or \"dirt sheets\", these sources have proliferated online and sometimes provide breaking news; some have expanded into radio shows.\nSome fans enjoy collecting recordings of wrestling shows from specific companies, of certain wrestlers, or of specific genres. Since the 1990s, many companies have been founded which deal primarily in wrestling footage. When the WWE purchased both WCW and ECW in 2001, they also obtained the entire past video libraries of both productions and have released many past matches online and on home video. Additionally, the internet has exposed fans to previously unavailable variations of wrestling from around the world.\nAs in competitive sports, fantasy leagues have developed around professional wrestling. Some take this concept further by creating E-feds (electronic federations), where a user can create their own fictional wrestling character, and role-playing storylines with other users, leading to scheduled \"shows\" where match results are determined by the organizers, usually based on a combination of the characters' statistics and the players' roleplaying aptitude, sometimes with audience voting.\nMainstream popularity.\nFrom the first established world championship, the top professional wrestlers have garnered fame within mainstream society. Each successive generation has produced a number of wrestlers who extend their careers into the realms of music, acting, writing, business, politics or public speaking, and are known to those who are unfamiliar with wrestling in general. Conversely, celebrities from other sports or general pop culture also become involved with wrestling for brief periods of time. A prime example of this is The Rock 'n' Wrestling Connection of the 1980s, which combined wrestling with MTV.\nProfessional wrestling is often portrayed within other works using parody, and its general elements have become familiar tropes and memes in American culture.\nSome terminology originating in professional wrestling has found its way into the common vernacular. Phrases such as \"body slam\", \"sleeper hold\" and \"tag team\" are used by those who do not follow professional wrestling. The term \"smackdown\", popularized by The Rock and \"SmackDown!\" in the 1990s, has been included in Merriam-Webster dictionaries since 2007.\nMany television shows and films have been produced which portray in-character professional wrestlers as protagonists, such as \"Ready to Rumble\", \"\u00a1Mucha Lucha!\", \"Nacho Libre\", and the Santo film series.\nThere have been multiple stage plays set in the world of pro wrestling: \"The Baron\" is a comedy that retells the life of an actual performer known as Baron von Raschke. \"From Parts Unknown...\" is an award-nominated Canadian drama about the rise and fall of a fictional wrestler. \"Trafford Tanzi\" is a play set in a wrestling ring and divided into ten rounds, in which all the cast members participate in wrestling. \"The Elaborate Entrance of Chad Deity\" is a dramatic comedy about a fictional wrestler, which involves scenes of professional wrestling that take place in a wrestling ring. \"Mythos: Ragnar\u00f6k\" adapts Norse mythology for the stage by combining dramatic dialogue with scenes of professional wrestling, in the first example of wrestling being used as theatrical stage combat.\nThe 2009 \"South Park\" episode \"W.T.F.\" played on the soap operatic elements of professional wrestling. One of the lead characters on the Disney Channel series \"Kim Possible\" was a huge fan of pro wrestling and actually featured it on an episode (with two former WWE wrestlers voicing the two fictitious wrestlers featured in the episode). The 2008 film \"The Wrestler\", about a washed-up professional wrestler, garnered several Oscar nominations. The 2017 TV series GLOW, based on the Gorgeous Ladies of Wrestling promotion, gained critical acclaim, including a nomination for Outstanding Comedy Series at the 70th Primetime Emmy Awards.\nThe 1950 film noir \"Night and the City\", directed by Jules Dassin and starring Richard Widmark and Gene Tierney, told the story of a promoter in London trying to make it big, and featured a match involving professional wrestler Stanislaus Zbyszko. The 2019 \"Fighting with My Family\" is a biographical sports comedy-drama film that depicts the career of English professional wrestler Paige. Walk Like A Panther is 2018 British comedy film about a group of 1980s wrestlers staging one final show to raise money to save their pub.\nMany professional wrestlers have also become mainstream in their own right, including John Cena, Dave Bautista, and Dwayne \"The Rock\" Johnson, mainly for acting in major films, as well as Chris Jericho and \"Macho Man\" Randy Savage for their musical ventures.\nWrestling has also gained a major following on YouTube, with WWE being the most subscribed wrestling channel and sixth most subscribed channel in the world. Other promotions, such as All Elite Wrestling, Major League Wrestling, Impact Wrestling and the National Wrestling Alliance have distributed their own weekly programming on the platform.\nMeasures of popularity.\nProfessional wrestling has become especially prominent in North America, Japan and Europe (especially the United Kingdom). In Brazil, there was a very popular wrestling television program that aired from the 1960s to the early 1980s called \"Telecatch\". High-profile figures in the sport have become celebrities and even cultural icons in their home countries.\nAlthough professional wrestling started out as a small sideshow in traveling circuses and carnivals, today it is a multi-billion-dollar industry. Revenue is drawn from ticket sales, network television broadcasts, pay-per-view broadcasts, branded merchandise and home video. Wrestling was instrumental in making pay-per-view a viable method of content delivery. Annual shows such as WrestleMania, All In, Bound for Glory, Wrestle Kingdom and formerly Starrcade are among the highest-selling pay-per-view programming each year. In modern day, internet programming has been utilized by a number of companies to air web shows, internet pay per views (IPPVs) or on-demand content, helping to generate internet-related revenue earnings from the evolving World Wide Web.\nHome video sales dominate the Billboard charts Recreational Sports DVD sales, with wrestling holding anywhere from 3 to 9 of the top 10 spots every week.\nDue to its persistent cultural presence and to its novelty within the performing arts, wrestling constitutes a recurring topic in both academia and the media. Several documentaries have been produced looking at professional wrestling, most notably \"Beyond the Mat\" directed by Barry W. Blaustein, and \"\" featuring retired wrestler Bret Hart and directed by Paul Jay. There have also been many fictional depictions of wrestling; the 2008 film \"The Wrestler\" received several Oscar nominations and began a career revival for its star Mickey Rourke.\nCurrently, the largest professional wrestling company worldwide is the United States\u2013based WWE, which bought out many smaller regional companies in the late 20th century, as well as primary competitors World Championship Wrestling (WCW) and ECW in early 2001. Other major companies worldwide include All Elite Wrestling (AEW) in the United States, Consejo Mundial de Lucha Libre (CMLL), and Lucha Libre AAA Worldwide (AAA) in Mexico; and New Japan Pro-Wrestling (NJPW), All Japan Pro Wrestling (AJPW), and Pro Wrestling Noah in Japan.\nStudy and analysis.\nWith its growing popularity, professional wrestling has attracted attention as a subject of serious academic study and journalistic criticism. Many courses, theses, essays and dissertations have analyzed wrestling's conventions, content, and its role in modern society. It is often included as part of studies on theater, sociology, performance, and media. The Massachusetts Institute of Technology developed a course of study on the cultural significance of professional wrestling, and anthropologist Heather Levi has written an ethnography about the culture of lucha libre in Mexico.\nIn the early 20th century, once it became apparent that the \"sport\" was worked, pro wrestling was looked down on as a cheap entertainment for the uneducated working class, an attitude that still exists to varying degrees today. The French theorist Roland Barthes was among the first to propose that wrestling was worthy of deeper analysis, in his essay \"The World of Wrestling\" from his book \"Mythologies\", first published in 1957. Barthes argued that it should be looked at not as a scamming of the ignorant, but as spectacle; a mode of theatric performance for a willing, if bloodthirsty, audience. Wrestling is described as performed art which demands an immediate reading of the juxtaposed meanings. The logical conclusion is given least importance over the theatrical performers of the wrestlers and the referee. According to Barthes, the function of a wrestler is not to win: it is to go exactly through the motions which are expected of him and to give the audience a theatrical spectacle. This work is considered a foundation of all later study.\nWhile pro wrestling is often described simplistically as a \"soap opera for males\", it has also been cited as filling the role of past forms of literature and theater; a synthesis of classical heroics, commedia dell'arte, revenge tragedies, morality plays, and burlesque. The characters and storylines portrayed by a successful promotion are seen to reflect the current mood, attitudes, and concerns of that promotion's society and can in turn influence those same things. For example, wrestling's high levels of violence and masculinity make it a vicarious outlet for aggression during peacetime. The displays of masculinity are said to incorporate homoerotic elements and elements of pageantry that have been compared to drag or Ball culture; some scholars posit that the homoerotic undertones target the desires of ostensibly heterosexual male viewers, \"[allowing] them the vicarious pleasure of transgressing gender norms\" by identifying with \"wrestlers who perform culturally transgressive notions of masculinity including flamboyance, attention to physical appearance, and ambiguous sexual identity\".\nDocumentary filmmakers have studied the lives of wrestlers and the effects the profession has on them and their families. The 1999 theatrical documentary \"Beyond the Mat\" focused on Terry Funk, a wrestler nearing retirement; Mick Foley, a wrestler within his prime; Jake Roberts, a former star fallen from grace; and a school of wrestling students trying to break into the business. The 2005 release ' chronicled the development of women's wrestling throughout the 20th century. Pro wrestling has been featured several times on HBO's \"Real Sports with Bryant Gumbel\". MTV's documentary series \"True Life\" featured two episodes titled \"I'm a Professional Wrestler\" and \"I Want to Be a Professional Wrestler\". Other documentaries have been produced by The Learning Channel (\"The Secret World of Professional Wrestling\") and A&amp;E ('). \"Bloodstained Memoirs\" explored the careers of several pro wrestlers, including Chris Jericho, Rob Van Dam and Roddy Piper.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24868", "revid": "50847995", "url": "https://en.wikipedia.org/wiki?curid=24868", "title": "Pauli matrices", "text": "Matrices important in quantum mechanics and the study of spin\nIn mathematical physics and mathematics, the Pauli matrices are a set of three 2 \u00d7 2 complex matrices that are traceless, Hermitian, involutory and unitary. Usually indicated by the Greek letter sigma (\u03c3), they are occasionally denoted by tau (\u03c4) when used in connection with isospin symmetries.\nformula_1\nThese matrices are named after the physicist Wolfgang Pauli. In quantum mechanics, they occur in the Pauli equation, which takes into account the interaction of the spin of a particle with an external electromagnetic field. They also represent the interaction states of two polarization filters for horizontal/vertical polarization, 45\u00a0degree polarization (right/left), and circular polarization (right/left).\nEach Pauli matrix is Hermitian, and together with the identity matrix I (sometimes considered as the zeroth Pauli matrix \"\u03c3\"0), the Pauli matrices form a basis of the vector space of 2 \u00d7 2 Hermitian matrices over the real numbers, under addition. This means that any 2 \u00d7 2 Hermitian matrix can be written in a unique way as a linear combination of Pauli matrices, with all coefficients being real numbers.\nThe Pauli matrices satisfy the useful product relation:\nformula_2\nwhere \u03b4ij is the Kronecker delta, which equals +1 if otherwise 0, and the Levi-Civita symbol \"\u03b5ijk\" is used.\nHermitian operators represent observables in quantum mechanics, so the Pauli matrices span the space of observables of the complex two-dimensional Hilbert space. In the context of Pauli's work, \u03c3k represents the observable corresponding to spin along the kth coordinate axis in three-dimensional Euclidean space formula_3\nThe Pauli matrices (after multiplication by i to make them anti-Hermitian) also generate transformations in the sense of Lie algebras: The matrices form a basis for the real Lie algebra formula_4 which exponentiates to the special unitary group SU(2). The algebra generated by the three matrices \"\u03c3\"1, \"\u03c3\"2, \"\u03c3\"3 is isomorphic to the Clifford algebra of formula_5 and the (unital) associative algebra generated by \"i\u03c3\"1, \"i\u03c3\"2, \"i\u03c3\"3 functions identically (is isomorphic) to that of quaternions (formula_6).\nAlgebraic properties.\nAll three of the Pauli matrices can be compacted into a single expression:\nformula_7\nThis expression is useful for \"selecting\" any one of the matrices numerically by substituting values of in turn useful when any of the matrices (but no particular one) is to be used in algebraic manipulations.\nThe matrices are \"involutory\":\nformula_8\nwhere I is the identity matrix.\nThe determinants and traces of the Pauli matrices are\nformula_9\nfrom which we can deduce that each matrix \u03c3j has eigenvalues +1 and \nWith the inclusion of the identity matrix I (sometimes denoted \"\u03c3\"0), the Pauli matrices form an orthogonal basis (in the sense of Hilbert\u2013Schmidt) of the Hilbert space formula_10 of 2 \u00d7 2 Hermitian matrices over formula_11 and the Hilbert space formula_12 of all complex 2 \u00d7 2 matrices over formula_13\nCommutation and anti-commutation relations.\nCommutation relations.\nThe Pauli matrices obey the following commutation relations:\nformula_14\nThese commutation relations make the Pauli matrices the generators of a representation of the Lie algebra formula_15\nAnticommutation relations.\nThey also satisfy the anticommutation relations:\nformula_16\nwhere formula_17 is defined as formula_18 and \"\u03b4jk\" is the Kronecker delta. I denotes the 2 \u00d7 2 identity matrix.\nThese anti-commutation relations make the Pauli matrices the generators of a representation of the Clifford algebra for formula_5 denoted formula_20\nThe usual construction of generators formula_21 of formula_22 using the Clifford algebra recovers the commutation relations above, up to unimportant numerical factors.\nA few explicit commutators and anti-commutators are given below as examples:\nEigenvectors and eigenvalues.\nEach of the (Hermitian) Pauli matrices has two eigenvalues: +1 and \u22121. The corresponding normalized eigenvectors are\nformula_23\nPauli vectors.\nThe Pauli vector is defined by\nformula_24\nwhere formula_25 formula_26 and formula_27 are an equivalent notation for the more familiar formula_28 formula_29 and formula_30\nThe Pauli vector provides a mapping mechanism from a vector basis to a Pauli matrix basis as follows:\nformula_31\nMore formally, this defines a map from formula_32 to the vector space of traceless Hermitian formula_33 matrices. This map encodes structures of formula_32 as a normed vector space and as a Lie algebra (with the cross-product as its Lie bracket) via functions of matrices, making the map an isomorphism of Lie algebras. This makes the Pauli matrices intertwiners from the point of view of representation theory.\nAnother way to view the Pauli vector is as a formula_35 Hermitian traceless matrix-valued dual vector, that is, an element of formula_36 that maps formula_37\nCompleteness relation.\nEach component of formula_38 can be recovered from the matrix (see completeness relation below) \nformula_39\nThis constitutes an inverse to the map formula_40 making it manifest that the map is a bijection.\nDeterminant.\nThe norm is given by the determinant (up to a minus sign)\nformula_41\nThen, considering the conjugation action of an formula_42 matrix formula_43 on this space of matrices,\n formula_44\nwe find formula_45 and that formula_46 is Hermitian and traceless. It then makes sense to define formula_47 where formula_48 has the same norm as formula_49 and therefore interpret formula_43 as a rotation of three-dimensional space. In fact, it turns out that the \"special\" restriction on formula_43 implies that the rotation is orientation preserving. This allows the definition of a map formula_52 given by\n formula_53\nwhere formula_54 This map is the concrete realization of the double cover of formula_55 by formula_56 and therefore shows that formula_57 The components of formula_58 can be recovered using the tracing process above:\n formula_59\nCross-product.\nThe cross-product is given by the matrix commutator (up to a factor of formula_60)\nformula_61\nIn fact, the existence of a norm follows from the fact that formula_62 is a Lie algebra (see Killing form).\nThis cross-product can be used to prove the orientation-preserving property of the map above.\nEigenvalues and eigenvectors.\nThe eigenvalues of formula_63 are formula_64 This follows immediately from tracelessness and explicitly computing the determinant.\nMore abstractly, without computing the determinant, which requires explicit properties of the Pauli matrices, this follows from formula_65 since this can be factorised into formula_66 A standard result in linear algebra (a linear map that satisfies a polynomial equation written in distinct linear factors is diagonalizable) means this implies formula_63 is diagonalizable with possible eigenvalues formula_68 The tracelessness of formula_63 means it has exactly one of each eigenvalue.\nIts normalized eigenvectors are \nformula_70\nThese expressions become singular for formula_71 They can be rescued by letting formula_72 and taking the limit formula_73 which yields the correct eigenvectors and of formula_74\nAlternatively, one may use spherical coordinates formula_75 to obtain the eigenvectors formula_76 and formula_77\nPauli 4-vector.\nThe Pauli 4-vector, used in spinor theory, is written formula_78 with components\nformula_79\nThis defines a map from formula_80 to the vector space of Hermitian matrices,\nformula_81\nwhich also encodes the Minkowski metric (with \"mostly minus\" convention) in its determinant:\nformula_82\nThis 4-vector also has a completeness relation. It is convenient to define a second Pauli 4-vector\nformula_83\nand allow raising and lowering using the Minkowski metric tensor. The relation can then be written\nformula_84\nSimilarly to the Pauli 3-vector case, we can find a matrix group that acts as isometries on formula_85 in this case the matrix group is formula_86 and this shows formula_87 Similarly to above, this can be explicitly realized for formula_88 with components\nformula_89\nIn fact, the determinant property follows abstractly from trace properties of the formula_90 For formula_91 matrices, the following identity holds:\nformula_92\nThat is, the 'cross-terms' can be written as traces. When formula_93 are chosen to be different formula_94 the cross-terms vanish. It then follows, now showing summation explicitly,\nformula_95 Since the matrices are formula_96 this is equal to formula_97\nRelation to dot and cross product.\nPauli vectors elegantly map these commutation and anticommutation relations to corresponding vector products. Adding the commutator to the anticommutator gives\nformula_98\nso that, \nformula_99\nContracting each side of the equation with components of two 3-vectors \"ap\" and \"bq\" (which commute with the Pauli matrices, i.e., \"ap\u03c3q\" = \"\u03c3qap\") for each matrix \"\u03c3q\" and vector component \"ap\" (and likewise with \"bq\") yields\nformula_100\nFinally, translating the index notation for the dot product and cross product results in \n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nIf i is identified with the pseudoscalar then the right hand side becomes formula_101 which is also the definition for the product of two vectors in geometric algebra.\nIf we define the spin operator as then J satisfies the commutation relation:formula_102 Or equivalently, the Pauli vector satisfies:formula_103\nSome trace relations.\nThe following traces can be derived using the commutation and anticommutation relations.\nformula_104\nIf the matrix \"\u03c3\"0 \n \"I\" is also considered, these relationships become\nformula_105\nwhere Greek indices \"\u03b1\", \"\u03b2\", \"\u03b3\" and \u03bc assume values from {0, \"x\", \"y\", \"z\"} and the notation formula_106 is used to denote the sum over the cyclic permutation of the included indices.\nExponential of a Pauli vector.\nFor \nformula_107\none has, for even powers, 2 \"p\", \"p\" \n 0, 1, 2, 3, ...\nformula_108\nwhich can be shown first for the \"p\" = 1 case using the anticommutation relations. For convenience, the case \"p\" \n 0 is taken to be I by convention.\nFor odd powers, 2 \"q\" + 1, \"q\" \n 0, 1, 2, 3, ...\nformula_109\nMatrix exponentiating, and using the Taylor series for sine and cosine,\nformula_110\nIn the last line, the first sum is the cosine, while the second sum is the sine; so, finally,\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nwhich is analogous to Euler's formula, extended to quaternions. In particular,\nformula_111\nNote that\nformula_112\nwhile the determinant of the exponential itself is just 1, which makes it the generic group element of SU(2).\nA more abstract version of formula (2) for a general 2 \u00d7 2 matrix can be found in the article on matrix exponentials. A general version of (2) for an analytic (at a and \u2212a) function is provided by application of Sylvester's formula,\nformula_113\nThe group composition law of SU(2).\nA straightforward application of formula (2) provides a parameterization of the composition law of the group SU(2). One may directly solve for c in \nformula_114\nwhich specifies the generic group multiplication, where, manifestly, \nformula_115\nthe spherical law of cosines. Given c, then, \nformula_116\nConsequently, the composite rotation parameters in this group element (a closed form of the respective BCH expansion in this case) simply amount to\nformula_117\n(Of course, when formula_118 is parallel to formula_119 so are formula_120 and \nAdjoint action.\nIt is also straightforward to likewise work out the adjoint action on the Pauli vector, namely rotation of any angle formula_121 along any axis formula_122:\nformula_123\nTaking the dot product of any unit vector with the above formula generates the expression of any single qubit operator under any rotation. For example, it can be shown that formula_124\nCompleteness relation.\nAn alternative notation that is commonly used for the Pauli matrices is to write the vector index k in the superscript, and the matrix indices as subscripts, so that the element in row \u03b1 and column \u03b2 of the k-th Pauli matrix is \nIn this notation, the \"completeness relation\" for the Pauli matrices can be written\nformula_125\n&lt;templatestyles src=\"Math_proof/styles.css\" /&gt;Proof\nThe fact that the Pauli matrices, along with the identity matrix I, form an orthogonal basis for the Hilbert space of all 2 \u00d7 2 complex matrices formula_126 over formula_127 means that we can express any 2 \u00d7 2 complex matrix M as\nformula_128\nwhere c is a complex number, and a is a 3-component, complex vector. It is straightforward to show, using the properties listed above, that\nformula_129\nwhere \"tr\" denotes the trace, and hence that \nformula_130\nwhich can be rewritten in terms of matrix indices as\nformula_131\nwhere summation over the repeated indices is implied \u03b3 and \u03b4. Since this is true for any choice of the matrix M, the completeness relation follows as stated above. Q.E.D.\nAs noted above, it is common to denote the 2 \u00d7 2 unit matrix by so The completeness relation can alternatively be expressed as\nformula_132\nThe fact that any Hermitian complex 2 \u00d7 2 matrices can be expressed in terms of the identity matrix and the Pauli matrices also leads to the Bloch sphere representation of 2 \u00d7 2 mixed states\u2019 density matrix, (positive semidefinite 2 \u00d7 2 matrices with unit trace. This can be seen by first expressing an arbitrary Hermitian matrix as a real linear combination of {\"\u03c3\"0, \"\u03c3\"1, \"\u03c3\"2, \"\u03c3\"3} as above, and then imposing the positive-semidefinite and trace 1 conditions.\nFor a pure state, in polar coordinates, formula_133 the idempotent density matrix\nformula_134\nacts on the state eigenvector formula_135 with eigenvalue +1, hence it acts like a projection operator.\nRelation with the permutation operator.\nLet \"Pjk\" be the transposition (also known as a permutation) between two spins \"\u03c3j\" and \"\u03c3k\" living in the tensor product space \nformula_136\nThis operator can also be written more explicitly as Dirac's spin exchange operator,\nformula_137\nIts eigenvalues are therefore 1 or \u22121. It may thus be utilized as an interaction term in a Hamiltonian, splitting the energy eigenvalues of its symmetric versus antisymmetric eigenstates.\nSU(2).\nThe group SU(2) is the Lie group of unitary 2 \u00d7 2 matrices with unit determinant; its Lie algebra is the set of all 2 \u00d7 2 anti-Hermitian matrices with trace 0. Direct calculation, as above, shows that the Lie algebra formula_138 is the three-dimensional real algebra spanned by the set {\"i\u03c3k\"}. In compact notation,\nformula_139\nAs a result, each \"i\u03c3j\" can be seen as an infinitesimal generator of SU(2). The elements of SU(2) are exponentials of linear combinations of these three generators, and multiply as indicated above in discussing the Pauli vector. Although this suffices to generate SU(2), it is not a proper representation of su(2), as the Pauli eigenvalues are scaled unconventionally. The conventional normalization is so that\nformula_140\nAs SU(2) is a compact group, its Cartan decomposition is trivial.\nSO(3).\nThe Lie algebra formula_141 is isomorphic to the Lie algebra formula_142, which corresponds to the Lie group SO(3), the group of rotations in three-dimensional space. In other words, one can say that the are a realization (and, in fact, the lowest-dimensional realization) of \"infinitesimal\" rotations in three-dimensional space. However, even though formula_141 and formula_142 are isomorphic as Lie algebras, SU(2) and SO(3) are not isomorphic as Lie groups. SU(2) is actually a double cover of SO(3), meaning that there is a two-to-one group homomorphism from see relationship between SO(3) and SU(2).\nQuaternions.\nThe real linear span of {\"I\", \" i\u03c3\"1, \"i \u03c3\"2, \"i \u03c3\"3} is isomorphic to the real algebra of quaternions, formula_6, represented by the span of the basis vectors formula_146 The isomorphism from formula_147 to this set is given by the following map (notice the reversed signs for the Pauli matrices):\nformula_148\nAlternatively, the isomorphism can be achieved by a map using the Pauli matrices in reversed order,\nformula_149\nAs the set of versors formula_150 forms a group isomorphic to SU(2), U gives yet another way of describing SU(2). The two-to-one homomorphism from SU(2) to SO(3) may be given in terms of the Pauli matrices in this formulation.\nPhysics.\nClassical mechanics.\nIn classical mechanics, Pauli matrices are useful in the context of the Cayley\u2013Klein parameters. The matrix P corresponding to the position formula_151 of a point in space is defined in terms of the above Pauli vector matrix,\nformula_152\nConsequently, the transformation matrix \"Q\u03b8\" for rotations about the x-axis through an angle \u03b8 may be written in terms of Pauli matrices and the unit matrix as\nformula_153\nSimilar expressions follow for general Pauli vector rotations as detailed above.\nQuantum mechanics.\nIn quantum mechanics, each Pauli matrix is related to an angular momentum operator that corresponds to an observable describing the spin of a spin &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 particle, in each of the three spatial directions. As an immediate consequence of the Cartan decomposition mentioned above, \"i\u03c3j\" are the generators of a projective representation (spin representation) of the rotation group SO(3) acting on non-relativistic particles with spin &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442. The states of the particles are represented as two-component spinors. In the same way, the Pauli matrices are related to the isospin operator.\nAn interesting property of spin &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 particles is that they must be rotated by an angle of 4\u03c0 in order to return to their original configuration. This is due to the two-to-one correspondence between SU(2) and SO(3) mentioned above, and the fact that, although one visualizes spin up/down as the north\u2013south pole on the 2-sphere they are actually represented by orthogonal vectors in the two-dimensional complex Hilbert space.\nFor a spin &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 particle, the spin operator is given by the fundamental representation of SU(2). By taking Kronecker products of this representation with itself repeatedly, one may construct all higher irreducible representations. That is, the resulting spin operators for higher spin systems in three spatial dimensions, for arbitrarily large \"j\", can be calculated using this spin operator and ladder operators. They can be found in . The analog formula to the above generalization of Euler's formula for Pauli matrices, the group element in terms of spin matrices, is tractable, but less simple.\nAlso useful in the quantum mechanics of multiparticle systems, the general Pauli group \"Gn\" is defined to consist of all n-fold tensor products of Pauli matrices.\nRelativistic quantum mechanics.\nIn relativistic quantum mechanics, the spinors in four dimensions are 4 \u00d7 1 (or matrices. Hence the Pauli matrices or the Sigma matrices operating on these spinors have to be They are defined in terms of Pauli matrices as\nformula_154\nIt follows from this definition that the formula_155 matrices have the same algebraic properties as the \u03c3k matrices.\nHowever, relativistic angular momentum is not a three-vector, but a second order four-tensor. Hence formula_156 needs to be replaced by \u03a3\"\u03bc\u03bd\", the generator of Lorentz transformations on spinors. By the antisymmetry of angular momentum, the \u03a3\"\u03bc\u03bd\" are also antisymmetric. Hence there are only six independent matrices.\nThe first three are the formula_157 The remaining three, formula_158 where the Dirac \"\u03b1k\" matrices are defined as\nformula_159\nThe relativistic spin matrices \u03a3\"\u03bc\u03bd\" are written in compact form in terms of commutator of gamma matrices as\nformula_160\nQuantum information.\nIn quantum information, single-qubit quantum gates are 2 \u00d7 2 unitary matrices. The Pauli matrices are some of the most important single-qubit operations. In that context, the Cartan decomposition given above is called the \"Z\u2013Y \"decomposition of a single-qubit gate\"\". Choosing a different Cartan pair gives a similar \"X\u2013Y \"decomposition of a single-qubit gate\" \".\nRemarks.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "24869", "revid": "19404073", "url": "https://en.wikipedia.org/wiki?curid=24869", "title": "Pie menu", "text": "Software menu where elements are arranged in a circle\nIn user interface design, a pie menu or radial menu is a circular context menu where selection depends on direction. It is a graphical control element. A pie menu is made of several \"pie slices\" around an inactive center and works best with stylus input, and well with a mouse. Pie slices are drawn with a hole in the middle for an easy way to exit the menu.\nPie menus work well with keyboard acceleration, particularly four and eight item menus, on the cursor keys and the number pad. A goal of pie menus is to provide a smooth, reliable gestural style of interaction for novices and experts. A slice can lead to another pie menu; selecting this may center the pointer in the new menu.\nA marking menu is a variant of this technique that makes the menu less sensitive to variance in gesture size.\nAs a kind of context menu, pie menus are often context-sensitive, showing different options depending on what the pointer was pointing at when the menu was requested.\nHistory.\nThe first documented radial menu is attributed to a system called PIXIE in 1969. Some universities explored alternative visual layouts.\nIn 1986, Mike Gallaher and Don Hopkins together independently arrived at the concept of a context menu based on the angle to the origin where the exact angle and radius could be passed as parameters to a command, and a mouse click could be used to trigger an item or submenu.\nThe first performance comparison to linear menus was performed in 1988, and showed an increase in performance of 15% less time and a reduction of selection errors.\nThe role-playing video game \"Secret of Mana\" featured an innovative icon-based radial menu system in 1993. Its ring menu system was adopted by later video games.\nUsage.\nPie menus are a self-revealing gestural interface: they display multiple options to a user and direct them to select one. \nUsers operate the menu by observing the labels or icons present as options, moving the pointer in the desired direction, then clicking to make a selection. This action is called a \"mark ahead\" (\"mouse ahead\" in the case of a mouse, \"wave ahead\" in the case of a dataglove).\nRepetition of actions and memorization of the interface further simplify the user experience. Pie menus take advantage of the body's ability to remember muscle motion and direction, even when the mind has forgotten the corresponding symbolic labels.\nComparison with other interaction techniques.\nPie menus are faster and more reliable to select from than linear menus, because selection depends on direction instead of distance. The circular menu slices are large in size and near the pointer for fast interaction (see Fitts's law). Experienced users use muscle memory without looking at the menu while selecting from it. Nested pie menus can efficiently offer many options, and some pie menus can pop up linear menus, and combine linear and radial items in the same menu. Pie menus, just like any popup menu, are shown only when requested, resulting in less visual distraction and cognitive load than toolbars and menu bars that are always shown.\nPie menus show available options, in contrast to invisible mouse gestures. Pie menus, which delay appearance until the pointer is not moving, reduce intrusiveness to the same level as mouse gestures for experienced users. Pie menus take up more screen space than linear menus, and the number of slices in an individual menu must be kept low for effectiveness by using submenus. When using pie menus, submenus may overlap with the parent menu, but the parent menu may become translucent or hidden.\nPie menus are most suited for actions that have been laid out by humans, and have logical grouping choices. Linear menus are most suited for dynamic, large menus that have many possible options, without any logical grouping, since pie menus can only show a limited number of menu items. Around 3-12 items can be reasonably accommodated in a radial layout, but additional items past that tend to counteract the benefits of using pie menus in the first place. This can be overcome with related techniques that allow chaining commands in one single gesture through submenus.\nHowever, using interaction techniques that are not pointer-based have proven problematic with both pie and linear menus for cluttered digital tabletop, where physical objects might occlude menu items.\nPie menus are unavailable as standard graphical control element in common commercial toolkits. Video games often require custom widget development, so pie menu cost is lower in that particular scenario.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24870", "revid": "6727347", "url": "https://en.wikipedia.org/wiki?curid=24870", "title": "PABX", "text": ""}
{"id": "24872", "revid": "43380000", "url": "https://en.wikipedia.org/wiki?curid=24872", "title": "Pollution", "text": "Introduction of contaminants that cause adverse change\nPollution is the introduction of contaminants into the natural environment that cause harm. Pollution can take the form of any substance (solid, liquid, or gas) or energy (such as radioactivity, heat, sound, or light). Pollutants, the components of pollution, can be either foreign substances/energies or naturally occurring contaminants.\nAlthough environmental pollution can be caused by natural events, the word pollution generally implies that the contaminants have a human source, such as manufacturing, extractive industries, poor waste management, transportation or agriculture. Pollution is often classed as point source (coming from a highly concentrated specific site, such as a factory, mine, construction site), or nonpoint source pollution (coming from widespread distributed sources, such as microplastics or agricultural runoff).\nMany sources of pollution were unregulated parts of industrialization during the 19th and 20th centuries until the emergence of environmental regulation and pollution policy in the later half of the 20th century. Sites where historically polluting industries released persistent pollutants may have legacy pollution long after the source of the pollution is stopped. Major forms of pollution include air pollution, water pollution, litter, noise pollution, plastic pollution, soil contamination, radioactive contamination, thermal pollution, light pollution, and visual pollution.\nPollution has widespread consequences on human and environmental health, having systematic impact on social and economic systems. In 2019, pollution killed approximately nine million people worldwide (about one in six deaths that year); about three-quarters of these deaths were caused by air pollution.&lt;ref name=\"10.1016/S2542-5196(22)00090-0\"&gt;&lt;/ref&gt; A 2022 literature review found that levels of anthropogenic chemical pollution have exceeded planetary boundaries and now threaten entire ecosystems around the world. Pollutants frequently have outsized impacts on vulnerable populations, such as children and the elderly, and marginalized communities, because polluting industries and toxic waste sites tend to be collocated with populations with less economic and political power. This outsized impact is a core reason for the formation of the environmental justice movement, and continues to be a core element of environmental conflicts, particularly in the Global South.\nBecause of the impacts of these chemicals, local, country-level, and international policy have increasingly sought to regulate pollutants, resulting in increasing air and water quality standards, alongside regulation of specific waste streams. Regional and national policy is typically supervised by environmental agencies or ministries, while international efforts are coordinated by the UN Environmental Program and other treaty bodies. Pollution mitigation is an important part of all of the Sustainable Development Goals.\nDefinitions and types.\nThe term \"pollution\" in the modern environmental sense was rare before the 1860s. The old sense referred to the desecration of something sacred. According to Adam Rome: To describe what we now call air pollution\u2013i.e., the gaseous, chemical, and metallic by-products of combustion and industrial processes\u2013people usually talked of \"the smoke nuisance.\" There were several variations of that term\u2013\"the smoke problem,\" \"the smoke evil,\" even \"the smoke plague.\" \nVarious definitions of pollution exist, which may or may not recognize certain types, such as noise pollution or greenhouse gases. The United States Environmental Protection Agency defines pollution as \"Any substances in water, soil, or air that degrade the natural quality of the environment, offend the senses of sight, taste, or smell, or cause a health hazard. The usefulness of the natural resource is usually impaired by the presence of pollutants and contaminants.\" In contrast, the United Nations considers pollution to be the \"presence of substances and heat in environmental media (air, water, land) whose nature, location, or quantity produces undesirable environmental effects.\"\nThe major forms of pollution are listed below along with the particular contaminants relevant to each of them:\nNatural causes.\nOne of the most significant natural sources of pollution are volcanoes, which during eruptions release large quantities of harmful gases into the atmosphere. Volcanic gases include carbon dioxide, which can be fatal in large concentrations and contributes to climate change, hydrogen halides which can cause acid rain, sulfur dioxide, which is harmful to animals and damages the ozone layer, and hydrogen sulfide, which is capable of killing humans at concentrations of less than 1 part per thousand. Volcanic emissions also include fine and ultrafine particles which may contain toxic chemicals and substances such as arsenic, lead, and mercury.\nWildfires, which can be caused naturally by lightning strikes, are also a significant source of air pollution. Wildfire smoke contains significant quantities of both carbon dioxide and carbon monoxide, which can cause suffocation. Large quantities of fine particulates are found within wildfire smoke as well, which pose a health risk to animals.\nHuman generation.\nMotor vehicle emissions are one of the leading causes of air pollution. China, United States, Russia, India, Mexico, and Japan are the world leaders in air pollution emissions. Principal stationary pollution sources include chemical plants, coal-fired power plants, oil refineries, petrochemical plants, nuclear waste disposal activity, incinerators, large livestock farms (dairy cows, pigs, poultry, etc.), PVC factories, metals production factories, plastics factories, and other heavy industry. Agricultural air pollution comes from contemporary practices which include clear felling and burning of natural vegetation as well as spraying of pesticides and herbicides.\nAbout 400 million metric tons of hazardous wastes are generated each year. The United States alone produces about 250 million metric tons. Americans constitute less than 5% of the world's population, but produce roughly 25% of the world's CO2, and generate approximately 30% of world's waste. In 2007, China overtook the United States as the world's biggest producer of CO2, while still far behind based on per capita pollution (ranked 78th among the world's nations).\nChlorinated hydrocarbons (CFH), heavy metals (such as chromium, cadmium\u2014found in rechargeable batteries, and lead\u2014found in lead paint, aviation fuel, and even in certain countries, gasoline), MTBE, zinc, arsenic, and benzene are some of the most frequent soil contaminants. A series of press reports published in 2001, culminating in the publication of the book Fateful Harvest, revealed a widespread practise of recycling industrial leftovers into fertilizer, resulting in metal poisoning of the soil. Ordinary municipal landfills are the source of many chemical substances entering the soil environment (and often groundwater), emanating from the wide variety of refuse accepted, especially substances illegally discarded there, or from pre-1970 landfills that may have been subject to little control in the U.S. or EU. There have also been some unusual releases of polychlorinated dibenzodioxins, commonly called \"dioxins\" for simplicity, such as TCDD.\nPollution can also occur as a result of natural disasters. Hurricanes, for example, frequently result in sewage contamination and petrochemical spills from burst boats or automobiles. When coastal oil rigs or refineries are involved, larger-scale and environmental damage is not unusual. When accidents occur, some pollution sources, such as nuclear power stations or oil ships, can create extensive and potentially catastrophic emissions.\nPlastic pollution is choking our oceans by making plastic gyres, entangling marine animals, poisoning our food and water supply, and ultimately inflicting havoc on the health and well-being of humans and wildlife globally. With the exception of a small amount that has been incinerating, virtually every piece of plastic that was ever made in the past still exists in one form or another. And since most of the plastics do not biodegrade in any meaningful sense, all that plastic waste could exist for hundreds or even thousands of years. If plastic production is not circumscribed, plastic pollution will be disastrous and will eventually outweigh fish in oceans.\nRaised levels of greenhouse gases such as carbon dioxide in the atmosphere are affecting the Earth's climate. Disruption of the environment can also highlight the connection between areas of pollution that would normally be classified separately, such as those of water and air. Recent studies have investigated the potential for long-term rising levels of atmospheric carbon dioxide to cause slight but critical increases in the acidity of ocean waters, and the possible effects of this on marine ecosystems.\nIn February 2007, a report by the UN's Intergovernmental Panel on Climate Change (IPCC), representing the work of 2,500 scientists, economists, and policymakers from more than 120 countries, confirmed that humans have been the primary cause of global warming since 1950. Humans have ways to cut greenhouse gas emissions and avoid the consequences of global warming, a major climate report concluded. But to change the climate, the transition from fossil fuels like coal and oil needs to occur within decades, according to the IPCC's final 2007 report.\nEffects.\nHuman health.\nPollution affects humans in every part of the world. An October 2017 study by the Lancet Commission on Pollution and Health found that global pollution, specifically toxic air, water, soil and workplaces, kills nine million people annually, which is triple the number of deaths caused by AIDS, tuberculosis and malaria combined, and 15 times higher than deaths caused by wars and other forms of human violence. The study concluded that \"pollution is one of the great existential challenges of the Anthropocene era. Pollution endangers the stability of the Earth's support systems and threatens the continuing survival of human societies.\"\nAdverse air quality can kill many organisms, including humans. Ozone pollution can cause respiratory disease, cardiovascular disease, throat inflammation, chest pain, and congestion. A 2010 analysis estimated that 1.2 million people died prematurely each year in China alone because of air pollution. China's high smog levels can damage the human body and cause various diseases. In 2019, air pollution caused 1.67 million deaths in India (17.8% of total deaths nationally). Studies have estimated that the number of people killed annually in the United States could be over 50,000. A study published in 2022 in \"GeoHealth\" concluded that energy-related fossil fuel emissions in the United States cause 46,900\u201359,400 premature deaths each year and PM2.5-related illness and death costs the nation $537\u2013$678 billion annually. In the US, deaths caused by coal pollution were highest in 1999, but decreased sharply after 2007. The number dropped by about 95% by 2020, as coal plants have been closed or have scrubbers installed.\nIn 2019, water pollution caused 1.4 million premature deaths. Contamination of drinking water by untreated sewage in developing countries is an issue, for example, over 732 million Indians (56% of the population) and over 92 million Ethiopians (92.9% of the population) do not have access to basic sanitation. In 2013, over 10 million people in India fell ill with waterborne illnesses, and 1,535 people died, most of them children. As of 2007[ [update]], nearly 500 million Chinese lack access to safe drinking water.\nAcute exposure to certain pollutants can have short and long term effects. Oil spills can cause skin irritations and rashes. Noise pollution induces hearing loss, high blood pressure, stress, and sleep disturbance. Mercury has been linked to developmental deficits in children and neurologic symptoms. Older people are significantly exposed to diseases induced by air pollution. Those with heart or lung disorders are at additional risk. Children and infants are also at serious risk. Lead and other heavy metals have been shown to cause neurological problems, intellectual disabilities and behavioural problems. Chemical and radioactive substances can cause cancer and birth defects.\nSocio economic impacts.\nThe health impacts of pollution have both direct and lasting social consequences. A 2021 study found that exposure to pollution causes an increase in violent crime. A 2019 paper linked pollution to adverse school outcomes for children. A number of studies show that pollution has an adverse effect on the productivity of both indoor and outdoor workers.\nEnvironment.\nPollution has been found to be present widely in the natural environment. A 2022 study published in \"Environmental Science &amp; Technology\" found that levels of anthropogenic chemical pollution have exceeded planetary boundaries and now threaten entire ecosystems around the world.\nThere are a number of effects of this:\nControl.\nPollution control is a term used in environmental management. It refers to the control of emissions and effluents into air, water or soil. Without pollution control, the waste products from overconsumption, heating, agriculture, mining, manufacturing, transportation and other human activities, whether they accumulate or disperse, will degrade the environment. In the hierarchy of controls, pollution prevention and waste minimization are more desirable than pollution control. In the field of land development, low impact development is a similar technique for the prevention of urban runoff.\nPolicy, law and monitoring/transparency/life-cycle assessment-attached economics could be developed and enforced to control pollution. A review concluded that there is a lack of attention and action such as work on a globally supported \"formal science\u2013policy interface\", e.g. to \"inform intervention, influence research, and guide funding\".\nIn September 2023 a Global Framework on Chemicals aiming to reduce pollution was agreed during an international conference in Bonn, Germany. The framework includes 28 targets, for example, to \"end the use of hazardous pesticides in agriculture where the risks have not been managed\" by 2035.\nCost.\nPollution has a cost. Manufacturing activities that cause air pollution impose health and clean-up costs on the whole of society. A manufacturing activity that causes air pollution is an example of a negative externality in production. A negative externality in production occurs \"when a firm's production reduces the well-being of others who are not compensated by the firm.\" For example, if a laundry firm exists near a polluting steel manufacturing firm, there will be increased costs for the laundry firm because of the dirt and smoke produced by the steel manufacturing firm. If external costs exist, such as those created by pollution, the manufacturer will choose to produce more of the product than would be produced if the manufacturer were required to pay all associated environmental costs. Because responsibility or consequence for self-directed action lies partly outside the self, an element of externalization is involved. If there are external benefits, such as in public safety, less of the good may be produced than would be the case if the producer were to receive payment for the external benefits to others. Goods and services that involve negative externalities in production, such as those that produce pollution, tend to be overproduced and underpriced since the externality is not being priced into the market.\nPollution can also create costs for the firms producing the pollution. Sometimes firms choose, or are forced by regulation, to reduce the amount of pollution that they are producing. The associated costs of doing this are called abatement costs, or marginal abatement costs if measured by each additional unit. In 2005 pollution abatement capital expenditures and operating costs in the US amounted to nearly $27 billion.\nDirtiest industries.\nThe Pure Earth, an international non-for-profit organization dedicated to eliminating life-threatening pollution in the developing world, issues an annual list of some of the world's most polluting industries. Below is the list for 2016:\nA 2018 report by the Institute for Agriculture and Trade Policy and GRAIN says that the meat and dairy industries are poised to surpass the oil industry as the world's worst polluters.\nFossil fuel related industries.\nOutdoor air pollution attributable to fossil fuel use alone causes ~3.61 million deaths annually, making it one of the top contributors to human death, beyond being a major driver of climate change whereby greenhouse gases are considered per se as a form of pollution &lt;templatestyles src=\"Crossreference/styles.css\" /&gt;.\nSocially optimal level.\nSociety derives some indirect utility from pollution; otherwise, there would be no incentive to pollute. This utility may come from the consumption of goods and services that inherently create pollution (albeit the level can vary) or lower prices or lower required efforts (or inconvenience) to abandon or substitute these goods and services. Therefore, it is important that policymakers attempt to balance these indirect benefits with the costs of pollution in order to achieve an efficient outcome.\nIt is possible to use environmental economics to determine which level of pollution is deemed the social optimum. For economists, pollution is an \"external cost and occurs only when one or more individuals suffer a loss of welfare\". There is a socially optimal level of pollution at which welfare is maximized. This is because consumers derive utility from the good or service manufactured, which will outweigh the social cost of pollution until a certain point. At this point the damage of one extra unit of pollution to society, the marginal cost of pollution, is exactly equal to the marginal benefit of consuming one more unit of the good or service.\nMoreover, the feasibility of pollution reduction rates could also be a factor of calculating optimal levels. While a study puts the global mean loss of life expectancy (LLE; similar to YPLL) from air pollution in 2015 at 2.9 years (substantially more than, for example, 0.3\u2009years from all forms of direct violence), it also indicated that a significant fraction of the LLE is unavoidable in terms of current economical-technological feasibility such as aeolian dust and wildfire emission control.&lt;ref name=\"10.1093/cvr/cvaa025\"&gt;&lt;/ref&gt;\nIn markets with pollution, or other negative externalities in production, the free market equilibrium will not account for the costs of pollution on society. If the social costs of pollution are higher than the private costs incurred by the firm, then the true supply curve will be higher. The point at which the social marginal cost and market demand intersect gives the socially optimal level of pollution. At this point, the quantity will be lower and the price will be higher in comparison to the free market equilibrium. Therefore, the free market outcome could be considered a market failure because it \"does not maximize efficiency\".\nThis model can be used as a basis to evaluate different methods of internalizing the externality, such as tariffs, a Pigouvian tax (such as a carbon tax) and cap and trade systems.\nHistory.\nPrior to 19th century.\nAir pollution has always accompanied civilizations. Pollution started from prehistoric times, when humans created the first fires. According to a 1983 article in the journal \"Science\", soot found on ceilings of prehistoric caves provides ample evidence of the high levels of pollution that was associated with inadequate ventilation of open fires.\nMetal forging appears to be a key turning point in the creation of significant air pollution levels outside the home. Core samples of glaciers in Greenland indicate increases in pollution associated with Greek, Roman, and Chinese metal production.\nThe burning of coal and wood, and the presence of many horses in concentrated areas made the cities the primary sources of pollution. King Edward I of England banned the burning of mineral coal by proclamation in London in 1306, after its smoke became a problem; the fuel was named seacoal at the time, getting its name from the fact that it was delivered from overseas (as opposed to charcoal, which was referred to as \"coal\").\n19th century.\nThe Industrial Revolution gave birth to environmental pollution as we know it today. London also recorded one of the earliest extreme cases of water quality problems with the Great Stink on the Thames of 1858, which led to the construction of the London sewerage system soon afterward. Pollution issues escalated as population growth far exceeded the ability of neighborhoods to handle their waste problem. Reformers began to demand sewer systems and clean water.\nIn 1870, the sanitary conditions in Berlin were among the worst in Europe. August Bebel recalled conditions before a modern sewer system was built in the late 1870s:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Waste-water from the houses collected in the gutters running alongside the curbs and emitted a truly fearsome smell. There were no public toilets in the streets or squares. Visitors, especially women, often became desperate when nature called. In the public buildings the sanitary facilities were unbelievably primitive...As a metropolis, Berlin did not emerge from a state of barbarism into civilization until after 1870.\n20th and 21st century.\nThe primitive conditions were intolerable for a world national capital, and the Imperial German government brought in its scientists, engineers, and urban planners to solve the deficiencies and forge Berlin as the world's model city. A British expert in 1906 concluded that Berlin represented \"the most complete application of science, order and method of public life,\" adding \"it is a marvel of civic administration, the most modern and most perfectly organized city that there is.\"\nThe emergence of great factories and consumption of immense quantities of coal gave rise to unprecedented air pollution, and the large volume of industrial chemical discharges added to the growing load of untreated human waste. Chicago and Cincinnati were the first two American cities to enact laws ensuring cleaner air in 1881. Pollution became a significant issue in the United States in the early twentieth century, as progressive reformers took issue with air pollution caused by coal burning, water pollution caused by bad sanitation, and street pollution caused by the three million horses who worked in American cities in 1900, generating large quantities of urine and manure. As historian Martin Melosi notes, the generation that first saw automobiles replacing horses saw cars as \"miracles of cleanliness\". By the 1940s, automobile-caused smog was a significant issue in Los Angeles.\nOther cities followed around the country until early in the 20th century when the short-lived Office of Air Pollution was created under the Department of the Interior. The cities of Los Angeles experienced extreme smog events and Donora, Pennsylvania, in the late 1940s, serving as another public reminder.\nAir pollution would continue to be a problem in England, especially later during the Industrial Revolution, and extending into the recent past with the Great Smog of 1952. Awareness of atmospheric pollution spread widely after World War II, with fears triggered by reports of radioactive fallout from atomic warfare and testing. Then a non-nuclear event\u2014the Great Smog of 1952 in London\u2014killed at least 4000 people. This prompted some of the first major modern environmental legislation: the Clean Air Act of 1956.\nPollution began to draw significant public attention in the United States between the mid-1950s and early 1970s, when Congress passed the Noise Control Act, the Clean Air Act, the Clean Water Act, and the National Environmental Policy Act. \nSevere incidents of pollution helped increase consciousness. PCB dumping in the Hudson River resulted in a ban by the EPA on consumption of its fish in 1974. National news stories in the late 1970s\u2014especially the long-term dioxin contamination at Love Canal starting in 1947 and uncontrolled dumping in Valley of the Drums\u2014led to the Superfund legislation of 1980. The pollution of industrial land gave rise to the name brownfield, a term now common in city planning.\nThe development of nuclear science introduced radioactive contamination, which can remain lethally radioactive for hundreds of thousands of years. Lake Karachay\u2014named by the Worldwatch Institute as the \"most polluted spot\" on earth\u2014served as a disposal site for the Soviet Union throughout the 1950s and 1960s. Chelyabinsk, Russia, is considered the \"Most polluted place on the planet\".\nNuclear weapons continued to be tested in the Cold War, especially in the earlier stages of their development. The toll on the worst-affected populations and the growth since then in understanding the critical threat to human health posed by radioactivity has also been a prohibitive complication associated with nuclear power. Though extreme care is practiced in that industry, the potential for disaster suggested by incidents such as those at Three Mile Island, Chernobyl, and Fukushima pose a lingering specter of public mistrust. Worldwide publicity has been intense on those disasters. Widespread support for test ban treaties has ended almost all nuclear testing in the atmosphere.\nInternational catastrophes such as the wreck of the Amoco Cadiz oil tanker off the coast of Brittany in 1978 and the Bhopal disaster in 1984 have demonstrated the universality of such events and the scale on which efforts to address them needed to engage. The borderless nature of the atmosphere and oceans inevitably resulted in the implication of pollution on a planetary level with the issue of global warming. Most recently, the term persistent organic pollutant (POP) has come to describe a group of chemicals such as PBDEs and PFCs, among others. Though their effects remain poorly understood owing to a lack of experimental data, they have been detected in various ecological habitats far removed from industrial activity, such as the Arctic, demonstrating diffusion and bioaccumulation after only a relatively brief period of widespread use.\nThe Great Pacific Garbage Patch is a concentration of plastics in the North Pacific Gyre. It and other garbage patches contain debris that can transport invasive species and that can entangle and be ingested by wildlife. Organizations such as 5 Gyres and the Algalita Marine Research Foundation have researched the Great Pacific Garbage Patch and found microplastics in the water.\nPollution introduced by light at night is becoming a global problem, more severe in urban centres, but contaminating also large territories, far away from towns.\nGrowing evidence of local and global pollution and an increasingly informed public over time have given rise to environmentalism and the environmental movement, which generally seek to limit human impact on the environment.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24873", "revid": "50677144", "url": "https://en.wikipedia.org/wiki?curid=24873", "title": "Polearm", "text": "Pole-mounted close combat weapon\nA polearm or pole weapon is a close combat weapon in which the main fighting part of the weapon is fitted to the end of a long shaft, typically of wood, extending the user's effective range and striking power. Polearms are predominantly melee weapons, with a subclass of spear-like designs fit for thrusting and/or throwing. Because many polearms were adapted from agricultural implements or other fairly abundant tools, and contained relatively little metal, they were cheap to make and readily available. When belligerents in warfare had a poorer class who could not pay for dedicated military weapons, they would often appropriate tools as cheap weapons. The cost of training was comparatively low, since these conscripted farmers had spent most of their lives using these \"weapons\" in the fields. This made polearms the favoured weapon of peasant levies and peasant rebellions the world over.\nPolearms can be divided into three broad categories: those designed for extended reach and thrusting tactics used in pike square or phalanx combat; those designed to increase leverage (due to hands moving freely on a pole) to maximize angular force (swinging tactics) against cavalry; and those designed for throwing tactics used in skirmish line combat. The hook on weapons such as the halberd was used for pulling or grappling tactics, especially against horsemen. Because of their versatility, high effectiveness and low cost, there were many variants of polearm, which were much-used weapons on the battlefield. Bills, picks, dane axes, spears, glaives, guandaos, pudaos, pikes, poleaxes, halberds, harpoons, sovnyas, tridents, naginatas, bardiches, war scythes, and lances are all varieties of polearms.\nPolearms were common weapons on post-classical battlefields of Asia and Europe. Their range and impact force made them effective weapons against armoured warriors on horseback, unhorsing the opponent and to some extent effective to penetrate armour. The Renaissance saw a plethora of varieties. Polearms in modern times are largely constrained to ceremonial military units such as the Papal Swiss Guard or Yeomen of the Guard, or traditional martial arts. Chinese martial arts in particular have preserved a wide variety of weapons and techniques.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nClassification difficulties.\nThe classification of polearms can be difficult, and European weapon classifications in particular can be confusing. This can be due to a number of factors, including uncertainty in original descriptions, changes in weapons or nomenclature through time, mistranslation of terms, and the well-meaning inventiveness of later experts. For example, the word \"halberd\" is also used to translate the Chinese ji and also a range of medieval Scandinavian weapons as described in sagas, such as the atgeir. As well, all polearms are developed from three early tools (the axe, the scythe, and the knife) and one weapon, the spear.\nIn the words of the arms expert Ewart Oakeshott,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Staff-weapons in Medieval or Renaissance England were lumped together under the generic term \"staves\" but when dealing with them in detail we are faced with terminological difficulty. There never seems to have been a clear definition of what was what; there were apparently far fewer staff-weapons in use than there were names to call them by; and contemporary writers up to the seventeenth century use these names with abandon, calling different weapons by the same name and similar weapons by different names. To add to this, we have various nineteenth century terminologies used by scholars. We must remember too that any particular weapon ... had everywhere a different name.\nWhile men-at-arms may have been armed with custom designed military weapons, militias were often armed with whatever was available. These may or may not have been mounted on poles and described by one of more names. The problems with precise definitions can be inferred by a contemporary description of Royalist infantry which were engaged in the Battle of Birmingham (1643) during the first year of English Civil War (in the early modern period). The infantry regiment that accompanied Prince Rupert's cavalry were armed:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;with pikes, half-pikes, halberds, hedge-bills, Welsh hooks, clubs, pitchforks, with chopping-knives, and pieces of scythes.\nList of polearms.\nAncient polearms.\nAsian.\nDagger-axe.\nThe \"dagger-axe\" (Chinese: \u6208; pinyin: g\u0113; Wade\u2013Giles: ko; sometimes confusingly translated \"halberd\") is a type of weapon that was in use from Shang dynasty until at least Han dynasty China. It consists of a dagger-shaped blade made of bronze (or later iron) mounted by the tang to a perpendicular wooden shaft: a common Bronze Age infantry weapon, also used by charioteers. Some dagger axes include a spear-point. There is a (rare) variant type with a divided two-part head, consisting of the usual straight blade and a scythe-like blade. Other rarities include archaeology findings with two or sometimes three blades stacked in line on top of a pole, but were generally thought as ceremonial polearms. Though the weapon saw frequent use in ancient China, the use of the dagger-axe decreased dramatically after the Qin and Han dynasties. The \"ji\" combines the dagger axe with a spear. By the post-classical Chinese dynasties, with the decline of chariot warfare, the use of the dagger-axe was almost nonexistent.\n\"Ji\".\nThe \"ji\" (Chinese: \u621f) was created by combining the dagger-axe with a spear. It was used as a military weapon at least as early as the Shang dynasty until the end of the Northern and Southern dynasties.\n\"Ngao\".\nThe \"ngao\" or \"ngau\" (\u0e07\u0e49\u0e32\u0e27,\u0e02\u0e2d\u0e07\u0e49\u0e32\u0e27) is a Thai polearm that was traditionally used by elephant-riding infantry and is still used by practitioners of \"krabi krabong\". Known in Malay as a \"dap\", it consists of a wooden shaft with a curved blade fashioned onto the end, and is similar in design to the Korean \"woldo\". Usually, it also had a hook (\u0e02\u0e2d) between the blade and shaft used for commanding the elephant. The elephant warrior used the \"ngao\" like a blade from atop an elephant or horse during battle.\nPost-classical polearms.\nEuropean.\nDane axe.\nThe Dane axe is a weapon with a heavy crescent-shaped head mounted on a haft in length. Originally a Viking weapon, it was adopted by the Anglo-Saxons and Normans in the 11th century, spreading through Europe in the 12th and 13th centuries. Variants of this basic weapon continued in use in Scotland and Ireland into the 16th century. A form of 'long axe'.\nSparth axe.\nIn the 13th century, variants on the Danish axe are seen. Described in English as a \"sparth\" (from the Old Norse ) or \"pale-axe\", the weapon featured a larger head with broader blade, the rearward part of the crescent sweeping up to contact (or even be attached to) the haft.\nIn Ireland, this axe was known as a \"sparr axe\". Originating in either Western Scotland or Ireland, the \"sparr\" was widely used by the galloglass. Although sometimes said to derive from the Irish for a joist or beam, a more likely definition is as a variant of sparth. Although attempts have been made to suggest that the sparr had a distinctive shaped head, illustrations and surviving weapons show there was considerable variation and the distinctive feature of the weapon was its long haft.\nFauchard.\nA fauchard is a type of polearm which was used in medieval Europe from the 11th through the 14th centuries. The design consists of a curved blade put atop a pole. The blade bears a moderate to strong curve along its length; however, unlike a bill or \"guisarme\", the cutting edge is on the convex side.\nGuisarme.\nA \"guisarme\" (sometimes \"gisarme\", \"giserne\" or \"bisarme\") is a polearm used in Europe primarily between 1000 and 1400. It was used primarily to dismount knights and horsemen. Like most polearms it was developed by peasants by combining hand tools with long poles, in this case by putting a pruning hook onto a spear shaft. While early designs were simply a hook on the end of a long pole, later designs implemented a small reverse spike on the back of the blade. Eventually weapon makers incorporated the usefulness of the hook in a variety of different polearms and \"guisarme\" became a catch-all for any weapon that included a hook on the blade. Ewart Oakeshott has proposed an alternative description of the weapon as a crescent shaped socketed axe.\nGlaive.\nA \"glaive\" is a polearm consisting of a single-edged tapering blade similar in shape to a modern kitchen knife on the end of a pole. The blade was around long, on the end of a pole long. However, instead of having a tang like a sword or naginata, the blade is affixed in a socket-shaft configuration similar to an axe head, both the blade and shaft varying in length. Illustrations in the 13th century Maciejowski Bible show a short staffed weapon with a long blade used by both infantry and cavalry. Occasionally glaive blades were created with a small hook or spike on the reverse side. Such glaives are named glaive-guisarme.\nVoulge.\nA \"voulge,\" also known as \"vouge\", is a single or double edged blade tapering to a sharp point, mounted onto the extremity of a shaft with a singular socket under the blade. It can be fitted with langlets to further stabilize it, similar to poleaxes, as well as a rondel on the shaft to protect the hand. \nSimilar in construction to a Glaive, it was used extensively in France and Burgundy throughout the 15th century\nSv\u00e4rdstav.\nA \"sv\u00e4rdstav\" (literally sword-staff) is a Swedish medieval polearm that consists of a two-edged sword blade attached to a staff. The illustrations often show the weapon being equipped with sword-like quillons. The illustrations sometimes show a socket mount and reinforcing langets being used, but sometimes they are missing; it is possible this weapon was sometimes manufactured by simply attaching an old sword blade onto a long pole on its tang, not unlike a \"naginata\".\nAsian.\nNaginata.\nA \"naginata\" (\u306a\u304e\u306a\u305f or \u8599\u5200) is a Japanese polearm that was traditionally used by members of the samurai class. A naginata consists of a wood shaft with a curved blade on the end. Usually it also had a sword-like guard (tsuba) between the blade and shaft. It was mounted with a tang and held in place with a pin or pins, rather than going over the shaft using a socket. The naginata was developed based on the hoko yari from the 1st millennium AD or the tachi from the late Heian period (794\u20131185). It was appreciated by samurai who fought on foot as a weapon to maintain optimal distance from the enemy in close combat, but after the Onin War in the 15th century, large groups of mobilized infantry called asigaru began to equip themselves with yari (spear) yumi (longbow) and tanegashima (gun), making naginata and tachi (long sword) obsolete on the battlefield and often replaced with nagamaki and katana. From the Edo period, naginata has been recognized as a martial art practiced by women in the samurai class.\nYari.\nA \"yari\" (\u3084\u308a or \u69cd) is a Japanese polearm that was traditionally used by members of the samurai class. There are various types of yari, which have different names depending on the shape of the blade attached to the end of the wooden shaft. For example, 'Jumonji yari' refers to a yari with a cross-shaped blade, and 'Sasaho yari' refers to a yari with a blade shaped like a sasa leaf. During the Sengoku period, a large group of ashigaru in a formation used yari as one of their main weapons and exerted tremendous power on the battlefield. Honda Tadakatsu a vassal of Tokugawa Ieyasu, had gained a reputation as a master of one of the Three Great Spears of Japan, Tonbokiri.\nWoldo.\nThe Korean \"woldo\" was a variation of the Chinese guan dao. It was originally used by the post-classical Shilla warriors. Wielding the woldo took time due to its weight, but in the hands of a trained soldier, the woldo was a fearsome, agile weapon famous for enabling a single soldier to cut down ranks of infantrymen. The woldo was continually in use for the military in Korea with various modifications made over the decades. Unlike the Chinese with the guan dao, the Koreans found the woldo unwieldy on horseback, and thus, it was specifically tailored to the needs of infantrymen. The Joseon government implemented rigorous training regimens requiring soldiers to be proficient with swordsmanship, and the use of the woldo. Though it was never widely used as a standard weapon, the woldo saw action on many fronts and was considered by many Korean troops to be a versatile weapon. Recently, a contemporary revival in various martial arts in Korea has brought interest into the application of the woldo and its history.\nGuandao.\nA \"guandao\" or \"kwan tou\" is a type of Chinese polearm. In Chinese, it is properly called a \"yanyue dao\" (\u5043\u6708\u5200), 'reclining moon blade'. Some believed it comes from the late Han Era and was supposedly used by the late Eastern Han dynasty general Guan Yu, but archaeological findings have shown that Han dynasty armies generally used straight, single-edged blades, and curved blades came several centuries later. There is no reason to believe their polearms had curved blades on them. Besides, historical accounts of the Three Kingdoms era describe Guan Yu thrusting his opponents down (probably with a spear-like polearm) in battle, not cutting them down with a curved blade. The guandao is also known as the \"chun qiu da dao\" ('spring autumn great knife'), again probably related to the depiction of Guan Yu in the Ming dynasty novel \"Romance of the Three Kingdoms\", but possibly a Ming author's invention. It consists of a heavy blade mounted atop a wooden or metal pole with a pointed metal counter weight used for striking and stabbing on the opposite end.\nThe blade is very deep and curved on its face, resembling a Chinese saber, or dao. Variant designs include rings along the length of the straight back edge, as found in the nine-ring guandao. The \"elephant\" guandao's tip curls into a rounded spiral, while the dragon head guandao features a more ornate design.\nPodao.\nA \"podao\", 'long-handled sabre', is a Chinese polearm, also known as the zhan ma dao ('horsecutter sabre'), which has a lighter blade and a ring at the end. A podao is an infantryman's weapon, mainly used for cutting the legs off oncoming charging horses to bring down the riders.\nFangtian ji.\nIn the Song dynasty, several weapons were referred to as \"ji\", but they were developed from spears, not from ancient \"ji\". One variety was called the \"qinglong ji\" (), and had a spear tip with a crescent blade on one side. Another type was the \"fangtian ji\" (), which had a spear tip with crescent blades on both sides. They had multiple means of attack: the side blade or blades, the spear tip, plus often a rear counterweight that could be used to strike the opponent. The way the side blades were fixed to the shaft differs, but usually there were empty spaces between the pole and the side blade. The wielder could strike with the shaft, with the option of then pulling the weapon back to hook with a side blade; or, he could slap his opponent with the flat side of the blade to knock him off his horse.\nBarcha and Ballam.\nThe \"Barcha\" is a type of lance with a wooden handle, once common in South Asia in the 16th century and was popular weapon of choice in the Maratha Empire. Variations of the \"barcha\" is the hand-like \"Karpa Barcha\" and the serpent-like \"Nagni Barcha\". Another variant included the \"Ballam\", a javelin effective at bringing down infantry and cavalry at a distance. \"Nagni Barcha\" is identified as the weapon used by the Sikh warrior Bhai Bachittar Singh to kill a drunken Mughal war elephant at the Siege of Lohgarh.\nLater polearms.\nEuropean.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCorseque.\nA \"corseque\" has a three-bladed head on a haft which, like the partisan, is similar to the winged spear or spetum in the later Middle Ages. It was popular in Europe in the 16th and 17th centuries. Surviving examples have a variety of head forms but there are two main variants, one with the side blades (known as flukes or wings) branching from the neck of the central blade at 45 degrees, the other with hooked blades curving back towards the haft. The corseque is usually associated with the rawcon, ranseur and runka. Another possible association is with the \"three-grayned staff\" listed as being in the armoury of Henry VIII in 1547 (though the same list also features 84 rawcons, suggesting the weapons were not identical in 16th century English eyes). Another modern term used for particularly ornate-bladed corseques is the \"chauve-souris\".\nHalberd.\nA \"halberd\" is a two-handed polearm that came to prominent use during the 14th and 15th centuries but has continued in use as a ceremonial weapon to the present day. First recorded as \"hellembart\" in 1279, the word \"halberd\" possibly comes from the German words \"Halm\" (staff) or \"Helm\" (helmet), and \"Barte\" (axe). The halberd consists of an axe blade topped with a spike mounted on a long shaft. It always has a hook or thorn on the back side of the axe blade for grappling mounted combatants. The Swiss were famous users of the halberd in the medieval and renaissance eras, with various cantons evolving regional variations of the basic form.\nPoleaxe.\nIn the 14th century, the basic long axe gained an armour-piercing spike on the back and another on the end of the haft for thrusting. This is similar to the pollaxe of 15th century. The poleaxe emerged in response to the need for a weapon that could penetrate plate armour and featured various combinations of an axe-blade, a back-spike and a hammer. It was the favoured weapon for men-at-arms fighting on foot into the sixteenth century.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24874", "revid": "43237577", "url": "https://en.wikipedia.org/wiki?curid=24874", "title": "PHD", "text": "PHD or PhD may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "24875", "revid": "95921", "url": "https://en.wikipedia.org/wiki?curid=24875", "title": "Personal jurisdiction", "text": "Court jurisdiction over the parties of a lawsuit\nPersonal jurisdiction is a court's jurisdiction over the \"parties\", as determined by the facts in evidence, which bind the parties to a lawsuit, as opposed to subject-matter jurisdiction, which is jurisdiction over the \"law\" involved in the suit. Without personal jurisdiction over a party, a court's rulings or decrees cannot be enforced upon that party, except by comity; i.e., to the extent that the sovereign which has jurisdiction over the party allows the court to enforce them upon that party. A court that has \"personal\" jurisdiction has both the authority to rule on the law and facts of a suit and the power to enforce its decision upon a party to the suit. In some cases, territorial jurisdiction may also constrain a court's reach, such as preventing hearing of a case concerning events occurring on foreign territory between two citizens of the home jurisdiction. A similar principle is that of standing or \"locus standi\", which is the ability of a party to demonstrate to the court sufficient connection to and harm from the law or action challenged to support that party's participation in the case.\nInternational principles.\nSince there is no world government which all countries recognize to arbitrate disputes over jurisdiction, sovereign powers can find themselves in conflict over which is the more appropriate venue to hear a case, or which country's laws should apply. These conflicts are sometimes resolved \"de facto\" by physical factors, such as which country has physical possession of a defendant or property, or sometimes by use of physical police or military force to seize people or property. A country with loose rule of law \u2013 for example an absolute monarchy with no independent judiciary \u2013 may arbitrarily choose to assert jurisdiction over a case without citing any particular justification. Such assertion can cause problems, such as encouraging other countries to take arbitrary actions over foreign citizens and property, or even provoking skirmishes or armed conflict.\nIn practice, many countries operate by one or another principle, either in written law or in practice, which communicate when the country will and will not assert jurisdiction:\nDifferent principles are applied by different countries, and different principles may be applied by the same country in different circumstances. Determination of whether or not a court has jurisdiction to hear a case is the first stage of a conflict of laws proceeding, potentially followed by choice of law to determine which jurisdiction's laws apply. Executive prosecutorial authority and foreign policy also play a role in scope and practical impact of jurisdiction choices.\nAny assertion of jurisdiction based on anything other than the territorial principle is known as extraterritorial jurisdiction. Prosecution of a case against an out-of-territory defendant is known as assertion of long-arm jurisdiction.\nWhen a person commits a crime in a foreign country against the laws of that country, usually the host country is responsible for prosecution. The Vienna Convention on Consular Relations requires that the host country notify the foreign embassy, potentially allowing the foreign country to assist in legal defense and monitor conditions of detention. (Most countries protect their citizens against foreign powers in general.)\nForeign diplomats enjoy diplomatic immunity in many countries based on the Vienna Convention on Diplomatic Relations or bilateral agreement, and foreign military personnel may be subject to the jurisdiction of their home country based on a status of forces agreement or Visiting Forces Agreement.\nIf a person is not physically present in the country which wishes to prosecute a case, that country may either wait until the person enters the national territory, or pursue extradition by legal or extralegal means, and with or without a general extradition treaty. Some countries (like China) prefer to prosecute their own citizens for crimes committed abroad rather than extradite them. Other countries defer to the host country.\nWhen a crime is committed outside the territory of any country, such as in Antarctica, on watercraft in international waters, on aircraft in international airspace, and on spacecraft, jurisdiction is usually determined by the nationality of defendants or victims, or by the flag state of the vessel. This is determined by the admiralty law of the countries involved and in international agreements.\nHistory in English and U.S. law.\nThe concept of personal jurisdiction in English law has its origin in the idea that a monarch could not exercise power over persons or property located outside of his or her kingdom. To some degree, this was a \"de facto\" rule; the monarch's men could not arrest people or seize property outside the kingdom without risking physical conflict with the soldiers and police of other kingdoms. Slowly this principle was incorporated into written law, but problems arose in cases where property owners could not be sued because they had left the kingdom or had died and therefore were not present within the kingdom at the time they were being sued. To solve this problem, the courts created another type of jurisdiction, called \"quasi in rem\", that is, jurisdiction over the land itself, even if the person who owned the land was not in the country. However, this jurisdiction was limited to the settlement of debts owed by the owner of the land.\nIn the United States, the exercise of personal jurisdiction by a court must both comply with Constitutional limitations, and be authorized by a statute. In the United Kingdom, the exercise of personal jurisdiction does not need a statutory basis, since the United Kingdom does not have a written constitution.\nUnited States.\nThe intersection of American federalism and the rules and theories of jurisdiction inherited from the common law of England has resulted in a highly complex body of law respecting personal jurisdiction in the United States. These rules limit both state and federal courts in their ability to hear cases.\nPrinciples.\nThree fundamentals of personal jurisdiction constrain the ability of courts in the United States to bind individuals or property to its decisions: consent, power, and notice.\nConsent.\nThe American legal system is an adversarial system. Civil actions cannot be initiated by third parties, nor by the court itself \"sua sponte\", but must be filed by the aggrieved party who seeks redress, the plaintiff. Generally, the action is initiated in the jurisdiction where the event occurred, where the defendant can be served or where the parties have agreed to have the case located. The filing of a complaint or \"prayer for relief\" is a voluntary action by the plaintiff, and as a necessary corollary to this, the plaintiff impliedly consents to be bound by the judgment of the court. \nThe doctrine of consent also applies to the person against whom relief is sought, the defendant. When a defendant responds to a civil action and actively litigates its merits without raising a timely objection to personal jurisdiction, that omission is treated as the defendant's implied consent to the jurisdiction of the court.\nConsent may also derive from a pre-litigation agreement by the parties, such as a forum selection clause in a contract (not to be confused with a choice of law clause). Doctrines such as claim preclusion normally prevent re-litigation of failed claims or defenses in alternative forums. Claim preclusion does not, however, prevent the refiling of a claim that was originally filed in a court that lacked personal jurisdiction over the defendant.\nPower.\nIn cases where a defendant challenges personal jurisdiction, a court may still exercise personal jurisdiction if it has independent power to do so. This power is founded in the inherent nature of the State: sovereignty over secular affairs within its territory.\nNotice.\nThe Fifth and Fourteenth Amendment to the United States Constitution preserve the right of the individual to \"due process\". Due process requires that notice be given in a manner \"reasonably calculated\" to inform a party of the action affecting him. Originally, \"Notice\" (and the power of the State) was often exercised more forcefully, the defendant in a civil case sometimes being seized and brought before the court under a writ of \"capias ad respondendum\". Notice in such a case is inferred from consent of the defendant to go with the officer. Nowadays, when exercising power over an individual without consent, notice is usually given by formal delivery of suitable papers to the defendant (service of process).\nHistorical background: territorial jurisdiction.\nOriginally, jurisdiction over parties in the United States was determined by strict interpretation of the geographic boundaries of each state's sovereign power. In \"Pennoyer v. Neff\", the Supreme Court discussed that though each state ceded certain powers (e.g. foreign relations) to the Federal Government or to no entity at all (e.g. the powers that are eliminated by the protections of the bill of rights), the states retained all the other powers of sovereignty, including the exclusive power to regulate the affairs of individuals and property within its territory. Necessarily following from this, one state's exercise of power could not infringe upon the sovereignty of another state. Thus, Constitutional limitations applied to the validity of state court judgments.\nThree types of jurisdiction developed, collectively termed territorial jurisdiction because of their reliance upon territorial control: \"in personam\" jurisdiction, \"in rem\" jurisdiction, and \"quasi in rem\" jurisdiction. Some sources refer to all three types of territorial jurisdiction as personal jurisdiction, since most actions against property (in rem jurisdiction) bear, in the end, upon the rights and obligations of persons. Others continue to recognize the traditional distinction between personal jurisdiction and jurisdiction over property, even after \"Shaffer v. Heitner\" (discussed below).\nIn personam jurisdiction referred to jurisdiction over a particular person (or entity, such as a company). \"In personam\" jurisdiction, if held by a state court, permitted that court to rule upon any case over which it otherwise held jurisdiction. Under territorial jurisdiction, pure \"in personam\" jurisdiction could only be established by serving notice upon the individual while that individual was within the territory of the state.\nIn rem jurisdiction referred to jurisdiction over a particular piece of property, most commonly real estate or land. Certain cases, notably government suits for unpaid property taxes, proceed not against an individual but against their property directly. Under territorial jurisdiction, \"in rem\" jurisdiction could be exercised by the courts of a state by seizing the property in question. Since an actual tract of land could not literally be brought into a courtroom as a person could, this was effected by giving notice upon the real property itself. \"In rem\" jurisdiction was thus supported by the assumption that the owner of that property, having a concrete economic interest in the property, had a duty to look after the affairs of their property, and would be notified of the pending case by such seizure. \"In rem\" jurisdiction was limited to deciding issues regarding the specific property in question.\nQuasi in rem jurisdiction involved the seizure of property held by the individual against whom the suit was brought, and attachment of that property to the case in question. This form of territorial jurisdiction developed from the rationale of \"in rem\" jurisdiction, namely that seizure of the property was reasonably calculated to inform an individual of the proceedings against them.\nOnce a valid judgment was obtained against an individual, however, the plaintiff could pursue recovery against the assets of the defendant regardless of their location, as other states were obligated by the Full Faith and Credit Clause of the Constitution to recognize such a judgment (i.e. had ceded their power to refuse comity to fellow states of the Union). Violations by a rogue state could be checked via collateral attack: when a plaintiff sought recovery against a defendant's assets in another state, that state could refuse judgment on the grounds that the original judgment was invalid.\nDifficulties in applying \"Pennoyer\" territorial jurisdiction.\nFollowing \"Pennoyer\", extreme applications of territorial jurisdiction revealed imperfections in the doctrine, and societal changes began to present new problems as the United States' national economy became more integrated by increasingly efficient multi-state transportation technology and business practices.\nWhile determining the physical location of an individual for the purposes of \"in personam\" jurisdiction was easy enough, applying the same principle to non-physical entities became difficult. Courts were presented with the question of where a company was present and amenable to service for the purpose of \"in personam\" jurisdiction over the company.\nExtension of \"quasi in rem\" jurisdiction led to extreme results that threatened the justification for the jurisdiction. Bearing in mind that territorial jurisdiction existed in a pre-industrial society where transportation across the country was difficult, long, and potentially treacherous, and consider the hypothetical wherein Alice owes Bob money, and Bob owes Carmel, a resident of New York, money. Carmel seeks to recover on Bob's debt to Carmel, however cannot do so because Bob avoids Carmel by traveling to California. Alice, however, happens to travel through New York. Carmel serves notice upon Alice, and attaches Alice's debt to Bob (considered to be property within the state) to the proceeding. Alice can no more certainly provide notice to Bob in California than Carmel could provide, and the transient and involuntary exposure of Bob to being hauled into court in New York by this attachment seems to erode the original rationale of \"quasi in rem\" jurisdiction.\nThe US Supreme Court largely abolished the exercise of jurisdiction on the basis of \"quasi in rem\" in \"Shaffer v. Heitner\", except in exceptional circumstances, which sometimes would arise while dealing with real property such as land, and when the owner of the land cannot be found.\nModern Constitutional doctrine: \"International Shoe\" doctrine.\nIn the modern era, the reach of personal jurisdiction has been expanded by judicial re-interpretation and legislative enactments. Under the new and current doctrine, a state court may only exert personal jurisdiction over an individual or entity with \"sufficient minimal contacts\" with the forum state such that the particular suit \"does not offend 'traditional notions of fair play and justice.'\" The \"minimum contacts\" must be purposefully directed towards the state by the defendant. This jurisdiction was initially limited to the particulars of the \"International Shoe Co. v. Washington\" holding, that is to jurisdictional inquiries regarding companies, but was soon extended to apply to all questions of personal jurisdiction. When an individual or entity has no \"minimum contacts\" with a forum State, the Due Process Clause of the Fourteenth Amendment prohibits that State from acting against that individual, or entity. The lack of \"minimum contacts\" with the owner of property also constitutionally prohibits action against that property (in rem jurisdiction) even when the property is located within the forum state.\nWhat constitutes sufficient \"minimum contacts\" has been delineated in numerous cases which followed the \"International Shoe\" decision. For example, in \"Hanson v. Denckla\", the Court proclaimed the \"unilateral activity of those who claim some relationship with a nonresident cannot satisfy the requirement of contact with the forum State. The application of that rule will vary with the nature and quality of the defendant's activity, but it is essential in each case that there be some act by which the defendant purposefully avails itself of the privilege of conducting activities within the forum State, thus invoking the benefits and protection of its laws.\"\nThe additional requirement of \"'purposeful availment' ensures that a defendant will not be hauled into a jurisdiction solely as a result of 'random,' 'fortuitous,' or 'attenuated' contacts, or of the unilateral activity of another party or a third person\". Jurisdiction may, however, be exercised, under some circumstances, even though the defendant never physically entered the forum state.\nIn addition, the claim must arise from those contacts that the defendant had with the forum state. In addition to the minimum contacts test asserted in \"International Shoe\", the assertion of specific personal jurisdiction must be reasonable. The Court in \"World-Wide Volkswagen Corp. v. Woodson\" asserted a five-part test for determining if the assertion of personal jurisdiction in a forum state was reasonable. This test considers: the burden on the defendant from litigating in the forum state; the interest of the forum state in having the case adjudicated there; the interests of the plaintiff in adjudicating in the forum state; the interests of the inter-state judiciary\u2014that is, that a court's assertion of personal jurisdiction over an out-of state defendant would not overreach and preempt the interests and judicial sovereignty of another state; and the interests in preserving the judicial integrity of the several states\u2014that is, ensuring one court's assertion of personal jurisdiction over an out of state defendant does not violate the Due Process Clause of the Fourteenth Amendment.\nGeneral v. specific.\nIn the 21st century, the Supreme Court began to develop an important distinction between specific and general forms of personal jurisdiction. In the 2011 case of \"Goodyear Dunlop Tires Operations, S. A. v. Brown\", Justice Ginsburg in her opinion for a unanimous court held that for a forum state to exercise general personal jurisdiction over claims that do not arise out of or relate to the defendant's actual contacts with the state, the defendant's contacts with the state must be so systematic and continuous that the defendant may be regarded as \"essentially at home\" in the state. This holding was reaffirmed in 2014 by the Supreme Court in \"Daimler AG v. Bauman\" and again in 2017 in \"BNSF Railway Co. v. Tyrrell\".\nThis series of landmark cases implied that general personal jurisdiction cannot be constitutionally asserted over most corporate defendants outside of the states in which they are incorporated or headquartered. This left plaintiffs in most cases with specific personal jurisdiction, which rests upon whether the plaintiff's claims \"arise out of or relate to\" the defendant's contacts to the forum state. In \"Bristol-Myers Squibb Co. v. Superior Court\" (2017), the Supreme Court held that in consolidated mass tort complex litigation in state courts, out-of-state plaintiffs cannot piggyback on in-state plaintiffs' claims to establish the forum state's jurisdiction over the defendant because the out-of-state plaintiffs' claims do not \"arise out of or relate to\" the defendant's contacts with the forum. \nHowever, in \"Ford Motor Co. v. Montana Eighth Judicial Dist.\" (2021), the Supreme Court rejected the argument that the phrase \"arise out of or relate to\" requires plaintiffs to show direct causation between the defendant's forum contacts and their claims (i.e., that the plaintiffs actually bought allegedly defective cars in the forum state because of the defendant's marketing in that state). Rather, to exercise specific personal jurisdiction, it is sufficient for the plaintiff to show that the defendant's contacts were systematic enough to establish a \"strong relationship among the defendant, the forum, and the litigation\", such that the defendant was on notice that it could be sued in the forum state.\nStatutory authorization.\nWhile the \"Pennoyer\" and \"International Shoe\" doctrines limit the maximum power of a sovereign state, courts must also have authorization from their own state to actually exercise power on behalf of that state; an individual state may choose to not grant its courts the full power that the state is constitutionally permitted to exercise. Similarly, the jurisdiction of federal courts (other than the Supreme Court) may rest upon and is bounded by the Constitution, but it is actually created and authorized by federal statutes. Thus, a particular exercise of personal jurisdiction must not only be permitted by constitutional doctrine, but be supported by statutory authorization as well. Under \"Pennoyer\", personal jurisdiction was authorized by statutes authorizing service of process, but these methods of service were often lacking because they required such service to be effected by officers of the state, such as sheriffs \u2013 an untenable method for defendants located outside of the state but still subject to jurisdiction due to their contacts with the state. Subsequent to the development of the \"International Shoe\" doctrine, states have enacted so-called long-arm statutes, by which courts in a state can exercise jurisdiction over a party located outside the state. \nThe doctrine of \"International Shoe\" applies only in cases where the defendant has no physical presence in the forum state. If the defendant is physically present and is served within the state, then \"tag jurisdiction\" applies. The Supreme Court reaffirmed the notion of \"tag jurisdiction\" over nonresident defendants in \"Burnham v. Superior Court of California\". \nRelationship to venue.\nVenue and personal jurisdiction are closely related for practical purposes. A lawyer should usually perform joint analysis of personal jurisdiction and venue issues. Personal jurisdiction is largely a constitutional requirement, though also shaped by state long-arm statutes and Rule 4 of the Federal Rules of Civil Procedure, while venue is purely statutory.\nIt is possible for either venue or personal jurisdiction to preclude a court from hearing a case. Consider these examples:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24877", "revid": "13974845", "url": "https://en.wikipedia.org/wiki?curid=24877", "title": "Pell's equation", "text": "Type of Diophantine equation\nPell's equation, also called the Pell\u2013Fermat equation, is any Diophantine equation of the form formula_1 where \"n\" is a given positive nonsquare integer, and integer solutions are sought for \"x\" and \"y\". In Cartesian coordinates, the equation is represented by a hyperbola; solutions occur wherever the curve passes through a point whose \"x\" and \"y\" coordinates are both integers, such as the trivial solution with \"x\"\u00a0=\u00a01 and \"y\"\u00a0=\u00a00. Joseph Louis Lagrange proved that, as long as \"n\" is not a perfect square, Pell's equation has infinitely many distinct integer solutions. These solutions may be used to accurately approximate the square root of\u00a0\"n\" by rational numbers of the form\u00a0\"x\"/\"y\".\nThis kind of equation was first studied extensively in India starting with Brahmagupta, who found an integer solution to formula_2 in his \"Br\u0101hmasphu\u1e6dasiddh\u0101nta\" circa 628. Bhaskara\u00a0II in the 12th century and Narayana Pandit in the 14th century both found general solutions to Pell's equation and other quadratic indeterminate equations. Bhaskara\u00a0II is generally credited with developing the \"chakravala\" method, building on the work of Jayadeva and Brahmagupta. Solutions to specific examples of Pell's equation, such as the Pell numbers arising from the equation with \"n\"\u00a0=\u00a02, had been known for much longer, since the time of Pythagoras in Greece and a similar date in India. William Brouncker was the first European to solve Pell's equation. The name of Pell's equation arose from Leonhard Euler mistakenly attributing Brouncker's solution of the equation to John Pell.\nHistory.\nSpecial cases.\nAs early as 400 BC in India and Greece, mathematicians studied the numbers arising from the \"n\"\u00a0=\u00a02 case of Pell's equation,\nformula_3\nand from the closely related equation\nformula_4\nbecause of the connection of these equations to the square root of 2. Indeed, if \"x\" and \"y\" are positive integers satisfying this equation, then \"x\"/\"y\" is an approximation of . The numbers \"x\" and \"y\" appearing in these approximations, called side and diameter numbers, were known to the Pythagoreans, and Proclus observed that in the opposite direction these numbers obeyed one of these two equations. Similarly, Baudhayana discovered that \"x\" = 17, \"y\" = 12 and \"x\" = 577, \"y\" = 408 are two solutions to the Pell equation, and that 17/12 and 577/408 are very close approximations to the square root of 2.\nLater, Archimedes approximated the square root of 3 by the rational number 1351/780. Although he did not explain his methods, this approximation may be obtained in the same way, as a solution to Pell's equation.\nLikewise, Archimedes's cattle problem\u2014an ancient word problem about finding the number of cattle belonging to the sun god Helios\u2014can be solved by reformulating it as a Pell's equation. The manuscript containing the problem states that it was devised by Archimedes and recorded in a letter to Eratosthenes, and the attribution to Archimedes is generally accepted today.\nGeneral case.\nAround AD 250, Diophantus considered the equation\nformula_5\nwhere \"a\" and \"c\" are fixed numbers, and \"x\" and \"y\" are the variables to be solved for.\nThis equation is different in form from Pell's equation but equivalent to it.\nDiophantus solved the equation for (\"a\",\u00a0\"c\") equal to (1,\u00a01), (1,\u00a0\u22121), (1,\u00a012), and (3,\u00a09). Al-Karaji, a 10th-century Persian mathematician, worked on similar problems to Diophantus.\nIn Indian mathematics, Brahmagupta discovered that\nformula_6\na form of what is now known as Brahmagupta's identity. Using this, he was able to \"compose\" triples formula_7 and formula_8 that were solutions of formula_9, to generate the new triples\n formula_10 and formula_11\nNot only did this give a way to generate infinitely many solutions to formula_12 starting with one solution, but also, by dividing such a composition by formula_13, integer or \"nearly integer\" solutions could often be obtained. For instance, for formula_14, Brahmagupta composed the triple (10,\u00a01,\u00a08) (since formula_15) with itself to get the new triple (192,\u00a020,\u00a064). Dividing throughout by 64 (\"8\" for formula_16 and formula_17) gave the triple (24,\u00a05/2,\u00a01), which when composed with itself gave the desired integer solution (1151,\u00a0120,\u00a01). Brahmagupta solved many Pell's equations with this method, proving that it gives solutions starting from an integer solution of formula_9 for \"k\" = \u00b11, \u00b12, or \u00b14.\nThe first general method for solving the Pell's equation (for all \"N\") was given by Bh\u0101skara\u00a0II in 1150, extending the methods of Brahmagupta. Called the chakravala (cyclic) method, it starts by choosing two relatively prime integers formula_19 and formula_20, then composing the triple formula_21 (that is, one which satisfies formula_22) with the trivial triple formula_23 to get the triple formula_24, which can be scaled down to\nformula_25\nWhen formula_26 is chosen so that formula_27 is an integer, so are the other two numbers in the triple. Among such formula_26, the method chooses one that minimizes formula_29 and repeats the process. This method always terminates with a solution. Bhaskara used it to give the solution \"x\"\u00a0=\u00a0, \"y\"\u00a0=\u00a0 to the \"N\"\u00a0=\u00a061 case.\nSeveral European mathematicians rediscovered how to solve Pell's equation in the 17th century. Pierre de Fermat found how to solve the equation and in a 1657 letter issued it as a challenge to English mathematicians. In a letter to Kenelm Digby, Bernard Fr\u00e9nicle de Bessy said that Fermat found the smallest solution for \"N\" up to 150 and challenged John Wallis to solve the cases \"N\" = 151 or 313. Both Wallis and William Brouncker gave solutions to these problems, though Wallis suggests in a letter that the solution was due to Brouncker.\nJohn Pell's connection with the equation is that he revised Thomas Branker's translation of Johann Rahn's 1659 book \"Teutsche Algebra\" into English, with a discussion of Brouncker's solution of the equation. Leonhard Euler mistakenly thought that this solution was due to Pell, as a result of which he named the equation after Pell.\nThe general theory of Pell's equation, based on continued fractions and algebraic manipulations with numbers of the form formula_30 was developed by Lagrange in 1766\u20131769. In particular, Lagrange gave a proof that the Brouncker\u2013Wallis algorithm always terminates.\nSolutions.\nFundamental solution via continued fractions.\nLet formula_31 denote the unique sequence of convergents of the regular continued fraction for formula_32. Then the pair of positive integers formula_33 solving Pell's equation and minimizing \"x\" satisfies \"x\"1 = \"hi\" and \"y\"1 = \"ki\" for some \"i\". This pair is called the \"fundamental solution\". The sequence of integers formula_34 in the regular continued fraction of formula_32 is always eventually periodic. It can be written in the form formula_36, where formula_37 denotes integer floor, and the sequence formula_38 repeats infinitely. Moreover, the tuple formula_39 is palindromic, the same left-to-right or right-to-left. \nThe fundamental solution is\nformula_40\nThe computation time for finding the fundamental solution using the continued fraction method, with the aid of the Sch\u00f6nhage\u2013Strassen algorithm for fast integer multiplication, is within a logarithmic factor of the solution size, the number of digits in the pair formula_33. However, this is not a polynomial-time algorithm because the number of digits in the solution may be as large as \u221a\"n\", far larger than a polynomial in the number of digits in the input value \"n\".\nAdditional solutions from the fundamental solution.\nOnce the fundamental solution is found, all remaining solutions may be calculated algebraically from\nformula_42\nexpanding the right side, equating coefficients of formula_32 on both sides, and equating the other terms on both sides. This yields the recurrence relations\nformula_44\nformula_45\nConcise representation and faster algorithms.\nAlthough writing out the fundamental solution (\"x\"1, \"y\"1) as a pair of binary numbers may require a large number of bits, it may in many cases be represented more compactly in the form\nformula_46\nusing much smaller integers \"a\"\"i\", \"b\"\"i\", and \"c\"\"i\".\nFor instance, Archimedes' cattle problem is equivalent to the Pell equation formula_47, the fundamental solution of which has digits if written out explicitly. However, the solution is also equal to\nformula_48\nwhere\nformula_49 \nand formula_50 and formula_51 only have 45 and 41 decimal digits respectively.\nMethods related to the quadratic sieve approach for integer factorization may be used to collect relations between prime numbers in the number field generated by \u221a\"n\" and to combine these relations to find a product representation of this type. The resulting algorithm for solving Pell's equation is more efficient than the continued fraction method, though it still takes more than polynomial time. Under the assumption of the generalized Riemann hypothesis, it can be shown to take time\nformula_52\nwhere \"N\"\u00a0=\u00a0log\u00a0\"n\" is the input size, similarly to the quadratic sieve.\nQuantum algorithms.\nHallgren showed that a quantum computer can find a product representation, as described above, for the solution to Pell's equation in polynomial time. Hallgren's algorithm, which can be interpreted as an algorithm for finding the group of units of a real quadratic number field, was extended to more general fields by Schmidt and V\u00f6llmer.\nExample.\nAs an example, consider the instance of Pell's equation for \"n\" = 7; that is,\nformula_53\nThe continued fraction of formula_54 has the form formula_55. Since the period has length formula_56, which is an even number, the convergent producing the fundamental solution is obtained by truncating the continued fraction right before the end of the first occurrence of the period: formula_57.\nThe sequence of convergents for the square root of seven are\nApplying the recurrence formula to this solution generates the infinite sequence of solutions\n(1, 0); (8, 3); (127, 48); (2024, 765); (32257, 12192); (514088,\u00a0194307); (8193151,\u00a03096720); (130576328,\u00a049353213);\u00a0... (sequence (\"x\") and (\"y\") in OEIS)\nFor the Pell's equation\nformula_58\nthe continued fraction formula_59 has a period of odd length. For this the fundamental solution is obtained by truncating the continued fraction right before the second occurrence of the period formula_60. Thus, the fundamental solution is formula_61.\nThe smallest solution can be very large. For example, the smallest solution to formula_62 is (,\u00a0), and this is the equation which Frenicle challenged Wallis to solve. Values of \"n\" such that the smallest solution of formula_63 is greater than the smallest solution for any smaller value of \"n\" are\n 1, 2, 5, 10, 13, 29, 46, 53, 61, 109, 181, 277, 397, 409, 421, 541, 661, 1021, 1069, 1381, 1549, 1621, 2389, 3061, 3469, 4621, 4789, 4909, 5581, 6301, 6829, 8269, 8941, 9949,\u00a0... (sequence in the OEIS).\nList of fundamental solutions of Pell's equations.\nThe following is a list of the fundamental solution to formula_64 with \"n\" \u2264 128. When \"n\" is an integer square, there is no solution except for the trivial solution (1,\u00a00). The values of \"x\" are sequence and those of \"y\" are sequence in OEIS.\nConnections.\nPell's equation has connections to several other important subjects in mathematics.\nAlgebraic number theory.\nPell's equation is closely related to the theory of algebraic numbers, as the formula\nformula_65\nis the norm for the ring formula_66 and for the closely related quadratic field formula_67. Thus, a pair of integers formula_68 solves Pell's equation if and only if formula_69 is a unit with norm 1 in formula_66. Dirichlet's unit theorem, that all units of formula_66 can be expressed as powers of a single fundamental unit (and multiplication by a sign), is an algebraic restatement of the fact that all solutions to the Pell's equation can be generated from the fundamental solution. The fundamental unit can in general be found by solving a Pell-like equation but it does not always correspond directly to the fundamental solution of Pell's equation itself, because the fundamental unit may have norm \u22121 rather than 1 and its coefficients may be half integers rather than integers.\nChebyshev polynomials.\nDemeyer mentions a connection between Pell's equation and the Chebyshev polynomials:\nIf formula_72 and formula_73 are the Chebyshev polynomials of the first and second kind respectively, then these polynomials satisfy a form of Pell's equation in any polynomial ring formula_74, with formula_75:\nformula_76\nThus, these polynomials can be generated by the standard technique for Pell's equations of taking powers of a fundamental solution:\nformula_77\nIt may further be observed that if formula_78 are the solutions to any integer Pell's equation, then formula_79 and formula_80.\nContinued fractions.\nA general development of solutions of Pell's equation formula_64 in terms of continued fractions of formula_32 can be presented, as the solutions \"x\" and \"y\" are approximates to the square root of \"n\" and thus are a special case of continued fraction approximations for quadratic irrationals.\nThe relationship to the continued fractions implies that the solutions to Pell's equation form a semigroup subset of the modular group. Thus, for example, if \"p\" and \"q\" satisfy Pell's equation, then\nformula_83\nis a matrix of unit determinant. Products of such matrices take exactly the same form, and thus all such products yield solutions to Pell's equation. This can be understood in part to arise from the fact that successive convergents of a continued fraction share the same property: If \"p\"\"k\"\u22121/\"q\"\"k\"\u22121 and \"p\"\"k\"/\"q\"\"k\" are two successive convergents of a continued fraction, then the matrix\nformula_84\nhas determinant (\u22121)\"k\".\nSmooth numbers.\nSt\u00f8rmer's theorem applies Pell equations to find pairs of consecutive smooth numbers, positive integers whose prime factors are all smaller than a given value. As part of this theory, St\u00f8rmer also investigated divisibility relations among solutions to Pell's equation; in particular, he showed that each solution other than the fundamental solution has a prime factor that does not divide\u00a0\"n\".\nThe negative Pell's equation.\nThe negative Pell's equation is given by\nformula_85\nand has also been extensively studied. It can be solved by the same method of continued fractions and has solutions if and only if the period of the continued fraction has odd length. A necessary (but not sufficient) condition for solvability is that \"n\" is not divisible by 4 or by a prime of form 4\"k\"\u00a0+\u00a03. Thus, for example, \"x\"2\u00a0\u2212\u00a03\u00a0\"y\"2\u00a0=\u00a0\u22121 is never solvable, but \"x\"2\u00a0\u2212\u00a05\u00a0\"y\"2\u00a0=\u00a0\u22121 may be.\nThe first few numbers \"n\" for which \"x\"2\u00a0\u2212\u00a0\"n\u00a0y\"2\u00a0=\u00a0\u22121 is solvable are 1 (with only one trivial solution) and\n2, 5, 10, 13, 17, 26, 29, 37, 41, 50, 53, 58, 61, 65, 73, 74, 82, 85, 89, 97,\u00a0... (sequence in the OEIS)\nwith infinitely many solutions. The solutions of the negative Pell's equation for formula_86 are:\nLet formula_87. The proportion of square-free \"n\" divisible by \"k\" primes of the form 4\"m\"\u00a0+\u00a01 for which the negative Pell's equation is solvable is at least \"\u03b1\". When the number of prime divisors is not fixed, the proportion is given by 1\u00a0\u2212\u00a0\"\u03b1.\"\nIf the negative Pell's equation does have a solution for a particular \"n\", its fundamental solution leads to the fundamental one for the positive case by squaring both sides of the defining equation:\nformula_88\nimplies\nformula_89\nAs stated above, if the negative Pell's equation is solvable, a solution can be found using the method of continued fractions as in the positive Pell's equation. The recursion relation works slightly differently however. Since formula_90, the next solution is determined in terms of formula_91 whenever there is a match, that is, when formula_92 is odd. The resulting recursion relation is (modulo a minus sign, which is immaterial due to the quadratic nature of the equation)\nformula_93\nformula_94\nwhich gives an infinite tower of solutions to the negative Pell's equation (except for formula_95).\nGeneralized Pell's equation.\nThe equation\nformula_96\nis called the generalized (or general) Pell's equation. The equation formula_97 is the corresponding Pell's resolvent. A recursive algorithm was given by Lagrange in 1768 for solving the equation, reducing the problem to the case formula_98. Such solutions can be derived using the continued-fractions method as outlined above.\nIf formula_99 is a solution to formula_100 and formula_101 is a solution to formula_102 then formula_103 such that formula_104 is a solution to formula_105, a principle named the \"multiplicative principle\". The solution formula_103 is called a \"Pell multiple\" of the solution formula_99.\nThere exists a finite set of solutions to formula_105 such that every solution is a Pell multiple of a solution from that set. In particular, if formula_109 is the fundamental solution to formula_97, then each solution to the equation is a Pell multiple of a solution formula_68 with formula_112 and formula_113, where formula_114.\nIf \"x\" and \"y\" are positive integer solutions to the Pell's equation with formula_115, then formula_116 is a convergent to the continued fraction of formula_117.\nSolutions to the generalized Pell's equation are used for solving certain Diophantine equations and units of certain rings, and they arise in the study of SIC-POVMs in quantum information theory.\nThe equation\nformula_118\nis similar to the resolvent formula_119 in that if a minimal solution to formula_120 can be found, then all solutions of the equation can be generated in a similar manner to the case formula_121. For certain formula_122, solutions to formula_119 can be generated from those with formula_120, in that if formula_125 then every third solution to formula_120 has formula_127 even, generating a solution to formula_119.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24879", "revid": "1315808081", "url": "https://en.wikipedia.org/wiki?curid=24879", "title": "Telephone card", "text": "Card used to pay for telephone services\nA telephone card (also telecard, teleca, calling card or phone card for short) is a credit card-size plastic or paper card used to pay for telephone services (often international or long-distance calling). It is not necessary to have the physical card except with a stored-value system; knowledge of the access telephone number to dial and the PIN is sufficient. Standard cards which can be purchased and used without any sort of account facility give a fixed amount of credit and are discarded when used up; rechargeable cards can be topped up, or collect payment in arrears. The system for payment and the way in which the card is used to place a telephone call vary from card to card.\nCalling cards usually come equipped with PIN for user protection and security. Most companies require user to enter the PIN before granting access to the calling card's funds. PINs often are printed on a piece of paper found inside the calling card's packaging. Once the users makes their first call, some companies offer the option of eliminating the PIN altogether to speed up the calling process. Companies that sell virtual calling cards online typically send the PIN via email.\nStored-value phone cards.\nA stored-value phone card stores the available credit balance in an analog or digital memory physically embedded in the card. This balance can be read by a public payphone when the card is inserted into the card reader. This is superficially similar to a bank automated teller machine, but a stored-value card is more closely analogous to a change purse. While ATMs (as well as the remote memory systems discussed below) use the card merely to identify the associated account and record changes in a central database, stored-value systems make a physical alteration to the card, or write data to an embedded chip or magnetic stripe to reflect the new balance after a call. Some magnetic cards also show the remaining value.\nUsed primarily for payphones, stored-value systems avoid the time lag and expense of communication with a central database, which would have been technically complex before the 1990s. \nThere are several ways in which the value can be encoded on the card:\nThe earliest system used a magnetic stripe as information carrier, similar to the technology of ATMs and key cards, and the first magnetic strip phonecard, manufactured by SIDA, was issued in 1976 in Italy.\nThe next technology used optical storage. Optical phonecards get their name from optical structure embossed inside the cards. This optical structure is heated and destroyed after use of the units. Visible marks are left on the top of the cards, so that the user can see the balance of remaining units. Optical cards were produced by Landis+Gyr and Sodeco from Switzerland and were popular early phonecards in many countries with first optical phonecards successfully introduced in 1977 in Belgium. Such technology was very secure and not easily hackable but chip cards phased out the optical phone cards around the world and the last Landis+Gyr factory closed in May 2006 when optical phonecards were still in use in few countries like Austria, Israel and Egypt.\nThe third system of stored-value phone cards are smart cards and use an embedded microchip. These were first launched on a large scale in 1986 in Germany by Deutsche Bundespost after three years of testing, and in France by France T\u00e9l\u00e9com. Many other countries followed suit, including Ireland in 1990 and the UK circa 1994\u20131995, which phased out the old green Landis+Gyr cards in favor of the chip (smart) cards. The initial microchips were easy to hack, typically by scratching off the programming-voltage contact on the card, which rendered the phone unable to reduce the card's value after a call. But by the mid-to-late 1990s, highly secure technology aided the spread of chip phonecards worldwide. \nBy the 2010s, the rise in the use of mobile phones led to the withdrawal of phone cards by some operators, with BT in the UK withdrawing phone cards from sale in 2012.\nRemote memory systems.\nMaking a remote memory prepaid or calling card call requires the user to make two calls. It is necessary to dial an access telephone number to connect to the calling card system. There are several methods. One is via a toll-free number, with larger companies offering this internationally. Access through a local number has become increasingly popular in recent years. Toll-free calls are paid for by the recipient (the calling card company), which passes on the cost through higher call charges; total cost of a call to the user is often lower using a local number. When travelling through several local areas a toll-free service may be preferable.\nOnce connected to the access number, the account is identified by keying in a PIN (the most popular method) or by swiping a card with embedded chip or magnetic stripe. After validation the balance remaining on the card may be announced, and the desired number may be keyed in. The available minutes may be announced, and the call is connected. Many cards make a verbal announcement if credit is running out.\nPrepaid or calling cards are usually much cheaper than other telephone services, particularly for travelers who do not have easy access to other services. Hotel telephones can be very expensive, particularly for long-distance calls. Cellular services are flexible, but may attract high roaming charges away from the home area.\nTelephone accounts symbolized by a card.\nThe second main technology of phonecards is remote memory, which uses a toll or toll-free access number to reach the database and check for balance on product.\nThe first public prepaid remote memory phonecard was issued in the United States in December 1980 by Phone Line. As telecom industries around the world became deregulated, remote memory cards were issued in various countries. Remote memory phonecards can be used from any tone-mode phone and do not require special card readers. Since remote memory cards are more accessible and have lower costs, remote memory phone cards have proliferated. However, the utility of these cards is reduced by the large number of digits that need to be entered during usage. To call a long-distance number, the user first dials the local access number, then keys in the secret code, followed by the actual long-distance number. Based on the long-distance number entered, the time remaining on the card is announced, and the call is finally processed through.\nRemote memory phonecards are in essence text; requiring an access number, a unique PIN and instructions. Therefore, the instructions can be printed on virtually anything, or can be delivered via e-mail or the Internet. Currently many websites post phone card details through e-mail.\nPhone cards are available in most countries in retail stores, retail chains and commonly post offices or corner stores. In general, remote memory phonecards can be issued by any company and come in countless varieties. They can focus on calling to certain countries or regions and have specific features such as rechargeability, pinless dial, speed dial and more. Phone cards may have connection fees, taxes and maintenance fees, all influencing the rates.\nAccounts without a card (Virtual phonecards).\nSince the early 2000s calling card service providers have introduced calling accounts not associated with a physical card. Calling accounts can be purchased over the Internet using credit cards and are instantly delivered to the customer via e-mail. This e-mail contains the PIN and instructions for using the service. The service may be prepaid, or may take payment from a credit card or by direct debit. Some prepaid card companies allow accounts to be recharged online manually or automatically via a method called auto-top-up.\nSome virtual cards offer PINless Dialing, either by dialling a number unique to the customer, or by recognising the telephone number which originated the call by Caller ID and relating it to the appropriate account. Some virtual phone cards allow customers to view their call detail reports (CDRs) online by logging into their account.\nThe virtual phonecard has become a multi-billion US dollar industry as of 2009, with a number of large corporations and smaller dot com companies. While long-distance inland calls have been offered by calling cards, by the mid-2000s conventional carriers reduced their rates to be competitive; however in many countries calling-card type indirect services can be much cheaper than normal calls.\nPhonecard as an artifact or collectible.\nTelecom companies have placed advertising on phonecards, or featured celebrity portraits, artwork, or attractive photography. As the supply of any one design is limited, this has led some people to collect disposable phonecards. Due to the large number of phonecards, collectors prefer to specialize and collect cards in a certain way. Some collect phonecards that have only one specific chip type or were issued in the same country, while others prefer to get one of everything. Online clubs and catalogs provide collectors with detailed information on phonecards. In addition, these clubs include forums to assist with discussions between collectors.\nSupport in telephones.\nMost modern telephones, both mobile and fixed, have memory locations in which telephone numbers can be stored. Some telephones have facilities to make calls through a calling card service whose access details and PIN are also stored in the telephone's memory. This may be implemented in different ways, often by pressing one button before making a call; some telephones support \"chain dialing\", allowing additional numbers to be dialed when on a call (e.g., dial a PIN and a second number after connecting to an access number). So long as long enough sequences can be stored it is possible to store an access number, pause, PIN, and ultimate telephone number in a single normal phone memory location. Software applications which add calling card support are available for a small charge or free for some smartphones.\nNotes and references.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24883", "revid": "6925706", "url": "https://en.wikipedia.org/wiki?curid=24883", "title": "CD-i", "text": "Interactive multimedia and video gaming standard\nThe Compact Disc-Interactive (CD-I, later CD-i) is a digital optical disc data storage format as well as a hardware platform, co-developed and marketed by Dutch company Philips and Japanese company Sony. It was created as an extension of CDDA and CD-ROM and specified in the \"Green Book\" specifications, co-developed by Philips and Sony, to combine audio, text and graphics. The two companies initially expected to impact the education/training, point of sale, and home entertainment industries, but the CD-i is largely remembered today for its video games.\nCD-i media physically have the same dimensions as CD, but with up to of digital data storage, including up to 72 minutes of full motion video. CD-i players were usually standalone boxes that connect to a standard television; some less common setups included integrated CD-i television sets and expansion modules for personal computers. Most players were created by Philips; the format was licensed by Philips and Microware for use by other manufacturers, notably Sony who released professional CD-i players under the \"Intelligent Discman\" brand. Unlike CD-ROM drives, CD-i players are complete computer systems centered around dedicated Motorola 68000-based microprocessors and its own operating system called CD-RTOS, which is an acronym for \"Compact disc \u2013 Real Time Operating System\".\nMedia released on the format included video games and \"edutainment\" and multimedia reference titles, such as interactive encyclopedias and museum tours \u2013 which were popular before public Internet access was widespread \u2013 as well as business software. Philips's CD-i system also implemented Internet features, including subscriptions, web browsing, downloading, e-mail, and online play. Philips's aim with its players was to introduce interactive multimedia content for the general public by combining features of a CD player and game console, but at a lower price than a personal computer with a CD-ROM drive.\nAuthoring kits for the format were released first in 1988, and the first player aimed for home consumers, Philips's CDI 910/205, was released in late 1991. It was initially priced around US$, and was capable of playing interactive CD-i discs, Audio CDs, CD+G (CD+Graphics), Photo CDs and Video CDs (VCDs), though the latter required an optional \"Digital Video Card\" to provide MPEG-1 decoding. Initially marketed to consumers as \"home entertainment systems\", and in later years as a \"gaming platform\", CD-i did not manage to find enough success in the market, and was mostly abandoned by Philips in 1996. The format continued to be supported for licensees for a few more years after.\nSpecifications.\nDevelopment of the \"Compact Disc-Interactive\" format began in 1984 (two years after the launch of the Compact disc) and it was first publicly announced by Philips and Sony \u2013 two of the largest electronics companies of the time \u2013 at Microsoft's CD-ROM Conference in Seattle in March 1986. Microsoft's CEO Bill Gates had no idea beforehand that the format was under development. The \"Green Book\", formally known as the \"CD-i Full Functional Specification\", defined the format for interactive, multimedia compact discs designed for CD-i players. The \"Green Book\" specification also defines a whole hardware set built around the Motorola 68000 microprocessor family, and an operating system called CD-RTOS based on OS-9, a product of Microware. The standard was originally not freely available and had to be licensed from Philips. However, the 1994 version of the standard was eventually made available free by Philips.\nCD-i discs conform to the \"Red Book\" specification of audio CDs (CD-DA). Tracks on a CD-i's program area can be CD-DA tracks or CD-i tracks, but the first track must always be a CD-i track, and all CD-i tracks must be grouped together at the beginning of the area. CD-i tracks are structured according to the CD-ROM XA specification (using either Mode 2 Form 1 or Mode 2 Form 2 modes), and have different classes depending on their contents (\"data\", \"video\", \"audio\", \"empty\" and \"message\"). \"Message\" sectors contain audio data to warn users of CD players that the track they are trying to listen to is a CD-i track and not a CD-DA track. The CD-i specification also specifies a file system similar to (but not compatible with) ISO 9660 to be used on CD-i tracks, as well as certain specific files that are required to be present in a CD-i compatible disc. Compared to the \"Yellow Book\" (specification for CD-ROM), the \"Green Book\" CD-i standard solves synchronisation problems by interleaving audio and video information on a single track.\nThe format quickly gained interest from large manufacturers, and received backing from many particularly Matsushita. Although a joint effort, Philips eventually took over the majority of CD-i development at the expense of Sony. Philips invested many millions in developing titles and players based on the CD-i specification. Initially branded \"CD-I\", the name was changed in 1991 to \"CD-i\" with a lowercase i.\nThe CD-i Ready format is a type of bridge format, also designed by Philips, that defines discs compatible with CD Digital audio players and CD-i players. This format puts CD-i software and data into the pregap of Track 1.\nThe CD-i Bridge format, defined in Philips' White Book, is a transitional format allowing bridge discs to be played both on CD-ROM drives and on CD-i players.\nThe CD-i Digital Video format was launched in 1993 containing movies that could be played on CD-i players with a Digital Video Cartridge add-on. The format was incompatible with Video CD (VCD), although a CD-i unit with the DVC could play both formats. Only about 20 movies were released on the format and it was stopped in 1995 in favor of VCD.\nCommercial software.\nCD-i software was typically developed using authoring tools from one of two companies: OptImage, which offered the Balboa Runtime Libraries and MediaMogul, and Script Systems, which produced ABCD-I. Much of the CD-i software was promoted or published by American Interactive Media (AIM), a joint venture between Philips and its subsidiary PolyGram, formed in Los Angeles in 1986 to publish CD-i consumer software. Philips Interactive Media was similarly launched in Europe.\nPhilips initially marketed CD-i as a family entertainment product and avoided emphasizing video games to prevent competition with game consoles. Early releases focused on educational, music, and self-improvement titles, with relatively few games, many of which were adaptations of board games such as \"Connect Four\". However, the system struggled in the multimedia device market against low-cost PCs, and games became its best-selling software. By 1993, Philips encouraged MS-DOS and console developers to create games, introduced a $250 peripheral with expanded memory and full-motion video support, and added a second controller port to new consoles for multiplayer games.\nAttempts to establish a foothold in the games market were largely unsuccessful, as the system, designed primarily as a multimedia player, was underpowered compared to other gaming platforms. Notable CD-i games included entries in Nintendo franchises, though not developed by Nintendo: \"Hotel Mario\" and three \"Zelda\" titles: ', ', and \"Zelda's Adventure\". These were made possible by an earlier agreement between Nintendo and Philips to develop a CD-based add-on for the Super Nintendo Entertainment System, which never progressed beyond the prototype stage. However, the agreement granted Philips the right to develop games using Nintendo characters.\nAs announced at CES 1992, numerous full-motion video titles appeared, including \"Dragon's Lair\" and \"Mad Dog McCree\". One, \"\", is considered one of the stronger CD-i titles and was later ported to PC. \"Electronic Gaming Monthly\" noted that CD-i\u2019s full-motion video capabilities were its strongest feature; however, most titles required the MPEG upgrade card to take advantage of them.\nPhilips also released CD-i adaptations of popular TV game shows, including \"Jeopardy!\" (hosted by Alex Trebek), \"Name That Tune\" (hosted by Bob Goen), and two versions of \"The Joker's Wild\" (an adult version with Wink Martindale and a kids' version with Marc Summers). All North American CD-i games, except \"Name That Tune\", featured Charlie O'Donnell as announcer. The Netherlands released its own version of \"Lingo\" in 1994.\nIn 1993, American musician Todd Rundgren created the first fully interactive music CD, \"No World Order\", for CD-i, enabling over 15,000 points of customization. Dutch Eurodance duo 2 Unlimited released a CD-i compilation album, \"Beyond Limits\" (1994), featuring standard CD tracks and CD-i-exclusive media.\nCD-i featured a range of children's edutainment titles, including \"Busytown\" and \"The Berenstain Bears\". By mid-1996, the U.S. CD-i software market had dried up, though Philips continued publishing titles in Europe. Philips then shifted focus to kiosk and industrial multimedia applications.\nIn later years, homebrew developers released new CD-i titles, including \"Frog Feast\" (2005), \"Super Quartet\" (2018), and \"Nobelia\" (2022).\nPlayer models.\nCD-i compatible models were released in Belgium, Canada, France, Germany, Hong Kong, Luxembourg, the Netherlands, Japan, Singapore, the United Kingdom, the United States, and the former European Eastern Bloc. Shortly before it was discontinued, It was reported to be released further in Brazil, India and Australia in the \"coming months\", with plans to also introduce it in China, South Africa, Indonesia and the Philippines.\nPhilips models.\nIn addition to consumer models, professional and development CD-i players were marketed by Philips Interactive Media Systems and its VARs. The first CD-i system, developed in collaboration with Kyocera, was introduced in 1988 as the Philips 180/181/182 modular system. In the United States, many players were sold rebranded under the Magnavox name, a Philips subsidiary.\nPhilips released several CD-i player series, targeting different consumer and professional markets:\nOther CD-i-compatible systems included hybrid devices such as the FW380i, a mini-stereo system with a built-in CD-i player; the 21TCDi30, a television with integrated CD-i functionality; and the CD-i/PC 2.0, a CD-i module with an ISA interface for IBM-compatible 486 PCs.\nOther manufacturers.\nIn addition to Philips, several manufacturers produced CD-i players some of which were still on sale years after Philips itself abandoned the format. These included:\nBefore the commercial debut of the CD-i format, several other companies expressed interest in producing players or developed prototypes that were never released. These included Panasonic (originally a major backer of the format), Pioneer, JVC, Toshiba, Epson, Ricoh, Fujitsu, Samsung, and Yamaha. Additionally, Sanyo displayed a prototype portable CD-i player in 1992.\nTeleCD-i and CD-MATICS.\nRecognizing the growing need among marketers for networked multimedia, Philips partnered in 1992 with Amsterdam-based CDMATICS to develop TeleCD-i (also TeleCD). In this concept, the CD-i player is connected to a network such as PSTN or Internet, enabling data-communication and rich media presentation. Dutch grocery chain Albert Heijn and mail-order company were early adopters and introduced award-winning TeleCD-i applications for their home-shopping and home-delivery services. CDMATICS also developed the special Philips TeleCD-i Assistant and a set of software tools to help the worldwide multimedia industry to develop and implement TeleCD-i. TeleCD-i is the world's first networked multimedia application at the time of its introduction. In 1996, Philips acquired source code rights from CDMATICS.\nCD-Online.\nInternet services on the CD-i devices were facilitated by the use of an additional hardware modem and \"CD-Online\" disc (renamed Web-i in the US), which Philips initially released in Britain in 1995 for $150 US. This service provided the CD-i with full internet access (with a 14.4k modem), including online shopping, email, and support for networked multiplayer gaming on select CD-i games. The service required a CD-i player with DV cartridge, and an \"Internet Starter Kit\" which initially retailed for \u00a399.99. It was advertised as bringing \"full Internet access to the living room on TV screens\". Andy Stout, a writer for the official CD-i magazine, explained CD-Online: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It is very much Internet-lite. The main advantages are that it's cheap - probably working out at a third of the cost of a PC or Mac solution - and incredibly user-friendly. The downside though is using a browser that doesn't support Netscape, and coping with all the drawbacks of the machine's minuscule memory - you can only ever access 10 articles on Usenet at a time, it'll only support 80 bookmarks maximum and for all that trouble all your saved games, preferences, and high scores will have been written over in RAM. ... It's got the full access right now but with only about 40% of the functionality, which will probably be fine for people who don't know what they're missing. But the virtual keyboard is a complete nightmare to use ... The CD-Online service went live in the UK on October 25, 1995 and in March 1996 in the Netherlands (for 399 guilders), and also released in Belgium. The system was reportedly scheduled to launch in the US as \"Web-i\" in August 1996. The domain cd-online.co.uk, which was used for the British CD-Online service, went offline in 2000. The Dutch domain cd-online.nl stopped updating too but remained online until 2007.\nOnly one game was released that supported CD-Online, the first-person shooter game \"RAM Raid\". Players from any country in the world could compete against each other as long as they had a copy of the game.\nReception and market performance.\nPhilips had invested heavily in the CD-i format and system, and it was often compared with the Commodore CDTV as a single combination of computer, CD, and television. The product was touted as a single machine for home entertainment connected to a standard TV and controlled by a regular remote control \u2013 although the format was noted to have various non-entertainment business opportunities too, such as travel and tourism or the military. In 1990, Peugeot used CD-i for its point of sale application promoting its then-new 605 automobile, and it was also at the time used by fellow car manufacturer Renault for staff training programmes, and in Japan by the Ministry of Trade and Industry for an exhibition there. A Philips executive, Gaston Bastiaens, quoted in 1990 \"CD-I will be 'the medium' for entertainment, education and information in the 90's.\". Sony introduced its three portable CD-i players in June 1990, pitching them as \"picture books with sound\".\nThe ambitious CD-i format had initially created much interest after its 1986 announcement, both in the west and in Japan, buoyed by the success of the CD. However, after repeated delays (hardware was first intended to be ready and shipped by Christmas 1987) interest was slowly lost. Electronic Arts for instance was enthusiastic about CD-i and formed a division for the development of video game titles on the format, but it was eventually halted with the intention of resuming when CD-i players would reach the market. The company eventually never resumed CD-i software development when it was released. The delay also gave more attention to the hyped Digital Video Interactive (DVI) in 1987, which demonstrated full screen, full motion video (FMV) using a compression chip on an IBM PC/AT computer. Amid the attention around its potential rival DVI, Philips and Sony decided to find a way to add full screen FMV abilities to the CD-i standard, causing further delay. Meanwhile, the Microsoft-backed CD-ROM standard was improving and solved certain video playback issues that were present on the CD-i \u2013 CD-ROM format products were already on the market by 1987. At the end, CD-ROM standard benefited from the CD-i and DVI mishaps, and by the time CD-i players for consumers were released in 1991, CD-ROM had already become known and established. Ron Gilbert commented in early 1990 \"The CD-I specifications look great, but where are the machines? If they'd come out four years ago, they'd have been hot, but now they're behind the times.\" Another reason that led to fading interest pre-launch was the fact CD-i players would not launch with FMV but instead receive it later through a purchasable add-on cartridge (it was originally expected to come built-in) \u2013 as well as the obsolete Motorola processor, OS-9 software, and a launch price considered high.\nAlthough Philips had aggressively promoted their CD-i products in the U.S., by August 1993 \"Computer Gaming World\" reported that \"skepticism persists about its long-term prospects\" compared to other platforms like IBM PC compatibles, Apple Macintosh, and Sega Genesis. The magazine stated in January 1994 that despite Philips' new emphasis on games \"CD-i is still not the answer for hardcore gamers\", but the console \"may yet surprise us all in the future\". It recommended the CD-i with video cartridge for those needing to buy a new console as \"The price is right and there is more software to support it\", but 3DO Interactive Multiplayer was probably better for those who could wait a few months. The \"Electronic Entertainment\" August 1994 issue noted that the CD-i, along with the Atari Jaguar, neither have an \"effective, let alone innovative\" game library to compete against the then newly released Sega CD.\nAfter being outsold in the market by cheaper multimedia PCs, in 1994 Philips attempted to emphasize CD-i as a game playing machine, but this did not help the situation. An early 1995 review of the system in \"GamePro\" stated that \"inconsistent game quality puts the CD-i at a disadvantage against other high-powered game producers.\" A late 1995 review in \"Next Generation\" criticized both Philips's approach to marketing the CD-i and the hardware itself (\"The unit excels at practically nothing except FMV, and then only with the addition of a $200 digital video cartridge\"). The magazine noted that while Philips had not yet officially discontinued the CD-i, it was dead for all intents and purposes, citing as evidence the fact that though Philips had a large booth at the 1995 Electronic Entertainment Expo, there was no CD-i hardware or software on display. \"Next Generation\" scored the console one out of five stars. Another trouble for Philips in 1995 was the formation of DVD-Video, which promised better quality video compared to Video CD's (VCD) MPEG-1 compression method \u2013 Philips had heavily promoted the CD-i's VCD playing capabilities. Philips Media consolidated its CD-i activities from its Los Angeles office in March 1996. It was reported in October 1996 that Philips was ready to \"call it quits\" in the American market.\nSales.\nIn October 1994, Philips claimed an installed base of one million units for the CD-i worldwide. In 1996, \"The Wall Street Journal\" reported that total US sales amounted to 400,000 units. In the Netherlands, about 60,000 CD-i players were sold by the end of December 1994.\nLegacy.\nAlthough extensively marketed by Philips, notably via infomercial, consumer interest in CD-i titles remained low. By 1994, sales of CD-i systems had begun to slow, and in 1998 the product line was dropped. Plans for a second generation CD-i system were certainly present and Argonaut Software was even designated to design chip sets for the successor to the CD-i. However, company president Cor Boonstra saw no interest in the media area for Philips and so Philips sold everything, including the media subsidiary Polygram.\nThe Dutch half of Philips Media was sold to Softmachine, which released \"The Lost Ride\" on the CD-i as the last product for the CD-i. The French side of the company, who had purchased German publishers Bomico Entertainment Software and Laguna Video Games the year prior, was sold to French publisher Infogrames in June 1997 along with the entire CD-i library as well as German publishers. A CD-ROM add-on for the Super NES, which was announced for development with Nintendo in 1991, was never made. The last CD-i game was \"Solar Crusade\", made by Infogrames and released in 1999.\nAfter its discontinuation, the CD-i was overwhelmingly panned by critics who blasted its graphics, games, and controls. Microsoft CEO Bill Gates admitted that initially he \"was worried\" about the CD-i due to Philips' heavy support for the device and its two-pronged attack on both the games console and PC markets, but that in retrospect, \"It was a device that kind of basically got caught in the middle. It was a terrible game machine, and it was a terrible PC.\" The CD-i's various controllers were ranked the fifth worst video game controller by IGN editor Craig Harris. \"PC World\" ranked it as fourth on their list of \"The 10 Worst Video Game Systems of All Time\". Gamepro.com listed it as number four on their list of \"The 10 Worst-Selling Consoles of All Time.\" In 2008, CNET listed the system on its list of the worst game console(s) ever. In 2007, GameTrailers ranked the Philips CD-i as the fourth worst console of all time in its Top 10 Worst Console lineup.\nIn later retrospective years, the CD-i has become (infamously) best known for its video games, particularly those from the Nintendo-licensed Mario and \"The Legend of Zelda\" series, considered by many to be of poor taste. Games that were most heavily criticized include \"Hotel Mario\", ', ', and \"Zelda's Adventure\". EGM's Seanbaby rated \"The Wand of Gamelon\" as one of the worst video games of all time. However, \"\" was positively received by critics and has often been held up as the standout title for the CD-i.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24884", "revid": "10884281", "url": "https://en.wikipedia.org/wiki?curid=24884", "title": "Peppered moth", "text": "Species of moth\n&lt;templatestyles src=\"Template:Taxobox/core/styles.css\" /&gt;\nThe peppered moth (Biston betularia) is a temperate species of night-flying moth. It is mostly found in the northern hemisphere in places like Asia, Europe and North America. Peppered moth evolution is an example of population genetics and natural selection.\nThe caterpillars of the peppered moth not only mimic the form but also the colour of a twig. Recent research indicates that the caterpillars can sense the twig's colour with their skin and match their body colour to the background to protect themselves from predators.\nDescription.\nThe wingspan ranges from 45\u00a0mm to 62\u00a0mm (median 55\u00a0mm). It is relatively stout-bodied, with forewings relatively narrow-elongate. The wings are white, \"peppered\" with black, and with more-or-less distinct cross lines, also black. These transverse wing lines and \"peppered\" maculation (spotting) can also, in rare instances, be gray or brown; the spotting pattern, in particularly very rare cases, is sometimes a combination of brown and black/gray. The black speckling varies in amount, in some examples it is almost absent, whilst in others it is so dense that the wings appear to be black sprinkled with white. The antennae of males are strongly bipectinate. Prout (1912\u201316) gives an account of the forms and congeners.\nDistribution.\n\"Biston betularia\" is found in China (Heilongjiang, Jilin, Inner Mongolia, Beijing, Hebei, Shanxi, Shandong, Henan, Shaanxi, Ningxia, Gansu, Qinghai, Xinjiang, Fujian, Sichuan, Yunnan,\nTibet), Russia, Mongolia, Japan, North Korea, South Korea, Nepal, Kazakhstan, Kyrgyzstan, Turkmenistan, Georgia, Azerbaijan, Armenia, Europe and North America.\nEcology and life cycle.\nIn Great Britain and Ireland, the peppered moth is univoltine (\"i.e.\", it has one generation per year), whilst in south-eastern North America it is bivoltine (two generations per year). The lepidopteran life cycle consists of four stages: ova (eggs), several larval instars (caterpillars), pupae, which overwinter in the soil, and imagines (adults). During the day, the moths typically rest on trees, where they are preyed on by birds.\nThe caterpillar is a twig mimic, varying in colour between green and brown. On a historical note, it was one of the first animals to be identified as being camouflaged with countershading to make it appear flat (shading being the main visual cue that makes things appear solid), in a paper by Edward Bagnall Poulton in 1887. Research indicates that the caterpillars can sense the twig's colour with their skin and match their body colour to the background to protect themselves from predators, an ability to camouflage themselves also found in cephalopods, chameleons and some fish, although this colour change is rather slower in the caterpillars.\nIt goes into the soil late in the season, where it pupates in order to spend the winter. The imagines emerge from the pupae between late May and August, the males slightly before the females (this is common and expected from sexual selection). They emerge late in the day and dry their wings before flying that night.\nThe males fly every night of their lives in search of females, whereas the females only fly on the first night. Thereafter, the females release pheromones to attract males. Since the pheromone is carried by the wind, males tend to travel up the concentration gradient, i.e., toward the source. During flight, they are subject to predation by bats. The males guard the female from other males until she lays the eggs. The female lays about 2,000 pale-green ovoid eggs about 1\u00a0mm in length into crevices in bark with her ovipositor.\nResting behaviour.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nA mating pair or a lone individual will spend the day hiding from predators, particularly birds. Males stay with the female to ensure paternity. Peppered moths generally rest in the upper part of the trees at unexposed positions. They use three main types of site: (1) a few inches below a branch-trunk joint on a tree trunk where the moth is in shadow; (2) on the underside of branches; and (3) on foliate twigs. Peppered moth researcher Michael Majerus notes:\nCreationist critics of the peppered moth have often pointed to a statement made by Clarke \"et al\". (1985): \"...\u00a0In 25 years we have only found two \"betularia\" on the tree trunks or walls adjacent to our traps, and none elsewhere\". The reason now seems obvious. Few people spend their time looking for moths up in the trees. That is where peppered moths rest by day.\nFurther support for these resting positions is given from experiments watching captive moths taking up resting positions in both males (Mikkola, 1979; 1984) and females (Liebert and Brakefield, 1987).\nMajerus, \"et al.\", (2000) have shown that peppered moths are cryptically camouflaged against their backgrounds when they rest in the boughs of trees. It is clear that in human visible wavelengths, \"typica\" are camouflaged against lichens and \"carbonaria\" against plain bark. However, birds are capable of seeing ultraviolet light that humans cannot see. Using an ultraviolet-sensitive video camera, Majerus et al. showed that \"typica\" reflect ultraviolet light in a speckled fashion and are camouflaged against crustose lichens common on branches, both in ultraviolet and human-visible wavelengths. However, \"typica\" are not as well camouflaged against foliose lichens common on tree trunks; though they are camouflaged in human wavelengths, in ultraviolet wavelengths, foliose lichens do not reflect ultraviolet light.\nDuring an experiment in Cambridge over the seven years 2001\u20132007 Majerus noted the natural resting positions of peppered moths, and of the 135 moths examined over half were on tree branches, mostly on the lower half of the branch, 37% were on tree trunks, mostly on the north side, and only 12.6% were resting on or under twigs.\nPolymorphism.\nIntroduction on forms.\nThere are several melanic and non-melanic morphs of the peppered moth. These are controlled genetically. A particular colour morph can be indicated in a standard way by following the species name in the form \"morpha \"morph name\"\". The use of \"form\" in the method of \"Biston betularia\" f. \"formname\" in detailing these variations is also a widespread practice.\nThese forms are often accidentally elevated to subspecies status when they appear in literature. Not adding the \"f.\" (forma) or morpha implies that the taxon is a subspecies instead of a form, as in \"Biston betularia carbonaria\" instead of \"Biston betularia\" f. \"carbonaria\". Rarely, forms have been elevated to species status, as in \"Biston carbonaria\". Either of these two circumstances might lead to the erroneous belief that speciation was involved in the observed evolution of the peppered moth. This is not the case; individuals of each morph interbreed and produce fertile offspring with individuals of all other morphs; hence there is only one peppered moth species.\nBy contrast, different subspecies of the same species can theoretically interbreed with one another and will produce fully fertile and healthy offspring, but in practice do not, as they live in different regions or reproduce in different seasons. Full-fledged species are either unable to produce fertile and healthy offspring, or do not recognize each other's courtship signals, or both.\nEuropean breeding experiments have shown that in \"Biston betularia betularia\", the allele for melanism producing morpha \"carbonaria\" is controlled by a single locus. The melanic allele is dominant to the non-melanic allele. This situation is, however, somewhat complicated by the presence of three other alleles that produce indistinguishable morphs of morpha \"medionigra\". These are of intermediate dominance, but this is not complete (Majerus, 1998).\nForm names.\nIn continental Europe, there are three morphs: the white morph typica (syn. morpha/f. \"betularia\"), the dark melanistic morph carbonaria (syn. \"doubledayaria\"), and an intermediate form medionigra.\nIn Britain, the typical white morph is known as typica, the melanic morph is carbonaria, and the intermediate phenotype is named insularia.\nIn North America, the melanic black morph is morpha swettaria. In \"Biston betularia cognataria\", the melanic allele (producing morpha \"swettaria\") is similarly dominant to the non-melanic allele. There are also some intermediate morphs. In Japan, no melanic morphs have been recorded; they are all morpha \"typica\".\nEvolution.\nThe evolution of the peppered moth over the last two hundred years has been studied in detail.\nAt the start of this period, the vast majority of peppered moths had light coloured wing patterns which effectively camouflaged them against the light-coloured trees and lichens upon which they rested. However, due to widespread pollution during the Industrial Revolution in England, many of the lichens died out, and the trees which peppered moths rested on became blackened by soot, causing most of the light-coloured moths, or \"typica\", to die off due to predation. At the same time, the dark-coloured, or melanic, moths, \"carbonaria\", flourished because they could hide on the darkened trees.\nSince then, with improved environmental standards, light-coloured peppered moths have again become common, and the dramatic change in the peppered moth's population has remained a subject of much interest and study. This has led to the coining of the term \"industrial melanism\" to refer to the genetic darkening of species in response to pollutants. As a result of the relatively simple and easy-to-understand circumstances of the adaptation, the peppered moth has become a common example used in explaining or demonstrating natural selection to laypeople and classroom students through simulations.\nThe first \"carbonaria\" morph was recorded by Edleston in Manchester in 1848, and over the subsequent years it increased in frequency. Predation experiments, particularly by Bernard Kettlewell, established that the agent of selection was birds who preyed on the \"carbonaria\" morph. Subsequent experiments and observations have supported the initial evolutionary explanation of the phenomenon.\nGenetic basis of melanism.\nThe evolution of the industrial melanism mutation has been shown to be due to the insertion of a transposable element into the first intron of the \"cortex\" gene, resulting in an increase in the abundance of the \"cortex\" transcript, which is expressed in developing wings.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24886", "revid": "47579147", "url": "https://en.wikipedia.org/wiki?curid=24886", "title": "Power Macintosh", "text": "Family of personal computers released by Apple Computer\nThe Power Macintosh, later Power Mac, is a family of personal computers designed, manufactured, and sold by Apple Computer, Inc as the core of the Macintosh brand from March 1994 until August 2006.\nDescribed by \"Macworld\" as \"the most important technical evolution of the Macintosh since the Mac II debuted in 1987\", it is the first computer with the PowerPC CPU architecture, the flagship product of the AIM alliance. Existing software for the Motorola 68k processors of previous Macintoshes do not run on it natively, so a Mac 68k emulator is in System 7.1.2. It provides good compatibility, at about two-thirds of the speed of contemporary Macintosh Quadra machines.\nThe Power Macintosh replaced the Quadra and was initially sold in the same enclosures. Over the next twelve years, it evolved through a succession of enclosure designs, a rename to \"Power Mac\", five major generations of PowerPC chips, and a great deal of press coverage, design accolades, and controversy about performance claims. It was discontinued as part of the Mac transition to Intel processors announced in 2005, making way for its replacement, the Mac Pro.\nHistory.\nThe first public demonstration of the new Power Macintosh \u2014 specifically, a prototype of what would become the Power Macintosh 6100 \u2013 was at an Apple Pacific sales meeting in Hawaii in October 1992. The demo was a success, and in the following months, the product plan expanded to include three models: the entry-level 6100, a mid-range 7100 housed in the Macintosh IIvx's desktop case, and a high-end 8100 based on the Quadra 800's mini-tower case. A fourth project, the Macintosh Processor Upgrade Card, was started in July 1993 to provide a straightforward upgrade path to owners of Centris- and Quadra-based Macintosh computers.23 The importance of this was especially significant for the Quadra 700, 900, and 950, which were not going to receive full logic board replacements. Computers upgraded in this fashion received new names such as \"Power Macintosh Q650\" and \"Power Macintosh 900\".\nRelease and reception (1994\u20131995).\nThe original plan was to release the first Power Macintosh machine on January 24, 1994, exactly ten years after the release of the first Macintosh.26 Ian Diery, who was EVP and general manager of the Personal Computer Division at the time, moved the release date back to March 14 in order to give manufacturing enough time to build enough machines to fill the sales channels and to ensure that the Macintosh Processor Upgrade Card would be available at the same time. This was a departure from prior practice at Apple; they had typically released upgrade packages months after the introduction of new Macintoshes.\nThe Power Macintosh was formally introduced at the Lincoln Center for the Performing Arts in Manhattan on March 14. Pre-orders for the new Power Macintosh models were brisk, with an announced 150,000 machines already having been sold by that date. MacWorld's review of the 6100/60 noted that \"Not only has Apple finally regained the performance lead it lost about eight years ago when PCs appeared using Intel's 80386 CPU, but it has pushed far ahead.\" The performance of 680x0 software is slower due to the emulation layer, but MacWorld's benchmarks showed noticeably faster CPU, disk, video, and floating-point performance than the Quadra 610 it replaced. By January 1995, Apple had sold 1 million Power Macintosh systems.\nSpeed-bumped versions of the Power Macintosh line were introduced at the beginning of 1995, followed in April by the first PowerPC 603 models: an all-in-one model called the Power Macintosh 5200 LC and a replacement for the Quadra 630 called the Power Macintosh 6200. Performa variants of these machines were sold as well, continuing the practice of re-branding other Macintosh models for sale in department stores and big-box electronics retailers. While the 5200 LC was well received by critics for its design, performance, and cost, both it and the 6200 suffered from stability issues (and in the case of the 5200, display issues as well) that could only be solved by bringing the machine to an Apple dealer for replacement parts.\nBy mid-1995, the burgeoning Power Macintosh line had all but completely supplanted every prior Macintosh line, with only the high-end Quadra 950 and two low-cost education models (the all-in-one Macintosh LC 580 and desktop LC 630) remaining in production. The competitive marketplace for \"accelerator cards\" that had existed for earlier Macintosh systems largely disappeared due to the comparatively low price of Apple's Macintosh Processor Upgrade Card (US$600). DayStar Digital sold upgrade cards for the IIci and various Quadra models, and full motherboard replacements were available from Apple as well. Macintosh clones from companies like DayStar Digital and Power Computing were also coming to the market at this time, undercutting Apple's prices.\nTransition to standardized hardware (1995\u20131999).\nWhen the Power Macintosh was introduced, it included the same internal and external expansion connections as other Macintosh models, all of which (save for audio input and output) were either wholly proprietary to, or largely exclusive to Apple computers. Over the next five years, Apple replaced all these ports with industry-standard connectors.\nThe first generation of Power Macintoshes had shipped with NuBus, but by the end of 1993, it was becoming clear that Intel's PCI bus was going to be the widely adopted future of internal expansion. Apple's position as a relatively small player in the larger personal computer market meant that few device manufacturers invested in creating both NuBus- and PCI-compatible versions of their cards. The first PCI-based system was the range-topping Power Macintosh 9500, introduced in May 1995. This was followed shortly afterwards by the introduction of the \"Power Surge\" line of second-generation Power Macintosh systems \u2013 the Power Macintosh 7200, 7500 and 8500. The 8500 and 9500 were built around the new PowerPC 604, offering speeds starting at 120\u00a0MHz. InfoWorld's review of the 8500 showed a speed improvement in their \"business applications suite\" benchmark from 10 minutes with the 8100/100, to 7:37 for the 8500/120. They also noted that the 8500 runs an average of 24 to 44 percent faster than a similarly clocked Intel Pentium chip, increasing to double on graphics and publishing tasks.\nThe transition to PCI continued into 1996, with the introduction of the all-in-one 5400, desktop 6300/160 (usually sold as a Performa 6360), and mini-tower 6400 models. The success of the Macintosh clone market also prompted Apple to produce its own inexpensive machine using parts and production techniques that were common in both the clone market and the Wintel desktop market at the time. The Power Macintosh 4400 (sold as a 7220 in Asia and Australia) employed bent sheet metal instead of plastic for its case internals, and included a standard ATX power supply.\nAlongside the transition to PCI, Apple began a gradual transition away from SCSI hard disks to IDE as a cost-saving measure, both for themselves and for users who wanted to upgrade their hard drives. The low-end 5200 and 6200 were the first to adopt IDE internal drives, though Apple's proprietary 25-pin external SCSI connector remained. The beige Power Macintosh G3 models being the last to include SCSI drives as standard, and it was the last Macintosh to include the external SCSI connector. When the Power Macintosh G3 (Blue and White) was introduced in early 1999, the port was replaced by two FireWire 400 ports. The Blue and White G3 was also the last Macintosh to include Apple Desktop Bus ports, a proprietary technology created by Steve Wozniak to connect keyboards, mice and software protection dongles such as those from Avid Technology. Two USB ports were also included, making this the only Power Macintosh to include both ADB and USB.\nAnother port that was retired during this time is the Apple Attachment Unit Interface. This was a proprietary version of the industry-standard Attachment Unit Interface connector for 10BASE5 Ethernet that Apple had created to avoid confusion with the 15-pin connector that Apple used for connecting external displays. The AAUI port required a costly external transceiver to connect to a network. By the early 1990s, the networking industry was coalescing around the 10BASE-T connector, leading Apple to include this port alongside AAUI in mid-1995, starting with the Power Macintosh 9500. The Power Macintosh G3 excluded the AAUI port.\nThe Power Mac G4 (AGP Graphics) was released in the second half of 1999; it was the first Power Macintosh to include only industry-standard internal and external expansion. For some years afterwards, a number of third parties created dongles that provided backwards compatibility to users of newer Power Mac systems with old hardware. This included companies like Griffin Technology, MacAlly Peripherals, Rose Electronics and many others. In some cases, these companies produced adapters that matched the aesthetic design of the Power Mac.\nIndustrial design and the Megahertz Myth (1999\u20132002).\nShortly after Steve Jobs' return to Apple in 1997, Jony Ive was appointed senior vice president of industrial design. Building on the critical and commercial success of the iMac, Ive and his team created an entirely new case design for the Power Macintosh G3, combining many of the aesthetic principles of the iMac (curves, translucent plastics, use of color) with the ease-of-access characteristics of the company's popular \"Outrigger\" Macintosh models from previous years. The result was the Power Macintosh G3 (Blue and White), a machine that received considerable plaudits from reviewers, including \"PC Magazine\"'s Technical Excellence Award for 1999. \"The Power Mac provides the fastest access to the insides of a computer we've ever seen,\" they wrote. \"Just lift a handle and a hinged door reveals everything inside.\" This case design, code-named \"El Capitan\", was retained through the entire lifetime of the Power Mac G4. The introduction of the Blue and White G3 mini-tower also marked the end of the desktop and all-in-one Power Macintosh case designs, the latter being replaced by the iMac.\nA second model called the Power Mac G4 Cube was introduced in 2000, which fitted the specifications of a mid-range Power Mac G4 into a cube less than 9\" in each axis. This model was on sale for about a year before being discontinued, and was not considered a sales success (150,000 units were sold, about one-third of Apple's projections), but the distinctive design of both the computer and its accompanying Harman Kardon speakers prompted the Museum of Modern Art in New York City to retain them in their collection.\nThe PowerPC chips in the G3 and G4 became a central part of Apple's branding and marketing for the Power Macintosh. For example, the Blue and White G3 features the letters \"G3\" on the side that are fully one-third the height of the entire case, a significant departure from the small labels typically used on prior Macintosh computers. And when the Power Mac G4 was introduced, print ads included pictures of the G4 chip and mentioned its AltiVec instruction set by its own marketing name, \"Velocity Engine\". A related element of Apple's marketing strategy, especially after mid-2001, was to highlight what they described as the \"Megahertz myth\", challenging the belief that a processor's clock speed is directly correlated with performance. This had become important with the introduction of Intel's Pentium 4, which featured significantly higher clock speeds than competing chips from Sun, IBM, and AMD, but without a corresponding performance benefit.\nThe company's public presentations \u2013 Stevenotes in particular \u2013 often featured lengthy segments pitting a high-powered Compaq or Dell computer against the Power Macintosh in a series of benchmarks and scripted tasks, usually in Adobe Photoshop. These presentations often showed the Power Macintosh besting Intel's Pentium chips by margins significantly exceeding 50%, but independent benchmarks did not bear this out. InfoWorld reviewer Jennifer Plonka reported that the 400\u00a0MHz G3 was 11% slower than a comparably-specced Pentium II-450 in an Office applications suite test, while Photoshop 5.0 was faster by 26%. And in 2003, Maximum PC ran a variety of gaming, Photoshop and LightWave 3D benchmarks, and reported that the Dual 1.25\u00a0GHz G4 system was about half the speed of a dual-processor Intel Xeon Prestonia 2.8\u00a0GHz system. A related criticism leveled at Power Mac systems from this time, particularly the G4 Mirrored Drive Doors, was the increased fan noise level compared to older systems.\nThe \"Power Mac G5\" and the end of the Power Mac (2003\u20132006).\nBy the time the Power Mac G5 was unveiled at Apple's Worldwide Developers Conference in July 2003, Apple's desktop range had fallen significantly behind competing computers in performance. The G5 closed much of this gap by moving to the PowerPC 970 processor with clock speeds up to 2.0\u00a0GHz, and a full 64-bit architecture. It also introduced a significantly revised enclosure design, replacing the use of plastics with anodized aluminum alloy.\nReviews were generally positive. InfoWorld described the G5 as \"Apple's best work yet\", and said it \"delivers on the present need for rapid computing, deep multitasking, and responsive user interfaces \u2014 as well as the future need for mainstream computers that rapidly process and analyze massive data sets.\" PC Magazine again awarded the Power Mac G5 with its Award for Technical Excellence for 2003. However, the G5's heavy weight (10 pounds more than the previous year's Quicksilver Power Mac G4), limited internal expansion options, issues with ground loop, and noise in the single-processor models' power supply units resulted in significant criticism of the product. Apple also continued to make unsubstantiated performance claims about the new Power Mac. This resulted in the Advertising Standards Authority for the United Kingdom banning Apple from using the phrase \"the world's fastest, most powerful personal computer\" to describe the Power Mac G5 after independent tests carried out by the Broadcast Advertising Clearance Centre determined the claim to be false. Another claim made by Steve Jobs at the 2003 Worldwide Developers Conference was that the company would be selling a 3\u00a0GHz G5 by mid-2004; this never happened.\nThree generations of Power Mac G5 were released before it was discontinued during the Mac transition to Intel processors. The announcement of the transition came in mid-2005, but the third generation of G5 systems was introduced towards the end of 2005. Most notably in this generation was the introduction of a Quad-core 2.5\u00a0GHz system. Not only was this the first Apple computer with four processing cores, it was the first to incorporate PCI Express instead of PCI-X for internal expansion. It also required an IEC 60320 C19 power connector that was more common on rackmounted server hardware, instead of the industry-standard C13 connector used with personal computers.\nThe official end to the \"Power Macintosh\" line came at the 2006 Worldwide Developers Conference, where Phil Schiller introduced its replacement, the Mac Pro. The G5's enclosure design was retained for the Mac Pro and continued to be used for seven more years, making it among the longest-lived designs in Apple's history.\nModels.\nThe Power Macintosh models can be broadly classified into two categories, depending on whether they were released before or after Apple introduced its \"four quadrant\" product strategy in 1998. Before the introduction of the Power Macintosh G3 (Blue and White) in 1999, Apple had shipped Power Macintosh-labelled machines in nine different form factors, some of which were carry-overs from pre-PowerPC product lines, such as the Quadra/Centris 610 and the IIvx. This was reduced to one model in the new product strategy, with the exception of the Power Mac G4 Cube in 2000 and 2001.\n1994\u20131997.\nApple named Power Macintosh models from this period after the first pre-PowerPC model of Macintosh to use a particular form factor, followed by a slash and the speed of the CPU. For example, the Power Macintosh 6300/120 uses the Quadra 630's form factor and has a 120 MHz CPU.\nMachines with \"AV\" in their name denote variants that include extended audio-video capabilities.\nMachines with \"PC Compatible\" or \"DOS Compatible\" in their name include a separate card with an x86-compatible CPU, typically a 486 or Pentium; these models are therefore capable of running MS-DOS and Microsoft Windows applications, typically Windows 3.1 (for earlier PC Compatible machines pre-1995) or Windows 95 (for later PC Compatible machines since 1995).\nMachines with \"MP\" in their name denote machines that include two CPUs.\nThese early models had two distinct generations. The first generation uses the PowerPC 601 and 603 processors and used the old NuBus/PDS expansion slots, while the second generation uses the faster 603e, 604 and 604e chips as well as industry-standard PCI expansion slots. The second generation also makes use of Open Firmware, allowing them to more easily boot alternate operating systems (including OS X via XPostFacto), though use of various hacks was still necessary.\nPower Macintosh 4400.\nThe Power Macintosh 4400 is a desktop case with a height of 5.4 inches, suitable for horizontal placement with a monitor on top.\nPower Macintosh 5200.\nThe Power Macintosh 5200 is an all-in-one form factor with specifications and internal designs similar to the Quadra 630. Collectively these machines are sometimes referred to as the \"Power Macintosh/Performa 5000 series\".\nQuadra 610.\nThe Quadra 610 form factor is a low-profile \"pizza-box\" design with a height of 3.4 inches, intended to be placed on a desktop with a monitor on top.\nQuadra 630.\nThe Quadra 630 form factor is a horizontally-oriented design with a height of 4.3 inches, suitable for placing a monitor on top.\nPerforma 6400.\nThe Performa 6400 form factor is a mini-tower design, suitable for being placed beside a monitor.\nIIvx.\nThe IIvx form factor is a horizontally-oriented desktop form factor with a height of 6 inches, suitable for placing a monitor on top.\nPower Macintosh 7500.\nThe Power Macintosh 7500 form factor is a horizontally-oriented desktop design with a height of 6.15 inches, suitable for placing a monitor on top.\nQuadra 800.\nThe Quadra 800 form factor is a mini-tower design, with a width of 7.7 inches.\nPower Macintosh 9600.\nThe Power Macintosh 9600 form factor is a mini-tower design with a width of 9.7 inches.\n1997\u20132006.\nStarting with the Power Macintosh G3, Apple changed its product naming to include the generation of PowerPC CPU, with the name of the form factor or a key feature afterwards in brackets.\nThe all-in-one models would eventually be spun off into the iMac line, whilst the compact form factor models would be spun off into the Mac Mini.\nPower Mac G5.\nThe Power Mac G5's name was changed to incorporate the time period in which the model was released.\nNaming.\nThe Power Mac brand name was used for Apple's high-end tower style computers, targeted primarily at businesses and creative professionals, in differentiation to their more compact \"iMac\" line (intended for home use) and the \"eMac\" line (for the education markets). They were usually equipped with Apple's newest technologies, and commanded the highest prices among Apple desktop models. Some Power Mac G4 and G5 models were offered in dual-processor configurations.\nPrior to the \"Power Mac\" name change, certain \"Power Macintosh\" models were otherwise identical to their lower-cost re-branded siblings sold as the Macintosh LC and Macintosh Performa, as well as the dedicated Apple Workgroup Server and Macintosh Server G3 &amp; G4 lines. Other past Macintosh lines which used PowerPC processors include the PowerBook 5300 and later models, iMac, iBook and Xserve as well as the Apple Network Server, which was technically not a Macintosh.\nAdvertising and marketing.\nApple positioned the Power Macintosh as a high-end personal computer aimed at businesses and creative professionals with an advertising campaign consisting of several television commercials and print ads. The television commercials used the slogan \"The Future Is Better Than You Expected\", featuring the first three Power Macintosh computers to showcase special features such as networking and MS-DOS compatibility.\nIn 1993 and 1994, a television advertising campaign created by BBDO aired with the slogan \"It does more, it costs less, it's that simple.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24888", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=24888", "title": "Promoter (genetics)", "text": "Region of DNA encouraging transcription\nIn genetics, a promoter is a sequence of DNA to which proteins bind to initiate transcription of a single RNA transcript from the DNA downstream of the promoter. The RNA transcript may encode a protein (mRNA), or can have a function in and of itself, such as tRNA or rRNA. Promoters are located near the transcription start sites of genes, upstream on the DNA (towards the 5' region of the sense strand).\nPromoters can be about 100\u20131000 base pairs long, the sequence of which is highly dependent on the gene and product of transcription, type or class of RNA polymerase recruited to the site, and species of organism.\nOverview.\nFor transcription to take place, the enzyme that synthesizes RNA, known as RNA polymerase, must attach to the DNA near a gene. Promoters contain specific DNA sequences such as response elements that provide a secure initial binding site for RNA polymerase and for proteins called transcription factors that recruit RNA polymerase. These transcription factors have specific activator or repressor sequences of corresponding nucleotides that attach to specific promoters and regulate gene expression.\nPromoters represent critical elements that can work in concert with other regulatory regions (enhancers, silencers, boundary elements/insulators) to direct the level of transcription of a given gene.\nA promoter is induced in response to changes in abundance or conformation of regulatory proteins in a cell, which enable activating transcription factors to recruit RNA polymerase.\nGiven the short sequences of most promoter elements, promoters can rapidly evolve from random sequences. For instance, in \"E. coli\", ~60% of random sequences can evolve expression levels comparable to the wild-type lac promoter with only one mutation, and that ~10% of random sequences can serve as active promoters even without evolution.\nIdentification of relative location.\nAs promoters are typically immediately adjacent to the gene in question, positions in the promoter are designated relative to the transcriptional start site, where transcription of DNA begins for a particular gene (i.e., positions upstream are negative numbers counting back from -1, for example -100 is a position 100 base pairs upstream).\nElements.\nBacterial.\nIn bacteria, the promoter contains two short sequence elements approximately 10 (Pribnow Box) and 35 nucleotides \"upstream\" from the transcription start site.\nThe above promoter sequences are recognized only by RNA polymerase holoenzyme containing sigma-70. RNA polymerase holoenzymes containing other sigma factors recognize different core promoter sequences.\n \u2190 upstream downstream \u2192\n 5'-XXXXXXXPPPPPPXXXXXXPPPPPPXXXXGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGXXXX-3'\n -35 -10 Gene to be transcribed\nProbability of occurrence of each nucleotide.\n for -10 sequence\n T A T A A T\n 77% 76% 60% 61% 56% 82%\n for -35 sequence\n T T G A C A\n 69% 79% 61% 56% 54% 54%\nBidirectional (prokaryotic).\nPromoters can be very closely located in the DNA. Such \"closely spaced promoters\" have been observed in the DNAs of all life forms, from humans to prokaryotes and are highly conserved. Therefore, they may provide some (presently unknown) advantages.\nThese pairs of promoters can be positioned in divergent, tandem, and convergent directions. They can also be regulated by transcription factors and differ in various features, such as the nucleotide distance between them, the two promoter strengths, etc.\nThe most important aspect of two closely spaced promoters is that they will, most likely, interfere with each other. Several studies have explored this using both analytical and stochastic models. There are also studies that measured gene expression in synthetic genes or from one to a few genes controlled by bidirectional promoters.\nMore recently, one study measured most genes controlled by tandem promoters in \"E. coli\". In that study, two main forms of interference were measured. One is when an RNAP is on the downstream promoter, blocking the movement of RNAPs elongating from the upstream promoter. The other is when the two promoters are so close that when an RNAP sits on one of the promoters, it blocks any other RNAP from reaching the other promoter. These events are possible because the RNAP occupies several nucleotides when bound to the DNA, including in transcription start sites.\nSimilar events occur when the promoters are in divergent and convergent formations. The possible events also depend on the distance between them.\nEukaryotic.\nGene promoters are typically located upstream of the gene and can have regulatory elements several kilobases away from the transcriptional start site (enhancers). In eukaryotes, the transcriptional complex can cause the DNA to bend back on itself, which allows for placement of regulatory sequences far from the actual site of transcription. Eukaryotic RNA-polymerase-II-dependent promoters can contain a TATA box (consensus sequence TATAAA), which is recognized by the general transcription factor TATA-binding protein (TBP); and a B recognition element (BRE), which is recognized by the general transcription factor TFIIB. The TATA element and BRE typically are located close to the transcriptional start site (typically within 30 to 40 base pairs).\nEukaryotic promoter regulatory sequences typically bind proteins called transcription factors that are involved in the formation of the transcriptional complex. An example is the E-box (sequence CACGTG), which binds transcription factors in the basic helix-loop-helix (bHLH) family (e.g. BMAL1-Clock, cMyc). Some promoters that are targeted by multiple transcription factors might achieve a hyperactive state, leading to increased transcriptional activity.\nMammalian promoters.\nUp-regulated expression of genes in mammals is initiated when signals are transmitted to the promoters associated with the genes. Promoter DNA sequences may include different elements such as CpG islands (present in about 70% of promoters), a TATA box (present in about 24% of promoters), initiator (Inr) (present in about 49% of promoters), upstream and downstream TFIIB recognition elements (BREu and BREd) (present in about 22% of promoters), and downstream core promoter element (DPE) (present in about 12% of promoters). The presence of multiple methylated CpG sites in CpG islands of promoters causes stable silencing of genes. However, the presence or absence of the other elements have relatively small effects on gene expression in experiments. Two sequences, the TATA box and Inr, caused small but significant increases in expression (45% and 28% increases, respectively). The BREu and the BREd elements significantly decreased expression by 35% and 20%, respectively, and the DPE element had no detected effect on expression.\nCis-regulatory modules that are localized in DNA regions distant from the promoters of genes can have very large effects on gene expression, with some genes undergoing up to 100-fold increased expression due to such a cis-regulatory module. These cis-regulatory modules include enhancers, silencers, insulators and tethering elements. Among this constellation of elements, enhancers and their associated transcription factors have a leading role in the regulation of gene expression.\nEnhancers are regions of the genome that are major gene-regulatory elements. Enhancers control cell-type-specific gene expression programs, most often by looping through long distances to come in physical proximity with the promoters of their target genes. In a study of brain cortical neurons, 24,937 loops were found, bringing enhancers to promoters. Multiple enhancers, each often at tens or hundred of thousands of nucleotides distant from their target genes, loop to their target gene promoters and coordinate with each other to control expression of their common target gene.\nThe schematic illustration in this section shows an enhancer looping around to come into close physical proximity with the promoter of a target gene. The loop is stabilized by a dimer of a connector protein (e.g. dimer of CTCF or YY1), with one member of the dimer anchored to its binding motif on the enhancer and the other member anchored to its binding motif on the promoter (represented by the red zigzags in the illustration). Several cell function specific transcription factors (there are about 1,600 transcription factors in a human cell) generally bind to specific motifs on an enhancer and a small combination of these enhancer-bound transcription factors, when brought close to a promoter by a DNA loop, govern the level of transcription of the target gene. Mediator (coactivator) (a complex usually consisting of about 26 proteins in an interacting structure) communicates regulatory signals from enhancer DNA-bound transcription factors directly to the RNA polymerase II (pol II) enzyme bound to the promoter.\nEnhancers, when active, are generally transcribed from both strands of DNA with RNA polymerases acting in two different directions, producing two eRNAs as illustrated in the Figure. An inactive enhancer may be bound by an inactive transcription factor. Phosphorylation of the transcription factor may activate it and that activated transcription factor may then activate the enhancer to which it is bound (see small red star representing phosphorylation of transcription factor bound to enhancer in the illustration). An activated enhancer begins transcription of its RNA before activating a promoter to initiate transcription of messenger RNA from its target gene.\nBidirectional (mammalian).\nBidirectional promoters are short (&lt;1 kbp) intergenic regions of DNA between the 5' ends of the genes in a bidirectional gene pair. A \"bidirectional gene pair\" refers to two adjacent genes coded on opposite strands, with their 5' ends oriented toward one another. The two genes are often functionally related, and modification of their shared promoter region allows them to be co-regulated and thus co-expressed. Bidirectional promoters are a common feature of mammalian genomes. About 11% of human genes are bidirectionally paired.\nBidirectionally paired genes in the Gene Ontology database shared at least one database-assigned functional category with their partners 47% of the time. Microarray analysis has shown bidirectionally paired genes to be co-expressed to a higher degree than random genes or neighboring unidirectional genes. Although co-expression does not necessarily indicate co-regulation, methylation of bidirectional promoter regions has been shown to downregulate both genes, and demethylation to upregulate both genes. There are exceptions to this, however. In some cases (about 11%), only one gene of a bidirectional pair is expressed. In these cases, the promoter is implicated in suppression of the non-expressed gene. The mechanism behind this could be competition for the same polymerases, or chromatin modification. Divergent transcription could shift nucleosomes to upregulate transcription of one gene, or remove bound transcription factors to downregulate transcription of one gene.\nSome functional classes of genes are more likely to be bidirectionally paired than others. Genes implicated in DNA repair are five times more likely to be regulated by bidirectional promoters than by unidirectional promoters. Chaperone proteins are three times more likely, and mitochondrial genes are more than twice as likely. Many basic housekeeping and cellular metabolic genes are regulated by bidirectional promoters.\nThe overrepresentation of bidirectionally paired DNA repair genes associates these promoters with cancer. Forty-five percent of human somatic oncogenes seem to be regulated by bidirectional promoters \u2013 significantly more than non-cancer causing genes. Hypermethylation of the promoters between gene pairs WNT9A/CD558500, CTDSPL/BC040563, and KCNK15/BF195580 has been associated with tumors.\nCertain sequence characteristics have been observed in bidirectional promoters, including a lack of TATA boxes, an abundance of CpG islands, and a symmetry around the midpoint of dominant Cs and As on one side and Gs and Ts on the other. A motif with the consensus sequence of TCTCGCGAGA, also called the CGCG element, was recently shown to drive PolII-driven bidirectional transcription in CpG islands. CCAAT boxes are common, as they are in many promoters that lack TATA boxes. In addition, the motifs NRF-1, GABPA, YY1, and ACTACAnnTCCC are represented in bidirectional promoters at significantly higher rates than in unidirectional promoters. The absence of TATA boxes in bidirectional promoters suggests that TATA boxes play a role in determining the directionality of promoters, but counterexamples of bidirectional promoters do possess TATA boxes and unidirectional promoters without them indicates that they cannot be the only factor.\nAlthough the term \"bidirectional promoter\" refers specifically to promoter regions of mRNA-encoding genes, luciferase assays have shown that over half of human genes do not have a strong directional bias. Research suggests that non-coding RNAs are frequently associated with the promoter regions of mRNA-encoding genes. It has been hypothesized that the recruitment and initiation of RNA polymerase II usually begins bidirectionally, but divergent transcription is halted at a checkpoint later during elongation. Possible mechanisms behind this regulation include sequences in the promoter region, chromatin modification, and the spatial orientation of the DNA.\nArchaea.\nThe archaeal promoter resembles an eukaryotic one: a TATA box (at -26/-27) and an upstream BRE (at -33/-34) are commonly found, binding to TBP and TFB (homolog of TFIIB). There are also occasionally an initiator element (INR) near the transcription start site [TSS], and a promoter proximal element (PPE) between BRE-TATA and TSS. These two are not necessary, but enhance the strength of a promoter. TFE (homolog of TFIIE) promotes initiation at suboptimal promoter sequences. It binds between -10 and +1, near the Inr.\nStrict conservation of these motifs are not necessary, and many archaea with high GC% show \"degenerated\" TATA boxes. Rather, it's the energetic (duplex enthalpy, duplex stability) and structual (intrinsic curvature, bendability) features of the promoter that mainly matter.\nSubgenomic.\nA subgenomic promoter is a promoter added to a virus for a specific heterologous gene, resulting in the formation of mRNA for that gene alone. Many positive-sense RNA viruses produce these subgenomic mRNAs (sgRNA) as one of the common infection techniques used by these viruses and generally transcribe late viral genes. Subgenomic promoters range from 24 nucleotide (Sindbis virus) to over 100 nucleotides (Beet necrotic yellow vein virus) and are usually found upstream of the transcription start.\nDetection.\nA wide variety of algorithms have been developed to facilitate detection of promoters in genomic sequence, and promoter prediction is a common element of many gene prediction methods. Many such tools have been developed. A bacterial promoter region is located before the -35 and -10 Consensus sequences. The closer the promoter region is to the consensus sequences the more often transcription of that gene will take place. There is not a set pattern for promoter regions as there are for consensus sequences.\nOne approach is to use a biophysical theory of why promoters work. For archaea, a combination of calculated energetic and structual features can detect promoters. For bacteria, a biophysical model that estimates RNAP-sigma70 binding probability can detect and estimate the strengths of promoters.\nAnother approach is to use a pattern-matching program based on known promoters, from simple hand-crafted regular expressions to advanced machine learning methods such as decision trees, hidden Markov models (HMM), and neural networks. YAPP, an 2000s eukaryotic core-promoter prediction program, uses HMM. A 2017 publication predicts bacterial and eukaryotic promoters using a convolutional neural network.\nBinding.\nThe initiation of the transcription is a multistep sequential process that involves several mechanisms: promoter location, initial reversible binding of RNA polymerase, conformational changes in RNA polymerase, conformational changes in DNA, binding of nucleoside triphosphate (NTP) to the functional RNA polymerase-promoter complex, and nonproductive and productive initiation of RNA synthesis.\nThe promoter binding process is crucial in the understanding of the process of gene expression. Tuning synthetic genetic systems relies on precisely engineered synthetic promoters with known levels of transcription rates.\nLocation.\nAlthough RNA polymerase holoenzyme shows high affinity to non-specific sites of the DNA, this characteristic does not allow us to clarify the process of promoter location. This process of promoter location has been attributed to the structure of the holoenzyme to DNA and sigma 4 to DNA complexes.\nDiseases associated with aberrant function.\nMost diseases are heterogeneous in cause, meaning that one \"disease\" is often many different diseases at the molecular level, though symptoms exhibited and response to treatment may be identical. How diseases of different molecular origin respond to treatments is partially addressed in the discipline of pharmacogenomics.\nNot listed here are the many kinds of cancers involving aberrant transcriptional regulation owing to creation of chimeric genes through pathological chromosomal translocation. Importantly, intervention in the number or structure of promoter-bound proteins is one key to treating a disease without affecting expression of unrelated genes sharing elements with the target gene. Some genes whose change is not desirable are capable of influencing the potential of a cell to become cancerous.\nCpG islands in promoters.\nIn humans, about 70% of promoters located near the transcription start site of a gene (proximal promoters) contain a CpG island. CpG islands are generally 200 to 2000 base pairs long, have a C:G base pair content &gt;50%, and have regions of DNA where a cytosine nucleotide is followed by a guanine nucleotide and this occurs frequently in the linear sequence of bases along its 5' \u2192 3' direction.\nDistal promoters also frequently contain CpG islands, such as the promoter of the DNA repair gene \"ERCC1\", where the CpG island-containing promoter is located about 5,400 nucleotides upstream of the coding region of the \"ERCC1\" gene. CpG islands also occur frequently in promoters for functional noncoding RNAs such as microRNAs.\nMethylation of CpG islands stably silences genes.\nIn humans, DNA methylation occurs at the 5' position of the pyrimidine ring of the cytosine residues within CpG sites to form 5-methylcytosines. The presence of multiple methylated CpG sites in CpG islands of promoters causes stable silencing of genes. Silencing of a gene may be initiated by other mechanisms, but this is often followed by methylation of CpG sites in the promoter CpG island to cause the stable silencing of the gene.\nPromoter CpG hyper/hypo-methylation in cancer.\nGenerally, in progression to cancer, hundreds of genes are silenced or activated. Although silencing of some genes in cancers occurs by mutation, a large proportion of carcinogenic gene silencing is a result of altered DNA methylation (see DNA methylation in cancer). DNA methylation causing silencing in cancer typically occurs at multiple CpG sites in the CpG islands that are present in the promoters of protein coding genes.\nAltered expressions of microRNAs also silence or activate many genes in progression to cancer (see microRNAs in cancer). Altered microRNA expression occurs through hyper/hypo-methylation of CpG sites in CpG islands in promoters controlling transcription of the microRNAs.\nSilencing of DNA repair genes through methylation of CpG islands in their promoters appears to be especially important in progression to cancer (see methylation of DNA repair genes in cancer).\nCanonical sequences and wild-type.\nThe usage of the term canonical sequence to refer to a promoter is often problematic, and can lead to misunderstandings about promoter sequences. Canonical implies perfect, in some sense.\nIn the case of a transcription factor binding site, there may be a single sequence that binds the protein most strongly under specified cellular conditions. This might be called canonical.\nHowever, natural selection may favor less energetic binding as a way of regulating transcriptional output. In this case, we may call the most common sequence in a population the wild-type sequence. It may not even be the most advantageous sequence to have under prevailing conditions.\nRecent evidence also indicates that several genes (including the proto-oncogene c-myc) have G-quadruplex motifs as potential regulatory signals.\nSynthetic promoter design and engineering.\nPromoters are important gene regulatory elements used in tuning synthetically designed genetic circuits and metabolic networks. For example, to overexpress an important gene in a network, to yield higher production of target protein, synthetic biologists design promoters to upregulate its expression. Automated algorithms can be used to design neutral DNA or insulators that do not trigger gene expression of downstream sequences.\nDiseases that may be associated with variations.\nSome cases of many genetic diseases are associated with variations in promoters or transcription factors.\nExamples include:\nConstitutive vs regulated.\nSome promoters are called constitutive as they are active in all circumstances in the cell, while others are regulated, becoming active in the cell only in response to specific stimuli.\nTissue-specific promoter.\nA tissue-specific promoter is a promoter that has activity in only certain cell types.\nUse of the term.\nWhen referring to a promoter some authors actually mean promoter + operator; i.e., the lac promoter is IPTG inducible, meaning that besides the lac promoter, the lac operon is also present. If the lac operator were not present the IPTG would not have an inducible effect.\nAnother example is the Tac-Promoter system (Ptac). Notice how tac is written as a tac promoter, while in fact tac is actually both a promoter and an operator.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24891", "revid": "8390765", "url": "https://en.wikipedia.org/wiki?curid=24891", "title": "Pepin", "text": ""}
{"id": "24893", "revid": "10199389", "url": "https://en.wikipedia.org/wiki?curid=24893", "title": "Adobe Photoshop", "text": "Raster graphics editing software\nAdobe Photoshop is a raster graphics editor developed and published by Adobe for Windows and macOS. It was created in 1987 by Thomas and John Knoll. It is the most used tool for professional digital art, especially in raster graphics editing, and its name has become genericised as a verb (e.g., to \"photoshop\" an image, \"photoshopping\", and \"photoshop contest\") although Adobe disapproves of such use.\nPhotoshop can edit and compose raster images in multiple layers and supports masks, alpha compositing and several color models. Photoshop uses its own PSD and PSB file formats to support these features. In addition to raster graphics, Photoshop has limited abilities to edit or render text and vector graphics (especially through clipping path for the latter), as well as 3D graphics and video. Its feature set can be expanded by plug-ins; programs developed and distributed independently of Photoshop that run inside it and offer new or enhanced features.\nPhotoshop's naming scheme was initially based on version numbers. However, in October 2002 (following the introduction of Creative Suite branding), each new version of Photoshop was designated with \"CS\" plus a number; e.g., the eighth major version of Photoshop was Photoshop CS and the ninth was Photoshop CS2. Photoshop CS3 through CS6 were also distributed in two different editions: Standard and Extended. With the introduction of the Creative Cloud branding in June 2013 (and, in turn, the change of the \"CS\" suffix to \"CC\"), Photoshop's licensing scheme was changed to that of subscription model. Historically, Photoshop was bundled with additional software such as Adobe ImageReady, Adobe Fireworks, Adobe Bridge, Adobe Device Central and Adobe Camera RAW.\nAlongside Photoshop, Adobe also develops and publishes Photoshop Elements, Photoshop Lightroom, Photoshop Express, Photoshop Fix, Adobe Illustrator, and Photoshop Mix. As of November 2019, Adobe has also released a full version of Photoshop for the iPad, and while initially limited, Adobe plans to bring more features to Photoshop for iPad. Collectively, they are branded as \"The Adobe Photoshop Family\".\nEarly history.\nPhotoshop was developed in 1987 by two brothers, Thomas and John Knoll, who sold the distribution license to Adobe Systems Incorporated in 1988. Thomas Knoll, a Ph.D. student at the University of Michigan, began writing a program on his Macintosh Plus to display grayscale images on a monochrome display. This program (at that time called Display) caught the attention of his brother John, an Industrial Light &amp; Magic employee, who recommended that Thomas turn it into a full-fledged image editing program. Thomas took a six-month break from his studies in 1988 to collaborate with his brother on the program. Thomas renamed the program ImagePro, but the name was already taken. Later that year, Thomas renamed his program Photoshop and worked out a short-term deal with scanner manufacturer Barneyscan to distribute copies of the program with a slide scanner; a \"total of about 200 copies of Photoshop were shipped\" this way.\nDuring this time, John traveled to Silicon Valley and gave a demonstration of the program to engineers at Apple Computer and Russell Brown, art director at Adobe. Both showings were successful, and Adobe decided to purchase the license to distribute in September 1988. While John worked on plug-ins in California, Thomas remained in Ann Arbor writing code. \"Photoshop\" 1.0 was released on February 19, 1990, for Macintosh exclusively. The Barneyscan version included advanced color editing features that were stripped from the first Adobe shipped version. The handling of color slowly improved with each release from Adobe and Photoshop quickly became the industry standard in digital color editing. When Photoshop 1.0 was released, digital retouching on dedicated high-end systems (such as the Scitex) cost around $300 an hour for basic photo retouching. The list price of Photoshop 1.0 for Macintosh in 1990 was $895.\nPhotoshop was initially only available on Macintosh. In 1993, Adobe chief architect Seetharaman Narayanan ported Photoshop to Microsoft Windows. The Windows port led to Photoshop reaching a wider mass market audience as Microsoft's global reach expanded within the next few years. On March 31, 1995, Adobe purchased the rights for Photoshop from Thomas and John Knoll for $34.5 million so Adobe would no longer need to pay a royalty for each copy sold.\nFile format.\nPhotoshop files have default file extension as .PSD, which stands for \"Photoshop Document\". A PSD file stores an image with support for all features of Photoshop; these include layers with masks, transparency, text, alpha channels and spot colors, clipping paths, and duotone settings. This is in contrast to many other file formats (e.g., .JPG or .GIF) that restrict content to provide streamlined, predictable functionality. A PSD file has a maximum height and width of 30,000 pixels, and a size limit of two gigabytes.\nFrom the beginning, Photoshop could save files in other formats, including TIF, JPEG, and GIF. These files are smaller than PSD files because they lack the editable features of a PSD file. These formats are required to use the file in publications or on the web. Adobe's discontinued program PageMaker required TIF format.\nPhotoshop can also create and use files with the extension .PSB, which stands for \"Photoshop Big\" (also known as \"large document format\"). A PSB file extends the PSD file format, increasing the maximum height and width to 300,000 pixels and the size limit to around 4 exabytes. PSD and PSB formats are documented.\nBecause of Photoshop's popularity, PSD files are widely used and supported to some extent by most competing software, including GIMP, Affinity Photo, and Clip Studio Paint. The .PSD file format can be exported to and from Adobe's other apps, such as Adobe Illustrator, Adobe Premiere Pro, and After Effects.\nPlugins.\nPhotoshop functionality can be extended by add-on programs called Photoshop plugins (or plug-ins). Adobe creates some, such as Adobe Camera Raw, but most are developed by third-parties. Some are free and some are commercial software.\nMost plugins work with only Photoshop or Photoshop-compatible hosts, but a few can also be run as standalone applications.\nThere are various types of plugins, such as filter, export, import, selection, color correction, and automation. The most popular plugins are the filter plugins (also known as a 8bf plugins), available under the Filter menu in Photoshop. Filter plugins can either modify the current image or create content. Below are some popular types of plugins, and some well-known companies associated with them:\nCamera Raw.\nAdobe Camera Raw (also known as ACR and Camera Raw) is a special plugin, supplied free by Adobe, used primarily to read and process raw image files so that the resulting images can be processed by Photoshop. It can also be used from within Adobe Bridge.\nCultural impact.\n\"Photoshop\" and derivatives such as \"Photoshopped\" (or just \"Shopped\") have become verbs that are sometimes used to refer to images edited by Photoshop, or any image manipulation program. The same happens not only in English but as the for image manipulation attests, even in that language, with the trademark being followed by the Portuguese verb termination \"-ar,\" yielding the word \"photoshopar\" (to photoshop). Such derivatives are discouraged by Adobe because, in order to maintain validity and protect the trademark from becoming generic, trademarks must be used as proper nouns.\nVersion history.\nPhotoshop's naming scheme was initially based on version numbers, from version 0.63 (codename \"Bond\"; double-oh-seven), through version 0.87 (codename \"Seurat\" which was the first commercial version, sold as \"Barneyscan XP\"), version 1.0 (February 1990) all the way to version 7.0.1. Adobe published 7 major and many minor versions before the October 2003 introduction of version 8.0 which brought with it the Creative Suite branding.\nNotable milestone features would be: Filters, Colour Separation, Virtual Memory (1.0), Paths, CMYK color (2.0), 16-bits-per-channel support, availability on Microsoft Windows (2.5), Layers, tabbed Palettes (3.0), Adjustments, Actions, Freeform Transform, PNG support (4.0), Editable Type, Magnetic Lasso and Pen, Freeform Pen, Multiple Undo, Layer Effects (5.0), Save For Web (5.5), Vector Shapes, revised User Interface (6.0), Vector Text, Healing Brush, Spell Check (7.0), Camera RAW (7.0.1).\nIn February 2013 Adobe donated the source code of the 1990 1.0.1 version of Photoshop to the Computer History Museum.\nPre-release versions.\nVersion 0.63 (October 1988) was the first known copy of Photoshop, though it was never publicly released.\nVersion 0.87 (March 1989) was the first publicly available version of Photoshop, distributed commercially under the name \"Barneyscan XP\".\nVersion 1.\nPhotoshop 1.0 was released in February 1990.\nVersion 2.\nPhotoshop 2.0 was released in June 1991. It added support for paths and the CMYK color model.\nPhotoshop 2.5, released in November 1992, was the first version available for Windows.\nVersion 3.\nPhotoshop 3.0 was released in September 1994 for Mac OS 7. The Windows version came out later in November. Notably, this was the first version that brought \"Layers\".\nVersion 4.\nPhotoshop 4.0 was released in November 1996.\nVersion 5.\nPhotoshop 5.0 was released in May 1998.\nVersion 6.\nPhotoshop 6.0 was released in September 2000.\nVersion 7.\nPhotoshop 7.0 was released in March 2002.\nCS (version 8).\nThe first Photoshop CS was commercially released in October 2003 as the eighth major version of Photoshop. Photoshop CS increased user control with a reworked file browser augmenting search versatility, sorting and sharing capabilities and the Histogram Palette which monitors changes in the image as they are made to the document. Match Color was also introduced in CS, which reads color data to achieve a uniform expression throughout a series of pictures.\nCS2 (version 9).\nPhotoshop CS2, released in May 2005, expanded on its predecessor with a new set of tools and features. It included an upgraded \"spot healing brush\", which is mainly used for handling common photographic problems such as blemishes, red-eye, noise, blurring and lens distortion. One of the most significant inclusions in CS2 was the implementation of \"smart objects\", which allows users to scale and transform images and vector illustrations without losing image quality, as well as create linked duplicates of embedded graphics so that a single edit updates across multiple iterations.\nAdobe responded to feedback from the professional media industry by implementing non-destructive editing as well as the producing and modifying of 32-bit high dynamic range (HDR) images, which are optimal for 3D rendering and advanced compositing. FireWire previews could also be viewed on a monitor via a direct export feature.\nPhotoshop CS2 brought the \"vanishing point\" and \"image warping\" tools. \"Vanishing point\" tool makes tedious graphic and photo retouching endeavors much simpler by letting users clone, paint and transform image objects while maintaining visual perspective. \"Image warping\" tool makes it easy to digitally distort an image into a shape by choosing on-demand presets or by dragging control points.\nThe file browser was upgraded to \"Adobe Bridge\", which functioned as a hub for productivity, imagery and creativity, providing multi-view file browsing and smooth cross-product integration across Adobe Creative Suite 2 software. Adobe Bridge also provided access to Adobe Stock Photos, a new stock photography service that offered users one-stop shopping across five elite stock image providers to deliver high-quality, royalty-free images for layout and design.\n\"Camera raw\" version 3.0 was a new addition in CS2, and it allowed settings for multiple raw files to be modified simultaneously. In addition, processing multiple raw files to other formats including JPEG, TIFF, DNG or PSD, could be done in the background without executing Photoshop itself.\nPhotoshop CS2 brought a streamlined interface, making it easier to access features for specific instances. In CS2 users were also given the ability to create their own custom presets, which was meant to save time and increase productivity.\nIn January 2013, Photoshop CS2 was released with a published serial number due to a technical glitch in Adobe's CS2 activation servers (see Creative Suite 1 and 2).\nCS3 (version 10).\nCS3 and CS3 Extended were released in April 2007 to the United States and Canada. They were also made available through Adobe's online store and Adobe Authorized Resellers. Both CS3 and CS3 Extended are offered as either a stand-alone application or feature of Adobe Creative Suite. Both products are compatible with Intel-based Macs and PowerPCs, supporting Windows XP and Windows Vista. CS3 is the first release of Photoshop that will run natively on Macs with Intel processors: previous versions can only run through the translation layer Rosetta, and will not run at all on Macs running Mac OS X 10.7 or later.\nCS3 improves on features from previous versions of Photoshop and introduces new tools. One of the most significant is the streamlined interface which allows increased performance, speed, and efficiency. There is also improved support for Camera RAW files which allow users to process images with higher speed and conversion quality. CS3 supports over 150 RAW formats as well as JPEG, TIFF and PDF. Enhancements were made to the Black and White Conversion, Brightness and Contrast Adjustment and Vanishing Point Module tools. The Black and White adjustment option improves control over manual grayscale conversions with a dialog box similar to that of Channel Mixer. There is more control over print options and better management with Adobe Bridge. The Clone Source palette is introduced, adding more options to the clone stamp tool. Other features include the nondestructive Smart Filters, optimizing graphics for mobile devices, Fill Light and Dust Busting tools. Compositing is assisted with Photoshop's new Quick Selection and Refine Edge tools and improved image stitching technology.\nCS3 Extended includes everything in CS3 and additional features. There are tools for 3D graphic file formats, video enhancement and animation, and comprehensive image measurement and analysis tools with DICOM file support. The 3D graphic formats allow 3D content to be incorporated into 2D compositions. As for video editing, CS3 supports layers and video formatting so users can edit video files per frame.\nCS4 (version 11).\nCS4 and CS4 Extended were released on October 15, 2008. They were also made available through Adobe's online store and Adobe Authorized Resellers. Both CS4 and CS4 Extended are offered as either a stand-alone application or feature of Adobe Creative Suite. Both products are compatible with Intel-based Mac OS X and PowerPCs, supporting Windows XP and Windows Vista.\nCS4 features smoother panning and zooming, allowing faster image editing at a high magnification. The interface is more simplified with its tab-based interface making it cleaner to work with. Photoshop CS4 features a new 3D engine allowing the conversion of gradient maps to 3D objects, adding depth to layers and text, and getting print-quality output with the new ray-tracing rendering engine. It supports common 3D formats; the new Adjustment and Mask panels; content-aware scaling (seam carving); fluid canvas rotation and File display options. The content-aware scaling allows users to intelligently size and scale images, and the canvas rotation tool makes it easier to rotate and edit images from any angle.\nAdobe released Photoshop CS4 Extended, which has the features of Adobe Photoshop CS4, plus capabilities for scientific imaging, 3D, motion graphics, accurate image analysis and high-end film and video users. The faster 3D engine allows users to paint directly on 3D models, wrap 2D images around 3D shapes and animate 3D objects. As the successor to Photoshop CS3, Photoshop CS4 is the first x64 edition of Photoshop on consumer computers for Windows. The color correction tool has also been improved significantly.\nCS5 (version 12).\nPhotoshop CS5 was launched on April 12, 2010. In a video posted on its official Facebook page, the development team revealed the new technologies under development, including three-dimensional brushes and warping tools.\nIn May 2011, Adobe Creative Suite 5.5 (CS5.5) was released, with new versions of some of the applications. Its version of Photoshop, 12.1, is identical to the concurrently released update for Photoshop CS5, version 12.0.4, except for support for the new subscription pricing that was introduced with CS5.5.\nCS5 introduces new tools such as the Content-Aware Fill, Refine Edge, Mixer Brush, Bristle Tips and Puppet Warp. The community also had a hand in the additions made to CS5 as 30 new features and improvements were included by request. These include automatic image straightening, the Rule-of-Thirds cropping tool, color pickup, and saving a 16-bit image as a JPEG. Another feature includes the Adobe Mini Bridge, which allows for efficient file browsing and management.\nCS5 Extended includes everything in CS5 plus features in 3D and video editing. A new materials library was added, providing more options such as Chrome, Glass, and Cork. The new Shadow Catcher tool can be used to further enhance 3D objects. For motion graphics, the tools can be applied to over more than one frame in a video sequence.\nCS5 and CS5 Extended were made available through Adobe's online store, Adobe Authorized Resellers and Adobe direct sales. Both CS5 and CS5 Extended are offered as either a stand-alone application or a feature of Adobe Creative Suite 5. Both products are compatible with Intel-based Mac OS X and Windows XP, Windows Vista, and Windows 7.\nCS6 (version 13).\nPhotoshop CS6, released in May 2012, added new creative design tools and provided a redesigned interface with a focus on enhanced performance. New features have been added to the Content-Aware tool such as the Content-Aware Patch and Content-Aware Move.\nAdobe Photoshop CS6 brought a suite of tools for video editing. Color and exposure adjustments, as well as layers, are among a few things that are featured in this new editor. Upon completion of editing, the user is presented with a handful of options of exporting into a few popular formats.\nCS6 brings the \"straighten\" tool to Photoshop, where a user simply draws a line anywhere on an image, and the canvas will reorient itself so that the line drawn becomes horizontal, and adjusts the media accordingly. This was created with the intention that users will draw a line parallel to a plane in the image, and reorient the image to that plane to more easily achieve certain perspectives.\nCS6 allows background saving, which means that while another document is compiling and archiving itself, it is possible to simultaneously edit an image. CS6 also features a customizable auto-save feature, preventing any work from being lost.\nWith version 13.1.3, Adobe dropped support for Windows XP (including Windows XP Professional x64 Edition); thus, the last version that works on Windows XP is 13.0.1. Adobe also announced that CS6 will be the last suite sold with perpetual licenses in favor of the new Creative Cloud subscriptions, though they will continue to provide OS compatibility support as well as bug fixes and security updates as necessary.\nStarting January 9, 2017, CS6 is no longer available for purchase, making a Creative Cloud license the only purchase option going forward. No more updates will be available for all CS6 software either.\nCC (version 14).\nPhotoshop CC (14.0) was launched on June 18, 2013. As the next major version after CS6, it is only available as part of a Creative Cloud subscription. Major features in this version include new Smart Sharpen, Intelligent Upsampling, and Camera Shake Reduction for reducing blur caused by camera shake. Editable Rounded Rectangles and an update to Adobe Camera Raw (8.0) were also included.\nSince the initial launch, Adobe has released two additional feature-bearing updates. The first, version 14.1, was launched on September 9, 2013. The major features in this version were Adobe Generator, a Node.js-based platform for creating plug-ins for Photoshop. Photoshop 14.1 shipped with two plug-ins, one to automatically generate image assets based on an extension in the layer name, and another to automatically generate assets for Adobe Edge Reflow.\nVersion 14.2 was released on January 15, 2014. Major features include Perspective Warp, Linked Smart Objects, and 3D Printing support.\nCC 2014 (version 15).\nPhotoshop CC 2014 (15.0) was released on June 18, 2014. CC 2014 features improvements to content-aware tools, two new blur tools (spin blur and path blur) and a new focus mask feature that enables the user to select parts of an image based on whether they are in focus or not. Other minor improvements have been made, including speed increases for certain tasks.\nCC 2015 (version 16 and version 17).\nPhotoshop CC 2015 was released on June 15, 2015. Adobe added various creative features including Adobe Stock, which is a library of custom stock images. It also includes and have the ability to have more than one layer style. For example, in the older versions of Photoshop, only one shadow could be used for a layer but in CC 2015, up to ten are available. Other minor features like Export As, which is a form of the Save For Web in CC 2014 were also added. The updated UI as of November 30, 2015, delivers a cleaner and more consistent look throughout Photoshop, and the user can quickly perform common tasks using a new set of gestures on touch-enabled devices like Microsoft Surface Pro. CC 2015 also marks the 25th anniversary of Photoshop.\nCC 2017 (version 18).\nPhotoshop CC 2017 was released on November 2, 2016. It introduced a new template selector when creating new documents, the ability to search for tools, panels and help articles for Photoshop, support for SVG OpenType fonts and other small improvements. In December 2016, a minor update was released to include support for the MacBook Pro Touch Bar.\nCC 2018 (version 19).\nPhotoshop CC 2018 (version 19) was released on October 18, 2017. It featured an overhaul to the brush organization system, allowing for more properties (such as color and opacity) to be saved per-brush and for brushes to be categorized in folders and sub-folders. It also added brush stroke smoothing, and over 1000 brushes created by Kyle T. Webster (following Adobe's acquisition of his website, KyleBrush.com). A Curvature Pen tool, similar to the one in Illustrator, was added, allowing for faster creation of B\u00e9zier paths. Other additions were Lightroom Photo access, Variable font support, select subject, copy-paste layers, enhanced tooltips, 360 panorama and HEIF support, PNG compression, increased maximum zoom level, symmetry mode, algorithm improvements to Face-aware and selection tools, color and luminance range masking, improved image resizing, and performance improvements to file opening, filters, and brush strokes.\nCC 2019 (version 20).\nPhotoshop CC 2019 was released on October 15, 2018. Beginning with Photoshop CC 2019 (version 20.0), the 32-bit version of Windows is no longer supported. This version Introduced a new tool called Frame Tool to create placeholder frames for images. It also added multiple undo mode, auto-commitment, and prevented accidental panel moves with lock work-space. Live blend mode previews are added, allowing for faster scrolling over different blend mode options in the layers panel. Other additions were Color Wheel, Transform proportionally without Shift key, Distribute spacing like in Illustrator, ability to see longer layer names, match font with Japanese fonts, flip document view, scale UI to font, reference point hidden by default, new compositing engine, which provides a more modern compositing architecture is added which is easier to optimize on all platforms.\n2020 (version 21).\nPhotoshop 2020 was released on November 4, 2019. Version 21 has many new and enhanced features like the new object selection tool for better automation of complex selections, new properties panel, enhanced transform warp, new keyboard shortcuts for paint &amp; brush and background image removal option. It added several improvements to the new content-aware fill and to the new document tab. Also added were animated GIF support, improved lens blur performance and one-click zoom to a layer's contents. It introduced new swatches, gradients, patterns, shapes and stylistic sets for OpenType fonts. With this version users now can easily convert smart objects to layers and also can adjust 32-bit layers for brightness/contrast and curves. Presets are now more intuitive to use and easier to organize.\nWith the February 2020 update (version 21.1) Photoshop now can iteratively fill multiple areas of an image without having to leave content-aware fill workspace. This version improved GPU based lens blur quality and provided performance improvements, such as accelerating workflows with smoother panning, zooming and navigation of documents.\nVersion 21 was the first version where the iPad version was released. With Photoshop on the iPad, combined with the new Cloud PSD file format, a user can save cloud documents and work across Windows, Mac and iPad. Photoshop on the iPad does not have all the features of the desktop Photoshop. Adobe promises to update Photoshop on the iPad at \"a much more aggressive pace than it has with its current Creative Cloud apps for the desktop\". Adobe has provided a timeline for enhancing Photoshop on the iPad to have more of the features of desktop Photoshop.\nVersion 21.2 of the desktop version was released in June 2020. It introduced faster portrait selection, Adobe Camera Raw improvements, auto-activated Adobe Fonts, rotatable patterns, and improved Match Font.\n2021 (version 22).\nVersion 22.0.0 was released in October 2020.\nVersion 22.0.1 was released in November 2020.\nVersion 22.1.0 was released in December 2020.\nVersion 22.1.1 was released in January 2021.\nVersion 22.2 was released in February 2021.\nVersion 22.3 was released in March 2021. This is the first macOS release to run natively on Apple silicon.\nVersion 22.3.1 was released in April 2021.\nVersion 22.4 was released in May 2021.\nVersion 22.4.1 was released in May 2021.\nVersion 22.4.2 was released in June 2021.\nVersion 22.4.3 was released in July 2021.\nVersion 22.5 was released in August 2021.\nVersion 22.5.1 was released in September 2021. Final version to include (as Legacy Swatches) a large set of Pantone color books, including Pastels &amp; Neons, and Premium Metallics.\n2022 (version 23).\nVersion 23.0 was released in October 2021. First version to include (as Legacy Swatches) a reduced set of Pantone color books - only CMYK, Metallics and Solid colors.\nContent Credentials (Beta) was introduced. When enabled, the editing information is captured in a tamper-evident form and resides with the file through successive copy generations. It aligns with the C2PA standard on digital provenance across the internet.\nVersion 23.0.1 was released in November 2021.\nVersion 23.0.2 was released in November 2021.\nVersion 23.1 was released in December 2021.\nVersion 23.1.1 was released in January 2022.\nVersion 23.2 was released in February 2022.\nVersion 23.3 was released in April 2022.\nVersion 23.4 was released in June 2022.\nVersion 23.5 was released in August 2022. Final version with built-in support for basic Pantone colors - CMYK, Metallics and Solid (as Legacy Swatches). Future versions require a separate subscription to access Pantone colors.\n2023 (version 24).\nVersion 24.0 was released in October 2022. First version without built-in support for Pantone colors. All Pantone colors have been removed as of August 16, 2022. Separate paid subscription now required to access Pantone Connect extension and download color \"fandecks\".\nVersion 24.1 was released in December 2022.\nVersion 24.4.1 was released on April 20, 2023.\nVersion 24.7 was released on July 27, 2023.\n2024 (version 25).\nVersion 25.0 was released in September 2023. This version added Generative Fill and Generative Expand for commercial use. This was the last version where the CPU requirements on the Intel platform were limited to only SSE 4.2 instructions, which meant the x86-64-v2 microarchitecture (Intel Nehalem and newer, AMD Bulldozer and newer).\n2025 (version 26).\nVersion 26 was released in October 2024. The CPU requirements on the Intel platform have been increased to support AVX2 instructions, which means the x86-64-v3 microarchitecture (Intel Haswell and newer, AMD Excavator and newer).\nAdobe Photoshop family.\nThe Adobe Photoshop family is a group of applications and services made by Adobe for the use of professional image editing. Several features of the Adobe Photoshop family are pixel manipulating, image organizing, photo retouching, and more.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24894", "revid": "20841863", "url": "https://en.wikipedia.org/wiki?curid=24894", "title": "PaintShop Pro", "text": "Raster and vector graphics editor\nPaintShop Pro (PSP) is a raster and vector graphics editor for Microsoft Windows. It was originally published by Jasc Software. In October 2004, Corel purchased Jasc Software and the distribution rights to PaintShop Pro. PSP functionality can be extended by Photoshop-compatible plugins.\nThe X-numbered editions have been sold in two versions: PaintShop Pro, which is the basic editing program, and PaintShop Pro Ultimate, which bundles in other standalone programs, additional artistic tools and/or plugins. The particular bundled programs have varied with each numbered version and have not been sold by Corel as separate products.\nFrom release 8.00 onwards PSP came with an interface for automating tasks with scripts written in Python.\nHistory.\nOriginally called GIF2PCX, the software was a file conversion utility, conceived by Robert Voit, used to move images between the major online platforms of the time, Compuserve and AOL. Each platform had their own file format for images, so the utility allowed users to share images on either platform. When basic image editing was added, the name was changed to Paint Shop. The first version, 1.0, supported image conversions picture converter between BMP, GIF and PCX formats, and basic full-image enhancements like changing brightness and contrast. Paint Shop 1.0 was released by Robert Voit in August 1990. The name was changed to Paint Shop Pro when full painting, such as with variable sized brushes, was added to the product. Paint Shop was originally distributed as shareware and is still available at many download sites (4.12 being a popular version). Most newer versions are only commercially available although some have been distributed in the United Kingdom in computer magazine CDs after they became obsolete.\nPaintShop Pro 5 added support for layers as well as CMYK and HSL colour modes, included JASC Animation Shop for creating animations and in fact was marketed as \"Paint Shop Pro 5.0 with Animation Shop\". PaintShop Pro X6 was the first to be available as a native 64-bit version (purchase includes both versions). PaintShop Pro X7 includes content-aware features such as \"Magic Fill\" and \"Smart Edge\" as well as support for XMP sidecar files that preserve edit settings for raw formats.\nFrom 2006 to 2011 (versions XI to X3), PaintShop Pro was marketed as \"Corel Paint Shop Pro Photo\". Having dropped the \"Photo\" part of the name in version X4, Paintshop Pro X5 was derived from Ulead Photo Explorer after Corel's acquisition of Ulead.\nOn November 28, 2007, Corel announced that the office in Eden Prairie, Minnesota, where Paint Shop Pro was created, would be shut down, with development moving to offices in California and China.\nVersion history.\nJASC Paint Shop releases: 1990?\u20131993.\nIn the table below, \"italicized\" dates are approximate, based on the earliest file timestamp on JASC or Corel's FTP server. Non-italicized dates are sourced from official press releases or notifications posted on JASC's web site.\nPicture tubes.\nPicture tubes are graphic images with no background. They are often used as a starting point for complex images; that is, they are combined with other image elements to produce a final work. Tubes can also be regarded as graphic brushes based on a pre-created image; this was their original use. Instead of leaving a trace of color on the canvas, they would leave a trail of images. Popular tube subjects include alphabets, humans (also known as dollz), animal and toy figures, flowers, love messages and seasonal symbols.\nThe tube system originated with PSP Pro version 5. Native tube files may be in .tub, .psp, .pspimage, and .psptube formats. XnView, IrfanView, and TubeEx are separate graphics programs that can convert tube files (.tub) to .png.\nUltimate edition.\nPaintShop Pro Photo X2 Ultimate was released towards the end of life of PaintShop Pro Photo X2, in September 2008. It included 150 additional picture frames and Picture Tubes, the programs Background Remover, Corel Painter Photo Essentials 4, and Photorecovery, as well as RAW support for 250 cameras and a 2GB flash drive.\nSubsequent Ultimate editions were released contemporaneously with the basic version. PaintShop Pro X4 Ultimate included Nik Color Efex Pro 3.0, a voucher for 21 images from Fotolia at high quality, and additional Picture Tubes. X5 Ultimate included Reallusion FaceFilter Studio 2.0, NIK Color Efex Pro 3.0, and \"over 100 unique brushes, textures and royalty-free backgrounds\". PaintShop Pro X6 Ultimate includes Athentech Imaging's Perfectly Clear and Reallusion's FaceFilter3 Standard. PaintShop Pro X7 Ultimate includes those same two items.\nThe bundled extras cannot be installed unless that version of the PaintShop program is already installed. However, once a bundled extra such as a plugin has been installed, the installed files can be copied to other versions, e.g., a plugin installed under X5 can be copied to X6 and even if X5 is then uninstalled, the plugin will continue to work under X6. Corel releases a new X version roughly annually, so this ability to copy means PSP users do not have to choose between updating or continued use of Ultimate add-ons from previous versions.\nLicense management software.\nVersions X through to X8 install a third-party program named PSIService.exe, a Windows service called ProtexisLicensing. Written by Protexis, this runs in the background and collects licensing information. This program communicates with a remote host. Manually disabling the Protexis Licensing service may cause Corel Paint Shop Pro Photo to cease functioning.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "24895", "revid": "43126305", "url": "https://en.wikipedia.org/wiki?curid=24895", "title": "Paleography", "text": ""}
