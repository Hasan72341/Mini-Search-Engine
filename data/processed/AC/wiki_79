{"id": "27954", "revid": "7852030", "url": "https://en.wikipedia.org/wiki?curid=27954", "title": "Susan B. Anthony", "text": "American women's rights activist (1820\u20131906)\nSusan B. Anthony (born Susan Anthony; February 15, 1820\u00a0\u2013 March 13, 1906) was an American social reformer and women's rights activist who played a pivotal role in the women's suffrage movement. Born into a Quaker family committed to social equality, she collected anti-slavery petitions at the age of 17. In 1856, she became the New York state agent for the American Anti-Slavery Society.\nIn 1851, she met Elizabeth Cady Stanton, who became her lifelong friend and co-worker in social reform activities, primarily in the field of women's rights. Together they founded the New York Women's State Temperance Society after Anthony was prevented from speaking at a temperance conference because she was female. During the Civil War they founded the Women's Loyal National League, which conducted the largest petition drive in United States history up to that time, collecting nearly 400,000 signatures in support of the abolition of slavery. After the war, they initiated the American Equal Rights Association, which campaigned for equal rights for both women and African Americans. They began publishing a women's rights newspaper in 1868 called \"The Revolution\". A year later, they founded the National Woman Suffrage Association as part of a split in the women's movement. The split was formally healed in 1890 when their organization merged with the rival American Woman Suffrage Association to form the National American Woman Suffrage Association, with Anthony as its key force. Anthony and Stanton began working with Matilda Joslyn Gage in 1876 on what eventually grew into the six-volume \"History of Woman Suffrage\". The interests of Anthony and Stanton diverged somewhat in later years, but the two remained close friends.\nIn 1872, Anthony was arrested in her hometown of Rochester, New York, for voting in violation of laws that allowed only men to vote. She was convicted in a widely publicized trial. Although she refused to pay the fine, the authorities declined to take further action. In 1878, Anthony and Stanton arranged for Congress to be presented with an amendment giving women the right to vote. Introduced by Sen. Aaron A. Sargent (R-CA), it later became known colloquially as the Susan B. Anthony Amendment. It was eventually ratified as the Nineteenth Amendment to the U.S. Constitution in 1920.\nAnthony traveled extensively in support of women's suffrage, giving as many as 75 to 100 speeches per year and working on many state campaigns. She worked internationally for women's rights, playing a key role in creating the International Council of Women, which is still active. She also helped to bring about the World's Congress of Representative Women at the World's Columbian Exposition in Chicago in 1893.\nWhen she first began campaigning for women's rights, Anthony was harshly ridiculed and accused of trying to destroy the institution of marriage. Public perception of her changed radically during her lifetime, however. Her 80th birthday was celebrated in the White House at the invitation of President William McKinley. She became the first female citizen to be depicted on U.S. coinage when her portrait appeared on the 1979 dollar coin.\nEarly life.\nSusan Anthony was born on February 15, 1820, to Daniel Anthony and Lucy Read Anthony in Adams, Massachusetts, the second-oldest of seven children. She was named for her maternal grandmother Susanah, and for her father's sister Susan. In her youth, she and her sisters responded to a \"great craze for middle initials\" by adding middle initials to their own names. Anthony adopted \"B.\" as her middle initial because her namesake Aunt Susan had married a man named Brownell. Anthony never used the name Brownell herself, and did not like it.\nHer family shared a passion for social reform. Her brothers Daniel and Merritt moved to Kansas to support the anti-slavery movement there. Merritt fought with John Brown against pro-slavery forces during the Bleeding Kansas crisis. Daniel eventually owned a newspaper and became mayor of Leavenworth. Anthony's sister Mary, with whom she shared a home in later years, became a public school principal in Rochester, and a woman's rights activist.\nAnthony's father was an abolitionist and a temperance advocate. A Quaker, he had a difficult relationship with his traditionalist congregation, which rebuked him for marrying a non-Quaker, and then disowned him for allowing a dance school to operate in his home. He continued to attend Quaker meetings anyway and became even more radical in his beliefs.\nAnthony's mother was a Baptist and helped raise their children in a more tolerant version of her husband's religious tradition. Their father encouraged them all, girls as well as boys, to be self-supporting, teaching them business principles and giving them responsibilities at an early age.\nWhen Anthony was six years old, her family moved to Battenville, New York, where her father managed a large cotton mill. Previously he had operated his own small cotton factory.\nWhen she was seventeen, Anthony was sent to a Quaker boarding school in Philadelphia, where she unhappily endured its strict and sometimes humiliating atmosphere.\nShe was forced to end her studies after one term because her family was financially ruined during an economic downturn known as the Panic of 1837. They were forced to sell everything they had at an auction, but they were rescued by her maternal uncle, who bought most of their belongings and restored them to the family.\nTo assist her family financially, Anthony left home to teach at a Quaker boarding school.\nIn 1845, the family moved to a farm on the outskirts of Rochester, New York, purchased partly with the inheritance of Anthony's mother, and the family became active in the anti-slavery movement. There they associated with a group of Quaker social reformers who had left their congregation because of the restrictions it placed on reform activities, and who in 1848 formed a new organization called the Congregational Friends. The Anthony farmstead soon became the Sunday afternoon gathering place for local activists, including Frederick Douglass, a former slave and a prominent abolitionist who became Anthony's lifelong friend.\nThe Anthony family began to attend services at the First Unitarian Church of Rochester, which was associated with social reform. The Rochester Women's Rights Convention of 1848 was held at that church in 1848, inspired by the Seneca Falls Convention, the first women's rights convention, which was held two weeks earlier in a nearby town. Anthony's parents and her sister Mary attended the Rochester convention and signed the Declaration of Sentiments that had been first adopted by the Seneca Falls Convention.\nAnthony did not take part in either of these conventions because she had moved to Canajoharie in 1846 to be headmistress of the female department of the Canajoharie Academy. Away from Quaker influences for the first time in her life, at the age of 26 she began to replace her plain clothing with more stylish dresses, and she quit using \"thee\" and other forms of speech traditionally used by Quakers. She was interested in social reform, and she was distressed at being paid much less than men with similar jobs, but she was amused at her father's enthusiasm over the Rochester women's rights convention. She later explained, \"I wasn't ready to vote, didn't want to vote, but I did want equal pay for equal work.\"\nWhen the Canajoharie Academy closed in 1849, Anthony took over the operation of the family farm in Rochester so her father could devote more time to his insurance business. She worked at this task for a couple of years but found herself increasingly drawn to reform activity. With her parents' support, she was soon fully engaged in reform work. For the rest of her life, she lived almost entirely on fees she earned as a speaker.\nActivism.\nEarly social activism.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nCautious, careful people, always casting about to preserve their reputation and social standing, never can bring about a reform. Those who are really in earnest must be willing to be anything or nothing in the world's estimation, and publicly and privately, in season and out, avow their sympathy with despised and persecuted ideas and their advocates, and bear the consequences.\nSusan B. Anthony, 1860\nAnthony embarked on her career of social reform with energy and determination. Schooling herself in reform issues, she found herself drawn to the more radical ideas of people like William Lloyd Garrison, George Thompson and Elizabeth Cady Stanton. Soon she was wearing the controversial Bloomer dress, consisting of pantaloons worn under a knee-length dress. Although she felt it was more sensible than the traditional heavy dresses that dragged the ground, she reluctantly quit wearing it after a year because it gave her opponents the opportunity to focus on her apparel rather than her ideas.\nPartnership with Elizabeth Cady Stanton.\nIn 1851, Anthony was introduced to Elizabeth Cady Stanton, who had been one of the organizers of the Seneca Falls Convention and had introduced the controversial resolution in support of women's suffrage. Anthony and Stanton were introduced by Amelia Bloomer, a feminist and mutual acquaintance. Anthony and Stanton soon became close friends and co-workers, forming a relationship that was pivotal for them and for the women's movement as a whole. After the Stantons moved from Seneca Falls to New York City in 1861, a room was set aside for Anthony in every house they lived in. One of Stanton's biographers estimated that over her lifetime, Stanton probably spent more time with Anthony than with any other adult, including her own husband.\nThe two women had complementary skills. Anthony excelled at organizing, while Stanton had an aptitude for intellectual matters and writing. Anthony was dissatisfied with her own writing ability and wrote relatively little for publication. When historians illustrate her thoughts with direct quotes, they usually take them from her speeches, letters, and diary entries.\nBecause Stanton was homebound with seven children while Anthony was unmarried and free to travel, Anthony assisted Stanton by supervising her children while Stanton wrote. One of Anthony's biographers said, \"Susan became one of the family and was almost another mother to Mrs. Stanton's children.\" A biography of Stanton says that during the early years of their relationship, \"Stanton provided the ideas, rhetoric, and strategy; Anthony delivered the speeches, circulated petitions, and rented the halls. Anthony prodded and Stanton produced.\"\nStanton's husband said, \"Susan stirred the puddings, Elizabeth stirred up Susan, and then Susan stirs up the world!\"\nStanton herself said, \"I forged the thunderbolts, she fired them.\"\nBy 1854, Anthony and Stanton \"had perfected a collaboration that made the New York State movement the most sophisticated in the country\", according to Ann D. Gordon, a professor of women's history.\nTemperance activities.\nTemperance was very much a women's rights issue at that time because of laws that gave husbands complete control of the family and its finances. A woman with a drunken husband had little legal recourse even if his alcoholism left the family destitute and he was abusive to her and their children. If she obtained a divorce, which was difficult to do, he could easily end up with sole guardianship of the children.\nWhile teaching in Canajoharie, Anthony joined the Daughters of Temperance and in 1849 gave her first public speech at one of its meetings.\nIn 1852, she was elected as a delegate to the state temperance convention, but the chairman stopped her when she tried to speak, saying that women delegates were there only to listen and learn. Anthony and some other women immediately walked out and announced a meeting of their own, which created a committee to organize a women's state convention. Largely organized by Anthony, the convention of 500 women met in Rochester in April and created the Women's State Temperance Society, with Stanton as president and Anthony as state agent.\nAnthony and her co-workers collected 28,000 signatures on a petition for a law to prohibit the sale of alcohol in New York State. She organized a hearing on that law before the New York legislature, the first that had been initiated in that state by a group of women. At the organization's convention the following year, however, conservative members attacked Stanton's advocacy of the right of a wife of an alcoholic to obtain a divorce. Stanton was voted out as president, whereupon she and Anthony resigned from the organization.\nIn 1853, Anthony attended the World's Temperance Convention in New York City, which bogged down for three chaotic days in a dispute about whether women would be allowed to speak there.\nYears later, Anthony observed, \"No advanced step taken by women has been so bitterly contested as that of speaking in public. For nothing which they have attempted, not even to secure the suffrage, have they been so abused, condemned and antagonized.\" After this period, Anthony focused her energy on abolitionist and women's rights activities.\nTeachers' conventions.\nWhen Anthony tried to speak at the New York State Teachers' Association meeting in 1853, her attempt sparked a half-hour debate among the men about whether it was proper for women to speak in public. Finally allowed to continue, Anthony said, \"Do you not see that so long as society says a woman is incompetent to be a lawyer, minister, or doctor, but has ample ability to be a teacher, that every man of you who chooses this profession tacitly acknowledges that he has no more brains than a woman.\"\nAt the 1857 teacher's convention, she introduced a resolution calling for the admission of black people to public schools and colleges, but it was rejected as \"not a proper subject for discussion\". When she introduced another resolution calling for males and females to be educated together at all levels, including colleges, it was fiercely opposed and decisively rejected. One opponent called the idea \"a vast social evil... the first step in the school which seeks to abolish marriage, and behind this picture I see a monster of social deformity.\"\nAnthony continued to speak at state teachers' conventions for several years, insisting that women teachers should receive equal pay with men and serve as officers and committee members within the organization.\nEarly women's rights activities.\nAnthony's work for the women's rights movement began at a time when that movement was already gathering momentum. Stanton had helped organize the Seneca Falls Convention in 1848, a local event that was the first women's rights convention. In 1850, the first in a series of National Women's Rights Conventions was held in Worcester, Massachusetts. In 1852, Anthony attended her first National Women's Rights Convention, which was held in Syracuse, New York, where she served as one of the convention's secretaries. According to Ida Husted Harper, Anthony's authorized biographer, \"Miss Anthony came away from the Syracuse convention thoroughly convinced that the right which woman needed above every other, the one indeed which would secure to her all others, was the right of suffrage.\" Suffrage, however, did not become the main focus of her work for several more years.\nA major hindrance to the women's movement was a lack of money. Few women at that time had an independent source of income, and even those with employment generally were required by law to turn over their pay to their husbands.\nPartly through the efforts of the women's movement, a law had been passed in New York in 1848 that recognized some rights for married women, but that law was limited. In 1853, Anthony worked with William Henry Channing, her activist Unitarian minister, to organize a convention in Rochester to launch a state campaign for improved property rights for married women, which Anthony would lead. She took her lecture and petition campaign into almost every county in New York during the winter of 1855 despite the difficulty of traveling in snowy terrain in horse and buggy days.\nWhen she presented the petitions to the New York State Senate Judiciary Committee, its members told her that men were actually the oppressed sex because they did such things as giving women the best seats in carriages. Noting cases in which the petition had been signed by both husbands and wives (instead of the husband signing for both, which was the standard procedure), the committee's official report sarcastically recommended that the petitioners seek a law authorizing the husbands in such marriages to wear petticoats and the wives trousers.\nThe campaign finally achieved success in 1860 when the legislature passed an improved Married Women's Property Act that gave married women the right to own separate property, enter into contracts and be the joint guardian of their children. The legislature rolled back much of this law in 1862, however, during a period when the women's movement was largely inactive because of the American Civil War.\nThe women's movement was loosely structured at that time, with few state organizations and no national organization other than a coordinating committee that arranged annual conventions.\nLucy Stone, who did much of the organizational work for the national conventions, encouraged Anthony to take over some of the responsibility for them. Anthony resisted at first, feeling that she was needed more in the field of anti-slavery activities. After organizing a series of anti-slavery meetings in the winter of 1857, Anthony told a friend that, \"the experience of the last winter is worth more to me than all my temperance and woman's rights work, though the latter were the school necessary to bring me into the antislavery work.\"\nDuring a planning session for the 1858 women's rights convention, Stone, who had recently given birth, told Anthony that her new family responsibilities would prevent her from organizing conventions until her children were older. Anthony presided at the 1858 convention, and when the planning committee for national conventions was reorganized, Stanton became its president and Anthony its secretary.\nAnthony continued to be heavily involved in anti-slavery work at the same time.\nAnti-slavery activities.\nIn 1837, at age 16, Anthony collected petitions against slavery as part of organized resistance to the newly established gag rule that prohibited anti-slavery petitions in the U.S. House of Representatives.\nIn 1851, she played a key role in organizing an anti-slavery convention in Rochester. She was also part of the Underground Railroad. An entry in her diary in 1861 read, \"Fitted out a fugitive slave for Canada with the help of Harriet Tubman.\"\nIn 1856, Anthony agreed to become the New York State agent for the American Anti-Slavery Society with the understanding that she would also continue her advocacy of women's rights.\nAnthony organized anti-slavery meetings throughout the state under banners that read \"No compromise with slaveholders. Immediate and Unconditional Emancipation.\"\nIn 1859, John Brown was executed for leading a violent raid on the U.S. arsenal at Harper's Ferry in what was intended to be the beginning of an armed slave uprising. Anthony organized and presided over a meeting of \"mourning and indignation\" in Rochester's Corinthian Hall on the day of his execution to raise money for Brown's family.\nShe developed a reputation for fearlessness in facing down attempts to disrupt her meetings, but opposition became overwhelming on the eve of the Civil War. Mob action shut down her meetings in every town from Buffalo to Albany in early 1861. In Rochester, the police had to escort Anthony and other speakers from the building for their own safety. In Syracuse, according to a local newspaper, \"Rotten eggs were thrown, benches broken, and knives and pistols gleamed in every direction.\"\nAnthony expressed a vision of a racially integrated society that was radical for a time when abolitionists were debating the question of what was to become of the slaves after they were freed, and when people like Abraham Lincoln were calling for African Americans to be shipped to newly established colonies in Africa. In a speech in 1861, Anthony said, \"Let us open to the colored man all our schools ... Let us admit him into all our mechanic shops, stores, offices, and lucrative business avocations ... let him rent such pew in the church, and occupy such seat in the theatre ... Extend to him all the rights of Citizenship.\"\nThe relatively small women's rights movement of that time was closely associated with the American Anti-Slavery Society led by William Lloyd Garrison. The women's movement depended heavily on abolitionist resources, with its articles published in their newspapers and some of its funding provided by abolitionists. There was tension, however, between leaders of the women's movement and male abolitionists who, although supporters of increased women's rights, believed that a vigorous campaign for women's rights would interfere with the campaign against slavery. In 1860, when Anthony sheltered a woman who had fled an abusive husband, Garrison insisted that the woman give up the child she had brought with her, pointing out that the law gave husbands complete control of children. Anthony reminded Garrison that he helped slaves escape to Canada in violation of the law and said, \"Well, the law which gives the father ownership of the children is just as wicked and I'll break it just as quickly.\"\nWhen Stanton introduced a resolution at the National Woman's Rights Convention in 1860 favoring more lenient divorce laws, leading abolitionist Wendell Phillips not only opposed it but attempted to have it removed from the record. When Stanton, Anthony, and others supported a bill before the New York legislature that would permit divorce in cases of desertion or inhuman treatment, Horace Greeley, an abolitionist newspaper publisher, campaigned against it in the pages of his newspaper.\nGarrison, Phillips and Greeley had all provided valuable help to the women's movement. In a letter to Lucy Stone, Anthony said, \"The Men, even the \"best\" of them, seem to think the Women's Rights question should be waived for the present. So let us do our own work, and in our own way.\"\nOn February 13, 1928, Representative Charles Hillyer Brand gave a \"brief statement of the life and activities\" of Anthony\u2014partly titled \"militant suffragist\"\u2014in which he noted that in 1861, Anthony was \"persuaded to give up preparations for the annual women's rights convention to concentrate on work to win the war, though she was not misled by the sophistry that the rights of women would be recognized after the war if they helped to end it.\"\nWomen's Loyal National League.\nAnthony and Stanton organized the Women's Loyal National League in 1863 to campaign for an amendment to the U.S. Constitution that would abolish slavery.\nIt was the first national women's political organization in the United States. In the largest petition drive in the nation's history up to that time, the League collected nearly 400,000 signatures to abolish slavery, representing approximately one out of every twenty-four adults in the Northern states.\nThe petition drive significantly assisted the passage of the Thirteenth Amendment, which ended slavery. Anthony was the chief organizer of this effort, which involved recruiting and coordinating some 2000 petition collectors.\nThe League provided the women's movement with a vehicle for combining the fight against slavery with the fight for women's rights by reminding the public that petitioning was the only political tool available to women at a time when only men were allowed to vote.\nWith a membership of 5000, it helped develop a new generation of women leaders, providing experience and recognition for not only Stanton and Anthony but also newcomers like Anna Dickinson, a gifted teenaged orator.\nThe League demonstrated the value of formal structure to a women's movement that had resisted being anything other than loosely organized up to that point.\nThe widespread network of women activists who assisted the League expanded the pool of talent that was available to reform movements, including the women's suffrage movement, after the war.\nAmerican Equal Rights Association.\nAnthony stayed with her brother Daniel in Kansas for eight months in 1865 to assist with his newspaper. She headed back east after she learned that an amendment to the U.S. Constitution had been proposed that would provide citizenship for African Americans but would also for the first time introduce the word \"male\" into the constitution. Anthony supported citizenship for blacks but opposed any attempt to link it with a reduction in the status of women. Her ally Stanton agreed, saying \"if that word 'male' be inserted, it will take us a century at least to get it out.\"\nAnthony and Stanton worked to revive the women's rights movement, which had become nearly dormant during the Civil War. In 1866, they organized the Eleventh National Women's Rights Convention, the first since the Civil War began. Unanimously adopting a resolution introduced by Anthony, the convention voted to transform itself into the American Equal Rights Association (AERA), whose purpose was to campaign for the equal rights of all citizens, especially the right of suffrage. The leadership of the new organization included such prominent activists as Lucretia Mott, Lucy Stone, and Frederick Douglass.\nThe AERA's drive for universal suffrage was resisted by some abolitionist leaders and their allies in the Republican Party. During the period before the 1867 convention to revise the New York state constitution, Horace Greeley, a prominent newspaper editor, told Anthony and Stanton, \"This is a critical period for the Republican Party and the life of our Nation... I conjure you to remember that this is 'the negro's hour,' and your first duty now is to go through the State and plead his claims.\" Abolitionist leaders Wendell Phillips and Theodore Tilton met with Anthony and Stanton in the office of the National Anti-Slavery Standard, a leading abolitionist newspaper. The two men tried to convince the two women that the time had not yet come for women's suffrage, that they should campaign not for voting rights for both women and African Americans in the revised state constitution but for voting rights for black men only. According to Ida Husted Harper, Anthony's authorized biographer, Anthony \"was highly indignant and declared that she would sooner cut off her right hand than ask the ballot for the black man and not for woman.\" Anthony and Stanton continued to work for the inclusion of suffrage for both African Americans and women.\nIn 1867, the AERA campaigned in Kansas for referendums that would enfranchise both African Americans and women. Wendell Phillips, who opposed mixing those two causes, blocked the funding that the AERA had expected for their campaign.\nAfter an internal struggle, Kansas Republicans decided to support suffrage for black men only and formed an \"Anti Female Suffrage Committee\" to oppose the AERA's efforts.\nBy the end of summer, the AERA campaign had almost collapsed, and its finances were exhausted. Anthony and Stanton created a storm of controversy by accepting help during the last days of the campaign from George Francis Train, a wealthy businessman who supported women's rights. Train antagonized many activists by attacking the Republican Party and openly disparaging the integrity and intelligence of African Americans.\nThere is reason to believe, however, that Anthony and Stanton hoped to draw the volatile Train away from his cruder forms of racism, and that he had actually begun to do so.\nAfter the Kansas campaign, the AERA increasingly divided into two wings, both advocating universal suffrage but with different approaches. One wing, whose leading figure was Lucy Stone, was willing for black men to achieve suffrage first and wanted to maintain close ties with the Republican Party and the abolitionist movement. The other, whose leading figures were Anthony and Stanton, insisted that women and black men should be enfranchised at the same time and worked toward a politically independent women's movement that would no longer be dependent on abolitionists. The AERA effectively dissolved after an acrimonious meeting in May 1869, and two competing woman suffrage organizations were created in its aftermath.\n\"The Revolution\".\nAnthony and Stanton began publishing a weekly newspaper called \"The Revolution\" in New York City in 1868. It focused primarily on women's rights, especially suffrage for women, but it also covered other topics, including politics, the labor movement and finance. Its motto was \"Men, their rights and nothing more: women, their rights and nothing less.\"\nOne of its goals was to provide a forum in which women could exchange opinions on key issues from a variety of viewpoints. Anthony managed the business aspects of the paper while Stanton was co-editor along with Parker Pillsbury, an abolitionist and a supporter of women's rights. Initial funding was provided by George Francis Train, the controversial businessman who supported women's rights but who alienated many activists with his political and racial views.\nIn the aftermath of the Civil War, major periodicals associated with the radical social reform movements had either become more conservative or had quit publishing or soon would.\nAnthony intended for \"The Revolution\" to partially fill that void, hoping to grow it eventually into a daily paper with its own printing press, all owned and operated by women. The funding Train had arranged for the newspaper, however, was less than Anthony had expected. Moreover, Train sailed for England after \"The Revolution\" published its first issue and was soon jailed for supporting Irish independence.\nTrain's financial support eventually disappeared entirely. After twenty-nine months, mounting debts forced Anthony to transfer the paper to Laura Curtis Bullard, a wealthy women's rights activist who gave it a less radical tone. The paper published its last issue less than two years later.\nDespite its short life, \"The Revolution\" gave Anthony and Stanton a means for expressing their views during the developing split within the women's movement. It also helped them promote their wing of the movement, which eventually became a separate organization.\nAttempted alliance with labor.\nThe National Labor Union (NLU), which was formed in 1866, began reaching out to farmers, African Americans and women, with the intention of forming a broad-based political party. \"The Revolution\" responded enthusiastically, declaring, \"The principles of the National Labor Union are our principles.\" It predicted that \"The producers\u2014the working-men, the women, the negroes\u2014are destined to form a triple power that shall speedily wrest the sceptre of government from the non-producers\u2014the land monopolists, the bond-holders, the politicians.\"\nAnthony and Stanton were seated as delegates to the NLU Congress in 1868, with Anthony representing the Working Women's Association (WWA), which had recently been formed in the offices of \"The Revolution\".\nThe attempted alliance did not last long. During a printers' strike in 1869, Anthony voiced approval of an employer-sponsored training program that would teach women skills that would enable them in effect to replace the strikers. Anthony viewed the program as an opportunity to increase employment of women in a trade from which women were often excluded by both employers and unions. At the next NLU Congress, Anthony was first seated as a delegate but then unseated because of strong opposition from those who accused her of supporting strikebreakers.\nAnthony worked with the WWA to form all-female labor unions, but with little success. She accomplished more in her work with the joint campaign by the WWA and \"The Revolution\" to win a pardon for Hester Vaughn, a domestic worker who had been found guilty of infanticide and sentenced to death. Charging that the social and legal systems treated women unfairly, the WWA petitioned, organized a mass meeting at which Anthony was one of the speakers, and sent delegations to visit Vaughn in prison and to speak with the governor. Vaughn was eventually pardoned.\nOriginally with a membership that included over a hundred wage-earning women, the WWA evolved into an organization consisting almost entirely of journalists, doctors and other middle-class working women. Its members formed the core of the New York City portion of the new national suffrage organization that Anthony and Stanton were in the process of forming.\nSplit in the women's movement.\nIn May 1869, two days after the final AERA convention, Anthony, Stanton and others formed the National Woman Suffrage Association (NWSA). In November 1869, Lucy Stone, Julia Ward Howe and others formed the competing American Woman Suffrage Association (AWSA). The hostile nature of their rivalry created a partisan atmosphere that endured for decades, affecting even professional historians of the women's movement.\nThe immediate cause for the split was the proposed Fifteenth Amendment to the U.S. Constitution, which would prohibit the denial of suffrage because of race. In one of her most controversial actions, Anthony campaigned against the amendment. She and Stanton called for women and African Americans to be enfranchised at the same time. They said that by effectively enfranchising all men while excluding all women, the amendment would create an \"aristocracy of sex\" by giving constitutional authority to the idea that men were superior to women. In 1873, Anthony said, \"An oligarchy of wealth, where the rich govern the poor; an oligarchy of learning, where the educated govern the ignorant; or even an oligarchy of race, where the Saxon rules the African, might be endured; but surely this oligarchy of sex, which makes the men of every household sovereigns, masters; the women subjects, slaves; carrying dissension, rebellion into every home of the Nation, cannot be endured.\"\nThe AWSA supported the amendment, but Lucy Stone, who became its most prominent leader, also made it clear that she believed that suffrage for women would be more beneficial to the country than suffrage for black men.\nThe two organizations had other differences as well. The NWSA was politically independent, but the AWSA at least initially aimed for close ties with the Republican Party, hoping that the ratification of the Fifteenth Amendment would lead to a Republican push for women's suffrage. The NWSA focused primarily on winning suffrage at the national level while the AWSA pursued a state-by-state strategy. The NWSA initially worked on a wider range of women's issues than the AWSA, including divorce reform and equal pay for women.\nEvents soon removed much of the basis for the split in the women's movement. In 1870, debate about the Fifteenth Amendment was made irrelevant when that amendment was officially ratified. In 1872, disgust with corruption in government led to a mass defection of abolitionists and other social reformers from the Republicans to the short-lived Liberal Republican Party. As early as 1875, Anthony began urging the NWSA to focus more exclusively on women's suffrage rather than a variety of women's issues. The rivalry between the two women's groups was so bitter, however, that a merger proved to be impossible for twenty years. The AWSA, which was especially strong in New England, was the larger of the two organizations, but it began to decline in strength during the 1880s.\nIn 1890, the two organizations merged as the National American Woman Suffrage Association (NAWSA), with Stanton as president but with Anthony as its effective leader. When Stanton retired from her post in 1892, Anthony became NAWSA's president.\nNational suffrage movement.\n\"By the end of the Civil War,\" according to historian Ann D. Gordon, \"Susan B. Anthony occupied new social and political territory. She was emerging on the national scene as a female leader, something new in American history, and she did so as a single woman in a culture that perceived the spinster as anomalous and unguarded ... By the 1880s, she was among the senior political figures in the United States.\"\nAfter the formation of the NWSA, Anthony dedicated herself fully to the organization and to women's suffrage. She did not draw a salary from either it or its successor, the NAWSA, but on the contrary used her lecture fees to fund those organizations. There was no national office, the mailing address being simply that of one of the officers.\nThat Anthony had remained unmarried gave her an important business advantage in this work. A married woman at that time had the legal status of \"feme covert\", which, among other things, excluded her from signing contracts (her husband could do that for her, if he chose). As Anthony had no husband, she was a \"feme sole\" and could freely sign contracts for convention halls, printed materials, etc.\nUsing fees she earned by lecturing, she paid off the debts she had accumulated while supporting \"The Revolution\". With the press treating her as a celebrity, she proved to be a major draw. Over her career she estimated that she averaged 75 to 100 speeches per year. Travel conditions in the earlier days were sometimes appalling. Once she gave a speech from the top of a billiard table. On another occasion her train was snowbound for days, and she survived on crackers and dried fish.\nBoth Anthony and Stanton joined the lecture circuit about 1870, usually traveling from mid-autumn to spring. The timing was right because the nation was beginning to discuss women's suffrage as a serious matter. Occasionally they traveled together but most often not. Lecture bureaus scheduled their tours and handled the travel arrangements, which generally involved traveling during the day and speaking at night, sometimes for weeks at a time, including weekends. Their lectures brought new recruits into the movement who strengthened suffrage organizations at the local, state and national levels. Their journeys during that decade covered a distance that was unmatched by any other reformer or politician.\nAnthony's other suffrage work included organizing national conventions, lobbying Congress and state legislatures, and participating in a seemingly endless series of state suffrage campaigns.\nA special opportunity arose in 1876 when the U.S. celebrated its 100th birthday as an independent country. The NWSA asked permission to present a Declaration of Rights for Women at the official ceremony in Philadelphia, but was refused. Undaunted, five women, headed by Anthony, walked onto the platform during the ceremony and handed their Declaration to the startled official in charge. As they left, they handed out copies of it to the crowd. Spotting an unoccupied bandstand outside the hall, Anthony mounted it and read the Declaration to a large crowd. Afterwards she invited everyone to a NWSA convention at the nearby Unitarian church where speakers like Lucretia Mott and Elizabeth Cady Stanton awaited them.\nThe work of all segments of the women's suffrage movement began to show clear results. Women won the right to vote in Wyoming in 1869 and in Utah in 1870. Her lectures in Washington and four other states led directly to invitations for her to address the state legislatures there.\nThe Grange, a large advocacy group for farmers, officially supported women's suffrage as early as 1885. The Women's Christian Temperance Union, the largest women's organization in the country, also supported suffrage.\nAnthony's commitment to the movement, her spartan lifestyle, and the fact that she did not seek personal financial gain, made her an effective fund-raiser and won her the admiration of many who did not agree with her goals. As her reputation grew, her working and travel conditions improved. She sometimes had the use of the private railroad car of Jane Stanford, a sympathizer whose husband owned a major railroad. While lobbying and preparing for the annual suffrage conventions in Washington, she was provided with a free suite of rooms in the Riggs Hotel, whose owners supported her work.\nTo ensure continuity, Anthony trained a group of younger activists, who were known as her \"nieces,\" to assume leadership roles within the organization. Two of them, Carrie Chapman Catt and Anna Howard Shaw, served as presidents of the NAWSA after Anthony retired from that position.\n\"United States v. Susan B. Anthony\".\nThe NWSA convention of 1871 adopted a strategy of urging women to attempt to vote, and then, after being turned away, to file suits in federal courts to challenge laws that prevented women from voting. The legal basis for the challenge would be the recently adopted Fourteenth Amendment, part of which reads: \"No State shall make or enforce any law which shall abridge the privileges or immunities of citizens of the United States\".\nFollowing the example set by Anthony and her sisters shortly before election day, a total of nearly fifty women in Rochester registered to vote in the presidential election of 1872. On election day, Anthony and fourteen other women from her ward convinced the election inspectors to allow them to cast ballots, but women in other wards were turned back. Anthony was arrested on November 18, 1872, by a U.S. Deputy Marshal and charged with illegally voting. The other women who had voted were also arrested but released pending the outcome of Anthony's trial.\nAnthony's trial generated a national controversy and became a major step in the transition of the broader women's rights movement into the women's suffrage movement.\nAnthony spoke throughout Monroe County, New York, where her trial was to be held and from where the jurors for her trial would be chosen. Her speech was entitled \"Is it a Crime for a U.S. Citizen to Vote?\" She said, \"We no longer petition Legislature or Congress to give us the right to vote. We appeal to women everywhere to exercise their too long neglected 'citizen's right to vote.'\"\nThe U.S. Attorney arranged for the trial to be moved to the federal circuit court, which would soon sit in neighboring Ontario County with a jury drawn from that county's inhabitants. Anthony responded by speaking throughout that county also before the trial began.\nResponsibility for that federal circuit was in the hands of Justice Ward Hunt, who had recently been appointed to the U.S. Supreme Court. Hunt had never served as a trial judge; originally a politician, he had begun his judicial career by being elected to the New York Court of Appeals.\nThe trial, \"United States v. Susan B. Anthony\", began on June 17, 1873, and was closely followed by the national press. Following a rule of common law at that time which prevented criminal defendants in federal courts from testifying, Hunt refused to allow Anthony to speak until the verdict had been delivered. On the second day of the trial, after both sides had presented their cases, Justice Hunt delivered his lengthy opinion, which he had put in writing. In the most controversial aspect of the trial, Hunt directed the jury to deliver a guilty verdict.\nOn the second day of the trial, Hunt asked Anthony if she had anything to say. She responded with \"the most famous speech in the history of the agitation for woman suffrage\", according to Ann D. Gordon, a historian of the women's movement.\nRepeatedly ignoring the judge's order to stop talking and sit down, she protested what she called \"this high-handed outrage upon my citizen's rights\", saying, \"you have trampled under foot every vital principle of our government. My natural rights, my civil rights, my political rights, my judicial rights, are all alike ignored.\"\nShe castigated Justice Hunt for denying her a trial by jury, but said that even if he had allowed the jury to discuss the case, she still would have been denied a trial by a jury of her peers because women were not allowed to be jurors.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n On the centennial of the Boston Tea Party\nSpeech to the Union League Club, N.Y.&lt;br&gt;December 16, 1873\nWhen Justice Hunt sentenced Anthony to pay a fine of $100 (), she responded, \"I shall never pay a dollar of your unjust penalty\", and she never did.\nIf Hunt had ordered her to be jailed until she paid the fine, Anthony could have taken her case to the Supreme Court. Hunt instead announced he would not order her taken into custody, closing off that legal avenue.\nThe U.S. Supreme Court in 1875 put an end to the strategy of trying to achieve women's suffrage through the court system when it ruled in \"Minor v. Happersett\" that \"the Constitution of the United States does not confer the right of suffrage upon anyone\". The NWSA decided to pursue the far more difficult strategy of campaigning for a constitutional amendment to achieve voting rights for women.\n\"History of Woman Suffrage\".\nAnthony and Stanton initiated the project of writing a history of the women's suffrage movement in 1876. Anthony had for years saved letters, newspaper clippings, and other materials of historical value to the women's movement. In 1876, she moved into the Stanton household in New Jersey along with several trunks and boxes of these materials to begin working with Stanton on the \"History of Woman Suffrage\".\nAnthony hated this type of work. In her letters, she said the project \"makes me feel growly all the time ... No warhorse ever panted for the rush of battle more than I for outside work. I love to make history but hate to write it.\"\nThe work absorbed much of her time for several years although she continued to work on other women's suffrage activities. She acted as her own publisher, which presented several problems, including finding space for the inventory. She was forced to limit the number of books she was storing in the attic of her sister's house because the weight was threatening to collapse the structure.\nOriginally envisioned as a modest publication that could be produced quickly, the history evolved into a six-volume work of more than 5700 pages written over a period of 41 years. The first three volumes, which cover the movement up to 1885, were published between 1881 and 1886 and were produced by Stanton, Anthony and Matilda Joslyn Gage. Anthony handled the production details and the extensive correspondence with contributors. Anthony published Volume 4, which covers the period from 1883 to 1900, in 1902, after Stanton's death, with the help of Ida Husted Harper, Anthony's designated biographer. The last two volumes, which bring the history up to 1920, were completed in 1922 by Harper after Anthony's death.\nThe \"History of Woman Suffrage\" preserves an enormous amount of material that might have been lost forever. Written by leaders of one wing of the divided women's movement (Lucy Stone, their main rival, refused to have anything to do with the project), it does not, however, give a balanced view of events where their rivals are concerned. It overstates the role of Anthony and Stanton, and it understates or ignores the roles of Stone and other activists who did not fit into the historical narrative that Anthony and Stanton developed. Because it was for years the main source of documentation about the suffrage movement, historians have had to uncover other sources to provide a more balanced view.\nInternational women's organizations.\nInternational Council of Women.\nAnthony traveled to Europe in 1883 for a nine-month stay, linking up with Stanton, who had arrived a few months earlier. Together they visited women's institutions, such as the newly founded Somerville College and Lady Margaret Hall in Oxford. They met with leaders of European women's movements and began the process of creating an international women's organization.\nThe National Woman Suffrage Association (NWSA) agreed to host its founding congress. The preparatory work was handled primarily by Anthony and two of her younger colleagues in the NWSA, Rachel Foster Avery and May Wright Sewall. Delegates from fifty-three women's organizations in nine countries met in Washington in 1888 to form the new association, which was called the International Council of Women (ICW). The delegates represented a wide variety of organizations, including suffrage associations, professional groups, literary clubs, temperance unions, labor leagues and missionary societies. The American Woman Suffrage Association, which had for years been a rival to the NWSA, participated in the congress. Anthony opened the first session of the ICW and presided over most events.\nThe ICW commanded respect at the highest levels. President Cleveland and his wife sponsored a reception at the White House for delegates to the ICW's founding congress. The ICW's second congress was an integral part of the World's Columbian Exposition held in Chicago in 1893. At its third congress in London in 1899, a reception for the ICW was held at Windsor Castle at the invitation of Queen Victoria. At its fourth congress in Berlin in 1904, Augusta Victoria, the German Empress, received the ICW leaders at her palace. Anthony played a prominent role on all four occasions.\nStill active, ICW is associated with the United Nations.\nWorld's Congress of Representative Women.\nThe World's Columbian Exposition, also known as the Chicago World's Fair, was held in 1893. It hosted several world congresses, each dealing with a specialized topic, such as religion, medicine and science. At almost the last moment, the U.S. Congress decided that the Exposition should also recognize the role of women. After it was over, one of the organizers of the Exposition's congress of women revealed that Anthony had played a pivotal but hidden role in that last-minute decision. Fearing that a public campaign would rouse opposition, Anthony had worked quietly to organize support for this project among women of the political elite. Anthony increased the pressure by covertly initiating a petition that was signed by wives and daughters of Supreme Court judges, senators, cabinet members and other dignitaries.\nA large structure called the Woman's Building, designed by Sophia Hayden Bennett, was constructed to provide meeting and exhibition spaces for women at the Exposition. Two of Anthony's closest associates were appointed to organize the women's congress. They arranged for the International Council of Women to make its upcoming meeting part of the Exposition by expanding its scope and calling itself the World's Congress of Representative Women. This week-long congress seated delegates from 27 countries. Its 81 sessions, many held simultaneously, were attended by over 150,000 people, and women's suffrage was discussed at almost every session. Anthony spoke to large crowds at the Exposition.\n\"Buffalo Bill\" Cody invited her as a guest to his Wild West Show, located just outside the Exposition. When the show opened, he rode his horse directly to her and greeted her with dramatic flair. According to a co-worker, Anthony, \"for the moment as enthusiastic as a girl, waved her handkerchief at him, while the big audience, catching the spirit of the scene, wildly applauded.\"\nInternational Woman Suffrage Alliance.\nAfter Anthony retired as president of the National American Woman Suffrage Association, Carrie Chapman Catt, her chosen successor, began working toward an international women's suffrage association, one of Anthony's long-time goals. The existing International Council of Women could not be expected to support a campaign for women's suffrage because it was a broad alliance whose more conservative members would object. In 1902, Catt organized a preparatory meeting in Washington, with Anthony as chair, that was attended by delegates from several countries. Organized primarily by Catt, the International Woman Suffrage Alliance was created in Berlin in 1904. The founding meeting was chaired by Anthony, who was declared to be the new organization's honorary president and first member.\nAccording to Anthony's authorized biographer, \"no event ever gave Miss Anthony such profound satisfaction as this one\".\nLater renamed the International Alliance of Women, the organization is still active and is affiliated with the United Nations.\nChanging relationship with Stanton.\nAnthony and Stanton worked together in a close and productive relationship. From 1880 to 1886, they were together almost every day working on the \"History of Woman Suffrage\".\nThey referred to each other as \"Susan\" and \"Mrs. Stanton\".\nAnthony deferred to Stanton in other ways also, not accepting an office in any organization that would place her above Stanton.\nIn practice this generally meant that Anthony, although ostensibly holding a less important office, handled most of the organization's daily activities.\nStanton sometimes felt the weight of Anthony's determination and drive. When Stanton arrived at an important meeting in 1888 with her speech not yet written, Anthony insisted that Stanton stay in her hotel room until she had written it, and she placed a younger colleague outside her door to make sure she did so.\nAt Anthony's 70th birthday celebration, Stanton teased her by saying, \"Well, as all women are supposed to be under the thumb of some man, I prefer a tyrant of my own sex, so I shall not deny the patent fact of my subjection.\"\nTheir interests began to diverge somewhat as they grew older. As the drive for women's suffrage gained momentum, Anthony began to form alliances with more conservative groups, such as the Women's Christian Temperance Union, the nation's largest women's organization and a supporter of women's suffrage.\nSuch moves irritated Stanton, who said, \"I get more radical as I get older, while she seems to grow more conservative.\" In 1895 Stanton published \"The Woman's Bible\", which attacked the use of the Bible to relegate women to an inferior status. It became a highly controversial best-seller. The NAWSA voted to disavow any connection with it despite Anthony's strong objection that such a move was unnecessary and hurtful.\nEven so, Anthony refused to assist with the book's preparation, telling Stanton: \"You say 'women must be emancipated from their superstitions before enfranchisement will have any benefit,' and I say just the reverse, that women must be enfranchised before they can be emancipated from their superstitions.\"\nDespite such friction, their relationship continued to be close. When Stanton died in 1902, Anthony wrote to a friend: \"Oh, this awful hush! It seems impossible that voice is stilled which I have loved to hear for fifty years. Always I have felt I must have Mrs. Stanton's opinion of things before I knew where I stood myself. I am all at sea...\"\nLater life.\nHaving lived for years in hotels and with friends and relatives, Anthony agreed to settle into her sister Mary Stafford Anthony's house in Rochester in 1891, at the age of 71.\nHer energy and stamina, which sometimes exhausted her co-workers, continued at a remarkable level. At age 75, she toured Yosemite National Park on the back of a mule.\nShe remained as leader of the NAWSA and continued to travel extensively on suffrage work. She also engaged in local projects. In 1893, she initiated the Rochester branch of the Women's Educational and Industrial Union. In 1898, she called a meeting of 73 local women's societies to form the Rochester Council of Women. She played a key role in raising the funds required by the University of Rochester before they would admit women students, pledging her life insurance policy to close the final funding gap.\nIn 1896, she spent eight months on the California suffrage campaign, speaking as many as three times per day in more than 30 localities. In 1900, she presided over her last NAWSA convention. During the six remaining years of her life, Anthony spoke at six more NAWSA conventions and four congressional hearings, completed the fourth volume of the \"History of Woman Suffrage\", and traveled to eighteen states and to Europe. As Anthony's fame grew, some politicians (certainly not all of them) were happy to be publicly associated with her. Her seventieth birthday was celebrated at a national event in Washington with prominent members of the House and Senate in attendance. Her eightieth birthday was celebrated at the White House at the invitation of President William McKinley.\nDeath and legacy.\nSusan B. Anthony died at the age of 86 of heart failure and pneumonia in her home in Rochester, New York, on March 13, 1906. She was buried at Mount Hope Cemetery, Rochester. At her birthday celebration in Washington, D.C., a few days earlier, Anthony had spoken of those who had worked with her for women's rights: \"There have been others also just as true and devoted to the cause\u2014I wish I could name every one\u2014but with such women consecrating their lives, failure is impossible!\" \"Failure is impossible\" quickly became a watchword for the women's movement.\nAnthony did not live to see the achievement of women's suffrage at the national level, but she still expressed pride in the progress the women's movement had made. At the time of her death, women had achieved suffrage in Wyoming, Utah, Colorado and Idaho, and several larger states followed soon after. Legal rights for married women had been established in most states, and most professions had at least a few women members. 36,000 women were attending colleges and universities, up from zero a few decades earlier.\" Two years before she died, Anthony said, \"The world has never witnessed a greater revolution than in the sphere of woman during this fifty years\".\nPart of the revolution, in Anthony's view, was in ways of thinking. In a speech in 1889, she noted that women had always been taught that their purpose was to serve men, but \"Now, after 40 years of agitation, the idea is beginning to prevail that women were created for themselves, for their own happiness, and for the welfare of the world.\" Anthony was sure that women's suffrage would be achieved, but she also feared that people would forget how difficult it was to achieve it, as they were already forgetting the ordeals of the recent past:\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nWe shall someday be heeded, and when we shall have our amendment to the Constitution of the United States, everybody will think it was always so, just exactly as many young people think that all the privileges, all the freedom, all the enjoyments which woman now possesses always were hers. They have no idea of how every single inch of ground that she stands upon today has been gained by the hard work of some little handful of women of the past.\nSusan B. Anthony, 1894\nAnthony's death was widely mourned. Clara Barton, founder of the American Red Cross, said just before Anthony's death, \"A few days ago someone said to me that every woman should stand with bared head before Susan B. Anthony. 'Yes,' I answered, 'and every man as well.' ... For ages he has been trying to carry the burden of life's responsibilities alone... Just now it is new and strange and men cannot comprehend what it would mean but the change is not far away.\"\nIn her history of the women's suffrage movement, Eleanor Flexner wrote, \"If Lucretia Mott typified the moral force of the movement, if Lucy Stone was its most gifted orator and Mrs. Stanton its most outstanding philosopher, Susan Anthony was its incomparable organizer, who gave it force and direction for half a century.\"\nThe Nineteenth Amendment, which prohibited the denial of suffrage because of sex, was colloquially known as the Susan B. Anthony Amendment. After it was ratified in 1920, the National American Woman Suffrage Association, whose character and policies were strongly influenced by Anthony, was transformed into the League of Women Voters, which is still an active force in U.S. politics.\nOn August 18, 2020\u2014the 100th anniversary of the ratification of the Nineteenth Amendment\u2014President Donald Trump announced that he would pardon Anthony, 148 years after her conviction. The president of the National Susan B. Anthony Museum and House wrote to \"decline\" the offer of a pardon on the principle that, to accept a pardon would wrongly \"validate\" the trial proceedings in the same manner that paying the $100 fine would have.\nAnthony's papers are held in library collections of Harvard University and its Radcliffe Institute, Rutgers University, the Library of Congress, and Smith College. She is the author of a 6 volume work \"History of Woman Suffrage\" (1881).\nViews.\nViews on religion.\nAnthony was raised a Quaker, but her religious heritage was mixed. On her mother's side, her grandmother was a Baptist and her grandfather was a Universalist. Her father was a radical Quaker who chafed under the restrictions of his more conservative congregation. When the Quakers split in the late 1820s into Orthodox and Hicksites, her family sided with the Hicksites, which Anthony described as \"the radical side, the Unitarian\".\nIn 1848, three years after the Anthony family moved to Rochester, a group of about 200 Quakers withdrew from the Hicksite organization in western New York, partly because they wanted to work in social reform movements without interference from that organization. Some of them, including the Anthony family, began attending services at the First Unitarian Church of Rochester. When Susan B. Anthony returned home from teaching in 1849, she joined her family in attending services there, and she remained with the Rochester Unitarians for the rest of her life. Her sense of spirituality was strongly influenced by William Henry Channing, a nationally known minister of that church who also assisted her with several of her reform projects. Anthony was listed as a member of First Unitarian in a church history written in 1881.\nAnthony, proud of her Quaker roots, continued to describe herself as a Quaker, however. She maintained her membership in the local Hicksite body but did not attend its meetings. She joined the Congregational Friends, an organization that was created by Quakers in western New York after the 1848 split among Quakers there. This group soon ceased to operate as a religious body, however, and changed its name to the Friends of Human Progress, organizing annual meetings in support of social reform that welcomed everyone, including \"Christians, Jews, Mahammedans, and Pagans\".\n Anthony served as secretary of this group in 1857.\nIn 1859, during a period when Rochester Unitarians were gravely impaired by factionalism, Anthony unsuccessfully attempted to start a \"Free church in Rochester ... where no doctrines should be preached and all should be welcome.\"\nShe used as her model the Boston church of Theodore Parker, a Unitarian minister who helped to set the direction of his denomination by rejecting the authority of the Bible and the validity of miracles. Anthony later became close friends with William Channing Gannett, who became the minister of the Unitarian Church in Rochester in 1889, and with his wife Mary, who came from a Quaker background. William had been a national leader of the successful movement within the Unitarian denomination to end the practice of binding it by a formal creed, thereby opening its membership to non-Christians and even non-theists, a goal for the denomination that resembled Anthony's goal for her proposed Free church.\nAfter Anthony reduced her arduous travel schedule and made her home in Rochester in 1891, she resumed regular attendance at First Unitarian and also worked with the Gannetts on local reform projects. Her sister Mary Stafford Anthony, whose home had provided a resting place for Anthony during her years of frequent travel, had long played an active role in this church.\nHer first public speech, delivered at a temperance meeting as a young woman, contained frequent references to God. She soon took a more distant approach, however. While in Europe in 1883, Anthony helped a desperately poor Irish mother of six children. Noting that \"the evidences were that 'God' was about to add a No. 7 to her flock\", she later commented, \"What a dreadful creature their God must be to keep sending hungry mouths while he withholds the bread to fill them!\"\nElizabeth Cady Stanton said that Anthony was an agnostic, adding, \"To her, work is worship ... Her belief is not orthodox, but it is religious.\"\nAnthony herself said, \"Work and worship are one with me. I can not imagine a God of the universe made happy by my getting down on my knees and calling him 'great.'\"\nWhen Anthony's sister Hannah was on her death bed, she asked Susan to talk about the great beyond, but, Anthony later wrote, \"I could not dash her faith with my doubts, nor could I pretend a faith I had not; so I was silent in the dread presence of death.\"\nWhen an organization offered to sponsor a women's rights convention on the condition that \"no speaker should say anything which would seem like an attack on Christianity\", Anthony wrote to a friend, \"I wonder if they'll be as particular to warn all other speakers not to say anything which shall sound like an attack on liberal religion. They never seem to think we have any feelings to be hurt when we have to sit under their reiteration of orthodox cant and dogma.\"\nViews on marriage.\nAs a teen, Anthony went to parties, and she had offers of marriage when she was older, but there is no record of her ever having a serious romance.\nAnthony loved children, however, and helped raise the children in the Stanton household. Referring to her niece, she wrote, \"The dear little Lucy engrosses most of my time and thoughts. A child one loves is a constant benediction to the soul, whether or not it helps to the accomplishment of great intellectual feats.\"\nAs a young worker in the women's rights movement, Anthony expressed frustration when some of her co-workers began to marry and have children, sharply curtailing their ability to work for the understaffed movement. When Lucy Stone abandoned her pledge to stay single, Anthony's scolding remarks caused a temporary rupture in their friendship. Journalists repeatedly asked Anthony to explain why she never married. She answered one by saying, \"It always happened that the men I wanted were those I could not get, and those who wanted me I wouldn't have.\" To another, she answered, \"I never found the man who was necessary to my happiness. I was very well as I was.\" To a third she said, \"I never felt I could give up my life of freedom to become a man's housekeeper. When I was young, if a girl married poor, she became a housekeeper and a drudge. If she married wealth she became a pet and a doll. Just think, had I married at twenty, I would have been a drudge or a doll for fifty-nine years. Think of it!\"\nAnthony fiercely opposed laws that gave husbands complete control over the marriage. Blackstone's \"Commentaries\", the basis for the legal systems in most states at that time, stated that, \"By marriage, the husband and wife are one person in law: that is, the very being or legal existence of the woman is suspended during the marriage\".\nIn a speech in 1877, Anthony predicted \"\"an epoch of single women\". If women will not accept marriage \"with subjugation\", nor men proffer it \"without\", there is, there can be, \"no alternative\". The woman who \"will not be ruled\" must live without marriage.\"\nViews on abortion.\nAnthony showed little interest in the topic of abortion. Ann D. Gordon, who led the Elizabeth Cady Stanton and Susan B. Anthony Papers project, an undertaking to collect and document materials written by those two co-workers, said that Anthony \"never voiced an opinion about the sanctity of fetal life\u00a0... and she never voiced an opinion about using the power of the state to require that pregnancies be brought to term.\" Lynn Sherr, author of a biography of Anthony, said that Anthony never stated her views on abortion, saying, \"I looked desperately for some kind of evidence one way or the other as to what her position was, and it just wasn't there.\"\nA dispute over Anthony's views on abortion developed after 1989 when some members of the anti-abortion movement began to portray Anthony as \"an outspoken critic of abortion\", citing various statements they said she had made. The anti-abortion advocacy group Susan B. Anthony List named itself after her on this basis. Gordon, Sherr and others contested this portrayal, saying these statements either were not made by Anthony, were not about abortion, or had been taken out of context.\nCommemoration.\nHalls of Fame.\nIn 1950, Anthony was inducted into the Hall of Fame for Great Americans. A bust of her that was sculpted by Brenda Putnam was placed there in 1952.\nIn 1973, Anthony was inducted into the National Women's Hall of Fame.\nArtwork.\nThe first memorial to Anthony was established by African Americans. In 1907, a year after Anthony's death, a stained-glass window was installed at the African Methodist Episcopal Zion church in Rochester that featured her portrait and the words \"Failure is Impossible\", a quote from her that had become a watchword for the women's suffrage movement. It was installed through the efforts of Hester C. Jeffrey, the president of the Susan B. Anthony Club, an organization of African American women in Rochester. Speaking at the window's dedication, Jeffrey said, \"Miss Anthony had stood by the Negroes when it meant almost death to be a friend of the colored people.\" This church had a history of involvement in issues of social justice: in 1847, Frederick Douglass printed the first editions of \"The North Star\", his abolitionist newspaper, in its basement.\nAnthony is commemorated along with Elizabeth Cady Stanton and Lucretia Mott in the \"Portrait Monument\" sculpture by Adelaide Johnson at the United States Capitol, unveiled in 1921. Originally kept on display in the crypt of the US Capitol, the sculpture was moved to its current location and more prominently displayed in the rotunda in 1997.\nIn 1922, sculptor Leila Usher donated a bas-relief of Susan B. Anthony to the National Woman's Party, which was installed at their headquarters near Washington, DC. Usher was also responsible for the creation of a similar bronze medallion donated to Bryn Mawr College in 1901.\nA sculpture by Ted Aub commemorating the introduction of Anthony to Elizabeth Cady Stanton by Amelia Bloomer on May 12, 1851, was unveiled In 1999. Called \"When Anthony Met Stanton\", it consists of life-size bronze statues of the three women near Van Cleef Lake in Seneca Falls, New York, where the introduction occurred.\nIn 2001, the Cathedral of St. John the Divine in Manhattan, one of the world's largest, added a sculpture honoring Anthony and three other heroes of the twentieth century: Martin Luther King Jr., Albert Einstein, and Mahatma Gandhi.\nAn installation artwork by Judy Chicago called \"The Dinner Party\", first exhibited in 1979, features a place setting for Anthony.\nA bronze sculpture of a locked ballot box flanked by two pillars marks the place where Anthony voted in 1872 in defiance of laws that prohibited women from voting. Called the 1872 Monument, it was dedicated in August 2009, on the 89th anniversary of the Nineteenth Amendment. Leading away from the 1872 Monument is the Susan B. Anthony Trail, which runs beside the 1872 Caf\u00e9, named for the year of Anthony's vote.\nNear the Susan B. Anthony Museum and House is the \"Let's Have Tea\" sculpture of Anthony and Frederick Douglass created by Pepsy Kettavong.\nOn February 15, 2020, Google celebrated Anthony's 200th birthday with a Google Doodle.\nLandmarks.\nAnthony's home in Rochester is a National Historic Landmark called the National Susan B. Anthony Museum and House. The house of her birth in Adams, Massachusetts, and her childhood home in Battenville, New York, are listed on the National Register of Historic Places.\nIn 2007, the new Frederick Douglass\u2013Susan B. Anthony Memorial Bridge replaced the old Troup\u2013Howell Bridge as the conveyor of expressway traffic on Interstate 490 through downtown Rochester.\nDocumentary projects.\nThe Elizabeth Cady Stanton and Susan B. Anthony Papers project was an academic undertaking to collect and document all available materials written by Elizabeth Cady Stanton and Anthony. The project began in 1982 and has since been ended.\nIn 1999, Ken Burns and others produced the television documentary \"Not for Ourselves Alone: The Story of Elizabeth Cady Stanton &amp; Susan B. Anthony\".\nBanknotes, coins and stamps.\nThe US Post Office issued its first postage stamp honoring Anthony in 1936 on the 16th anniversary of the ratification of the 19th Amendment, which ensured women's right to vote. A second stamp honoring Anthony was issued in April 1958.\nIn 1979, the United States Mint began issuing the Susan B. Anthony dollar coin, the first US coin to honor a female citizen.\nThe US Treasury Department announced on April 20, 2016, that an image of Anthony would appear on the back of a newly designed $10 bill along with Lucretia Mott, Sojourner Truth, Elizabeth Cady Stanton and Alice Paul. The original plan was for a woman to appear on the front of the $10 bill, with Anthony under consideration for that position. The final plan, however, calls for Alexander Hamilton, the first US Secretary of the Treasury, to retain his current position there. Designs for new $5, $10 and $20 bills will be unveiled in 2020 in conjunction with the 100th anniversary of American women winning the right to vote via the 19th Amendment.\nNames of awards and organizations.\nSince 1970, the Susan B. Anthony Award is given annually by the New York City chapter of the National Organization for Women to honor \"grassroots activists dedicated to improving the lives of women and girls in New York City.\"\nNew York Radical Feminists, founded in 1969, was organized into small cells or \"brigades\" named after notable feminists of the past. The Stanton-Anthony Brigade was led by Anne Koedt and Shulamith Firestone.\nIn 1971, Zsuzsanna Budapest founded the Susan B. Anthony Coven #1 \u2013 the first feminist, women-only, witches' coven.\nThe Susan B. Anthony List is a non-profit organization that seeks to reduce and ultimately end abortion in the U.S.\nOther.\nSusan B. Anthony Day is a commemorative holiday to celebrate the birth of Anthony and women's suffrage in the United States. The holiday is February 15\u2014Anthony's birthday.\nIn 2016, Lovely Warren, the mayor of Rochester, put a red, white and blue sign next to Anthony's grave on the day after Hillary Clinton obtained the nomination at the Democratic National Convention. The sign stated, \"Dear Susan B., we thought you might like to know that for the first time in history, a woman is running for president representing a major party. 144 years ago, your illegal vote got you arrested. It took another 48 years for women to finally gain the right to vote. Thank you for paving the way.\" The city of Rochester put pictures of the message on Twitter and requested that residents go to Anthony's grave to sign it.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n* Volume I: https:// and http://\n* Volume 2: https:// and http://\n* Volume 3: https:// and https://\nExternal links.\n1873 voting trial\n1873 contemporaneous newspaper reports\n* \u2013 Includes defense arguments\n* \u2013 Newspaperman's case review and opinion piece advocating continued gender discrimination\n* \u2013 Description of judicial opinion (June 19); and closing argument and sentencing (June 20)\n* \u2013 Includes Anthony's speech to the Union League Club, New York, on the centennial of the Boston Tea Party"}
{"id": "27956", "revid": "51059816", "url": "https://en.wikipedia.org/wiki?curid=27956", "title": "South Carolina", "text": "U.S. state\nSouth Carolina ( ) is a state in the Southeastern, South Atlantic and Deep South regions of the United States. It borders North Carolina to the north and northeast, the Atlantic Ocean to the southeast, and Georgia to the west and south across the Savannah River. Along with North Carolina, it makes up the Carolinas region of the East Coast. South Carolina is the 11th-smallest and 23rd-most populous U.S. state with a recorded population of 5,118,425 according to the 2020 census. In 2019[ [update]], its GDP was $213.45\u00a0billion. South Carolina is composed of 46 counties. The capital is Columbia with a population of 136,632 in 2020; while its most populous city is Charleston with a 2020 population of 150,227. The Greenville-Spartanburg-Anderson, SC Combined Statistical Area is the most populous combined metropolitan area in the state, with an estimated 2023 population of 1,590,636.\nSouth Carolina was named in honor of King Charles I of England, who first formed the English colony, with \"Carolus\" being Latin for \"Charles\". In 1712 the Province of South Carolina was formed. One of the original Thirteen Colonies, South Carolina became a royal colony in 1719. During the American Revolutionary War, South Carolina was the site of major activity among the American colonies, with more than 200 battles and skirmishes fought within the state. South Carolina became the eighth state to ratify the U.S. Constitution on May 23, 1788. A slave state, it was the first state to vote in favor of secession from the Union on December 20, 1860. After the Civil War ended, the state was readmitted to the Union on July 9, 1868.\nDuring the early-to-mid 20th century, the state started to see economic progress as many textile mills and factories were built across the state. The civil rights movement of the mid-20th century helped end segregation and legal discrimination policies within the state. Economic diversification in South Carolina continued to pick up speed during and in the ensuing decades after World War II. In the early 21st century, South Carolina's economy is based on industries such as aerospace, agribusiness, automotive manufacturing, and tourism.\nWithin South Carolina from east to west are three main geographic regions, the Atlantic coastal plain, the Piedmont, and the Blue Ridge Mountains in the northwestern corner of Upstate South Carolina. South Carolina has primarily a humid subtropical climate, with hot, humid summers and mild winters. Areas in the Upstate have a subtropical highland climate. Along South Carolina's eastern coastal plain are many salt marshes and estuaries. South Carolina's southeastern Lowcountry contains portions of the Sea Islands, a chain of barrier islands along the Atlantic Ocean.\nHistory.\nPrecolonial period.\nThere is evidence of human activities in the area dating to about 50,000 years ago. At the time Europeans arrived, marking the end Pre-Columbian era around 1500, there were many separate Native American polities including the powerful Cofitachequi populated by a variety of nations including the largest the Cherokee and the Catawba, with a total population being up to 20,000 around 1600.\nUp the rivers of the eastern coastal plain lived about a dozen tribes of Siouan background. Along the Savannah River were the Apalachee, Yuchi, and the Yamasee. Further west were the Cherokee, and along the Catawba River, the Catawba. These tribes were village-dwellers, relying on agriculture as their primary food source. The Cherokee lived in wattle and daub houses made with wood and clay, roofed with wood or thatched grass.\nAbout a dozen or more separate small tribes summered on the coast harvesting oysters and fish, and cultivating corn, peas and beans. Travelling inland as much as mostly by canoe, they wintered on the coastal plain, hunting deer and gathering nuts and fruit. The names of these tribes survive in place names like Edisto Island, Kiawah Island, and the Ashepoo River.\nExploration.\nThe Spanish were the first Europeans in the area. From June 24 to July 14, 1521, they explored the land around Winyah Bay. On October 8, 1526, they founded San Miguel de Gualdape, near present-day Georgetown, South Carolina. It was the first European settlement in what is now the contiguous United States. Established with five hundred settlers, it was abandoned eight months later by one hundred and fifty survivors. In 1540, Hernando de Soto explored the region and the main town of Cofitachequi, where he captured the queen of the Maskoki (Muscogee) and the Chelaque (Cherokee) who had welcomed him.\nIn 1562 French Huguenots established a settlement at what is now the Charlesfort-Santa Elena archaeological site on Parris Island. Many of these settlers preferred a natural life far from civilization and the atrocities of the Wars of Religion. The garrison lacked supplies, however, and the soldiers (as in the France Antarctique) soon ran away. The French returned two years later but settled in present-day Florida rather than South Carolina.\nColonization.\nSixty years later, in 1629, King Charles I of England established the province of Carolana, an area covering what is now South and North Carolina, Georgia and Tennessee. Carolana was granted to Sir Robert Heath, who intended to allow French Huguenots to settle there; however, King Charles refused to grant permission to settle to anyone who was not a member of the Anglican Church, leading to the failure of the colony. In 1663, King Charles II created the Province of Carolina by granting the same land to eight Lords Proprietors in return for their financial and political assistance in restoring him to the throne in 1660. Anthony Ashley Cooper, one of the Lord Proprietors, planned the Grand Model for the Province of Carolina and wrote the Fundamental Constitutions of Carolina, which laid the basis for the future colony. His utopia was inspired by John Locke, an English philosopher and physician, widely regarded as one of the most influential of Enlightenment thinkers and commonly known as the \"Father of Liberalism\".\nThe Carolina slave trade, which included both trading and direct raids by colonists, was the largest among the British colonies in North America. Between 1670 and 1715, between 24,000 and 51,000 captive Native Americans were exported from South Carolina \u2013 more than the number of Africans imported to the colonies of the future United States during the same period. Additional enslaved Native Americans were exported from South Carolina to other U.S. colonies. The historian Alan Gallay says, \"the trade in Indian slaves was at the center of the English empire's development in the American South. The trade in Indian slaves was the most important factor affecting the South in the period 1670 to 1715\".\nIn the 1670s, English planters from Barbados established themselves near what is now Charleston. Settlers from all over Europe built rice plantations in the South Carolina Lowcountry, east of the Atlantic Seaboard fall line. Plantation labor was done by African slaves who formed the majority of the population by 1720. Another cash crop was the indigo plant, a plant source of blue dye, developed by Eliza Lucas.\nMeanwhile, Upstate South Carolina, west of the Fall Line, was settled by small farmers and traders, who due to resource competition fought a number of wars with confederated Native American tribes westward. Colonists overthrew the proprietors' rule, seeking more direct representation. In 1712, the former Province of Carolina split into North and South Carolina. In 1719, South Carolina was officially made a royal colony.\nSouth Carolina prospered from the fertility of the lowcountry and the harbors, such as at Charleston. It allowed religious toleration, encouraging settlement, and trade in deerskin, lumber, and beef thrived. Rice cultivation was developed on a large scale on the back of slave labor.\nBy the second half of the 1700s, South Carolina was one of the richest of the Thirteen Colonies.\nThe American Revolution.\nOn March 26, 1776, the colony adopted the Constitution of South Carolina, electing John Rutledge as the state's first president. In February 1778, South Carolina became the first state to ratify the Articles of Confederation, the initial governing document of the United States, and in May 1788, South Carolina ratified the United States Constitution, becoming the eighth state to enter the union.\nDuring the American Revolutionary War (1775\u20131783), about a third of combat action took place in South Carolina, more than any other state. Inhabitants of the state endured being invaded by British forces and an ongoing civil war between loyalists and partisans that devastated the backcountry. It is estimated 25,000 slaves (30% of those in South Carolina) fled, migrated or died during the war.\nAntebellum.\nAmerica's first census in 1790 put the state's population at nearly 250,000. By the 1800 census, the population had increased 38 per cent to nearly 340,000 of which 146,000 were slaves. At that time South Carolina had the largest population of Jews in the sixteen states of the United States, mostly based in Savannah and Charleston, the latter being the country's fifth largest city.\nIn the Antebellum period (before the Civil War) the state's economy and population grew. Cotton became an important crop after the invention of the cotton gin. While nominally democratic, from 1790 until 1865, wealthy male landowners were in control of South Carolina. For example, a man was not eligible to sit in the State House of Representatives unless he possessed an estate of 500 acres of land and 10 Negroes, or at least 150 pounds sterling.\nColumbia, the new state capital was founded in the center of the state, and the State Legislature first met there in 1790. The town grew after it was connected to Charleston by the Santee Canal in 1800, one of the first canals in the United States.\nAs dissatisfaction of the planters ruling class with the federal government grew, in the 1820s John C. Calhoun became a leading proponent of states' rights, limited government, nullification of the U.S. Constitution, and free trade. In 1832, the Ordinance of Nullification declared federal tariff laws unconstitutional and not to be enforced in the state, leading to the Nullification Crisis. The federal Force Bill was enacted to use whatever military force necessary to enforce federal law in the state, bringing South Carolina back into line.\nAn 1831 House Report from the Committee on Military Affairs noted that &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Before the commencement of the war with Great Britain, and for a long time afterwards, the State of South Carolina was almost destitute of any of the means of military protection, excepting as such could be furnished by her own resources. In the harbor of Charleston alone were there any forts, and these were in so feeble a condition, that at a period, when a British squadron was engaged in sounding the depth of water off the bar, and its commander apparently meditating an attack upon the forts, the quantity of gunpowder in the harbor, belonging to the United States, was not more than sufficient to have enabled the garrison to fire a single round.\nIn the United States presidential election of 1860, voting was sharply divided, with the South voting for the Southern Democrats and the North for Abraham Lincoln's Republican Party. Lincoln was anti-slavery, did not acknowledge the right to secession, and would not yield federal property in Southern states. Southern secessionists believed Lincoln's election meant long-term doom for their slavery-based agrarian economy and social system.\nLincoln was elected president on November 6, 1860. The state House of Representatives three days later passed the \"Resolution to Call the Election of Abraham Lincoln as U.S. President a Hostile Act\", and within weeks South Carolina became the first state to secede.\nAmerican Civil War 1861\u20131865.\nOn April 12, 1861, Confederate batteries began shelling the Union Fort Sumter in Charleston Harbor, and the American Civil War began. In November of that year, the Union attacked Port Royal Sound and soon occupied Beaufort County and the neighboring Sea Islands. For the rest of the war, this area served as a Union base and staging point for other operations. Whites abandoned their plantations, leaving behind about ten thousand enslaved people. Several Northern charities partnered with the federal government to help these people run the cotton farms themselves under the Port Royal Experiment. Workers were paid by the pound harvested and thus became the first enslaved people freed by the Union forces to earn wages.\nAlthough the state was not a major battleground, the war ruined the state's economy. More than 60,000 soldiers from South Carolina served in the war, with the state losing an estimated 18,000 troops. Though no regiments of Southern Unionists were formed in South Carolina due to a smaller unionist presence, the Upstate region of the state would be a haven for Confederate Army deserters and resisters, as they used the Upstate topography and traditional community relations to resist service in the Confederate ranks. At the end of the war in early 1865, the troops of General William Tecumseh Sherman marched across the state devastating plantations and most of Columbia. South Carolina would be readmitted to the Union on July 9, 1868.\nReconstruction 1865\u20131877.\nIn \"Texas vs. White\" (1869), the Supreme Court ruled the ordinances of secession (including that of South Carolina) were invalid, and thus those states had never left the Union. However, South Carolina did not regain representation in Congress until that date.\nUntil the 1868 presidential election, South Carolina's legislature, not the voters, chose the state's electors for the presidential election. South Carolina was the last state to choose its electors in this manner. During Reconstruction, South Carolina maintained a majority-black government, which lasted until approximately 1876 when Democrats and former Confederates committed voter fraud to regain power. On October 19, 1871, President Ulysses S. Grant suspended habeas corpus in nine South Carolina counties under the authority of the Ku Klux Klan Act. Led by Grant's Attorney General Amos T. Akerman, hundreds of Klansmen were arrested while 2,000 Klansmen fled the state. This was done to suppress Klan violence against African-American and white voters in the South. In the mid-to-late 1870s, white Democrats used paramilitary groups such as the Red Shirts to intimidate and terrorize black voters. They regained political control of the state under conservative white \"Redeemers\" and pro-business Bourbon Democrats. In 1877, the federal government withdrew its troops as part of the Compromise of 1877 that ended Reconstruction.\nPopulist and agrarian movements.\nThe state became a hotbed of racial and economic tensions during the Populist and Agrarian movements of the 1890s. A Republican-Populist biracial coalition took power away from White Democrats temporarily. To prevent that from happening again, Democrats gained passage of a new constitution in 1895 which effectively disenfranchised almost all blacks and many poor whites by new requirements for poll taxes, residency, and literacy tests that dramatically reduced the voter rolls. By 1896, only 5,500 black voters remained on the voter registration rolls, although they constituted a majority of the state's population. The 1900 census demonstrated the extent of disenfranchisement: the 782,509 African American citizens comprised more than 58% of the state's population, but they were essentially without any political representation in the Jim Crow society.\nThe 1895 constitution overturned local representative government, reducing the role of the counties to agents of state government, effectively ruled by the General Assembly, through the legislative delegations for each county. As each county had one state senator, that person had considerable power. The counties lacked representative government until home rule was passed in 1975.\nGovernor \"Pitchfork Ben\" Tillman, a Populist, led the effort to disenfranchise the blacks and poor whites, although he controlled Democratic state politics from the 1890s to 1910 with a base among poor white farmers. During the constitutional convention in 1895, he supported another man's proposal that the state adopt a one-drop rule, as well as prohibit marriage between whites and anyone with any known African ancestry.\nSome members of the convention realized prominent white families with some African ancestry could be affected by such legislation. In terms similar to a debate in Virginia in 1853 on a similar proposal (which was dropped), George Dionysius Tillman said in opposition:\nIf the law is made as it now stands respectable families in Aiken, Barnwell, Colleton, and Orangeburg will be denied the right to intermarry among people with whom they are now associated and identified. At least one hundred families would be affected to my knowledge. They have sent good soldiers to the Confederate Army, and are now landowners and taxpayers. Those men served creditably, and it would be unjust and disgraceful to embarrass them in this way. It is a scientific fact that there is not one full-blooded Caucasian on the floor of this convention. Every member has in him a certain mixture of... colored blood. The pure-blooded white has needed and received a certain infusion of darker blood to give him readiness and purpose. It would be a cruel injustice and the source of endless litigation, of scandal, horror, feud, and bloodshed to undertake to annul or forbid marriage for a remote, perhaps obsolete trace of Negro blood. The doors would be open to scandal, malice and greed; to statements on the witness stand that the father or grandfather or grandmother had said that A or B had Negro blood in their veins. Any man who is half a man would be ready to blow up half the world with dynamite to prevent or avenge attacks upon the honor of his mother in the legitimacy or purity of the blood of his father.\nThe state postponed such a one-drop law for years. Virginian legislators adopted a one-drop law in 1924, forgetting that their state had many people of mixed ancestry among those who identified as white.\n20th century.\nEarly in the 20th century, South Carolina developed a thriving textile industry. The state also converted its main agricultural base from cotton, to more profitable crops. It would attract large military bases during World War I, through its majority Democratic congressional delegation, part of the one-party Solid South following disfranchisement of blacks.\nIn the late 19th century, South Carolina would implement Jim Crow laws which enforced racial segregation policies until the 1960s. During the early-to-mid part of the 20th century, millions of African Americans left South Carolina and other southern states for jobs, opportunities, and relative freedom in U.S. cities outside the former Confederate states. In total from 1910 to 1970, 6.5\u00a0million blacks left the South in the Great Migration. By 1930, South Carolina had a white majority population for the first time since 1708. South Carolina was one of several states that initially rejected the Nineteenth Amendment (1920) giving women the right to vote. The South Carolina legislature later ratified the amendment on July 1, 1969.\nThe struggle of the civil rights movement took place in South Carolina, as they did in other Southern states and elsewhere within the country. South Carolina would experience a much less violent movement than other Deep South states. This tranquil transition from a Jim Crow society occurred because the state's white and black leaders were willing to accept slow change, rather than being utterly unwilling to accept change at all. Other South Carolina political figures, like Sen. Strom Thurmond, on the other hand, were among the nation's most radical and effective opponents of social equality and integration.\nDuring the mid-to-late 20th century, South Carolina started to see economic progress first in the textile industry and then in manufacturing. Tourism also started to form into a major industry within the state during the 20th century, especially in areas such as Myrtle Beach and Charleston.\n21st century.\nAs the 21st century progresses, South Carolina has attracted new business by having a 5% corporate income tax rate, no state property tax, no local income tax, no inventory tax, no sales tax on manufacturing equipment, industrial power or materials for finished products; no wholesale tax, and no unitary tax on worldwide profits.\nSouth Carolina was one of the first states to stop paying for \"early elective\" deliveries of babies, under either Medicaid and private insurance. The term early elective is defined as a labor induction or Cesarean section between 37 and 39 weeks. The change was intended to result in healthier babies and fewer costs for the state of South Carolina.\nOn November 20, 2014, South Carolina became the 35th state to legalize same-sex marriages, when a federal court ordered the change.\nAs of 2022, South Carolina had one of the lowest percentages among all states of women in state legislature, at 17.6% (only five states had a lower percentage; the national average is 30.7%; with the highest percentage being in Nevada at 61.9%).\nGeography.\nRegions.\nThe state can be divided into three natural geographic areas which then can be subdivided into five distinct cultural regions. The natural environment is divided from east to west by the Atlantic coastal plain, the Piedmont, and the Blue Ridge Mountains. Culturally, the coastal plain is split into the Lowcountry and the Pee Dee region. While, the upper Piedmont region is referred to as the Piedmont and the lower Piedmont region is referred to as the Midlands. The area surrounding the Blue Ridge Mountains is known as the Upstate. The Atlantic Coastal Plain makes up two-thirds of the state. Its eastern border is the Sea Islands, a chain of tidal and barrier islands. The border between the lowcountry and the upcountry is defined by the Atlantic Seaboard fall line, which marks the limit of navigable rivers.\nAltogether, the state has a total area of , of which is land and (6.12%) is water.\nAtlantic Coastal Plain.\nThe Atlantic Coastal plain consists of sediments and sedimentary rocks that range in age from Cretaceous to Present. The terrain is relatively flat and the soil is composed predominantly of sand, silt, and clay. Areas with better drainage make excellent farmland, though some land is swampy. An unusual feature of the coastal plain is a large number of low-relief topographic depressions named Carolina bays. The bays tend to be oval, lining up in a northwest to southeast orientation. The eastern portion of the coastal plain contains many salt marshes and estuaries, as well as natural ports such as Georgetown and Charleston. The natural areas of the coastal plain are part of the Middle Atlantic coastal forests ecoregion.\nThe Sandhills or Carolina Sandhills is a wide region within the Atlantic Coastal Plain province, along the inland margin of this province. The Carolina Sandhills are interpreted as eolian (wind-blown) sand sheets and dunes that were mobilized episodically from approximately 75,000 to 6,000 years ago. Most of the published luminescence ages from the sand are coincident with the last glaciation, a time when the southeastern United States was characterized by colder air temperatures and stronger winds.\nPiedmont.\nMuch of Piedmont consists of Paleozoic metamorphic and igneous rocks, and the landscape has relatively low relief. Due to the changing economics of farming, much of the land is now reforested in loblolly pine for the lumber industry. These forests are part of the Southeastern mixed forests ecoregion. At the southeastern edge of Piedmont is the fall line, where rivers drop to the coastal plain. The fall line was an important early source of water power. Mills built to this resource encouraged the growth of several cities, including the capital, Columbia. The larger rivers are navigable up to the fall line, providing a trade route for mill towns.\nThe northwestern part of Piedmont is also known as the Foothills. The Cherokee Parkway is a scenic driving route through this area. This is where Table Rock State Park is located.\nBlue Ridge.\nThe Blue Ridge consists primarily of Precambrian metamorphic rocks, and the landscape has relatively high relief. The Blue Ridge Region contains an escarpment of the Blue Ridge Mountains that continues into North Carolina and Georgia as part of the southern Appalachian Mountains. Sassafras Mountain, South Carolina's highest point at , is in this area. Also in this area is Caesars Head State Park. The environment here is that of the Appalachian-Blue Ridge forests ecoregion. The Chattooga River, on the border between South Carolina and Georgia, is a favorite whitewater rafting destination.\nLakes.\nSouth Carolina has several major lakes covering over . All major lakes in South Carolina are human-made. The following are the lakes listed by size.\nEarthquakes.\nSouth Carolina is the most seismically active state on the East Coast. Between July 1, 2021, and July 1, 2022, there were 74 recorded earthquakes in South Carolina, six of which exceeded a 3 magnitude. In 2021 and 2022, most of which were concentrated in Kershaw County and the coastal area of Charleston. The Charleston area demonstrates the greatest frequency of earthquakes in South Carolina. South Carolina averages 10\u201315 earthquakes a year below magnitude3 (FEMA). The Charleston earthquake of 1886 was the largest quake ever to hit the eastern United States. The 7.0\u20137.3 magnitude earthquake killed 60 people and destroyed much of the city. Faults in this region are difficult to study at the surface due to thick sedimentation on top of them. Many of the ancient faults are within plates rather than along plate boundaries.\nClimate.\nSouth Carolina has a humid subtropical climate (K\u00f6ppen climate classification \"Cfa\"), although high-elevation areas in the Upstate area have fewer subtropical characteristics than areas on the Atlantic coastline. In the summer, South Carolina is hot and humid, with daytime temperatures averaging between in most of the state and overnight lows averaging on the coast and from inland. Winter temperatures are much less uniform in South Carolina. Coastal areas of the state have very mild winters, with high temperatures approaching an average of and overnight lows around 40\u00a0\u00b0F (5\u20138\u00a0\u00b0C). Inland, the average January overnight low is around in Columbia and temperatures well below freezing in the Upstate. While precipitation is abundant the entire year in almost the entire state, the coast tends to have a slightly wetter summer, while inland, the spring and autumn transitions tend to be the wettest periods and winter the driest season, with November being the driest month. The highest recorded temperature is in Johnston and Columbia on June 29, 2012, and the lowest recorded temperature is at Caesars Head on January 21, 1985.\nSnowfall in South Carolina is minimal in the lower elevation areas south and east of Columbia. It is not uncommon for areas along the southernmost coast to not receive measurable snowfall for several years. In the Piedmont and Foothills, especially along and north of Interstate 85, measurable snowfall occurs one to three times in most years. Annual average total amounts range from 2 to 6 inches. The Blue Ridge Escarpment receives the most average total measurable snowfall; amounts range from 7 to 12 inches.\nSouth Carolina averages around 50 days of thunderstorm activity a year. This is less than some of the states further south, and it is slightly less vulnerable to tornadoes than the states which border on the Gulf of Mexico. Some notable tornadoes have struck South Carolina, and the state averages around 14 tornadoes annually. Hail is common with many of the thunderstorms in the state, as there is often a marked contrast in temperature of warmer ground conditions compared to the cold air aloft.\nHurricanes and tropical cyclones.\nThe state is occasionally affected by tropical cyclones. This is an annual concern during hurricane season, which lasts from June1 to November 30. The peak time of vulnerability for the southeast Atlantic coast is from early August to early October, during the Cape Verde hurricane season. Memorable hurricanes to hit South Carolina include Hazel (1954), Hugo (1989), and Florence (2018).\nClimate change.\nSouth Carolina released its Climate, Energy, and Commerce Committee Final Report in 2008. The report recommends a voluntary economy-wide goal of reducing emissions to 5% below 1990 levels by 2020. Key policy recommendations in the report include developing renewable portfolio standards, increasing use of local agricultural products, and increasing advanced recycling and composting.\nFlora and fauna.\nSouth Carolina is home to two dominant ecosystems, the bottomlands, which consist of floodplains and creeks, and the toplands. The floodplains contain large tracts of old and mature second growth cypress and tupelo forest. The uplands are home to longleaf pine, shortleaf pine, and mixed hardwood forests. The Longleaf Pine are an important part of South Carolina's coastal ecosystem. They improve soil, water, and air quality while providing a habitat for deer and songbirds. These forests are endangered by logging for agriculture and development.\nOysters are a critical part of South Carolina's coastal ecology. They serve a dual function, filtering the water and forming reefs that provide a habitat for small fish and crabs. Oysters are imperiled by overharvesting because young oysters need older oysters to latch on to as they age. South Carolina is home to many shorebirds including various sandpipers and ibises. The state serves as a stopover site for birds migrating farther south and a wintering ground for birds that do not fly as far south.\nMajor cities.\n&lt;templatestyles src=\"Template:Largest_cities/styles.css\" /&gt;\nStatistical areas.\nThe following tables show the major metropolitan and combined statistical areas of South Carolina. Some statistical areas of South Carolina overlap with neighboring states of North Carolina and Georgia.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\nThe 2020 census determined the state had a population of 5,118,425, a 10.7% percentage increase since the 2010 census.\nAccording to HUD's 2022 Annual Homeless Assessment Report, there were an estimated 3,608 homeless people in South Carolina.\nAt the 2020 census, the racial make up of the state was 63.4% White (62.1% non-Hispanic white), 25.0% Black or African American, 0.5% American Indian and Alaska Native, 1.8% Asian, 0.1% Native Hawaiian and other Pacific Islander, 3.5% from some other race, and 5.8% from two or more races. 6.9% of the total population was of Hispanic or Latino origin of any race.\nAt the 2019 census estimate, South Carolina had an estimated population of 5,148,714, which is an increase of 64,587 from the prior year and an increase of 523,350, or 11.31%, since the year 2010. Immigration from outside the United States resulted in a net increase of 36,401 people, and migration within the country produced a net increase of 115,084 people. According to the University of South Carolina's Arnold School of Public Health, Consortium for Latino Immigration Studies, South Carolina's foreign-born population grew faster than any other state between 2000 and 2005. South Carolina has banned sanctuary cities.\nThe top countries of origin for South Carolina's immigrants were Mexico, India, Germany, Honduras and the Philippines, as of 2018[ [update]].\nEnslaved Africans were brought to the state during the slave trade. There is also a Gullah community in South Carolina. Additionally, there is one federally recognized tribe in South Carolina, the Catawba Indian Nation, and 24,303 identified as being Native American alone, and 83,808 did in combination with one or more other races in 2020.\nHistorical South Carolina racial breakdown of population\n&lt;includeonly&gt;&lt;templatestyles src=\"Chart/styles.css\"/&gt; View .&lt;/includeonly&gt;\nLanguages.\nMany indigenous languages such as Muskogean languages have disappeared. Cherokee and Catawba lasted the longest. European settlers in South Carolina spoke Spanish, French, German, Irish, English, Welsh, and Scots. Gullah is spoken in the state by African Americans. Newer residents in South Carolina speak Tagalog, Greek, Indic, Italian, Chinese, Korean or Japanese.\nReligion.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nAccording to the Association of Religion Data Archives (ARDA), in 2010, the largest religion is Christianity, of which the largest denominations were the Southern Baptist Convention with 913,763 adherents, the United Methodist Church with 274,111 adherents, and the Roman Catholic Church with 181,743 adherents. Fourth-largest is the African Methodist Episcopal Church with 564 congregations and 121,000 members and fifth-largest is the Presbyterian Church (USA) with 320 congregations and almost 100,000 members. As of 2010, South Carolina was the American state with the highest per capita proportion of citizens who follow the Bah\u00e1\u02bc\u00ed Faith, with 17,559 adherents, making Bah\u00e1\u02bc\u00ed the second-largest religion in the state at the time.\nAccording to the Public Religion Research Institute in 2020, Christianity remained the largest religion at approximately 74% of the population. Among the Christian population, evangelical Protestantism remained the majority; the irreligious community was 18% of the total population. Per ARDA's 2020 religion census, Southern Baptists remained the majority with 816,405 adherents, and Roman Catholics had 407,840 adherents, followed by United Methodists at 242,467. As other Baptist denominations had from 10 to 40,000+ members individually, nondenominational/interdenominational Protestants increased to 454,063 adherents.\nOutside of Christianity, ARDA's 2020 study reported 6,677 Muslims in the state, and 830 Orthodox Jews; Reform Judaism consisted of 3,430 adherents. Altogether, Hinduism had 8,383 adherents. With respect to Judaism in the state, there is a substantial history of the Jews in Charleston, South Carolina.\nIn 2022, the Public Religion Research Institute estimated that Christians increased to 76% of the population (64% Protestant, 11% Catholic, and 1% Jehovah's Witness). The unaffiliated also increased, forming 20% of the state's population, although New Agers constituted 3% of the state. Judaism was 1% of the total population.\nEconomy.\nIn 2019, South Carolina's GDP was $249.9\u00a0billion, making the state the 26th largest by GDP in the United States. According to the U.S. Bureau of Economic Analysis, South Carolina's gross state product (GSP) was $97\u00a0billion in 1997 and $153\u00a0billion in 2007. Its per-capita real gross domestic product (GDP) in chained 2000 dollars was $26,772 in 1997 and $28,894 in 2007; which represented 85% of the $31,619 per-capita real GDP for the United States overall in 1997, and 76% of the $38,020 for the U.S. in 2007. The state debt in 2012 was calculated by one source to be $22.9bn, or $7,800 per taxpayer.\nIndustrial outputs include textile goods, chemical products, paper products, machinery, automobiles, automotive products and tourism. Major agricultural outputs of the state are tobacco, poultry, cotton, cattle, dairy products, soybeans, hay, rice, and swine. According to the Bureau of Labor Statistics, as of March 2012, South Carolina had 1,852,700 nonfarm jobs of which 12% are in manufacturing, 11.5% are in leisure and hospitality, 19% are in trade, transportation, and utilities, and 11.8% are in education and health services. The service sector accounts for 83.7% of the South Carolina economy.\nMany large corporations have moved their locations to South Carolina. Boeing opened an aircraft manufacturing facility at Charleston International Airport in 2011, which serves as one of two final assembly sites for the 787 Dreamliner. South Carolina is a right-to-work state and many businesses use staffing agencies to temporarily fill positions. Domtar, in Rock Hill, used to be the only Fortune 500 company headquartered in South Carolina, but it was later moved into the Fortune 1000 list. The three Fortune 1000 companies headquartered in the state are Domtar, Sonoco Products, and ScanSource.\nSouth Carolina also benefits from foreign investment. There are 1,950 foreign-owned firms operating in South Carolina employing almost 135,000 people. Foreign Direct Investment (FDI) brought 1.06\u00a0billion dollars to the state economy in 2010. Since 1994, BMW has had a production facility in Spartanburg County near Greer and since 1996 the Zapp Group operates in Summerville near Charleston.\nTransportation and infrastructure.\nThe state has the fourth largest state-maintained highway system in the country, consisting of 11 Interstates, numbered highways, state highways, and secondary roads, totalling approximately .\nOn secondary roads, South Carolina uses a numbering system to keep track of all non-interstate and primary highways that the South Carolina Department of Transportation maintains. Secondary roads are numbered by the number of the county followed by a unique number for the particular road.\nRail.\n&lt;templatestyles src=\"Routemap/styles.css\"/&gt;\nCSX Transportation and Norfolk Southern are the only Class I railroad companies in South Carolina, as other freight companies in the state are short lines.\nAmtrak operates four passenger routes in South Carolina: the \"Crescent\", the \"Palmetto\", the \"Silver Meteor\", and the \"Silver Star\". The \"Crescent\" route serves the Upstate cities, the \"Silver Star\" serves the Midlands cities, and the \"Palmetto\" and \"Silver Meteor\" routes serve the lowcountry cities.\nMajor and regional airports.\nThere are seven significant airports in South Carolina, all of which act as regional airport hubs. The busiest by passenger volume is Charleston International Airport. Just across the border in North Carolina is Charlotte/Douglas International Airport, the 30th busiest airport in the world, in terms of passengers.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nEducation.\nSouth Carolina has 1,167 K\u201312 schools in 79 school districts with an enrollment of 751,660 as of 2022. In 2022, South Carolina spent $11,747 per public school student.\nIn 2023, the average SAT score in South Carolina was 1028, in line with the national average.\nSouth Carolina does not currently implement Common Core in schools, having repealed the standards in 2014.\nIn 2014, the South Carolina Supreme Court ruled the state had failed to provide a \"minimally adequate\" education to children in all parts of the state as required by the state's constitution.\nSouth Carolina is the only state which owns and operates a statewide school bus system. As of December 2016, the state maintains a 5,582-bus fleet with the average vehicle in service being fifteen years old (the national average is six) having logged 236,000 miles. Half of the state's school buses are more than 15 years old and some are reportedly up to 30 years old. In 2017 in the budget proposal, Superintendent of Education Molly Spearman requested the state lease to purchase 1,000 buses to replace the most decrepit vehicles. An additional 175 buses could be purchased immediately through the State Treasurer's master lease program. On January 5, 2017, the U.S. Environmental Protection Agency awarded South Carolina more than $1.1\u00a0million to replace 57 school buses with new cleaner models through its Diesel Emissions Reduction Act program.\nHigher education.\nSouth Carolina has diverse institutions from large state-funded research universities to small colleges that cultivate a liberal arts, religious, or military tradition. (List below sorted by year established.)\nHealth care.\nFor overall health care, South Carolina is ranked 37th out of the 50 states in 2022, according to The Commonwealth Fund, a private health foundation working to improve the health care system. The state's teen birth rate was 53 births per 1,000 teens, compared to the national average of 41.9 births, according to the Kaiser Family Foundation. The state's infant mortality rate was 9.4 deaths per 1,000 births compared to the national average of 6.9 deaths.\nThere were 2.6 physicians per 1,000 people compared to the national average of 3.2 physicians. There was $5,114 spent on health expenses per capita in the state, compared to the national average of $5,283. There were 26 percent of children and 13 percent of elderly living in poverty in the state, compared to 23 percent and 13 percent, respectively, doing so in the U.S. There were 34 percent of children that were overweight or obese, compared to the national average of 32 percent.\nMedia.\nThere are 36 TV stations (including PBS affiliates) serving South Carolina with terrestrial, and some online streaming access. Markets in which the stations are located include Columbia, Florence, Allendale, Myrtle Beach, Greenville, Charleston, Conway, Beaufort, Hardeeville, Spartanburg, Greenwood, Anderson and Sumter. There are multiple news companies in South Carolina, some major ones are The Charleston Chronicle, Greenville News, The Post and Courier, The State, and The Sun News.\nGovernment and politics.\nSouth Carolina's state government consists of executive, legislative, and judicial branches. The governor of South Carolina heads the executive branch; the South Carolina General Assembly heads the legislative branch; and the South Carolina Supreme Court heads the judicial branch.\nSouth Carolina is a largely conservative state. Since the Declaration of Independence, South Carolina's politics have been controlled by three main parties: the Democratic-Republican Party in the early 1800s, the Democratic Party through most of the 19th and 20th centuries, and the Republican Party in the 21st century. Since the mid-1990s, the South Carolina General Assembly has been controlled by the Republican party, and currently, eight of nine statewide offices are held by Republican officeholders and one by a Democratic officeholder.\nAt the federal level, South Carolina has voted Republican in every presidential election since the 1980 election of Ronald Reagan. The last Democratic candidate to carry the state was Jimmy Carter in 1976. Both of South Carolina's senators are Republican. The most recent Democratic senator to serve was Fritz Hollings, who left office in 2005. South Carolina has seven representatives in the United States House of Representatives, six of whom are Republican. As of November 8, 2022, there were 3,740,743 registered voters. In a 2020 study, South Carolina was ranked by the \"Election Law Journal\" as the 7th hardest state for citizens to vote in. South Carolina retains the death penalty. Authorized methods of execution include by electric chair or firing squad.\nAn April 2023 \"Winthrop University\" poll found that an overwhelming majority of South Carolinians supported legalizing medical marijuana and believed that a separation between church and state was \"critical\". A large majority were also found to support same-sex marriage, legalized recreational marijuana and sports gambling, along with an independent commission system for congressional redistricting.\nCulture.\nSouth Carolina has many venues for visual and performing arts. The Gibbes Museum of Art in Charleston, the Greenville County Museum of Art, the Columbia Museum of Art, Spartanburg Art Museum, and the South Carolina State Museum in Columbia among others provide access to visual arts to the state. There are also numerous historic sites and museums scattered throughout the state paying homage to many events and periods in the state's history from Native American inhabitation to the present day.\nSouth Carolina also has performing art venues including the Peace Center in Greenville, the Koger Center for the Arts in Columbia, and the Newberry Opera House, among others to bring local, national, and international talent to the stages of South Carolina. Several large venues can house major events, including Colonial Life Arena in Columbia, Bon Secours Wellness Arena in Greenville, and North Charleston Coliseum.\nOne of the nation's major performing arts festivals, Spoleto Festival USA, is held annually in Charleston. There are also countless local festivals throughout the state highlighting many cultural traditions, historical events, and folklore.\nAccording to the South Carolina Arts Commission, creative industries generate $9.2\u00a0billion annually and support over 78,000 jobs in the state. A 2009 statewide poll by the University of South Carolina Institute for Public Service and Policy Research found that 67% of residents had participated in the arts in some form during the past year and on average citizens had participated in the arts 14 times in the previous year.\nSports.\nAlthough no major league professional sports teams are based in South Carolina, the Carolina Panthers have training facilities in the state and played their inaugural season's home games at Clemson's Memorial Stadium in 1995. They now play at Bank of America Stadium in Charlotte, North Carolina. The Panthers consider themselves \"The Carolinas' Team\" and refrained from naming themselves after Charlotte or either of the Carolinas. The state is also home to numerous minor league professional teams. College teams represent their particular South Carolina institutions, and are the primary options for football, basketball and baseball attendance in the state. South Carolina is also a top destination for golf and water sports.\nSouth Carolina is also home to one of NASCAR's first tracks and its first paved speedway, Darlington Raceway, located northwest of Florence.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27958", "revid": "2366721", "url": "https://en.wikipedia.org/wiki?curid=27958", "title": "Lucius Cornelius Sulla", "text": ""}
{"id": "27960", "revid": "1161152567", "url": "https://en.wikipedia.org/wiki?curid=27960", "title": "Sessions", "text": "Sessions may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "27962", "revid": "1289606", "url": "https://en.wikipedia.org/wiki?curid=27962", "title": "Session", "text": "Session may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "27963", "revid": "4928500", "url": "https://en.wikipedia.org/wiki?curid=27963", "title": "Spy novel", "text": ""}
{"id": "27964", "revid": "51016423", "url": "https://en.wikipedia.org/wiki?curid=27964", "title": "Sikhism", "text": "Religion originating in Punjab, India\nSikhism is an Indian religion and philosophy that originated in the Punjab region of the Indian subcontinent around the end of the 15th century CE. It is one of the most recently founded major religions and is followed by 25\u201330million adherents, known as Sikhs.\nSikhism developed from the spiritual teachings of Guru Nanak (1469\u20131539), the faith's first guru, and the nine Sikh gurus who succeeded him. The tenth guru, Guru Gobind Singh (1666\u20131708), named the Guru Granth Sahib, which is the central religious scripture in Sikhism, as his successor. This brought the line of human gurus to a close. Sikhs regard the Guru Granth Sahib as the 11th and eternally living guru.\nThe core beliefs and practices of Sikhism, articulated in the Guru Granth Sahib and other Sikh scriptures, include faith and meditation in the name of the one creator (\"Ik Onkar\"), the divine unity and equality of all humankind, engaging in selfless service to others (\"sev\u0101\"), striving for justice for the benefit and prosperity of all (\"sarbat da bhala\"), and honest conduct and livelihood. Following this standard, Sikhism rejects claims that any particular religious tradition has a monopoly on absolute truth. As a consequence, Sikhs do not actively proselytise, although voluntary converts are generally accepted. Sikhism emphasises meditation and remembrance as a means to feel God's presence (\"simran\"), which can be expressed musically through \"kirtan\" or internally through \"naam japna\" (lit.\u2009'meditation on God's name'). Baptised Sikhs are obliged to wear the five Ks, which are five articles of faith which physically distinguish Sikhs from non-Sikhs. Among these include the \"kesh\" (uncut hair). Most religious Sikh men thus do not cut their hair but rather wear a turban.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n The definition of a Sikh, according to the \"Rehat Maryada\", the Sikh code of conduct, is any human being who faithfully believes in the following:\n and who does not owe allegiance to any other religion.\nThe religion developed and evolved in times of religious persecution, gaining converts from both Hinduism and Islam. The Mughal emperors of India tortured and executed two of the Sikh gurus\u2014Guru Arjan (1563\u20131605) and Guru Tegh Bahadur (1621\u20131675)\u2014after they refused to convert to Islam. The persecution of the Sikhs triggered the founding of the \"Khalsa\" by Guru Gobind Singh in 1699 as an order to protect the freedom of conscience and religion, with members expressing the qualities of a \"sant-sip\u0101h\u012b\" (\"saint-soldier\").\nTerminology.\nThe majority of Sikh scriptures were originally written in the alphabet of \"Gurmukh\u012b\", a script standardised by Guru Angad out of La\u1e47\u1e0d\u0101 scripts historically used in present-day Pakistan and North India. Adherents of Sikhism are known as \"Sikhs\", meaning \"students\" or \"disciples\" of the guru. The English word \"Sikhism\" derives from the Punjabi word for the religion \"Sikhi\" ( ', , from ), which connotes the \"temporal path of learning\" and is rooted in the verb (lit.\u2009'to learn').\nSome Sikhs oppose the exonym term \"Sikhism\" as they claim the word was coined by the British colonists rather than by Sikhs themselves, and they instead prefer the endonym \"Sikhi\". They argue that an \"-ism\" connotes a fixed and immutable worldview which is not congruent with the internally fluid nature of the Sikh philosophy.\nPhilosophy and teachings.\nThe basis of Sikhism lies in the teachings of Guru Nanak and his successors. Sikhs emphasise the congruence between spiritual development and everyday moral conduct. Its founder, Guru Nanak, summarised this perspective by saying, \"Truth is the highest virtue, but higher still is truthful living.\" Sikhism emphasises \"\u0116k n\u016br te sab jag upji\u0101\", 'From the one light, the entire universe welled up.' Guru Nanak also emphasised his teachings to his disciples by giving them real-life examples.\nGod.\nSikhism is a monotheistic and panentheistic religion. Sikhs believe that only one God exists and that God is simultaneously within everything and is all-encompassing. The oneness of God is reflected by the phrase \"Ik Onkar\". In Sikhism, the word for God is \"Waheguru\" (lit.\u2009'wondrous teacher'). The \"Waheguru\" is considered to be \"Nirankar\" (\"shapeless\"), \"Akal\" (\"timeless\"), \"Karta Purakh\" (\"the creator being\"), \"Akaal Purkh\" (\"beyond time and death\") and \"Agam Agochar\" (\"incomprehensible and invisible\").\nIn a literal sense, God has no gender in Sikhism, but metaphorically, God is presented as masculine and God's power as feminine. For example, Guru Gobind Singh refers to God as his father and God's creative power as his mother. Similarly, another example is that the \"Guru Granth Sahib\", the primary Sikh scripture, says that all humans are soul-brides who long to unite with their husband Lord. In addition, the gurus also wrote in the Guru Granth Sahib that there are many worlds on which the transcendental God has created life.\nThe Sikh scripture begins with God as \"Ik Onkar\" (), the 'One Creator', understood in the Sikh tradition as monotheistic unity of God. \"Ik onkar\" (sometimes capitalised) is more loosely rendered 'the one supreme reality', 'the one creator', 'the all-pervading spirit', and other ways of expressing a diffused but unified and singular sense of God and creation.\nThe traditional \"Mul Mantar\" goes from \"ik onkar\" until \"Nanak hosee bhee sach.\" The opening line of the \"Guru Granth Sahib\" and each subsequent \"raga\" mentions \"ik onkar\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;&lt;templatestyles src=\"Interlinear/styles.css\" /&gt;\u2014\u200a\nWorldly illusion.\n\"M\u0101y\u0101\", defined as a temporary illusion or \"unreality\", is one of the core deviations from the pursuit of God and salvation: where worldly attractions give only illusory, temporary satisfaction and pain that distracts from the process of the devotion of God. However, Nanak emphasised m\u0101y\u0101 as not a reference to the world's unreality but its values. In Sikhism, the influences of ego, anger, greed, attachment, and lust, known as the \"p\u0101nj chor\" ('Five Thieves'), are believed to be particularly distracting and hurtful. Sikhs believe the world is currently in a state of \"Kali Yuga\" ('age of darkness') because the world is led astray by the love of and attachment to \"m\u0101y\u0101\". The fate of people vulnerable to the five thieves is separation from God, and the situation may be remedied only after intensive and relentless devotion.\nTimeless truth.\nAccording to Guru Nanak, the supreme purpose of human life is to reconnect with \"Akal\" ('The Timeless One'). However, egotism is the most significant barrier to making this connection. Using the Guru's teaching remembrance of \"n\u0101m\" (the divine Name of the Lord) leads to the end of egotism. Guru Nanak designated the word \"Guru\" ('teacher') to mean the voice of \"the spirit\": the source of knowledge and the guide to salvation. As \"ik onkar\" is universally immanent, \"Guru\" is indistinguishable from \"Akal\" and are one and the same.\nLiberation.\nGuru Nanak's teachings are founded not on a final destination of heaven or hell but on a spiritual union with the \"Akal\", which results in salvation or \"jivanmukti\" ('enlightenment/liberation within one's lifetime'), a concept also found in Hinduism. Guru Gobind Singh makes it clear that human birth is obtained with great fortune, and therefore one needs to be able to make the most of this life.\nSikhs accept reincarnation and karma concepts found in Buddhism, Hinduism, and Jainism, but do not necessarily infer a metaphysical soteriology such as a state of \"heaven\" or \"nirvana.\" Nevertheless, in Sikhism, both karma and liberation are \"modified by the concept of God's grace\" (\"nadar, mehar, kirpa, karam\", etc.). Guru Nanak states that \"the body takes birth because of karma, but salvation is attained through grace.\" To get closer to God, Sikhs: avoid the evils of \"maya\"; keep the everlasting truth in mind; practice \"shabad kirtan\" (musical recitation of hymns); meditate on \"naam\"; and serve humanity. Sikhs believe that being in the company of the \"satsang\" (association with \"sat\", 'true', people) or \"sadh sangat\" is one of the key ways to achieve liberation from the cycles of reincarnation. The Sikh community may be seen to correspond to A.D. Smith's definition of a politicised community, sharing common ancestry myths and historical memories of martyrdom and persecution under successive rulers.\nPower and devotion (Miri and Piri).\nMiri Piri is a doctrine practiced in the Sikh religion since the seventeenth century. The doctrine of the \"Mir\" (social and political aspects of life) and the \"Pir\" (guides to the spiritual aspect of life) was revealed by the first guru of Sikhism, Guru Nanak, but propounded by the sixth guru of Sikhism, Guru Hargobind, on 12 June 1606. After the martyrdom of his father, Guru Hargobind was elevated to the Guruship and fulfilled the prophecy that was given by the primal figure of Sikh, Baba Buddha, that the guru will possess spiritual and temporal power. Guru Hargobind introduced the two swords of Miri and Piri, symbolising both worldly (social and political) and spiritual authority. The two kirpan of Miri and Piri are tied together with a khanda in the center, so the combination of both is considered supreme. This means that all action informed or arising out of the spiritual heart completes one's purpose and meaning in the world of action: spirituality.\nGuru Nanak, the first Sikh guru and the founder of Sikhism, was a Bhakti saint. He taught that the most important form of worship is \"Bhakti\" (devotion to Waheguru). Guru Arjan, in the \"Sukhmani Sahib\", recommended the true religion as one of loving devotion to God. The \"Guru Granth Sahib\" includes suggestions on how a Sikh should perform constant Bhakti. Some scholars call Sikhism a Bhakti sect of Indian traditions, adding that it emphasises \"nirguni Bhakti\", i.e. loving devotion to a divine without qualities or physical form. While Western scholarship generally places Sikhism as arising primarily within a Hindu Bhakti movement milieu while recognising some Sufi Islamic influences, some Indian Sikh scholars disagree and state that Sikhism transcended the environment it emerged from. The basis of the latter analysis is that Bhakti traditions did not clearly disassociate from Vedic texts and their cosmologies and metaphysical worldview, while the Sikh tradition clearly did disassociate from the Vedic tradition.\nSeveral Sikh sects outside the Punjab region of India, such as those found in Maharashtra and Bihar, practice \"aarti\" (the ceremonial use of lamps) during Bhakti observances in a Sikh gurdwara. However, most Sikh gurdwaras forbid \"aarti\" during their Bhakti practices. While emphasising Bhakti, the Sikh gurus also taught that the spiritual life and secular householder life are intertwined, and not separate. This logically follows from the panentheistic nature of Sikh philosophy. In Sikh worldview, the everyday world is part of the Infinite Reality, increased spiritual awareness leads to increased and vibrant participation in the everyday world. Guru Nanak described living an \"active, creative, and practical life\" of \"truthfulness, fidelity, self-control and purity\" as being higher than the metaphysical truth.\nThe sixth guru, Guru Hargobind, after Guru Arjan's martyrdom, faced with oppression by the Islamic Mughal Empire, affirmed the philosophy that the political/temporal (\"Miri\") and spiritual (\"Piri\") realms are mutually coexistent. According to the ninth Sikh guru, Tegh Bahadur, the ideal Sikh should have both \"Shakti\" (power that resides in the temporal), and \"Bhakti\" (spiritual meditative qualities). This was developed into the concept of the \"saint soldier\" by the tenth Sikh guru, Gobind Singh.\nThe concept of humanity, as elaborated by Guru Nanak, refines and negates the \"monotheistic concept of self/God\", declaring that \"monotheism becomes almost redundant in the movement and crossings of love\". Sikh gurus have taught that the human's goal is to end all dualities of \"self and other, I and not-I\", attain the \"attendant balance of separation-fusion, self-other, action-inaction, attachment-detachment, in the course of daily life\".\nSinging and music.\nSikhs refer to the hymns of the gurus as \"Gurbani\" (lit.\u2009'Guru's word'). Shabad Kirtan is the singing of Gurbani. The entire Guru Granth Sahib is written in the form of poetry and rhyme to be recited in thirty-one ragas of classical Indian music as specified. However, the exponents of these are rarely to be found amongst the Sikhs who are conversant with all the Ragas in the Guru Granth Sahib. Guru Nanak started the Shabad Kirtan tradition and taught that listening to kirtan is a powerful way to achieve tranquility while meditating, and singing of the glories of the \"Supreme Timeless One\" (God) with devotion is the most effective way to come in communion with the \"Supreme Timeless One\". The three morning prayers for Sikhs consist of Japji Sahib, Jaap Sahib, and Tav-Prasad Savaiye. Baptised Sikhs (Amritdharis) rise early and meditate, then recite all the Five Banis of Nitnem, before breakfast. The Five Banis consist of Japji Sahib, Jaap Sahib, Tav-Prasad Savaiye, Chaupai Sahib, Anand Sahib; recitation of the banis \"paath\" is followed by Ard\u0101s, in which the Sarbat da Bhala principle is taught by gurus.\nRemembrance of the Divine Name.\nA key practice by Sikhs is remembrance of the \"Naam\" (divine name), Waheguru. This contemplation is done through \"N\u0101m Jap\u014d\" (repetition of the Divine Name) or \"Simran\" (remembrance of the Divine Name through recitation). The verbal repetition of the name of God\u2014or a sacred syllable\u2014is an established practice in religious traditions in India; however, Sikhism developed \"Naam-simran\" as an important Bhakti practice. Guru Nanak's ideal is the total exposure of one's being to the Divine Name and a conformation to Dharma, the \"Divine Order\". Nanak described the result of the disciplined application of \"n\u0101m simra\u1e47\" as a \"growing towards and into God\" through a gradual process of five stages. The last of these is \"Sach Khand\" (\"The Realm of Truth\"): the final union of the spirit with God.\nService and action.\nThe Sikh gurus taught that by constantly remembering the divine name (\"naam simran\") and through selfless service (\"s\u0113v\u0101\") the devotee overcomes egotism (\"Haumai\"). This, it states, is the primary root of five evil impulses and the cycle of birth and death.\nService in Sikhism takes three forms: \"Tan\" (physical service, i.e. labor), \"Man\" (mental service, such as dedicating your heart for service of others), and \"Dhan\" (material service, including financial support). Sikhism stresses \"kirat kar\u014d\", that is, \"honest work\". Sikh teachings also stress the concept of sharing, or \"va\u1e47\u1e0d chakk\u014d\", giving to the needy for the benefit of the community.\nJustice and equality.\nSikhism regards God as the true emperor, the king of all kings, the one who dispenses justice through the law of \"karma\", a retributive model and divine grace.\nThe term for justice in the Sikh tradition is Ni\u0101y\u0101. It is related to the term \"dharam\", which in Sikhism connotes 'moral order' and righteousness (derived, but distinct from the etymologically related Hindu concept of dharma). According to the tenth Sikh guru, Guru Gobind Singh, states Pashaura Singh (a professor of Sikh studies), \"one must first try all the peaceful means of negotiation in the pursuit of justice\" and if these fail then it is legitimate to \"draw the sword in defense of righteousness\". Sikhism considers \"an attack on dharam is an attack on justice, on righteousness, and on the moral order generally\" and the dharam \"must be defended at all costs\". The divine name is its antidote for pain and vices. Forgiveness is taught as a virtue in Sikhism, yet it also teaches its faithful to shun those with evil intentions and to pick up the sword to fight injustice and religious persecution.\nSikhism does not differentiate religious obligations by sex. God in Sikhism has no sex, and the Sikh scripture does not discriminate against women, nor bar them from any roles. Women in Sikhism have been in positions of leadership, including leading in wars and issuing orders or hukamnamas.\nTen Gurus and authority.\nThe term \"guru\" is derived from the Sanskrit \"gur\u016b\", meaning teacher, enlightener, guide, or mentor. The traditions and philosophy of Sikhism were established by ten gurus from 1469 to 1708. Each guru added to and reinforced the message taught by the previous, resulting in the creation of the Sikh religion. Guru Nanak was the first guru and appointed a disciple as successor. Guru Gobind Singh was the final guru in human form. Before his death, Guru Gobind Singh decreed in 1708, that the Gur\u016b Granth S\u0101hib would be the final and perpetual guru of the Sikhs.\nGuru Nanak stated that his guru is God who is the same from the beginning of time to the end of time. Nanak said to be a God's slave and servant, but maintained that he was only a guide and teacher. Nanak stated that the human guru is mortal, who is to be respected and loved but not worshipped. When \"guru\", or satguru (lit.\u2009'the true guru') is used in \"Gurbani\" it is often referring to the highest expression of truthfulness.\nGuru Angad succeeded Guru Nanak. Later, an important phase in the development of Sikhism came with the third successor, Guru Amar Das. Guru Nanak's teachings emphasised the pursuit of salvation; Guru Amar Das began building a cohesive community of followers with initiatives such as sanctioning distinctive ceremonies for birth, marriage, and death. Amar Das also established the \"manji\" (comparable to a diocese) system of clerical supervision.\nThe Sikh gurus established a mechanism which allowed the Sikh religion to react as a community to changing circumstances. The sixth guru, Guru Hargobind, was responsible for the creation of the concept of Akal Takht (\"throne of the timeless one\"), which serves as the supreme decision-making centre of Sikhism and sits opposite the Harmandir Sahib. The Akal Takht is located in the city of Amritsar. The leader is appointed by the Shiromani Gurdwara Pabandhak Committee (SPGC). The \"Sarbat \u1e34\u1e96\u0101ls\u0101\" (a representative portion of the Khalsa Panth) historically gathers at the Akal Takht on special festivals such as Vaisakhi or Hola Mohalla and when there is a need to discuss matters that affect the entire Sikh nation. A \"gurmat\u0101\" (literally, 'guru's intention') is an order passed by the Sarbat \u1e34\u1e96\u0101ls\u0101 in the presence of the Gur\u016b Granth S\u0101hib. A \"gurmat\u0101\" may only be passed on a subject that affects the fundamental principles of Sikh religion; it is binding upon all Sikhs.\nThe word \"guru\" in Sikhism also refers to \"Akal Purkh\" (God), and God and \"guru\" can sometimes be synonymous in \"Gurbani\" (Sikh writings).\nScripture.\nThere is one primary scripture for the Sikhs: the \"Guru Granth Sahib\". It is sometimes synonymously referred to as the \"\u0100di Granth\". Chronologically, however, the \"\u0100di Granth\" \u2013 literally, 'First Volume' \u2013 refers to the version of the scripture created by Guru Arjan in 1604. The Guru Granth Sahib is the final expanded version of the scripture compiled by Guru Gobind Singh. While the Guru Granth Sahib is an unquestioned scripture in Sikhism, another important religious text, the \"Dasam Granth\", does not enjoy universal consensus, but is considered a secondary scripture by many Sikhs.\n\u0100di Granth.\nThe \"\u0100di Granth\" was compiled primarily by Bhai Gurdas under the supervision of Guru Arjan between the years 1603 and 1604. It is written in the Gurmukh\u012b script, which is a descendant of the La\u1e47\u1e0d\u0101 script used in the Punjab at that time. The Gurmukh\u012b script was standardised by Guru Angad, the second guru of the Sikhs, for use in the Sikh scriptures and is thought to have been influenced by the \u015a\u0101rad\u0101 and Devan\u0101gar\u012b scripts. An authoritative scripture was created to protect the integrity of hymns and teachings of the Sikh gurus, as well as thirteen Hindu and two Muslim bhagats of the Bhakti movement sant tradition in medieval India. The thirteen Hindu \"bhagats\" whose teachings were entered into the text included Ramananda, Namdev, Pipa, Ravidas, Beni, Bhikhan, Dhanna, Jaidev, Parmanand, Sadhana, Sain, Sur, Trilochan, while the two Muslim \"bhagats\" were Kabir and Sufi saint Farid. However, the bhagats in context often spoke of transcending their religious labels; Kabir, often attributed to being a Muslim, states in the \"\u0100di Granth\", \"I am not Hindu nor Muslim.\" The gurus following this message taught that different methods of devotion are for the same infinite God.\nGuru Granth Sahib.\nThe Guru Granth Sahib is the holy scripture of the Sikhs and is regarded as the living guru.\nCompilation.\nThe Guru Granth Sahib started as a volume of Guru Nanak's poetic compositions. Prior to his death, he passed on his volume to the subsequent guru, Guru Angad. The final version of the Guru Granth Sahib was compiled by Guru Gobind Singh in 1678. It consists of the original \u0100di Granth with the addition of Guru Tegh Bahadur's hymns. The predominant bulk of Guru Granth Sahib consists of compositions by seven Sikh gurus: Guru Nanak, Guru Angad, Guru Amar Das, Guru Ram Das, Guru Arjan, Guru Teg Bahadur and Guru Gobind Singh. It also contains the traditions and teachings of thirteen Hindu Bhakti movement \"sants\" (saints) such as Ramananda, Namdev, Sant kabir among others, and two Muslim saints: the Sufi Sheikh Farid.\nThe text comprises 6,000 \"\u015babads\" (line compositions), which are poetically rendered and set to rhythmic ancient north Indian classical music. The bulk of the scripture is classified into sixty \"r\u0101gas\", with each Granth r\u0101ga subdivided according to length and author. The hymns in the scripture are arranged primarily by the \"r\u0101gas\" in which they are read.\nLanguage and script.\nThe primary language used in the scripture is known as \"Sant Bh\u0101\u1e63\u0101\", a language related to both Punjabi and Hindi and used extensively across medieval northern India by proponents of popular devotional religion (bhakti). The text is printed in Gurumukhi script, believed to have been developed by Guru Angad. The language shares the Indo-European roots found in numerous regional languages of India.\nTeachings.\nThe vision in the Guru Granth Sahib, states Torkel Brekke, is a society based on divine justice without oppression.\nOne God exists, truth by name, creative power, without fear, without enmity, timeless form, unborn, self-existent, by the guru's grace.\nAs guru.\nThe tenth guru, Guru Gobind Singh, named the Sikh scripture Guru Granth Sahib as his successor, terminating the line of human gurus and making the scripture the literal embodiment of the eternal, impersonal guru, serving as the spiritual guide for Sikhs.\nThe Guru Granth Sahib is installed in all Sikh \"Gurdwara\"s (temples); many Sikhs bow or prostrate before it when entering the temple. The Guru Granth Sahib is installed every morning and put to bed at night in many \"Gurdwaras\". The Granth is revered as eternal \"gurb\u0101n\u012b\" and the spiritual authority.\nThe copies of the Guru Granth Sahib are not regarded as material objects but as living subjects. According to Myrvold, the Sikh scripture is treated with respect like a living person, in a manner similar to the Gospel in early Christian worship. Old copies of the Sikh scripture are not thrown away. Instead, funerary services are performed.\nIn India, the Guru Granth Sahib is officially recognised by the Supreme Court of India as a judicial person who can receive donations and own land. Yet, some Sikhs also warn that, without proper comprehension of the text, veneration for the text can lead to bibliolatry, with the concrete form of the teachings becoming the object of worship instead of the teachings themselves.\nDistinction from Other Monotheistic Religions.\nThe Abrahamic religions do not deny the existence of spiritual beings such as angels, Satan (Iblis), and jinn under the one true God. However, Sikhism does not acknowledge the existence of such spiritual entities; it recognises only the one, formless, omnipotent, and omniscient God (Waheguru), emphasising the directness and oneness of God. Although Sikh scriptures mention angels, devas, Yama, and demons, these references are merely literary metaphors or borrowings, and are not regarded as descriptions of real, existing spiritual beings.\nRelation to Hinduism and Islam.\nThe Sikh scriptures use Hindu terminology, with references to the Vedas, and the names of gods and goddesses in Hindu bhakti movement traditions, such as Vishnu, Shiva, Brahma, Parvati, Lakshmi, Saraswati, Rama, Krishna, but not to worship. It also refers to the spiritual concepts in Hinduism (\"Ishvara, Bhagavan, Brahman\") and the idea of God in Islam (\"Allah\") to assert that these are just \"alternate names for the Almighty One\".\nWhile the Guru Granth Sahib acknowledges the Vedas, Puranas and Quran, it does not imply a syncretic bridge between Hinduism and Islam, but emphasises focusing on nitnem banis like Japu (repeating mantra of the divine Name of God \u2013 Waheguru), instead of practices such as praying by prostrating on the ground to God towards a specific direction by Muslims, or Hindu rituals such as wearing thread; the former being, though, a disciplinary aspect of worship, given Dhikr (remembrance of Allah) is similarly emphasised in Islam.\nDasam Granth.\nThe Dasam Granth is a Sikh scripture which contains texts attributed to Guru Gobind Singh. Scholars, on the other hand, attribute the work to after the guru's death, being authored by an unknown poet. The \"Dasam Granth\" is important to a great number of Sikhs. However, it does not have the same authority as the \"Guru Granth Sahib\". Some compositions of the \"Dasam Granth\" like Jaap Sahib (Amrit Savaiye), and Benti Chaupai are part of the daily prayers (Nitnem) for Sikhs. The first verse of the ard\u0101s prayer is from Chandi di Var. The \"Dasam Granth\" is largely a version of Hindu mythology from the Puranas: secular stories from a variety of sources called \"Charitro Pakhyan\"\u2014tales to protect careless men from the perils of lust.\nMany versions of \"Dasam Granth\" exist, and the authenticity of the \"Dasam Granth\" has, in modern times, become one of the most debated topics within Sikhism. The Akali Nihangs consider the Dasam and Sarbloh Granth as extensions of the Guru Granth Sahib. The text played a significant role in Sikh history, but in modern times parts of the text have seen antipathy and discussion among Sikhs.\nSarbloh Granth.\nThe Sarbloh Granth is a holy text containing 6,500 poetic stanzas traditionally attributed to Guru Gobind Singh. Scholars, on the other hand, attribute the work to after the guru's death, being authored by an unknown poet. This scripture contains, alongside various topics, the Sikh Art and Laws of War. Akali Nihangs largely revere this scripture, and many non-Nihang Sikhs reject it as an authentic work of the 10th guru. According to Harbans Singh the authenticity of the work is rejected on the grounds of its writing style and mastery of poetry not matching up with Guru Gobind Singh's \"Dasam Granth\" work. Also, the text makes mention of a work composed in 1719, much after the death of Guru Gobind Singh. W. H. McLeod dates the work to the late 18th century and believes an unknown poet authored it, which was mistakenly attributed to the tenth guru.\nJanamsakhis.\nThe Janams\u0101kh\u012bs (literally \"birth stories\") are writings that profess to be biographies of Guru Nanak. Although not scripture in the strictest sense, they provide a hagiographic look at Guru Nanak's life and the early start of Sikhism.\nObservances.\nObservant Sikhs adhere to long-standing practices and traditions to strengthen and express their faith. The daily recitation of the divine name of God, Waheguru, and from a memory of specific passages from the Guru Granth Sahib, like the \"Japu\" (or \"Japj\u012b\", literally \"chant\") hymns is recommended immediately after rising and bathing. Baptised Sikhs recite the five-morning prayers, the evening and night prayer. Family customs include both reading passages from the scripture and attending the gurdwara (also \"gurdu\u0101r\u0101\", meaning \"the doorway to God\"; sometimes transliterated as \"Gurudwara\"). There are many gurdwaras prominently constructed and maintained across India, as well as in almost every country where Sikhs reside. Gurdwaras are open to all, regardless of religion, background, caste, or race.\nWorship in a gurdwara consists chiefly of the singing of passages from the scripture. Sikhs will commonly prostrate before the holy scripture when entering a gurdwara. The recitation of the eighteenth century \"ard\u0101s\" is also customary for attending Sikhs. The ard\u0101s recalls past sufferings and glories of the community, invoking divine grace for all humanity.\nThe gurdwara is also the location for the historic Sikh practice of \"langar\" or the community meal. All gurdwaras are open to anyone of any faith for a free meal, which is always vegetarian. People eat together, and the kitchen is maintained and serviced by Sikh community volunteers.\nSikh festivals/events.\nGuru Amar Das chose festivals for celebration by Sikhs like Vaisakhi, wherein he asked Sikhs to assemble and share the festivities as a community.\nVaisakhi is one of the most important festivals of Sikhs, while other significant festivals commemorate the birth, lives of the gurus and Sikh martyrs. Historically, these festivals have been based on the moon calendar Bikrami calendar. In 2003, the SGPC, the Sikh organisation in charge of upkeep of the historical gurdwaras of Punjab, adopted Nanakshahi calendar. The new calendar is highly controversial among Sikhs and is not universally accepted. Sikh festivals include the following:\nCeremonies and customs.\n \nSikhs have also supported and helped develop major pilgrimage traditions to sacred sites such as Harmandir Sahib, Anandpur Sahib, Fatehgarh Sahib, Patna Sahib, Hazur Nanded Sahib, Hemkund Sahib and others. Sikh pilgrims and Sikhs of other sects customarily consider these as holy and a part of their \"Tirath\". The Hola Mohalla around the festival of Holi, for example, is a ceremonial and customary gathering every year in Anandpur Sahib attracting over 100,000 Sikhs. Major Sikh temples feature a \"sarovar\" where some Sikhs take a customary dip. Some take home the sacred water of the tank particularly for sick friends and relatives, believing that the waters of such sacred sites have restorative powers and the ability to purify one's \"karma\". The various gurus of Sikhism have had different approaches to pilgrimage.\nUpon a child's birth, the Guru Granth Sahib is opened at a random point and the child is named using the first letter on the top left hand corner of the left page. All boys are given the last name Singh, and all girls are given the last name Kaur (this was once a title which was conferred on an individual upon joining the Khalsa).\nThe Sikh marriage ritual includes the \"anand k\u0101raj\" ceremony. The marriage ceremony is performed in front of the Guru Granth Sahib by a baptised Khalsa, Granthi of the Gurdwara. Its official recognition and adoption came in 1909, during the Singh Sabha Movement.\nUpon death, the body of a Sikh is usually cremated. If this is not possible, any respectful means of disposing the body may be employed. The \"k\u012brtan s\u014dhil\u0101\" and \"ard\u0101s\" prayers are performed during the funeral ceremony (known as \"antim sansk\u0101r\").\nInitiation and the Khalsa.\nKhalsa (meaning \"pure and sovereign\") is the collective name given by Guru Gobind Singh, to those Sikhs who have been fully initiated by taking part in a ceremony called \"ammrit sa\u00f1c\u0101r\" (nectar ceremony). During this ceremony, sweetened water is stirred with a double-edged sword while liturgical prayers are sung; it is offered to the initiating Sikh, who ritually drinks it. Many Sikhs are not formally and fully initiated, as they do not undergo this ceremony, but do adhere to some components of Sikhism and identify as Sikhs. The initiated Sikh, who is believed to be reborn, is referred to as Amritdhari or Khalsa Sikh, while those who are not initiated or baptised are referred to as Kesdhari or Sahajdhari Sikhs.\nThe first time that this ceremony took place was on Vaisakhi, which fell on 30 March 1699 at Anandpur Sahib in Punjab. It was on that occasion that Gobind Singh baptised the Pa\u00f1j Pi\u0101r\u0113 \u2013 the five beloved ones, who in turn baptised Guru Gobind Singh himself. To males who initiated, the last name Singh, meaning \"lion\", was given, while the last name Kaur, meaning \"princess\", was given to baptised Sikh females.\nBaptised Sikhs wear five items, called the five Ks (in Punjabi known as \"pa\u00f1j kakk\u0113\" or \"pa\u00f1j kak\u0101r\"), at all times. The five items are: \"k\u0113s\" (uncut hair), \"ka\u1e45gh\u0101\" (small wooden comb), \"ka\u1e5b\u0101\" (circular steel or iron bracelet), \"kirp\u0101n\" (sword/dagger), and \"kacchera\" (special undergarment). The five Ks have both practical and symbolic purposes.\nHistory.\nSikhism originated around the 15th century. Guru Nanak (1469\u20131539), the founder of Sikhism, was born in the village of \"R\u0101i Bh\u014di d\u012b Talwand\u012b\", now called Nankana Sahib (in present-day Pakistan). His parents were Punjabi Khatri Hindus. According to the hagiography \"Puratan Janamsakhi\" composed more than two centuries after his death and probably based on oral tradition, Nanak as a boy was fascinated by religion and spiritual matters, spending time with wandering ascetics and holy men. His friend was Mardana, a Muslim. Together they would sing devotional songs all night in front of the public, and bathe in the river in the morning. One day, at the usual bath, Nanak went missing and his family feared he had drowned. Three days later he returned home, and declared: \"There is no Hindu, there is no Muslim\" (\"n\u0101 k\u014di hind\u016b n\u0101 k\u014di musalm\u0101n\"). Thereafter, Nanak started preaching his ideas that form the tenets of Sikhism. In 1526, Guru Nanak at age 50, started a small commune in Kartarpur and his disciples came to be known as \"Sikhs\". Although the exact account of his itinerary is disputed, hagiographic accounts state he made five major journeys, spanning thousands of miles: the first tour being east towards Bengal and Assam; the second south towards Andhra and Tamil Nadu; the third north to Kashmir, Ladakh, and Mount Sumeru in Tibet; and the fourth to Baghdad. In his last and final tour, he returned to the banks of the Ravi River to end his days.\nThere are two competing theories on Guru Nanak's teachings. One, according to Cole and Sambhi, is based on hagiographical Janamsakhis, and states that Nanak's teachings and Sikhism were a revelation from God, and not a social protest movement nor any attempt to reconcile Hinduism and Islam in the 15th century. The other states that Nanak was a guru. According to Singha, \"Sikhism does not subscribe to the theory of incarnation or the concept of prophethood. But it has a pivotal concept of Guru. He is not an incarnation of God, not even a prophet. He is an illumined soul.\" The second theory continues that hagiographical \"Janamsakhis\" were not written by Nanak, but by later followers without regard for historical accuracy, and contain numerous legends and myths created to show respect for Nanak. The term \"revelation\", clarify Cole and Sambhi, in Sikhism is not limited to the teachings of Nanak, but is extended to all Sikh gurus, as well as the words of past, present and future men and women, who possess divine knowledge intuitively through meditation. The Sikh revelations include the words of non-Sikh bhagats, some who lived and died before the birth of Nanak, and whose teachings are part of the Sikh scriptures. The Adi Granth and successive Sikh gurus repeatedly emphasised, states Mandair, that Sikhism is \"not about hearing voices from God, but it is about changing the nature of the human mind, and anyone can achieve direct experience and spiritual perfection at any time\".\nHistorical influences.\nThe roots of the Sikh tradition are, states Louis Fenech, perhaps in the Sant-tradition of India whose ideology grew to become the Bhakti tradition. Furthermore, adds Fenech:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Few Sikhs would mention these Indic texts and ideologies in the same breadth as the Sikh tradition, let alone trace elements of their tradition to this chronological and ideological point, despite the fact that the Indic mythology permeates the Sikh sacred canon, the \"Guru Granth Sahib\", and the secondary canon, the \"Dasam Granth\"\u00a0... and adds delicate nuance and substance to the sacred symbolic universe of the Sikhs of today and of their past ancestors.\nThe development of Sikhism was influenced by the Bhakti movement; however, Sikhism was not simply an extension of the Bhakti movement. Sikhism, for instance, disagreed with some of the views of Bhakti saints Kabir and Ravidas. Sikhism developed while the region was being ruled by the Mughal Empire. Two of the Sikh gurus, Guru Arjan and Guru Tegh Bahadur, refused to convert to Islam and were tortured and executed by the Mughal rulers. The Islamic era persecution of Sikhs triggered the founding of the Khalsa, as an order for freedom of conscience and religion. A Sikh is expected to embody the qualities of a \"Sant-Sip\u0101h\u012b\"\u00a0\u2013 a saint-soldier.\nGrowth of Sikhism.\nAfter its inception, Sikhism grew as it gained converts among Hindus and Muslims in the Punjab region. In 1539, Guru Nanak chose his disciple Lahi\u1e47\u0101 as a successor to the Guruship rather than either of his sons. Lahi\u1e47\u0101 was named Guru Angad and became the second guru of the Sikhs. Nanak conferred his choice at the town of Kartarpur on the banks of the river Ravi. Sri Chand, Guru Nanak's son was also a religious man, and continued his own commune of Sikhs. His followers came to be known as the Udasi Sikhs, the first parallel sect of Sikhism that formed in Sikh history. The Udasis believe that the Guruship should have gone to Sri Chand, since he was a man of pious habits in addition to being Nanak's son.\nGuru Angad, before joining Guru Nanak's commune, worked as a \"pujari\" (priest) and religious teacher centered around Hindu goddess Durga. On Nanak's advice, Guru Angad moved from Kartarpur to Khadur, where his wife Khivi and children were living, until he was able to bridge the divide between his followers and the Udasis. Guru Angad continued the work started by Guru Nanak and is widely credited for standardising the Gurmukh\u012b script as used in the sacred scripture of the Sikhs.\nGuru Amar Das became the third Sikh guru in 1552 at the age of 73. He adhered to the Vaishnavism tradition of Hinduism for much of his life, before joining the commune of Guru Angad. Goindval became an important centre for Sikhism during the Guruship of Guru Amar Das. He was a reformer, and discouraged veiling of women's faces (a Muslim custom) as well as sati (a Hindu custom). He encouraged the Kshatriya people to fight in order to protect people and for the sake of justice, stating this is Dharma. Guru Amar Das started the tradition of appointing \"manji\" (zones of religious administration with an appointed chief called \"sangatias\"), introduced the \"dasvandh\" (tithe) system of revenue collection in the name of guru and as pooled community religious resource, and the famed \"langar\" tradition of Sikhism where anyone, without discrimination of any kind, could get a free meal in a communal seating. The collection of revenue from Sikhs through regional appointees helped Sikhism grow.\nGuru Amar Das named his disciple and son-in-law J\u0113\u1e6dh\u0101 as the next guru, who came to be known as Guru Ram Das. The new guru faced hostilities from the sons of Guru Amar Das and therefore shifted his official base to lands identified by Guru Amar Das as Guru-ka-Chak. He moved his commune of Sikhs there and the place then was called Ramdaspur, after him. This city grew and later became Amritsar \u2013 the holiest city of Sikhism. Guru Ram Das expanded the \"manji\" organisation for clerical appointments in Sikh temples, and for revenue collections to theologically and economically support the Sikh movement.\nIn 1581, Guru Arjan, the youngest son of Guru Ram Das, became the fifth guru of the Sikhs. The choice of successor, as throughout most of the history of Sikh guru successions, led to disputes and internal divisions among the Sikhs. The elder son of Guru Ram Das named Prithi Chand is remembered in the Sikh tradition as vehemently opposing Guru Arjan, creating a faction Sikh community which the Sikhs following Guru Arjan called as \"Minaas\" (literally, \"scoundrels\").\nGuru Arjan is remembered among Sikhs for many accomplishments. He built the first Harimandir Sahib (later to become the Golden Temple). He was a poet, and he created the first edition of Sikh sacred text known as the \u0100di Granth (literally \"the first book\") and included the writings of the first five gurus and other enlightened 13 Hindu and 2 Muslim Sufi saints. In 1606, he was tortured and killed by the Mughal emperor Jahangir, for refusing to convert to Islam. His martyrdom is considered a watershed event in the history of Sikhism.\nPolitical advancement.\nAfter the martyrdom of Guru Arjan, his son Guru Hargobind at age eleven became the sixth guru of the Sikhs, and Sikhism dramatically evolved to become a political movement in addition to being religious. Guru Hargobind carried two swords, calling one spiritual and the other for temporal purpose, reflecting the concept of Miri Piri. According to the Sikh tradition, Guru Arjan asked his son Hargobind to start a military tradition to protect the Sikh people and always keep himself surrounded by armed Sikhs. The building of an armed Sikh militia began with Guru Hargobind. Guru Hargobind was soon arrested by the Mughals and kept in jail in Gwalior. It is unclear how many years he served in prison, with different texts stating it to be between 2 and 12. He married three women, built a fort to defend Ramdaspur and created a formal court called Akal Takht, now the highest Khalsa Sikh religious authority.\nIn 1644, Guru Hargobind named his grandson Har Rai as the guru. The Mughal emperor Shah Jahan attempted political means to undermine the Sikh tradition, by dividing and influencing the succession. The Mughal ruler gave land grants to Dhir Mal, a grandson of Guru Hargobind living in Kartarpur, and attempted to encourage Sikhs to recognise Dhir Mal as the rightful successor to Guru Hargobind. Dhir Mal issued statements in favour of the Mughal state and critical of his grandfather Guru Arjan. Guru Hargobind rejected Dhir Mal, the latter refused to give up the original version of the Adi Granth he had, and the Sikh community was divided.\nGuru Har Rai is famed to have met Dara Shikoh during a time Dara Shikoh and his younger brother Aurangzeb were in a bitter succession fight. Aurangzeb summoned Guru Har Rai, who refused to go and sent his elder son Ram Rai instead. The emperor found a verse in the Sikh scripture insulting to Muslims, and Ram Rai agreed it was a mistake then changed it. Ram Rai thus pleased Aurangzeb, but displeased Guru Har Rai who excommunicated his elder son. He nominated his younger son Guru Har Krishan to succeed him in 1661. Aurangzeb responded by granting Ram Rai a jagir (land grant). Ram Rai founded a town there and enjoyed Aurangzeb's patronage; the town came to be known as Dehradun, after \"Dehra\" referring to Ram Rai's shrine. Sikhs who followed Ram Rai came to be known as Ramraiya Sikhs. However, according to rough estimates, there are around 120\u2013150 million (12\u201315 crore) Guru Har Krishan became the eighth guru at the age of five, and died of smallpox before reaching the age of eight. No hymns composed by these three gurus are included in the Guru Granth Sahib.\nGuru Tegh Bahadur, the uncle of Guru Har Krishan, became guru in 1665. Tegh Bahadur resisted the forced conversions of Kashmiri Pandits and non-Muslims to Islam, and was publicly beheaded in 1675 on the orders of Mughal emperor Aurangzeb in Delhi for refusing to convert to Islam. His beheading traumatised the Sikhs. His body was cremated in Delhi, while the head was carried secretively by Sikhs and cremated in Anandpur. He was succeeded by his son, Gobind Rai, who militarised his followers by creating the Khalsa in 1699, and baptising the \"Pa\u00f1j Pi\u0101r\u0113\". From then on, he was known as Guru Gobind Singh, and Sikh identity was redefined into a political force resisting religious persecution.\nSikh confederacy and the rise of the Khalsa.\nGuru Gobind Singh inaugurated the Khalsa (the collective body of all initiated Sikhs) as the Sikh temporal authority in the year 1699. It created a community that combines its spiritual purpose and goals with political and military duties. Shortly before his death, Guru Gobind Singh proclaimed the Guru Granth Sahib to be the ultimate spiritual authority for the Sikhs.\nAfter the Guru Gobind's death, Banda Singh Bahadur became the commander-in-chief of the Khalsa. He organised the civilian rebellion and abolished or halted the Zamindari system in time he was active and gave the farmers proprietorship of their own land.\nThe Sikh empire, with its capital in Lahore, spread over almost comprising what is now northwestern Indian subcontinent. The Sikh Empire entered into a treaty with the colonial British powers, with each side recognising Sutlej River as the line of control and agreeing not to invade the other side. Ranjit Singh's most lasting legacy was the restoration and expansion of the Harmandir Sahib, most revered Gurudwara of the Sikhs, with marble and gold, from which the popular name of the \"Golden Temple\" is derived. After the death of Ranjit Singh in 1839, the Sikh Empire fell into disorder. Ranjit Singh had failed to establish a lasting structure for Sikh government or stable succession, and the Sikh Empire rapidly declined after his death. Factions divided the Sikhs, and led to Anglo-Sikh wars. The British defeated the confused and demoralised Khalsa forces, then disbanded them into destitution. The youngest son of Ranjit Singh, named Duleep Singh, ultimately succeeded, but he was arrested and exiled after the defeat of the Sikhs.\nSingh Sabha movement.\nThe Singh Sabha movement, a movement to revitalise Sikhism, also saw the resurgence of the Khalsa after their defeat in wars with the British \u2013 latterly in the Second Anglo-Sikh War \u2013 and the subsequent decline and corruption of Sikh institutions during colonial rule, and the proselytisation of other faith groups in the Punjab. It was started in the 1870s, and after a period of interfactional rivalry, united under the Tat Khalsa to reinvigorate Sikh practice and institutions.\nThe last Maharaja of the Sikh Empire, Duleep Singh, converted to Christianity in 1853, a controversial but influential event in Sikh history. Along with his conversion, and after Sikh Empire had been dissolved and the region made a part of the colonial British Empire, proselytising activities of Christians, Brahmo Samajis, Arya Samaj, Muslim Anjuman-i-Islamia and Ahmadiyah sought to convert the Sikhs in northwestern Indian subcontinent into their respective faiths. These developments launched the Singh Sabha Movement.\nThe first meeting of the movement was in the Golden Temple, Amritsar in 1873, and it was largely launched by the Sanatan Sikhs, Gianis, priests, and granthis. Shortly thereafter, Nihang Sikhs began influencing the movement, followed by a sustained campaign by the Tat Khalsa, which had quickly gained dominance by the early 1880s. The movement became a struggle between Sanatan Sikhs and Tat Khalsa in defining and interpreting Sikhism.\nSanatan Sikhs led by Khem Singh Bedi \u2013 who claimed to be a direct descendant of Guru Nanak, Avtar Singh Vahiria and others supported a more inclusive approach which considered Sikhism as a reformed tradition of Hinduism, while Tat Khalsa campaigned for an exclusive approach to the Sikh identity, disagreeing with Sanatan Sikhs and seeking to modernise Sikhism. The Sikh Sabha movement expanded in north and northwest Indian subcontinent, leading to more than 100 Singh Sabhas. By the early decades of the 20th century, the influence of Tat Khalsa increased in interpreting the nature of Sikhism and their control over the Sikh gurdwaras. The Tat Khalsa banished Brahmanical practices including the use of the \"yagna\" fire, replaced by the \"Anand Karaj\" marriage ceremony in accordance with Sikh scripture, and the idols and the images of Sikh gurus from the Golden Temple in 1905, traditions which had taken root during the administration of the \"mahants\" during the 1800s. They undertook a sustained campaign to standardise how Sikh gurdwaras looked and ran, while looking to Sikh scriptures and the early Sikh tradition to purify the Sikh identity.\nThe spiritual successors of the Singh Sabha include the Akali movement of the 1920s, as well as the modern-day Shiromani Gurdwara Parbandhak Committee (SGPC), a gurdwara administration body, and the Akali Dal political party.\nPartition of India.\nSikhs participated and contributed to the decades-long Indian independence movement in the first half of the 20th century. Ultimately when the British Empire recognised independent India, the land was partitioned into Hindu-majority India and Muslim-majority Pakistan (East and West) in 1947. According to Banga, the partition was a watershed event in Sikh history. The Sikhs had historically lived in northwestern region of Indian subcontinent on both sides of the partition line (\"Radcliffe Line\"). According to Banga and other scholars, the Sikhs had strongly opposed the Muslim League demands and saw it as \"perpetuation of Muslim domination\" and anti-Sikh policies in what just a hundred years before was a part of the Sikh Empire. As such, Sikh organisations, including the Chief Khalsa Dewan and Shiromani Akali Dal led by Master Tara Singh, condemned the Lahore Resolution and the movement to create Pakistan, viewing it as inviting possible persecution; the Sikhs largely thus strongly opposed the partition of India. During the discussions with the colonial authorities, Tara Singh emerged as an important leader who campaigned to prevent the partition of colonial India and for the recognition of Sikhs as a third community.\nWhen partition was announced, the newly created line divided the Sikh population. Along with Hindus, Sikhs suffered organised violence and riots against them in West Pakistan. As a result, Sikhs moved en masse to the Indian side, leaving behind their property and holy sites. However, the anti-Sikh violence was not one-sided. As Sikhs moved to the eastern side of the partition line, they engaged in reprisals against Muslims there, forcing them into Pakistan. Before the partition, Sikhs constituted about 15% of the population in West Punjab, the majority being Muslims (55%). The Sikhs were the economic elite in West Punjab, however. They had the largest representation in West Punjab's aristocracy, and there were nearly 700 Gurdwaras and 400 educational institutions that served the interests of the Sikhs. Prior to the partition, there were a series of disputes between the majority Muslims and minority Sikhs, such as on the matters of jhatka versus halal meat, the disputed ownership of Gurdwara Sahidganj in Lahore which Muslims sought as a mosque and Sikhs as a Gurdwara, and the insistence of the provincial Muslim government on switching from Indian Gurmukhi script to Arabic-Persian Nastaliq script in schools. During and after the Simla Conference in June 1945, headed by Lord Wavell, the Sikh leaders initially expressed their desire to be recognised as a third community, but ultimately relegated these demands and sought a United India where Sikhs, Hindus and Muslims would live together, under a Swiss-style constitution. The Muslim League rejected this approach, demanding that the entire Punjab should be granted to Pakistan. The Sikh leaders then sought the original partition instead, and the Congress Working Committee passed a resolution in support of partitioning Punjab and Bengal.\nBetween March and August 1947, a series of riots, arson, plunder of Sikh and property, assassination of Sikh leaders, and killings in Jhelum districts, Rawalpindi, Attock and other places led to Tara Singh calling the situation in Punjab a \"civil war\", while Lord Mountbatten stated \"civil war preparations were going on.\" The riots had triggered the early waves of migration in April, with some 20,000 people leaving northwest Punjab and moving to Patiala. In Rawalpindi, 40,000 people became homeless. The Sikh leaders made desperate petitions, but all religious communities were suffering in the political turmoil. Sikhs constituted only 4\u00a0million out of a total of 28\u00a0million in Punjab, and 6\u00a0million out of nearly 400\u00a0million in India; they did not constitute the majority, not even in a single district.\nWhen the partition line was formally announced in August 1947, the violence was unprecedented, with Sikhs being one of the most affected religious community both in terms of deaths, as well as property loss, injury, trauma and disruption. Sikhs and Muslims were both victims and perpetrators of retaliatory violence against each other. Estimates range between 200,000 and 2\u00a0million deaths of Sikhs, Hindus and Muslims. There were numerous rapes of and mass suicides by Sikh women, they being taken captives, their rescues and above all a mass exodus of Sikhs from newly created Pakistan into newly independent India. The partition created the \"largest foot convoy of refugees recorded in [human] history, stretching over 100 kilometer long\", states Banga, with nearly 300,000 people consisting of mostly \"distraught, suffering, injured and angry Sikhs\". Sikh and Hindu refugees from Pakistan flooded into India, Muslim refugees from India flooded into Pakistan, each into their new homeland.\nKhalistan.\nIn 1940, a few Sikhs such as the victims of Komagata Maru in Canada proposed the idea of Khalistan as a buffer state between an independent India and what would become Pakistan. These leaders, however, were largely ignored. The early 1980s witnessed some Sikh groups seeking an independent state named Khalistan carved out from India and Pakistan. The Golden Temple and Akal Takht were occupied by various militant groups in 1982. These included the Dharam Yudh Morcha led by Jarnail Singh Bhindranwale, the Babbar Khalsa, the AISSF and the National Council of Khalistan. Between 1982 and 1983, there were Anandpur Resolution demand-related terrorist attacks against civilians in parts of India. By late 1983, the Bhindranwale led group had begun to build bunkers and observations posts in and around the Golden Temple, with militants involved in weapons training. In June 1984, the then Prime Minister of India Indira Gandhi ordered Indian Army to begin Operation Blue Star against the militants. The fierce engagement took place in the precincts of Darbar Sahib and resulted in many deaths, including Bhindranwale. It also resulted in the destruction of the Sikh Reference Library, which was considered a national treasure that contained over a thousand rare manuscripts and the Akal Takht. Numerous soldiers, civilians and militants died in the cross fire. Within days of the Operation Bluestar, some 2,000 Sikh soldiers in India mutinied and attempted to reach Amritsar to liberate the Golden Temple. Within six months, on 31 October 1984, Indira Gandhi's Sikh bodyguards Satwant and Beant Singh assassinated her. The assassination triggered the 1984 anti-Sikh riots. According to Donald Horowitz, while anti-Sikh riots led to much damage and deaths, many serious provocations by militants also failed to trigger ethnic violence in many cases throughout the 1980s. The Sikhs and their neighbors, for most part, ignored attempts to provoke riots and communal strife.\nSikh people.\nEstimates as of 2019[ [update]] state that Sikhism has some 25\u201330\u00a0million followers worldwide. A 2020 estimate by Charles Preston gives a figure of 29,254,000 of Sikhs worldwide. According to Pew Research, a think tank and research group based in Washington, DC, over 9-in-10 Sikhs are in India, but there are also sizable Sikh communities in the United States, the United Kingdom, and Canada. Within India, the Sikh population is found in every state and union territory, but it is predominantly found in the northwestern and northern states. Only in the state of Punjab do Sikhs constitute a majority (58% of the total, per 2011 census). In addition to Punjab, the states and union territories of India where Sikhs constitute more than 1.5% of its population are Chandigarh, Haryana, Delhi, Uttarakhand, and Jammu and Kashmir, all of which are in the northern half of India.\nCanada is home to the largest proportion of Sikhs, as a ratio of the country's total population, in the world, at 2.1%. Within Canada, Sikhs form 5.9% of the total population in the western province of British Columbia, representing the third-largest Sikh proportion amongst all global administrative divisions, behind only Punjab and Chandigarh in India. British Columbia, Manitoba, and Yukon hold the distinction of being three of the only four administrative divisions in the world with Sikhism as the second-most followed religion among the population.\nPrior to the 1947 partition of British India, millions of Sikhs lived in what later became Pakistan. Likewise, Sikhism was founded in what is now Pakistan, and some of the gurus were born near Lahore and in other parts of Pakistan. During the partition, Sikhs and Hindus left the newly created Muslim-majority Pakistan and mostly moved to Hindu-majority India\u2014with some moving to Muslim-majority Afghanistan\u2014while numerous Muslims in India moved to Pakistan. According to 2017 news reports, only about 20,000 Sikhs remain in Pakistan, and their population is dwindling (0.01% of the country's estimated 200\u00a0million population).\nSikh sects.\nSikh sects are sub-traditions within Sikhism that believe in an alternate lineage of gurus, or have a different interpretation of the Sikh scriptures, or believe in following a living guru, or hold other concepts that differ from the orthodox Khalsa Sikhs. The major historic sects of Sikhism have included Udasi, Nirmala, Nanakpanthi, Khalsa, Sahajdhari, Namdhari Kuka, Nirankari, and Sarvaria.\nSikhs originally had only five orders, or sampradas (not to be confused as deviant sects). These include:\nNihangs \u2013 the Sikh Panth's warriors or armed troops. There are two main groups within this order: Buddha Dal, or the army of veterans, and Tarna Dal, or the army of youth. There are other smaller sub-orders connected to these two. The president of Buddha Dal, previously always served as the president of the Akaal Takht, which has jurisdiction over all things pertaining to the Akaali Nihang order. \nNirmalas \u2013 scholars. Composed texts as well as traditionally studying a wide range of Indian and some non-Indian literature. They converse with other Dharmik pathways as well. The tenth guru also institutionalised them. Bhai Daya Singh Ji Samparda and Bhai Dharam Singh Ji Samparda, two of the Panj Pyare or cherished ones of the tenth guru, founded two Nirmala orders.\nUdasis \u2013 an ascetic group that historically looked after Gurdwaras and carried out missionary activity. Although not promoting it to others, certain of their practices depart from the majority of Sikh beliefs. Baba Sri Chand, the eldest Sahibzada (son) of the first guru, Guru Nanak Dev, founded the order. Their Gurdev is Baba Sri Chand.\nSevapanthis \u2013 philanthropists who engage in charitable work/seva, or selfless service, without expecting payment. They also work on academic projects. Bhai Kahnaiya, a Sikh of the ninth and tenth guru, served as the first head of the order and is renowned for his wartime medical assistance to wounded enemy soldiers. Very few of them exist today. The environment in which they lived and with which they interacted was a predominantly Muslim one.\nGyaaniyan Samparda \u2013 the university of Sikhi, whilst technically not an order, it essentially serves as one. Made up from individuals belonging to all of the above sects. Many branches within this order.\nThe early Sikh sects were Udasis and Minas founded by Baba Sri Chand \u2013 the elder son of Guru Nanak, and Prithi Chand \u2013 the elder son of Guru Ram Das respectively, in parallel to the official succession of the Sikh gurus. Later on Ramraiya sect, founded by Ram Rai, grew in Dehradun with the patronage of Aurangzeb. Many splintered Sikh communities formed during the Mughal Empire era. Some of these sects were financially and administratively supported by the Mughal rulers in the hopes of gaining a more favorable and compliant citizenry.\nAfter the collapse of Mughal Empire, and particularly during the rule of Ranjit Singh, Udasi Sikhs protected Sikh shrines, preserved the Sikh scripture and rebuilt those that were desecrated or destroyed during the Muslim\u2013Sikh wars. However, Udasi Sikhs kept idols and images inside these Sikh temples. In the 19th century, Namdharis and Nirankaris sects were formed in Sikhism, seeking to reform and return to what each believed was the pure form of Sikhism.\nAll these sects differ from Khalsa orthodox Sikhs in their beliefs and practices, such as continuing to solemnise their weddings around fire and being strictly vegetarian. Many accept the concept of living gurus such as Guru Baba Dyal Singh. The Nirankari sect, though unorthodox, was influential in shaping the views of Tat Khalsa and the contemporary-era Sikh beliefs and practices. Another significant Sikh sect of the 19th century was the Radhasoami movement in Punjab led by Baba Shiv Dyal. Other contemporary era Sikhs sects include the 3HO, formed in 1971, which exists outside India, particularly in North America and Europe.\nSikh castes.\nAccording to Surinder Jodhka, the state of Punjab with a Sikh majority has the \"largest proportion of scheduled caste population in India\". Although decried by Sikhism, Sikhs have practiced a caste system. The system, along with untouchability, has been more common in rural parts of Punjab. The landowning dominant Sikh castes, states Jodhka, \"have not shed all their prejudices against the lower castes or dalits; while dalits would be allowed entry into the village gurdwaras they would not be permitted to cook or serve langar.\" The Sikh dalits of Punjab have tried to build their own gurdwara, other local level institutions and sought better material circumstances and dignity. According to Jodhka, due to economic mobility in contemporary Punjab, castes no longer mean an inherited occupation, nor are work relations tied to a single location.\nIn 1953, the government of India acceded to the demands of the Sikh leader, Master Tara Singh, to include Sikh Dalit castes in the list of scheduled castes. In the Shiromani Gurdwara Prabandhak Committee, 20 of the 140 seats are reserved for low-caste Sikhs.\nOver 60% of Sikhs belong to the Jat caste, which is an agrarian caste. Despite being very small in numbers, the mercantile Khatri and Arora castes wield considerable influence within the Sikh community. Other common Sikh castes include Sainis, Ramgarhias (artisans), Brahmins, Ahluwalias (formerly brewers), Rajputs, Rai Sikh (Rai), Kambojs (rural caste), Labanas, Kumhars and the two Dalit castes, known in Sikh terminology as the Mazhabis (the Chuhras) and the Ravidasias (the Chamars).\nSikh diaspora.\nWorldwide, there are 30\u00a0million Sikhs, which makes up 0.4% of the world's population. Approximately 75% of Sikhs live in Punjab, where they constitute 57.7% of the state's population. Large communities of Sikhs migrate to the neighboring states such as Indian State of Haryana which is home to the second largest Sikh population in India with 1.1\u00a0million Sikhs as per 2001 census, and large immigrant communities of Sikhs can be found across India. However, Sikhs only comprise about 1.7% of the Indian population.\nMost Sikhs outside India live in the core Anglosphere, with 771,790 in Canada (2.1% Sikh), 524,140 in the United Kingdom (0.9% Sikh), 280,000 in the United States (0.1% Sikh), 210,400 in Australia (0.8% Sikh), and 40,908 in New Zealand (0.9% Sikh). While these communities are over 125 years old, most Sikhs in the West are first, second, or third-generation immigrants. As of[ [update]] the 2021 Canadian Census, more than half of Canada's Sikhs can be found in one of four cities: Brampton (163,260), Surrey (154,415), Calgary (49,465), and Abbotsford (38,395).\nSikhs also migrated to East Africa, the Middle East, and Southeast Asia. These communities developed as Sikhs migrated out of Punjab to fill in gaps in imperial labour markets.\nProhibitions in Sikhism.\nFour major transgressions:\nOther mentioned practices to be avoided, as per the Sikh Rehat Maryada:\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27966", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=27966", "title": "Saussure, Ferdinand de", "text": ""}
{"id": "27968", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=27968", "title": "Securing a climb", "text": ""}
{"id": "27969", "revid": "7852030", "url": "https://en.wikipedia.org/wiki?curid=27969", "title": "Structural isomer", "text": "Chemical compounds with the same atoms but arranged and connected differently\nIn chemistry, a structural isomer (or constitutional isomer in the IUPAC nomenclature) of a compound is a compound that contains the same number and type of atoms, but with a different connectivity (i.e. arrangement of bonds) between them. The term metamer was formerly used for the same concept.\nFor example, butanol , methyl propyl ether , and diethyl ether have the same molecular formula but are three distinct structural isomers.\nThe concept applies also to polyatomic ions with the same total charge. A classical example is the cyanate ion and the fulminate ion . It is also extended to ionic compounds, so that (for example) ammonium cyanate and urea are considered structural isomers, and so are methylammonium formate and ammonium acetate .\nStructural isomerism is the most radical type of isomerism. It is opposed to stereoisomerism, in which the atoms and bonding scheme are the same, but only the relative spatial arrangement of the atoms is different. Examples of the latter are the enantiomers, whose molecules are mirror images of each other, and the \"cis\" and \"trans\" versions of 2-butene.\nAmong the structural isomers, one can distinguish several classes including skeletal isomers, positional isomers (or regioisomers), functional isomers, tautomers, and structural isotopomers.\nSkeletal isomerism.\nA skeletal isomer of a compound is a structural isomer that differs from it in the atoms and bonds that are considered to comprise the \"skeleton\" of the molecule. For organic compounds, such as alkanes, that usually means the carbon atoms and the bonds between them.\nFor example, there are three skeletal isomers of pentane: \"n\"-pentane (often called simply \"pentane\"), isopentane (2-methylbutane) and neopentane (dimethylpropane).\nIf the skeleton is acyclic, as in the above example, one may use the term chain isomerism.\nPosition isomerism (regioisomerism).\nPosition isomers (also positional isomers or regioisomers) are structural isomers that can be viewed as differing only on the position of a functional group, substituent, or some other feature on the same \"parent\" structure.\nFor example, replacing one of the 12 hydrogen atoms \u2013H by a hydroxyl group \u2013OH on the \"n\"-pentane parent molecule can give any of three different position isomers:\nAnother example of regioisomers are \u03b1-linolenic and \u03b3-linolenic acids, both octadecatrienoic acids, each of which has three double bonds, but on different positions along the chain.\nFunctional isomerism.\nFunctional isomers are structural isomers which have different functional groups, resulting in significantly different chemical and physical properties.\nAn example is the pair propanal H3C\u2013CH2\u2013C(=O)-H and acetone H3C\u2013C(=O)\u2013CH3: the first has a \u2013C(=O)H functional group, which makes it an aldehyde, whereas the second has a C\u2013C(=O)\u2013C group, that makes it a ketone.\nAnother example is the pair ethanol H3C\u2013CH2\u2013OH (an alcohol) and dimethyl ether H3C\u2013O\u2013CH2H (an ether). In contrast, 1-propanol and 2-propanol are structural isomers, but not functional isomers, since they have the same significant functional group (the hydroxyl \u2013OH) and are both alcohols.\nBesides the different chemistry, functional isomers typically have very different infrared spectra. The infrared spectrum is largely determined by the vibration modes of the molecule, and functional groups like hydroxyl and esters have very different vibration modes. Thus 1-propanol and 2-propanol have relatively similar infrared spectra because of the hydroxyl group, which are fairly different from that of methyl ethyl ether.\nStructural isotopomers.\nIn chemistry, one usually ignores distinctions between isotopes of the same element. However, in some situations (for instance in Raman, NMR, or microwave spectroscopy) one may treat different isotopes of the same element as different elements. In the second case, two molecules with the same number of atoms of each isotope but distinct bonding schemes are said to be structural isotopomers.\nThus, for example, ethene would have no structural isomers under the first interpretation; but replacing two of the hydrogen atoms (1H) by deuterium atoms (2H) may yield any of two structural isotopomers (1,1-dideuteroethene and 1,2-dideuteroethene), if both carbon atoms are the same isotope. If, in addition, the two carbons are different isotopes (say, 12C and 13C), there would be three distinct structural isotopomers, since 1-13C-1,1-dideuteroethene would be different from 1-13C-2,2-dideuteroethene. And, in both cases, the 1,2-dideutero structural isotopomer would occur as two stereoisotopomers, \"cis\" and \"trans\".\nStructural equivalence and symmetry.\nStructural equivalence.\nTwo molecules (including polyatomic ions) A and B have the same structure if each atom of A can be paired with an atom of B of the same element, in a one-to-one way, so that for every bond in A there is a bond in B, of the same type, between corresponding atoms; and vice versa. This requirement applies also to complex bonds that involve three or more atoms, such as the delocalized bonding in the benzene molecule and other aromatic compounds.\nDepending on the context, one may require that each atom be paired with an atom of the same isotope, not just of the same element.\nTwo molecules then can be said to be structural isomers (or, if isotopes matter, structural isotopomers) if they have the same molecular formula but do not have the same structure.\nStructural symmetry and equivalent atoms.\nStructural symmetry of a molecule can be defined mathematically as a permutation of the atoms that exchanges at least two atoms but does not change the molecule's structure. Two atoms then can be said to be structurally equivalent if there is a structural symmetry that takes one to the other.\nThus, for example, all four hydrogen atoms of methane are structurally equivalent, because any permutation of them will preserve all the bonds of the molecule.\nLikewise, all six hydrogens of ethane (C2H6) are structurally equivalent to each other, as are the two carbons; because any hydrogen can be switched with any other, either by a permutation that swaps just those two atoms, or by a permutation that swaps the two carbons and each hydrogen in one methyl group with a different hydrogen on the other methyl. Either operation preserves the structure of the molecule. That is the case also for the hydrogen atoms in cyclopentane, allene, 2-butyne, hexamethylenetetramine, prismane, cubane, dodecahedrane, etc.\nOn the other hand, the hydrogen atoms of propane are not all structurally equivalent. The six hydrogens attached to the first and third carbons are equivalent, as in ethane, and the two attached to the middle carbon are equivalent to each other; but there is no equivalence between these two equivalence classes.\nSymmetry and positional isomerism.\nStructural equivalences between atoms of a parent molecule reduce the number of positional isomers that can be obtained by replacing those atoms for a different element or group. Thus, for example, the structural equivalence between the six hydrogens of ethane C2H6 means that there is just one structural isomer of ethanol C2H5OH, not 6. The eight hydrogens of propane C3H8 are partitioned into two structural equivalence classes (the six on the methyl groups, and the two on the central carbon); therefore there are only two positional isomers of propanol (1-propanol and 2-propanol). Likewise there are only two positional isomers of butanol, and three of pentanol or hexanol.\nSymmetry breaking by substitutions.\nOnce a substitution is made on a parent molecule, its structural symmetry is usually reduced, meaning that atoms that were formerly equivalent may no longer be so. Thus substitution of two or more equivalent atoms by the same element may generate more than one positional isomer.\nThe classical example is the derivatives of benzene. Its six hydrogens are all structurally equivalent, and so are the six carbons; because the structure is not changed if the atoms are permuted in ways that correspond to flipping the molecule over or rotating it by multiples of 60 degrees. Therefore, replacing any hydrogen by chlorine yields only one chlorobenzene. However, with that replacement, the atom permutations that moved that hydrogen are no longer valid. Only one permutation remains, that corresponds to flipping the molecule over while keeping the chlorine fixed. The five remaining hydrogens then fall into three different equivalence classes: the one opposite to the chlorine is a class by itself (called the \"para\" position), the two closest to the chlorine form another class (\"ortho\"), and the remaining two are the third class (\"meta\"). Thus a second substitution of hydrogen by chlorine can yield three positional isomers: 1,2- or \"ortho\"-, 1,3- or \"meta\"-, and 1,4- or \"para\"-dichlorobenzene.\nFor the same reason, there is only one phenol (hydroxybenzene), but three benzenediols; and one toluene (methylbenzene), but three toluols, and three xylenes.\nOn the other hand, the second replacement (by the same substituent) may preserve or even increase the symmetry of the molecule, and thus may preserve or reduce the number of equivalence classes for the next replacement. Thus, the four remaining hydrogens in \"meta\"-dichlorobenzene still fall into three classes, while those of \"ortho\"- fall into two, and those of \"para\"- are all equivalent again. Still, some of these 3 + 2 + 1 = 6 substitutions end up yielding the same structure, so there are only three structurally distinct trichlorobenzenes: 1,2,3-, 1,2,4-, and 1,3,5-.\nIf the substituents at each step are different, there will usually be more structural isomers. Xylenol, which is benzene with one hydroxyl substituent and two methyl substituents, has a total of 6 isomers:\nIsomer enumeration and counting.\nEnumerating or counting structural isomers in general is a difficult problem, since one must take into account several bond types (including delocalized ones), cyclic structures, and structures that cannot possibly be realized due to valence or geometric constraints, and non-separable tautomers.\nFor example, there are nine structural isomers with molecular formula C3H6O having different bond connectivities. Seven of them are air-stable at room temperature, and these are given in the table below.\nTwo structural isomers are the enol tautomers of the carbonyl isomers (propionaldehyde and acetone), but these are not stable."}
{"id": "27970", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=27970", "title": "Stereoisomerism", "text": "When molecules have the same atoms and bond structure but differ in 3D orientation\nIn stereochemistry, stereoisomerism, or spatial isomerism, is a form of isomerism in which molecules have the same molecular formula and sequence of bonded atoms (constitution), but differ in the three-dimensional orientations of their atoms in space. This contrasts with structural isomers, which share the same molecular formula, but the bond connections or their order differs. By definition, molecules that are stereoisomers of each other represent the same structural isomer.\nEnantiomers.\nEnantiomers, also known as optical isomers, are two stereoisomers that are related to each other by a reflection: they are mirror images of each other that are non-superposable. Human hands are a macroscopic analog of this. Every stereogenic center in one has the opposite configuration in the other. Two compounds that are enantiomers of each other have the same physical properties, except for the direction in which they rotate polarized light and how they interact with different enantiomers of other compounds. As a result, different enantiomers of a compound may have substantially different biological effects. Pure enantiomers also exhibit the phenomenon of optical activity and can be separated only with the use of a chiral agent. In nature, only one enantiomer of most chiral biological compounds, such as amino acids (except glycine, which is achiral), is present. Enantiomers differ by the direction they rotate polarized light: the amount of a chiral compound's optical rotation in the (+) direction is equal to the amount of its enantiomer's rotation in the (\u2013) direction. \nDiastereomers.\nDiastereomers are stereoisomers not related through a reflection operation. They are not mirror images of each other. These include meso compounds, \"cis\"\u2013\"trans\" isomers, E\u2013Z isomers, and non-enantiomeric optical isomers. Diastereomers seldom have the same physical properties. In the example shown below, the meso form of tartaric acid forms a diastereomeric pair with both levo- and dextro-tartaric acids, which form an enantiomeric pair.\nThe D- and L- labeling of the isomers above is not the same as the \"d\"- and \"l\"- labeling more commonly seen, explaining why these may appear reversed to those familiar with only the latter naming convention. \nA Fischer projection can be used to differentiate between L- and D-molecules (see Chirality (chemistry)). For instance, by definition, in a Fischer projection the penultimate carbon of D-sugars are depicted with hydrogen on the left and hydroxyl on the right. L-sugars will be shown with the hydrogen on the right and the hydroxyl on the left. \nThe other refers to optical rotation, when looking at the source of light, the rotation of the plane of polarization may be either to the right (dextrorotary \u2014 d-rotary, represented by (+), clockwise), or to the left (levorotary \u2014 l-rotary, represented by (\u2212), counter-clockwise) depending on which stereoisomer is dominant. For instance, sucrose and camphor are d-rotary whereas cholesterol is l-rotary. \nCis\u2013trans and E\u2013Z isomerism.\nStereoisomerism about double bonds arises because rotation about the double bond is restricted, keeping the substituents fixed relative to each other. If the two substituents on at least one end of a double bond are the same, then there is no stereoisomer and the double bond is not a stereocenter, e.g. propene, CH3CH=CH2 where the two substituents at one end are both H.\nTraditionally, double bond stereochemistry was described as either \"cis\" (Latin, on this side) or \"trans\" (Latin, across), in reference to the relative position of substituents on either side of a double bond. A simple example of \"cis\"\u2013\"trans\" isomerism is the 1,2-disubstituted ethenes, like the dichloroethene (C2H2Cl2) isomers shown below.\nMolecule I is \"cis\"-1,2-dichloroethene and molecule II is \"trans\"-1,2-dichloroethene. Due to occasional ambiguity, IUPAC adopted a more rigorous system wherein the substituents at each end of the double bond are assigned priority based on their atomic number. If the high-priority substituents are on the same side of the bond, it is assigned Z (Ger. \"zusammen\", together). If they are on opposite sides, it is E (Ger. \"entgegen\", opposite). Since chlorine has a larger atomic number than hydrogen, it is the highest-priority group. Using this notation to name the above pictured molecules, molecule I is (\"Z\")-1,2-dichloroethene and molecule II is (\"E\")-1,2-dichloroethene. It is not the case that Z and \"cis\", or E and \"trans\", are always interchangeable. Consider the following fluoromethylpentene:\nThe proper name for this molecule is either \"trans\"-2-fluoro-3-methylpent-2-ene because the alkyl groups that form the backbone chain (i.e., methyl and ethyl) reside across the double bond from each other, or (\"Z\")-2-fluoro-3-methylpent-2-ene because the highest-priority groups on each side of the double bond are on the same side of the double bond. Fluoro is the highest-priority group on the left side of the double bond, and ethyl is the highest-priority group on the right side of the molecule.\nThe terms \"cis\" and \"trans\" are also used to describe the relative position of two substituents on a ring; \"cis\" if on the same side, otherwise \"trans\".\nConformers.\nConformational isomerism is a form of isomerism that describes the phenomenon of molecules with the same structural formula but with different shapes due to rotations about one or more bonds. Different conformations can have different energies, can usually interconvert, and are very rarely isolatable. For example, there exists a variety of Cyclohexane conformations (which cyclohexane is an essential intermediate for the synthesis of nylon\u20136,6) including a \"chair conformation\" where four of the carbon atoms form the \"seat\" of the chair, one carbon atom is the \"back\" of the chair, and one carbon atom is the \"foot rest\"; and a \"boat conformation\", the boat conformation represents the energy maximum on a conformational itinerary between the two equivalent chair forms; however, it does not represent the transition state for this process, because there are lower-energy pathways. The conformational inversion of substituted cyclohexanes is a very rapid process at room temperature, with a half-life of 0.00001 seconds.\nThere are some molecules that can be isolated in several conformations, due to the large energy barriers between different conformations. 2,2',6,6'-Tetrasubstituted biphenyls can fit into this latter category.\nAnomers.\nAnomerism is an identity for single bonded ring structures where \"cis\" or \"Z\" and \"trans\" or \"E\" (geometric isomerism) needs to name the substitutions on a carbon atom that also displays the identity of chirality; so anomers have carbon atoms that have geometric isomerism and optical isomerism (enantiomerism) on one or more of the carbons of the ring. Anomers are named \"alpha\" or \"axial\" and \"beta\" or \"equatorial\" when substituting a cyclic ring structure that has single bonds between the carbon atoms of the ring for example, a hydroxyl group, a methyl hydroxyl group, a methoxy group or another pyranose or furanose group which are typical single bond substitutions but not limited to these. Axial geometric isomerism will be perpendicular (90 degrees) to a reference plane and equatorial will be 120 degrees away from the axial bond or deviate 30 degrees from the reference plane.\nAtropisomers.\nAtropisomers are stereoisomers resulting from hindered rotation about single bonds where the steric strain barrier to rotation is high enough to allow for the isolation of the conformers.\nLe Bel-van't Hoff rule.\nLe Bel-van't Hoff rule states that for a structure with \"n\" asymmetric carbon atoms, there is a maximum of 2\"n\" different stereoisomers possible. As an example, -glucose is an aldohexose and has the formula C6H12O6. Four of its six carbon atoms are stereogenic, which means -glucose is one of 24=16 possible stereoisomers.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27971", "revid": "44889062", "url": "https://en.wikipedia.org/wiki?curid=27971", "title": "Subaru Impreza WRX", "text": ""}
{"id": "27972", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=27972", "title": "Sylvia Sayer", "text": "British environmental conservator\nSylvia Rosalind Pleadwell Sayer, Lady Sayer (6 March 1904 \u2013 4 January 2000), was a passionate conservationist and environmental campaigner on behalf of Dartmoor, an area of mostly granite moorland in Devon in the south-west of England. She was chairman of the Dartmoor Preservation Association from 1951 to 1973, and remained deeply involved with the organisation until her death.\nBiography.\nSayer's grandfather was Robert Burnard (1848\u20131920), who with Sabine Baring-Gould performed the first scientific excavations of ancient monuments on Dartmoor, including Grimspound; and who was one of the founding members in 1883 of the Dartmoor Preservation Association. He leased Huccaby House, on the West Dart River, near Hexworthy, from the Duchy of Cornwall and Sayer used to visit as a child.\nHer mother was Olive Louise Munday (born Burnard; c. 1873\u20131960), Robert Burnard's eldest daughter. Her father was the Principal Medical Officer at the Naval Hospital School in Greenwich. She attended Princess Helena College in Ealing, and then the Central School of Art in London. In 1925 she married Guy Sayer, who was a midshipman in the Royal Navy, and they spent some time in China. Three years later they bought Old Middle Cator, a dilapidated Dartmoor longhouse about two miles west of the village of Widecombe-in-the-Moor in Dartmoor. They had twin sons, Geoffrey and Oliver, born in 1930, and until World War Two the family travelled widely to meet the needs of Guy's navy career. After VE Day, Guy was posted to the Far East and Sylvia settled at Cator and became interested in local politics, at first as a parish councillor for Widecombe, then as a Rural District Councillor and a member of the Dartmoor Sub-Committee of Devon County Council.\nLady Sayer acquired her title in 1959 when her husband was knighted on his retirement as the vice-admiral commanding the Reserve Fleet. After his retirement he spent much of his time helping his wife with her conservation work. She was chairman of the Dartmoor Preservation Association between 1951 and 1973, and after that, as its patron, she continued to attend virtually every meeting of its executive committee until 1999.\nShe lived at Cator almost until her death, moving to a nursing home in Chagford two weeks before. On 10 February 2000 a service of celebration for her life was held in the parish church of Widecombe-in-the-Moor. It was attended by over 300 people, including representatives of the Dartmoor National Park Authority, the Association of National Park Authorities, the Council for National Parks, the Campaign to Protect Rural England (CPRE), the Ramblers' Association, and the Duchy of Cornwall.\nConservation work.\nSayer was described in \"The Times\" newspaper in 1971 as \"a militant conservationist, who is a full-time thorn in the sides of those authorities and others who want to flood, fence, dig up, knock down and otherwise damage the Dartmoor national park.\" Crispin Gill wrote about her in his introduction to \"Dartmoor \u2013 A New Study\" published in 1970 as having \"roused the conscience of a [vast] number of people\" and he described her as an indefatigable worker with an enormous knowledge; he also referred to Henry Slesser's description of her as \"the shield of the moor\".\nShe regularly wrote letters to newspapers, both local and national, about matters related to Dartmoor. In her first published letter to \"The Times\", in 1948, she expressed concerns about local authorities (specifically Devon County Council) seeking to subvert the implementation of Arthur Hobhouse's recommendations for the creation of national parks by demanding that they retain their own planning powers. She noted that local authorities had been unable to control development by Government departments in areas such as Dartmoor, referring to the 32,800 acres held by the Admiralty and War Department and the 3,763 acres that had been taken by the Forestry Commission. She also referred to Dartmoor's uniqueness in that most of it was owned by the Duchy of Cornwall which, as a department of the Crown, could basically do what it liked with its land. She urged that control of the soon-to-be-formed National Parks should be at the highest possible level within the Government so there would be a chance of exercising control over the Duchy and other Government departments.\nThe National Parks and Access to the Countryside Act 1949 created the National Parks Commission whose first chairman was Sir Patrick Duff. Ten National Parks were created in the 1950s under this Act \u2013 Dartmoor National Park was the fourth to be created, in October 1951. It was administered by Dartmoor National Park Authority which was a special committee of Devon County Council and subsidiary to the County Planning Committee which could veto its recommendations. Sayer was a member of the committee from its formation, but she resigned in 1957 in protest at its failure to protect the moor as she would wish.\nTV mast.\nAs chairman of the Dartmoor Preservation Association (DPA), Sayer was heavily involved in all that organisation's fights for what it saw as conservation issues. The first of these was against the proposed installation of a television transmitting mast on North Hessary Tor in the centre of the moor. When the Dartmoor Standing Committee voted in June 1952 to approve the application, Sayer complained that it had relied on the casting vote of the chairman in the absence of three members who would have voted against.\nContinued objection from Sayer and the DPA, and the CPRE, led to a public enquiry which took place in September 1953. Sir Patrick Duff, the National Parks Commission chairman, was well briefed by Sayer and at the enquiry his case was mainly based on the damage the mast would do to the scenery of the moor. Although congratulatory letters were passed between all the main objectors after the enquiry, the ministry granted the planning application in January 1954, though with some minor provisos to minimise the impact. Although Duff had failed to stop the installation of the mast, Sayer rewarded him for his efforts with a painting of North Hessary Tor saying it was \"almost the last representation of that landscape that can be made while it is still unshadowed and unspoiled\".\nThe military.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n...determined and articulate, Sylvia was single-minded in her pursuit of the things she believed in. Never a compromiser, she was unimpressed by the size and power of her adversaries, whom she would fight to a standstill when the occasion demanded. Many respected her as a foe...\nAddress by Geoffrey Sayer, her son, at the thanksgiving service for her life, 10 February 2000.\nFrom 1955 onwards Sayer kept up a correspondence about the military roads that lead across the northern moor from Okehampton Camp.\nIn 1966 she and her husband deliberately interrupted live-firing exercises on Dartmoor's Royal Marines firing range to inspect and photograph any damage done to a prehistoric stone row. In February 1967 she disrupted a large-scale mock battle at Ringmoor Down that involved low-flying helicopters. She told the press that she did this to exercise her rights and to ensure that no damage was caused to ancient monuments, pointing out that the public could not be excluded from the area involved because it was not a firing area, and that sheep and ponies had been frightened away as the helicopters converged \u2013 \"it could have been pony trekkers and hikers and might have resulted in a serious accident\", she said.\nReservoirs.\nIn the late 1960s and early 1970s she was involved, as DPA chairman, with the disputes over the proposed construction of two new reservoirs on Dartmoor. The largest, which was to supply Plymouth, was known as \"Swincombe\" after the small River Swincombe that flows through Foxtor Mires, the proposed site of the reservoir. The proposal was eventually rejected in December 1970 at the Bill's committee stage, and a reservoir known as Roadford Lake was built west of the moor near the village of Broadwoodwidger instead.\nHowever, the Meldon Reservoir on the north-west edge of the moor was passed, despite claims that the water would be poisoned by arsenic and lead because of the presence of three disused metalliferous mines and their spoil heaps in the area to be flooded. The dam was built in 1972, and in that year Sayer wrote a 62-page booklet entitled \"The Meldon Story\" that was published by the DPA. After expounding at length all the arguments made against building a dam at Meldon and in favour of an alternative site at Gorhuish, and the responses from the establishment, it ended with this statement:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The effect on the younger generation of the methods of present-day misgovernment is alarming but inevitable. When they utterly despair of a fair hearing or a just decision, they tend to stop talking and reach for the nearest brick. And who can blame them? Certainly we do not. We well know that the provocation to lawlessness often starts in Whitehall.\nChina clay workings.\nFollowing these efforts, she concentrated on the two companies involved in the extraction of china clay in the south west of the moor. They had permission dating from 1951 to expand their pits and tips. Shaugh Moor is an adjacent area that is rich in ancient monuments and it was there that the companies planned to tip the vast quantities of spoil that is generated from clay extraction. At the time the area became known as \"Area Y\", from an explanatory diagram that Sayer had drawn. The activism culminated in an adjournment debate in the House of Commons in which Janet Fookes, a Plymouth MP, argued against irreparably damaging the ancient landscape. In June 1978, the two companies agreed to share their waste tips, as Sayer had recommended, saving Shaugh Moor.\nOkehampton bypass.\nIn the 1970s there were plans to create a bypass for the A30 road around the town of Okehampton on the northern edge of Dartmoor. Two alternative routes were proposed: a northern one through agricultural land, or a southern one which would encroach on the National Park. After a public enquiry was held in 1979 and 1980 arguments continued for over five years with Sayer vigorously opposing the route through the moor. The matter was finally settled when the southern route was approved in December 1985 by the House of Lords. After the decision had been made, Sayer wrote a letter to Peter Bottomley, the then Minister of Transport that included the following extract:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The end of the Lords debate, when the vote was about to be taken and the half-empty Chamber suddenly filled up with well-wined and dined Lordships totally ignorant of the facts but jovially resolved to vote as directed, was only too typical of the whole disastrous charade...\nOther.\nShe opposed proposals to build a new Dartmoor Prison at Princetown in the centre of the moor in 1959. In the 1960s she complained about off-road car parking, and the poor treatment of Dartmoor ponies by those who only keep them for the subsidies they can obtain.\nIn 1983 she refused an invitation from the Prince of Wales to attend the launch of the Duchy of Cornwall's management plan for Dartmoor, since it allowed for a continuance of military usage. She was also one of a deputation who met the Prince in 1990 to explain to him why they thought he should not renew the military licences for a further term. However, the licences were renewed that year until 2011.\nLegacy.\nThe DPA set up a Lady Sayer Land Purchase Fund after her retirement as chairman in 1973. It was used in 1984 to purchase 32 acres of land at Sharpitor, near Burrator Reservoir, in celebration of the successful fight against the Swincombe reservoir. As of March 2013 the fund held about \u00a329,400.\nOn the centenary of her birth in 2004 John Bainbridge, the then chief executive of the DPA, revealed plans to memorialise Sayer by organising annual walks to some part of Dartmoor that she had saved, and also by holding an annual Sylvia Sayer lecture given by a prominent speaker.\nWriting in 2009 in \"Dartmoor \u2013 A Statement of its Time\", one of the New Naturalist series of books, Professor Ian Mercer (former Chief Officer of the Dartmoor National Park Authority), said of Sayer:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;She was the scourge of farmers, foresters, quarrymen, civil [...] engineers, of generals and even of the National Park Authority when its professed pragmatism appeared to her, in the sort of words that she would use, 'snivelling cowardice'. [...] No modern history of Dartmoor would be valid without reference to her, but quite naturally reactions to her actions and statements divided the world of Dartmoor stakeholders for 50 years.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27974", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=27974", "title": "Star Formation", "text": ""}
{"id": "27977", "revid": "49248264", "url": "https://en.wikipedia.org/wiki?curid=27977", "title": "South Park", "text": "American animated sitcom\nSouth Park is an American animated sitcom created by Trey Parker and Matt Stone for Comedy Central. The series revolves around four boys \u2014 Stan Marsh, Kyle Broflovski, Eric Cartman, and Kenny McCormick \u2014 and their adventures in and around the titular Colorado town. \"South Park\" also features many recurring characters. The series became infamous for its profanity and dark, surreal humor that satirizes a large range of subject matter.\nParker and Stone developed \"South Park\" from two animated short films, both titled \"The Spirit of Christmas\", released in 1992 and 1995. The second short became one of the first viral Internet videos, leading to the series' production. The pilot episode was produced using cutout animation; the remainder of the series uses computer animation based on the cutout technique. Since the fourth season, episodes have generally been written and produced during the week preceding their broadcast, with Parker serving as the lead writer and director.\nSince its debut on August 13, 1997, episodes of \"South Park\" have been broadcast. It debuted with great success, consistently earning the highest ratings of any basic cable program. Subsequent ratings have varied, but it remains one of Comedy Central's longest-running programs. In August 2021, \"South Park\" was renewed through 2027, and a series of television specials was announced for Paramount+, the first two of which were released later that year. In October 2019, it was announced that WarnerMedia had acquired exclusive streaming rights to \"South Park\" starting in June 2020 for HBO Max. After the HBO Max deal expired in late June 2025, on July 21, 2025, Parker and Stone announced a five-year agreement with Paramount+ to stream the series exclusively and to have 10 episodes produced per year. The twenty-eighth season premiered on October 16, 2025.\n\"South Park\" has received critical acclaim, and is included in various publications' lists of the greatest television shows. It has received numerous accolades, including five Primetime Emmy Awards and a Peabody Award. A theatrical film, \"\", was released in June 1999 to commercial and critical success, garnering an Academy Award nomination. In 2013, \"TV Guide\" ranked \"South Park\" the tenth Greatest TV Cartoon of All Time.\nPremise.\nSetting and characters.\n\"South Park\" centers around four boys: Stan Marsh, Kyle Broflovski, Eric Cartman and Kenny McCormick. The boys live in the fictional small town of South Park, located within the real-life South Park basin in the Rocky Mountains of central Colorado, approximately a one-hour drive from Denver. The town is also home to an assortment of other characters, including students, families, elementary school staff, and other various residents. Prominent settings include South Park Elementary, various neighborhoods and the surrounding mountain range, actual Colorado landmarks, and the businesses along the town's main street, all of which are based on the appearance of similar locations in Fairplay, Colorado. As one of the few television programs set in the Mountain West region that takes place outside the urban core of Denver, \"South Park\" frequently features the unique culture of the region, including cattle ranchers, Old West theme parks, snowy climates, mountaineering, Mormons, real-life Colorado locations such as Casa Bonita and Cave of the Winds, and many other regionally specific characteristics.\nStan is portrayed as an average American boy; however, he has many mishaps throughout the series. In the first 22 seasons, Stan lived in South Park, but in the episodes during and after season 22, Stan resided in Tegridy Farms. Kyle is Jewish, and his portrayal as one of the few such people in South Park is often dealt with satirically. Stan is modeled after Parker, while Kyle is modeled after Stone. They are best friends, and their friendship, symbolically intended to reflect Parker and Stone's friendship, is a common topic throughout the series. Cartman (as he is commonly referred to) is amoral and increasingly psychopathic, and is commonly portrayed as an antagonist. His staunch antisemitism has resulted in a progressive rivalry with Kyle. Kenny, who comes from a poor family, tightly wears his parka hood to the point where it obscures most of his face and muffles his speech. During the first five seasons, Kenny died in almost every episode before reappearing in the next with no definite explanation. He was killed off in the fifth season episode \"Kenny Dies\", before being reintroduced in the sixth season finale, \"Red Sleigh Down\". Since then, Kenny is depicted as dying sporadically. During the first 58 episodes, the children were in the third grade. During the fourth season, they entered the fourth grade, where they have remained ever since.\nPlots are often set in motion by events, ranging from the fairly typical to the supernatural and extraordinary, which frequently happen in the town. The boys often act as the voice of reason when these events cause panic or incongruous behavior among the adult populace, who are customarily depicted as irrational, gullible, and prone to overreaction. They are frequently confused by the contradictory and hypocritical behavior of their parents and other adults, and often perceive them as having distorted views on morality and society.\nThemes and style.\nEach episode opens with a tongue-in-cheek all persons fictitious disclaimer: \"All characters and events in this show\u2014even those based on real people\u2014are entirely fictional. All celebrity voices are impersonated...poorly. The following program contains coarse language and due to its content it should not be viewed by anyone.\"\n\"South Park\" was the first weekly program to be rated TV-MA, and is generally intended for adult audiences. The boys and most other child characters use strong profanity, with only the most taboo words being bleeped during a typical broadcast. Parker and Stone perceive this as the manner in which real-life small boys speak when they are alone.\n\"South Park\" commonly makes use of carnivalesque and absurdist techniques, numerous running gags, violence, sexual content, offhand pop-cultural references, and satirical portrayal of celebrities.\nEarly episodes tended to be shock value-oriented and featured more slapstick-style humor. While social satire had been used on the show occasionally earlier on, it became more prevalent as the series progressed, with the show retaining some of its focus on the boys' fondness of scatological humor in an attempt to remind adult viewers \"what it was like to be eight years old\". Parker and Stone also began further developing other characters by giving them larger roles in certain storylines, and began writing plots as parables based on religion, politics, and numerous other topics. This provided the opportunity for the show to spoof both extreme sides of contentious issues, while lampooning both liberal and conservative points of view. Rebecca Raphael described the show as \"an equal opportunity offender\", while Parker and Stone describe their main purpose as to \"be funny\" and \"make people laugh\", while stating that no particular topic or group of people be exempt from mockery and satire.\nParker and Stone insist that the show is still more about \"kids being kids\" and \"what it's like to be in [elementary school] in America\", stating that the introduction of a more satirical element to the series was the result of the two adding more of a \"moral center\" to the show so that it would rely less on simply being crude and shocking in an attempt to maintain an audience. While profane, Parker notes that there is still an \"underlying sweetness\" aspect to the child characters, and \"Time\" described the boys as \"sometimes cruel but with a core of innocence\". Usually, the boys or other characters pondered over what transpired during an episode and conveyed the important lesson taken from it with a short monologue. During earlier seasons, this speech commonly began with a variation of the phrase \"You know, I've learned something today...\".\nDevelopment.\nParker and Stone met in film class at the University of Colorado in 1992 and discovered a shared love of Monty Python, which they often cite as one of their primary inspirations. They created an animated short entitled \"The Spirit of Christmas\". The film was created by animating construction paper cutouts with stop motion, and features prototypes of the main characters of \"South Park\", including a character resembling Cartman but named \"Kenny\", an unnamed character resembling what is today Kenny, and two near-identical unnamed characters who resemble Stan and Kyle. Fox Broadcasting Company executive and mutual friend Brian Graden commissioned Parker and Stone to create a second short film as a video Christmas card. Created in 1995, the second \"The Spirit of Christmas\" short resembled the style of the later series more closely. To differentiate between the two homonymous shorts, the first short is often referred to as \"Jesus vs. Frosty\", and the second short as \"Jesus vs. Santa\". Graden sent copies of the video to several of his friends, and from there it was copied and distributed, including on the internet, where it became one of the first viral videos.\nAs \"Jesus vs. Santa\" became more popular, Parker and Stone began talks of developing the short into a television series about four children residing in a fictional Colorado town in the real-life South Park basin. Fox eagerly agreed to meet with the duo about the show's premise, having prided itself on edgier products such as \"Cops\", \"The Simpsons\", and \"The X-Files\". However, during the meeting at the Fox office in Century City, disagreements between the two creators and the network began to arise, mainly over the latter's refusal to air a show that included a supporting talking stool character named Mr. Hankey. Some executives at 20th Century Fox Television (which was to produce the series) agreed with its then-sister network's stance on Mr. Hankey and repeatedly requested Parker and Stone to remove the character in order for the show to proceed. Refusing to meet their demands, the duo cut ties with Fox and its sister companies all together and began shopping the series somewhere else.\nThe two then entered negotiations with both MTV and Comedy Central. Parker preferred the show be produced by Comedy Central, fearing that MTV would turn it into a kids show. When Comedy Central executive Doug Herzog watched the short, he commissioned for it to be developed into a series. Parker and Stone assembled a small staff and spent three months creating the pilot episode \"Cartman Gets an Anal Probe\". \"South Park\" was in danger of being canceled before it even aired when the show fared poorly with test audiences, particularly with women. However, the shorts were still gaining more popularity over the Internet, and Comedy Central ordered a run of six episodes. \"South Park\" debuted with \"Cartman Gets an Anal Probe\" on August 13, 1997.\nProduction.\nExcept for the pilot episode, which was produced using cutout animation, all episodes of \"South Park\" are created with the use of software, primarily Autodesk Maya. As opposed to the pilot, which took three months to complete, and other animated sitcoms, which are traditionally hand-drawn by companies in South Korea in a process that takes roughly eight to nine months, individual episodes of \"South Park\" take significantly less time to produce. Using computers as an animation method, the show's production staff were able to generate an episode in about three weeks during the first seasons. Now, with a staff of about 70 people, episodes are typically completed in one week, with some in as little as three to four days. Nearly the entire production of an episode is accomplished within one set of offices, which were originally at a complex in Westwood, Los Angeles, California and are now part of South Park Studios in Culver City, California. Parker and Stone have been the show's executive producers throughout its entire history. Debbie Liebling, who was Senior Vice President of original programming and development for Comedy Central, also served as an executive producer during the show's first five seasons, coordinating the show's production efforts between South Park Studios and Comedy Central's headquarters in New York City. During its early stages, finished episodes of \"South Park\" were hastily recorded to D-2 to be sent to Comedy Central for airing in just a few days' time. Each episode used to cost $250,000.\nWriting.\nScripts are not written before a season begins. Production of an episode begins on a Thursday, with the show's writing consultants brainstorming with Parker and Stone. Former staff writers include Pam Brady, who has since written scripts for the films \"Hot Rod\", \"Hamlet 2\" and \"\" (with Parker and Stone), and Nancy Pimental, who served as co-host of \"Win Ben Stein's Money\" and wrote the film \"The Sweetest Thing\" after her tenure with the show during its first three seasons. Television producer and writer Norman Lear, an idol of both Parker and Stone, and who also saw \"South Park\" as a way to bond with his son Benjamin, served as a guest writing consultant for the season seven (2003) episodes \"Cancelled\" and \"I'm a Little Bit Country\". During the 12th and 13th seasons, \"Saturday Night Live\" actor and writer Bill Hader served as a creative consultant and co-producer.\nAfter exchanging ideas, Parker will write a script, and from there the entire team of animators, editors, technicians, and sound engineers will each typically work 100\u2013120 hours in the ensuing week. Since the show's fourth season (2000), Parker has assumed most of the show's directorial duties, while Stone relinquished his share of the directing to focus on handling the coordination and business aspects of the production. On Wednesday, a completed episode is sent to Comedy Central's headquarters via satellite uplink, sometimes just a few hours before its air time of 10\u00a0PM Eastern Time.\nParker and Stone state that subjecting themselves to a one-week deadline creates more spontaneity amongst themselves in the creative process, which they feel results in a funnier show. The schedule also allows \"South Park\" to both stay more topical and respond more quickly to specific current events than other satiric animated shows. One of the earliest examples of this was in the season four (2000) episode \"Quintuplets 2000\", which references the United States Border Patrol's raid of a house during the Eli\u00e1n Gonz\u00e1lez affair, an event which occurred only four days before the episode originally aired. The season nine (2005) episode \"Best Friends Forever\" references the Terri Schiavo case, and originally aired in the midst of the controversy and less than 12 hours before she died. A scene in the season seven (2003) finale \"It's Christmas in Canada\" references the discovery of dictator Saddam Hussein in a \"spider hole\" and his subsequent capture, which happened a mere three days prior to the episode airing. The season 12 (2008) episode \"About Last Night...\" revolves around Barack Obama's victory in the 2008 presidential election, and aired less than 24 hours after Obama was declared the winner, using segments of dialogue from Obama's real victory speech.\nOn October 16, 2013, the show failed to meet their production deadline for the first time ever, after a power outage on October 15 at the production studio prevented the episode, season 17's \"\", from being finished in time. The episode was rescheduled to air a week later on October 23, 2013.\nAnimation.\nThe show's style of animation is inspired by the paper cut-out cartoons made by Terry Gilliam for \"Monty Python's Flying Circus\", of which Parker and Stone have been lifelong fans. Construction paper and traditional stop motion cutout animation techniques were used in the original animated shorts and in the pilot episode. Subsequent episodes have been produced by computer animation, providing a similar look to the originals while requiring a fraction of the time to produce. Before computer artists begin animating an episode, a series of animatics drawn in Toon Boom are provided by the show's storyboard artists.\nThe characters and objects are composed of simple geometrical shapes and primary and secondary colors. Most child characters are the same size and shape, and are distinguished by their clothing, hair and skin colors, and headwear. Characters are mostly presented two-dimensionally and from only one angle. Their movements are animated in an intentionally jerky fashion, as they are purposely not offered the same free range of motion associated with hand-drawn characters. Occasionally, some non-fictional characters are depicted with photographic cutouts of their actual head and face in lieu of a face reminiscent of the show's traditional style. Canadians on the show are often portrayed in an even more minimalist fashion; they have simple beady eyes, and the top halves of their heads simply flap up and down when the characters speak.\nWhen the show began using computers, the cardboard cutouts were scanned and re-drawn with CorelDRAW, then imported into PowerAnimator, which was used with SGI workstations to animate the characters. The workstations were linked to a 54-processor render farm that could render 10 to 15 shots an hour. Beginning with season five, the animators began using Maya instead of PowerAnimator. As of 2012, the studio ran a 120-processor render farm that can produce 30 or more shots an hour.\nPowerAnimator and Maya are high-end programs mainly used for 3D computer graphics, while co-producer and former animation director Eric Stough notes that PowerAnimator was initially chosen because its features helped animators retain the show's \"homemade\" look. PowerAnimator was also used for making some of the show's visual effects, which are now created using Motion, a newer graphics program created by Apple, Inc. for their Mac OS X operating system. The show's visual quality has improved in recent seasons, though several other techniques are used to intentionally preserve the cheap cutout animation look.\nA few episodes feature sections of live-action footage, while others have incorporated other styles of animation. Portions of the season eight (2004) premiere \"Good Times with Weapons\" are done in anime style, while the season 10 episode \"Make Love, Not Warcraft\" is done partly in machinima. The season 12 episode \"Major Boobage\", a homage to the 1981 animated film \"Heavy Metal\", implements scenes accomplished with rotoscoping.\nVoice cast.\nParker and Stone voice most of the male \"South Park\" characters. Mary Kay Bergman voiced the majority of the female characters until her death in November 1999. Mona Marshall and Eliza Schneider succeeded Bergman, with Schneider leaving the show after its seventh season (2003). She was replaced by April Stewart, who, along with Marshall, continues to voice most of the female characters. Bergman was originally listed in the credits under the alias Shannen Cassidy to protect her reputation as the voice of several Disney and other kid-friendly characters. Stewart was originally credited under the name Gracie Lazar, while Schneider was sometimes credited under her rock opera performance pseudonym Blue Girl.\nOther voice actors and members of \"South Park\"'s production staff have voiced minor characters for various episodes, while a few staff members voice recurring characters. Supervising producer Jennifer Howell voices student Bebe Stevens; co-producer and storyboard artist Adrien Beard voices Tolkien Black, who was the school's only African-American student until the introduction of Nichole in \"Cartman Finds Love\"; writing consultant Vernon Chatman voices an anthropomorphic towel named Towelie; and production supervisor John Hansen voices Mr. Slave, the former gay lover of Mr. Garrison. Throughout the show's run, the voices for toddler and kindergarten characters have been provided by various small children of the show's production staff.\nWhen voicing child characters, the voice actors speak within their normal vocal range while adding a childlike inflection. The recorded audio is then edited with Pro Tools, and the pitch is altered to make the voice sound more like that of a fourth grader.\nIsaac Hayes voiced the character of Chef, an African-American, soul-singing cafeteria worker who was one of the few adults the boys consistently trusted. Hayes agreed to voice the character after being among Parker and Stone's ideal candidates, which also included Lou Rawls and Barry White. Hayes, who lived and hosted a radio show in New York during his tenure with \"South Park\", recorded his dialogue on a digital audio tape while a director gave directions over the phone, after which the tape would be shipped to the show's production studio in California. After Hayes left the show in early 2006, the character of Chef was killed off in the season 10 (2006) premiere \"The Return of Chef\".\nGuest stars.\nCelebrities who are depicted on the show are usually impersonated, though some celebrities do their own voices for the show. Celebrities who have voiced themselves include Michael Buffer, Brent Musburger, Jay Leno, Robert Smith, and the bands Radiohead and Korn.\nComedy team Cheech &amp; Chong voiced characters representing their likenesses for the season four (2000) episode \"Cherokee Hair Tampons\", which was the duo's first collaborative effort in 20 years. Malcolm McDowell appears in live-action sequences as the narrator of the season four episode \"Pip\".\nJennifer Aniston, Richard Belzer, Natasha Henstridge, Norman Lear, and Peter Serafinowicz have guest starred as other speaking characters. During \"South Park\"'s earliest seasons, several high-profile celebrities inquired about guest-starring on the show. As a joke, Parker and Stone responded by offering low-profile, non-speaking roles, most of which were accepted; George Clooney provided the barks for Stan's dog Sparky in the season one (1997) episode \"Big Gay Al's Big Gay Boat Ride\", Leno provided the meows for Cartman's cat in the season one finale \"Cartman's Mom Is a Dirty Slut\", and Henry Winkler voiced the various growls and grunts of a kid-eating monster in the season two (1998) episode \"City on the Edge of Forever\". Jerry Seinfeld offered to lend his voice for the Thanksgiving episode \"Starvin' Marvin\", but declined to appear when he was only offered a role as \"Turkey #2\".\nMusic.\nParker says that the varying uses of music are of utmost importance to \"South Park\". Several characters often play or sing songs in order to change or influence a group's behavior, or to educate, motivate, or indoctrinate others. The show also frequently features scenes in which its characters have disapproving reactions to the performances of certain popular musicians.\nAdam Berry, the show's original score composer, used sound synthesis to simulate a small orchestra, and frequently alluded to existing famous pieces of music. Berry also used signature acoustic guitar and mandolin cues as leitmotifs for the show's establishing shots. After Berry left in 2001, Jamie Dunlap and Scott Nickoley of the Los Angeles-based Mad City Production Studios provided the show's original music for the next seven seasons. Since 2008, Dunlap has been credited as the show's sole score composer. Dunlap's contributions to the show are one of the few that are not achieved at the show's own production offices. Dunlap reads a script, creates a score using digital audio software, and then e-mails the audio file to South Park Studios, where it is edited to fit with the completed episode.\nIn addition to singing in an effort to explain something to the children, Chef would also sing about things relevant to what had transpired in the plot. These songs were original compositions written by Parker, and they were performed by Hayes in the same sexually suggestive R&amp;B style he had used during his own music career. The band DVDA, which consists of Parker and Stone, along with show staff members Bruce Howell and D.A. Young, performed the music for these compositions and, until the character's death on the show, were listed as \"Chef's Band\" in the closing credits.\nRick James, Elton John, Meat Loaf, Joe Strummer, Ozzy Osbourne, Primus, Rancid, and Ween all guest starred and briefly performed in the season two (1998) episode \"Chef Aid\". Korn debuted their single \"Falling Away from Me\" as guest stars on the season three (1999) episode \"Korn's Groovy Pirate Ghost Mystery\".\nMain theme.\nThe show's theme song was a musical score performed by the band Primus, with the lyrics alternately sung by the band's lead singer, Les Claypool, and the show's four central characters during the opening title sequence. Kenny's muffled lines are altered after every few seasons. His lines are usually sexually explicit in nature, such as his original lines, \"I like girls with big fat titties, I like girls with deep vaginas\".\nThe original unaired opening composition was originally slower and had a length of 40 seconds. It was deemed too long for the opening sequence. So Parker and Stone sped it up for the show's opening, having Claypool re-record his vocals. The instrumental version of the original composition is often played during the show's closing credits.\nThe opening song played in the first four seasons (and the end credits in all seasons) has a folk rock instrumentation with bass guitar, trumpets and rhythmic drums. Its beat is fast in the opening and leisurely in the closing credits. It is in the minor key and it features a tritone or a diminished fifth, creating a melodic dissonance, which captures the show's surrealistic nature. In the latter parts of seasons 4 and 5, the opening tune has an electro funk arrangement with pop qualities. Seasons 6\u20139 have a sprightly bluegrass instrumentation with a usage of banjo and is set in the major key. For the later seasons, the arrangement is electro rock with a breakbeat influence, which feature electric guitars backed up by synthesized, groovy drumbeats.\nThe opening theme song has been remixed three times during the course of the series, including a remix performed by Paul Robb. In 2006, the theme music was remixed with the song \"Whamola\" by Colonel Les Claypool's Fearless Flying Frog Brigade, from the album \"Purple Onion\".\nDistribution.\nInternational.\n\"South Park\" is broadcast internationally in several countries and territories, including India, New Zealand, and several countries throughout Europe and Latin America on channels that are subsidiaries of Comedy Central and Paramount Media Networks, both subsidiaries of Paramount. In distribution deals with Comedy Central, other independent networks also broadcast the series in other international markets. In Australia, the show is broadcast on The Comedy Channel, Comedy Central and free-to-air channel SBS Viceland (before 2009), while new episodes aired on SBS. The program also airs free-to-air in Australia on 10 Shake, a sister network to Comedy Central through Paramount. The series is broadcast uncensored in Canada in English on The Comedy Network and, later, Much. The series was formerly broadcast on Global. \"South Park\" also airs in Irish on TG4 in Ireland, STV in Scotland, Comedy Central and MTV in the UK (previously on Sky One, Channel 4, VIVA and 5Star), B92 in Serbia, and on Game One and NRJ 12 in France. In September 2020, SBS, which aired South Park in Australia since 1997, removed South Park from its television line-up, though reruns could air on SBS Viceland.\nSyndication.\nBroadcast syndication rights to \"South Park\" were acquired by Debmar-Mercury and Tribune Entertainment in 2003 and 2004 respectively. Episodes further edited for content began running in syndication on September 19, 2005, and were aired in the United States with the TV-14 rating. 20th Television replaced Tribune as co-distributor in early 2008. By the time its run in syndication ended in 2015, it aired in 90 percent of the television markets across the United States and Canada, where it generated an estimated US$25\u00a0million a year in advertising revenue. In 2019, CBS Television Distribution (the syndication arm of ViacomCBS, now known as Paramount Skydance), took over the full distribution rights following the acquisition of 21st Century Fox (parent of 20th Television) by The Walt Disney Company (who had employed Debmar-Mercury founder Mort Marcus as the head of their syndication division), distributing the show in syndication. In 2021, South Park Studios struck a deal with ViacomCBS, which allows the show to be renewed all the way up to season 30 and 14 additional films, enough to carry the show to at least 2027.\nHome media.\nComplete seasons of \"South Park\" have been regularly released in their entirety on DVD since 2002, with season twenty-six being the most recently released. Several other themed DVD compilations have been released by Rhino Entertainment and Comedy Central, while the three-episode \"\" story arc was reissued straight-to-DVD as a full-length feature in 2008. Blu-ray releases started in 2008 with the release of season twelve. Subsequent seasons have been released in this format alongside the longer-running DVD releases. The first eleven seasons were released on Blu-ray for the first time in December 2017.\nStreaming.\nIn March 2008, Comedy Central made every episode of \"South Park\" available for free full-length on-demand legal streaming on the official South Park Studios website. From March 2008 until December 2013, new episodes were added to the site the day following their debut, and an uncensored version was posted the following day. The episode stayed up for the remainder of the week, then taken down, and added to the site three weeks later.\nWithin a week, the site served more than a million streams of full episodes, and the number grew to 55 million by October 2008. Legal issues prevent the U.S. content from being accessible outside the United States, so local servers have been set up in other countries. In September 2009, a South Park Studios website with streaming episodes was launched in the United Kingdom and Ireland. In Canada, episodes were available for streaming from The Comedy Network's website, though due to digital rights restrictions, they are no longer available.\nIn April 2010, the season five episode \"Super Best Friends\" and the season fourteen episodes \"200\" and \"201\" were removed from the site; additionally, these episodes no longer air in reruns and are only available exclusively on DVD and Blu-ray. These episodes remain unavailable following the 2014 purchase by Hulu.\nIn July 2014, it was announced that Hulu had signed a three-year deal purchasing exclusive online streaming rights to \"South Park\" for a reported $80\u00a0million. Following the announcement every episode remained available for free on the South Park Studios website, using the Hulu player. As of September 2014, following the premiere of the eighteenth season, only 30 select episodes would be featured for free viewing at a time on a rotating basis on the website, with new episodes being available for an entire month starting the day following their original airings. The entire series was available on Hulu by this point.\nAs of July 2015, all episodes of \"South Park\" are available for streaming in Canada on the service CraveTV, which first consisted of seasons 1\u201318. Subsequent seasons were released the following July.\nIn early October 2019, industry rumors suggested that the streaming rights for \"South Park\" were being offered to various services, creating an intense bidding war that was estimated to be as high as US$. HBO and South Park Digital Studios announced that HBO had secured a multi-year deal for the exclusive streaming rights for \"South Park\" on their HBO Max service starting June 24, 2020. While the terms of the deal were not disclosed, \"Variety\" reported the deal fell between US$ and US$. Beginning with season 25 in 2022, HBO Max posts new episodes the next day after their Comedy Central airing. Once that deal expires in 2025, Paramount+ will become the exclusive streaming home. In addition, the season 27 episodes would stream first on Paramount+ before hitting HBO Max. Though season 27 would have originally aired in 2024, the season was delayed due to what Parker and Stone claimed to be uncertainties about the 2024 United States presidential election (mainly the exhaustion of humor set around Donald Trump), along with the merger of Skydance Media and Paramount Global.\nIn February 2023, Warner Bros. Discovery filed a lawsuit which claimed that Paramount breached its exclusivity contract with HBO Max by airing \"South Park\" on its own streaming platform.\nRe-rendered episodes.\nFrom its debut in 1997 to the season twelve finale in 2008 the series had been originally produced in standard definition, with a 4:3 aspect ratio. In 2009, the series switched to being produced in high definition 1080p with the beginning of the thirteenth season. All twelve seasons originally produced in standard definition have been remastered by South Park Studios, being fully re-rendered in high definition. The aspect ratio of these episodes was converted from 4:3 to 16:9 as well. The re-rendered versions were also released on Blu-ray. Several of the re-rendered episodes from the earlier seasons have their original uncensored audio tracks; they had previously been released in censored form.\nThe fifth-season episode \"Super Best Friends\", which was pulled from syndication and online streams following the controversy surrounding episode \"201\", was not released alongside the rest of the season when it was released in HD on iTunes in 2011. The episode was later re-rendered and made available for the Blu-ray release of the season that was released on December 5, 2017. The episode is presented in its original presentation, without Muhammad's image being obscured as in later episodes of the series.\nReception.\nRatings.\nWhen \"South Park\" debuted, it was a huge ratings success for Comedy Central and is seen as being largely responsible for the success of the channel, with Herzog crediting it for putting the network \"on the map\".\nThe show's first episode, \"Cartman Gets an Anal Probe\", earned a Nielsen rating of 1.3 (980,000 viewers), at the time considered high for a cable program. The show instantly generated buzz among television viewers, and mass viewing parties began assembling on college campuses. By the time the eighth episode, \"Starvin' Marvin\", aired\u2014three months after the show debuted\u2014ratings and viewership had tripled, and \"South Park\" was already the most successful show in Comedy Central's history. When the tenth episode \"Damien\" aired the following February, viewership increased another 33 percent. The episode earned a 6.4 rating, which at the time was over 10 times the average rating earned by a cable show aired in prime time. The ratings peaked with the second episode of season two, \"Cartman's Mom Is Still a Dirty Slut\", which aired on April 22, 1998. The episode earned an 8.2 rating (6.2 million viewers) and, at the time, set a record as the highest-rated non-sports show in basic cable history. During the spring of 1998, eight of the ten highest-rated shows on basic cable were \"South Park\" episodes. \"South Park's\" second season would average a 5.8 rating (12.5 million viewers) which was a lower rating due to Comedy Central's households being much higher.\nThe success of \"South Park\" prompted more cable companies to carry Comedy Central and led it to its becoming one of the fastest-growing cable channels. The number of households that had Comedy Central jumped from 9.1 million in 1997 to 50 million in June 1998. When the show debuted, the most Comedy Central had earned for a 30-second commercial was US$7,500. Within a year, advertisers were paying an average of US$40,000 for 30 seconds of advertising time during airings of \"South Park\" in its second season, while some paid as much as US$80,000.\nBy the third season (1999), the series' ratings began to decrease. The third-season premiere episode drew 3.4\u00a0million viewers, a dramatic drop from the 5.5\u00a0million of the previous season's premiere. Stone and Parker attributed this drop in the show's ratings to the media hype that surrounded the show in the previous year, adding that the third season ratings reflected the show's \"true\" fan base. Regardless the viewership stayed consistent with an average rating being between 3.0 (8 million viewers) to a 5.5 (17.5 million viewers). The show's ratings dropped further in its fourth season (2000), with episodes averaging just above 1.5 million viewers (though the season premiere would get 22.1 million viewers due to the hype caused by the movie). The ratings eventually increased, and seasons five through nine consistently averaged about 3 million viewers per episode. Season 8's episode \"Goobacks\" would have \"South Park\"'s viewership peak at 30 million viewers. Seasons 10 to 12 would average 5 million viewers. Though its viewership is lower than it was at the height of its popularity in its earliest seasons, \"South Park\" remains one of the highest-rated series on Comedy Central. The season 14 (2010) premiere gained 3.7\u00a0million viewers, the show's highest-rated season premiere since 1998. In 2016, a \"New York Times\" study of the 50 TV shows with the most Facebook Likes found that \"perhaps unsurprisingly, South Park ... is most popular in Colorado\". Subsequent seasons saw substantially lower ratings, with season 25 averaging 0.65\u00a0million viewers an episode.\nRecognitions and awards.\nIn 2004, Channel 4 voted \"South Park\" the third-greatest cartoon of all time. In 2007, \"Time\" magazine included the show on its list of the \"100 Best TV Shows of All Time\", proclaiming it as \"America's best source of rapid-fire satire for [the past] decade\". The same year, \"Rolling Stone\" declared it to be the funniest show on television since its debut 10 years prior. In 2008, \"South Park\" was named the 12th-greatest TV show of the past 25 years by \"Entertainment Weekly\", while AOL declared it as having the \"most astute\" characters of any show in history when naming it the 16th-best television comedy series of all time. In 2011, \"South Park\" was voted number one in the \"25 Greatest Animated TV Series\" poll by \"Entertainment Weekly\". The character of Cartman ranked 10th on TV Guide's 2002 list of the \"Top 50 Greatest Cartoon Characters\", 198th on VH1's \"200 Greatest Pop Culture Icons\", 19th on Bravo's \"100 Greatest TV Characters\" television special in 2004, and second on MSNBC's 2005 list of TV's scariest characters behind Mr. Burns from \"The Simpsons\". In 2006, Comedy Central received a Peabody Award for \"South Park\"'s \"stringent social commentary\" and \"undeniably fearless lampooning of all that is self-important and hypocritical in American life\". In 2013, the Writers Guild of America ranked \"South Park\" at number 63 among the \"101 Best-Written Shows Ever\". Also in 2013, TV Guide listed the show at number 10 among the \"60 Greatest Cartoons of All Time\". In 2019, the series was ranked 42nd on \"The Guardian\" newspaper's list of the 100 best TV shows of the 21st century.\n\"South Park\" won the CableACE Award for Best Animated Series in 1997, the last year the awards were given out. In 1998, \"South Park\" was nominated for the Annie Award for Outstanding Achievement in an Animated Primetime or Late Night Television Program. It was also nominated for the 1998 GLAAD Award for Outstanding TV \u2013 Individual Episode for \"Big Gay Al's Big Gay Boat Ride\".\n\"South Park\" has been nominated for the Emmy Award for Outstanding Animated Program eighteen times (1998, 2000, 2002, 2004\u20132011, 2013\u20132018 and 2021). The show has won the award for Outstanding Animated Program (For Programming Less Than One Hour) four times, for the 2005 episode \"Best Friends Forever\", the 2006 episode \"Make Love, Not Warcraft\", the 2009 episode \"Margaritaville\", and the 2012 episode \"Raising the Bar\". The \"Imaginationland\" trilogy of episodes won the Emmy Award for Outstanding Animated Program (For Programming One Hour or More) in 2008. It was also nominated twice for the Emmy Award for Outstanding Voice-Over Performance for the 68th Emmy Awards.\nCriticism.\nThe show's frequent depiction of taboo subject matter, general toilet humor, accessibility to younger viewers, disregard for conservative sensibilities, negative depiction of liberal causes, and portrayal of religion for comic effect have generated controversy and debate over the course of its run.\nAs the series became popular, students in two schools were barred from wearing \"South Park\"-related T-shirts, and the headmaster of a UK public school asked parents not to let their children watch the programme after eight- and nine-year-old children voted the \"South Park\" character Cartman as their favorite personality in a 1999 poll. Parker and Stone assert that the show is not meant to be viewed by young children, and the show is certified with TV ratings that indicate its intention for mature audiences. In 1999, they went on record to cancel the release of the Game Boy Color game based on the series, as Parker and Stone determined that a game based on an adult animated series would be inappropriate for a console whose core demographic consisted of children.\nParents Television Council founder L. Brent Bozell III and Action for Children's Television founder Peggy Charren have both condemned the show, with the latter claiming it is \"dangerous to the democracy\". Several other activist groups have protested the show's parodies of Christianity and portrayal of Jesus Christ. Stone has stated that parents who disapprove of \"South Park\" for its portrayal of how kids behave are upset because they \"have an idyllic vision of what kids are like\", adding \"[kids] don't have any kind of social tact or etiquette, they're just complete little raging bastards\".\nControversies.\nThe show further lampooned the controversy surrounding its use of profanity, as well as the media attention surrounding the network show \"Chicago Hope\"'s singular use of the word \"shit\", with the season five premiere \"It Hits the Fan\", in which the word \"shit\" is said 162 times without being bleeped for censorship purposes, while also appearing uncensored in written form. In the days following the show's original airing, 5,000 disapproving e-mails were sent to Comedy Central. Despite its 43 uncensored uses of the racial slur \"nigger\", the season 11 episode \"With Apologies to Jesse Jackson\" generated relatively little controversy, as most in the black community and the NAACP praised the episode for its context and its comedic way of conveying other races' perceptions of how black people feel when hearing the word.\nSpecific controversies regarding the show have included an April Fools' Day prank played on its viewers in 1998, its depiction of the Virgin Mary in the season nine (2005) finale \"Bloody Mary\" that angered several Catholics, its depiction of Steve Irwin with a stingray barb stuck in his chest in the episode \"Hell on Earth 2006\", which originally aired less than two months after Irwin was killed in the same fashion, Comedy Central's censorship of the depiction of Muhammad in the season 10 episode \"Cartoon Wars Part II\" in the wake of the \"Jyllands-Posten\" Muhammad cartoons controversy and consistent mockery of the concept of climate change by using climate change denialist talking points.\nThe season nine (2005) episode \"Trapped in the Closet\" denounces Scientology as nothing more than \"a big fat global scam\", while freely divulging church information that Scientology normally only reveals to members who make significant monetary contributions to the church. The episode also ambiguously parodies the rumors involving the sexual orientation of Scientologist Tom Cruise, who allegedly demanded any further reruns of the episode be canceled. Isaac Hayes, a Scientologist, later quit \"South Park\" because of his objection to the episode.\nThe season fourteen episodes \"200\" and \"201\" were mired in controversy for satirizing issues surrounding the depiction of the Islamic prophet, Muhammad. The website for the organization Revolution Muslim, a New York-based radical Muslim organization, posted an entry that included a warning to creators Parker and Stone that they risk violent retribution for their depictions of Muhammad. It said that they \"will probably wind up like Theo van Gogh for airing this show\". The posting provided the addresses to Comedy Central in New York and the production company in Los Angeles. The author of the post, Zachary Adam Chesser (whose alias is Abu Talhah al-Amrikee), said it was meant to serve as a warning to Parker and Stone, not a threat, and that providing the addresses was meant to give people the opportunity to protest.\nDespite Chesser's claims that the website entry was a warning, several media outlets and observers interpreted it as a threat. Comedy Central censored the episode's broadcast in response, by bleeping out several speeches and covering Mohammed's appearances with a giant \"censored\" label. Support for the episode has come in the form of Everybody Draw Mohammed Day, a movement started on Facebook that encourages people to draw Muhammad on May 20. The \"200\" episode, which also depicted the Buddha snorting cocaine, prompted the government of Sri Lanka to ban the series outright.\nDue to many taboo topics in China\u2014such as Dalai Lama, Winnie the Pooh, labor camps, freedom of speech and cannabis culture\u2014being involved in the season 23 (2019) episode \"Band in China\", \"South Park\" was entirely banned in China after the episode's broadcast. The series' Baidu Baike article, Baidu Tieba forum, Douban page, Zhihu page and Bilibili videos have been deleted or inaccessible to the public, all related keywords and topics have been prohibited from being searched and discussed on China-based search engines and social media sites including Baidu, QQ, Weibo and on WeChat public platforms. Parker and Stone issued a sarcastic apology in response.\nLegacy.\nCultural.\nCommentary made in episodes has been interpreted as statements Parker and Stone are attempting to make to the viewing public, and these opinions have been subject to much critical analysis in the media and literary world within the framework of popular philosophical, theological, social, and political concepts. Since \"South Park\" debuted, college students have written term papers and doctoral theses analyzing the show, while Brooklyn College offers a course called \"\"South Park\" and Political Correctness\".\nSoon after one of Kenny's trademark deaths on the show, other characters would typically shout \"Oh my God, they killed Kenny!\", followed by another yelling out \"You bastard(s)!\"\u2014these lines were usually said by the characters Stan and Kyle, respectively. The exclamation quickly became a popular catchphrase, while the running gag of Kenny's recurring deaths is one of the more recognized hallmarks among viewers of modern television. Cartman's exclamations of \"Respect my authori-tah!\" and \"Screw you guys ...I'm going home!\" became catchphrases as well, and during the show's earlier seasons, were highly popular in the lexicon of viewers. Cartman's eccentric intonation of \"Hey!\" was included in the 2002 edition of \"The Oxford Dictionary of Catchphrases\".\nIn the season two episode \"Chef Aid\", attorney Johnnie Cochran uses what's called in the show the Chewbacca defense, which is a legal strategy that involves addressing plot holes related to Chewbacca in the film \"Return of the Jedi\" rather than discussing the trial at hand during a closing argument in a deliberate attempt to confuse jurors into thinking there is reasonable doubt. The term \"Chewbacca defense\" has been documented as being used by criminologists, forensic scientists, and political commentators in their various discussions of similar methods used in legal cases and public forums.\nAnother season two episode, \"Gnomes\", revolves around a group of \"underpants gnomes\" who, as their name suggests, run a corporation stealing people's underpants. When asked about their business model, various gnomes reply that theirs is a three-step process: Phase 1 is \"collect underpants\". Phase 3 is \"profit\". However, the gnomes are unable to explain what is to occur between the first and final steps, and \"Phase 2\" is accompanied by a large question mark on their corporate flow chart. Using \"????\" and \"PROFIT!\" as the last two steps in a process (usually jokingly) became a widely popular Internet meme because of this. Especially in the context of politics and economics, \"underpants gnomes\" has been used by some commentators to characterize a conspicuous gap of logic or planning.\nWhen Sophie Rutschmann of the University of Strasbourg discovered a mutated gene that causes an adult fruit fly to die within two days after it is infected with certain bacteria, she named the gene \"kep1\" in honor of Kenny. Similarly, when a mutated ortholog of KIAA1109 was also found for said species that inhibited their ability to stand upright, walk, and caused seizures, indicative of severe neurological defects, a different set of researchers named it \"Tweek\" in honor of Tweek.\nPolitical.\nWhile some conservatives have condemned \"South Park\" for its vulgarity, a growing population of people who hold center-right political beliefs, including teenagers and young adults, have embraced the show for its tendency to mock liberal viewpoints and lampoon liberal celebrities and icons. Political commentator Andrew Sullivan dubbed the group \"South Park\" Republicans, or \"South Park\" conservatives. Sullivan averred that members of the group are \"extremely skeptical of political correctness but also are socially liberal on many issues\", though he says the phrase applied to them is meant to be more of a casual indication of beliefs than a strong partisan label. Brian C. Anderson describes the group as \"generally characterized by holding strong libertarian beliefs and rejecting more conservative social policy\", and notes that although the show makes \"wicked fun of conservatives\", it is \"at the forefront of a conservative revolt against liberal media\" and Hollywood's \"liberal hegemony\".\nParker and Stone reject the idea that the show has any underlying political position, and deny having a political agenda when creating an episode.\nThe two claim the show's higher proportion of instances lampooning liberal rather than conservative orthodoxies stems simply from their preference for making fun of liberals. While Stone has been quoted saying, \"I hate conservatives, but I really fucking hate liberals\", Stone and Parker have explained that their drive to lampoon a given target comes first from the target's insistence on telling other people how to behave. The duo explain that they regard liberals as having both delusions of entitlement to remain free from satire, and a propensity to enforce political correctness while patronizing the citizens of Middle America. Parker and Stone are uncomfortable with the idea of themselves or \"South Park\" being assigned any kind of partisan classification. Parker said he rejects the \"\"South Park\" Republican\" and \"\"South Park\" conservative\" labels, feeling that either tag implies that one only adheres to strictly conservative or liberal viewpoints. The duo has in the past reluctantly labeled themselves libertarians and fans of government gridlock. In 2006, they said that they were \"rooting for Hillary Clinton in 2008 simply because it would be weird to have her as president\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27978", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=27978", "title": "Skin", "text": "Soft outer covering organ of vertebrates\nSkin is the layer of usually soft, flexible outer tissue covering the body of a vertebrate animal, with three main functions: protection, regulation, and sensation.\nOther animal coverings, such as the arthropod exoskeleton, have different developmental origin, structure and chemical composition. The adjective cutaneous means \"of the skin\" (from Latin \"cutis\" 'skin'). In mammals, the skin is an organ of the integumentary system made up of multiple layers of ectodermal tissue and guards the underlying muscles, bones, ligaments, and internal organs. Skin of a different nature exists in amphibians, reptiles, and birds. Skin (including cutaneous and subcutaneous tissues) plays crucial roles in formation, structure, and function of extraskeletal apparatus such as horns of bovids (e.g., cattle) and rhinos, cervids' antlers, giraffids' ossicones, armadillos' osteoderm, and os penis/os clitoris.\nAll mammals have some hair on their skin, even marine mammals like whales, dolphins, and porpoises that appear to be hairless.\nThe skin interfaces with the environment and is the first line of defense from external factors. For example, the skin plays a key role in protecting the body against pathogens and excessive water loss. Its other functions are insulation, temperature regulation, sensation, and the production of vitamin D folates. Severely damaged skin may heal by forming scar tissue. This is sometimes discoloured and depigmented. The thickness of skin also varies from location to location on an organism. In humans, for example, the skin located under the eyes and around the eyelids is the thinnest skin on the body at 0.5\u00a0mm thick and is one of the first areas to show signs of aging such as \"crows feet\" and wrinkles. The skin on the palms and the soles of the feet is the thickest skin on the body at 4\u00a0mm thick. The speed and quality of wound healing in skin is promoted by estrogen.\nFur is dense hair. Primarily, fur augments the insulation the skin provides but can also serve as a secondary sexual characteristic or as camouflage. On some animals, the skin is very hard and thick and can be processed to create leather. Reptiles and most fish have hard protective scales on their skin for protection, and birds have hard feathers, all made of tough beta-keratins. Amphibian skin is not a strong barrier, especially regarding the passage of chemicals via skin, and is often subject to osmosis and diffusive forces. For example, a frog sitting in an anesthetic solution would be sedated quickly as the chemical diffuses through its skin. Amphibian skin plays key roles in everyday survival and their ability to exploit a wide range of habitats and ecological conditions.\nOn 11 January 2024, biologists reported the discovery of the oldest known skin, fossilized about 289 million years ago, and possibly the skin from an ancient reptile.\nEtymology.\nThe word skin originally only referred to dressed and tanned animal hide and the usual word for human skin was hide. Skin is a borrowing from Old Norse \"animal hide, fur\", ultimately from the Proto-Indo-European root *sek-, meaning \"to cut\" (probably a reference to the fact that in those times animal hide was commonly cut off to be used as garment).\nStructure in mammals.\nMammalian skin is composed of two primary layers:\nEpidermis.\nThe epidermis is composed of the outermost layers of the skin. It forms a protective barrier over the body's surface, responsible for keeping water in the body and preventing pathogens from entering, and is a stratified squamous epithelium, composed of proliferating basal and differentiated suprabasal keratinocytes.\nKeratinocytes are the major cells, constituting 95% of the epidermis, while Merkel cells, melanocytes and Langerhans cells are also present. The epidermis can be further subdivided into the following \"strata\" or layers (beginning with the outermost layer):\nKeratinocytes in the stratum basale proliferate through mitosis and the daughter cells move up the strata changing shape and composition as they undergo multiple stages of cell differentiation to eventually become anucleated. During that process, keratinocytes will become highly organized, forming cellular junctions (desmosomes) between each other and secreting keratin proteins and lipids which contribute to the formation of an extracellular matrix and provide mechanical strength to the skin. Keratinocytes from the stratum corneum are eventually shed from the surface (desquamation).\nThe epidermis contains no blood vessels, and cells in the deepest layers are nourished by diffusion from blood capillaries extending to the upper layers of the dermis.\nBasement membrane.\nThe epidermis and dermis are separated by a thin sheet of fibers called the basement membrane, which is made through the action of both tissues.\nThe basement membrane controls the traffic of the cells and molecules between the dermis and epidermis but also serves, through the binding of a variety of cytokines and growth factors, as a reservoir for their controlled release during physiological remodeling or repair processes.\nDermis.\nThe dermis is the layer of skin beneath the epidermis that consists of connective tissue and cushions the body from stress and strain. The dermis provides tensile strength and elasticity to the skin through an extracellular matrix composed of collagen fibrils, microfibrils, and elastic fibers, embedded in hyaluronan and proteoglycans. Skin proteoglycans are varied and have very specific locations. For example, hyaluronan, versican and decorin are present throughout the dermis and epidermis extracellular matrix, whereas biglycan and perlecan are only found in the epidermis.\nIt harbors many mechanoreceptors (nerve endings) that provide the sense of touch and heat through nociceptors and thermoreceptors. It also contains the hair follicles, sweat glands, sebaceous glands, apocrine glands, lymphatic vessels and blood vessels. The blood vessels in the dermis provide nourishment and waste removal from its own cells as well as for the epidermis.\nDermis and subcutaneous tissues are thought to contain germinative cells involved in formation of horns, osteoderm, and other extra-skeletal apparatus in mammals.\nThe dermis is tightly connected to the epidermis through a basement membrane and is structurally divided into two areas: a superficial area adjacent to the epidermis, called the \"papillary region\", and a deep thicker area known as the \"reticular region\".\nPapillary region.\nThe papillary region is composed of loose areolar connective tissue. This is named for its fingerlike projections called \"papillae\" that extend toward the epidermis. The papillae provide the dermis with a \"bumpy\" surface that interdigitates with the epidermis, strengthening the connection between the two layers of skin.\nReticular region.\nThe reticular region lies deep in the papillary region and is usually much thicker. It is composed of dense irregular connective tissue and receives its name from the dense concentration of collagenous, elastic, and reticular fibers that weave throughout it. These protein fibers give the dermis its properties of strength, extensibility, and elasticity.\nAlso located within the reticular region are the roots of the hair, sweat glands, sebaceous glands, receptors, nails, and blood vessels.\nSubcutaneous tissue.\nThe subcutaneous tissue (also hypodermis) is not part of the skin, and lies below the dermis. Its purpose is to attach the skin to underlying bone and muscle as well as supplying it with blood vessels and nerves. It consists of loose connective tissue and elastin. The main cell types are fibroblasts, macrophages and adipocytes (the subcutaneous tissue contains 50% of body fat). Fat serves as padding and insulation for the body.\nMicroorganisms like \"Staphylococcus epidermidis\" colonize the skin surface. The density of skin flora depends on region of the skin. The disinfected skin surface gets recolonized from bacteria residing in the deeper areas of the hair follicle, gut and urogenital openings.\nStructure in fish, amphibians, birds, and reptiles.\nFish.\nThe epidermis of fish and of most amphibians consists entirely of live cells, with only minimal quantities of keratin in the cells of the superficial layer. It is generally permeable, and in the case of many amphibians, may actually be a major respiratory organ. The dermis of bony fish typically contains relatively little of the connective tissue found in tetrapods. Instead, in most species, it is largely replaced by solid, protective bony scales. Apart from some particularly large dermal bones that form parts of the skull, these scales are lost in tetrapods, although many reptiles do have scales of a different kind, as do pangolins. Cartilaginous fish have numerous tooth-like denticles embedded in their skin, in place of true scales.\nSweat glands and sebaceous glands are both unique to mammals, but other types of skin gland are found in other vertebrates. Fish typically have a numerous individual mucus-secreting skin cells that aid in insulation and protection, but may also have poison glands, photophores, or cells that produce a more watery, serous fluid. In amphibians, the mucous cells are gathered together to form sac-like glands. Most living amphibians also possess \"granular glands\" in the skin, that secrete irritating or toxic compounds.\nAlthough melanin is found in the skin of many species, in the reptiles, the amphibians, and fish, the epidermis is often relatively colorless. Instead, the color of the skin is largely due to chromatophores in the dermis, which, in addition to melanin, may contain guanine or carotenoid pigments. Many species, such as chameleons and flounders may be able to change the color of their skin by adjusting the relative size of their chromatophores.\nAmphibians.\nOverview.\nAmphibians possess two types of glands, mucous and granular (serous). Both of these glands are part of the integument and thus considered cutaneous. Mucous and granular glands are both divided into three different sections which all connect to structure the gland as a whole. The three individual parts of the gland are the duct, the intercalary region, and lastly the alveolar gland (sac). Structurally, the duct is derived via keratinocytes and passes through to the surface of the epidermal or outer skin layer thus allowing external secretions of the body. The gland alveolus is a sac-shaped structure that is found on the bottom or base region of the granular gland. The cells in this sac specialize in secretion. Between the alveolar gland and the duct is the intercalary system which can be summed up as a transitional region connecting the duct to the grand alveolar beneath the epidermal skin layer. In general, granular glands are larger in size than the mucous glands, which are greater in number.\nGranular glands.\nGranular glands can be identified as venomous and often differ in the type of toxin as well as the concentrations of secretions across various orders and species within the amphibians. They are located in clusters differing in concentration depending on amphibian taxa. The toxins can be fatal to most vertebrates or have no effect against others. These glands are alveolar meaning they structurally have little sacs in which venom is produced and held before it is secreted upon defensive behaviors.\nStructurally, the ducts of the granular gland initially maintain a cylindrical shape. When the ducts mature and fill with fluid, the base of the ducts become swollen due to the pressure from the inside. This causes the epidermal layer to form a pit like opening on the surface of the duct in which the inner fluid will be secreted in an upwards fashion.\nThe intercalary region of granular glands is more developed and mature in comparison with mucous glands. This region resides as a ring of cells surrounding the basal portion of the duct which are argued to have an ectodermal muscular nature due to their influence over the lumen (space inside the tube) of the duct with dilation and constriction functions during secretions. The cells are found radially around the duct and provide a distinct attachment site for muscle fibers around the gland's body.\nThe gland alveolus is a sac that is divided into three specific regions/layers. The outer layer or tunica fibrosa is composed of densely packed connective-tissue which connects with fibers from the spongy intermediate layer where elastic fibers, as well as nerves, reside. The nerves send signals to the muscles as well as the epithelial layers. Lastly, the epithelium or tunica propria encloses the gland.\nMucous glands.\nMucous glands are non-venomous and offer a different functionality for amphibians than granular. Mucous glands cover the entire surface area of the amphibian body and specialize in keeping the body lubricated. There are many other functions of the mucous glands such as controlling the pH, thermoregulation, adhesive properties to the environment, anti-predator behaviors (slimy to the grasp), chemical communication, even anti-bacterial/viral properties for protection against pathogens.\nThe ducts of the mucous gland appear as cylindrical vertical tubes that break through the epidermal layer to the surface of the skin. The cells lining the inside of the ducts are oriented with their longitudinal axis forming 90-degree angles surrounding the duct in a helical fashion.\nIntercalary cells react identically to those of granular glands but on a smaller scale. Among the amphibians, there are taxa which contain a modified intercalary region (depending on the function of the glands), yet the majority share the same structure.\nThe alveolar or mucous glands are much more simple and only consist of an epithelium layer as well as connective tissue which forms a cover over the gland. This gland lacks a tunica propria and appears to have delicate and intricate fibers which pass over the gland's muscle and epithelial layers.\nBirds and reptiles.\nThe epidermis of birds and reptiles is closer to that of mammals, with a layer of dead keratin-filled cells at the surface, to help reduce water loss. A similar pattern is also seen in some of the more terrestrial amphibians such as toads. In these animals, there is no clear differentiation of the epidermis into distinct layers initially, as occurs in humans, with the change in cell type being relatively gradual. The mammalian epidermis always possesses at least a stratum germinativum and stratum corneum, but the other intermediate layers found in humans are not always distinguishable.\nHair is a distinctive feature of mammalian skin, while feathers are (at least among living species) similarly unique to birds.\nBirds and reptiles have relatively few skin glands, although there may be a few structures for specific purposes, such as pheromone-secreting cells in some reptiles, or the uropygial gland of most birds.\nDevelopment.\nCutaneous structures arise from the epidermis and include a variety of features such as hair, feathers, claws and nails. During embryogenesis, the epidermis splits into two layers: the periderm (which is lost) and the basal layer. The basal layer is a stem cell layer and through asymmetrical divisions, becomes the source of skin cells throughout life. It is maintained as a stem cell layer through an autocrine signal, TGF alpha, and through paracrine signaling from FGF7 (keratinocyte growth factor) produced by the dermis below the basal cells. In mice, over-expression of these factors leads to an overproduction of granular cells and thick skin.\nHair and feathers are formed in a regular pattern and it is believed to be the result of a reaction-diffusion system. This reaction-diffusion system combines an activator, Sonic hedgehog, with an inhibitor, BMP4 or BMP2, to form clusters of cells in a regular pattern. Sonic hedgehog-expressing epidermal cells induce the condensation of cells in the mesoderm. The clusters of mesodermal cells signal back to the epidermis to form the appropriate structure for that position. BMP signals from the epidermis inhibit the formation of placodes in nearby ectoderm.\nIt is believed that the mesoderm defines the pattern. The epidermis instructs the mesodermal cells to condense and then the mesoderm instructs the epidermis of what structure to make through a series of reciprocal inductions. Transplantation experiments involving frog and newt epidermis indicated that the mesodermal signals are conserved between species but the epidermal response is species-specific meaning that the mesoderm instructs the epidermis of its position and the epidermis uses this information to make a specific structure.\nFunctions.\nSkin performs the following functions:\nMechanics.\nSkin is a soft tissue and exhibits key mechanical behaviors of these tissues. The most pronounced feature is the J-curve stress strain response, in which a region of large strain and minimal stress exists and corresponds to the microstructural straightening and reorientation of collagen fibrils. In some cases the intact skin is prestreched, like wetsuits around the diver's body, and in other cases the intact skin is under compression. Small circular holes punched on the skin may widen or close into ellipses, or shrink and remain circular, depending on preexisting stresses.\nAging.\nTissue homeostasis generally declines with age, in part because stem/progenitor cells fail to self-renew or differentiate. Skin aging is caused in part by TGF-\u03b2 by blocking the conversion of dermal fibroblasts into fat cells which provide support. Common changes in the skin as a result of aging range from wrinkles, discoloration, and skin laxity, but can manifest in more severe forms such as skin malignancies. Moreover, these factors may be worsened by sun exposure in a process known as photoaging.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27979", "revid": "1317169187", "url": "https://en.wikipedia.org/wiki?curid=27979", "title": "Sunlight", "text": "Light emitted by the Sun\nSunlight is the portion of the electromagnetic radiation which is emitted by the Sun (i.e. solar radiation) and received by the Earth, in particular the visible light perceptible to the human eye as well as invisible infrared (typically perceived by humans as warmth) and ultraviolet (which can have physiological effects such as sunburn) lights. However, according to the American Meteorological Society, there are \"conflicting conventions as to whether all three [...] are referred to as light, or whether that term should only be applied to the visible portion of the spectrum\". Upon reaching the Earth, sunlight is scattered and filtered through the Earth's atmosphere as daylight when the Sun is above the horizon. When direct solar radiation is not blocked by clouds, it is experienced as sunshine, a combination of bright light and radiant heat (atmospheric). When blocked by clouds or reflected off other objects, sunlight is diffused. Sources estimate a global average of between 164 watts to 340 watts per square meter over a 24-hour day; this figure is estimated by NASA to be about a quarter of Earth's average total solar irradiance.\nThe ultraviolet radiation in sunlight has both positive and negative health effects, as it is both a requisite for vitamin D3 synthesis and a mutagen.\nSunlight takes about 8.3\u00a0minutes to reach Earth from the surface of the Sun. A photon starting at the center of the Sun and changing direction every time it encounters a charged particle would take between 10,000 and 170,000 years to get to the surface.\nSunlight is a key factor in photosynthesis, the process used by plants and other autotrophic organisms to convert light energy, normally from the Sun, into chemical energy that can be used to synthesize carbohydrates and fuel the organisms' activities.\n\"Daylighting\" is the natural lighting of interior spaces by admitting sunlight.\n\"Solar irradiance\" is the rate of solar energy received by a unit area from sunlight.\nMeasurement.\nResearchers can measure the intensity of sunlight using a sunshine recorder, pyranometer, or pyrheliometer. To calculate the amount of sunlight reaching the ground, both the eccentricity of Earth's elliptic orbit and the attenuation by Earth's atmosphere have to be taken into account. The extraterrestrial solar illuminance (\"E\"ext), corrected for the elliptic orbit by using the day number of the year (dn), is given to a good approximation by\nformula_1\nwhere dn=1 on January 1; dn=32 on February 1; dn=59 on March 1 (except on leap years, where dn=60), etc. In this formula dn\u20133 is used, because in modern times Earth's perihelion, the closest approach to the Sun and, therefore, the maximum {{math|\"E\"ext}} occurs around January 3 each year. The value of 0.033412 is determined knowing that the ratio between the perihelion (0.98328989\u00a0AU) squared and the aphelion (1.01671033\u00a0AU) squared should be approximately 0.935338.\nThe solar illuminance constant ({{math|\"E\"sc}}), is equal to 128\u00d7103\u00a0lux. The direct normal illuminance ({{math|\"E\"dn}}), corrected for the attenuating effects of the atmosphere is given by:\nformula_2\nwhere {{mvar|c}} is the atmospheric extinction and {{mvar|m}} is the relative optical airmass. The atmospheric extinction brings the number of lux down to around 100,000 lux.\nThe total amount of energy received at ground level from the Sun at the zenith depends on the distance to the Sun and thus on the time of year. It is about 3.3% higher than average in January and 3.3% lower in July (see below). If the extraterrestrial solar radiation is 1,367 watts per square meter (the value when the Earth\u2013Sun distance is 1 astronomical unit), then the direct sunlight at Earth's surface when the Sun is at the zenith is about 1,050 W/m2, but the total amount (direct and indirect from the atmosphere) hitting the ground is around 1,120 W/m2. In terms of energy, sunlight at Earth's surface is around 52 to 55 percent infrared (above 700 nm), 42 to 43 percent visible (400 to 700\u00a0nm), and 3 to 5 percent ultraviolet (below 400\u00a0nm). At the top of the atmosphere, sunlight is about 30% more intense, having about 8% ultraviolet (UV), with most of the extra UV consisting of biologically damaging short-wave ultraviolet.\nDividing the irradiance of 1,050\u00a0W/m2 by the size of the Sun's disk in steradians gives an average radiance of 15.4\u00a0MW per square metre per steradian. (However, the radiance at the center of the Sun's disk is somewhat higher than the average over the whole disk due to limb darkening.) Multiplying this by \u03c0 gives an upper limit to the irradiance which can be focused on a surface using mirrors: 48.5\u00a0MW/m2.\nComposition and power.\nThe spectrum of the Sun's solar radiation can be compared to that of a black body with a temperature of about 5,800\u00a0K (see graph). The Sun emits EM radiation across most of the electromagnetic spectrum. Although the radiation created in the solar core consists mostly of x rays, internal absorption and thermalization convert these super-high-energy photons to lower-energy photons before they reach the Sun's surface and are emitted out into space. As a result, the photosphere of the Sun does not emit much X radiation (solar X-rays), although it does emit such \"hard radiations\" as X-rays and even gamma rays during solar flares. The quiet (non-flaring) Sun, including its corona, emits a broad range\nof wavelengths: X-rays, ultraviolet, visible light, infrared, and radio waves. Different depths in the photosphere have different temperatures, and this partially explains the deviations from a black-body spectrum.\nThere is also a flux of gamma rays from the quiescent Sun, obeying a power law between 0.5 and 2.6 TeV. Some gamma rays are caused by cosmic rays interacting with the solar atmosphere, but this does not explain these findings.\nThe only direct signature of the nuclear processes in the core of the Sun is via the very weakly interacting neutrinos.\nAlthough the solar corona is a source of extreme ultraviolet and X-ray radiation, these rays make up only a very small amount of the power output of the Sun (see spectrum at right). The spectrum of nearly all (roughly 98.7%) of the solar electromagnetic radiation striking the Earth's atmosphere spans a range of 200 nm to about 4000 nm. This band of significant radiation power can be divided into five regions in increasing order of wavelengths:\nThe sunlight reaching Earth's surface is 49.4% infrared, 42.3% visible, and 8% ultraviolet.\nIt is sometimes asserted that the Sun's maximum output is in the visible range. However, this statement is a misconception based on only seeing the solar spectral irradiance plotted on a per-wavelength basis. When plotted that way, the power spectral density of sunlight peaks at a wavelength of about 501 nm, which is in the visible range. However, the solar spectral irradiance can with equal validity be calculated on a per-frequency basis, in which case the maximum is at {{val|3.40e14|u=Hz}}, corresponding to a wavelength of about 882 nm, which is in the near infrared (Infrared-A) range. Counterintuitively, it is not meaningful to assert that the solar output is greatest at some precise location in the spectrum.\nPublished tables.\nTables of direct solar radiation on various slopes from 0 to 60 degrees north latitude, in calories per square centimetre, issued in 1972 and published by Pacific Northwest Forest and Range Experiment Station, Forest Service, U.S. Department of Agriculture, Portland, Oregon, USA, appear on the web.\nIntensity in the Solar System.\nDifferent bodies of the Solar System receive light of an intensity inversely proportional to the square of their distance from the Sun.\nA table comparing the amount of solar radiation received by each planet in the Solar System at the top of its atmosphere:\nThe actual brightness of sunlight that would be observed at the surface also depends on the presence and composition of an atmosphere. For example, Venus's thick atmosphere reflects more than 60% of the solar light it receives. The actual illumination of the surface is about 14,000\u00a0lux, comparable to that on Earth \"in the daytime with overcast clouds\".\nSunlight on Mars would be more or less like daylight on Earth during a slightly overcast day, and, as can be seen in the pictures taken by the rovers, there is enough diffuse sky radiation that shadows would not seem particularly dark. Thus, it would give perceptions and \"feel\" very much like Earth daylight. The spectrum on the surface is slightly redder than that on Earth, due to scattering by reddish dust in the Martian atmosphere.\nFor comparison, sunlight on Saturn is slightly brighter than Earth sunlight at the average sunset or sunrise. Even on Pluto, the sunlight would still be bright enough to almost match the average living room. To see sunlight as dim as full moonlight on Earth, a distance of about 500\u00a0AU (~69\u00a0light-hours) is needed; only a handful of objects in the Solar System have been discovered that are known to orbit farther than such a distance, among them 90377 Sedna and {{mpl|(87269) 2000 OO|67}}.\nVariations in solar irradiance.\nSeasonal and orbital variation.\nOn Earth, the solar radiation varies with the angle of the Sun above the horizon, with longer sunlight duration at high latitudes during summer, varying to no sunlight at all in winter near the pertinent pole. When the direct radiation is not blocked by clouds, it is experienced as \"sunshine\". The warming of the ground (and other objects) depends on the absorption of the electromagnetic radiation in the form of heat.\nThe amount of radiation intercepted by a planetary body varies inversely with the square of the distance between the star and the planet. Earth's orbit and obliquity change with time (over thousands of years), sometimes forming a nearly perfect circle, and at other times stretching out to an orbital eccentricity of 5% (currently 1.67%). As the orbital eccentricity changes, the average distance from the Sun (the semimajor axis does not significantly vary, and so the total insolation over a year remains almost constant due to Kepler's second law,\nformula_3\nwhere formula_4 is the \"areal velocity\" invariant. That is, the integration over the orbital period (also invariant) is a constant.\nformula_5\nIf we assume the solar radiation power\u00a0{{mvar|P}} as a constant over time and the solar irradiation given by the inverse-square law, we obtain also the average insolation as a constant. However, the seasonal and latitudinal distribution and intensity of solar radiation received at Earth's surface does vary. The effect of Sun angle on climate results in the change in solar energy in summer and winter. For example, at latitudes of 65\u00a0degrees, this can vary by more than 25% as a result of Earth's orbital variation. Because changes in winter and summer tend to offset, the change in the annual average insolation at any given location is near zero, but the redistribution of energy between summer and winter does strongly affect the intensity of seasonal cycles. Such changes associated with the redistribution of solar energy are considered a likely cause for the coming and going of recent ice ages (see: Milankovitch cycles).\nSolar intensity variation.\nSpace-based observations of solar irradiance started in 1978. These measurements show that the solar constant is not constant. It varies on many time scales, including the 11-year sunspot solar cycle. When going further back in time, one has to rely on irradiance reconstructions, using sunspots for the past 400\u00a0years or cosmogenic radionuclides for going back\u00a010,000 years.\nSuch reconstructions have been done. These studies show that in addition to the solar irradiance variation with the solar cycle (the (Schwabe) cycle), the solar activity varies with longer cycles, such as the proposed 88 year (Gleisberg cycle), 208 year (DeVries cycle) and 1,000 year (Eddy cycle).\nSolar irradiance.\nSolar constant.\nThe solar constant is a measure of flux density, is the amount of incoming solar electromagnetic radiation per unit area that would be incident on a plane perpendicular to the rays, at a distance of one astronomical unit (AU) (roughly the mean distance from the Sun to Earth). The \"solar constant\" includes all types of solar radiation, not just the visible light. Its average value was thought to be approximately 1,366\u00a0W/m2, varying slightly with solar activity, but recent recalibrations of the relevant satellite observations indicate a value closer to 1,361\u00a0W/m2 is more realistic.\nTotal solar irradiance (TSI) and spectral solar irradiance (SSI) upon Earth.\nSince 1978, a series of overlapping NASA and ESA satellite experiments have measured total solar irradiance (TSI) \u2013 the amount of solar radiation received at the top of Earth's atmosphere \u2013 as 1.365 kilo\u2060watts per square meter (kW/m2). TSI observations continue with the ACRIMSAT/ACRIM3, SOHO/VIRGO and SORCE/TIM satellite experiments. Observations have revealed variation of TSI on many timescales, including the solar magnetic cycle and many shorter periodic cycles. TSI provides the energy that drives Earth's climate, so continuation of the TSI time-series database is critical to understanding the role of solar variability in climate change.\nSince 2003, the SORCE Spectral Irradiance Monitor (SIM) has monitored Spectral solar irradiance (SSI) \u2013 the spectral distribution of the TSI. Data indicate that SSI at UV (ultraviolet) wavelength corresponds in a less clear, and probably more complicated fashion, with Earth's climate responses than earlier assumed, fueling broad avenues of new research in \"the connection of the Sun and stratosphere, troposphere, biosphere, ocean, and Earth's climate\".\nSurface illumination and spectrum.\nThe spectrum of surface illumination depends upon solar elevation due to atmospheric effects, with the blue spectral component dominating during twilight before and after sunrise and sunset, respectively, and red dominating during sunrise and sunset. These effects are apparent in natural light photography where the principal source of illumination is sunlight as mediated by the atmosphere.\nWhile the color of the sky is usually determined by Rayleigh scattering, an exception occurs at sunset and twilight. \"Preferential absorption of sunlight by ozone over long horizon paths gives the zenith sky its blueness when the sun is near the horizon\".\nSpectral composition of sunlight at Earth's surface.\nThe Sun may be said to illuminate, which is a measure of the light within a specific sensitivity range. Many animals (including humans) have a sensitivity range of approximately 400\u2013700\u00a0nm, and given optimal conditions the absorption and scattering by Earth's atmosphere produces illumination that approximates an equal-energy illuminant for most of this range. The useful range for color vision in humans, for example, is approximately 450\u2013650\u00a0nm. Aside from effects that arise at sunset and sunrise, the spectral composition changes primarily in respect to how directly sunlight is able to illuminate. When illumination is indirect, Rayleigh scattering in the upper atmosphere will lead blue wavelengths to dominate. Water vapour in the lower atmosphere produces further scattering and ozone, dust and water particles will also absorb particular wavelengths.\nLife on Earth.\nThe existence of nearly all life on Earth is fueled by light from the Sun. Most autotrophs, such as plants, use the energy of sunlight, combined with carbon dioxide and water, to produce simple sugars\u2014a process known as photosynthesis. These sugars are then used as building-blocks and in other synthetic pathways that allow the organism to grow.\nHeterotrophs, such as animals, use light from the Sun indirectly by consuming the products of autotrophs, either by consuming autotrophs, by consuming their products, or by consuming other heterotrophs. The sugars and other molecular components produced by the autotrophs are then broken down, releasing stored solar energy, and giving the heterotroph the energy required for survival. This process is known as cellular respiration.\nIn prehistory, humans began to further extend this process by putting plant and animal materials to other uses. They used animal skins for warmth, for example, or wooden weapons to hunt. These skills allowed humans to harvest more of the sunlight than was possible through glycolysis alone, and human population began to grow.\nDuring the Neolithic Revolution, the domestication of plants and animals further increased human access to solar energy. Fields devoted to crops were enriched by inedible plant matter, providing sugars and nutrients for future harvests. Animals that had previously provided humans with only meat and tools once they were killed were now used for labour throughout their lives, fueled by grasses inedible to humans. Fossil fuels are the remnants of ancient plant and animal matter, formed using energy from sunlight and then trapped within Earth for millions of years.\nCultural aspects.\nThe effect of sunlight is relevant to painting, evidenced for instance in works of \u00c9douard Manet and Claude Monet on outdoor scenes and landscapes.\nMany people find direct sunlight to be too bright for comfort; indeed, looking directly at the Sun can cause long-term vision damage. To compensate for the brightness of sunlight, many people wear sunglasses. Cars, many helmets and caps are equipped with visors to block the Sun from direct vision when the Sun is at a low angle. Sunshine is often blocked from entering buildings through the use of walls, window blinds, awnings, shutters, curtains, or nearby shade trees. Sunshine exposure is needed biologically for the production of Vitamin D in the skin, a vital compound needed to make strong bone and muscle in the body.\nIn many world religions, such as Hinduism, the Sun is considered to be a god, as it is the source of life and energy on Earth. The Sun was also considered to be a god in Ancient Egypt.\nSunbathing.\nSunbathing is a popular leisure activity in which a person sits or lies in direct sunshine. People often sunbathe in comfortable places where there is ample sunlight. Some common places for sunbathing include beaches, open air swimming pools, parks, gardens, and sidewalk cafes. Sunbathers typically wear limited amounts of clothing or some simply go nude. For some, an alternative to sunbathing is the use of a sunbed that generates ultraviolet light and can be used indoors regardless of weather conditions. Tanning beds have been banned in a number of states in the world.\nFor many people with light skin, one purpose for sunbathing is to darken one's skin color (get a sun tan), as this is considered in some cultures to be attractive, associated with outdoor activity, vacations/holidays, and health. Some people prefer naked sunbathing so that an \"all-over\" or \"even\" tan can be obtained, sometimes as part of a specific lifestyle.\nControlled heliotherapy, or sunbathing, has been used as a treatment for psoriasis and other maladies.\nSkin tanning is achieved by an increase in the dark pigment inside skin cells called melanocytes, and is an automatic response mechanism of the body to sufficient exposure to ultraviolet radiation from the Sun or from artificial sunlamps. Thus, the tan gradually disappears with time, when one is no longer exposed to these sources.\nEffects on human health.\nThe ultraviolet radiation in sunlight has both positive and negative health effects, as it is both a principal source of vitamin D3 and a mutagen. A dietary supplement can supply vitamin D without this mutagenic effect, but bypasses natural mechanisms that would prevent overdoses of vitamin D generated internally from sunlight. Vitamin D has a wide range of positive health effects, which include strengthening bones and possibly inhibiting the growth of some cancers. Sun exposure has also been associated with the timing of melatonin synthesis, maintenance of normal circadian rhythms, and reduced risk of seasonal affective disorder.\nLong-term sunlight exposure is known to be associated with the development of skin cancer, skin aging, immune suppression, and eye diseases such as cataracts and macular degeneration. Short-term overexposure is the cause of sunburn, snow blindness, and solar retinopathy.\nUV rays, and therefore sunlight and sunlamps, are the only listed carcinogens that are known to have health benefits, and a number of public health organizations state that there needs to be a balance between the risks of having too much sunlight or too little. There is a general consensus that sunburn should always be avoided.\nEpidemiological data shows that people who have more exposure to sunlight have less high blood pressure and cardiovascular-related mortality. While sunlight (and its UV rays) are a risk factor for skin cancer, \"sun avoidance may carry more of a cost than benefit for over-all good health\". A study found that there is no evidence that UV reduces lifespan in contrast to other risk factors like smoking, alcohol and high blood pressure.\nEffect on plant genomes.\nElevated solar UV-B doses increase the frequency of DNA recombination in \"Arabidopsis thaliana\" and tobacco (\"Nicotiana tabacum\") plants. These increases are accompanied by strong induction of an enzyme with a key role in recombinational repair of DNA damage. Thus the level of terrestrial solar UV-B radiation likely affects genome stability in plants."}
{"id": "27980", "revid": "17839019", "url": "https://en.wikipedia.org/wiki?curid=27980", "title": "Stellar evolution", "text": "Changes to stars over their lifespans\nStellar evolution is the process by which a star changes over the course of time. Depending on the mass of the star, its lifetime can range from a few million years for the most massive to trillions of years for the least massive, which is considerably longer than the current age of the universe. The table shows the lifetimes of stars as a function of their masses. All stars are formed from collapsing clouds of gas and dust, often called nebulae or molecular clouds. Over the course of millions of years, these protostars settle down into a state of equilibrium, becoming what is known as a main sequence star.\nNuclear fusion powers a star for most of its existence. Initially the energy is generated by the fusion of hydrogen atoms at the core of the main-sequence star. Later, as the preponderance of atoms at the core becomes helium, stars like the Sun begin to fuse hydrogen along a spherical shell surrounding the core. This process causes the star to gradually grow in size, passing through the subgiant stage until it reaches the red-giant phase. Stars with at least half the mass of the Sun can also begin to generate energy through the fusion of helium at their core, whereas more-massive stars can fuse heavier elements along a series of concentric shells. Once a star like the Sun has exhausted its nuclear fuel, its core collapses into a dense white dwarf and the outer layers are expelled as a planetary nebula. Stars with around ten or more times the mass of the Sun can explode in a supernova as their inert iron cores collapse into an extremely dense neutron star or black hole. Although the universe is not old enough for any of the smallest red dwarfs to have reached the end of their existence, stellar models suggest they will slowly become brighter and hotter before running out of hydrogen fuel and becoming low-mass white dwarfs.\nStellar evolution is not studied by observing the life of a single star, as most stellar changes occur too slowly to be detected, even over many centuries. Instead, astrophysicists come to understand how stars evolve by observing numerous stars at various points in their lifetime, and by simulating stellar structure using computer models.\nStar formation.\nProtostar.\nStellar evolution starts with the gravitational collapse of a giant molecular cloud. Typical giant molecular clouds are roughly across and contain up to . As it collapses, a giant molecular cloud breaks into smaller and smaller pieces. In each of these fragments, the collapsing gas releases gravitational potential energy as heat. As its temperature and pressure increase, a fragment condenses into a rotating ball of superhot gas known as a protostar. Filamentary structures are truly ubiquitous in the molecular cloud. Dense molecular filaments will fragment into gravitationally bound cores, which are the precursors of stars. Continuous accretion of gas, geometrical bending, and magnetic fields may control the detailed fragmentation manner of the filaments. In supercritical filaments, observations have revealed quasi-periodic chains of dense cores with spacing comparable to the filament inner width, and embedded two protostars with gas outflows.\nA protostar continues to grow by accretion of gas and dust from the molecular cloud, becoming a pre-main-sequence star as it reaches its final mass. Further development is determined by its mass. Mass is typically compared to the mass of the Sun: means 1 solar mass.\nProtostars are encompassed in dust, and are thus more readily visible at infrared wavelengths.\nObservations from the Wide-field Infrared Survey Explorer (WISE) have been especially important for unveiling numerous galactic protostars and their parent star clusters.\nBrown dwarfs and sub-stellar objects.\nProtostars with masses less than roughly never reach temperatures high enough for nuclear fusion of hydrogen to begin. These are known as brown dwarfs. The International Astronomical Union defines brown dwarfs as stars massive enough to fuse deuterium at some point in their lives (13 Jupiter masses (MJ), 2.5\u00a0\u00d7\u00a01028\u00a0kg, or 0.0125\u00a0M\u2609). Objects smaller than 13\u00a0MJ are classified as sub-brown dwarfs (but if they orbit around another stellar object they are classified as planets). Both types, deuterium-burning and not, shine dimly and fade away slowly, cooling gradually over hundreds of millions of years.\nMain sequence stellar mass objects.\n &lt;imagemap&gt;\nImage:Zams and tracks.png\nWR\nLBV\nYHG\nBSG\nRSG\nAGB\nRG\n&lt;imagemap&gt;\nImage:Zams and tracks.png\nThe evolutionary tracks of stars with different initial masses on the Hertzsprung\u2013Russell diagram. The tracks start once the star has evolved to the main sequence and stop when fusion stops (for massive stars) and at the end of the red-giant branch (for stars 1\u00a0M\u2609 and less).A yellow track is shown for the Sun, which will become a red giant after its main-sequence phase ends before expanding further along the asymptotic giant branch, which will be the last phase in which the Sun undergoes fusion.\nFor a more-massive protostar, the core temperature will eventually reach 10 million kelvin, initiating the proton\u2013proton chain reaction and allowing hydrogen to fuse, first to deuterium and then to helium. In stars of slightly over , the carbon\u2013nitrogen\u2013oxygen fusion reaction (CNO cycle) contributes a large portion of the energy generation. The onset of nuclear fusion leads relatively quickly to a hydrostatic equilibrium in which energy released by the core maintains a high gas pressure, balancing the weight of the star's matter and preventing further gravitational collapse. The star thus evolves rapidly to a stable state, beginning the main-sequence phase of its evolution.\nA new star will sit at a specific point on the main sequence of the Hertzsprung\u2013Russell diagram, with the main-sequence spectral type depending upon the mass of the star. Small, relatively cold, low-mass red dwarfs fuse hydrogen slowly and will remain on the main sequence for hundreds of billions of years or longer, whereas massive, hot O-type stars will leave the main sequence after just a few million years. A mid-sized yellow dwarf star, like the Sun, will remain on the main sequence for about 10 billion years. The Sun is thought to be in the middle of its main sequence lifespan.\nPlanetary system.\nA star may gain a protoplanetary disk, which furthermore can develop into a planetary system.\nMature stars.\nEventually the star's core exhausts its supply of hydrogen and the star begins to evolve off the main sequence. Without the outward radiation pressure generated by the fusion of hydrogen to counteract the force of gravity, the core contracts until either electron degeneracy pressure becomes sufficient to oppose gravity or the core becomes hot enough (around 100 MK) for helium fusion to begin. Which of these happens first depends upon the star's mass.\nLow-mass stars.\nWhat happens after a low-mass star ceases to produce energy through fusion has not been directly observed; the universe is around 13.8 billion years old, which is less time (by several orders of magnitude, in some cases) than it takes for fusion to cease in such stars.\nRecent astrophysical models suggest that red dwarfs of 0.1\u00a0M\u2609 may stay on the main sequence for some six to twelve trillion years, gradually increasing in both temperature and luminosity, and take several hundred billion years more to collapse, slowly, into a white dwarf. Such stars will not become red giants as the whole star is a convection zone and it will not develop a degenerate helium core with a shell burning hydrogen. Instead, hydrogen fusion will proceed until almost the whole star is helium.\nSlightly more massive stars do expand into red giants, but their helium cores are not massive enough to reach the temperatures required for helium fusion so they never reach the tip of the red-giant branch. When hydrogen shell burning finishes, these stars move directly off the red-giant branch like a post-asymptotic-giant-branch (AGB) star, but at lower luminosity, to become a white dwarf. A star with an initial mass about 0.6\u00a0M\u2609 will be able to reach temperatures high enough to fuse helium, and these \"mid-sized\" stars go on to further stages of evolution beyond the red-giant branch.\nMid-sized stars.\nStars of roughly 0.6\u201310\u00a0M\u2609 become red giants, which are large non-main-sequence stars of stellar classification K or M. Red giants lie along the right edge of the Hertzsprung\u2013Russell diagram due to their red color and large luminosity. Examples include Aldebaran in the constellation Taurus and Arcturus in the constellation of Bo\u00f6tes.\nMid-sized stars are red giants during two different phases of their post-main-sequence evolution: red-giant-branch stars, with inert cores made of helium and hydrogen-burning shells, and asymptotic-giant-branch stars, with inert cores made of carbon and helium-burning shells inside the hydrogen-burning shells. Between these two phases, stars spend a period on the horizontal branch with a helium-fusing core. Many of these helium-fusing stars cluster towards the cool end of the horizontal branch as K-type giants and are referred to as red clump giants.\nSubgiant phase.\nWhen a star exhausts the hydrogen in its core, it leaves the main sequence and begins to fuse hydrogen in a shell outside the core. The core increases in mass as the shell produces more helium. Depending on the mass of the helium core, this continues for several million to one or two billion years, with the star expanding and cooling at a similar or slightly lower luminosity to its main sequence state. Eventually either the core becomes degenerate, in stars around the mass of the sun, or the outer layers cool sufficiently to become opaque, in more massive stars. Either of these changes cause the hydrogen shell to increase in temperature and the luminosity of the star to increase, at which point the star expands onto the red-giant branch.\nRed-giant-branch phase.\nThe expanding outer layers of the star are convective, with the material being mixed by turbulence from near the fusing regions up to the surface of the star. For all but the lowest-mass stars, the fused material has remained deep in the stellar interior prior to this point, so the convecting envelope makes fusion products visible at the star's surface for the first time. At this stage of evolution, the results are subtle, with the largest effects, alterations to the isotopes of hydrogen and helium, being unobservable. The effects of the CNO cycle appear at the surface during the first dredge-up, with lower 12C/13C ratios and altered proportions of carbon and nitrogen. These are detectable with spectroscopy and have been measured for many evolved stars.\nThe helium core continues to grow on the red-giant branch. It is no longer in thermal equilibrium, either degenerate or above the Sch\u00f6nberg\u2013Chandrasekhar limit, so it increases in temperature which causes the rate of fusion in the hydrogen shell to increase. The star increases in luminosity towards the tip of the red-giant branch. Red-giant-branch stars with a degenerate helium core all reach the tip with very similar core masses and very similar luminosities, although the more massive of the red giants become hot enough to ignite helium fusion before that point.\nHorizontal branch.\nIn the helium cores of stars in the 0.6 to 2.0 solar mass range, which are largely supported by electron degeneracy pressure, helium fusion will ignite on a timescale of days in a helium flash. In the nondegenerate cores of more massive stars, the ignition of helium fusion occurs relatively slowly with no flash. The nuclear power released during the helium flash is very large, on the order of 108 times the luminosity of the Sun for a few days and 1011 times the luminosity of the Sun (roughly the luminosity of the Milky Way Galaxy) for a few seconds. However, the energy is consumed by the thermal expansion of the initially degenerate core and thus cannot be seen from outside the star. Due to the expansion of the core, the hydrogen fusion in the overlying layers slows and total energy generation decreases. The star contracts, although not all the way to the main sequence, and it migrates to the horizontal branch on the Hertzsprung\u2013Russell diagram, gradually shrinking in radius and increasing its surface temperature.\nCore helium flash stars evolve to the red end of the horizontal branch but do not migrate to higher temperatures before they gain a degenerate carbon-oxygen core and start helium shell burning. These stars are often observed as a red clump of stars in the colour-magnitude diagram of a cluster, hotter and less luminous than the red giants. Higher-mass stars with larger helium cores move along the horizontal branch to higher temperatures, some becoming unstable pulsating stars in the yellow instability strip (RR Lyrae variables), whereas some become even hotter and can form a blue tail or blue hook to the horizontal branch. The morphology of the horizontal branch depends on parameters such as metallicity, age, and helium content, but the exact details are still being modelled.\nAsymptotic-giant-branch phase.\nAfter a star has consumed the helium at the core, hydrogen and helium fusion continues in shells around a hot core of carbon and oxygen. The star follows the asymptotic giant branch on the Hertzsprung\u2013Russell diagram, paralleling the original red-giant evolution, but with even faster energy generation (which lasts for a shorter time). Although helium is being burnt in a shell, the majority of the energy is produced by hydrogen burning in a shell further from the core of the star. Helium from these hydrogen burning shells drops towards the center of the star and periodically the energy output from the helium shell increases dramatically. This is known as a thermal pulse and they occur towards the end of the asymptotic-giant-branch phase, sometimes even into the post-asymptotic-giant-branch phase. Depending on mass and composition, there may be several to hundreds of thermal pulses.\nThere is a phase on the ascent of the asymptotic-giant-branch where a deep convective zone forms and can bring carbon from the core to the surface. This is known as the second dredge up, and in some stars there may even be a third dredge up. In this way a carbon star is formed, very cool and strongly reddened stars showing strong carbon lines in their spectra. A process known as hot bottom burning may convert carbon into oxygen and nitrogen before it can be dredged to the surface, and the interaction between these processes determines the observed luminosities and spectra of carbon stars in particular clusters.\nAnother well known class of asymptotic-giant-branch stars is the Mira variables, which pulsate with well-defined periods of tens to hundreds of days and large amplitudes up to about 10 magnitudes (in the visual, total luminosity changes by a much smaller amount). In more-massive stars the stars become more luminous and the pulsation period is longer, leading to enhanced mass loss, and the stars become heavily obscured at visual wavelengths. These stars can be observed as OH/IR stars, pulsating in the infrared and showing OH maser activity. These stars are clearly oxygen rich, in contrast to the carbon stars, but both must be produced by dredge ups.\nPost-AGB.\nThese mid-range stars ultimately reach the tip of the asymptotic-giant-branch and run out of fuel for shell burning. They are not sufficiently massive to start full-scale carbon fusion, so they contract again, going through a period of post-asymptotic-giant-branch superwind to produce a planetary nebula with an extremely hot central star. The central star then cools to a white dwarf. The expelled gas is relatively rich in heavy elements created within the star and may be particularly oxygen or carbon enriched, depending on the type of the star. The gas builds up in an expanding shell called a circumstellar envelope and cools as it moves away from the star, allowing dust particles and molecules to form. With the high infrared energy input from the central star, ideal conditions are formed in these circumstellar envelopes for maser excitation.\nIt is possible for thermal pulses to be produced once post-asymptotic-giant-branch evolution has begun, producing a variety of unusual and poorly understood stars known as born-again asymptotic-giant-branch stars. These may result in extreme horizontal-branch stars (subdwarf B stars), hydrogen deficient post-asymptotic-giant-branch stars, variable planetary nebula central stars, and R Coronae Borealis variables.\nMassive stars.\nIn massive stars, the core is already large enough at the onset of the hydrogen burning shell that helium ignition will occur before electron degeneracy pressure has a chance to become prevalent. Thus, when these stars expand and cool, they do not brighten as dramatically as lower-mass stars; however, they were more luminous on the main sequence and they evolve to highly luminous supergiants. Their cores become massive enough that they cannot support themselves by electron degeneracy and will eventually collapse to produce a neutron star or black hole.\nSupergiant evolution.\nExtremely massive stars (more than approximately 40\u00a0M\u2609), which are very luminous and thus have very rapid stellar winds, lose mass so rapidly due to radiation pressure that they tend to strip off their own envelopes before they can expand to become red supergiants, and thus retain extremely high surface temperatures (and blue-white color) from their main-sequence time onwards. The largest stars of the current generation are about 100\u2013150\u00a0M\u2609 because the outer layers would be expelled by the extreme radiation. Although lower-mass stars normally do not burn off their outer layers so rapidly, they can likewise avoid becoming red giants or red supergiants if they are in binary systems close enough so that the companion star strips off the envelope as it expands, or if they rotate rapidly enough so that convection extends all the way from the core to the surface, resulting in the absence of a separate core and envelope due to thorough mixing.\nThe core of a massive star, defined as the region depleted of hydrogen, grows hotter and denser as it accretes material from the fusion of hydrogen outside the core. In sufficiently massive stars, the core reaches temperatures and densities high enough to fuse carbon and heavier elements via the alpha process. At the end of helium fusion, the core of a star consists primarily of carbon and oxygen. In stars heavier than about 8\u00a0M\u2609, the carbon ignites and fuses to form neon, sodium, and magnesium. Stars somewhat less massive may partially ignite carbon, but they are unable to fully fuse the carbon before electron degeneracy sets in, and these stars will eventually leave an oxygen-neon-magnesium white dwarf.\nThe exact mass limit for full carbon burning depends on several factors such as metallicity and the detailed mass lost on the asymptotic giant branch, but is approximately 8\u20139\u00a0M\u2609. After carbon burning is complete, the core of these stars reaches about 2.5\u00a0M\u2609 and becomes hot enough for heavier elements to fuse. Before oxygen starts to fuse, neon begins to capture electrons which triggers neon burning. For a range of stars of approximately 8-12\u00a0M\u2609, this process is unstable and creates runaway fusion resulting in an electron capture supernova.\nIn more massive stars, the fusion of neon proceeds without a runaway deflagration. This is followed in turn by complete oxygen burning and silicon burning, producing a core consisting largely of iron-peak elements. Surrounding the core are shells of lighter elements still undergoing fusion. The timescale for complete fusion of a carbon core to an iron core is so short, just a few hundred years, that the outer layers of the star are unable to react and the appearance of the star is largely unchanged. The iron core grows until it reaches an \"effective Chandrasekhar mass\", higher than the formal Chandrasekhar mass due to various corrections for the relativistic effects, entropy, charge, and the surrounding envelope. The effective Chandrasekhar mass for an iron core varies from about 1.34\u00a0M\u2609 in the least massive red supergiants to more than 1.8\u00a0M\u2609 in more massive stars. Once this mass is reached, electrons begin to be captured into the iron-peak nuclei and the core becomes unable to support itself. The core collapses and the star is destroyed, either in a supernova or direct collapse to a black hole.\nSupernova.\nWhen the core of a massive star collapses, it will form a neutron star, or in the case of cores that exceed the Tolman\u2013Oppenheimer\u2013Volkoff limit, a black hole. Through a process that is not completely understood, some of the gravitational potential energy released by this core collapse is converted into a Type Ib, Type Ic, or Type II supernova. It is known that the core collapse produces a massive surge of neutrinos, as observed with supernova SN 1987A. The extremely energetic neutrinos fragment some nuclei; some of their energy is consumed in releasing nucleons, including neutrons, and some of their energy is transformed into heat and kinetic energy, thus augmenting the shock wave started by rebound of some of the infalling material from the collapse of the core. Electron capture in very dense parts of the infalling matter may produce additional neutrons. Because some of the rebounding matter is bombarded by the neutrons, some of its nuclei capture them, creating a spectrum of heavier-than-iron material including the radioactive elements up to (and likely beyond) uranium. Although non-exploding red giants can produce significant quantities of elements heavier than iron using neutrons released in side reactions of earlier nuclear reactions, the abundance of elements heavier than iron (and in particular, of certain isotopes of elements that have multiple stable or long-lived isotopes) produced in such reactions is quite different from that produced in a supernova. Neither abundance alone matches that found in the Solar System, so both supernovae, neutron star mergers and ejection of elements from red giants are required to explain the observed abundance of heavy elements and isotopes thereof.\nThe energy transferred from collapse of the core to rebounding material not only generates heavy elements, but provides for their acceleration well beyond escape velocity, thus causing a Type Ib, Type Ic, or Type II supernova. Current understanding of this energy transfer is still not satisfactory; although current computer models of Type Ib, Type Ic, and Type II supernovae account for part of the energy transfer, they are not able to account for enough energy transfer to produce the observed ejection of material. However, neutrino oscillations may play an important role in the energy transfer problem as they not only affect the energy available in a particular flavour of neutrinos but also through other general-relativistic effects on neutrinos.\nSome evidence gained from analysis of the mass and orbital parameters of binary neutron stars (which require two such supernovae) hints that the collapse of an oxygen-neon-magnesium core may produce a supernova that differs observably (in ways other than size) from a supernova produced by the collapse of an iron core.\nThe most massive stars that exist today may be completely destroyed by a supernova with an energy greatly exceeding its gravitational binding energy. This rare event, caused by pair-instability, leaves behind no black hole remnant. In the past history of the universe, some stars were even larger than the largest that exists today, and they would immediately collapse into a black hole at the end of their lives, due to photodisintegration.\nStellar remnants.\nAfter a star has burned out its fuel supply, its remnants can take one of three forms, depending on the mass during its lifetime.\nWhite and black dwarfs.\nFor a star of 1\u00a0M\u2609, the resulting white dwarf is of about 0.6\u00a0M\u2609, compressed into approximately the volume of the Earth. White dwarfs are stable because the inward pull of gravity is balanced by the degeneracy pressure of the star's electrons, a consequence of the Pauli exclusion principle. Electron degeneracy pressure provides a rather soft limit against further compression; therefore, for a given chemical composition, white dwarfs of higher mass have a smaller volume. With no fuel left to burn, the star radiates its remaining heat into space for billions of years.\nA white dwarf is very hot when it first forms, more than 100,000 K at the surface and even hotter in its interior. It is so hot that a lot of its energy is lost in the form of neutrinos for the first 10 million years of its existence and will have lost most of its energy after a billion years.\nThe chemical composition of the white dwarf depends upon its mass. A star that has a mass of about 8-12 solar masses will ignite carbon fusion to form magnesium, neon, and smaller amounts of other elements, resulting in a white dwarf composed chiefly of oxygen, neon, and magnesium, provided that it can lose enough mass to get below the Chandrasekhar limit (see below), and provided that the ignition of carbon is not so violent as to blow the star apart in a supernova. A star of mass on the order of magnitude of the Sun will be unable to ignite carbon fusion, and will produce a white dwarf composed chiefly of carbon and oxygen, and of mass too low to collapse unless matter is added to it later (see below). A star of less than about half the mass of the Sun will be unable to ignite helium fusion (as noted earlier), and will produce a white dwarf composed chiefly of helium.\nIn the end, all that remains is a cold dark mass sometimes called a black dwarf. However, the universe is not old enough for any black dwarfs to exist yet.\nIf the white dwarf's mass increases above the Chandrasekhar limit, which is 1.4\u00a0M\u2609 for a white dwarf composed chiefly of carbon, oxygen, neon, and/or magnesium, then electron degeneracy pressure fails due to electron capture and the star collapses. Depending upon the chemical composition and pre-collapse temperature in the center, this will lead either to collapse into a neutron star or runaway ignition of carbon and oxygen. Heavier elements favor continued core collapse, because they require a higher temperature to ignite, because electron capture onto these elements and their fusion products is easier; higher core temperatures favor runaway nuclear reaction, which halts core collapse and leads to a Type Ia supernova. These supernovae may be many times brighter than the Type II supernova marking the death of a massive star, even though the latter has the greater total energy release. This instability to collapse means that no white dwarf more massive than approximately 1.4\u00a0M\u2609 can exist (with a possible minor exception for very rapidly spinning white dwarfs, whose centrifugal force due to rotation partially counteracts the weight of their matter). Mass transfer in a binary system may cause an initially stable white dwarf to surpass the Chandrasekhar limit.\nIf a white dwarf forms a close binary system with another star, hydrogen from the larger companion may accrete around and onto a white dwarf until it gets hot enough to fuse in a runaway reaction at its surface, although the white dwarf remains below the Chandrasekhar limit. Such an explosion is termed a nova.\nNeutron stars.\nOrdinarily, atoms are mostly electron clouds by volume, with very compact nuclei at the center (proportionally, if atoms were the size of a football stadium, their nuclei would be the size of dust mites). When a stellar core collapses, the pressure causes electrons and protons to fuse by electron capture. Without electrons, which keep nuclei apart, the neutrons collapse into a dense ball (in some ways like a giant atomic nucleus), with a thin overlying layer of degenerate matter (chiefly iron unless matter of different composition is added later). The neutrons resist further compression by the Pauli exclusion principle, in a way analogous to electron degeneracy pressure, but stronger.\nThese stars, known as neutron stars, are extremely small\u2014on the order of radius 10\u00a0km, no bigger than the size of a large city\u2014and are phenomenally dense. Their period of rotation shortens dramatically as the stars shrink (due to conservation of angular momentum); observed rotational periods of neutron stars range from about 1.5 milliseconds (over 600 revolutions per second) to several seconds. When these rapidly rotating stars' magnetic poles are aligned with the Earth, there is a detectable pulse of radiation each revolution. Such neutron stars are called pulsars, and were the first neutron stars to be discovered. Though electromagnetic radiation detected from pulsars is most often in the form of radio waves, pulsars have also been detected at visible, X-ray, and gamma ray wavelengths.\nBlack holes.\nIf the mass of the stellar remnant is high enough, the neutron degeneracy pressure will be insufficient to prevent collapse below the Schwarzschild radius. The stellar remnant thus becomes a black hole. The mass at which this occurs is not known with certainty, but is currently estimated at between 2 and 3\u00a0M\u2609.\nBlack holes are predicted by the theory of general relativity. According to classical general relativity, no matter or information can flow from the interior of a black hole to an outside observer, although quantum effects may allow deviations from this strict rule. The existence of black holes in the universe is well supported, both theoretically and by astronomical observation.\nBecause the core-collapse mechanism of a supernova is, at present, only partially understood, it is still not known whether it is possible for a star to collapse directly to a black hole without producing a visible supernova, or whether some supernovae initially form unstable neutron stars which then collapse into black holes; the exact relation between the initial mass of the star and the final remnant is also not completely certain. Resolution of these uncertainties requires the analysis of more supernovae and supernova remnants.\nModels.\nA stellar evolutionary model is a mathematical model that can be used to compute the evolutionary phases of a star from its formation until it becomes a remnant. The mass and chemical composition of the star are used as the inputs, and the luminosity and surface temperature are the only constraints. The model formulae are based upon the physical understanding of the star, usually under the assumption of hydrostatic equilibrium. Extensive computer calculations are then run to determine the changing state of the star over time, yielding a table of data that can be used to determine the evolutionary track of the star across the Hertzsprung\u2013Russell diagram, along with other evolving properties. Accurate models can be used to estimate the current age of a star by comparing its physical properties with those of stars along a matching evolutionary track.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27982", "revid": "12118640", "url": "https://en.wikipedia.org/wiki?curid=27982", "title": "Snake River", "text": "Major river in the northwestern United States\nThe Snake River is a major river in the interior Pacific Northwest region of the United States. About long, it is the largest tributary of the Columbia River, which is the largest North American river that empties into the Pacific Ocean. Beginning in Yellowstone National Park, western Wyoming, it flows across the arid Snake River Plain of southern Idaho, the rugged Hells Canyon on the borders of Idaho, Oregon and Washington, and finally the rolling Palouse Hills of southeast Washington. It joins the Columbia River just downstream from the Tri-Cities, Washington, in the southern Columbia Basin.\nThe river's watershed, which drains parts of six U.S. states, is situated between the Rocky Mountains to the north and east, the Great Basin to the south, and the Blue Mountains and Oregon high desert to the west. The region has a long history of volcanism; millions of years ago, Columbia River basalts covered vast areas of the western Snake River watershed, while the Snake River Plain was a product of the Yellowstone volcanic hotspot. The river was further altered by catastrophic flooding in the most recent Ice Age, which created such features as the Snake River Canyon and Shoshone Falls.\nThe Snake River once hosted some of the largest North American runs of salmon and other anadromous fish. For thousands of years, salmon fishing has played a central role in the culture and diet of indigenous peoples. The Shoshone and Nez Perce were the largest of several tribes that lived along the river by the turn of the 19th century. In 1805, while searching for a route from the eastern US to the Pacific, Lewis and Clark became the first non-natives to see the river. Fur trappers explored more of the watershed, and drove beaver to near extinction as the Americans and British vied for control of Oregon Territory.\nAlthough travelers on the Oregon Trail initially shunned the dry and rocky Snake River region, a flood of settlers followed gold discoveries in the 1860s, leading to decades of military conflict and the eventual expulsion of tribes to reservations. At the turn of the 20th century, some of the first large irrigation projects in the western US were developed along the Snake River. South-central Idaho earned the nickname \"Magic Valley\" with the rapid transformation of desert into farmland. Numerous hydroelectric dams were also constructed, and four navigation dams on its lower section created a shipping channel to Lewiston, Idaho \u2013 the furthest inland seaport on the West Coast.\nWhile dam construction, commercial fishing and other human activities have greatly reduced anadromous fish populations since the late 19th century, the Snake River watershed is still considered important habitat for these fish. The Snake and its tributary, the Salmon River, host the longest sockeye salmon run in the world, stretching from the Pacific to Redfish Lake, Idaho. Since the 1950s, public agencies, tribal governments and private utilities have invested heavily in fishery restoration and hatchery programs, with limited success. The proposed removal of the four lower Snake River dams for fish passage is a significant ongoing policy debate in the Pacific Northwest.\nCourse.\nThe Snake River starts to the north of Two Ocean Pass near the southern border of Yellowstone National Park, about above sea level in the Rocky Mountains of Wyoming. The river descends west through the high mountains of the Teton Wilderness meeting the Lewis River and continuing south into Jackson Lake in Grand Teton National Park, a natural glacial lake enlarged by Jackson Lake Dam. Joined by Pacific Creek and Buffalo Fork below the dam, it meanders southward through the alpine valley of Jackson Hole situated on the plain in front of the Teton Range to the west and the Gros Ventre Range to the east. \nBelow the town of Jackson it forms the Snake River Canyon of Wyoming, turns west and crosses into Idaho, where the Palisades Dam forms Palisades Reservoir. From there it flows northwest through Swan Valley to join the Henrys Fork on an alluvial plain near Rexburg. The Henrys Fork is sometimes called the \"North Fork\" of the Snake River, while the section of the main Snake River above their confluence is sometimes called the \"South Fork\".\nTurning southwest, the river begins its long journey across the Snake River Plain, passing through Idaho Falls and receiving the Blackfoot River from the left before entering the -long American Falls Reservoir, formed by American Falls Dam. From American Falls it turns west, flowing through Minidoka Dam and Milner Dam, where large volumes of water are diverted for irrigation. Below Milner Dam it enters the Snake River Canyon of Idaho, where the river narrows, forming rapids and waterfalls. In the stretch between Milner Dam and the confluence with the Malad River near Hagerman Fossil Beds National Monument, the Snake River descends a total of over a series of cataracts and rapids, chief of which include Caldron Linn, Twin, Shoshone, Pillar, Auger, and Salmon Falls. Idaho Power operates several small hydroelectric plants along this stretch of the river. The largest single drop is Shoshone Falls, which in the spring flows with such force that 19th-century writers called it the \"Niagara of the West\".\nThe Snake River continues flowing west, through the C. J. Strike Reservoir where it is joined from the left by the Bruneau River, then through the Morley Nelson Snake River Birds of Prey National Conservation Area before entering farmland on the western side of Idaho's Treasure Valley. Passing west of Boise, it crosses briefly into Oregon before turning north to form the Oregon\u2013Idaho border. It is joined by several major tributaries in quick succession \u2013 the Boise River from the right, the Owyhee and Malheur Rivers from the left, the Payette and Weiser Rivers from the right near Ontario, Oregon, then the Powder and Burnt Rivers from the left. Continuing north, the river enters Hells Canyon, which slices between the Rocky Mountains of Idaho and the Blue Mountains of Oregon and Washington. The Hells Canyon Hydroelectric Complex includes the Brownlee, Oxbow and Hells Canyon Dams in the upper reaches of the canyon. Since its construction in 1967, Hells Canyon Dam has been the upriver limit for migrating salmon; in the past, salmon swam as far upriver as Shoshone Falls.\nEmerging from Hells Canyon Dam, the Snake surges northward through the Hells Canyon Wilderness, where the majority of the river corridor is accessible only by boat and numerous Class III-IV rapids historically posed a major barrier to navigation. Today, the canyon and the surrounding Hells Canyon National Recreation Area are a popular location for whitewater boating, fishing, horseback riding and backpacking. With the adjacent Seven Devils Mountains rising up to above the river, Hells Canyon is one of the deepest canyons in North America, almost one-third deeper than the Grand Canyon. Within the canyon it is joined from the left by the Imnaha River, then from the right by its longest tributary, the Salmon River. Further north, it begins to form the Idaho\u2013Washington border, and receives the Grande Ronde River from the left. From the end of Hells Canyon at Asotin, Washington, it flows north to Lewiston, Idaho, where it is joined from the right by the Clearwater River, its largest tributary by volume. The Snake then turns sharply west to enter Washington.\nThe final stretch of the Snake River flows through steep-sided valleys in the Palouse Hills of southeast Washington. Near Lyons Ferry State Park, it is joined from the left by the Tucannon River, then from the right by the Palouse River, which forms Palouse Falls about upstream of its confluence with the Snake. The Lower Snake River Project consists of four dams equipped with navigation locks \u2013 Lower Granite, Little Goose, Lower Monumental and Ice Harbor \u2013 which have transformed the once fast-flowing lower Snake River into a series of lakes, enabling heavy barges to travel between the Columbia River and the Port of Lewiston. About downstream from Ice Harbor Dam, the Snake empties into the Columbia River at Burbank, Washington, southeast of the Tri-Cities. The confluence is located on Lake Wallula, the impoundment behind McNary Dam on the Columbia, above sea level. From there, the Columbia River flows another west to empty into the Pacific Ocean.\nDischarge.\nThe U.S. Army Corps of Engineers has measured the discharge, or flow rate, of the Snake River at Ice Harbor Dam since 1962. The mean annual discharge for the 61-year period between 1962 and 2023 was , with a maximum recorded daily mean of on June 19, 1974, and a minimum daily mean of on November 29, 1961. A historic June 1894 flood at the Ice Harbor site reached an estimated peak of . In terms of discharge, the Snake River is the twelfth largest river in the United States, and it contributes about one-fifth of the Columbia's total outflow into the Pacific.\nThe volume of the Snake River peaks in late spring and early summer as snow melts in the Rocky Mountains, and reaches its lowest point in the fall. Despite the numerous dams regulating its flow, its discharge into the Columbia remains highly seasonal. At Ice Harbor Dam, the mean monthly discharge is highest in May and June at over , and lowest in September and October at less than . Mean annual discharge also fluctuates significantly, from a record high of in 1965, to a low of in 1997.\nIn southern Idaho, Snake River flows are significantly influenced by the Eastern Snake River Plain Aquifer. One of the largest groundwater reserves in the US, the aquifer is founded in porous volcanic rock underneath the plain. It absorbs and stores large volumes of water from the Snake River in the eastern Plain to re-emerge further west as springs in the Snake River Canyon. Water from the lost streams of Idaho, several rivers that disappear underground in the eastern Plain, travels through the aquifer to reach the Snake River, as does excess irrigation water absorbed into the ground. The major spring complexes at American Falls and Thousand Springs (near Hagerman, Idaho) keep the river flowing steadily even in the driest of summers. At King Hill, about northwest of Twin Falls, water levels remain about for most of the year, increasing about 20\u00a0percent during snowmelt and decreasing about 20\u00a0percent with late summer irrigation diversions.\nDespite its great length, the Snake River accumulates most of its water in the lower one-fourth of its course. By the time it reaches Hells Canyon Dam, from the mouth, the mean annual discharge is about \u2013 just over a third of the discharge at the mouth. Just two downstream tributaries, the Clearwater and Salmon Rivers, contribute about half of the total flow of the Snake.\nWatershed.\nThe Snake River watershed drains about 87\u00a0percent of the state of Idaho, 18\u00a0percent of Washington and 17\u00a0percent of Oregon, in addition to small portions of Wyoming, Utah and Nevada. From the Lost Trail Pass north of Salmon, Idaho to Tri-Basin Divide south of Afton, Wyoming, the eastern edge of the Snake River watershed follows the Continental Divide. As the Continental Divide also forms the Idaho\u2013Montana border south of Lost Trail Pass, the Snake watershed touches Montana for a long distance, but does not extend into it. The Snake drains by far the largest area of any Columbia River tributary, making up about 40\u00a0percent of the entire Columbia River watershed. Compared with the Columbia above their confluence, the Snake River is about longer and drains a similarly sized area, though the Columbia carries more than twice the volume of water.\nThe Snake River watershed is very mountainous, with the northern two-thirds of it occupied by vast mountain ranges of the Rockies, primarily the Salmon River Mountains of central Idaho and the Bitterroot Range along the Idaho\u2013Montana border. The Blue Mountains form much of the western boundary of the Snake watershed from southeast Washington down into Oregon. To the south are numerous small isolated mountain ranges of the Basin and Range Province, such as the Independence and Albion Mountains. To the east are more ranges of the Rockies including the Tetons and the Wind River Range; the latter includes Gannett Peak, the highest point in the Snake River basin at . Surface volcanic features \u2013 such as lava fields, cones, and thermal springs \u2013 are replete in the southern part of the Snake watershed, from Craters of the Moon National Monument northeast of Twin Falls to the Yellowstone caldera, while ancient lava flows of the Columbia River basalts underlie the western part of the watershed. The Snake River Plain is the largest area without mountains, but it still features rugged terrain, being crisscrossed by canyons formed by the Snake River and its tributaries.\nDue to the rain shadow effect of the Cascades, precipitation as a whole is scant, averaging across the entire watershed. Most precipitation falls at higher elevations as snow, thus, most runoff in the Snake River watershed derives from snowmelt. Jackson Hole, Wyoming experiences an alpine climate with an average of of rain and of snow. The coldest month is January, with a mean temperature of , and the hottest is July at . Twin Falls experiences a semi-arid climate, with about of rain and of snow. Monthly mean temperatures range from in January to in July. The Columbia Basin around the river's mouth also has a semi-arid climate, with about of rain and of snow as measured at Ice Harbor Dam. January is the coldest month with a mean temperature of , and July is the hottest month at .\nSemi-arid shrubland and rangeland covers about 50\u00a0percent of the Snake River watershed. Natural vegetation is primarily sagebrush, mixed with wheatgrasses and bunchgrasses. About 30\u00a0percent of the watershed is farmland; irrigated farming of potatoes, sugar beets, onions, cereal grains and alfalfa are dominant in the Snake River Plain, while the Palouse Hills of the northwest host mainly dryland wheat and legume production. About 15\u00a0percent of the watershed is forested, distributed across two temperate coniferous forest ecoregions: South Central Rockies forests, consisting primarily of Douglas fir, Engelmann spruce, subalpine fir, and lodgepole pine, and North Central Rockies forests, which include mountain hemlock, white spruce, alpine fir and western larch. About 4\u00a0percent of the watershed is barren desert, and only about 1\u00a0percent is urbanized.\nMost of the Snake River watershed is public land, with the U.S. Forest Service managing the Nez Perce, Clearwater, Bitterroot, Umatilla, Wallowa\u2013Whitman, Payette, Boise, Salmon\u2013Challis, Sawtooth, Caribou\u2013Targhee and Bridger\u2013Teton National Forests that cover much of the northern and eastern parts of the watershed. The forests contain numerous designated wilderness areas, including the Sawtooth, Selway\u2013Bitterroot, Frank Church-River of No Return, Gospel Hump, Hells Canyon, Teton and Gros Ventre. National Park Service land includes Craters of the Moon National Monument and Yellowstone and Grand Teton National Parks. Large areas of privately owned farmland are concentrated in the Snake River Plain and the Palouse, though the majority of the Snake River Plain is Bureau of Land Management land.\nThe Snake River watershed borders several other major North American watersheds. To the south it borders the endorheic Great Basin, including the area draining to Utah's Great Salt Lake. To the east it borders the watersheds of the Green River (part of the Colorado River system which drains to the Sea of Cortez) and the Yellowstone and upper Missouri Rivers (part of the Mississippi River system which drains to the Gulf of Mexico). On the north it borders the watersheds of the Clark Fork and Spokane Rivers, both part of the Columbia River system. To the northwest it borders several other tributary watersheds of the Columbia River, including those of the John Day and Umatilla Rivers.\nMajor tributaries.\nFifty-four named tributaries of the Snake River drain more than . Of these, the twelve listed below drain an area greater than .\nGeology.\nThe present-day course of the Snake River was pieced together over millions of years from several formerly disconnected drainage systems. Much of what would become the Pacific Northwest lay under shallow seas until it was uplifted starting about 60\u00a0million years ago (Ma). The outlet of the ancestral Columbia River to the Pacific was established about 40\u00a0Ma. By about 17\u00a0Ma, the \"Salmon-Clearwater River\", or the modern day lower Snake River, flowed west into the Columbia and on to the Pacific. Another ancient river system drained what is now the western Snake River Plain. Some geologists propose that this flowed to the Columbia on a course south of the present-day Blue Mountains, while others propose it drained towards Northern California. The Columbia River basalts, a series of massive flood basalt events that engulfed the Columbia Basin and surrounding lands, reshaped the landscape and erased most evidence of the pre-volcanic river channels starting about 17\u00a0Ma. Erupting from fissures in the southern Columbia Basin, the first basalt flows pushed the ancient Salmon-Clearwater much further north than its present course.\nAbout 12\u201310\u00a0Ma, the Blue Mountains region began to experience uplift, raising the basalt layers to form a plateau. From about 11\u20139\u00a0Ma, crustal deformation related to the Yellowstone hotspot caused the western half of the Snake River Plain near Boise to sink, creating a graben-type valley between parallel fault zones to the northeast and southwest. The outlet of the ancient Snake River was blocked, and water accumulated to form the vast Lake Idaho starting about 10 Ma. The eastern half of the Snake River Plain formed as the North American Plate moved westward over the Yellowstone hotspot. Upwelling magma caused the continental crust to rise, forming highlands in a similar fashion to the modern Yellowstone plateau and leaving behind enormous basalt flows in its wake.\nAs the hotspot migrated east relative to the North American Plate, the land behind it collapsed and sank, creating the geographic depression of the eastern Snake River Plain. The gradual eastward migration of this topographic high had the effect of pushing the Continental Divide to the east. Prior to the formation of the eastern Snake River Plain, the drainage area east of Arco, Idaho \u2013 the modern headwaters and upper course of the Snake River \u2013 flowed towards the Atlantic Ocean via the Mississippi River system. However, about 4.5 Ma, the eastward migrating Continental Divide tilted the regional slope such that drainage reversed, and flowed west into Lake Idaho. This was evidenced by an increase of water levels of Lake Idaho at that time. The Snake River Plain drainage system continued to expand east, towards what is now Yellowstone National Park. During this expansion, the Snake also captured the Bear River, which was later rerouted towards its modern outlet in the Great Salt Lake Basin about 50,000 or 60,000 years ago by lava flows in southeast Idaho.\nIn the Columbia Basin about 10.5\u00a0Ma, the Elephant Mountain basalt eruption forced the Salmon-Clearwater River into roughly its present course through southeast Washington. By 8.5\u00a0Ma the Salmon-Clearwater was established in the Columbia River's modern path through Wallula Gap, although the Columbia itself still flowed somewhere to the west, nearer to the Cascades south of Yakima. The last of the Columbia basalt flows occurred around 6\u00a0Ma; by then, the present-day confluence of the Columbia River and Salmon-Clearwater had been established, with the combined flow draining through Wallula Gap. About 2.5\u00a0Ma, Lake Idaho reached a maximum elevation of above modern sea level, and overflowed northward into the Salmon-Clearwater drainage near present-day Huntington, Oregon. Over a period of about two million years, the outflow carved Hells Canyon, emptying Lake Idaho and uniting the upper Snake and Salmon-Clearwater into a single river system.\nThe Teton Range, a defining topographic feature of the modern Snake River headwaters, first began to rise about 10\u00a0Ma as the Teton Fault began to move, displacing the mountain block upward as the surrounding land dropped. About 2\u00a0Ma, the Hoback Fault formed east of the Tetons, and a graben valley developed between the Hoback and Teton fault zones, creating Jackson Hole. As the valley dropped, water filled it to create Lake Teewinot, which drained east into the Green River\u2013Colorado River system. About 1 Ma, the Snake River captured the Jackson Hole watershed, draining Lake Teewinot instead of the Green River, and finally connecting the modern-day Snake headwaters to the rest of the river. This landscape around the Snake headwaters was sculpted by multiple Ice Age glaciations. Starting about 200,000 years ago, the Buffalo glaciation filled Jackson Hole to a depth of . Ice flowed down the Snake River Canyon all the way to Idaho. The Bull Lake glaciation, about 80,000\u201335,000 years ago, and the Pinedale glaciation, ending about 15,000 years ago, were much smaller and did not fill the entire valley. These glaciations carved the distinctive peaks of the Tetons into their present form and scoured lake basins in the valley floor, including modern-day Jackson Lake.\nWhile the Snake River course beyond Jackson Hole was not directly impacted by glaciations, its landscape was dramatically changed by Ice Age flooding events. About 30,000 years ago, the climate of western North America was much wetter than today. The Great Salt Lake Basin filled with water to form the massive Lake Bonneville, about the size of modern-day Lake Michigan. About 15,000 years ago the lip of Red Rock Pass south of present-day Pocatello, Idaho abruptly collapsed, releasing a tremendous volume of water from Lake Bonneville into the Snake River Plain. The peak of the flood was about 500 times bigger than the largest recorded flood of the Snake at Idaho Falls in modern times. The flood completely altered the landscape of the Snake River Plain, creating the Snake River Canyon and its waterfalls, vast boulder fields, cliffs and coulees. The floodwaters then emptied through Hells Canyon. \nHowever, most evidence of the Bonneville Floods on the lower Snake River was erased by the much larger Missoula Floods that engulfed the Columbia Basin during the same period. Caused by the repeated collapse of an ice dam in western Montana, dozens of floods back-flowed into the lower Snake River from the north, backing water as far upstream as Lewiston. The formerly west-flowing Palouse River was rerouted to flow south into the Snake River, forming Palouse Falls, whose outsized plunge pool attests to the force of the floods.\nHistory.\nIndigenous peoples.\nStarting around the end of the last glacial period, the Snake River Plain was inhabited by hunter-gatherers of the ancient Clovis (10000\u20139000 BCE), Folsom (9000\u20138000 BCE) and Plano (8600\u20135800 BCE) cultures. Along the lower Snake River in Washington, the Marmes Rockshelter \u2013 flooded in 1968 after the construction of Lower Monumental Dam \u2013 has yielded archeological evidence of continuous human occupation from about 9000\u00a0BCE until about 1300\u00a0CE. Starting about 2200\u00a0BCE, people in the western Snake River basin began to adopt a semi-sedentary lifestyle, with an increased reliance on fish (primarily salmon) and food preservation and storage. Shoshoni-speaking peoples arrived in the Snake River Plain between 600 and 1500\u00a0CE.\nBy the time of first European contact, the Snake River watershed was populated by several Native American tribes. The territory of the Nez Perce (Nimiipuu) stretched across what is now north-central Idaho, southeast Washington and northeast Oregon, including much of the lower Snake River below Hells Canyon, most of the Clearwater and Grande Ronde River, and the lower Salmon River. The Northern Shoshone and the Bannock, a Northern Paiute group that became culturally associated with the Shoshone, occupied an area stretching from the Snake River Plain east to the Rocky Mountains and south towards the Great Basin, as well as valleys of the upper Salmon River. A Nez Perce name for the river was \"Kimooenim\" or variations thereof, meaning \"the stream/place of the hemp weed\". Another Nez Perce name for the Snake River was \"Pik\u00faunen\", specifically referring to the stretch upstream of the Clearwater confluence. The Wanapum and Walla Walla people called the lower Snake River below the Clearwater \"Nax\u00edyam W\u00e1na\". The Shoshone called the river \"Yampapah\", after the \"yampah\" plant that grew profusely along its banks.\nDownriver of Shoshone Falls, salmon and their cousins such as steelhead trout \u2013 anadromous fish which spend their adult lives in the ocean, returning to fresh water to spawn \u2013 were a key food source for indigenous peoples, and were of great cultural importance. Rituals such as the first salmon ceremony were widely observed along the Columbia, Snake and other Northwest rivers, and so were strict catch limits, such that a healthy number of salmon would survive to reach their natal streams. The Nez Perce had more than seventy permanent villages among their fishing grounds on the Snake, Clearwater and Salmon Rivers. Clans gathered at communal fishing sites starting about May or June. Fishing moved from the lower rivers to higher elevation streams throughout the summer, while fall-run fish were preserved for winter use.\nShoshones in the western part of the Snake River Plain also depended heavily on the salmon run. At Shoshone Falls and the smaller cataracts downstream, fishing platforms, temporary brush weirs, spears, baskets and fish traps were employed at large scale. Captain Benjamin Bonneville in 1832 observed that \"Indians at Salmon Falls on the Snake River took several thousand salmon in one afternoon by means of spears.\" To the east and upriver of the falls, many Shoshone and Bannock lived in more nomadic groups, traveling to the falls during the spring salmon run then gathering camas bulbs and hunting bison through the summer and autumn months.\nThe Snake River at Hells Canyon formed a natural dividing line between the Nez Perce and Shoshone, who considered each other enemies. The Nez Perce allied with the Cayuse against the Shoshone, Bannock and Northern Paiute, and stopped the latter from expanding their territory towards the Columbia Plateau. Both the Nez Perce and Shoshone acquired horses in the late 1600s or early 1700s, enabling far-reaching trade and hunting expeditions. With horses, the Nez Perce were able to travel east of the Bitterroot Mountains to hunt bison, via the trail over Lolo Pass, which the Lewis and Clark expedition would later follow in order to reach the Snake and Columbia Rivers.\nOrigin of name.\nThe river's modern name comes from a misunderstanding of the Shoshone Tribal Sign in PISL. The Plains Indians referred to the Shoshone people as \"Snake People\", while the Shoshone are believed to have referred to themselves as \"People of the River of Many Fish\". However, the Shoshone sign for \"salmon\" was the same or similar to the Plains Indian common sign for \"snake.\" The English name for the river was likely derived from this interpretation of the hand gesture, although it is uncertain when the name was first used.\nExploration and fur trade.\nThe first Euro-Americans to reach the Snake River watershed were the Lewis and Clark Expedition, who in August 1805 crossed the Continental Divide at Lemhi Pass and descended to the Salmon River at what is now Salmon, Idaho, naming the stream \"Lewis's River\". Thwarted by the river's rapids, they were forced to cross the Bitterroot Mountains via the Nez Perce trail at Lolo Pass. After paddling down the \"Kooskooskee\" (Clearwater River), they reached the junction with the Snake and camped there with the Nez Perces on October 10, 1805. They correctly surmised that the river coming from the south was a continuation of \"Lewis's\" or Salmon River. The expedition journals note the Nez Perce called it \"Kimooenim\", although William Clark later erased mentions of the name to replace with \"Lewis's\". Six days later they reached the confluence of the Snake and Columbia Rivers, after noting a number of dangerous rapids as well as many native fishing sites on the lower Snake. The expedition established friendly relations with the Nez Perces, who they visited again on their return trip in 1806.\nOther explorers quickly followed, many of them fur trappers who began scouting the upper Snake River watershed for beaver. John Colter, a former member of the Lewis and Clark expedition, explored the Jackson Hole area in 1808. In 1810, Andrew Henry explored and named the Henrys Fork of the Snake River. He established Fort Henry, the first American fur trading post west of the Rocky Mountains, but abandoned it after that year's harsh winter. The 1811 Pacific Fur Company expedition led by Wilson Price Hunt attempted to find a route from Henrys Fork to the Columbia River. After suffering a wreck in the falls of the Snake River Canyon, they took an overland route through the Snake River Plain, through what is now the Boise Valley or Treasure Valley, then crossed the Blue Mountains to bypass Hells Canyon and reach the lower Snake River. After the hazardous experience, Hunt gave it the name \"Mad River\". A group led by Robert Stuart, a member of the Hunt expedition, returned eastward across the plain the following year. The route they mapped would eventually become that section of the Oregon Trail.\nIn 1818 Donald Mackenzie and Alexander Ross established Fort Nez Perc\u00e9s for the North West Company near the confluence of the Snake and Columbia Rivers. The following year, Mackenzie traveled up the Snake River and reached Boise Valley by making the first recorded river ascent of Hells Canyon. Mackenzie's goal was to bypass the arduous trek over the Blue Mountains. He wrote that \"the passage by water is now proved to be safe and practicable for loaded boats, without one single carrying place or portage; therefore, the doubtful question is set at rest forever. Yet from the force of the current and the frequency of rapids, it may still be advisable, and perhaps preferable, to continue the land transport.\"\nCanadian fur trappers with the British Hudson's Bay Company (HBC) reached the Snake River watershed in 1819. As American fur trappers kept coming to the region, the HBC ordered the Canadians to kill as many beavers as they could, under the rationale that \"if there are no beavers, there will be no reason for the Yanks to come,\" and even if the Americans did ultimately gain control, the HBC would already have taken all the profit. Focused primarily on the upper Snake River region, the \"fur desert\" policy was carried out in nine expeditions from about 1824\u20131831 and aimed to decrease the Americans' economic interest in the Oregon Country, the vast region of the Pacific Northwest centering on modern-day British Columbia, Washington, Oregon and Idaho. By the time the Americans annexed Oregon Territory in 1848, beaver were nearly extirpated across much of the Rocky Mountains.\nStarting in the 1840s, the Oregon Trail became well established, and thousands of settlers passed through the Snake River Plain on their way to the Willamette Valley. Coming from Wyoming, the Oregon Trail reached the Snake River at Fort Hall, Idaho, and stayed south of the river until Three Island Crossing near modern-day Glenns Ferry. Here the trail diverged, with the northern route fording the river to reach the HBC trading post at Fort Boise while the southern route continued into what is now the eastern Oregon desert. While the northern route passed through more favorable country, the Snake River posed a formidable barrier; during high water, many travelers were forced to take the hot, dry southern route, or risk drowning. Travelers going via Fort Boise had to cross the river one more time to rejoin the trail heading west. A ferry existed at Fort Boise since at least 1843; the Three Island crossing was also replaced by a ferry in 1869. A new wave of travelers came in the 1860s with the Montana Trail providing access to gold strikes in Montana Territory. This crossed the Snake River by the Eagle Rock Ferry and later a bridge which the city of Idaho Falls would soon grow around.\nConquest and conflict.\nAs the flow of settlers increased, the Nez Perce and their neighbors the Cayuse and Walla Walla came under pressure to cede portions of their territory. Tensions flared in 1855 after tribes were coerced into relinquishing huge amounts of territory in the Treaty of Walla Walla. In retaliation for Lt. Col. Edward Steptoe's defeat at the 1858 Battle of Pine Creek, a force led by Col. George Wright entered the lower Snake River country in 1859 and constructed Fort Taylor at the confluence of the Tucannon River below present-day Starbuck, Washington. Over several months Wright fought the natives along the river, killing their horses and destroying stored food. The sternwheeler \"Colonel Wright\" was commissioned to haul supplies up the Snake River to Fort Taylor. Captained by veteran Oregon river pilot Len White, the \"Wright\" was the first steamboat to run on the Snake River and the Columbia above The Dalles.\nTwo years later, Elias D. Pierce discovered gold to the east on Nez Perce treaty land. As thousands of fortune seekers flocked to the area, the city of Lewiston was founded in 1861, in violation of the 1855 treaty. The US government sided with the settlers, and pressured some Nez Perce leaders into signing a second treaty which shrank their reservation by 90\u00a0percent. Many Nez Perce including Chief Joseph's band refused to leave, calling the new treaty the \"thief treaty\". In March 1863, the Idaho Territory was split from Oregon, and Lewiston became its capital. More than 60,000 prospectors and others entered the Lewiston Valley by 1863. Many new steamboats were pressed into service, including the \"Spray\", \"Cascadilla\", \"Tenino\", \"Okanogan\", and \"Nez Perce Chief\". The river's rapids posed a major navigation hazard, and from November to April the river was generally too low for ships. Despite these challenges, the water transport of freight and passengers was greatly profitable.\nUp river, the Shoshone and other tribes were also becoming increasingly wary of settlers; in 1854 a Shoshone war party attacked a wagon train in the Boise Valley, and the U.S. Army mounted a counterattack, the Winnas Expedition. The situation became so unstable that Fort Boise was abandoned, and the Army had to escort wagon trains through the area. While early settlers had simply passed through this area on their way to Oregon, gold strikes brought renewed interest in the 1860s. The Army rebuilt Fort Boise further east of the original site in 1863. A military detachment was stationed there to quell any further violence; however, tensions continued to increase, and more wagon trains and mining parties were attacked. Starting in 1864, the Snake War was fought across much of southern Idaho, with numerous battles between the U.S. Army and the Shoshone, Bannock and Paiute. By 1868, exhausted after years of fighting, Chief Pocatello and many others surrendered and relocated to the Fort Hall Indian Reservation on the Snake River in southeast Idaho.\nTribal resistance would continue for years to come. In 1877 the US government attempted to force the remaining Nez Perce onto their reservation, at which point Chief Joseph's band and several others opted to seek refuge elsewhere. After a treacherous crossing of the Snake at Dug Bar, Hells Canyon on May 31, the Nez Perce were pursued by the Army for over east, through Yellowstone before turning north through Montana, fighting several battles along the way. On October 5, 1877, Chief Joseph surrendered to US forces, thus ending the Nez Perce War. The survivors were distributed to various reservations across the western US. In 1878, an uprising occurred in response to overcrowding and food shortages at the Fort Hall Reservation, leading to the Bannock War. The US army defeated the Bannock and their Paiute allies and proceeded to restrict travel in and out of the reservation.\nWhile Lewiston was now well connected by river, travel to Boise and other points upstream on the Snake River remained difficult due to the formidable obstacle of Hells Canyon. In 1865, Thomas Stump attempted to pilot the \"Colonel Wright\" up Hells Canyon, making it upriver before hitting rocks in a rapid, forcing their retreat. On the Snake River above Hells Canyon, several steamboats were built at great expense (as manufactured parts such as engines had to be hauled in overland), the first being the \"Shoshone\" in 1866. However, running the upper Snake proved unprofitable, due to lack of demand. The owners of \"Shoshone\" decided to move her to the lower Snake River, and in April 1870, they made the first successful river descent of Hells Canyon, a harrowing ride that skirted disaster several times. In 1895 the steamboat \"Norma\", which had been built to haul copper ore on the Snake River above Hells Canyon, also made the run under similar circumstances.\nIn the 1870s, Boise (to which Idaho's capital was moved in 1866) expanded rapidly as growth slowed in Lewiston. Gold drew more than 25,000 prospectors to the Boise Valley, and a new city quickly grew around the U.S. Army post at Fort Boise. With Hells Canyon impractical for river navigation, interest grew in connecting the area by rail. By 1884, the Oregon Railroad &amp; Navigation Company (later integrated into Union Pacific) had connected Portland, Oregon, to the Union Pacific line at Granger, Wyoming, via Huntington and Pocatello. Boise, initially bypassed due to a steep grade, was connected three years later. In addition to commerce, the railroad also opened the Snake River region \u2013 which just a few years ago had been seen as a remote, rough frontier \u2013 to recreation. The Union Pacific heavily promoted tourism in places like Shoshone Falls, Payette Lake and Soda Springs, Idaho. Countering the reputation of southern Idaho as a wasteland, a brochure described Shoshone Falls: \"Shoshone differs from every other waterfall in this or the old country. It is its lonely grandeur that impresses one so deeply; all of the other historic places have the adjuncts of civilization, and one is almost overshadowed by a city while in their presence.\"\nReclamation and development.\nIrrigation.\nMost travelers on the Oregon Trail regarded the arid Snake River Plain as an obstacle to be crossed, not a land to be settled. This began to change with the Boise gold strikes, where the demands of the mining industry and the difficulty of importing goods set off an agricultural boom in the Boise Valley. By the 1880s, settlers also came to the upper Snake River north of Idaho Falls, where fertile, sandy soils presented ideal conditions for the iconic russet potato (\"Idaho potato\"). The dry climate made irrigation necessary, and numerous private irrigation companies were formed. Private canal systems around Boise and Idaho Falls saw some success, but all the easily farmable land was soon developed, and they could not raise the capital for further expansion. In addition, low water by late summer posed a challenge to farmers, and the irrigation companies could not afford to build dams to provide water storage.\nWith many private irrigation companies verging on insolvency, the federal government began to explore programs assisting agricultural development. The 1894 Carey Act granted large tracts of dry federal land to western states, which then sold the land to farmers and solicited private investors to organize irrigation districts. Investors would then recoup their capital by selling water rights to farmers. Irrigation plans were reviewed by engineers, who determined the economic feasibility of the projects. Although the Carey Act saw little success in most states, it greatly benefited Idaho. Some 60\u00a0percent of all lands developed under the Carey Act were in Idaho, and almost all of that utilized Snake River water.\nI. B. Perrine, who homesteaded near Shoshone Falls in the 1880s, went on to develop one of the most successful Carey Act projects. In 1900 Perrine filed a claim for water from the Snake River, and backed by significant private capital, oversaw the construction of Milner Dam and a canal system to irrigate some of the Snake River Plain. Completed in 1905, the project was an immediate success. The rapid transformation of the barren landscape into productive farmland led to the moniker \"Magic Valley\", and led to massive growth of the city of Twin Falls. During certain times of the year, almost all the Snake River's flow was diverted at Milner Dam, and since then, Shoshone Falls has regularly run dry in the summer. The Idaho State Historical Society writes that \"Perrine\u2019s venture contrasted remarkably with private canal company failures that led to congressional provision for federal reclamation projects after 1902. As a rare successful example of state supervised private irrigation development provided for in [the Carey Act] of 1894, Milner Dam and its canal system have national significance in agricultural history.\"\nWith the creation of the Reclamation Service (now the Bureau of Reclamation) in 1902, the federal government began to play a more direct role in water resources development. The expansive Minidoka Project was the first federal reclamation project in Idaho. Starting with Minidoka Dam in 1906, the project would grow over the next few decades to include major reservoirs at Jackson Lake, American Falls and Island Park, and a large network of canals and pump stations. The Minidoka Project would eventually bring water to a million acres (2,500\u00a0km2) of the Magic Valley. During World War II, many Japanese Americans interned at Minidoka were made to work on the project. The Boise Project, which would ultimately water in and around the Boise Valley, was another major early reclamation undertaking. At its completion, Arrowrock Dam (1915) on the Boise River was the tallest dam in the world, and its construction process was an important prototype for future federal projects such as Hoover Dam.\nStarting around the 1950s, farmers made heavy use of the Snake River aquifer, bringing large new areas into production. Surface water development also increased with projects such as Cascade Dam (1948) and Anderson Ranch Dam (1950), which provided additional storage for the Boise Project. Palisades Dam was built in 1956, providing flood control and irrigation for the Snake River above Idaho Falls, an area which the Bureau of Reclamation had previously overlooked. Near Rexburg, the Teton Dam was also built to provide water for this area. In 1976, the Teton Dam failed catastrophically, killing eleven people and causing at least $400 million in damage along the Henrys Fork and Snake Rivers. The political fallout from this disaster marked the end of large new irrigation developments not only for the Snake River system, but for the Bureau of Reclamation as a whole. \nAgriculture has significantly impacted water quality in the Snake River upstream of Hells Canyon. Water removed from the river for irrigation becomes contaminated with chemical fertilizers and manure, and percolates into the Snake River Aquifer. Pollutants collect in the groundwater and eventually enter the river via spring flows. Excess nitrogen, phosphorus and bacterial loads occur in many locations across southern Idaho. Large algae blooms are a recurring issue in summer. The U.S. Environmental Protection Agency has established water quality guidelines for Snake River flows entering Hells Canyon, which cover bacteria, mercury, excess nutrients, pesticides, sediments and water temperature. Implementation of the guidelines include best management practices for agriculture and forestry, and regular water quality monitoring.\nHydroelectricity.\nPower development of the Snake River began in the early 20th century as cities, farms, mines and industry grew around the river. The first small hydroelectric plant on the Snake River, Swan Falls Dam, was built in 1901, followed by one at American Falls in 1902. Many other projects followed, particularly around Shoshone Falls where the natural drop of the river offered great energy potential. After developing the Milner Dam irrigation scheme, I. B. Perrine built a hydroelectric plant at Shoshone Falls in 1907. Small private utilities built power plants at Salmon Falls (1910) and Thousand Springs (1912). Idaho Power was incorporated in 1915, and acquired all the aforementioned plants the following year. It proceeded to build a second, larger plant at Shoshone Falls in 1921, and another plant at Twin Falls in 1935. The advent of electric pumps opened up large new areas to agriculture, which had previously been limited to land where water could flow by gravity. The Minidoka Project, which included the Bureau of Reclamation's first hydroelectric plant in Idaho, was an early adopter of this system. The project generated more power than it needed, and surplus was sold to nearby towns such as Burley and Rupert, which created their own municipal electric systems.\nBy the 1940s, following the construction of massive hydropower dams on the Columbia River such as Grand Coulee, interest turned to the considerable untapped power potential of the Snake River in Hells Canyon. In 1947, Idaho Power set its sights on the upper section of the canyon, where it proposed a series of three medium-sized dams. Two years later, the U.S. Army Corps of Engineers (Army Corps) proposed a single massive dam, over high, to be built in lower Hells Canyon. In 1955 the Federal Power Commission authorized the Idaho Power project, but initially only one of the three dams, Brownlee (completed 1958), was built. The other dams, located downstream, would have been in the flood zone of not only the Army Corps' high dam, but two other competing proposals.\nThe Pacific Northwest Power Company, a consortium of four private utilities, proposed the \"High Mountain Sheep Dam\" on the Snake River just upstream of the Salmon River. The even bigger \"Nez Perce Dam\", proposed by the Washington Public Power Supply System, would be located downstream of the Salmon River. While that location offered greater power potential, the fishery supported by the Salmon River was considered too economically valuable to wipe out, and in 1964 the Commission chose to authorize the High Mountain Sheep project. By then, significant public opposition had formed against the high dam, as it would still block salmon migration to the upper Snake, and adversely affect wildlife and recreational values in Hells Canyon. It was also challenged by Washington Public Power, which argued that the commission should give priority to public utilities over private ones.\nThe case reached the Supreme Court, which in the landmark 1967 ruling of \"Udall v. Federal Power Commission\" issued an injunction temporarily halting the project. Justice William O. Douglas wrote that in licensing projects, the Commission must consider \"future power demand and supply, alternate sources of power, the public interest in preserving reaches of wild rivers and wilderness areas, the preservation of anadromous fish for commercial and recreational purposes, and the protection of wildlife.\" This was the first time the court cited environmental protection as a consideration for whether to approve a dam project.\nIn 1975, President Gerald R. Ford signed the Hells Canyon Wilderness into law, ending the high dam project for good.\nMeanwhile, Idaho Power moved forward with the Oxbow and Hells Canyon Dams, though the question of fish passage still remained. From 1956 to 1964, returning adult salmon had been trapped at the base of Brownlee Dam (whose height made a fish ladder impractical) and released upstream. Downstream passage of juvenile salmon posed a much bigger problem; many were killed passing through the hydroelectric turbines, and efforts to trap and release them downstream met with failure. In 1960, Idaho Power proposed abandoning fish passage altogether and compensating for the loss by building fish hatcheries. By 1966 it reached an agreement with the Federal Power Commission to move forward with the hatchery plan, and by 1967 both Oxbow and Hells Canyon dams had been completed, neither with provision for fish passage. Idaho Power was tasked with building and operating the Oxbow, Rapid River, Niagara Springs and Pahsimeroi fish hatcheries at its own expense.\nAs of 2007, the Hells Canyon Hydroelectric Complex was responsible for 40\u00a0percent of Idaho Power's total power generation. The three dams have a capacity of 1,167 megawatts combined and produce about 6,053 gigawatt hours per year. Idaho Power's hatcheries produce almost seven million salmon and steelhead smolt to release in the Snake River system each year. Since the completion of the Hells Canyon complex, with the exception of the lower Snake River dams, only one major hydroelectric dam has been built in the Snake River system \u2013 the Army Corps' Dworshak Dam (1973), in the Clearwater River basin. Like the Hells Canyon dams, Dworshak also generated controversy over its impact on fisheries, and also made no provision for fish passage; rather, a hatchery was built at the base of the dam.\nNavigation.\nAs gold mining declined in the late 19th century, the wheat industry boomed in the Palouse of southeast Washington. By the 1870s, the Oregon Steam Navigation Company was operating seven steamboats transporting grain from the Snake River to lower Columbia River ports. These were the \"Harvest Queen\", \"John Gates\", \"Spokane\", \"Annie Faxon\", \"Mountain Queen\", \"R.R. Thompson\", and \"Wide West\". In the 1890s, a huge copper deposit was discovered at Eureka Bar in Hells Canyon. Several ships transported ore from there to Lewiston, including \"Imnaha\", \"Mountain Gem\", and \"Norma\". In 1893 the \"Annie Faxon\" suffered a boiler explosion and sank on the Snake below Lewiston, killing five people. Starting in the 1880s, the Army Corps began dredging the Snake River below Lewiston to maintain a deep navigation channel.\nRiver traffic declined rapidly once railroads arrived. By 1899, the Union Pacific line along the south bank of the Snake River had reached Riparia, Washington. It then joined forces with the Northern Pacific Railroad, which was building a line along the north bank, to build the shared Camas Prairie Railroad the rest of the way to Lewiston, which it reached in 1908. The Open River Transportation Company, which operated steamboats between Lewiston and Celilo Falls on the Columbia, went bankrupt in 1912. The 1915 completion of the Celilo Canal made it much easier for boats from the upper Columbia and Snake to reach Portland, and the Columbia River Transportation Company began operating a water route between Lewiston and Portland. Still, steamboats were unable to compete with railroads on speed and efficiency. The last steamboat on the lower Snake ran in 1920.\nOnce the railroads monopolized grain shipments, they raised shipping rates, to farmers' consternation. In 1934, political activist Herbert G. West organized the Inland Empire Waterways Association (IEWA), to promote an \"open river\" \u2013 a deep-water shipping channel on the Snake and Columbia Rivers that could compete with rail. The IEWA initially pushed for improvements such as bigger locks at Bonneville Dam in 1938 and the construction of McNary Dam on the Columbia, which would improve navigation to the mouth of the Snake. In 1941 a bill was first introduced in Congress authorizing the Army Corps to develop the lower Snake River. The 1941 bill failed, but after several years of debate, Congress finally authorized the Snake River development in 1945. Early plans included anywhere from six to ten low dams for the lower Snake. Eventually this was reduced to four bigger dams, which would lower costs, but would require what at the time were the tallest navigation locks in the world, at over .\nTribes, state wildlife agencies and the fishing industry opposed the dams, arguing that they would kill too many salmon. In 1947, the U.S. Department of the Interior proposed a ten-year moratorium on dam construction while the fishery problem was studied. With the onset of the Cold War, rising electricity demand in the Pacific Northwest \u2013 particularly at the nearby Hanford nuclear site \u2013 turned the project's focus towards hydropower. By 1948, the Army Corps estimated that over 80\u00a0percent of the economic benefits would come from power, and only 15\u00a0percent from navigation. Dam opponents countered that if the primary objective was now power, other dam sites existed in the Northwest that would have less impact on fish. These objections proved futile, as the lower Snake River dams were already authorized, and the federal government had little interest in studying alternatives. While opponents continued to stall the project for a few more years, Washington Senator Warren G. Magnuson pushed through a budget amendment in 1955 to start construction on the first dam, Ice Harbor.\nOnce construction began in 1956, Congress quickly approved more money to finish the project. Ice Harbor Dam was completed in 1962, and Lower Monumental and Little Goose Dams were completed in 1969 and 1970. The Lower Monumental project generated controversy as it threatened to flood the Marmes Rockshelter archeological site. Although the Army Corps agreed to build a dike around the site, it began to leak as the reservoir filled and the site was inundated. By the 1970s, the environmental movement in the US had become significantly larger, and groups such as the Association of Northwest Steelheaders lobbied to stop the construction of the fourth dam, Lower Granite. These efforts were unsuccessful, and the dam was completed in 1975. The first upriver barge reached Lewiston on April 10 of that year. The Army Corps had planned one more dam at Asotin, which would have extended navigation to mines upstream of Lewiston. Faced with public opposition, Congress deauthorized the project in 1975.\nOnce the dams were completed, barges up to 12,000 tonnes and drawing of water were able to reach Lewiston. Today, multiple barge terminals operate along the lower Snake, including Lewiston, Clarkston, Wilma, Central Ferry and Almota. Grain accounts for the majority of barge traffic on the river; other shipments include forestry products, fuel, chemicals and fertilizers. In 2020, a total of of cargo were barged on the Snake River. Since 2000, the tonnage of commercial shipping on the Snake River has declined, due mostly to the loss of petroleum products after a pipeline was constructed. After the general decline of the Great Recession, other sectors have been slow to recover. As of 2015, grain tonnage had fallen about a third from 2000 levels, while forestry products had fallen by nearly three-quarters, with many shipments switching back to rail. Container shipping at the Port of Lewiston ceased in 2015, due to its primary source, the Port of Portland, no longer receiving containers. From 2015 to 2023, grain exports from the Port of Lewiston have remained relatively steady while breakbulk cargo has increased.\nAs dam opponents had feared, Snake River salmon returns declined greatly after the dams were built. Since 2000, there have been renewed calls for removing the lower Snake River dams, which have become a significant political issue for the Pacific Northwest.\nEcology and environmental issues.\nAquatic habitats.\nThe World Wide Fund for Nature (WWF) divides the Snake River into two freshwater ecoregions \u2013 the Upper Snake and Columbia Unglaciated \u2013 with Shoshone Falls marking the boundary between the two. Shoshone Falls has presented a total barrier to the upstream movement of fish at least since the Bonneville flood 15,000 years ago. The Big Wood River (the main tributary of the Malad River) is also included in the Upper Snake ecoregion, due to the presence of a separate natural waterfall barrier. As a result, only 35\u00a0percent of the fish fauna above Shoshone falls, and 40\u00a0percent of the Big Wood River's fish fauna, are shared with the lower Snake River.\nCompared to the lower Snake River and the rest of the Columbia River system, the Upper Snake ecoregion has a high level of endemism, especially among freshwater molluscs such as snails and clams. At least 21 snail and clam species are of special concern, including 15 that appear to exist only in single clusters. There are 14 fish species found in the Upper Snake region that do not occur elsewhere in the Columbia's watershed, but which do occur in some western Utah watersheds and the Yellowstone River. These include healthy populations of Yellowstone cutthroat trout and Snake River fine-spotted cutthroat trout. The Wood River sculpin is endemic to the Wood River. The Shoshone sculpin is endemic to the small portion of the Snake River between Shoshone Falls and the Wood River.\nThe Snake River below Shoshone Falls is home to about 35 native fish species, of which 12 are also found in the Columbia River and four of which are endemic to the Snake or nearby watersheds: the sand roller, shorthead sculpin, margined sculpin and the Oregon chub, which also occurs in a few other Oregon streams. Bull trout migrate from the main stem of the Snake to spawn in several tributary basins, including the Bruneau, Imnaha and Grande Ronde Rivers. Large white sturgeon, introduced to the Snake River in the 19th century, were once widespread in the Snake River below Shoshone Falls; due to dam construction, only a few fragmented populations remain. The Idaho Department of Fish and Game has occasionally recorded sturgeon more than long in Hells Canyon. Other common introduced species include whitefish, pikeminnow, smallmouth bass, and rainbow, brown, brook and lake trout.\nAnadromous fish.\nAnadromous salmonids (\"Oncorhynchus\"), including chinook, coho, and sockeye salmon, and redband and steelhead trout, were historically the most abundant fish and a keystone species of the Snake River system. Benke and Cushing's \"Rivers of North America\" describes the Snake as a \"wild salmon factory;\" prior to the 19th century, between two and six million adult salmon and steelhead returned each year from the Pacific to spawn in the Snake River watershed. Salmon die after spawning, and their carcasses represent a crucial influx of organic matter to mountain rivers that have few natural nutrient sources. Tributaries below Hells Canyon, particularly the Salmon River, held the richest spawning grounds, although substantial numbers also made it above Hells Canyon as far as Shoshone Falls. The Snake River produced about 40\u00a0percent of all chinook salmon and 50\u00a0percent of all steelhead in the Columbia River watershed.\nPopulations of anadromous fish began to decline in the late 1800s due to the impact of commercial fishing, logging, mining and agriculture, but even in the 1930s, returning fall chinook alone numbered 500,000. Populations further collapsed once dams were built on the lower Snake and Columbia Rivers, and Hells Canyon Dam blocked access to the upper Snake. Wild Snake River spring and summer chinook returns declined from 130,000 in the 1950s to less than 5,000 in the 1990s. Wild steelhead returns followed a similar pattern, falling from 110,000 in the 1960s to less than 10,000 in the 1990s. Spring, summer and fall-run chinook were all listed as threatened in 1992. Snake River steelhead were also listed as threatened in 1997.\nWild chinook salmon and steelhead continued to decline into the 1990s, but have begun an unsteady recovery since 2000, with both chinook and steelhead returns up to 20,000\u201330,000 in some years. Coho salmon had disappeared from the Snake River by the 1980s, they were reintroduced to the watershed in 1995.\nSnake River sockeye once numbered to up 150,000 adults. Between 24,000 and 30,000 sockeye returned to Wallowa Lake in the Grande Ronde River watershed, but the run was eliminated by 1905 due to overharvest and unscreened irrigation diversions. The Payette Lake population once numbering up to 100,000 was blocked by the Black Canyon Dam in 1924. Sockeye in the Yellowbelly, Stanley, and Pettit Lakes of the Sawtooth basin were eradicated by management actions of the Idaho Department of Fish and Game in the 1950s, and irrigation diversions lead to the extirpation of the Pettit Lake population. Snake River sockeye returns declined to 4,500 in the 1950s and only a few dozen by the late 1960s. Snake River sockeye were listed as endangered in 1991.\nNumerous hatcheries are operated by agencies such as the Army Corps, Idaho Power, the Bonneville Power Administration, the U.S. Bureau of Indian Affairs and the U.S. Fish and Wildlife Service, to supplement wild fish populations. Hatcheries release about 33 million salmon and steelhead smolt into the Snake River watershed each year. However, the survival rate for hatchery fish is poor. Just 0.4\u00a0percent of hatchery chinook and 1.5\u00a0percent of hatchery steelhead returned as adults, as measured at Lower Granite Dam between 2007 and 2016.\nUpstream of the four lower dams, the Snake River watershed contains some of the best remaining spawning habitat in the Columbia River system, particularly along the Clearwater and Salmon Rivers; the latter is one of the longest undammed rivers in the continental US. A much depleted sockeye salmon run continues to spawn in Redfish Lake near Stanley, Idaho, more than inland from the Pacific Ocean. This represents the southernmost, highest elevation and longest sockeye run in the world.\nTerrestrial and wetland habitats.\nThe Snake River provides important wildlife habitat along much of its course, particularly in the arid Snake River Plain where it is the only source of water for many miles. The upper reaches of the Snake River, including in Jackson Hole and the floodplain north of Idaho Falls where it joins the Henrys Fork, have extensive riparian gallery forests dominated by black cottonwood and narrowleaf cottonwood. The Northwest Power and Conservation Council describes these as \"some of the most important cottonwood gallery forests in the Intermountain West\". Seasonal floods scour and change the shoreline, clearing areas of older trees and making way for new growth. Ute lady's tresses, a rare orchid, are found in riparian wetlands along with willows, rushes, sedges and horsetails.\nThe Fort Hall Bottoms in the southern Snake River Plain are an important wetland along the river, and create a major wintering and nesting site for waterfowl, shorebirds and raptors, including bald eagles and trumpeter swans. Part of these wetlands were flooded with the construction of American Falls Dam, and large portions of the remainder have been degraded by cattle grazing. Ponds and wetlands in the Hagerman Valley, near the Hagerman Fossil Beds National Monument, are also heavily used by both migratory and resident birds. On the Snake River south of Boise is the nearly Morley Nelson Snake River Birds of Prey National Conservation Area, which hosts the densest concentration of nesting raptors in the US.\nThe Snake River headwaters are part of the Greater Yellowstone Ecosystem, which the National Park Service describes as \"one of the largest nearly intact temperate-zone ecosystems on Earth.\" The region is home to some of the largest wild elk and bison populations in the US, and provides habitat for grizzly bear, wolverine and lynx. The other major wild area in the Snake River watershed centers on Idaho's extremely rugged Frank Church\u2013River of No Return Wilderness, the largest federally designated wilderness in the contiguous US. Although the Snake River watershed remains lightly populated, most of its landscape has seen significant human impact since the 19th century. Heavy logging has historically occurred in the Boise area and on the Clearwater River, which hosted the last whitewater log drive in the US in 1971. Logging is still a major industry in the region, though since the 1990s, logging south of the Clearwater has decreased. Large areas of native sagebrush-steppe ecosystems, mostly in the Snake River Plain and Palouse, have been developed for agriculture. About two-thirds of the Snake River Plain remains grassland or shrubland; however, much of this acreage is impacted by livestock grazing, and fire regimes have become more severe with the proliferation of invasive species like cheatgrass.\nProposed dam removal.\nThe lower Snake River dams have remained controversial since their construction, and in the 21st century there has been increased debate over potentially removing the dams. Although the dams were built with fish ladders, the warm, slow-moving water in reservoirs disoriented migrating fish, and juvenile fish experienced significant mortality passing through the dams. In 1980 Congress passed the Northwest Power Act, which requires federal agencies in the Northwest to mitigate the impact of their dams on fish and wildlife. While installation of fish screens and bypasses have improved survival rates for juvenile fish, efforts to capture fish and transport them around the dams have seen little success. Although wild salmonid returns have seen a positive trend since their nadir in the 1990s, they remain well below pre-dam levels.\nSupporters of dam removal, which include tribal organizations such as the Columbia River Inter-Tribal Fish Commission and environmental advocacy groups such as the Natural Resources Defense Council and the Sierra Club, argue that the most economical way to restore the fishery is to remove the dams, rather than continuing recovery efforts at great expense. As of 2023, over $17 billion had been spent on Snake River salmon recovery and hatchery operations. There are other economic arguments for dam removal, particularly that the annual cost of maintaining the barge channel exceeds the economic benefits provided by shipping, and the freight can be moved by rail instead. Furthermore, the dams only account for a small percentage of the total hydropower in the Northwest. A University of Idaho analysis estimated that over a 20-year period, removing the dams would be less expensive than the cost of continuing fish recovery efforts with the dams in place. Representative Mike Simpson (R-ID) has been a major supporter of dam removal, and in 2021 put forth an ambitious proposal to remove the dams, though Simpson's plan has come under scrutiny as among other actions, it would also impose \"a 35-year moratorium on litigation related to anadromous fish\" at federal Columbia River Basin dams.\nOpponents of dam removal include farmers, local governments such as the city of Lewiston, congressional representatives in eastern Washington and the Bonneville Power Administration, which manages federal hydroelectric dams in the Northwest. In the context of shipping, while river traffic has declined in recent years, it remains important to the area's economy, and moving cargo by barge is cheaper and twice as fuel-efficient as diesel trains. While the dams do not generate much baseload power, they are crucial to managing peak demand on a daily basis, as hydropower can be ramped up and down quickly. As more wind and solar energy is added to the Northwest grid, more load balancing will be needed to compensate for the intermittent nature of those sources. Although Washington governor Jay Inslee and Washington Senator Patty Murray have tentatively endorsed dam removal, they stressed that hydropower must be replaced by other renewable sources, and economic impacts such as the loss of the ship channel should be \"mitigated or replaced.\"\nIn December 2023, the Biden administration expressed its support for the Columbia Basin Restoration Initiative, which would develop a strategy to replace the power and navigation benefits provided by the Snake River dams, and explore options for post-dam river restoration. The initiative is an agreement between the federal government, four tribal nations, the states of Washington and Oregon, and several conservation groups. It would not authorize the removal of the dams, which would require a separate act of Congress.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27983", "revid": "13220696", "url": "https://en.wikipedia.org/wiki?curid=27983", "title": "Surd", "text": "Surd may refer to:\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "27984", "revid": "1316943335", "url": "https://en.wikipedia.org/wiki?curid=27984", "title": "Strong interaction", "text": "Binding of quarks in subatomic particles\nIn nuclear physics and particle physics, the strong interaction, also called the strong force or strong nuclear force, is one of the four known fundamental interactions. It confines quarks into protons, neutrons, and other hadron particles, and also binds neutrons and protons to create atomic nuclei, where it is called the nuclear force.\nMost of the mass of a proton or neutron is the result of the strong interaction energy; the individual quarks provide only about 1% of the mass of a proton. At the range of 10\u221215\u00a0m (1 femtometer, slightly more than the radius of a nucleon), the strong force is approximately 100 times as strong as electromagnetism, 106 times as strong as the weak interaction, and 1038 times as strong as gravitation.\nIn the context of atomic nuclei, the force binds protons and neutrons together to form a nucleus and is called the nuclear force (or \"residual strong force\"). Because the force is mediated by massive, short lived mesons on this scale, the residual strong interaction obeys a distance-dependent behavior between nucleons that is quite different from when it is acting to bind quarks within hadrons. There are also differences in the binding energies of the nuclear force with regard to nuclear fusion versus nuclear fission. Nuclear fusion accounts for most energy production in the Sun and other stars. Nuclear fission allows for decay of radioactive elements and isotopes, although it is often mediated by the weak interaction. Artificially, the energy associated with the nuclear force is partially released in nuclear power and nuclear weapons, both in uranium or plutonium-based fission weapons and in fusion weapons like the hydrogen bomb.\nHistory.\nBefore 1971, physicists were uncertain as to how the atomic nucleus was bound together. It was known that the nucleus was composed of protons and neutrons and that protons possessed positive electric charge, while neutrons were electrically neutral. Based on established principles of electromagnetism, positive charges would be expected to repel one another and the positively charged protons would be expected to cause the nucleus to fly apart. However, this was never observed. New discoveries in physics were needed to explain this phenomenon.\nA stronger attractive force was postulated to explain how the atomic nucleus was bound despite the protons' mutual electromagnetic repulsion. This hypothesized force was called the \"strong force\", which was believed to be a fundamental force that acted on the protons and neutrons that make up the nucleus.\nIn 1964, Murray Gell-Mann, and separately George Zweig, proposed that baryons, which include protons and neutrons, and mesons were composed of elementary particles. Zweig called the elementary particles \"aces\" while Gell-Mann called them \"quarks\"; the theory came to be called the quark model. The strong attraction between nucleons was the side-effect of a more fundamental force that bound the quarks together into protons and neutrons. The theory of quantum chromodynamics explains that quarks carry what is called a color charge, although it has no relation to visible color. Quarks with unlike color charge attract one another as a result of the strong interaction, and the particle that mediates this was called the gluon.\nBehavior of the strong interaction.\nThe strong interaction is observable at two ranges, and mediated by different force carriers in each one. On a scale less than about 0.8\u00a0fm (roughly the radius of a nucleon), the force is carried by gluons and holds quarks together to form protons, neutrons, and other hadrons. On a larger scale, up to about 3\u00a0fm, the force is carried by mesons and binds nucleons (protons and neutrons) together to form the nucleus of an atom. In the former context, it is often known as the color force, and is so strong that if hadrons are struck by high-energy particles, they produce jets of massive particles instead of emitting their constituents (quarks and gluons) as freely moving particles. This property of the strong force is called color confinement.\nWithin hadrons.\nThe word \"strong\" is used since the strong interaction is the \"strongest\" of the four fundamental forces. At a distance of 10\u221215\u00a0m, its strength is around 100\u00a0times that of the electromagnetic force, some 106\u00a0times as great as that of the weak force, and about 1038\u00a0times that of gravitation.\nThe strong force is described by quantum chromodynamics (QCD), a part of the Standard Model of particle physics. Mathematically, QCD is a non-abelian gauge theory based on a local (gauge) symmetry group called SU(3).\nThe force carrier particle of the strong interaction is the gluon, a massless gauge boson. Gluons are thought to interact with quarks and other gluons by way of a type of charge called color charge. Color charge is analogous to electromagnetic charge, but it comes in three types (\u00b1red, \u00b1green, and \u00b1blue) rather than one, which results in different rules of behavior. These rules are described by quantum chromodynamics (QCD), the theory of quark\u2013gluon interactions.\nUnlike the photon in electromagnetism, which is neutral, the gluon carries a color charge. Quarks and gluons are the only fundamental particles that carry non-vanishing color charge, and hence they participate in strong interactions only with each other. The strong force is the expression of the gluon interaction with other quark and gluon particles.\nAll quarks and gluons in QCD interact with each other through the strong force. The strength of interaction is parameterized by the strong coupling constant. This strength is modified by the gauge color charge of the particle, a group-theoretical property.\nThe strong force acts between quarks. Unlike all other forces (electromagnetic, weak, and gravitational), the strong force does not diminish in strength with increasing distance between pairs of quarks. After a limiting distance (about the size of a hadron) has been reached, it remains at a strength of about , no matter how much farther the distance between the quarks. As the separation between the quarks grows, the energy added to the pair creates new pairs of matching quarks between the original two; hence it is impossible to isolate quarks. The explanation is that the amount of work done against a force of is enough to create particle\u2013antiparticle pairs within a very short distance. The energy added to the system by pulling two quarks apart would create a pair of new quarks that will pair up with the original ones. In QCD, this phenomenon is called color confinement; as a result, only hadrons, not individual free quarks, can be observed. The failure of all experiments that have searched for free quarks is considered to be evidence of this phenomenon.\nThe elementary quark and gluon particles involved in a high energy collision are not directly observable. The interaction produces jets of newly created hadrons that are observable. Those hadrons are created, as a manifestation of mass\u2013energy equivalence, when sufficient energy is deposited into a quark\u2013quark bond, as when a quark in one proton is struck by a very fast quark of another impacting proton during a particle accelerator experiment. However, quark\u2013gluon plasmas have been observed.\nBetween hadrons.\nWhile color confinement implies that the strong force acts without distance-diminishment between pairs of quarks in compact collections of bound quarks (hadrons), at distances approaching or greater than the radius of a proton, a residual force (described below) remains. It manifests as a force between the \"colorless\" hadrons, and is known as the \"nuclear force\" or \"residual strong force\" (and historically as the \"strong nuclear force\").\nThe nuclear force acts between hadrons, known as mesons and baryons. This \"residual strong force\", acting indirectly, transmits gluons that form part of the virtual \u03c0 and \u03c1\u00a0mesons, which, in turn, transmit the force between nucleons that holds the nucleus (beyond hydrogen-1 nucleus) together.\nThe residual strong force is thus a minor residuum of the strong force that binds quarks together into protons and neutrons. This same force is much weaker \"between\" neutrons and protons, because it is mostly neutralized \"within\" them, in the same way that electromagnetic forces between neutral atoms (van der Waals forces) are much weaker than the electromagnetic forces that hold electrons in association with the nucleus, forming the atoms.\nUnlike the strong force, the residual strong force diminishes with distance, and does so rapidly. The decrease is approximately as a negative exponential power of distance, though there is no simple expression known for this; see \"Yukawa potential\". The rapid decrease with distance of the attractive residual force and the less rapid decrease of the repulsive electromagnetic force acting between protons within a nucleus, causes the instability of larger atomic nuclei, such as all those with atomic numbers larger than 82 (the element lead).\nAlthough the nuclear force is weaker than the strong interaction itself, it is still highly energetic: transitions produce gamma rays. The mass of a nucleus is significantly different from the summed masses of the individual nucleons. This mass defect is due to the potential energy associated with the nuclear force. Differences between mass defects power nuclear fusion and nuclear fission.\nUnification.\nThe so-called Grand Unified Theories (GUT) aim to describe the strong interaction and the electroweak interaction as aspects of a single force, similarly to how the electromagnetic and weak interactions were unified by the Glashow\u2013Weinberg\u2013Salam model into electroweak interaction. The strong interaction has a property called asymptotic freedom, wherein the strength of the strong force diminishes at higher energies (or temperatures). The theorized energy where its strength becomes equal to the electroweak interaction is the grand unification energy. However, no Grand Unified Theory has yet been successfully formulated to describe this process, and Grand Unification remains an unsolved problem in physics.\nIf GUT is correct, after the Big Bang and during the electroweak epoch of the universe, the electroweak force separated from the strong force. Accordingly, a grand unification epoch is hypothesized to have existed prior to this.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27985", "revid": "11896266", "url": "https://en.wikipedia.org/wiki?curid=27985", "title": "Singing in the Rain", "text": ""}
{"id": "27987", "revid": "9092818", "url": "https://en.wikipedia.org/wiki?curid=27987", "title": "Strong nuclear force", "text": ""}
{"id": "27988", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=27988", "title": "Seidhr", "text": ""}
{"id": "27989", "revid": "50608147", "url": "https://en.wikipedia.org/wiki?curid=27989", "title": "September 3", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearSeptember 3 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27990", "revid": "46051904", "url": "https://en.wikipedia.org/wiki?curid=27990", "title": "September 5", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearSeptember 5 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27991", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=27991", "title": "Stout", "text": "Style of dark beer\nStout is a type of dark beer that is generally warm fermented, such as dry stout, oatmeal stout, milk stout and imperial stout. \nThe first known use of the word \"stout\" for beer is in a document dated 1677 in the Egerton Manuscripts, referring to its strength. Porters were brewed to a variety of strengths, with the stronger beers called \"stout porters\". The history and development of stout and porter are thus intertwined.\nHistory.\nPorter originated in London, England in the early 1720s. The beer became popular in the city, especially with porters (hence its name): it had a strong flavour, took longer to spoil than other beers, was significantly cheaper than other beers, and was not easily affected by heat. Within a few decades, porter breweries in London had grown \"beyond any previously known scale\". Large volumes were exported to Ireland and by 1776 it was being brewed by Arthur Guinness at his St. James's Gate Brewery. In the 19th century, the beer gained its customary black colour through the use of black patent malt, and became stronger in flavour.\nOriginally the adjective \"stout\" meant \"proud\" or \"brave\", but after the 14th century it took on the connotation of \"strong\". The first known use of the word \"stout\" for beer was in a document dated 1677 found in the Egerton Manuscript, the sense being that a stout beer was a strong beer. The expression \"stout porter\" was applied during the 18th century to strong versions of porter. \"Stout\" still meant only \"strong\" and it could be related to any kind of beer, as long as it was strong: in the UK it was possible to find \"stout pale ale\", for example. Later, \"stout\" was eventually to be associated only with porter, becoming a synonym of dark beer.\nBecause of the huge popularity of porters, brewers made them in a variety of strengths. The beers with higher gravities were called \"Stout Porters\". There is still division and debate on whether stouts should be a separate style from porter. Usually the only deciding factor is strength.\n\"Nourishing\" and sweet \"milk\" stouts became popular in Great Britain in the years following the First World War, though their popularity declined towards the end of the 20th century, apart from pockets of local interest such as in Glasgow with Sweetheart Stout.\nBeer writer Michael Jackson wrote about stouts and porters in the 1970s, but in the mid 1980s a survey by \"What's Brewing\" found just 29 brewers in the UK and Channel Islands still making stout, most of them milk stouts. In the 21st century, stout is making a comeback with a new generation of drinkers, thanks to new products from burgeoning craft and regional brewers.\nMilk stout.\n\"Milk stout\" (also called \"sweet stout\" or \"cream stout\") is a stout containing lactose, a sugar derived from milk. Because lactose cannot be fermented by beer yeast, it adds sweetness and perceived body to the finished beer. \nMilk stout has historically been claimed to be nutritious, advertised to nursing mothers as helping to increase their milk production. An archetypical surviving example of milk stout is Mackeson's, for which the original brewers advertised that \"each pint contains the energising carbohydrates of 10 ounces [1/2 pint, 284\u00a0ml] of pure dairy milk.\" The style was rare until being revived by a number of craft breweries in the twenty-first century.\nWell known examples include the Bristol Beer Factory Milk Stout, the Left Hand Milk Stout and the Lancaster Milk Stout.\nThere were prosecutions in Newcastle upon Tyne in 1944 under the Food and Drugs Act 1938 regarding misleading labelling of milk stout.\nIrish stout.\nWith sweet stouts becoming the dominant stout in the UK in the early 20th century, it was mainly in Ireland that the non-sweet or standard stout was being made. As standard stout has a drier taste than the English and American sweet stouts, they came to be called \"dry stout\" or \"Irish stout\" to differentiate them from stouts with added lactose or oatmeal. This is the style that represents a typical stout to most people. The best selling stouts worldwide are Irish stouts made by Guinness (now owned by Diageo) at St. James's Gate Brewery (also known as the Guinness Brewery) in Dublin. Guinness makes a number of different varieties of its Irish stouts. Other examples of Irish dry stout include Murphy's and Beamish, now both owned by Heineken. Native Irish stouts are brewed by independent Irish craft breweries, most of whom include a stout in their core ranges. Draught Irish stout is normally served with a nitrogen propellant in addition to the carbon dioxide most beers use, to create a creamy texture with a long-lasting head. Some canned and bottled stouts include a special device called a \"widget\" to nitrogenate the beer in the container to replicate the experience of the keg varieties.\nPorter.\nThere were no differences between stout and porter historically, though there had been a tendency for breweries to differentiate the strengths of their beers with the words \"extra\", \"double\" and \"stout\". The term \"stout\" was initially used to indicate a stronger porter than other porters from a brewery.\nOatmeal stout.\n\"Oatmeal stout\" is a stout with a proportion of oats, normally a maximum of 30%, added during the brewing process.\nEven though a larger proportion of oats in beer can lead to a bitter or astringent taste, during the medieval period in Europe, oats were a common ingredient in ale, and proportions up to 35% were standard. In 17th-century England, mixed oat and barley malt was referred to as 'dredge'. Despite some areas of Europe, such as Norway, still clinging to the use of oats in brewing until the early part of the 20th century, the practice had largely died out by the 16th century, so much so that in 1513 Tudor sailors refused to drink oat beer offered to them because of the bitter flavour.\nThere was a revival of interest in using oats during the end of the 19th century, when (supposedly) restorative, nourishing and invalid beers, such as the later milk stout, were popular, because of the association of porridge with health. Maclay of Alloa produced an Original Oatmalt Stout in 1895 that used 70% \"oatmalt\", and a 63/- Oatmeal Stout in 1909, which used 30% \"flaked (porridge) oats\".\nIn the 20th century, many oatmeal stouts contained only a minimal amount of oats. For example, in 1936 Barclay Perkins Oatmeal Stout used only 0.5% oats. As the oatmeal stout was brewed in a parti-gyle process with their porter and standard stout, these two also contained the same proportion of oats. (Parti-gyle brewing involves extracting multiple worts from a single mash through separate sparges. Each subsequent sparge extracts a more diluted lower gravity wort from the same ingredients in proportion. As a result each wort is boiled and fermented to produces a different strength beer from same ingredients) The name seems to have been a marketing device more than anything else. In the 1920s and 1930s Whitbread's London Stout and Oatmeal Stout were identical, just packaged differently. The amount of oats Whitbread used was minimal, again around 0.5%. With such a small quantity of oats used, it could only have had little impact on the flavour or texture of these beers.\nMany breweries were still brewing oatmeal stouts in the 1950s, for example Brickwoods in Portsmouth, Matthew Brown in Blackburn and Ushers in Trowbridge. When Michael Jackson mentioned the defunct Eldrige Pope \"Oat Malt Stout\" in his 1977 book \"The World Guide to Beer\", oatmeal stout was no longer being made anywhere, but Charles Finkel, founder of Merchant du Vin, was curious enough to commission Samuel Smith to produce a version. Samuel Smith's Oatmeal Stout then became the template for other breweries' versions.\nOatmeal stouts do not usually taste specifically of oats. The smoothness of oatmeal stouts comes from the high content of proteins, lipids (includes fats and waxes), and gums imparted by the use of oats. The gums increase the viscosity and body adding to the sense of smoothness.\nOyster stout.\nOysters have had a long association with stout. When stouts were emerging in the 18th century, oysters were a commonplace food often served in public houses and taverns. By the 20th century, oyster beds were in decline, and stout had given way to pale ale. Ernest Barnes came up with the idea of combining oysters with stout using an oyster concentrate made by Thyrodone Development Ltd. in Bluff, New Zealand, where he was factory manager. It was first sold by the Dunedin Brewery Company in New Zealand in 1938, with the Hammerton Brewery in London, UK, beginning production using the same formula the following year. Hammerton Brewery was re-established in 2014 and is once again brewing an oyster stout.\nModern \"oyster stouts\" may be made with a handful of oysters in the barrel, hence the warning by one establishment, the Porterhouse Brewery in Dublin, that their award-winning Oyster Stout was not suitable for vegetarians. Others, such as Marston's Oyster Stout, use the name with the implication that the beer would be suitable for drinking with oysters.\nChocolate stout.\n\"Chocolate stout\" is a name brewers sometimes give to certain stouts having a noticeable dark chocolate flavour through the use of darker, more aromatic malt; particularly chocolate malt\u2014a malt that has been roasted or kilned until it acquires a chocolate colour. Sometimes, as with Muskoka Brewery's Double Chocolate Cranberry Stout, Young's Double Chocolate Stout, and Rogue Brewery's Chocolate Stout, the beers are also brewed with a small amount of chocolate, chocolate flavouring, or cacao nibs.\nImperial stout.\n\"Imperial stout\", also known as \"Russian imperial stout\" (sometimes abbreviated as \"RIS\"), is a stronger stout. The style originated in 18th-century London, created by Thrale's Anchor Brewery for export to the court of Catherine II of Russia. In 1781 the brewery changed hands and the beer became known as \"Barclay Perkins Imperial Brown Stout\". It was shipped to Russia by Albert von Le Coq who was awarded a Russian royal warrant which entitled him to use the name \"Imperial\". Historical analyses from the time period of 1849 to 1986 show that the beer had an original gravity between 1.100 and 1.107 and an alcohol content of around 10% ABV. This remained virtually unchanged over the whole time period. A recipe from 1856 also indicates that it was hopped at a rate of 10 pounds of hops to the barrel (). When Barclay's brewery was taken over by Courage in 1955, the beer was renamed \"Courage Imperial Russian Stout\" and it was brewed sporadically until 1993. The bottle cap still said \"Barclay's\".\nIn Canada, Imperial Stout was produced in Prince Albert first by Fritz Sick, and then by Molson following a 1958 takeover. Denmark's Wiibroe Brewery launched its 8.2 per cent Imperial Stout in 1930. The first brewery to brew an Imperial Stout in the United States was Bert Grant's Yakima Brewing.\nImperial stouts have a high alcohol content, usually over 9% abv, and are among the darkest available beer styles. Samuel Smith's brewed a version for export to the United States in the early 1980s, and today Imperial stout is among the most popular beer styles with U.S. craft brewers. American interpretations of the style often include ingredients such as vanilla beans, chili powder, maple syrup, coffee, and marshmallows. Many are aged in bourbon barrels to add additional layers of flavour. The word \"Imperial\" is now commonly added to other beer styles to denote a stronger version, hence Imperial IPAs, Imperial pilsners etc.\nA similar beer style, Baltic porter, originated in the Baltic region in the 19th century. Imperial stouts imported from Britain were recreated locally using local ingredients and brewing traditions.\nPastry stout.\nA pastry stout refers to a sweet stout style which is brewed to emulate the taste of various desserts. Many breweries who produce pastry stouts will experiment with flavours such as chocolate, marshmallow, maple syrup, vanilla or fruit.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27992", "revid": "4444", "url": "https://en.wikipedia.org/wiki?curid=27992", "title": "Slavery", "text": "Ownership of people as property\nSlavery is the ownership of a person as property, especially in regards to their labour. It is an economic phenomenon and its history resides in economic history. Slavery typically involves compulsory work, with the slave's location of work and residence dictated by the party that holds them in bondage. Enslavement is the placement of a person into slavery, and the person is called a slave or an enslaved person.\nMany historical cases of enslavement occurred as a result of breaking the law, becoming indebted, suffering a military defeat, or exploitation for cheaper labor; other forms of slavery were instituted along demographic lines such as race or sex. Slaves would be kept in bondage for life, or for a fixed period of time after which they would be granted freedom. Although slavery is usually involuntary and involves coercion, there are also cases where people voluntarily enter into slavery to pay a debt or earn money due to poverty. In the course of human history, slavery was a typical feature of civilization, and existed in most societies throughout history, but it is now outlawed in most countries of the world, except as a punishment for a crime. In general there were two types of slavery throughout human history: domestic and productive.\nIn chattel slavery, the slave is legally rendered the personal property (chattel) of the slave owner. In economics, the term de facto slavery describes the conditions of unfree labour and forced labour that most slaves endure. In 2019, approximately 40 million people, of whom 26% were children, were still enslaved throughout the world despite slavery being illegal. In the modern world, more than 50% of slaves provide forced labour, usually in the factories and sweatshops of the private sector of a country's economy. In industrialised countries, human trafficking is a modern variety of slavery; in non-industrialised countries, people in debt bondage are common, others include captive domestic servants, people in forced marriages, and child soldiers. \n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nEtymology.\nThe word \"\" was borrowed into Middle English through the Old French which ultimately derives from Byzantine Greek () or ().\nAccording to the widespread view, which has been known since the 18th century, the Byzantine (), (), borrowed from a Slavic tribe self-name *Slov\u011bne, turned into , (Late Latin scl\u0101vus) in the meaning 'prisoner of war slave', 'slave' in the 8th/9th century, because they often became captured and enslaved. However this version has been disputed since the 19th century.\nAn alternative contemporary hypothesis suggests that Medieval Latin via derives from Byzantine (, ) or (, ) with the meaning \"to strip the enemy (killed in a battle)\" or \"to make booty / extract spoils of war\". This version has been criticized as well.\nTerminology.\nThere is no consensus among historians about whether terms such as \"unfree labourer\" or \"enslaved person\", rather than \"slave\", should be used when describing the victims of slavery. According to those proposing a change in terminology, \"slave\" perpetuates the crime of slavery in language by reducing its victims to a nonhuman noun instead of \"carry[ing] them forward as people, not the property that they were\" (see also \"People-first language\"). Other historians prefer \"slave\" because the term is familiar and shorter, or because it accurately reflects the inhumanity of slavery, with \"person\" implying a degree of autonomy that slavery does not allow.\nChattel slavery.\nAs a social institution, chattel slavery classes slaves as \"chattels\" (personal property) owned by the enslaver; like livestock, they can be bought and sold at will. Chattel slavery was historically the normal form of slavery worldwide and was practiced in places such as classical Greece and the Roman Empire, where it was considered a keystone of society. \nOther examples include the institution of slavery in the Muslim world such as Medieval Egypt, as well as Subsaharan Africa, Brazil, the Antebellum United States, and parts of the Caribbean such as Cuba and Haiti. \nThe Iroquois enslaved others in ways that \"looked very like chattel slavery.\"\nBeginning in the 18th century, a series of abolitionist movements in Europe and the Americas saw slavery as a violation of the slaves' rights as people (\"all men are created equal\"), and sought to abolish it. Abolitionism encountered extreme resistance but was eventually successful. Several of the states of the United States began abolishing slavery during the American Revolutionary War. \nAfter the French Revolution, the government of France abolished slavery in 1794, but Napoleon reintroduced it in 1802 and permanent abolition did not occur until 1848. \nIn much of the British Empire, slavery was subject to abolition in 1833, throughout the United States it was abolished in 1865 as a result of the Civil War, which was fought after the attempted secession of the South in order to protect its \"Peculiar Institution\" (I.e. slavery). In Cuba slavery was abolished in 1886. The last country in the Americas to abolish slavery was Brazil, in 1888.\nChattel slavery survived longest in the Middle East. After the trans-Atlantic slave trade had been suppressed, the ancient trans-Saharan slave trade, the Indian Ocean slave trade and the Red Sea slave trade continued to traffic slaves from the African continent to the Middle East. \nDuring the 20th century, the issue of chattel slavery was addressed and investigated globally by international bodies created by the League of Nations and the United Nations (UN), such as the Temporary Slavery Commission in 1924\u20131926, the Committee of Experts on Slavery in 1932, and the Advisory Committee of Experts on Slavery in 1934\u20131939. By the time of the UN Ad Hoc Committee on Slavery in 1950\u20131951, legal chattel slavery still existed only in the Arabian Peninsula: in Oman, in Qatar, in Saudi Arabia, in the Trucial States and in Yemen. Legal chattel slavery was finally abolished in the Arabian Peninsula in the 1960s: Saudi Arabia and Yemen in 1962, in Dubai in 1963, and Oman as the last in 1970.\nThe last country to abolish slavery, Mauritania, did so in 1981. While slavery had technically been banned by colonial France in French West Africa (including Mauritania) already in 1905, this had been a purely nominal ban. The 1981 ban on slavery was not enforced in practice, as legal mechanisms to prosecute those who used slaves were not implemented until 2007.\nBonded labour.\nIndenture, also known as bonded labour or debt bondage, is a form of unfree labour in which a person works to pay off a debt by pledging themself as collateral. The services required to repay the debt, and their duration, may be undefined. Debt bondage can be passed on from generation to generation, with children required to pay off their progenitors' debt. Debt bondage is most prevalent in South Asia, and is the most widespread form of slavery today.\nMoney marriage refers to a marriage where a child, usually a girl, is married off to settle debts owed by their parents. The Chukri system is a debt bondage system found in parts of Bengal where a woman or girl can be coerced into prostitution in order to pay off debts.\nDependents.\nThe word \"slavery\" has also been used to refer to a legal state of dependency to somebody else. For example, in Persia, the situations and lives of such slaves could be better than those of common citizens.\nForced labour.\nForced labour, or unfree labour, is sometimes used to describe an individual who is forced to work against their own will, under threat of violence or other punishment. This may also include institutions not commonly classified as slavery, such as serfdom, conscription and penal labour. As slavery has been legally outlawed in all countries, forced labour in the present day (frequently referred to as \"modern slavery\") revolves around illegal control.\nHuman trafficking primarily involves women and children forced into prostitution and is the fastest growing form of forced labour, with Thailand, Cambodia, India, Brazil and Mexico having been identified as leading hotspots of commercial sexual exploitation of children.\nChild soldiers and child labour.\nIn 2007, Human Rights Watch estimated that 200,000 to 300,000 children served as soldiers in then-current conflicts. More girls under 16 work as domestic workers than any other category of child labour, often sent to cities by parents living in rural poverty as with the Haitian restaveks.\nForced marriage.\nForced marriages or early marriages are often considered types of slavery. Forced marriage continues to be practiced in parts of the world including some parts of Asia and Africa and in immigrant communities in the West. Marriage by abduction occurs in many places in the world today, with a 2003 study finding a national average of 69% of marriages in Ethiopia being through abduction.\nOther uses of the term.\nThe word \"slavery\" is often used as a pejorative to describe any activity in which one is coerced into performing. Some argue that military drafts and other forms of coerced government labour constitute \"state-operated slavery.\" Some libertarians and anarcho-capitalists view government taxation as a form of slavery.\n\"Slavery\" has been used by some anti-psychiatry proponents to define involuntary psychiatric patients, claiming there are no unbiased physical tests for mental illness and yet the psychiatric patient must follow the orders of the psychiatrist. They assert that instead of chains to control the slave, the psychiatrist uses drugs to control the mind. Drapetomania was a pseudoscientific psychiatric diagnosis for a slave who desired freedom; \"symptoms\" included laziness and the tendency to flee captivity.\nSome proponents of animal rights have applied the term \"slavery\" to the condition of some or all human-owned animals, arguing that their status is comparable to that of human slaves.\nThe labour market, as institutionalized under contemporary capitalist systems, has been criticized by mainstream socialists and by anarcho-syndicalists, who utilise the term wage slavery as a pejorative or dysphemism for wage labour. Socialists draw parallels between the trade of labour as a commodity and slavery. Cicero is also known to have suggested such parallels.\nCharacteristics.\nEconomics.\nEconomists have modeled the circumstances under which slavery (and variants such as serfdom) appear and disappear. One theoretical model is that slavery becomes more desirable for landowners where land is abundant, but labour is scarce, such that rent is depressed and paid workers can demand high wages. If the opposite holds true, then it is more costly for landowners to guard the slaves than to employ paid workers who can demand only low wages because of the degree of competition. Thus, first slavery and then serfdom gradually decreased in Europe as the population grew. They were reintroduced in the Americas and in Russia as large areas of land with few inhabitants became available.\nSlavery is more common when the tasks are relatively simple and thus easy to supervise, such as large-scale monocrops such as sugarcane and cotton, in which output depended on economies of scale. This enables systems of labour, such as the gang system in the United States, to become prominent on large plantations where field hands toiled with factory-like precision. Then, each work gang was based on an internal division of labour that assigned every member of the gang to a task and made each worker's performance dependent on the actions of the others. The slaves chopped out the weeds that surrounded the cotton plants as well as excess sprouts. Plow gangs followed behind, stirring the soil near the plants and tossing it back around the plants. Thus, the gang system worked like an assembly line.\nSince the 18th century, critics have argued that slavery hinders technological advancement because the focus is on increasing the number of slaves doing simple tasks rather than upgrading their efficiency. For example, it is sometimes argued that, because of this narrow focus, technology in Greece \u2013 and later in Rome \u2013 was not applied to ease physical labour or improve manufacturing.\nScottish economist Adam Smith stated that free labour was economically better than slave labour, and that it was nearly impossible to end slavery in a free, democratic, or republican form of government since many of its legislators or political figures were slave owners and would not punish themselves. He further stated that slaves would be better able to gain their freedom under centralized government, or a central authority like a king or church. Similar arguments appeared later in the works of Auguste Comte, especially given Smith's belief in the separation of powers, or what Comte called the \"separation of the spiritual and the temporal\" during the Middle Ages and the end of slavery, and Smith's criticism of masters, past and present. As Smith stated in the \"Lectures on Jurisprudence\", \"The great power of the clergy thus concurring with that of the king set the slaves at liberty. But it was absolutely necessary both that the authority of the king and of the clergy should be great. Where ever any one of these was wanting, slavery still continues...\"\nEven after slavery became a criminal offense, slave owners could get high returns. According to researcher Siddharth Kara, the profits generated worldwide by all forms of slavery in 2007 were $91.2\u00a0billion. That was second only to drug trafficking, in terms of global criminal enterprises. At the time the weighted average global sales price of a slave was estimated to be approximately $340, with a high of $1,895 for the average trafficked sex slave, and a low of $40 to $50 for debt bondage slaves in part of Asia and Africa. The weighted average annual profits generated by a slave in 2007 was $3,175, with a low of an average $950 for bonded labour and $29,210 for a trafficked sex slave. Approximately 40% of slave profits each year were generated by trafficked sex slaves, representing slightly more than 4% of the world's 29\u00a0million slaves.\nIdentification.\nSlaves are often identified or marked via mutilation or tattooing. A widespread practice was branding, either to explicitly mark slaves as property or as punishment. Some slaves are forced to wear shackles that cannot be removed such as cuffs, legcuffs, collars, chains, or anklets.\nLegal aspects.\nPrivate versus state-owned slaves.\nSlaves have been owned privately by individuals but have also been under state ownership. For example, the were women from low castes in pre modern Korea, who were owned by the state under government officials known as and were required to provide entertainment to the aristocracy. In the 2020s, in North Korea, (\"Pleasure Brigades\") are made up of women selected from the general population to serve as entertainers and as concubines to the rulers of North Korea. \"Tribute labor\" is compulsory labor for the state and has been used in various iterations such as corv\u00e9e, mit'a and repartimiento. The internment camps of totalitarian regimes such as the Nazis and the Soviet Union placed increasing importance on the labor provided in those camps, leading to a growing tendency among historians to designate such systems as slavery.\nA combination of these include the encomienda where the Spanish Crown granted private individuals the right to the free labour of a specified number of natives in a given area. In the \"Red Rubber System\" of both the Congo Free State and French ruled Ubangi-Shari, labour was demanded as taxation; private companies were conceded areas within which they were allowed to use any measures to increase rubber production. Convict leasing was common in the Southern United States where the state would lease prisoners for their free labour to companies.\nLegal rights.\nDepending upon the era and the country, slaves sometimes had a limited set of legal rights. For example, in the Province of New York, people who deliberately killed slaves were punishable under a 1686 statute. And, as already mentioned, certain legal rights attached to the nobi in Korea, to slaves in various African societies, and to black female slaves in the French colony of Louisiana. Giving slaves legal rights has sometimes been a matter of morality, but also sometimes a matter of self-interest. For example, in ancient Athens, protecting slaves from mistreatment simultaneously protected people who might be mistaken for slaves, and giving slaves limited property rights incentivized slaves to work harder to get more property. In the southern United States prior to the extirpation of slavery in 1865, a proslavery legal treatise reported that slaves accused of crimes typically had a legal right to counsel, freedom from double jeopardy, a right to trial by jury in graver cases, and the right to grand jury indictment, but they lacked many other rights such as white adults' ability to control their own lives.\nHistory.\nSlavery predates written records and has existed in many cultures. Slavery is rare among hunter-gatherer populations because it requires economic surpluses and a substantial population density. Thus, although it has existed among unusually resource-rich hunter gatherers, such as the American Indian peoples of the salmon-rich rivers of the Pacific Northwest coast, slavery became widespread only with the invention of agriculture during the Neolithic Revolution about 11,000 years ago. Slavery was practiced in almost every ancient civilization. Such institutions included debt bondage, punishment for crime, the enslavement of prisoners of war, child abandonment, and the enslavement of slaves' offspring.\nAfrica.\nSlavery was widespread in Africa, which pursued both internal and external slave trade. In the Senegambia region, between 1300 and 1900, close to one-third of the population was enslaved. In early Islamic states of the western Sahel, including Ghana, Mali, Segou, and Songhai, about a third of the population were enslaved.\nIn European courtly society, and European aristocracy, black African slaves and their children became visible in the late 1300s and 1400s. Starting with Frederick II, Holy Roman Emperor, black Africans were included in the retinue. In 1402 an Ethiopian embassy reached Venice. In the 1470s black Africans were painted as court attendants in wall paintings that were displayed in Mantua and Ferrara. In the 1490s black Africans were included on the emblem of the Duke of Milan.\nDuring the trans-Saharan slave trade, slaves from West Africa were transported across the Sahara desert to North Africa to be sold to Mediterranean and Middle eastern civilizations. During the Red Sea slave trade, slaves were transported from Africa across the Red Sea to the Arabian Peninsula. The Indian Ocean slave trade, sometimes known as the east African slave trade, was multi-directional. Africans were sent as slaves to the Arabian Peninsula, to Indian Ocean islands (including Madagascar), to the Indian subcontinent, and later to the Americas. These traders captured Bantu peoples (Zanj) from the interior in present-day Kenya, Mozambique and Tanzania and brought them to the coast. There, the slaves gradually assimilated in rural areas, particularly on Unguja and Pemba islands.\nSome historians assert that as many as 17\u00a0million people were sold into slavery on the coast of the Indian Ocean, the Middle East, and North Africa, and approximately 5\u00a0million African slaves were bought by Muslim slave traders and taken from Africa across the Red Sea, Indian Ocean, and Sahara Desert between 1500 and 1900. The captives were sold throughout the Middle East. This trade accelerated as superior ships led to more trade and greater demand for labour on plantations in the region. Eventually, tens of thousands of captives were being taken every year. The Indian Ocean slave trade was multi-directional and changed over time. To meet the demand for menial labour, Bantu slaves bought by east African slave traders from southeastern Africa were sold in cumulatively large numbers over the centuries to customers in Egypt, Arabia, the Persian Gulf, India, European colonies in the Far East, the Indian Ocean islands, Ethiopia , Sudan and Somalia.\nAccording to the \"Encyclopedia of African History\", \"It is estimated that by the 1890s the largest slave population of the world, about 2 million people, was concentrated in the territories of the Sokoto Caliphate. The use of slave labour was extensive, especially in agriculture.\" The Anti-Slavery Society estimated there were 2\u00a0million slaves in Ethiopia in the early 1930s out of an estimated population of 8 to 16\u00a0million.\nSlave labour in East Africa was drawn from the \"Zanj\", Bantu peoples that lived along the East African coast. The Zanj were for centuries shipped as slaves by Arab traders to all the countries bordering the Indian Ocean during the Indian Ocean slave trade. The Umayyad and Abbasid caliphs recruited many Zanj slaves as soldiers and, as early as 696, there were slave revolts of the Zanj against their Arab enslavers during their slavery in the Umayyad Caliphate in Iraq. The Zanj Rebellion, a series of uprisings that took place between 869 and 883 near Basra (also known as Basara), against the slavery in the Abbasid Caliphate situated in present-day Iraq, is believed to have involved enslaved Zanj that had originally been captured from the African Great Lakes region and areas further south in East Africa. It grew to involve over 500,000 slaves and free men who were imported from across the Muslim empire and claimed over \"tens of thousands of lives in lower Iraq\".\nThe Zanj who were taken as slaves to the Middle East were often used in strenuous agricultural work. As the plantation economy boomed and the Arabs became richer, agriculture and other manual labour work was thought to be demeaning. The resulting labour shortage led to an increased slave market.\nIn Algiers, the capital of Algeria, captured Christians and Europeans were forced into slavery. In about 1650, there were as many as 35,000 Christian slaves in Algiers. By one estimate, raids by Barbary slave traders on coastal villages and ships extending from Italy to Iceland, enslaved an estimated 1 to 1.25\u00a0million Europeans between the 16th and 19th centuries. However, this estimate is the result of an extrapolation which assumes that the number of European slaves captured by Barbary pirates was constant for a 250-year period:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nDavis' numbers have been refuted by other historians, such as David Earle, who cautions that true picture of Europeans slaves is clouded by the fact the corsairs also seized non-Christian whites from eastern Europe. In addition, the number of slaves traded was hyperactive, with exaggerated estimates relying on peak years to calculate averages for entire centuries, or millennia. Hence, there were wide fluctuations year-to-year, particularly in the 18th and 19th centuries, given slave imports, and also given the fact that, prior to the 1840s, there are no consistent records. Middle East expert, John Wright, cautions that modern estimates are based on back-calculations from human observation. Such observations, across the late 16th and early 17th century observers, account for around 35,000 European Christian slaves held throughout this period on the Barbary Coast, across Tripoli, Tunis, but mostly in Algiers. The majority were sailors (particularly those who were English), taken with their ships, but others were fishermen and coastal villagers. However, most of these captives were people from lands close to Africa, particularly Spain and Italy. This eventually led to the bombardment of Algiers by an Anglo-Dutch fleet in 1816.\nUnder Omani Arabs, Zanzibar became East Africa's main slave port, with as many as 50,000 African slaves passing through every year during the 19th century. Some historians estimate that between 11 and 18\u00a0million African slaves crossed the Red Sea, Indian Ocean, and Sahara Desert from 650 to 1900 AD. Eduard R\u00fcppell described the losses of Nuba slaves from Southern sudan being transported on foot to Egypt: \"after the Daftardar bey's 1822 campaign in the southern Nuba mountains, nearly 40,000 slaves were captured. However, through bad treatment, disease and desert travel barely 5,000 made it to Egypt.\" W.A. Veenhoven wrote: \"The German doctor, Gustav Nachtigal, an eye-witness, believed that for every slave who arrived at a market three or four died on the way\u00a0... Keltie (\"The Partition of Africa\", London, 1920) believes that for every slave the Arabs brought to the coast at least six died on the way or during the slavers' raid. Livingstone puts the figure as high as ten to one.\"\nSystems of servitude and slavery were common in parts of Africa, as they were in much of the ancient world. In many African societies where slavery was prevalent, the slaves were not treated as chattel slaves and were given certain rights in a system similar to indentured servitude elsewhere in the world. The forms of slavery in Africa were closely related to kinship structures. In many African communities, where land could not be owned, enslavement of individuals was used as a means to increase the influence a person had and expand connections. This made slaves a permanent part of a master's lineage and the children of slaves could become closely connected with the larger family ties. Children of slaves born into families could be integrated into the master's kinship group and rise to prominent positions within society, even to the level of chief in some instances. However, stigma often remained attached and there could be strict separations between slave members of a kinship group and those related to the master. Slavery was practiced in many different forms: debt slavery, enslavement of war captives, military slavery, and criminal slavery were all practiced in various parts of Africa. Slavery for domestic and court purposes was widespread throughout Africa.\nWhen the Atlantic slave trade began, many of the local slave systems began supplying captives for chattel slave markets outside Africa. Although the Atlantic slave trade was not the only slave trade from Africa, it was the largest in volume and intensity. As Elikia M'bokolo wrote in :\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The African continent was bled of its human resources via all possible routes. Across the Sahara, through the Red Sea, from the Indian Ocean ports and across the Atlantic. At least ten centuries of slavery for the benefit of the Muslim countries (from the ninth to the nineteenth)... Four million enslaved people exported via the Red Sea, another four million through the Swahili ports of the Indian Ocean, perhaps as many as nine million along the trans-Saharan caravan route, and eleven to twenty million (depending on the author) across the Atlantic Ocean.\nThe trans-Atlantic slave trade peaked in the late 18th century, when the largest number of slaves were captured on raiding expeditions into the interior of West Africa. These expeditions were typically carried out by African kingdoms, such as the Oyo Empire (Yoruba), the Ashanti Empire, the kingdom of Dahomey, and the Aro Confederacy. It is estimated that about 15 percent of slaves died during the voyage, with mortality rates considerably higher in Africa itself in the process of capturing and transporting indigenous peoples to the ships.\nMauritania was the last country in the world to officially ban slavery, in 1981, with legal prosecution of slaveholders established in 2007.\nMiddle East.\nIn the earliest known records, slavery is treated as an established institution. The Code of Hammurabi (c.\u20091760\u00a0BC), for example, prescribed death for anyone who helped a slave escape or who sheltered a fugitive. The Bible mentions slavery as an established institution. Slavery existed in Pharaonic Egypt, but studying it is complicated by terminology used by the Egyptians to refer to different classes of servitude over the course of history. Interpretation of the textual evidence of classes of slaves in ancient Egypt has been difficult to differentiate by word usage alone. The three apparent types of enslavement in ancient Egypt were chattel slavery, bonded labour, and forced labour.\nFollowing the Islamic conquests of the 7th and 8th century, slavery was regulated by the Islamic law, in parallel to the Middle East being more or less united by a succession of Islamic empires. The history of slavery in the Muslim Middle East was therefore reflected in the slavery of the Islamic empires that succeeded each other between the 7th and the 20th century. Slavery was hence reflected in the institution of slavery in the Rashidun Caliphate (632\u2013661), slavery in the Umayyad Caliphate (661\u2013750), slavery in the Abbasid Caliphate (750\u20131258), slavery in the Mamluk Sultanate (1258\u20131517) and slavery in the Ottoman Empire (1517\u20131922), before slavery was finally abolished in one Muslim country after another during the 20th century.\nHistorically, slaves in the Arab World came from many different regions, including Sub-Saharan Africa (mainly \"Zanj\"), the Caucasus (mainly Circassians), Central Asia (mainly Tartars), and Central and Eastern Europe (mainly Slavs \"Saqaliba\"). \nThese slaves were trafficked to the Arab world from Africa via the Trans-Saharan slave trade, the Baqt treaty, the Red Sea slave trade and the Indian Ocean slave trade; from Asia via the Bukhara slave trade; and from Europe via the Prague slave trade, the Venetian slave trade and the Barbary slave trade, respectively.\nBetween 1517 and 1917, most of the Middle East consisted of the Ottoman Empire. In the Ottoman capital of Constantinople, about one-fifth of the population consisted of slaves. The city was a major centre of the slave trade in the 15th and later centuries.\nEastern European slaves were provided for slavery in the Ottoman Empire via the Crimean slave trade by Tatar raids on Slavic villages but also by conquest and the suppression of rebellions, in the aftermath of which entire populations were sometimes enslaved and sold across the Empire, reducing the risk of future rebellion.\nThe Ottomans also purchased slaves from traders who brought slaves into the Empire from Europe and Africa. It has been estimated that some 200,000 slaves \u2013 mainly Circassians \u2013 were imported into the Ottoman Empire between 1800 and 1909.\nIn 1908, women slaves were still sold in the Ottoman Empire.\nGerman orientalist, Gustaf Dalman, reported seeing slaves in Muslim houses in Aleppo, belonging to Ottoman Syria, in 1899, and that boys could be bought as slaves in Damascus and Cairo in as late as 1909.\nA major center of slave trade to the Middle east was central Asia, where the Bukhara slave trade had supplied slaves to the Middle East for thousands of years from antiquity until the 1870s.\nA slave market for captured Russian and Persian slaves was the Khivan slave trade centred in the Central Asian khanate of Khiva.\nIn the early 1840s, the population of the Uzbek states of Bukhara and Khiva included about 900,000 slaves.\nBy 1870, chattel slavery had been at least formally banned in most areas of the world, with the exception of Muslim lands in Caucasus, Africa, and the Persian Gulf.\nWhile slavery was by the 1870s viewed as morally unacceptable in the West, slavery was not considered to be immoral in the Muslim world since it was an institution recognized (halal) in the Quran and morally justified under the guise of warfare against non-Muslims (kafir of Dar al-Harb), and non-Muslims were kidnapped and enslaved by Muslims around the Muslim world: in the Balkans, the Caucasus, the Baluchistan, India, South West Asia and the Philippines. \nSlaves where marched in shackles to the coasts of Sudan, Ethiopia and Somali, placed upon dhows and trafficked across the Indian Ocean to the Gulf of Aden, or across the Red Sea to Arabia and Aden, with weak slaves being thrown in the sea; or across the Sahara desert via the Trans-Saharan slave trade to the Nile, while dying from exposure and swollen feet.\nOttoman anti slavery laws where not enforced in the late 19th-century, particularly not in Hejaz; the first attempt to ban the Red Sea slave trade in 1857, the firman of 1857, resulted in a rebellion in the Hejaz Province, the Hejaz rebellion, which resulted in Hejaz being exempted from the ban. The Anglo-Ottoman Convention of 1880 formally banned the Red Sea slave trade, but it was not enforced in the Ottoman Provinces in the Arabian Peninsula. In the late 19th century, the Sultan of Morocco stated to Western diplomats that it was impossible for him to ban slavery because such a ban would not be enforceable, but the British asked him to ensure that the slave trade in Morocco would at least be handled discreet and away from the eyes of foreign witnesses.\nChattel slavery lasted in most of the Middle East until the 20th century. The Red Sea slave trade still provided enslaved people from Africa to the Arabian Peninsula after World War II. As recently as the 1960s, Saudi Arabia's slave population was estimated at 300,000. Along with Yemen, the Saudis abolished slavery in 1962.\nAmericas.\nEnslavement in the Americas existed before European arrival and was used for numerous reasons. Slavery in Mexico can be traced back to the Aztecs. Other Amerindians, such as the Inca of the Andes, the Tupinamb\u00e1 of Brazil, the Creek of Georgia, and the Comanche of Texas, also practiced slavery.\nSlavery in Canada was practiced by First Nations and by European settlers. Slave-owning people of what became Canada were, for example, the fishing societies, such as the Yurok, that lived along the Pacific coast from Alaska to California, on what is sometimes described as the Pacific or Northern Northwest Coast. Some of the indigenous peoples of the Pacific Northwest Coast, such as the Haida and Tlingit, were traditionally known as fierce warriors and slave-traders, raiding as far as California. Slavery was hereditary, the slaves being prisoners of war and their descendants were slaves. Some nations in British Columbia continued to segregate and ostracize the descendants of slaves as late as the 1970s.\nSlavery in America remains a contentious issue and played a major role in the history and evolution of some countries, triggering a revolution, a civil war, and numerous rebellions.\nThe countries that controlled most of the transatlantic slave market in terms of number of slaves shipped were the UK, Portugal and France.\nIn order to establish itself as an American empire, Spain had to fight against the relatively powerful civilizations of the New World. The Spanish conquest of the indigenous peoples in the Americas included using the Natives as forced labour. The Spanish colonies were the first Europeans to use African slaves in the New World on islands such as Cuba and Hispaniola. It was argued by some contemporary writers to be intrinsically immoral. Bartolom\u00e9 de las Casas, a 16th-century Dominican friar and Spanish historian, participated in campaigns in Cuba (at Bayamo and Camag\u00fcey) and was present at the massacre of Hatuey; his observation of that massacre led him to fight for a social movement away from the use of natives as slaves. Also, the alarming decline in the native population had spurred the first royal laws protecting the native population. The first African slaves arrived in Hispaniola in 1501. This era saw a growth in race-based slavery. England played a prominent role in the Atlantic slave trade. The \"slave triangle\" was pioneered by Francis Drake and his associates, though English slave-trading would not take off until the mid-17th century.\nMany whites who arrived in North America during the 17th and 18th centuries came under contract as indentured servants. The transformation from indentured servitude to slavery was a gradual process in Virginia. The earliest legal documentation of such a shift was in 1640 where a black man, John Punch, was sentenced to lifetime slavery, forcing him to serve his master, Hugh Gwyn, for the remainder of his life, for attempting to run away. This case was significant because it established the disparity between his sentence as a black man and that of the two white indentured servants who escaped with him (one described as Dutch and one as a Scotchman). It is the first documented case of a black man sentenced to lifetime servitude and is considered one of the first legal cases to make a racial distinction between black and white indentured servants.\nAfter 1640, planters started to ignore the expiration of indentured contracts and keep their servants as slaves for life. This was demonstrated by the 1655 case \"Johnson v. Parker\", where the court ruled that a black man, Anthony Johnson of Virginia, was granted ownership of another black man, John Casor, as the result of a civil case. This was the first instance of a judicial determination in the Thirteen Colonies holding that a person who had committed no crime could be held in servitude for life.\nSpanish colonial America.\nIn Jamaica and elsewhere in the Caribbean area, the Spanish enslaved many of the Taino natives. Some of them escaped, and some hurled themselves and their children off of cliffs to avoid enslavement, but most died from European diseases and overwork. The practice began under Christopher Columbus, who was looking for gold to finance his future expeditions, and was continued by the other conquistadors who followed in his wake.\nIn 1519, Hern\u00e1n Cort\u00e9s brought the first modern slave to Mexico. In the mid-16th century, the Spanish New Laws, prohibited slavery of the indigenous people, including the Aztecs. A labour shortage resulted. This led to the African slaves being imported, as they were not susceptible to smallpox. In exchange, many Africans were afforded the opportunity to buy their freedom, while eventually others were granted their freedom by their masters. \nSpain practically did not trade in slaves until 1810 after the rebellions and independence of its American territories or viceroyalties. After the Napoleonic invasions, Spain had lost its industry and its American territories, except in Cuba and Puerto Rico, where the African slave trade to Cuba began on a massive scale from 1810 onwards. It was started by French planters exiled from the French lost colony Saint Domingue (Haiti) who settled in the eastern part of Cuba.\nIn 1789, the Spanish Crown led an effort to reform slavery, as the demand for slave labour in Cuba was growing. The Crown issued a decree, (Spanish Black Code), that specified food and clothing provisions, put limits on the number of work hours, limited punishments, required religious instruction, and protected marriages, forbidding the sale of young children away from their mothers. The British made other changes to the institution of slavery in Cuba. However, planters often flouted the laws and protested against them, considering them a threat to their authority and an intrusion into their personal lives.\nEnglish and Dutch Caribbean.\nIn the early 17th century, the majority of the labour in Barbados was provided by European indentured servants, mainly English, Irish and Scottish, with African and native American slaves providing little of the workforce. The introduction of sugar cane in 1640 completely transformed society and the economy. Barbados eventually had one of the world's largest sugar industries. The workable sugar plantation required a large investment and a great deal of heavy labour. At first, Dutch traders supplied the equipment, financing, and African slaves, in addition to transporting most of the sugar to Europe. In 1644, the population of Barbados was estimated at 30,000, of which about 800 were of African descent, with the remainder mainly of English descent. By 1700, there were 15,000 free whites and 50,000 enslaved Africans. In Jamaica, although the African slave population in the 1670s and 1680s never exceeded 10,000, by 1800 it had increased to over 300,000. The increased implementation of slave codes or black codes, which created differential treatment between Africans and the white workers and ruling planter class. In response to these codes, several slave rebellions were attempted or planned during this time, but none succeeded.\nThe planters of the Dutch colony of Suriname relied heavily on African slaves to cultivate, harvest and process the commodity crops of coffee, cocoa, sugar cane and cotton plantations. The Netherlands abolished slavery in Suriname in 1863.\nMany slaves escaped the plantations. With the help of the native South Americans living in the adjoining rain forests, these runaway slaves established a new and unique culture in the interior that was highly successful in its own right. They were known collectively in English as Maroons, in French as (literally meaning \"brown negroes\", that is \"pale-skinned negroes\"), and in Dutch as . The Maroons gradually developed several independent tribes through a process of ethnogenesis, as they were made up of slaves from different African ethnicities. These tribes include the Saramaka, Paramaka, Ndyuka or Aukan, Kwinti, Aluku or Boni, and Matawai. The Maroons often raided plantations to recruit new members from the slaves and capture women, as well as to acquire weapons, food and supplies. They sometimes killed planters and their families in the raids. The colonists also mounted armed campaigns against the Maroons, who generally escaped through the rain forest, which they knew much better than did the colonists. To end hostilities, in the 18th century the European colonial authorities signed several peace treaties with different tribes. They granted the Maroons sovereign status and trade rights in their inland territories, giving them autonomy.\nBrazil.\nSlavery in Brazil began long before the first Portuguese settlement was established in 1532, as members of one tribe would enslave captured members of another.\nLater, Portuguese colonists were heavily dependent on indigenous labour during the initial phases of settlement to maintain the subsistence economy, and natives were often captured by expeditions called . The importation of African slaves began midway through the 16th century, but the enslavement of indigenous peoples continued well into the 17th and 18th centuries.\nDuring the Atlantic slave trade era, Brazil imported more African slaves than any other country. Nearly 5\u00a0million slaves were brought from Africa to Brazil during the period from 1501 to 1866. Until the early 1850s, most African slaves who arrived on Brazilian shores were forced to embark at West Central African ports, especially in Luanda (in present-day Angola). Today, with the exception of Nigeria, the country with the largest population of people of African descent is Brazil.\nSlave labour was the driving force behind the growth of the sugar economy in Brazil, and sugar was the primary export of the colony from 1600 to 1650. Gold and diamond deposits were discovered in Brazil in 1690, which sparked an increase in the importation of African slaves to power this newly profitable market. Transportation systems were developed for the mining infrastructure, and population boomed from immigrants seeking to take part in gold and diamond mining. Demand for African slaves did not wane after the decline of the mining industry in the second half of the 18th century. Cattle ranching and foodstuff production proliferated after the population growth, both of which relied heavily on slave labour. 1.7\u00a0million slaves were imported to Brazil from Africa from 1700 to 1800, and the rise of coffee in the 1830s further enticed expansion of the slave trade.\nBrazil was the last country in the Western world to abolish slavery. Forty percent of the total number of slaves brought to the Americas were sent to Brazil.\nHaiti.\nSlavery in Haiti began at an unknown time with slavery being already practiced by the native populations when Christopher Columbus on the island in 1492. European colonists would go and institutionalize slavery on the island and turn it into a major business which was devastating to the native population. Following the indigenous Ta\u00edno's near decimation from forced labour, disease and war, the Spanish, under advisement of the Catholic priest Bartolom\u00e9 de las Casas, and with the blessing of the Catholic church, who also wished to protect the indigenous people, began engaging in earnest in the use of African slaves. During the French colonial period beginning in 1625, the economy of Haiti (then known as Saint-Domingue) was based on slavery, and the practice there was regarded as the most brutal in the world.\nFollowing the Treaty of Ryswick of 1697, Hispaniola was divided between France and Spain. France received the western third and subsequently named it Saint-Domingue. To develop it into sugarcane plantations, the French imported thousands of slaves from Africa. Sugar was a lucrative commodity crop throughout the 18th century. By 1789, approximately 40,000 white colonists lived in Saint-Domingue. The whites were vastly outnumbered by the tens of thousands of African slaves they had imported to work on their plantations, which were primarily devoted to the production of sugarcane. In the north of the island, slaves were able to retain many ties to African cultures, religion and language; these ties were continually being renewed by newly imported Africans. Blacks outnumbered whites by about ten to one.\nThe French-enacted (\"Black Code\"), prepared by Jean-Baptiste Colbert and ratified by Louis XIV, had established rules on slave treatment and permissible freedoms. Saint-Domingue has been described as one of the most brutally efficient slave colonies; one-third of newly imported Africans died within a few years. Many slaves died from diseases such as smallpox and typhoid fever. They had birth rates around 3 percent, and there is evidence that some women aborted fetuses, or committed infanticide, rather than allow their children to live within the bonds of slavery.\nAs in its Louisiana colony, the French colonial government allowed some rights to free people of color: the mixed-race descendants of white male colonists and black female slaves (and later, mixed-race women). Over time, many were released from slavery. They established a separate social class. White French Creole fathers frequently sent their mixed-race sons to France for their education. Some men of color were admitted into the military. More of the free people of color lived in the south of the island, near Port-au-Prince, and many intermarried within their community. They frequently worked as artisans and tradesmen, and began to own some property. Some became slave holders. The free people of color petitioned the colonial government to expand their rights.\nSlaves that made it to Haiti from the trans-Atlantic journey and slaves born in Haiti were first documented in Haiti's archives and transferred to France's Ministry of Defense and the Ministry of Foreign Affairs. As of 2015[ [update]], these records are in The National Archives of France. According to the 1788 Census, Haiti's population consisted of nearly 40,000 whites, 30,000 free coloureds and 450,000 slaves.\nThe Haitian Revolution of 1804, the only successful slave revolt in human history, precipitated the end of slavery in all French colonies, which came in 1848.\nUnited States.\nSlavery in the United States was the legal institution of human chattel enslavement, primarily of Africans and African Americans, that existed in the United States of America in the 18th and 19th centuries, after it gained independence from the British and before the end of the American Civil War. Slavery had been practiced in British America from early colonial days and was legal in all Thirteen Colonies, at the time of the Declaration of Independence in 1776. By the time of the American Revolution, the status of slave had been institutionalized as a racial caste associated with African ancestry. The United States became polarized over the issue of slavery, represented by the slave and free states divided by the Mason\u2013Dixon line, which separated free Pennsylvania from slave Maryland and Delaware.\nCongress, during the Jefferson administration, prohibited the importation of slaves, effective 1808, although smuggling (illegal importing) was not unusual. Domestic slave trading, however, continued at a rapid pace, driven by labour demands from the development of cotton plantations in the Deep South. Those states attempted to extend slavery into the new western territories to keep their share of political power in the nation. Such laws proposed to Congress to continue the spread of slavery into newly ratified states include the Kansas-Nebraska Act.\nThe treatment of slaves in the United States varied widely depending on conditions, times, and places. The power relationships of slavery corrupted many whites who had authority over slaves, with children showing their own cruelty. Masters and overseers resorted to physical punishments to impose their wills. Slaves were punished by whipping, shackling, hanging, beating, burning, mutilation, branding and imprisonment. Punishment was most often meted out in response to disobedience or perceived infractions, but sometimes abuse was carried out to re-assert the dominance of the master or overseer of the slave. Treatment was usually harsher on large plantations, which were often managed by overseers and owned by absentee slaveholders.\nWilliam Wells Brown, who escaped to freedom, reported that on one plantation, slave men were required to pick of cotton per day, while women were required to pick per day; if any slave failed in their quota, they were subject to whip lashes for each pound they were short. The whipping post stood next to the cotton scales. A New York man who attended a slave auction in the mid-19th century reported that at least three-quarters of the male slaves he saw at sale had scars on their backs from whipping. By contrast, small slave-owning families had closer relationships between the owners and slaves; this sometimes resulted in a more humane environment but was not a given.\nMore than one million slaves were sold from the Upper South, which had a surplus of labour, and taken to the Deep South in a forced migration, splitting up many families. New communities of African American culture were developed in the Deep South, and the total slave population in the South eventually reached 4\u00a0million before liberation. In the 19th century, proponents of slavery often defended the institution as a \"necessary evil\". White people of that time feared that emancipation of black slaves would have more harmful social and economic consequences than the continuation of slavery. The French writer and traveler Alexis de Tocqueville, in \"Democracy in America\" (1835), expressed opposition to slavery while observing its effects on American society. He felt that a multiracial society without slavery was untenable, as he believed that prejudice against black people increased as they were granted more rights. Others, like James Henry Hammond argued that slavery was a \"positive good\" stating: \"Such a class you must have, or you would not have that other class which leads progress, civilization, and refinement.\"\nThe Southern state governments wanted to keep a balance between the number of slave and free states to maintain a political balance of power in Congress. The new territories acquired from Britain, France, and Mexico were the subject of major political compromises. By 1850, the newly rich cotton-growing South was threatening to secede from the Union, and tensions continued to rise. Many white Southern Christians, including church ministers, attempted to justify their support for slavery as modified by Christian paternalism. The largest denominations, the Baptist, Methodist, and Presbyterian churches, split over the slavery issue into regional organizations of the North and South.\nWhen Abraham Lincoln won the 1860 election on a platform of halting the expansion of slavery, according to the 1860 U.S. census, roughly 400,000 individuals, representing 8% of all U.S. families, owned nearly 4,000,000 slaves. One-third of Southern families owned slaves. The South was heavily invested in slavery. As such, upon Lincoln's election, seven states broke away to form the Confederate States of America. The first six states to secede held the greatest number of slaves in the South. Shortly after, over the issue of slavery, the United States erupted into an all-out Civil War, with slavery legally ceasing as an institution following the war in December 1865.\nIn 1865, the United States ratified the 13th Amendment to the United States Constitution, which banned slavery and involuntary servitude \"except as punishment for a crime whereof the party shall have been duly convicted,\" providing a legal basis for forced labor to continue in the country. This led to the system of convict leasing, which affected primarily African Americans. The Prison Policy Initiative, an American criminal justice think tank, cites the 2020 US prison population as 2.3 million, and nearly all able-bodied inmates work in some fashion. In Texas, Georgia, Alabama and Arkansas, prisoners are not paid at all for their work. In other states, prisoners are paid between $0.12 and $1.15 per hour. Federal Prison Industries paid inmates an average of $0.90 per hour in 2017. Inmates who refuse to work may be indefinitely remanded into solitary confinement or have family visitation revoked. From 2010 to 2015 and again in 2016 and in 2018, some prisoners in the US refused to work, protesting for better pay, better conditions, and for the end of forced labor. Strike leaders were punished with indefinite solitary confinement. Forced prison labor occurs in both government-run prisons and private prisons. CoreCivic and GEO Group constitute half the market share of private prisons, and they made a combined revenue of $3.5 billion in 2015. The value of all labor by inmates in the United States is estimated to be in the billions. In California, 2,500 incarcerated workers fought wildfires for only $1 per hour through the CDCR's Conservation Camp Program, which saves the state as much as $100 million a year.\nAsia-Pacific.\nEast Asia.\nSlavery existed in ancient China as early as the Shang dynasty. Slavery was employed largely by governments as a means of maintaining a public labour force. Until the Han dynasty, slaves were sometimes discriminated against but their legal status was guaranteed. As can be seen from the some historical records as \"Duansheng, Marquis of Shouxiang, had his territory confiscated because he killed a female slave\" (\"Han dynasty records in DongGuan\"), \"Wang Mang's son Wang Huo murdered a slave, Wang Mang severely criticized him and forced him to commit suicide\" (\"Book of Han: Biography of Wang Mang\"), Murder against slaves was as taboo as murder against free people, and perpetrators were always severely punished. Han dynasty can be said to be very distinctive compared to other countries of the same period(In most cases, lords were free to kill their slaves) in terms of slaves human rights.\nAfter the Southern and Northern Dynasties, Due to years of poor harvests, the influx of foreign tribes, and the resulting wars, The number of slaves exploded. They became a class and were called \"jianmin (Chinese: \u8d31\u6c11)\", The word literally means \"inferior person\". As stated in \"The commentary of Tang Code\": \"Slaves and inferior people are legally equivalent to livestock products\", They always had a low social status, and even if they were deliberately murdered, the perpetrators received only a year in prison, and were punished even when they reported the crimes of their lords. However, in the Later period of the dynasty, perhaps because the increase in the number of slaves slowed down again, the penalties for crimes against them became harsh again. For example, the famous contemporary female poet Yu Xuanji, she was publicly executed for murdering her own slave.\nMany Han Chinese were enslaved in the process of the Mongol invasion of China proper. According to Japanese historians Sugiyama Masaaki (\u6749\u5c71\u6b63\u660e) and Funada Yoshiyuki (\u8229\u7530\u5584\u4e4b), Mongolian slaves were owned by Han Chinese during the Yuan dynasty. Slavery has taken various forms throughout China's history. It was reportedly abolished as a legally recognized institution, including in a 1909 law fully enacted in 1910, although the practice continued until at least 1949. Tang Chinese soldiers and pirates enslaved Koreans, Turks, Persians, Indonesians, and people from Inner Mongolia, central Asia, and northern India. The greatest source of slaves came from southern tribes, including Thais and aboriginals from the southern provinces of Fujian, Guangdong, Guangxi, and Guizhou. Malays, Khmers, Indians, and \"black skinned\" peoples (who were either Austronesian Negritos of Southeast Asia and the Pacific Islands, or Africans, or both) were also purchased as slaves in the Tang dynasty.\nIn the 17th century Qing dynasty, there was a hereditarily servile people called \"Booi Aha\" (Manchu: ; Chinese transliteration: \u5305\u8863\u963f\u54c8), which is a Manchu word literally translated as \"household person\" and sometimes rendered as \"nucai.\" The Manchu was establishing close personal and paternalist relationship between masters and their slaves, as Nurhachi said, \"The Master should love the slaves and eat the same food as him\". However, booi aha \"did not correspond exactly to the Chinese category of \"bond-servant slave\" (Chinese:\u5974\u50d5); instead, it was a relationship of personal dependency on a master which in theory guaranteed close personal relationships and equal treatment, even though many western scholars would directly translate \"booi\" as \"bond-servant\" (some of the \"booi\" even had their own servant). Chinese Muslim (Tungans) Sufis who were charged with practicing xiejiao (heterodox religion), were punished by exile to Xinjiang and being sold as a slave to other Muslims, such as the Sufi begs. Han Chinese who committed crimes such as those dealing with opium became slaves to the begs, this practice was administered by Qing law. Most Chinese in Altishahr were exile slaves to Turkestani Begs. While free Chinese merchants generally did not engage in relationships with East Turkestani women, some of the Chinese slaves belonging to begs, along with Green Standard soldiers, Bannermen, and Manchus, engaged in affairs with the East Turkestani women that were serious in nature.\nSlavery in Korea existed since before the Three Kingdoms of Korea period, in the first century BCE. Slavery has been described as \"very important in medieval Korea, probably more important than in any other East Asian country, but by the 16th century, population growth was making [it] unnecessary\". Slavery went into decline around the 10th century but came back in the late Goryeo period when Korea also experienced multiple slave rebellions. In the Joseon period of Korea, members of the slave class were known as . The nobi were socially indistinct from freemen (i.e., the middle and common classes) other than the ruling yangban class, and some possessed property rights, and legal and civil rights. Hence, some scholars argue that it is inappropriate to call them \"slaves\", while some scholars describe them as serfs. The nobi population could fluctuate up to about one-third of the total, but on average the nobi made up about 10% of the total population. In 1801, the majority of government nobi were emancipated, and by 1858, the nobi population stood at about 1.5 percent of the Korean population. During the Joseon period, the nobi population could fluctuate up to about one-third of the population, but on average the nobi made up about 10% of the total population. The nobi system declined beginning in the 18th century. Since the outset of the Joseon dynasty and especially beginning in the 17th century, there was harsh criticism among prominent thinkers in Korea about the nobi system. Even within the Joseon government, there were indications of a shift in attitude toward the nobi. King Yeongjo implemented a policy of gradual emancipation in 1775, and he and his successor King Jeongjo made many proposals and developments that lessened the burden on nobi, which led to the emancipation of the vast majority of government nobi in 1801. In addition, population growth, numerous escaped slaves, growing commercialization of agriculture, and the rise of the independent small farmer class contributed to the decline in the number of nobi to about 1.5% of the total population by 1858. The hereditary nobi system was officially abolished around 1886\u201387, and the rest of the nobi system was abolished with the Gabo Reform of 1894. However, slavery did not completely disappear in Korea until 1930, during Imperial Japanese rule. During the Imperial Japanese occupation of Korea around World War II, some Koreans were used in forced labour by the Imperial Japanese, in conditions which have been compared to slavery. These included women forced into sexual slavery by the Imperial Japanese Army before and during World War II, known as \"comfort women\".\nAfter the Portuguese first made contact with Japan in 1543, slave trade developed in which Portuguese purchased Japanese as slaves in Japan and sold them to various locations overseas, including Portugal, throughout the 16th and 17th centuries. Many documents mention the slave trade along with protests against the enslavement of Japanese. Japanese slaves are believed to be the first of their nation to end up in Europe, and the Portuguese purchased numbers of Japanese slave girls to bring to Portugal for sexual purposes, as noted by the Church in 1555. Japanese slave women were even sold as concubines to Asian lascar and African crew members, along with their European counterparts serving on Portuguese ships trading in Japan, mentioned by Luis Cerqueira, a Portuguese Jesuit, in a 1598 document. Japanese slaves were brought by the Portuguese to Macau, where they were enslaved to Portuguese or became slaves to other slaves. Some Korean slaves were bought by the Portuguese and brought back to Portugal from Japan, where they had been among the tens of thousands of Korean prisoners of war transported to Japan during the Japanese invasions of Korea (1592\u201398). Historians pointed out that at the same time Hideyoshi expressed his indignation and outrage at the Portuguese trade in Japanese slaves, he was engaging in a mass slave trade of Korean prisoners of war in Japan.\nFillippo Sassetti saw some Chinese and Japanese slaves in Lisbon among the large slave community in 1578, although most of the slaves were black.\nThe Portuguese also valued Oriental slaves more than the black Africans and the Moors for their rarity. Chinese slaves were more expensive than Moors and blacks and showed off the high status of the owner. The Portuguese attributed qualities like intelligence and industriousness to Chinese, Japanese and Indian slaves. King Sebastian of Portugal feared rampant slavery was having a negative effect on Catholic proselytization, so he commanded that it be banned in 1571. Hideyoshi was so disgusted that his own Japanese people were being sold \"en masse\" into slavery on Kyushu, that he wrote a letter to Jesuit Vice-Provincial Gaspar Coelho on July 24, 1587, to demand the Portuguese, Siamese (Thai), and Cambodians stop purchasing and enslaving Japanese and return Japanese slaves who ended up as far as India. Hideyoshi blamed the Portuguese and Jesuits for this slave trade and banned Christian proselytizing as a result. In 1595, a law was passed by Portugal banning the selling and buying of Chinese and Japanese slaves.\nSouth Asia.\nSlavery in India was widespread by the 6th century BC, and perhaps even as far back as the Vedic period. Slavery intensified during the Muslim domination of northern India after the 11th century. Slavery existed in Portuguese India after the 16th century. The Dutch, too, largely dealt in Abyssian slaves, known in India as Habshis or Sheedes. Arakan/Bengal, Malabar, and Coromandel remained the largest sources of forced labour until the 1660s.\nBetween 1626 and 1662, the Dutch exported on an average 150\u2013400 slaves annually from the Arakan-Bengal coast. During the first 30 years of Batavia's existence, Indian and Arakanese slaves provided the main labour force of the Dutch East India Company, Asian headquarters. An increase in Coromandel slaves occurred during a famine following the revolt of the Nayaka Indian rulers of South India (Tanjavur, Senji, and Madurai) against Bijapur overlordship (1645) and the subsequent devastation of the Tanjavur countryside by the Bijapur army. Reportedly, more than 150,000 people were taken by the invading Deccani Muslim armies to Bijapur and Golconda. In 1646, 2,118 slaves were exported to Batavia, the overwhelming majority from southern Coromandel. Some slaves were also acquired further south at Tondi, Adirampatnam, and Kayalpatnam. Another increase in slaving took place between 1659 and 1661 from Tanjavur as a result of a series of successive Bijapuri raids. At Nagapatnam, Pulicat, and elsewhere, the company purchased 8,000\u201310,000 slaves, the bulk of whom were sent to Ceylon, while a small portion were exported to Batavia and Malacca. Finally, following a long drought in Madurai and southern Coromandel, in 1673, which intensified the prolonged Madurai-Maratha struggle over Tanjavur and punitive fiscal practices, thousands of people from Tanjavur, mostly children, were sold into slavery and exported by Asian traders from Nagapattinam to Aceh, Johor, and other slave markets.\nIn September 1687, 665 slaves were exported by the English from Fort St. George, Madras. And, in 1694\u201396, when warfare once more ravaged South India, a total of 3,859 slaves were imported from Coromandel by private individuals into Ceylon. The volume of the total Dutch Indian Ocean slave trade has been estimated to be about 15\u201330% of the Atlantic slave trade, slightly smaller than the trans-Saharan slave trade, and one-and-a-half to three times the size of the Swahili and Red Sea coast and the Dutch West India Company slave trades.\nAccording to Sir Henry Bartle Frere (who sat on the Viceroy's Council), there were an estimated 8 or 9\u00a0million slaves in India in 1841. About 15% of the population of Malabar were slaves. Slavery was legally abolished in the possessions of the East India Company by the Indian Slavery Act, 1843.\nSouth East Asia.\nThe hill tribe people in Indochina were \"hunted incessantly and carried off as slaves by the Siamese (Thai), the Anamites (Vietnamese), and the Cambodians\". A Siamese military campaign in Laos in 1876 was described by a British observer as having been \"transformed into slave-hunting raids on a large scale\". The census, taken in 1879, showed that 6% of the population in the Malay sultanate of Perak were slaves. Enslaved people made up about two-thirds of the population in part of North Borneo in the 1880s.\nOceania.\nSlaves (\"he m\u014dkai\") had a recognised social role in traditional M\u0101ori society in New Zealand. Blackbirding occurred on islands in the Pacific Ocean and Australia, especially in the 19th century.\nEurope.\nAncient Greece and Rome.\nRecords of slavery in Ancient Greece begin with Mycenaean Greece. Classical Athens had the largest slave population, with as many as 80,000 in the 6th and 5th centuries BC. As the Roman Republic expanded outward, entire populations were enslaved, across Europe and the Mediterranean. Slaves were used for labour, as well as for amusement (e.g., gladiators and sex slaves). This oppression by an elite minority eventually led to slave revolts (see Roman Servile Wars); the Third Servile War was led by Spartacus.\nBy the late Republican era, slavery had become an economic pillar of Roman wealth, as well as Roman society. It is estimated that 25% or more of the population of Ancient Rome was enslaved, although the actual percentage is debated by scholars and varied from region to region. Slaves represented 15\u201325% of Italy's population, mostly war captives, especially from Gaul and Epirus. Estimates of the number of slaves in the Roman Empire suggest that the majority were scattered throughout the provinces outside of Italy. Generally, slaves in Italy were indigenous Italians. Foreigners (including both slaves and freedmen) born outside of Italy were estimated to have peaked at 5% of the total in the capital, where their number was largest. Those from outside of Europe were predominantly of Greek descent. Jewish slaves never fully assimilated into Roman society, remaining an identifiable minority. These slaves (especially the foreigners) had higher death rates and lower birth rates than natives and were sometimes subjected to mass expulsions. The average recorded age at death for the slaves in Rome was seventeen and a half years (17.2 for males; 17.9 for females).\nMedieval and early modern Europe.\nSlavery in early medieval Europe was so common that the Catholic Church repeatedly prohibited it, or at least the export of Christian slaves to non-Christian lands, as for example at the Council of Koblenz (922), the Council of London (1102) (which aimed mainly at the sale of English slaves to Ireland) and the Council of Armagh (1171). Serfdom, on the contrary, was widely accepted. In 1452, Pope Nicholas V issued the papal bull , granting the kings of Spain and Portugal the right to reduce any \"Saracens (Muslims), pagans and any other unbelievers\" to perpetual slavery, legitimizing the slave trade as a result of war. The approval of slavery under these conditions was reaffirmed and extended in his bull of 1455. Large-scale trading in slaves was mainly confined to the South and East of early medieval Europe: the Byzantine Empire and the Muslim world were the destinations, while pagan Central and Eastern Europe (along with the Caucasus and Tartary) were important sources. Viking, Arab, Greek, and Radhanite Jewish merchants were all involved in the slave trade during the Early Middle Ages. The trade in European slaves reached a peak in the 10th century following the Zanj Rebellion, which dampened the use of African slaves in the Arab world.\nIn Britain, slavery continued to be practiced following the fall of Rome, while sections of \u00c6thelstan's and Hywel the Good's laws dealt with slaves in medieval England and medieval Wales respectively. The trade particularly picked up after the Viking invasions, with major markets at Chester and Bristol supplied by Danish, Mercian, and Welsh raiding of one another's borderlands. At the time of the \"Domesday Book\", nearly 10% of the English population were slaves. William the Conqueror introduced a law preventing the sale of slaves overseas. According to historian John Gillingham, by 1200 slavery in the British Isles was non-existent. Slavery had never been authorized by statute within England and Wales, and in 1772, in the case Somerset v Stewart, Lord Mansfield declared that it was also unsupported within England by the common law. The slave trade was abolished by the Slave Trade Act 1807, although slavery remained legal in possessions outside Europe until the passage of the Slavery Abolition Act 1833 and the Indian Slavery Act, 1843. \nHowever, when England began to have colonies in the Americas, and particularly from the 1640s, African slaves began to make their appearance in England and remained a presence until the eighteenth century. In Scotland, slaves continued to be sold as chattels until late in the eighteenth century (on the second May 1722, an advertisement appeared in the \"Edinburgh Evening Courant\", announcing that a stolen slave had been found, who would be sold to pay expenses, unless claimed within two weeks). For nearly two hundred years in the history of coal mining in Scotland, miners were bonded to their \"maisters\" by a 1606 Act \"Anent Coalyers and Salters\". The Colliers and Salters (Scotland) Act 1775 stated that \"many colliers and salters are in a state of slavery and bondage\" and announced emancipation; those starting work after July 1, 1775, would not become slaves, while those already in a state of slavery could, after 7 or 10 years depending on their age, apply for a decree of the Sheriff's Court granting their freedom. Few could afford this, until a further law in 1799 established their freedom and made this slavery and bondage illegal.\nThe Byzantine-Ottoman wars and the Ottoman wars in Europe brought large numbers of slaves into the Islamic world. \nTo staff its bureaucracy, the Ottoman Empire established a janissary system which seized hundreds of thousands of Christian boys through the dev\u015firme system. They were well cared for but were legally slaves owned by the government and were not allowed to marry. They were never bought or sold. The empire gave them significant administrative and military roles. The system began about 1365; there were 135,000 janissaries in 1826, when the system ended. After the Battle of Lepanto, 12,000 Christian galley slaves were recaptured and freed from the Ottoman fleet. \nEastern Europe suffered a series of Tatar invasions, the goal of which was to loot and capture slaves for selling them to Ottomans as jasyr. Seventy-five Crimean Tatar raids were recorded into Poland\u2013Lithuania between 1474 and 1569.\nMedieval Spain and Portugal were the scene of almost constant Muslim invasion of the predominantly Christian area. Periodic raiding expeditions were sent from Al-Andalus to ravage the Iberian Christian kingdoms, bringing back booty and slaves. In a raid against Lisbon in 1189, for example, the Almohad caliph Yaqub al-Mansur took 3,000 female and child captives, while his governor of C\u00f3rdoba, in a subsequent attack upon Silves, Portugal, in 1191, took 3,000 Christian slaves. From the 11th to the 19th century, North African Barbary Pirates engaged in raids on European coastal towns to capture Christian slaves to sell at slave markets in places such as Algeria and Morocco.\nThe maritime town of Lagos was the first slave market created in Portugal (one of the earliest colonizers of the Americas) for the sale of imported African slaves\u00a0\u2013 the , opened in 1444. In 1441, the first slaves were brought to Portugal from northern Mauritania. By 1552, black African slaves made up 10% of the population of Lisbon. In the second half of the 16th century, the Crown gave up the monopoly on slave trade, and the focus of European trade in African slaves shifted from import to Europe to slave transports directly to tropical colonies in the Americas\u00a0\u2013 especially Brazil. In the 15th century one-third of the slaves were resold to the African market in exchange of gold.\nUntil the late 18th century, the Crimean Khanate (a Muslim Tatar state) maintained a massive slave trade with the Ottoman Empire and the Middle East. The slaves were captured in southern Russia, Poland-Lithuania, Moldavia, Wallachia, and Circassia by Tatar horsemen and sold in the Crimean port of Kaffa. About 2\u00a0million mostly Christian slaves were exported over the 16th and 17th centuries until the Crimean Khanate was destroyed by the Russian Empire in 1783. \nIn Kievan Rus and Muscovy, slaves were usually classified as kholops. According to David P. Forsythe, \"In 1649 up to three-quarters of Muscovy's peasants, or 13 to 14 million people, were serfs whose material lives were barely distinguishable from slaves. Perhaps another 1.5 million were formally enslaved, with Russian slaves serving Russian masters.\" Slavery remained a major institution in Russia until 1723, when Peter the Great converted the household slaves into house serfs. Russian agricultural slaves were formally converted into serfs earlier in 1679. Slavery in Poland was forbidden in the 15th century; in Lithuania, slavery was formally abolished in 1588; they were replaced by the second serfdom.\nIn Scandinavia, thralldom was abolished in the mid-14th century.\nDuring the Age of Enlightenment, individuals, whether religious or not, held diverse and inconsistent beliefs about race and slavery and despite discussions on individual rights and freedoms; slavery was not abolished, but expanded significantly. The secular enlightenment allowed for scientific racism to emerge as a basis for slavery. It allowed for coexistence of conflicting views on the moral status of black enslavement and the inferior physical status of those people being enslaved, based on the science at the time. The theory of polygenesis (multiple independent human origins) generally lead to support or symapathy with slavery and this was used by nonreligious individuals to counter religious theories of monogenesis (single origin to one couple).\nNazi Germany.\nDuring the Second World War, Nazi Germany effectively enslaved about 12 million people, both those considered undesirable and citizens of conquered countries, with the avowed intention of treating these \"Untermenschen\" (sub-humans) as a permanent slave-class of inferior beings who could be worked until they died, and who possessed neither the rights nor the legal status of members of the Aryan race.\nBesides Jews, the harshest deportation and forced labour policies were applied to the populations of Poland, Belarus, Ukraine, and Russia. By the end of the war, half of Belarus' population had been killed or deported.\nCommunist states.\nBetween 1930 and 1960, the Soviet Union created a system of, according to Anne Applebaum and the \"perspective of the Kremlin\", slave labor camps called the \"Gulag\" ().\nPrisoners in these camps were worked to death by a combination of extreme production quotas, physical and psychological brutality, hunger, lack of medical care, and the harsh environment. Aleksandr Solzhenitsyn, who survived eight years of Gulag incarceration, provided firsthand testimony about the camps with the publication of \"The Gulag Archipelago\", after which he was awarded the Nobel Prize in Literature. Fatality rate was as high as 80% during the first months in many camps. Hundreds of thousands of people, possibly millions, died as a direct result of forced labour under the Soviets.\nGolfo Alexopoulos suggests comparing labor in the Gulag with \"other forms of slave labor\" and notes its \"violence of human exploitation\" in \"Illness and Inhumanity in Stalin's Gulag\":\nStalin's Gulag was, in many ways, less a concentration camp than a forced labor camp and less a prison system than a system of slavery. The image of the slave appears often in Gulag memoir literature. As Varlam Shalamov wrote: \"Hungry and exhausted, we leaned into a horse collar, raising blood blisters on our chests and pulling a stone-filled cart up the slanted mine floor. The collar was the same device used long ago by the ancient Egyptians.\" Thoughtful and rigorous historical comparisons of Soviet forced labor and other forms of slave labor would be worthy of scholarly attention, in my view. For as in the case of global slavery, the Gulag found legitimacy in an elaborate narrative of difference that involved the presumption of dangerousness and guilt. This ideology of difference and the violence of human exploitation have left lasting legacies in contemporary Russia.\nHistorian Anne Applebaum writes in the introduction of her book that the word \"GULAG\" has come to represent \"the system of Soviet slave labor itself, in all its forms and varieties\":\nThe word \"GULAG\" is an acronym for \"Glavnoe Upravlenie Lagerei\", or Main Camp Administration, the institution which ran the Soviet camps. But over time, the word has also come to signify the system of Soviet slave labor itself, in all its forms and varieties: labor camps, punishment camps, criminal and political camps, women's camps, children's camps, transit camps. Even more broadly, \"Gulag\" has come to mean the Soviet repressive system itself, the set of procedures that Alexander Solzhenitsyn once called \"our meat grinder\": the arrests, the interrogations, the transport in unheated cattle cars, the forced labor, the destruction of families, the years spent in exile, the early and unnecessary deaths.\nApplebaum's introduction has been criticized by Gulag researcher Wilson Bell, stating that her book \"is, \"aside from the introduction\", a well-done overview of the Gulag, but it did not offer an interpretative framework much beyond Solzhenitsyn's paradigms\".\nContemporary slavery.\nEven though slavery is now outlawed in every country, the number of slaves today is estimated as between 12\u00a0million and 29.8\u00a0million. According to a broad definition of slavery, there were 27\u00a0million people in slavery in 1999, spread all over the world. In 2005, the International Labour Organization provided an estimate of 12.3\u00a0million forced labourers. Siddharth Kara has also provided an estimate of 28.4\u00a0million slaves at the end of 2006 divided into three categories: bonded labour/debt bondage (18.1\u00a0million), forced labour (7.6\u00a0million), and trafficked slaves (2.7\u00a0million). Kara provides a dynamic model to calculate the number of slaves in the world each year, with an estimated 29.2\u00a0million at the end of 2009.\nAccording to a 2003 report by Human Rights Watch, an estimated 15\u00a0million children in debt bondage in India work in slavery-like conditions to pay off their family's debts.\nSlavoj \u017di\u017eek asserts that new forms of contemporary slavery have been created in the post-Cold War era of global capitalism, including migrant workers deprived of basic civil rights on the Arabian Peninsula, the total control of workers in Asian sweatshops and the use of forced labor in the exploitation of natural resources in Central Africa.\nDistribution.\nIn June 2013, U.S. State Department released a report on slavery. It placed Russia, China, and Uzbekistan in the worst offenders category. Cuba, Iran, North Korea, Sudan, Syria, and Zimbabwe were at the lowest level. The list also included Algeria, Libya, Saudi Arabia and Kuwait among a total of 21 countries.\nIn Kuwait, there are more than 600,000 migrant domestic workers who are vulnerable to forced labor and legally tied to their employers, who often illegally take their passports. In 2019, online slave markets on apps such as Instagram were uncovered.\nIn the preparations for the 2022 World Cup in Qatar, thousands of Nepalese, the largest group of labourers, faced slavery in the form of denial of wages, confiscation of documents, and inability to leave the workplace. In 2016, the United Nations gave Qatar 12 months to end migrant worker slavery or face investigation.\nThe Walk Free Foundation reported in 2018 that slavery in wealthy Western societies is much more prevalent than previously known, in particular the United States and Great Britain, which have 403,000 (one in 800) and 136,000 slaves respectively. Andrew Forrest, founder of the organization, said that \"The United States is one of the most advanced countries in the world yet has more than 400,000 modern slaves working under forced labour conditions.\" An estimated 40.3\u00a0million are enslaved globally, with North Korea having the most slaves at 2.6\u00a0million (one in 10). Of the estimated 40.3 million people in contemporary slavery, 71% are women and 29% are men. The report found of the 40.3 million in modern slavery, 15.4 million are in forced marriages and 24.9 million are in forced labor. The foundation defines contemporary slavery as \"situations of exploitation that a person cannot refuse or leave because of threats, violence, coercion, abuse of power, or deception.\"\nChina.\nIn March 2020, the Chinese government was found to be using the Uyghur minority for forced labour, inside sweat shops. According to a report published then by the Australian Strategic Policy Institute (ASPI), no fewer than around 80,000 Uyghurs were forcibly removed from the region of Xinjiang and used for forced labour in at least twenty-seven corporate factories. According to the Business and Human Rights resource center, corporations such as Abercrombie &amp; Fitch, Adidas, Amazon, Apple, BMW, Fila, Gap, H&amp;M, Inditex, Marks &amp; Spencer, Nike, North Face, Puma, PVH, Samsung, and UNIQLO have each sourced products from these factories prior to the publication of the ASPI report.\nLibya.\nDuring the Second Libyan Civil War, Libyans started capturing Sub-Saharan African migrants trying to get to Europe through Libya and selling them on slave markets or holding them hostage for ransom Women are often raped, used as sex slaves, or sold to brothels. Child migrants suffer from abuse and child rape in Libya.\nMauritania.\nMauritania, was the last country to abolish slavery (in 1981), it is estimated that 20% of its population of 3 million people are enslaved as bonded labourers, with black Haratin being slaves and Berbers and Arabs the owners. Slavery in Mauritania was criminalized in August 2007. However, although slavery, as a practice, was legally banned in 1981, it was not a crime to own a slave until 2007. Although many slaves have escaped or have been freed since 2007, as of 2012[ [update]], only one slave owner had been sentenced to serve time in prison.\nNorth Korea.\nNorth Korea's human rights record is often considered to be the worst in the world and has been globally condemned, with the United Nations, the European Union and groups such as Human Rights Watch all critical of the country's record. Forms of torture, forced labour, and abuses are all widespread. Most international human rights organizations consider North Korea to have no contemporary parallel with respect to violations of liberty.\nTaiwan.\nTaiwan's migrant worker population\u2014estimated in 2018 to be up to 660,000 in number\u2014have reportedly faced slavery-like conditions involving sexual abuse in the domestic work sector and forced labor in fishing sectors. Taiwan is among a minority of places in the world that legally allows labor brokers to charge migrant workers for services which elsewhere are covered by employers as human resource costs. A few Taiwanese universities have reportedly tricked students from Eswatini, Uganda and Sri Lanka into forced labour at factories as payment for the university programs. Some charity groups in 2007 also insisted that foreign women\u2014mostly from China and Southeast Asia\u2014were being forced into prostitution, although local police in Tainan disagreed and said they deliberately came to Taiwan \"to sell sex\".\nYemen.\nDespite being formally abolished in the 1960s, slavery in Yemen remains a significant issue exacerbated by ongoing conflict and socio-economic instability. An estimated 85,000 people remaining enslaved as of 2022. The Iran-backed Houthi militias have been accused of reinstating traditional slavery systems. Reports indicate that over 1,800 Yemenis have been forced into servitude by prominent Houthi leaders, with the Houthis dividing society into hierarchical classes of masters and slaves.\nThis modern slavery encompasses various forms, such as forced labor, sexual exploitation, human trafficking, and child recruitment.\nVulnerable populations include the Al Muhamash\u012bn community, Ethiopian migrants, and children who are subjected to severe discrimination and exploitation.\n \nDespite legal prohibitions against slavery in Yemen, enforcement is weak due to political instability and ongoing civil war.\nInternational organizations have documented these abuses, highlighting the need for stronger interventions to combat slavery and human trafficking in the region.\nEconomics.\nWhile American slaves in 1809 were sold for around $40,000 (in inflation adjusted dollars), a slave nowadays can be bought for just $90, making replacement more economical than providing long-term care. Slavery is a multibillion-dollar industry with estimates of up to $35\u00a0billion generated annually.\nTrafficking.\nVictims of human trafficking are typically recruited through deceit or trickery (such as a false job offer, false migration offer, or false marriage offer), sale by family members, recruitment by former slaves, or outright abduction. Victims are forced into a \"debt slavery\" situation by coercion, deception, fraud, intimidation, isolation, threat, physical force, debt bondage or even force-feeding with drugs to control their victims. \"Annually, according to U.S. government-sponsored research completed in 2006, approximately 800,000 people are trafficked across national borders, which does not include millions trafficked within their own countries. Approximately 80% of transnational victims are women and girls, and up to 50% are minors, reports the U.S. State Department in a 2008 study.\nWhile the majority of trafficking victims are women who are forced into prostitution (in which case the practice is called sex trafficking), victims also include men, women and children who are forced into manual labour. Because of the illegal nature of human trafficking, its extent is unknown. A U.S. government report, published in 2005, estimates that about 700,000 people worldwide are trafficked across borders each year. This figure does not include those who are trafficked internally. Another research effort revealed that roughly 1.5\u00a0million individuals are trafficked either internally or internationally each year, of which about 500,000 are sex trafficking victims.\nAbolitionism.\nSlavery has existed, in one form or another, throughout recorded human history\u00a0\u2013 as have, in various periods, movements to free large or distinct groups of slaves.\nIn antiquity.\nEmperor Ashoka, who ruled the Maurya Empire in the Indian subcontinent from 269 to 232 BCE, abolished the slave trade but not slavery. The Qin dynasty, which ruled China from 221 to 206 BCE, abolished slavery and discouraged serfdom. However, many of its laws were overturned when the dynasty was overthrown. Slavery was again abolished by Wang Mang in China in 17 CE but was reinstituted after his assassination.\nAmericas.\nThe Spanish colonization of the Americas sparked a discussion about the right to enslave Native Americans. A prominent critic of slavery in the Spanish New World colonies was the Spanish missionary and bishop, Bartolom\u00e9 de las Casas, who was the first to document the European maltreatment of and cruelty towards American natives.\nIn the United States, all of the northern states had abolished slavery by 1804, with New Jersey being the last to act. Abolitionist pressure produced a series of small steps towards emancipation. After the Act Prohibiting Importation of Slaves went into effect on January 1, 1808, the importation of slaves into the United States was prohibited, but not the internal slave trade, nor involvement in the international slave trade externally. Legal slavery persisted outside the northern states, but abolitionists took an active role in opposing slavery by supporting the Underground Railroad, and violent clashes between anti-slavery and pro-slavery Americans occurred, including in Bleeding Kansas, a series of political and armed disputes in 1854\u20131858 as to whether Kansas would join the United States as a slave or free state. By 1860, the total number of slaves reached almost four million, and the American Civil War, beginning in 1861, led to the end of slavery in the United States. Slaves in areas controlled by the Confederacy were legally emancipated in 1863, when Lincoln issued the Emancipation Proclamation, and slavery was banned nationwide, except as punishment for a crime, in 1865, with the ratification of the 13th Amendment to the U.S. Constitution.\nMany of the freed slaves became sharecroppers and indentured servants. In this manner, some became tied to the very parcel of land into which they had been born a slave having little freedom or economic opportunity because of Jim Crow laws which perpetuated discrimination, limited education, promoted persecution without due process and resulted in continued poverty. Fear of reprisals such as unjust incarcerations and lynchings deterred upward mobility further.\nEurope.\nFrance abolished slavery in 1794 during the Revolution, but it was restored in 1802 under Napoleon. It has been asserted that, before the Revolution, slavery was illegal in metropolitan France (as opposed to its colonies), but this has been refuted.\nOne of the most significant milestones in the campaign to abolish slavery throughout the world occurred in England in 1772, with British Judge Lord Mansfield, whose opinion in Somersett's Case was widely taken to have held that slavery was illegal in England. This judgement also laid down the principle that slavery contracted in other jurisdictions could not be enforced in England. The last person to be deemed a slave in a British court was Bell (Belinda) who was transported to the Americas in 1772 as a \"slave for life\" by a Perth court.\nSons of Africa was a late 18th-century British group that campaigned to end slavery. Its members were Africans in London, freed slaves who included Ottobah Cugoano, Olaudah Equiano and other leading members of London's black community. It was closely connected to the Society for Effecting the Abolition of the Slave Trade, a non-denominational group founded in 1787, whose members included Thomas Clarkson. British Member of Parliament William Wilberforce led the anti-slavery movement in the United Kingdom, although the groundwork was an anti-slavery essay by Clarkson. Wilberforce was urged by his close friend, Prime Minister William Pitt the Younger, to make the issue his own and was also given support by reformed Evangelical John Newton. The Slave Trade Act was passed by the British Parliament on March 25, 1807, making the slave trade illegal throughout the British Empire, Wilberforce also campaigned for abolition of slavery in the British Empire, which he lived to see in the Slavery Abolition Act 1833.\nAfter the 1807 act abolishing the slave trade was passed, these campaigners switched to encouraging other countries to follow suit, notably France and the British colonies. Between 1808 and 1860, the British West Africa Squadron seized approximately 1,600 slave ships and freed 150,000 Africans who were aboard. Action was also taken against African leaders who refused to agree to British treaties to outlaw the trade, for example against \"the usurping King of Lagos\", deposed in 1851. Anti-slavery treaties were signed with over 50 African rulers.\nWorldwide.\nIn 1839, the world's oldest international human rights organization, Anti-Slavery International, was formed in Britain by Joseph Sturge, which campaigned to outlaw slavery in other countries. There were celebrations in 2007 to commemorate the 200th anniversary of the abolition of the slave trade in the United Kingdom through the work of the British Anti-Slavery Society.\nIn the 1860s, David Livingstone's reports of atrocities within the Arab slave trade in Africa stirred up the interest of the British public, reviving the flagging abolitionist movement. The Royal Navy throughout the 1870s attempted to suppress \"this abominable Eastern trade\", at Zanzibar in particular. In 1905, the French abolished indigenous slavery in most of French West Africa.\nOn December 10, 1948, the United Nations General Assembly adopted the Universal Declaration of Human Rights, which declared freedom from slavery is an internationally recognized human right. Article 4 of the Universal Declaration of Human Rights states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;No one shall be held in slavery or servitude; slavery and the slave trade shall be prohibited in all their forms.\nIn 2014, for the first time in history, major leaders of many religions, Buddhist, Hindu, Christian, Jewish, and Muslim met to sign a shared commitment against modern-day slavery; the declaration they signed calls for the elimination of slavery and human trafficking by 2020. The signatories were: Pope Francis, M\u0101t\u0101 Am\u1e5bt\u0101nandamay\u012b, Bhikkhuni Thich Nu Ch\u00e2n Kh\u00f4ng (representing Zen Master Th\u00edch Nh\u1ea5t H\u1ea1nh), Datuk K Sri Dhammaratana, Chief High Priest of Malaysia, Rabbi Abraham Skorka, Rabbi David Rosen, Abbas Abdalla Abbas Soliman, Undersecretary of State of Al Azhar Alsharif (representing Mohamed Ahmed El-Tayeb, Grand Imam of Al-Azhar), Grand Ayatollah Mohammad Taqi al-Modarresi, Sheikh Naziyah Razzaq Jaafar, Special advisor of Grand Ayatollah (representing Grand Ayatollah Sheikh Basheer Hussain al Najafi), Sheikh Omar Abboud, Justin Welby, Archbishop of Canterbury, and Metropolitan Emmanuel of France (representing Ecumenical Patriarch Bartholomew.)\nGroups such as the American Anti-Slavery Group, Anti-Slavery International, Free the Slaves, the Anti-Slavery Society, and the Norwegian Anti-Slavery Society continue to campaign to eliminate slavery.\nUNESCO has been working to break the silence surrounding the memory of slavery since 1994, through The Slave Route Project.\nApologies.\nOn May 21, 2001, the National Assembly of France passed the Taubira law, recognizing slavery as a crime against humanity. Apologies on behalf of African nations, for their role in trading their countrymen into slavery, remain an open issue since slavery was practiced in Africa even before the first Europeans arrived and the Atlantic slave trade was performed with a high degree of involvement of several African societies. The black slave market was supplied by well-established slave trade networks controlled by local African societies and individuals.\nThere is adequate evidence citing case after case of African control of segments of the trade. Several African nations such as the Calabar and other southern parts of Nigeria had economies depended solely on the trade. African peoples such as the Imbangala of Angola and the Nyamwezi of Tanzania would serve as middlemen or roving bands warring with other African nations to capture Africans for Europeans.\nSeveral historians have made important contributions to the global understanding of the African side of the Atlantic slave trade. By arguing that African merchants determined the assemblage of trade goods accepted in exchange for slaves, many historians argue for African agency and ultimately a shared responsibility for the slave trade.\nIn 1999, President Mathieu K\u00e9r\u00e9kou of Benin issued a national apology for the central role Africans played in the Atlantic slave trade. Luc Gnacadja, minister of environment and housing for Benin, later said: \"The slave trade is a shame, and we do repent for it.\" Researchers estimate that 3\u00a0million slaves were exported out of the Slave Coast bordering the Bight of Benin. President Jerry Rawlings of Ghana also apologized for his country's involvement in the slave trade.\nThe issue of an apology is linked to reparations for slavery and is still being pursued by entities across the world. For example, the Jamaican Reparations Movement approved its declaration and action plan. In 2007, British Prime Minister Tony Blair made a formal apology for Great Britain's involvement in slavery.\nOn February 25, 2007, the Commonwealth of Virginia resolved to 'profoundly regret' and apologize for its role in the institution of slavery. Unique and the first of its kind in the U.S., the apology was unanimously passed in both Houses as Virginia approached the 400th anniversary of the founding of Jamestown.\nOn August 24, 2007, Mayor of London Ken Livingstone issued a public apology for London's role in Atlantic slave trade, which took place at an event commemorating the 200th anniversary of the British slave trade's abolition. In his speech, Livingstone described the slave trade as \"the racial murder of not just those who were transported but generations of enslaved African men, women and children. To justify this murder and torture black people had to be declared inferior or not human... We live with the consequences today.\" City officials in Liverpool, which was a large slave trading port, apologized in 1999.\nOn July 30, 2008, the United States House of Representatives passed a resolution apologizing for American slavery and subsequent discriminatory laws. In June 2009, the U.S. Senate passed a resolution apologizing to African-Americans for the \"fundamental injustice, cruelty, brutality, and inhumanity of slavery\". The news was welcomed by President Barack Obama, the nation's first president of African descent. Some of President Obama's ancestors may have been slave owners.\nIn 2010, Libyan leader Muammar Gaddafi apologized for Arab involvement in the slave trade, saying: \"I regret the behavior of the Arabs... They brought African children to North Africa, they made them slaves, they sold them like animals, and they took them as slaves and traded them in a shameful way.\"\nReparations.\nThere have been movements to achieve reparations for those formerly held as slaves or for their descendants. Claims for reparations for being held in slavery are handled as a civil law matter in almost every country. This is often decried as a serious problem, since former slaves' relatives lack of money means they often have limited access to a potentially expensive and futile legal process. Mandatory systems of fines and reparations paid to an as yet undetermined group of claimants from fines, paid by unspecified parties, and collected by authorities have been proposed by advocates to alleviate this \"civil court problem.\" Since in almost all cases there are no living ex-slaves or living ex-slave owners these movements have gained little traction. In nearly all cases the judicial system has ruled that the statute of limitations on these possible claims has long since expired.\nIn June 2023, The Brattle Group presented a report at an event at the University of the West Indies in which reparations were estimated, for harms both during and after the period of transatlantic chattel slavery, at over 100 trillion dollars.\nMedia.\nFilm has been the most influential medium in the presentation of the history of slavery to the general public around the world. The American film industry has had a complex relationship with slavery and until recent decades often avoided the topic. Films such as \"The Birth of a Nation\" (1915) and \"Gone with the Wind\" (1939) became controversial because they gave a favourable depiction. In 1940 \"The Santa Fe Trail\" gave a liberal but ambiguous interpretation of John Brown's attacks on slavery.\nThe Civil Rights Movement in the 1950s made defiant slaves into heroes. The question of slavery in American memory necessarily involves its depictions in feature films.\nMost Hollywood films used American settings, although \"Spartacus\" (1960), dealt with an actual revolt in the Roman Empire known as the Third Servile War. The revolt failed, and all the rebels were executed, but their spirit lived on according to the film. \"Spartacus\" stays surprisingly close to the historical record.\n\"The Last Supper\" (\"La \u00faltima cena\" in Spanish) was a 1976 film directed by Cuban Tom\u00e1s Guti\u00e9rrez Alea about the teaching of Christianity to slaves in Cuba, and emphasizes the role of ritual and revolt. \"Burn!\" takes place on the imaginary Portuguese island of Queimada (where the locals speak Spanish) and it merges historical events that took place in Brazil, Cuba, Santo Domingo, Jamaica, and elsewhere.\nHistorians agree that films have largely shaped historical memories, but they debate issues of accuracy, plausibility, moralism, sensationalism, how facts are stretched in search of broader truths, and suitability for the classroom. Berlin argues that critics complain if the treatment emphasizes historical brutality, or if it glosses over the harshness to highlight the emotional impact of slavery.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27993", "revid": "51063856", "url": "https://en.wikipedia.org/wiki?curid=27993", "title": "September 17", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearSeptember 17 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27995", "revid": "764407", "url": "https://en.wikipedia.org/wiki?curid=27995", "title": "Supply chain management", "text": "Management of the flow of goods and services\nIn commerce, supply chain management (SCM) deals with a system of procurement (purchasing raw materials/components), operations management, logistics and marketing channels, through which raw materials can be developed into finished products and delivered to their end customers. A more narrow definition of supply chain management is the \"design, planning, execution, control, and monitoring of supply chain activities with the objective of creating net value, building a competitive infrastructure, leveraging worldwide logistics, synchronising supply with demand and measuring performance globally\". This can include the movement and storage of raw materials, work-in-process inventory, finished goods, and end to end order fulfilment from the point of origin to the point of consumption. Interconnected, interrelated or interlinked networks, channels and node businesses combine in the provision of products and services required by end customers in a supply chain.\nSCM is the broad range of activities required to plan, control and execute a product's flow from materials to production to distribution in the most economical way possible. SCM encompasses the integrated planning and execution of processes required to optimize the flow of materials, information and capital in functions that broadly include demand planning, sourcing, production, inventory management and logistics\u2014or storage and transportation.\nSupply chain management strives for an integrated, multidisciplinary, multimethod approach. Current research in supply chain management is concerned with topics related to resilience, sustainability, and risk management, among others. Some suggest that the \"people dimension\" of SCM, ethical issues, internal integration, transparency/visibility, and human capital/talent management are topics that have, so far, been underrepresented on the research agenda.\nIntention.\nSupply chain management, techniques with the aim of coordinating all parts of SC, from supplying raw materials to delivering and/or resumption of products, tries to minimize total costs with respect to existing conflicts among the chain partners. An example of these conflicts is the interrelation between the sale department desiring to have higher inventory levels to fulfill demands and the warehouse for which lower inventories are desired to reduce holding costs.\nOrigin of the term and definitions.\nIn 1982, Keith Oliver, a consultant at Booz Allen Hamilton, introduced the term \"supply chain management\" to the public domain in an interview for the Financial Times. In 1983 WirtschaftsWoche in Germany published for the first time the results of an implemented and so called \"Supply Chain Management project\", led by Wolfgang Partsch.\nIn the mid-1990s, the term \"supply chain management\" gained popularity when a flurry of articles and books came out on the subject. Supply chains were originally defined as encompassing all activities associated with the flow and transformation of goods from raw materials through to the end user or final consumer, as well as the associated information flows. Mentzer \"et al.\" consider it worthy of note that the final consumer was included within these early definitions. Supply chain management was then further defined as the integration of supply chain activities through improved supply chain relationships to achieve a competitive advantage.\nIn the late 1990s, \"supply chain management\" (SCM) rose to prominence, and operations managers began to use it in their titles with increasing regularity. A supply chain, as opposed to supply chain management, is a set of firms who move materials \"forward\", or a set of organizations, directly linked by one or more upstream and downstream flows of products, services, finances, or information from a source to a customer. Supply chain management is the management of such a chain.\nOther commonly accepted definitions of supply chain management include:\nMentzer \"et al.\" make a further distinction between \"supply chain management\" and a \"supply chain orientation\". The latter term involves a recognition that a business strategy cannot be fulfilled without managing the activities of suppliers and customers upstream and downstream, whereas the former term is used for \"the actual implementation of this orientation\".\nSupply chain visibility, in its origins, was concerned with knowledge of the location, production stage and expected delivery date of incoming products and materials, so that production could be planned, but the development of the term has enabled it to be used to plan orders using knowledge of potential supplies, and to track post-production processes as far as delivery to customers. The UK Government also uses the term \"supply chain visibility\" in conjunction with its mandate to ensure that potential suppliers have visibility into future supply opportunities. The government's action note on supply chain visibility covers obligations and appropriate contractual wording requiring prime suppliers to advertise sub-contracting opportunities and to report on their spend with small and medium-sized enterprises and voluntary/community organisations within their supply chains. The concept of a \"supply chain control tower\" reflects the \"end-to-end visibility\" provided by an air traffic control tower. Writing for Gartner, sees a \"supply chain control tower\" as a concept which combines the capacities of \"people, process, data, organization and technology\" to improve supply chain visibility, noting that the technology behind a system which draws together information from a number of sources should not be separated from the people and processes it supports in order to improve visibility. \nSupply chain management software includes tools or modules used to execute supply chain transactions, manage supplier relationships, and control associated business processes. The overall goal of the software is to improve supply chain performance by monitoring a company's supply chain network from end-to-end (suppliers, transporters, returns, warehouses, retailers, manufacturers, and customers).\nIn some cases, a supply chain includes the collection of goods after consumer use for recycling or the reverse logistics processes for returning faulty or unwanted products back to producers up the value chain.\nFunctions.\nSupply chain management is a cross-functional approach that includes managing the movement of raw materials into an organization, certain aspects of the internal processing of materials into finished goods, and the movement of finished goods out of the organization and toward the end consumer. As organizations strive to focus on core competencies and become more flexible, they reduce ownership of raw materials sources and distribution channels. These functions are increasingly being outsourced to other firms that can perform the activities better or more cost effectively. The effect is to increase the number of organizations involved in satisfying customer demand, while reducing managerial control of daily logistics operations. Less control and more supply chain partners lead to the creation of the concept of supply chain management. Supply chain management is concerned with improving trust and collaboration among supply chain partners, thus improving inventory visibility and the velocity of inventory movement.\nImportance.\nOrganizations increasingly find that they must rely on effective supply chains, or networks, to compete in the global market and networked economy. In Peter Drucker's (1998) new management paradigms, this concept of business relationships extends beyond traditional enterprise boundaries and seeks to organize entire business processes throughout a value chain of multiple companies. According to Drucker, \"the greatest change in corporate culture\u2014and the way business is being conducted\u2014may be the accelerated growth of relationships based not on ownership, but on partnership.\" This approach allows companies to leverage the strengths and capabilities of various partners to achieve greater efficiency and innovation, ultimately enhancing overall business performance.\nIn recent decades, globalization, outsourcing, and information technology have enabled many organizations, such as Dell and Hewlett-Packard, to successfully operate collaborative supply networks in which each specialized business partner focuses on only a few key strategic activities. This inter-organizational supply network can be acknowledged as a new form of organization. However, with the complicated interactions among the players, the network structure fits neither \"market\" nor \"hierarchy\" categories. It is not clear what kind of performance impacts different supply-network structures could have on firms, and little is known about the coordination conditions and trade-offs that may exist among the players. From a systems perspective, a complex network structure can be decomposed into individual component firms. Traditionally, companies in a supply network concentrate on the inputs and outputs of the processes, with little concern for the internal management working of other individual players. Therefore, the choice of an internal management control structure is known to impact local firm performance.\nIn the 21st century, changes in the business environment have contributed to the development of supply chain networks. First, as an outcome of globalization and the proliferation of multinational companies, joint ventures, strategic alliances, and business partnerships, significant success factors were identified, complementing the earlier \"just-in-time\", lean manufacturing, and agile manufacturing practices. Second, technological changes, particularly the dramatic fall in communication costs (a significant component of transaction costs), have led to changes in coordination among the members of the supply chain network.\nMany researchers have recognized supply network structures as a new organizational form, using terms such as \"Keiretsu\", \"Extended Enterprise\", \"virtual supply chain\", \"Global Production Network\", and \"Next Generation Manufacturing System\". In general, such a structure can be defined as \"a group of semi-independent organizations, each with their capabilities, which collaborate in ever-changing constellations to serve one or more markets in order to achieve some business goal specific to that collaboration\".\nThe importance of supply chain management proved crucial in the 2019-2020 fight against the coronavirus (COVID-19) pandemic that swept across the world. During the pandemic period, governments in countries which had in place effective domestic supply chain management had enough medical supplies to support their needs and enough to donate their surplus to front-line health workers in other jurisdictions. The devastating COVID-19 crisis in US has turned many sectors of the local economy upside down, including the country's storied logistics industry. Some organizations were able to quickly develop foreign supply chains in order to import much needed medical supplies.\nSupply chain management is also important for organizational learning. Firms with geographically more extensive supply chains connecting diverse trading cliques tend to become more innovative and productive.\nThe security-management system for supply chains is described in ISO/IEC 28000 and ISO/IEC 28001 and related standards published jointly by the ISO and the IEC. Supply Chain Management draws heavily from the areas of operations management, logistics, procurement, and information technology, and strives for an integrated approach.\nSupply chain resilience.\nAn important element of SCM is supply chain resilience, defined as \"the capacity of a supply chain to persist, adapt, or transform in the face of change\". For a long time, the interpretation of resilience in the sense of engineering resilience (= robustness) prevailed in supply chain management, leading to the notion of \"persistence\". A popular implementation of this idea is given by measuring the \"time-to-survive\" and the \"time-to-recover\" of the supply chain, allowing to identify weak points in the system. The APICS Certified Supply Chain Professional (CSCP) program emphasizes the importance of managing risks and enhancing resilience. According to APICS, in order to manage global interruptions and preserve operational continuity, a robust supply chain is vital.\nMore recently, the interpretations of resilience in the sense of ecological resilience and social\u2013ecological resilience have led to the notions of \"adaptation\" and \"transformation\", respectively. A supply chain is thus interpreted as a social-ecological system that \u2013 similar to an ecosystem (e.g. forest) \u2013 is able to constantly adapt to external environmental conditions and \u2013 through the presence of social actors and their ability to foresight \u2013 also to transform itself into a fundamentally new system. This leads to a panarchical interpretation of a supply chain, embedding it into a system of systems, allowing to analyze the interactions of the supply chain with systems that operate at other levels (e.g. society, political economy, planet Earth).\nFor example, these three components of resilience can be discussed for the 2021 Suez Canal obstruction, when a ship blocked the canal for several days. Persistence means to \"bounce back\"; in our example it is about removing the ship as quickly as possible to allow \"normal\" operations. Adaptation means to accept that the system has reached a \"new normal\" state and to act accordingly; here, this can be implemented by redirecting ships around the African cape or use alternative modes of transport. Finally, transformation means to question the assumptions of globalization, outsourcing and linear supply chains and to envision alternatives; in this example this could lead to local and circular supply chains that do not need global transportation routes any longer.\nHistorical developments.\nSix major movements can be observed in the evolution of supply chain management studies: creation, integration, globalization, specialization phases one and two, and SCM 2.0.\nCreation era.\nThe term \"supply chain management\" was first coined by Keith Oliver in 1982. However, the concept of a supply chain in management was of great importance long before, in the early 20th century, especially with the creation of the assembly line. The characteristics of this era of supply chain management include the need for large-scale changes, re-engineering, downsizing driven by cost reduction programs, and widespread attention to Japanese management practices. However, the term became widely adopted after the publication of the seminal book \"Introduction to Supply Chain Management\" in 1999 by Robert B. Handfield and Ernest L. Nichols, Jr., which published over 25,000 copies and was translated into Japanese, Korean, Chinese, and Russian.\nIntegration era.\nThis era of supply chain management studies was highlighted with the development of electronic data interchange (EDI) systems in the 1960s and developed through the 1990s by the introduction of enterprise resource planning (ERP) systems. This era has continued to develop into the 21st century with the expansion of Internet-based collaborative systems. This era of supply chain evolution is characterized by both increasing value-added and reducing costs through integration.\nA supply chain can be classified as a stage 1, 2, or 3 network. In stage 1\u2013type supply chain, systems such as production, storage, distribution, and material control are not linked and are independent of each other. In a stage 2 supply chain, these are integrated under one plan, and enterprise resource planning (ERP) is enabled. A stage 3 supply chain is one that achieves vertical integration with upstream suppliers and downstream customers. An example of this kind of supply chain is Tesco.\nGlobalization era.\nIt is the third movement of supply chain management development, the globalization era, can be characterized by the attention given to global systems of supplier relationships and the expansion of supply chains beyond national boundaries and into other continents. Although the use of global sources in organizations' supply chains can be traced back several decades (e.g., in the oil industry), it was not until the late 1980s that a considerable number of organizations started to integrate global sources into their core business. This era is characterized by the globalization of supply chain management in organizations with the goal of increasing their competitive advantage, adding value, and reducing costs through global sourcing.\nSpecialization era (phase I): outsourced manufacturing and distribution.\nIn the 1990s, companies began to focus on \"core competencies\" and specialization. They abandoned vertical integration, sold off non-core operations, and outsourced those functions to other companies. This changed management requirements, as the supply chain extended beyond the company walls and management was distributed across specialized supply chain partnerships.\nThis transition also refocused the fundamental perspectives of each organization. Original equipment manufacturers (OEMs) became brand owners that required visibility deep into their supply base. They had to control the entire supply chain from above, instead of from within. Contract manufacturers had to manage bills of material with different part-numbering schemes from multiple OEMs and support customer requests for work-in-process visibility and vendor-managed inventory (VMI).\nThe specialization model creates manufacturing and distribution networks composed of several individual supply chains specific to producers, suppliers, and customers that work together to design, manufacture, distribute, market, sell, and service a product. This set of partners may change according to a given market, region, or channel, resulting in a proliferation of trading partner environments, each with its own unique characteristics and demands.\nSpecialization era (phase II): supply chain management as a service.\nSpecialization within the supply chain began in the 1980s with the inception of transportation brokerages, warehouse management (storage and inventory), and non-asset-based carriers, and has matured beyond transportation and logistics into aspects of supply planning, collaboration, execution, and performance management.\nMarket forces sometimes demand rapid changes from suppliers, logistics providers, locations, or customers in their role as components of supply chain networks. This variability has significant effects on supply chain infrastructure, from the foundation layers of establishing and managing electronic communication between trading partners to more complex requirements such as the configuration of processes and workflows that are essential to the management of the network itself.\nSupply chain specialization enables companies to improve their overall competencies in the same way that outsourced manufacturing and distribution has done; it allows them to focus on their core competencies and assemble networks of specific, best-in-class partners to contribute to the overall value chain itself, thereby increasing overall performance and efficiency. The ability to quickly obtain and deploy this domain-specific supply chain expertise without developing and maintaining an entirely unique and complex competency in house is a leading reason why supply chain specialization is gaining popularity.\nOutsourced technology hosting for supply chain solutions debuted in the late 1990s and has taken root primarily in transportation and collaboration categories. This has progressed from the application service provider (ASP) model from roughly 1998 through 2003 to the on-demand model from approximately 2003 through 2006, to the software as a service (SaaS) model currently in focus today.\nSupply chain management 2.0 (SCM 2.0).\nThe term SCM 2.0 has been coined to describe both changes within supply chains themselves as well as the evolution of processes, methods, and tools to manage them in a new era of globalization and specialization. One element of this is the growing popularity of supply chain collaboration platforms that connect multiple buyers and suppliers with financial institutions, enabling them to conduct automated supply chain finance transactions.\nWeb 2.0 is a trend in the use of the World Wide Web that is meant to increase creativity, information sharing, and collaboration among users. At its core, the common attribute of Web 2.0 is to help navigate the vast information available on the Web in order to find what is being bought. It is the notion of a usable pathway. SCM 2.0 replicates this notion in supply chain operations. It is the pathway to SCM results, a combination of processes, methodologies, tools, and delivery options to guide companies to their results quickly as the complexity and speed of the supply chain increase due to global competition; rapid price fluctuations; changing oil prices; short product life cycles; expanded specialization; near-, far-, and off-shoring; and talent scarcity. \nIncreasing volatility has characterized supply chains since about 2000. Douglass in 2010 referred to an SCM management style known as \"extreme supply chain management\", which:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nBusiness-process integration.\nSuccessful SCM requires a change from managing individual functions to integrating activities into key supply chain processes. In an example scenario, a purchasing department places orders as its requirements become known. The marketing department, responding to customer demand, communicates with several distributors and retailers as it attempts to determine ways to satisfy this demand. Information shared between supply chain partners can only be fully leveraged through business process integration, e.g., using electronic data interchange.\nSupply chain business process integration involves collaborative work between buyers and suppliers, joint product development, common systems, and shared information. According to Lambert and Cooper (2000), operating an integrated supply chain requires a continuous information flow. However, in many companies, management has concluded that optimizing product flows cannot be accomplished without implementing a process approach. The key supply chain processes as stated by Lambert (2004) are:\nMuch has been written about demand management. Best-in-class companies have similar characteristics, which include the following:\nOne could suggest other critical supply business processes that combine these processes stated by Lambert, such as:\n Customer relationship management concerns the relationship between an organization and its customers. Customer service is the source of customer information. It also provides the customer with real-time information on scheduling and product availability through interfaces with the company's production and distribution operations. Successful organizations use the following steps to build customer relationships:\n* determine mutually satisfying goals for organization and customers\n* establish and maintain customer rapport\n* induce positive feelings in the organization and the customers\nBusiness strategy integration.\nEffective business process integration in supply chain management requires not only continuous communication, but also strategic coordination across departments and partner companies. The main reason for this is that it can effectively improve agility. At the same time, this integration can help businesses respond quickly to changes in demand and improve customer satisfaction.\nInventory management is concerned with ensuring the right stock at the right levels, in the right place, at the right time and the right cost. Inventory management entails inventory planning and forecasting: forecasting helps planning inventory.\n Strategic plans are drawn up with suppliers to support the manufacturing flow management process and the development of new products. In firms whose operations extend globally, sourcing may be managed on a global basis. The desired outcome is a relationship where both parties benefit and a reduction in the time required for the product's design and development. The purchasing function may also develop rapid communication systems, such as electronic data interchange (EDI) and internet linkage, to convey possible requirements more rapidly. Activities related to obtaining products and materials from outside suppliers involve resource planning, supply sourcing, negotiation, order placement, inbound transportation, storage, handling, and quality assurance, many of which include the responsibility to coordinate with suppliers on matters of scheduling, supply continuity (inventory), hedging, and research into new sources or programs. Procurement has recently been recognized as a core source of value, driven largely by the increasing trends to outsource products and services, and the changes in the global ecosystem requiring stronger relationships between buyers and sellers.\n Here, customers and suppliers must be integrated into the product development process in order to reduce the time to market. As product life cycles shorten, the appropriate products must be developed and successfully launched with ever-shorter time schedules in order for firms to remain competitive. According to Lambert and Cooper (2000), managers of the product development and commercialization process must:\n# coordinate with customer relationship management to identify customer-articulated needs;\n# select materials and suppliers in conjunction with procurement; and\n# develop production technology in manufacturing flow to manufacture and integrate into the best supply chain flow for the given combination of product and markets.\nIntegration of suppliers into the new product development process was shown to have a major impact on product target cost, quality, delivery, and market share. Tapping into suppliers as a source of innovation requires an extensive process characterized by development of technology sharing, but also involves managing intellectual property issues.\n The manufacturing process produces and supplies products to the distribution channels based on past forecasts. Manufacturing processes must be flexible in order to respond to market changes and must accommodate mass customization. Orders are processes operating on a just-in-time (JIT) basis in minimum lot sizes. Changes in the manufacturing flow process lead to shorter cycle times (cycle time compression), meaning improved responsiveness and efficiency in meeting customer demand. La Londe and Masters found in 1994 research that improved supply chain management and cycle time compression were complementary strategies adopted by forward-looking businesses in the United States. This process manages activities related to planning, scheduling, and supporting manufacturing operations, such as work-in-process storage, handling, transportation, and time phasing of components, inventory at manufacturing sites, and maximum flexibility in the coordination of geographical and final assemblies postponement of physical distribution operations.\n This concerns the movement of a finished product or service to customers. In physical distribution, the customer is the final destination of a marketing channel, and the availability of the product or service is a vital part of each channel participant's marketing effort. It is also through the physical distribution process that the time and space of customer service become an integral part of marketing. Thus it links a marketing channel with its customers (i.e., it links manufacturers, wholesalers, and retailers).\n Fleet management is the function within supply chain management that is responsible for overseeing a company's fleet of vehicles. This includes not only trucks and vans but also other assets like ships, planes, and specialized machinery. The primary goals are to ensure the efficient and safe operation of these assets, manage maintenance schedules, and control costs, particularly fuel consumption.\nModern fleet management is a key component of fleet digitalization. It relies heavily on telematics and vehicle tracking systems to provide real-time data on vehicle location, driver behavior, and engine diagnostics. This telemetry data is used to optimize routes, schedule predictive maintenance, and enhance the overall visibility and control of the physical distribution network.\n This includes not just the outsourcing of the procurement of materials and components, but also the outsourcing of services that traditionally have been provided in-house. The logic of this trend is that the company will increasingly focus on those activities in the value chain in which it has a distinctive advantage and outsource everything else. This movement has been particularly evident in logistics, where the provision of transport, storage, and inventory control is increasingly subcontracted to specialists or logistics partners. Also, managing and controlling this network of partners and suppliers requires a blend of central and local involvement: strategic decisions are taken centrally, while the monitoring and control of supplier performance and day-to-day liaison with logistics partners are best managed locally.\n Experts found a strong relationship from the largest arcs of supplier and customer integration to market share and profitability. Taking advantage of supplier capabilities and emphasizing a long-term supply chain perspective in customer relationships can both be correlated with a firm's performance. As logistics competency becomes a critical factor in creating and maintaining competitive advantage, measuring logistics performance becomes increasingly important, because the difference between profitable and unprofitable operations becomes narrower. A.T. Kearney Consultants (1985) noted that firms engaging in comprehensive performance measurement realized improvements in overall productivity. According to experts, internal measures are generally collected and analyzed by the firm, including cost, customer service, productivity, asset measurement, and quality. External performance is measured through customer perception measures and \"best practice\" benchmarking.\n To reduce a company's cost and expenses, warehousing management is concerned with storage, reducing manpower cost, dispatching authority with on time delivery, loading and unloading facilities with proper area, inventory management system etc.\n Integrating suppliers and customers tightly into a workflow (or business process) and thereby achieving an efficient and effective supply chain is a key goal of workflow management.\nTheories.\nThere are gaps in the literature on supply chain management studies at present. A few authors, such as Halldorsson et al., Ketchen and Hult (2006), and Lavassani et al. (2009), have tried to provide theoretical foundations for different areas related to supply chain by employing organizational theories, which may include the following:\nHowever, the unit of analysis of most of these theories is not the supply chain but rather another system, such as the firm or the supplier-buyer relationship. Among the few exceptions is the relational view, which outlines a theory for considering dyads and networks of firms as a key unit of analysis for explaining superior individual firm performance (Dyer and Singh, 1998).\nOrganization and governance.\nThe management of supply chains involve a number of specific challenges regarding the organization of relationships among the different partners along the value chain. Formal and informal governance mechanisms are central elements in the management of supply chain. Particular combinations of governance mechanisms may impact the relational dynamics within the supply chain. The need for interdisciplinarity in SCM research has been pointed out by academics in the field.\nSupply chain centroids.\nIn the study of supply chain management, the concept of centroids has become a useful economic consideration. In mathematics and physics, a centroid is the arithmetic mean position of all the points in a plane figure. For supply chain management, a centroid is a location with a high proportion of a country's population and a high proportion of its manufacturing, generally within . In the US, two major supply chain centroids have been defined, one near Dayton, Ohio, and a second near Riverside, California.\nThe centroid near Dayton is particularly important because it is closest to the population center of the US and Canada. Dayton is within 500\u00a0miles of 60% of the US population and manufacturing capacity, as well as 60% of Canada's population. The region includes the interchange between I-70 and I-75, one of the busiest in the nation, with 154,000 vehicles passing through per day, of which 30\u201335% are trucks hauling goods. In addition, the I-75 corridor is home to the busiest north\u2013south rail route east of the Mississippi River.\nA supply chain is the network of all the individuals, organizations, resources, activities and technology involved in the creation and sale of a product. A supply chain encompasses everything from the delivery of source materials from the supplier to the manufacturer through to its eventual delivery to the end user. The supply chain segment involved with getting the finished product from the manufacturer to the consumer is known as the distribution channel.\nWal-Mart strategic sourcing approaches.\nIn 2010, Wal-Mart announced a big change in its sourcing strategy. Initially, Wal-Mart relied on intermediaries in the sourcing process. It bought only 20% of its stock directly, but the rest were bought through the intermediaries. Therefore, the company came to realize that the presence of many intermediaries in the product sourcing was actually increasing the costs in the supply chain. To cut these costs, Wal-Mart decided to do away with intermediaries in the supply chain and started direct sourcing of its goods from the suppliers. Eduardo Castro-Wright, the then Vice President of Wal-Mart, set an ambitious goal of buying 80% of all Wal-Mart goods directly from the suppliers. Walmart started purchasing fruits and vegetables on a global scale, where it interacted directly with the suppliers of these goods. The company later engaged the suppliers of other goods, such as cloth and home electronics appliances, directly and eliminated the importing agents. The purchaser, in this case Wal-Mart, can easily direct the suppliers on how to manufacture certain products so that they can be acceptable to the consumers. Thus, Wal-Mart, through direct sourcing, manages to get the exact product quality as it expects, since it engages the suppliers in the producing of these products, hence quality consistency. Using agents in the sourcing process in most cases lead to inconsistency in the quality of the products, since the agent's source the products from different manufacturers that have varying qualities.\nWal-Mart managed to source directly 80% profit its stock; this has greatly eliminated the intermediaries and cut down the costs between 5-15%, as markups that are introduced by these middlemen in the supply chain are cut. This saves approximately $4\u201315 billion. This strategy of direct sourcing not only helped Wal-Mart in reducing the costs in the supply chain but also helped in the improvement of supply chain activities through boosting efficiency throughout the entire process. In other words, direct sourcing reduced the time that takes the company to source and stocks the products in its stock. The presence of the intermediaries elongated the time in the process of procurement, which sometimes led to delays in the supply of the commodities in the stores, thus, customers finding empty shelves. Wal-Mart adopted this strategy of sourcing through centralizing the entire process of procurement and sourcing by setting up four global merchandising points for general goods and clothing. The company instructed all the suppliers to bring their products to these central points that are located in different markets. The procurement team assesses the quality brought by the suppliers, buys the goods, and distributes them to various regional markets. The procurement and sourcing at centralized places helped the company to consolidate the suppliers.\nThe company has established four centralized points, including an office in Mexico City and Canada. Just a mere piloting test on combining the purchase of fresh apples across the United States, Mexico, and Canada led to the savings of about 10%. As a result, the company intended to increase centralization of its procurement in North America for all its fresh fruits and vegetables. Thus, centralization of the procurement process to various points where the suppliers would be meeting with the procurement team is the latest strategy which the company is implementing, and signs show that this strategy is going to cut costs and also improve the efficiency of the procurement process.\nStrategic vendor partnerships is another strategy the company is using in the sourcing process. Wal-Mart realized that in order for it to ensure consistency in the quality of the products it offers to the consumers and also maintain a steady supply of goods in its stores at a lower cost, it had to create strategic vendor partnerships with the suppliers. Wal-Mart identified and selected the suppliers who met its demand and at the same time offered it the best prices for the goods. It then made a strategic relationship with these vendors by offering and assuring the long-term and high volume of purchases in exchange for the lowest possible prices. Thus, the company has managed to source its products from same suppliers as bulks, but at lower prices. This enables the company to offer competitive prices for its products in its stores, hence, maintaining a competitive advantage over its competitors whose goods are a more expensive in comparison.\nAnother sourcing strategy Wal-Mart uses is implementing efficient communication relationships with the vendor networks; this is necessary to improve the material flow. The company has all the contacts with the suppliers whom they communicate regularly and make dates on when the goods would be needed, so that the suppliers get ready to deliver the goods in time. The efficient communication between the company's procurement team and the inventory management team enables the company to source goods and fill its shelves on time, without causing delays and empty shelves. In other words, the company realized that in ensuring a steady flow of the goods into the store, the suppliers have to be informed early enough, so that they can act accordingly to avoid delays in the delivery of goods. Thus, efficient communication is another tool which Wal-Mart is using to make the supply chain be more efficient and to cut costs.\nCross-docking is another strategy that Wal-Mart is using to cut costs in its supply chain. Cross-docking is the process of transferring goods directly from inbound trucks to outbound trucks. When the trucks from the suppliers arrive at the distribution centers, most of the trucks are not offloaded to keep the goods in the distribution centers or warehouses; they are transferred directly to another truck designated to deliver goods to specific retail stores for sale. Cross-docking helps in saving the storage costs. Initially, the company was incurring considerable costs of storing the goods from the suppliers in its warehouses and the distributions centers to await the distribution trucks to the retail stores in various regions.\nTax-efficient supply chain management.\nTax-efficient supply chain management is a business model that considers the effect of tax in the design and implementation of supply chain management. As the consequence of globalization, cross-national businesses pay different tax rates in different countries. Due to these differences, they may legally optimize their supply chain and increase profits based on tax efficiency.\nSustainability and social responsibility in supply chains.\nSupply chain networks are integral to an economy, but their health is dependent on the well-being of the environment and society. Supply chain sustainability is a business issue affecting an organization's supply chain or logistics network, and is frequently quantified by comparison with SECH ratings, which address social, ethical, cultural, and health footprints. These build on the triple bottom line incorporating economic, social, and environmental aspects. The more commonly used ESG terminology represents Environment, Social and Governance. Consumers have become more aware of the environmental impact of their purchases and companies' ratings and, along with non-governmental organizations (NGOs), are setting the agenda, and beginning to push for transitions to more sustainable approaches such as organically grown foods, anti-sweatshop labor codes, and locally produced goods that support independent and small businesses. Because supply chains may account for over 75% of a company's carbon footprint, many organizations are exploring ways to reduce this and thus improve their profile.\nFor example, in July 2009, Wal-Mart announced its intentions to create a global sustainability index that would rate products according to the environmental and social impacts of their manufacturing and distribution. The index is intended to create environmental accountability in Wal-Mart's supply chain and to provide motivation and infrastructure for other retail companies to do the same.\nIt has been reported that companies are increasingly taking environmental performance into account when selecting suppliers. A 2011 survey by the Carbon Trust found that 50% of multinationals expect to select their suppliers based upon carbon performance in the future and 29% of suppliers could lose their places on 'green supply chains' if they do not have adequate performance records on carbon.\nIn addition to environmental concerns, increased globalization within global supply chains challenges human rights and worker exploitation risks within multinational corporations including forced labor and modern slavery. Textiles, agriculture, and manufacturing are some of the industries with significant labor exploitation risks. There are many different methods governments, corporations, and NGOs use to prevent labor exploitation, including corporate social responsibility, export controls, import bans, and monitoring labor standards.\nThe US Dodd\u2013Frank Wall Street Reform and Consumer Protection Act, signed into law by President Obama in July 2010, contained a supply chain sustainability provision in the form of the Conflict Minerals law. This law requires SEC-regulated companies to conduct third party audits of their supply chains in order to determine whether any tin, tantalum, tungsten, or gold (together referred to as \"conflict minerals\") is mined or sourced from the Democratic Republic of the Congo, and create a report (available to the general public and SEC) detailing the due diligence efforts taken and the results of the audit. The chain of suppliers and vendors to these reporting companies will be expected to provide appropriate supporting information.\nIncidents like the 2013 Savar building collapse, with more than 1,100 victims, have led to widespread discussions about corporate social responsibility across global supply chains. Wieland and Handfield (2013) suggest that companies need to audit products and suppliers and that supplier auditing needs to go beyond direct relationships with first-tier suppliers. They also demonstrate that visibility needs to be improved if supply cannot be directly controlled and that smart and electronic technologies play a key role to improve visibility. Finally, they highlight that collaboration with local partners, across the industry and with universities is crucial to successfully managing social responsibility in supply chains. Recent research proposes a two-phase approach for auditing multitier supply networks. Under this strategy, buyers first audit and drop noncompliant suppliers and then proceed to audit and rectify the remaining ones; when auditing an upper tier, the approach recommends selecting the \"least valuable unaudited supplier\" as the next candidate for auditing.\nCircular supply chain management.\nCircular Supply Chain Management (CSCM) is \"the configuration and coordination of the organizational functions marketing, sales, R&amp;D, production, logistics, IT, finance, and customer service within and across business units and organizations to close, slow, intensify, narrow, and dematerialise material and energy loops to minimize resource input into and waste and emission leakage out of the system, improve its operative effectiveness and efficiency and generate competitive advantages\". By reducing resource input and waste leakage along the supply chain and configure it to enable the recirculation of resources at different stages of the product or service lifecycle, potential economic and environmental benefits can be achieved. These comprise e.g. a decrease in material and waste management cost and reduced emissions and resource consumption.\nComponents.\nManagement components.\nSCM components are the third element of the four-square circulation framework. The level of integration and management of a business process link is a function of the number and level of components added to the link. Consequently, adding more management components or increasing the level of each component can increase the level of integration of the business process link.\nLiterature on business process reengineering, buyer-supplier relationships, and SCM suggests various possible components that should receive managerial attention when managing supply relationships. Lambert and Cooper (2000) identified the following components:\nHowever, a more careful examination of the existing literature leads to a more comprehensive understanding of what should be the key critical supply chain components, or \"branches\" of the previously identified supply chain business processes\u2014that is, what kind of relationship the components may have that are related to suppliers and customers. Bowersox and Closs (1996) state that the emphasis on cooperation represents the synergism leading to the highest level of joint achievement. A primary-level channel participant is a business that is willing to participate in responsibility for inventory ownership or assume other financial risks, thus including primary level components. A secondary-level participant (specialized) is a business that participates in channel relationships by performing essential services for primary participants, including secondary level components, which support primary participants. Third-level channel participants and components that support primary-level channel participants and are the fundamental branches of secondary-level components may also be included.\nConsequently, Lambert and Cooper's framework of supply chain components does not lead to any conclusion about what are the primary- or secondary-level (specialized) supply chain components \u2014that is, which supply chain components should be viewed as primary or secondary, how these components should be structured in order to achieve a more comprehensive supply chain structure, and how to examine the supply chain as an integrative one.\nPower in supply chain management.\nAndrew Cox, Joe Sanderson and Glyn Watson argue that the power resources of buyers and suppliers should be analyzed in order to understand how a supply chain relationship operates. In some cases, a purchasing firm may exercise more power over its suppliers, in other cases, suppliers may have more power; yet again there will be cases where buyers and suppliers may be interdependent or may have no real power over each other. Cox, Sanderson and Watson have written extensively on the operation of power regimes within a supply chain context; they have described their work for themselves as \"a new perspective on managing in supply chains and networks\". Other studies of power in supply chain relationships have looked at drivers impacting on the potential integration of supply chains. A study by Michael Maloni and W. C. Benton in 1998 looked at whether potential asymmetries in inter-firm power within a supply chain could prevent the implementation of effective supply chain execution. Maloni and Benton note that until their research, \"little power research\" had been presented in the supply chain literature. Using French and Raven's typology of the sources of power in the context of the automotive industry, they aimed to analyse the effects of distinct power strategies on relationships between buyers and sellers, and upon supply chain performance and satisfaction. Their findings showed that:\nThey concluded that \"prudent use of power\" can be beneficial for both the power source and the power target.\nReverse supply chain.\nReverse logistics is the process of managing the return of goods and may be considered as an aspect of \"aftermarket customer services\". Any time money is taken from a company's warranty reserve or service logistics budget, one can speak of a reverse logistics operation. Reverse logistics also includes the process of managing the return of goods from store, which the returned goods are sent back to warehouse and after that either warehouse scrap the goods or send them back to supplier for replacement depending on the warranty of the merchandise.\nSupply Chain Engineering.\nAlthough it has the same goals as supply chain engineering, supply chain management is focused on a more traditional management and business based approach, whereas supply chain engineering is focused on a mathematical model based one.\nDigitizing supply chains.\nConsultancies and media expect the performance efficacy of digitizing supply chains to be high. Additive manufacturing and blockchain technology have emerged as the two technologies with some of the highest economic relevance.\nSystems and value.\nSupply chain systems configure value for those that organize the networks. Value is the additional revenue over and above the costs of building the network. Co-creating value and sharing the benefits appropriately to encourage effective participation is a key challenge for any supply system. Tony Hines defines value as follows: \"Ultimately it is the customer who pays the price for service delivered that confirms value and not the producer who simply adds cost until that point\".\nGlobal applications.\nGlobal supply chains pose challenges regarding both quantity and value. Supply and value chain trends include:\nThese trends have many benefits for manufacturers because they make possible larger lot sizes, lower taxes, and better environments (e.g., culture, infrastructure, special tax zones, or sophisticated OEM) for their products. There are many additional challenges when the scope of supply chains is global. This is because with a supply chain of a larger scope, the lead time is much longer, and because there are more issues involved, such as multiple currencies, policies, and laws. The consequent problems include different currencies and valuations in different countries, different tax laws, different trading protocols, vulnerability to natural disasters and cyber threats, and lack of transparency of cost and profit.\nRoles and responsibilities.\nSupply chain professionals play major roles in the design and management of supply chains. In the design of supply chains, they help determine whether a product or service is provided by the firm itself (insourcing) or by another firm elsewhere (outsourcing). In the management of supply chains, supply chain professionals coordinate production among multiple providers, ensuring that production and transport of goods happen with minimal quality control or inventory problems. One goal of a well-designed and maintained supply chain for a product is to successfully build the product at minimal cost. Such a supply chain could be considered a competitive advantage for a firm.\nBeyond design and maintenance of a supply chain itself, supply chain professionals participate in aspects of business that have a bearing on supply chains, such as sales forecasting, quality management, strategy development, customer service, and systems analysis. Production of a good may evolve over time, rendering an existing supply chain design obsolete. Supply chain professionals need to be aware of changes in production and business climate that affect supply chains and create alternative supply chains as the need arises.\nIn a research project undertaken by Michigan State University's Broad College of Business, with input from 50 participating organizations, the main issues of concern to supply chain managers were identified as capacity/resource availability, talent (recruitment), complexity, threats/challenges (supply chain risks), compliance and cost/purchasing issues. Keeping up with frequent changes in regulation was identified as a particular concern. Complexity within supply chains has also been highlighted in \"Supply Chain Digest\" and by Gartner as a perennial challenge.\nSupply chain consultants may provide expert knowledge in order to assess the productivity of a supply chain and, ideally, to enhance its productivity. Supply chain consulting involves the transfer of knowledge on how to exploit existing assets through improved coordination and can hence be a source of competitive advantage: the role of the consultant is to help management by adding value to the whole process through the various sectors from the ordering of the raw materials to the final product. In this regard, firms may either build internal teams of consultants to tackle the issue or engage external ones: companies choose between these two approaches taking into consideration various factors.\nThe use of external consultants is a common practice among companies. The whole consulting process generally involves the analysis of the entire supply chain process, including the countermeasures or correctives to take to achieve a better overall performance.\nSkills and competencies.\nSupply chain professionals need to have knowledge of managing supply chain functions such as transportation, warehousing, inventory management, and production planning. In the past, supply chain professionals emphasized logistics skills, such as knowledge of shipping routes, familiarity with warehousing equipment and distribution center locations and footprints, and a solid grasp of freight rates and fuel costs. More recently, supply chain management extends to logistical support across firms and management of global supply chains. Supply chain professionals need to have an understanding of business continuity basics and strategies, and Tramarico \"et al\" noted that several processes from other disciplinary theories, including the resource-based view, supply chain design and interorganizational relationships are integral to a mature understanding of supply chain management. A shortage of skilled supply chain professionals was highlighted in a study by the Massachusetts Institute of Technology published in 2010, which highlighted plentiful supply of staff with \"narrow technical skillsets\" but shortages in the numbers of job applicants with \"broader business skills\".\nCertification.\nIndividuals working in supply chain management can attain professional certification by passing an exam developed by a third party certification organization. The purpose of certification is to guarantee a certain level of expertise in the field. The knowledge needed to pass a certification exam may be gained from several sources. Some knowledge may come from college courses, but most of it is acquired from a mix of on-the-job learning experiences, attending industry events, learning best practices with their peers, and reading books and articles in the field. Certification organizations may provide certification workshops tailored to their exams.\nUniversity rankings.\nThe following North American universities rank high in their master's education in the SCM World University 100 ranking, which was published in 2017 and which is based on the opinions of supply chain managers: Michigan State University, Penn State University, University of Tennessee, Massachusetts Institute of Technology, Arizona State University, University of Texas at Austin and Western Michigan University. In the same ranking, the following European universities rank high: Cranfield School of Management, Vlerick Business School, INSEAD, Cambridge University, Eindhoven University of Technology, London Business School and Copenhagen Business School. \nThe following universities rank high in the 2016 Eduniversal Best Masters ranking for supply chain and logistics: Massachusetts Institute of Technology, KEDGE Business School, Purdue University, Rotterdam School of Management, Pontificia Universidad Catolica del Peru, Universidade Nova de Lisboa, Vienna University of Economics and Business and Copenhagen Business School.\nOrganizations.\nA number of organizations provide certification in supply chain management, such as the Council of Supply Chain Management Professionals (CSCMP), IIPMR (International Institute for Procurement and Market Research), APICS (the Association for Operations Management), ISCEA (International Supply Chain Education Alliance) and IoSCM (Institute of Supply Chain Management). APICS' certification is called \"Certified Supply Chain Professional\", or CSCP, and ISCEA's certification is called the \"Certified Supply Chain Manager\" (CSCM), CISCM (Chartered Institute of Supply Chain Management) awards certificate as \"Chartered Supply Chain Management Professional\" (CSCMP). Another, the Institute for Supply Management, is developing one called the \"Certified Professional in Supply Management\" (CPSM) focused on the procurement and sourcing areas of supply chain management. The Supply Chain Management Association (SCMA) is the main certifying body for Canada with the designations having global reciprocity. The designation Supply Chain Management Professional (SCMP) is the title of the supply chain leadership designation.\nTopics addressed by selected professional supply chain certification programmes.\nThe following table compares topics addressed by selected professional supply chain certification programmes.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27998", "revid": "1316770235", "url": "https://en.wikipedia.org/wiki?curid=27998", "title": "Synchronized swimming", "text": "Hybrid form of swimming, dance and gymnastics\nSynchronized swimming (in British English, synchronised swimming), also known as artistic swimming, is a sport where swimmers perform a synchronized choreographed routine, accompanied by music. The sport is governed internationally by World Aquatics (formerly known as FINA). It has traditionally been a women's sport, although FINA introduced a new mixed-gender duet competition that included one male swimmer in each duet at the 2015 World Aquatics Championships and European Aquatics introduced men's individual events at the 2022 European Aquatics Championships. From 2024, men are able to compete in the team event at the Olympics.\nSynchronized swimming has been part of the Summer Olympics program since 1984, featuring both women's duet and team events. In 2017, under the instruction of the International Olympic Committee (IOC), FINA renamed the sport from \"synchronized swimming\" to \"artistic swimming\" \u2013 a decision that has faced controversy. The new official name has yet to gain general acceptance beyond the core of the sport.\nIn 2022, the synchronized-swimming rules were overhauled to reduce subjectivity in judging. This change brings the sport's rules closer to the sport of artistic gymnastics and also figure skating.\nRoutine.\nRoutines are composed of elements and transitions. Under World Aquatics rules, they are from two to three minutes long, with competition category determining routine length. There is a penalty for touching the bottom of the pool during the routine. Swimmers are synchronized to each other and to the music. Routines are judged on execution and artistic impression and a pre-determined degree of difficulty. The degree of difficulty is declared prior to performing, and may decrease in the final score if athletes fail to complete the declared movements. Each routine has a coach card, where the elements and their difficulty are declared in order of performance. \nElements.\nThere are three types of elements: hybrid, acrobatic, and technical required element. Each category of routine has a certain number of elements which must be performed. Elements have a difficulty score which is declared prior to the routine's performance. If the element is not performed as it is declared, the element will receive a base mark, reducing its difficulty to its base value. A panel of judges scores each element for execution, which is multiplied by the difficulty of the element, making it a significant loss to the routine's score if an element receives a base mark. \nHybrids.\nA hybrid is a combination of leg movements, with the head and torso underneath the water. It is defined as five or more movements performed with the head underneath the hips. A hybrid consists of skills, with each skill having a difficulty value determined by World Aquatics. The difficulty of the skills is added to the base value (0.5) to get the declared difficulty. An example of how a hybrid could receive a base mark would be if a skill with a 360 degree spin is declared, but the swimmer doesn't spin the full amount.\nAcrobatic.\nAn acrobatic is a movement where one or more swimmers are lifted out the water by their teammates. They are also referred to as lifts or highlights.\nTechnical required element (TRE).\nA technical required element is a predetermined movement that must be performed in a technical routine. They are visually similar to hybrids, but will stay the same across routines in the same category. The required elements vary in different categories, so teams and duets and solos all have different required elements.\nTechnical and free routines.\nTechnical routines include technical required elements and are shorter than free routines. They also include free hybrids and acrobatics, but the majority of the elements performed are technical elements. A free routine does not include technical required elements, only hybrids and acrobatics. Free routines allow for more creativity and innovation in choreography. Younger categories of competition will compete in figures competitions, performing predetermined movements outside of a routine, rather than technical routines.\nAcrobatic movements.\nA acrobatic movement, also referred to as a lift or highlight, is when an athlete is propelled out of the water with the assistance of other swimmers. Generally, an acrobatic movement is an element in the routine, and has a degree of difficulty. Under the World Aquatics rules, there are four types of acrobatic movement:\nConstruction.\nThere are varying techniques used in acrobatics. The featured swimmer, or the flyer, is the athlete who is lifted out of the water to perform poses or acrobatic movements. The featured swimmer will often need gymnastics and diving skills to perform high-difficulty acrobatics. They are supported by swimmers underneath the water who typically use eggbeater to generate the power to lift the flyer out of the water.\nOlympic Games.\nThe first Olympic demonstration of synchronized swimming was at the 1952 Olympic Games, where the Helsinki officials welcomed Katherine Curtis and lit a torch in her honour. Curtis died in 1980, but synchronized swimming did not become an official Olympic sport until the 1984 Summer Olympic Games. It was also not until 1968 that synchronized swimming became officially recognized by FINA as the fourth water sport next to swimming, platform diving and water polo.\nFrom 1984 through 1992, the Summer Olympic Games featured solo and duet competitions, but they were both dropped in 1996 in favor of team competition. At the 2000 Olympic Games, however, the duet competition was restored and is now featured alongside the team competition. At the 2024 Olympic Games, men were included in competition for the first time. Additionally, these games included a team acrobatic routine round.\nWorld Aquatics Championships.\nSynchronized swimming has been part of the World Aquatics Championships since the beginning. From 1973 through 2001, the World Aquatics Championships featured solo, duet and team competitions. In 2003, a free routine combination, comprising elements of solo, duet and team, was added. In 2005, it was renamed free combination. In 2007, solo, duet and team events were split between technical and free routines. In 2015, the mixed duet (technical and free) were added to the competition program. In 2019, the highlight routine was added into the competition program and it was renamed into acrobatic routine in 2023. Also in 2023, the men's solo (technical and free routines) were added to the competition program.\nEuropean Aquatics Championships.\nArtistic swimming is part of the program of the European Aquatics Championships from 1974. A stand alone European Aquatics Artistic Swimming Championships was incorporated into the 2023 European Games, for the first time taking place outside the larger European Aquatics Championships.\nBasic skills.\nSculls.\nSculls (hand movements used to propel the body) are some of the most essential skills in synchronized swimming. Commonly used sculls include support scull, stationary scull, propeller scull, alligator scull, torpedo scull, split scull, barrel scull, spinning scull, totem scull, canoe scull and paddle scull. The support scull is used most often to support the body while a swimmer is performing upside down.\nEggbeater.\nThe \"eggbeater kick\" is another important skill of synchronized swimming. It is a form of treading water that allows for stability and height above the water while leaving the hands free to perform arm motions. An average eggbeater height is usually around collarbone level. Eggbeater is used in all \"arm\" sections, a piece of choreography in which the swimmer is upright, often with one or both arms in the air. Another variation is a body boost, which is executed through an eggbeater buildup and a strong whip kick, propelling the swimmer out of the water vertically. A body boost can raise a swimmer out of the water to hip level\nPositions.\nThere are hundreds of different regular positions that can be used to create seemingly infinite combinations. These are a few basic and commonly used ones:\nThe International Olympic Committee has further described the technical positions.\nCompetitions.\nCompetitors wear a noseclip to keep water from entering their nose when submerged. While competing, hair is typically worn in a bun and gelatin is applied to keep the hair in place. Rarely, swimmers compete with custom-made swimming caps in place of their hair in buns.\nCompetitors wear custom swimsuits, usually elaborately decorated with bright fabric and sequins to reflect the music to which they are swimming. Headpieces are part of the costume, and attached to the bun. Athletes are not permitted to wear goggles during competition. Athletes will normally compete wearing makeup. \nUnderwater speakers ensure that swimmers can hear the music and synchronize with each other. \nFigures.\nA figure is a combination of body movements, similar to a technical required element. They are performed outside of a routine, and without music accompaniment, in front of a panel of judges. Figures are competed by younger swimmers, generally under the age of sixteen, instead of the technical routine. The scores of the figures competition will contribute to the free routine scores. The origin of figures in the sport comes from compulsory figures in figure skating. \nUnited States.\nIn the United States, competitors are divided into groups by age. The eight age groups are: 12 and under, 13\u201315, 16\u201317, 18\u201319, Junior (elite 15\u201318), Senior (elite 15+), Collegiate, and Master. In addition to these groups, younger swimmers may be divided by ability into three levels: Novice, Intermediate, and age group. Certain competitions require the athlete(s) to pass a certain Grade Level. Grades as of now range from Level one to Level six, and will soon go to Level ten. Seasons range in length, and some swimmers participate year-round in competitions. There are many levels of competition, including but not limited to: State, Regional, Zone, National, Junior Olympic, and US Junior and Senior Opens. Each swimmer may compete in the following routine events: solo, duet, combo (consisting of ten swimmers), and team (consisting of eight swimmers). In the 12 &amp; under and 13-15 age groups, figure scores are combined with routines to determine the final rankings. The 16-17 and 18-19 age groups combine the scores of the technical and free routines to determine the final rankings. USA Synchro's annual intercollegiate championships have been dominated by The Ohio State University, Stanford University, Lindenwood University (which no longer has a collegiate program), and The University of the Incarnate Word.\nCanada.\nIn Canada, as of 2010, synchronized swimming has an age-based structure system with age groups 10 &amp; under, 12 &amp; under, and 13\u201315 for the provincial levels. There is also a skill level which is 13\u201315 and juniors (16\u201318) known as national stream, as well as competition at the Masters and University levels. The 13\u201315 age group and 16\u201318 age group are national stream athletes that align with international age groups \u2013 15 and Under and Junior (16\u201318) and Senior (18+) level athletes. Wildrose age group is for competitors before they reach 13\u201315 national stream. Wildrose ranges from Tier 8 and under 16 and over provincial/wildrose. These are also competitive levels. Recreational levels, called \"stars\", also exist. Synchro Canada requires that a competitor must pass Star 3 before entering Tier 1. To get into a Tier a swimmer must take a test for that Tier. In these tests, the swimmer must be able to perform the required movements for the level. (Canada no longer uses Tiers as a form of level placement). The Canadian University synchronised swimming League (CUASL) is intended for Canadian Swimmers who wish to continue their participation in the sport during their university studies, as well as offering a \"Novice\" category for those new to the sport. Traditionally, the top teams hail from McGill University, the University of Ottawa, and the University of British Columbia.\nMen's and mixed competition.\nSome international, national and regional competitions allow men to compete, and the F\u00e9d\u00e9ration internationale de natation (FINA) introduced a new mixed duet competition at the 2015 World Aquatics Championships.\nIn the late 19th century, synchronized swimming was a male-only event. However, in the 20th century it became a women's sport, with men banned from many competitions. In the U.S., men were allowed to participate with women until 1941, when synchronized swimming became part of the Amateur Athletic Union (AAU). The AAU required men and women to compete separately, which resulted in a decline of male participants. In the 1940s and 1950s, Bert Hubbard and Donn Squire were among the top US male competitors.\nIn 1978, the U.S. changed their rules to allow men to once again compete with women. Rules in other countries varied; in the UK, men were prohibited from competing until 2014, while in France, Beno\u00eet Beaufils was allowed to compete at national events in the 1990s. American Bill May was a top competitor in the late-1990s and early-2000s. He medalled in several international events, including the 1998 Goodwill Games. However, male competitors were barred from top competitions, including the World Aquatics Championships and the Olympics. However, at the 2015 World Aquatics Championships, FINA introduced a new mixed duet discipline. Both May and Beaufils returned from decade-long retirements to represent their countries. Among their competitors were Russian Aleksandr Maltsev and Italian Giorgio Minisini, both over 15 years younger than May and Beaufils. Pairs from ten countries competed in the inaugural events. The 2016 European Aquatics Championships was the first time men were allowed to compete at the European Championships. While men are allowed in more events, they were still barred from competing in the 2016 Summer Olympics. FINA did propose adding the mixed duet competition to the 2020 Summer Olympics.\nIn 2022, FINA allowed men to compete as soloists at the 2022 FINA Artistic Swimming World Series and the 2022 FINA World Junior Artistic Swimming Championships and LEN allowed men to compete as soloists both at the European Junior Championships and the 2022 European Aquatics Championships. The International Olympic Committee allowed for the participation of up to two men per team of eight in a mixed gender team event at the 2024 Olympic Games, competition of men in duet, solo, and men-only team events was not permitted. The mixed team format for the 2024 Olympic Games was adapted from the mixed team format, up to two men allowed per team, used at the 2022 FINA Artistic Swimming World Series (March to May 2022).\nMen's solo events debuted at the senior World Championships level at the 2023 World Aquatics Championships with solo technical and solo free routines.\nHistory.\nAt the turn of the 20th century, synchronized swimming was referred to as water ballet. The first recorded synchronized swimming competition took place in 1891 in Berlin, Germany. During this period, many swim clubs were formed, and the sport simultaneously developed in Canada. As well as existing as a sport, it often constituted a popular addition to Music Hall evenings, in the larger variety theatres of London or Glasgow which were equipped with on-stage water tanks for the purpose.\nIn 1917, Australian Annette Kellerman popularised the sport when she performed in a water ballet at the New York Hippodrome. After experimenting with various diving actions and stunts in the water, Katherine Curtis started one of the first water ballet clubs at the University of Chicago, where the team began executing strokes, \"tricks\", and floating formations. Curtis is widely credited as the true originator of synchronized swimming; important historical details regarding the origin of the phrase \"synchronized swimming\", its reference to the Olympic sport, and the technical structure of that sport are all credited to Curtis.\nBusby Berkeley created a 15-minute \"aquacade\" for the 1933 film \"Footlight Parade\", \"By a Waterfall\". According to TCM.com, \"The set, complete with an 80-by-40-foot swimming pool, took up an entire soundstage. Berkeley had the pool lined with glass walls and a glass floor so he could shoot the swimmers from every possible angle. Then he designed the swimming suits and bathing caps to create the illusion that the women were almost naked.\" It was shot in six days after two weeks' rehearsal... \"The results were so spectacular that the audience at the premiere gave the number a standing ovation and threw their programs in the air. Broadway impresario Billy Rose even tried to steal Berkeley from Warners to stage his aquacade.\"\nOn May 27, 1939, the first U.S. synchronized-swimming competition took place at Wright Junior College between Wright and the Chicago Teachers' College.\nIn 1924, the first competition in North America was in Montreal, with Peg Seller as the first champion. Other important pioneers of the sport are Beulah Gundling, K\u00e4the Jacobi, Marion Kane Elston, Dawn Bean, Billie MacKellar, Teresa Anderson, Gail Johnson, Gail Emery, Charlotte Davis, Mary Derosier, Norma Olsen, and Clark Leach. Charlotte Davis coached Tracie Ruiz and Candy Costie, who won the gold medal in duet synchronied swimming at the 1984 Olympics in Los Angeles.\nIn 1933 and 1934, Katherine Curtis organised a show, \"The Kay Curtis Modern Mermaids\", for the World Exhibition in Chicago. The announcer, Norman Ross, introduced the sport as \"synchronized swimming\" for the first time. The term eventually became standardised through the AAU, but Curtis still used the term \"rhythmic swimming\" in her book, \"Rhythmic Swimming: A Source Book of Synchronised Swimming and Water Pageantry\" (Minneapolis: Burgess Publishing Co., 1936).\nCurtis persuaded the AAU to make synchronised swimming an officially recognised sport in December 1941, but she herself transferred overseas in 1943. She served as the Recreation Director of the Red Cross under Generals Patton and Eisenhower, during which time she produced the first international aquacade in Caserta, Italy. She was the Director of Travel in post-war Europe until 1962. In 1959 the Helms Hall of Fame officially recognised Curtis (along with Annette Kellerman) \u2013 ascribing to her the primary development of synchronised swimming. In 1979, the International Swimming Hall of Fame inducted Curtis with similar accolades.\nThe first Official National Team Championships were held in Chicago at Riis Pool on August 11, 1946. The Town Club 'C' team were the first national champions. The team was composed of: Polly Wesner, Nancy Hanna, Doris Dieskow, Marion Mittlacher, Shirley Brown, Audrey Huettenrauch, Phyllis Burrell and Priscilla Hirsch.\nEsther Williams, a national AAU champion swimmer, popularized synchronized swimming during World War II and after, through (often elaborately staged) scenes in Hollywood films such as \"Bathing Beauty\" (1944), \"Million Dollar Mermaid\" (1952), and \"Jupiter's Darling\" (1955). In the 1970s and 1980s, Ft. Lauderdale swimming champion Charkie Phillips revived water ballet on television with The Krofftettes in \"The Brady Bunch Hour\" (1976\u20131977), NBC's \"The Big Show\" (1980), and then on screen with Miss Piggy in \"The Great Muppet Caper\" (1981).\nMargaret Swan Forbes published \"Coaching Synchronized Swimming Effectively\" in 1984; it was the first official teaching manual for synchronized swimming.\nIn July 2017, following a request by the IOC, FINA approved changes to its constitution that renamed synchronized swimming to \"artistic swimming\". FINA justified the change by stating that it would help to clarify the nature of the sport (with the new name being similar to artistic gymnastics), and claimed it would help \"enhance its popularity\". The changes received criticism, with swimmers and coaches arguing that they were never consulted, and that the name \"artistic swimming\" diminishes the athleticism of the sport which already had historically faced an \"uphill battle to be taken seriously\". Another objection raised was that rebranding would cost federations and other groups involved in the sport sums of money that neither the IOC nor FINA was willing to compensate. Deputy Prime Minister of Russia Vitaly Mutko vowed that the country would still refer to the sport as synchronized swimming, stating that \"to keep the name synchronised swimming is our right, and if the Federation itself, the coaches will want it, we will do it\". Since then, most national governing bodies have adopted the new name, some such as the U.S. adopted it after a delay (in 2020), with the CEO of USA Artistic Swimming stating that \"19 of the top 25 countries in the world are either partially or fully using the name artistic swimming\". Competitions where the new name was first used include the 2019 World Aquatics Championships and the 2018 Asian Games. It was also used at the 2020 Summer Olympics and the 2020 European Aquatics Championships.\nIn 2022, a spattering of competitions introduced men-only individual (solo) events for the first time, including the 2022 European Aquatics Championships and the 2022 World Junior Artistic Swimming Championships. This followed the addition of mixed gender events featuring one male and one female swimmer at the 2015 World Aquatics Championships. Later in the year, in December, the International Olympic Committee announced men were eligible to compete at the 2024 Olympic Games only in a mixed gender team event, with a cap on male participation at 25% of team event members, following the up-to-two men format of mixed gender team events at the 2022 FINA Artistic Swimming World Series.\nIn 2023, World Aquatics added men's solo events to the artistic swimming program for the first time at a World Aquatics Championships, scheduling the debut for the 2023 World Aquatics Championships.\nInjuries.\nCommon injuries that may occur in synchronized swimming are tendon injuries, as the sport tends to cause muscle imbalances. Common joint injuries include the rotator cuff and the knees.\nIn their 2012 book \"Concussions and Our Kids\", Dr. Robert Cantu and Mark Hyman quoted Dr. Bill Moreau, the medical director for the U.S. Olympic Committee (USOC), as saying, \"These women are superior athletes. They're in the pool eight hours a day. Literally, they're within inches of one another, sculling and paddling. As they go through their various routines, they're literally kicking each other in the head.\" Moreau said that during a two-week training session in Colorado Springs, the female athletes suffered a 50% concussion rate. As a result, the USOC began reassessing concussion awareness and prevention for all sports.\nOthers believe the incidence of concussions among synchronized swimmers is much higher, especially among the sport's elite athletes. \"I would say 100 percent of my athletes will get a concussion at some point,\" said Myriam Glez, a former French synchronized swimmer and coach. \"It might be minor, might be more serious, but at some point or another, they will get hit.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27999", "revid": "48096126", "url": "https://en.wikipedia.org/wiki?curid=27999", "title": "Swimming", "text": "Self-propulsion of a person through water\nSwimming is the self-propulsion of a person through water, such as saltwater or freshwater environments, usually for recreation, sport, exercise, or survival. Swimmers achieve locomotion by coordinating limb and body movements to achieve hydrodynamic thrust that results in directional motion. Newborns can instinctively hold their breath underwater and exhibit rudimentary swimming movements as part of a survival reflex. Swimming requires endurance, skill and efficient techniques to maximize speed and minimize energy consumption.\nSwimming is a popular activity and competitive sport where certain techniques are deployed to move through water. It offers numerous health benefits, such as strengthened cardiovascular health, muscle strength, and increased flexibility. It is suitable for people of all ages and fitness levels.\nSwimming is consistently among the top public recreational activities, and in some countries, swimming lessons are a compulsory part of the educational curriculum. As a formalized sport, swimming is featured in various local, national, and international competitions, including every modern Summer Olympics.\nSwimming involves repeated motions known as strokes to propel the body forward. While the front crawl, also known as freestyle, is widely regarded as the fastest of the four main strokes, other strokes are practiced for special purposes, such as training.\nSwimming comes with many risks, mainly because of the aquatic environment where it takes place. For instance, swimmers may find themselves incapacitated by panic and exhaustion, both potential causes of death by drowning. Other dangers may arise from exposure to infection or hostile aquatic fauna. To minimize such eventualities, most facilities employ a lifeguard to keep alert for any signs of distress.\nSwimmers often wear specialized swimwear, although depending on the area's culture, some swimmers may also swim nude or wear their day attire. In addition, a variety of equipment can be used to enhance the swimming experience or performance, including but not limited to the use of swimming goggles, floatation devices, swim fins, and snorkels.\nScience.\nSwimming relies on the nearly neutral buoyancy of the human body. On average, the body has a relative density of 0.98 compared to water, which causes the body to float. However, buoyancy varies based on body composition, lung inflation, muscle and fat content, centre of gravity and the salinity of the water. Higher levels of body fat and saltier water both lower the relative density of the body and increase its buoyancy. Because they tend to have a lower centre of gravity and higher muscle content, human males find it more difficult to float or be buoyant. See also: \"Hydrostatic weighing.\" \nSince the human body is less dense than water, water can support the body's weight during swimming. As a result, swimming is \"low-impact\" compared to land activities such as running. The density and viscosity of water also create resistance for objects moving through the water. Swimming strokes use this resistance to create propulsion, but this same resistance also generates drag on the body.\nHydrodynamics is important to stroke technique for swimming faster, and swimmers who want to swim faster or exhaust less try to reduce the drag of the body's motion through the water. To be more hydrodynamically effective, swimmers can either increase the power of their strokes or reduce water resistance. However, power must increase by a factor of three to achieve the same effect as reducing resistance. Efficient swimming by reducing water resistance involves a horizontal water position, rolling the body to reduce the breadth of the body in the water, and extending the arms as far as possible to reduce wave resistance.\nJust before plunging into the pool, swimmers may perform exercises such as squatting. Squatting helps enhance a swimmer's start by warming up the thigh muscles.\nInfant swimming.\nHuman babies demonstrate an innate swimming or diving reflex from newborn until approximately ten months. Other mammals also demonstrate this phenomenon (see mammalian diving reflex). The diving response involves apnea, reflex bradycardia, and peripheral vasoconstriction; in other words, babies immersed in water spontaneously hold their breath, slow their heart rate, and reduce blood circulation to the extremities (fingers and toes).\nBecause infants exhibit instinctual swimming behaviors, classes for babies about six months old are offered in many locations, and formal training is recommended to reinforce these abilities. This helps build muscle memory and makes strong swimmers from a young age.\nTechnique.\nSwimming can be undertaken using a wide range of styles, known as 'strokes,' and which are used for different purposes or to distinguish between classes in competitive swimming. Using a defined stroke for propulsion through the water is unnecessary, and untrained swimmers may use a 'doggy paddle' of arm and leg movements, similar to how four-legged animals swim.\nFour main strokes are used in competition and recreational swimming: the front crawl, breaststroke, backstroke, and butterfly. \nIn non-competitive swimming, there are some additional swimming strokes, including the sidestroke. The sidestroke, toward the end of the 19th century, changed this pattern by raising one arm above the water first, then the other, and then each in turn. It is still used in lifesaving and recreational swimming.\nOther strokes exist for particular reasons, such as training, school lessons, and rescue, and it is often possible to change strokes to avoid using parts of the body, either to separate specific body parts, such as swimming with only arms or legs to exercise them harder, or for amputees or those affected by paralysis.\nHistory.\nSwimming has been recorded since prehistoric times, and the earliest records of swimming date back to Stone Age paintings from around 7,000 years ago. Written references date from 2000 BCE. Some earliest references include the Epic of Gilgamesh, the Iliad, the Odyssey, the Bible (Ezekiel 47:5, Acts 27:42, Isaiah 25:11), Beowulf, and other sagas.\nIn 450 BC, Herodotus described a failed seaborne expedition of Mardonius with the words \"\u2026those who could not swim perished from that cause, others from the cold\".\nThe coastal tribes living in the volatile Low Countries were known as excellent swimmers by the Romans. Men and horses of the Batavi tribe could cross the Rhine without a loss of formation, according to Tacitus. Dio Cassius describes one surprise tactic employed by Aulus Plautius against the Celts at the Battle of the Medway:\nThe [British Celts] thought that Romans would not be able to cross it without a bridge, and consequently bivouacked in rather careless fashion on the opposite bank; but he sent across a detachment of [Batavii], who were accustomed to swim easily in full armour across the most turbulent streams. ... Thence the Britons retired to the river Thames at a point near where it empties into the ocean and at flood-tide forms a lake. This they easily crossed because they knew where the firm ground and the easy passages in this region were to be found, but the Romans in attempting to follow them were not so successful. However, the [Batavii] swam across again and some others got over by a bridge a little way up-stream, after which they assailed the barbarians from several sides at once and cut down many of them.\nThe Talmud, a compendium of Jewish law written compiled c. 500 CE, requires fathers to teach their son how to swim.\nIn 1538, Nikolaus Wynmann, a Swiss\u2013German professor of languages, wrote the earliest known complete book about swimming, \"Colymbetes, sive de arte natandi dialogus et festivus et iucundus lectu\" (\"The Swimmer, or A Dialogue on the Art of Swimming and Joyful and Pleasant to Read\").\nCompetitive swimming in Europe started around 1800, mostly using the breaststroke, which started as the current breaststroke arms and the legs of the butterfly stroke. In 1873, John Arthur Trudgen introduced the trudgen to Western swimming competitions. Swimming was introduced as a competitional sporting event in the 1896 Summer Olympics in Athens, Greece.\nThe butterfly was developed in the 1930s and was considered a variant of the breaststroke until it was accepted as a separate style in 1953.\nPurpose.\nThere are many reasons why people swim, from recreational intentions to swimming as a necessary part of a job or other activity. Swimming may also be used to rehabilitate injuries, especially various cardiovascular and muscle injuries. Professional opportunities in swimming range from competitive sports to coaching, lifeguarding, and working in aquatic therapy. Some may be gifted and choose to compete professionally and go on to claim fame.\nRecreation.\nMany swimmers swim for recreation, with swimming consistently ranking as one of the physical activities people are most likely to participate in. Recreational swimming can also be used for exercise, relaxation, or rehabilitation. The support of the water and the reduction in impact make swimming accessible for people unable to undertake activities such as running. Swimming is one of the most relaxing activities, and water is known to calm us and help reduce stress.\nHealth.\nSwimming is primarily a cardiovascular/aerobic exercise due to the long exercise time, requiring a constant oxygen supply, except for short sprints where the muscles work anaerobically. Furthermore, swimming can help tone and strengthen muscles. Regular swimming can help in weight management and contribute to maintaining a healthy body weight. (Robinson 2022) Swimming allows sufferers of arthritis to exercise affected joints without worsening their symptoms. Swimming is often recommended for individuals with joint conditions or injuries, as the buoyancy of water reduces stress on the joints. Under the right conditions, it is also an excellent form of exercise for children and senior citizens. However, swimmers with arthritis may wish to avoid swimming breaststroke, as improper technique can exacerbate arthritic knee pain. As with most aerobic exercise, swimming reduces the harmful effects of stress. Swimming also improves health for people with cardiovascular problems and chronic illnesses. It is proven to impact the mental health of pregnant women and mothers positively. Swimming can even improve mood. Although many forms of physical activity have been shown to improve bone density and health, this is where swimming has its downfalls. Due to the low-impact nature of the sport, studies have demonstrated that bone mass acquisition will be negatively impacted, which could be an issue for adolescent athletes in particular. A 2025 study found that swimming outdoors is associated with greater levels of well-being. However, 'wild swimming' or open water swimming, where swimming takes place in rivers, lakes or the sea, has been found to be associated with higher well-being than swimming in outdoor pools. \nDisabled swimmers.\nSince 2010, the Americans with Disabilities Act has required that swimming pools in the United States be accessible to disabled swimmers.\nElderly swimmers.\n\"Water-based exercise can benefit older adults by improving quality of life and decreasing disability. It also improves or maintains the bone health of post-menopausal women.\"\nSwimming is an ideal workout for the elderly, as it is a low-impact sport with very little risk of injury. Exercise in the water works out all muscle groups, helping with conditions such as muscular dystrophy which is common in seniors. It is also a common way to relieve pain from arthritis.\nSport.\nSwimming as a sport predominantly involves participants competing to be the fastest over a given distance in a certain period of time. Competitors swim different distances in different levels of competition. For example, swimming has been an Olympic sport since 1896, and the current program includes events from 50 m to 1500 m in length, across all four main strokes and medley. During the season competitive swimmers typically train multiple times per day and week to increase endurance, strength, and preserve fitness. Furthermore when the cycle of work is completed swimmers go through a stage called taper where intensity is reduced in preparation for competition season. During taper, focus is on power and water feel.\nThe sport is governed internationally by World Aquatics, formerly known as FINA (F\u00e9d\u00e9ration Internationale de Natation) before it adopted its current name in December 2022. World Aquatics recognizes competitions of the 25 meter and 50 meter pools for International Competitions. In the United States, a pool of 25 yards in length is commonly used for competition, especially in the College Level. \nOther swimming and water-related sporting disciplines include open water swimming, diving, synchronized swimming, water polo, triathlon, and the modern pentathlon.\nSafety.\nTo prioritize safety when swimming, swimmers can ensure that there are certified lifeguards present, swimming in designated areas, and being aware of potential hazards such as currents and underwater obstacles. \nAs a popular leisure activity done all over the world, one of the primary risks of swimming is drowning. Drowning may occur from a variety of factors, from swimming fatigue to simply inexperience in the water. From 2005 to 2014, an average of 3,536 fatal unintentional drownings occurred in the United States, approximating 10 deaths a day and 67 deaths a week.\nTo minimize the risk and prevent potential drownings from occurring, lifeguards are often employed to supervise swimming locations such as public pools, waterparks, lakes and beaches. Different lifeguards receive different training depending on the sites that they are employed at; i.e. a waterfront lifeguard receives more rigorous training than a poolside lifeguard. Well-known aquatic training services include the https:// and the Canadian Red Cross, which specialize in training lifeguards in North America. \nLearning basic water safety skills, such as swimming with a buddy and knowing how to respond to emergencies, is essential for swimmers of all levels.\nOccupation.\nSome occupations require workers to swim, such as abalone and pearl diving, and spearfishing.\nSwimming is used to rescue people in the water who are in distress, including exhausted swimmers, non-swimmers who have accidentally entered the water, and others who have come to harm on the water. Lifeguards or volunteer lifesavers are deployed at many pools and beaches worldwide to fulfil this purpose, and they, as well as rescue swimmers, may use specific swimming styles for rescue purposes.\nSwimming is also used in marine biology to observe plants and animals in their natural habitat. Other sciences use swimming; for example, Konrad Lorenz swam with geese as part of his studies of animal behavior.\nSwimming also has military purposes. Military swimming is usually done by special operation forces, such as Navy SEALs and US Army Special Forces. Swimming is used to approach a location, gather intelligence, engage in sabotage or combat, and subsequently depart. This may also include airborne insertion into water or exiting a submarine while it is submerged. Due to regular exposure to large bodies of water, all recruits in the United States Navy, Marine Corps, and Coast Guard are required to complete basic swimming or water survival training.\nSwimming is also a professional sport. Companies sponsor swimmers who have the skills to compete at the international level. Many swimmers compete competitively to represent their home countries in the Olympics. Professional swimmers may also earn a living as entertainers, performing in water ballets.\nLocomotion.\nLocomotion by swimming over brief distances is frequent when alternatives are precluded. There have been cases of political refugees swimming in the Baltic Sea and of people jumping in the water and swimming ashore from vessels not intended to reach land where they planned to go.\nRisks.\nThere are many risks associated with voluntary or involuntary human presence in water, which may result in death directly or through drowning asphyxiation. Swimming is both the goal of much voluntary presence and the prime means of regaining land in accidental situations.\nMost recorded water deaths fall into these categories:\nAdverse effects of swimming can include:\nAround any pool area, safety equipment is often important, and is a zoning requirement for most residential pools in the United States. Supervision by personnel trained in rescue techniques is required at most competitive swimming meets and public pools.\nLessons.\nTraditionally, children were considered not able to swim independently until 4 years of age,\nalthough now infant swimming lessons are recommended to prevent drowning.\nIn Sweden, Denmark, Norway, Estonia and Finland, the curriculum for the fifth grade (fourth grade in Estonia) states that all children should learn to swim as well as how to handle emergencies near water. Most commonly, children are expected to be able to swim \u2014of which at least on their back \u2013 after first falling into deep water and getting their head under water. Even though about 95 percent of Swedish school children know how to swim, drowning remains the third most common cause of death among children.\nIn both the Netherlands and Belgium swimming lessons under school time (\"schoolzwemmen\", school swimming) are supported by the government. Most schools provide swimming lessons. There is a long tradition of swimming lessons in the Netherlands and Belgium, the Dutch translation for the breaststroke swimming style is even \"schoolslag\" (schoolstroke). In France, swimming is a compulsory part of the curriculum for primary schools. Children usually spend one semester per year learning swimming during CP/CE1/CE2/CM1 (1st, 2nd, 3rd and 4th grade).\nIn many places, swimming lessons are provided by local swimming pools, both those run by the local authority and by private leisure companies. Many schools also include swimming lessons into their Physical Education curricula, provided either in the schools' own pool or in the nearest public pool.\nIn the UK, the \"Top-ups scheme\" calls for school children who cannot swim by the age of 11 to receive intensive daily lessons. Children who have not reached Great Britain's National Curriculum standard of swimming 25 meters by the time they leave primary school receive a half-hour lesson every day for two weeks during term-time.\nIn Canada and Mexico there has been a call to include swimming in public school curriculum.\nIn the United States there is the Infant Swimming Resource (ISR) initiative that provides lessons for infant children, to cope with an emergency where they have fallen into the water. They are taught how to roll-back-to-float (hold their breath underwater, to roll onto their back, to float unassisted, rest and breathe until help arrives), while clothed and unclothed. In ISR they teach the children how to roll with their clothes on, as a simulation, if they were to actually fall in walking or crawling by.\nIn Switzerland, swimming lessons for babies are popular, to help them getting used to be in another element. At the competition level, unlike in other countries - such as the Commonwealth countries, swimming teams are not related to educational institutions (high-schools and universities), but rather to cities or regions.\nClothing and equipment.\nSwimsuits.\nStandard everyday clothing is usually impractical for swimming and is unsafe under some circumstances. Most cultures today expect swimmers to wear proper swimsuits in public swimming pools and swimming events. \nMale swimsuits (also known as swim trunks) commonly resemble shorts or briefs. Casual swimsuits (for example, boardshorts) are not always skintight, unlike competitive swimwear like jammers or diveskins. In most cases, boys and men swim with their upper body exposed, except for practical reasons such as sun protection. Briefs may be discouraged or restricted for male students and instrctors in certain educational swimming contexts due to the potential for distraction or inadequacy. \nFemale swimsuits are generally skintight, covering the crotch and the midriff area. Female swimwear may also only cover the breasts and nipples, although this can be discouraged or restricted in contexts where swimming is the primary focus. One-piece swimsuits are generally preferred and often required for girls and women in competitive swimming or educational swimming contexts for reasons of comfort, modesty, and swimming functionality.\nCompetitive swimwear is built so that the wearer can swim faster and more efficiently. Modern competitive swimwear is skintight and lightweight. There are many kinds of competitive swimwear for each gender. It is used in aquatic competitions, such as water polo, swim racing, diving, and rowing.\nWetsuits provide both thermal insulation and flotation. Many swimmers lack buoyancy in the legs. The wetsuit provides additional volume at a lower density and therefore improves buoyancy and trim while swimming. It provides insulation between the skin and water which reduces heat loss. The wetsuit is the usual choice for those who swim in cold water for long periods of time, as it reduces susceptibility to hypothermia.\nSome people also choose to wear no clothing while swimming. In some European countries public pools allow clothes-free swimming and many countries have beaches where one can swim naked. It is legal to swim naked in the sea at all UK beaches. It was common for males to swim naked in a public setting up to the early 20th century. Today, swimming naked can be a rebellious activity or merely a casual one.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28002", "revid": "42354497", "url": "https://en.wikipedia.org/wiki?curid=28002", "title": "Simple machine", "text": "Mechanical device that changes the direction or magnitude of a force\nA simple machine is a mechanical device that changes the direction or magnitude of a force. In general, they can be defined as the simplest mechanisms that use mechanical advantage (also called leverage) to multiply force. Usually the term refers to the six classical simple machines that were defined by Renaissance scientists:\nA simple machine uses a single applied force to do work against a single load force. Ignoring friction losses, the work done on the load is equal to the work done by the applied force. The machine can increase the amount of the output force, at the cost of a proportional decrease in the distance moved by the load. The ratio of the output to the applied force is called the \"mechanical advantage\".\nSimple machines can be regarded as the elementary \"building blocks\" of which all more complicated machines (sometimes called \"compound machines\") are composed. For example, wheels, levers, and pulleys are all used in the mechanism of a bicycle. The mechanical advantage of a compound machine is just the product of the mechanical advantages of the simple machines of which it is composed.\nAlthough they continue to be of great importance in mechanics and applied science, modern mechanics has moved beyond the view of the simple machines as the ultimate building blocks of which all machines are composed, which arose in the Renaissance as a neoclassical amplification of ancient Greek texts. The great variety and sophistication of modern machine linkages, which arose during the Industrial Revolution, is inadequately described by these six simple categories. Various post-Renaissance authors have compiled expanded lists of \"simple machines\", often using terms like \"basic machines\", \"compound machines\", or \"machine elements\" to distinguish them from the classical simple machines above. By the late 1800s, Franz Reuleaux had identified hundreds of machine elements, calling them \"simple machines\". Modern machine theory analyzes machines as kinematic chains composed of elementary linkages called kinematic pairs.\nHistory.\nThe idea of a simple machine originated with the Greek philosopher Archimedes around the 3rd century BC, who studied the Archimedean simple machines: lever, pulley, and screw. He discovered the principle of mechanical advantage in the lever. Archimedes' famous remark with regard to the lever: \"Give me a place to stand on, and I will move the Earth,\" () expresses his realization that there was no limit to the amount of force amplification that could be achieved by using mechanical advantage. Later Greek philosophers defined the classic five simple machines (excluding the inclined plane) and were able to calculate their (ideal) mechanical advantage. For example, Heron of Alexandria (c.\u200910\u201375 AD) in his work \"Mechanics\" lists five mechanisms that can \"set a load in motion\": lever, windlass, pulley, wedge, and screw, and describes their fabrication and uses. However the Greeks' understanding was limited to the statics of simple machines (the balance of forces), and did not include dynamics, the tradeoff between force and distance, or the concept of work.\nDuring the Renaissance the dynamics of the \"mechanical powers\", as the simple machines were called, began to be studied from the standpoint of how far they could lift a load, in addition to the force they could apply, leading eventually to the new concept of mechanical work. In 1586 Flemish engineer Simon Stevin derived the mechanical advantage of the inclined plane, and it was included with the other simple machines. The complete dynamic theory of simple machines was worked out by Italian scientist Galileo Galilei in 1600 in (\"On Mechanics\"), in which he showed the underlying mathematical similarity of the machines as force amplifiers. He was the first to explain that simple machines do not create energy, only transform it.\nThe classic rules of sliding friction in machines were discovered by Leonardo da Vinci (1452\u20131519), but were unpublished and merely documented in his notebooks, and were based on pre-Newtonian science such as believing friction was an ethereal fluid. They were rediscovered by Guillaume Amontons (1699) and were further developed by Charles-Augustin de Coulomb (1785).\nIdeal simple machine.\nIf a simple machine does not dissipate energy through friction, wear or deformation, then energy is conserved and it is called an ideal simple machine. In this case, the power into the machine equals the power out, and the mechanical advantage can be calculated from its geometric dimensions.\nAlthough each machine works differently mechanically, the way they function is similar mathematically. In each machine, a force formula_1 is applied to the device at one point, and it does work moving a load formula_2 at another point. Although some machines only change the direction of the force, such as a stationary pulley, most machines multiply the magnitude of the force by a factor, the mechanical advantage\nformula_3\nthat can be calculated from the machine's geometry and friction.\nSimple machines do not contain a source of energy, so they cannot do more work than they receive from the input force. A simple machine with no friction or elasticity is called an \"ideal machine\". Due to conservation of energy, in an ideal simple machine, the power output (rate of energy output) at any time formula_4 is equal to the power input formula_5\nformula_6\nThe power output equals the velocity of the load formula_7 multiplied by the load force formula_8. Similarly the power input from the applied force is equal to the velocity of the input point formula_9 multiplied by the applied force formula_10. Therefore,\nformula_11\nSo the mechanical advantage of an ideal machine formula_12 is equal to the \"velocity ratio\", the ratio of input velocity to output velocity\nformula_13\nThe \"velocity ratio\" is also equal to the ratio of the distances covered in any given period of time\nformula_14\nTherefore, the mechanical advantage of an ideal machine is also equal to the \"distance ratio\", the ratio of input distance moved to output distance moved\nformula_15\nThis can be calculated from the geometry of the machine. For example, the mechanical advantage and distance ratio of the lever is equal to the ratio of its lever arms.\nThe mechanical advantage can be greater or less than one:\nIn the screw, which uses rotational motion, the input force should be replaced by the torque, and the velocity by the angular velocity the shaft is turned.\nFriction and efficiency.\nAll real machines have friction, which causes some of the input power to be dissipated as heat. If formula_20 is the power lost to friction, from conservation of energy\nformula_21\nThe mechanical efficiency formula_22 of a machine (where formula_23) is defined as the ratio of power out to the power in, and is a measure of the frictional energy losses\nformula_24\nAs above, the power is equal to the product of force and velocity, so\nformula_25\nTherefore,\nformula_26\nSo in non-ideal machines, the mechanical advantage is always less than the velocity ratio by the product with the efficiency formula_22. So a machine that includes friction will not be able to move as large a load as a corresponding ideal machine using the same input force.\nCompound machines.\nA \"compound machine\" is a machine formed from a set of simple machines connected in series with the output force of one providing the input force to the next. For example, a bench vise consists of a lever (the vise's handle) in series with a screw, and a simple gear train consists of a number of gears (wheels and axles) connected in series.\nThe mechanical advantage of a compound machine is the ratio of the output force exerted by the last machine in the series divided by the input force applied to the first machine, that is\nformula_28\nBecause the output force of each machine is the input of the next, formula_29, this mechanical advantage is also given by\nformula_30\nThus, the mechanical advantage of the compound machine is equal to the product of the mechanical advantages of the series of simple machines that form it\nformula_31\nSimilarly, the efficiency of a compound machine is also the product of the efficiencies of the series of simple machines that form it\nformula_32\nSelf-locking machines.\nIn many simple machines, if the load force formula_33 on the machine is high enough in relation to the input force formula_34, the machine will move backwards, with the load force doing work on the input force. So these machines can be used in either direction, with the driving force applied to either input point. For example, if the load force on a lever is high enough, the lever will move backwards, moving the input arm backwards against the input force. These are called \"reversible\", \"non-locking\" or \"overhauling\" machines, and the backward motion is called \"overhauling\".\nHowever, in some machines, if the frictional forces are high enough, no amount of load force can move it backwards, even if the input force is zero. This is called a \"self-locking\", \"nonreversible\", or \"non-overhauling\" machine. These machines can only be set in motion by a force at the input, and when the input force is removed will remain motionless, \"locked\" by friction at whatever position they were left.\nSelf-locking occurs mainly in those machines with large areas of sliding contact between moving parts: the screw, inclined plane, and wedge:\nA machine will be self-locking if and only if its efficiency formula_22 is below 50%:\nformula_36\nWhether a machine is self-locking depends on both the friction forces (coefficient of static friction) between its parts, and the distance ratio formula_37 (ideal mechanical advantage). If both the friction and ideal mechanical advantage are high enough, it will self-lock.\nProof.\nWhen a machine moves in the forward direction from point 1 to point 2, with the input force doing work on a load force, from conservation of energy the input work formula_38 is equal to the sum of the work done on the load force formula_39 and the work lost to friction formula_40\n&lt;templatestyles src=\"Numbered block/styles.css\" /&gt;\nIf the efficiency is below 50% \nformula_41\nFrom Eq. 1\nformula_42\nWhen the machine moves backward from point 2 to point 1 with the load force doing work on the input force, the work lost to friction formula_43 is the same\nformula_44\nSo the output work is\nformula_45\nThus the machine self-locks, because the work dissipated in friction is greater than the work done by the load force moving it backwards even with no input force.\nModern machine theory.\nMachines are studied as mechanical systems consisting of actuators and mechanisms that transmit forces and movement, monitored by sensors and controllers. The components of actuators and mechanisms consist of links and joints that form kinematic chains.\nKinematic chains.\nSimple machines are elementary examples of kinematic chains that are used to model mechanical systems ranging from the steam engine to robot manipulators. The bearings that form the fulcrum of a lever and that allow the wheel and axle and pulleys to rotate are examples of a kinematic pair called a hinged joint. Similarly, the flat surface of an inclined plane and wedge are examples of the kinematic pair called a sliding joint. The screw is usually identified as its own kinematic pair called a helical joint.\nTwo levers, or cranks, are combined into a planar four-bar linkage by attaching a link that connects the output of one crank to the input of another. Additional links can be attached to form a six-bar linkage or in series to form a robot.\nClassification of machines.\nThe identification of simple machines arises from a desire for a systematic method to invent new machines. Therefore, an important concern is how simple machines are combined to make more complex machines. One approach is to attach simple machines in series to obtain compound machines.\nHowever, a more successful strategy was identified by Franz Reuleaux, who collected and studied over 800 elementary machines. He realized that a lever, pulley, and wheel and axle are in essence the same device: a body rotating about a hinge. Similarly, an inclined plane, wedge, and screw are a block sliding on a flat surface.\nThis realization shows that it is the joints, or the connections that provide movement, that are the primary elements of a machine. Starting with four types of joints, the revolute joint, sliding joint, cam joint and gear joint, and related connections such as cables and belts, it is possible to understand a machine as an assembly of solid parts that connect these joints.\nKinematic synthesis.\nThe design of mechanisms to perform required movement and force transmission is known as kinematic synthesis. This is a collection of geometric techniques for the mechanical design of linkages, cam and follower mechanisms and gears and gear trains.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28005", "revid": "43967069", "url": "https://en.wikipedia.org/wiki?curid=28005", "title": "Semi-Automatic Ground Environment", "text": "Historic US military computer and radar network\nThe Semi-Automatic Ground Environment (SAGE) was a system of large computers and associated networking equipment that coordinated data from many radar sites and processed it to produce a single unified image of the airspace over a wide area. SAGE directed and controlled the NORAD response to a possible Soviet air attack, operating in this role from the late 1950s into the 1980s.\nThe processing power behind SAGE was supplied by the largest discrete component-based computer ever built, the AN/FSQ-7, manufactured by IBM. Each SAGE Direction Center (DC) housed an FSQ-7 which occupied an entire floor, approximately not including supporting equipment. The FSQ-7 was actually two computers, \"A\" side and \"B\" side. Computer processing was switched from \"A\" side to \"B\" side on a regular basis, allowing maintenance on the unused side. Information was fed to the DCs from a network of radar stations as well as readiness information from various defense sites. The computers, based on the raw radar data, developed \"tracks\" for the reported targets, and automatically calculated which defenses were within range. Operators used light guns to select targets on-screen for further information, select one of the available defenses, and issue commands to attack. These commands would then be automatically sent to the defense site via teleprinter.\nConnecting the various sites was an enormous network of telephones, modems and teleprinters. Later additions to the system allowed SAGE's tracking data to be sent directly to CIM-10 Bomarc missiles and some of the US Air Force's interceptor aircraft in-flight, directly updating their autopilots to maintain an intercept course without operator intervention. Each DC also forwarded data to a Combat Center (CC) for \"supervision of the several sectors within the division\" (\"each combat center [had] the capability to coordinate defense for the whole nation\").\nSAGE became operational in the late 1950s and early 1960s at an estimated total cost between 8 and 12 billion dollars, four times the cost of the Manhattan Project. Throughout its development, there were continual concerns about its real ability to deal with large attacks, and the Operation Sky Shield tests showed that only about one-fourth of enemy bombers would have been intercepted. Nevertheless, SAGE was the backbone of NORAD's air defense system into the 1980s, by which time the tube-based FSQ-7s were increasingly costly to maintain and completely outdated. Today the same command and control task is carried out by microcomputers, based on the same basic underlying data.\nBackground.\nEarlier systems.\nJust prior to World War II, Royal Air Force (RAF) tests with the new Chain Home (CH) radars had demonstrated that relaying information to the fighter aircraft directly from the radar sites was not feasible. The radars determined the map coordinates of the enemy, but could generally not see the fighters at the same time. This meant the fighters had to be able to determine where to fly to perform an interception but were often unaware of their own exact location and unable to calculate an interception while also flying their aircraft.\nThe solution was to send all of the radar information to a central control station where operators collated the reports into single \"tracks\", and then reported these tracks to the airbases, or \"sectors\". The sectors used additional systems to track their own aircraft, plotting both on a single large map. Operators viewing the map could then see what direction their fighters would have to fly to approach their targets and relay that simply by telling them to fly along a certain heading or \"vector\". This Dowding system was the first ground-controlled interception (GCI) system of large scale, covering the entirety of the UK. It proved enormously successful during the Battle of Britain, and is credited as being a key part of the RAF's success.\nThe system was slow, often providing information that was up to five minutes out of date. Against propeller driven bombers flying at perhaps this was not a serious concern, but it was clear the system would be of little use against jet-powered bombers flying at perhaps . The system was extremely expensive in manpower terms, requiring hundreds of telephone operators, plotters and trackers in addition to the radar operators. This was a serious drain on manpower, making it difficult to expand the network.\nThe idea of using a computer to handle the task of taking reports and developing tracks had been explored beginning late in the war. By 1944, analog computers had been installed at the CH stations to automatically convert radar readings into map locations, eliminating two people. Meanwhile, the Royal Navy began experimenting with the Comprehensive Display System (CDS), another analog computer that took X and Y locations from a map and automatically generated tracks from repeated inputs. Similar systems began development with the Royal Canadian Navy, DATAR, and the US Navy, the Naval Tactical Data System. A similar system was also specified for the Nike SAM project, specifically referring to a US version of CDS, coordinating the defense over a battle area so that multiple batteries did not fire on a single target. All of these systems were relatively small in geographic scale, generally tracking within a city-sized area.\nValley Committee.\nWhen the Soviet Union tested its first atomic bomb in August 1949, the topic of air defense of the US became important for the first time. A study group, the \"Air Defense Systems Engineering Committee\", was set up under the direction of Dr. George Valley to consider the problem and is known to history as the \"Valley Committee\".\nTheir December report noted a key problem in air defense using ground-based radars. A bomber approaching a radar station would detect the signals from the radar long before the reflection off the bomber was strong enough to be detected by the station. The committee suggested that when this occurred, the bomber would descend to low altitude, thereby greatly limiting the radar horizon, allowing the bomber to fly past the station undetected. Although flying at low altitude greatly increased fuel consumption, the team calculated that the bomber would only need to do this for about 10% of its flight, making the fuel penalty acceptable.\nThe only solution to this problem was to build a huge number of stations with overlapping coverage. At that point the problem became one of managing the information. Manual plotting was ruled out as too slow, and a computerized solution was the only possibility. To handle this task, the computer would need to be fed information directly, eliminating any manual translation by phone operators, and it would have to be able to analyze that information and automatically develop tracks. A system tasked with defending cities against the predicted future Soviet bomber fleet would have to be dramatically more powerful than the models used in the NTDS or DATAR.\nThe Committee then had to consider whether or not such a computer was possible. The Valley Committee was introduced to Jerome Wiesner, associate director of the Research Laboratory of Electronics at MIT. Wiesner noted that the Servomechanisms Laboratory had already begun development of a machine that might be fast enough. This was the Whirlwind I, originally developed for the Office of Naval Research as a general purpose flight simulator that could simulate any current or future aircraft by changing its software.\nWiesner introduced the Valley Committee to Whirlwind's project lead, Jay Forrester, who convinced him that Whirlwind was sufficiently capable. In September 1950, an early microwave early-warning radar system at Hanscom Field was connected to Whirlwind using a custom interface developed by Forrester's team. An aircraft was flown past the site, and the system digitized the radar information and successfully sent it to Whirlwind. With this demonstration, the technical concept was proven. Forrester was invited to join the committee.\nProject Charles.\nWith this successful demonstration, Louis Ridenour, chief scientist of the Air Force, wrote a memo stating \"It is now apparent that the experimental work necessary to develop, test, and evaluate the systems proposals made by ADSEC will require a substantial amount of laboratory and field effort.\" Ridenour approached MIT President James Killian with the aim of beginning a development lab similar to the war-era Radiation Laboratory that made enormous progress in radar technology. Killian was initially uninterested, desiring to return the school to its peacetime civilian charter. Ridenour eventually convinced Killian the idea was sound by describing the way the lab would lead to the development of a local electronics industry based on the needs of the lab and the students who would leave the lab to start their own companies. Killian agreed to at least consider the issue, and began Project Charles to consider the size and scope of such a lab.\nProject Charles was placed under the direction of Francis Wheeler Loomis and included 28 scientists, about half of whom were already associated with MIT. Their study ran from February to August 1951, and in their final report they stated that \"We endorse the concept of a centralized system as proposed by the Air Defense Systems Engineering Committee, and we agree that the central coordinating apparatus of this system should be a high-speed electronic digital computer.\" The report went on to describe a new lab that would be used for generic technology development for the Air Force, Army and Navy, and would be known as Project Lincoln.\nProject Lincoln.\nLoomis took over direction of Project Lincoln and began planning by following the lead of the earlier RadLab. By September 1951, only months after the Charles report, Project Lincoln had more than 300 employees. By the end of the summer of 1952 this had risen to 1300, and after another year, 1800. The only building suitable for classified work at that point was Building 22, suitable for a few hundred people at most, although some relief was found by moving the non-classified portions of the project, administration and similar, to Building 20. But this was clearly insufficient space. After considering a variety of suitable locations, a site at Laurence G. Hanscom Field was selected, with the groundbreaking taking place in 1951.\nThe terms of the National Security Act were formulated during 1947, leading to the creation of the US Air Force out of the former US Army Air Force. During April of the same year, US Air Force staff were identifying specifically the requirement for the creation of automatic equipment for radar-detection which would relay information to an air defence control system, a system which would function without the inclusion of persons for its operation. The December 1949 \"Air Defense Systems Engineering Committee\" led by Dr. George Valley had recommended computerized networking for \"radar stations guarding the northern air approaches to the United States\" (e.g., in Canada). After a January 1950 meeting, Valley and Jay Forrester proposed using the Whirlwind I (completed 1951) for air defense. On August 18, 1950, when the \"1954 Interceptor\" requirements were issued, the USAF \"noted that manual techniques of aircraft warning and control would impose \"intolerable\" delays\" (Air Materiel Command (AMC) published \"Electronic Air Defense Environment for 1954\" in December .) During February\u2013August 1951 at the new Lincoln Laboratory, the USAF conducted Project Claude which concluded an improved air defense system was needed.\nIn a test for the US military at Bedford, Massachusetts on 20 April 1951, data produced by a radar was transmitted through telephone lines to a computer for the first time, showing the detection of a mock enemy aircraft. This first test was directed by C. Robert Wieser.\nThe \"Summer Study Group\" of scientists in 1952 recommended \"computerized air direction centers\u2026to be ready by 1954.\"\nIBM's \"Project High\" assisted under their October 1952 Whirlwind subcontract with Lincoln Laboratory, and a 1952 USAF Project Lincoln \"fullscale study\" of \"a large scale integrated ground control system\" resulted in the SAGE approval \"first on a trial basis in 1953\". The USAF had decided by April 10, 1953, to cancel the competing ADIS (based on CDS), and the University of Michigan's Aeronautical Research Center withdrew in the spring. Air Research and Development Command (ARDC) planned to \"finalize a production contract for the Lincoln Transition System\". Similarly, the July 22, 1953, report by the Bull Committee (NSC 159) identified completing the Mid-Canada Line radars as the top priority and \"on a second-priority-basis: the Lincoln automated system\" (the decision to control Bomarc with the automated system was also in 1953.)\nThe Priority Permanent System with the initial (priority) radar stations was completed in 1952 as a \"manual air defense system\" (e.g., NORAD/ADC used a \"Plexiglas plotting board\" at the Ent command center.) The Permanent System radar stations included 3 subsequent phases of deployments and by June 30, 1957, had 119 \"Fixed CONUS\" radars, 29 \"Gap-filler low altitude\" radars, and 23 control centers\". At \"the end of 1957, ADC operated 182 radar stations [and] 17 control centers \u2026 32 [stations] had been added during the last half of the year as low-altitude, unmanned gap-filler radars. The total consisted of 47 gap-filler stations, 75 Permanent System radars, 39 semimobile radars, 19 Pinetree stations,\u20261 Lashup -era radar and a single Texas Tower\". \"On 31 December 1958, USAF ADC had 187 operational land-based radar stations\" (74 were \"P-sites\", 29 \"M-sites\", 13 \"SM-sites\", &amp; 68 \"ZI Gap Fillers\").\nDevelopment.\nSystems scientist Jay Forrester was instrumental in directing the development of the key concept of an interception system during his work at Servomechanisms Laboratory of MIT. The concept of the system, according to the Lincoln Laboratory site was to \n\"develop a digital computer that could receive vast quantities of data from multiple radars and perform real-time processing to produce targeting information for intercepting aircraft and missiles.\"\nThe AN/FSQ-7 was developed by the Lincoln Laboratory's Digital Computer Laboratory and Division 6, working closely with IBM as the manufacturer. Each FSQ-7 actually consisted of two nearly identical computers operating in \"duplex\" for redundancy. The design used an improved version of the Whirlwind I magnetic core memory and was an extension of the Whirlwind II computer program, renamed AN/FSQ-7 in 1953 to comply with Air Force nomenclature. It has been suggested the FSQ-7 was based on the IBM 701 but, while the 701 was investigated by MIT engineers, its design was ultimately rejected due to high error rates and generally being \"inadequate to the task.\" IBM's contributions were essential to the success of the FSQ-7, and IBM benefited immensely from its association with the SAGE project, most evidently during development of the IBM 704.\nOn October 28, 1953, the Air Force Council recommended 1955 funding for \"ADC to convert to the Lincoln automated system\" (\"redesignated the SAGE System in 1954\"). The \"experimental SAGE subsector, located in Lexington, Mass., was completed in 1955\u2026with a prototype AN/FSQ-7\u2026known as XD-1\" (single computer system in Building F). In 1955, Air Force personnel began IBM training at the Kingston, New York, prototype facility, and the \"4620th Air Defense Wing (experimental SAGE) was established at Lincoln Laboratory\"\nOn May 3, 1956, General Partridge presented \"CINCNORAD's Operational Concept for Control of Air Defense Weapons\" to the Armed Forces Policy Council, and a June 1956 symposium presentation identified advanced programming methods of SAGE code. For SAGE consulting Western Electric and Bell Telephone Laboratories formed the Air Defense Engineering Service (ADES), which was contracted in January 1954. IBM delivered the FSQ-7 computer's prototype in June 1956, and Kingston's XD-2 with dual computers guided a Cape Canaveral BOMARC to a successful aircraft intercept on August 7, 1958. Initially contracted to RCA, the AN/FSQ-7 production units were started by IBM in 1958 (32 DCs were planned for networking NORAD regions.) IBM's production contract developed 56 SAGE computers for $.5 billion (~$18 million per computer pair in each FSQ-7)\u2014cf. the $2 billion WWII Manhattan Project.\nGeneral Operational Requirements (GOR) 79 and 97 were \"the basic USAF documents guiding development and improvement of [the semi-automatic] ground environment. Prior to fielding the AN/FSQ-7 centrals, the USAF initially deployed \"pre-SAGE semiautomatic intercept systems\" (AN/GPA-37) to Air Defense Direction Centers, ADDCs (e.g., at \"NORAD Control Centers\"). On April 22, 1958, NORAD approved Nike AADCPs to be collocated with the USAF manual ADDCs at Duncanville Air Force Station TX, Olathe Air Force Station KS, Belleville Air Force Station IL, and Osceola Air Force Station KS.\nDeployment.\nIn 1957, SAGE System groundbreaking at McChord AFB was for DC-12 where the \"electronic brain\" began arriving in November 1958, and the \"first SAGE regional battle post [CC-01] began operating in Syracuse, New York in early 1959\". BOMARC \"crew training was activated January 1, 1958\", and AT&amp;T \"hardened many of its switching centers, putting them in deep underground bunkers\", The North American Defense Objectives Plan (NADOP 59\u201363) submitted to Canada in December 1958 scheduled 5 Direction Centers and 1 Combat Center to be complete in Fiscal Year 1959, 12 DCs and 3 CCs complete at the end of FY 60, 19 DC/4 CC FY 61, 25/6 FY 62, and 30/10 FY 63. On June 30 NORAD ordered that \"Air Defense Sectors (SAGE) were to be designated as NORAD sectors\", (the military reorganization had begun when effective April 1, 1958, CONAD \"designated four SAGE sectors \u2013 New York, Boston, Syracuse, and Washington \u2013 as CONAD Sectors\".)\nSAGE Geographic Reorganization: The SAGE Geographic Reorganization Plan of July 25, 1958, by NORAD was \"to provide a means for the orderly transition and phasing from the manual to the SAGE system.\" The plan identified deactivation of the Eastern, Central, and Western Region/Defense Forces on July 1, 1960, and \"current manual boundaries\" were to be moved to the new \"eight SAGE divisions\" (1 in Canada, \"the 35th\") as soon as possible. Manual divisions \"not to get SAGE computers were to be phased out\" along with their Manual Air Defense Control Centers at the headquarters base: \"9th [at] Geiger Field\u2026 32d, Syracuse AFS\u2026 35th, Dobbins AFB\u2026 58th, Wright-Patterson AFB\u2026 85th, Andrews AFB\". The 26th SAGE Division (New York, Boston, Syracuse &amp; Bangor SAGE sectors)--the 1st of the SAGE divisions\u2014became operational at Hancock Field on 1 January 1959 after the redesignation started for AC&amp;W Squadrons (e.g., the Highlands P-9 unit became the 646th Radar Squadron (SAGE) October 1.) Additional sectors included the Los Angeles Air Defense Sector (SAGE) designated in February 1959. A June 23 JCS memorandum approved the new \"March 1959 Reorganization Plan\" for HQ NORAD/CONAD/ADC.\nProject Wild Goose teams of Air Materiel Command personnel installed c.\u20091960 the Ground Air Transmit Receive stations for the SAGE TDDL (in April 1961, Sault Ste Marie was the first operational sector with TDDL). By the middle of 1960, AMC had determined that about 800,000 man-hours (involving 130 changes) would be required to bring the F-106 fleet to the point where it would be a valuable adjunct to the air defense system. Part of the work (Project Broad Jump) was accomplished by Sacramento Air Materiel Area. The remainder (Project Wild Goose) was done at ADC bases by roving AMC field assistance teams supported by ADC maintenance personnel. (cited by Volume I p.\u00a0271 &amp; Schaffel p.\u00a0325) After a September 1959 experimental ATABE test between an \"abbreviated\" AN/FSQ-7 staged at Fort Banks and the Lexington XD-1, the 1961 \"SAGE/Missile Master test program\" conducted large-scale field testing of the ATABE \"mathematical model\" using radar tracks of actual SAC and ADC aircraft flying mock penetrations into defense sectors. Similarly conducted was the joint SAC-NORAD Sky Shield II exercise followed by Sky Shield III on 2 September 1962 On July 15, 1963, ESD's CMC Management Office assumed \"responsibilities in connection with BMEWS, Space Track, SAGE, and BUIC.\" The Chidlaw Building's computerized NORAD/ADC Combined Operations Center in 1963 became the highest echelon of the SAGE computer network when operations moved from Ent AFB's 1954 manual Command Center to the partially underground \"war room\". Also in 1963, radar stations were renumbered (e.g., Cambria AFS was redesignated from P-2 to Z-2 on July 31) and the vacuum-tube SAGE System was completed (and obsolete).\nOn \"June 26, 1958,\u2026the New York sector became operational\" and on December 1, 1958, the Syracuse sector's DC-03 was operational (\"the SAGE system [did not] become operational until January 1959.\") Construction of CFB North Bay in Canada was started in 1959 for a bunker ~ underground (operational October 1, 1963), and by 1963 the system had 3 Combat Centers. The 23 SAGE centers included 1 in Canada, and the \"SAGE control centers reached their full 22 site deployments in 1961 (out of 46 originally planned).\" The completed Minot AFB blockhouse received an AN/FSQ-7, but never received the FSQ-8 (the April 1, 1959, Minot Air Defense Sector consolidated with the Grand Forks ADS on March 1, 1963).\nSAGE sites.\nThe SAGE system included a direction center (DC) assigned to air defense sectors as they were defined at the time.\nDescription.\nThe environment allowed radar station personnel to monitor the radar data and systems' status (e.g., Arctic Tower radome pressure) and to use the range height equipment to process height requests from Direction Center (DC) personnel. DCs received the Long Range Radar Input from the sector's radar stations, and DC personnel monitored the radar tracks and IFF data provided by the stations, requested height-finder radar data on targets, and monitored the computer's evaluation of which fighter aircraft or Bomarc missile site could reach the threat first. The DC's \"NORAD sector commander's operational staff\" could designate fighter intercept of a target or, using the Senior Director's keyed console in the Weapons Direction room, launch a Bomarc intercept with automatic Q-7 guidance of the surface-to-air missile to a final homing dive (equipped fighters eventually were automatically guided to intercepts).\nThe \"NORAD sector direction center (NSDC) [also had] air defense artillery director (ADAD) consoles [and an Army] ADA battle staff officer\", and the NSDC automatically communicated crosstelling of \"SAGE reference track data\" to/from adjacent sectors' DCs and to 10 Nike Missile Master AADCPs. Forwardtelling automatically communicated data from multiple DCs to a 3-story Combat Center (CC) usually at one of the sector's DCs (cf. planned Hamilton AFB CC-05 near the Beale AFB DC-18) for coordinating the air battle in the NORAD region (multiple sectors) and which forwarded data to the NORAD Command Center (Ent AFB, 1963 Chidlaw Building, &amp; 1966 Cheyenne Mountain). NORAD's integration of air warning data (at the ADOC) along with space surveillance, intelligence, and other data allowed attack assessment of an Air Defense Emergency for alerting the SAC command centers (465L SACCS nodes at Offutt AFB &amp; The Notch), The Pentagon/Raven Rock NMCC/ANMCC, and the public via CONELRAD radio stations.\nThe Burroughs 416L SAGE component (ESD Project 416L, Semi Automatic Ground Environment System) was the Cold War network connecting IBM supplied computer system at the various DC and that created the display and control environment for operation of the separate radars and to provide outbound command guidance for ground-controlled interception by air defense aircraft in the \"SAGE Defense System\" (\"Air Defense Weapons System\"). Burroughs Corporation was a prime contractor for SAGE network interface equipment which included 134 Burroughs AN/FST-2 Coordinate Data Transmitting Sets (CDTS) at radar stations and other sites, the IBM supplied AN/FSQ-7 at 23 Direction Centers, and the AN/FSQ-8 Combat Control Computers at 8 Combat Centers. The 2 computers of each AN/FSQ-7 together weighing used about \u2153 of the DC's 2nd floor space and at ~$50 per instruction had approximately 125,000 \"computer instructions support[ing] actual operational air-defense mission\" processing. The AN/FSQ-7 at Luke AFB had additional memory (32K total) and was used as a \"computer center for all other\" DCs. Project 416L was the USAF predecessor of NORAD, SAC, and other military organizations' \"Big L\" computer systems (e.g., 438L Air Force Intelligence Data Handling System &amp; 496L Space Detection and Tracking System).\nNetwork communications: The SAGE network of computers connected by a \"Digital Radar Relay\" (SAGE data system) used AT&amp;T voice lines, microwave towers, switching centers (e.g., SAGE NNX 764 was at Delta, Utah &amp; 759 at Mounds, Oklahoma), etc.; and AT&amp;T's \"main underground station\" was in Kansas (Fairview) with other bunkers in Connecticut (Cheshire), California (Santa Rosa), Iowa (Boone) and Maryland (Hearthstone Mountain). CDTS modems at automated radar stations transmitted range and azimuth, and the Air Movements Identification Service (AMIS) provided air traffic data to the SAGE System. Radar tracks by telephone calls (e.g., from Manual Control Centers in the Albuquerque, Minot, and Oklahoma City sectors) could be entered via consoles of the 4th floor \"Manual Inputs\" room adjacent to the \"Communication Recording-Monitoring and VHF\" room. In 1966, SAGE communications were integrated into the AUTOVON Network.\nSAGE Sector Warning Networks (cf. NORAD Division Warning Networks) provided the radar netting communications for each DC and eventually also allowed transfer of command guidance to autopilots of TDDL-equipped interceptors for vectoring to targets via the Ground to Air Data Link Subsystem and the Ground Air Transmit Receive (GATR) network of radio sites for \"HF/VHF/UHF voice &amp; TDDL\" each generally co-located at a CDTS site. SAGE Direction Centers and Combat Centers were also nodes of NORAD's Alert Network Number 1, and SAC Emergency War Order Traffic included \"Positive Control/Noah's Ark instructions\" through northern NORAD radio sites to confirm or recall SAC bombers if \"SAC decided to launch the alert force before receiving an execution order from the JCS\".\nA SAGE System ergonomic test at Luke AFB in 1964 \"showed conclusively that the wrong timing of human and technical operations was leading to frequent truncation of the flight path tracking system\" (Harold Sackman). SAGE software development was \"grossly underestimated\" (60,000 lines in September 1955): \"the biggest mistake [of] the SAGE computer program was [underestimating the] jump from the 35,000 [WWI] instructions \u2026 to the more than 100,000 instructions on the\" AN/FSQ-8. NORAD conducted a \"Sage/Missile Master Integration/ECM-ECCM Test\" in 1963, and although SAGE used AMIS input of air traffic information, the 1959 plan developed by the July 1958 USAF Air Defense Systems Integration Division for SAGE Air Traffic Integration (SATIN) was cancelled by the DoD.\nRadar stations.\nSAGE radar stations, including 78 DEW Line sites in December 1961, provided radar tracks to DCs and had frequency diversity (FD) radars United States Navy picket ships also provided radar tracks, and seaward radar coverage was provided. By the late 1960s EC-121 Warning Star aircraft based at Otis AFB MA and McClellan AFB CA provided radar tracks via automatic data link to the SAGE System. Civil Aeronautics Administration radars were at some stations (e.g., stations of the Joint Use Site System), and the ARSR-1 Air Route Surveillance Radar rotation rate had to be modified \"for SAGE [IFF/SIF] Modes III and IV\" (\"antenna gear box modification\" for compatibility with FSQ-7 &amp; FSG-1 centrals.)\nInterceptors.\nADC aircraft such as the F-94 Starfire, F-89 Scorpion, F-101B Voodoo, and F-4 Phantom were controlled by SAGE GCI. The F-104 Starfighter was \"too small to be equipped with [SAGE] data link equipment\" and used voice-commanded GCI, but the F-106 Delta Dart was equipped for the automated data link (ADL). The ADL was designed to allow Interceptors that reached targets to transmit real-time tactical friendly and enemy movements and to determine whether sector defence reinforcement was necessary.\nFamiliarization flights allowed SAGE weapons directors to fly on two-seat interceptors to observe GCI operations. Surface-to-air missile installations for CIM-10 Bomarc interceptors were displayed on SAGE consoles.\nImprovements.\nPartially solid-state AN/FST-2B and later AN/FYQ-47 computers replaced the AN/FST-2, and sectors without AN/FSQ-7 centrals requiring a \"weapon direction control device\" for USAF air defense used the solid-state AN/GSG-5 CCCS instead of the AN/GPA-73 recommended by ADC in June 1958. Back-Up Interceptor Control (BUIC) with CCCS dispersed to radar stations for survivability allowed a diminished but functional SAGE capability. In 1962, Burroughs \"won the contract to provide a military version of its D825\" modular data processing system for BUIC II. BUIC II was first used at North Truro Z-10 in 1966, and the Hamilton AFB BUIC II was installed in the former MCC building when it was converted to a SAGE Combat Center in 1966 (CC-05). On June 3, 1963, the Direction Centers at Marysville CA, Marquette/K I Sawyer AFB (DC-14) MI, Stewart AFB NY (DC-02), and Moses Lake WA (DC-15) were planned for closing and at the end of 1969, only 6 CONUS SAGE DCs remained (DC-03, -04, -10, -12, -20, &amp; -21) all with the vacuum tube AN/FSQ-7 centrals. In 1966, NORAD Combined Operations Center operations at Chidlaw transferred to the Cheyenne Mountain Operations Center (425L System) and in December 1963, the DoD approved solid state replacement of Martin AN/FSG-1 centrals with the AN/GSG-5 and subsequent Hughes AN/TSQ-51. The \"416L/M/N Program Office\" at Hanscom Field had deployed the BUIC III by 1971 (e.g., to Fallon NAS), and the initial BUIC systems were phased out 1974\u20135. ADC had been renamed Aerospace Defense Command on January 15, 1968, and its general surveillance radar stations transferred to ADTAC in 1979 when the ADC major command was broken up (space surveillance stations went to SAC and the Aerospace Defense Center was activated as a DRU.)\nReplacement and disposition.\nFor airborne command posts, \"as early as 1962 the Air Force began exploring possibilities for an Airborne Warning and Control System (AWACS)\", and the Strategic Defense Architecture (SDA-2000) planned an integrated air defense and air traffic control network. The USAF declared full operational capability of the first seven Joint Surveillance System ROCCs on December 23, 1980, with Hughes AN/FYQ-93 systems, and many of the SAGE radar stations became Joint Surveillance System (JSS) sites (e.g., San Pedro Hill Z-39 became FAA Ground Equipment Facility J-31.) The North Bay AN/FSQ-7 was dismantled and sent to Boston's Computer Museum. In 1996, AN/FSQ-7 components were moved to Moffett Federal Airfield for storage and later moved to the Computer History Museum in Mountain View, California. The last AN/FSQ-7 centrals were demolished at McChord AFB (August 1983) and Luke AFB (February 1984). Decommissioned AN/FSQ-7 equipment was also used as science fiction cinema and TV series props (e.g., Voyage to the Bottom of the Sea, amongst others).\nHistoriography.\nSAGE histories include a 1983 special issue of the \"Annals of the History of Computing\", and various personal histories were published, e.g., Valley in 1985 and Jacobs in 1986. In 1998, the SAGE System was identified as one of four \"Monumental Projects\", and a SAGE lecture presented the vintage film \"In Your Defense\" followed by anecdotal information from Les Earnest, Jim Wong, and Paul Edwards. In 2013, a copy of a 1950s cover girl image programmed for SAGE display was identified as the \"earliest known figurative computer art\". Company histories identifying employees' roles in SAGE include the 1981 \"System Builders: The Story of SDC\" and the 1998 \"Architects of Information Advantage: The MITRE Corporation Since 1958\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28009", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=28009", "title": "Sydney underground railways", "text": ""}
{"id": "28011", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=28011", "title": "Subgroup", "text": "Subset of a group that forms a group itself\nIn group theory, a branch of mathematics, a subset of a group G is a subgroup of G if the members of that subset form a group with respect to the group operation in G. \nFormally, given a group G under a binary operation\u00a0\u2217, a subset H of G is called a subgroup of G if H also forms a group under the operation\u00a0\u2217. More precisely, H is a subgroup of G if the restriction of \u2217 to \"H\" \u00d7 \"H\" is a group operation on H. This is often denoted \"H\" \u2264 \"G\", read as \"H is a subgroup of G\".\nThe trivial subgroup of any group is the subgroup {\"e\"} consisting of just the identity element.\nA proper subgroup of a group G is a subgroup H which is a proper subset of G (that is, \"H\" \u2260 \"G\"). This is often represented notationally by \"H\" &lt; \"G\", read as \"H is a proper subgroup of G\". Some authors also exclude the trivial group from being proper (that is, \"H\" \u2260 {\"e\"}\u200b).\nIf H is a subgroup of G, then G is sometimes called an overgroup of H.\nThe same definitions apply more generally when G is an arbitrary semigroup, but this article will only deal with subgroups of groups.\nSubgroup tests.\nSuppose that G is a group, and H is a subset of G. For now, assume that the group operation of G is written multiplicatively, denoted by juxtaposition.\nIf the group operation is instead denoted by addition, then \"closed under products\" should be replaced by \"closed under addition\", which is the condition that for every a and b in H, the sum \"a\" + \"b\" is in H, and \"closed under inverses\" should be edited to say that for every a in H, the inverse \u2212\"a\" is in H.\nCosets and Lagrange's theorem.\nGiven a subgroup H and some a in G, we define the left coset \"aH\" = {\"ah\" : \"h\" in \"H\"}. Because a is invertible, the map \u03c6 : \"H\" \u2192 \"aH\" given by \u03c6(\"h\") = \"ah\" is a bijection. Furthermore, every element of G is contained in precisely one left coset of H; the left cosets are the equivalence classes corresponding to the equivalence relation \"a\"1 ~ \"a\"2 if and only if &amp;NoBreak;&amp;NoBreak; is in H. The number of left cosets of H is called the index of H in G and is denoted by [\"G\" : \"H\"].\nLagrange's theorem states that for a finite group G and a subgroup H, \n formula_1\nwhere and denote the orders of G and H, respectively. In particular, the order of every subgroup of G (and the order of every element of G) must be a divisor of .\nRight cosets are defined analogously: \"Ha\" = {\"ha\" : \"h\" in \"H\"}. They are also the equivalence classes for a suitable equivalence relation and their number is equal to [\"G\" : \"H\"].\nIf \"aH\" = \"Ha\" for every a in G, then H is said to be a normal subgroup. Every subgroup of index 2 is normal: the left cosets, and also the right cosets, are simply the subgroup and its complement. More generally, if p is the lowest prime dividing the order of a finite group G, then any subgroup of index p (if such exists) is normal.\nExample: Subgroups of Z8.\nLet G be the cyclic group Z8 whose elements are\nformula_2\nand whose group operation is addition modulo 8. Its Cayley table is\nThis group has two nontrivial subgroups: and , where J is also a subgroup of H. The Cayley table for H is the top-left quadrant of the Cayley table for G; The Cayley table for J is the top-left quadrant of the Cayley table for H. The group G is cyclic, and so are its subgroups. In general, subgroups of cyclic groups are also cyclic.\nExample: Subgroups of S4.\nS4 is the symmetric group whose elements correspond to the permutations of 4 elements.&lt;br&gt;\nBelow are all its subgroups, ordered by cardinality.&lt;br&gt;\nEach group is represented by its Cayley table.\n24 elements.\nLike each group, S4 is a subgroup of itself.\n12 elements.\nThe alternating group contains only the even permutations.&lt;br&gt;\nIt is one of the two nontrivial proper normal subgroups of S4. \n2 elements.\nEach permutation p of order 2 generates a subgroup {1, \"p\"}.\nThese are the permutations that have only 2-cycles:&lt;br&gt;\n1 element.\nThe trivial subgroup is the unique subgroup of order 1."}
{"id": "28012", "revid": "49194911", "url": "https://en.wikipedia.org/wiki?curid=28012", "title": "Series", "text": "Series may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "28013", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=28013", "title": "Silicon Graphics", "text": "1981\u20132009 American computing company\nSilicon Graphics, Inc. (stylized as SiliconGraphics before 1999, later rebranded SGI, historically known as Silicon Graphics Computer Systems or SGCS) was an American high-performance computing manufacturer, producing computer hardware and software. Founded in Mountain View, California, in November 1981 by James H. Clark, the computer scientist and entrepreneur perhaps best known for founding Netscape (with Marc Andreessen). Its initial market was 3D graphics computer workstations, but its products, strategies and market positions developed significantly over time.\nEarly systems were based on the Geometry Engine that Clark and Marc Hannah had developed at Stanford University, and were derived from Clark's broader background in computer graphics. The Geometry Engine was the first very-large-scale integration (VLSI) implementation of a geometry pipeline, specialized hardware that accelerated the \"inner-loop\" geometric computations needed to display three-dimensional images. For much of its history, the company focused on 3D imaging and was a major supplier of both hardware and software in this market.\nSilicon Graphics reincorporated as a Delaware corporation in January 1990. Through the mid to late-1990s, the rapidly improving performance of commodity Wintel machines began to erode SGI's stronghold in the 3D market. The porting of Maya to other platforms was a major event in this process. SGI made several attempts to address this, including a disastrous move from their existing MIPS platforms to the Intel Itanium, as well as introducing their own Linux-based Intel IA-32 based workstations and servers that failed in the market. In the mid-2000s the company repositioned itself as a supercomputer vendor, a move that also failed.\nOn April 1, 2009, SGI filed for Chapter 11 bankruptcy protection and announced that it would sell substantially all of its assets to Rackable Systems, a deal finalized on May 11, 2009, with Rackable assuming the name Silicon Graphics International. The remnants of Silicon Graphics, Inc. became Graphics Properties Holdings, Inc.\nHistory.\nEarly years.\nJames H. Clark left his position as an electrical engineering associate professor at Stanford University to found SGI in 1982 along with a group of seven graduate students and research staff from Stanford University: Kurt Akeley, David J. Brown, Tom Davis, Rocky Rhodes, Marc Hannah, Herb Kuta, and Mark Grossman; along with Abbey Silverstone and a few others.\nGrowth.\nEd McCracken was CEO of Silicon Graphics from 1984 to 1997. During those years, SGI grew from annual revenues of $5.4 million to $3.7 billion. Silicon Graphics systems dominated the market for high-speed rendering of three-dimensional graphics, an area rivals like IBM and Sun Microsystems avoided.\nDecline.\nThe addition of 3D graphic capabilities to PCs, and the ability of clusters of Linux- and BSD-based PCs to take on many of the tasks of larger SGI servers, ate into SGI's core markets. The porting of Maya to Linux, Mac OS and Microsoft Windows further eroded the low end of SGI's product line.\nIn response to challenges faced in the marketplace and a falling share price, Ed McCracken was fired and SGI brought in Richard Belluzzo to replace him. Under Belluzzo's leadership a number of initiatives were taken which are considered to have accelerated the corporate decline.\nOne such initiative was trying to sell workstations running Windows NT called Visual Workstations in addition to workstations running IRIX, the company's version of UNIX. This put the company in even more direct competition with the likes of Dell, making it more difficult to justify a price premium. The product line was unsuccessful and abandoned a few years later.\nSGI's premature announcement of its migration from MIPS to Itanium and its abortive ventures into IA-32 architecture systems (the Visual Workstation line, the ex-Intergraph Zx10 range and the SGI 1000-series Linux servers) damaged SGI's credibility in the market.\nIn 1999, in an attempt to clarify their current market position as more than a graphics company, Silicon Graphics Inc. changed its corporate identity to \"SGI\", although its legal name was unchanged.\nAt the same time, SGI announced a new logo consisting of only the letters \"sgi\" in a proprietary font called \"SGI\", created by branding and design consulting firm Landor Associates, in collaboration with designer Joe Stitzlein. SGI continued to use the \"Silicon Graphics\" name for its workstation product line, and later re-adopted the cube logo for some workstation models.\nIn November 2005, SGI announced that it had been delisted from the New York Stock Exchange because its common stock had fallen below the minimum share price for listing on the exchange. SGI's market capitalization dwindled from a peak of over seven billion dollars in 1995 to just $120 million at the time of delisting. In February 2006, SGI noted that it could run out of cash by the end of the year.\nRe-emergence.\nIn mid-2005, SGI hired Alix Partners to advise it on returning to profitability and received a new line of credit. SGI announced it was postponing its scheduled annual December stockholders meeting until March 2006. It proposed a reverse stock split to deal with the de-listing from the New York Stock Exchange.\nIn January 2006, SGI hired Dennis McKenna as its new CEO and chairman of the board of directors. Mr. McKenna succeeded Robert Bishop, who remained vice chairman of the board of directors.\nOn May 8, 2006, SGI announced that it had filed for Chapter 11 bankruptcy protection for itself and U.S. subsidiaries as part of a plan to reduce debt by $250 million. Two days later, the U.S. Bankruptcy Court approved its first day motions and its use of a $70 million financing facility provided by a group of its bondholders. Foreign subsidiaries were unaffected.\nOn September 6, 2006, SGI announced the end of development for the MIPS/IRIX line and the IRIX operating system. Production would end on December 29 and the last orders would be fulfilled by March 2007. Support for these products would end after December 2013.\nSGI emerged from bankruptcy protection on October 17, 2006. Its stock symbol on Pink Sheets at that point, \"SGID\", was canceled, and new stock was issued on the NASDAQ exchange under the symbol \"SGIC\". This new stock was distributed to the company's creditors, and the SGID common stockholders were left with worthless shares. At the end of that year, the company moved its headquarters from Mountain View to Sunnyvale. Its earlier North Shoreline headquarters is now occupied by the Computer History Museum; the newer Amphitheatre Parkway headquarters was sold to Google (which had already subleased and moved into the facility in 2003). Both of these locations were award-winning designs by Studios Architecture.\nIn April 2008, SGI re-entered the visualization market with the SGI Virtu range of visualization servers and workstations, which were re-badged systems from BOXX Technologies based on Intel Xeon or AMD Opteron processors and Nvidia Quadro graphics chipsets, running Red Hat Enterprise Linux, SUSE Linux Enterprise Server or Windows Compute Cluster Server.\nFinal bankruptcy and acquisition by Rackable Systems.\nIn December 2008, SGI received a delisting notification from NASDAQ, as its market value had been below the minimum $35 million requirement for 10 consecutive trading days, and also did not meet NASDAQ's alternative requirements of a minimum stockholders' equity of $2.5 million or annual net income from continuing operations of $500,000 or more.\nOn April 1, 2009, SGI filed for Chapter 11 again, and announced that it would sell substantially all of its assets to Rackable Systems for $25 million. The sale, ultimately for $42.5 million, was finalized on May 11, 2009; at the same time, Rackable announced their adoption of \"Silicon Graphics International\" as their global name and brand. The Bankruptcy Court scheduled continuing proceedings and hearings for June 3 and 24, 2009, and July 22, 2009.\nAfter the Rackable acquisition, \"Vizworld\" magazine published http://\nHewlett Packard Enterprise acquired Silicon Graphics International in November 2016, which allowed HPE to place the SGI Pleiades, a TOP500 supercomputer at NASA Ames Research Center, in its portfolio.\nGraphics Properties Holdings, Inc. era.\nDuring Silicon Graphics Inc.'s second bankruptcy phase, it was renamed to Graphics Properties Holdings, Inc.(GPHI) in June 2009.\nIn 2010, GPHI announced it had won a significant favorable ruling in its litigation with ATI Technologies and AMD in June 2010, following the patent lawsuit originally filed during the Silicon Graphics, Inc. era. Following the 2008 appeal by ATI over the validity of https:// ('327) and Silicon Graphics Inc's voluntary dismissal of the https:// ('376) patent from the lawsuit, the Federal Circuit upheld the jury verdict on the validity of GPHI's U.S. Patent No. 6,650,327, and furthermore found that AMD had lost its right to challenge patent validity in future proceedings. On January 31, 2011, the District Court entered an order that permits AMD to pursue its invalidity affirmative defense at trial and does not permit SGI to accuse AMD's Radeon R700 series of graphics products of infringement in this case. On April 18, 2011, GPHI and AMD had entered into a confidential Settlement and License Agreement that resolved this litigation matter for an immaterial amount and that provides immunity under all GPHI patents for alleged infringement by AMD products, including components, software and designs. On April 26, 2011, the Court entered an order granting the parties' agreed motion for dismissal and final judgment.\nIn November 2011, GPHI filed another patent infringement lawsuit against Apple Inc. in Delaware involving more patents than their original patent infringement case against Apple last November, for alleged violation of U.S. patents 6,650,327 ('327), https:// ('145) and https:// ('881).\nIn 2012, GPHI filed lawsuit against Apple, Sony, HTC Corp, LG Electronics Inc. and Samsung Electronics Co., Research in Motion Ltd. for allegedly violating patent relating to a computer graphics process that turns text and images into pixels to be displayed on screens. Affected devices include Apple iPhone, HTC EVO4G, LG Thrill, Research in Motion Torch, Samsung Galaxy S and Galaxy S II, and Sony Xperia Play smartphones.\nTechnology.\nMotorola 680x0-based systems.\nSGI's first generation products, starting with the IRIS (Integrated Raster Imaging System) 1000 series of high-performance graphics terminals, were based on the Motorola 68000 family of microprocessors. The later IRIS 2000 and 3000 models developed into full UNIX workstations.&lt;ref name=\"sgi/iptable\"&gt;&lt;/ref&gt;\nIRIS 1000 series.\nThe first entries in the 1000 series (models 1000 and 1200, introduced in 1984) were graphics terminals, peripherals to be connected to a general-purpose computer such as a Digital Equipment Corporation VAX, to provide graphical raster display abilities. They used 8\u00a0MHz Motorola 68000 CPUs with 768 kB of RAM and had no disk drives. They booted over the network (via an Excelan EXOS/101 Ethernet card) from their controlling computer. They used the \"PM1\" CPU board, which was a variant of the board that was used in Stanford University's SUN workstation and later in the Sun-1 workstation from Sun Microsystems. The graphics system was composed of the GF1 frame buffer, the UC3 \"Update Controller\", DC3 \"Display Controller\", and the BP2 bitplane. The 1000-series machines were designed around the Multibus standard.\nLater 1000-series machines, the 1400 and 1500, ran at 10\u00a0MHz and had 1.5 MB of RAM. The 1400 had a 72 MB ST-506 disk drive, while the 1500 had a 474 MB SMD-based disk drive with a Xylogics 450 disk controller. They may have used the PM2 CPU and PM2M1 RAM board from the 2000 series. The usual monitor for the 1000 series ran at 30\u00a0Hz interlaced. Six beta-test units of the 1400 workstation were produced, and the first production unit (SGI's first commercial computer) was shipped to Carnegie-Mellon University's Electronic Imaging Laboratory in 1984.\nIRIS 2000 and 3000 series.\nSGI rapidly developed its machines into workstations with its second product line \u2014 the IRIS 2000 series, first released in August 1985. SGI began using the UNIX System V operating system. There were five models in two product ranges, the 2000/2200/2300/2400/2500 range which used 68010 CPUs (the PM2 CPU module), and the later \"Turbo\" systems, the 2300T, 2400T and 2500T, which had 68020s (the IP2 CPU module). All used the Excelan EXOS/201 Ethernet card, the same graphics hardware (GF2 Frame Buffer, UC4 Update Controller, DC4 Display Controller, BP3 Bitplane). Their main differences were the CPU, RAM, and Weitek Floating Point Accelerator boards, disk controllers and disk drives (both ST-506 and SMD were available). These could be upgraded, for example from a 2400 to a 2400T. The 2500 and 2500T had a larger chassis, a standard 6' 19\" EIA rack with space at the bottom for two SMD disk drives weighing approximately 68 kg each. The non-Turbo models used the Multibus for the CPU to communicate with the floating point accelerator, while the Turbos added a ribbon cable dedicated for this. 60\u00a0Hz monitors were used for the 2000 series.\nThe height of the machines using Motorola CPUs was reached with the IRIS 3000 series (models 3010/3020/3030 and 3110/3115/3120/3130, the 30s both being full-size rack machines). They used the same graphics subsystem and Ethernet as the 2000s, but could also use up to 12 \"geometry engines\", the first widespread use of hardware graphics accelerators. The standard monitor was a 19\" 60\u00a0Hz non-interlaced unit with a tilt/swivel base; 19\" 30\u00a0Hz interlaced and a 15\" 60\u00a0Hz non-interlaced (with tilt/swivel base) were also available.\nThe IRIS 3130 and its smaller siblings were impressive for the time, being complete UNIX workstations. The 3130 was powerful enough to support a complete 3D animation and rendering package without mainframe support. With large capacity hard drives by standards of the day (two 300 MB drives), streaming tape and Ethernet, it could be the centerpiece of an animation operation.\nThe line was formally discontinued in November 1989, with about 3,500 systems shipped of all 2000 and 3000 models combined.\nRISC era.\nWith the introduction of the IRIS 4D series, SGI switched to MIPS microprocessors. These machines were more powerful and came with powerful on-board floating-point capability. As 3D graphics became more popular in television and film during this time, these systems were responsible for establishing much of SGI's reputation.\nSGI produced a broad range of MIPS-based workstations and servers during the 1990s, running SGI's version of UNIX System V, now called IRIX. These included the massive Onyx visualization systems, the size of refrigerators and capable of supporting up to 64 processors while managing up to three streams of high resolution, fully realized 3D graphics.\nIn October 1991, MIPS announced the first commercially available 64-bit microprocessor, the R4000. SGI used the R4000 in its Crimson workstation. IRIX 6.2 was the first fully 64-bit IRIX release, including 64-bit pointers.\nTo secure the supply of future generations of MIPS microprocessors (the 64-bit R4000), SGI acquired the company in 1992 for $333 million and renamed it as MIPS Technologies Inc., a wholly owned subsidiary of SGI.\nIn 1993, Silicon Graphics (SGI) signed a deal with Nintendo to develop the Reality Coprocessor (RCP) GPU used in the Nintendo 64 (N64) video game console. The deal was signed in early 1993, and it was later made public in August of that year. The console itself was later released in 1996. The RCP was developed by SGI's Nintendo Operations department, led by engineer Dr. Wei Yen. In 1997, twenty SGI employees, led by Yen, left SGI and founded ArtX (later acquired by ATI Technologies in 2000).\nIn 1998, SGI relinquished some ownership of MIPS Technologies, Inc in a Re-IPO, and fully divested itself in 2000.\nIn the late 1990s, when much of the industry expected the Itanium to replace both CISC and RISC architectures in non-embedded computers, SGI announced their intent to phase out MIPS in their systems. Development of new MIPS microprocessors stopped, and the existing R12000 design was extended multiple times until 2003 to provide existing customers more time to migrate to Itanium.\nIn August 2006, SGI announced the end of production for MIPS/IRIX systems, and by the end of the year MIPS/IRIX products were no longer generally available from SGI.\nIRIS GL and OpenGL.\nUntil the second generation Onyx Reality Engine machines, SGI offered access to its high performance 3D graphics subsystems through a proprietary API known as \"IRIS Graphics Library\" (IRIS GL). As more features were added over the years, IRIS GL became harder to maintain and more cumbersome to use. In 1992, SGI decided to clean up and reform IRIS GL and made the bold move of allowing the resulting OpenGL API to be cheaply licensed by SGI's competitors, and set up an industry-wide consortium to maintain the OpenGL standard (the OpenGL Architecture Review Board).\nThis meant that for the first time, fast, efficient, cross-platform graphics programs could be written. For over 20 years \u2013 until the introduction of the Vulkan API \u2013 OpenGL remained the only real-time 3D graphics standard to be portable across a variety of operating systems.\nACE Consortium.\nSGI was part of the Advanced Computing Environment initiative, formed in the early 1990s with 20 other companies, including Compaq, Digital Equipment Corporation, MIPS Computer Systems, Groupe Bull, Siemens, NEC, NeTpower, Microsoft and Santa Cruz Operation. Its intent was to introduce workstations based on the MIPS architecture and able to run Windows NT and SCO UNIX. The group produced the Advanced RISC Computing (ARC) specification, but began to unravel little more than a year after its formation.\nEntertainment industry.\nFor eight consecutive years (1995\u20132002), all films nominated for an Academy Award for Distinguished Achievement in Visual Effects were created on Silicon Graphics computer systems. The technology was also used in commercials for a host of companies.\nAn SGI Crimson system with the fsn three-dimensional file system navigator appeared in the 1993 movie \"Jurassic Park\".\nIn the movie \"Twister\", protagonists can be seen using an SGI laptop computer; however, the unit shown was not an actual working computer, but rather a fake laptop shell built around an SGI Corona LCD flat screen display.\nThe 1995 film \"Congo\" also features an SGI laptop computer being used by Dr. Ross (Laura Linney) to communicate via satellite to TraviCom HQ.\nThe purple, lowercased \"sgi\" logo can be seen at the beginning of the opening credits of the HBO series \"Silicon Valley\", before being taken down and replaced by the Google logo as the intro graphics progress. Google leased the former SGI buildings in 2003 for their headquarters in Mountain View, CA until they purchased the buildings outright in 2006.\nOnce inexpensive PCs began to have graphics performance close to the more expensive specialized graphical workstations which were SGI's core business, SGI shifted its focus to high performance servers for digital video and the Web. Many SGI graphics engineers left to work at other computer graphics companies such as ATI and Nvidia, contributing to the PC 3D graphics revolution.\nFree software.\nSGI was a promoter of free software, supporting several projects such as Linux and Samba, and opening some of its own previously proprietary code such as the XFS filesystem and the Open64 compiler.\nSGI was also important in its contribution to the C++ Standard Template Library (STL) with many useful extensions in the MIT-like licensed SGI STL implementation. The extension keeps being carried by the direct descendant STLport and GNU's libstdc++.\nAcquisition of Alias, Wavefront, Cray and Intergraph.\nIn 1995, SGI purchased Alias Research, Kroyer Films, and Wavefront Technologies in a deal totaling approximately $500 million and merged the companies into Alias|Wavefront. In June 2004 SGI sold the business, later renamed to Alias/Wavefront, to the private equity investment firm Accel-KKR for $57.5 million. In October 2005, Autodesk announced that it signed a definitive agreement to acquire Alias for $182 million in cash.\nIn February 1996, SGI purchased the well-known supercomputer manufacturer Cray Research for $740 million, and began to use marketing names such as \"CrayLink\" for (SGI-developed) technology integrated into the SGI server line. Three months later, it sold the Cray Business Systems Division, responsible for the CS6400 SPARC/Solaris server, to Sun Microsystems for an undisclosed amount (acknowledged later by a Sun executive to be \"significantly less than $100 million\"). Many of the Cray T3E engineers designed and developed the SGI Altix and NUMAlink technology. SGI sold the Cray brand and product lines to Tera Computer Company on March 31, 2000, for $35 million plus one million shares. SGI also distributed its remaining interest in MIPS Technologies through a spin-off effective June 20, 2000.\nIn September 2000, SGI acquired the Zx10 series of Windows workstations and servers from Intergraph Computer Systems (for a rumored $100 million), and rebadged them as SGI systems. The product line was discontinued in June 2001.\nSGI Visual Workstations.\nAnother attempt by SGI in the late 1990s to introduce its own family of Intel-based workstations running Windows NT or Red Hat Linux (see also SGI Visual Workstation) proved to be a financial disaster, and shook customer confidence in SGI's commitment to its own MIPS-based line.\nSwitch to Itanium.\nIn 1998, SGI announced that future generations of its machines would be based not on their own MIPS processors, but the upcoming \"super-chip\" from Intel, code-named \"Merced\" and later called Itanium. Funding for its own high-end processors was reduced, and it was planned that the R10000 would be the last MIPS mainstream processor. MIPS Technologies would focus entirely on the embedded market, where it was having some success, and SGI would no longer have to fund development of a CPU that, since the failure of ARC, found use only in their own machines. The Origin 2000 server line was intended to get nodeboards loaded with Merced. Production and development delays in as early as 1999 made it clear that the Merced release was going to be delivered late. Stopgap MIPS CPUs, all refinements of the successful R10000 such as the R12000, R14000 and R16000 were released. These were used in a series of MIPS servers and workstations from 1999 through 2006.\nSGI's first Itanium-based system was the short-lived SGI 750 workstation, launched in 2001. SGI's MIPS-based systems were not to be superseded until the launch of the Itanium 2-based Altix servers and Prism workstations some time later. Unlike the MIPS systems, which ran IRIX, the Itanium systems used SuSE Linux Enterprise Server with SGI enhancements as their operating system. SGI used Transitive Corporation's QuickTransit software to allow their old MIPS/IRIX applications to run (in emulation) on the new Itanium/Linux platform.\nIn the server market, the Itanium 2-based Altix eventually replaced the MIPS-based Origin product line. In the workstation market, the switch to Itanium was not completed before SGI exited the market.\nThe Altix was the most powerful computer in the world in 2006, assuming that a \"computer\" is defined as a collection of hardware running under a single instance of an operating system. The Altix had 512 Itanium processors running under a single instance of Linux. A cluster of 20 machines was then the eighth-fastest supercomputer. All faster supercomputers were clusters, but none have as many FLOPS per machine. However, more recent supercomputers are very large clusters of machines that are individually less capable. SGI acknowledged this and in 2007 moved away from the \"massive NUMA\" model to clusters.\nSwitch to Xeon.\nAlthough SGI continued to market Itanium-based machines, its more recent machines were based on the Intel Xeon processor. The first Altix XE systems were relatively low-end machines, but by December 2006 the XE systems were more capable than the Itanium machines by some measures (e.g., power consumption in FLOPS/W, density in FLOPS/m3, cost/FLOPS). The XE1200 and XE1300 servers used a cluster architecture. This was a departure from the pure NUMA architectures of the earlier Itanium and MIPS servers.\nIn June 2007, SGI announced the Altix ICE 8200, a blade-based Xeon system with up to 512 Xeon cores per rack. An Altix ICE 8200 installed at New Mexico Computing Applications Center (with 14336 processors) ranked at number 3 on the TOP500 list of November 2007.\nUser base and core market.\nConventional wisdom holds that SGI's core market has traditionally been Hollywood visual effects studios. In fact, SGI's largest revenue has always been generated by government and defense applications, energy, and scientific and technical computing. In one case Silicon Graphics' largest single sale ever was to the United States Postal Service. SGI's servers powered an artificial intelligence program to mechanically read, tag and sort the mail (hand-written and block) at a number of USPS's key mail centers. The rise of cheap yet powerful commodity workstations running Linux, Windows and Mac OS X, and the availability of diverse professional software for them, effectively pushed SGI out of the visual effects industry in all but the most niche markets.\nHigh-end server market.\nSGI continued to enhance its line of servers (including some supercomputers) based on the SN architecture. SN, for Scalable Node, is a technology developed by SGI in the mid-1990s that uses cache-coherent non-uniform memory access (cc-NUMA). In an SN system, processors, memory, and a bus- and memory-controller are coupled together into an entity called a node, usually on a single circuit board. Nodes are connected by a high-speed interconnect called NUMAlink (originally marketed as CrayLink). There is no internal bus, and instead access between processors, memory, and I/O devices is done through a switched fabric of links and routers.\nThanks to the cache coherence of the distributed shared memory, SN systems scale along several axes at once: as CPU count increases, so does memory capacity, I/O capacity, and system bisection bandwidth. This allows the combined memory of all the nodes to be accessed under a single OS image using standard shared-memory synchronization methods. This makes an SN system far easier to program and able to achieve higher sustained-to-peak performance than non-cache-coherent systems like conventional clusters or massively parallel computers which require applications code to be written (or re-written) to do explicit message-passing communication between their nodes.\nThe first SN system, known as SN-0, was released in 1996 under the product name Origin 2000. Based on the MIPS R10000 processor, it scaled from 2 to 128 processors and a smaller version, the Origin 200 (SN-00), scaled from 1 to 4. Later enhancements enabled systems of as large as 512 processors.\nThe second generation system, originally called SN-1 but later SN-MIPS, was released in July 2000, as the Origin 3000. It scaled from 4 to 512 processors, and 1,024-processor configurations were delivered by special order to some customers. A smaller, less scalable implementation followed, called Origin 300.\nIn November 2002, SGI announced a repackaging of its SN system, under the name Origin 3900. It quadrupled the processor area density of the SN-MIPS system, from 32 up to 128 processors per rack while moving to a \"fat tree\" interconnect topology.\nIn January 2003, SGI announced a variant of the SN platform called the Altix 3000 (internally called SN-IA). It used Intel Itanium 2 processors and ran the Linux operating system kernel. At the time it was released, it was the world's most scalable Linux-based computer, supporting up to 64 processors in a single system node. Nodes could be connected using the same NUMAlink technology to form what SGI predictably termed \"superclusters\".\nIn February 2004, SGI announced general support for 128 processor nodes to be followed by 256 and 512 processor versions that year.\nIn April 2004, SGI announced the sale of its Alias software business for approximately $57 million.\nIn October 2004, SGI built the supercomputer Columbia, which broke the world record for computer speed, for the NASA Ames Research Center. It was a cluster of 20 Altix supercomputers each with 512 Intel Itanium 2 processors running Linux, and achieved sustained speed of 42.7 trillion floating-point operations per second (teraflops), easily topping Japan's famed Earth Simulator's record of 35.86 teraflops. (A week later, IBM's upgraded Blue Gene/L clocked in at 70.7 teraflops.)\nIn July 2006, SGI announced an SGI Altix 4700 system with 1,024 processors and 4 TB of memory running a single Linux system image.\nHardware products.\nSome 68k- and MIPS-based models were also rebadged by other vendors, including CDC, Tandem Computers, Prime Computer and Siemens-Nixdorf.\nSGI Onyx and SGI Indy series systems were used for video game development for the Nintendo 64.\nMIPS-based systems.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nIntel IA-32-based systems.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28014", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=28014", "title": "Snow boarding", "text": ""}
{"id": "28016", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=28016", "title": "Steiner system", "text": "Block design in combinatorial mathematics\nIn combinatorial mathematics, a Steiner system (named after Jakob Steiner) is a type of block design, specifically a with \u03bb = 1 and \"t\" = 2 or (recently) \"t\" \u2265 2.\nA Steiner system with parameters \"t\", \"k\", \"n\", written S(\"t\",\"k\",\"n\"), is an \"n\"-element set \"S\" together with a set of \"k\"-element subsets of \"S\" (called blocks) with the property that each \"t\"-element subset of \"S\" is contained in exactly one block. In an alternative notation for block designs, an S(\"t\",\"k\",\"n\") would be a \"t\"-(\"n\",\"k\",1) design.\nThis definition is relatively new. The classical definition of Steiner systems also required that \"k\" = \"t\" + 1. An S(2,3,\"n\") was (and still is) called a \"Steiner triple\" (or \"triad\") \"system\", while an S(3,4,\"n\") is called a \"Steiner quadruple system\", and so on. With the generalization of the definition, this naming system is no longer strictly adhered to.\nLong-standing problems in design theory were whether there exist any nontrivial Steiner systems (nontrivial meaning \"t\" &lt; \"k\" &lt; \"n\") with \"t\" \u2265 6; also whether infinitely many have \"t\" = 4 or 5. Both existences were proved by Peter Keevash in 2014. His proof is non-constructive and, as of 2019, no actual Steiner systems are known for large values of \"t\".\nTypes of Steiner systems.\nA finite projective plane of order \"q\", with the lines as blocks, is an S(2, \"q\" + 1, \"q\"2 + \"q\" + 1), since it has \"q\"2 + \"q\" + 1 points, each line passes through \"q\" + 1 points, and each pair of distinct points lies on exactly one line.\nA finite affine plane of order \"q\", with the lines as blocks, is an S(2,\u00a0\"q\",\u00a0\"q\"2). An affine plane of order \"q\" can be obtained from a projective plane of the same order by removing one block and all of the points in that block from the projective plane. Choosing different blocks to remove in this way can lead to non-isomorphic affine planes.\nAn S(3,4,\"n\") is called a Steiner quadruple system. A necessary and sufficient condition for the existence of an S(3,4,\"n\") is that \"n\" formula_1 2 or 4 (mod 6). The abbreviation SQS(\"n\") is often used for these systems. Up to isomorphism, SQS(8) and SQS(10) are unique, there are 4 SQS(14)s and 1,054,163 SQS(16)s.\nAn S(4,5,\"n\") is called a Steiner quintuple system. A necessary condition for the existence of such a system is that \"n\" formula_1 3 or 5 (mod 6) which comes from considerations that apply to all the classical Steiner systems. An additional necessary condition is that \"n\" formula_3 4 (mod 5), which comes from the fact that the number of blocks must be an integer. Sufficient conditions are not known. There is a unique Steiner quintuple system of order 11, but none of order 15 or order 17. Systems are known for orders 23, 35, 47, 71, 83, 107, 131, 167 and 243. The smallest order for which the existence is not known (as of 2011) is 21.\nSteiner triple systems.\nAn S(2,3,\"n\") is called a Steiner triple system, and its blocks are called triples. It is common to see the abbreviation STS(\"n\") for a Steiner triple system of order \"n\". The total number of pairs is \"n(n-1)/2\", of which three appear in a triple, and so the total number of triples is \"n\"(\"n\"\u22121)/6. This shows that \"n\" must be of the form \"6k+1\" or \"6k + 3\" for some \"k\". The fact that this condition on \"n\" is sufficient for the existence of an S(2,3,\"n\") was proved by Raj Chandra Bose and T. Skolem. The projective plane of order 2 (the Fano plane) is an STS(7) and the affine plane of order 3 is an STS(9). Up to isomorphism, the STS(7) and STS(9) are unique, there are two STS(13)s, 80 STS(15)s, and 11,084,874,829 STS(19)s.\nWe can define a multiplication on the set \"S\" using the Steiner triple system by setting \"aa\" = \"a\" for all \"a\" in \"S\", and \"ab\" = \"c\" if {\"a\",\"b\",\"c\"} is a triple. This makes \"S\" an idempotent, commutative quasigroup. It has the additional property that \"ab\" = \"c\" implies \"bc\" = \"a\" and \"ca\" = \"b\". Conversely, any (finite) quasigroup with these properties arises from a Steiner triple system. Commutative idempotent quasigroups satisfying this additional property are called \"Steiner quasigroups\".\nResolvable Steiner systems.\nSome of the S(2,3,n) systems can have their triples partitioned into (n-1)/2 sets each having (n/3) pairwise disjoint triples. This is called \"resolvable\" and such systems are called \"Kirkman triple systems\" after Thomas Kirkman, who studied such resolvable systems before Steiner. Dale Mesner, Earl Kramer, and others investigated collections of Steiner triple systems that are mutually disjoint (i.e., no two Steiner systems in such a collection share a common triplet). It is known (Bays 1917, Kramer &amp; Mesner 1974) that seven different S(2,3,9) systems can be generated to together cover all 84 triplets on a 9-set; it was also known by them that there are 15360 different ways to find such 7-sets of solutions, which reduce to two non-isomorphic solutions under relabeling, with multiplicities 6720 and 8640 respectively.\nThe corresponding question for finding thirteen different disjoint S(2,3,15) systems was asked by James Sylvester in 1860 as an extension of the Kirkman's schoolgirl problem, namely whether Kirkman's schoolgirls could march for an entire term of 13 weeks with no triplet of girls being repeated over the whole term. The question was solved by RHF Denniston in 1974, who constructed Week 1 as follows:\nfor girls labeled A to O, and constructed each subsequent week's solution from its immediate predecessor by changing A to B, B to C, ... L to M and M back to A, all while leaving N and O unchanged. The Week 13 solution, upon undergoing that relabeling, returns to the Week 1 solution. Denniston reported in his paper that the search he employed took 7 hours on an Elliott 4130 computer at the University of Leicester, and he immediately ended the search on finding the solution above, not looking to establish uniqueness. The number of non-isomorphic solutions to Sylvester's problem remains unknown as of 2021.\nProperties.\nIt is clear from the definition of S(\"t\", \"k\", \"n\") that formula_4. (Equalities, while technically possible, lead to trivial systems.)\nIf S(\"t\", \"k\", \"n\") exists, then taking all blocks containing a specific element and discarding that element gives a \"derived system\" S(\"t\"\u22121, \"k\"\u22121, \"n\"\u22121). Therefore, the existence of S(\"t\"\u22121, \"k\"\u22121, \"n\"\u22121) is a necessary condition for the existence of S(\"t\", \"k\", \"n\").\nThe number of \"t\"-element subsets in S is formula_5, while the number of \"t\"-element subsets in each block is formula_6. Since every \"t\"-element subset is contained in exactly one block, we have formula_7, or \nformula_8\nwhere \"b\" is the number of blocks. Similar reasoning about \"t\"-element subsets containing a particular element gives us formula_9, or \nformula_10 =formula_11\nwhere \"r\" is the number of blocks containing any given element. From these definitions follows the equation formula_12. It is a necessary condition for the existence of S(\"t\", \"k\", \"n\") that \"b\" and \"r\" are integers. As with any block design, Fisher's inequality formula_13 is true in Steiner systems.\nGiven the parameters of a Steiner system S(\"t, k, n\") and a subset of size formula_14, contained in at least one block, one can compute the number of blocks intersecting that subset in a fixed number of elements by constructing a Pascal triangle. In particular, the number of blocks intersecting a fixed block in any number of elements is independent of the chosen block.\nThe number of blocks that contain any \"i\"-element set of points is:\nformula_15\nIt can be shown that if there is a Steiner system S(2, \"k\", \"n\"), where \"k\" is a prime power greater than 1, then \"n\" formula_1 1 or \"k\" (mod \"k\"(\"k\"\u22121)). In particular, a Steiner triple system S(2, 3, \"n\") must have \"n\" = 6\"m\" + 1 or 6\"m\" + 3. And as we have already mentioned, this is the only restriction on Steiner triple systems, that is, for each natural number \"m\", systems S(2, 3, 6\"m\" + 1) and S(2, 3, 6\"m\" + 3) exist.\nHistory.\nSteiner triple systems were defined for the first time by Wesley S. B. Woolhouse in 1844 in the Prize question #1733 of Lady's and Gentlemen's Diary. The posed problem was solved by Thomas Kirkman\u00a0(1847). In 1850 Kirkman posed a variation of the problem known as Kirkman's schoolgirl problem, which asks for triple systems having an additional property (resolvability). Unaware of Kirkman's work, Jakob Steiner\u00a0(1853) reintroduced triple systems, and as this work was more widely known, the systems were named in his honor.\nIn 1910 Geoffrey Thomas Bennett gave a graphical representation for Steiner triple systems.\nMathieu groups.\nSeveral examples of Steiner systems are closely related to group theory. In particular, the finite simple groups called Mathieu groups arise as automorphism groups of Steiner systems:\nThe Steiner system S(5, 6, 12).\nThere is a unique S(5,6,12) Steiner system; its automorphism group is the Mathieu group M12, and in that context it is denoted by W12.\nProjective line construction.\nThis construction is due to Carmichael (1937).\nAdd a new element, call it \u221e, to the 11 elements of the finite field F11 (that is, the integers mod 11). This set, \"S\", of 12 elements can be formally identified with the points of the projective line over F11. Call the following specific subset of size 6,\nformula_17\na \"block\" (it contains \u221e together with the 5 nonzero squares in F11). From this block, we obtain the other blocks of the S(5,6,12) system by repeatedly applying the linear fractional transformations:\nformula_18\nwhere a,b,c,d are in F11 and \"ad \u2212 bc\" = 1.\nWith the usual conventions of defining \"f\" (\u2212\"d\"/\"c\") = \u221e and \"f\" (\u221e) = \"a\"/\"c\", these functions map the set \"S\" onto itself. In geometric language, they are projectivities of the projective line. They form a group under composition which is the projective special linear group PSL(2,11) of order 660. There are exactly five elements of this group that leave the starting block fixed setwise, namely those such that \"b=c=0\" and \"ad\"=1 so that \"f(z) = a\"2 \"z\". So there will be 660/5 = 132 images of that block. As a consequence of the multiply transitive property of this group acting on this set, any subset of five elements of \"S\" will appear in exactly one of these 132 images of size six.\nKitten construction.\nAn alternative construction of W12 is obtained by use of the 'kitten' of R.T. Curtis, which was intended as a \"hand calculator\" to write down blocks one at a time. The kitten method is based on completing patterns in a 3x3 grid of numbers, which represent an affine geometry on the vector space F3xF3, an S(2,3,9) system.\nConstruction from K6 graph factorization.\nThe relations between the graph factors of the complete graph K6 generate an S(5,6,12). A K6 graph has 6 vertices, 15 edges, 15 perfect matchings, and 6 different 1-factorizations (ways to partition the edges into disjoint perfect matchings). The set of vertices (labeled 123456) and the set of factorizations (labeled \"ABCDEF\") provide one block each. Every pair of factorizations has exactly one perfect matching in common. Suppose factorizations \"A\" and \"B\" have the common matching with edges 12, 34 and 56. Add three new blocks \"AB\"3456, 12\"AB\"56, and 1234\"AB\", replacing each edge in the common matching with the factorization labels in turn. Similarly add three more blocks 12\"CDEF\", 34\"CDEF\", and 56\"CDEF\", replacing the factorization labels by the corresponding edge labels of the common matching. Do this for all 15 pairs of factorizations to add 90 new blocks. Finally, take the full set of formula_19 combinations of 6 objects out of 12, and discard any combination that has 5 or more objects in common with any of the 92 blocks generated so far. Exactly 40 blocks remain, resulting in 2 + 90 + 40 = 132 blocks of the S(5,6,12). This method works because there is an outer automorphism on the symmetric group \"S\"6, which maps the vertices to factorizations and the edges to partitions. Permuting the vertices causes the factorizations to permute differently, in accordance with the outer automorphism.\nThe Steiner system S(5, 8, 24).\nThe Steiner system S(5, 8, 24), also known as the Witt design or Witt geometry, was first described by Carmichael\u00a0(1931) and rediscovered by Witt\u00a0(1938). This system is connected with many of the sporadic simple groups and with the exceptional 24-dimensional lattice known as the Leech lattice. The automorphism group of S(5, 8, 24) is the Mathieu group M24, and in that context the design is denoted W24 (\"W\" for \"Witt\")\nDirect lexicographic generation.\nAll 8-element subsets of a 24-element set are generated in lexicographic order, and any such subset which differs from some subset already found in fewer than four positions is discarded.\nThe list of octads for the elements 01, 02, 03, ..., 22, 23, 24 is then:\n 01 02 03 04 05 06 07 08\n 01 02 03 04 09 10 11 12\n 01 02 03 04 13 14 15 16\n . (next 753 octads omitted)\n 13 14 15 16 17 18 19 20\n 13 14 15 16 21 22 23 24\n 17 18 19 20 21 22 23 24\nEach single element occurs 253 times somewhere in some octad. Each pair occurs 77 times. Each triple occurs 21 times. Each quadruple (tetrad) occurs 5 times. Each quintuple (pentad) occurs once. Not every hexad, heptad or octad occurs.\nConstruction from the binary Golay code.\nThe 4096 codewords of the 24-bit binary Golay code are generated, and the 759 codewords with a Hamming weight of 8 correspond to the S(5,8,24) system.\nThe Golay code can be constructed by many methods, such as generating all 24-bit binary strings in lexicographic order and discarding those that differ from some earlier one in fewer than 8 positions. The result looks like this:\nThe codewords form a group under the XOR operation.\nProjective line construction.\nThis construction is due to Carmichael (1931).\nAdd a new element, call it \u221e, to the 23 elements of the finite field F23 (that is, the integers mod 23). This set, \"S\", of 24 elements can be formally identified with the points of the projective line over F23. Call the following specific subset of size 8,\nformula_20\na \"block\". (We can take any octad of the extended binary Golay code, seen as a quadratic residue code.) From this block, we obtain the other blocks of the S(5,8,24) system by repeatedly applying the linear fractional transformations:\nformula_18\nwhere a,b,c,d are in F23 and \"ad \u2212 bc\" = 1.\nWith the usual conventions of defining \"f\" (\u2212\"d\"/\"c\") = \u221e and \"f\" (\u221e) = \"a\"/\"c\", these functions map the set \"S\" onto itself. In geometric language, they are projectivities of the projective line. They form a group under composition which is the projective special linear group PSL(2,23) of order 6072. There are exactly 8 elements of this group that leave the initial block fixed setwise. So there will be 6072/8 = 759 images of that block. These form the octads of S(5,8,24).\nConstruction from the Miracle Octad Generator.\nThe Miracle Octad Generator (MOG) is a tool to generate octads, such as those containing specified subsets. It consists of a 4x6 array with certain weights assigned to the rows. In particular, an 8-subset should obey three rules in order to be an octad of S(5,8,24). First, each of the 6 columns should have the same parity, that is, they should all have an odd number of cells or they should all have an even number of cells. Second, the top row should have the same parity as each of the columns. Third, the rows are respectively multiplied by the weights 0, 1, 2, and 3 over the finite field of order 4, and column sums are calculated for the 6 columns, with multiplication and addition using the finite field arithmetic definitions. The resulting column sums should form a valid \"hexacodeword\" of the form (\"a\", \"b\", \"c\", \"a\" + \"b\" + \"c\", \"3a\" + \"2b\" + \"c\", \"2a\" + \"3b\" + \"c\") where \"a, b, c\" are also from the finite field of order 4. If the column sums' parities don't match the row sum parity, or each other, or if there do not exist \"a, b, c\" such that the column sums form a valid hexacodeword, then that subset of 8 is not an octad of S(5,8,24).\nThe MOG is based on creating a bijection (Conwell 1910, \"The three-space PG(3,2) and its group\") between the 35 ways to partition an 8-set into two different 4-sets, and the 35 lines of the Fano 3-space PG(3,2). It is also geometrically related (Cullinane, \"Symmetry Invariance in a Diamond Ring\", Notices of the AMS, pp A193-194, Feb 1979) to the 35 different ways to partition a 4x4 array into 4 different groups of 4 cells each, such that if the 4x4 array represents a four-dimensional finite affine space, then the groups form a set of parallel subspaces.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28017", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=28017", "title": "Sirius", "text": "Brightest star in the night sky, in the constellation Canis Major\nAs the brightest star in the night sky, Sirius appears in some of the earliest astronomical records. Its displacement from the ecliptic causes its heliacal rising to be remarkably regular compared to other stars, with a period of almost exactly 365.25\u00a0days holding it constant relative to the solar year. This rising occurs at Cairo on 19\u00a0July (Julian), placing it just before the onset of the annual flooding of the Nile during antiquity. Owing to the flood's own irregularity, the extreme precision of the star's return made it important to the ancient Egyptians, who worshipped it as the goddess Sopdet (, \"Triangle\"; }, \"S\u014d\u0302this\"), guarantor of the fertility of their land (see Sothic cycle). As Sirius is visible together with the constellation of Orion, the Egyptians worshiped Orion as the god Sah, the husband of Sopdet, with whom she had a son, the sky god Sopdu. The goddess Sopdet was later syncretized with the goddess Isis, Sah was linked with Osiris (which is by some suggested as a root for the name of Sirius), and Sopdu was linked with Horus. The joining of Sopdet with Isis would allow Plutarch to state that \"The soul of Isis is called Dog by the Greeks\", meaning Sirius worshiped as Isis-Sopdet by Egyptians was named the Dog by the Greeks and Romans. The 70\u00a0day period of the absence of Sirius from the sky was understood as the passing of Sopdet-Isis and Sah-Osiris through the Egyptian underworld.\nThe ancient Greeks observed that the appearance of Sirius as the morning star heralded the hot and dry summer and feared that the star caused plants to wilt, men to weaken, and women to become aroused. Owing to its brightness, Sirius would have been seen to twinkle more in the unsettled weather conditions of early summer. To Greek observers, this signified emanations that caused its malignant influence. Anyone suffering its effects was said to be \"star-struck\" (, \"astrob\u00f3l\u0113tos\"). It was described as \"burning\" or \"flaming\" in literature. The season following the star's reappearance came to be known as the \"dog days\". The inhabitants of the island of Ceos in the Aegean Sea would offer sacrifices to Sirius and Zeus to bring cooling breezes and would await the reappearance of the star in summer. If it rose clear, it would portend good fortune; if it was misty or faint then it foretold (or emanated) pestilence. Coins retrieved from the island from the 3rd\u00a0century BC feature dogs or stars with emanating rays, highlighting Sirius's importance.\nThe Romans celebrated the heliacal setting of Sirius around 25\u00a0April, sacrificing a dog, along with incense, wine, and a sheep, to the goddess Robigo so that the star's emanations would not cause wheat rust on wheat crops that year.\nBright stars were important to the ancient Polynesians for navigation of the Pacific Ocean. They also served as latitude markers; the declination of Sirius matches the latitude of the archipelago of Fiji at 17\u00b0S and thus passes directly over the islands each sidereal day. Sirius served as the body of a \"Great Bird\" constellation called \"Manu\", with Canopus as the southern wingtip and Procyon the northern wingtip, which divided the Polynesian night sky into two hemispheres. Just as the appearance of Sirius in the morning sky marked summer in Greece, it marked the onset of winter for the M\u0101ori, whose name \"Takurua\" described both the star and the season. Its culmination at the winter solstice was marked by celebration in Hawaii, where it was known as \"Ka'ulua\", \"Queen of Heaven\". Many other Polynesian names have been recorded, including \"Tau-ua\" in the Marquesas Islands, \"Rehua\" in New Zealand, and \"Ta'urua-fau-papa\" \"Festivity of original high chiefs\" and \"Ta'urua-e-hiti-i-te-tara-te-feiai\" \"Festivity who rises with prayers and religious ceremonies\" in Tahiti.\nKinematics.\nIn 1717, Edmond Halley discovered the proper motion of the hitherto presumed \"fixed stars\" after comparing contemporary astrometric measurements with those from the second century AD given in Ptolemy's \"Almagest\". The bright stars Aldebaran, Arcturus and Sirius were noted to have moved significantly; Sirius had progressed about 30 arcminutes (about the diameter of the Moon) to the southwest.\nIn 1868, Sirius became the first star to have its velocity measured, the beginning of the study of celestial radial velocities. Sir William Huggins examined the spectrum of the star and observed a red shift. He concluded that Sirius was receding from the Solar System at about 40\u00a0km/s. Compared to the modern value of \u22125.5\u00a0km/s, this was an overestimate and had the wrong sign; the minus sign (\u2212) means that it is approaching the Sun.\nDistance.\nIn his 1698 book, \"Cosmotheoros\", Christiaan Huygens estimated the distance to Sirius at 27,664\u00a0times the distance from the Earth to the Sun (about 0.437\u00a0light-year, translating to a parallax of roughly 7.5\u00a0arcseconds). There were several unsuccessful attempts to measure the parallax of Sirius: by Jacques Cassini (6\u00a0seconds); by some astronomers (including Nevil Maskelyne) using Lacaille's observations made at the Cape of Good Hope (4\u00a0seconds); by Piazzi (the same amount); using Lacaille's observations made at Paris, more numerous and certain than those made at the Cape (no sensible parallax); by Bessel (no sensible parallax).\nScottish astronomer Thomas Henderson used his observations made in 1832\u20131833 and South African astronomer Thomas Maclear's observations made in 1836\u20131837, to determine that the value of the parallax was 0.23\u00a0arcsecond, and error of the parallax was estimated not to exceed a quarter of a second, or as Henderson wrote in 1839, \"On the whole we may conclude that the parallax of Sirius is not greater than half a second in space; and that it is probably much less.\" Astronomers adopted a value of 0.25\u00a0arcsecond for much of the 19th\u00a0century. It is now known to have a parallax of nearly .\nThe Hipparcos parallax for Sirius indicates a distance of , statistically accurate to plus or minus 0.04\u00a0light years. Sirius\u00a0B is generally assumed to be at the same distance. Sirius\u00a0B has a Gaia Data Release 3 parallax with a much smaller statistical margin of error, giving a distance of , but it is flagged as having a very large value for astrometric excess noise, which indicates that the parallax value may be unreliable.\nDiscovery of Sirius B.\nIn a letter dated 10\u00a0August 1844, the German astronomer Friedrich Wilhelm Bessel deduced from changes in the proper motion of Sirius that it had an unseen companion. On 31 January 1862, American telescope-maker and astronomer Alvan Graham Clark first observed the faint companion, which is now called Sirius\u00a0B. This happened during testing of an aperture great refractor telescope for Dearborn Observatory, which was one of the largest refracting telescope lenses in existence at the time, and the largest telescope in the United States. Sirius\u00a0B's sighting was confirmed on 8\u00a0March with smaller telescopes.\nThe visible star is now sometimes known as Sirius\u00a0A. Since 1894, some apparent orbital irregularities in the Sirius system have been observed, suggesting a third very small companion star, but this has never been confirmed. The best fit to the data indicates a six-year orbit around Sirius\u00a0A and a mass of 0.06\u00a0M\u2609. This star would be five to ten magnitudes fainter than the white dwarf Sirius\u00a0B, which would make it difficult to observe. Observations published in 2008 were unable to detect either a third star or a planet. An apparent \"third star\" observed in the 1920s is now believed to be a background object.\nIn 1915, Walter Sydney Adams, using a reflector at Mount Wilson Observatory, observed the spectrum of Sirius\u00a0B and determined that it was a faint whitish star. This led astronomers to conclude that it was a white dwarf\u2014the second to be discovered. The diameter of Sirius\u00a0A was first measured by Robert Hanbury Brown and Richard Q. Twiss in 1959 at Jodrell Bank using their stellar intensity interferometer. In 2005, using the Hubble Space Telescope, astronomers determined that Sirius\u00a0B has nearly the diameter of the Earth, , with a mass 102% of the Sun's.\nColour controversy.\nAround the year 150\u00a0AD, Claudius Ptolemy of Alexandria, an ethnic Greek Egyptian astronomer of the Roman period, mapped the stars in Books\u00a0VII and VIII of his \"Almagest\", in which he used Sirius as the location for the globe's central meridian. He described Sirius as reddish, along with five other stars, Betelgeuse, Antares, Aldebaran, Arcturus, and Pollux, all of which are at present observed to be of orange or red hue. The discrepancy was first noted by amateur astronomer Thomas Barker, squire of Lyndon Hall in Rutland, who prepared a paper and spoke at a meeting of the Royal Society in London in 1760. The existence of other stars changing in brightness gave credibility to the idea that some may change in colour too; Sir John Herschel noted this in 1839, possibly influenced by witnessing Eta Carinae two years earlier. Thomas J.J. See resurrected discussion on red Sirius with the publication of several papers in 1892, and a final summary in 1926. He cited not only Ptolemy but also the poet Aratus, the orator Cicero, and general Germanicus all calling the star red, though acknowledging that none of the latter three authors were astronomers, the last two merely translating Aratus's poem \"Phaenomena\". Seneca had described Sirius as being of a deeper red than Mars. It is therefore possible that the description as red is a poetic metaphor for ill fortune. In 1985, German astronomers Wolfhard Schlosser and Werner Bergmann published an account of an 8th-century Lombardic manuscript, which contains \"De cursu stellarum ratio\" by St.\u00a0Gregory of Tours. The Latin text taught readers how to determine the times of nighttime prayers from positions of the stars, and a bright star described as \"rubeola\" (\"reddish\") was claimed to be Sirius. The authors proposed this as evidence that Sirius\u00a0B had been a red giant at the time of observation. Other scholars replied that it was likely St.\u00a0Gregory had been referring to Arcturus.\nIt is notable that not all ancient observers saw Sirius as red. The 1st-century poet Marcus Manilius described it as \"sea-blue\", as did the 4th-century Avienius. Furthermore, Sirius was consistently reported as a white star in ancient China: a detailed re-evaluation of Chinese texts from the 2nd\u00a0century BC up to the 7th\u00a0century AD concluded that all such reliable sources are consistent with Sirius being white.\nNevertheless, historical accounts referring to Sirius as red are sufficiently extensive to lead researchers to seek possible physical explanations. Proposed theories fall into two categories: intrinsic and extrinsic. Intrinsic theories postulate a real change in the Sirius system over the past two millennia, of which the most widely discussed is the proposal that the white dwarf Sirius B was a red giant as recently as 2000 years ago. Extrinsic theories are concerned with the possibility of transient reddening in an intervening medium through which the star is observed, such as might be caused by dust in the interstellar medium, or by particles in the terrestrial atmosphere.\nThe possibility that stellar evolution of either Sirius\u00a0A or Sirius\u00a0B could be responsible for the discrepancy has been rejected on the grounds that the timescale of thousands of years is orders of magnitude too short and that there is no sign of the nebulosity in the system that would be expected had such a change taken place. Similarly, the presence of a third star sufficiently luminous to affect the visible colour of the system in recent millennia is inconsistent with observational evidence. Intrinsic theories may therefore be disregarded. Extrinsic theories based on reddening by interstellar dust are similarly implausible. A transient dust cloud passing between the Sirius system and an observer on Earth would indeed redden the appearance of the star to some degree, but reddening sufficient to cause it to appear similar in colour to intrinsically red bright stars such as Betelgeuse and Arcturus would also dim the star by several magnitudes, inconsistent with historical accounts: indeed, the dimming would be sufficient to render the colour of the star imperceptible to the human eye without the aid of a telescope.\nExtrinsic theories based on optical effects in the Earth's atmosphere are better supported by available evidence. Scintillations caused by atmospheric turbulence result in rapid, transient changes in the apparent colour of the star, especially when observed near the horizon, although with no particular preference for red. However, systematic reddening of the star's light results from absorption and scattering by particles in the atmosphere, exactly analogous to the redness of the Sun at sunrise and sunset. Because the particles that cause reddening in the Earth's atmosphere are different (typically much smaller) than those that cause reddening in the interstellar medium, there is far less dimming of the starlight, and in the case of Sirius the change in colour can be seen without the aid of a telescope. There may be cultural reasons to explain why some ancient observers might have reported the colour of Sirius preferentially when it was situated low in the sky (and therefore apparently red). In several Mediterranean cultures, the local visibility of Sirius at heliacal rising and setting (whether it appeared bright and clear or dimmed) was thought to have astrological significance and was thus subject to systematic observation and intense interest. Thus Sirius, more than any other star, was observed and recorded while close to the horizon. Other contemporary cultures, such as Chinese, lacking this tradition, recorded Sirius only as white.\nObservation.\nWith an apparent magnitude of \u22121.46, Sirius is the brightest star in the night sky, almost twice as bright as the second-brightest star, Canopus. From Earth, Sirius always appears dimmer than Jupiter and Venus, and at certain times also dimmer than Mercury and Mars. Sirius is visible from almost everywhere on Earth, except latitudes north of 73\u00b0\u00a0N, and it does not rise very high when viewed from some northern cities (reaching only 13\u00b0\u00a0above the horizon from Saint Petersburg). Because of its declination of roughly \u221217\u00b0, Sirius is a circumpolar star from latitudes south of 73\u00b0\u00a0S. From the Southern Hemisphere in early July, Sirius can be seen in both the evening where it sets after the Sun and in the morning where it rises before the Sun. Along with Procyon and Betelgeuse, Sirius forms one of the three vertices of the Winter Triangle to observers in the Northern Hemisphere. Sirius often flashes rainbow colors in the sky due to its twinkling.\nSirius can be observed in daylight with the naked eye under the right conditions. Ideally, the sky should be very clear, with the observer at a high altitude, the star passing overhead, and the Sun low on the horizon. These conditions are most easily met around sunset in March and April, and around sunrise in September and October. Observing conditions are more favorable in the Southern Hemisphere, owing to the southerly declination of Sirius.\nThe orbital motion of the Sirius binary system brings the two stars to a minimum angular separation of 3\u00a0arcseconds and a maximum of 11\u00a0arcseconds. At the closest approach, it is an observational challenge to distinguish the white dwarf from its more luminous companion, requiring a telescope with at least aperture and excellent seeing conditions. After a periastron occurred in 1994,\nthe pair moved apart, making them easier to separate with a telescope. Apoastron occurred in 2019,\nbut from the Earth's vantage point, the greatest observational separation occurred in 2023, with an angular separation of 11.333\u2033.\nLocation.\nAt a distance of 2.6\u00a0parsecs (8.6\u00a0ly), the Sirius system contains two of the eight nearest stars to the Sun, and it is the fifth closest stellar system to the Sun. This proximity is the main reason for its brightness, as with other near stars such as Alpha Centauri, Procyon and Vega and in contrast to distant, highly luminous supergiants such as Canopus, Rigel or Betelgeuse (although Canopus may be a bright giant). It is still around 25 times more luminous than the Sun. The closest large neighbouring star to Sirius is Procyon, 1.61 parsecs (5.24\u00a0ly) away. The \"Voyager 2\" spacecraft, launched in 1977 to study the four giant planets in the Solar System, is expected to pass within of Sirius in approximately 296,000 years.\nStellar system.\nSirius is a binary star system consisting of two white stars orbiting each other with a separation of about 20\u00a0AU\n(roughly the distance between the Sun and Uranus) and a period of 50.1\u00a0years. The brighter component, termed Sirius\u00a0A, is a main-sequence star of spectral type early\u00a0A, with an estimated surface temperature of 9,940\u00a0K. Its companion, Sirius\u00a0B, is a star that has already evolved off the main sequence and become a white dwarf. Currently 10,000\u00a0times less luminous in the visual spectrum, Sirius\u00a0B was once the more massive of the two. The age of the system has been estimated at 230\u00a0million years. Early in its life, it is thought to have been two bluish-white stars orbiting each other in an elliptical orbit every 9.1\u00a0years. The system emits a higher than expected level of infrared radiation, as measured by IRAS space-based observatory. This might be an indication of dust in the system, which is considered somewhat unusual for a binary star. The Chandra X-ray Observatory image shows Sirius\u00a0B outshining its partner as an X-ray source.\nIn 2015, Vigan and colleagues used the VLT Survey Telescope to search for evidence of substellar companions, and were able to rule out the presence of giant planets 11\u00a0times more massive than Jupiter at 0.5\u00a0AU distance from Sirius\u00a0A, 6\u20137\u00a0times the mass of Jupiter at 1\u20132\u00a0AU distance, and down to around 4\u00a0times the mass of Jupiter at 10\u00a0AU distance. Similarly, Lucas and colleagues did not detect any companions around Sirius\u00a0B.\nSirius A.\nSirius\u00a0A, also known as the Dog Star, has a mass of 2.063\u00a0M\u2609. The radius of this star has been measured by an astronomical interferometer, giving an estimated angular diameter of 5.936\u00b10.016\u00a0mas. The projected rotational velocity is a relatively low 16\u00a0km/s, which does not produce any significant flattening of its disk. This is at marked variance with the similar-sized Vega, which rotates at a much faster 274\u00a0km/s and bulges prominently around its equator. A weak magnetic field has been detected on the surface of Sirius\u00a0A.\nStellar models suggest that the star formed during the collapsing of a molecular cloud and that, after 10\u00a0million years, its internal energy generation was derived entirely from nuclear reactions. The core became convective and used the CNO cycle for energy generation. It is calculated that Sirius\u00a0A will have completely exhausted the store of hydrogen at its core within a billion (109)\u00a0years of its formation, and will then evolve away from the main sequence. It will pass through a red giant stage and eventually become a white dwarf.\nSirius\u00a0A is classed as a type Am star, because the spectrum shows deep metallic absorption lines, indicating an enhancement of its surface layers in elements heavier than helium, such as iron. The spectral type has been reported as A0mA1 Va, which indicates that it would be classified as A1 from hydrogen and helium lines, but A0 from the metallic lines that cause it to be grouped with the Am\u00a0stars. When compared to the Sun, the proportion of iron in the atmosphere of Sirius\u00a0A relative to hydrogen is given by formula_1 meaning iron is 316% as abundant as in the Sun's atmosphere. The high surface content of metallic elements is unlikely to be true of the entire star; rather the iron-peak and heavy metals are radiatively levitated towards the surface.\nSirius B.\nSirius\u00a0B (sometimes called \"the Pup\") is one of the most massive white dwarfs known. With a mass of 1.02\u00a0M\u2609, it is almost double the 0.5\u20130.6\u00a0M\u2609 average. This mass is packed into a volume roughly equal to the Earth's. The current surface temperature is 25,200\u00a0K. Because there is no internal heat source, Sirius\u00a0B will steadily cool as the remaining heat is radiated into space over the next two billion years or so.\nA white dwarf forms after a star has evolved from the main sequence and then passed through a red giant stage. This occurred when Sirius B was less than half its current age, around 120\u00a0million years ago. The original star had an estimated 5\u00a0M\u2609 and was a B-type star (most likely B5V for 5\u00a0M\u2609) when it was still on the main sequence, potentially burning around 600\u20131200 times more luminous than the Sun. While it passed through the red giant stage, Sirius\u00a0B may have enriched the metallicity of its companion, explaining the very high metallicity of Sirius\u00a0A.\nThis star is primarily composed of a carbon\u2013oxygen mixture that was generated by helium fusion in the progenitor star. This is overlaid by an envelope of lighter elements, with the materials segregated by mass because of the high surface gravity. The outer atmosphere of Sirius\u00a0B is now almost pure hydrogen\u2014the element with the lowest mass\u2014and no other elements are seen in its spectrum.\nApparent third star.\nSince 1894, irregularities have been tentatively observed in the orbits of Sirius\u00a0A and B with an apparent periodicity of 6\u20136.4\u00a0years. A 1995 study concluded that such a companion likely exists, with a mass of roughly 0.05\u00a0solar mass\u2014a small red dwarf or large brown dwarf, with an apparent magnitude of more than 15, and less than 3 arcseconds from Sirius A.\nIn 2017, more accurate astrometric observations by the Hubble Space Telescope ruled out the existence of a stellar mass sized Sirius\u00a0C, while still allowing a substellar mass candidate such as a lower mass brown dwarf. The 1995 study predicted an astrometric movement of roughly 90\u00a0mas (0.09\u00a0arcsecond), but Hubble was unable to detect any location anomaly to an accuracy of 5\u00a0mas (0.005\u00a0arcsec). This ruled out any objects orbiting Sirius\u00a0A with more than 0.033\u00a0solar mass (35\u00a0Jupiter masses) in 0.5\u00a0years, and 0.014 (15 Jupiter masses) in 2\u00a0years. The study was also able to rule out any companions to Sirius\u00a0B with more than 0.024\u00a0solar mass (25\u00a0Jupiter masses) orbiting in 0.5\u00a0year, and 0.0095 (10\u00a0Jupiter masses) orbiting in 1.8\u00a0years. Effectively, there are almost certainly no additional bodies in the Sirius system larger than a small brown dwarf or large exoplanet.\nStar cluster membership.\nIn 1909, Ejnar Hertzsprung was the first to suggest that Sirius was a member of the Ursa Major Moving Group, based on his observations of the system's movements across the sky. The Ursa Major Group is a set of 220\u00a0stars that share a common motion through space. It was once a member of an open cluster, but has since become gravitationally unbound from the cluster. Analyses in 2003 and 2005 found Sirius's membership in the group to be questionable: the Ursa Major Group has an estimated age of 500 \u00b1 100\u00a0million years, whereas Sirius, with metallicity similar to the Sun's, has an age that is only half this, making it too young to belong to the group. Sirius may instead be a member of the proposed Sirius Supercluster, along with other scattered stars such as Beta Aurigae, Alpha Coronae Borealis, Beta Crateris, Beta Eridani and Beta Serpentis. This would be one of three large clusters located within of the Sun. The other two are the Hyades and the Pleiades, and each of these clusters consists of hundreds of stars.\nDistant star cluster.\nIn 2017, a massive star cluster was discovered only 10\u00a0arcminutes from Sirius, making the two appear to be visually close to one other when viewed from the point of view of the Earth. It was discovered during a statistical analysis of \"Gaia\" data. The cluster is over a thousand times further away from us than the star system, but given its size it still appears at magnitude 8.3.\nCultural significance.\nDog Star.\nMany cultures have historically attached special significance to Sirius, particularly in relation to dogs. It is often colloquially called the \"Dog Star\" as the brightest star of Canis Major, the \"Great Dog\" constellation. Canis Major was classically depicted as Orion's dog. The Ancient Greeks thought that Sirius's emanations could affect dogs adversely, making them behave abnormally during the \"dog days\", the hottest days of the summer. The Romans knew these days as , and the star Sirius was called Canicula, \"little dog\". The excessive panting of dogs in hot weather was thought to place them at risk of desiccation and disease. In extreme cases, a foaming dog might have rabies, which could infect and kill humans they had bitten. Homer, in the \"Iliad\", describes the approach of Achilles toward Troy in these words:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;&lt;poem&gt;\nSirius rises late in the dark, liquid sky\nOn summer nights, star of stars,\nOrion's Dog they call it, brightest\nOf all, but an evil portent, bringing heat\nAnd fevers to suffering humanity.\n&lt;/poem&gt;\nOther canine associations.\nIn Chinese astronomy Sirius is known as the star of the \"celestial wolf\" (Chinese and Japanese: \u5929\u72fc Chinese romanization: Ti\u0101nl\u00e1ng; Japanese romanization: Tenr\u014d; Korean and romanization: \ucc9c\ub791 /Cheonrang) in the Mansion of J\u01d0ng (\u4e95\u5bbf). Many nations among the indigenous peoples of North America also associated Sirius with canines; the Seri and Tohono O\u02bcodham of the southwest note the star as a dog that follows mountain sheep, while the Blackfoot called it \"Dog-face\". The Cherokee paired Sirius with Antares as a dog-star guardian of either end of the \"Path of Souls\". The Pawnee of Nebraska had several associations; the Wolf (Skidi) tribe knew it as the \"Wolf Star\", while other branches knew it as the \"Coyote Star\". Further north, the Alaskan Inuit of the Bering Strait called it \"Moon Dog\".\nRange of associations.\nIn a little-attested Greek myth, the star-god that personified Sirius fell in love with a fertility goddess named Opora, but he was unable to have her. Thus he began to burn hot, making humans suffer, who prayed to the gods. The god of the north wind, Boreas, solved the problem by ordering his sons to deliver Opora to Sirius, while he cooled down the earth with blasts of his own cold wind.\nIranian mythology and Zoroastrianism.\nIn Iranian mythology, especially in Persian mythology and in Zoroastrianism, the ancient religion of Persia, Sirius appears as \"Tishtrya\" and is revered as the rain-maker divinity (Tishtar of New Persian poetry). Beside passages in one of the hymns of the Avesta, the Avestan language \"Tishtrya\" followed by the version \"Tir\" in Middle and New Persian is also depicted in the Persian epic \"Shahnameh\" of Ferdowsi. Because of the concept of the yazatas, powers which are \"worthy of worship\", Tishtrya is a divinity of rain and fertility and an antagonist of apaosha, the demon of drought. In this struggle, Tishtrya is depicted as a white horse.\nSeveral cultures also associated the star with a bow and arrows. The ancient Chinese visualized a large bow and arrow across the southern sky, formed by the constellations of Puppis and Canis Major. In this, the arrow tip is pointed at the wolf Sirius. A similar association is depicted at the Temple of Hathor in Dendera, where the goddess Satet has drawn her arrow at Hathor (Sirius). Known as \"Tir\", the star was portrayed as the arrow itself in later Persian culture.\nIn Islam.\nSirius is mentioned in \"Surah\" An-Najm (\"The Star\") of the Qur'an, where it is referred to as (), meaning \"the Bright Star\" or \"Leader\"). The verse is:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a [Quran\u00a0https://]\nIn Islamic belief, celestial bodies mentioned in the Qur\u2019an often symbolize divine power and serve as signs (\"\u0101y\u0101t\") of God's creation. Ibn Kathir, in his commentary on the verse, noted that it refers to the bright star known as \"Mirzam al-Jawza' (Sirius)\", which some pre-Islamic Arab tribes used to worship.\nThe alternative Western name \"Aschere\", once used by Johann Bayer, is derived from this Arabic reference.\nIn Theosophy.\nIn theosophy, it is believed the \"Seven Stars of the Pleiades\" transmit the spiritual energy of the Seven Rays from the \"Galactic Logos\" to the \"Seven Stars of the Great Bear\", then to Sirius. From there is it sent via the Sun to the god of Earth (Sanat Kumara), and finally through the seven Masters of the Seven Rays to the human race.\nNew Year culmination.\nThe midnight culmination of Sirius in the northern hemisphere coincides with the beginning of the New Year of the Gregorian calendar during the decades around the year 2000. Over the years, its midnight culmination moves slowly, owing to the combination of the star's proper motion and the precession of the equinoxes. At the time of the introduction of the Gregorian calendar in the year 1582, its culmination occurred 17 minutes before midnight into the new year under the assumption of a constant motion. According to Richard Hinckley Allen its midnight culmination was celebrated at the Temple of Demeter at Eleusis.\nDogon.\nThe Dogon people are an ethnic group in Mali, West Africa, reported by some researchers to have traditional astronomical knowledge about Sirius that would normally be considered impossible without the use of telescopes. According to Marcel Griaule, they knew about the fifty-year orbital period of Sirius and its companion prior to western astronomers.\nDoubts have been raised about the validity of Griaule and Dieterlein's work. In 1991, anthropologist Walter van Beek concluded about the Dogon, \"Though they do speak about \"sigu tolo\" [which is what Griaule claimed the Dogon called Sirius] they disagree completely with each other as to which star is meant; for some it is an invisible star that should rise to announce the \"sigu\" [festival], for another it is Venus that, through a different position, appears as \"sigu tolo\". All agree, however, that they learned about the star from Griaule.\" According to Noah Brosch cultural transfer of relatively modern astronomical information could have taken place in 1893, when a French expedition arrived in Central West Africa to observe the total eclipse on 16 April.\nSerer religion.\nIn the religion of the Serer people of Senegal, the Gambia and Mauritania, Sirius is called \"Yoonir\" from the Serer language (and some of the Cangin language speakers, who are all ethnically Serers). The star Sirius is one of the most important and sacred stars in Serer religious cosmology and symbolism. The Serer high priests and priestesses (Saltigues, the hereditary \"rain priests\") chart \"Yoonir\" to forecast rainfall and enable Serer farmers to start planting seeds. In Serer religious cosmology, it is the symbol of the universe.\nModern significance.\nSirius features on the coat of arms of Macquarie University, and is the name of its alumnae journal. Seven ships of the Royal Navy have been called since the 18th century, with the first being the flagship of the First Fleet to Australia in 1788. The Royal Australian Navy subsequently named a vessel in honor of the flagship. American vessels include the as well as a monoplane model\u2014the Lockheed Sirius, the first of which was flown by Charles Lindbergh. The name was also adopted by Mitsubishi Motors as the Mitsubishi Sirius engine in 1980. The name of the North American satellite radio company CD Radio was changed to Sirius Satellite Radio in November 1999, being named after \"the brightest star in the night sky\". Sirius is one of the 27 stars on the flag of Brazil, where it represents the state of Mato Grosso.\nComposer Karlheinz Stockhausen, who wrote a piece called \"Sirius\", is claimed to have said on several occasions that he came from a planet in the Sirius system. To Stockhausen, Sirius stood for \"the place where music is the highest of vibrations\" and where music had been developed in the most perfect way.\nSirius has been the subject of poetry. Dante and John Milton reference the star, and it is the \"powerful western fallen star\" of Walt Whitman's \"When Lilacs Last in the Dooryard Bloom'd\", while Tennyson's poem \"The Princess\" describes the star's scintillation:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;&lt;poem&gt;\n...the fiery Sirius alters hue\nAnd bickers into red and emerald.\n&lt;/poem&gt;\nThroughout the 1990s, several members of the occult group the Order of the Solar Temple committed mass murder-suicide with the goal of leaving their bodies and spiritually \"transiting\" to Sirius. In total, 74 people died in all of the suicides and murders.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28018", "revid": "50436820", "url": "https://en.wikipedia.org/wiki?curid=28018", "title": "Simon Magus", "text": "Religious figure who confronted Peter\nSimon Magus (Greek \u03a3\u03af\u03bc\u03c9\u03bd \u1f41 \u03bc\u03ac\u03b3\u03bf\u03c2, Latin: Simon Magus), also known as Simon the Magician, was a religious figure whose confrontation with Peter is recorded in the Acts of the Apostles. The act of simony, or paying for position, is named after Simon, who tried to buy his way into the power of the Apostles.\nAccording to Acts, Simon was a Samaritan magus or religious figure of the 1st century AD and a convert to Christianity, baptised by Philip the Evangelist. Simon later clashed with Peter. Accounts of Simon by writers of the second century exist, but are not considered verifiable. Surviving traditions about Simon appear in traditional texts, such as those of Irenaeus, Justin Martyr, Hippolytus, and Epiphanius, where he is often described as the founder of Gnosticism, which has been accepted by some modern scholars, while others reject claims that he was a Gnostic, maintaining that he was merely considered to be one by the Church Fathers.\nJustin, who was himself a 2nd-century native of Samaria, wrote that nearly all the Samaritans in his time were adherents of a certain Simon of Gitta, a village not far from Flavia Neapolis. Irenaeus believed him to have been the founder of the sect of the Simonians. Hippolytus quotes from a work he attributes to Simon or his followers the Simonians, \"Apophasis Megale\", or \"Great Declaration\". According to the early church heresiologists, Simon is also supposed to have written several lost treatises, two of which bear the titles \"The Four Quarters of the World\" and \"The Sermons of the Refuter\".\nIn apocryphal works including the \"Acts of Peter\", Pseudo-Clementines, and the \"Epistle of the Apostles\", Simon also appears as a formidable sorcerer with the ability to levitate and fly at will. He is sometimes referred to as \"the Bad Samaritan\" due to his malevolent character. The \"Apostolic Constitutions\" also accuses him of \"lawlessness\" (antinomianism).\nHistory.\nActs of the Apostles.\nThe canonical Acts of the Apostles features a short narrative about Simon Magus; this is his only appearance in the New Testament.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;But there was a certain man, called Simon, which beforetime in the same city used sorcery, and bewitched the people of Samaria, giving out that himself was some great one: to whom they all gave heed, from the least to the greatest, saying, \"This man is the great power [Gr. \"Dynamis Megale\"] of God.\" And to him they had regard, because that of long time he had bewitched them with sorceries. But when they believed Philip preaching the things concerning the kingdom of God, and the name of Jesus Christ, they were baptized, both men and women. Then Simon himself believed also: and when he was baptized, he continued with Philip, and wondered, beholding the miracles and signs which were done. Now when the apostles which were at Jerusalem heard that Samaria had received the word of God, they sent unto them Peter and John: who, when they were come down, prayed for them, that they might receive the Holy Ghost: (for as yet he was fallen upon none of them: only they were baptized in the name of the Lord Jesus.) Then laid they their hands on them, and they received the Holy Ghost. And when Simon saw that through laying on of the apostles' hands the Holy Ghost was given, he offered them money, saying, \"Give me also this power, that on whomsoever I lay hands, he may receive the Holy Ghost.\" But Peter said unto him, \"Thy money perish with thee, because thou hast thought that the gift of God may be purchased with money. Thou hast neither part nor lot in this matter: for thy heart is not right in the sight of God. Repent therefore of this thy wickedness, and pray God, if perhaps the thought [Gr. \"Epinoia\"] of thine heart may be forgiven thee, for I perceive that thou art in the gall of bitterness, and in the bond of iniquity.\" Then answered Simon, and said, \"Pray ye to the Lord for me, that none of these things which ye have spoken come upon me.\"\u2014\u200a\nJosephus.\nJosephus mentions a magician named Atomus (Simon in Latin manuscripts) as being involved with the procurator Felix, King Agrippa II and his sister Drusilla, where Felix has Simon convince Drusilla to marry him instead of the man she was engaged to. Some scholars have considered the two to be identical, although this is not generally accepted, as the Simon of Josephus is a Jew rather than a Samaritan.\nJustin Martyr and Irenaeus.\nJustin Martyr (in his \"Apologies\", and in a lost work against heresies, which Irenaeus used as his main source) and Irenaeus (\"Adversus Haereses\") record that after being cast out by the Apostles, Simon Magus came to Rome where, having joined to himself a profligate woman of the name of Helen, he gave out that it was he who appeared among the Jews as the Son, in Samaria as the Father and among other nations as the Holy Spirit. He performed such signs by magic acts during the reign of Claudius that he was regarded as a god and honored with a statue on the island in the Tiber which the two bridges cross, with the inscription \"Simoni Deo Sancto\", \"To Simon the Holy God\" (). However, in the 16th century, a statue was unearthed on the island in question, inscribed to Semo Sancus, a Sabine deity, leading some scholars to conclude that Justin Martyr confused \"Semoni Sancus\" with Simon.\nMyth of Simon and Helen.\nJustin and Irenaeus are the first to recount the myth of Simon and Helen, which became the center of Simonian doctrine. Epiphanius of Salamis also makes Simon speak in the first person in several places in his \"Panarion\", and the implication is that he is quoting from a version of it, though perhaps not verbatim.\nAs described by Epiphanius, in the beginning God had his first thought, his \"Ennoia\", which was female, and that thought was to create the angels. The First Thought then descended into the lower regions and created the angels. But the angels rebelled against her out of jealousy and created the world as her prison, imprisoning her in a female body. Thereafter, she was reincarnated many times, each time being shamed. Her many reincarnations included Helen of Troy, among others, and she finally was reincarnated as Helen, a slave and prostitute in the Phoenician city of Tyre. God then descended in the form of Simon Magus, to rescue his \"Ennoia\", and to confer salvation upon men through knowledge of himself.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"And on her account\", he says, \"did I come down; for this is that which is written in the Gospel 'the lost sheep'.\"\u2014\u200a\nFor as the angels were mismanaging the world, owing to their individual lust for rule, he had come to set things straight, and had descended under a changed form, likening himself to the Principalities and Powers through whom he passed, so that among men he appeared as a man, though he was not a man, and was thought to have suffered in Judaea, though he had not suffered.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"But in each heaven I changed my form\", says he, \"in accordance with the form of those who were in each heaven, that I might escape the notice of my angelic powers and come down to the Thought, who is none other than her who is also called Prunikos and Holy Ghost, through whom I created the angels, while the angels created the world and men.\"\u2014\u200a\nBut the prophets had delivered their prophecies under the inspiration of the world-creating angels: wherefore those who had their hope in him and in Helen minded them no more, and, as being free, did what they pleased; for men were saved according to his grace, but not according to just works. For works were not just by nature, but only by convention, in accordance with the enactments of the world-creating angels, who by precepts of this kind sought to bring men into slavery. Wherefore he promised that the world should be dissolved, and that those who were his should be freed from the dominion of the world-creators.\nIn this account of Simon there is a large portion common to almost all forms of Gnostic myths, together with something special to this form. They have in common the place in the work of creation assigned to the female principle, the conception of the Deity; the ignorance of the rulers of this lower world with regard to the Supreme Power; the descent of the female (Sophia) into the lower regions, and her inability to return. Special to the Simonian tale is the identification of Simon himself with the Supreme, and of his consort Helena with the female principle.\nHippolytus.\nIn \"Philosophumena\", Hippolytus retells the narrative on Simon written by Irenaeus (who in his turn based it on the lost \"Syntagma\" of Justin). Upon the story of \"the lost sheep\", Hippolytus comments as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;But the liar was enamoured of this wench, whose name was Helen, and had bought her and had her to wife, and it was out of respect for his disciples that he invented this fairy-tale.\nAlso, Hippolytus demonstrates acquaintance with the folk tradition on Simon which depicts him rather as a magician than Gnostic, and in constant conflict with Peter (also present in the apocrypha and Pseudo-Clementine literature). Reduced to despair by the curse laid upon him by Peter in the Acts, Simon soon abjured the faith and embarked on the career of a sorcerer:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Until he came to Rome also and fell foul of the Apostles. Peter withstood him on many occasions. At last he came\u00a0... and began to teach sitting under a plane tree. When he was on the point of being shown up, he said, in order to gain time, that if he were buried alive he would rise again on the third day. So he bade that a tomb should be dug by his disciples and that he should be buried in it. Now they did what they were ordered, but he remained there until now: for he was not the Christ.\nSimonians.\nHippolytus gives a much more doctrinally detailed account of Simonianism, including a system of divine emanations and interpretations of the Old Testament, with extensive quotations from the \"Apophasis Megale\". Some believe that Hippolytus' account is of a later, more developed form of Simonianism, and that the original doctrines of the group were simpler, close to the account given by Justin Martyr and Irenaeus (this account however is also included in Hippolytus' work).\nHippolytus says the free love doctrine was held by them in its purest form, and speaks in language similar to that of Irenaeus about the variety of magic arts practiced by the Simonians, and also of their having images of Simon and Helen under the forms of Zeus and Athena. But he also adds, \"if any one, on seeing the images either of Simon or Helen, shall call them by those names, he is cast out, as showing ignorance of the mysteries.\"\nEpiphanius.\nEpiphanius writes that there were some Simonians still in existence in his day (c. AD 367), but he speaks of them as almost extinct. Gitta, he says, had sunk from a town into a village. Epiphanius further charges Simon with having tried to wrest the words of St. Paul about the armour of God into agreement with his own identification of the with Athena. He tells us also that he gave barbaric names to the \"principalities and powers\", and that he was the beginning of the Gnostics. The Law, according to him, was not of God, but of \"the sinister power\". The same was the case with the prophets, and it was death to believe in the Old Testament.\nCyril of Jerusalem.\nCyril of Jerusalem (346 AD) in the sixth of his Catechetical Lectures prefaces his history of the Manichaeans by a brief account of earlier heresies: Simon Magus, he says, had given out that he was going to be translated to heaven, and was actually careening through the air in a chariot drawn by demons when Peter and Paul knelt down and prayed, and their prayers brought him to earth a mangled corpse.\nApocrypha.\n\"Acts of Peter\".\nThe apocryphal \"Acts of Peter\" gives a more elaborate tale of Simon Magus' death. Simon is performing magic in the Forum, and, in order to prove himself to be a god, he levitates into the air above the Forum. The apostle Peter prays to God to stop his flying, and he stops mid-air and falls into a place called \"the \"Sacra Via\"\" (meaning \"Holy Way\" in Latin), breaking his legs \"in three parts\". The previously non-hostile crowd then stones him. Now gravely injured, he has some people carry him on a bed at night from Rome to Ariccia, and is brought from there to Terracina to a person named Castor, who has been banished from Rome, on account of accusations of sorcery levelled against him. The Acts then continue to say that he died \"while being sorely cut by two physicians\".\n\"Acts of Peter and Paul\".\nAnother apocryphal document, the \"Acts of Peter and Paul\" gives a slightly different version of the above incident, which was shown in the context of a debate in front of the Emperor Nero. In this version, Paul the Apostle is present along with Peter, Simon levitates from a high wooden tower made upon his request, and dies \"divided into four parts\" due to the fall. Peter and Paul are then imprisoned by Nero, who further orders that Simon's body be kept carefully for three days, in case, Christ-like, the magician should rise again.\nPseudo-Clementine literature.\nThe Pseudo-Clementine \"Recognitions\" and \"Homilies\" give an account of Simon Magus and some of his teachings in regards to the Simonians. They are of uncertain date and authorship, and seem to have been worked over by several hands in the interest of diverse forms of belief.\nSimon was a Samaritan, and a native of Gitta. The name of his father was Antonius, that of his mother Rachel. He studied Greek literature in Alexandria, and, having in addition to this great power in magic, became so ambitious that he wished to be considered a highest power, higher even than the God who created the world. And sometimes he \"darkly hinted\" that he himself was Christ, calling himself the Standing One. Which name he used to indicate that he would stand for ever, and had no cause in him for bodily decay. He did not believe that the God who created the world was the highest, nor that the dead would rise. He denied Jerusalem, and introduced Mount Gerizim in its stead. In place of the Christ of the Christians he proclaimed himself; and the Law he allegorized in accordance with his own preconceptions. He did indeed preach righteousness and judgment to come.\nThere was one John the Baptist, who was the forerunner of Jesus in accordance with the law of parity; and as Jesus had twelve Apostles, bearing the number of the twelve solar months, so had he thirty leading men, making up the monthly tale of the moon. One of these thirty leading men was a woman called Helen, and the first and most esteemed by John was Simon. But on the death of John, he was away in Egypt for the practice of magic, and one Dositheus, by spreading a false report of Simon's death, succeeded in installing himself as head of the sect. Simon on coming back thought it better to dissemble, and, pretending friendship for Dositheus, accepted the second place. Soon, however, he began to hint to the thirty that Dositheus was not as well acquainted as he might be with the doctrines of the school.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe encounter between Dositheus and Simon Magus was the beginnings of the sect of Simonians. The narrative goes on to say that Simon, having fallen in love with Helen, took her about with him, saying that she had come down into the world from the highest heavens, and was his mistress, inasmuch as she was Sophia, the Mother of All. It was for her sake, he said, that the Greeks and Barbarians fought the Trojan War, deluding themselves with an image of truth, for the real being was then present with the First God. By such allegories Simon deceived many, while at the same time he astounded them by his magic. A description is given of how he made a familiar spirit for himself by conjuring the soul out of a boy and keeping his image in his bedroom, and many instances of his feats of magic are given.\nAnti-Paulinism.\nThe Pseudo-Clementine writings were used in the 4th century by members of the Ebionite sect, one characteristic of which was hostility to Paul, whom they refused to recognize as an apostle. Ferdinand Christian Baur (1792\u20131860), founder of the T\u00fcbingen School, drew attention to the anti-Pauline characteristic in the Pseudo-Clementines, and pointed out that in the disputations between Simon and Peter, some of the claims Simon is represented as making (e.g. that of having seen the Lord, though not in his lifetime, yet subsequently in vision) were really the claims of Paul; and urged that Peter's refutation of Simon was in some places intended as a polemic against Paul. The enmity between Peter and Simon is clearly shown. Simon's magical powers are juxtaposed with Peter's powers in order to express Peter's authority over Simon through the power of prayer, and in the , the identification of Paul with Simon Magus is effected. Simon is there made to maintain that he has a better knowledge of the mind of Jesus than the disciples, who had seen and conversed with Jesus in person. His reason for this strange assertion is that visions are superior to waking reality, as divine is superior to human. Peter has much to say in reply to this, but the passage which mainly concerns us is as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe anti-Pauline context of the Pseudo-Clementines is recognised, but the association with Simon Magus is surprising, according to Jozef Verheyden, since they have little in common. However the majority of scholars accept Baur's identification, though others, including Lightfoot, argued extensively that the \"Simon Magus\" of the Pseudo-Clementines was not meant to stand for Paul. More recently, Berlin pastor Hermann Detering (1995) has made the case that the veiled anti-Pauline stance of the Pseudo-Clementines has historical roots, that the Acts 8 encounter between Simon the magician and Peter is itself based on the conflict between Peter and Paul. Detering's belief has not found general support among scholars, but Robert M. Price argues much the same case in \"The Amazing Colossal Apostle:The Search for the Historical Paul\" (2012).\nIdentification of Simon as the Apostle Paul.\nSince Ferdinand Christian Baur in the 19th century, scholars including Hermann Detering and Margaret Barket have concluded that the attacks on \"Simon Magus\" in the 4th-century Pseudo-Clementines may be attacks on Paul. Detering takes the attacks of the Pseudo-Clementines as literal and historical, and suggests that the attacks of the Pseudo-Clementines are correct in identifying \"Simon Magus\" as a for Paul of Tarsus, with Simon-Paul originally having been detested by the church, and the name changed to Paul when he was rehabilitated by virtue of forged Epistles \"correcting\" the genuine ones. Robert Price has stated his agreement with this assertion.\nAnti-Marcionism.\nThere are other features in the portrait which are reminiscent of Marcion. The first thing mentioned in the \"Homilies\" about Simon's opinions is that he denied that God was just. By \"God\" he meant the creator god. But he undertakes to prove from the Jewish scriptures that there is a higher god, who really possesses the perfections which are falsely ascribed to the lower god. On these grounds Peter complains that, when he was setting out for the gentiles to convert them from their worship of \"many gods upon earth\", Satan had sent Simon before him to make them believe that there were \"many gods in heaven\".\nDruidism.\nIn Irish legend, Simon Magus came to be associated with Druidism. He is said to have come to the aid of the Druid Mog Ruith. The fierce denunciation of Christianity by Irish Druids appears to have resulted in Simon Magus being associated with Druidism. The word Druid was sometimes translated into Latin as \"magus\", and Simon Magus was also known in Ireland as \"Simon the Druid\".\nMedieval legends, later interpretations.\nThe church of Santa Francesca Romana, Rome, is claimed to have been built on the spot where Simon fell. Within the Church is a dented slab of marble that purports to bear the imprints of the knees of Peter and Paul during their prayer. The fantastic stories of Simon the Sorcerer persisted into the later Middle Ages, becoming a possible inspiration for the \"Faustbuch\" and Goethe's Faust.\nThe opening story in Danilo Ki\u0161's 1983 collection \"The Encyclopedia of the Dead\", \"Simon Magus\", retells the confrontation between Simon and Peter agreeing with the account in the \"Acts of Peter\", and provides an additional alternative ending in which Simon asks to be buried alive in order to be resurrected three days later (after which his body is found putrefied).\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral and cited references.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "28020", "revid": "14896122", "url": "https://en.wikipedia.org/wiki?curid=28020", "title": "September 10", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearSeptember 10 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28021", "revid": "27834473", "url": "https://en.wikipedia.org/wiki?curid=28021", "title": "September 12", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearSeptember 12 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28022", "revid": "17488477", "url": "https://en.wikipedia.org/wiki?curid=28022", "title": "School", "text": "Institution for the education of students by teachers\nA school is the educational institution (and, in the case of in-person learning, the building) designed to provide learning environments for the teaching of students, usually under the direction of teachers. Most countries have systems of formal education, which is sometimes compulsory. In these systems, students progress through a series of schools that can be built and operated by both government and private organization. The names for these schools vary by country (discussed in the \"Regional terms\" section below) but generally include primary school for young children and secondary school for teenagers who have completed primary education. An institution where higher education is taught is commonly called a university college or university.\nIn addition to these core schools, students in a given country may also attend schools before and after primary (elementary in the U.S.) and secondary (middle school in the U.S.) education. Kindergarten or preschool provide some schooling to very young children (typically ages 3\u20135). University, vocational school, college, or seminary may be available after secondary school. A school may be dedicated to one particular field, such as a school of economics or dance. Alternative schools may provide nontraditional curriculum and methods.\nNon-government schools, also known as private schools, may be required when the government does not supply adequate or specific educational needs. Other private schools can also be religious, such as Christian schools, gurukula (Hindu schools), madrasa (Arabic schools), hawzas (Shi'i Muslim schools), yeshivas (Jewish schools), and others; or schools that have a higher standard of education or seek to foster other personal achievements. Schools for adults include institutions of corporate training, military education and training, and business schools.\nCritics of school often accuse the school system of failing to adequately prepare students for their future lives, of encouraging certain temperaments while inhibiting others, of prescribing students exactly what to do, how, when, where and with whom, which would suppress creativity, and of using extrinsic measures such as grades and homework, which would inhibit children's natural curiosity and desire to learn.\nIn homeschooling and distance education, teaching and learning take place independent from the institution of school or in a virtual school outside a traditional school building, respectively. Schools are organized in several different organizational models, including departmental, small learning communities, academies, integrated, and schools-within-a-school.\nEtymology.\nThe word \"school\" derives from Greek \"(\"), originally meaning \"leisure\" and also \"that in which leisure is employed\", but later \"a group to whom lectures were given, school\".\nHistory and development.\nThe concept of grouping students together in a centralized location for learning has existed since Classical antiquity. Formal schools have existed at least since ancient Greece (see Academy), ancient Rome (see Education in Ancient Rome) ancient India (see Gurukul), and ancient China (see History of education in China). The Byzantine Empire had an established schooling system beginning at the primary level. According to \"Traditions and Encounters\", the founding of the primary education system began in 425 AD and \"...\u00a0military personnel usually had at least a primary education\u00a0...\". The sometimes efficient and often large government of the Empire meant that educated citizens were a must. Although Byzantium lost much of the grandeur of Roman culture and extravagance in the process of surviving, the Empire emphasized efficiency in its war manuals. The Byzantine education system continued until the empire's collapse in 1453 AD.\nIn Western Europe, a considerable number of cathedral schools were founded during the Early Middle Ages in order to teach future clergy and administrators, with the oldest still existing, and continuously operated, cathedral schools being The King's School, Canterbury (established 597 CE), King's School, Rochester (established 604 CE), St Peter's School, York (established 627 CE) and Thetford Grammar School (established 631 CE). Beginning in the 5th century CE, monastic schools were also established throughout Western Europe, teaching religious and secular subjects.\nIn Europe, universities emerged during the 12th century; here, scholasticism was an important tool, and the academicians were called \"schoolmen\". During the Middle Ages and much of the Early Modern period, the main purpose of schools (as opposed to universities) was to teach the Latin language. This led to the term grammar school, which in the United States informally refers to a primary school, but in the United Kingdom means a school that selects entrants based on ability or aptitude. The school curriculum has gradually broadened to include literacy in the vernacular language and technical, artistic, scientific, and practical subjects.\nObligatory school attendance became common in parts of Europe during the 18th century. In Denmark-Norway, this was introduced as early as in 1739\u20131741, the primary end being to increase the literacy of the \"\", i.e., the \"regular people\". Many of the earlier public schools in the United States and elsewhere were one-room schools where a single teacher taught seven grades of boys and girls in the same classroom. Beginning in the 1920s, one-room schools were consolidated into multiple classroom facilities with transportation increasingly provided by kid hacks and school buses.\nIslam was another culture that developed a school system in the modern sense of the word. Emphasis was put on knowledge, which required a systematic way of teaching and spreading knowledge and purpose-built structures. At first, mosques combined religious performance and learning activities. However, by the 9th century, the madrassa was introduced, a school that was built independently from the mosque, such as al-Qarawiyyin, founded in 859 CE. They were also the first to make the \"Madrassa\" system a public domain under Caliph's control.\nUnder the Ottomans, the towns of Bursa and Edirne became the main centers of learning. The Ottoman system of K\u00fclliye, a building complex containing a mosque, a hospital, madrassa, and public kitchen and dining areas, revolutionized the education system, making learning accessible to a broader public through its free meals, health care, and sometimes free accommodation.\nRegional terms.\nThe term \"school\" varies by country, as do the names of the various levels of education within the country.\nUnited Kingdom and Commonwealth of Nations.\nIn the United Kingdom, the term \"school\" refers primarily to pre-university institutions, and these can, for the most part, be divided into pre-schools or nursery schools, primary schools (sometimes further divided into infant school and junior school), and secondary schools. Various types of secondary schools in England and Wales include grammar schools, comprehensives, secondary moderns, and city academies. While they may have different names in Scotland, there is only one type of secondary school. However, they may be funded either by the state or independently funded. Scotland's school performance is monitored by Education Scotland. Ofsted reports on performance in England and Estyn reports on performance in Wales.\nIn the United Kingdom, most schools are publicly funded and known as state schools or maintained schools in which tuition is provided for free. There are also private schools or private schools that charge fees. Some of the most selective and expensive private schools are known as public schools, a usage that can be confusing to speakers of North American English. In North American usage, a public school is publicly funded or run.\nIn much of the Commonwealth of Nations, including Australia, New Zealand, India, Pakistan, Bangladesh, Sri Lanka, South Africa, Kenya, and Tanzania, the term \"school\" refers primarily to pre-university institutions.\nIndia.\nIn ancient India, schools were in the form of Gurukuls. Gurukuls were traditional Hindu residential learning schools, typically the teacher's house or a monastery. Schools today are commonly known by the Sanskrit terms \"Vidyashram\", \"Vidyalayam\", \"Vidya\" \"Mandir\", \"Vidya Bhavan\" in India. In southern languages, it is known as \"Pallikoodam\" or \"PaadaSaalai\". During the Mughal rule, Madrasahs were introduced in India to educate the children of Muslim parents. British records show that indigenous education was widespread in the 18th century, with a school for every temple, mosque, or village in most regions. The subjects taught included Reading, Writing, Arithmetic, Theology, Law, Astronomy, Metaphysics, Ethics, Medical Science, and Religion.\nUnder British rule, Christian missionaries from England, the United States, and other countries established missionary and boarding schools in India. Later as these schools gained popularity, more were started, and some gained prestige. These schools marked the beginning of modern schooling in India. The syllabus and calendar they followed became the benchmark for schools in modern India. Today most schools follow the missionary school model for tutoring, subject/syllabus, and governance, with minor changes.\nSchools in India range from large campuses with thousands of students and hefty fees to schools where children are taught under a tree with a small / no campus and are free of cost. There are various boards of schools in India, namely Central Board for Secondary Education (CBSE), Council for the Indian School Certificate Examinations (CISCE), Madrasa Boards of various states, Matriculation Boards of various states, State Boards of various boards, Anglo Indian Board, among others. Today's typical syllabus includes language(s), mathematics, science\u00a0\u2013 physics, chemistry, biology, geography, history, general knowledge, and information technology/computer science. Extracurricular activities include physical education/sports and cultural activities like music, choreography, painting, and theatre/drama.\nEurope.\nIn much of continental Europe, the term \"school\" usually applies to primary education, with primary schools that last between four and nine years, depending on the country. It also applies to secondary education, with secondary schools often divided between \"Gymnasiums\" and vocational schools, which again, depending on country and type of school, educate students for between three and six years. In Germany, students graduating from Grundschule are not allowed to progress into a vocational school directly. Instead, they are supposed to proceed to one of Germany's general education schools such as Gesamtschule, Hauptschule, Realschule or Gymnasium. When they leave that school, which usually happens at age 15\u201319, they may proceed to a vocational school. The term school is rarely used for tertiary education, except for some \"upper\" or \"high\" schools (German: Hochschule), which describe colleges and universities.\nIn Eastern Europe modern schools (after World War II), of both primary and secondary educations, often are combined. In contrast, secondary education might be split into accomplished or not. The schools are classified as middle schools of general education. For the technical purposes, they include \"degrees\" of the education they provide out of three available: the first\u00a0\u2013 primary, the second\u00a0\u2013 unaccomplished secondary, and the third\u00a0\u2013 accomplished secondary. Usually, the first two degrees of education (eight years) are always included. In contrast, the last one (two years) permits the students to pursue vocational or specialized educations.\nNorth America and the United States.\nIn North America, the term \"school\" can refer to any educational institution at any level and covers all of the following: preschool (for toddlers), kindergarten, elementary school, middle school (also called intermediate school or junior high school, depending on specific age groups and geographic region), high school (or in some cases senior high school), college, university, and graduate school.\nIn the United States, school performance through high school is monitored by each state's department of education. Charter schools are publicly funded elementary or secondary schools that have been freed from some of the rules, regulations, and statutes that apply to other public schools. The terms grammar school and \"grade school\" are sometimes used to refer to a primary school due to British colonial legacies. In addition, there are tax-funded magnet schools which offer different programs and instruction not available in traditional schools.\nAfrica.\nIn West Africa, \"school\" can also refer to \"bush\" schools, Quranic schools, or apprenticeships. These schools include formal and informal learning.\nBush schools are training camps that pass down cultural skills, traditions, and knowledge to their students. Bush schools are semi-similar to traditional western schools because they are separated from the larger community. These schools are located in forests outside of the towns and villages, and the space used is solely for these schools. Once the students have arrived in the forest, they cannot leave until their training is complete. Visitors are prohibited from these areas.\nInstead of being separated by age, Bush schools are separated by gender. Women and girls cannot enter the boys' bush school territory and vice versa. Boys receive training in cultural crafts, fighting, hunting, and community laws among other subjects. Girls are trained in their own version of the boys' bush school. They practice domestic affairs such as cooking, childcare, and being a good wife. Their training is focused on how to be a proper woman by societal standards.Qur'anic schools are the principal way of teaching the Quran and knowledge of the Islamic faith. These schools also fostered literacy and writing during the time of colonization. Today, the emphasis is on the different levels of reading, memorizing, and reciting the Quran. Attending a Qur'anic school is how children become recognized members of the Islamic faith. Children often attend state schools and a Qur'anic school.\nIn Mozambique, specifically, there are two kinds of Qur'anic schools. They are the tariqa based and the Wahhabi-based schools. What makes these schools different is who controls them. Tariqa schools are controlled at the local level. In contrast, the Wahhabi are controlled by the Islamic Council. Within the Qur'anic school system, there are levels of education. They range from a basic level of understanding, called chuo and kioni in local languages, to the most advanced, which is called ilimu.\nIn Nigeria, the term \"school\" broadly covers daycares, nursery schools, primary schools, secondary schools and tertiary institutions. Primary and secondary schools are either privately funded by religious institutions and corporate organisations or government-funded. Government-funded schools are commonly referred to as public schools. Students spend six years in primary school, three years in junior secondary school, and three years in senior secondary school. The first nine years of formal schooling is compulsory under the Universal Basic Education Program (UBEC). Tertiary institutions include public and private universities, polytechnics, and colleges of education. Universities can be funded by the federal government, state governments, religious institutions, or individuals and organisations.\nOwnership and operation.\nMany schools are owned or funded by states. Private schools operate independently from the government. Private schools usually rely on fees from families whose children attend the school for funding; however, sometimes such schools also receive government support (for example, through School vouchers). Many private schools are affiliated with a particular religion; these are known as parochial schools.\nComponents of most schools.\nSchools are organized spaces purposed for teaching and learning. The classrooms where teachers teach and students learn are of central importance. Classrooms may be specialized for certain subjects, such as laboratory classrooms for science education and workshops for industrial arts education.\nTypical schools have many other rooms and areas, which may include:\nEducation facilities in low-income countries.\nIn low-income countries, only 32% of primary, 43% of lower secondary and 52% of upper secondary schools have access to electricity. This affects access to the internet, which is just 37% in upper secondary schools in low-income countries, as compared to 59% in those in middle-income countries and 93% in those in high-income countries.\nAccess to basic water, sanitation and hygiene is also far from universal. Among upper secondary schools, only 53% in low-income countries and 84% in middle-income countries have access to basic drinking water. Access to water and sanitation is universal in high-income countries.\nSecurity.\nThe safety of staff and students is increasingly becoming an issue for school communities in the U.S., an issue most schools are addressing through improved security. Some have also taken measures such as installing metal detectors or video surveillance. Others have even taken measures such as having the children swipe identification cards as they board the school bus. These plans have included door numbering to aid public safety response for some schools.\nOther security concerns faced by schools include bomb threats, gangs, and vandalism. In recognition of these threats, the United Nations Sustainable Development Goal 4 advocates for upgrading education facilities to provide a safe, non-violent learning environment.\nHealth services.\nSchool health services are services from medical, teaching and other professionals applied in or out of school to improve the health and well-being of children and, in some cases, whole families. These services have been developed in different ways around the globe. However, the fundamentals are constant: the early detection, correction, prevention, or amelioration of disease, disability, and abuse from which school-aged children can suffer.\nOnline schools and classes.\nSome schools offer remote access to their classes over the internet. Online schools also can provide support to traditional schools, as in the case of the School Net Namibia. Some online classes also provide experience in a class. When people take them, they have already been introduced to the subject and know what to expect. Classes provide high school/college credit, allowing students to take the classes at their own pace. Many online classes cost money to take, but some are offered free.\nInternet-based distance learning programs are offered widely through many universities. Instructors teach through online activities and assignments. Online classes are taught the same as in-person, with the same curriculum. The instructor offers the syllabus with their fixed requirements like any other class. Students can virtually turn their assignments in to their instructors according to deadlines. This being through via email or on the course webpage. This allows students to work at their own pace yet meet the correct deadlines. Students taking an online class have more flexibility in their schedules to take their classes at a time that works best.\nConflicts with taking an online class may include not being face to face with the instructor when learning or being in an environment with other students. Online classes can also make understanding the content challenging, especially when unable to get in quick contact with the instructor. Online students have the advantage of using other online sources with assignments or exams for that specific class. Online classes also have the advantage of students not needing to leave their house for a morning class or worrying about their attendance for that class. Students can work at their own pace to learn and achieve within that curriculum.\nThe convenience of learning at home has been an attraction point for enrolling online. Students can attend class anywhere a computer can go\u00a0\u2013 at home, in a library, or while traveling internationally. Online school classes are designed to fit a student's needs while allowing students to continue working and tending to their other obligations. Online school education is divided into three subcategories: Online Elementary School, Online Middle School, Online High school.\nStress.\nAs a profession, teaching has levels of work-related stress (WRS) that are among the highest of any profession in some countries, such as the United Kingdom and the United States. The degree of this problem is becoming increasingly recognized and support systems are being put into place.\nStress sometimes affects students more severely than teachers, up to the point where the students are prescribed stress medication. This stress is claimed to be related to standardized testing, and the pressure on students to score above average.\nAccording to a 2008 mental health study by the Associated Press and mtvU, eight in 10 U.S. college students said they had sometimes or frequently experienced stress in their daily lives. This was an increase of 20% from a survey five years previously. Thirty-four percent had felt depressed at some point in the past three months, 13 percent had been diagnosed with a mental health condition such as an anxiety disorder or depression, and 9 percent had seriously considered suicide.\nDiscipline towards students.\nSchools and their teachers have always been under pressure\u00a0\u2013 for instance, pressure to cover the curriculum, perform well compared to other schools, and avoid the stigma of being \"soft\" or \"spoiling\" toward students. Forms of discipline, such as control over when students may speak, and normalized behaviour, such as raising a hand to speak, are imposed in the name of greater efficiency. Practitioners of critical pedagogy maintain that such disciplinary measures have no positive effect on student learning. Indeed, some argue that disciplinary practices detract from learning, saying that they undermine students' dignity and sense of self-worth\u00a0\u2013 the latter occupying a more primary role in students' hierarchy of needs.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n\u00a0This article incorporates text from a free content work. Licensed under CC BY-SA 3.0 IGO. Text taken from https://, 35, UNESCO. "}
{"id": "28024", "revid": "44604045", "url": "https://en.wikipedia.org/wiki?curid=28024", "title": "Sontaran", "text": "Alien species from the television show Doctor Who\nThe Sontarans ( ) are an alien species that appear in the British science fiction television programme \"Doctor Who\" and its spin-off series \"The Sarah Jane Adventures\". In-universe, they are a clone race bred to fight a never-ending war against a species known as the Rutans. They first appeared in the 1973 serial \"The Time Warrior\", where a Sontaran uses time travel technology to try and return to his home planet. The Sontarans have gone on to be recurring antagonists within the series. A Sontaran named Strax serves as a supporting character and as a member of the Paternoster Gang. \nThe Sontarans were created by writer Robert Holmes, who conceived of the Sontarans after reading the 1832 war treatise \"On War\". He was also inspired by the history of the Vietnam War. The Sontarans' design would change throughout the years, with different Sontarans being portrayed by a variety of different actors. \nSome critics found the Sontarans to be among the more successful and popular alien species on the show, while others thought they were under-used or taken less seriously in the series.\nAppearances.\n\"Doctor Who\" is a long-running British science-fiction television series that began in 1963. It stars its protagonist, The Doctor, an alien who travels through time and space in a ship known as the TARDIS, as well as their travelling companions. When the Doctor dies, they are able to undergo a process known as \"regeneration\", completely changing the Doctor's appearance and personality. Throughout their travels, the Doctor often comes into conflict with various alien species and antagonists.\nThe Sontarans are a clone race that hail from the planet Sontar, and are bred for war from birth. They are engaged in a constant, never-ending war against a species known as the Rutans. They have a culture dedicated almost solely to war, where dying in battle is the ultimate honor among their race, as is entering a battle without a protective helmet. They also have a war chant consisting of the phrase \"Sontar-ha!\" Sontarans only have a single weak point: a \"probic vent\" on the back of their neck, through which they receive energy. A single hit here can result in heavy damage. Sontarans are physically shorter than humans due to their homeworld planet having high gravity. Sontarans are capable of genetically modifying themselves, even allowing them to produce breast milk. Sontarans only have one gender and are also sexist against women by nature, associating womanhood with weakness.\nTelevision.\nThe Sontarans first appear in the 1973 serial \"The Time Warrior\", where a Sontaran named Linx crash lands on Earth in the past and attempts to use time travel technology to fix his ship and return to combat. A Sontaran named Styre appears in the 1975 serial \"The Sontaran Experiment\", where in the far future he seeks to test the strength of humans left to survive on an Earth ravaged by solar flares. The Fourth Doctor kills Styre and stops a further Sontaran invasion. The Sontarans then appear in the 1978 serial \"The Invasion of Time\", where the Sontarans, under commander Stor, lead an invasion of Gallifrey, the Doctor's home planet; they are defeated by the Doctor. They next appear in the 1985 serial \"The Two Doctors\", where a pair of Sontarans named Stike and Varl plan to obtain more powerful time travel technology from human scientists, but end up being killed by their allies, the Androgums. \nIn the show's 2005 revival, the Sontarans appear in the two-part story \"The Sontaran Stratagem\" and \"The Poison Sky\" (both 2008). They try to terraform Earth into a new cloning planet, but the Tenth Doctor destroys their ship, halting the invasion. The Sontarans make subsequent cameos in the episodes \"The End of Time\" (2009\u20132010), \"The Pandorica Opens\" (2010), and \"Face the Raven\" (2015). They later appear as antagonists in , the 2021 series of the revival, first appearing in \"The Halloween Apocalypse\" (2021). As part of a scheme to conquer Earth from all points in time in \"War of the Sontarans\" (2021), they change the timeline of the Crimean War, but are defeated by the Thirteenth Doctor and her allies. The Sontarans later invade Earth again during \"The Vanquishers\" (2021), where they use humans to pinpoint the location of the flux, a destructive anti-matter wave. The Sontarans aim to use the flux to wipe out the Daleks and Cybermen but end up being destroyed by it and the Doctor.\nA former Sontaran commander named Kaagh, a survivor of the invasion of Earth from \"The Sontaran Stratagem\" and \"The Poison Sky\", appears in \"The Sarah Jane Adventures\" serials \"The Last Sontaran\" and \"Enemy of the Bane\". In the former serial, he tries to return to Sontar, but later ends up allying with antagonist Mrs. Wormwood to conquer the universe in the latter serial. Kaagh later sacrifices himself after he realises Wormwood will betray him. Another Sontaran named Strax appears as a supporting character in the main television series. Debuting in the 2011 episode \"A Good Man Goes to War\", Strax was punished for cowardice by his people, who forced him to serve as a nurse. Strax would later join the Silurian Madame Vastra and human Jenny Flint as part of the Paternoster Gang, serving in a comedic role as their butler. Strax subsequently appears in \"The Snowmen\" (2012), \"The Crimson Horror\" (2013), \"The Name of the Doctor\" (2013), and \"Deep Breath\" (2014).\nSpin-off media.\nThe Sontarans appear in several media spin-offs for the series, including novels, comics, audio dramas, and video games. The Sontarans also appear in the spin-off films \"Mindgame\" and \".\"\nDevelopment.\nClassic era.\nThe Sontarans were originally created for the 1973 serial \"The Time Warrior\" by writer Robert Holmes. Holmes conceived of the Sontarans after reading the 1832 war treatise \"On War\", and was additionally inspired by the history of the Vietnam War. In the script, the Sontaran is described as being \"squat\", wearing armour resembling that of a medieval knight. The Sontarans' physical appearance in the serial was created by costume designer James Acheson and make-up designer Sandra Exelby. Linx, the Sontaran in this serial, was portrayed by actor Kevin Lindsay. Lindsay wore a prosthetic mask, make-up, and occasionally a helmet, which was a challenge during filming due to his heart condition. \nHolmes wished to re-use the Sontarans in the 1974\u20131975 season. This would allow him to collect a fee and make it possible for the production team to make use of Linx's costume again. Holmes briefed the serial's writers, Bob Baker and Dave Martin on the Sontarans' lore and history to ensure an accurate depiction in the serial (dubbed \"The Sontaran Experiment\"). Holmes re-wrote dialogue in the final script to fit his vision for the species. Styre, the Sontaran in the serial, was modeled on Nazi generals in terms of his behavior and actions.\nAlthough the production team had hoped to re-use the Linx costume and prosthetic mask, the mask was in poor condition, requiring a new one to be made. The new head of the Sontaran was much larger, with a different skin tone compared to the Sontarans' prior appearance. Despite his heart condition, Lindsay returned for the serial to portray Styre, the Sontaran commander. To alleviate the strain Lindsay experienced in the previous serial, he wore less intensive makeup and prosthetics and only wore the Sontaran helmet for a single scene. Lindsay also portrayed the Sontaran Marshal with whom Styre communicates in the serial, characterised by an insignia on the costume's collar. Stuntman Stuart Fell filled in for Lindsay in several intensive scenes.\nThe 1978 serial \"The\" \"Invasion of Time\" had a troubled production, and its original antagonists, a race of cat people, could not be used as adversaries due to complications during development. Producer Graham Williams decided that since no returning antagonists had been used in the 1978 season at that point, the Sontarans could be used, as Williams was fond of them. Holmes agreed to let the production team use the Sontarans, knowing they were in a tough spot in production, but was uncomfortable about other writers using the character. Since Lindsay had died in 1975, the role of Sontaran commander Stor was portrayed by actor Derek Deadman. New costumes were created for the serial, with the Sontarans having another change in skin-tone and dark rims placed around Styre's eyes to show that he was stressed by his leadership role as commander. \nFor the 1985 season of the show, producer John Nathan-Turner wanted the Sontarans to return. Though several Sontaran serials had been pitched before this time, this serial was the only one that was produced. Holmes had recently returned to writing for the series, but he disliked bringing back returning monsters. He was convinced to write the serial as it would allow him to make up for what he saw as the mishandling of the Sontarans in their prior two appearances. New masks and costumes were developed, with the masks custom-made for the two Sontarans, Stike and Varl. The masks and costumes were based on those used in previous Sontaran appearances. Actors Clinton Greyn and Tim Raynham portrayed Stike and Varl, respectively. This version of the Sontarans was much taller than in previous appearances. As part of the publicity for the serial, a special segment featuring the Sontarans, titled \"A Fix With Sontarans\", aired on the show \"Jim'll Fix It\". \nRevived era.\nFor the show's 2005 revival, showrunner Russell T Davies had wanted to bring back the Sontarans for some time, eventually electing to bring them back in the 2008 two-part story \"The Sontaran Stratagem\" and \"The Poison Sky\". Davies believed the Sontarans' culture and personality had more potential for strong dialogue than other returning antagonists such as the Daleks and Cybermen, and also felt they would be easy for children to draw, as well as visually striking. This version of the Sontarans was designed by Neill Gorton of Millennium FX, with a pitch to make the Sontarans resemble their original appearance with a modern update. The Sontarans' armour was re-colored blue, while the Sontarans themselves were designed with a more furrowed brow, giving them an \"angrier\" look. Davies believed that shorter actors should portray the Sontarans, akin to their older appearances. The costumes were modelled on actor Christopher Ryan, who portrays the Sontaran commander Staal in the story. The production team found other actors who would fit within Ryan's body cast to perform in the role of other Sontarans in the episode. \nPhil Ford, a writer for the spin-off series \"The Sarah Jane Adventures\", was keen on adapting the Sontarans into the series, resulting in their appearance in \"The Last Sontaran\", the first serial of the show's second season. Though many Sontaran props and objects could be re-used from the main show in the serial, Kaagh (portrayed by actor Anthony O'Donnell), the Sontaran who appears in the episode, had a new cast taken for his armour instead of re-using the old one. Kaagh was later brought back for the season finale, \"Enemy of the Bane\". In an unused script for writer Gareth Roberts's later serial \"Death of the Doctor\", a Sontaran named Skorm would have appeared; Skorm's concept would later be adapted into Strax (portrayed by Dan Starkey) in the 2011 episode \"A Good Man Goes to War\". Strax would go on to serve as a recurring character in the main \"Doctor Who\" series. Steven Moffat, the creator of Strax, said that his continued appearances came about due to his popularity among fans, particularly alongside Madame Vastra and Jenny Flint, who had debuted in the same episode.\nFor their re-appearance in , then-showrunner Chris Chibnall aimed to return the Sontarans to a level of threat with audiences that they had not been at in some time. Costume designer Ray Holman and prosthetics expert Danny Marie Elias worked together on the new design. Compared to the 2008 design, these new Sontarans were built to be \"dirtier\" to convey their experience in battle. The design took inspiration from the Sontarans' appearance in the classic era, particularly from their appearances in the 1970s. According to Sontaran actor Jonathan Watson, who portrays the Sontaran commander Skaak, the Sontarans were originally intended to be written out of \"Flux\" after \"War of the Sontarans\", with scripts re-written during filming to facilitate a later return.\nReception and analysis.\nGraham Sleight, writing in the book \"The Doctor's Monsters\", regarded the Sontarans as a success. Despite being an \"average\" monster conceptually, the Sontarans had a thoroughly well-defined culture. \"Radio Times\" identified the Sontarans as among the more iconic monsters within the series that are popular with fans, with their design and culture a fan favorite. Adi Tantimedh, writing for \"Bleeding Cool\", observed that the Sontarans symbolised the constant warfare linked to fascism, with their tactics and plans more akin to Cold War-era fears. She viewed the Sontarans as a species who only improved with further appearances, as budget increases allowed their design to become more detailed. \nSleight felt the Sontarans' subsequent appearances were less in-depth than their first, and that their culture was often less well-defined, reducing them to unremarkable antagonists. Sleight saw the appearance of the Sontarans in the revival as a step-up from classic era appearances, with the improved visual quality of the Sontarans and expanded culture. The book \"Inside the TARDIS\" argued that the Sontarans' return in the revival was a failure compared to other returns, as the Sontarans were taken less seriously as antagonists and were described as an \"embarrassment\". Mick Joest, writing for \"CinemaBlend\", remarked that following the Sontarans' appearances in the show's revival, the race had largely been reduced to comic relief instead of as a genuine threat. \"Radio Times\" agreed, stating that because of their limited appearances compared to other monsters like the Daleks and Cybermen, the Sontarans were unable to capitalise on their story potential; additionally due to Strax's increased comic relief prominence in the series, the Sontarans came off in a more comedic fashion than they did before. \nThe book \"The Science of Doctor Who\" analysed the Sontarans' cloning technology and feeding via probic vent in terms of real-world feasibility. The book noted that for their manner of cloning and feeding to work, Sontarans would need to be much more complicated biologically than they are depicted on-screen.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28025", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=28025", "title": "Skydiving", "text": ""}
{"id": "28027", "revid": "9467159", "url": "https://en.wikipedia.org/wiki?curid=28027", "title": "Skateboarding", "text": "Action sport on skateboards\nSkateboarding is an action sport that involves riding and performing tricks using a skateboard, as well as a recreational activity, an art form, an entertainment industry job, and a method of transportation. Originating in the United States, skateboarding has been shaped and influenced by many skateboarders throughout the years. A 2009 report found that the skateboarding market is worth an estimated $4.8 billion in annual revenue, with 11.08 million active skateboarders in the world. In 2016, it was announced that skateboarding would be represented at the 2020 Summer Olympics in Tokyo, for both male and female teams. Skateboarding made its Olympic debut in 2020 and was included in the 2024 games.\nSince the 1970s, skateparks have been constructed specifically for use by skateboarders, freestyle BMXers, aggressive skaters, and more recently, scooters. However, skateboarding has become controversial in areas in which the activity, although legal, has damaged curbs, stoneworks, steps, benches, plazas, and parks.\nHistory.\n1940s\u20131960s.\nThe first skateboards started with wooden boxes, or boards, with roller skate wheels attached to the bottom. Crate scooters preceded skateboards, having a wooden crate attached to the nose (front of the board), which formed rudimentary handlebars. The boxes turned into planks, similar to the skateboard decks of today.\nSkateboarding, as it exists today, was probably born sometime in the late 1940s, or early 1950s, when surfers in California wanted something to do when the waves were flat. This was called \"sidewalk surfing\" \u2013 a new wave of surfing on the sidewalk as the sport of surfing became highly popular. No one knows who made the first board; it seems that several people came up with similar ideas at around the same time. The first manufactured skateboards were ordered by a Los Angeles, California, surf shop, meant to be used by surfers in their downtime. The shop owner, Bill Richard, made a deal with the Chicago Roller Skate Company to produce sets of skate wheels, which they attached to square wooden boards. Accordingly, skateboarding was originally denoted \"sidewalk surfing\" and early skaters emulated surfing style and maneuvers, and performed barefoot.\nBy the 1960s a small number of surfing manufacturers in Southern California such as Jack's, Kips', Hobie, Bing's and Makaha started building skateboards that resembled small surfboards, and assembled teams to promote their products. One of the earliest Skateboard exhibitions was sponsored by Makaha's founder, Larry Stevenson, in 1963 and it was held at the Pier Avenue Junior High School in Hermosa Beach, California. Some of these same teams of skateboarders were also featured on a television show called \"Surf's Up\" in 1964, hosted by Stan Richards, that helped promote skateboarding as something new and fun to do.\nAs the popularity of skateboarding began expanding, the first skateboarding magazine, \"The Quarterly Skateboarder\", was published in 1964. John Severson, who published the magazine, wrote in his first editorial:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Today's skateboarders are founders in this sport\u2014they're pioneers\u2014they are the first. There is no history in Skateboarding\u2014its being made now\u2014by you. The sport is being molded and we believe that doing the right thing now will lead to a bright future for the sport. Already, there are storm clouds on the horizon with opponents of the sport talking about ban and restriction.\nThe magazine only lasted four issues, but resumed publication as \"Skateboarder\" in 1975. The first broadcast of an actual skateboarding competition was the 1965 National Skateboarding Championships, which were held in Anaheim, California and aired on ABC's \"Wide World of Sports\". Because skateboarding was a new sport during this time, there were only two original disciplines during competitions: flatland freestyle and slalom downhill racing.\nAnimated cartoons of the time occasionally featured skateboard gags. Two Road Runner cartoons made in 1965, \"Shot and Bothered\" and \"Out and Out Rout\", feature Wile E. Coyote riding a skateboard.\nOne of the earliest sponsored skateboarders, Patti McGee, was paid by Hobie and Vita Pak to travel around the country to do skateboarding exhibitions and to demonstrate skateboarding safety tips. McGee made the cover of \"Life\" magazine in 1965 and was featured on several popular television programs\u2014\"The Mike Douglas Show\", \"What's My Line?\" and \"The Tonight Show Starring Johnny Carson\"\u2014which helped make skateboarding even more popular at the time. Some other well known surfer-style skateboarders of the time were Danny Bearer, Torger Johnson, Bruce Logan, Bill and Mark Richards, Woody Woodward, and Jim Fitzpatrick.\nThe growth of the sport during this period can also be seen in sales figures for Makaha, which quoted $4 million worth of board sales between 1963 and 1965. By 1966 a variety of sources began to claim that skateboarding was dangerous, resulting in shops being reluctant to sell them, and parents being reluctant to buy them. In 1966 sales had dropped significantly and \"Skateboarder Magazine\" had stopped publication. The popularity of skateboarding dropped and remained low until the early 1970s.\n1970s.\nIn the early 1970s, Frank Nasworthy started to develop a skateboard wheel made of polyurethane, calling his company Cadillac Wheels. Prior to this new material, skateboards wheels were metal or \"clay\" wheels. The improvement in traction and performance was so immense that from the wheel's release in 1972 the popularity of skateboarding started to rise rapidly again, causing companies to invest more in product development. Nasworthy commissioned artist Jim Evans to do a series of paintings promoting Cadillac Wheels, they were featured as ads and posters in the resurrected \"Skateboarder Magazine\", and proved immensely popular in promoting the new style of skateboarding.\nIn the early 1970s, the precursors to the modern skateparks for skateboarding would be the repurposing of urban hydro and storm water infrastructure such as the Escondido reservoir in San Diego, California. \"Skateboarding\" magazine would publish the location and skateboarders made up nicknames for each location such as the Tea Bowl, the Fruit Bowl, Bellagio, the Rabbit Hole, Bird Bath, the Egg Bowl, Upland Pool and the Sewer Slide. Some of the development concepts in the terrain of skateparks were actually taken from the Escondido reservoir. Many companies started to manufacture trucks (axles) specially designed for skateboarding, reached in 1976 by Tracker Trucks. As the equipment became more maneuverable, the decks started to get wider, reaching widths of and over, thus giving the skateboarder even more control. A banana board is a skinny, flexible skateboard made of polypropylene with ribs on the underside for structural support. These were very popular during the mid-1970s and were available in a myriad of colors, bright yellow probably being the most memorable, hence the name.\nIn 1975, skateboarding had risen back in popularity enough to have one of the largest skateboarding competitions since the 1960s, the Del Mar National Championships, which is said to have had up to 500 competitors. The competition lasted two days and was sponsored by Bahne Skateboards and Cadillac Wheels. While the main event was won by freestyle spinning skate legend Russ Howell, a local skate team from Santa Monica, California, the Zephyr team, ushered in a new era of surfer style skateboarding during the competition that would have a lasting impact on skateboarding's history. With a team of 12, including skating legends such as Jay Adams, Tony Alva, Peggy Oki and Stacy Peralta, they brought a new progressive style of skateboarding to the event, based on the style of Hawaiian surfers Larry Bertlemann, Buttons Kaluhiokalani and Mark Liddell. Craig Stecyk, a photo journalist for \"Skateboarder Magazine\", wrote about and photographed the team, along with Glen E. Friedman, and shortly afterwards ran a series on the team called the Dogtown articles, which eventually immortalized the Zephyr skateboard team. The team became known as the Z-Boys and would go on to become one of the most influential teams in skateboarding's history.\nSoon, skateboarding contests for cash and prizes, using a professional tier system, began to be held throughout California, such as the California Free Former World Professional Skateboard Championships, which featured freestyle and slalom competitions.\nA precursor to the extreme sport of street luge, that was sanctioned by the United States Skateboarding Association (USSA), also took place during the 1970s in Signal Hill, California. The competition was called \"The Signal Hill Skateboarding Speed Run\", with several competitors earning entries into the \"Guinness Book of World Records\", at the time clocking speeds of over on a skateboard. Due to technology and safety concerns at the time, when many competitors crashed during their runs, the sport did not gain popularity or support during this time.\nIn March 1976, Skateboard City skatepark in Port Orange, Florida and Carlsbad Skatepark in San Diego County, California would be the first two large size US skateparks to be opened to the public, just a week apart. They were the first of some 200 skateparks that would be built through 1982. This was due in part to articles that were running in the investment journals at the time, stating that skateparks were a good investment. Notable skateboarders from the 1970s also include Ty Page, Tom Inouye, Laura Thornhill, Ellen O'Neal, Kim Cespedes, Bob Biniak, Jana Payne, Waldo Autry, Robin Logan, Bobby Piercy, Russ Howell, Ellen Berryman, Shogo Kubo, Desiree Von Essen, Henry Hester, Robin Alaway, Paul Hackett, Michelle Matta, Bruce Logan, Steve Cathey, Edie Robertson, Mike Weed, David Hackett, Gregg Ayres, Darren Ho, and Tom Sims.\nManufacturers started to experiment with more exotic composites and metals, like fiberglass and aluminum, but the common skateboards were made of maple plywood. The skateboarders took advantage of the improved handling of their skateboards and started inventing new tricks. Skateboarders, most notably Ty Page, Bruce Logan, Bobby Piercy, Kevin Reed, and the Z-Boys started to skate the vertical walls of swimming pools that were left empty in the 1976 California drought. This started the \"vert\" trend in skateboarding. With increased control, vert skaters could skate faster and perform more dangerous tricks, such as slash grinds and frontside/backside airs. This caused liability concerns and increased insurance costs to skatepark owners, and the development (first by Norcon, then more successfully by Rector) of improved knee pads that had a hard sliding cap and strong strapping proved to be too-little-too-late. During this era, the \"freestyle\" movement in skateboarding began to splinter off and develop into a much more specialized discipline, characterized by the development of a wide assortment of flat-ground tricks.\nAs a result of the \"vert\" skating movement, skate parks had to contend with high liability costs that led to many park closures. In response, vert skaters started making their own ramps, while freestyle skaters continued to evolve their flatland style. Thus, by the beginning of the 1980s, skateboarding had once again declined in popularity.\n1980s.\nThis period was fueled by skateboard companies that were run by skateboarders. The focus was initially on vert ramp skateboarding. The invention of the no-hands aerial (later known as the ollie) by Alan Gelfand in Florida in 1976, and the almost parallel development of the grabbed aerial by George Orton and Tony Alva in California, made it possible for skaters to perform airs on vertical ramps. While this wave of skateboarding was sparked by commercialized vert ramp skating, a majority of people who skateboarded during this period did not ride vert ramps. As most people could not afford to build vert ramps, or did not have access to nearby ramps, street skating increased in popularity.\nFreestyle skating remained healthy throughout this period, with pioneers such as Rodney Mullen inventing many of the basic tricks that would become the foundation of modern street skating, such as the \"Impossible\" and the \"kickflip\". The influence that freestyle exerted upon street skating became apparent during the mid-1980s; however, street skating was still performed on wide vert boards with short noses, slide rails, and large soft wheels. In response to the tensions created by this confluence of skateboarding \"genres\", a rapid evolution occurred in the late 1980s to accommodate the street skater. Since few skateparks were available to skaters at this time, street skating pushed skaters to seek out shopping centers and public and private property as their \"spot\" to skate. (Public opposition, in which businesses, governments, and property owners have banned skateboarding on properties under their jurisdiction or ownership, would progressively intensify over the following decades.) By 1992, only a small fraction of skateboarders continuing to take part in a highly technical version of street skating, combined with the decline of vert skating, produced a sport that lacked the mainstream appeal to attract new skaters.\nDuring this period, numerous skateboarders\u2014as well as companies in the industry\u2014paid tribute to the scenes of Marty McFly skateboarding in the film \"Back to the Future\" for its influence in this regard. Examples can be seen in promotional material, in interviews in which professional skateboarders cite the film as an initiation into the action sport, and in the public's recognition of the film's influence. Tony Hawk has stated that \u201cthere are plenty of legendary pros that I know of that started skating because they saw that [film].\u201d \n1990s.\nSkateboarding during the 1990s became dominated by street skateboarding. Most boards are about wide and long. The wheels are made of an extremely hard polyurethane, with hardness (durometer) approximately 99A. The wheel sizes are relatively small so that the boards are lighter, and the wheels' inertia is overcome quicker, thus making tricks more manageable. Board styles have changed dramatically since the 1970s but have remained mostly alike since the mid-1990s. The contemporary shape of the skateboard is derived from the freestyle boards of the 1980s with a largely symmetrical shape and relatively narrow width. This form had become standard by the mid-1990s.\n2000s.\nBy 2001, skateboarding had gained so much popularity that more American people under the age of 18 rode skateboards (10.6 million) than played baseball (8.2 million), although traditional organized team sports still dominated youth programs overall. Skateboarding and skateparks began to be viewed and used in a variety of new ways to complement academic lessons in schools, including new non-traditional physical education skateboarding programs, like Skatepass and Skateistan, to encourage youth to have better attendance, self-discipline and confidence. This was also based on the healthy physical opportunities skateboarding was understood to bring participants for muscle &amp; bone strengthening and balance, as well as the positive impacts it can have on youth in teaching them mutual respect, social networking, artistic expression and an appreciation of the environment.\nIn 2003, Go Skateboarding Day was founded in southern California by the International Association of Skateboard Companies (IASC) to promote skateboarding throughout the world. It is celebrated annually on June 21 \"to define skateboarding as the rebellious, creative celebration of independence it continues to be.\"\nAccording to market research firm American Sports Data the number of skateboarders worldwide increased by more than 60 percent between 1999 and 2002\u2014from 7.8 million to 12.5 million.\nMany cities also began implementing recreation plans and statutes during this time period, as part of their vision for local parks and communities to make public lands more available, in particular, for skateboarding, inviting skateboarders to come in off of the city streets and into organized skateboarding activity areas. By 2006, there were over 2,400 skateparks worldwide and the design of skateparks themselves had made a transition, as skaters turned designers. Many new places to skateboard designed specifically for street skaters, such as the Buszy in Milton Keynes, UK, and the Safe Spot Skate Spot program, first initiated by professional skateboarder Rob Dyrdek throughout many cities, allowed for the creation of smaller alternative safe skate plazas to be built at a lower cost. One of the largest locations ever built to skateboard in the world, SMP Skatepark in China, at 12,000 square meters in size, was built complete with a 5,000-seat stadium.\nIn 2009, Skatelab opened the Skateboarding Hall of Fame &amp; Skateboard Museum. Nominees are chosen by the IASC.\n2010s\u2013present.\nEfforts have been taken to improve recognition of the cultural heritage as well as the positive effects of encouraging skateboarding within designated spaces. In 2015, the John F. Kennedy Center for the Performing Arts in Washington, D.C., hosted an event at which skateboarders accompanied by music did tricks on a ramp constructed for a festival of American culture. The event was the climax of a ten-day project that transformed a federal institution formerly off-limits to the skateboarding community into a platform for that community to show its relevance through shared cultural action in a cultural common space.\nBy raising \u00a3790,000, the Long Live Southbank initiative managed in 2017 to curb the destruction of a forty year old spot in London, the Southbank Undercroft, a popular skate park, due to urban planning, a salvaging operation whose effect extends beyond skateboarding. The presence of a designated skating area within this public space keeps the space under nearly constant watch and drives homeless people away, increasing the feeling of safety in and near the space. The activity attracts artists such as photographers and film makers, as well as a significant number of tourists, which in turn drives economic activity in the neighborhood.\nRecently, barefoot skating has been experiencing a revival. Many skaters ride barefoot, particularly in summer and in warmer countries, such as South Africa, Australia, Spain and South America. The plastic penny board is intended to be ridden barefoot, as is the surfboard-inspired hamboard.\nElectric skateboards became popular during the 2010s, as did self-balancing unicycles in a board format. The sport of skateboarding made its Olympics debut at the 2020 Summer Olympics in Tokyo, with both men's and women's events. Competitions took place during July and August 2021 in two disciplines: street and park (see Skateboarding at the 2020 Summer Olympics).\nTrick skating.\nWith the evolution of skateparks and ramp skating, the skateboard began to change. Early skate tricks had consisted mainly of two-dimensional freestyle maneuvers like riding on only two wheels (\"wheelie\" or \"manual\"), spinning only on the back wheels (a \"pivot\"), high jumping over a bar and landing on the board again, also known as a \"hippie jump\", long jumping from one board to another, (often over small barrels or fearless teenagers), or slalom. Another popular trick was the Bertlemann slide, named after Larry Bertelemann's surfing maneuvers.\nIn 1976, skateboarding was transformed by the invention of the ollie by Alan \"Ollie\" Gelfand. It remained largely a unique Florida trick until the summer of 1978, when Gelfand made his first visit to California. Gelfand and his revolutionary maneuvers caught the attention of the West Coast skaters and the media where it began to spread worldwide. The ollie was adapted to flat ground by Rodney Mullen in 1982. Mullen also invented the \"Magic Flip\", which was later renamed the kickflip, as well as many other tricks including the 360 Kickflip, which is a 360 pop shove-it and a kickflip in the same motion. The flat ground ollie forms the basis of many street skating tricks, allowing skateboarders to perform tricks in mid-air without any more equipment than the skateboard itself. A recent development in the world of trick skating is the 1080, which was first ever landed by Tom Schaar in 2012.\nCulture.\nFilm.\nSkateboarding was popularized by the 1986 skateboarding cult classic \"Thrashin'\". Directed by David Winters and starring Josh Brolin, it features appearances from many famous skaters such as Tony Alva, Tony Hawk, Christian Hosoi and Steve Caballero. \"Thrashin'\" also had a direct impact on \"Lords of Dogtown\", as Catherine Hardwicke, who directed \"Lords of Dogtown\", was hired by Winters to work on \"Thrashin'\" as a production designer where she met, worked with and befriended many famous skaters including the real Alva, Hawk, Hosoi and Caballero.\nSkateboarding was, at first, tied to the culture of surfing. As skateboarding spread across the United States to places unfamiliar with surfing or surfer culture, it developed an image of its own. For example, the classic film short \"Video Days\" (1991) portrayed skateboarders as \"reckless rebels\".\nCalifornia duo Jan and Dean recorded the song \"Sidewalk Surfin'\" in 1964, which is the Beach Boys song \"Catch a Wave\" with new lyrics associated with skateboarding instead of surfing.\nSkate parks.\nCertain cities still oppose the building of skate parks in their neighborhoods, for fear of increased crime and drugs in the area. The rift between the old image of skateboarding and a newer one is quite visible: magazines such as \"Thrasher\" portray skateboarding as dirty, rebellious, and still firmly tied to punk, while other publications, \"Transworld Skateboarding\" as an example, paint a more diverse and controlled picture of skateboarding. As more professional skaters use hip hop, reggae, or hard rock music accompaniment in their videos, many urban youths, hip hop fans, reggae fans, and hard rock fans are also drawn to skateboarding, further diluting the sport's punk image.\nGroup spirit supposedly influences the members of this community. In presentations of this sort, showcasing of criminal tendencies is absent, and no attempt is made to tie extreme sports to any kind of illegal activity. Female based skateboarding groups also exist, such as Brujas which is based in New York City. Many women use their participation in skate crews to perform an alternative form of femininity. These female skate crews offer a safe haven for women and girls in cities, where they can skate and bond without male expectations or competition.\nVideo.\nThe increasing availability of technology is apparent within the skateboarding community. Many skateboarders record and edit videos of themselves and friends skateboarding. However, part of this culture is to not merely replicate but to innovate; emphasis is placed on finding new places and landing new tricks.\nVideo games.\nSkateboarding video games have also become very popular in skateboarding culture. Some of the most popular are the \"Tony Hawk\" series and \"Skate\" series for various consoles (including hand-held) and personal computer.\nSkate shoe.\nBecause early skateboarders were surfers trying to emulate the sport of surfing, many rode barefoot, which led to foot injuries. This led to the need for a shoe that was specifically designed and marketed for skateboarding, such as the Randy \"720\", manufactured by the Randolph Rubber Company, and Vans sneakers, which eventually became cultural iconic signifiers for skateboarders during the 1970s and '80s as skateboarding became more widespread. One of the early leading trends associated with the sub-culture of skateboarding itself was the sticky-soled slip-on skate shoe, most popularized by Sean Penn's skateboarding character from the 1982 film \"Fast Times at Ridgemont High\".\nWhile the skate shoes design afforded better connection and traction with the deck, skateboarders themselves could often be identified when wearing the shoes, with Tony Hawk once saying, \"If you were wearing Vans shoes in 86, you were a skateboarder\". Because of its connection with skateboarding, Vans financed the legendary skateboarding documentary \"Dogtown and Z-Boys\" and was the first sneaker company to endorse a professional skateboarder, Stacy Peralta. Vans has a long history of being a major sponsor of many skateboarding competitions and events throughout skateboarding history as well, including the Vans Warped Tour and the Vans Triple Crown Series.\nAs it eventually became more apparent that skateboarding had a particular identity with a style of shoe, other brands of shoe companies began to specifically design skate shoes for functionality and style to further enhance the experience and culture of skateboarding including such brands as; Converse, Nike, DC Shoes, Globe, Adidas, Zoo York and World Industries. Many professional skateboarders are designed a pro-model skate shoe, with their name on it, once they have received a skateboarding sponsorship after becoming notable skateboarders. Some shoe companies involved with skateboarding, like Sole Technology, an American footwear company that makes the Etnies skate shoe brand, further distinguish themselves in the market by collaborating with local cities to open public skateparks, such as the etnies Skatepark in Lake Forest, California.\nSkateboard deck.\nIndividuality and a self-expressed casual style have always been cultural values for skateboarders, as uniforms and jerseys are not typically worn. This type of personal style for skateboarders is often reflected in the graphical designs illustrated on the bottom of the deck of skateboards, since its initial conception in the mid-seventies, when Wes Humpston and Jim Muri first began doing design work for Dogtown Skateboards out of their garage by hand, creating the very first iconic skateboard-deck art with the design of the \"Dogtown Cross\".\nPrior to the mid-seventies many early skateboards were originally based upon the concept of \u201cSidewalk Surfing\u201d and were tied to the surf culture, skateboards were surfboard like in appearance with little to no graphics located under the bottom of the skateboard-deck. Some of the early manufactured skateboards such as \"Roller Derby\", the \"Duraflex Surfer\" and the \"Banana board\" are characteristic. Some skateboards during that time were manufactured with company logo's or stickers across the top of the deck of the skateboard, as griptape was not initially used for construction. But as skateboarding progressed and evolved, and as artists began to design and add influence to the artwork of skateboards, designs and themes began to change.\nThere were several artistic skateboarding pioneers that had an influence on the culture of skateboarding during the 1980s, that transformed skateboard-deck art like Jim Phillips, whose edgy comic-book style \"Screaming Hand\", not only became the main logo for Santa Cruz Skateboards, but eventually transcended into tattoos of the same image for thousands of people and vinyl collectible figurines over the years. Artist Vernon Courtlandt Johnson is said to have used his artwork of skeletons and skulls, for Powell Peralta, during the same time that the music genres of punk rock and new wave music were beginning to mesh with the culture of skateboarding. Some other notable skateboard artists that made contributions to the culture of skateboarding also include Andy Jenkins, Todd Bratrud, Neil Blender, Marc McKee, Tod Swank, Mark Gonzales, Lance Mountain, Natas Kaupas and Jim Evans.\nOver the years skateboard-deck art has continued to influence and expand the culture of skateboarding, as many people began collecting skateboards based on their artistic value and nostalgia. Productions of limited editions with particular designs and types of collectible prints that can be hung on the wall, have been created by such famous artists as Andy Warhol and Keith Haring. Most professional skateboarders today have their own signature skateboard decks, with their favorite artistic designs printed on them using computer graphics.\nHigh value and collectible skateboards.\nIn January 2019, Sotheby's in New York auctioned the full set of the 248 skateboard deck designs ever sold by Supreme, collected by Ryan Fuller. The full set sold for $800,000 to 17 year old Carson Guo from Vancouver who plans to exhibit them in a local gallery.\nNew York based SHUT Skateboards had a goldplated skateboard for sale at $15,000 in 2014, then the most expensive skateboard in the world.\nIn 2019, artist Adrian Wilson created the SUPREME Mundi, a cross between an artist palette and a skateboard as a commentary on the record bids at auction of the Supreme decks and the restored \"Salvator Mundi\" which was sold by a New York art gallery for $20,000\nSafety.\nSkateboards, along with other small-wheeled transportation such as in-line skates and scooters, suffer a safety problem: riders may easily be thrown from small cracks and outcroppings in pavement, especially where the cracks run across the direction of travel. Hitting such an irregularity is the major cause of falls and injuries. The risk may be reduced at higher travel speeds.\nSevere injuries are relatively rare. Commonly, a skateboarder who falls suffers from scrapes, cuts, bruises, and sprains. Among injuries reported to a hospital, about half involve broken bones, usually the long bones in the leg or arm. One third of skateboarders with reported injuries are very new to the sport, having started skating within one week of the injury. Although less common, involving 3.5\u20139 percent of reported injuries, traumatic head injuries and death are possible severe outcomes.\nSkating as a form of transportation exposes the skateboarder to the dangers of other traffic. Skateboarders on the street may be hit by other vehicles or may fall into vehicular traffic.\nSkateboarders also occasionally pose a risk to other pedestrians and traffic. If the skateboarder falls, the skateboard may roll or fly into another person. A skateboarder who collides with a person who is walking or biking may injure or, rarely, kill that person.\nMany jurisdictions require skateboarders to wear bicycle helmets to reduce the risk of head injuries and death. Other protective gear, such as wrist guards, also reduce injury. Some medical researchers have proposed restricting skateboarding to designated, specially designed areas, to reduce the number and severity of injuries, and to eliminate injuries caused by motor vehicles or to other pedestrians.\nThe use, ownership and sale of skateboards were forbidden in Norway from 1978 to 1989 because of the high number of injuries caused by boards. The ban led skateboarders to construct ramps in the forest and other secluded areas to avoid the police. There was, however, one legal skatepark in the country in Frogner Park in Oslo.\nOther uses and styles.\nTransportation.\nThe use of skateboards solely as a form of transportation is often associated with the longboard. Depending on local laws, using skateboards as a form of transportation outside residential areas may or may not be legal. Backers cite portability, exercise, and environmental friendliness as some of the benefits of skateboarding as an alternative to automobiles.\nMilitary.\nThe United States Marine Corps tested the usefulness of commercial off-the-shelf skateboards during urban combat military exercises in the late 1990s in a program called Urban Warrior '99. Their special purpose was \"for maneuvering inside buildings in order to detect tripwires and sniper fire\".\nTrampboarding.\nTrampboarding is a variant of skateboarding that uses a board without the trucks and the wheels on a trampoline. Using the bounce of the trampoline gives height to perform tricks, whereas in skateboarding one needs to make the height by performing an ollie. Trampboarding is seen on YouTube in numerous videos.\nSwing boarding.\nSwing boarding is the activity where a skateboard deck is suspended from a pivot point above the rider which allows the rider to swing about that pivot point. The board swings in an arc which is a similar movement to riding a half pipe. The incorporation of a harness and frame allows the rider to perform turns and spins all while flying through the air.\nControversy.\nSkateboarding damages urban terrain features such as curbs, benches, and ledges when skateboarders perform \"grinds\" and other tricks on these surfaces. Private industry has responded to this problem by using skate deterrent devices, such as the Skatestopper, in efforts to prevent further damage and to reduce skateboarding on these surfaces.\nThe enactment of ordinances and the posting of signs stating \"Skateboarding is not allowed\" have also become common methods to discourage skateboarding in public areas in many cities, to protect pedestrians and property. In the area of street skating, tickets and arrest from police for trespassing and vandalism are not uncommon.\nSkateboarding has become an important problem in Freedom Plaza, a National Park within the Pennsylvania Avenue National Historic Site in Washington, D.C. The Plaza has become a popular location for skateboarding, although the activity is illegal and has resulted in police actions. The Plaza contains copies of portions of Pierre (Peter) Charles L'Enfant's 1791 plan for the nation's capital city that have been inscribed in the park's raised marble surface. A 2016 National Park Service management plan for the Historic Site states that skateboarding has damaged stonework, sculptures, walls, benches, steps, and other surfaces in some areas of the Plaza. The management plan further states that skateboarding presents a persistent law enforcement and management challenge, as popular websites advertise the Plaza's attractiveness for the activity. The plan notes that vandals have removed \"No Skateboarding\" signs and recommends the replacement of those signs.\nA professional skateboarder promoted on Facebook the use of governmental sites for the prohibited activity during the 2013 federal government shutdown in the United States.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28028", "revid": "50436820", "url": "https://en.wikipedia.org/wiki?curid=28028", "title": "Speed skating", "text": "Competitive form of ice skating\nSpeed skating is a competitive form of ice skating in which the competitors race each other in travelling a certain distance on skates. Types of speed skating are long-track speed skating, short-track speed skating, and marathon speed skating. In the Olympic Games, long-track speed skating is usually referred to as just \"speed skating\", while short-track speed skating is known as \"short track\". The International Skating Union (ISU), the governing body of competitive ice sports, refers to long track as \"speed skating\" and short track as \"short track skating\". Long track speed skating takes place on a 400m ice track, while short track takes place on a 111m track.\nAn international federation was founded in 1892, the first for any winter sport. The sport enjoys large popularity in the Netherlands, Norway and South Korea. There are top international rinks in a number of other countries, including Canada, the United States, Germany, Italy, Japan, Russia, Kazakhstan, China, Belarus and Poland. A World Cup circuit is held with events in those countries plus two events in the Thialf ice hall in Heerenveen, Netherlands.\nOverview.\nThe standard rink for long track is 400 meters long, but tracks of 200, 250 and 333&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20443\u00a0meters are used occasionally. It is one of two Olympic forms of the sport and the one with the longer history.\nISU rules allow some leeway in the size and radius of curves.\nShort track speed skating takes place on a smaller rink, normally the size of an ice hockey rink, on a 111.12\u00a0m oval track. Distances are shorter than in long-track racing, with the longest Olympic individual race being 1500 meters (the women's relay is 3000 meters and the men's relay 5000 meters). Events are usually held with a knockout format, with the best two in heats of four or five qualifying for the final race, where medals are awarded. Disqualifications and falls are not uncommon.\nThere are variations on the mass-start races. In the regulations of roller sports, eight different types of mass starts are described. Among them are elimination races, where one or more competitors are eliminated at fixed points during the course; simple distance races, which may include preliminary races; endurance races with time limits instead of a fixed distance; points races; and individual pursuits.\nRaces usually have rules about disqualification if an opponent is unfairly hindered; these rules vary between the disciplines. In long track speed skating, almost any infringement on the pairmate is punished, though skaters are permitted to change from the inner to the outer lane out of the final curve if they are not able to hold the inner curve, as long as they are not interfering with the other skater. In mass-start races, skaters will usually be allowed some physical contact.\nTeam races are also held; in long track speed skating, the only team race at the highest level of competition is the team pursuit, though athletics-style relay races are held at children's competitions. Relay races are also held in short track and inline competitions, but here exchanges may take place at any time during the race, though exchanges may be banned during the last couple of laps.\nMost speed skating races are held on an oval course, but there are exceptions. Oval sizes vary; in short track speed skating, the rink must be an oval of 111.12 metres, while long track speed skating uses a similarly standardized 400\u00a0m rink. Inline skating rinks are between 125 and 400 metres, though banked tracks can only be 250 metres long. Inline skating can also be held on closed road courses between 400 and 1,000 metres, as well as open-road competitions where starting and finishing lines do not coincide. This is also a feature of outdoor marathons.\nIn the Netherlands, marathon competitions may be held on natural ice on canals, and bodies of water such as lakes and rivers, but may also be held on artificially frozen 400\u00a0m tracks, with skaters circling the track 100 times, for example.\nHistory.\nThe origins of speed skating date back over a millennium in the North of Europe, especially Scandinavia and the Netherlands, where the natives added bones to their shoes and used them to travel on frozen rivers, canals and lakes. Later, in Norway, King Eystein Magnusson, later King Eystein I of Norway, boasts of his skills racing on bone skates, so called \"ice legs\".\nHowever, skating and speed skating was not limited to the Netherlands and Scandinavia; in 1592, a Scotsman designed a skate with an iron blade. It was iron-bladed skates that led to the spread of skating and, in particular, speed skating.\nBy 1642, the first known skating club, The Skating Club of Edinburgh, was born, and, in 1763, the first speed skating race known in any detail was held from Wisbech to Whittlesey on the Fens in England for a prize sum of 20 guineas, won by John Lamb of Wisbech.\nWhile in the Netherlands, people began touring the waterways connecting the 11 cities of Friesland, a challenge which eventually led to the Elfstedentocht.\nThe first known speed skating competition for women was in Heerenveen, the Netherlands from 1 to 2 February 1805. The competition was won by Trijntje Pieters Westra.\nBy 1851, North Americans had discovered a love of the sport, and the all-steel blade was later developed there. In Norway speed skating also became popular, as there was a huge interest in the 1885 speed skating race at Frognerkilen between Axel Paulsen and Renke van der Zee.\nThe Netherlands came back to the fore in 1889 with the organization of the first world championships. The ISU (International Skating Union) was also born in the Netherlands in 1892.\nBy the start of the 20th century, skating and speed skating had come into its own as a major popular sporting activity.\nISU development.\nOrganized races on ice skates developed in the 19th century. Norwegian clubs hosted competitions from 1863, with races in Christiania drawing five-digit crowds. In 1884, the Norwegian Axel Paulsen was named Amateur Champion Skater of the World after winning competitions in the United States. Five years later, a sports club in Amsterdam held an ice-skating event they called a world championship, with participants from Russia, the United States and the United Kingdom, as well as the host country. The \"Internationale Eislauf Vereinigung\", now known as the International Skating Union, was founded at a meeting of 15 national representatives in Scheveningen in 1892, the first international winter sports federation. The Nederlandse Schaatsrijderbond was founded in 1882 and organised the world championships of 1890 and 1891. Competitions were held around tracks of varying lengths\u2014the 1885 match between Axel Paulsen and Remke van der Zee was skated on a track of 6/7 mile (1400 metres)\u2014but the 400 metre track was standardised by the ISU in 1892, along with the standard distances for world championships, 500\u00a0m, 1500\u00a0m, 5000\u00a0m and 10,000\u00a0m. Skaters started in pairs, each to their own lane, and changed lanes for every lap to ensure that each skater completed the same distance. This is what is now known as long track speed skating. Competitions were exclusively for amateur skaters, which was enforced. Peter Sinnerud was disqualified for professionalism in 1904 and lost his world title.\nLong track world records were first registered in imperial distances and since 1880 in metrical distances. The latter ones improved rapidly since their adoption as standard distances by the ISU, with Jaap Eden lowering the world 5000-metre record by half a minute during the Hamar European Championships in 1894. However, the record stood for 17 years, and it took over 50 years to lower it by further half a minute.\nElfstedentocht.\nThe Elfstedentocht was organized as a competition in 1909 and has been held at irregular intervals, whenever the ice on the course is deemed good enough. Other outdoor races developed later, with Friesland in the northern Netherlands hosting a race in 1917, but the Dutch natural ice conditions have rarely been conducive to skating. The Elfstedentocht has been held 15 times in the nearly 100 years since 1909, and, before artificial ice was available in 1962, national championships had been held in 25 of the years between 1887, when the first championship was held in Slikkerveer, and 1961. Since artificial ice became common in the Netherlands, Dutch speed skaters have been among the world top in long track ice skating and marathon skating. Another solution to still be able to skate marathons on natural ice became the Alternative Elfstedentocht. The Alternative Elfstedentocht races take part in other countries, such as Austria, Finland or Canada, and all top marathon skaters, as well as thousands of recreative skaters, travel from the Netherlands to the location where the race is held. According to the NRC Handelsblad journalist Jaap Bloembergen, the country \"takes a carnival look\" during international skating championships.\nOlympic Games.\nAt the 1914 Olympic Congress, the delegates agreed to include ice speed skating in the 1916 Olympics, after figure skating had featured in the 1908 Olympics. However, World War I put an end to the plans of Olympic competition, and it was not until the winter sports week in Chamonix in 1924\u2014retroactively awarded Olympic status\u2014that ice speed skating reached the Olympic programme. Charles Jewtraw from Lake Placid, New York, won the first Olympic gold medal, though several Norwegians in attendance claimed Oskar Olsen had clocked a better time. Timing issues on the 500 were a problem within the sport until electronic clocks arrived in the 1960s; during the 1936 Olympic 500\u2013metre race, it was suggested that Ivar Ballangrud's 500-metre time was almost a second too good. Finland won the remaining four gold medals at the 1924 Games, with Clas Thunberg winning 1,500 metres, 5,000 metres, and allround. It was the first and only time an allround Olympic gold medal has been awarded in speed skating. Speed Skating is also a sport in today's Olympics.\nNorwegian and Finnish skaters won all the gold medals in world championships between the world wars, with Latvians and Austrians visiting the podium in the European Championships. However, North American races were usually conducted pack-style, similar to the marathon races in the Netherlands, but the Olympic races were to be held over the four ISU-approved distances. The ISU approved the suggestion that the speed skating at the 1932 Winter Olympics should be held as pack-style races, and Americans won all four gold medals. Canada won five medals, all silver and bronze, while defending World Champion Clas Thunberg stayed at home, protesting against this form of racing. At the World Championships held immediately after the games, without the American champions, Norwegian racers won all four distances and occupied the three top spots in the allround standings.\nNorwegians, Swedes, Finns, and Japanese skating leaders protested to the USOC, condemning the manner of competition and expressing the wish that mass-start races were never to be held again at the Olympics. However, the ISU adopted the short track speed skating branch, with mass-start races on shorter tracks, in 1967, arranged international competitions from 1976, and brought them back to the Olympics in 1992.\nTechnical developments.\nArtificial ices entered the long track competitions with the 1960 Winter Olympics, and the competitions in 1956 on Lake Misurina were the last Olympic competitions on natural ice. 1960 also saw the first Winter Olympic competitions for women. Lidia Skoblikova won two gold medals in 1960 and four in 1964.\nMore aerodynamic skating suits were also developed, with Swiss skater Franz Krienb\u00fchl (who finished 8th on the Olympic 10,000\u00a0m at the age of 46) at the front of development. After a while, national teams took over development of bodysuits, which are also used in short track skating, though without headcover attached to the suit\u2014short trackers wear helmets instead, as falls are more common in mass-start races. Suits and indoor skating, as well as the clap skate, has helped to lower long track world records considerably; from 1971 to 2009, the average speed on the men's 1500 metres has been raised from 45 to 52\u00a0km/h. Similar speed increases are shown in the other distances.\nProfessionalism.\nAfter the 1972 season, European long track skaters founded a professional league, International Speedskating League, which included Ard Schenk, three-time Olympic gold medallist in 1972, as well as five Norwegians, four other Dutchmen, three Swedes, and a few other skaters. Jonny Nilsson, 1963 world champion and Olympic gold medallist, was the driving force behind the league, which folded in 1974 for economic reasons, and the ISU also excluded tracks hosting professional races from future international championships. The ISU later organised its own World Cup circuit with monetary prizes, and full-time professional teams developed in the Netherlands during the 1990s, which led them to a dominance on the men's side only challenged by Japanese 500\u00a0m racers and American inline skaters who changed to long tracks to win Olympic gold.\nNorth American professionals.\nDuring the 20th century, roller skating also developed as a competitive sport. Roller-skating races were professional from an early stage. Professional World Championships were arranged in North America between the competitors on that circuit. Later, roller derby leagues appeared, a professional contact sport that originally was a form of racing. FIRS World Championships of inline speed skating go back to the 1980s, but many world champions, such as Derek Parra and Chad Hedrick, have switched to ice in order to win Olympic medals.\nLike roller skating, ice speed skating was also professional in North America. Oscar Mathisen, five-time ISU world champion and three-time European champion, renounced his amateur status in 1916 and travelled to America, where he won many races but was beaten by Bobby McLean of Chicago, four-time American champion, in one of the races. Chicago was a centre of ice speed skating in America; the \"Chicago Tribune\" sponsored a competition called the Silver Skates from 1912 to 2014.\nShort track enters the Olympics.\nIn 1992, short track speed skating was accepted as an Olympic sport. Short track speed skating had little following in the long track speed skating countries of Europe, such as Norway, the Netherlands and the former Soviet Union, with none of these nations having won official medals (though the Netherlands won two gold medals when the sport was a demonstration event in 1988). The Norwegian publication \"Sportsboken\" spent ten pages detailing the long track speed skating events at the Albertville Games in 1993, but short track was not mentioned by word, though the results pages appeared in that section.\nAlthough this form of speed skating is newer, it is growing faster than long-track speed skating, largely because short track can be done on an ice hockey rink rather than a long-track oval.\nRules.\nShort track.\nRaces are run counter-clockwise on a 111-meter track. Short track races are almost always run in a mass start format in which two to six skaters may race at once. Skaters may be disqualified for false starts, impeding, and cutting inside the track. False starts occur when a skater moves before the gun goes off at the start of a race. Skaters are disqualified for impeding when one skater cuts in front of another skater and causes the first skater to stand up to avoid collision or fall. Cutting inside the track occurs when a skater's skates goes inside the blocks which mark the track on the ice. If disqualified the skater will be given last place in their heat or final.\nLong track.\nRaces are run counter-clockwise on a 400-meter oval. In all individual competition forms, only two skaters are allowed to race at once. Skaters must change lanes every lap. The skater changing from the outside lane to the inside has right-of-way. Skaters may be disqualified for false starts, impeding, and cutting inside the track. If a skater misses their race or falls they have the option to race their distance again. There are no heats or finals in long track, all rankings are by time.\nThe starting procedure in long-track speed skating consists of three parts. First, the referee tells the athletes to \"Go to the start\". Second, the referee cues the athletes to get \"Ready\", and waits until the skaters have stopped moving. Finally, the referee waits for a random duration between 1 and 1.5 seconds, and then fires the starting shot. Some argue that this inherent timing variability could disadvantage athletes that start after longer pauses, due to the alerting effect.\nIn the only non-individual competition form, the team pursuit, two teams of each three to four skaters are allowed to race at once. Both teams remain in the inner lane for the duration of the race; they start on opposite sides of the rink. If four skaters are racing one skater is allowed to drop off and stop racing. The clock stops when the third skater crosses the finish line.\nTeam pursuit.\nThe team pursuit is a team event in speed skating and is skated by teams of three skaters. Races resemble the team pursuit event in track cycling. Two teams race at a time, starting at a line in the middle of the straightaway. One team starts on each side of the track. Only the inner lane is used. The distance is eight laps for men and six for women. The team's time is the third skater to cross the finish line.\nThere are several formats for the team pursuit. The Olympic format is unusual in that it is a cup format, with several rounds of exclusion between two teams. In the World Cup and World Championships, one race is skated and the teams are ranked by their finishing time. In the Olympic format, a team that overtakes the other has automatically won the race and the remaining distance is not skated. In practice, the distance is so short that this rarely happens unless one team has a fall.\nThe team pursuit is a new event in major international competitions. The event was introduced at international level at the world junior championships around the turn of the millennium, and to the World Cup in 2003, but it was not considered an official ISU event until around 2004, and eventually introduced at the Olympics in 2006.\nEquipment.\nSpeed skates Speed skates differ greatly from hockey skates and figure skates. Unlike hockey skates and figure skates, speed skates cut off at the ankle and are built more like a shoe than a boot to allow for more ankle compression. The blades range in length from 30 to 45\u00a0cm depending on the age and height of the skater. Short track blades are fixed to the boot in at the heel and immediately behind the ball of the foot. Long track skates, also called clap skates, attach to a hinge at the front of the boot. The heel of the boot detaches from the blade on every stroke, through a spring mechanism located at the front connector. This extends the skater's stroke by keeping the blade on the ice longer. Speed skates are manually sharpened using a jig to hold them in place.\nShort track\nAll short track skaters must have speed skates, a spandex skin suit, protective helmet, specific cut proof skating gloves, knee pads and shin pads (in suit), neck guard (bib style) and ankle protection. Protective eyewear is mandatory. Many skaters wear smooth ceramic or carbon fiber tips on the left hand glove to reduce friction when their hand is on the ice at corners. All skaters who race at a national level must wear a cutproof kevlar suit to protect against being cut from another skater's blade.\nLong track\nFor long track skaters the same equipment should be worn as short track racers but with the exception of a helmet, shin pads, knee pads, and neck guard which are not required; along with their blades. Long track skaters skate on what are called \"clap blades\". These blades have hinges under the boot towards the back. It is described in more detail above. Protective eyewear is not mandatory. The suit also does not need to be kevlar. Long track skaters wear a hood that is built into the suit.\nSkate Sharpening\nTo sharpen their skates, skaters must place their skates on a jig and move diamond or stone stones back and forth. The diamond stones will have different colors that will be assigned to them depending on how much they eat into the blade, black as the one that affects the blades the most and gold as the one that affects the least.\nReferences and notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28029", "revid": "8005368", "url": "https://en.wikipedia.org/wiki?curid=28029", "title": "Stephen Biko", "text": ""}
{"id": "28030", "revid": "24013162", "url": "https://en.wikipedia.org/wiki?curid=28030", "title": "September 13", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearSeptember 13 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28032", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=28032", "title": "Square (disambiguation)", "text": "A square is a regular quadrilateral with four equal sides and four right angles.\nSquare or Squares may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "28034", "revid": "199747", "url": "https://en.wikipedia.org/wiki?curid=28034", "title": "Scanning electron microscope", "text": "Electron microscope where a small beam is scanned across a sample\nA scanning electron microscope (SEM) is a type of electron microscope that produces images of a sample by scanning the surface with a focused beam of electrons. The electrons interact with atoms in the sample, producing various signals that contain information about the surface topography and composition. The electron beam is scanned in a raster scan pattern, and the position of the beam is combined with the intensity of the detected signal to produce an image. In the most common SEM mode, secondary electrons emitted by atoms excited by the electron beam are detected using a secondary electron detector (Everhart\u2013Thornley detector). The number of secondary electrons that can be detected, and thus the signal intensity, depends, among other things, on specimen topography. Some SEMs can achieve resolutions better than 1 nanometer.\nSpecimens are observed in high vacuum in a conventional SEM, or in low vacuum or wet conditions in a variable pressure or environmental SEM, and at a wide range of cryogenic or elevated temperatures with specialized instruments.\nHistory.\nAn account of the early history of scanning electron microscopy has been presented by McMullan. Although Max Knoll produced a photo with a 50\u00a0mm object-field-width showing channeling contrast by the use of an electron beam scanner, it was Manfred von Ardenne who in 1937 invented a microscope with high resolution by scanning a very small raster with a demagnified and finely focused electron beam. In the same year, Cecil E. Hall also completed the construction of the first emission microscope in North America, just two years after being tasked by his supervisor, E. F. Burton at the University of Toronto. Ardenne applied scanning of the electron beam in an attempt to surpass the resolution of the transmission electron microscope (TEM), as well as to mitigate substantial problems with chromatic aberration inherent to real imaging in the TEM. He further discussed the various detection modes, possibilities and theory of SEM, together with the construction of the . Further work was reported by Zworykin's group, followed by the Cambridge groups in the 1950s and early 1960s headed by Charles Oatley, all of which finally led to the marketing of the first commercial instrument by Cambridge Scientific Instrument Company as the \"Stereoscan\" in 1965, which was delivered to DuPont.\nPrinciples and capacities.\nThe signals used by an SEM to make an image result from interactions between the electron beam and atoms at various depths within the sample. Various types of signals are produced including secondary electrons (SE), reflected or back-scattered electrons (BSE), characteristic X-rays and light (cathodoluminescence) (CL), absorbed current (specimen current) and transmitted electrons. Secondary electron detectors are standard equipment in all SEMs, but it is rare for a single machine to have detectors for all other possible signals.\nSecondary electrons have very low energies on the order of 50 eV, which limits their mean free path in solid matter. Consequently, SEs can only escape from the top few nanometers of the surface of a sample. The signal from secondary electrons tends to be highly localized at the point of impact of the primary electron beam, making it possible to collect images of the sample surface with a resolution of below 1 nm. Back-scattered electrons (BSE) are beam electrons that are reflected from the sample by elastic scattering. Since they have much higher energy than SEs, they emerge from deeper locations within the specimen and, consequently, the resolution of BSE images is less than SE images. However, BSE are often used in analytical SEM, along with the spectra made from the characteristic X-rays, because the intensity of the BSE signal is strongly related to the atomic number (Z) of the specimen. BSE images can provide information about the distribution, but not the identity, of different elements in the sample. In samples predominantly composed of light elements, such as biological specimens, BSE imaging can image colloidal gold immuno-labels of 5\u00a0or\u00a010\u00a0nm diameter, which would otherwise be difficult or impossible to detect in secondary electron images. Characteristic X-rays are emitted when the electron beam removes an inner shell electron from the sample, causing a higher-energy electron to fill the shell and release energy. The energy or wavelength of these characteristic X-rays can be measured by Energy-dispersive X-ray spectroscopy or Wavelength-dispersive X-ray spectroscopy and used to identify and measure the abundance of elements in the sample and map their distribution.\nDue to the very narrow electron beam, SEM micrographs have a large depth of field yielding a characteristic three-dimensional appearance useful for understanding the surface structure of a sample. This is exemplified by the micrograph of pollen shown above. A wide range of magnifications is possible, from about 10 times (about equivalent to that of a powerful hand-lens) to more than 500,000 times, about 250 times the magnification limit of the best light microscopes.\nSample preparation.\nSEM samples have to be small enough to fit on the specimen stage, and may need special preparation to increase their electrical conductivity and to stabilize them, so that they can withstand the high vacuum conditions and the high energy beam of electrons. Samples are generally mounted rigidly on a specimen holder or stub using a conductive adhesive. SEM is used extensively for defect analysis of semiconductor wafers, and manufacturers make instruments that can examine any part of a 300\u00a0mm semiconductor wafer. Many instruments have chambers that can tilt an object of that size to 45\u00b0 and provide continuous 360\u00b0 rotation.\nNonconductive specimens collect charge when scanned by the electron beam, and especially in secondary electron imaging mode, this causes scanning faults and other image artifacts. For conventional imaging in the SEM, specimens must be electrically conductive, at least at the surface, and electrically grounded to prevent the accumulation of electrostatic charge. Metal objects require little special preparation for SEM except for cleaning and conductively mounting to a specimen stub. Non-conducting materials are usually coated with an ultrathin coating of electrically conducting material, deposited on the sample either by low-vacuum sputter coating, electroless deposition or by high-vacuum evaporation. Conductive materials in current use for specimen coating include gold, gold/palladium alloy, platinum, iridium, tungsten, chromium, osmium, and graphite. Coating with heavy metals may increase signal/noise ratio for samples of low atomic number (Z). The improvement arises because secondary electron emission for high-Z materials is enhanced.\nAn alternative to coating for some biological samples is to increase the bulk conductivity of the material by impregnation with osmium using variants of the OTO staining method (O-osmium tetroxide, T-thiocarbohydrazide, O-osmium).\nNonconducting specimens may be imaged without coating using an environmental SEM (ESEM) or low-voltage mode of SEM operation. In ESEM instruments the specimen is placed in a relatively high-pressure chamber and the electron optical column is differentially pumped to keep vacuum adequately low at the electron gun. The high-pressure region around the sample in the ESEM neutralizes charge and provides an amplification of the secondary electron signal. Low-voltage SEM is typically conducted in an instrument with a field emission guns (FEG) which is capable of producing high primary electron brightness and small spot size even at low accelerating potentials. To prevent charging of non-conductive specimens, operating conditions must be adjusted such that the incoming beam current is equal to sum of outgoing secondary and backscattered electron currents, a condition that is most often met at accelerating voltages of 0.3\u20134 kV.\nEmbedding in a resin with further polishing to a mirror-like finish can be used for both biological and materials specimens when imaging in backscattered electrons or when doing quantitative X-ray microanalysis.\nThe main preparation techniques are not required in the environmental SEM outlined below, but some biological specimens can benefit from fixation.\nBiological samples.\nSince the SEM specimen chamber is under high vacuum, a SEM specimen must be completely dry or cryogenically cooled. Hard, dry materials such as wood, bone, feathers, dried insects, or shells (including egg shells) can be examined with little further treatment, but living cells and tissues and whole, soft-bodied organisms require chemical fixation to preserve and stabilize their structure.\nFixation is usually performed by incubation in a solution of a buffered chemical fixative, such as glutaraldehyde, sometimes in combination with formaldehyde and other fixatives, and optionally followed by postfixation with osmium tetroxide. The fixed tissue is then dehydrated. Because air-drying causes collapse and shrinkage, this is commonly achieved by replacement of water in the cells with organic solvents such as ethanol or acetone, and replacement of these solvents in turn with a transitional fluid such as liquid carbon dioxide by critical point drying. The carbon dioxide is finally removed while in a supercritical state, so that no gas\u2013liquid interface is present within the sample during drying.\nThe dry specimen is usually mounted on a specimen stub using an adhesive such as epoxy resin or electrically conductive double-sided adhesive tape, and sputter-coated with gold or gold/palladium alloy before examination in the microscope. Samples may be sectioned (with a microtome) if information about the organism's internal ultrastructure is to be exposed for imaging.\nIf the SEM is equipped with a cold stage for cryo microscopy, cryofixation may be used and low-temperature scanning electron microscopy performed on the cryogenically fixed specimens. Cryo-fixed specimens may be cryo-fractured under vacuum in a special apparatus to reveal internal structure, sputter-coated and transferred onto the SEM cryo-stage while still frozen. Low-temperature scanning electron microscopy (LT-SEM) is also applicable to the imaging of temperature-sensitive materials such as ice and fats.\nFreeze-fracturing, freeze-etch or freeze-and-break is a preparation method particularly useful for examining lipid membranes and their incorporated proteins in \"face on\" view. The preparation method reveals the proteins embedded in the lipid bilayer.\nMaterials.\nBack-scattered electron imaging, quantitative X-ray analysis, and X-ray mapping of specimens often requires grinding and polishing the surfaces to an ultra-smooth surface. Specimens that undergo WDS or EDS analysis are often carbon-coated. In general, metals are not coated prior to imaging in the SEM because they are conductive and provide their own pathway to ground. Fractography is the study of fractured surfaces that can be done on a light microscope or, commonly, on an SEM. The fractured surface is cut to a suitable size, cleaned of any organic residues, and mounted on a specimen holder for viewing in the SEM. Integrated circuits may be cut with a focused ion beam (FIB) or other ion beam milling instrument for viewing in the SEM. The SEM in the first case may be incorporated into the FIB, enabling high-resolution imaging of the result of the process. Metals, geological specimens, and integrated circuits all may also be chemically polished for viewing in the SEM. Special high-resolution coating techniques are required for high-magnification imaging of inorganic thin films.\nScanning process and image formation.\nIn a typical SEM, an electron beam is thermionically emitted from an electron gun fitted with a tungsten filament cathode. Tungsten is normally used in thermionic electron guns because it has the highest melting point and lowest vapor pressure of all metals, thereby allowing it to be electrically heated for electron emission, and because of its low cost. Other types of electron emitters include lanthanum hexaboride (LaB6) cathodes, which can be used in a standard tungsten filament SEM if the vacuum system is upgraded, or field emission guns (FEG), which may be of the cold-cathode type using tungsten single crystal emitters or the thermally assisted Schottky type, that use emitters of tungsten single crystals coated in zirconium oxide.\nThe electron beam, which typically has an energy ranging from 0.2 keV to 40 keV, is focused by one or two condenser lenses to a spot about 0.4\u00a0nm to 5\u00a0nm in diameter. The beam passes through pairs of scanning coils or pairs of deflector plates in the electron column, typically in the final lens, which deflect the beam in the \"x\" and \"y\" axes so that it scans in a raster fashion over a rectangular area of the sample surface.\nWhen the primary electron beam interacts with the sample, the electrons lose energy by repeated random scattering and absorption within a teardrop-shaped volume of the specimen known as the interaction volume, which extends from less than 100\u00a0nm to approximately 5\u00a0\u03bcm into the surface. The size of the interaction volume depends on the electron's landing energy, the atomic number of the specimen, and the specimen's density. The energy exchange between the electron beam and the sample results in the reflection of high-energy electrons by elastic scattering, the emission of secondary electrons by inelastic scattering, and the emission of electromagnetic radiation, each of which can be detected by specialized detectors. The beam current absorbed by the specimen can also be detected and used to create images of the distribution of specimen current. Electronic amplifiers of various types are used to amplify the signals, which are displayed as variations in brightness on a computer monitor (or, for vintage models, on a cathode-ray tube). Each pixel of computer video memory is synchronized with the position of the beam on the specimen in the microscope, and the resulting image is, therefore, a distribution map of the intensity of the signal being emitted from the scanned area of the specimen. Older microscopes captured images on film, but most modern instruments collect digital images.\nMagnification.\nMagnification in an SEM can be controlled over a range of about 6 orders of magnitude from about 10 to 3,000,000 times. Unlike optical and transmission electron microscopes, image magnification in an SEM is not a function of the power of the objective lens. SEMs may have condenser and objective lenses, but their function is to focus the beam to a spot, and not to image the specimen. Provided the electron gun can generate a beam with a sufficiently small diameter, an SEM could in principle work entirely without condenser or objective lenses. However, it might not be very versatile or achieve very high resolution. In an SEM, as in scanning probe microscopy, magnification results from the ratio of the raster on the display device and dimensions of the raster on the specimen. Assuming that the display screen has a fixed size, higher magnification results from reducing the size of the raster on the specimen, and vice versa. Magnification is therefore controlled by the current supplied to the x, y scanning coils, or the voltage supplied to the x, y deflector plates, and not by objective lens power.\nDetection of secondary electrons.\nThe most common imaging mode collects low-energy (&lt;50 eV) secondary electrons that are ejected from conduction or valence bands of the specimen atoms by inelastic scattering interactions with beam electrons. Due to their low energy, these electrons originate from within a few nanometers below the sample surface. The electrons are detected by an Everhart\u2013Thornley detector, which is a type of collector-scintillator-photomultiplier system. The secondary electrons are first collected by attracting them towards an electrically biased grid at about +400 V, and then further accelerated towards a phosphor or thin scintillator positively biased to about 2-10 kV. The accelerated secondary electrons are now sufficiently energetic to cause the scintillator to emit flashes of light (cathodoluminescence), which are conducted to a photomultiplier outside the SEM column via a light pipe and a window in the wall of the specimen chamber. The amplified electrical signal output by the photomultiplier is displayed as a two-dimensional intensity distribution that can be viewed and photographed on an analogue video display, or subjected to analog-to-digital conversion and displayed and saved as a digital image. This process relies on a raster-scanned primary beam. The brightness of the signal depends on the number of secondary electrons reaching the detector. If the beam enters the sample perpendicular to the surface, then the activated region is uniform about the axis of the beam and a certain number of electrons \"escape\" from within the sample. As the angle of incidence increases, the interaction volume increases and the \"escape\" distance of one side of the beam decreases, resulting in more secondary electrons being emitted from the sample. Thus steep surfaces and edges tend to be brighter than flat surfaces, which results in images with a well-defined, three-dimensional appearance. Using the signal of secondary electrons image resolution less than 0.5\u00a0nm is possible.\nDetection of backscattered electrons.\nBackscattered electrons (BSE) consist of high-energy electrons originating in the electron beam, that are reflected or back-scattered out of the specimen interaction volume by elastic scattering interactions with specimen atoms. Since heavy elements (high atomic number) backscatter electrons more strongly than light elements (low atomic number), and thus appear brighter in the image, BSEs are used to detect contrast between areas with different chemical compositions. The Everhart\u2013Thornley detector, which is normally positioned to one side of the specimen, is inefficient for the detection of backscattered electrons because few such electrons are emitted in the solid angle subtended by the detector, and because the positively biased detection grid has little ability to attract the higher energy BSE. Dedicated backscattered electron detectors are positioned above the sample in a \"doughnut\" type arrangement, concentric with the electron beam, maximizing the solid angle of collection. BSE detectors are usually either of scintillator or of semiconductor types. When all parts of the detector are used to collect electrons symmetrically about the beam, atomic number contrast is produced. However, strong topographic contrast is produced by collecting back-scattered electrons from one side above the specimen using an asymmetrical, directional BSE detector; the resulting contrast appears as illumination of the topography from that side. Semiconductor detectors can be made in radial segments that can be switched in or out to control the type of contrast produced and its directionality.\nBackscattered electrons can also be used to form an electron backscatter diffraction (EBSD) image that can be used to determine the crystallographic structure of the specimen.\nBeam-injection analysis of semiconductors.\nThe nature of the SEM's probe, energetic electrons, makes it uniquely suited to examining the optical and electronic properties of semiconductor materials. The high-energy electrons from the SEM beam will inject charge carriers into the semiconductor. Thus, beam electrons lose energy by promoting electrons from the valence band into the conduction band, leaving behind holes.\nIn a direct bandgap material, recombination of these electron-hole pairs will result in cathodoluminescence; if the sample contains an internal electric field, such as is present at a p-n junction, the SEM beam injection of carriers will cause electron beam induced current (EBIC) to flow. Cathodoluminescence and EBIC are referred to as \"beam-injection\" techniques, and are very powerful probes of the optoelectronic behavior of semiconductors, in particular for studying nanoscale features and defects.\nCathodoluminescence.\nCathodoluminescence, the emission of light when atoms excited by high-energy electrons return to their ground state, is analogous to UV-induced fluorescence, and some materials such as zinc sulfide and some fluorescent dyes, exhibit both phenomena. Over the last decades, cathodoluminescence was most commonly experienced as the light emission from the inner surface of the cathode-ray tube in television sets and computer CRT monitors. In the SEM, CL detectors either collect all light emitted by the specimen or can analyse the wavelengths emitted by the specimen and display an emission spectrum or an image of the distribution of cathodoluminescence emitted by the specimen in real color.\nX-ray microanalysis.\nCharacteristic X-rays that are produced by the interaction of electrons with the sample may also be detected in an SEM equipped for energy-dispersive X-ray spectroscopy or wavelength dispersive X-ray spectroscopy. Analysis of the x-ray signals may be used to map the distribution and estimate the abundance of elements in the sample.\nComplementary techniques.\nMany SEM-based research studies are supported by complementary nanoscale techniques such as atomic force microscopy (AFM) and its electrical imaging modes. These methods provide insights that go beyond surface morphology. For example, AFM can probe the sample's surface topography at the nanometer scale using a sharp tip in contact or tapping mode. Conductive AFM (C-AFM) enables mapping of local electrical conductivity, useful in studying resistive switching materials and semiconductors. Kelvin probe force microscopy (KPFM) measures surface potential variations, which is valuable for analyzing charge distributions in electronic or photovoltaic materials. When used alongside SEM, these techniques offer a comprehensive understanding of both structural and functional properties of materials.\nResolution of the SEM.\nA SEM is not a camera and the detector is not continuously image-forming like a CCD array or film. Unlike in an optical system, the resolution is not limited by the diffraction limit, fineness of lenses or mirrors or detector array resolution. The focusing optics can be large and coarse, and the SE detector is fist-sized and simply detects current. Instead, the spatial resolution of the SEM depends on the size of the electron spot, which in turn depends on both the wavelength of the electrons and the electron-optical system that produces the scanning beam. The resolution is also limited by the size of the interaction volume, the volume of specimen material that interacts with the electron beam. The spot size and the interaction volume are both large compared to the distances between atoms, so the resolution of the SEM is not high enough to image individual atoms, as is possible with a transmission electron microscope (TEM). The SEM has compensating advantages, though, including the ability to image a comparatively large area of the specimen; the ability to image bulk materials (not just thin films or foils); and the variety of analytical modes available for measuring the composition and properties of the specimen. Depending on the instrument, the resolution can fall somewhere between less than 1\u00a0nm and 20\u00a0nm. As of 2009, The world's highest resolution conventional (\u226430\u00a0kV) SEM can reach a point resolution of 0.4\u00a0nm using a secondary electron detector.\nEnvironmental SEM.\nConventional SEM requires samples to be imaged under vacuum, because a gas atmosphere rapidly spreads and attenuates electron beams. As a consequence, samples that produce a significant amount of vapour, e.g. wet biological samples or oil-bearing rock, must be either dried or cryogenically frozen. Processes involving phase transitions, such as the drying of adhesives or melting of alloys, liquid transport, chemical reactions, and solid-air-gas systems, in general cannot be observed with conventional high-vacuum SEM. In environmental SEM (ESEM), the chamber is evacuated of air, but water vapor is retained near its saturation pressure, and the residual pressure remains relatively high. This allows the analysis of samples containing water or other volatile substances. With ESEM, observations of living insects have been possible.\nThe first commercial development of the ESEM in the late 1980s allowed samples to be observed in low-pressure gaseous environments (e.g. 1\u201350 Torr or 0.1\u20136.7\u00a0kPa) and high relative humidity (up to 100%). This was made possible by the development of a secondary-electron detector capable of operating in the presence of water vapour and by the use of pressure-limiting apertures with differential pumping in the path of the electron beam to separate the vacuum region (around the gun and lenses) from the sample chamber. The first commercial ESEMs were produced by the ElectroScan Corporation in USA in 1988. ElectroScan was taken over by Philips (who later sold their electron-optics division to FEI Company) in 1996.\nESEM is especially useful for non-metallic and biological materials because coating with carbon or gold is unnecessary. Uncoated plastics and elastomers can be routinely examined, as can uncoated biological samples. This is useful because coating can be difficult to reverse, may conceal small features on the surface of the sample and may reduce the value of the results obtained. X-ray analysis is difficult with a coating of a heavy metal, so carbon coatings are routinely used in conventional SEMs, but ESEM makes it possible to perform X-ray microanalysis on uncoated non-conductive specimens; however some specific for ESEM artifacts are introduced in X-ray analysis. ESEM may be the preferred for electron microscopy of unique samples from criminal or civil actions, where forensic analysis may need to be repeated by several different experts. It is possible to study specimens in liquid with ESEM or with other liquid-phase electron microscopy methods.\nTransmission SEM.\nThe SEM can also be used in transmission mode by simply incorporating an appropriate detector below a thin specimen section. Detectors are available for bright field, dark field, as well as segmented detectors for mid-field to high angle annular dark-field. Despite the difference in instrumentation, this technique is still commonly referred to as scanning transmission electron microscopy (STEM).\nSEM in forensic science.\nThe SEM is used often in Forensic Science for magnified analysis of microscopic things such as diatoms and gunshot residue. Because SEM is a nondestructive force on the sample, it can be used to analyze evidence without damaging it. The SEM shoots a beam of high energy electrons to the sample which bounce off of the sample without changing or destroying it. This is great when it comes to analyzing diatoms. When a person dies by drowning, they inhale the water which causes what is in the water (diatoms) to get in the blood stream, brain, kidneys, and more. These diatoms in the body can be magnified with the SEM to determine the type of diatoms which aid in understanding how and where the person died. By using the images produced by the SEM, forensic scientists can compare diatoms types to confirm the body of water a person died in.\nGunshot residue (GSR) analysis can be done with many different analytical instruments, but SEM is a common way to analyze inorganic compounds because of the way it can closely analyze the types of elements (mostly metals) through its three detectors: backscatter electron detector, secondary electron detector, and X-ray detector. GSR can be collected from the crime scene, victim, or shooter and analyzed with the SEM. This can help scientists determine proximity and or contact with the discharged firearm.\nColor in SEM.\nElectron microscopes do not naturally produce color images. A secondary electron detector produces a single value per pixel that corresponds to the number of electrons received by the detector during the short period of time when the beam is targeted to the (x,\u00a0y) pixel position. For each pixel, this single value is represented by a grey level, forming a monochrome image. However, several methods can used to get color electron microscopy images.\nFalse color using a single detector.\nThe easiest way to get color is to replace each grey level with an arbitrary color, using a color look-up table. This method is known as false color imaging and can help to distinguish phases of the sample with similar properties or composition.\nAs an alternative to simply replacing each grey level by a color, a sample observed by an oblique beam allows researchers to create an approximative topography image (see further section \"Photometric 3D rendering from a single SEM image\"). Such topography can then be processed by 3D-rendering algorithms for a more natural rendering of the surface texture.\nSEM image coloring.\nVery often, published SEM images are artificially colored. This may be done for aesthetic effect, to clarify structure or to add a realistic appearance to the sample and generally does not add information about the specimen.\nColoring may be performed manually with photo-editing software, or semi-automatically with dedicated software using feature-detection or object-oriented segmentation. \nAlternately, when additional information from other detectors like EDX, EBSD, ECCI or cathodoluminescence is available, it can be merged as color channel(s) to provide rich material information in a single, high-resolution image.\nColor built using multiple electron detectors.\nIn some configurations more information is gathered per pixel, often by the use of multiple detectors.\nAs a common example, secondary electron and backscattered electron detectors are superimposed and a color is assigned to each of the images captured by each detector, with a result of a combined color image where colors are related to the density of the components. This method is known as density-dependent color SEM (DDC-SEM). Micrographs produced by DDC-SEM retain topographical information, which is better captured by the secondary electrons detector and combine it to the information about density, obtained by the backscattered electron detector.\nAnalytical signals based on generated photons.\nMeasurement of the energy of photons emitted from the specimen is a common method to get analytical capabilities. Examples are the energy-dispersive X-ray spectroscopy (EDS) detectors used in elemental analysis and cathodoluminescence microscope (CL) systems that analyse the intensity and spectrum of electron-induced luminescence in (for example) geological specimens. In SEM systems using these detectors it is common to color code these extra signals and superimpose them in a single color image, so that differences in the distribution of the various components of the specimen can be seen clearly and compared. Optionally, the standard secondary electron image can be merged with the one or more compositional channels, so that the specimen's structure and composition can be compared. Such images can be made while maintaining the full integrity of the original signal data, which is not modified in any way.\n3D in SEM.\nSEMs do not naturally provide 3D images contrary to SPMs. However 3D data can be obtained using an SEM with different methods as follows.\nPhotometric 3D SEM reconstruction from a four-quadrant detector by \"shape from shading\".\nThis method typically uses a four-quadrant BSE detector (alternatively for one manufacturer, a 3-segment detector). The microscope produces four images of the same specimen at the same time, so no tilt of the sample is required. The method gives metrological 3D dimensions as far as the slope of the specimen remains reasonable. Most SEM manufacturers now (2018) offer such a built-in or optional four-quadrant BSE detector, together with proprietary software to calculate a 3D image in real time.\nOther approaches use more sophisticated (and sometimes GPU-intensive) methods like the optimal estimation algorithm and offer much better results at the cost of high demands on computing power.\nIn all instances, this approach works by integration of the slope, so vertical slopes and overhangs are ignored; for instance, if an entire sphere lies on a flat, little more than the upper hemisphere is seen emerging above the flat, resulting in wrong altitude of the sphere apex. The prominence of this effect depends on the angle of the BSE detectors with respect to the sample, but these detectors are usually situated around (and close to) the electron beam, so this effect is very common.\nPhotometric 3D rendering from a single SEM image.\nThis method requires an SEM image obtained in oblique low angle lighting. The grey-level is then interpreted as the slope, and the slope integrated to restore the specimen topography. This method is interesting for visual enhancement and the detection of the shape and position of objects; however the vertical heights cannot usually be calibrated, contrary to other methods such as photogrammetry.\nApplications of 3D SEM.\nOne possible application is measuring the roughness of ice crystals. This method can combine variable-pressure environmental SEM and the 3D capabilities of the SEM to measure roughness on individual ice crystal facets, convert it into a computer model and run further statistical analysis on the model. Other measurements include fractal dimension, examining fracture surface of metals, characterization of materials, corrosion measurement, and dimensional measurements at the nano scale (step height, volume, angle, flatness, bearing ratio, coplanarity, etc.).\nSEM is also used by art conservationists to discern threats to paintings' surface stability due to aging, such as the formations of complexes of zinc ions with fatty acids. Forensic scientists use SEM to detect art forgeries.\nGallery of SEM images.\nThe following are examples of images taken using an SEM.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28042", "revid": "7009628", "url": "https://en.wikipedia.org/wiki?curid=28042", "title": "Relief funds created in reaction to the September 11, 2001 Terrorist Attacks", "text": ""}
{"id": "28043", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=28043", "title": "September 11, 2001 Terrorist Attack/Misinformation", "text": ""}
{"id": "28044", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=28044", "title": "Timeline of the September 11 attacks", "text": "The following timeline is a chronological list of all the major events leading up to, during, and immediately following the September 11 attacks against the United States in 2001, through the first anniversary of the attacks in 2002.\nSeptember 11, 2001.\nAll times are in local time (EDT or UTC\u22124).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28045", "revid": "2842084", "url": "https://en.wikipedia.org/wiki?curid=28045", "title": "Hijackers in the September 11 attacks", "text": "The aircraft hijackers in the September 11 attacks were 19 men affiliated with al-Qaeda, a jihadist organization based in Afghanistan. They hailed from four countries; 15 of them were citizens of Saudi Arabia, two were from the United Arab Emirates, one was from Egypt, and one from Lebanon. To carry out the attacks, the hijackers were organized into four teams each led by a pilot-trained hijacker who would commandeer the flight with three or four \"muscle hijackers\" who were trained to help subdue the pilots, passengers, and crew. Each team was assigned to a different flight and given a unique target to crash their respective planes into. Mohamed Atta was the assigned ringleader over all four groups.\nThe first hijackers to arrive in the United States were Khalid al-Mihdhar and Nawaf al-Hazmi, who settled in San Diego County, California, in January 2000. They were followed by three hijacker-pilots, Hamburg cell members Mohamed Atta, Marwan al-Shehhi, and Ziad Jarrah in mid-2000 to undertake flight training at Huffman Aviation flight-training school in Venice, Florida. The fourth hijacker-pilot, Hani Hanjour, who was not a member of the Hamburg cell, arrived in San Diego in December 2000. The rest of the \"muscle hijackers\" arrived in early- and mid-2001.\nSelection.\nKhalid al-Mihdhar and Nawaf al-Hazmi were both experienced and respected jihadists in the eyes of al-Qaeda's leader Osama bin Laden.\nAs for the pilots who would go on to participate in the attacks, three of them were original members of the Hamburg cell (Mohamed Atta, Marwan al-Shehhi, and Ziad Jarrah). Following their training at al-Qaeda training camps in Afghanistan, they were chosen by Bin Laden and al-Qaeda's military wing due to their extensive knowledge of Western culture and language skills, increasing the mission's operational security and its chances for success. Mohamed Atta himself was immediately given command over the planning and execution of the attack upon his arrival in Afghanistan in January 2000. The fourth intended pilot, Ramzi bin al-Shibh, a member of the Hamburg cell, was also chosen to participate in the attacks, but he was unable to obtain a visa for entry into the United States. He was later replaced by Hani Hanjour, a Saudi national.\nAl-Mihdhar and al-Hazmi were also potential pilot hijackers but did not do well in their initial pilot lessons in San Diego. Both were kept on as \"muscle\" hijackers, who would help overpower the passengers and crew and allow the pilot hijackers to take control of the flights. In addition to al-Mihdhar and al-Hazmi, 13 other muscle hijackers were selected in late 2000 or early 2001. All were from Saudi Arabia, with the exception of Fayez Banihammad, who was from the United Arab Emirates.\nShortly after the attacks the FBI concluded that the majority of the \"muscle\" hijackers did not know that they were on a suicide mission, as unlike the pilots they had not prepared last wills and testaments or given other indications that they expected their lives to end. According to an audio recording of Osama bin Laden from 2001, the \"muscle\" hijackers were not in contact with the pilot hijackers and were not told the true nature of their mission until the day of the attacks.\nHijackers.\n&lt;templatestyles src=\"Template:Bar chart/styles.css\"/&gt;\n&lt;templatestyles src=\"Template:Bar chart/styles.css\"/&gt;\n N.B.: Bold text notes the hijackers who piloted the planes.\nHijacked aircraft.\nAmerican Airlines Flight 11: One World Trade Center, North Tower.\nHijackers: Mohamed Atta (Egyptian), Abdulaziz al-Omari (Saudi Arabian), Wail al-Shehri (Saudi Arabian), Waleed al-Shehri (Saudi Arabian), Satam al-Suqami (Saudi Arabian).\nTwo flight attendants called the American Airlines reservation desk during the hijacking. Betty Ong reported that \"the five hijackers had come from first-class seats: 2A, 2B, 9A, 9C and 9B.\" Flight attendant Amy Sweeney called a flight services manager at Logan Airport in Boston and described them as Middle Eastern. She gave the staff the seat numbers and they pulled up the ticket and credit card information of the hijackers, identifying Mohamed Atta.\nMohamed Atta's voice was heard over the air traffic control system, broadcasting messages thought to be intended for the passengers.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"We have some planes. Just stay quiet and you'll be okay. We are returning to the airport.\"\n\"Nobody move. Everything will be okay. If you try to make any moves, you'll endanger yourself and the airplane. Just stay quiet.\"\n\"Nobody move, please. We are going back to the airport. Don't try to make any stupid moves.\"\nUnited Airlines Flight 175: Two World Trade Center, South Tower.\nHijackers: Marwan al-Shehhi (Emirati), Fayez Banihammad (Emirati), Mohand al-Shehri (Saudi Arabian), Hamza al-Ghamdi (Saudi Arabian), Ahmed al-Ghamdi (Saudi Arabian).\nA United Airlines mechanic was called by a flight attendant who stated the pilots had been murdered and the plane hijacked.\nAmerican Airlines Flight 77: Pentagon.\nHijackers: Hani Hanjour (Saudi Arabian), Khalid al-Mihdhar (Saudi Arabian), Majed Moqed (Saudi Arabian), Nawaf al-Hazmi (Saudi Arabian), Salem al-Hazmi (Saudi Arabian).\nTwo hijackers, Hani Hanjour and Majed Moqed were identified by clerks as having bought single, first-class tickets for Flight 77 from Advance Travel Service in Totowa, New Jersey with $1,842.25 in cash.\nRenee May, a flight attendant on Flight 77, used a cell phone to call her mother in Las Vegas. She said her flight was being hijacked by six individuals who had moved them to the rear of the plane. Unlike the other flights, there was no report of stabbings or bomb threats. According to the \"9/11 Commission Report\", it is possible that pilots were not stabbed to death and were sent to the rear of the plane. One of the hijackers, most likely Hanjour, announced on the intercom that the flight had been hijacked.\nPassenger Barbara Olson called her husband, Theodore Olson, the Solicitor General of the United States, stating the flight had been hijacked and the hijackers had knives and box cutters.\nTwo of the hijackers had been on the FBI's watch list: Khalid al-Mihdhar and Nawaf al-Hazmi. Al-Mihdhar and Nawaf al-Hazmi flew to Los Angeles in January 2000 and later took flying lessons in San Diego, during which time they were allegedly assisted by Omar al-Bayoumi and Saudi diplomats Fahad al-Thumairy and Mussaed Ahmed al-Jarrah.\nUnited Airlines Flight 93: Shanksville, Pennsylvania.\nHijackers: Ziad Jarrah (Lebanese), Ahmed al-Haznawi (Saudi Arabian), Ahmed al-Nami (Saudi Arabian), Saeed al-Ghamdi (Saudi Arabian).\nPassenger Jeremy Glick stated that the hijackers were Arabic-looking, wearing red headbands, and carrying knives.\nSpoken messages (from Jarrah) intended for passengers were mistakenly broadcast over the air traffic control system.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Ladies and gentlemen, this is the captain. Please sit down. Keep remaining sitting [\"sic\"]. We have a bomb on board. So sit.\"\n\"Uh, this is the captain. Would like you all to remain seated. There is a bomb on board and are going back to the airport and to have our demands met. Please remain quiet.\"\nJarrah is also heard on the cockpit voice recorder. In addition, DNA samples submitted by his girlfriend were matched to remains recovered in Shanksville.\nInvestigation.\nBefore the attacks.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n'[W]e've got to tell the Bureau about this. These guys clearly are bad. One of them, at least, has a multiple-entry visa to the U.S. We've got to tell the FBI.' And then [the CIA officer] said to me, 'No, it's not the FBI's case, not the FBI's jurisdiction.'\nMark Rossini , \"The Spy Factory\"\nBefore the attacks, FBI agent Robert Wright Jr. had written vigorous criticisms of FBI's alleged incompetence in investigating suspected extremists residing within the United States. Wright was part of the Bureau's Chicago counter-terrorism task force and involved in project Vulgar Betrayal, which was linked to Yasin al-Qadi.\nAccording to James Bamford, the NSA had picked up communications of al-Mihdhar and al-Hazmi back in 1999, but had been hampered by internal bureaucratic conflicts between itself and the CIA, and did not do a full analysis of the information it passed on to the agency. For example, it only passed on the first names, Nawaf and Khalid.\nBamford also claims that the CIA's Alec Station (a unit assigned to bin Laden) knew that al-Mihdhar was planning to come to New York as far back as January 2000. Doug Miller, one of three FBI agents working inside the CIA station, tried to send a message (a CIR) to the FBI to alert them about this, so they could put al-Mihdhar on a watch list. His CIA boss, Tom Wilshire, deputy station chief, allegedly denied permission to Miller. Miller asked his associate Mark Rossini for advice; Rossini pressed Wilshire's deputy but was rebuffed also.\nBamford also claims that al-Mihdhar and al-Hazmi wound up living with Abdussattar Shaikh for a time to save money. Shaikh was, coincidentally, an FBI informant, but since they never acted suspiciously around him, he never reported them. The CIA Bangkok station told Alec Station that al-Hazmi had gone to Los Angeles. None of this information made it back to the FBI headquarters.\nOn August 23, 2001, less than three weeks before the attacks, the Mossad gave the American government the names of 19 residents suspected of intending to perpetrate an attack against the United States. Among the names were those of Mohamed Atta, Marwan al-Shehhi, Khalid al-Mihdhar, and Nawaf al-Hazmi. It is not known if the list contained all the names of the hijackers or if the list length itself were a coincidence; only those four have been made known.\nAttacks.\nWithin minutes of the attacks, the Federal Bureau of Investigation opened the largest FBI investigation in United States history, operation PENTTBOM. The suspects were identified within 72 hours because few made any attempt to disguise their names on flight and credit card records. They were also among the few non-US citizens and nearly the only passengers with Arabic names on their flights, enabling the FBI to identify them using such details as dates of birth, known or possible residences, visa status, and specific identification of the suspected pilots. On September 14, three days after the attacks, the FBI announced the names of 19 hijackers, and on September 27, they released photos of the hijackers, along with information about their possible nationalities and aliases. Fifteen of the suspected hijackers hailed from Saudi Arabia, two from the United Arab Emirates, and one each from Lebanon and Egypt.\nThe passport of Satam al-Suqami was reportedly recovered \"a few blocks from where the World Trade Center's twin towers once stood\"; a passerby picked it up and gave it to an NYPD detective shortly before the towers collapsed. The passports of two other hijackers, Ziad Jarrah and Saeed al-Ghamdi, were recovered from the crash site of United Airlines Flight 93 in Pennsylvania, and a fourth passport, that of Abdulaziz al-Omari was recovered from luggage that did not make it onto American Airlines Flight 11.\nAccording to the \"9/11 Commission Report\", 26 al-Qaeda conspirators sought to enter the United States to carry out a suicide mission. In the end, the FBI reported that there were 19 hijackers in all: five on three of the flights, and four on the fourth. After a controversy about an earlier remark, U.S. Homeland Security Secretary Janet Napolitano stated in May 2009 that the 9/11 Commission found that none of the hijackers entered the United States through Canada.\nNawaf al-Hazmi and Hani Hanjour, attended the Dar al-Hijrah Falls Church, Virginia, Islamic Center where the Imam Anwar al-Awlaki preached, in early April 2001. Through interviews with the FBI, it was discovered that Awlaki had previously met Nawaf al-Hazmi several times while the two lived in San Diego. At the time, al-Hazmi was living with al-Mihdhar. The hijackers of the same plane often had very strong ties as many of them attended school together or lived together prior to the attacks.\nRecovery of the hijackers' remains.\nAfter the 9/11 attacks, remains of the victims and attackers were recovered from the World Trade Center site, from the Pentagon, and in Shanksville, Pennsylvania.\nIn New York, the remains of two hijackers, potentially from Flight11, were identified and removed from Memorial Park in Manhattan and turned over to the FBI as evidence. The remains of the other hijackers on Flight 11 and Flight 175 have not been identified and are buried with other unidentified remains at this park.\nThe remains of the five hijackers on Flight 77 were identified through a process of elimination by October 2, 2001, and were turned over to the FBI as evidence.\nFor Flight 93, the remains of Ziad Jarrah were identified and turned over to the FBI as evidence after DNA samples submitted by his girlfriend were matched to remains recovered in Shanksville. The rest of the remains of the hijackers were identified by the process of elimination, and were turned over to the FBI as evidence.\nPossible cases of mistaken identity.\nSoon after the attacks and before the FBI had released the pictures of all the hijackers, several reports claimed some of the men named as hijackers on 9/11 were alive and had their identities stolen.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28046", "revid": "10232273", "url": "https://en.wikipedia.org/wiki?curid=28046", "title": "Closings and cancellations following the September 11 attacks", "text": " \nMany closings and cancellations followed the September 11 attacks, including major landmarks, buildings, restrictions on access to Lower Manhattan, as well as postponement or cancellation of major sporting and other events. Landmarks were closed primarily because of fears that they may be attacked. At some places, streets leading up to the institutions were also closed. When they reopened, there was heightened security. Many U.S. states declared a state of emergency.\nLower Manhattan.\nSpeaking at a press conference at 11:02\u00a0a.m. on the morning of the attacks, Mayor Rudy Giuliani told New Yorkers: \"If you are south of Canal Street, get out. Walk slowly and carefully. If you can't figure what else to do, just walk north.\" The neighborhood was covered in dust and debris, and electrical failures caused traffic light outages. Emergency vehicles were given priority to respond to ongoing fires, building collapses, and expected mass casualties. Over a million workers and residents south of Canal Street were evacuated, and police stopped pedestrians from entering Lower Manhattan. With subways shut down, vehicle traffic restricted, and tunnels closed, they mainly fled on foot, pouring over bridges and ferries to Brooklyn and New Jersey.\nOn September 12, vehicle traffic was banned south of 14th Street, subway stations south of Canal Street were bypassed, and pedestrians were not permitted below Chambers Street. Vehicle traffic below Canal Street was not allowed until October 13.\nThe New York Stock Exchange (NYSE) did not open on September 11 even as CNBC showed futures numbers early in the day. As Wall Street was covered in debris from the World Trade Center (WTC) and suffered infrastructure damage, it remained closed until September 17.\nBridges and tunnels.\nFor at least a full day after the attacks, bridges and tunnels to Manhattan were closed to non-emergency traffic in both directions. Among other things, this interrupted scheduled deliveries of food and other perishables, leading to shortages in restaurants. Most of these reopened, fully or partially, by September 14, but vehicles were subject to security checks, and the eastbound Holland Tunnel remained closed until October 15 because of its proximity to the World Trade Center site.\nMany Manhattan office workers returned to their jobs for the first time on Monday, September 24. With security restrictions creating hours-long delays, drivers entering the city experienced severe traffic jams. Officials urged commuters to take mass transit instead of driving, and a spokesman for the New York City Department of Transportation said that September 25 \"might have been the worst traffic day since Henry Ford invented the car.\"\nTo alleviate the traffic, city officials activated an HOV plan that had been created in the 1980s but never used. Starting September 27, cars with only one occupant (estimated to make up 64% of vehicles entering Manhattan) were not allowed to cross any of the bridges and tunnels connecting to the island south of 63rd Street on weekdays between 6:00 and 11:00\u00a0a.m. On October 17, the ending time of the ban was moved to 10:00\u00a0a.m. An NYC DOT study found that traffic during these hours was reduced by 15%. However, many chose to enter Manhattan earlier, leading to a 26% increase in traffic during the hour between 5:00 and 6:00\u00a0a.m. Some advocated for the rule to be put in place permanently, but it was based on the city's emergency administrative powers and provoked threats of lawsuits from parking garage owners. The ban was lifted for some bridges and tunnels on April 22, 2002, though it remained in place for the Holland and Brooklyn Battery Tunnels and the Brooklyn and Manhattan Bridges. The remaining restrictions were removed on November 17, 2003.\nMass transit.\nNew York City Subway.\nThe tracks and stations under the World Trade Center were shut down within minutes of the first plane crash. All remaining New York City Subway service was suspended from 10:20\u00a0a.m. to 12:48\u00a0p.m. Immediately after the attacks and more so after the collapses of the Twin Towers, many trains running in Lower Manhattan lost power and had to be evacuated through the tunnels. Some trains had power but the signals did not, requiring special operating procedures to ensure safety.\nThe IRT Broadway\u2013Seventh Avenue Line, which ran below the World Trade Center between Chambers Street and Rector Street, was the most crippled. This section of the tunnel, including Cortlandt Street station (located directly underneath the World Trade Center), was badly damaged, and had to be rebuilt. Service was immediately suspended south of Chambers Street and then cut back to 14th Street. There was also subsequent flooding on the line south of 34th Street\u2013Penn Station. After the flood was cleaned up, express service was able to resume on September 17 with 1 trains running between Van Cortlandt Park\u2013242nd Street and 14th Street, making local stops north of and express stops south of 96th Street, while 2 and 3 trains made all stops in Manhattan (but bypassed all stations between Canal Street and Fulton Street until October 1). 1/9 skip-stop service was suspended.\nAfter a few switching delays at 96th Street, service was changed on September 19. The 1 train resumed local service in Manhattan, but was extended to New Lots Avenue in Brooklyn (switching onto the express tracks at Chambers Street) to replace the 3, which now terminated at 14th Street as an express. The 2 train continued to make local stops in Manhattan and service between Chambers Street and South Ferry as well as skip-stop service remained suspended. Normal service on all four trains was restored September 15, 2002, but Cortlandt Street remained closed until September 8, 2018.\nService on the BMT Broadway Line was also disrupted because the tracks from the Montague Street Tunnel run adjacent to the World Trade Center and there were concerns that train movements could cause unsafe settling of the debris pile. Cortlandt Street station, which sits under Church Street, sustained significant damage in the collapse of the towers. It was closed until September 15, 2002 for removal of debris, structural repairs, and restoration of the track beds, which had suffered flood damage in the aftermath of the collapse. Starting September 17, 2001, N and R service was suspended and respectively replaced by the M (which was extended to Coney Island\u2013Stillwell Avenue via the BMT Montague Street Tunnel, BMT Fourth Avenue Line, and BMT Sea Beach Line) and the J (also extended via Fourth Avenue to Bay Ridge\u201395th Street). In Queens, the Q replaced the R while the W replaced the N. All service on the BMT Broadway Line ran local north of Canal Street except for the &lt;Q&gt;, which ran normally from 57th Street to Brighton Beach via Broadway and Brighton Express. J/Z skip-stop service was suspended at this time. Normal service on all seven trains resumed on October 28.\nThe IND Eighth Avenue Line, which has a stub terminal serving the E train under Five World Trade Center, was undamaged, but covered in soot. E trains were extended to Euclid Avenue, Brooklyn, replacing the then suspended C train (the A and D trains replaced it as the local north of 59th Street\u2013Columbus Circle on nights and weekends, respectively. The B train, which ran normally from 145th Street or Bedford Park Boulevard to 34th Street\u2013Herald Square via Central Park West Local, also replaced C trains on weekdays). Service was cut back to Canal Street when C service resumed on September 21, but Chambers Street and Broadway\u2013Nassau Street remained closed until October 1. World Trade Center remained closed until January 2002.\nThe only subway line running between Midtown and Lower Manhattan nearby the former World Trade Center Complex was the IRT Lexington Avenue Line, which was overcrowded before the attacks and at crush density until the BMT Broadway Line reopened. Wall Street was closed until September 21.\nThe IND 6th Avenue line and BMT Nassau Street line were the only two routes in lower Manhattan to be completely unaffected by the 9/11 attacks due to them not being near the complex itself \nThere were no reported casualties on the subway or loss of train cars, but a Motor Coach Industries coach bus was destroyed. Another bus was damaged, but was repaired and returned to normal service with a special commemoration livery.\nPATH.\nPATH started evacuating passengers from its Manhattan trains and tracks within minutes of the first plane crash. The PATH station at World Trade Center was heavily damaged (a train parked in the station was crushed by debris and was removed during the excavation process in January 2002) and all service was suspended. For several hours, PATH did not run any trains to Manhattan, but was able to restore service on the Uptown Hudson Tubes to 33rd Street by the afternoon. Exchange Place was unusable since the switch configuration at the time required all trains to continue to World Trade Center. As a result, PATH ran a modified service: Hoboken-Journal Square, Hoboken-33rd Street, and Newark-33rd Street. Exchange Place reopened with modifications on June 29, 2003; a temporary station replacing World Trade Center opened on November 23.\nFerries.\nLiberty Water Taxi and NY Waterway had a ferry terminal at the World Financial Center. As the area around the terminal was in the restricted zone, NY Waterway suspended service to the terminal with alternate service going to Midtown and Wall Street and Liberty Water Taxi service was suspended. Free ad-hoc ferry service to New Jersey, Brooklyn, and Queens began by evening, with about half a million evacuees transported by Circle Line Tours, NY Waterway, privately owned dining boats, tug boats, and at least one fire boat.\nBuses.\nMetropolitan Transportation Authority buses were temporarily suspended south of Canal Street, and MTA and NJ Transit buses were re-routed to serve passengers arriving in Brooklyn and New Jersey by walking and taking ferries out of Manhattan.\nIntercity transit.\nThe Port Authority Bus Terminal was closed until September 13. Amtrak suspended all of its rail service nationwide until 6pm, but by September 13 it had increased its capacity by 30% to deal with an influx of stranded flight passengers. Greyhound Bus Lines cancelled its bus service in the Northeast, but was running normally by September 13.\nNorth American airspace.\nThe entire airspaces of the United States and Canada were closed (\"ground stop\") by order of FAA National Operations Manager Ben Sliney (who was working his first day in that position) except for military, police, and medical flights. The unprecedented implementation of Security Control of Air Traffic and Air Navigation Aids (SCATANA) was the first unplanned closure in the U.S.; military exercises known as Operation Skyshield had temporarily closed the airspace in the early 1960s. Domestic planes were diverted to the nearest available airport, and grounded passengers and planes were searched for security threats. United Airlines cancelled all flights worldwide temporarily. President George W. Bush was transported to a secure location via Air Force One. Many incoming international flights were diverted to Atlantic Canada to avoid proximity to potential targets in the United States and large cities in Canada. Some international flights that departed from South America were diverted to Mexico, as its airspace was not shut down. \nDuring the closure of American airspace, there were only a few civilian flights which received special approval to fly from the FAA, such as the Civil Air Patrol's aerial photography unit which conducted aerial surveys of the damage to New York.\nOn Thursday night, the New York area airports (JFK, LaGuardia, and Newark) were closed again and reopened the next morning. The only traffic from LaGuardia during the closure was a single C-9C government VIP jet, departing at approximately 5:15 p.m. on the 12th. Civilian air traffic was allowed to resume on September 13, with stricter airport security checks, disallowing for example the box cutting knives that were used by the hijackers. (Reinforcement of cockpit doors began in October 2001, and was required for larger airlines by 2003.) First, stranded planes were allowed to fly to their intended destinations, then limited service resumed. The backlog of delayed passengers took several days to clear. \nDue to a translation error, controllers believed Korean Air Flight 85 might have been hijacked. Canadian Prime Minister Jean Chr\u00e9tien and U.S. authorities ordered the United States Air Force to surround the plane and force it to land in Whitehorse, Yukon and to shoot down the plane if the pilots did not cooperate. Alaska Governor Tony Knowles ordered the evacuation of large hotels and government buildings in Anchorage. Also in Alaska at nearby Valdez, the U.S. Coast Guard ordered all tankers filling up with oil to head out to sea. Canadian officials evacuated all schools and large buildings in Whitehorse before the plane landed safely.\nPrecautionary building closings and evacuations.\nMany businesses across the United States closed after the intentional nature of the events became clear, and many national landmarks and financial district skyscrapers were evacuated out of fear of further attacks.\nGovernment and cultural cancellations and postponements.\nIn an atmosphere reminiscent of the assassination of John F. Kennedy in 1963, everyday life in many places around the world came to a standstill in the days after the September 11 attacks. For this reason, as well as for reasons of perceived threat associated with large gatherings, many events were postponed or cancelled. Other events were also cancelled, postponed, or modified:\nSee also.\nAir traffic control during the September 11 attacks\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28047", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=28047", "title": "Memorials and services for the September 11 attacks", "text": "The first memorials to the victims of the September 11 attacks in 2001 began to take shape online, as hundreds of webmasters posted their own thoughts, links to the Red Cross and other rescue agencies, photos, and eyewitness accounts. Numerous online September 11 memorials began appearing a few hours after the attacks, although many of these memorials were only temporary. Around the world, U.S. embassies and consulates became makeshift memorials as people came out to pay their respects.\nThe first reading of the names of the victims of 9/11 took place at the World Trade Center site on September 11, 2002.\nThe \"Tribute in Light\" was the first major physical memorial at the World Trade Center site. A permanent memorial and museum, the National September 11 Memorial &amp; Museum at the World Trade Center, were built as part of the design for overall site redevelopment. The 9/11 Memorial consists of two massive pools set within the original footprints of the Twin Towers with waterfalls cascading down their sides. The names of the victims of the attacks are inscribed around the edges of the waterfalls. Other permanent memorials have been constructed around the world.\nOne of the places that saw many memorials and candlelight vigils was Pier A in Hoboken, New Jersey. There was also a memorial service on March 11, 2002, at dusk on Pier A when the \"Tribute in Light\" first turned on, marking the half-year anniversary of the terrorist attack. A permanent September 11 memorial for Hoboken, called Hoboken Island, was chosen in September 2004.\n\"The Sphere\", the monumental and world's largest cast bronze sculpture of modern times created by German artist Fritz Koenig stood between the twin towers on the Austin J. Tobin Plaza of the World Trade Center in New York City from 1971 until the terrorist attacks on September 11, 2001. The artefact, weighing more than 20 tons, was the only remaining work of art to be recovered largely intact from the ruins of the collapsed Twin Towers after the attacks. Since then, the bronze sphere, primarily known in the United States as \"The Sphere\", has been transformed into a symbolic memorial to commemorate 9/11. Having become a major tourist attraction, the unrestored sculpture was rededicated on August 16, 2017, by the Port Authority at a permanent location in Liberty Park overlooking the September 11 Memorial.\nList.\nTemporary memorials.\nSoon after the attacks, temporary memorials were set up in New York and elsewhere.\nIn other countries.\nIn Europe, annually a commemoration of September 11 to never forget, Nissoria was one of the first public places that dedicated a memorial to September 11 in Europe. Nissoria is in a small town located in the Province of Enna in Sicily, Italy. Two family members of this community, Vincenzo DiFazio and Salvatore Lopez, died on Sept 11 at the World Trade Center.\nThe then-mayor Dr. Marco Murgo along with the Chiara family Benito Sr. and son Mario developed the project to dedicate a small plot of land adjacent to a local school and museum that was entitled \"Parco 11 Settembre\". The Commanding Officer of the nearby U.S. Naval Air Station Sigonella met with this delegation from Nissoria and embraced this truly heartfelt initiative.\nEver since its dedication, and thanks to the present-day Mayor of Nissoria Dott. Armando Glorioso and Dott. Alberto Lunetta who continues this important event, a representation of both American and Italian military personnel from the nearby Military base NAS Sigonella comes to visit and annually commemorate along with all local Italian Authorities, Dignitaries and citizens who truly will never forget this tragic event.\nPermanent memorials.\nIn addition with the main permanent memorial in New York City, other permanent memorials are located mostly across the United States.\nPerformances and benefits.\n2002 and later events.\nOn February 3, 2002, during the halftime show of Super Bowl XXXVI, rock group U2 performed\" Where the Streets Have No Name\", while the names of the victims were projected onto banners. Bono opened his jacket to reveal a U.S. flag pattern sewn in the inside lining.\nAt the opening ceremony of the 2002 Winter Olympics in Salt Lake City on February 8, a tattered American flag recovered from the World Trade Center site was carried into the stadium by American athletes, members of the Port Authority police, and members of the New York City police and fire departments.\nOn February 23, 2003, the 45th Annual Grammy Awards were held at Madison Square Garden and paid tribute to those who died during the attacks, to whom the ceremony was dedicated. Ceremony host Bruce Springsteen performed \"The Rising\" at the Awards.\nAmerican country singer Darryl Worley paid tribute to the people with his 2003 single, \"Have You Forgotten?\" from the album of the same name.\nNewark International Airport was renamed \"Newark Liberty International Airport\".\nOn September 11, 2002, representatives from over 90 countries came to Battery Park City as New York City Mayor Michael Bloomberg lit an eternal flame to mark the first anniversary of the attacks. Leading the dignitaries were Canadian Prime Minister Jean Chr\u00e9tien, U.N. Secretary General Kofi Annan, Bloomberg, and Secretary of State Colin Powell. The same day, the Victims of Terrorist Attack on the Pentagon Memorial was dedicated at Arlington National Cemetery near the Pentagon. The memorial is dedicated to the five individuals at the Pentagon whose remains were never found, and the partial remains of another 25 victims are buried beneath the memorial. The names of the 184 victims of the Pentagon attack are inscribed on the memorial's side.\nOn September 11, 2002, the documentary play \"Bystander 9/11\" was performed at Church of the Transfiguration, Episcopal (Manhattan), the play has since been published and has been regularly performed on the anniversary of the event, with numerous performances around the United States on the 20th anniversary.\nA 9/11 memorial public sculpture by Ingrid Lahti was on display at Bellevue Downtown Park, Bellevue, Washington; it was installed September 11, 2002 and displayed through October.\n10th anniversary memorial services.\nMany organizations held memorial services and events for the 10th anniversary of the attacks.\n20th anniversary memorial services.\nThe 20th anniversary came just weeks after a hastened withdrawal of United States troops from Afghanistan following the 2021 Taliban offensive in which the Taliban reconquered most of Afghanistan. It was in this climate that former President George W. Bush said in a speech at the Shanksville memorial that both foreign and domestic extremists were \"children of the same foul spirit\", a comparison which angered some right-wing politicians and media figures. President Joe Biden, former presidents Barack Obama and Bill Clinton, and their respective first ladies attended a memorial ceremony together at the National September 11 Memorial, where the World Trade Center towers fell two decades prior. Biden then went on to visit the other two 9/11 crash sites, stopping at the national memorial in Shanksville, Pennsylvania, and finally, the Pentagon. Former President Donald Trump visited police and fire houses in New York City to commemorate the attack.\nThe Acting Ambassador to the United Kingdom, Philip Reeker attended a special changing of the guard at Windsor Castle during which the US National Anthem was performed.\nMemorial flags.\nThe National 9/11 Flag was made from a tattered remains of a American flag found by recovery workers in the early morning of September 12, 2001. It was hanging precariously from some scaffolding at a construction site next to Ground Zero. Because of safety reasons the flag could not be taken down until late October 2001. Charlie Vitchers, a construction superintendent for the Ground Zero cleanup effort, had a crew recover the flag. It was placed in storage for seven years.\nThe flag has made a number of appearances across the country, including a Boston Red Sox Game, a New York Giants Home Opener, and the USS \"New York\" Commissioning Ceremony. It also appeared on the CBS Evening News and on ABC World News Tonight \"Persons of the Week\".\nThe flag began a national tour on Flag day, which was on June 14, 2009. It visited all 50 states where service heroes, veterans, and other honorees each added stitching and material from other retired American flags in order to restore the original 13 stripes of the flag. The flag now resides at the National September 11 Memorial and Museum.\nThe 9-11 Remembrance Flag was created to be a permanent reminder of the thousands of people lost in the September 11 attacks. The purpose of keeping the memories of September 11 alive is not to be forever mourning, but for \"learning from the circumstances and making every effort to prevent similar tragedies in our future.\" The flag is also meant to be a reminder of how the people of this country came together to help each other after the attacks. The red background of the flag represents the blood shed by Americans for their country. The stars represent the lost airplanes and their passengers. The blue rectangles stand for the twin towers and the white pentagon represents the Pentagon building. The blue circle symbolizes the unity of this country after the attacks.\nThe 9/11 National Remembrance Flag was designed by Stephan and Joanne Galvin soon after September 11, 2001. They wanted to do something to help and were inspired by a neighbor's POW/MIA flag. They wanted to sell the flag so people would remember the September 11 attacks and in order to raise money for relief efforts. The blue represents the colors of the state flags that were involved in the attacks. The black represents sorrow for innocent lives lost. The four stars stand for the four planes that crashed and the lives lost, both in the crash and in the rescue efforts, as well as the survivors. The blue star is a representation of American Airlines Flight 77 and the Pentagon. The two white stars represent American Airlines Flight 11 and United Airlines flight 175, as well as the twin towers. The red star stands for United Flight 93 that crashed in Shanksville, Pennsylvania and all those who sacrifice their lives to protect the innocent. The colors of the stars represent the American flag. The four stars are touching each other and the blue parts of the flag in order to symbolize the unity of the people of the United States.\nThe National Flag of Honor and the National Flag of Heroes were created by John Michelotti for three main reasons: (1)\"To immortalize the individual victims that were killed in the terrorist attacks of September 11, 2001.\" (2)\"To give comfort to the families left behind knowing that their loved one will be forever honored and remembered.\" (2)\"To create an enduring symbol, recognized by the world, of the human sacrifice that occurred on September 11, 2001.\"\nThe Flag of Honor and the Flag of Heroes are based on the American flag. They both have the names of all the innocent people who were killed in the September 11 attacks printed on the red and white stripes of the American Flag. Both flags have a white space across the bottom with the name of the flag and a description printed in black. The Flag of Honor reads: \"This flag contains the names of those killed in the terrorist attacks of September 11. Now and forever it will represent their immortality. We shall never forget them\" The Flag of Heroes reads: \" This flag contains the names of the emergency service personnel who gave their lives to save others in the terrorist attacks of September 11. Now and forever it will represent their immortality. We shall never forget them.\"\nThe Flag of Honor and the Flag of Heroes were featured at the NYC 9/11 Memorial Field 5th Anniversary in Manhattan's Inwood Hill Park September 8\u201312, 2006. There 3,000 flags which represented those who died in the September 11 attacks. The flags were also featured on NBC's \"Today\" and on ABC affiliate WVEC in Norfolk, Virginia.\nThe Remembrance Flag has a white background with large, black Roman numerals IX/XI in the center and four black stars across the top. The IX/XI are the Roman numerals for 9/11. The four stars represent World Trade Center North, World Trade Center South, the Pentagon, and Shanksville, PA.\nVirtual memorials.\nThe growing popularity of virtual worlds such as \"Second Life\" has led to the construction of permanent virtual memorials and exhibits. Examples include:\nOn September 11, 2007, a virtual reality World Trade Center Memorial will be presented to the people of the world. The location is in Second Life, on the island we have named after the original design: Celestial Requiem NYC. We have built this memorial because, to be blunt, the world needed it done years ago, and the two years longer to await the completion of the \"Reflected Absence\" memorial in New York city (by Michael Arad and Peter Walker) was in our opinion two years too long.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28051", "revid": "1313717741", "url": "https://en.wikipedia.org/wiki?curid=28051", "title": "Airport security repercussions due to the September 11 attacks", "text": " \nAfter the September 11 attacks, there was an immediate call to action regarding the state of aviation security measures as the hijackers involved in 9/11 were able to successfully pass through security and take command of the plane. The existing security measures flagged more than half of the 19 hijackers in 9/11; however, they were cleared to board the plane because their bags were not found to contain any explosives. In the months and years following September 11, 2001, security at many airports worldwide were reformed to deter similar terrorist plots.\nChanges in airport security.\nPrior to September 11, 2001, airport screening was provided in the U.S. by private security companies contracted by the airline or airport. In November 2001, the Transportation Security Administration (TSA) was introduced to take over all of the security functions of the country's airports. The TSA increased the number of security agents employed from 16,200 to 56,000 and increased their compensation. In addition, they reformed the training for these agents. Prior to 9/11, the security staff was generally undertrained with a reported training time of 12 hours; afterwards, this training was increased to more than 100 hours. They also implemented verification tests of the training by projecting images of banned objects on machines to see if workers would be able to identify them. The actual process of security screening was revised as well after 9/11. Passenger pre-checks became standard and the percent of baggage screened for explosives increased from an approximate 5% to 100%. In some countries, for example, Sweden, Norway, and Finland, there were no or only random security checks for domestic flights prior to September 11, 2001. On or quickly after September 11, decisions were made to introduce full security checks there. It was immediately implemented where possible, but took one to two years to implement everywhere since terminals were often not prepared with room for it. The TSA also introduced changes on the airplanes themselves, including bulletproof and locked cockpit doors and air marshals which became standard on commercial passenger aircraft.\nIncreased security on aircraft.\nCockpit doors on many aircraft are reinforced and bulletproof to prevent unauthorized access. Passengers are now prohibited from entering the cockpit during flight. Some aircraft are also equipped with CCTV cameras, so the pilots can monitor cabin activity. Pilots are now allowed to carry firearms, but they must be trained and licensed. In the U.S., more air marshals have been placed on flights to improve security.\nIncreased security screening.\nOn September 11, hijackers Khalid al-Mihdhar, Majed Moqed, and Nawaf al-Hazmi all set off the metal detector. Despite being scanned with a hand-held detector, the hijackers were passed through. Security camera footage later showed some hijackers had what appeared to be box cutters clipped to their back pockets. Box cutters and similar small knives were allowed onboard certain aircraft at the time.\nAirport checkpoint screening has been significantly tightened since 2001, and security personnel are more thoroughly trained to detect weapons or explosives. In addition to standard metal detectors, many U.S. airports now employ full-body scanning machines, in which passengers are screened with millimeter wave technology to check for potential hidden weapons or explosives on their persons. Initially, early body scanners provoked quite a bit of controversy because the images produced by the machines were deemed graphic and intrusive. Many considered this an invasion of personal privacy, as TSA screeners were essentially shown an image of each passenger's naked body. Newer body scanners have since been introduced which do not produce an image, but rather alert TSA screeners of areas on the body where an unknown item or substance may be hidden. A TSA security screener then inspects the indicated area(s) manually.\nIdentification checks.\nOn September 11, some hijackers lacked proper identification, yet they were allowed to board due to being on domestic aircraft. After 9/11, all passengers 18 years or older in the U.S. must now have valid government-issued photo ID in order to fly. Airports may check the ID of any passenger (and staff member) at any time to ensure the details on the ID match those on the printed boarding pass. Only under exceptional circumstances may an individual fly without a valid ID. If approved for flying without an ID, the individual will be subject to extra screening of their person and their carry-on items. TSA does not have the capability to conduct background checks on passengers at checkpoints. Sensitive areas in airports, including airport ramps and operational spaces, are restricted from the general public. Called a SIDA (Security Identification Display Area) in the U.S., these spaces require special qualifications to enter. Non-passengers can also no longer meet passengers at their gate inside the terminal, but rather must wait on the other side of the TSA security check.\nA European Union regulation demanded airlines make sure that the individual boarding the aircraft is the same individual who checked in his or her luggage; this was implemented by verifying an individual's identification both at luggage check-in and when boarding.\nSome countries also fingerprint travellers or use retina and iris scanning to help detect potential criminals, although this is predominantly in relation to detection of immigration violations by inbound passengers rather than security checking of outbound passengers.\nCriticism.\nWith regard to the 2015 Germanwings flight 9525 crash incident, a suicide by pilot where the captain was unable to regain access to the flight deck, some have stated that security features added to commercial airliners after 9/11 actually work against the safety of such planes.\nLawsuit.\nIn 2003, John Gilmore sued United Airlines, Southwest Airlines, and then-U.S. Attorney General John Ashcroft, arguing that requiring passengers to show identification before boarding domestic flights is tantamount to an internal passport, and is unconstitutional. Gilmore lost the case, known as \"Gilmore v. Gonzales\", and an appeal to the U.S. Supreme Court was denied.\nPrivacy issues.\nAir security and restrictions after the September, 2001 terrorist attacks have helped prevent further attacks from happening, but many Americans have issues with their privacy when traveling. The Computer-Assisted Passenger Prescreening System (CAPPS), was first implemented in the late 1990's by the FFA. CAPPS flagged 6 of the 19 terrorists that were part of the attacks in 2001. The concern with CAPPS was that it also flagged 65,000 other passengers that day. Many Americans viewed this as a threat to their privacy and their information. CAPPS II was created post 9/11 and was created for the same purpose of preventing terrorist attacks and ensuring the safety of Americans. Many Americans had issues with CAPPS II because they believe that it racially and politically profiled passengers. In 2004, the TSA was delayed in testing and developing CAPPS II because they could not obtain passenger data because of privacy concerns.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28056", "revid": "42316941", "url": "https://en.wikipedia.org/wiki?curid=28056", "title": "September 11, 2001 Terrorist Attack/Misinformation and Rumors", "text": ""}
{"id": "28061", "revid": "6326132", "url": "https://en.wikipedia.org/wiki?curid=28061", "title": "U.S. government response to the September 11 attacks", "text": "After the September\u00a011 attacks, the United States government responded by commencing immediate rescue operations at the World Trade Center site, grounding civilian aircraft, and beginning a long-term response that included official investigations, legislative changes, military action, and restoration projects. \nImmediately following the attacks, massive search and rescue operations were launched, and terrorism investigations led to the declaration of War on Terrorism that launched military engagements in Afghanistan and Iraq. The \"9/11 Commission\" inspected the causes and motives of the attacks, and released its findings in the \"9/11 Commission Report\". \nAs a result of the attacks, the U.S. federal government enacted the Homeland Security Act of 2002, creating the Department of Homeland Security, and the USA PATRIOT Act, to help detect and prosecute terrorism and other crimes. Subsequent clean-up and restoration efforts led to the rebuilding of Lower Manhattan, and federal grants helped support the development of the National September 11 Memorial &amp; Museum, both of which opened in the early 2010s.\nInvestigations.\n\"9/11 Commission Report\".\nThe \"National Commission on Terrorist Attacks Upon the United States\", known as the 9/11 Commission and chaired by former New Jersey Governor Thomas Kean, was formed in late 2002 to prepare a full and complete account of the circumstances surrounding the attacks, including preparedness for, and the immediate response to, the September 11 attacks. On July\u00a022,\u00a02004, the commission released its findings in the \"9/11 Commission Report\".\nInternal CIA review.\nThe Central Intelligence Agency Office of Inspector General conducted an internal review of the Central Intelligence Agency's performance prior to the September 11 attacks and was harshly critical of senior CIA officials for not doing everything possible to confront terrorism, including failing to stop two of the 9/11 hijackers, Nawaf al-Hazmi and Khalid al-Mihdhar, as they entered the United States, and hit failure to share information on the two men with the FBI.\nWorld Trade Center collapse.\nA federal technical building and fire safety investigation of the collapses of the Twin Towers was conducted by the United States Department of Commerce's National Institute of Standards and Technology (NIST). The goals of this investigation were to investigate the building construction, the materials used, and the technical conditions that contributed to the outcome of the WTC disaster. The investigation was to serve as the basis for:\nThe report was completed on April 6, 2005, concluding that the fireproofing on the Twin Towers' steel infrastructures was blown off by the initial impact of the planes and that, if this had not occurred, the towers would likely have remained standing. The fires weakened the trusses supporting the floors, making them sag. The sagging floors pulled on the exterior steel columns to the point where exterior columns bowed inward. With the damage to the core columns, the buckling exterior columns could no longer support the buildings, causing them to collapse. In addition, the report asserts that the towers' stairwells were not adequately reinforced to provide emergency escape for people above the impact zones. NIST stated that the final report on the collapse of 7 WTC will appear in a separate report.\nCivilian aircraft grounding.\nFor the first time in history, all nonemergency civilian aircraft in the United States and several other countries including Canada were immediately grounded, stranding tens of thousands of passengers across the world. The order was given at 9:42 by Federal Aviation Administration Command Center national operations manager Ben Sliney. According to the \"9/11 Commission Report\", \"This was an unprecedented order. The air traffic control system handled it with great skill, as about 4,500 commercial and general aviation aircraft soon landed without incident.\nInvocation of the continuity of government.\nContingency plans for the continuity of government and the evacuation of leaders were implemented almost immediately after the attacks. Congress, however, was not told that the US was under a continuity of government status until February 2002.\nRescue, recovery, and compensation.\nWithin hours of the attacks on New York City, a massive search and rescue (SAR) operation was launched, which included over 350 search and rescue dogs. Initially, only a handful of wounded people were found at the site, and in the weeks that followed it became evident that there were no survivors to be found. Only twenty survivors were found alive in the rubble.\nRescue and recovery efforts took months to complete. It took several weeks to put out the fires burning in the rubble of the buildings, with the clean-up not being completed until May 2002. Temporary wooden \"viewing platforms\" were set up for tourists to view construction crews clearing out the gaping holes where the towers once stood. All of these platforms were closed on May 30, 2002.\nMany relief funds were set up to assist victims of the attacks, with the task of providing financial assistance to the survivors and families of victims. By the deadline for victim's compensation of September 11, 2003, 2,833 applications had been received from the families of those killed.\nWar on terror.\nIn the aftermath of the terrorist attacks, many U.S. citizens believed that the attacks had \"changed the world forever.\" The Bush administration announced a war on terror, with the goal of bringing Osama bin Laden and al-Qaeda to justice and preventing the emergence of other terrorist networks. These goals would be accomplished by means including economic and military sanctions against states perceived as harboring terrorists and increasing global surveillance and intelligence sharing. Immediately after the September 11 attacks, U.S. officials speculated on possible involvement by Saddam Hussein, which later was proven to be false.\nAs the attacks on the United States were judged to be within the parameters of its charter, NATO declared that Article 5 of the NATO agreement was satisfied on September 12, 2001, making the US war on terrorism the first time since its inception that NATO would actually participate in a \"hot\" war.\nOsama bin Laden himself was located by US intelligence in 2011, and was killed in Abbottabad, Pakistan by a US special operations unit on 2 May 2011.\nIn 2014, President Barack Obama claimed the formal end of the war in Afghanistan. However, U.S. troops did not withdraw entirely, as fewer than 15,000 troops still remained in the country. \nFrom 2019 to August 30, 2021, Presidents Donald Trump and Joe Biden withdrew the remaining 14,000 U.S. troops from Afghanistan, marking the official end of the 2001-2021 war.\nAyman al-Zawahiri, another planner of the attacks who succeeded Bin Laden as leader of Al-Qaeda, was killed by a U.S. drone strike in Kabul, Afghanistan on July 31, 2022.\nArrests.\nFollowing the attacks, 762 suspects were taken into custody in the United States. On December 12, 2001, Fox News reported that some 60 Israelis were among them. Federal investigators were reported to have described them as part of a long-running effort to spy on American government officials. A \"handful\" of these Israelis were described as active Israeli military or intelligence operatives.\nIn a letter to the editor, Ira Glaser, former head of the ACLU, claimed that none of those 762 detainees were charged with terrorism. \"The Justice Department inspector general's report implies more than the violation of the civil liberties of 762 non-citizens. It also implies a dysfunctional and ineffective approach to protecting the public after Sept. 11, 2001... No one can be made safer by arresting the wrong people\".\nDomestic response.\nImmediately after opening the hunt on Osama bin Laden, President Bush also visited the Islamic Center of Washington and asked the public to view Arabs and Muslims living in the United States as American patriots. However, Islamophobia, or the fear of, hatred of, or prejudice against the religion of Islam or Muslims in general, still rose. Incidents of harassment and hate crimes against Muslims, Arabs, Middle Easterners, and South Asians was reported rose by a factor of more than 16 in the days following the attacks.\nCongress passed and President Bush signed the Homeland Security Act of 2002, creating the Department of Homeland Security, representing the largest restructuring of the U.S. government in contemporary history. Congress passed the USA PATRIOT Act, stating that it would help detect and prosecute terrorism and other crimes. Civil liberties groups have criticized the PATRIOT Act, saying that it allows law enforcement to invade the privacy of citizens and eliminates judicial oversight of law-enforcement and domestic intelligence gathering. The Bush Administration also invoked 9/11 as the reason to have the National Security Agency initiate a secret operation, \"to eavesdrop on telephone and e-mail communications between the United States and people overseas without court approval.\"\nNational Security Entry-Exit Registration System (NSEERS).\nOn June 6, 2002, Attorney General Ashcroft proposed regulations that would create a special registration program that required males aged 16 to 64 who were citizens of designated foreign nations resident in the U.S. to register with the Immigration and Naturalization Service (INS), have their identity verified, and be interviewed, photographed and fingerprinted. Called the National Security Entry-Exit Registration System (NSEERS), it comprised two programs, the tracking of arrivals and departures on the one hand, and voluntary registrations of those already in the U.S., known as the \"call-in\" program. The DOJ acted under the authority of the Immigration and Nationality Act of 1952, which had authorized a registration system but was allowed to lapse in the 1980s because of budget concerns. Ashcroft identified those required to register as \"individuals of elevated national security concern who stay in the country for more than 30 days.\"\nThe processing of arrivals as part of their customs screening began in October 2002. It first focused on arrivals from Iran, Iraq, Libya, Sudan, and Syria. It handled 127,694 people before being phased out as universal screening processes were put in place.\nThe \"call-in\" registrations began in December. It initially applied to nationals of five countries, Iran, Iraq, Syria, Libya, and Sudan, who were required to register by December 16, 2002. On November 6, the United States Department of Justice (DOJ) set a deadline of January 10 for those from another 13 countries: Afghanistan, Algeria, Bahrain, Eritrea, Lebanon, Morocco, North Korea, Oman, Qatar, Somalia, Tunisia, the United Arab Emirates, and Yemen. On December 16, it set a deadline of February 21 for those from Armenia, Pakistan, and Saudi Arabia. It later included those from Egypt, Jordan, Kuwait, Indonesia, and Bangladesh. It eventually included citizens of 23 nations with majority Muslim populations, as well as Eritrea, which has a large Muslim population, and North Korea. Failure to register at an INS office resulted in deportation. Those found in violation of their visa were allowed to post bail while processed for deportation. The program registered 82,880 people, of whom 13,434 were found in violation of their visas. Because nationality and Muslim affiliation are only approximations of one another, the program extended to such non-Muslims as Iranian Jews. The program was phased out beginning in May 2003.\nThe program received a mixed response. Some government officials pronounced the program a success. They said in the course of the combined programs, registration upon entry, and that of residents, they had arrested 11 suspected terrorists, found more than 800 criminal suspects or deportable convicts, and identified more than 9,000 illegal aliens. DOJ general counsel Kris Kobach said: \"I regard this as a great success. Sept. 11th awakened the country to the fact that weak immigration enforcement presents a huge vulnerability that terrorists can exploit.\" DOJ officials said fewer than 5% of those who came into INS offices to register were detained. James W. Ziglar, former head of INS who left the agency early in 2002, in part because of his differing opinions about the program with Ashcroft, said his objections to it had been proven correct: \"The people who could be identified as terrorists weren't going to show up. This project was a huge exercise and caused us to use resources in the field that could have been much better deployed.\" \"As expected, we got nothing out of it.\" Although Homeland Security officials said that six men allegedly linked to terrorism were arrested as a result of the call-in program, that contention was challenged by the Sept. 11 commission, which found little evidence to support that claim.\nIn 2011, DHS suspended the program on efficiency grounds, stating that all NSEERS information was now collected from other sources. It completely glossed over the program's civil liberties costs and did not communicate with those harmed by the program, according to the ACLU. NSEERS was finally officially terminated in 2016 by the Obama administration in order to make it more difficult for President-elect Donald Trump to achieve his goal of introducing a Muslim registry.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28064", "revid": "12396222", "url": "https://en.wikipedia.org/wiki?curid=28064", "title": "Financial assistance following the September 11 attacks", "text": "Charities and relief agencies raised over $657 million in the three weeks following the September 11, 2001 attacks, the vast bulk going to immediate survivors and victims' families.\nGovernment assistance.\nOn September 21, 2001, the Congress approved a bill to aid the airline industry and establish a federal fund for victims. The cost of the mostly open-ended fund reached $7 billion. Victims of earlier terrorist attacks, including those linked to al-Qaida, were not included in the fund, nor were those who would not surrender the right to hold the airlines legally responsible.\nAmerican Red Cross.\nIn the aftermath of the attack, the American Red Cross' Liberty Fund amassed $547 million in donations. The charitable organization halted the collection of donations in October 2001, announcing that the monies pledged would be enough to cover immediate and longterm efforts to support the victims of the attack. While the Red Cross initially announced its intentions to put as much as $247 million of the fund toward preparedness for future terrorist attacks, the organization reversed course in the wake of extreme criticism and announced the entire fund would go toward victims.\nIn February of 2002, the New York Times reported that the Red Cross had \"distributed about $200 million to more than 30,000 displaced workers\" as of the date of publication.\nIn addition to financial donations, the American Red Cross collected nearly 1.2 million units of blood between Sept. 11 and Oct. 30, according to a New York Times article published in November of 2001.\nEmergency supplies.\nOn Thursday and Friday, September 14\u201315 September 2001, various relief supplies for the World Trade Center relief effort were collected from the New York City area, and dropped off at the Javits Convention Center or at a staging area at Union Square. By Saturday morning, enough supplies (and volunteers) were collected.\nMemorial funds.\nMany families and friends of victims have set up memorial funds and projects to give back to their communities and change the world in honor of their loved ones' lives. Examples include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28066", "revid": "992015", "url": "https://en.wikipedia.org/wiki?curid=28066", "title": "Rescue and recovery effort after the September 11 attacks on the World Trade Center", "text": "The September 11 attacks on the World Trade Center elicited a large response of local emergency and rescue personnel to assist in the evacuation of the two towers, resulting in a large loss of the same personnel when the towers collapsed. After the attacks, the media termed the World Trade Center site \"Ground Zero\", while rescue personnel referred to it as \"the Pile\".\nIn the ensuing recovery and cleanup efforts, personnel related to the metalwork and construction professions would descend on the site to offer their services and remained until the site was cleared in May 2002. In the years since, investigations and studies have examined effects upon those who participated, noting a variety of afflictions attributed to the debris and stress.\nBuilding evacuation.\nAfter American Airlines Flight 11 crashed into the North Tower (1 WTC) of the World Trade Center, a standard announcement was given to tenants in the South Tower (2 WTC) to stay put and that the building was secure. However, many defied those instructions and proceeded to evacuate the South Tower (most notably, Rick Rescorla, Security Director at Morgan Stanley, evacuated 2,687 of the 2,700 Morgan Stanley employees in the building). People evacuating from WTC 2 were ordered up from the lobby level to a door on the mezzanine level that led to a covered footbridge over West Street to a building complex then called the World Financial Center. People evacuating from WTC 1 were directed from the lobby level through the WTC shopping mall beneath the outdoor plaza. The firefighters directing evacuees did not want anyone going through the front doors because of falling debris and falling people.\nStandard evacuation procedures for fires in the World Trade Center called for evacuating only the floors immediately above and below the fire, as simultaneous evacuation of up to 50,000 workers would be too chaotic.\nEmergency response.\nFirefighters.\nFirefighters from the New York City Fire Department (FDNY) rushed to the World Trade Center minutes after the first plane struck the North Tower. Chief Joseph W. Pfeifer and his crew with Battalion 1 were among the first on the scene (Battalion 1 was the first Unit to notify the Manhattan Central Office.). Engine 10 and Ladder 10 were also some of the first on scene because their firehouse was directly across the street from the Towers. At 8:50\u00a0a.m., an Incident Command Post was established in the lobby of the North Tower. By 9:00\u00a0a.m., shortly before United Airlines Flight 175 hit the South Tower, the FDNY chief had arrived and taken over command of the response operations. Concerned about falling debris, he moved the incident command center to a spot located across West Street, but numerous fire chiefs remained in the lobby which continued to serve as an operations post where alarms, elevators, communications systems, and other equipment were operated. The initial response by the FDNY was on rescue and evacuation of building occupants, which involved sending firefighters up to assist people that were trapped in elevators and elsewhere. Firefighters were also required to ensure all floors were completely evacuated.\nNumerous staging areas were set up near the World Trade Center, where responding fire units could report and get deployment instructions. However, many firefighters arrived at the World Trade Center without stopping at the staging areas, partly because at 8:48\u00a0a.m. Battalion 1 transmitted a Third Alarm and ordered third alarm units to the Staging Area and second alarm units to the Towers. As a result, many chiefs could not keep track of the whereabouts of their units. Numerous firefighters reported directly to the building lobbies and were ordered by those commanding the operating post to proceed into the building.\nProblems with radio communication caused commanders to lose contact with many of the firefighters who went into the buildings. The repeater system in the World Trade Center, which was required for portable radio signals to transmit reliably, was malfunctioning after the impact of the planes. As a result, firefighters were unable to report to commanders on their progress, and were unable to hear evacuation orders. In addition, many off-duty firefighters arrived to help without their radios. FDNY commanders lacked communication with the New York City Police Department (NYPD), who had helicopters at the scene, or with Emergency Medical Services (EMS) dispatchers. The firefighters on the scene also did not have access to television reports or other outside information, which could help in assessing the situation. When the South Tower collapsed at 9:59\u00a0a.m., firefighters in the North Tower were not aware of exactly what happened. The battalion chief in the North Tower lobby immediately issued an order over the radio for firefighters in the tower to evacuate, but many did not hear the order on the faulty radios. Because of this, 342 firefighters died in the collapse of the towers.\nThe command post located across West Street was taken out when the South Tower collapsed, making command and control even more difficult and disorganized. When the North Tower collapsed, falling debris killed Peter Ganci, the FDNY chief. Following the collapse of the World Trade Center, a command post was set up at a firehouse in Greenwich Village.\nThe FDNY deployed more than 200 units (about half of all units) to the site, with more than 400 firefighters on the scene when the buildings collapsed. This included a total of 121 engine companies, 62 ladder companies, and other special units. The FDNY also received assistance from fire departments in Nassau, Suffolk, Westchester County, and other neighboring jurisdictions, but with limited ability to manage and coordinate efforts.\nBesides assisting with recovery operations at Ground Zero, volunteer firefighters from Long Island and Westchester manned numerous firehouses throughout the city to assist with other fire and emergency calls.\nSteve Buscemi helped as a volunteer the day after the attacks \nDoctors, EMS, and other medical staff.\nFDNY emergency medical technicians (EMTs) and paramedics, along with 9-1-1 system ambulances operated by voluntary hospitals and volunteer ambulance corps, began arriving at 8:53\u00a0a.m., and quickly set up a staging area outside the North Tower, at West Street, which was quickly moved over to the corner of Vesey and West Streets. As more providers responded to the scene, five triage areas were set up around the World Trade Center site. EMS chiefs experienced difficulties communicating via their radios because of the overwhelming volume of radio traffic. At 9:45, an additional dispatch channel was set aside for use by chiefs and supervisors only, but many did not know about this and continued to operate on the other channel. The communication difficulties meant that commanders lacked good situational awareness.\nDispatchers at the 9-1-1 call center, who coordinate EMS response and assign units, were overwhelmed with incoming calls, as well as communications over the radio system. Dispatchers were unable to process and make sense of all the incoming information, including information from people trapped in the towers, about conditions on the upper floors. Overwhelmed dispatchers were unable to effectively give instructions and manage the situation.\nEMS personnel were in disarray after the collapse of the South Tower at 9:59\u00a0a.m. Following the collapse of the North Tower at 10:28\u00a0a.m., EMS commanders regrouped on the North End of Battery Park City, at the Embassy Suites Hotel. Around 11:00\u00a0a.m., EMS triage centers were relocated and consolidated at the Chelsea Piers and the Staten Island Ferry Terminal. Throughout the early afternoon, the soundstages at the pier were separated into two areas, one for the more seriously injured and one for the walking wounded. On the acute side, multiple makeshift tables, each with a physician, nurse, and other health care workers, and non-emergency service volunteers, were set up for the arrival of mass casualties.\nSupplies, including equipment for airway and vascular control, were obtained from neighboring hospitals. Throughout the afternoon, local merchants arrived to donate food. Despite this, few patients arrived for treatment, the earliest at about 5 p.m. around the time that Building 7 collapsed, and were not seriously injured, being limited to smoke inhalation. An announcement was made around 6\u20137 p.m. that a second shift of providers would cover the evening shift, and that an area was being set up for the day personnel to sleep. Soon after, when it was realized that few would have survived the collapse and be brought to the piers, many decided to leave and the area was closed down.\nPolice.\nThe New York City Police Department (NYPD) quickly responded with the Emergency Service Units (ESU) and other responders after the crash of American Airlines Flight 11 into the North Tower. The NYPD set up its incident command center at Church Street and Vesey Street, on the opposite side of the World Trade Center from where the FDNY was commanding its operations. NYPD helicopters were soon at the scene, reporting on the status of the burning buildings. When the buildings collapsed, 23 NYPD officers were killed, along with 37 Port Authority Police Department officers. The NYPD helped facilitate the evacuation of civilians out of Lower Manhattan, including approximately 5,000 civilians evacuated by the Harbor Unit to Staten Island and to New Jersey. In ensuing days, the police department worked alternating 12-hour shifts to help in the rescue and recovery efforts.\nCoast Guard, maritime industry, individual boat owners.\nImmediately after the first attack, the captains and crews of a large number of local boats steamed into the attack zone to assist in evacuation. These ships had responded to a request from the U.S. Coast Guard to help evacuate those stranded on Manhattan Island. Others, such as the \"John J. Harvey\", provided supplies and water, which became urgently needed after the Towers' collapse severed downtown water mains. The Coast Guard Auxiliary helped lead a massive maritime evacuation with estimates of the number of people evacuated by water from Lower Manhattan that day in the eight-hour period following the attacks ranging from 500,000 to 1,000,000. Norman Mineta, Secretary of Transportation during the attacks, called the efforts \"the largest maritime evacuation conducted in the United States\". The evacuation was the largest maritime evacuation or \"boatlift\" in history by most estimates, passing the nine-day evacuation of Dunkirk during World War II. As many as 2,000 people injured in the attacks were evacuated by these means.\nAmateur radio.\nAmateur radio played a role in the rescue and clean-up efforts. Amateur radio operators established communications, maintained emergency networks, and formed bucket brigades with hundreds of other volunteer personnel. Approximately 500 amateur radio operators volunteered their services during the disaster and recovery.\nThe New Jersey Legislature honored the role of amateur radio operators in a proclamation on December 12, 2002.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"I would like to take this opportunity to commend you for your hard work and efforts,\" said Assembly Speaker Albio Sires. \"During times of disaster, your group has displayed superior service and dedication to the safety of our citizens. I applaud the efforts of the independent radio operators and thank you for your selfless actions on September 12, 2001. Allow me to express my sincere gratitude for your participation with the New Jersey General Assembly on this day, December 12, 2002.\"\nNote: \"Government exhibits are from the trial of Zacarias Moussaoui.\"\nSearch and rescue efforts.\nOn the day following the attacks, eleven people were rescued from the rubble, including six firefighters and three police officers. One woman was rescued from the rubble, near where a West Side Highway pedestrian bridge had been. Two PAPD officers, John McLoughlin and Will Jimeno, were also rescued. Discovered by former U.S. Marines Jason Thomas and Dave Karnes, McLoughlin and Jimeno were pulled out alive after spending nearly 24 hours beneath of rubble. Their rescue was later portrayed in the 2006 film \"World Trade Center\". In total, twenty survivors were pulled out of the rubble. The final survivor, Port Authority secretary Genelle Guzman-McMillan, was rescued 27 hours after the collapse of the North Tower.\nSome firefighters and civilians who survived made cell phone calls from voids beneath the rubble, though the amount of debris made it difficult for rescue workers to get to them.\nBy Wednesday night, 82 deaths had been confirmed by officials in New York City.\nRescue efforts were paused numerous times in the days after the attack because nearby buildings, including One Liberty Plaza, were in danger of collapsing. The last fires at the World Trade Center site were extinguished on December 20, exactly 100 days after the attacks.\nRecovery efforts.\nThe search and rescue effort in the immediate aftermath at the World Trade Center site involved ironworkers, structural engineers, heavy machinery operators, asbestos workers, boilermakers, carpenters, cement masons, construction managers, electricians, insulators, machinists, plumbers and pipefitters, riggers, sheet metal workers, steelworkers, truckers and teamsters, American Red Cross volunteers, and many others. Lower Manhattan, south of 14th Street, was off-limits, except for rescue and recovery workers. There were also about 400 working dogs, the largest deployment of dogs in the nation's history.\nOrganization.\nNew York City Office of Emergency Management (OEM) was the agency responsible for coordination of the city's response to the attacks. Headed by then-Director Richard Sheirer, the agency was forced to vacate its headquarters, located in 7 World Trade Center, within hours of the attack. The building later collapsed. OEM reestablished operations temporarily at the police academy, where Mayor Giuliani gave many press conferences throughout the afternoon and evening of September 11. By Friday, rescue and reliefs were organized and administered from Pier 92 on the Hudson River.\nVolunteers quickly descended on Ground Zero to help in the rescue and recovery efforts. At Jacob Javits Convention Center, thousands showed up to offer help, where they registered with authorities. Construction projects around the city came to a halt, as workers walked off the jobs to help at Ground Zero. Ironworkers, welders, steel burners, and others with such skills were in high demand. By the end of the first week, over one thousand ironworkers from across North America had arrived to help, along with countless others.\nThe New York City Department of Design &amp; Construction oversaw the recovery efforts. Beginning on September 12, the Structural Engineers Association of New York (SEAoNY) became involved in the recovery efforts, bringing in experts to review the stability of the rubble, evaluate safety of hundreds of buildings near the site, and designing support for the cranes brought in to clear the debris. The City of New York hired the engineering firm, LZA-Thornton Tomasetti, to oversee the structural engineering operations at the site.\nTo make the effort more manageable, the World Trade Center site was divided into four quadrants or zones. Each zone was assigned a lead contractor, and a team of three structural engineers, subcontractors, and rescue workers.\nThe Federal Emergency Management Agency (FEMA), the United States Army Corps of Engineers, the Occupational Safety and Health Administration (OSHA), and the New York City Office of Emergency Management (OEM) provided support. Forestry incident management teams (IMTs) also provided support beginning in the days after the attacks to help manage operations.\nA nearby Burger King restaurant was used as a center for police operations. Given that workers worked at the site, or \"The Pile\", for shifts as long as twelve hours, a specific culture developed at the site, leading to workers developing their own argot.\nDebris removal.\n\"The Pile\" was the term coined by the rescue workers to describe the 1.8 million tons of wreckage left from the collapse of the World Trade Center. They avoided the use of \"ground zero\", which describes the epicenter of a bomb explosion.\nNumerous volunteers organized to form \"bucket brigades\", which passed 5-gallon buckets full of debris down a line to investigators, who sifted through the debris in search of evidence and human remains. Ironworkers helped cut up steel beams into more manageable sizes for removal. Much of the debris was hauled off to the Fresh Kills Landfill on Staten Island where it was further searched and sorted.\nAccording to \"The New York Times\", by September 24, 2001, more than 100,000 tons of debris had been removed from the site. Some structural engineers have criticized the decision to recycle the steel from the buildings before it could be analyzed as part of the post-collapse investigation.\nReuse of steel.\nSome of the steel was reused for memorials. New York City firefighters donated a cross made of steel from the World Trade Center to the Shanksville Volunteer Fire Company in Shanksville, Pennsylvania. The beam, mounted atop a platform shaped like the Pentagon, was erected outside the Shanksville's firehouse near the crash site of United Airlines Flight 93.\nTwenty-four tons of the steel used in construction of USS \"New York\" (LPD-21) came from the small amount of rubble from the World Trade Center preserved for posterity.\nVaulted bullion.\nIn the days following the destruction of the towers, rescuers found scorch marks, likely made by a cutting torch on a basement doorway underneath 4 WTC; this was thought to be the result of looters. Further exploration of the building's basement revealed that the vault contained large amounts of gold and silver in the form of coins, as well as gold and silver bars. An armored truck operated by COMEX was also located below the World Trade Center among the other vehicles, which was fully loaded with gold and silver bars. In order to retrieve the bullion from the vault, electricity had to be supplied to its doors, which had withstood the force of the destruction above them.\nOver the subsequent months, much of the bullion was recovered. Approximately 560,000 dollars' worth of coins and bars were stored in the vault by the Bank of Nova Scotia prior to September 11, 2001, with the bank having stored a total of 379,036 troy ounces of gold and 29,942,619 troy ounces of silver inside the vault. Many of these coins were purchased by Lee S. Minshull of Palos Verdes, California, who then sent them to PCGS for grading in 2002. These coins were then sold to collectors. Coins salvaged from 4 WTC's vault included American Silver Eagles, Canadian Gold Maple Leafs, South African Krugerrands and British Gold Britannias.\nHazards.\nHazards at the World Trade Center site included a diesel fuel tank buried seven stories below. Approximately 2,000 automobiles that had been in the parking garage also presented a risk, with each containing, on average, at least of gasoline. Once recovery workers reached down to the parking garage level, they found some cars that had exploded and burned. The United States Customs Service, which was housed in 6 World Trade Center, had 1.2 million rounds of ammunition and weapons in storage in a third-floor vault, to support their firing range.\nMorale.\nIn the hours immediately after the attacks on the World Trade Center, three firefighters raised an American flag over the rubble. The flag was taken from a yacht, and the moment, which was captured on a well-known photograph, evoked comparisons to the iconic Iwo Jima photograph from 1945. Morale of rescue workers was boosted on September 14, 2001, when President George W. Bush paid a visit to Ground Zero. Standing with retired firefighter Bob Beckwith, Bush addressed the firefighters and rescue workers with a bullhorn and thanked them. Bush later remarked, \"I'm shocked at the size of the devastation, It's hard to describe what it's like to see the gnarled steel and broken glass and twisted buildings silhouetted against the smoke. I said that this was the first act of war on America in the 21st century, and I was right, particularly having seen the scene.\" After some workers shouted that they could not hear the President, Bush famously responded by saying \"I can hear you! The rest of the world hears you. And the people who knocked these buildings down will hear all of us soon!\"\nAt some point, rescue workers realized that they were not going to find any more survivors. After a couple of weeks, the conditions at Ground Zero remained harsh, with lingering odors of decaying human remains and smoke. Morale among workers was boosted by letters they received from children around the United States and the world, as well as support from thousands of neighbors in TriBeCa and other Lower Manhattan neighborhoods.\nThis support continued to spread and eventually led to the founding of over 250 non-profit organizations of which raised almost $700 million within their first two years of operation. One of the nonprofits included One Day's Pay, later changed to MyGoodDeed, which championed the effort to designate September 11 as an official National Day of Service (9/11 Day).\nBy 2012, many of the more than 250 organizations had disbanded for lack of funding. Of the ones that remain, a handful remained functioning for those who remain in need. One of these organizations, Tuesday's Children, was founded the day after September 11 in hopes of supporting the children immediately affected by the attacks. The founder of this non-profit, David Weild IV, now calls them one of the \"last men standing\" in that they are now one of the few remaining organizations who \"provide direct services for what social-service groups and survivors of the attacks call the '9-11 Community.'\"\nOther notable non-profits who are \"still standing\" include:\nMilitary support.\nCivil Air Patrol.\nImmediately following the attacks, members of the Civil Air Patrol (CAP) were called up to help respond. Northeast Region placed its personnel and assets on alert moments after learning of the attack. With the exception of CAP, civilian flights were grounded by the Federal Aviation Administration. CAP flew aerial reconnaissance missions over Ground Zero in order to provide detailed analysis of the wreckage and aid in recovery efforts, including transportation of blood donations.\nNational Guard.\nElements of the New York Army National Guard's 1-101st Cavalry (Staten Island), 258th Field Artillery, 442nd Military Police Company, and 69th Infantry Regiment based in Manhattan were the first military force to secure Ground Zero on September 11. The 69th Infantry's armory on Lexington Avenue became the Family Information Center to assist persons in locating missing family members.\nThe National Guard supplemented the NYPD and FDNY, with 2,250 guard members on the scene by the next morning. Eventually thousands of New York Army and Air National Guardsmen participated in the rescue/recovery efforts. They conducted site security at the WTC, and at other locations. They provided the NYPD with support for traffic control, and they participated directly in recovery operations providing manpower in the form of \"bucket brigades\" sorting through the debris by hand.\nAdditionally service members provided security at a variety of location throughout the city and New York State to deter further attacks and reassure the public.\nMembers of the Air National Guard's 109th Airlift Wing out of Scotia, and Syracuse's 174th Fighter Wing immediately responded to New York City, setting up camp at places such as Fort Hamilton. Mostly civil engineers, firefighters and military police, they greatly aided in the clean-up effort. F-16s from the 174th Fighter Wing also ramped up their flying sorties and patrolled the skies.\nThe New Jersey National Guard assisted the New York National Guard's efforts following the attacks.\nU.S. Marine Corps.\nU.S. Marines were also present to assist in the rescue efforts. No official numbers of men who helped out was released but there was evidence that they were there.\nFilms such as 2006 docudrama \"World Trade Center\" and the 2021 documentary \"\" talked of two Marines who rescued two trapped police officers in the rubble. U.S. Marines were headquartered at 340 Westside Hwy Bloomberg News Building. The commanding officer was Navy Commander Hardy, and executive officer was Maj. Priester. These two oversaw 110 military personnel of various branches, various police departments and EMTs.\nU.S. Navy.\nThe U.S. Navy deployed a hospital ship USNS \"Comfort\" (T-AH-20) to Pier 92 in Manhattan. Crew members provided food and shelter for more than 10,000 relief workers. Comfort's 24-hour galley also provided 30,000 meals. Its medical resources were also used to provide first-aid and sick call services to nearly 600 people. The ship's psychological response team also saw more than 500 patients.\nHandling of cleanup procedure.\nA May 14, 2007, \"New York Times\" article, \"Ground Zero Illness Clouding Giuliani's Legacy\", gave the interpretation that thousands of workers at Ground Zero have become sick and that \"regard Mr. Giuliani's triumph of leadership as having come with a human cost\". The article reported that the mayor seized control of the cleanup of Ground Zero, taking control away from established federal agencies, such as the Federal Emergency Management Agency, the U.S. Army Corps of Engineers and the Occupational Safety and Health Administration. He instead handed over responsibility to the \"largely unknown\" city Department of Design and Construction. Documents indicate that the Giuliani administration never enforced federal requirements requiring the wearing of respirators. Concurrently, the administration threatened companies with dismissal if cleanup work slowed.\nWorkers at the Ground Zero pit worked without proper respirators. They wore painters' masks or no facial covering. Specialists claim that the only effective protection against toxins, such as airborne asbestos, is a special respirator. New York Committee for Occupational Safety and Health industrial hygienist David Newman said, \"I was down there watching people working without respirators.\" He continued, \"Others took off their respirators to eat. It was a surreal, ridiculous, unacceptable situation.\"\nThe local EPA office sidelined the regional EPA office. Dr. Cate Jenkins, a whistle-blower EPA scientist, said that on September 12, 2001, a regional EPA office offered to dispatch 30 to 40 electron microscopes to the WTC pit to test bulk dust samples for the presence of asbestos fibers. Instead, the local office chose the less effective polarized light microscopy testing method. Dr. Jenkins alleged that the local office refused, and said, \"We don't want you fucking cowboys here. The best thing they could do is reassign you to Alaska.\"\nHealth effects.\nThere were many health problems caused by the toxins. 99% of exposed firefighters reported at least one new respiratory problem while working at the World Trade Center site that they had not experienced before. Chronic airway disease is the main lung injury among firefighters who were exposed to toxins during 9/11. Six years after the attacks, among those who never smoked, approximately 13% of firefighters and 22% of EMS had lungs that did not function as well as others around the same age. Steep declines in pulmonary lung function has been a problem since first detected among firefighters and EMS within a year of 9/11 have persisted.\nIncreasing numbers of Ground Zero workers are getting illnesses, such as cancer. Between September 11, 2001, through 2008, there were 263 new cases of cancer found in 8,927 male firefighters who responded to 9/11 attacks. This number is 25 more than what is expected from men from a similar age group and race. There is a 19% increase in cancer overall, between firefighters who responded to the attacks and those who were not exposed to toxins from responding to the attacks on September 11.\nOn January 30, 2007, Ground Zero workers and groups such as Sierra Club and Unsung Heroes Helping Heroes met at the Ground Zero site and urged President George Bush to spend more money on aid for sick Ground Zero workers. They said that the $25 million that Bush promised for the ill workers was inadequate. A Long Island iron-worker, John Sferazo, at the protest rally said, \"Why has it taken you 5\u00bd years to meet with us, Mr. President?\"\nFirefighters, police and their unions, have criticized Mayor Rudy Giuliani over the issue of protective equipment and illnesses after the attacks. A study by the National Institute of Environmental Safety and Health said that cleanup workers lacked adequate protective gear. The Executive Director of the National Fraternal Order of Police reportedly said of Giuliani: \"Everybody likes a Churchillian kind of leader who jumps up when the ashes are still falling and takes over. But two or three good days don't expunge an eight-year record.\" Sally Regenhard, said, \"There's a large and growing number of both FDNY families, FDNY members, former and current, and civilian families who want to expose the true failures of the Giuliani administration when it comes to 9/11.\" She told the \"New York Daily News\" that she intends to \"Swift Boat\" Giuliani.\nVarious health programs arose after the attacks to provide treatment for 9/11-related illnesses among responders, recovery workers, and other survivors. When the James Zadroga 9/11 Health and Compensation Act became federal law in January 2011, these programs were replaced by the World Trade Center Health Program.\nInvestigations.\nSoon after the attacks, New York City commissioned McKinsey &amp; Company to investigate the response of both the New York City Fire Department and New York City Police Department and make recommendations on how to respond more effectively to such large-scale emergencies in the future.\nOfficials with the International Association of Fire Fighters have also criticized Rudy Giuliani for failing to support modernized radios that might have spared the lives of more firefighters. Some firefighters never heard the evacuation orders and died in the collapse of the towers.\nEstimated costs.\nEstimated total costs, as of October 3, 2001\n$5 billion for debris removal\n$14 billion for reconstruction\n$3 billion in overtime payments to uniformed workers\n$1 billion for replacement of destroyed vehicles and equipment\n(one Fire Department accident response vehicle costs $400,000)\nReconstruction.\nPlans for the World Trade Center rebuilding started in July 2002 which was headed by the Lower Manhattan Development Corporation. There were rounds of proposals on how to rebuild the World Trade Center; however, many of the early schemes were criticized for lacking creativity. There was division among members of the public, architects, and political leadership as to what an appropriate new World Trade Center would look like. Several architects were chosen and replaced throughout the planning and design process; there were issues with implementing the early designs. By 2006 all architects for the site had been chosen and designs were largely finalized in 2007. The date of completion for the World Trade Center was scheduled for 2016. As of \u00a011, 2018[ [update]], four of seven planned buildings were completed, as were the transportation hub, 9/11 Memorial, and Liberty Park.\nReferences.\nNotes\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography\nExternal links.\nNew York Times:\nOther:"}
