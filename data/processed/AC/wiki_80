{"id": "28070", "revid": "47988270", "url": "https://en.wikipedia.org/wiki?curid=28070", "title": "Communication during the September 11 attacks", "text": "Communication problems during the September 11 attacks\nCommunication problems and successes played an important role during the September 11 attacks in 2001 and their aftermath. Systems were variously destroyed or overwhelmed by loads greater than they were designed to carry, or failed to operate as intended or desired.\nAttackers.\nThe organizers of the September 11, 2001 terrorist attacks apparently planned and coordinated their mission in face to face meetings and used little or no electronic communication. This \"radio silence\" made their plan more difficult to detect.\nFederal government.\nAccording to 9/11 Commission staff statement No. 17 there were several communications failures at the federal government level during and after the 9/11 attacks. Perhaps the most serious occurred in an \"Air Threat Conference Call\" initiated by the National Military Command Center (NMCC) after two planes had crashed into the World Trade Center, but shortly before The Pentagon was hit. The participants were unable to include the Federal Aviation Administration (FAA) air traffic control command center, which had the most information about the hijackings, in the call.\nAccording to the staff report:\nOperators worked feverishly to include the FAA in this teleconference, but they had equipment problems and difficulty finding secure phone numbers. NORAD asked three times before 10:03 to confirm the presence of FAA on the conference, to provide an update on hijackings. The FAA did not join the call until 10:17. The FAA representative who joined the call had no familiarity with or responsibility for a hijack situation, had no access to decision makers, and had none of the information available to senior FAA officials by that time.\nWe found no evidence that, at this critical time, during the morning of September 11, NORAD\u2019s top commanders, in Florida or Cheyenne Mountain Complex, ever coordinated with their counterparts at FAA headquarters to improve situational awareness and organize a common response. Lower-level officials improvised\u2014the FAA\u2019s Boston Center bypassing the chain of command to contact NEADS. But the highest level Defense Department officials relied on the NMCC\u2019s Air Threat Conference, in which FAA did not meaningfully participate.\nFirst responders.\nAfter the 1993 World Trade Center bombing, radio repeaters for New York City Fire Department communication were installed in the tower complex. Because they were unaware that several controls needed to be operated to fully activate the repeater system, fire chiefs at their command post in the lobby of the North Tower thought the repeater was not functioning and did not use it, though it did work and was used by some firefighters. When police officials concluded the twin towers were in danger of collapsing and ordered police to leave the complex, fire officials were not notified. Fire officials on the scene were not monitoring broadcast news reports and did not immediately understand what had happened when the first (South) tower collapsed.\nThere was little communication between New York City Police Department and fire department commands even though an Office of Emergency Management (OEM) had been created in 1996 in part to provide such coordination. A primary reason for OEM's inability to coordinate communications and information-sharing in the early hours of the WTC response was the loss of its emergency operations center, located on the twenty third floor of 7 World Trade Center, which had been evacuated after debris from the main tower's collapse struck the building. This ignited several fires that caused it to collapse at 5 pm later that day.\nEmergency relief efforts in both Lower Manhattan and at the Pentagon were augmented by volunteer amateur radio operators in the weeks after the attacks.\nVictims.\nCell phones and in-plane credit card phones played a major role during and after the attack, starting with hijacked passengers who called family or notified the authorities about what was happening. Passengers and crew who made calls include: Sandra Bradshaw, Todd Beamer, Tom Burnett, Mark Bingham, Peter Hanson, Jeremy Glick, Barbara Olson, Renee May, Madeline Amy Sweeney, Betty Ong, Robert Fangman, Brian David Sweeney, and Ed Felt. Passengers and crew aboard United Airlines Flight 93 were able to assess their situation based on these conversations and plan a revolt that resulted in the aircraft crashing before reaching the hijackers\u2019 intended target. According to the commission staff: \"Their actions saved the lives of countless others, and may have saved either the U.S. Capitol or the White House from destruction.\"\nAccording to the \"9/11 Commission Report\", 13 passengers from Flight 93 made a total of over 30 calls to both family and emergency personnel (twenty-two confirmed air phone calls, two confirmed cell phone and eight not specified in the report). Brenda Raney, Verizon Wireless spokesperson, said that Flight 93 was supported by several cell sites. There were reportedly three phone calls from Flight 11, five from Flight 175, and three calls from Flight 77. Two calls from these flights were recorded, placed by flight attendants: Betty Ong on Flight 11 and CeeCee Lyles on Flight 93.\nAlexa Graf, an AT&amp;T spokesperson, said it was almost a fluke\nthat the calls reached their destinations. Marvin Sirbu, professor of Engineering and Public Policy at Carnegie Mellon University said on September 14, 2001, that \"The fact of the matter is that cell phones can work in almost all phases of a commercial flight.\" Other industry experts said that it is possible to use cell phones with varying degrees of success during the ascent and descent of commercial airline flights.\nAfter each of the hijacked aircraft struck the World Trade Center, people inside the towers made calls to family and loved ones; for the victims, this was their last communication. Other callers directed their pleas for help to 9-1-1. Over nine hours of the 9-1-1 calls were eventually released after petitioning by \"The New York Times\" and families of the WTC victims. In 2001, U.S. cell phones did not yet have the photography capabilities that became widespread by the mid-2000s.\nGeneral public.\nAfter the attack, the cell phone networks of New York City and the Tri-State area were rapidly overloaded (a mass call event) as traffic doubled over normal levels. Cell phone traffic also overloaded across the East Coast, leading to crashes of the cell phone network. Verizon's downtown wire phone service was interrupted for days and weeks because of cut subscriber cables, and to the 140 West Street exchange being shut for days. Capacity between Brooklyn and Manhattan was also diminished by cut trunk cables.\nFollowing the attacks, the issues with the cell network weren't resolved until 36 cellular COWs (cell towers on wheels) were deployed by September 14, 2001, in Lower Manhattan to support the U.S. Federal Emergency Management Agency (FEMA) and provide critical phone service to rescue and recovery workers.\nSince three of the major television broadcast network owned-and-operated stations had their transmission towers atop the North Tower (One World Trade Center), coverage was limited after the collapse of the tower. The FM transmitter of National Public Radio station WNYC was also destroyed in the collapse of the North Tower and its offices evacuated. For an interim period, it continued broadcasting on its AM frequency and used NPR's New York offices to produce its programming.\nThe satellite feed of one television station, WPIX, froze on the last image received from the WTC mast; the image (a remote-camera shot of the burning towers), viewable across North America (as WPIX is available on cable TV in many areas), remained on the screen for much of the day until WPIX was able to set up alternate transmission facilities. It shows the WTC at the moment power cut off to the WPIX transmitter, prior to the towers' collapse.\nDuring the September 11 attacks, WCBS-TV channel 2 and WXTV-TV channel 41 stayed on the air. Unlike most other major New York television stations, WCBS-TV maintained a full-powered backup transmitter at the Empire State Building after moving its main transmitter to the North Tower of the World Trade Center. The station was also simulcasted nationally on Viacom (which at the time owned CBS) cable network VH1 that day. In the immediate aftermath of the attacks, the station lent transmission time to the other stations who had lost their transmitters, until they found suitable backup equipment and locations.\nThe Emergency Alert System was never activated in the terrorist attacks, as the extensive media coverage made it unnecessary.\nAT&amp;T eliminated any costs for domestic calls originating from the New York City area (phones using area codes 212, 718, 917, 646, and 347) in the days following 9/11.\nRadio communications.\nRadio communications during the September 11 attacks served a vital role in coordinating rescue efforts by New York Police Department, New York Fire Department, Port Authority Police Department, and emergency medical services.\nWhile radio communications were modified to address problems discovered after the 1993 World Trade Center bombing, investigations into the radio communications during the September 11 attacks discovered that communication systems and protocols that distinguished each department was hampered by the lack of interoperability, damaged or failed network infrastructure during the attack, and overwhelmed by simultaneous communication between superiors and subordinates.\nBackground.\nA rough time line of the incident could include:\nThe scale of the incident was described in the National Commission report on the attacks as \"unprecedented\". In roughly seventeen minutes from 8:46 to 9:03 am, over a thousand police, fire, and emergency medical services (EMS) staff arrived at the scene. At some point during a large incident, any agency will reach a point where they find their resources overrun by needs. For example, the Port Authority Police could not schedule staff as if a September 11 attack would occur every shift. There is always a balance struck between readiness and costs. There is conflicting data but some sources suggest there may have been 2,000 to 3,000 workers involved in the rescue operation. It would be rare for most agencies to see an event where there were that many people to be rescued.\nThere is some level of confusion present in any large incident. The National Institute of Standards and Technology (NIST) asserts commanders did not have adequate information and interagency information sharing was inadequate. For example, on September 11, persons in the New York City Police Department (NYPD) 9-1-1 center told callers from the World Trade Center to remain in place and wait for instruction from firefighters and police officers. This was the plan for managing a fire incident in the building and the 9-1-1 center staff were following the plan. This was partly countered by public safety workers going floor-by-floor and telling people to evacuate. The 9/11 Commission report suggests people in the NYPD 9-1-1 center and New York City Fire Department (FDNY) dispatch would benefit from better situation awareness. The Commission described the call centers as not \"fully integrated\" with line personnel at the WTC. The report suggests the NYPD 9-1-1 center and FDNY dispatch were overrun by call volumes that had never been seen before. Adding to the confusion, radio coverage problems, radio traffic blocking, and building system problems occurred inside the burning towers. The facts show that much of the equipment worked as designed and users made the best of what was available to them.\nTypical of any large fire, many 9-1-1 calls with conflicting information were received beginning at 8:46 am. In addition to reports that a plane had hit the World Trade Center, the EMS computer-aided dispatch (CAD) log shows reports of a helicopter crash, explosions, and a building fire. Throughout the incident, people at different locations had very different views of the situation. After the collapse of the first tower, many firefighters in the remaining tower had no idea the first tower had fallen.\nA factor in radio communications problems included the fact that off-duty personnel self-dispatched to the incident scene. Some off-duty staff went into the towers without radios. According to the Commission report and news coverage, this was true of NYPD, Port Authority Police Department (PAPD), and FDNY personnel. Regardless of any radio coverage problems, these persons could not be commanded or informed by radio. In any incident of this scale, self-dispatched staff without radios would likely be a problem. Even if a cache of radios were brought to the scene to hand out, the scale of this incident would be likely to overrun the number of radios in the cache.\nNIST concluded, at the beginning of the incident, there was an approximate factor of five (peak) increase in radio communications traffic over a normal level. After the initial peak, radio traffic through the incident followed an approximate factor of three steady increase. FDNY recordings suggest the dispatch personnel were overloaded: both fire and EMS dispatch were often delayed in responding to radio calls. Many 9-1-1 telephone calls to dispatch were disconnected or routed to \"all circuits are busy now\", intercept recordings.\nVoice radio systems.\nNIST calculated that about one third of radio messages transmitted during the surge of communications were incomplete or unintelligible. Documentary footage suggests the tactical channels were also overloaded; some footage captured audio of two or three conversations occurring simultaneously on a particular channel.\nIn this study of WTC incident communications, radio systems used at the site had problems but were generally effective in that users were able to communicate with one another. A 2002 video documentary \"9/11\" by Gedeon and Jules Naudet, (referred to as \"the documentary\") was reviewed. It captured audio from hand-held radios in use at the incident and showed users communicating over radios from the lobby command post in the North Tower. 26 Red Book audio CDs of New York City Fire Department radio transmissions, covering the incident's initial dispatch and the tower failures, were reviewed. These CDs were digitized versions of audio from the Fire Department's logging recorders. In addition, text on an oral history CD with transcripts of fire personnel debriefed on the incident were reviewed.\nNYPD and PAPD systems in 2001.\nIn 2001, the NYPD used Ultra High Frequency (UHF) radios and divided the city into 35 radio zones. Most hand-held radios had at least 20 channels: while not all officers had all channels, all officers had the ability to communicate citywide. As a characteristic of physics, UHF signals penetrate buildings better than lower Very High Frequency (VHF) frequencies used by the FDNY fire units but generally cover shorter distances over open terrain. The Commission report did not cite any technical flaws with the NYPD radio system.\nPAPD has systems described as \"low-power UHF\". The Commission report says the systems were specific to a single site with the exception of one channel which was Port-Authority-wide. It's unclear whether the PAPD systems were interstitial and limited to 2 watts output, used normal local-control channels but were limited in power output by the frequency coordinator, or used leaky cable systems which were solely intended to work inside the Port Authority buildings. The report says there were 7, site-specific Port Authority Police channels. In 2001, officers at one site could not, (in all cases), carry their radios to another site and use them. Not all radios had all channels.\nFire and EMS dispatch channels.\nRecordings of Citywide, Brooklyn, and Manhattan channels for Fire and Citywide, Brooklyn, and Manhattan channels for Emergency medical services were reviewed. Systems generally performed well. The audio coupling point for the logging recorder on Manhattan Fire made the dispatcher's voice difficult to hear. An anonymous fire dispatcher who identifies as \"Dispatcher 416\" is noteworthy.\nThe Commission report says that, in 2001, FDNY used a system with 5 repeater channels: one for each of the boroughs of Manhattan, Brooklyn, Queens, with the Bronx and Staten Island sharing a single frequency using different Private Line (PL) tones, and a citywide channel. There were also five simplex channels in FDNY radios.\nObservation shows, back in 2001, that the citywide EMS channel was voting more frequently than normal, signals were noisy, interfering signals were present, and that some receiver sites had equalization differences. Some transmissions had choppy audio possibly representative of interference from FSK paging or intermittent microwave radio paths to one or more receiver sites. For example, if a microwave radio path fails for half-second intervals, the voting comparator may vote out that receiver site until silence is detected. This can cause dropped syllables in the voted audio. Some transmissions were noisy, although transactions show the dispatcher was understanding radio traffic in spite of audio drop-outs in almost every case.\nPort Authority fire repeater system (Repeater 7).\nThe Port Authority radio repeater, intended to allow communications inside the towers, did not appear to work as intended on September 11. The system, also called \"Port Authority Channel 30\", was installed at Port Authority police desk in WTC 5 in 1994 after the 1993 World Trade Center attack. News accounts said the system had been turned off for unspecified technical reasons. The Commission report said it was customary to turn the system off because it somehow caused interference to radios in use at fire operations in other parts of the city. The documentary film gives different information, with a Fire Department member from Engine 7/Ladder 1 claiming that the aircraft's impact caused the system to fail. Evidence suggests the remote control console in the lobby command was not working but the repeater was. The radio repeater was located in 5 World Trade Center. A remote control console was connected to the repeater allowing staff at the North Tower lobby command post to communicate without using a hand-held radio.\nIn a review of the logging recorder track of the Port Authority repeater, someone arrived early during the incident and began to establish a command post. From the command post in the lobby of the North Tower (1 World Trade Center), the user can be heard trying to transmit using a remote control unit. After several failed attempts to communicate with a user on the channel, the user steps through every channel selection on the remote, trying each one. The recording contains the tone remote control console stepping through all of its eight function tones. Someone says, \"... the wireline isn't working\", over the Port Authority channel. Something that looks like a Motorola T-1380-series remote is shown in the documentary. The fact that users pressing buttons on the remote control can clearly be heard on the logging recorder shows the transmit audio path was working. The recording does not reveal whether or not the console function tones were keying the transmitter.\nSome users in the North Tower lobby interpreted the remote control unit not working as a failure of the entire channel. Other fire units, not knowing the channel had failed, arrived and began using it successfully. The recordings show at least some units were successfully using the repeater to communicate inside the South Tower until the moment it collapsed. The Commission report says the North Tower lobby command may not have worked because of a technical problem, the volume control turned all the way down, or because a button that must be pressed to enable it had not been pushed.\nOn the audio track, an outside agency, possibly in New Jersey and using a repeater, comes through the receive audio on the Port Authority Repeater 7 system. An ambulance being dispatched by the outside (non-FDNY) agency is heard. This may be what the FDNY had described as interference caused when the repeater was left enabled at all times. The distant user appears to be repeated through the system, (possibly on the same CTCSS tone as was configured in Repeater 7). This appears to be a distant co-channel user on the same input frequency as Repeater 7. It's possible that by the random button pressing, a user sent a function tone that temporarily put the base station in \"monitor\" and that's what caused the outside agency's traffic to be heard. This is unlikely because subsequent transmit function tones should have toggled the receiver from monitor back to CTCSS-enabled.\nFire Department system.\nAn oral history interview revealed the Port Authority UHF radios were normally used at incidents inside the World Trade Center. The interviewee said in normal, day-to-day calls, the WTC staff handed Port Authority UHF radios to firefighters on their arrival and that these radios, \"worked all over.\" This implies, but does not prove, that it was common knowledge among department members that FDNY radios had coverage problems inside the buildings. The 9-11 Commission uses the phrase, \"performed poorly\" to describe FDNY radios during the incident.\nOral history files show that at least four channels were employed at WTC:\nOne officer said a channel named \"Command 3\" was used for the North Tower. To those unfamiliar with the details of the FDNY system, it is unclear whether the interviewee meant Tactical 3 or a fifth channel.\nFDNY personnel are seen using radios during the documentary footage of the WTC lobby area. Analysis of these scenes showed the radios all appeared to be receiving properly. Oral history files confirm radio communications were at least partly functional.\nA problem that shows up in these types of incidents is that receivers in hand-held radios are subjected to signal levels that are likely to overload the receiver. Several radios may be transmitting within feet of one another on different channels. If overloading occurs, only very strong signals can be received while weaker signals disappear and are not received. The hand held radio receivers shown in the documentary appeared to work properly even though several other hand-held radios were transmitting only feet away. This is a hostile environment and suggests the hand-held equipment used by FDNY had good quality receivers, though in this case, the suggestion is incorrect. Second-hand observation is hardly the proper way to 'test' radio receivers or to distinguish 'good quality' from 'bad' and this is likely a source of continued misunderstanding; particularly when these same radios were operating at higher floors, in closer proximity to, and in direct line-of-sight of digital cellular repeaters. Those repeaters were likely operating at unlicensed power levels, which was a common practice of cellular providers at the time, and continues to this day. Footage reveals intelligible recovered audio coming out of the radios and shows radio users communicating with others. This may not have been true of the entire WTC complex but was true of radio users in the crowded lobby.\nAnalysis of the 26 FDNY audio CDs showed the radios seemed to transmit into the radio systems okay. Radios calling dispatch got through. Calling units were intelligible. Users spoke with dispatchers. Dispatchers answered in ways that suggest they understood what was said. There were no noisy or truncated transmissions heard on any channel, (the equivalent of a dropped cellular call). This suggests the Fire Department's radio backbone is soundly designed and working properly. It is possible that system coverage problems are present; problems that could have been mitigated had the Command Post radio (with greater transmit power) been used. It is also likely that some transmissions did not reach any of the receivers in the system and therefore would not be a detectable problem when listening to the recordings. At the same time those recordings were made, the cellular system was operating at or near full-capacity, meaning every cellular repeater was transmitting. The dense RF interference environment created in NYC that day was essentially a 'perfect storm'; one in which a radio designed 25 years prior could not possibly contend with.\nIn some scenes, captured documentary audio showed the channels were busy. In some cases, two or more conversations were taking place over a single radio channel at the same time. Users on Tactical 1 may have been close enough to one another to communicate because signals in proximity to each other would overpower weaker signals. At any incident of this size, there is likely to be some overlapping radio traffic. In the same way that large incidents exhaust all the firefighting vehicles and staff, the radio channel resources may become taxed to their limits. NIST says about one third of the fire department radio transmissions were not complete or not understandable.\nSome radio users had selected the wrong channels. For example, on the Repeater 7 channel, a unit was heard to call \"Manhattan\" dispatch and \"Citywide\". Although the circumstances that led to the user selecting the wrong channel are not known, this can occur when the user is trapped in darkness or smoke and cannot see the radio. Users will typically try to count steps in a rotary switch channel selector starting from one end of the switch's travel.\nA communications van operated by FDNY responded to the incident. Its radio identifier was, \"Field Comm.\" A backup van was in use on the day of the incident because the primary van was out-of-service. The backup van was destroyed and audio recordings of tactical channels used at the incident site were lost.\nFDNY radio programming.\nOne annoyance with the fire systems was the presence of \"unit ID\" data bursts. These constant squawks, heard at the end of transmissions, are decoded at dispatch to identify the calling radio. The annoyance of the data bursts is a trade-off that could help find a firefighter who has been injured or needs help. It also automatically displays the unit ID at the dispatch console. In most systems, it also saves dispatch personnel from typing the unit ID. They press one key and the calling unit's ID is inserted into the current CAD screen or command line.\nRecordings show radios were programmed to send unit ID on tactical channels. Radios accept unit ID on a per-channel basis. When mobile or hand-held radios are programmed, the unit ID encoders should be disabled on all channels where the feature is not used. This saves air time for about two to three syllables of speech per push-to-talk press. For example, unless the communications van or chief's vehicles had push-to-talk unit ID decoders, or the channels were recorded for later analysis where unit IDs were decoded from the recordings, the encoders should be turned off for tactical channels to reduce air time used.\nIt also sounded like some vehicle radios may have had \"status buttons\" using the data bursts. If true, the operator presses a button on the vehicle radio which sends a short data burst to dispatch. Dispatch gets the unit identity and the new status from a data decoder. These can cause interruptions in voice traffic but cut down on total air time required to conduct business because they occupy the channel for less time than it takes to say, \"Engine fifty on scene.\"\nTactical 1.\nThis channel was the primary method of communication in the North tower. It was a simplex channel. Users complained it would only reach from the lobby to floors in the thirties. Tactical 1 was a default channel for use at some fire scenes. Some users who realized Repeater 7 was functional switched to that channel and were afforded better coverage than simplex users on Tactical 1. Audio recordings on the documentary film and NIST analysis show Tactical 1 was overloaded with heavy radio traffic. In contrast, the audio CD of Repeater 7 shows the channel was mostly idle.\nThe 9-11 commission report said a new portable repeater system had been developed to address shortcomings of Tactical 1 at a large incident. The system, called, \"the post\", is carried to an area near the incident and set up for the duration to augment weak signals.\nCommand channel.\nThe command channel used by officers at the incident was either called \"Channel 5\" or \"Command 5\" in documentation. Documents suggest the channel had a repeater but it was not clear if the repeater was citywide, installed in the Field Comm van, or housed in a battalion chief's vehicle. Recordings of this channel were lost when the Field Comm van was destroyed. The documentary film and oral history records show the channel being used effectively.\nInteroperability.\nThe federal \"9/11 Commission Report\" included recommendations on communications systems used by police, fire, and emergency medical services (EMS) at the WTC incident. In the report and in appearances on television news programs, commissioners said the capabilities of communications systems lacked the ability to communicate across department lines. That is to say, police units could not communicate with fire units directly by radio. Ambulances could not talk with police units directly by radio. Commission member Lee Hamilton, in several television appearances related to a 2006 book on the topic of the WTC incident, reiterated this factually correct view.\nAviation assets.\nAn example that was cited by Hamilton: during the incident the Police Department helicopter was unable to communicate with Fire Department units in order to warn them of the towers' imminent collapse. The NIST document suggests the helicopter may have been able to offer several minutes warning. \"Several minutes\" may have been enough to get some people from the lower floors outside. This warning of imminent collapse went out over at least one police radio channel but there is nothing showing it was relayed to other people or channels. FDNY operates at least two communications vans: one of which was brought to the scene at the WTC incident. The Commission report reveals the primary FDNY van was equipped to talk to NYPD helicopters but the backup van (which had no NYPD helicopter capability) was in use on September 11, 2001.\nIn practice, many US helicopters used in emergency services are equipped with radios that allow communications on nearly any conventional two-way radio system, so long as the aircrew know the frequency and associated signaling tones. The radios usually have presets, like a car's broadcast radio, that allow some channels to be configured ahead of need. There was no information in the Commission report suggesting NYPD helicopters had such a capability.\nCross-department.\nWhile it is technically possible to implement communications across departments, doing so introduces a host of new training and incident command problems. These are problems that would need to be managed in addition to the existing set of issues present at any large incident. The ability to maintain command, and monitor the safety of, groups working at an incident is diminished if a group of firefighters cannot be reached because they've switched over to the EMS channel. This could cause people to be sent to rescue them when there was no need. Similarly, if the Manhattan EMS dispatcher can't reach an ambulance because they are on one of the fire channels, patient care is affected. New York City Police Commissioner Raymond Kelly, appearing on the \"Charlie Rose\" show, expressed his view that the existing radio systems performed satisfactorily during the WTC incident. In his view, the interoperability desired by the 9-11 Commission was not needed.\nNeed for NYPD/FDNY cross-department links?\nThese problems are not new to the World Trade Center incident; cross-department and cross-discipline communication has been a hotly contested and long-identified issue. For example, at the Oklahoma City federal building bombing incident, the inability to communicate among departments was also cited as a problem. Firefighters heard an evacuation order on their radio channel because of the reported presence of a second bomb. Police and EMS workers reportedly did not know of the order.\nIn Hurricane Katrina's wake, a sergeant in the Louisiana Department of Wildlife and Fisheries appeared on national television to describe not being able to reach persons from other agencies who were assisting with the recovery. She described seeing the people in a nearby boat but not being able to communicate with them.\nEven if the technical problems are solved, the issue is more complicated than just adding radio channels or talk groups. It is also a cultural problem. In one local incident, a large number of officers from three police agencies were fielded to search for a violent criminal who had evaded officers from one of the agencies. The officers did not coordinate by switching to a shared radio channel. After the incident, one participant said the users thought their radios were incompatible and did not understand how the shared channel worked. This possibly reflects a training problem or a technology literacy problem. The problem seems to have been remedied since then.\nIn another instance, a fire agency had thoroughly trained for interoperability scenarios. During an incident where two agencies with different radio channels responded, a decision-maker said personnel from his agency would stay on their own channel. Decision-makers may occasionally act in unpredictable ways, even if technology literate and well-trained. It is not solely a technical problem, but an operational problem as well. Changes to ICS command structure, or operational changes in how the command post for an incident is set up, may produce better results than buying equipment or adding channels. Sometimes there are interoperability problems even where a structure for interoperability exists.\nICS: part of the solution?\nOne view of the Incident Command System is that units across department lines would communicate with their own representative at the command post or division level. That representative would relay any needs to another department. For example, a fire unit requesting five paramedic ambulances would identify the magnitude of a medical problem to their fire officer at the command post. This request would add to their commander's operational picture of the division or incident command as she called EMS to request the ambulances. Situation awareness is an important part of effective command and is easy to lose at a large incident. Bypassing incident commanders can contribute to a decomposing of command.\nTrunked systems, commercial services, and cross-department netting.\nOne approach to cross-department netting is the capability of some modern trunked systems to provide a function called \"dynamic regrouping\"; a feature that Motorola doesn't support in simplex (e.g. 'fireground') operations. It is therefore necessary for a disaster to be near enough the infrastructure to allow for repeater access/operation. Many agencies with Motorola trunked systems already have this capability but it's hardly ever used; even in a crisis. The difficulty of operating such a system is often too great for poorly educated dispatchers who often have no college \u2013 much less any particular training in computers or communications systems \u2013 other than the 'cursory' training they receive in a 3 or 5 day class the vendors offer. The feature allows the dispatch center personnel to send units from different agencies who are responding to the same incident to a common talk group or virtual channel. This assumes the agencies all share a capability to operate over the same trunked radio system, which is rare. In an informal survey of three agencies with trunked systems that included this feature, users at two sites reported they did not think their system included the feature. A representative from a third site said he \"...thought they had the feature but never used it.\" Of the three agencies with the feature, no one knew how to use it. This would suggest, (in at least the three agencies contacted,) that \"dynamic regrouping\" was not valuable. Like other disaster readiness processes, users would have to practice using the feature in order for it to be useful during an incident.\nSome agencies use commercial two-way radio as an adjunct to their own communications networks. One professional engineering evaluation of public safety radio systems explains that commercial systems such as Nextel's are not built to the same standards of coverage and non-blocking as public safety trunked systems. Like toy walkie talkies marketed to children, they are usable and helpful for non-urgent communications but should not be considered reliable enough for life safety uses. It is also true that most trunked radio system users are likely to hear busy signals, (error tones showing no channels are available,) for the first time during a large disaster. All systems have a finite capacity.\n\"We don't want or need trunking\" is what Chief Charles Dowd (NYPD) was heard to say at an APCO convention in Orlando (2006). NYPD operates a large, conventional repeater network with many legacy channels in the UHF band; and a technology developed \"so a large number of users can share a small number of channels\" (e.g. trunking) is clearly unnecessary and a frivolous waste of money.\nWith sufficient channels, there is no need for trunking. There are no 'busy' tones in a conventional repeater system. In the event an individual needs to chime in, he simply waits his turn \u2013 just as he would do in a trunked system.\nMobile data terminals.\nAll 911 ambulances and other FDNY vehicles have data terminals, sometimes referred to by staff in recordings and transcripts as MDTs. These terminals are connected to the computer-aided dispatch (CAD) back end or server. They can display text, page through screens describing jobs, and display lists of units assigned to a job.\nA thorough analysis of data communications is not possible. What recordings show is that data terminals in at least some field units did not work properly during at least a portion of the incident. At 09:11:14, \"Division 3\" told Manhattan Fire dispatch, referring to the \"summary\" screen, \"Summary is only giving me a few units. You're going to have to give it to me over the radio. I'm ready to write.\" This means the terminal was not displaying the entire list of units assigned to Division 3, as it would under normal conditions. The work-around: the Chief had to hand-write the list of units responding. In this one instance, the dispatcher reading the list of about 29 units tied up the Manhattan Fire channel for 53 seconds. During the reading of the list of units responding, one can hear several FDNY units try to interrupt the dispatcher. Their radio traffic was delayed until the entire list was read. This need to read lists of units because of slow or inoperable terminals occurred in at least three or four cases.\nIt's unclear what caused data delays and incomplete screens on the mobile data terminals. Evidenced by the dispatcher reading the list of units assigned to Division 3, the CAD system was working properly at dispatch positions. At least some field units experienced problems. Possible causes of problems with data terminals in vehicles may have included:\nData terminals are partly purchased and installed to reduce load on dispatch staff and to reduce traffic on voice channels. When they work properly, they have a significant operational benefit. A data outage during an occurrence of high call traffic can quickly overrun dispatch and voice channel capacity in cases where a routine level of calls for service requires both data terminals and voice channels.\nNew York City Council investigation.\nNew York City Council member Eric Gioia introduced a measure to have the Council investigate the issue of FDNY radio problems.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28071", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=28071", "title": "September 11, 2001 Terrorist Attack/Foreign Casualties", "text": ""}
{"id": "28080", "revid": "11952314", "url": "https://en.wikipedia.org/wiki?curid=28080", "title": "Slogans and terms derived from the September 11 attacks", "text": ""}
{"id": "28082", "revid": "1318013885", "url": "https://en.wikipedia.org/wiki?curid=28082", "title": "Timeline for October following the September 11 attacks", "text": "This article summarizes the events in October 2001 that were related to the September 11 attacks. All times, except where otherwise noted, are in Eastern Daylight Time (EDT), or .\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28112", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=28112", "title": "September 11, 2001 Terrorist Attack/Timeline November 2001", "text": ""}
{"id": "28113", "revid": "1318013852", "url": "https://en.wikipedia.org/wiki?curid=28113", "title": "Timeline for September following the September 11 attacks", "text": "The September 11 attacks of 2001 were a major event that had a significant long-lasting impact even beyond the day of the attacks itself. This article summarizes events which relate to the attacks in the remaining days of September 2001. News coverage was significant in the period after the attacks which meant that many of these events were reported on quickly by news agencies at the time.\nAll times, except where otherwise noted, are in Eastern Daylight Time (EDT), or .\nSeptember 2001.\nTuesday, September 11.\nCBS and CNN report that a van filled with explosives has been stopped on the George Washington Bridge. According to the report, the New Jersey police claimed there were enough explosives to destroy the entire bridge. The FBI denied the report. \nFriday, September 14.\nThe National Day of Prayer and Remembrance\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28116", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=28116", "title": "September 11, 2001 Terrorist Attack/Timeline December 2001", "text": ""}
{"id": "28117", "revid": "36623386", "url": "https://en.wikipedia.org/wiki?curid=28117", "title": "SAC", "text": "SAC or Sac may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "28118", "revid": "50129093", "url": "https://en.wikipedia.org/wiki?curid=28118", "title": "Strategic Air Command", "text": "1946\u20131992 US Air Force major command\nMilitary unit\nStrategic Air Command (SAC) was a Cold War-era United States Department of Defense Specified Command and a United States Air Force (USAF) Major Command (MAJCOM) responsible for command and control of the strategic bomber and intercontinental ballistic missile components of the United States military's strategic nuclear forces from 1946 to 1992, active for most of the Cold War. SAC was also responsible for strategic reconnaissance aircraft; airborne command posts; and most of the USAF's aerial refueling aircraft.\nSAC primarily consisted of the Second Air Force (2AF), Eighth Air Force (8AF) and the Fifteenth Air Force (15AF), while SAC headquarters (HQ SAC) included Directorates for Operations &amp; Plans, Intelligence, Command &amp; Control, Maintenance, Training, Communications, and Personnel. At a lower echelon, SAC headquarters divisions included Aircraft Engineering, Missile Concept, and Strategic Communications. At the height of the Cold War, SAC controlled a total of 37 different wings organized under Air Divisions assigned to its component Numbered Air Forces. It operated 316 B-52 Stratofortress strategic bombers, 56 FB-111 Aardvarks, 14 EC-135 'Looking Glass' command and control aircraft, 615 KC-135 Stratotankers, several E-4 'Nightwatch' planes, and 48 LGM-25C Titan II as well as 1000 Minuteman II and III intercontinental ballistic missiles.\nIn 1992, as part of an overall post-Cold War reorganization of the U.S. Air Force, SAC was disestablished as both a Specified Command and as a MAJCOM. Its and equipment redistributed among the Air Combat Command (ACC), Air Mobility Command (AMC), Pacific Air Forces (PACAF), United States Air Forces in Europe (USAFE), and Air Education and Training Command (AETC), while SAC's central headquarters complex at Offutt AFB, Nebraska was concurrently transferred to the newly created United States Strategic Command (USSTRATCOM), which was established as a joint Unified Combatant Command to replace SAC's Specified Command role. In 2009, SAC was reactivated and redesignated as the Air Force Global Strike Command (AFGSC). AFGSC eventually acquired all USAF bomber aircraft and the intercontinental ballistic missile force, inheriting the role of its predecessor.\nBackground.\nThe Strategic Air Forces of the United States during World War II included General Carl Spaatz's European command, United States Strategic Air Forces in Europe (USSTAF), consisting of the 8AF and 15AF, and the United States Strategic Air Forces in the Pacific (USASTAF) and its Twentieth Air Force (20AF).\nThe U.S. Army Air Forces' first mission in the Strategic Bombing Campaign in the European Theater during World War II included the VIII Bomber Command, which conducted the first European \"heavy bomber\" attack by the USAAF on 17 August 1942; the Ninth Air Force, which conducted the first Operation Crossbow \"No-Ball\" missions on 5 December 1943; the Twelfth Air Force; and the Fifteenth Air Force, which executed bombing operations on 2 November 1943 during Operation Pointblank.\nThe Operation Overlord air plan for the strategic bombing of both Germany and German military forces in continental Europe prior to the 1944 invasion of France used several Air Forces, primarily those of the USAAF and those of the Royal Air Force (RAF), with the command of air operations transferring to the Supreme Commander of the Allied Expeditionary Force on 14 April 1944.\nPlanning to reorganize for a separate and independent postwar U.S. Air Force had begun by the fall of 1945, with the Simpson Board tasked to plan, \"...the reorganization of the Army and the Air Force...\". In January 1946, Generals Eisenhower and Spaatz agreed on an Air Force organization composed of the Strategic Air Command, the Air Defense Command, the Tactical Air Command, the Air Transport Command and the supporting Air Technical Service Command, Air Training Command, the Air University, and the Air Force Center.\nEstablishment and transfer to USAF.\nStrategic Air Command was originally established in the U.S. Army Air Forces on 21 March 1946 upon the redesignation of Continental Air Forces (CAF), the World War II command tasked with the air defense of the continental United States (CONUS). At the time, CAF headquarters was located at Bolling Field (later Bolling AFB) in the District of Columbia and SAC assumed occupancy of its headquarters facilities until relocating SAC headquarters (HQ SAC) to nearby Andrews Field (later Andrews AFB), Maryland as a tenant activity until assuming control of Andrews Field in October 1946.\nSAC initially totaled 37,000 USAAF personnel. In addition to Bolling Field and, seven months later, Andrews Field, SAC also assumed responsibility for:\nSAC also had seven additional CAF bases transferred on 21 March 1946 which remained in SAC through the 1947 establishment of the U.S. Air Force as an independent service. Those installations included:\nOn 31 March 1946, the following additional installation was also assigned to SAC:\nUnder the first SAC Commander in Chief, General George C. Kenney, initial units reporting to the Strategic Air Command headquarters on 21 March 1946 included the Second Air Force, the IX Troop Carrier Command and the 73d Air Division.\nFifteenth Air Force was assigned to SAC on 31 March (15th AF's 263rd Army Air Force Base Unit\u2014with \u2014transferred the same date directly under HQ SAC ), while the IX Troop Carrier Command was inactivated the same date and its assets redistributed within SAC. With postwar demobilization still underway, eight of the ten assigned bomb groups were inactivated before the Eighth Air Force was assigned to SAC on 7 June 1946. Despite the pressures of demobilization, SAC continued the training and evaluation of bomber crews and units still on active duty in the postwar Army Air Forces. Radar Bomb Scoring became the preferred method of evaluating bomber crews, with the last of 888 simulated bomb runs scored against a bombing site near San Diego, California during 1946, subsequently increasing to 2,449 bomb runs by 1947. In the wake of the successful employment of air-dropped nuclear weapons against Hiroshima and Nagasaki to effectively end World War II, SAC became the focus of the nation's nuclear strike capability, to the extent that Joint Chiefs of Staff (JCS) Publication 1259/27 on 12 December 1946 identified that, \"...the 'air atomic' strategic air force should only come under the orders of the JCS.\"\nIn addition to the strategic bombing mission, SAC also devoted significant resources to aerial reconnaissance. In 1946, SAC's reconnaissance aircraft inventory consisted of F-2 photo variants of the C-45 Expeditor support aircraft, but by 1947 SAC had acquired an F-9C squadron consisting of twelve photo-reconnaissance variants of the B-17G Flying Fortress. An F-13 squadron, the F-13 later re-designated as the RB-29 Superfortress, was also established. SAC conducted routine aerial reconnaissance missions near the Soviet borders or near the 12-mile international waters limit, although some missions actually penetrated into Soviet airspace. The flight profiles of these missions\u2014above 30,000 feet and in excess of 300 knots\u2014made interception by Soviet air forces difficult until the Soviet's 1948 introduction of the MiG-15 jet fighter. Project Nanook, the Cold War's first Top Secret reconnaissance effort, used the first RB-29 missions for mapping and visual reconnaissance in the Arctic and along the northern Soviet coast. Later missions were Project LEOPARD along the Chukchi Peninsula, followed by Projects RICKRACK, STONEWORK, and COVERALLS.\nIn 1946, the US possessed only nine atomic bombs and twenty-seven B-29s capable at any one time of delivering them. Furthermore, it was later determined that an attack by the 509th Composite Bomb Group during the 1947 to 1948 time frame would have required at least five to six days just to transfer custody of the bombs from United States Atomic Energy Commission (AEC) sites to SAC and deploy the aircraft and weapons to forward operating bases before launching nuclear strikes. Postwar budget and personnel cuts had an insidious effect on SAC as its Deputy Commander, Major General Clements McMullen, implemented mandated force reductions. This continued to wear down SAC as a command and morale plummeted. As a result, by the end of 1947, only two of SAC's eleven groups were combat ready. After the 1948 Bikini Atoll nuclear tests, the \"Half Moon\" Joint Emergency War Plan developed in May 1948 proposed dropping 50 atomic bombs on twenty Soviet cities, with President Harry S. Truman approving \"Half Moon\" during the June 1948 Berlin Blockade, (Truman sent B-29s to Europe in July). SAC also ordered special ELINT RB-29s to detect improved Soviet radars and, in cooperation with the 51st Air Force Base Unit, SAC also monitored radioactive fallout from Soviet atomic testing on Novaya Zemlya.\nIn terms of overall Air Force basing and infrastructure, SAC continued to acquire an ever-increasing share of USAF infrastructure and the USAF associated budget. In 1947, before the USAF was established as an independent service, construction commenced on Limestone AAF, Maine (later renamed Loring AFB), a new SAC installation specifically designed to accommodate the B-36 Peacemaker. Fort Dix AAF, New Jersey (later McGuire AFB); Spokane AAF, Washington (later Fairchild AFB); and Wendover Field, Utah (later Wendover AFB) were also transferred to SAC between 30 April and 1 September 1947. Following the establishment of the USAF as a separate service, SAC bases in the United States consisted of:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nThose bases subsequently added to SAC in the United States included:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nIn addition to bases under its operational control, SAC also maintained tenant wings at several bases under the control of other USAF MAJCOMs. These non-SAC bases with SAC tenants included:\nSAC also often maintained a tenant presence at former SAC bases that the command subsequently transferred and relinquished to other MAJCOMs, to include but not limited to:\nRun-up to Korea and start of the Cold War.\nSAC transferred to the United States Air Force on 26 September 1947, concurrent with the latter's establishment as a separate military service. Units directly under SAC HQ included the 8AF and 15AF, as well as the 311th Air Division, 4th Fighter Wing, 82nd Fighter Wing, 307th Bomb Wing, and two reconnaissance units, the 311th Reconnaissance Wing and the 46th Reconnaissance Squadron. The 56th Fighter Wing was subsequently assigned to SAC on 1 October 1947.\nFollowing the establishment of the U.S. Air Force, most SAC installations on U.S. territory were renamed as \"Air Force Base\" during late 1947 and into 1948, while non-U.S. installations were renamed as \"Air Base\".\nIn May 1948, in an exercise versus Air Defense Command's \"Blue\" force, a SAC \"Red\" strike force simulated attacks on Eastern Seaboard targets as far south as Virginia. After a \"scathing\" 1948 Lindbergh review of SAC operations in the air and at six SAC bases, General Kenney was removed as Commanding General on 15 October 1948 and replaced on 19 October 1948 by 8AF's commander, Lieutenant General Curtis LeMay. Upon LeMay's assumption of command, SAC had only 60 nuclear-capable aircraft, none of which possessed a realistic long range capability against the Soviet Union. LeMay proposed that SAC should be able to deliver 80% of its weapons in one mission. The B-29D, which had become the B-50 in December 1945, was first delivered to SAC in June 1948. This was followed by SAC's first Convair B-36 Peacemaker bomber arriving at Kirtland AFB, New Mexico in September 1948.\nIn November 1948, LeMay had SAC's headquarters and its command post moved from Andrews AFB, Maryland to Offutt AFB, Nebraska. At Offutt, the command moved into the \"A Building\", a three-story facility that had previously been used by the Glenn L. Martin Company during World War II. Concurrent with the establishment of this new headquarters facility, Lemay also increased SAC Radar Bomb Scoring (RBS) runs the same year to 12,084. SAC also enhanced its organic fighter escort capability by initiating replacement of its World War II vintage piston-engine F-51D Mustang and F-82E Twin Mustang fighter aircraft with F-84G Thunderjets. In January 1949, SAC conducted simulated raids on Wright-Patterson AFB, Ohio. Assessments of these simulated raids by \"...LeMay's entire command...were appalling\", despite the SAC deputy commander, Major General McMullen, having instructed all bomber units to improve their effectiveness. To motivate crews and improve operational effectiveness command-wide, SAC established a competition, the first so-called \"Bomb Comp\" in 1948. Winners of this inaugural event were the 43rd Bombardment Group (unit) and, for aircrew award, a B-29 team from the 509th Bombardment Group. Given its global operating environment, SAC also opened its own survival school at Camp Carson, Colorado in 1949, later moving this school to Stead AFB, Nevada in 1952 before transferring the school to the Air Training Command in 1954.\nSAC also created Emergency War Plan 1\u201349 (EWP 1\u201349), which outlined the means for delivering 133 atomic bombs, \"...the entire stockpile...in a single massive attack...\" on 70 Soviet cities over a 30-day period. The first Soviet atomic bomb test occurred on 29 August 1949 and the Joint Chiefs of Staff (JCS) subsequently identified SAC's primary objective was to damage or destroy the Soviet Union's ability to deliver nuclear weapons. The JCS further defined SAC's secondary objective was to stop any Soviet advances into Western Europe, and its tertiary objective was the previous EWP 1\u201349 industrial mission.\nKorean War.\nIn July 1950, in response to combat operations on the Korean peninsula, SAC dispatched ten nuclear-capable bombers to Guam and deployed four B-29 bomber wings in Korea for tactical operations, although this action caused SAC commander LeMay to comment \"...too many splinters were being whittled off the [deterrence] stick\".\nInitial SAC B-29 successes against North Korea in the summer of 1950 were countered by subsequent Soviet MiG-15 fighter-interceptors, and SAC's 27th Fighter Escort Wing began escorting the bombers with F\u201384 Thunderjets. Ground-directed bombing (GDB) was subsequently used for close air support (CAS) missions after three SAC radar bomb scoring (RBS) squadron detachments (Dets C, K, &amp; N) arrived at Pusan in September 1950. In 1951, SAC \"began to eliminate its combat groups\", transferring medium bombardment groups \"to Far East Air Forces (FEAF) Bomber Command for combat.\" In 1951, LeMay convinced the Air Staff to allow SAC to approve nuclear targets, and he continued refusing to submit war plans for JCS review, which the JCS eventually came to accept (of 20,000 candidates in 1960, SAC designated 3,560 as bombing targets\u2014mostly Soviet air defense: airfields and suspected missile sites.)\nAlthough experimented with prior to World War II, SAC refined aerial refueling to a fine art. SAC's in-flight refueling mission began in July 1952 when its 31st Fighter-Escort Wing refueled sixty F-84G Thunderjets from Turner AFB, Georgia to Travis AFB, California non-stop with fuel from twenty-four KB-29P Superfortresses modified into aerial tankers. Exercise FOX PETER ONE followed with 31st FEW fighters being refueled Hickam AFB en route to Hawaii. On 15 March 1953, a 38th Strategic Reconnaissance Squadron RB-50 returned fire on a Soviet MiG-15, while a 343d Strategic Reconnaissance Squadron RB-50 was shot down over the Sea of Japan 2 days after the Korean Armistice, while on 7 November 1954, an RB-29 was shot down near Hokkaido Island in northern Japan. By the time of 27 July 1953 Korean War cease-fire, SAC B-29s had flown over 21,000 sorties and dropped nearly 167,000 tons of bombs, with thirty-four B-29s lost in combat and forty-eight B-29s were lost to damage or crashes.\nCold War and massive retaliation.\nSAC's first jet strategic bomber was the swept-wing B-47 medium bomber, which first entered service in 1951 and became operational within SAC in 1953. The B-47 was a component of the October 1953 \"New Look\" strategy, which articulated, in part, that: \"\"...to minimize the threat...the major purpose of air defense was not to shoot down enemy bombers\u2014it was to allow SAC...to get into the air\"[--and]\" not be destroyed on the ground\"[--to allow]\" massive retaliation\".\"\nConcern of a bomber gap grew after the 1955 Soviet Aviation Day and the Soviets rejected the \"Open Skies\" Treaty proposed at the Geneva Summit on 21 July 1955. US bomber strength peaked with \"over 2,500 bombers\" after production \"of over 2,000 B-47s and almost 750 B-52s\" (circa 1956, 50% of SAC aircraft &amp; 80% of SAC bombers were B-47s).\nIn an effort to concurrently enhance its reconnaissance capabilities, SAC also received several RB-57D Canberra aircraft in April 1956, with the aircraft initially based at Turner AFB, Georgia. In 1957, these aircraft were forward deployed to Rhein-Main Air Base, West Germany, in order to conduct reconnaissance missions along the borders of the Soviet Union and other Warsaw Pact nations. However, an unintended consequence of this deployment was that Hawker Hunter fighters of the Royal Air Force stationed in the United Kingdom and in continental Europe often intercepted these classified RB-57 missions as they returned to Rhein-Main AB from over the Baltic.\nSince it was designed as a medium bomber, SAC's B-47 Stratojet traded speed for range. Because of this shorter range, and in order to better enable the B-47 fleet to reach its target sets in the Soviet Union, SAC routinely deployed its US-based B-47 wings to overseas forward operating bases in North Africa, Spain and Turkey. This program, in effect from 1957 to 1966, was known as Operation Reflex with Sixteenth Air Force (16AF), a SAC numbered air force permanently stationed in Europe, having tactical and administrative control of the forward-deployed aircraft and units. Beginning in 1955, SAC also moved a portion of its bomber and aerial refueling aircraft to 24-hour alert status, either on the ground or airborne. By 1960, fully one third of SAC's bombers and aerial refueling aircraft were on 24-hour alert, with those crews and aircraft not already airborne ready to take off from designated alert sites at their respective bases within fifteen minutes. Bomber aircraft on ground alert were armed with nuclear weapons while aerial tanker aircraft were sufficiently fueled to provide maximum combat fuel offload to the bombers.\nConcurrent with this increased alert posture and in order to better hone strategic bombing skillsets, the 1955 SAC Bombing and Navigation Competition was characterized by radar bomb scoring (RBS) runs on Amarillo, Denver, Salt Lake City, Kansas City, San Antonio and Phoenix; and the 1957 competition (nicknamed \"Operation Longshot\") had three targets: Atlanta, Kansas City, and St. Louis. This use of RBS with simulated target areas utilizing mobile and fixed bomb scoring sites adjacent to major cities, industrial areas, military installations and dedicated bombing ranges throughout the United States. This format would continue through successive SAC Bombing and Navigation Competitions through the remainder of the 1950s, 1960s, 1970s and 1980s. Commencing in the late 1950s, in addition to representation from every SAC wing with a bombing and/or air refueling mission, later SAC competitions would also include participating bomber and aerial refueling units from the Royal Air Force's Bomber Command and (after 30 April 1968) its successor, RAF Strike Command.\nNuclear Bunkers, SAC Ground Alert, and transfer of SAC's Fighter-Escort Wings.\nIt was described as the \"Western Pentagon,\" specifically a, \"...four-story, reinforced concrete and masonry office building...\" above ground and a \"...segregated, adjacent three-story below ground command post.\" This was the description of what would become Building 500 at Offutt AFB and the new headquarters complex built expressly for SAC, with construction commencing in 1955. SAC headquarters moved from the A Building at Offutt AFB to Building 500 in 1957. The underground nuclear bunker had 24-inch thick walls and base floor, 10-inch thick intermediate floors, and 24-to-42-inch thick roof. It also contained a war room with six 16-foot data display screens and the capacity to sustain up to 800 people underground for two weeks. The below ground bunker portion of the headquarters complex also contained an IBM 704 computer, which was used to develop monthly weather forecasts at targets, as well as for computing fuel consumption and fallout cloud patterns for planning strike routes and egress routes (e.g., determining the timing as to which targets to bomb first).\nIn 1957, SAC also constructed The Notch, a facility alternatively known as the 8th Air Force Combat Operations Center (COC) and the Westover Communications Annex, since it was a sub-post of nearby Westover AFB. A 3-story nuclear bunker located on Bare Mountain, Massachusetts, The Notch was built with three-foot thick walls, 1.5 foot thick steel blast doors, and 20 feet underground to protect 350 people for 35 days. The Notch was shut down as a SAC facility in 1970 when 8th Air Force was relocated to Barksdale AFB, Louisiana.\nDespite this investment in \"hardened\" headquarters and command and control facilities, the 1957 Gaither Commission identified, \"...little likelihood of SAC's bombers surviving [a Soviet first strike] since there was no way to detect an incoming attack until the first [Soviet nuclear weapon] warhead landed.\" As a result, SAC's bombers and tankers began sitting armed ground alert at their respective bases on 1 Oct 57. In another organizational change during this time period, SAC's fighter escort wings were transferred to Tactical Air Command (TAC) during 1957 and 1958. Finally, during January 1958's Exercise Fir Fly, SAC \"faker\" aircraft (twelve B-47s) simulated bombing strikes against metropolitan areas and military installations in the United States defended by Air Defense Command's 28th Air Division.\nNuclear missiles, aircrew readiness, airborne alert, and strategic reconnaissance.\nAfter SAC's 1st Missile Division was activated on 18 March 1957, SAC HQ established the Office of Assistant CINCSAC (SAC MIKE) at the Air Force Ballistic Missile Division in California on 1 January 1958. SAC MIKE was responsible for missile development liaison, the intermediate range Jupiter and Thor missiles having been transferred to SAC for alert in 1958.\nBeginning on 1 February 1958, a SAC Liaison Team was also located at the NORAD Command Post at Ent AFB, Colorado, and the two commands agreed that direct land line communications should connect SAC bases with NORAD's Air Defense Direction Centers. Also in the late 1950s, SAC continued to enhance its intelligence collection activities and develop innovative means of improving the survivability of its forces to surprise attack. From 1958 to about 1967, a SAC Detachment (TUSLOG Det 50) operated at Incirlik AB, Turkey, monitoring Soviet missile telemetry from the Kapustin Yar and Tyuratam launch complexes. In 1959\u201360, SAC evaluated deploying Minuteman I ICBMs via civilian railroad tracks on USAF-operated locomotives and trains.\nPresident Eisenhower approved the first Atlas ICBM launch by a SAC crew for 9 September 1959 at Vandenberg AFB. While missile operations continued to ramp up, robust training for flight crews to ensure survivability for strike missions also continued. In some instances SAC bombers would oppose ADC fighter-interceptors simulating Soviet interceptors. Conversely, SAC assisted ADC readiness by simulating Soviet bomber threats to the continental United States that ADC fighters would respond to. However, following a mid-air collision between an ADC F-102 and a SAC B-47 during a 17 December 1959 Quick Kick exercise, simulated NORAD fighter attacks were prohibited against SAC bombers.\nOn 18 March 1960, SAC intercontinental missiles began alert at Maine's Snark Missile Launch Complex adjacent to Presque Isle AFB. The following month, on 22 April 1960, SAC turned over the last British-based PGM-17 Thor IRBM to the Royal Air Force. This was soon followed by SAC's first Titan I ICBMs at Lowry AFB's Titan I Missile Complex 1A in Colorado being placed on alert that June.\nBeginning in November 1959, in order to counter Soviet surface-to-air missile threats, SAC began adding low-altitude bombing training for its manned bomber force as an adjunct to its legacy high-altitude training. Use of low level flight route corridors known as \"Oil Burner\" routes (later renamed \"Olive Branch\" routes in the 1970s), and the first of three SAC RBS trains were utilized starting in 1960. On 30 June 1960, SAC had 696 aircraft on alert in the Zone of Interior, also known as the ZI (referred to today as the Continental United States, or CONUS) and at overseas bases. These 696 aircraft were 113 B-52s, 346 B-47s, 85 KC-135s, and 152 KC-97s. SAC's Emergency War Order (EWO) required the first aircraft to be airborne within 8 minutes and all aircraft to be airborne within 15 minutes after notification. During the mid-1950s, having recalled numerous World War II USAAF and Korean War USAF combat veteran pilots, navigators, bombardiers and aircrewmen from inactive reserve status back to various lengths of active duty, SAC took the lead in integrating the Air Force's reserve components into the overall SAC structure. By the beginning of the 1960s, SAC had also engineered the assignment of KC-97 Stratofreighter aerial refueling aircraft to Air National Guard groups and wings and having them fall under SAC's operational claimancy.\nOn 11 August 1960, President Eisenhower approved the creation of the Joint Strategic Target Planning Staff (JSTPS), co-located at SAC headquarters at Offutt AFB.) JSTPS also included non-SAC agencies tasked with preparing the Single Integrated Operation Plan, or SIOP, and the National Strategic Target List for nuclear war. On 1 July 1960, a SAC RB-47 with a six-man crew was shot down in international airspace over the Barents Sea by a Soviet MiG-19. Four of the crewmen were killed and two surviving crewmen were captured and held in Lubyanka Prison in Moscow for seven months.On 3 February 1961, SAC's Boeing EC-135 Looking Glass, began operations as the Airborne Command Post for the Nuclear Triad and the Post-Attack Command and Control System. From this date and for the next &lt;templatestyles src=\"Fraction/styles.css\" /&gt;29+1\u20442 years, until 24 July 1990, SAC would maintain at least one Looking Glass aircraft continuously aloft 24 hours a day, 365 days a year, with an embarked SAC general officer and battle staff, ready to assume command of all strategic nuclear strike forces in the event that SAC headquarters was destroyed in a Soviet first strike. SAC's airborne alerts during this period also included Operation Chrome Dome for the bomber and tanker force. Although ostensibly a peacetime mission, Chrome Dome placed heavy demands on flight crews and five B-52 aircraft were lost to airborne mishaps during the operation's eight-year period.\nOn 11 May 1961, SAC took delivery of its first B-58 Hustler supersonic medium bomber, assigning it to the 305th Bombardment Wing at Bunker Hill AFB. Optimized for high-altitude, high-speed penetration into Soviet territory prior to Soviet advancements in high-altitude surface-to-air missiles, the B-58 was expensive to operate and inefficient at lower altitudes. Its service in SAC would be comparatively short, eventually being replaced by the FB-111 by 1970.\nAfter an early 1961 development by SAC of a Radar Bomb Scoring (RBS) field kit for use in the U.S. Army's Nike surface-to-air missile systems, SAC aircraft flew several mock penetrations into Air Defense Command sectors in the 1961 SAGE/Missile Master test program, as well as the joint SAC-NORAD Sky Shield II exercise followed by Sky Shield III on 2 September 1962.\nIn 1961, following the Berlin Crisis, President John F. Kennedy increased the number of SAC aircraft on alert to 50 percent and during periods of increased tensions SAC kept some B-52 airborne in the event of a surprise attack. In 1962, SAC gained full control of the various \"Q Areas\" developed by Sandia Laboratories for nuclear weapon storage adjacent to Loring AFB (Site E (Maine)/Caribou AFS), Ellsworth AFB (Site F (South Dakota)/Rushmore AFS), Fairchild AFB (Site G (Washington)/Deep Creek AFS), Travis AFB (Site H (California)/Fairfield AFS), and Westover AFB (Site I (Massachusetts)/Stony Brook AFS). These adjunct sites were subsequently converted to USAF-operated and maintained weapon storage areas (WSAs) in the same manner as WSAs on other SAC bases.\nThe solid fuel LGM-30A Minuteman I was first deployed in 1962 and the LGM-25C Titan II reached operational service in 1963. Project Added Effort phased out all first-generation ICBMs beginning on 1 May 1964 when Atlas-D were taken off alert at Vandenberg AFB's 576th SMS (LGM-30F Minuteman II replaced Minuteman I in 1965). In October 1962, an SAC BRASS KNOB mission U-2 piloted by Major Richard S. Heyser detected Soviet intermediate range ballistic missiles in Cuba. BRASS KNOB operations involving multiple U-2 aircraft were subsequently commenced at a forward operating location at McCoy AFB, Florida the same month. On the morning of 27 October, a SAC RB-47H of the 55th Strategic Reconnaissance Wing, forward deployed to Kindley AFB, Bermuda crashed on takeoff, killing all four crewmembers, while later that afternoon, a 4028th Strategic Reconnaissance Squadron U-2 forward deployed to McCoy AFB for BRASS KNOB operations was shot down over Cuba by an SA-2 Guideline missile, killing the pilot, Major Rudolf Anderson.\nThroughout the early 1960s, the Kennedy Administration, under the aegis of Secretary of Defense McNamara, cancelled numerous SAC modernization programs. This included the Mach 3 North American B-70 Valkyrie in 1961, the GAM-87 Skybolt missile in 1962, and the Rocky Mountain Deep Underground Support Center in 1963. The B-70's demise came due to its design as a high-altitude bomber with very limited low-altitude performance, making it vulnerable to rapid advances in Soviet high altitude surface-to-air missile defense systems. The following year, Skybolt, an air-launched ballistic missile, was cancelled following numerous test failures and the perceived greater reliability of land-based and submarine-based ballistic missile systems. Although initially entering service in 1957, SAC's 2nd-generation aerial refueling aircraft, the KC-135 Stratotanker, had reached sufficient inventory numbers to allow SAC to begin divestiture of its KC-97 Stratofreighter tankers, transferring them to SAC-gained Air Force Reserve and Air National Guard units. As the KC-135 became the primary aerial tanker in active service, SAC employed the aircraft for several non-stop B-52 and KC-135 flights around the world, demonstrating that SAC no longer needed to depend on Reflex stations at air bases in Spain and Britain.)\nVietnam War and latter half of the Cold War.\nSAC's air war in Vietnam.\nAfter the Secretary of Defense rejected LeMay's November 1964 proposal for a \"...strategic air campaign against 94 targets in North Vietnam...\", thirty SAC B-52Fs were deployed to Andersen AFB, Guam on 17 February 1965, representing the first increment of SAC aircraft forward deployed for the Vietnam War. The following month, in March 1965, the Strategic Air Command Advanced Echelon (SACADVON) was established as a \"...liaison unit for CINCSAC [was] located at MACV Headquarters to assist with the B-52 effort.\" On 23 May 1965, SAC B-52Fs began unarmed missions for radar mapping \"...and later to test bombing with the assistance of ground homing beacons...\" SAC began saturation bombing on 18 June 1965 (8000 tons per month in 1966) and conducted Operation Arc Light missions from 1965 until the end of hostilities involving U.S. forces in 1973.\nAll B-52F missions in 1965 were against targets in South Vietnam (RVN) except for the December \"...Duck Flight mission [that] hit a suspected VC supply storage area [for which] part of the target box was in Laos.\" In April 1966, Vietnam operations began with the B-52D model, a 1956 model designed to use the AGM-28 Hound Dog cruise missile and the ADM-20 Quail aerial decoys for low altitude operations and modified in late 1965 by Project Big Belly to increase conventional bomb capacity.\nSAC's RBS Squadrons were discontinued when most detachment personnel transferred to Vietnam from 1966 to 1973 for Combat Skyspot ground-directed bombing operations. The first \"Quick Reaction\" bombing was the \"Pink Lady\" mission on 6 July 1966 using SAC B-52D/Fs to support the U.S. Army's 1st Air Cavalry Division. The 1972 Operation Linebacker II also used Skyspot for Hanoi/Haiphong bombings in North Vietnam which resulted in the loss of 25 SAC aircrew members.\nBy May 1967, SACADVON had moved to Seventh Air Force headquarters at Tan Son Nhut Air Base, South Vietnam to schedule and coordinate \"...strikes for the 7th AF and MACV.\" From a level of 161,921 military and 20,215 civilian assigned to SAC in June 1968, SAC lost 13,698 first term airmen from November 1968 to May 1969 in a three phase drawdown known as Project 693 to comply with Public Law 90-364. While conventional bombing, air refueling and strategic air reconnaissance operations in Southeast Asia increasingly occupied SAC's operational commitments, SAC's primary mission of nuclear deterrence continued to remain its primary focus. In 1969, \"...SAC's B-52s and B-58s could carry B28, B41, B43, B53, and BA53 nuclear weapons\" (SAC had 311 nuclear AGM-28 Hound Dog missiles at the end of the year.) This also coincided with the B-58 Hustler's in-progress retirement from SAC's active inventory and its replacement with the FB-111.\nOn 18 March 1969, along the South Vietnamese border, SAC first bombed Cambodia (Operation Menu through 26 May 1970 was controlled by Skyspot). On 17 February 1970, SAC conducted the first \"GOOD LOOK\" bombing of Laos at the Plaine des Jarres after B-52 photorecon missions (\"GOOD LOOK ALPHA\" in August 1969 and \"GOOD LOOK BRAVO\" c.\u200915 January 1970) and the observations of a Skyspot installation in Thailand. SAC transferred \"...HQ 8th AF...to Andersen AFB, Guam on 1 April 1970 to oversee B-52D/G operations and to complement SACADVON\". 8th AF took over from Third Air Division the generation of \"frag\" orders based on daily strike requests and amendments from COMUSMACV. In 1970, SAC deployed the LGM-30G Minuteman III ICBM with multiple independently targetable reentry vehicle or MIRVs, for striking 3 targets, while concurrently retiring the B-58 Hustler supersonic bomber.\n1972 saw the commencement of Operation Linebacker II, a combined Seventh Air Force and U.S. Navy Task Force 77 aerial bombing campaign, conducted against targets in North Vietnam during the final period of US involvement in the Vietnam War. Linebacker II was conducted from 18 to 29 December 1972, leading to several informal names such as \"The December Raids\" and \"The Christmas Bombings\". Unlike the previous Operation Rolling Thunder and Operation Linebacker interdiction operations, Linebacker II would be a \"maximum effort\" bombing campaign to destroy major target complexes in the Hanoi and Haiphong areas which could only be accomplished by SAC B-52D/Gs. It saw the largest heavy bomber strikes launched by the U.S. Air Force since the end of World War II. Linebacker II was a modified extension of the Operation Linebacker bombings conducted from May to October 1972, with the emphasis of the new campaign shifted to attacks by B-52 Stratofortress heavy bombers rather than smaller tactical fighter aircraft. During Linebacker II, a total of 741 B-52D/G sorties were dispatched from bases in Thailand and Guam to bomb North Vietnam and 729 actually completed their missions. Overall SAC losses during Linebacker II numbered fifteen B-52s. The U.S. government claimed that the operation had succeeded in forcing North Vietnam's Politburo to return to the negotiating table, with the Paris Peace Accords signed shortly after the operation.\nBy early 1973, offensive SAC air operations in Southeast Asia ceased and numerous SAC aircrewmen who had been shot down and captured as prisoners of war by North Vietnam were repatriated to the United States. SAC aircraft used during the Vietnam War included B-52D, B-52F, B-52G, KC-135A, KC-135Q, various versions of the RC-135, SR-71, U-2, and EC-135.\nPost-Vietnam, 1970s budget cuts, 1980s renewal, and the Cold War redux.\nDuring the Vietnam War, due to the escalating costs of combat operations in Southeast Asia, SAC was required to close several SAC bases, consolidate other bases, or transfer several bases to other MAJCOMs, other services, or the Air Reserve Component in order to remain within budgetary constraints. This included:\nWith the Vietnam War draw-down following the Paris Peace Treaty in 1973, reduced defense budgets forced SAC to inactivate several more wings, close still more bases in CONUS and Puerto Rico, transfer still additional bases to other MAJCOMS or the Air Reserve Component, and retire older B-52B, B-52C, B-52E and B-52F aircraft:\nIn 1973, the National Emergency Airborne Command Post, or NEACP, aircraft entered SAC's inventory. Consisting of four Boeing E-4 aircraft, these highly modified Boeing 747 airframes were assigned to the 55th Strategic Reconnaissance Wing at Offutt AFB and were forward deployed as necessary to support the National Command Authority.\nBy 1975, SAC's manned bomber strength included several hundred B-52D, B-52G, B-52H and FB-111A aircraft, and \"...SAC's first major exercise in 23 years\" was Exercise Global Shield 79. As for the ICBM force, SAC reached a peak strength of 1000 Minuteman II and III and 54 Titan II ICBMs on active status before seeing reductions and retirements through a combination of obsolescing systems and various arms reduction treaties with the Soviet Union. By 1977, SAC had been pinning its hopes for a new manned strategic bomber in the form of the Rockwell B-1A Lancer. However, on 30 June 1977, President Jimmy Carter Carter announced that the B-1A would be canceled in favor of ICBMs, submarine-launched ballistic missiles (SLBMs), and a fleet of modernized B-52s armed with air-launched cruise missiles (ALCMs). On 1 December 1979, SAC assumed control of the ballistic missile warning system (BMEWS) and all Space Surveillance Network facilities from the inactivating Aerospace Defense Command (ADC). These activities would later be (transferred to Air Force Space Command (AFSPC) when the latter was established in 1982. SAC also continued to operate the Air Force's entire KC-135 aerial refueling fleet, its EC-135 LOOKING GLASS and E-4 NEACAP command post aircraft, as well the entire strategic reconnaissance aircraft fleet consisting of the U-2, SR-71, RC-135, and WC-135.\nIn 1981, SAC received a new air refueling tanker aircraft to supplement the aging KC-135 Stratotanker force. Based on the McDonnell Douglas DC-10 commercial airliner, the KC-10A Extender was deployed equipped with improved military avionics, aerial refueling, and satellite communications equipment. That same year, President Ronald Reagan reversed the 1977 Carter administration decision regarding the B-1, directing that 100 examples of a refined version of the aircraft, now designated the B-1B Lancer, be procured as a long-range combat aircraft for SAC. The LGM-118A Peacekeeper ICBM reached SAC in 1986, and the 114 Peacekeepers had a total warhead yield of about 342 megatons. This also served to offset the retirement of the obsolescent and maintenance-intensive LGM-25C Titan II ICBM, the last example of which was deactivated in May 1987. An additional underground \"16,000 square-foot, two-story reinforced concrete\" command post for HQ SAC was also constructed at Offutt AFB from 1986 to 1989 from a design by Leo A. Daly, who had designed the adjoining 1957 bunker. The first Rockwell B-1B Lancer was also delivered to SAC in 1987. On 22 November 1988, the Northrop Grumman B-2 Spirit, under development as the Advanced Technology Bomber (ATB), a so-called \"black program\" since 1979, was officially acknowledged and rolled out for the first time for public display. The first \"stealth bomber\" designed for SAC, the aircraft made its first flight in May 1989.\nEnd of the Cold War and Operation Desert Storm.\nSAC reorganization at the end of the Cold War began as early as 1988 when the Carlucci Commission planned the closure of:\nThe closures were the beginning of a post-Cold War process that would later become known as Base Realignment and Closure or BRAC. Although Mather AFB's navigator training mission would relocate to Randolph AFB, Texas, the Mather B-52G bomber/KC-135A tanker wing would inactivate and the AFRES KC-135 tanker group would relocate to nearby McClellan AFB, relocating again four years later to Beale AFB when another BRAC process would close McClellan AFB. Concurrently, the Pease AFB bomber/tanker wing would lose its FB-111 aircraft and transfer to Whiteman AFB, Missouri in preparation for transition to the B-2 Spirit while a portion of Pease would be transferred to the New Hampshire Air National Guard for its ANG KC-135 air refueling wing and be renamed Pease Air National Guard Base.\nAdditional closures and divestments of SAC bases would continue throughout the late 1980s and early 1990s, accelerating even more so as a result the START I Treaty's mandated elimination of both the entire B-52G fleet and the inactivation of all Minuteman II and Peacekeeper ICBMs, as well as the 1992 reorganization of the Air Force that disestablished SAC and dispersed its assets to other new or existing MAJCOMs, primarily ACC and AMC. In addition to closures of Mather AFB and Pease AFB, this would eventually include the following subsequent closure and realignment actions, primarily due to BRAC:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nOn 1 July 1989, the 1st Combat Evaluation Group reporting directly to SAC headquarters was split with most HQ 1CEVG organizations transferring to SAC HQ (e.g., the Command Instrument Flight Division) and RBS personnel, equipment, and becoming the 1st Electronic Combat Range Group. Airborne NEACP alerts ended in 1990 and during 1991's Operation Desert Storm to liberate Kuwait from Iraqi invasion and occupation, SAC bomber, tanker and reconnaissance aircraft flew operations (e.g., B-52s with conventional bombs and conventional warhead AGM-86 ALCMs) near Iraq from bases in Great Britain, Turkey, Cyprus, Diego Garcia, Saudi Arabia, and the United Arab Emirates. Following Operation Desert Storm, the dissolution of the Soviet Union and the \"de facto\" end of the Cold War, President George H. W. Bush and Secretary of Defense Dick Cheney directed SAC to take all bomber and refueling aircraft and Minuteman II ICBMs off of continuous nuclear alert on 27 September 1991 and placing said aircraft on quick reaction ground alert.\nThe 31 May 1992 major reorganization of the USAF organizational structure subsequently disestablished SAC, moving its bomber, reconnaissance and aerial command post aircraft and all SAC ICBMs, along with all Tactical Air Command aircraft, to the newly established Air Combat Command (ACC). The newly established Air Mobility Command (AMC) inherited most of SAC's KC-135 Stratotanker aircraft and the entire KC-10 Extender aerial refueling tanker force, while some KC-135s were reassigned directly to USAFE and PACAF, with one additional air refueling wing assigned to the Air Education and Training Command (AETC) as the KC-135 formal training unit. Land-based ICBMs were later transferred from ACC to Air Force Space Command (AFSPC), while manned bombers remained in ACC. USAF nuclear forces in ACC and AFSPC were then combined with the United States Navy's Fleet Ballistic Missile submarine forces to form the United States Strategic Command (USSTRATCOM), which took over the SAC Headquarters complex at Offutt AFB. In 2009, the entire land-based USAF ICBM force and that portion of the USAF manned bomber force that was still nuclear-capable, e.g., the B-2 Spirit and B-52 Stratofortress, was transferred to the newly established Air Force Global Strike Command (AFGSC), while the B-1 Lancer conventional bomber force remained in ACC. In 2015, these B-1 units were also transferred to Air Force Global Strike Command, which assumed responsibility for all current and future USAF bomber forces.\nCulture and legacy.\nThe Strategic Air Command left a lasting cultural impact in addition to its military legacy. The most prominent slogan associated with SAC is the official motto, \u201cPeace Is Our Profession.\u201d This phrase captured the command's role in maintaining peace through deterrence during the Cold War. Another unofficial slogan became part of SAC lore: \u201cTo err is human; to forgive is not SAC policy.\u201d This saying reflected the high standards and strict discipline within SAC, where precision and accountability were paramount due to the critical nature of its mission. Additional, unofficial slogans include \"Peace Through Strength\" and \"Peace Through Superior Firepower\".\nCommemoration and new commands.\nThe SAC Museum located adjacent to Offutt AFB was moved in 1998 to a site near Ashland, Nebraska and renamed as the Strategic Air and Space Museum in 2001. Organizations commemorating SAC include the Strategic Air Command Veterans Association, the SAC Society, the B-47 Stratojet Association, the B-52 Stratofortress Association, the FB-111 Association, the SAC Airborne Command Control Association, the Association of Air Force Missileers, the SAC Elite Guard Association and the Strategic Air Command Memorial Amateur Radio Club. After the Cold War, SAC histories included a 1990 almanac and a 2006 organizational history.\nIn 2009, the Air Force Global Strike Command (AFGSC) was activated with the lineage of Strategic Air Command. AFGSC, headquartered at Barksdale AFB, Louisiana, is one of two USAF component commands assigned to United States Strategic Command (USSTRATCOM). AFGSC currently consists of Eighth Air Force (8AF), responsible for the nuclear-capable manned heavy bomber force, and Twentieth Air Force (20AF), responsible for the ICBM force.\n Redesignated: Strategic Air Command on 21 March 1946\nLineage.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nStrategic Air Command in the United Kingdom was among the command's largest overseas concentrations of forces, with additional forces under SAC's 16th Air Force at air bases in North Africa, Spain and Turkey during the 1950s and 1960s.\nSAC \"Provisional\" wings were also located in Kadena AB, Okinawa and U-Tapao Royal Thai Navy Airfield / U-Tapao AB, Thailand during the Vietnam War\nSAC also maintained bomber, tanker, and/or reconnaissance aircraft assets at the former Ramey AFB, Puerto Rico in the 1950s, 1960s and 1970s, and at Andersen AFB, Guam; RAF Mildenhall, RAF Fairford and RAF Alconbury in the United Kingdom; Moron AB, Spain; Lajes Field, Azores (Portugal); Diego Garcia, BIOT; and the former NAS Keflavik, Iceland through the 1990s.\nSAC also conducted operations from RAF Fairford, RAF Alconbury and RAF Mildenhall in the United Kingdom, Moron AB in Spain, Lajes Field in the Azores (Portugal), RAF Akrotiri in Cyprus, Incirlik AB in Turkey, Diego Garcia in the British Indian Ocean Territory, and from multiple air bases in Egypt, Saudi Arabia, Oman, and the United Arab Emirates during the first Gulf War (Operations Desert Shield and Desert Storm) from 1990 to 1991.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28119", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=28119", "title": "Scheme (programming language)", "text": "Dialect of Lisp\nScheme is a dialect of the Lisp family of programming languages. Scheme was created during the 1970s at the MIT Computer Science and Artificial Intelligence Laboratory (MIT CSAIL) and released by its developers, Guy L. Steele and Gerald Jay Sussman, via a series of memos now known as the Lambda Papers. It was the first dialect of Lisp to choose lexical scope and the first to require implementations to perform tail-call optimization, giving stronger support for functional programming and associated techniques such as recursive algorithms. It was also one of the first programming languages to support first-class continuations. It had a significant influence on the effort that led to the development of Common Lisp.\nThe Scheme language is standardized in the official Institute of Electrical and Electronics Engineers (IEEE) standard and a \"de facto\" standard called the \"Revisedn Report on the Algorithmic Language Scheme\" (R\"n\"RS). A widely implemented standard is R5RS (1998). The most recently ratified standard of Scheme is \"R7RS-small\" (2013). The more expansive and modular R6RS was ratified in 2007. Both trace their descent from R5RS; the timeline below reflects the chronological order of ratification.\nHistory.\nOrigins.\nScheme started in the 1970s as an attempt to understand Carl Hewitt's Actor model, for which purpose Steele and Sussman wrote a \"tiny Lisp interpreter\" using Maclisp and then \"added mechanisms for creating actors and sending messages\". Scheme was originally called \"Schemer\", in the tradition of other Lisp-derived languages such as Planner or \"Conniver\". The current name resulted from the authors' use of the ITS operating system, which limited filenames to two components of at most six characters each. Currently, \"Schemer\" is commonly used to refer to a Scheme programmer.\nR6RS.\nA new language standardization process began at the 2003 Scheme workshop, with the goal of producing an R6RS standard in 2006. This process broke with the earlier R\"n\"RS approach of unanimity.\nR6RS features a standard module system, allowing a split between the core language and libraries. Several drafts of the R6RS specification were released, the final version being R5.97RS. A successful vote resulted in ratifying the new standard, announced on August 28, 2007.\nCurrently the newest releases of various Scheme implementations support the R6RS standard. There is a portable reference implementation of the proposed implicitly phased libraries for R6RS, called psyntax, which loads and bootstraps itself properly on various older Scheme implementations.\nA feature of R6RS is the record-type descriptor (RTD). When an RTD is created and used, the record type representation can show the memory layout. It also calculated object field bit mask and mutable Scheme object field bit masks, and helped the garbage collector know what to do with the fields without traversing the whole fields list that are saved in the RTD. RTD allows users to expand the basic RTD to create a new record system.\nR6RS introduces numerous significant changes to the language. The source code is now specified in Unicode, and a large subset of Unicode characters may now appear in Scheme symbols and identifiers, and there are other minor changes to the lexical rules. Character data is also now specified in Unicode. Many standard procedures have been moved to the new standard libraries, which themselves form a large expansion of the standard, containing procedures and syntactic forms that were formerly not part of the standard. A new module system has been introduced, and systems for exception handling are now standardized. Syntax-rules has been replaced with a more expressive syntactic abstraction facility (syntax-case) which allows the use of all of Scheme at macro expansion time. Compliant implementations are now \"required\" to support Scheme's full numeric tower, and the semantics of numbers have been expanded, mainly in the direction of support for the IEEE 754 standard for floating point numerical representation.\nR7RS.\nThe R6RS standard has caused controversy because some see it as a departure from the minimalist philosophy. In August 2009, the Scheme Steering Committee, which oversees the standardization process, announced its intention to recommend splitting Scheme into two languages: a large modern programming language for programmers; and a small version, a subset of the large version retaining the minimalism praised by educators and casual implementors. Two working groups were created to work on these two new versions of Scheme. The Scheme Reports Process site has links to the working groups' charters, public discussions and issue tracking system.\nThe ninth draft of R7RS (small language) was made available on April 15, 2013. A vote ratifying this draft closed on May 20, 2013, and the final report has been available since August 6, 2013, describing \"the 'small' language of that effort: therefore it cannot be considered in isolation as the successor to R6RS\".\nDistinguishing features.\nScheme is primarily a functional programming language. It shares many characteristics with other members of the Lisp programming language family. Scheme's very simple syntax is based on s-expressions, parenthesized lists in which a prefix operator is followed by its arguments. Scheme programs thus consist of sequences of nested lists. Lists are also the main data structure in Scheme, leading to a close equivalence between source code and data formats (homoiconicity). Scheme programs can easily create and evaluate pieces of Scheme code dynamically.\nThe reliance on lists as data structures is shared by all Lisp dialects. Scheme inherits a rich set of list-processing primitives such as codice_1, codice_2 and codice_3 from its Lisp progenitors. Scheme uses strictly but dynamically typed variables and supports first class procedures. Thus, procedures can be assigned as values to variables or passed as arguments to procedures.\nThis section concentrates mainly on innovative features of the language, including those features that distinguish Scheme from other Lisps. Unless stated otherwise, descriptions of features relate to the R5RS standard. In examples provided in this section, the notation \"===&gt; result\" is used to indicate the result of evaluating the expression on the immediately preceding line. This is the same convention used in R5RS.\nMinimalism.\nScheme is a very simple language, much easier to implement than many other languages of comparable expressive power. This ease is attributable to the use of lambda calculus to derive much of the syntax of the language from more primitive forms. For instance of the 23 s-expression-based syntactic constructs defined in the R5RS Scheme standard, 14 are classed as derived or library forms, which can be written as macros involving more fundamental forms, principally lambda. As R5RS (\u00a73.1) says: \"The most fundamental of the variable binding constructs is the lambda expression, because all other variable binding constructs can be explained in terms of lambda expressions.\"\n Fundamental forms: define, lambda, quote, if, define-syntax, let-syntax, letrec-syntax, syntax-rules, set!\n Derived forms: do, let, let*, letrec, cond, case, and, or, begin, named let, delay, unquote, unquote-splicing, quasiquote\nExample: a macro to implement codice_4 as an expression using codice_5 to perform the variable bindings.\n(define-syntax let\n (syntax-rules ()\n ((let ((var expr) ...) body ...)\n ((lambda (var ...) body ...) expr ...))))\nThus using codice_4 as defined above a Scheme implementation would rewrite \"codice_7\" as \"codice_8\", which reduces implementation's task to that of coding procedure instantiations.\nIn 1998, Sussman and Steele remarked that the minimalism of Scheme was not a conscious design goal, but rather the unintended outcome of the design process. \"We were actually trying to build something complicated and discovered, serendipitously, that we had accidentally designed something that met all our goals but was much simpler than we had intended...we realized that the lambda calculus\u2014a small, simple formalism\u2014could serve as the core of a powerful and expressive programming language.\"\nLexical scope.\nLike most modern programming languages and unlike earlier Lisps such as Maclisp, Scheme is lexically scoped: all possible variable bindings in a program unit can be analyzed by reading the text of the program unit without consideration of the contexts in which it may be called. This contrasts with dynamic scoping which was characteristic of early Lisp dialects, because of the processing costs associated with the primitive textual substitution methods used to implement lexical scoping algorithms in compilers and interpreters of the day. In those Lisps, it was perfectly possible for a reference to a free variable inside a procedure to refer to quite distinct bindings external to the procedure, depending on the context of the call.\nThe impetus to incorporate lexical scoping, which was an unusual scoping model in the early 1970s, into their new version of Lisp, came from Sussman's studies of ALGOL. He suggested that ALGOL-like lexical scoping mechanisms would help to realize their initial goal of implementing Hewitt's Actor model in Lisp.\nThe key insights on how to introduce lexical scoping into a Lisp dialect were popularized in Sussman and Steele's 1975 Lambda Paper, \"Scheme: An Interpreter for Extended Lambda Calculus\", where they adopted the concept of the lexical closure (on page 21), which had been described in an AI Memo in 1970 by Joel Moses, who attributed the idea to Peter J. Landin.\nLambda calculus.\nAlonzo Church's mathematical notation, the lambda calculus, has inspired Lisp's use of \"lambda\" as a keyword for introducing a procedure, as well as influencing the development of functional programming techniques involving the use of higher-order functions in Lisp. But early Lisps were not suitable expressions of the lambda calculus because of their treatment of free variables.\nA formal lambda system has axioms and a complete calculation rule. It is helpful for the analysis using mathematical logic and tools. In this system, calculation can be seen as a directional deduction. The syntax of lambda calculus follows the recursive expressions from x, y, z, ...,parentheses, spaces, the period and the symbol \u03bb. The function of lambda calculation includes: First, serve as a starting point of powerful mathematical logic. Second, it can reduce the requirement of programmers to consider the implementation details, because it can be used to imitate machine evaluation. Finally, the lambda calculation created a substantial meta-theory.\nThe introduction of lexical scope resolved the problem by making an equivalence between some forms of lambda notation and their practical expression in a working programming language. Sussman and Steele showed that the new language could be used to elegantly derive all the imperative and declarative semantics of other programming languages including ALGOL and Fortran, and the dynamic scope of other Lisps, by using lambda expressions not as simple procedure instantiations but as \"control structures and environment modifiers\". They introduced continuation-passing style along with their first description of Scheme in the first of the Lambda Papers, and in subsequent papers, they proceeded to demonstrate the raw power of this practical use of lambda calculus.\nBlock structure.\nScheme inherits its block structure from earlier block structured languages, particularly ALGOL. In Scheme, blocks are implemented by three \"binding constructs\": codice_4, codice_10 and codice_11. For instance, the following construct creates a block in which a symbol called codice_12 is bound to the number 10:\n ;; statements go here. Any reference to var here will be bound to 10.\nBlocks can be nested to create arbitrarily complex block structures according to the need of the programmer. The use of block structuring to create local bindings alleviates the risk of namespace collision that can otherwise occur.\nOne variant of codice_4, codice_10, permits bindings to refer to variables defined earlier in the same construct, thus:\n (var2 (+ var1 12)))\n ;; But the definition of var1 could not refer to var2\nThe other variant, codice_11, is designed to enable mutually recursive procedures to be bound to one another.\n (letrec ((female (lambda (n)\n (if (= n 0)\n 1\n (- n (male (female (- n 1)))))))\n (male (lambda (n)\n (if (= n 0)\n 0\n (- n (female (male (- n 1))))))))\n (let loop ((i 0))\n (if (&gt; i n)\n (cons (cons (female i)\n (male i))\n (loop (+ i 1)))))))\n===&gt; ((1 . 0) (1 . 0) (2 . 1) (2 . 2) (3 . 2) (3 . 3) (4 . 4) (5 . 4) (5 . 5))\nAll procedures bound in a single codice_11 may refer to one another by name, as well as to values of variables defined earlier in the same codice_11, but they may not refer to \"values\" defined later in the same codice_11.\nA variant of codice_4, the \"named let\" form, has an identifier after the codice_4 keyword. This binds the let variables to the argument of a procedure whose name is the given identifier and whose body is the body of the let form. The body may be repeated as desired by calling the procedure. The named let is widely used to implement iteration.\nExample: a simple counter\n (if (&gt; n 10)\n (cons n\n (loop (+ n 1)))))\n===&gt; (1 2 3 4 5 6 7 8 9 10)\nLike any procedure in Scheme, the procedure created in the named let is a first-class object.\nProper tail recursion.\nScheme has an iteration construct, codice_21, but it is more idiomatic in Scheme to use tail recursion to express iteration. Standard-conforming Scheme implementations are required to optimize tail calls so as to support an unbounded number of active tail calls (R5RS sec. 3.5)\u2014a property the Scheme report describes as \"proper tail recursion\"\u2014making it safe for Scheme programmers to write iterative algorithms using recursive structures, which are sometimes more intuitive. Tail recursive procedures and the \"named codice_4\" form provide support for iteration using tail recursion.\n (let loop ((i n) (res '()))\n (if (&lt; i 0)\n res\n (loop (- i 1) (cons (* i i) res)))))\n===&gt; (0 1 4 9 16 25 36 49 64 81)\nFirst-class continuations.\nContinuations in Scheme are first-class objects. Scheme provides the procedure codice_23 (also known as codice_24) to capture the current continuation by packing it up as an escape procedure bound to a formal argument in a procedure provided by the programmer. (R5RS sec. 6.4) First-class continuations enable the programmer to create non-local control constructs such as iterators, coroutines, and backtracking.\nContinuations can be used to emulate the behavior of return statements in imperative programming languages. The following function codice_25, given function codice_26 and list codice_27, returns the first element codice_28 in codice_27 such that codice_30 returns true.\n (call-with-current-continuation\n (lambda (return-immediately)\n (for-each (lambda (x)\n (if (func x)\n (return-immediately x)))\n lst)\n #f)))\n===&gt; 7\n===&gt; #f\nThe following example, a traditional programmer's puzzle, shows that Scheme can handle continuations as first-class objects, binding them to variables and passing them as arguments to procedures.\n(let* ((yin\n ((lambda (cc) (display \"@\") cc) (call-with-current-continuation (lambda (c) c))))\n (yang\n ((lambda (cc) (display \"*\") cc) (call-with-current-continuation (lambda (c) c)))))\n (yin yang))\nWhen executed this code displays a counting sequence: codice_31\nShared namespace for procedures and variables.\nIn contrast to Common Lisp, all data and procedures in Scheme share a common namespace, whereas in Common Lisp functions and data have separate namespaces making it possible for a function and a variable to have the same name, and requiring special notation for referring to a function as a value. This is sometimes known as the \"Lisp-1 vs. Lisp-2\" distinction, referring to the unified namespace of Scheme and the separate namespaces of Common Lisp.\nIn Scheme, the same primitives that are used to manipulate and bind data can be used to bind procedures. There is no equivalent of Common Lisp's codice_32 and codice_33 primitives.\nf\n===&gt; 10\nf\n===&gt; 26\n===&gt; 18\nf\n===&gt; 13\n===&gt; 21\n===&gt; (101 102 103)\nImplementation standards.\nThis subsection documents design decisions that have been taken over the years which have given Scheme a particular character, but are not the direct outcomes of the original design.\nNumerical tower.\nScheme specifies a comparatively full set of numerical datatypes including complex and rational types, which is known in Scheme as the numerical tower (R5RS sec. 6.2). The standard treats these as abstractions, and does not commit the implementor to any particular internal representations.\nNumbers may have the quality of exactness. An exact number can only be produced by a sequence of exact operations involving other exact numbers\u2014inexactness is thus contagious. The standard specifies that any two implementations must produce equivalent results for all operations resulting in exact numbers.\nThe R5RS standard specifies procedures codice_34 and codice_35 which can be used to change the exactness of a number. codice_35 produces \"the exact number that is numerically closest to the argument\". codice_34 produces \"the inexact number that is numerically closest to the argument\". The R6RS standard omits these procedures from the main report, but specifies them as R5RS compatibility procedures in the standard library (rnrs r5rs (6)).\nIn the R5RS standard, Scheme implementations are not required to implement the whole numerical tower, but they must implement \"a coherent subset consistent with both the purposes of the implementation and the spirit of the Scheme language\" (R5RS sec. 6.2.3). The new R6RS standard does require implementation of the whole tower, and \"exact integer objects and exact rational number objects of practically unlimited size and precision, and to implement certain procedures...so they always return exact results when given exact arguments\" (R6RS sec. 3.4, sec. 11.7.1).\nExample 1: exact arithmetic in an implementation that supports exact \nrational complex numbers.\nx\n===&gt; 509/60+1/3i\n===&gt; #t\nExample 2: Same arithmetic in an implementation that supports neither exact \nrational numbers nor complex numbers but does accept real numbers in rational notation.\nxr\n===&gt; 8.48333333333333\nxi\n===&gt; 0.333333333333333\n===&gt; #f\n===&gt; #f\nBoth implementations conform to the R5RS standard but the second does not conform to R6RS because it does not implement the full numerical tower.\nDelayed evaluation.\nScheme supports delayed evaluation through the codice_38 form and the procedure codice_39.\n===&gt; 22\n (force eval-aplus50))\n===&gt; 70\n===&gt; 22\nThe lexical context of the original definition of the promise is preserved, and its value is also preserved after the first use of codice_39. The promise is only ever evaluated once.\nThese primitives, which produce or handle values known as promises, can be used to implement advanced lazy evaluation constructs such as streams.\nIn the R6RS standard, these are no longer primitives, but instead, are provided as part of the R5RS compatibility library (rnrs r5rs (6)).\nIn R5RS, a suggested implementation of codice_38 and codice_39 is given, implementing the promise as a procedure with no arguments (a thunk) and using memoization to ensure that it is only ever evaluated once, irrespective of the number of times codice_39 is called (R5RS sec. 6.4).\nSRFI 41 enables the expression of both finite and infinite sequences with extraordinary economy. For example, this is a definition of the Fibonacci sequence using the functions defined in SRFI 41:\n(define fibs\n (stream-cons 0\n (stream-cons 1\n (stream-map +\n fibs\n (stream-cdr fibs)))))\n===&gt; 218922995834555169026\nOrder of evaluation of procedure arguments.\nMost Lisps specify an order of evaluation for procedure arguments. Scheme does not. Order of evaluation\u2014including the order in which the expression in the operator position is evaluated\u2014may be chosen by an implementation on a call-by-call basis, and the only constraint is that \"the effect of any concurrent evaluation of the operator and operand expressions is constrained to be consistent with some sequential order of evaluation.\" (R5RS sec. 4.1.3)\n (display (if (procedure? n) \"procedure\" n))\n (newline) n)))\n ((ev +) (ev 1) (ev 2)))\n===&gt; 3\nEvaluating 1\nEvaluating 2\nEvaluating procedure\nev is a procedure that describes the argument passed to it, then returns the value of the argument. In contrast with other Lisps, the appearance of an expression in the operator position (the first item) of a Scheme expression is quite legal, as long as the result of the expression in the operator position is a procedure.\nIn calling the procedure \"+\" to add 1 and 2, the expressions (ev +), (ev 1) and (ev 2) may be evaluated in any order, as long as the effect is not as if they were evaluated in parallel. Thus the following three lines may be displayed in any order by standard Scheme when the above example code is executed, although the text of one line may not be interleaved with another because that would violate the sequential evaluation constraint.\nHygienic macros.\nIn the R5RS standard and in later reports, the syntax of Scheme can easily be extended via the macro system. The R5RS standard introduced a powerful hygienic macro system that allows the programmer to add new syntactic constructs to the language using a simple pattern matching sublanguage (R5RS sec 4.3). Prior to this, the hygienic macro system had been relegated to an appendix of the R4RS standard, as a \"high level\" system alongside a \"low level\" macro system, both of which were treated as extensions to Scheme rather than an essential part of the language.\nImplementations of the hygienic macro system, also called codice_44, are required to respect the lexical scoping of the rest of the language. This is assured by special naming and scoping rules for macro expansion and avoids common programming errors that can occur in the macro systems of other programming languages. R6RS specifies a more sophisticated transformation system, codice_45, which has been available as a language extension to R5RS Scheme for some time.\n(define-syntax when\n (syntax-rules ()\n ((when pred exp exps ...)\n (if pred (begin exp exps ...)))))\nInvocations of macros and procedures bear a close resemblance\u2014both are s-expressions\u2014but they are treated differently. When the compiler encounters an s-expression in the program, it first checks to see if the symbol is defined as a syntactic keyword within the current lexical scope. If so, it then attempts to expand the macro, treating the items in the tail of the s-expression as arguments without compiling code to evaluate them, and this process is repeated recursively until no macro invocations remain. If it is not a syntactic keyword, the compiler compiles code to evaluate the arguments in the tail of the s-expression and then to evaluate the variable represented by the symbol at the head of the s-expression and call it as a procedure with the evaluated tail expressions passed as arguments to it.\nMost Scheme implementations also provide additional macro systems. Among popular ones are syntactic closures, explicit renaming macros and codice_46, a non-hygienic macro system similar to codice_47 system provided in Common Lisp.\nThe inability to specify whether or not a macro is hygienic is one of the shortcomings of the macro system. Alternative models for expansion such as scope sets provide a potential solution.\nEnvironments and eval.\nPrior to R5RS, Scheme had no standard equivalent of the codice_48 procedure which is ubiquitous in other Lisps, although the first Lambda Paper had described codice_49 as \"similar to the LISP function EVAL\" and the first Revised Report in 1978 replaced this with codice_50, which took two arguments. The second, third and fourth revised reports omitted any equivalent of codice_48.\nThe reason for this confusion is that in Scheme with its lexical scoping the result of evaluating an expression depends on where it is evaluated. For instance, it is not clear whether the result of evaluating the following expression should be 5 or 6:\n (let ((+ *))\n (evaluate (list name 2 3))))\nIf it is evaluated in the outer environment, where codice_52 is defined, the result is the sum of the operands. If it is evaluated in the inner environment, where the symbol \"+\" has been bound to the value of the procedure \"*\", the result is the product of the two operands.\nR5RS resolves this confusion by specifying three procedures that return environments and providing a procedure codice_48 that takes an s-expression and an environment and evaluates the expression in the environment provided. (R5RS sec. 6.5) R6RS extends this by providing a procedure called codice_54 by which the programmer can specify exactly which objects to import into the evaluation environment.\nWith modern scheme (usually compatible with R5RS) to evaluate this expression, one needs to define a function codice_49 which can look like this:\n (eval expr (interaction-environment)))\ncodice_56 is the interpreter's global environment.\nTreatment of non-Boolean values in Boolean expressions.\nIn most dialects of Lisp including Common Lisp, by convention the value codice_57 evaluates to the value false in a Boolean expression. In Scheme, since the IEEE standard in 1991, all values except codice_58, including codice_57's equivalent in Scheme which is written as codice_60, evaluate to the value true in a Boolean expression. (R5RS sec. 6.3.1)\nWhere the constant representing the Boolean value of true is codice_61 in most Lisps, in Scheme it is codice_62.\nDisjointness of primitive datatypes.\nIn Scheme the primitive datatypes are disjoint. Only one of the following predicates can be true of any Scheme object: codice_63, codice_64, codice_65, codice_66, codice_67, codice_68, codice_69, codice_70, codice_71. (R5RS sec 3.2)\nWithin the numerical datatype, by contrast, the numerical values overlap. For example, an integer value satisfies all of the codice_72, codice_73, codice_74, codice_75 and codice_66 predicates at the same time. (R5RS sec 6.2)\nEquivalence predicates.\nScheme has three different types of equivalence between arbitrary objects denoted by three different \"equivalence predicates\", relational operators for testing equality, codice_77, codice_78 and codice_79:\nType dependent equivalence operations also exist in Scheme: codice_87 and codice_88 compare two strings (the latter performs a case-independent comparison); codice_89 and codice_90 compare characters; codice_91 compares numbers.\nComments.\nUp to the R5RS standard, the standard comment in Scheme was a semicolon, which makes the rest of the line invisible to Scheme. Numerous implementations have supported alternative conventions permitting comments to extend for more than a single line, and the R6RS standard permits two of them: an entire s-expression may be turned into a comment (or \"commented out\") by preceding it with codice_92 (introduced in SRFI 62) and a multiline comment or \"block comment\" may be produced by surrounding text with codice_93 and codice_94.\nInput/output.\nScheme's input and output is based on the \"port\" datatype. (R5RS sec 6.6) R5RS defines two default ports, accessible with the procedures codice_95 and codice_96, which correspond to the Unix notions of standard input and standard output. Most implementations also provide codice_97. Redirection of input and standard output is supported in the standard, by standard procedures such as codice_98 and codice_99. Most implementations provide string ports with similar redirection capabilities, enabling many normal input-output operations to be performed on string buffers instead of files, using procedures described in SRFI 6. The R6RS standard specifies much more sophisticated and capable port procedures and many new types of port.\nThe following examples are written in strict R5RS Scheme.\nExample 1: With output defaulting to (current-output-port):\n (hello0))\nExample 2: As 1, but using optional port argument to output procedures\n (hello1 (current-output-port)))\nExample 3: As 1, but output is redirected to a newly created file\n (with-output-to-file \"helloworldoutputfile\" hello0))\nExample 4: As 2, but with explicit file open and port close to send output to file\n (output-port (open-output-file \"helloworldoutputfile\")))\n (hello1 output-port)\n (close-output-port output-port))\nExample 5: As 2, but with using call-with-output-file to send output to a file.\n (call-with-output-file \"helloworldoutputfile\" hello1))\nSimilar procedures are provided for input. R5RS Scheme provides the predicates codice_100 and codice_101. For character input and output, codice_102, codice_103, codice_104 and codice_105 are provided. For writing and reading Scheme expressions, Scheme provides codice_106 and codice_107. On a read operation, the result returned is the end-of-file object if the input port has reached the end of the file, and this can be tested using the predicate codice_108.\nWith the standard, SRFI 28 also defines a basic formatting procedure resembling Common Lisp's codice_109 function, after which it is named.\nRedefinition of standard procedures.\nIn Scheme, procedures are bound to variables. At R5RS the language standard formally mandated that programs may change the variable bindings of built-in procedures, effectively redefining them. (R5RS \"Language changes\") For example, codice_110 can be extended to accept strings as well as numbers by redefining it:\n(set! +\n (let ((original+ +))\n (lambda args\n (apply (if (or (null? args) (string? (car args)))\n string-append\n original+)\n args))))\n===&gt; 6\n===&gt; \"123\"\nIn R6RS every binding, including the standard ones, belongs to some library, and all exported bindings are immutable. (R6RS sec 7.1) Because of this, redefinition of standard procedures by mutation is forbidden. Instead, it is possible to import a different procedure under the name of a standard one, which in effect is similar to redefinition.\nNomenclature and naming conventions.\nIn Standard Scheme, procedures that convert from one datatype to another contain the character string \"-&gt;\" in their name, predicates end with a \"?\", and procedures that change the value of already-allocated data end with a \"!\". These conventions are often followed by Scheme programmers.\nIn formal contexts such as Scheme standards, the word \"procedure\" is used in preference to \"function\" to refer to a lambda expression or primitive procedure. In normal usage, the words \"procedure\" and \"function\" are used interchangeably. Procedure application is sometimes referred to formally as \"combination\".\nAs in other Lisps, the term \"thunk\" is used in Scheme to refer to a procedure with no arguments. The term \"proper tail recursion\" refers to the property of all Scheme implementations, that they perform tail-call optimization so as to support an indefinite number of active tail calls.\nThe form of the titles of the standards documents since R3RS, \"Revisedn Report on the Algorithmic Language Scheme\", is a reference to the title of the ALGOL 60 standard document, \"Revised Report on the Algorithmic Language Algol 60,\" The Summary page of R3RS is closely modeled on the Summary page of the ALGOL 60 Report.\nReview of standard forms and procedures.\nThe language is formally defined in the standards R5RS (1998) and R6RS (2007). They describe standard \"forms\": keywords and accompanying syntax, which provide the control structure of the language, and standard procedures which perform common tasks.\nStandard forms.\nThis table describes the standard forms in Scheme. Some forms appear in more than one row because they cannot easily be classified into a single function in the language.\nForms marked \"L\" in this table are classed as derived \"library\" forms in the standard and are often implemented as macros using more fundamental forms in practice, making the task of implementation much easier than in other languages.\nWhile codice_111 is defined as a library syntax in R5RS, the expander must know about it to achieve the splicing function. In R6RS it is no longer a library syntax.\nStandard procedures.\nThe following two tables describe the standard procedures in R5RS Scheme. R6RS is far more extensive and a summary of this type would not be practical.\nSome procedures appear in more than one row because they cannot easily be classified into a single function in the language.\nString and character procedures that contain \"-ci\" in their names perform case-independent comparisons between their arguments: upper case and lower case versions of the same character are taken to be equal.\nImplementations of - and / that take more than two arguments are defined but left optional at R5RS.\nScheme Requests for Implementation.\nBecause of Scheme's minimalism, many common procedures and syntactic forms are not defined by the standard. In order to keep the core language small but facilitate standardization of extensions, the Scheme community has a \"Scheme Request for Implementation\" (SRFI) process by which extension libraries are defined through careful discussion of extension proposals. This promotes code portability. Many of the SRFIs are supported by all or most Scheme implementations.\nSRFIs with fairly wide support in different implementations include:\nImplementations.\nThe elegant, minimalist design has made Scheme a popular target for language designers, hobbyists, and educators, and because of its small size, that of a typical interpreter, it is also a popular choice for embedded systems and scripting. This has resulted in scores of implementations, most of which differ from each other so much that porting programs from one implementation to another is quite difficult, and the small size of the standard language means that writing a useful program of any great complexity in standard, portable Scheme is almost impossible. The R6RS standard specifies a much broader language, in an attempt to broaden its appeal to programmers.\nAlmost all implementations provide a traditional Lisp-style read\u2013eval\u2013print loop for development and debugging. Many also compile Scheme programs to executable binary. Support for embedding Scheme code in programs written in other languages is also common, as the relative simplicity of Scheme implementations makes it a popular choice for adding scripting capabilities to larger systems developed in languages such as C. The Gambit, Chicken, and Bigloo Scheme interpreters compile Scheme to C, which makes embedding far easier. Further, Bigloo's compiler can be configured to generate bytecode for the Java virtual machine (JVM), and has an experimental bytecode generator for .NET.\nSome implementations support added features. For example, Kawa and JScheme provide integration with Java classes, and the Scheme to C compilers often make it easy to use external libraries written in C, up to allowing the embedding of C code in the Scheme source code. Another example is Pvts, which offers a set of visual tools that support Scheme learning.\nUsage.\nScheme is widely used by several schools; in particular, several introductory computer science courses use Scheme in conjunction with the textbook \"Structure and Interpretation of Computer Programs\" (SICP). For the past 12 years, PLT has run the ProgramByDesign (formerly TeachScheme!) project, which has exposed close to 600 high school teachers and thousands of high school students to rudimentary Scheme programming. MIT's old introductory programming class 6.001 was taught in Scheme, Although 6.001 has been replaced by more modern courses, SICP continues to be taught at MIT. Likewise, the introductory class at UC Berkeley, CS 61A, was until 2011 taught entirely in Scheme, save minor diversions into Logo to demonstrate dynamic scope. Today, like MIT, Berkeley has replaced the syllabus with a more modern version that is primarily taught in Python 3, but the current syllabus is still based on the old curriculum, and parts of the class are still taught in Scheme.\nThe textbook \"How to Design Programs\" is used by some institutes of higher education for their introductory computer science courses. Worcester Polytechnic Institute uses Scheme exclusively for its introductory course Introduction to Program Design (CS1101). Rose-Hulman Institute of Technology uses Scheme in its more advanced Programming Language Concepts course. Brandeis University's core course, Structure and Interpretations of Computer Programs (COSI121b), is also taught exclusively in Scheme by theoretical computer scientist Harry Mairson. Indiana University's introductory class, C211, is taught entirely in Scheme. A self-paced version of the course, CS 61AS, continues to use Scheme. The introductory computer science courses at Yale and Grinnell College are also taught in Scheme. \nThe former introductory computer science course at the University of Minnesota - Twin Cities, CSCI 1901, also used Scheme as its primary language, followed by a course that introduced students to the Java language; however, following the example of MIT, the department replaced 1901 with the Python-based CSCI 1133, while functional programming is covered in detail in the third-semester course CSCI 2041.\nScheme is/was also used for the following:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28120", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=28120", "title": "Strategic Voting", "text": ""}
{"id": "28122", "revid": "17843555", "url": "https://en.wikipedia.org/wiki?curid=28122", "title": "Society for Psychical Research", "text": "UK nonprofit organisation\nThe Society for Psychical Research (SPR) is a nonprofit organisation in the United Kingdom. Its stated purpose is to understand events and abilities commonly described as psychic or paranormal. It describes itself as the \"first society to conduct organised scholarly research into human experiences that challenge contemporary scientific models.\" It does not, however, since its inception in 1882, hold any corporate opinions: SPR members assert a variety of beliefs with regard to the nature of the phenomena studied.\nOrigins.\nThe Society for Psychical Research (SPR) originated from a discussion between journalist Edmund Rogers and the physicist William F. Barrett in autumn 1881. This led to a conference on 5 and 6 January 1882 at the headquarters of the British National Association of Spiritualists, at which the foundation of the Society was proposed. The committee included Barrett, Rogers, Stainton Moses, Charles Massey, Edmund Gurney, Hensleigh Wedgwood and Frederic W. H. Myers. The SPR was formally constituted on 20 February 1882 with philosopher Henry Sidgwick as its first president.\nThe SPR was the first organisation of its kind in the world, its stated purpose being \"to approach these varied problems without prejudice or prepossession of any kind, and in the same spirit of exact and unimpassioned enquiry which has enabled science to solve so many problems, once not less obscure nor less hotly debated.\"\nIn 1882 Mary Everest Boole became the first female member of the SPR; however, she resigned after six months. Some other early members included the author Jane Barlow, the renowned chemist Sir William Crookes, physicist Sir Oliver Lodge, Nobel laureate Charles Richet, artist Lewis Charles Powles and psychologist William James.\nMembers of the SPR initiated and organised the International Congresses of Physiological/Experimental psychology.\nAreas of study included hypnotism, dissociation, thought-transference, mediumship, Reichenbach phenomena, apparitions and haunted houses and the physical phenomena associated with s\u00e9ances. The SPR were to introduce a number of neologisms which have entered the English language, such as 'telepathy', which was coined by Frederic Myers.\nThe Society is run by a President and a Council of twenty members, and is open to interested members of the public to join. The organisation is based at 1 Vernon Mews, London, with a library and office open to members, and with large book and archival holdings in Cambridge University Library, Cambridgeshire, England. It publishes the peer-reviewed quarterly \"Journal of the Society for Psychical Research\" (\"JSPR\"), the irregular \"Proceedings\" and the magazine \"Paranormal Review\". It holds an annual conference, regular lectures and two study days per year and supports the \"LEXSCIEN\" on-line library project.\nResearch.\nPsychical research.\nAmong the first important works was the two-volume publication in 1886, \"Phantasms of the Living\", concerning telepathy and apparitions, co-authored by Gurney, Myers and Frank Podmore. This text, and subsequent research in this area, was received negatively by the scientific mainstream, though Gurney and Podmore provided a defence of the society's early work in this area in mainstream publications.\nThe SPR \"devised methodological innovations such as randomized study designs\" and conducted \"the first experiments investigating the psychology of eyewitness testimony (Hodgson and Davey, 1887), [and] empirical and conceptual studies illuminating mechanisms of dissociation and hypnotism\"\nIn 1894, the \"Census of Hallucinations\" was published which sampled 17,000 people. Out of these, 1,684 persons reported having experienced a hallucination of an apparition. Such efforts were claimed to have undermined \"the notion of dissociation and hallucinations as intrinsically pathological phenomena\".\nThe SPR investigated many spiritualist mediums such as Eva Carri\u00e8re and Eusapia Palladino.\nDuring the early twentieth century, the SPR studied a series of automatic scripts and trance utterances from a group of automatic writers, known as the cross-correspondences.\nFamous cases investigated by the Society include Borley Rectory and the Enfield Poltergeist.\nIn 1912 the Society extended a request for a contribution to a special medical edition of its Proceedings to Sigmund Freud. Though according to Ronald W. Clark (1980) \"Freud surmised, no doubt correctly, that the existence of any link between the founding fathers of psychoanalysis and investigation of the paranormal would hamper acceptance of psychoanalysis\" as would any perceived involvement with the occult. Nonetheless, Freud did respond, contributing an essay titled \"A Note on the Unconscious in Psycho-Analysis\" to the Medical Supplement to the Proceedings of the Society for Psychical Research.\nExposures of fraud.\nMuch of the society's early work involved investigating, exposing and in some cases duplicating fake phenomena. In the late 19th century, SPR investigations into s\u00e9ance phenomena led to the exposure of many fraudulent mediums.\nRichard Hodgson distinguished himself in that area. In 1884, Hodgson was sent by the SPR to India to investigate Helena Blavatsky and concluded that her claims of psychic power were fraudulent. However, in 1985 the original finding of fraud was questioned and reinvestigated by the SPR researcher Vernon Harrison, president of the Royal Photographic Society and an expert at detecting forgery. Harrison determined that \"As an investigator, Hodgson is weighed in the balances and found wanting. His case against Madame H. P. Blavatsky is not proven.\"\nIn 1886 and 1887 a series of publications by S. J. Davey, Hodgson and Sidgwick in the SPR journal exposed the slate writing tricks of the medium William Eglinton. Hodgson with his friend, S. J. Davey, had staged fake s\u00e9ances for educating the public (including SPR members). Davey gave sittings under an assumed name, duplicating the phenomena produced by Eglinton, and then proceeded to point out to the sitters the manner in which they had been deceived. Because of this, some spiritualist members such as Stainton Moses resigned from the SPR.\nIn 1891, Alfred Russel Wallace requested for the Society to properly investigate spirit photography. Eleanor Sidgwick responded with a critical paper in the SPR which cast doubt on the subject and discussed the fraudulent methods that spirit photographers such as \u00c9douard Isidore Buguet, Frederic Hudson and William H. Mumler had utilised.\nDue to the exposure of William Hope and other fraudulent mediums, Arthur Conan Doyle led a mass resignation of eighty-four members of the Society for Psychical Research, as they believed the Society was opposed to spiritualism. Science historian William Hodson Brock has noted that \"By the 1900s most avowed spiritualists had left the SPR and gone back to the BNAS (the London Spiritualist Alliance since 1884), having become upset by the sceptical tone of most of the SPR's investigations.\"\nCriticism of the SPR.\nThe Society has been criticized by both spiritualists and skeptics.\nCriticism from spiritualists.\nProminent spiritualists at first welcomed the SPR and cooperated fully, but relations soured when spiritualists discovered that the SPR would not accept outside testimony as proof, and the society accused some prominent mediums of fraud. Spiritualist Arthur Conan Doyle resigned from the SPR in 1930, to protest what he regarded as the SPR's overly restrictive standards of proof. Psychic investigator and believer in spiritualism Nandor Fodor criticised the SPR for its \"strong bias\" against physical manifestations of spiritualism.\nCriticism from sceptics.\nSceptics have criticised members of the SPR for having motives liable to impair scientific objectivity. According to SPR critics John Grant and Eric Dingwall (a member of the SPR), early SPR members such as Henry Sidgwick, Frederic W. H. Myers, and William Barrett hoped to cling to something spiritual through psychical research. Myers stated that \u201c[T]he Society for Psychical Research was founded, with the establishment of thought-transference\u2014already rising within measurable distance of proof\u2014as its primary aim.\u201d Defenders of the SPR have stated in reply that \u201ca \u2018will to believe\u2019 in post-mortem survival, telepathy and other scientifically unpopular notions, does not necessarily exclude a \u2018will to know\u2019 and thus the capacity for thorough self-criticism, methodological rigour and relentless suspicion of errors.\u201d\nThe sceptic and physicist Victor J. Stenger has written:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; The SPR ... on occasion exposed blatant cases of fraud even their own credulous memberships could not swallow. But their journals have never succeeded in achieving a high level of credibility in the eyes of the rest of the scientific community. ... most articles usually begin with the assumption that psychic phenomena are demonstrated realities.\nIvor Lloyd Tuckett, an author of an early sceptical work on psychical research, wrote that although the SPR have collected some valuable work, most of its active members have \"no training in psychology fitting them for their task, and have been the victims of pronounced bias, as sometimes they themselves have admitted.\" Trevor H. Hall, an ex-member of the Society for Psychical Research, criticised SPR members for their \"credulous and obsessive wish... to believe.\" Hall also claimed SPR members \"lack knowledge of deceptive methods.\"\nWriter Edward Clodd asserted that the SPR members William F. Barrett and Oliver Lodge had insufficient competence for the detection of fraud and suggested that their spiritualist beliefs were based on magical thinking and primitive superstition. Clodd described the SPR as offering \"barbaric spiritual philosophy\", and characterised the language of SPR members as using such terms as \"subliminal consciousness\" and \"telepathic energy,\" as a disguise for \"bastard supernaturalism.\"\nA 2004 psychological study involving 174 members of the Society for Psychical Research completed a delusional ideation questionnaire and a deductive reasoning task. The study found that \"individuals who reported a strong belief in the paranormal made more errors and displayed more delusional ideation than skeptical individuals\". The study also claims that reasoning abnormalities may have a causal role in the formation of paranormal belief.\nSome sceptical members have resigned from the SPR. Eric Dingwall resigned and wrote \"After sixty years' experience and personal acquaintance with most of the leading parapsychologists of that period I do not think I could name half a dozen whom I could call objective students who honestly wished to discover the truth. The great majority wanted to prove something or other: They wanted the phenomena into which they were inquiring to serve some purpose in supporting preconceived theories of their own.\"(1985)\nPresidents.\nThe following is a list of presidents:\nPublications.\nThe Society publishes \"Proceedings of the Society for Psychical Research\", the \"Journal of the Society for Psychical Research\", and the \"Paranormal Review\", as well as the online \"Psi Encyclopedia\".\n\"Proceedings of the Society for Psychical Research\".\nFirst published in 1882 as a public record of the activities of the SPR, the \"Proceedings\" are now reserved for longer pieces of work, such as Presidential Addresses, and are only occasionally published. The current editor is David Vernon.\n\"Journal of the Society for Psychical Research\".\nThe \"Journal of the Society for Psychical Research\" has been published quarterly since 1884. It was introduced as a private, members-only periodical to supplement the \"Proceedings\". It now focuses on current laboratory and field research, but also includes theoretical, methodological and historical papers on parapsychology. It also publishes book reviews and correspondence. The current editor is David Vernon.\n\"Magazine of the Society for Psychical Research\".\nThe \"Magazine of the Society for Psychical Research\", formerly known as the \"Psi Researcher\" and \"Paranormal Review\", has been published since 1996. Previous editors have included Nicola J. Holt. The current editor is Leo Ruickbie.\n\"Psi Encyclopedia\".\nThe \"Psi Encyclopedia\" is a collection of https://, involving the scientific investigation of psychic phenomena. A bequest of Nigel Buckmaster enabled the foundation of the encyclopedia.\nOther societies.\nA number of other psychical research organisations use the term 'Society for Psychical Research' in their name.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\nSPR histories\nScholarly studies\nCriticism\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "28123", "revid": "28809222", "url": "https://en.wikipedia.org/wiki?curid=28123", "title": "Sniper", "text": "Marksman\nA sniper is a military or paramilitary marksman who engages targets from positions of concealment or at distances exceeding the target's detection capabilities. Snipers generally have specialized training and are equipped with telescopic sights. Modern snipers use high-precision rifles and high-magnification optics. They often also serve as scouts or observers feeding tactical information back to their units or command headquarters.\nIn addition to long-range and high-grade marksmanship, military snipers are trained in a variety of special operation techniques: detection, stalking, target range estimation methods, camouflage, tracking, bushcraft, field craft, infiltration, special reconnaissance and observation, surveillance and target acquisition. Snipers need to have complete control of their bodies and senses in order to be effective. They also need to have the skill set to use data from their scope and monitors to adjust their aim to hit targets that are extremely far away. In training, snipers are given charts to ensure they can make last-minute calculations in the field.\nEtymology.\nThe name \"sniper\" comes from the verb \"to snipe\", which originated in the 1770s among soldiers in British India in reference to shooting snipes, a wader that was considered an extremely challenging game bird for hunters due to its alertness, camouflaging color and erratic flight behavior. Snipe hunters therefore needed to be stealthy in addition to being good trackers and marksmen. In the 18th century, letters sent home by English officers in India referred to a day's rough shooting as \"going sniping\", as it took a skilled flintlock sportsman a lot of patience and endurance to wing-shoot a snipe in flight. Accomplishing such a shot was regarded as exceptional. During the late 18th century, the term \"snipe shooting\" was simplified to \"sniping\". This evolved to the agent noun \"sniper\", first appearing by the 1820s. The term \"sniper\" became commonplace in the First World War.\nThe older term \"sharpshooter\" comes from the calque of German word , in use by British newspapers as early as 1801. The word alludes to good marksmanship, itself descendent of the shooting competitions () that took place throughout the year in Munich in the 15th century. Small companies of shooters () from the German states and Swiss cantons would form teams of for such popular competitions; proudly carrying flags depicting a crossbow on one side and a target musket on the other. The earliest known date for the creation of a shooting club formed specifically for the use of firearms comes from Lucerne, Switzerland, where one club has a charter dating from 1466. During the American Civil War, Confederate marksmen equipped with the imported Whitworth rifles were known as the Whitworth Sharpshooters.\nSnipers are also called \"hunters\" in many languages, due to the nature of the craft (with the hunting horn also being a symbol of marksmanship), being called , and . Other words for sniper include , and . Completely different and peculiar is the Italian term , in common use since First World War. The term is derived from Cecco (Beppe), familiarly and mockingly referring to the Austro-Hungarian Emperor Franz Joseph I (in Italian Francesco Giuseppe I; Cecco and Beppe are nicknames for Francesco and Giuseppe respectively).\nModern warfare.\nMilitary doctrine.\nDifferent countries use different military doctrines regarding snipers in military units, settings, and tactics.\nA sniper's primary function in modern warfare is to stay concealed at all times and avoid detection. Then from long range, to provide detailed surveillance from a concealed position and, if necessary, to reduce the enemy's combat ability by shooting high-value targets (especially officers and other key personnel), and in the process, cause disruption, pinning down and demoralizing the enemy. Typical sniper missions include managing intelligence information they gather during reconnaissance, target acquisition and impact feedback for air strikes and artillery, assisting employed combat force with accurate fire support and counter-sniper tactics, killing enemy commanders, selecting targets of opportunity, and even destruction of military equipment, which tend to require use of anti-materiel rifles in the larger calibers such as the .50 BMG, like the Barrett M82, McMillan Tac-50, and Denel NTW-20.\nSoviet- and Russian-derived military doctrines include squad-level snipers. Snipers have increasingly been demonstrated as useful by US and UK forces in the recent Iraq campaign in a fire support role to cover the movement of infantry, especially in urban areas.\nMilitary snipers from the US, UK and other countries that adopt their military doctrine are typically deployed in two-man sniper teams consisting of a shooter and a spotter. A common practice is for a shooter and a spotter to take turns to avoid eye fatigue. In most recent combat operations occurring in large densely populated towns, such as Fallujah, Iraq, two teams would be deployed together to increase their security and effectiveness in an urban environment. A sniper team would be armed with a long-range weapon and a rapid-firing shorter-ranged weapon in case of close quarter combat.\nThe German doctrine of largely independent snipers and emphasis on concealment, developed during the Second World War, has been most influential on modern sniper tactics, and is currently used throughout Western militaries (examples are specialized camouflage clothing, concealment in terrain and emphasis on coup d'\u0153il).\nSniper teams.\nSniper rifles are classified as crew-served in the United States military. A sniper team (or sniper cell) consists of a combination of at least one primary weapon operator, (i.e.: the shooter), with other support personnel and force protection elements, such as a \"spotter\" or a \"flanker\". Within the \"Table of Organization and Equipment\" for both the United States Army and Marine Corps, the shooter does not operate alone, but has a backup shooter trained to fulfill multiple roles in addition to being sniper-qualified in the operation of the main weapon.\nThe shooter focuses mainly on firing the shot, while the spotter assists in observation of targets, accounts for atmospheric conditions and handles ancillary tasks such as immediate security of their location, communication with other parties (e.g. directing artillery fire and close air support). A flanker is an extra teammate who is tasked to act as a sentry observing areas not immediately visible to the sniper and spotter, assisting with the team's rear security and perimeter defense, and therefore are usually armed with a faster-firing weapon such as an assault rifle, battle rifle or designated marksman rifle. Both the spotter and flanker carry additional ammunition and associated equipment.\nThe spotter is responsible for detecting, identifying and assigning priority of targets for the shooter, as well as assessing the outcome of the shot. Using a spotting scope and/or a rangefinder, the spotter will predict the external ballistics and read the wind speed using an anemometer or physical indicators like the mirage caused by ground heat. Also, in conjunction with the shooter, the spotter will calculate the distance, shooting angle (slant range), mil-related correction, interference by atmospheric factors and the required leads for moving targets. It is not unusual for the spotter to be equipped with a ballistic table, a notebook or a tablet computer specifically for performing these calculations.\nLaw enforcement applications.\nLaw enforcement snipers, commonly called police snipers, and military snipers differ in many ways, including their areas of operation and tactics. A police sharpshooter is part of a police operation and usually takes part in relatively short missions. Police forces typically deploy such sharpshooters in hostage scenarios. This differs from a military sniper, who operates as part of a larger army, engaged in warfare. Sometimes as part of a SWAT team, police snipers are deployed alongside negotiators and an assault team trained for close quarters combat. As policemen, they are trained to shoot only as a last resort, when there is a direct threat to life; the police sharpshooter has a well-known rule: \"Be prepared to take a life to save a life.\" Police snipers typically operate at much shorter ranges than military snipers, generally under and sometimes even less than . Both types of snipers do make difficult shots under pressure, and often perform one-shot kills.\nPolice units that are unequipped for tactical operations may rely on a specialized SWAT team, which may have a dedicated sniper. Some police sniper operations begin with military assistance. Police snipers placed in vantage points, such as high buildings, can provide security for events. In one high-profile incident commonly referred to as \"The Shot Seen Around the World\" due to going viral online, Mike Plumb, a SWAT sniper in Columbus, Ohio, prevented a suicide by shooting a revolver out of the individual's hand, leaving him unharmed.\nThe need for specialized training for police sharpshooters was made apparent in 1972 during the Munich massacre when the German police could not deploy specialized personnel or equipment during the standoff at the airport in the closing phase of the crisis, and consequently all of the Israeli hostages were killed. While the German army did have snipers in 1972, the use of army snipers in the scenario was impossible due to the German constitution's explicit prohibition of the use of the military in domestic matters. This lack of trained snipers who could be used in civilian roles was later addressed with the founding of the specialized police counter-terrorist unit GSG 9.\nLongest recorded sniper kill.\nThe longest confirmed sniper kill in combat was achieved by an undisclosed member of the Security Service of Ukraine in November 2023, hitting a Russian soldier at a distance of during the Russian invasion of Ukraine.\nThe previous record holder was a member of the Canadian JTF2 special forces who in June 2017 achieved a hit at a distance of .\nIn November 2009, Craig Harrison, a Corporal of Horse (CoH) in the Blues and Royals RHG/D of the British Army struck two Taliban machine gunners consecutively south of Musa Qala in Helmand Province in Afghanistan at a range of or 1.54 miles using a L115A3 Long Range Rifle.\nThe QTU Lapua external ballistics software, using continuous doppler drag coefficient (Cd) data provided by Lapua, predicts that such shots traveling would likely have struck their targets after nearly 6.0 seconds of flight time, having lost 93% of their kinetic energy, retaining of their original velocity, and having dropped or 2.8\u00b0 from the original bore line. Due to the extreme distances and travel time involved, even a light cross-breeze of would have diverted such shots off target, which would have required compensation.\nThe calculation assumes a \"flat-fire scenario\" (a situation where the shooting and target positions are at equal elevation), using British military custom high-pressure .338 Lapua Magnum cartridges, loaded with 16.2 g (250 gr) Lapua LockBase B408 bullets, fired at 936\u00a0m/s (3,071\u00a0ft/s) muzzle velocity under the following on-site (average) atmospheric conditions: barometric pressure: at sea-level equivalent or on-site, humidity: 25.9%, and temperature: in the region for November 2009, resulting in an air density \u03c1 = 1.0854\u00a0kg/m3 at the elevation of Musa Qala. Harrison mentions in reports that the environmental conditions were perfect for long range shooting, \"... no wind, mild weather, clear visibility.\" In a BBC interview, Harrison reported it took about nine shots for him and his spotter to initially range the target successfully.\nMilitary history.\nBefore the development of rifling, firearms were smoothbore and inaccurate over long distance. Barrel rifling was invented at the end of the fifteenth century, but was only employed in large cannons. Over time, rifling, along with other gunnery advances, has increased the performance of modern firearms.\n1543\u20131600.\nLong range marksmanship occurred as early as the mid-sixteenth century.\nOne example is the Ise-no-kami school of gunnery. It was founded by the Christian feudal lord of the Saiki Domain, Mori Takamasa (\u6bdb\u5229\u9ad8\u653f, 1559\u20131628). Takamasa had aspired to become a marksman from a young age, and in his prime, he used up a 10-tan sailboat's worth of ammunition in just a few years, showing his considerable passion. He is said to have always told people, \"You won't improve your skills unless you fire that much ammunition.\" During the battle of Ulsan Castle in Korea, he was a master of guns, firing at the enemy from a distance of seven cho (about 770 meters) with a 278\u00a0cm long \"\u7114\u9b54\u738b - Flaming Demon King\" O-zutsu (Matchlock Cannon) throwing the enemy camp into confusion with his accurate shots.\n1701\u20131800.\nLater \"sharpshooting\" or \"sniping\" became implemented in shooting terminology.\nFor example: in the 1752 Appin Murder, Colin Roy Campbell of Glenure was shot in the back near Duror by an unknown sniper, most likely from within Clan Stewart of Appin, in retaliation for Campbell's role in an early version of the Highland Clearances; the mass eviction of Stewart clansmen and their replacement by members of Clan Campbell.\nHunting terminology was quickly adapted to warfare by British soldiers. In a 1772 letter, a soldier described enemies firing very accurately:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2026 in erecting our batteries, the people frequently play tricks, by putting a hat with a cockade in it on a spunge staff, which the enemy fire at and often hit, to the diversion of the soldiery, who humorously call it sniping, and watch the flash to return the fire.\nOn 11 September 1777, during the Battle of Brandywine, British Captain Patrick Ferguson had a tall, distinguished American officer in his rifle's iron sights. Ferguson did not take the shot, as he considered shooting anyone in the back dishonourable. Only later, did Ferguson learn that George Washington had been on the battlefield that day.\nAt the Battles of Saratoga, Morgan's Riflemen hid in the trees and used early model rifles to shoot senior British officers. Most notably, Timothy Murphy shot and killed General Simon Fraser of Balnain on 7 October 1777 at a distance of about 400 yards.\nIn early 1800, Colonel Coote Manningham and Lieutenant-Colonel the Hon. William Stewart of the British Army proposed using what they had learned while leading light infantry to establish a special unit of marksmen. Subsequently raised as the \"Experimental Corps of Riflemen\", they were armed with the formidable Baker rifle rather than the inaccurate smoothbore muskets used by most troops at that time. Through the combination of a leather wad and tight grooves on the inside of the barrel (rifling), this weapon was far more accurate, though slower to load. On 25 August 1800, three companies, under the command of Stewart, spearheaded an amphibious landing at Ferrol, Spain.\n1801\u20131900.\nThe term, \"sharp shooter\" was in use in British newspapers as early as 1801. In the \"Edinburgh Advertiser\", 23 June 1801, can be found the following quote in a piece about the North British Militia; \"This Regiment has several Field Pieces, and two companies of Sharp Shooters, which are very necessary in the modern Stile of War\". The term appears even earlier, around 1781, in Continental Europe, translated from the German Scharfsch\u00fctze.\nScouts in the Ashanti army were made up of professional hunters who used their skill as marksmen to snipe at advancing enemy forces in response to detection by the enemy. They executed this often from a perch high in trees.\nThe Whitworth rifle was arguably the first long-range sniper rifle in the world. A muzzleloader designed by Sir Joseph Whitworth, a prominent British engineer, it used polygonal rifling instead, which meant that the projectile did not have to bite into grooves as was done with conventional rifling. The Whitworth rifle was far more accurate than the Pattern 1853 Enfield, which had shown some weaknesses during the recent Crimean War. At trials in 1857 which tested the accuracy and range of both weapons, Whitworth's design outperformed the Enfield at a rate of about three to one. The Whitworth rifle was capable of hitting the target at a range of 2,000 yards, whereas the Enfield could only manage it at 1,400 yards.\nDuring the Crimean War, the first optical sights were designed to fit onto rifles. Much of this pioneering work was the brainchild of Colonel D. Davidson, using optical sights produced by Chance Brothers of Birmingham. This allowed a marksman to observe and target objects more accurately at a greater distance than ever before. The telescopic sight, or scope, was originally fixed and could not be adjusted, which therefore limited its range.\nDespite its success at the trials, the rifle was not adopted by the British Army. However, the Whitworth Rifle Company was able to sell the weapon to the French army, and also to the Confederacy during the American Civil War, where both the Union and Confederate armies employed sharpshooters. The most notable incident was during the Battle of Spotsylvania Court House, where on 9 May 1864, Union General John Sedgwick was killed by a Confederate Whitworth sharpshooter at a range of about after saying the enemy \"couldn't hit an elephant at this distance\".\nSecond Boer War.\nDuring the Boer War the latest breech-loading rifled guns with magazines and smokeless powder were used by both sides. The British were equipped with the Lee\u2013Metford rifle, while the Boers had received the latest Mauser rifles from Germany. In the open terrain of South Africa the marksmen were a crucial component to the outcome of the battle.\nThe first British sniper unit began life as the Lovat Scouts, a Scottish Highland regiment formed in 1899, that earned high praise during the Second Boer War (1899\u20131902). The unit was formed by Lord Lovat and reported to an American, Major Frederick Russell Burnham, the British Army Chief of Scouts under Lord Roberts. Burnham fittingly described these scouts as \"half wolf and half jackrabbit.\". Just like their Boer scout opponents, these scouts were well practised in the arts of marksmanship, field craft, map reading, observation, and military tactics. They were skilled woodsmen and practitioners of discretion: \"He who shoots and runs away, lives to shoot another day.\" They were also the first known military unit to wear a ghillie suit. \nHesketh Hesketh-Prichard said of them that \"keener men never lived\", and that \"Burnham was the greatest scout of our time.\" Burnham distinguished himself in wars in South Africa, Rhodesia, and in Arizona fighting the Apaches, and his definitive work, \"Scouting on Two Continents,\" provides a dramatic and enlightening picture of what a sniper was at the time and how he operated.\nAfter the war, this regiment went on to formally become the first official sniper unit, then better known as \"sharpshooters\".\nWorld War I.\nDuring World War I, snipers appeared as deadly sharpshooters in the trenches. At the start of the war, only Imperial Germany had troops that were issued scoped sniper rifles. Although sharpshooters existed on all sides, the Germans specially equipped some of their soldiers with scoped rifles that could pick off enemy soldiers showing their heads out of their trench. At first the French and British believed such hits to be coincidental hits, until the German scoped rifles were discovered. During World War I, the German army received a reputation for the deadliness and efficiency of its snipers, partly because of the high-quality lenses that German industry could manufacture.\nDuring the First World War, the static movement of trench warfare and a need for protection from snipers created a requirement for loopholes both for discharging firearms and for observation. Often a steel plate was used with a \"key hole\", which had a rotating piece to cover the loophole when not in use.\nSoon the British army began to train their own snipers in specialized sniper schools. Major Hesketh Hesketh-Prichard was given formal permission to begin sniper training in 1915, and founded the First Army School of Sniping, Observation, and Scouting at Linghem in France in 1916. Starting with a first class of only six, in time he was able to lecture to large numbers of soldiers from different Allied nations, proudly proclaiming in a letter that his school was turning out snipers at three times the rate of any such other school in the world.\nHe also devised a metal-armoured double loophole that would protect the sniper observer from enemy fire. The front loophole was fixed, but the rear was housed in a metal shutter sliding in grooves. Only when the two loopholes were lined up\u2014a one-to-twenty chance\u2014could an enemy shoot between them. Another innovation was the use of a dummy head to find the location of an enemy sniper. The papier-m\u00e2ch\u00e9 figures were painted to resemble soldiers to draw sniper fire. Some were equipped with rubber surgical tubing so the dummy could \"smoke\" a cigarette and thus appear realistic. Holes punched in the dummy by enemy sniper bullets then could be used for triangulation purposes to determine the position of the enemy sniper, who could then be attacked with artillery fire. He developed many of the modern techniques in sniping, including the use of spotting scopes and working in pairs, and using Kim's Game to train observational skills.\nIn 1920, he wrote his account of his war time activities in his book \"\", to which reference is still made by modern authors regarding the subject.\nThe main sniper rifles used during the First World War were the German Mauser Gewehr 98; the British Pattern 1914 Enfield and Lee\u2013Enfield SMLE Mk III, the Canadian Ross rifle, the American M1903 Springfield, the Italian M1891 Carcano, and the Russian M1891 Mosin\u2013Nagant.\nThe Ottoman Empire initiated very effective sniper tactics against the British and ANZAC troops. The Allied forces on the Gallipoli Campaign come to believe that the Ottoman forces employed women snipers as well.\nWorld War II.\nDuring the interbellum, most nations dropped their specialized sniper units, notably the Germans. Effectiveness and dangers of snipers once again came to the fore during the Spanish Civil War. The only nation that had specially trained sniper units during the 1930s was the Soviet Union. Soviet snipers were trained in their skills as marksmen, in using the terrain to hide themselves from the enemy and the ability to work alongside regular forces. This made the Soviet sniper training focus more on \"normal\" combat situations than those of other nations.\nSnipers reappeared as important factors on the battlefield from the first campaign of World War II. During Germany's 1940 campaigns, lone, well-hidden French and British snipers were able to halt the German advance for a considerable amount of time. For example, during the pursuit to Dunkirk, British snipers were able to significantly delay the German infantry's advance. This prompted the British once again to increase training of specialized sniper units. Apart from marksmanship, British snipers were trained to blend in with the environment, often by using special camouflage clothing for concealment. However, because the British Army offered sniper training exclusively to officers and non-commissioned officers, the resulting small number of trained snipers in combat units considerably reduced their overall effectiveness.\nDuring the Winter War, Finnish snipers took a heavy toll of the invading Red Army. Simo H\u00e4yh\u00e4 is credited with 505 confirmed kills, most with the Finnish version of the iron-sighted bolt-action Mosin\u2013Nagant. The most successful German sniper was Matth\u00e4us Hetzenauer with 345 confirmed kills. In Germany, kills are only confirmed in the presence of an officer, so Hetzenauer's estimated kills are many times higher. His longest confirmed kill was reported at . Hetzenauer received the Knight's Cross of the Iron Cross on 17 April 1945.\nOne of the best known battles involving snipers, and the battle that made the Germans reinstate their specialized sniper training, was the Battle of Stalingrad. Their defensive position inside a city filled with rubble meant that Soviet snipers were able to inflict significant casualties on the Wehrmacht troops. Because of the nature of fighting in city rubble, snipers were very hard to spot and seriously dented the morale of the German attackers. The best known of these snipers was probably Vasily Zaytsev, featured in the novel \"War of the Rats\" and the subsequent film \"Enemy at the Gates\".\nGerman \"Scharfsch\u00fctzen\" were prepared before the war, equipped with Karabiner 98 and later Gewehr 43 rifles, but there were often not enough of these weapons available, and as such some were armed with captured scoped Mosin\u2013Nagant 1891/30, SVT, Czech Mauser rifles or scoped Gewehr 98 from WW1. The Wehrmacht re-established its sniper training in 1942, drastically increasing the number of snipers per unit with the creation of an additional 31 sniper training companies by 1944. German snipers were at the time the only snipers in the world issued with purpose-manufactured sniping ammunition, known as the 'effect-firing' sS round. The 'effect-firing' sS round featured an extra carefully measured propellant charge and seated a heavy 12.8\u00a0gram (198 gr) full-metal-jacketed boat-tail projectile of match-grade build quality, lacking usual features such as a seating ring to improve the already high ballistic coefficient of .584 (G1) further. For aiming optics German snipers used the Zeiss Zielvier 4x (ZF39) telescopic sight which had bullet drop compensation in 50 m increments for ranges from 100 m up to 800 m or in some variations from 100 m up to 1000 m or 1200 m. There were ZF42, Zielfernrohr 43 (ZF 4), Zeiss Zielsechs 6x, Zeiss Zielacht 8x and other telescopic sights by various manufacturers like the Ajack 4x, Hensoldt Dialytan 4x and Kahles Heliavier 4x with similar features employed on German sniper rifles. Several different mountings produced by various manufacturers were used for mounting aiming optics to the rifles. In February 1945 the Zielger\u00e4t 1229 active infrared aiming device was issued for night sniping with the StG 44 assault rifle.\nA total of 428,335 individuals received Red Army sniper training, including Soviet and non-Soviet partisans, with 9,534 receiving the sniping 'higher qualification'. During World War \u0406\u0406, over 100,000 women went through sniper training, of which more than two thousand later served in the army. Some used the PTRD anti-tank rifle with an adapted scope as an early example of an anti-materiel rifle.\nIn the United States Armed Forces, sniper training was only very elementary and was mainly concerned with being able to hit targets over long distances. Snipers were required to be able to hit a body over 400 meters away, and a head over 200 meters away. There was almost no instruction in blending into the environment. Sniper training varied from place to place, resulting in wide variation in the qualities of snipers. The main reason the US did not extend sniper training beyond long-range shooting was the limited deployment of US soldiers until the Normandy Invasion. During the campaigns in North Africa and Italy, most fighting occurred in arid and mountainous regions where the potential for concealment was limited, in contrast to Western and Central Europe.\nThe U.S. Army's lack of familiarity with sniping tactics proved disastrous in Normandy and the campaign in Western Europe where they encountered well trained German snipers. In Normandy, German snipers could remain hidden in the dense vegetation and were able to encircle American units, firing at them from all sides. The American and British forces were surprised by how near the German snipers could approach in safety and attack them, as well as by their ability to hit targets at up to 1,000m. A notable mistake made by inexperienced American soldiers was to lie down and wait when targeted by German snipers, allowing the snipers to pick them off one after another. German snipers often infiltrated Allied lines, and when the front-lines moved, they would sometimes continue fighting from their sniping positions, refusing to surrender until their rations and munitions were exhausted.\nThose tactics were also a consequence of changes in German enlistment. After several years of war and heavy losses on the Eastern Front, the German army was forced to rely more heavily on enlisting teenage soldiers. Due to lack of training in more complex group tactics, and thanks to rifle training provided by the Hitlerjugend, those soldiers were often used as autonomous left-behind snipers. While an experienced sniper would take a few lethal shots and retreat to a safer position, those young boys, due both to a disregard for their own safety and to lack of tactical experience would frequently remain in a concealed position and fight until they ran out of ammunition or were killed or wounded. While this tactic generally ended in the demise of the sniper, giving rise to the nickname \"Suicide Boys\" that was given to those soldiers, this irrational behavior proved quite disruptive to the Allied forces' progress. After World War II, many elements of German sniper training and doctrine were copied by other countries.\nIn the Pacific War, the Empire of Japan also trained snipers. In the jungles of Asia and the Pacific Islands, snipers posed a serious threat to U.S., British, and Commonwealth troops. Japanese snipers were specially trained to use the environment to conceal themselves, using foliage on their uniforms and digging well-concealed hide-outs that often connected to small trenches. There was no need for long range accuracy because most combat in the jungle took place within a few hundred meters. Japanese snipers were known for their patience and ability to remain hidden for long periods, almost never leaving their carefully camouflaged sniping spots. This meant that whenever a sniper was in the area, the location of the sniper could sometimes only be determined after the sniper had fired a few shots. The Allies also used their own snipers in the Pacific, notably the U.S. Marines, who used M1903 Springfield rifles.\nCommon sniper rifles used during the Second World War include: the Soviet M1891/30 Mosin\u2013Nagant and, to a lesser extent, the SVT-40; the German Mauser Karabiner 98k and Gewehr 43; the British Lee\u2013Enfield No. 4 and Pattern 1914 Enfield; the Japanese Arisaka 97; the American M1903A4 Springfield and M1C Garand. The Italians trained few snipers and supplied them with a scoped Carcano Model 1891.\nTraining.\nMilitary sniper training aims to teach a high degree of proficiency in camouflage and concealment, stalking, observation and map reading as well as precision marksmanship under various operational conditions. Trainees typically shoot thousands of rounds over a number of weeks, while learning these core skills.\nSnipers are trained to squeeze the trigger straight back with the ball of their finger, to avoid jerking the gun sideways. The most accurate position is prone, with a sandbag supporting the stock, and the stock's cheek-piece against the cheek. In the field, a bipod can be used instead. Sometimes a sling is wrapped around the weak arm (or both) to reduce stock movement. Some doctrines train a sniper to breathe deeply before shooting, then hold their lungs empty while they line up and take their shot. Other doctrines assert that exhausting the lungs results in an accelerated heart rate and suggest only a partial exhale before firing. Some go further, teaching their snipers to shoot between heartbeats to minimize barrel motion.\nAccuracy.\nThe key to sniping is considered to be accuracy, which applies to both the weapon and the shooter. The weapon should be able to consistently place shots within tight tolerances. The sniper in turn must use the weapon to accurately place shots under varying conditions.\nA sniper must have the ability to accurately estimate the various factors that influence a bullet's trajectory and point of impact, such as range to the target, wind direction, wind velocity, altitude and elevation of the sniper, and the target and ambient temperature. Mistakes in estimation compound over distance and can decrease lethality or cause a shot to miss completely.\nSnipers zero their weapons at a target range or in the field. This is the process of adjusting the scope so that the bullets' points-of-impact are at the point-of-aim (centre of scope or scope's cross-hairs) for a specific distance. A rifle and scope should retain its zero as long as possible under all conditions to reduce the need to re-zero during missions.\nA sandbag can serve as a useful platform for shooting a sniper rifle, although any soft surface such as a rucksack will steady a rifle and contribute to consistency. In particular, bipods help when firing from a prone position, and enable the firing position to be sustained for an extended period of time. Many police and military sniper rifles come equipped with an adjustable bipod. Makeshift bipods known as shooting sticks can be constructed from items such as tree branches or ski poles. Some military snipers use three-legged shooting sticks.\nU.S. military.\nServicemen volunteer for the rigorous sniper training and are accepted on the basis of their aptitude, physical ability, marksmanship, patience and mental stability. Military snipers may be further trained as forward air controllers (FACs) to direct air strikes or forward observers (FOs) to direct artillery or mortar fire.\nRussian Army.\nFrom 2011, the Russian armed forces have run newly developed sniper courses in military district training centres. In place of the Soviet practice of mainly squad sharpshooters, which were often designated during initial training (and of whom only few become snipers per se), these new army snipers are trained intensively for three months (for conscripts) or longer (for contract soldiers). The training program includes theory and practice of countersniper engagements, artillery spotting, and coordination of air support. The first instructors are the graduates of the Solnechnogorsk sniper training centre.\nThe method of sniper deployment, according to the Ministry of Defence, is likely to be one three-platoon company at the brigade level, with one of the platoons acting independently and the other two supporting the battalions as needed.\nTargeting, tactics, and techniques.\nRange finding.\nThe range to the target is measured or estimated as precisely as conditions permit and correct range estimation becomes absolutely critical at long ranges, because a bullet travels with a curved trajectory and the sniper must compensate for this by aiming higher at longer distances. If the exact distance is not known the sniper may compensate incorrectly and the bullet path may be too high or low. As an example, for a typical military sniping cartridge such as 7.62\u00d751mm NATO (.308 Winchester) M118 Special Ball round this difference (or \"drop\") from is . This means that if the sniper incorrectly estimated the distance as 700 meters when the target was in fact 800 meters away, the bullet will be 200 millimeters lower than expected by the time it reaches the target.\nLaser rangefinders may be used, and range estimation is often the job of both parties in a team. One useful method of range finding without a laser rangefinder is comparing the height of the target (or nearby objects) to their size on the mil dot scope, or taking a known distance and using some sort of measure (utility poles, fence posts) to determine the additional distance. The average human head is in width, average human shoulders are apart and the average distance from a person's pelvis to the top of their head is .\nTo determine the range to a target without a laser rangefinder, the sniper may use the mil dot reticle on a scope to accurately find the range. Mil dots are used like a slide rule to measure the height of a target, and if the height is known, the range can be as well. The height of the target (in yards) \u00d71000, divided by the height of the target (in mils), gives the range in yards; alternatively in metric the height of the target in centimeters \u00d710, divided by the height of the target in mils, gives the range in meters. It is important to note that angular mil (\"mil\") is only an approximation of a milliradian and different organizations use different approximations. This can vary as mil dot sizing and spacing changes. The USMC standard mil dot is sized at .25 mil based on a definition of 1 mil (that is, 1 milliradian) equals 3.438 MOA (minute of arc, or, equivalently, minute of angle) which is typically rounded off to 3.44 MOA for ease of use; this format facilitates estimating a target's height in inches and providing the resulting distance in yards. In comparison, the US Army standard mil dot is sized at .22 (often rounded to .2 for ease of use) mil based on a definition of 1 mil equals 3.6 MOA, which facilitates estimating a target's height in inches and providing the resulting distance in meters. \nAt longer ranges, bullet drop plays a significant role in targeting. The effect can be estimated from a chart, which may be memorized or taped to the rifle, although some scopes come with Bullet Drop Compensator (BDC) systems that only require the range be dialed in. These are tuned to both a specific class of rifle and specific ammunition. Every bullet type and load will have different ballistics. .308 Federal 175 grain (11.3 g) BTHP match shoots at . Zeroed at , a 16.2 MOA adjustment would have to be made to hit a target at . If the same bullet was shot with 168 grain (10.9 g), a 17.1 MOA adjustment would be necessary.\nShooting uphill or downhill is confusing for many because gravity does not act perpendicular to the direction the bullet is traveling. Thus, gravity must be divided into its component vectors. Only the fraction of gravity equal to the cosine of the angle of fire with respect to the horizon affects the rate of fall of the bullet, with the remainder adding or subtracting negligible velocity to the bullet along its trajectory. To find the correct zero, the sniper multiplies the actual distance to the range by this fraction and aims as if the target were that distance away. For example, a sniper who observes a target 500 meters away at a 45-degree angle downhill would multiply the range by the cosine of 45 degrees, which is 0.707. The resulting distance will be 353 meters. This number is equal to the horizontal distance to the target. All other values, such as windage, time-to-target, impact velocity, and energy will be calculated based on the actual range of 500 meters. Recently, a small device known as a cosine indicator has been developed. This device is clamped to the tubular body of the telescopic sight, and gives an indicative readout in numerical form as the rifle is aimed up or down at the target. This is translated into a figure used to compute the horizontal range to the target.\nWindage plays a significant role, with the effect increasing with wind speed or the distance of the shot. The slant of visible convections near the ground can be used to estimate crosswinds, and correct the point of aim. All adjustments for range, wind, and elevation can be performed by aiming off the target, called \"holding over\" or Kentucky windage. Alternatively, the scope can be adjusted so that the point of aim is changed to compensate for these factors, sometimes referred to as \"dialing in\". The shooter must remember to return the scope to zeroed position. Adjusting the scope allows for more accurate shots, because the cross-hairs can be aligned with the target more accurately, but the sniper must know exactly what differences the changes will have on the point-of-impact at each target range.\nFor moving targets, the point-of-aim is ahead of the target in the direction of movement. Known as \"leading\" the target, the amount of \"lead\" depends on the speed and angle of the target's movement as well as the distance to the target. For this technique, holding over is the preferred method. Anticipating the behavior of the target is necessary to accurately place the shot.\nHide sites and hiding techniques.\nThe term \"hide site\" refers to a covered and concealed position from which a sniper and his team can conduct surveillance or fire at targets. A good hide conceals and camouflages the sniper effectively, provides cover from enemy fire and allows a wide view of the surrounding area.\nThe main purpose of ghillie suits and hide sites is to break up the outline of a person with a rifle.\nMany snipers use ghillie suits to hide and stay hidden. Ghillie suits vary according to the terrain into which the sniper wishes to blend. For example, in dry grassland the sniper will typically wear a ghillie suit covered in dead grass.\nShot placement.\nShot placement, which is where on the body the sniper is aiming, varies with the type of sniper. Military snipers, who generally do not shoot at targets at less than , usually attempt body shots, aiming at the chest. These shots depend on tissue damage, organ trauma, and blood loss to kill the target. Body shots are used because the chest is a larger target.\nPolice snipers, who generally shoot at much shorter distances, may attempt a more precise shot at particular parts of body or particular devices: in one incident in 2007 in Marseille, a GIPN sniper took a shot from at the pistol of a police officer threatening to commit suicide, destroying the weapon and preventing the police officer from killing himself.\nIn high-risk or hostage situations where a suspect is threatening to imminently kill a hostage, police snipers may take head shots to ensure an instant kill. The snipers aim for the medulla oblongata to sever the spine from the brain. While this is believed to prevent the target from reflexively firing their weapon, there is evidence that any brain-hit is sufficient.\nTarget acquisition.\nSnipers are trained for the detection, identification, and location of a targeted soldier in sufficient detail to permit the effective employment of lethal and non-lethal means. Since most kills in modern warfare are by other crew-served weapons, reconnaissance is one of the most effective uses of snipers. They use their aerobic conditioning, infiltration skills and excellent long-distance observation equipment (optical scopes) and tactics to approach and observe the enemy. In this role, their rules of engagement typically let them shoot at high-value targets of opportunity, such as enemy officers.\nThe targets may be personnel or high-value materiel (military equipment and weapons) but most often they target the most important enemy personnel such as officers or specialists (e.g. communications operators) so as to cause maximum disruption to enemy operations. Other personnel they might target include those who pose an immediate threat to the sniper, like dog handlers, who are often employed in a search for snipers. A sniper identifies officers by their appearance and behavior such as symbols of rank, talking to radio operators, sitting as a passenger in a car, sitting in a car with a large radio antenna, having military servants, binoculars/map cases or talking and moving position more frequently. If possible, snipers shoot in descending order by rank, or if rank is unavailable, they shoot to disrupt communications.\nSome rifles, such as the Denel NTW-20 and Vidhwansak, are designed for a purely anti-materiel (AM) role, e.g. shooting turbine disks of parked aircraft, missile guidance packages, expensive optics, and the bearings, tubes or wave guides of radar sets. A sniper equipped with the correct rifle can target radar dishes, water containers, the engines of vehicles, and any number of other targets. Other rifles, such as the .50 caliber rifles produced by Barrett and McMillan, are not designed exclusively as AM rifles, but are often employed in such a way, providing the range and power needed for AM applications in a lightweight package compared to most traditional AM rifles. Other calibers, such as the .408 Cheyenne Tactical and the .338 Lapua Magnum, are designed to be capable of limited AM application, but are ideally suited as long range anti-personnel rounds.\nRelocating.\nOften in situations with multiple targets, snipers will use relocation. After firing a few shots from a certain position, snipers move unseen to another location before the enemy can determine where they are and mount a counter-attack. Snipers will frequently use this tactic to their advantage, creating an atmosphere of chaos and confusion. In other, rarer situations, relocation is used to eliminate the factor of wind.\nSound masking.\nAs sniper rifles are often extremely powerful and consequently very loud, it is common for snipers to use a technique known as sound masking. When employed by a highly skilled marksman, this tactic can be used as a substitute for a noise suppressor. In this technique, very loud sounds in the environment, such as artillery shells air bursting or claps of thunder, are used to mask the sound of the shot. This technique is frequently used in clandestine operations, infiltration tactics, and guerrilla warfare.\nPsychological warfare.\nDue to the surprise nature of sniper fire, high lethality of aimed shots and frustration at the inability to locate and counterattack snipers, sniper tactics have a significant negative effect on morale. Extensive use of sniper tactics can be used to induce constant stress and fear in opposing forces, making them afraid to move about or leave cover. In many ways, the psychological impact imposed by snipers is quite similar to those of landmines, booby-traps, and IEDs (constant threat, high \"per event\" lethality, inability to strike back).\nHistorically, captured snipers are often summarily executed. This happened during World War I and World War II; for example, the second Biscari Massacre was when 36 suspected snipers were lined up and executed on 14 July 1943.\nAs a result, if a sniper is in imminent danger of capture, he may discard any items (sniper rifle, laser rangefinder, etc.) which might indicate his status as a sniper. The risk of captured snipers being summarily executed is explicitly referred to in Chapter 6 of US Army doctrine document FM 3-060.11 entitled \"SNIPER AND COUNTERSNIPER TACTICS, TECHNIQUES, AND PROCEDURES\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Historically, units that suffered heavy and continual casualties from urban sniper fire and were frustrated by their inability to strike back effectively often have become enraged. Such units may overreact and violate the laws of land warfare concerning the treatment of captured snipers. This tendency is magnified if the unit has been under the intense stress of urban combat for an extended time. It is vital that commanders and leaders at all levels understand the law of land warfare and understand the psychological pressures of urban warfare. It requires strong leadership and great moral strength to prevent soldiers from releasing their anger and frustration on captured snipers or civilians suspected of sniping at them.\nThe negative reputation and perception of snipers can be traced back to the American Revolution, when American \"Marksmen\" intentionally targeted British officers, an act considered uncivilized by the British Army at the time (this reputation was cemented during the Battle of Saratoga, when Benedict Arnold allegedly ordered his marksmen to target British General Simon Fraser, an act that won the battle and French support). The British side used specially selected sharpshooters as well, often German Hessians.\nCounter-sniper tactics.\nThe occurrence of sniper warfare has led to the evolution of many counter-sniper tactics in modern military strategies. These aim to reduce the damage caused by a sniper to an army, which can often be harmful to both combat capabilities and morale.\nThe risk of damage to a chain of command can be reduced by removing or concealing features that would otherwise indicate an officer's rank. Modern armies tend to avoid saluting officers in the field, and eliminate rank insignia on battle dress uniforms. Officers can seek cover through mundane actions such as reading maps or using radios.\nFriendly snipers can be used to hunt the enemy sniper. Besides direct observation, defending forces can use other techniques. These include calculating the trajectory of a bullet by triangulation. Traditionally, triangulation of a sniper's position was done manually, though radar-based technology recently became available. Once located, the defenders can attempt to approach the sniper from cover and overwhelm them. The United States military is funding a project known as RedOwl (Robot Enhanced Detection Outpost With Lasers), which uses laser and acoustic sensors to determine the exact direction from which a sniper round has been fired.\nThe more rounds fired by a sniper, the greater the chance the target has of locating him. Thus, attempts to draw fire are often made, sometimes by offering a helmet slightly out of concealment, a tactic successfully employed in the Winter War by the Finns known as \"Kylm\u00e4-Kalle\" (Cold Charlie). They used a shop mannequin or other doll dressed as a tempting target, such as an officer. The doll was then presented as if it were a real man sloppily covering himself. Usually, Soviet snipers were unable to resist the temptation of an apparently easy kill. Once the angle where the bullet came from was determined, a large caliber gun, such as a Lahti L-39 \"Norsupyssy\" (\"Elephant rifle\") anti-tank rifle was fired at the sniper to kill him.\nOther tactics include directing artillery or mortar fire onto suspected sniper positions, the use of smoke screens, placing tripwire-operated munitions, mines, or other booby-traps near suspected sniper positions. Even dummy trip-wires can be placed to hamper sniper movement. If anti-personnel mines are unavailable, it is possible to improvise booby-traps by connecting trip-wires to hand grenades, smoke grenades or flares. Though these may not kill a sniper, they will reveal their location. Booby-trap devices can be placed near likely sniper hides, or along the probable routes to and from positions. Knowledge of sniper field-craft will assist in this task.\nThe use of canine units had been very successful, especially during the Vietnam War.\nIrregular and asymmetric warfare.\nThe use of sniping (in the sense of shooting at relatively long range from a concealed position) to murder came to public attention in a number of sensational U.S. criminal cases, including the Austin sniper incident of 1966 (Charles Whitman), the John F. Kennedy assassination (Lee Harvey Oswald), and the Beltway sniper attacks of late 2002 (Lee Boyd Malvo). However, these incidents usually do not involve the range or skill of military snipers; in all three cases the perpetrators had U.S. military training, but in other specialties. News reports will often (inaccurately) use the term sniper to describe anyone shooting with a rifle at another person.\nSniping has been used in asymmetric warfare situations, for example in the Northern Ireland Troubles, where in 1972, the bloodiest year of the conflict, the majority of the soldiers killed were shot by concealed IRA riflemen. There were some instances in the early 1990s of British soldiers and RUC personnel being shot with .50 caliber Barrett rifles by sniper teams collectively known as the South Armagh sniper.\nThe sniper is particularly suited to combat environments where one side is at a disadvantage. A careful sniping strategy can use a few individuals and resources to thwart the movement or other progress of a much better equipped or larger force. Sniping enables a few persons to instil terror in a much larger regular force \u2013 regardless of the size of the force the snipers are attached to. It is widely accepted that sniping, while effective in specific instances, is much more effective as a broadly deployed psychological attack or as a force-multiplier.\nWar in Iraq.\nIn 2003, the U.S.-led multinational coalition composed of primarily U.S. and UK troops occupied Iraq and attempted to establish a new government in the country. However, shortly after the initial invasion, violence against coalition forces and among various sectarian groups led to asymmetric warfare with the Iraqi insurgency and civil war between many Sunni and Shia Iraqis.\nThrough to November 2005 the Army had attributed 28 of 2,100 U.S. deaths to enemy snipers. In 2006, it was claimed that one insurgent sniper, \"Juba\", had shot up to 37 American soldiers.\nTraining materials obtained by U.S. intelligence had among its tips for shooting U.S. troops, \"Killing doctors and chaplains is suggested as a means of psychological warfare.\", suggesting that those casualties would demoralize entire units.\nArab Spring.\nSniper activity was reported during the Arab Spring civil unrest in Libya in 2011, both from anti-governmental and pro-governmental supporters, and in Syria at least from pro-government forces.\nNotable military marksmen and snipers.\nEven before firearms were available, soldiers such as archers were specially trained as elite marksmen.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "28124", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=28124", "title": "Stranglers/Golden Brown", "text": ""}
{"id": "28130", "revid": "23755636", "url": "https://en.wikipedia.org/wiki?curid=28130", "title": "Sign", "text": "Entity whose presence indicates the probable existence of something else\nA sign is an object, quality, event, or entity whose presence or occurrence indicates the probable presence or occurrence of something else. A natural sign bears a causal relation to its object\u2014for instance, thunder is a sign of storm, or medical symptoms a sign of disease. A conventional sign signifies by agreement, as a full stop signifies the end of a sentence; similarly the words and expressions of a language, as well as bodily gestures, can be regarded as signs, expressing particular meanings. The physical objects most commonly referred to as signs (notices, road signs, etc., collectively known as signage) generally inform or instruct using written text, symbols, pictures or a combination of these.\nThe philosophical study of signs and symbols is called semiotics; this includes the study of semiosis, which is the way in which signs (in the semiotic sense) operate.\nNature.\nSemiotics, epistemology, logic, and philosophy of language are concerned about the nature of signs, what they are and how they signify. The nature of signs and symbols and significations, their definition, elements, and types, is mainly established by Aristotle, Augustine, and Aquinas. According to these classic sources, significance is a relationship between two sorts of things: signs and the kinds of things they signify (intend, express or mean), where one term necessarily causes something else to come to the mind. Distinguishing natural signs and conventional signs, the traditional theory of signs (Augustine) sets the following threefold partition of things:\nall sorts of indications, evidences, symptoms, and physical signals, there are signs which are \"always\" signs (the entities of the mind as ideas and images, thoughts and feelings, constructs and intentions); and there are signs that \"have\" to get their signification (as linguistic entities and cultural symbols). So, while natural signs serve as the source of signification, the human mind is the agency through which signs signify naturally occurring things, such as objects, states, qualities, quantities, events, processes, or relationships. Human language and discourse, communication, philosophy, science, logic, mathematics, poetry, theology, and religion are only some of fields of human study and activity where grasping the nature of signs and symbols and patterns of signification may have a decisive value. Communication takes place without words but via the mind as a result of signs and symbols; They communicate/pass across/ messages to the human mind through their pictorial representation.\nTypes.\nThe word \"sign\" has a variety of meanings in English, including:\nChristianity.\nSt. Augustine was the first man who synthesized the classical and Hellenistic theories of signs. For him a sign is a thing which is used to signify other things and to make them come to mind (\"De Doctrina Christiana\" (hereafter DDC) 1.2.2; 2.1.1). The most common signs are spoken and written words (DDC 1.2.2; 2.3.4-2.4.5). Although God cannot be fully expressible, Augustine gave emphasis to the possibility of God's communication with humans by signs in Scripture (DDC 1.6.6). Augustine endorsed and developed the classical and Hellenistic theories of signs. Among the mainstream in the theories of signs, i.e., that of Aristotle and that of Stoics, the former theory filtered into the works of Cicero (106-43 BC, \"De inventione rhetorica\" 1.30.47-48) and Quintilian (circa 35\u2013100, \"Institutio Oratoria\" 5.9.9-10), which regarded the sign as an instrument of inference. In his commentary on Aristotle's \"De Interpretatione\", Ammonius said, \"according to the division of the philosopher Theophrastus, the relation of speech is twofold, first in regard to the audience, to which speech signifies something, and secondly in regard to the things about which the speaker intends to persuade the audience.\" If we match DDC with this division, the first part belongs to DDC Book IV and the second part to DDC Books I-III. Augustine, although influenced by these theories, advanced his own theological theory of signs, with whose help one can infer the mind of God from the events and words of Scripture. \nBooks II and III of DDC enumerate all kinds of signs and explain how to interpret them. Signs are divided into natural (\"naturalia\") and conventional (\"data\"); the latter is divided into animal (\"bestiae\") and human (\"homines\"); the latter is divided into non-words (\"cetera\") and words (\"verba\"); the latter is divided into spoken words (\"voces\") and written words (\"litterae\"); the latter is divided into unknown signs (\"signa ignota\") and ambiguous signs (\"signa ambigua\"); both the former and the latter are divided respectively into particular signs (\"signa propria\") and figurative signs (\"signa translata\"), among which the unknown figurative signs belong to the pagans.\nIn addition to exegetical knowledge (Quintilian, \"Institutio Oratoria\" 1.4.1-3 and 1.8.1-21) which follows the order of reading (\"lectio\"), textual criticism (\"emendatio\"), explanation (\"enarratio\"), and judgment (\"iudicium\"), one needs to know the original language (Hebrew and Greek) and broad background information on Scripture (DDC 2.9.14-2.40.60).\nAugustine's understanding of signs includes several hermeneutical presuppositions as important factors. First, the interpreter should proceed with humility, because only a humble person can grasp the truth of Scripture (DDC 2.41.62). Second, the interpreter must have a spirit of active inquiry and should not hesitate to learn and use pagan education for the purpose of leading to Christian learning, because all truth is God's truth (DDC 2.40.60-2.42.63). Third, the heart of interpreter should be founded, rooted, and built up in love which is the final goal of the entire Scriptures (DDC 2.42.63).\nThe sign does not function as its own goal, but its purpose lies in its role as a signification (\"res significans\", DDC 3.9.13). God gave signs as a means to reveal himself; Christians need to exercise hermeneutical principles in order to understand that divine revelation. Even if the Scriptural text is obscure, it has meaningful benefits. For the obscure text prevents us from falling into pride, triggers our intelligence (DDC 2.6.7), tempers our faith in the history of revelation (DDC 3.8.12), and refines our mind to be suitable to the holy mysteries (DDC 4.8.22). When interpreting signs, the literal meaning should first be sought, and then the figurative meaning (DDC 3.10.14-3.23.33). Augustine suggests the hermeneutical principle that the obscure Scriptural verse is interpreted with the help of plain and simple verses, which formed the doctrine of \"scriptura scripturae interpres\" (Scripture is the Interpreter of Scripture) in the Reformation Era. Moreover, he introduces the seven rules of Tyconius the Donatist to interpret the obscure meaning of the Bible, which demonstrates his understanding that all truth belongs to God (DDC 3.3.42-3.37.56). In order to apply Augustine's hermeneutics of the sign appropriately in modern times, every division of theology must be involved and interdisciplinary approaches must be taken.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28131", "revid": "18872885", "url": "https://en.wikipedia.org/wiki?curid=28131", "title": "Lepsius Standard Alphabet", "text": "Latin-script transcription alphabet\nThe Lepsius Standard Alphabet is a Latin-script alphabet developed by Karl Richard Lepsius. Lepsius initially used it to transcribe Egyptian hieroglyphs in his \"Denkm\u00e4ler aus \u00c4gypten und \u00c4thiopien\", and extended it to write African languages, published in 1853, 1854 and 1855, and in a revised edition in 1863. The alphabet was comprehensive but was not used much as it contained many diacritic marks and was difficult to read and typeset at that time. It was, however, influential in later projects such as Ellis's Paleotype, and diacritics such as the acute accent for palatalization, under-dot for retroflex, underline for Arabic emphatics, and his click letters continue in modern use.\nVowels.\nVowel length is indicated by a macron (\"\u0101\") or a breve (\"\u0103\") for long and short vowels, respectively. Open vowels are marked by a line under the letter (\"e\u0331\"), while a dot below the letter makes it a close vowel (\"\u1eb9\"). Rounded front vowels are written with an umlaut (\"\u00f6\" and \"\u00fc\" ), generally above, but below when the space above the letter is needed for vowel length marks (thus \"\u1e73\u0304\" or \"\u1e73\u0306\"). Unrounded back vowels are indicated by a 'hook' (ogonek) on \"\u0119\" or \"\u012f\". Central vowels may be written as one of these series, or as reduced vowels.\nAs in the International Phonetic Alphabet, nasal vowels get a tilde (\"\u00e3\").\nA small circle below a letter is used to mark both the schwa (\"e\u0325\", also \"\u1e01\" etc. for other reduced vowels) and syllabic consonants (\"r\u0325\" or \"l\u0325\", for instance).\nDiphthongs do not receive any special marking, they are simply juxtaposed (\"ai\" ). A short sign can be used to distinguish which element of the diphthong is the on- or off-glide (\"u\u012d, \u016di\"). Vowels in hiatus can be indicated with a diaeresis when necessary (\"a\u00ef\" ).\nOther vowels are \"a\" with a subscript \"e\" for ; \"a\" with a subscript \"o\" for , and \"o\u0329\" for or maybe . The English syllabic is \"\u1e59\u0325\".\nWord stress is marked with an acute accent on a long vowel (\"\u00e1\") and with a grave accent on a short vowel (\"\u00e0\").\nKlemp (p.\u00a056*\u201358*) interprets the values of Lepsius's vowels as follows:\nConsonants.\nThe Lepsius letters without predictable diacritics are as follows:\nOther consonant sounds may be derived from these. For example, palatal and palatalized consonants are marked with an acute accent: \"\u1e31\" , \"\u01f5\" , \"\u0144\" , \"\u03c7\u0301\" , \"\u0161\u0301\" , \"\u03b3\u0301\" , \"\u017e\u0301\" , \"\u013a\" , \"\u2018\u013a\" , \"\u0131\u0301\" , \"\u1e55\" , etc. These can also be written \"ky, py\" etc.\nLabialized velars are written with an overdot: \"\u0121\" , etc. (A dot on a non-velar letter, as in \"\u1e45\" and \"\u1e59\" in the table above, indicates a guttural articulation.)\nRetroflex consonants are marked with an underdot: \"\u1e6d\" , \"\u1e0d\" , \"\u1e47\" , \"\u1e63\u030c\" , \"\u1e93\u030c\" , \"\u1e5b\" , \"\u1e37\" , and \"\u0131\u0323\" .\nThe Semitic \"emphatic\" consonants are marked with an underline: \"\u1e6f\" , \"\u1e0f\" , \"s\u0331\" , \"\u1e95\" , \"\u03b4\u0331\" , \"\u1e3b\" .\nAspiration is typically marked by \"h\": \"kh\" , but a turned apostrophe (Greek \"spiritus asper\") is also used: \"k\u0312\" , \"\u0123\" . Either convention may be used for voiceless sonorants: \"m\u0312\" , \"\u2018l\" .\nAffricates are generally written as sequences, e.g. \"t\u0161\" for . But the single letters \"\u010d\" , \"\u01f0\" , \"c\u0300\" , \"j\u0300\" , \"\u021b\" , and \"d\u0326\" are also used.\nImplosives are written with a macron: \"b\u0304\" , \"d\u0304\" , \"j\u0304\" , \"\u1e21\" . As with vowels, long (geminate) consonants may also be written with a macron, so this transcription can be ambiguous.\nLepsius typically characterized ejective consonants as tenuis, as they are completely unaspirated, and wrote them with the Greek \"spiritus lenis\" (\"p\u2019\", \"t\u2019\", etc.), which may be the source of the modern convention for ejectives in the IPA. However, when his sources made it clear that there was some activity in the throat, he transcribed them as emphatics.\nWhen transcribing consonant letters which are pronounced the same but are etymologically distinct, as in Armenian, diacritics from the original alphabet or roman transliteration may be carried over. Similarly, unique sounds such as Czech \"\u0159\" may be carried over into Lepsius transcription. Lepsius used a diacritic \"r\" under \"t\u1dca\" and \"d\u1dca\" for some poorly-described sounds in Dravidian languages.\nStandard capitalization is used. For example, when written in all caps, \"\u03b3\" becomes \"\u0393\" (as in \"AF\u0393AN\" \"Afghan\").\nTones.\nTones are marked with acute accents and grave accents (backticks) to the right and near the top or the bottom of the corresponding vowel. The diacritic may be underlined for a lower pitch, distinguishing eight possible tones in all.\nTone is not written directly, but rather needs to be established separately for each language. For example, the acute accent may indicate a high tone, a rising tone, or, in the case of Chinese, any tone called \"rising\" (\u4e0a) for historical reasons.\nLow rising and falling tones can be distinguished from high rising and falling tones by underlining the accent mark: \u27e8ma\u00b4\u0320, ma`\u0320\u27e9. The underline also transcribes the Chinese \"yin\" tones, under the mistaken impression that these tones are actually lower. Two additional tone marks, without any defined phonetic value, are used for Chinese: \"level\" ma\u02cf (\u5e73) and checked ma\u02ce (\u5165); these may also be underlined.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28132", "revid": "41273739", "url": "https://en.wikipedia.org/wiki?curid=28132", "title": "Sidehill gouger", "text": "Mythical creature from American folklore\nIn American folklore, a Sidehill gouger is a fearsome critter adapted to living on hillsides by having legs on one side of their body shorter than the legs on the opposite side, having evolved to resemble any form of mammals such as pangolins, goats, humans, and bears. This peculiarity allows them to walk on steep hillsides, although only in one direction; when lured or chased into the plain, they are trapped in an endless circular path. Some claim these creatures play a large role in, and in some cases are responsible for, the creation of hoodoos. The creature is variously known as the Sidehill Dodger Sidehill Hoofer, or Side-hill Gazink.\nSidehill gougers are mammals who dwell in hillside burrows, and are occasionally depicted as laying eggs. There are usually 6 to 8 pups to a litter. Since the gouger is footed for hillsides, it cannot stand up on level ground. If by accident a gouger falls from a hill, it can easily be captured or starve to death. When a clockwise gouger meets a counter-clockwise gouger, they have to fight to the death since they can only go in one direction. The formation of terracettes has been attributed to gouger activity.\nGougers are said to have migrated to the west from New England, a feat accomplished by a pair of gougers who clung to each other in a fashion comparable to \"a pair of drunks going home from town with their longer legs on the outer sides\". \nA Vermont variation is known as the Wampahoofus. It was reported that farmers crossbreed them with their cows so they could graze easily on mountain sides. Others claim that a pair of Wampahoofus circle the summit of Mount Mansfield, mating as their paths cross.\nFrank C. Whitmore and Nicholas Hotton, in their joint tongue-in-cheek response to an article in \"Smithsonian Magazine\", expounded the taxonomy of sidehill gougers (\"Membriinequales declivitous\"), noting in particular \"the sidehill dodger, which inhabits the Driftless Area of Wisconsin; the dextrosinistral limb ratio approaches unity although the metapodials on the downhill side are noticeably stouter.\" A special award, the Order of the Sidehill Gouger, is awarded to worthy members for hard and long standing volunteer efforts by the Alberta Group of the Royal Canadian Air Force Association.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28133", "revid": "49739718", "url": "https://en.wikipedia.org/wiki?curid=28133", "title": "Strike", "text": "Strike may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "28134", "revid": "50863892", "url": "https://en.wikipedia.org/wiki?curid=28134", "title": "Second Vatican Council", "text": "Catholic ecumenical council (1962\u20131965)\nThe Second Ecumenical Council of the Vatican, commonly known as the Second Vatican Council or Vatican II, was the 21st and most recent ecumenical council of the Catholic Church. The council met each autumn from 1962 to 1965 in St. Peter's Basilica in Vatican City for sessions of 8 and 12 weeks. \nPope John XXIII convened the council because he felt the Church needed \"updating\" (). He believed that to better connect with people in an increasingly secularized world, some of the Church's practices needed to be improved and presented in a more understandable and relevant way. \nSupport for won out over resistance to change, and as a result 16 magisterial documents were produced by the council, including four \"constitutions\":\nOther decrees and declarations included:\nThe documents proposed a wide variety of changes to doctrine and practice that would change the life of the Church. Some of the most notable were in performance of the Mass, including that vernacular languages could be authorized as well as Latin.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nBackground.\nBiblical movement.\nPope Pius XII's 1943 encyclical gave a renewed impetus to Catholic Bible studies and encouraged the production of new Bible translations from the original languages. This led to a pastoral attempt to get ordinary Catholics to re-discover the Bible, to read it and to make it a source of their spiritual life. This found a response in very limited circles. By 1960, the movement was still progressing slowly.\nand.\nBy the 1930s, mainstream theology based on neo-scholasticism and papal encyclicals was being rejected by some theologians as dry and uninspiring. Thus was the movement, called , the return to the sources: basing theology directly on the Bible and the Church Fathers. Some theologians also began to discuss new topics, such as the history of theology, the theology of work, ecumenism, the theology of the laity, and the theology of \"earthly realities\".\nThe writings, whose new style came to be called ('the new theology'), attracted Rome's attention, and in 1950 Pius XII published , an encyclical \"concerning some false opinions threatening to undermine the foundations of Catholic doctrine\". Without citing specific people, he criticized those who advocated new schools of theology. It was generally understood that the encyclical was directly against the as well as developments in ecumenism and Bible studies. Some works were placed on the Index of Prohibited Books, and some of the authors were forbidden to teach or to publish. Those who suffered most were Henri de Lubac and Yves Congar , who were unable to teach or publish until the death of Pius XII in 1958. By the early 1960s, other theologians under suspicion included Karl Rahner and the young Hans K\u00fcng.\nIn addition, there was the unfinished business of the First Vatican Council (1869\u201370). When it had been cut short by the Italian Army's entry into Rome at the end of Italian unification, the only topics that had been completed were the theology of the papacy and the relationship of faith and reason, while the theology of the episcopate and of the laity were left unaddressed. The task of the Second Vatican Council in continuing and completing the work of the first was noted by Pope Paul VI in his encyclical letter (1964).\nAt the same time, the world's bishops were challenged by political, social, economic, and technological change. Some of those bishops were seeking new ways of addressing those challenges.\nBeginnings.\nAnnouncement and expectations.\nPope John XXIII gave notice of his intention to convene a diocesan synod for Rome and an ecumenical council for the universal church on 25 January 1959, less than three months after his election in October 1958. His announcement, in the chapter hall of the Benedictine monastery attached to the Basilica of Saint Paul Outside the Walls in Rome, came as a surprise to the cardinals present.\nHe had tested the idea only ten days before with one of them, his Cardinal Secretary of State Domenico Tardini, who gave enthusiastic support to the idea. Although the pope later said the idea came to him in a flash in his conversation with Tardini, two cardinals had earlier attempted to interest him in the idea. They were two of the most conservative, Ernesto Ruffini and Alfredo Ottaviani, who had already in 1948 proposed the idea to Pius XII and who put it before John XXIII on 27 October 1958.\nOver the next 3 years, the Pope would make many statements describing the results he expected from the council. They formed something like 3 concentric circles:\nTwo less solemn statements are attributed to John XXIII about the purpose of the council. One is about opening the windows of the Church to let in some fresh air; the other about shaking off the imperial dust accumulated on the throne of St. Peter. The source for the second statement is Cardinal L\u00e9ger of Montr\u00e9al, as reported by Congar. The first statement has been repeated so many times as to be extremely difficult to verify.\nOnce the officials of the Curia had recovered from their shock at the Pope's announcement of a Council, they realized that it could be the culmination of the Church's program of resistance to Protestantism, the Enlightenment and all the other perceived errors of the modern world. It was also seen as an opportunity to give the stamp of conciliar infallibility to the teachings of the most recent popes and to the Curia's vision of the role of the Church in the modern world, provided the Pope could be convinced to forget about .\nOn the other side were those theologians and bishops who had been working towards a new way of doing things, some of whom had been silenced and humiliated by the Curia in the 1940s and 1950s. For them, the council came as a \"divine surprise\", the opportunity to convince the bishops of the world to turn away from a fortress-like defensive attitude to the modern world and set off in a new direction towards a renewed theology of the Church and of the laity, ecumenism and the reform of the liturgy.\nThe council was officially summoned by the apostolic constitution on 25 December 1961.\nPreparation.\nPreparation for the council took over three years, from the summer of 1959 to the autumn of 1962.\nThe first year was known officially as the \"antepreparatory period\". On 17 May 1959, Pope John appointed an Antepreparatory Commission to conduct a vast consultation of the Catholic world concerning topics to be examined at the council. Three groups of people were consulted: the bishops of the world, the Catholic universities and faculties of theology, and the departments of the Curia. By the following summer, 2,049 individuals and institutions had replied with 9,438 individual \"vota\" (\"wishes\"). Some were typical of past ways of doing things, asking for new dogmatic definitions or condemnations of errors. Others were in the spirit of \"aggiornamento\", asking for reforms and new ways of doing things.\nThe next two years (known officially as the \"preparatory period\") were occupied with preparing the drafts, called \"schemas\", that would be submitted to the bishops for discussion at the council. On 5 June 1960, ten Preparatory Commissions were created, to which a total of 871 bishops and experts were appointed. Each preparatory commission had the same area of responsibility as one of the main departments of the Curia and was chaired by the cardinal who headed that department. From the 9,438 proposals, a list of topics was created, and these topics were parcelled out to these commissions according to their area of competence.\nSome commissions prepared a separate schema for each topic they were asked to treat, others a single schema encompassing all the topics they were handed. These were the preparatory commissions and the number of schemas they prepared:\nTwo secretariats \u2013 one the offshoot of an existing Vatican office, the other a new body \u2013 also had a part in drafting schemas:\nThe total number of schemas was 70. As most of these preparatory bodies were predominantly conservative, the schemas they produced showed only modest signs of updating. The schemas drafted by the preparatory commission for theology, dominated by officials of the Holy Office (the curial department for theological orthodoxy) showed no signs of \"aggiornamento\" at all. The two notable exceptions were the preparatory commission for liturgy and the Secretariat for Christian unity, whose schemas were very much in the spirit of renewal.\nIn addition to these specialist commissions and secretariats, there was a Central Preparatory Commission, to which all the schemas had to be submitted for final approval. It was a large body of 108 members from 57 countries, including two thirds of the cardinals. As a result of its work, 22 schemas were eliminated from the conciliar agenda, mainly because they could be dealt with during a planned revision of the 1917 \"Code of Canon Law\" after the council, and a number of schemas were consolidated and merged, with the result that the total number of schemas was whittled down from 70 to 22.\nOrganization.\nParagraph numbers in this section refer to the Council Regulations published in the motu proprio \"Appropinquante concilio\" of 6 August 1962.\nCouncil Fathers (\u00a71). All the bishops of the world, as well as the heads of the main religious orders of men, were entitled to be \"Council Fathers\", that is, full participants with the right to speak and vote. Their number was about 2,900, though some 500 of them would be unable to attend, either for reasons of health or old age, or because the Communist authorities of their country would not let them travel. The Council Fathers in attendance represented 79 countries: 38% were from Europe, 31% from the Americas, 20% from Asia &amp; Oceania, and 10% from Africa. (At Vatican I a century earlier there were 737 Council Fathers, mostly from Europe). At Vatican II, some 250 bishops were native-born Asians and Africans, whereas at Vatican I, there were none at all.\nGeneral Congregations (\u00a73, 20, 33, 38\u201339, 52\u201363). The Council Fathers met in daily sittings \u2013 known as General Congregations \u2013 to discuss the schemas and vote on them. These sittings took place in St. Peter's Basilica every morning until 12:30 Monday to Saturday (except Thursday). The average daily attendance was about 2,200. Stands with tiers of seats for all the Council Fathers had been built on both sides of the central nave of St. Peter's. During the first session, a council of presidents, of 10 cardinals, was responsible for presiding over the general assemblies, its members taking turns chairing each day's sitting (\u00a74). During the later sessions, this task belonged to a council of 4 Moderators.\nAll votes required a two-thirds majority. For each schema, after a preliminary discussion there was a vote whether it was considered acceptable in principle, or rejected. If acceptable, debate continued with votes on individual chapters and paragraphs. Bishops could submit amendments, which were then written into the schema if they were requested by many bishops. Votes continued in this way until wide agreement was reached, after which there was a final vote on a document. This was followed some days later by a public session where the Pope promulgated the document as the official teaching of the council, following another, ceremonial, vote of the Council Fathers. There was an unwritten rule that, in order to be considered official Church teaching, a document had to receive an overwhelming majority of votes, somewhere in the area of 90%. This led to many compromises, as well as formulations that were broad enough to be acceptable by people on either side of an issue.\nAll General Congregations were closed to the public. Council Fathers were under an obligation not to reveal anything that went on in the daily sittings (\u00a726). Secrecy soon broke down, and much information about the daily General Congregations was leaked to the press.\nThe Pope did not attend General Congregations, but followed the deliberations on closed-circuit television.\nPublic Sessions (\u00a72, 44\u201351). These were similar to General Congregations, except that they were open to the press and television, and the Pope was present. There were 10 public sessions in the course of the council: the opening day of each of the council's four periods, 5 days when the Pope promulgated Council documents, and the final day of the council.\nCommissions (\u00a75\u20136, 64\u201370). Much of the detailed work of the council was done in these commissions. Like the preparatory commissions during the preparatory period, they were 10 in number, each covering the same area of Church life as a particular curial department and chaired by the cardinal who headed that department: \nEach commission included 25 Council Fathers (16 elected by the council and 9 appointed by the Pope) as well as consultors (official \"periti\" appointed by the pope). In addition, the Secretariat for Promoting Christian Unity, appointed during the preparatory period, continued to exist under its president Cardinal Augustin Bea throughout the 4 years of the council, with the same powers as a commission. The commissions were tasked with revising the schemas as Council Fathers submitted amendments. They met in the afternoons or evenings. Procedure was more informal than in the general assemblies: there was spontaneous debate, sometimes heated, and Latin was not the only language used. Like the General Congregations, they were closed to the public and subject to the same rules of secrecy.\nOfficial \"Periti\" (\u00a79\u201310). These experts in theology, canon law and other areas were appointed by the Pope to advise the Council Fathers, and were assigned as consultors to the commissions, where they were an important part in re-writing the council documents. At the beginning of the council, there were 224 official \"periti,\" but their number would eventually rise to 480. They could attend the debates in the General Congregations, but could not speak. The theologians who had been silenced during the 1940s and 1950s, such as Yves Congar and Henri de Lubac, and some theologians who were under suspicion in Roman circles at the beginning of the 1960s, such as Karl Rahner and Hans K\u00fcng, were appointed \"periti\" because of their expertise. Their appointment served to vindicate their ideas and gave them a platform from which they could work to further their views.\nPrivate \"Periti\" (\u00a711). Each bishop was allowed to bring along a personal theological adviser of his choice. Known as \"private \"periti\"\", they were not official Council participants and could not attend General Congregations or commission meetings. But like the official \"periti\", they gave informal teachings to groups of bishops, bringing them up to date on developments in their particular area of expertise. Karl Rahner, Joseph Ratzinger and Hans K\u00fcng first went to the council as some bishop's personal theologian, and were later appointed official \"periti\". Some notable theologians, such as Edward Schillebeeckx, remained private \"periti\" for the whole duration of the council.\nObservers (\u00a718) . An important innovation was the invitation by Pope John to Orthodox and Protestant Churches to send observers to the council. Eventually 21 denominations or bodies such as the World Council of Churches were represented. The observers were entitled to sit in on all general assemblies (but not the commissions) and they mingled with the Council Fathers during the breaks and let them know their reactions to speeches or to schemas. Pope Paul VI welcomed their participation \"with gratitude and respect\". Their presence helped to break down centuries of mistrust.\nLay auditors. While not provided for in the Official Regulations, a small number of lay people were invited to attend as \"auditors\" beginning with the Second Session. While not allowed to take part in debate, a few of them were asked to address the council about their concerns as lay people. The first auditors were all male, but beginning with the third session, a number of women were also appointed.\nMain caucuses.\nIn the very first weeks of the council proceedings, it became clear to the participants that there were two \"tendencies\" among the Council Fathers, those who were supporters of \"aggiornamento\" and renewal, and those who were not. The two tendencies had already appeared in the deliberations of the Central Preparatory Commission before the opening of the council.\nIn addition to popes John XXIII and Paul VI, these were the prominent contributors at the council:\nProminent Conservative Bishops at the Council\nProminent Reformist Bishops at the Council\nProminent reformist theologians at the Council\nChronology of the council.\nThe council was opened on 11 October 1962 by Pope John XXIII with his opening address Gaudet Mater Ecclesia (\"Mother Church Rejoices\") at St. Peter's Basilica. The next few days, from 13 October to 16 October, saw the election of the members of the 10 conciliar commissions, with candidates being drawn from national groups. The first schema was discussed on 22 October, involving liturgy, and debate lasted for 15 days before being accepted in principle and returned to the commission. The schema on revelation was debated for six days before being put to a vote on 20 November, where 62% of the participants voted to reject the schema, yet this was short of the two-thirds majority needed. The schema was resolved on the next day when Pope John announced that it would undergo revision by a special joint commission representing the conservative and renewal tendencies. The schema on the modern means of communication was accepted in principle on 27 November, and was returned to the commission to only pertain to essential principles. The schema on unity with the Eastern Orthodox, one of three that were on ecumenism, was ordered to be merged with two other documents on Christian unity by the Council Fathers. Discussion of the schema on the church began on 1 December, with only a week left before the end of the scheduled first session, but on the day before the scheduled vote on acceptance in principle, Pope John appointed a special commission to rewrite the schemas to more closely resemble his outlined vision from his opening address. With only 5 of the 22 schemas having been reviewed up to this point, the first period of the council ended on 8 December.\nDocuments of the council.\nVatican II's teaching is contained in sixteen documents: 4 constitutions, 9 decrees and 3 declarations. While the constitutions are clearly the documents of the highest importance, \"the distinction between decrees and declarations, no matter what it originally meant, has become meaningless\".\nFor each document, approval of the final text was followed a few days later by the pope's promulgation of the document as the Church's official teaching. On the day of promulgation, there was a second vote of approval by the Council Fathers: it was \"basically ceremonial\" since the document's final text had already been approved a few days earlier. It is this earlier vote that best indicates the degree of support for, or opposition to, the document. Most documents were approved by overwhelming margins. In only 6 cases were the negative votes in the triple digits. In 3 of these cases (Church and Modern World, Non-Christian Religions and Religious Freedom), 10% to 12% of the Fathers rejected the document on theological grounds. In 2 other cases (Media and Christian Education), the negative votes mostly expressed disappointment in a bland text, rather than opposition.\nMuch of the documents' theology, particularly on the development of doctrine, was influenced by the work of St. John Henry Newman causing Pope Paul VI to call Vatican II, \"Newman's Council\". \nConstitution on the Sacred Liturgy.\n\"Sacrosanctum Concilium\", the Constitution on the Sacred Liturgy, was the blueprint for an extensive reform of the Western liturgy.\nChapter 1 of the Constitution set out principles to guide this reform:\nChapter 2: Mass. The Eucharist is both the sacrifice of Christ's body and blood and a paschal banquet (SC 47). In addition to repeating the need for active participation (SC 47), simplification of the rites (SC 50) and a greater variety of Scripture readings (SC 51), the chapter decrees that certain practices that had disappeared, such as the prayer of the faithful (SC 53), concelebration (SC 57), and communion under both kinds for the laity (SC 55), are to be restored under certain conditions, and that the homily should be a commentary on the Scripture readings (SC 52).\nChapter 3: Sacraments. The rite of each sacrament is to be simplified in order to make its meaning clear (SC 62); the catechumenate is to be restored for adult baptism (SC 64); the link between confirmation and baptism is to be made clear (SC 71); the sacrament then called extreme unction is to become a sacrament for those who are seriously ill (anointing of the sick) and not just of those who are on the point of death (SC 73-5); funerals are to focus on the hope of the resurrection and not on mourning (SC 81), and local cultural practices may be included in the celebration of some sacraments such as weddings (SC 63).\nChapters 4 to 7 provide that the divine office (now called Liturgy of the Hours) is to be adapted to modern conditions by reducing its length for those in active ministry (SC 97), that the calendar is to be revised to give Sunday and the mysteries of Christ priority over saints' days (SC 108), and that, while traditional music forms such as Gregorian chant (SC 116) and organ music (SC 120) are to be preserved, congregational singing is to be encouraged (SC 114) and the use of other instruments is permissible (SC 120).\nThe Constitution on the Sacred Liturgy launched the most extensive revision of the liturgy in the history of the Church.\nThe invitation for more active, conscious participation of the laity through Mass in the vernacular did not stop with the constitution on the liturgy. It was taken up by the later documents of the council that called for a more active participation of the laity in the life of the Church. Pope Francis referred to a turn away from clericalism toward a new age of the laity.\nDogmatic Constitution on the Church.\nThe Dogmatic Constitution on the Church ('Light of the Nations') gave direction to several of the documents that followed it, including those on Ecumenism, on Non-Christian Religions, on Religious Freedom, and on The Church in the Modern World (see below). According to Paul VI, \"the most characteristic and ultimate purpose of the teachings of the Council\" is the universal call to holiness. John Paul II calls this \"an intrinsic and essential aspect of [the council Fathers'] teaching on the Church\", where \"all the faithful of Christ of whatever rank or status, are called to the fullness of the Christian life and to the perfection of charity\" (\"Lumen gentium\", 40). Francis, in his apostolic letter \"Evangelii Gaudium\" (17) which laid out the programmatic for his pontificate, said that \"on the basis of the teaching of the Dogmatic Constitution \"Lumen Gentium\"\" he would discuss the entire People of God which evangelizes, missionary outreach, the inclusion of the poor in society, and peace and dialogue within society. Francis has also followed the call of the council for a more collegial style of leadership, through synods of bishops and through his personal use of a worldwide advisory council of eight cardinals. A most contentious conclusion that seems to follow from the Bishops' teaching in the decree is that while \"in some sense other Christian communities are institutionally defective,\" these communities can \"in some cases be more effective as vehicles of grace.\" Belgian Bishop Emil de Smedt, commenting on institutional defects that had crept into the Catholic church, \"contrasted the hierarchical model of the church that embodied the triad of 'clericalism, legalism, and triumphalism' with one that emphasized the 'people of God', filled with the gifts of the Holy Spirit and radically equal in grace,\" that was extolled in \"Lumen Gentium\".\nDogmatic Constitution on Divine Revelation.\nThe council's document \"Dei Verbum\" (\"The Word of God\") states the principle active in the other council documents that \"The study of the sacred page is, as it were, the soul of sacred theology\". It is said of \"Dei Verbum\" that \"arguably it is the most seminal of all the conciliar documents,\" with the fruits of a return to the Bible as the foundation of Christian life and teaching, evident in the other council documents. Joseph Ratzinger, who would become Benedict XVI, said of the emphasis on the Bible in the council that prior to Vatican II the theology manuals continued to confuse \"propositions about revelation with the content of revelation. It represented not abiding truths of faith, but rather the peculiar characteristics of post-Reformation polemic.\" In spite of the guarded approval of biblical scholarship under Pius XII, scholars suspected of Modernism were silenced right up to Vatican II. The council brought a definitive end to the Counter-Reformation and, in a spirit of \"aggiornamento\", reached back \"behind St. Thomas himself and the Fathers, to the biblical theology which governs the first two chapters of the Constitution on the Church.\" \"The documents of the Second Vatican Council are shot through with the language of the Bible. ...The church's historical journey away from its earlier focus upon these sources was reversed at Vatican II.\" For instance, the council's document on the liturgy called for a broader use of liturgical texts, which would now be in the vernacular, along with more enlightened preaching on the Bible explaining \"the love affair between God and humankind\". The translation of liturgical texts into vernacular languages, the allowance of communion under both kinds for the laity, and the expansion of Scripture readings during the Mass was resonant with the sensibilities of other Christian denominations, thus making the Second Vatican Council \"a milestone for Catholic, Protestants, [and] the Orthodox\".\nPastoral Constitution on the Church in the Modern World.\nThis document, named for its first words \"Gaudium et Spes\" (\"Joy and Hope\"), built on \"Lumen Gentium\"'s understanding of the Church as the \"pilgrim people of God\" and as \"communion\", aware of the long history of the Church's teaching and in touch with what it calls the \"signs of the times\". It reflects the understanding that Baptism confers on all the task that Jesus entrusted to the Church, to be on mission to the world in ways that the present age can understand, in cooperation with the ongoing work of the Spirit.\nDecrees and declarations on the Church as People of God.\nThese seven documents apply the teaching contained in the Constitution on the Church to the various categories of people in the Church \u2013 bishops, priests, religious, laity, Eastern Catholics \u2013 and to Christian education.\nThe Pastoral Office of Bishops \u2013 The decree \"Christus Dominus\" (\"Christ the Lord\", 1965) deals with practical matters concerning bishops and dioceses, on the basis of the theology of the episcopate found in chapter 3 of \"Lumen gentium\", including collegiality. It deals with the three levels where a bishop exercises his ministry: the universal Church, his own diocese and the national or regional level.\nThe Ministry and Life of Priests \u2013 The decree \"Presbyterorum ordinis\" (\"The order of priests\", 1965) describes priests as \"father and teacher\" but also \"brothers among brothers with all those who have been reborn at the baptismal font.\" Priests must \"promote the dignity\" of the laity, \"willingly listen\" to them, acknowledge and diligently foster \"exalted charisms of the laity\", and \"entrust to the laity duties in the service of the Church, allowing them freedom and room for action.\" Also, the human and spiritual needs of priests are discussed in detail.\nPriestly Training \u2013 The decree \"Optatam totius\" (\"Desired [renewal] of the whole [Church]\", 1965) seeks to adapt the training of priests to modern conditions. While some of the points made in the decree are quite traditional, such as the insistence that seminaries remain the main place for priestly training, there are interesting proposals for adaptation to new conditions. The first is that instead of having the program of formation set for the whole Catholic world by the Congregation for Seminaries and Universities in Rome, the bishops of each country may devise a program that is adapted to the needs of their particular country (though it still needs Rome's approval). Another is that training for the priesthood has to integrate three dimensions: spiritual, intellectual and pastoral.\nSpiritual formation aims to produce a mature minister, and to this end may call on the resources of psychology. There are many proposals for improving intellectual formation: the use of modern teaching methods; a better integration of philosophy and theology; the centrality of Scripture in theological studies; knowledge of other religions. Pastoral formation should be present throughout the course of studies and should include practical experience of ministry. Finally, there should be ongoing formation after ordination.\nThe Adaptation and Renewal of Religious Life \u2013 The decree \"Perfectae Caritatis\" (\"Of perfect charity\", 1965) deals with the adaptation of religious life to modern conditions. The decree presupposes the theology of the religious life found in chapter 6 of the Constitution on the Church (\"Lumen Gentium\"), to which it adds guidelines for renewal. The two basic principles that should guide this renewal are: \"the constant return [...] to the original spirit of the institutes and their adaptation to the changed conditions of our time\" (PC 2). The decree deals mainly with religious orders, also known as religious institutes (whose members take vows and live a communal life), but touches also societies of common life (whose members take no vows but live a communal life) and secular institutes (whose members take vows but do not share a communal life).\nThe decree restates well-known views on the religious life, such as the consecrated life as a life of following Christ, the importance of the three vows of poverty, chastity and obedience, and the importance of charity in the life of an order. To these it adds a call for every order, whether contemplative or active, to renew itself, as well as specific proposals for adaptation to new conditions, such as the simplification of the religious habit, the importance of education for members of all religious orders (and not just priests), and the need for poverty not just for individual members but for each order as a whole.\nThe Apostolate of the Laity \u2013 The decree \"Apostolicam actuositatem\" (\"Apostolic Activity\", 1965) declares that the apostolate of the laity is \"not only to bring the message and grace of Christ to men but also to penetrate and perfect the temporal order with the spirit of the Gospel\", in every field of life, together or through various groups, with respectful cooperation with the Church's hierarchy.\nThe Eastern Catholic Churches \u2013 The decree \"Orientalium Ecclesiarum\" (\"Of the Eastern Churches\", 1964) deals with the Eastern Catholic Churches, those communities that are in full union with Rome, but have their own distinctive liturgy, customs (such as married priests) and forms of organization (patriarchs and synods). The decree states that they are not simply different rites (as they were commonly called previously) but are \"sui iuris\" particular Churches along with the much larger Latin Church, and with the same rights as the Latin Church, including the right to govern themselves according to their traditional organizational practices. The decree affirms certain practices typical of the Eastern Churches, such as the administration of confirmation by priests, as well as the possibility of satisfying Sunday obligation by taking part in the Canonical Hours. It also provides guidelines concerning common worship and shared communion between Eastern Catholics and members of the Eastern Orthodox Church.\nChristian Education \u2013 The declaration \"Gravissimum educationis\" (\"Extreme [importance] of education\", 1965) discusses the importance of education (GE 1), of Christian education (GE 2-7), of Catholic schools (GE 8-9) and of Catholic colleges and universities (GE 10-12). Most everything in the declaration had been said many times before: the Church has the right to establish Catholic schools; parents have the right to choose the education they want for their children, governments have a duty to fund Catholic schools; and Catholics have a duty to support Catholic schools.\nMany observers found the declaration disappointing: \"Even at the last minute, dissatisfaction with the text was widespread and wide-ranging\". It was called \"probably the most inferior document produced by the Council\". But as it was late in the 4th session when everyone was under pressure to bring the council's business to a close, most bishops chose to vote for the text, though close to 9% rejected it.\nDecrees and declarations on the Church in the world.\nThese 5 documents deal with the Church in its relationship with the surrounding world: other religious groups \u2013 non-Catholic Christians, non-Christians \u2013 missionary outreach, religious freedom, and the media. Three of them \u2013 on ecumenism, non-Christian religions and religious freedom \u2013 were important advances in the Church's teaching.\nMission Activity \u2013 The decree \"Ad gentes\"\u00a0(\"To the Nations\", 1965) treats evangelization as the fundamental mission of the Catholic Church, \"to bring good news to the poor.\" It includes sections on training missionaries and on forming communities.\nEcumenism \u2013 The decree \"Unitatis redintegratio\" (\"Restoration of Unity\", 1964)\u00a0opens with the statement: \"The restoration of unity among all Christians is one of the principal concerns of the Second Vatican Council.\" This was a reversal of the Church's previous position, one of hostility or, at best, indifference to the ecumenical movement, because the Church claimed the only way unity would come about was if the non-Catholics returned to the true Church. The text produced by the Secretariat for Christian Unity said many things Catholics had not heard before:\nInstead of showing hostility or indifference to the ecumenical movement, a movement which originated among Protestant and Orthodox Christians, the decree states it was fostered by the Holy Spirit. Instead of repeating the previous prohibition on Catholics taking part in ecumenical activities, the decree states that a concern for unity is an obligation for all Catholics.\nInstead of claiming that disunity is the fault of non-Catholic Christians, the decree states that the Catholic Church must accept its share of the blame and ask for forgiveness. Instead of claiming that the Catholic Church is in no need of reform, the decree states that all Christians, including Catholics, must examine their own faithfulness to Christ's will, and undertake whatever internal reforms are called for. Ecumenism requires a new attitude, a \"change of heart\" (UR 7), an interior conversion, on the part of Catholics.\nInstead of claiming that only the Catholic Church has the means of salvation, the decree states that non-Catholic Christians have many of the elements of the true Church and, thanks to these, they can achieve salvation. All baptized are members of Christ's body. Catholics must get rid of false images of non-Catholics and come to appreciate the riches of their traditions.\nTheological experts from both sides should enter into dialogue, in which each side sets out clearly its understanding of the Gospel. It should be remembered there is a hierarchy of truths, that not all teachings are equally central to the faith. Christians of various traditions should pray together, though intercommunion is still not possible, and undertake actions for the common good of humanity.\nThe last chapter addresses the situation of the Eastern Orthodox and of Protestants. The Orthodox are very close to the Catholic Church: they have valid sacraments and a valid priesthood, and though their customs and liturgical practices are different, this is not an obstacle to unity. Protestants comprise many denominations and their closeness to the Catholic Church varies according to the denomination; however all of them share with Catholics the belief in Jesus as saviour, the Bible, baptism, worship and the effort to lead a moral life.\nIn circa 1960-1962, preparatory work for draft texts of Second Vatican Council documents \"report urged respectful use of the terms dissidents or separated brethren, in place of heretics and schismatics.\" After the Council, however, \"that habit of unthinkingly hurling accusations of heresy at Protestants pretty much died out\" in some contexts to avoid offense. Since at least the mid-1990s, the term has often been replaced by Catholics with phrases such as \"other Christians\".\nThis new way of considering the issue of Church unity met with great approval at the council and was adopted with very few dissenting voices.\nRelation of the Church to Non-Christian Religions \u2013 The declaration \"Nostra aetate\"\u00a0(\"In our time\", 1965), the shortest of Vatican II's documents, is a brief commentary on non-Christian religions, with a special section on the Jews. Pope John wanted the council to condemn antisemitism, including any Catholic teaching that might encourage antisemitism. It was felt that the way to avoid stirring up trouble in the Middle East was to include the passage on the Jews within a broader document about non-Christian religions.\nAvoiding argument or criticism, the declaration points out some positive features of Hinduism, Buddhism and Islam. \"The Catholic Church rejects nothing of what is holy and true in these religions\"; they often \"reflect a ray of that truth which enlightens all men and women,\" an idea that was rejected by all the popes from St. Peter to Pius XII.\nAs for the Jews, the declaration says they are very dear to God: \"God does not take back the gifts He bestowed or the choice He made\" (NA 4). Jews are not rejected or cursed by God because of the death of Jesus: neither all Jews then, nor any Jew today, can be blamed for the death of Jesus. The Church deplores all hatred and antisemitism.\" And the declaration ends with a condemnation of all forms of discrimination based on religion or ethnicity.\nBetter Jewish-Catholic relations have been emphasized since the council.\nReligious Freedom \u2013 The declaration \"Dignitatis humanae\"\u00a0(\"Of the Dignity of the Human Person\", 1965), \"on the right of the person and of communities to social and civil freedom in matters religious\", is the most striking instance of the council's staking out a new position.\nTraditional Catholic teaching rejected freedom of religion as a basic human right. The argument: only Catholics have the truth and so they alone are entitled to freedom of belief and of practice. All other religions are in error and, since \"error has no rights\", other religions have no right to freedom of belief and practice, and Catholic states have the right to suppress them. While it may be prudent to tolerate the existence of other religions in order to avoid civil unrest, this is merely a favour extended to them, not a matter of right. This double standard became increasingly intolerable to many Catholics. Furthermore, Protestants would not believe in the sincerity of Catholics' involvement in ecumenism, if they continued to support this double standard. Pope John's last encyclical, \"Pacem in terris\" (April 1963), listed freedom of religion among the basic human rights \u2013 the first papal document to support freedom of religion \u2013 and he wanted Vatican II to address the issue.\n\"Dignitatis humanae\" broke with the traditional position and asserted that every human being was entitled to religious freedom. The argument: belief cannot be coerced. Since the Church wants people's religious belief to be genuine, people must be left free to see the truth of what is preached. The declaration also appealed to revelation: Jesus did not coerce people to accept his teaching, but invited them to believe, and so did his immediate followers.\nMost Council Fathers supported this position, but 11% of them rejected it on the day of the final vote. If this position was true, they said, then the Church's previous teaching was wrong, and this was a conclusion they could not accept. The council's position on religious freedom raised in an acute way the issue of the development of doctrine: how can later teachings develop out of earlier ones? And how to tell whether a new position is a legitimate development of previous teaching or is heresy?\nThe Means of Social Communication \u2013 The decree \"Inter mirifica\" (\"Among the wonderful [discoveries]\", 1963) addresses issues concerning the press, cinema, television, and other media of communication. Chapter 1 is concerned with the dangers presented by the media, and insists that media producers should ensure that the media offer moral content, that media consumers should avoid media whose content is not moral, and that parents should supervise their children's media consumption. Chapter 2 discusses the usefulness of the media for the Church's mission: Catholic press and cinema should be promoted, and suitable persons within the Church should be trained in the use of the media.\n\"The text [is] generally considered to be one of the weakest of the Council.\" Rather than improve it, most Council Fathers preferred approving it as is and moving on to more important matters. Some 25% of the Council Fathers voted against it to express their disappointment.\nImpact of Vatican II.\nAccording to theologian Adrian Hastings, the key theological and practical developments due to Vatican II are of 3 kinds:\nChanges resulting from Vatican II.\nThe council addressed relations between the Catholic Church and the modern world. Several changes resulting from the council include the renewal of consecrated life with a revised charism, ecumenical efforts with other Christian denominations, interfaith dialogue with other religions, and the universal call to holiness, which according to Paul VI was \"the most characteristic and ultimate purpose of the teachings of the Council\".\nAccording to Pope Benedict XVI, the most important and essential message of the council was \"the Paschal Mystery as the center of what it is to be Christian and therefore of the Christian life, the Christian year, the Christian seasons\". Other changes that followed the council included the widespread use of vernacular languages in the Mass instead of Latin, the allowance of communion under both kinds for the laity, the subtle disuse of ornate clerical regalia, the revision of Eucharistic (liturgical) prayers, the abbreviation of the liturgical calendar, the ability to celebrate the Mass (with the officiant facing the congregation), as well as (facing the \"East\" and the Crucifix), and modern aesthetic changes encompassing contemporary Catholic liturgical music and artwork. With many of these changes resonating with the perspectives of other Christian denominations who sent observers to the Second Vatican Council, it was an ecumenical \"milestone for Catholics, Protestants, [and] the Orthodox\". These changes, while praised by many faithful Catholics, remain divisive among those identifying as traditionalist Catholics.\n\"Dignitatis humanae\", authored largely by United States theologian John Courtney Murray, challenged the council fathers to find \"reasons for religious freedom\" in which they believed, and drew from scripture scholar John L. McKenzie the comment: \"The Church can survive the disorder of development better than she can stand the living death of organized immobility.\" \nAs a result of the reforms of Vatican II, on 15 August 1972 Paul issued the \"motu proprio\" \"Ministeria Quaedam\" which in effect suppressed the minor orders and replaced them with two instituted ministries, those of lector and acolyte. A major difference was: \"Ministries may be assigned to lay Christians; hence they are no longer to be considered as reserved to candidates for the sacrament of orders.\"\nControversies.\nValidity of the Council.\nSome Traditionalist Catholics claim that several council statements conflict with established teaching regarding faith, morals and doctrine, and are therefore in error. As a result, some traditionalists say, Vatican II is invalid.\nThe largest of the traditionalist groups rejecting the validity of Vatican II is the Society of Saint Pius X (SSPX), which recognizes the authority of the Pope but rejects the validity of the Second Vatican Council. In 1988, the SSPX faced a conflict with Pope John Paul II over the consecration of bishops (\u00c9c\u00f4ne consecrations), which led to canonical sanctions (although the SSPX rejected the validity of them). This event has been a subject of ongoing debate within the Catholic community regarding the validity of any purported excommunications.\nOther groups have gone further than the SSPX and have declared that the Holy See has been vacant since the death of Pope Pius XII (sedevacantism) or that all the Pontiffs since Pope John XXIII are popes materially but not formally (sedeprivationism). The most notable of these groups are the Congregation of Mary Immaculate Queen and the Institute Mater Boni Consilii.\nAuthority of the council's teaching.\nSince Vatican II issued no dogmatic definitions or anathemas, in accordance with the wishes of Pope John XXIII expressed particularly in his opening address to the Council, it would be easy to conclude that, apart from where it repeats teaching that was already infallible before the Council, the Council's teaching is not binding, and that a Catholic is free to accept it or reject it.\nThis issue was addressed by Pope Paul VI five weeks after the end of the council in the talk he gave at his general audience of 12 January 1966:\nThere are those who ask what is the authority, the theological qualification, that the Council wished to attribute to its teachings, knowing that it avoided giving solemn dogmatic definitions engaging the infallibility of the ecclesiastical magisterium. And the answer is known to those who recall the conciliar declaration of March 6, 1964, repeated on November 16, 1964: given the pastoral character of the Council, it avoided proclaiming in an extraordinary way dogmas endowed with the note of infallibility; but it nevertheless endowed its teachings with the authority of the supreme ordinary magisterium, and this ordinary\u00a0\u2013 and obviously authentic\u00a0\u2013 magisterium must be accepted docilely and sincerely by all the faithful, according to the mind of the Council regarding the nature and purposes of the individual documents.\nThe issue is also addressed by the Code of Canon Law. While the 1917 \"Code of Canon Law\", in force in the Latin Church at the time of the council, simply stated \"An Ecumenical Council enjoys supreme power over the universal Church,\" the 1983 \"Code of Canon Law\"\u00a0states that Catholics may not disregard the teaching of an ecumenical council even if it does not propose its teaching as definitive: \nAlthough not an assent of faith, a religious submission of the intellect and will must be given to a Doctrine which the Supreme Pontiff or the College of Bishops declares concerning faith or morals when they exercise the authentic\u00a0Magisterium, even if they do not intend to proclaim it by definitive act; therefore, the Christian faithful are to take care to avoid those things which do not agree with it.\n\"The Spirit of Vatican II\".\nBy \"the spirit of Vatican II\" is often meant promoting teachings and intentions attributed to the Second Vatican Council in ways not limited to literal readings of its documents, spoken of as the \"letter\" of the council (cf. Saint Paul's phrase, \"the letter kills, but the Spirit gives life\").\nAcademic Michael Novak who had covered Vatican II as a journalist described it as a spirit that\nsometimes soared far beyond the actual, hard-won documents and decisions of Vatican II. ...It was as though the world (or at least the history of the Church) were now to be divided into only two periods, pre-Vatican II and post-Vatican II. Everything \"pre\" was then pretty much dismissed, so far as its \"authority\" mattered. For the most extreme, to be a Catholic now meant to believe more or less anything one wished to believe, or at least in the sense in which one personally interpreted it. One could be a Catholic \"in spirit\". One could take \"Catholic\" to mean the 'culture' in which one was born, rather than to mean a creed making objective and rigorous demands. One could imagine Rome as a distant and irrelevant anachronism, embarrassment, even adversary. Rome as \"them\". \nFrom another perspective, Church historian John W. O'Malley wrote: \nFor the new churches it recommended adaptation to local cultures, including philosophical and theological adaptation. It also recommended that Catholic missionaries seek ways of cooperating with missionaries of other faiths and of fostering harmonious relations with them. It asserted that art from every race and country be given scope in the liturgy of the church. More generally, it made clear that the church was sympathetic to the way of life of different peoples and races and was ready to appropriate aspects of different cultural traditions. Though obvious-sounding, these provisions were portentous. Where would they lead?\nLegacy.\nVatican II participants who later became pope.\nOf those who took part in the council's opening session, four later became pope: \nSaints of Vatican II.\nA number of those involved in Vatican II as pope, council father, \"peritus\" or official observer have been canonized or beatified, or are in the process of canonization.\nCanonized saints:\nBeatified:\nProcess ongoing:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28135", "revid": "20957809", "url": "https://en.wikipedia.org/wiki?curid=28135", "title": "Slovene language", "text": "Slavic language, mainly spoken in Slovenia\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nSlovene ( or ) or Slovenian ( ; ) is a South Slavic language of the Balto-Slavic branch of the Indo-European language family. Most of its 2.5 million speakers are the inhabitants of Slovenia, the majority of them ethnic Slovenes. As Slovenia is part of the European Union, Slovene is also one of its 24 official and working languages. Its grammar is highly fusional, and it has a dual grammatical number, an archaic feature shared with some other Indo-European languages. Two accentual norms (one characterized by pitch accent) are used. Its flexible word order is often adjusted for emphasis or stylistic reasons, although basically it is an SVO language. It has a T\u2013V distinction: the use of the V-form demonstrates a respectful attitude towards superiors and the elderly, while it can be sidestepped through the passive form.\nStandard Slovene.\nStandard Slovene is the national standard language that was formed in the 18th and 19th centuries, based on the Upper and Lower Carniolan dialect groups, more specifically on the language of Ljubljana and adjacent areas. The Lower Carniolan dialect group was the dialect used in the 16th century by Primo\u017e Trubar for his writings, while he also used Slovene as spoken in Ljubljana, since he lived in the city for more than 20 years. It was the speech of Ljubljana that Trubar took as a foundation of what later became standard Slovene, with small addition of his native speech, the Lower Carniolan dialect. Trubar's choice was also later adopted by other Protestant writers in the 16th century, and ultimately led to the formation of a more standard language. The Upper dialect was also used by most authors during the language revival in the 18th and early 19th centuries, and was also the language spoken by France Pre\u0161eren, who, like most Slovene writers and poets, lived and worked in Ljubljana, where the speech was growing closer to the Upper Carniolan dialect group. Unstandardized dialects are better preserved in regions of the Slovene Lands where compulsory schooling was in languages other than Standard Slovene, as was the case with the Carinthian Slovenes in Austria, and the Slovene minority in Italy. For example, the Resian and Torre (Ter) dialects in the Italian Province of Udine differ most from other Slovene dialects.\nClassification.\nSlovene is an Indo-European language belonging to the Western subgroup of the South Slavic branch of the Slavic languages, together with Serbo-Croatian. It is close to the Chakavian and especially Kajkavian dialects of Serbo-Croatian, but genealogically more distant from the Shtokavian dialect, the basis for the Bosnian, Croatian, Montenegrin, and Serbian standard languages. Slovene in general, and Prekmurje Slovene in particular, shares the highest level of mutual intelligibility with transitional Kajkavian dialects of Hrvatsko Zagorje and Me\u0111imurje. Furthermore, Slovene shares certain linguistic characteristics with all South Slavic languages, including those of the Eastern subgroup, namely Bulgarian, Macedonian, and Torlakian dialects.\nMutual intelligibility with varieties of Serbo-Croatian is hindered by differences in vocabulary, grammar, and pronunciation, Kajkavian being firmly the most mutually intelligible. Slovene has some commonalities with the West Slavic languages that are not found in other South Slavic languages.\nHistory.\nEarly history.\nLike all Slavic languages, Slovene traces its roots to the same proto-Slavic group of languages that produced Old Church Slavonic. The earliest known examples of a distinct, written dialect connected to Slovene are from the \"Freising manuscripts\", known in Slovene as . The consensus estimate of their date of origin is between 972 and 1039 CE (most likely before 1000). These religious writings are among the oldest surviving manuscripts in any Slavic language.\nThe \"Freising manuscripts\" are a record of a proto-Slovene that was spoken in a more scattered territory than modern Slovene, which included most of the present-day Austrian states of Carinthia and Styria, as well as East Tyrol, the Val Pusteria in South Tyrol, and some areas of Upper and Lower Austria.\nBetween the 9th and 12th century, proto-Slovene spread into northern Istria and in the areas around Trieste. By the 15th century, most of the northern areas were gradually Germanized: The northern border of the Slovene-speaking territory stabilized on the line going from north of Klagenfurt to south of Villach and east of Hermagor in Carinthia, while in Styria it was more or less identical with the current Austrian-Slovenian border. This linguistic border remained almost unchanged until the late 19th century, when a second process of Germanization took place, mostly in Carinthia. \nDuring most of the Middle Ages, Slovene was a vernacular language of the peasantry, although it was also spoken in most of the towns on Slovenian territory, together with German or Italian. Although during this time German emerged as the spoken language of the nobility, Slovene had some role in the courtly life of the Carinthian, Carniolan, and Styrian nobility as well. This is proved by the survival of certain ritual formulas in Slovene (such as the ritual installation of the Dukes of Carinthia). The words ('God be With You, Queen Venus!'), with which Bernhard von Spanheim greeted the poet Ulrich von Liechtenstein, who was travelling around Europe in guise of Venus, upon his arrival in Carinthia in 1227 (or 1238), is another example of some level of Slovene knowledge among high nobility in the region.\nThe first printed Slovene words, (meaning 'old justice' or 'old laws'), appeared in 1515 in Vienna in a poem of the German mercenaries who suppressed the Slovene peasant revolt: the term was presented as the peasants' motto and battle cry. Standard Slovene emerged in the second half of the 16th century, thanks to the works of Slovene Lutheran authors, who were active during the Protestant Reformation. The most prominent authors from this period are Primo\u017e Trubar, who wrote the first books in Slovene; Adam Bohori\u010d, the author of the first Slovene grammar; and Jurij Dalmatin, who translated the entire Bible into Slovene.\nFrom the high Middle Ages up to the dissolution of the Austro-Hungarian Empire in 1918, in the territory of present-day Slovenia, German was the language of the elite, and Slovene was the language of the common people. During this period, German had a strong influence on Slovene; many Germanisms are preserved in contemporary colloquial Slovene. Many Slovene scientists before the 1920s also wrote in foreign languages, mostly German, which was the \"lingua franca\" of science throughout Central Europe at the time.\nRecent history.\nDuring the rise of Romantic nationalism in the 19th century, the cultural movements of Illyrism and Pan-Slavism brought words from Serbo-Croatian, specifically Croatian dialects, and Czech into standard Slovene, mostly to replace words previously borrowed from German. Most of these innovations have remained, although some were dropped in later development. In the second half of the 19th century, many nationalist authors made an abundant use of Serbo-Croatian vocabulary but adapted it to Slovene orthography: among them were Fran Levstik and Josip Jur\u010di\u010d, who wrote the first novel in Slovene in 1866. This tendency was reversed in the Fin de si\u00e8cle period by the first generation of modernist Slovene authors (most notably the writer Ivan Cankar), who resorted to a more purist and locally derived language without excessive Serbo-Croatian borrowings.\nDuring the Kingdom of Yugoslavia in the 1920s and 1930s, the influence of Serbo-Croatian increased again. This was opposed by the younger generations of Slovene authors and intellectuals; among the fiercest opponents of an excessive Serbo-Croatian influence on Slovene were the intellectuals associated with the leftist journal \"Sodobnost\", as well as some younger Catholic activists and authors. After 1945, numerous Serbo-Croatian words that had been used in the previous decades were dropped. The result was that a Slovene text from the 1910s is frequently closer to modern Slovene than a text from the 1920s and 1930s.\nBetween 1920 and 1941, the official language of the Kingdom of Yugoslavia was defined as \"Serbo-Croato-Slovene\", which was in practice merely Serbo-Croatian. In Slovenia, however, Slovene remained in use in education and administration. Many state institutions used only Serbo-Croatian, and a Slovene\u2013Serbo-Croatian bilingualism was applied in many spheres of public life in Slovenia. For example, at post offices, on railways, and in administrative offices, Serbo-Croatian was used alongside Slovene. However, state employees were expected to be able to speak Slovene in Slovenia.\nDuring the same time, western Slovenia (the Slovenian Littoral and the western districts of Inner Carniola) was under Italian administration and subjected to a violent policy of Fascist Italianization; the same policy was applied to Slovene speakers in Venetian Slovenia, Gorizia, and Trieste. Between 1923 and 1943, all public use of Slovene in these territories was strictly prohibited, and Slovene-language activists were persecuted by the state.\nAfter the Carinthian Plebiscite of 1920, a less severe policy of Germanization took place in the Slovene-speaking areas of southern Carinthia which remained under Austrian administration. After the Anschluss of 1938, the use of Slovene was strictly forbidden in Carinthia as well. This accelerated a process of language shift in Carinthia, which continued throughout the second half of the 20th century: according to the Austro-Hungarian census of 1910, around 21% of inhabitants of Carinthia spoke Slovene in their daily communication; by 1951, this figure had dropped to less than 10%, and by 2001 to a mere 2.8%.\nDuring World War II, Slovenia was divided among the Axis powers of Fascist Italy, Nazi Germany, and Hungary. Each of the occupying powers tried to either discourage or entirely suppress Slovene.\nFollowing World War II, Slovenia became part of the Federal Yugoslavia. While there was no official language at federal level, Serbo-Croatian dominated as prestige dialect in all aspects whereas Slovene remained confined to now federal Slovenia where it was made an official language recognized once again. In the territory of Slovenia, it was commonly used in almost all areas of public life. One important exception was the Yugoslav army, where Serbo-Croatian was used exclusively, even in Slovenia.\nNational independence has further fortified the language: since 1991, when Slovenia gained independence, Slovene has been used as an official language in all areas of public life. In 2004, it became one of the official languages of the European Union upon the admission of Slovenia.\nNonetheless, the post-breakup influence of Serbo-Croatian on Slovene continued to a lesser extent, most prominently in slang in colloquial language.\nJo\u017ea Mahni\u010d, a literary historian and president of the publishing house , said in February 2008 that Slovene is a language rich enough to express everything, including the most sophisticated and specialised texts. In February 2010, Janez Dular, a prominent Slovene linguist, commented that, although Slovene is not an endangered language, its scope has been shrinking, especially in science and higher education.\nGeographic distribution.\nThe language is spoken by about 2.5 million people, mainly in Slovenia, but also by Slovene national minorities in Friuli-Venezia Giulia, Italy (around 90,000 in Venetian Slovenia, Resia Valley, Canale Valley, Province of Trieste, and in those municipalities of the Province of Gorizia bordering Slovenia), in southern Carinthia, some parts of Styria in Austria (25,000), and in the western part of Croatian Istria bordering Slovenia. It is also spoken in Rijeka and Zagreb (11,800-13,100), in southwestern Hungary (3\u20135,000), in Serbia (5,000), and by the Slovene diaspora throughout Europe and the rest of the world (around 300,000), particularly in the United States (most notably Ohio, home to an estimated 3,400 speakers), Canada, Argentina, Australia, and South Africa.\nDialects.\nSlovene is sometimes characterized as the most diverse Slavic language in terms of its dialects, with different degrees of mutual intelligibility. Accounts of the number of dialects range from as few as seven dialects, often considered dialect groups or dialect bases that are further subdivided into as many as 50 dialects. Other sources characterize the number of dialects as nine or eight. The Slovene proverb \"Every village has its own voice\" () depicts the differences in dialects.\nThe Prekmurje dialect used to have a written norm of its own at one point. The Resian dialects have an independent written norm that is used by their regional state institutions. Speakers of those two dialects have considerable difficulties with being understood by speakers of other varieties of Slovene, needing to code-switch to Standard Slovene. Other dialects are mutually intelligible when speakers avoid the excessive usage of regionalisms.\nRegionalisms are mostly limited to culinary and agricultural expressions, although there are many exceptions. Some loanwords have become so deeply rooted in the local language that people have considerable difficulties in finding a standard expression for the dialect term (for instance, meaning a type of custard cake is in Standard Slovene, but the latter term is very rarely used in speech, being considered inappropriate for non-literary registers). Southwestern dialects incorporate many calques and loanwords from Italian, whereas eastern and northwestern dialects are replete with lexemes of German origin. Usage of such words hinders intelligibility between dialects and is greatly discouraged in formal situations.\nPhonology.\nSlovene has a phoneme set consisting of 21 consonants and 8 vowels.\nConsonants.\nSlovene has 21 distinctive consonant phonemes.\nAll voiced obstruents are devoiced at the end of words unless immediately followed by a word beginning with a vowel or a voiced consonant. In consonant clusters, the voicing distinction is neutralized and all consonants assimilate the voicing of the rightmost segment, i.e., the final consonant in the cluster. In this context, , , and may occur as voiced allophones of , , and , respectively (e.g., ).\n has several allophones depending on context.\nThe sequences , , and occur only before a vowel. Before a consonant or word-finally, they are reduced to , , and , respectively. This is reflected in the spelling in the case of , but not for and .\nUnder certain (somewhat unpredictable) circumstances, at the end of a syllable may become , merging with the allophone of in that position.\nVowels.\nSlovene has an eight-vowel (or, according to Peter Jurgec, nine-vowel) system, in comparison to the five-vowel system of Serbo-Croatian.\nGrammar.\nNouns.\nSlovene nouns retain six of the seven Slavic noun cases: nominative, accusative, genitive, dative, locative, and instrumental. There is no distinct vocative; the nominative is used in that role. Nouns, adjectives, and pronouns have three numbers: singular, dual, and plural.\nNouns in Slovene are either masculine, feminine, or neuter gender. In addition, there is a distinction between animate and inanimate nouns. This is only relevant for masculine nouns and only in the singular, at odds with some other Slavic languages, e.g., Russian, for which it is also relevant in the plural for all genders. Animate nouns have an accusative singular form that is identical to the genitive, while for inanimate nouns the accusative singular is the same as the nominative. Animacy is based mostly on semantics and is less rigid than gender. Generally speaking, a noun is animate if it refers to something that is generally thought to have free will or the ability to move of its own accord. This includes all nouns for people and animals. All other nouns are inanimate, including plants and other non-moving life forms, and also groups of people or animals. However, there are some nouns for inanimate objects that are generally animate, which mostly include inanimate objects that are named after people or animals. This includes:\nDefiniteness.\nThere are no definite or indefinite articles as in English (\"the\", \"a\", \"an\") or German (). A noun is described without articles; the grammatical gender is shown by the ending of the word. It is enough to say ('a' or 'the barge'), ('Noah's ark'). The gender is known in this case to be feminine. In declensions, endings are normally changed; see below. If one would like to somehow distinguish between the definiteness or indefiniteness of a noun, one would say ('that/precise/exact barge') for 'the barge' and ('some/a barge') for 'a barge'.\nThe definiteness of a noun phrase can also be discerned through the ending of the accompanying adjective. One should say ('[exactly that] red tent') or ('[a] red tent'). This difference is observable only for masculine nouns in nominative or accusative case. Because of the lack of article in Slovene and audibly insignificant difference between the masculine adjective forms, most dialects do not distinguish between definite and indefinite variants of the adjective, leading to hypercorrection when speakers try to use Standard Slovene.\nT\u2013V distinction.\nSlovene, like most other European languages, has a T\u2013V distinction, or two forms of 'you' for formal and informal situations. Although informal address using the 2nd person singular form (known as ) is officially limited to friends and family, talk among children, and addressing animals, it is increasingly used among the middle generation to signal a relaxed attitude or lifestyle instead of its polite or formal counterpart using the 2nd person plural form (known as ).\nAn additional nonstandard but widespread use of a singular participle combined with a plural auxiliary verb (known as ) signals a somewhat more friendly and less formal attitude while maintaining politeness:\nThe use of nonstandard forms () might be frowned upon by many people and would not likely be used in a formal setting.\nThe use of the 3rd person plural ('they') form (known as in both direct address and indirect reference; this is similar to using in German) as an ultra-polite form is now archaic or dialectal. It is associated with servant-master relationships in older literature, the child-parent relationship in certain conservative rural communities, and parishioner-priest relationships.\nVocabulary.\nForeign words.\nForeign words used in Slovene are of various types depending on the assimilation they have undergone. The types are:\nThe loanwords are mostly from German and Italian, while the more recently borrowed and less assimilated words are typically from English. Among the earliest borrowings in Slovene vocabulary are Romanisms, which began to enter the Slovene language with the settlement of Slovenia by the Slavs and continued during the Middle Ages. These are primarily toponyms: Latin \"Capris / Caprae\" \u2192 Koper, Latin \"Sontius\" \u2192 So\u010da. In addition, there are words such as \"jambor\" 'mast' &lt; Latin \"arbor\" 'tree', \"golida\" 'milking pail' &lt; Vulgar Latin \"galeda\", \"hla\u010de\" 'trousers' &lt; Medieval Latin \"calcae\", \"fant\" 'boy, lad' &lt; Italian \"fante\".\nSlovene vocabulary also contains a large number of Germanisms, borrowed from the 8th to the 19th centuries: \"flinta\" 'rifle' &lt; German \"Flinte\", \"gmajna\" 'community, common land' &lt; Middle High German \"gemeine\", \"krompir\" 'potato' &lt; German \"Grundbirne\". Through German mediation, vocabulary of Latin and Greek origin also entered Slovene: \"klo\u0161ter\" 'monastery', \"\u0161krinja\" 'chest', \"\u0161pital\" 'hospital'.\nWriting system.\nThis alphabet () was derived in the mid-1840s from the system created by the Croatian linguist Ljudevit Gaj. Intended for the Serbo-Croatian language (in all its varieties), it was patterned on the Czech alphabet of the 1830s. Before that was, for example, written as \u27e8\u0283\u27e9, \u27e8\u0283\u0283\u27e9, or \u27e8\u017f\u27e9; as \u27e8t\u0283ch\u27e9, \u27e8cz\u27e9, \u27e8t\u0283cz\u27e9, or \u27e8tcz\u27e9; sometimes as \u27e8y\u27e9; as \u27e8y\u27e9; as \u27e8ll\u27e9; as \u27e8w\u27e9; as \u27e8\u0283\u27e9, \u27e8\u0283\u0283\u27e9, or \u27e8\u0283z\u27e9.\nThe standard Slovene orthography, employed in almost all situations, uses only the letters of the ISO basic Latin alphabet plus \u27e8\u010d\u27e9, \u27e8\u0161\u27e9, and \u27e8\u017e\u27e9. The letters \u27e8q\u27e9, \u27e8w\u27e9, \u27e8x\u27e9, and \u27e8y\u27e9 are not included:\nThe orthography thus underdifferentiates several phonemic distinctions:\nIn the tonemic varieties of Slovene, the ambiguity is even greater: \u27e8e\u27e9 in a final syllable can stand for any of (although is rare; and Slovene, except in some dialects, does not distinguish tonemic accentuation).\nThe reader is expected to gather the interpretation of the word from the context, as in these examples:\nDiacritics.\nTo compensate for the shortcomings of the standard orthography, Slovene also uses standardized diacritics or accent marks to denote stress, vowel length, and pitch accent, much like the closely related Serbo-Croatian. However, as in Serbo-Croatian, use of such accent marks is restricted to dictionaries, language textbooks, and linguistic publications. In normal writing, the diacritics are almost never used, except in a few minimal pairs where real ambiguity could arise.\nTwo different and mutually-incompatible systems of diacritics are used. The first is the simpler non-tonemic system, which can be applied to all Slovene dialects. It is more widely used and is the standard representation in dictionaries such as SSKJ. The tonemic system also includes tone as part of the representation. However, neither system reliably distinguishes schwa from the front mid-vowels, nor vocalised l from regular l . Some sources, such as Maks Pleter\u0161nik's 1894/95 dictionary, write these as \"\u0259\" and \"\u0142\", respectively, but this is not as common.\nNon-tonemic diacritics.\nIn the non-tonemic system, the distinction between the two mid-vowels is indicated, as well as the placement of stress and the length of vowels:\nTonemic diacritics.\nThe tonemic system uses the diacritics somewhat differently from the non-tonemic system. The high-mid vowels and are written \u27e8\u1eb9 \u1ecd\u27e9 with a subscript dot, while the low-mid vowels and are written as plain \u27e8e o\u27e9.\nPitch accent and vowel length is indicated by four diacritical marks:\nThe schwa vowel is written ambiguously as \u27e8e\u27e9, but its accentuation will sometimes distinguish it: a long vowel mark can never appear on a schwa, while a grave accent can appear only on a schwa. Thus, only \u27e8\u0205\u27e9 and unstressed \u27e8e\u27e9 are truly ambiguous.\nRegulation.\nStandard Slovene spelling and grammar are defined by the Orthographic Committee and the Fran Ramov\u0161 Institute of the Slovene Language, which are both part of the Slovenian Academy of Sciences and Arts (, SAZU). The newest reference book of standard Slovene spelling (and to some extent also grammar) is the (\"SP2001\"; Slovene Normative Guide). The latest printed edition was published in 2001 (reprinted in 2003 with some corrections) and contains more than 130,000 dictionary entries. In 2003, an electronic version was published.\nThe official dictionary of modern Slovene, which was also prepared by SAZU, is (\"SSKJ\"; Standard Slovene Dictionary). It was published in five volumes by Dr\u017eavna Zalo\u017eba Slovenije between 1970 and 1991 and contains more than 100,000 entries and subentries with accentuation, part-of-speech labels, common collocations, and various qualifiers. In the 1990s, an electronic version of the dictionary was published and is available online.\nThe SAZU considers SP2001 to be the normative source on Slovene. When dictionary entries in SP2001 and SSKJ differ, the SP2001 entry takes precedence. SP2001 is called a Spelling Dictionary by the European Network of e-Lexicography.\nSample text.\nArticle 1 of the \"Universal Declaration of Human Rights\" in Slovene.\nArticle 1 of the \"Universal Declaration of Human Rights\" in English:\n\"All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28136", "revid": "1319716684", "url": "https://en.wikipedia.org/wiki?curid=28136", "title": "Slovak language", "text": "West Slavic language\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nSlovak ( ; endonym: or ), is a West Slavic language of the Czech\u2013Slovak group, written in Latin script. It is part of the Indo-European language family, and is one of the Slavic languages, which are part of the larger Balto-Slavic branch. Spoken by approximately 5 million people as a native language, primarily ethnic Slovaks, it serves as the official language of Slovakia and one of the 24 official languages of the European Union.\nSlovak is closely related to Czech, to the point of very high mutual intelligibility, as well as to Polish. Like other Slavic languages, Slovak is a fusional language with a complex system of morphology and relatively flexible word order. Its vocabulary has been extensively influenced by Latin and German, as well as other Slavic languages.\nHistory.\nThe Czech\u2013Slovak group developed within West Slavic in the high medieval period, and the standardization of Czech and Slovak within the Czech\u2013Slovak dialect continuum emerged in the early modern period. In the later mid-19th century, the modern Slovak alphabet and written standard became codified by \u013dudov\u00edt \u0160t\u00far and reformed by Martin Hattala. The Moravian dialects spoken in the western part of the country along the border with the Czech Republic are also sometimes classified as Slovak, although some of their western variants are closer to Czech; they nonetheless form the bridge dialects between the two languages.\nGeographic distribution and status.\nSlovak language is primarily spoken in Slovakia. The country's constitution declared it the official language of the state (\u0161t\u00e1tny jazyk):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;(1) Na \u00fazem\u00ed Slovenskej republiky je \u0161t\u00e1tnym jazykom slovensk\u00fd jazyk.\n(2) Pou\u017e\u00edvanie in\u00fdch jazykov ne\u017e \u0161t\u00e1tneho jazyka v \u00faradnom styku ustanov\u00ed z\u00e1kon.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;(1) The Slovak language is the official language on the territory of the Slovak Republic.\n(2) The use of languages other than the official language in official communication shall be laid down by law.\nConstitution of Slovakia, Article 6.\nBeside that, national minorities and ethnic groups also have explicit permission to use their distinct languages. Slovakia is a country with established Language policy concerning its official language.\nRegulation.\nStandard Slovak () is defined by an Act of Parliament on the State Language of the Slovak Republic (language law). According to this law, the Ministry of Culture approves and publishes the codified form of Slovak based on the judgment of specialised Slovak linguistic institutes and specialists in the area of the state language. This is traditionally the \u013dudov\u00edt \u0160t\u00far Institute of Linguistics, which is part of the Slovak Academy of Sciences. In practice, the Ministry of Culture publishes a document that specifies authoritative reference books for standard Slovak usage, which is called the codification handbook (). The current regulations were published on 15 March 2021. There are four such publications:\nSlovak speakers are also found in the Slovak diaspora in the United States, the Czech Republic, Argentina, Serbia, Ireland, Romania, Poland, Canada, Hungary, Germany, Croatia, Israel, the United Kingdom, Australia, Austria, Ukraine, Norway, and other countries to a lesser extent.\nSlovak language is one of the official languages of Autonomous Province of Vojvodina.\nDialects.\nThere are many Slovak dialects, which are divided into the following four basic groups:\nThe fourth group of dialects is often not considered a separate group, but a subgroup of Central and Western Slovak dialects (see e.g. \u0160tolc, 1968), but it is currently undergoing changes due to contact with surrounding languages (Serbo-Croatian, Romanian, and Hungarian) and long-time geographical separation from Slovakia (see the studies in \"Zborn\u00edk Spolku vojvodinsk\u00fdch slovakistov\", e.g. Dudok, 1993).\nThe dialect groups differ mostly in phonology, vocabulary, and tonal inflection. Syntactic differences are minor. Central Slovak forms the basis of the present-day standard language. Not all dialects are fully mutually intelligible. It may be difficult for an inhabitant of the western Slovakia to understand a dialect from eastern Slovakia and the other way around.\nThe dialects are fragmented geographically, separated by numerous mountain ranges. The first three groups already existed in the 10th century. All of them are spoken by the Slovaks outside Slovakia, and central and western dialects form the basis of the lowland dialects (see above).\nThe western dialects contain features common with the Moravian dialects in the Czech Republic, the southern central dialects contain a few features common with South Slavic languages, and the eastern dialects a few features common with Polish and the East Slavonic languages (cf. \u0160tolc, 1994). Lowland dialects share some words and areal features with the languages surrounding them (Serbo-Croatian, Hungarian, and Romanian).\nPhonology.\nSlovak contains 15 vowel phonemes (11 monophthongs and four diphthongs) and 29 consonants.\nThe phoneme /\u00e6/ is marginal and often merges with /e/; the two are normally only distinguished in higher registers.\nVowel length is phonemic in Slovak and both short and long vowels have the same quality. In addition, Slovak, unlike Czech, employs a \"rhythmic law\" which forbids two long vowels from following one another within the same word. In such cases the second vowel is shortened. For example, adding the locative plural ending to the root creates , not . This law also applies to diphthongs; for example, the adjective meaning \"white\" is , not (compare Czech ).\nSlovak has final devoicing; when a voiced consonant () is at the end of a word before a pause, it is devoiced to its voiceless counterpart (, respectively). For example, is pronounced and is pronounced .\nConsonant clusters containing both voiced and voiceless elements are entirely voiced if the last consonant is a voiced one, or voiceless if the last consonant is voiceless. For example, is pronounced and is pronounced . This rule applies also over the word boundary. For example, (to come home) and (more strawberries). The voiced counterpart of \" is , and the unvoiced counterpart of \" is .\nOrthography.\nSlovak uses the Latin script with small modifications that include the four diacritics (\u02c7, \u00b4, \u00a8, \u02c6) placed above certain letters ()\n\"Italic\" letters (Q and W) are used in loanwords and foreign names.\nThe primary principle of Slovak spelling is the phonemic principle. The secondary principle is the morphological principle: forms derived from the same stem are written in the same way even if they are pronounced differently. An example of this principle is the assimilation rule (see below). The tertiary principle is the etymological principle, which can be seen in the use of \"i\" after certain consonants and of \"y\" after other consonants, although both \"i\" and \"y\" are usually pronounced the same way.\nFinally, the rarely applied grammatical principle occurs when, for example, the basic singular form and plural form of masculine adjectives are written differently with no difference in pronunciation (e.g. = nice \u2013 singular versus = nice \u2013 plural). Such spellings are most often remnants of differences in pronunciation that were present in Proto-Slavic (in Polish, where the vowel merger did not occur, and and in Czech and are pronounced differently).\nMost loanwords from foreign languages are respelt using Slovak principles either immediately or later. For example, \"weekend\" is spelled , \"software\" \u2013 , \"gay\" \u2013 (both not exclusively), and \"quality\" is spelled . Personal and geographical names from other languages using Latin alphabets keep their original spelling unless a Slovak exonym exists (e.g. for \"London\").\nSlovak features some heterophonic homographs (words with identical spelling but different pronunciation and meaning), the most common examples being (beautiful) versus (beautifully).\nGrammar.\nSyntax.\nThe main features of Slovak syntax are as follows:\nSome examples include the following:\n. (The+singer+feminine suffix is+singing.)\n(, where -\u2205 is (the empty) third-person-singular ending)\n. (Singer+feminine suffix +plural suffix are+singing.)\n(; is a third-person-plural ending, and /j/ is a hiatus sound)\n. (We the+singer+feminine suffix +plural suffix are+singing.)\n(, where is the first-person-plural ending)\nand so forth.\nWord order in Slovak is relatively free, since strong inflection enables the identification of grammatical roles (subject, object, predicate, etc.) regardless of word placement. This relatively free word order allows the use of word order to convey topic and emphasis.\nSome examples are as follows:\n. = That big man is opening a store there today. ( = that; = big; = man; = there; = today; = opens; = store) \u2013 The word order does not emphasize any specific detail, just general information.\n. = That big man is today opening a store there. \u2013 This word order emphasizes the place ( = there).\n. = Today over there a store is being opened by that big man. \u2013 This word order focuses on the person who is opening the store ( = that; = big; = man).\n. = The store over there is today being opened by that big man. \u2013 Depending on the intonation the focus can be either on the store itself or on the person.\nThe unmarked order is subject\u2013verb\u2013object. Variation in word order is generally possible, but word order is not completely free.\nIn the above example, the noun phrase cannot be split up, so that the following combinations are not possible:\n. ...\nAnd the following sentence is stylistically infelicitous:\n. (Only possible in a poem or other forms of artistic style.)\nThe regular variants are as follows: \n \n \n \nMorphology.\nArticles.\nSlovak, like every major Slavic language other than Bulgarian and Macedonian, does not have articles. The demonstrative pronoun in masculine form (that one) or in feminine and in neuter respectively, may be used in front of the noun in situations where definiteness must be made explicit.\nNouns, adjectives, pronouns.\nSlovak nouns are inflected for case and number. There are six cases: nominative, genitive, dative, accusative, locative, and instrumental. The vocative is purely optional and most of the time unmarked. It is used mainly in spoken language and in some fixed expressions: mum (nominative) vs. mum! (vocative), , dad (N) vs. , dad! (V), Mr., sir vs. sir (when addressing someone e.g. in the street). There are two numbers: singular and plural. Nouns have inherent gender. There are three genders: masculine, feminine, and neuter. Adjectives and pronouns must agree with nouns in case, number, and gender.\nNumerals.\nThe numerals 0\u201310 have unique forms, with numerals 1\u20134 requiring specific gendered representations. Numerals 11\u201319 are formed by adding to the end of each numeral. The suffix is used to create numerals 20, 30 and 40; for numerals 50, 60, 70, 80 and 90, is used. Compound numerals (21, 1054) are combinations of these words formed in the same order as their mathematical symbol is written (e.g. 21 = , literally \"twenty-one\").\nThe numerals are as follows:\nSome higher numbers: (200) , (300) , (400) \"\u0161tyristo\", (900) , (1,000) , (1,100) , (2,000) , (100,000) , (200,000) , (1,000,000) , (1,000,000,000) .\nCounted nouns have two forms. The most common form is the plural genitive (e.g. = five houses or = one hundred two women), while the plural form of the noun when counting the amounts of 2\u20134, etc., is usually the nominative form without counting (e.g. = two houses or = two women) but gender rules do apply in many cases.\nVerbs.\nVerbs have three major conjugations. Three persons and two numbers (singular and plural) are distinguished. Subject personal pronouns are omitted unless they are emphatic.\n (I hid / I have hidden); (I had hidden)\n\n (I would hide), (I would have hidden)\n\n\n\n (by hiding (perfective))\n ((while/during) hiding)\n\nConjugations.\nSeveral conjugation paradigms exist as follows:\nAdverbs.\nAdverbs are formed by replacing the adjectival ending with the ending - or - / -. Sometimes both - and - are possible. Examples include the following:\n (high) \u2013 (highly)\n (nice) \u2013 (nicely)\n (friendly) \u2013 (in a friendly manner)\n (fast) \u2013 (quickly)\nThe comparative of adverbs is formed by replacing the adjectival ending with a comparative/superlative ending - or -, whence the superlative is formed with the prefix \"naj-.\" Examples include the following:\n (fast) \u2013 (faster) \u2013 (fastest): (quickly) \u2013 (more quickly) \u2013 (most quickly)\nPrepositions.\nEach preposition is associated with one or more grammatical cases. The noun governed by a preposition must agree with the preposition in the given context. The preposition always calls for the genitive case, but some prepositions such as can call for different cases depending on the intended sense of the preposition.\nfrom friends = (genitive case of )\naround the square = (locative case of )\nup to the square = (accusative case of )\nVocabulary.\nSlovak is a descendant of Proto-Slavic, itself a descendant of Proto-Indo-European. It is closely related to the other West Slavic languages, primarily to Czech and Polish. Czech also influenced the language in its later development. The highest number of borrowings in the old Slovak vocabulary come from Latin, German, Czech, Hungarian, Polish and Greek (in that order). Recently, it is also influenced by English.\nCzech.\nAlthough most dialects of Czech and Slovak are mutually intelligible (see Comparison of Slovak and Czech), eastern Slovak dialects are less intelligible to speakers of Czech and closer to Polish and East Slavic, and contact between speakers of Czech and speakers of the eastern dialects is limited.\nSince the dissolution of Czechoslovakia it has been permitted to use Czech in TV broadcasting and during court proceedings (Administration Procedure Act 99/1963 Zb.). From 1999 to August 2009, the Minority Language Act 184/1999 Z.z., in its section (\u00a7) 6, contained the variously interpreted unclear provision saying that \"When applying this act, it holds that the use of the Czech language fulfills the requirement of fundamental intelligibility with the state language\"; the state language is Slovak and the Minority Language Act basically refers to municipalities with more than 20% ethnic minority population (no such Czech municipalities are found in Slovakia). Since 1 September 2009 (due to an amendment to the State Language Act 270/1995 Z.z.) a language \"fundamentally intelligible with the state language\" (i.e. the Czech language) may be used in contact with state offices and bodies by its native speakers, and documents written in it and issued by bodies in the Czech Republic are officially accepted. Regardless of its official status, Czech is used commonly both in Slovak mass media and in daily communication by Czech natives as an equal language.\nCzech and Slovak have a long history of interaction and mutual influence well before the creation of Czechoslovakia in 1918, a state which existed until 1993. Literary Slovak shares significant orthographic features with Czech, as well as technical and professional terminology dating from the Czechoslovak period, but phonetic, grammatical, and vocabulary differences do exist.\nOther Slavic languages.\nSlavic language varieties are relatively closely related, and have had a large degree of mutual influence, due to the complicated ethnopolitical history of their historic ranges. This is reflected in the many features Slovak shares with neighboring language varieties. Standard Slovak shares high degrees of mutual intelligibility with many Slavic varieties. Despite this closeness to other Slavic varieties, significant variation exists among Slovak dialects. In particular, eastern varieties differ significantly from the standard language, which is based on central and western varieties.\nEastern Slovak dialects have the greatest degree of mutual intelligibility with Polish of all the Slovak dialects, followed by Rusyn, but both Eastern Slovak and Rusyn lack familiar technical terminology and upper register expressions. Polish and Sorbian also differ quite considerably from Czech and Slovak in upper registers, but non-technical and lower register speech is readily intelligible. Some mutual intelligibility occurs with spoken Rusyn, Ukrainian, and even Russian (in this order), as their orthographies are based on the Cyrillic script.\nEnglish.\nSports:\nFood:\nClothing:\nExclamations:\nGerman.\nNouns:\nVerbs:\nGreetings:\n is commonly used as a greeting or upon parting in Slovak-speaking regions and some German-speaking regions, particularly Austria. is also commonly used upon parting in these regions. Both and are used in colloquial, informal conversation.\nHungarian.\nHungarians and Slovaks have had language interaction ever since the settlement of Hungarians in the Carpathian area. Hungarians also adopted many words from various Slavic languages related to agriculture and administration, and a number of Hungarian loanwords are found in Slovak. Some examples are as follows:\nSample text.\nArticle 1 of the Universal Declaration of Human Rights in Slovak (latin script):\n\"V\u0161etci \u013eudia sa rodia slobodn\u00ed a rovn\u00ed v d\u00f4stojnosti aj pr\u00e1vach. S\u00fa obdaren\u00ed rozumom a svedom\u00edm a maj\u00fa sa k sebe spr\u00e1va\u0165 v duchu bratstva.\"\nArticle 1 of the \"Universal Declaration of Human Rights\" in English:\n\"All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "28142", "revid": "49957049", "url": "https://en.wikipedia.org/wiki?curid=28142", "title": "Supercluster", "text": "Large group of smaller galaxy clusters or galaxy groups\nA supercluster is a large group of smaller galaxy clusters or galaxy groups; they are among the largest known structures in the universe. The Milky Way is part of the Local Group galaxy group (which contains more than 54 galaxies), which in turn is part of the Virgo Supercluster, which is part of the Laniakea Supercluster, which is part of the Pisces\u2013Cetus Supercluster Complex. The large size and low density of superclusters means that most of them, unlike clusters, expand with the Hubble expansion. The number of superclusters in the observable universe is estimated to be 10 million.\nExistence.\nThe existence of superclusters indicates that the galaxies in the Universe are not uniformly distributed; most of them are drawn together in groups and clusters, with groups containing up to some dozens of galaxies and clusters up to several thousand galaxies. Those groups and clusters and additional isolated galaxies in turn form even larger structures called superclusters.\nTheir existence was first postulated by George Abell in his 1958 Abell catalogue of galaxy clusters. He called them \"second-order clusters\", or clusters of clusters.\nSuperclusters form massive structures of galaxies, called \"filaments\", \"supercluster complexes\", \"hyperclusters\", \"chains\", \"strands\", \"superstructures\", \"walls\" or \"sheets\", that may span between several hundred million light-years to 10 billion light-years, covering more than 5% of the observable universe. These are the largest structures known to date. Observations of superclusters can give information about the initial condition of the universe, when these superclusters were created. The directions of the rotational axes of galaxies within superclusters are studied by those who believe that they may give insight and information into the early formation process of galaxies in the history of the Universe.\nInterspersed among superclusters are large voids of space where few galaxies exist. Superclusters are frequently subdivided into groups of clusters called galaxy groups and clusters.\nAlthough superclusters are supposed to be the largest structures in the universe according to the cosmological principle, larger structures have been observed in surveys, including the Sloan Great Wall.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28143", "revid": "48891756", "url": "https://en.wikipedia.org/wiki?curid=28143", "title": "Salicylic acid", "text": "Chemical compound used in medicines and industry\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nSalicylic acid is an organic compound with the formula HOC6H4COOH. A colorless (or white), bitter-tasting solid, it is a precursor to and a metabolite of acetylsalicylic acid (aspirin). It is a plant hormone, and has been listed by the EPA Toxic Substances Control Act (TSCA) Chemical Substance Inventory as an experimental teratogen. The name is from Latin for willow tree, from which it was initially identified and derived. It is an ingredient in some anti-acne products. Salts and esters of salicylic acid are known as salicylates.\nUses.\nMedicine.\nSalicylic acid as a medication is commonly used to remove the outermost layer of the skin. As such, it is used to treat warts, psoriasis, acne vulgaris, ringworm, dandruff, and ichthyosis.\nSimilar to other hydroxy acids, salicylic acid is an ingredient in many skincare products for the treatment of seborrhoeic dermatitis, acne, psoriasis, calluses, corns, keratosis pilaris, acanthosis nigricans, ichthyosis, and warts.\nUses in manufacturing.\nSalicylic acid is used as a food preservative, a bactericide, and an antiseptic.\nSalicylic acid is used in the production of other pharmaceuticals, including 4-aminosalicylic acid, sandulpiride, and landetimide (via salethamide). It is also used in picric acid production.\nSalicylic acid has long been a key starting material for making acetylsalicylic acid (ASA or aspirin). ASA is prepared by the acetylation of salicylic acid with the acetyl group from acetic anhydride or acetyl chloride. ASA is the standard to which all the other non-steroidal anti-inflammatory drugs (NSAIDs) are compared. In veterinary medicine, this group of drugs is mainly used for treatment of inflammatory musculoskeletal disorders.\nBismuth subsalicylate, a salt of bismuth and salicylic acid, \"displays anti-inflammatory action (due to salicylic acid) and also acts as an antacid and mild antibiotic\". It is an active ingredient in stomach-relief aids such as Pepto-Bismol and some formulations of Kaopectate.\nOther derivatives include methyl salicylate, used as a liniment to soothe joint and muscle pain, and choline salicylate, which is used topically to relieve the pain of mouth ulcers. Aminosalicylic acid is used to induce remission in ulcerative colitis, and has been used as an antitubercular agent often administered in association with isoniazid.\nSodium salicylate is a useful phosphor in the vacuum ultraviolet spectral range, with nearly flat quantum efficiency for wavelengths between 10 and 100\u00a0nm. It fluoresces in the blue at 420\u00a0nm. It is easily prepared on a clean surface by spraying a saturated solution of the salt in methanol followed by evaporation.\nMechanism of action.\nSalicylic acid modulates COX-1 enzymatic activity to decrease the formation of pro-inflammatory prostaglandins. Salicylate may competitively inhibit prostaglandin formation.\nSalicylic acid, when applied to the skin surface, works by causing the cells of the epidermis to slough off more readily, preventing pores from clogging up, and allowing room for new cell growth. Salicylic acid inhibits the oxidation of uridine-5-diphosphoglucose (UDPG) competitively with NADH and noncompetitively with UDPG. It also competitively inhibits the transferring of glucuronyl group of uridine-5-phosphoglucuronic acid to the phenolic acceptor.\nThe wound-healing retardation action of salicylates is probably due mainly to its inhibitory action on mucopolysaccharide synthesis.\nSafety.\nIn excess, salicylates have toxic effects, which can be fatal. Toxicity is most often due to oral overdose. \nCosmetic applications of the drug pose no significant risk. Even in a worst-case use scenario in which one was using multiple salicylic acid-containing topical products, the aggregate plasma concentration of salicylic acid was well below what was permissible for acetylsalicylic acid (aspirin). Since oral aspirin (which produces much higher salicylic acid plasma concentrations than dermal salicylic acid applications) poses no significant adverse pregnancy outcomes in terms of frequency of stillbirth, birth defects or developmental delay, use of salicylic acid containing cosmetics is safe for pregnant women. Salicylic acid is present in most fruits and vegetables as for example in greatest quantities in berries and in beverages like tea.\nIn one documented case, a patient applied extreme levels of salicyate ointment topically (40% ointment, over 41% of the total skin surface), and subsequently received hemodialysis to reduce blood salicylate concentration.\nProduction and chemical reactions.\nBiosynthesis.\nSalicylic acid is biosynthesized from the amino acid phenylalanine. In \"Arabidopsis thaliana\", it can be synthesized via a phenylalanine-independent pathway.\nChemical synthesis.\nCommercial vendors prepare sodium salicylate by treating sodium phenolate (the sodium salt of phenol) with carbon dioxide at high pressure (100atm) and high temperature (115\u00b0C)\u00a0\u2013 a method known as the Kolbe-Schmitt reaction. Acidifying the product with sulfuric acid gives salicylic acid:\nAt the laboratory scale, it can also be prepared by the hydrolysis of aspirin (acetylsalicylic acid) or methyl salicylate (oil of wintergreen) with a strong acid or base; these reactions reverse those chemicals' commercial syntheses.\nReactions.\nUpon heating, salicylic acid converts to phenyl salicylate:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nFurther heating gives xanthone.\nSalicylic acid as its conjugate base is a chelating agent, with an affinity for iron(III).\nSalicylic acid slowly degrades to phenol and carbon dioxide at 200\u2013230\u00a0\u00b0C: \n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;C6H4OH(CO2H) \u2192 C6H5OH + CO2\nAll isomers of chlorosalicylic acid and of dichlorosalicylic acid are known. 5-Chlorosalicylic acid is produced by direct chlorination of salicylic acid.\nHistory.\nWillow has long been used for medicinal purposes. Dioscorides, whose writings were highly influential for more than 1,500 years, used \"Itea\" (which was possibly a species of willow) as a treatment for \"painful intestinal obstructions\", birth control, for \"those who spit blood\", to remove calluses and corns and, externally, as a \"warm pack for gout\". William Turner, in 1597, repeated this, saying that willow bark, \"being burnt to ashes, and steeped in vinegar, takes away corns and other like risings in the feet and toes\". Some of these cures may describe the action of salicylic acid, which can be derived from the salicin present in willow. It is, however, a modern myth that Hippocrates used willow as a painkiller.\nHippocrates, Galen, Pliny the Elder, and others knew that decoctions containing salicylate could ease pain and reduce fevers.\nIt was used in Europe and China to treat these conditions. This remedy is mentioned in texts from Ancient Egypt, Sumer, and Assyria.\nThe Cherokee and other Native Americans use an infusion of the bark for fever and other medicinal purposes. In 2014, archaeologists identified traces of salicylic acid on seventh-century pottery fragments found in east-central Colorado.\nEdward Stone, a vicar from Chipping Norton, Oxfordshire, England, reported in 1763 that the bark of the willow was effective in reducing a fever.\nAn extract of willow bark, called salicin, after the Latin name for the white willow (\"Salix alba\"), was isolated and named by German chemist Johann Andreas Buchner in 1828. A larger amount of the substance was isolated in 1829 by Henri Leroux, a French pharmacist. Raffaele Piria, an Italian chemist, was able to convert the substance into a sugar and a second component, which on oxidation becomes salicylic acid.\nSalicylic acid was also isolated from the herb meadowsweet (\"Filipendula ulmaria\", formerly classified as \"Spiraea ulmaria\") by German researchers in 1839. Their extract caused digestive problems such as gastric irritation, bleeding, diarrhea, and even death when consumed in high doses.\nIn 1874 the Scottish physician Thomas MacLagan experimented with salicin as a treatment for acute rheumatism, with considerable success, as he reported in \"The Lancet\" in 1876. Meanwhile, German scientists tried sodium salicylate with less success and more severe side effects.\nIn 1979, salicylates were found to be involved in induced defenses of tobacco against tobacco mosaic virus. In 1987, salicylic acid was identified as the long-sought signal that causes thermogenic plants, such as the voodoo lily, \"Sauromatum guttatum\", to produce heat.\nDietary sources.\nSalicylic acid occurs in plants as free salicylic acid and its carboxylated esters and phenolic glycosides. Several studies suggest that humans metabolize salicylic acid in measurable quantities from these plants. High-salicylate beverages and foods include beer, coffee, tea, numerous fruits and vegetables, sweet potato, nuts, and olive oil. Meat, poultry, fish, eggs, dairy products, sugar, breads and cereals have low salicylate content.\nSome people with sensitivity to dietary salicylates may have symptoms of allergic reaction, such as bronchial asthma, rhinitis, gastrointestinal disorders, or diarrhea, so may need to adopt a low-salicylate diet.\nPlant hormone.\nSalicylic acid is a phenolic phytohormone, and is found in plants with roles in plant growth and development, photosynthesis, transpiration, and ion uptake and transport. Salicylic acid is involved in endogenous signaling, mediating plant defense against pathogens. It plays a role in the resistance to pathogens (i.e. systemic acquired resistance) by inducing the production of pathogenesis-related proteins and other defensive metabolites. SA's defense signaling role is most clearly demonstrated by experiments which do away with it: Delaney et al. 1994, Gaffney et al. 1993, Lawton et al. 1995, and Vernooij et al. 1994 each use \"Nicotiana tabacum\" or \"Arabidopsis\" expressing \"nahG\", for salicylate hydroxylase. Pathogen inoculation did not produce the customarily high SA levels, SAR was not produced, and no pathogenesis-related (PR) genes were expressed in systemic leaves. Indeed, the subjects were more susceptible to virulent \u2013 and even normally avirulent \u2013 pathogens.\nExogenously, salicylic acid can aid plant development via enhanced seed germination, bud flowering, and fruit ripening, though too high of a concentration of salicylic acid can negatively regulate these developmental processes.\nThe volatile methyl ester of salicylic acid, methyl salicylate, can also diffuse through the air, facilitating plant-plant communication. Methyl salicylate is taken up by the stomata of the nearby plant, where it can induce an immune response after being converted back to salicylic acid.\nSignal transduction.\nA number of proteins have been identified that interact with SA in plants, especially salicylic acid binding proteins (SABPs) and the NPR genes (nonexpressor of pathogenesis-related genes), which are putative receptors.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28144", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=28144", "title": "Seaborgium", "text": "element with atomic number 106 (Sg)\nSeaborgium is a synthetic chemical element; it has symbol Sg and atomic number 106. It is named after the American nuclear chemist Glenn T. Seaborg. As a synthetic element, it can be created in a laboratory but is not found in nature. It is also radioactive; the most stable known isotopes have half-lives on the order of several minutes.\nIn the periodic table of the elements, it is a d-block transactinide element. It is a member of the 7th period and belongs to the group 6 elements as the fourth member of the 6d series of transition metals. Chemistry experiments have confirmed that seaborgium behaves as the heavier homologue to tungsten in group 6. The chemical properties of seaborgium are characterized only partly, but they compare well with the chemistry of the other group 6 elements.\nIn 1974, a few atoms of seaborgium were produced in laboratories in the Soviet Union and in the United States. The priority of the discovery and therefore the naming of the element was disputed between Soviet and American scientists, and it was not until 1997 that the International Union of Pure and Applied Chemistry (IUPAC) established seaborgium as the official name for the element. It is one of only two elements named after a living person at the time of naming, the other being oganesson, element 118.\nHistory.\nFollowing claims of the observation of elements 104 and 105 in 1970 by Albert Ghiorso et al. at the Lawrence Livermore National Laboratory, a search for element 106 using oxygen-18 projectiles and the previously used californium-249 target was conducted. Several 9.1 MeV alpha decays were reported and are now thought to originate from element 106, though this was not confirmed at the time. In 1972, the HILAC accelerator received equipment upgrades, preventing the team from repeating the experiment, and data analysis was not done during the shutdown. This reaction was tried again several years later, in 1974, and the Berkeley team realized that their new data agreed with their 1971 data, to the astonishment of Ghiorso. Hence, element 106 could have actually been discovered in 1971 if the original data was analyzed more carefully.\nTwo groups claimed discovery of the element. Evidence of element 106 was first reported in 1974 by a Russian research team in Dubna led by Yuri Oganessian, in which targets of lead-208 and lead-207 were bombarded with accelerated ions of chromium-54. In total, fifty-one spontaneous fission events were observed with a half-life between four and ten milliseconds. After having ruled out nucleon transfer reactions as a cause for these activities, the team concluded that the most likely cause of the activities was the spontaneous fission of isotopes of element 106. The isotope in question was first suggested to be seaborgium-259, but was later corrected to seaborgium-260.\n[&lt;noinclude /&gt;[lead-208|Pb]&lt;noinclude /&gt;] + [&lt;noinclude /&gt;[chromium-54|Cr]&lt;noinclude /&gt;] \u2192 [&lt;noinclude /&gt;[seaborgium-260|Sg]&lt;noinclude /&gt;] + 2 \n[&lt;noinclude /&gt;[lead-207|Pb]&lt;noinclude /&gt;] + Cr \u2192 Sg + \nA few months later in 1974, researchers including Glenn T. Seaborg, Carol Alonso and Albert Ghiorso at the University of California, Berkeley, and E. Kenneth Hulet from the Lawrence Livermore National Laboratory, also synthesized the element by bombarding a californium-249 target with oxygen-18 ions, using equipment similar to that which had been used for the synthesis of element 104 five years earlier, observing at least seventy alpha decays, seemingly from the isotope seaborgium-263m with a half-life of seconds. The alpha daughter rutherfordium-259 and granddaughter nobelium-255 had previously been synthesised and the properties observed here matched with those previously known, as did the intensity of their production. The cross-section of the reaction observed, 0.3\u00a0nanobarns, also agreed well with theoretical predictions. These bolstered the assignment of the alpha decay events to seaborgium-263m.\n[&lt;noinclude /&gt;[californium-249|Cf]&lt;noinclude /&gt;] + [&lt;noinclude /&gt;[oxygen-18|O]&lt;noinclude /&gt;] \u2192 [&lt;noinclude /&gt;[seaborgium-263m|Sg]&lt;noinclude /&gt;] + 4 \u2192 [&lt;noinclude /&gt;[rutherfordium-259|Rf]&lt;noinclude /&gt;] + \u2192 [&lt;noinclude /&gt;[nobelium-255|No]&lt;noinclude /&gt;] + \nA dispute thus arose from the initial competing claims of discovery, though unlike the case of the synthetic elements up to element 105, neither team of discoverers chose to announce proposed names for the new elements, thus averting an element naming controversy temporarily. The dispute on discovery, however, dragged on until 1992, when the IUPAC/IUPAP Transfermium Working Group (TWG), formed to put an end to the controversy by making conclusions regarding discovery claims for elements 101 to 112, concluded that the Soviet synthesis of seaborgium-260 was not convincing enough, \"lacking as it is in yield curves and angular selection results\", whereas the American synthesis of seaborgium-263 was convincing due to its being firmly anchored to known daughter nuclei. As such, the TWG recognised the Berkeley team as official discoverers in their 1993 report.\nSeaborg had previously suggested to the TWG that if Berkeley was recognised as the official discoverer of elements 104 and 105, they might propose the name \"kurchatovium\" (symbol Kt) for element 106 to honour the Dubna team, which had proposed this name for element 104 after Igor Kurchatov, the former head of the Soviet nuclear research programme. However, due to the worsening relations between the competing teams after the publication of the TWG report (because the Berkeley team vehemently disagreed with the TWG's conclusions, especially regarding element 104), this proposal was dropped from consideration by the Berkeley team. After being recognized as official discoverers, the Berkeley team started deciding on a name in earnest:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a\nSeaborg's son Eric remembered the naming process as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a\nThe name \"seaborgium\" and symbol \"Sg\" were announced at the 207th national meeting of the American Chemical Society in March 1994 by Kenneth Hulet, one of the co-discovers. However, IUPAC resolved in August 1994 that an element could not be named after a living person, and Seaborg was still alive at the time. Thus, in September 1994, IUPAC recommended a set of names in which the names proposed by the three laboratories (the third being the GSI Helmholtz Centre for Heavy Ion Research in Darmstadt, Germany) with competing claims to the discovery for elements 104 to 109 were shifted to various other elements, in which \"rutherfordium\" (Rf), the Berkeley proposal for element 104, was shifted to element 106, with \"seaborgium\" being dropped entirely as a name.\nThis decision ignited a firestorm of worldwide protest for disregarding the historic discoverer's right to name new elements, and against the new retroactive rule against naming elements after living persons; the American Chemical Society stood firmly behind the name \"seaborgium\" for element 106, together with all the other American and German naming proposals for elements 104 to 109, approving these names for its journals in defiance of IUPAC. At first, IUPAC defended itself, with an American member of its committee writing: \"Discoverers don't have a right to name an element. They have a right to suggest a name. And, of course, we didn't infringe on that at all.\" However, Seaborg responded:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a\nBowing to public pressure, IUPAC proposed a different compromise in August 1995, in which the name \"seaborgium\" was reinstated for element 106 in exchange for the removal of all but one of the other American proposals, which met an even worse response. Finally, IUPAC rescinded these previous compromises and made a final, new recommendation in August 1997, in which the American and German proposals for elements 104 to 109 were all adopted, including \"seaborgium\" for element 106, with the single exception of element 105, named \"dubnium\" to recognise the contributions of the Dubna team to the experimental procedures of transactinide synthesis. This list was finally accepted by the American Chemical Society, which wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In the interest of international harmony, the Committee reluctantly accepted the name 'dubnium' for element 105 in place of 'hahnium' [the American proposal], which has had long-standing use in literature. We are pleased to note that 'seaborgium' is now the internationally approved name for element 106.\u2014\u200a\nSeaborg commented regarding the naming:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I am, needless to say, proud that U.S. chemists recommended that element 106, which is placed under tungsten (74), be called 'seaborgium.' I was looking forward to the day when chemical investigators will refer to such compounds as seaborgous chloride, seaborgic nitrate, and perhaps, sodium seaborgate.This is the greatest honor ever bestowed upon me\u2014even better, I think, than winning the Nobel Prize. Future students of chemistry, in learning about the periodic table, may have reason to ask why the element was named for me, and thereby learn more about my work.\u2014\u200a\nSeaborg died a year and a half later, on 25 February 1999, at the age of 86.\nIsotopes.\nSuperheavy elements such as seaborgium are produced by bombarding lighter elements in particle accelerators that induces fusion reactions. Whereas most of the isotopes of seaborgium can be synthesized directly this way, some heavier ones have only been observed as decay products of elements with higher atomic numbers.\nDepending on the energies involved, fusion reactions that generate superheavy elements are separated into \"hot\" and \"cold\". In hot fusion reactions, very light, high-energy projectiles are accelerated toward very heavy targets (actinides), giving rise to compound nuclei at high excitation energy (~40\u201350\u00a0MeV) that may either fission or evaporate several (3 to 5) neutrons. In cold fusion reactions, the produced fused nuclei have a relatively low excitation energy (~10\u201320\u00a0MeV), which decreases the probability that these products will undergo fission reactions. As the fused nuclei cool to the ground state, they require emission of only one or two neutrons, and thus, allows for the generation of more neutron-rich products. The latter is a distinct concept from that of where nuclear fusion claimed to be achieved at room temperature conditions (see cold fusion).\nSeaborgium has no stable or naturally occurring isotopes. Several radioactive isotopes have been synthesized in the laboratory, either by fusing two atoms or by observing the decay of heavier elements. Fourteen different isotopes of seaborgium have been reported with mass numbers 257\u2013269 and 271, four of which, seaborgium-261, \u2212263, \u2212265, and \u2212267, have known metastable states. All of these decay only through alpha decay and spontaneous fission, with the single exception of seaborgium-261 that can also undergo electron capture to dubnium-261.\nThere is a trend toward increasing half-lives for the heavier isotopes, though even\u2013odd isotopes are generally more stable than their neighboring even\u2013even isotopes, because the odd neutron leads to increased hindrance of spontaneous fission; among known seaborgium isotopes, alpha decay is the predominant decay mode in even\u2013odd nuclei whereas fission dominates in even\u2013even nuclei. Three of the heaviest known isotopes, 267Sg, 269Sg, and 271Sg, are also the longest-lived, having half-lives on the order of several minutes. Some other isotopes in this region are predicted to have comparable or even longer half-lives. Additionally, 263Sg, 265Sg, 265mSg, and 268Sg have half-lives measured in seconds. All the remaining isotopes have half-lives measured in milliseconds, with the exception of the shortest-lived isotope, 261mSg, with a half-life of only 9.3\u00a0microseconds.\nThe proton-rich isotopes from 257Sg to 261Sg were directly produced by cold fusion; all heavier isotopes were produced from the repeated alpha decay of the heavier elements hassium, darmstadtium, and flerovium, with the exceptions of the isotopes 263mSg, 264Sg, 265Sg, and 265mSg, which were directly produced by hot fusion through irradiation of actinide targets.\nPredicted properties.\nVery few properties of seaborgium or its compounds have been measured; this is due to its extremely limited and expensive production and the fact that seaborgium (and its parents) decays very quickly. A few singular chemistry-related properties have been measured, but properties of seaborgium metal remain unknown and only predictions are available.\nPhysical.\nSeaborgium is expected to be a solid under normal conditions and assume a body-centered cubic crystal structure, similar to its lighter congener tungsten. Early predictions estimated that it should be a very heavy metal with density around 35.0\u00a0g/cm3, but calculations in 2011 and 2013 predicted a somewhat lower value of 23\u201324\u00a0g/cm3.\nChemical.\nSeaborgium is the fourth member of the 6d series of transition metals and the heaviest member of group 6 in the periodic table, below chromium, molybdenum, and tungsten. All the members of the group form a diversity of oxoanions. They readily portray their group oxidation state of +6, although this is highly oxidising in the case of chromium, and this state becomes more and more stable to reduction as the group is descended: indeed, tungsten is the last of the 5d transition metals where all four 5d electrons participate in metallic bonding. As such, seaborgium should have +6 as its most stable oxidation state, both in the gas phase and in aqueous solution, and this is the only positive oxidation state that is experimentally known for it; the +5 and +4 states should be less stable, and the +3 state, the most common for chromium, would be the least stable for seaborgium.\nThis stabilisation of the highest oxidation state occurs in the early 6d elements because of the similarity between the energies of the 6d and 7s orbitals, since the 7s orbitals are relativistically stabilised and the 6d orbitals are relativistically destabilised. This effect is so large in the seventh period that seaborgium is expected to lose its 6d electrons before its 7s electrons (Sg, [Rn]5f146d47s2; Sg+, [Rn]5f146d37s2; Sg2+, [Rn]5f146d37s1; Sg4+, [Rn]5f146d2; Sg6+, [Rn]5f14). Because of the great destabilisation of the 7s orbital, SgIV should be even more unstable than WIV and should be very readily oxidised to SgVI. The predicted ionic radius of the hexacoordinate Sg6+ ion is 65\u00a0pm, while the predicted atomic radius of seaborgium is 128\u00a0pm. Nevertheless, the stability of the highest oxidation state is still expected to decrease as LrIII &gt; RfIV &gt; DbV &gt; SgVI. Some predicted standard reduction potentials for seaborgium ions in aqueous acidic solution are as follows:\nSeaborgium should form a very volatile hexafluoride (SgF6) as well as a moderately volatile hexachloride (SgCl6), pentachloride (SgCl5), and oxychlorides SgO2Cl2 and SgOCl4. SgO2Cl2 is expected to be the most stable of the seaborgium oxychlorides and to be the least volatile of the group 6 oxychlorides, with the sequence MoO2Cl2 &gt; WO2Cl2 &gt; SgO2Cl2. The volatile seaborgium(VI) compounds SgCl6 and SgOCl4 are expected to be unstable to decomposition to seaborgium(V) compounds at high temperatures, analogous to MoCl6 and MoOCl4; this should not happen for SgO2Cl2 due to the much higher energy gap between the highest occupied and lowest unoccupied molecular orbitals, despite the similar Sg\u2013Cl bond strengths (similarly to molybdenum and tungsten).\nMolybdenum and tungsten are very similar to each other and show important differences to the smaller chromium, and seaborgium is expected to follow the chemistry of tungsten and molybdenum quite closely, forming an even greater variety of oxoanions, the simplest among them being seaborgate, SgO42-, which would form from the rapid hydrolysis of Sg(H2O)66+, although this would take place less readily than with molybdenum and tungsten as expected from seaborgium's greater size. Seaborgium should hydrolyse less readily than tungsten in hydrofluoric acid at low concentrations, but more readily at high concentrations, also forming complexes such as SgO3F\u2212 and SgOF5-: complex formation competes with hydrolysis in hydrofluoric acid.\nExperimental chemistry.\nExperimental chemical investigation of seaborgium has been hampered due to the need to produce it one atom at a time, its short half-life, and the resulting necessary harshness of the experimental conditions. The isotope 265Sg and its isomer 265mSg are advantageous for radiochemistry: they are produced in the 248Cm(22Ne,5n) reaction.\nIn the first experimental chemical studies of seaborgium in 1995 and 1996, seaborgium atoms were produced in the reaction 248Cm(22Ne,4n)266Sg, thermalised, and reacted with an O2/HCl mixture. The adsorption properties of the resulting oxychloride were measured and compared with those of molybdenum and tungsten compounds. The results indicated that seaborgium formed a volatile oxychloride akin to those of the other group 6 elements, and confirmed the decreasing trend of oxychloride volatility down group 6:\nSg + O2 + 2 HCl \u2192 SgO2Cl2 + H2\nIn 2001, a team continued the study of the gas phase chemistry of seaborgium by reacting the element with O2 in a H2O environment. In a manner similar to the formation of the oxychloride, the results of the experiment indicated the formation of seaborgium oxide hydroxide, a reaction well known among the lighter group 6 homologues as well as the pseudohomologue uranium.\n2 Sg + 3 O2 \u2192 2 SgO3\nSgO3 + H2O \u2192 SgO2(OH)2\nPredictions on the aqueous chemistry of seaborgium have largely been confirmed. In experiments conducted in 1997 and 1998, seaborgium was eluted from cation-exchange resin using a HNO3/HF solution, most likely as neutral SgO2F2 or the anionic complex ion [SgO2F3]\u2212 rather than SgO42-. In contrast, in 0.1 M nitric acid, seaborgium does not elute, unlike molybdenum and tungsten, indicating that the hydrolysis of [Sg(H2O)6]6+ only proceeds as far as the cationic complex [Sg(OH)4(H2O)]2+ or [SgO(OH)3(H2O)2]+, while that of molybdenum and tungsten proceed to neutral [MO2(OH)2].\nThe only other oxidation state known for seaborgium other than the group oxidation state of +6 is the zero oxidation state. Similarly to its three lighter congeners, forming chromium hexacarbonyl, molybdenum hexacarbonyl, and tungsten hexacarbonyl, seaborgium has been shown in 2014 to also form seaborgium hexacarbonyl, Sg(CO)6. Like its molybdenum and tungsten homologues, seaborgium hexacarbonyl is a volatile compound that reacts readily with silicon dioxide.\nAbsence in nature.\nSearches for long-lived primordial nuclides of seaborgium in nature have all yielded negative results. One 2022 study estimated the concentration of seaborgium atoms in natural tungsten (its chemical homolog) is less than atom(Sg)/atom(W).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28145", "revid": "892079", "url": "https://en.wikipedia.org/wiki?curid=28145", "title": "September 15", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearSeptember 15 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28146", "revid": "35325894", "url": "https://en.wikipedia.org/wiki?curid=28146", "title": "September 18", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearSeptember 18 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28147", "revid": "24013162", "url": "https://en.wikipedia.org/wiki?curid=28147", "title": "September 19", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearSeptember 19 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28148", "revid": "6326132", "url": "https://en.wikipedia.org/wiki?curid=28148", "title": "September 20", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearSeptember 20 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28149", "revid": "50459348", "url": "https://en.wikipedia.org/wiki?curid=28149", "title": "Serpens", "text": "Constellation split into two non-contiguous parts\nSerpens () is a constellation in the northern celestial hemisphere. One of the 48 constellations listed by the 2nd-century astronomer Ptolemy, it remains one of the 88 modern constellations designated by the International Astronomical Union. It is unique among the modern constellations in being split into two non-contiguous parts, Serpens Caput (Serpent Head) to the west and Serpens Cauda (Serpent Tail) to the east. Between these two halves lies the constellation of Ophiuchus, the \"Serpent-Bearer\". In figurative representations, the body of the serpent is represented as passing behind Ophiuchus between Mu Serpentis in \"Serpens Caput\" and Nu Serpentis in \"Serpens Cauda\".\nThe brightest star in Serpens is the red giant star Alpha Serpentis, or Unukalhai, in Serpens Caput, with an apparent magnitude of 2.63. Also located in Serpens Caput are the naked-eye globular cluster Messier 5 and the naked-eye variables R Serpentis and Tau4 Serpentis. Notable extragalactic objects include Seyfert's Sextet, one of the densest galaxy clusters known; Arp 220, the prototypical ultraluminous infrared galaxy; and Hoag's Object, the most famous of the very rare class of galaxies known as ring galaxies.\nPart of the Milky Way's galactic plane passes through Serpens Cauda, which is therefore rich in galactic deep-sky objects, such as the Eagle Nebula (IC 4703) and its associated star cluster Messier 16. The nebula measures 70 light-years by 50 light-years and contains the Pillars of Creation, three dust clouds that became famous for the image taken by the Hubble Space Telescope. Other striking objects include the Red Square Nebula, one of the few objects in astronomy to take on a square shape; and Westerhout 40, a massive nearby star-forming region consisting of a molecular cloud and an H II region.\nHistory.\nIn Greek mythology, Serpens represents a snake held by the healer Asclepius. Represented in the sky by the constellation Ophiuchus, Asclepius once killed a snake, but the animal was subsequently resurrected after a second snake placed a revival herb on it before its death. As snakes shed their skin every year, they were known as the symbol of rebirth in ancient Greek society, and legend says Asclepius would revive dead humans using the same technique he witnessed. Although this is likely the logic for Serpens' presence with Ophiuchus, the true reason is still not fully known. Sometimes, Serpens was depicted as coiling around Ophiuchus, but the majority of atlases showed Serpens passing either behind Ophiuchus' body or between his legs.\nIn some ancient atlases, the constellations Serpens and Ophiuchus were depicted as two separate constellations, although more often they were shown as a single constellation. One notable figure to depict Serpens separately was Johann Bayer; thus, Serpens' stars are cataloged with separate Bayer designations from those of Ophiuchus. When Eug\u00e8ne Delporte established modern constellation boundaries in the 1920s, he elected to depict the two separately. However, this posed the problem of how to disentangle the two constellations, with Deporte deciding to split Serpens into two areas\u2014the head and the tail\u2014separated by the continuous Ophiuchus. These two areas became known as Serpens Caput and Serpens Cauda, \"caput\" being the Latin word for head and \"cauda\" the Latin word for tail.\nIn Chinese astronomy, most of the stars of Serpens represented part of a wall surrounding a marketplace, known as Tianshi, which was in Ophiuchus and part of Hercules. Serpens also contains a few Chinese constellations. Two stars in the tail represented part of Shilou, the tower with the market office. Another star in the tail represented Liesi, jewel shops. One star in the head (Mu Serpentis) marked Tianru, the crown prince's wet nurse, or sometimes rain.\nThere were two \"serpent\" constellations in Babylonian astronomy, known as Mu\u0161\u1e2bu\u0161\u0161u and Ba\u0161mu. It appears that Mu\u0161\u1e2bu\u0161\u0161u was depicted as a hybrid of a dragon, a lion and a bird, and loosely corresponded to Hydra. Ba\u0161mu was a horned serpent (cf. Ningishzida) and roughly corresponds to the \u1f4c\u03c6\u03b9\u03c2 constellation of Eudoxus of Cnidus on which the \u1f4c\u03c6\u03b9\u03c2 (\"Serpens\") of Ptolemy is based.\nCharacteristics.\nSerpens is the only one of the 88 modern constellations to be split into two disconnected regions in the sky: \"Serpens Caput\" (the head) and \"Serpens Cauda\" (the tail). The constellation is also unusual in that it depends on another constellation for context; specifically, it is being held by the Serpent Bearer Ophiuchus.\nSerpens Caput is bordered by Libra to the south, Virgo and Bo\u00f6tes to the west, Corona Borealis to the north, and Ophiuchus and Hercules to the east; Serpens Cauda is bordered by Sagittarius to the south, Scutum and Aquila to the east, and Ophiuchus to the north and west. Covering 636.9 square degrees total, it ranks 23rd of the 88 constellations in size. It appears prominently in both the northern and southern skies during the Northern Hemisphere's summer. Its main asterism consists of 11 stars, and 108 stars in total are brighter than magnitude 6.5, the traditional limit for naked-eye visibility.\nSerpens Caput's boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a 10-sided polygon, while Serpens Cauda's are defined by a 22-sided polygon. In the equatorial coordinate system, the right ascension coordinates of Serpens Caput's borders lie between 15h 10.4m and 16h 22.5m, while the declination coordinates are between \u00b0 and \u00b0. Serpens Cauda's boundaries lie between right ascensions of 17h 16.9m and 18h 58.3m and declinations of \u00b0 and \u00b0. The International Astronomical Union (IAU) adopted the three-letter abbreviation \"Ser\" for the constellation in 1922.\nFeatures.\nStars.\nHead stars.\nMarking the heart of the serpent is the constellation's brightest star, Alpha Serpentis. Traditionally called Unukalhai, is a red giant of spectral type K2III located approximately 23 parsecs distant with a visual magnitude of 2.630 \u00b1 0.009, meaning it can easily be seen with the naked eye even in areas with substantial light pollution. A faint companion is in orbit around the red giant star, although it is not visible to the naked eye. Situated near Alpha is Lambda Serpentis, a magnitude 4.42 \u00b1 0.05 star rather similar to the Sun positioned only 12 parsecs away. It has an exoplanet orbiting around it. Another solar analog in Serpens is the primary of Psi Serpentis, a binary star located slightly further away at approximately 14 parsecs.\nBeta (the proper name is Zhou since 5 December 2024), Gamma, and Iota Serpentis form a distinctive triangular shape marking the head of the snake, with Kappa Serpentis (the proper name is Gudja) being roughly midway between Gamma and Iota. The brightest of the four with an apparent magnitude of roughly 3.67, Beta Serpentis is a white main-sequence star roughly 160 parsecs distant. It is likely that a nearby 10th-magnitude star is physically associated with Beta, although it is not certain. The Mira variable R Serpentis, situated between Beta and Gamma, is visible to the naked eye at its maximum of 5th-magnitude, but, typical of Mira variables, it can fade to below magnitude 14. Gamma Serpentis itself is an F-type subgiant located only 11 parsecs distant and thus is quite bright, being of magnitude 3.84 \u00b1 0.05. The star is known to show solar-like oscillations. Iota Serpentis is a binary star system.\nDelta Serpentis, forming part of the body of the snake between the heart and the head, is a multiple star system positioned around 70 parsecs from Earth. Consisting of four stars, the system has a total apparent magnitude of 3.79 as viewed from Earth, although two of the stars, with a combined apparent magnitude of 3.80, provide nearly all the light. The primary, a white subgiant, is a Delta Scuti variable with an average apparent magnitude of 4.23. Positioned very near Delta, both in the night sky and likely in actual space at an estimated distance of around 70 parsecs, is the barium star 16 Serpentis. Another notable variable star visible to the naked eye is Chi Serpentis, an Alpha\u00b2 Canum Venaticorum variable situated midway between Delta and Beta which varies from its median brightness of 5.33 by 0.03 magnitudes over a period of approximately 1.5 days. Chi Serpentis is a chemically peculiar star.\nThe two stars in Serpens Caput that form part of the Snake's body below the heart are Epsilon and Mu Serpentis, both third-magnitude A-type main-sequence stars. Both have a peculiarity: Epsilon is an Am star, while Mu is a binary. Located slightly northwest of Mu is 36 Serpentis, another A-type main-sequence star. This star also has a peculiarity; it is a binary with the primary component being a Lambda Bo\u00f6tis star, meaning that it has solar-like amounts of carbon, nitrogen, and oxygen, while containing very low amounts of iron peak elements. The secondary star has also been a source of X-ray emissions. 25 Serpentis, positioned a few degrees northeast of Mu Serpentis, is a spectroscopic binary consisting of a hot B-type giant and an A-type main-sequence star. The primary is a slowly pulsating B star, which causes the system to vary by 0.03 magnitudes.\nSerpens Caput contains many RR Lyrae variables, although most are too faint to be seen without professional photography. The brightest is VY Serpentis, only of 10th magnitude. This star's period has been increasing by approximately 1.2 seconds per century. A variable star of a different kind is Tau4 Serpentis, a cool red giant that pulsates between magnitudes 5.89 and 7.07 in 87 days. This star has been found to display an inverse P Cygni profile, where cold infalling gas on to the star creates redshifted hydrogen absorption lines next to the normal emission lines.\nSeveral stars in Serpens have been found to have planets. The brightest, Omega Serpentis, located between Epsilon and Mu, is an orange giant with a planet of at least 1.7 Jupiter-masses. NN Serpentis, an eclipsing post-common-envelope binary consisting of a white dwarf and a red dwarf, is very likely to have two planets causing variations in the period of the eclipses. Although it does not have a planet, the solar analog HD 137510 has been found to have a brown dwarf companion within the brown-dwarf desert.\nPSR B1534+11 is a system consisting of two neutron stars orbiting each other, one of which is a pulsar with a period of 37.9 milliseconds. Situated approximately 1000 parsecs distant, the system was used to test Albert Einstein's theory of general relativity, validating the system's relativistic parameters to within 0.2% of values predicted by the theory. The X-ray emission from the system has been found to be present when the non-pulsar star intersects the equatorial pulsar wind of the pulsar, and the system's orbit has been found to vary slightly.\nTail stars.\nThe brightest star in the tail, Eta Serpentis, is similar to Alpha Serpentis' primary in that it is a red giant of spectral class K. This star, however, is known to exhibit solar-like oscillations over a period of approximately 2.16 hours. The other two stars in Serpens Cauda forming its asterism are Theta and Xi Serpentis. Xi, where the asterism crosses over to Mu Serpentis in the head, is a triple star system located approximately 105 parsecs away. Two of the stars, with a combined apparent magnitude of around 3.5, form a spectroscopic binary with an angular separation of only 2.2 milliarcseconds, and thus cannot be resolved with modern equipment. The primary is a white giant with an excess of strontium. Theta, forming the tip of the tail, is also a multiple system, consisting of two A-type main-sequence stars with a combined apparent magnitude of around 4.1 separated by almost half an arcminute. There is also a third G-type star with a mass and radius similar to that of the Sun.\nLying near the boundary with Ophiuchus are Zeta, Nu, and Omicron Serpentis. All three are 4th-magnitude main-sequence stars, with Nu and Omicron being of spectral type A and Zeta being of spectral type F. Nu is a single star with a 9th-magnitude visual companion, while Omicron is a Delta Scuti variable with amplitude variations of 0.01 magnitudes. In 1909, the symbiotic nova RT Serpentis appeared near Omicron, although it only reached a maximum magnitude of 10.\nThe star system 59 Serpentis, also known as d Serpentis, is a triple star system consisting of a spectroscopic binary containing an A-type star and an orange giant and an orange giant secondary. The system shows irregular variations in brightness between magnitudes 5.17 and 5.2. In 1970, the nova FH Serpentis appeared just slightly north of 59 Serpentis, reaching a maximum brightness of 4.5. Also near 59 Serpentis in the Serpens Cloud are several Orion variables. MWC 297 is a Herbig Be star that in 1994 exhibited a large X-ray flare and increased in X-ray luminosity by five times before returning to the quiescent state. The star also appears to possess a circumstellar disk. Another Orion variable in the region is VV Serpentis, a Herbig Ae star that has been found to exhibit Delta Scuti pulsations. VV Serpentis has also, like MWC 297, been found to have a dusty disk surrounding it, and is also a UX Orionis star, meaning that it shows irregular variations in its brightness.\nThe star HR 6958, also known as MV Serpentis, is an Alpha2 Canum Venaticorum variable that is faintly visible to the naked eye. The star's metal abundance is ten times higher than the Sun for most metals at the iron peak and up to 1,000 times more for heavier elements. It has also been found to contain excess silicon. Barely visible to the naked eye is HD 172365, a likely post-blue straggler in the open cluster IC 4756 that contains a large excess of lithium. HD 172189, also located in IC 4756, is an Algol variable eclipsing binary with a 5.70 day period. The primary star in the system is also a Delta Scuti variable, undergoing multiple pulsation frequencies, which, combined with the eclipses, causes the system to vary by around a tenth of a magnitude.\nAs the galactic plane passes through it, Serpens Cauda contains many massive OB stars. Several of these are visible to the naked eye, such as NW Serpentis, an early Be star that has been found to be somewhat variable. The variability is interesting; according to one study, it could be one of the first discovered hybrids between Beta Cephei variables and slowly pulsating B stars. Although not visible to the naked eye, HD 167971 (MY Serpentis) is a Beta Lyrae variable triple system consisting of three very hot O-type stars. A member of the cluster NGC 6604, the two eclipsing stars are both blue giants, with one being of the very early spectral type O7.5III. The remaining star is either a blue giant or supergiant of a late O or early B spectral type. Also an eclipsing binary, the HD 166734 system consists of two O-type blue supergiants in orbit around each other. Less extreme in terms of mass and temperature is HD 161701, a spectroscopic binary consisting of a B-type primary and an Ap secondary, although it is the only known spectroscopic binary to consist of a star with excess of mercury and manganese and an Ap star.\nSouth of the Eagle Nebula on the border with Sagittarius is the eclipsing binary W Serpentis, whose primary is a white giant that is interacting with the secondary. The system has been found to contain an accretion disk, and was one of the first discovered Serpentids, which are eclipsing binaries containing exceptionally strong far-ultraviolet spectral lines. It is suspected that such Serpentids are in an earlier evolutionary phase, and will evolve first into double periodic variables and then classical Algol variables. Also near the Eagle Nebula is the eclipsing Wolf\u2013Rayet binary CV Serpentis, consisting of a Wolf\u2013Rayet star and a hot O-type subgiant. The system is surrounded by a ring-shaped nebula, likely formed during the Wolf\u2013Rayet phase of the primary. The eclipses of the system vary erratically, and although there are two theories as to why, neither of them is completely consistent with current understanding of stars.\nSerpens Cauda contains a few X-ray binaries. One of these, GX 17+2, is a low-mass X-ray binary consisting of a neutron star and, as in all low-mass X-ray binaries, a low-mass star. The system has been classified as a Sco-like Z source, meaning that its accretion is near the Eddington limit. The system has also been found to approximately every 3 days brighten by around 3.5 K-band magnitudes, possibly due to the presence of a synchrotron jet. Another low-mass X-ray binary, Serpens X-1, undergoes occasional X-ray bursts. One in particular lasted nearly four hours, possibly explained by the burning of carbon in \"a heavy element ocean\".\n\u03a6 332 (Finsen 332) is a tiny and difficult double-double star at 18:45 / +5\u00b030', named Tweedledee and Tweedledum by South African astronomer William Stephen Finsen, who was struck by the nearly identical position angles and separations at the time of his 1953 discovery. Gliese 710 is a star that is expected to pass very close to the Solar System in around 1.29 million years.\nDeep-sky objects.\nHead objects.\nAs the galactic plane does not pass through this part of Serpens, a view to many galaxies beyond it is possible. However, a few structures of the Milky Way Galaxy are present in Serpens Caput, such as Messier 5, a globular cluster positioned approximately 8\u00b0 southwest of \u03b1 Serpentis, next to the star 5 Serpentis. Barely visible to the naked eye under good conditions, and is located approximately 25,000\u00a0ly distant. Messier 5 contains a large number of known RR Lyrae variable stars, and is receding from us at over 50\u00a0km/s. The cluster contains two millisecond pulsars, one of which is in a binary, allowing the proper motion of the cluster to be measured. The binary could help our understanding of neutron degenerate matter; the current median mass, if confirmed, would exclude any \"soft\" equation of state for such matter. The cluster has been used to test for magnetic dipole moments in neutrinos, which could shed light on some hypothetical particles such as the axion. The brightest stars in Messier 5 are around magnitude 10.6, and the globular cluster was first observed by William Herschel in 1791.\nAnother globular cluster is Palomar 5, found just south of Messier 5. Many stars are leaving this globular cluster due to the Milky Way's gravity, forming a tidal tail over 30000 light-years long. It is over 11 billion years old. It has also been flattened and distorted by tidal effects.\nThe L134/L183 is a dark nebula complex that, along with a third cloud, is likely formed by fragments of a single original cloud located 36 degrees away from the galactic plane, a large distance for dark nebulae. The entire complex is thought to be around 140 parsecs distant. L183, also referred to as L134N, is home to several infrared sources, indicating pre-stellar sources thought to present the first known observation of the contraction phase between cloud cores and prestellar cores. The core is split into three regions, with a combined mass of around 25 solar masses.\nOutside of the Milky Way, there are no bright deep-sky objects for amateur astronomers in Serpens Caput, with nothing else above 10th magnitude. The brightest is NGC 5962, a spiral galaxy positioned around 28 megaparsecs distant with an apparent magnitude of 11.34. Two supernovae have been observed in the galaxy, and NGC 5962 has two satellite galaxies. Slightly fainter is NGC 5921, a barred spiral galaxy with a LINER-type active galactic nucleus situated somewhat closer at a distance of 21 megaparsecs. A type II supernova was observed in this galaxy in 2001 and was designated SN 2001X. Fainter still are the spirals NGC 5964 and NGC 6118, with the latter being host to the supernova SN 2004dk.\nHoag's Object, located 600 million light-years from Earth, is a member of the very rare class of galaxies known as ring galaxies. The outer ring is largely composed of young blue stars while the core is made up of older yellow stars. The predominant theory regarding its formation is that the progenitor galaxy was a barred spiral galaxy whose arms had velocities too great to keep the galaxy's coherence and therefore detached. Arp 220 is another unusual galaxy in Serpens. The prototypical ultraluminous infrared galaxy, Arp 220 is somewhat closer than Hoag's Object at 250 million light-years from Earth. It consists of two large spiral galaxies in the process of colliding with their nuclei orbiting at a distance of 1,200 light-years, causing extensive star formation throughout both components. It possesses a large cluster of more than a billion stars, partially covered by thick dust clouds near one of the galaxies' core. Another interacting galaxy pair, albeit in an earlier stage, consists of the galaxies NGC 5953 and NGC 5954. In this case, both are active galaxies, with the former a Seyfert 2 galaxy and the latter a LINER-type galaxy. Both are undergoing a burst of star formation triggered by the interaction.\nSeyfert's Sextet is a group of six galaxies, four of which are interacting gravitationally and two of which simply appear to be a part of the group despite their greater distance. The gravitationally bound cluster lies at a distance of 190 million light-years from Earth and is approximately 100,000 light-years across, making Seyfert's Sextet one of the densest galaxy groups known. Astronomers predict that the four interacting galaxies will eventually merge to form a large elliptical galaxy. The radio source 3C 326 was originally thought to emanate from a giant elliptical galaxy. However, in 1990, it was shown that the source is instead a brighter, smaller galaxy a few arcseconds north. This object, designated 3C 326 N, has enough gas for star formation, but is being inhibited due to the energy from the radio galaxy nucleus.\nA much larger galaxy cluster is the redshift-0.0354 Abell 2063. The cluster is thought to be interacting with the nearby galaxy group MKW 3s, based on radial velocity measurements of galaxies and the positioning of the cD galaxy at the center of Abell 2063. The active galaxy at the center of MKW 3s\u2014NGC 5920\u2014appears to be creating a bubble of hot gas from its radio activity. Near the 5th-magnitude star Pi Serpentis lies AWM 4, a cluster containing an excess of metals in the intracluster medium. The central galaxy, NGC 6051, is a radio galaxy that is probably responsible for this enrichment. Similar to AWM 4, the cluster Abell 2052 has central cD radio galaxy, 3C 317. This radio galaxy is believed to have restarted after a period of inactivity less than 200 years ago. The galaxy has over 40,000 known globular clusters, the highest known total of any galaxy as of 2002.\nConsisting of two quasars with a separation of less than 5 arcseconds, the quasar pair 4C 11.50 is one of the visually closest pairs of quasars in the sky. The two have markedly different redshifts, however, and are thus unrelated. The foreground member of the pair (4C 11.50 A) does not have enough mass to refract light from the background component (4C 11.50 B) enough to produce a lensed image, although it does have a true companion of its own. An even stranger galaxy pair is 3C 321. Unlike the previous pair, the two galaxies making up 3C 321 are interacting with each other and are in the process of merging. Both members appear to be active galaxies; the primary radio galaxy may be responsible for the activity in the secondary by means of the former's jet driving material onto the latter's supermassive black hole.\nAn example of gravitational lensing is found in the radio galaxy 3C 324. First thought to be a single overluminous radio galaxy with a redshift of \"z\"\u00a0=\u00a01.206, it was found in 1987 to actually be two galaxies, with the radio galaxy at the aforementioned redshift being lensed by another galaxy at redshift \"z\"\u00a0=\u00a00.845. The first example of a multiply-imaged radio galaxy discovered, the source appears to be an elliptical galaxy with a dust lane obscuring our view of the visual and ultraviolet emission from the nucleus. In even shorter wavelengths, the BL Lac object PG 1553+113 is a heavy emitter of gamma rays. This object is the most distant found to emit photons with energies in the TeV range as of 2007. The spectrum is unique, with hard emission in some ranges of the gamma-ray spectrum in stark contrast to soft emission in others. In 2012, the object flared in the gamma-ray spectrum, tripling in luminosity for two nights, allowing the redshift to be accurately measured as \"z\"\u00a0=\u00a00.49.\nSeveral gamma-ray bursts (GRBs) have been observed in Serpens Caput, such as GRB 970111, one of the brightest GRBs observed. An optical transient event associated with this GRB has not been found, despite its intensity. The host galaxy initially also proved elusive, however it now appears that the host is a Seyfert I galaxy located at redshift \"z\"\u00a0=\u00a00.657. The X-ray afterglow of the GRB has also been much fainter than for other dimmer GRBs. More distant is GRB 060526 (redshift \"z\"\u00a0=\u00a03.221), from which X-ray and optical afterglows were detected. This GRB was very faint for a long-duration GRB.\nTail objects.\nPart of the galactic plane passes through the tail, and thus Serpens Cauda is rich in deep-sky objects within the Milky Way galaxy. The Eagle Nebula and its associated star cluster, Messier 16 lie around 5,700 light-years from Earth in the direction of the Galactic Center. The nebula measures 70 light-years by 50 light-years and contains the Pillars of Creation, three dust clouds that became famous for the image taken by the Hubble Space Telescope. The stars being born in the Eagle Nebula, added to those with an approximate age of 5 million years have an average temperature of 45,000 kelvins and produce prodigious amounts of radiation that will eventually destroy the dust pillars. Despite its fame, the Eagle Nebula is fairly dim, with an integrated magnitude of approximately 6.0. The star-forming regions in the nebula are often evaporating gaseous globules; unlike Bok globules they only hold one protostar.\nNorth of Messier 16, at a distance of approximately 2000 parsecs, is the OB association Serpens OB2, containing over 100 OB stars. Around 5 million years old, the association appears to still contain star-forming regions, and the light from its stars is illuminating the HII region S 54. Within this HII region is the open cluster NGC 6604, which is the same age as the surrounding OB association, and the cluster is now thought to simply be the densest part of it. The cluster appears to be producing a thermal chimney of ionized gas, caused by the interaction of the gas from the galactic disk with the galactic halo.\nAnother open cluster in Serpens Cauda is IC 4756, containing at least one naked-eye star, HD 172365 (another naked-eye star in the vicinity, HD 171586, is most likely unrelated). Positioned approximately 440 parsecs distant, the cluster is estimated to be around 800 million years old, quite old for an open cluster. Despite the presence of the Milky Way in Serpens Cauda, one globular cluster can be found: NGC 6535, although invisible to the naked eye, can be made out in small telescopes just north of Zeta Serpentis. Rather small and sparse for a globular cluster, this cluster contains no known RR Lyrae variables, which is unusual for a globular cluster.\nMWC 922 is a star surrounded by a planetary nebula. Dubbed the Red Square Nebula due to its similarities to the Red Rectangle Nebula, the planetary nebula appears to be a nearly perfect square with a dark band around the equatorial regions. The nebula contains concentric rings, which are similar to those seen in the supernova SN 1987A. MWC 922 itself is an FS Canis Majoris variable, meaning that it is a Be star containing exceptionally bright hydrogen emission lines as well as select forbidden lines, likely due to the presence of a close binary. East of Xi Serpentis is another planetary nebula, Abell 41, containing the binary star MT Serpentis at its center. The nebula appears to have a bipolar structure, and the axis of symmetry of the nebula has been found to be within 5\u00b0 of the line perpendicular to the orbital plane of the stars, strengthening the link between binary stars and bipolar planetary nebulae. On the other end of the stellar age spectrum is L483, a dark nebula which contains the protostar IRAS 18418-0440. Although classified as a class 0 protostar, it has some unusual features for such an object, such as a lack of high-velocity stellar winds, and it has been proposed that this object is in transition between class 0 and class I. A variable nebula exists around the protostar, although it is only visible in infrared light.\nThe Serpens cloud is a massive star-forming molecular cloud situated in the southern part of Serpens Cauda. Only two million years old and 420 parsecs distant, the cloud is known to contain many protostars such as Serpens FIRS 1 and Serpens SVS 20. The Serpens South protocluster was uncovered by NASA's Spitzer Space Telescope in the southern portion of the cloud, and it appears that star formation is still continuing in the region. Another site of star formation is the Westerhout 40 complex, consisting of a prominent HII region adjacent to a molecular cloud. Located around 500 parsecs distant, it is one of the nearest massive regions of star formation, but as the molecular cloud obscures the HII region, rendering it and its embedded cluster tough to see visibly, it is not as well-studied as others. The embedded cluster likely contains over 600 stars above 0.1 solar masses, with several massive stars, including at least one O-type star, being responsible for lighting the HII region and the production of a bubble.\nDespite the presence of the Milky Way, several active galaxies are visible in Serpens Cauda as well, such as PDS 456, found near Xi Serpentis. The most intrinsically luminous nearby active galaxy, this AGN has been found to be extremely variable in the X-ray spectrum. This has allowed light to be shed on the nature of the supermassive black hole at the center, likely a Kerr black hole. It is possible that the quasar is undergoing a transition from an ultraluminous infrared galaxy to a classical radio-quiet quasar, but there are problems with this theory, and the object appears to be an exceptional object that does not completely lie within current classification systems. Nearby is NRAO 530, a blazar that has been known to flare in the X-rays occasionally. One of these flares was for less than 2000 seconds, making it the shortest flare ever observed in a blazar as of 2004. The blazar also appears to show periodic variability in its radio wave output over two different periods of six and ten years.\nMeteor showers.\nThere are two daytime meteor showers that radiate from Serpens, the Omega Serpentids and the Sigma Serpentids. Both showers peak between December 18 and December 25.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28150", "revid": "46866511", "url": "https://en.wikipedia.org/wiki?curid=28150", "title": "Sculptor Group", "text": "Loosely grouped galaxy group in the constellation Sculptor\nThe Sculptor Group is a loose group of galaxies visible near the south galactic pole. The group is one of the closest groups of galaxies to the Local Group; the distance to the center of the group from the Milky Way is approximately .\nThe Sculptor Galaxy (NGC 253) and a few other galaxies form a gravitationally-bound core in the center of this group. A few other galaxies at the periphery may be associated with the group but may not be gravitationally bound. Because most of the galaxies in this group are actually weakly gravitationally bound, the group may also be described as a filament. It is considered to be at an early stage of evolution in which galaxies are still falling into the group along filamentary structures.\nMembers.\nThe table below lists galaxies that have been identified as associated with the Sculptor Galaxy (and hence associated with the group) by I. D. Karachentsev and collaborators.\nThe object names used in the above table differ from the names used by Karachentsev and collaborators. NGC, IC, UGC, and PGC numbers have been used when possible to allow for easier referencing.\nField galaxies.\nThe irregular galaxy NGC 55, the spiral galaxy NGC 300, and their companion galaxies have been considered by many researchers to be part of this group. However, recent distance measurements to these and other galaxies in the same region of the sky show that NGC 55, NGC 300, and their companions may simply be foreground galaxies that are physically unassociated with the Sculptor Group. The galaxies NGC 24 and NGC 45 are located in the vicinity of the Sculptor Group, but are now considered background objects.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28151", "revid": "2003421", "url": "https://en.wikipedia.org/wiki?curid=28151", "title": "State (polity)", "text": "Type of political organization\nA state is a political entity that regulates society and the population within a definite territory. Government is considered to form the fundamental apparatus of contemporary states.\nA country often has a single state, with various administrative divisions. A state may be a unitary state or some type of federal union; in the latter type, the term \"state\" is sometimes used to refer to the federated polities that make up the federation, and they may have some of the attributes of a sovereign state, except being under their federation and without the same capacity to act internationally. (Other terms that are used in such federal systems may include \"province\", \"region\" or other terms.)\nFor most of prehistory, people lived in stateless societies. The earliest forms of states arose about 5,500 years ago. Over time societies became more stratified and developed institutions leading to centralised governments. These gained state capacity in conjunction with the growth of cities, which was often dependent on climate and economic development, with centralisation often spurred on by insecurity and territorial competition.\nOver time, varied forms of states developed that used many different justifications for their existence (such as divine right, the theory of the social contract, etc.). Today, the modern nation state is the predominant form of state to which people are subject. Sovereign states have sovereignty; any ingroup's claim to have a state faces some practical limits via the degree to which other states recognize them as such. Satellite states are states that have \"de facto\" sovereignty but are often indirectly controlled by another state.\nDefinitions of a state are disputed. According to sociologist Max Weber, a \"state\" is a polity that maintains a monopoly on the legitimate use of violence, although other definitions are common. Absence of a state does not preclude the existence of a society, such as stateless societies like the Haudenosaunee Confederacy that \"do not have either purely or even primarily political institutions or roles\". The degree and extent of governance of a state is used to determine whether it has failed.\nEtymology.\nThe word \"state\" and its cognates in some other European languages (such as \"stato\" in Italian, \"estado\" in Spanish and Portuguese, \"\u00e9tat\" in French, \"Staat\" in German and Dutch) ultimately derive from the Latin word \"status\", meaning \"condition, circumstances\". Latin \"status\" derives from \"stare\", \"to stand\", or remain or be permanent, thus providing the sacred or magical connotation of the political entity.\nThe English noun \"state\" in the generic sense \"condition, circumstances\" predates the political sense. It was introduced to Middle English c.\u20091200 both from Old French and directly from Latin.\nWith the revival of the Roman law in 14th-century Europe, the term came to refer to the legal standing of persons (such as the various \"estates of the realm\" \u2013 noble, common, and clerical), and in particular the special status of the king. The highest estates, generally those with the most wealth and social rank, were those that held power. The word also had associations with Roman ideas (dating back to Cicero) about the \"status rei publicae\", the \"condition of public matters\". In time, the word lost its reference to particular social groups and became associated with the legal order of the entire society and the apparatus of its enforcement.\nThe early 16th-century works of Machiavelli (especially \"The Prince\") played a central role in popularizing the use of the word \"state\" in something similar to its modern sense. The contrasting of church and state still dates to the 16th century. The expression (\"I am the State\") attributed to Louis XIV, although probably apocryphal, is recorded in the late 18th century.\nDefinition.\nThere is no academic consensus on the definition of the state. The term \"state\" refers to a set of different, but interrelated and often overlapping, theories about a certain range of political phenomena. According to Walter Scheidel, mainstream definitions of the state have the following in common: \"centralized institutions that impose rules, and back them up by force, over a territorially circumscribed population; a distinction between the rulers and the ruled; and an element of autonomy, stability, and differentiation. These distinguish the state from less stable forms of organization, such as the exercise of chiefly power.\"\nThe most commonly used definition is by Max Weber who describes the state as a compulsory political organization with a centralized government that maintains a monopoly of the legitimate use of force within a certain territory. Weber writes that the state \"is a human community that (successfully) claims the monopoly of the legitimate use of physical force within a given territory.\"\nWhile defining a state, it is important not to confuse it with a nation; an error that occurs frequently in common discussion. A state refers to a political unit with sovereignty over a given territory. While a state is more of a \"political-legal abstraction,\" the definition of a nation is more concerned with political identity and cultural or historical factors. Importantly, nations do not possess the organizational characteristics like geographic boundaries or authority figures and officials that states do. Additionally, a nation does not have a claim to a monopoly on the legitimate use of force over their populace, while a state does, as Weber indicated. An example of the instability that arises when a state does not have a monopoly on the use of force can be seen in African states which remain weak due to the lack of war which European states relied on. A state should not be confused with a government; a government is an organization that has been granted the authority to act on the behalf of a state. Nor should a state be confused with a society; a society refers to all organized groups, movements, and individuals who are independent of the state and seek to remain out of its influence.\nNeuberger offers a slightly different definition of the state with respect to the nation: the state is \"a primordial, essential, and permanent expression of the genius of a specific [nation].\"\nThe definition of a state is also dependent on how and why it forms. The contractarian view of the state suggests that states form because people can all benefit from cooperation with others and that without a state, there would be chaos. The contractarian view focuses more on the alignment and conflict of interests between individuals in a state. On the other hand, the predatory view of the state focuses on the potential mismatch between the interests of the people and the interests of the state. Charles Tilly goes so far as to say that states \"resemble a form of organized crime and should be viewed as extortion rackets.\" He argued that the state sells protection from itself and raises the question about why people should trust a state when they cannot trust one another.\nTilly defines states as \"coercion-wielding organisations that are distinct from households and kinship groups and exercise a clear priority in some respects over all other organizations within substantial territories.\" Tilly includes city-states, theocracies and empires in his definition along with nation-states, but excludes tribes, lineages, firms and churches. According to Tilly, states can be seen in the archaeological record as of 6000 BC; in Europe, they appeared around 990, but became particularly prominent after 1490. Tilly defines a state's \"essential minimal activities\" as:\nImportantly, Tilly makes the case that war is an essential part of state-making; that wars create states and vice versa.\nModern academic definitions of the state frequently include the criterion that a state has to be recognized as such by the international community.\nLiberal thought provides another possible teleology of the state. According to John Locke, the goal of the state or commonwealth is \"the preservation of property\" (Second Treatise on Government), with 'property' in Locke's work referring not only to personal possessions but also to one's life and liberty. On this account, the state provides the basis for social cohesion and productivity, creating incentives for wealth-creation by providing guarantees of protection for one's life, liberty, and personal property. Provision of public goods is considered by some such as Adam Smith as a central function of the state, since these goods would otherwise be underprovided. Tilly has challenged narratives of the state as being the result of a societal contract or provision of services in a free market \u2013\u00a0 he characterizes the state more akin to a protection racket in the vein of organized crime.\nWhile economic and political philosophers have contested the monopolistic tendency of states, Robert Nozick argues that the use of force naturally tends towards monopoly.\nAnother commonly accepted definition of the state is the one given at the Montevideo Convention on the Rights and Duties of States in 1933. It provides that \"[t]he state as a person of international law should possess the following qualifications: (a) a permanent population; (b) a defined territory; (c) government; and (d) capacity to enter into relations with the other states.\" And that \"[t]he federal state shall constitute a sole person in the eyes of international law.\"\nConfounding the definition problem is that \"state\" and \"government\" are often used as synonyms in common conversation and even some academic discourse. According to this definition schema, the states are nonphysical persons of international law, and governments are organizations of people. The relationship between a government and its state is one of representation and authorized agency.\nTypes of states.\nCharles Tilly distinguished between empires, theocracies, city-states, and nation-states. According to Michael Mann, the four persistent types of state activities are:\nJosep Colomer distinguished between empires and states in the following way:\nAccording to Michael Hechter and William Brustein, the modern state was differentiated from \"leagues of independent cities, empires, federations held together by loose central control, and theocratic federations\" by four characteristics:\nStates may be classified by political philosophers as sovereign if they are not dependent on, or subject to any other power or state. Other states are subject to external sovereignty or hegemony where ultimate sovereignty lies in another state. Many states are federated states which participate in a federal union. A federated state is a territorial and constitutional community forming part of a federation. (Compare confederacies or confederations such as Switzerland.) Such states differ from sovereign states in that they have transferred a portion of their sovereign powers to a federal government.\nOne can commonly and sometimes readily (but not necessarily usefully) classify states according to their apparent make-up or focus. The concept of the nation-state, theoretically or ideally co-terminous with a \"nation\", became very popular by the 20th century in Europe, but occurred rarely elsewhere or at other times. In contrast, some states have sought to make a virtue of their multi-ethnic or multinational character (Habsburg Austria-Hungary, for example, or the Soviet Union), and have emphasised unifying characteristics such as autocracy, monarchical legitimacy, or ideology. Other states, often fascist or authoritarian ones, promoted state-sanctioned notions of racial superiority. Other states may bring ideas of commonality and inclusiveness to the fore: note the \"res publica\" of ancient Rome and the \"Rzeczpospolita\" of Poland-Lithuania which finds echoes in the modern-day republic. The concept of temple states centred on religious shrines occurs in some discussions of the ancient world. Relatively small city-states, once a relatively common and often successful form of polity, have become rarer and comparatively less prominent in modern times. Modern-day independent city-states include Vatican City, Monaco, and Singapore. Other city-states survive as federated states, like the present day German city-states, or as otherwise autonomous entities with limited sovereignty, like Hong Kong, Gibraltar, and Ceuta. To some extent, urban secession, the creation of a new city-state (sovereign or federated), continues to be discussed in the early 21st century in cities such as London.\nState and government.\nA state can be distinguished from a government. The state is the organization, while the government is the particular group of people, the administrative bureaucracy that controls the state apparatus at a given time. That is, governments are the means through which state power is employed. States are served by a continuous succession of different governments. States are immaterial and nonphysical social objects, whereas governments are groups of people with certain coercive powers.\nEach successive government is composed of a specialized and privileged body of individuals who monopolize political decision-making and are separated by status and organization from the population as a whole.\nStates and nation-states.\nStates can also be distinguished from the concept of a \"nation\", where \"nation\" refers to a cultural-political community of people. A nation-state refers to a situation where a single ethnicity is associated with a specific state.\nState and civil society.\nIn the classical thought, the state was identified with both political society and civil society as a form of political community, while the modern thought distinguished the nation state as a political society from civil society as a form of economic society.\nThus, in modern thought, the state is contrasted with civil society.\nAntonio Gramsci believed that civil society is the primary locus of political activity because it is where all forms of \"identity formation, ideological struggle, the activities of intellectuals, and the construction of hegemony take place,\" and that civil society was the nexus connecting the economic and political spheres. Arising out of the collective actions of civil society is what Gramsci calls \"political society\", which Gramsci differentiates from the notion of the state as a polity. He stated that politics was not a \"one-way process of political management\" but, rather, that the activities of civil organizations conditioned the activities of political parties and state institutions, and were conditioned by them in turn. Louis Althusser argued that civil organizations such as church, schools, and the family are part of an \"ideological state apparatus\" which complements the \"repressive state apparatus\" (such as police and military) in reproducing social relations.\nJ\u00fcrgen Habermas spoke of a public sphere that was distinct from both the economic and political sphere.\nGiven the role that many social groups have in the development of public policy and the extensive connections between state bureaucracies and other institutions, it has become increasingly difficult to identify the boundaries of the state. Privatization, nationalization, and the creation of new regulatory bodies also change the boundaries of the state in relation to society. Often, the nature of quasi-autonomous organizations is unclear, generating debate among political scientists on whether they are part of the state or civil society. Some political scientists thus prefer to speak of policy networks and decentralized governance in modern societies rather than of state bureaucracies and direct state control over policy.\nHistory.\nThe earliest forms of the state emerged whenever it became possible to centralize power in a durable way. Agriculture and a settled population have been attributed as necessary conditions to form states. Certain types of agriculture are more conducive to state formation, such as grain (wheat, barley, millet), because they are suited to concentrated production, taxation, and storage. Agriculture and writing are almost everywhere associated with this process: agriculture because it allowed for the emergence of a social class of people who did not have to spend most of their time providing for their own subsistence, and writing (or an equivalent of writing, like Inca quipus) because it made possible the centralization of vital information. Bureaucratization made expansion over large territories possible.\nThe first known states were created in Egypt, Mesopotamia, India, China, Mesoamerica, and the Andes. It is only in relatively modern times that states have almost completely displaced alternative \"stateless\" forms of political organization of societies all over the planet. Roving bands of hunter-gatherers and even fairly sizable and complex tribal societies based on herding or agriculture have existed without any full-time specialized state organization, and these \"stateless\" forms of political organization have in fact prevailed for all of the prehistory and much of human history and civilization.\nThe primary competing organizational forms to the state were religious organizations (such as the Church), and city republics.\nSince the late 19th century, virtually the entirety of the world's inhabitable land has been parcelled up into areas with more or less definite borders claimed by various states. Earlier, quite large land areas had been either unclaimed or uninhabited, or inhabited by nomadic peoples who were not organised as states. However, even within present-day states, there are vast areas of wilderness, like the Amazon rainforest, which are uninhabited or inhabited solely or mostly by indigenous people (and some of them remain uncontacted). Also, there are so-called \"failed states\" which do not hold de facto control over all of their claimed territory or where this control is challenged. The international community comprises around 200 sovereign states, the vast majority of which are represented in the United Nations.\nPrehistoric stateless societies.\nFor most of human history, people have lived in stateless societies, characterized by a lack of concentrated authority, and the absence of large inequalities in economic and political power.\nThe anthropologist Tim Ingold writes:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It is not enough to observe, in a now rather dated anthropological idiom, that hunter gatherers live in 'stateless societies', as though their social lives were somehow lacking or unfinished, waiting to be completed by the evolutionary development of a state apparatus. Rather, the principle of their society, as Pierre Clastres has put it, is fundamentally \"against\" the state.\nNeolithic period.\nDuring the Neolithic period, human societies underwent major cultural and economic changes, including the development of agriculture, the formation of sedentary societies and fixed settlements, increasing population densities, and the use of pottery and more complex tools.\nSedentary agriculture led to the development of property rights, domestication of plants and animals, and larger family sizes. It also provided the basis for an external centralized state. By producing a large surplus of food, more division of labor was realized, which enabled people to specialize in tasks other than food production. Early states were characterized by highly stratified societies, with a privileged and wealthy ruling class that was subordinate to a monarch. The ruling classes began to differentiate themselves through forms of architecture and other cultural practices that were different from those of the subordinate laboring classes.\nIn the past, it was suggested that the centralized state was developed to administer large public works systems (such as irrigation systems) and to regulate complex economies. However, modern archaeological and anthropological evidence does not support this thesis, pointing to the existence of several non-stratified and politically decentralized complex societies.\nAncient Eurasia.\nMesopotamia is generally considered to be the location of the earliest civilization or complex society, meaning that it contained cities, full-time division of labor, social concentration of wealth into capital, unequal distribution of wealth, ruling classes, community ties based on residency rather than kinship, long distance trade, monumental architecture, standardized forms of art and culture, writing, and mathematics and science. It was the world's first literate civilization, and formed the first sets of written laws. Bronze metallurgy spread within Afro-Eurasia from c.\u20093000 BC, leading to a military revolution in the use of bronze weaponry, which facilitated the rise of states.\nClassical antiquity.\nAlthough state-forms existed before the rise of the Ancient Greek empire, the Greeks were the first people known to have explicitly formulated a political philosophy of the state, and to have rationally analyzed political institutions. Prior to this, states were described and justified in terms of religious myths.\nSeveral important political innovations of classical antiquity came from the Greek city-states and the Roman Republic. The Greek city-states before the 4th century granted citizenship rights to their free population, and in Athens these rights were combined with a directly democratic form of government that was to have a long afterlife in political thought and history.\nFeudal state.\nDuring medieval times in Europe, the state was organized on the principle of feudalism, and the relationship between lord and vassal became central to social organization. Feudalism led to the development of greater social hierarchies.\nThe formalization of the struggles over taxation between the monarch and other elements of society (especially the nobility and the cities) gave rise to what is now called the Standestaat, or the state of Estates, characterized by parliaments in which key social groups negotiated with the king about legal and economic matters. These estates of the realm sometimes evolved in the direction of fully-fledged parliaments, but sometimes lost out in their struggles with the monarch, leading to greater centralization of lawmaking and military power in his hands. Beginning in the 15th century, this centralizing process gave rise to the absolutist state.\nModern state.\nCultural and national homogenization figured prominently in the rise of the modern state system. Since the absolutist period, states have largely been organized on a national basis. The concept of a national state, however, is not synonymous with nation state. Even in the most ethnically homogeneous societies, there is not always a complete correspondence between state and nation, hence the active role often taken by the state to promote nationalism through an emphasis on shared symbols and national identity.\nCharles Tilly argues that the number of total states in Western Europe declined rapidly from the Late Middle Ages to the Early Modern Era during a process of state formation. Other research has disputed whether such a decline took place.\nFor Edmund Burke (Dublin 1729 - Beaconsfield 1797), \"a state without the means of some change is without the means of its conservation\" (Reflections on the Revolution in France).\nAccording to Hendrik Spruyt, the modern state is different from its predecessor polities in two main aspects: (1) Modern states have a greater capacity to intervene in their societies, and (2) Modern states are buttressed by the principle of international legal sovereignty and the judicial equivalence of states. The two features began to emerge in the Late Middle Ages, but the modern state form took centuries to come firmly into fruition. Other aspects of modern states is that they tend to be organized as unified national polities, and that they have rational-legal bureaucracies.\nSovereign equality did not become fully global until after World War II amid decolonization. Adom Getachew writes that it was not until the 1960 Declaration on the Granting of Independence to Colonial Countries and Peoples that the international legal context for popular sovereignty was instituted. Historians Jane Burbank and Frederick Cooper argue that \"Westphalian sovereignty\" \u2013 the notion that bounded, unitary states interact with equivalent states \u2013\u00a0 \"has more to do with 1948 than 1648.\"\nTheories for the emergence of the state.\nEarliest states.\nTheories for the emergence of the earliest states emphasize grain agriculture and settled populations as necessary conditions.\nHowever, not all types of property are equally exposed to the risk of looting or equally subject to taxation. Goods differ in their shelf life. Certain agricultural products, fish, and dairy spoil quickly and cannot be stored without refrigeration or freezing technology, which was unavailable in ancient times. As a result, such perishable goods were of little interest to either looters or the king (In ancient times, especially before the invention of money, taxation was primarily collected from agricultural produce.) Both looters and rulers sought goods with long shelf lives, such as grains (wheat, barley, rice, corn, etc.), which, under proper storage conditions, could be preserved for extended periods. With the domestication of wheat and the establishment of agricultural communities, the need for protection from bandits arose, along with the emergence of strong governance to provide it. Mayshar et al. (2020) demonstrated that societies cultivating grains tended to develop hierarchical structures with a ruling elite that collected taxes, whereas societies that relied on root crops (which have short shelf lives) did not develop such hierarchies. The cultivation of grains became concentrated in regions with fertile soil, where grain production was more profitable than root crops, even after accounting for taxes imposed by rulers and raids by looters.\nHowever, protection was not the only public good necessitating a centralized government. The shift to agriculture based on irrigation systems, as seen in ancient Egypt, required cooperation among farmers. An individual farmer could not control the floods from the Nile River alone. Managing the vast amounts of water during the annual floods and utilizing them efficiently allowed for a significant increase in agricultural yield, but this required an elaborate network of irrigation canals to distribute water efficiently across fields while minimizing waste.\nSuch a system exhibited characteristics of a natural monopoly, as its construction involved substantial fixed costs, making it a lucrative asset for the ruling elite. Bentzen, Kaarsen, and Wingender (2017) showed that in pre-modern societies, regions dependent on irrigation-intensive agriculture experienced higher levels of land inequality. The concentration of land and control over water resources strengthened elite power, enabling them to resist democratization in the modern era. Even today, countries that rely on irrigated agriculture tend to be less democratic than those relying on rain-fed farming.\nSome argue that climate change led to a greater concentration of human populations around dwindling waterways.\nModern state.\nHendrik Spruyt distinguishes between three prominent categories of explanations for the emergence of the modern state as a dominant polity: (1) Security-based explanations that emphasize the role of warfare, (2) Economy-based explanations that emphasize trade, property rights and capitalism as drivers behind state formation, and (3) Institutionalist theories that sees the state as an organizational form that is better able to resolve conflict and cooperation problems than competing political organizations.\nAccording to Philip Gorski and Vivek Swaroop Sharma, the \"neo-Darwinian\" framework for the emergence of sovereign states is the dominant explanation in the scholarship. The neo-Darwinian framework emphasizes how the modern state emerged as the dominant organizational form through natural selection and competition.\nTheories of state function.\nMost political theories of the state can roughly be classified into two categories:\nAnarchist perspective.\nAnarchism as a political philosophy regards the state and hierarchies as unnecessary and harmful, and instead promotes a stateless society, or anarchy, a self-managed, self-governed society based on voluntary, cooperative institutions.\nAnarchists believe that the state is inherently an instrument of domination and repression, no matter who is in control of it. Anarchists note that the state possesses the monopoly on the legal use of violence. Unlike Marxists, anarchists believe that revolutionary seizure of state power should not be a political goal. They believe instead that the state apparatus should be completely dismantled, and an alternative set of social relations created, which are not based on state power at all.\nVarious Christian anarchists, such as Jacques Ellul, have identified the state and political power as the Beast in the Book of Revelation.\nAnarcho-capitalist perspective.\nAnarcho-capitalists, such as Murray Rothbard, come to some of the same conclusions about the state apparatus as anarchists, but for different reasons. The two principles that anarcho-capitalists rely on most are consent and non-initiation. Consent in anarcho-capitalist theory requires that individuals explicitly assent to the jurisdiction of the State excluding Lockean tacit consent. Consent may also create a right of secession, which destroys any concept of government monopoly on force. Coercive monopolies are excluded by the non-initiation of force principle because they must use force in order to prevent others from offering the same service that they do. Anarcho-capitalists start from the belief that replacing monopolistic states with competitive providers is necessary from a normative, justice-based scenario.\nAnarcho-capitalists believe that the market values of competition and privatization can better provide the services provided by the state. Murray Rothbard argues in \"Power and Market\" that any and all government functions could better be fulfilled by private actors, including defense, infrastructure, and legal adjudication.\nMarxist perspective.\nMarx and Engels were clear in that the goal of communism was a classless society in which the state would have \"withered away\", replaced only by \"administration of things\". Their views are found throughout their Collected Works, and address past or then-extant state forms from an analytical and tactical viewpoint, but not future social forms, speculation about which is generally antithetical to groups considering themselves Marxist but who \u2013 not having conquered the existing state power(s) \u2013 are not in the situation of supplying the institutional form of an actual society. To the extent that it makes sense, there is no single \"Marxist theory of state\", but rather several different purportedly \"Marxist\" theories have been developed by adherents of Marxism.\nMarx's early writings portrayed the bourgeois state as parasitic, built upon the superstructure of the economy, and working against the public interest. He also wrote that the state mirrors class relations in society in general, acting as a regulator and repressor of class struggle, and as a tool of political power and domination for the ruling class. The \"Communist Manifesto\" claims the state to be nothing more than \"a committee for managing the common affairs of the \"bourgeoisie\".\"\nFor Marxist theorists, the role of the modern bourgeois state is determined by its function in the global capitalist order. Ralph Miliband argued that the ruling class uses the state as its instrument to dominate society by virtue of the interpersonal ties between state officials and economic elites. For Miliband, the state is dominated by an elite that comes from the same background as the capitalist class. State officials, therefore, share the same interests as owners of capital and are linked to them through a wide array of social, economic, and political ties.\nGramsci's theories of state emphasized that the state is only one of the institutions in society that helps maintain the hegemony of the ruling class, and that state power is bolstered by the ideological domination of the institutions of civil society, such as churches, schools, and mass media.\nPluralism.\nPluralists view society as a collection of individuals and groups, who are competing for political power. They then view the state as a neutral body that simply enacts the will of whichever groups dominate the electoral process. Within the pluralist tradition, Robert Dahl developed the theory of the state as a neutral arena for contending interests or its agencies as simply another set of interest groups. With power competitively arranged in society, state policy is a product of recurrent bargaining. Although pluralism recognizes the existence of inequality, it asserts that all groups have an opportunity to pressure the state. The pluralist approach suggests that the modern democratic state's actions are the result of pressures applied by a variety of organized interests. Dahl called this kind of state a polyarchy.\nPluralism has been challenged on the grounds that it is not supported by empirical evidence. Citing surveys showing that the large majority of people in high leadership positions are members of the wealthy upper class, critics of pluralism claim that the state serves the interests of the upper class rather than equitably serving the interests of all social groups.\nContemporary critical perspectives.\nJ\u00fcrgen Habermas believed that the base-superstructure framework, used by many Marxist theorists to describe the relation between the state and the economy, was overly simplistic. He felt that the modern state plays a large role in structuring the economy, by regulating economic activity and being a large-scale economic consumer/producer, and through its redistributive welfare state activities. Because of the way these activities structure the economic framework, Habermas felt that the state cannot be looked at as passively responding to economic class interests.\nMichel Foucault believed that modern political theory was too state-centric, saying, \"Maybe, after all, the state is no more than a composite reality and a mythologized abstraction, whose importance is a lot more limited than many of us think.\" He thought that political theory was focusing too much on abstract institutions and not enough on the actual practices of government. In Foucault's opinion, the state had no essence. He believed that instead of trying to understand the activities of governments by analyzing the properties of the state (a reified abstraction), political theorists should be examining changes in the practice of government to understand changes in the nature of the state. Foucault developed the concept of governmentality while considering the genealogy of state, and considers the way in which an individual's understanding of governance can influence the function of the state.\nFoucault argues that it is technology that has created and made the state so elusive and successful and that instead of looking at the state as something to be toppled we should look at the state as a technological manifestation or system with many heads; Foucault argues instead of something to be overthrown as in the sense of the Marxist and anarchist understanding of the state. Every single scientific technological advance has come to the service of the state, Foucault argues, and it is with the emergence of the Mathematical sciences and essentially the formation of mathematical statistics that one gets an understanding of the complex technology of producing how the modern state was so successfully created. Foucault insists that the nation state was not a historical accident but a deliberate production in which the modern state had to now manage coincidentally with the emerging practice of the police (cameral science) 'allowing' the population to now 'come in' into \"jus gentium\" and \"civitas\" (civil society) after deliberately being excluded for several millennia. Democracy wasn't (the newly formed voting franchise) as is always painted by both political revolutionaries and political philosophers as a cry for political freedom or wanting to be accepted by the 'ruling elite', Foucault insists, but was a part of a skilled endeavour of switching over new technology such as; translatio imperii, plenitudo potestatis and \"extra Ecclesiam nulla salus\" readily available from the past medieval period, into mass persuasion for the future industrial 'political' population (deception over the population) in which the political population was now asked to insist upon itself \"the president must be elected\". Where these political symbol agents, represented by the pope and the president, are now democratised. Foucault calls these new forms of technology biopower and form part of our political inheritance which he calls biopolitics.\nHeavily influenced by Gramsci, Nicos Poulantzas, a Greek neo-Marxist theorist argued that capitalist states do not always act on behalf of the ruling class, and when they do, it is not necessarily the case because state officials consciously strive to do so, but because the 'structural' position of the state is configured in such a way to ensure that the long-term interests of capital are always dominant. Poulantzas' main contribution to the Marxist literature on the state was the concept of 'relative autonomy' of the state. While Poulantzas' work on 'state autonomy' has served to sharpen and specify a great deal of Marxist literature on the state, his own framework came under criticism for its 'structural functionalism'.\nStructural universe of the state or structural reality of the state.\nIt can be considered as a single structural universe: the historical reality that takes shape in societies characterized by a codified or crystallized right, with a power organized hierarchically and justified by the law that gives it authority, with a well-defined social and economic stratification, with an economic and social organization that gives the society precise organic characteristics, with one (or multiple) religious organizations, in justification of the power expressed by such a society and in support of the religious beliefs of individuals and accepted by society as a whole. Such a structural universe, evolves in a cyclical manner, presenting two different historical phases (a mercantile phase, or \"open society\", and a feudal phase or \"closed society\"), with characteristics so divergent that it can qualify as two different levels of civilization which, however, are never definitive, but that alternate cyclically, being able, each of the two different levels, to be considered progressive (in a partisan way, totally independent of the real value of well-being, degrees of freedom granted, equality realized and a concrete possibility to achieve further progress of the level of civilization), even by the most cultured fractions, educated and intellectually more equipped than the various societies, of both historical phases.\nState autonomy within institutionalism.\nState autonomy theorists believe that the state is an entity that is impervious to external social and economic influence and that it has interests of its own.\n\"New institutionalist\" writings on the state, such as the works of Theda Skocpol, suggest that state actors are to an important degree autonomous. In other words, state personnel have interests of their own, which they can and do pursue independently of (and at times in conflict with) actors in society. Since the state controls the means of coercion, and given the dependence of many groups in civil society on the state for achieving any goals they may espouse, state personnel can, to some extent, impose their own preferences on civil society.\nTheories of state legitimacy.\nStates generally rely on a claim to some form of political legitimacy in order to maintain domination over their subjects.\nSocial contract theory.\nVarious social contract theories have been proffered to establish state legitimacy and to explain state formation. Common elements in these theories are a state of nature that incentivizes people to seek out the establishment of a state. Thomas Hobbes described the state of nature as \"solitary, poor, nasty, brutish, and short\" (\"Leviathan\", Chapters XIII\u2013XIV). Locke takes a more benign view of the state of nature and is unwilling to take as hard a stance on the degeneracy of the state of nature. He does agree that it is equally incapable of providing a high quality of life. Locke argues for inalienable human rights. One of the most significant rights for Locke was the right to property. He viewed it as a keystone right that was inadequately protected in the state of nature. Social contract theorists frequently argue for some level of natural rights. In order to protect their ability to exercise these rights, they are willing to give up some other rights to the state to allow it to establish governance. Social contract theory then bases government legitimacy on the consent of the governed, but such legitimacy only extends as far as the governed have consented. This line of reasoning figures prominently in The United States Declaration of Independence.\nDivine right of kings.\nThe rise of the modern-day state system was closely related to changes in political thought, especially concerning the changing understanding of legitimate state power and control. Early modern defenders of absolutism (Absolute monarchy), such as Thomas Hobbes and Jean Bodin, undermined the doctrine of the divine right of kings by arguing that the power of kings should be justified by reference to the people. Hobbes, in particular, went further to argue that political power should be justified with reference to the individual (Hobbes wrote in the time of the English Civil War), not just to the people understood collectively. Hobbes and Bodin thought they were defending the power of kings, not advocating for democracy, but their arguments about the nature of sovereignty were fiercely resisted by more traditional defenders of the power of kings, such as Robert Filmer in England, who thought that such defenses ultimately opened the way to more democratic claims.\nRational-legal authority.\nMax Weber identified three main sources of political legitimacy in his works. The first, legitimacy based on traditional grounds, is derived from a belief that things should be as they have been in the past, and that those who defend these traditions have a legitimate claim to power. The second, legitimacy based on charismatic leadership, is devotion to a leader or group that is viewed as exceptionally heroic or virtuous. Max Weber's concept of charisma is also explored by Fukuyama, who uses it to explain why individuals relinquish their personal freedoms and more egalitarian, smaller communities in favor of larger, more authoritarian states. The Scholars go further by saying that Charismatic leaders can leverage this mass mobilization as a military force, achieving victories and securing peace, which in turn further legitimizes their authority. Fukuyama cites the example of Muhammad, whose influence facilitated the rise of a powerful state in North Africa and the Middle East, despite limited economic foundations.\nThe third is rational-legal authority, whereby legitimacy is derived from the belief that a certain group has been placed in power in a legal manner, and that their actions are justifiable according to a specific code of written laws. Weber believed that the modern state is characterized primarily by appeals to rational-legal authority.\nState failure.\nSome states are often labeled as \"weak\" or \"failed\". In David Samuels's words \"...a failed state occurs when sovereignty over claimed territory has collapsed or was never effectively at all\". Authors like Samuels and Joel S. Migdal have explored the emergence of weak states, how they are different from Western \"strong\" states and its consequences to the economic development of developing countries.\nSamuels introduces the idea of state capacity, which he uses to refer to the ability of the state to fulfill its basic functions, such as providing security, maintaining law and order, and delivering public services. When a state does not accomplish this, state failure happens (Samuels, 2012). Other authors like Jeffrey Herbst add to this idea by arguing that state failure is the result of weak or non-existent institutions, which means that there is no state legitimacy because states are not able to provide goods or services or maintain order and safety (Herbst, 1990). However, there are also ideas that challenge this notion of state failure. Stephen D. Krasner argues that state failure is not just the result of weak institutions, but rather a very complex phenomenon that varies according to context-specific circumstances, and should therefore not be analyzed through a simplistic understanding like the one normally presented (Krasner, 2004).\nThe problem with state failure.\nIn \"The Problem of Failed States\", Susan Rice argues that state failure is an important threat to global stability and security, since failed states are vulnerable to terrorism and conflict (Rice, 1994). Additionally, it is believed that state failure hinders democratic values, since these states often experience political violence, authoritarian rules, and a number of human rights abuses (Rotberg, 2004). While there is great discussion regarding the direct effects of state failure, its indirect effects should also be highlighted: state failure could lead to refugee flows and cross-border conflicts, while also becoming safe havens for criminal or extremist groups (Corbridge, 2005). In order to solve and prevent these issues in the future, it is necessary to focus on building strong institutions, promoting economic diversification and development, and addressing the causes of violence in each state (Mkandawire, 2001).\nEarly state formation.\nTo understand the formation of weak states, Samuels compares the formation of European states in the 1600s with the conditions under which more recent states were formed in the twentieth century. In this line of argument, the state allows a population to resolve a collective action problem, in which citizens recognize the authority of the state and exercise the power of coercion over them. This kind of social organization required a decline in the legitimacy of traditional forms of ruling (like religious authorities) and replaced them with an increase in the legitimacy of depersonalized rule; an increase in the central government's sovereignty; and an increase in the organizational complexity of the central government (bureaucracy).\nThe transition to this modern state was possible in Europe around 1600 thanks to the confluence of factors like the technological developments in warfare, which generated strong incentives to tax and consolidate central structures of governance to respond to external threats. This was complemented by the increase in the production of food (as a result of productivity improvements), which allowed to sustain a larger population and so increased the complexity and centralization of states. Finally, cultural changes challenged the authority of monarchies and paved the way for the emergence of modern states.\nLate state formation.\nThe conditions that enabled the emergence of modern states in Europe were different from other countries that started this process later. As a result, many of these states lack effective capabilities to tax and extract revenue from their citizens, which results in problems like corruption, tax evasion, and low economic growth. Unlike the European case, late state formation occurred in a context of limited international conflict that diminished the incentives to tax and increase military spending. Also, many of these states emerged from colonization in a state of poverty and with institutions designed to extract natural resources, which have made it more difficult to form states. European colonization also defined many arbitrary borders that mixed different cultural groups under the same national identities, which has made it difficult to build states with legitimacy among all the population, since some states have to compete for it with other forms of political identity.\nAs a complement to this argument, Migdal gives a historical account of how sudden social changes in the Third World during the Industrial Revolution contributed to the formation of weak states. The expansion of international trade that started around 1850 brought profound changes in Africa, Asia, and Latin America that were introduced with the objective of ensuring the availability of raw materials for the European market. These changes consisted in: i) reforms to landownership laws with the objective of integrate more lands to the international economy, ii) increase in the taxation of peasants and little landowners, as well as collecting of these taxes in cash instead of in kind as was usual up to that moment and iii) the introduction of new and less costly modes of transportation, mainly railroads. As a result, the traditional forms of social control became obsolete, deteriorating the existing institutions and opening the way to the creation of new ones, that not necessarily lead these countries to build strong states. This fragmentation of the social order induced a political logic in which these states were captured to some extent by \"strongmen\", who were capable to take advantage of the above-mentioned changes and that challenge the sovereignty of the state. As a result, this decentralization of social control impedes to consolidation of strong states.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "28152", "revid": "1318351480", "url": "https://en.wikipedia.org/wiki?curid=28152", "title": "Stevia", "text": "Sweetener and sugar substitute\nStevia () is a sweet sugar substitute that is about 50 to 300\u00a0times sweeter than sugar. It is extracted from the leaves of \"Stevia rebaudiana\", a plant native to areas of Paraguay and Brazil. The active compounds in stevia are steviol glycosides (mainly stevioside and rebaudioside).&lt;ref name=\"Joint FAO/WHO2016\"&gt;&lt;/ref&gt; Stevia is heat-stable, pH-stable, and not fermentable. Humans cannot metabolize the glycosides in stevia, and it therefore has zero calories. Its taste has a slower onset and longer duration than that of sugar, and at high concentrations some of its extracts may have an aftertaste described as licorice-like or bitter. Stevia is used in sugar- and calorie-reduced food and beverage products as an alternative for variants with sugar.\nThe plant \"Stevia rebaudiana\" has been used for centuries by the Guaran\u00ed peoples of South America, who called it \"ka'a he'\u00ea\" (\"sweet herb\"). The leaves have been used traditionally for hundreds of years in both Paraguay and Brazil to sweeten local teas, and as a \"sweet treat\".\nThe legal status of stevia as a food additive or dietary supplement varies from country to country. Stevia has been widely used in Japan as a sweetener for decades. The European Union approved stevia additives in 2011. In the United States, extracts of certain high-purity steviol glycosides have been Generally Recognized As Safe (GRAS) and may be lawfully marketed and added to food products, but stevia leaf and crude extracts do not have GRAS or Food and Drug Administration (FDA) approval for use in food.\nThe genus was named for the Spanish botanist and physician Pedro Jaime Esteve (\"Petrus James Stevus\", 1500\u20131556) a professor of botany at the University of Valencia.\nHistory.\nSwiss botanist Mois\u00e9s Santiago Bertoni first described the plant and its sweet taste in detail in 1899, while conducting research in eastern Paraguay. Little research was conducted on the topic until 1931, when two French chemists isolated the glycosides that give stevia its sweet taste.\nRegulation.\nIn the early 1990s, the United States Food and Drug Administration (FDA) denied two petitions requesting that stevia be classified as GRAS. Stevia remained banned for all uses until the Dietary Supplement Health and Education Act of 1994, after which the FDA revised its stance and permitted stevia to be used as a dietary supplement, although still not as a food additive.\nIn 1999, the European Commission banned stevia's use in food products within the European Union pending further research. In 2006 and 2016, research data compiled in the safety evaluations released by the World Health Organization found no adverse effects.\nIn December 2008, the FDA gave a \"no objection\" approval for GRAS status to Truvia and PureVia, both of which use rebaudioside A derived from the \"Stevia rebaudiana\" plant. The FDA declared that these products are not stevia, but highly purified \"Stevia rebaudiana\" extracts. In 2015, the FDA still regarded stevia as \"not an approved food additive\", and stated that it \"has not been affirmed as GRAS in the United States due to inadequate toxicological information\". In June 2016, the U.S. Customs and Border Protection issued an order of detention for stevia products made in China based on information that the products were made using prison labor. As of 2017, certain high-purity steviol glycoside extracts have been GRAS in the US, and may be lawfully marketed and added to food products.\nCommercial use.\nUse of stevia as a sweetener began in Japan, with the aqueous extract of the leaves yielding purified steviosides developed as sweeteners. Japanese firm Morita Kagaku Kogyo claims they were the first, in 1971, to commercialize stevia sweetener production.\nIn the mid-1980s, stevia was commonly used in U.S. natural foods and health food industries, as a noncaloric natural sweetener for teas and weight-loss blends. The makers of the synthetic sweetener NutraSweet (at the time Monsanto) asked the FDA to require testing of stevia extracts. \nIn 2007, the Coca-Cola Company announced plans to obtain approval for its \"Stevia\"-derived sweetener, Rebiana, for use as a food additive within the United States by 2009, as well as plans to market Rebiana-sweetened products in 12\u00a0countries that allow stevia's use as a food additive.\nIn May 2008, Coca-Cola and Cargill announced the availability of Truvia, a consumer-brand \"Stevia\" sweetener containing erythritol and Rebiana, which the FDA permitted as a food additive in December 2008. Coca-Cola announced intentions to release stevia-sweetened beverages in late December 2008. From 2013 onwards, Coca-Cola Life, containing stevia as a sweetener, was launched in various countries around the world.\nShortly afterward, PepsiCo and Pure Circle announced PureVia, their brand of \"Stevia\"-based sweetener, but withheld release of beverages sweetened with rebaudioside A until receipt of FDA confirmation. Since the FDA permitted Truvia and PureVia, both the Coca-Cola Company and PepsiCo have introduced products that contain their new sweeteners.\nIndustrial extracts.\nRebaudioside A has the least bitterness of all the steviol glycosides in the \"Stevia rebaudiana\" plant. To produce steviol glycosides commercially, \"Stevia rebaudiana\" plants are dried and subjected to a hot water extraction process. This crude extract contains about 50% rebaudioside\u00a0A. The various glycosides are separated and purified via crystallization techniques, typically using ethanol or methanol as solvent. The dried extract contains no less than 95% steviol glycosides.\n\"Stevia rebaudiana\" extracts and derivatives are produced industrially and marketed under different trade names.\nMechanism of action.\nGlycosides are molecules that contain glucose residues bound to other non-sugar substances called aglycones (molecules with other sugars are polysaccharides). Preliminary experiments deduce that the tongue's taste receptors react to the glycosides and transduce the sweet taste sensation and the lingering bitter aftertaste by direct activation of sweet and bitter receptors.\nAccording to basic research, steviol glycosides and steviol interact with a protein channel called TRPM5, potentiating the signal from the sweet or bitter receptors, amplifying the taste of other sweet, bitter and umami tastants. The synergetic effect of the glycosides on the sweet receptor and TRPM5 explains the sweetness sensation. Some steviol glycosides (rebaudioside\u00a0A) are perceived sweeter than others (stevioside).\nSteviol is processed by intestinal microflora and is also taken up into the bloodstream, further metabolised by the liver to steviol glucuronide and several other metabolites, and excreted in the urine.\nA three-dimensional map of the proteins produced by the stevia plant, showing the crystalline structures that produce both the sensation of sweetness and bitter aftertaste in the sweetener, was reported in 2019.\nSafety and regulations.\nA 2010 review found that the use of \"Stevia rebaudiana\" sweeteners as replacements for sugar might benefit children, people with diabetes, and those wishing to lower their intake of calories.\nAlthough both steviol and rebaudioside A have been found to be mutagenic in laboratory \"in vitro\" testing, these effects have not been demonstrated for the doses and routes of administration to which humans are exposed. Two 2010 review studies found no health concerns with \"Stevia rebaudiana\" or its sweetening extracts.\nThe WHO's Joint Experts Committee on Food Additives has approved, based on long-term studies, an acceptable daily intake of steviol glycoside of up to 4\u00a0mg/kg of body mass. In 2010, The European Food Safety Authority established an acceptable daily intake of 4\u00a0mg/kg of steviol, in the form of steviol glycosides. Meanwhile, the Memorial Sloan Kettering Cancer Center warns that \"steviol at high dosages may have weak mutagenic activity,\" and a review \"conducted for\" the Center for Science in the Public Interest notes that there are no published carcinogenicity results for rebaudioside\u00a0A (or stevioside).\nIn August 2019, the US FDA placed an import alert on \"Stevia\" leaves and crude extracts \u2013 which do not have GRAS status \u2013 and on foods or dietary supplements containing them due to concerns about safety and potential for toxicity.\nAvailability and legal status by country or area.\nThe plant may be grown legally in most countries, although some countries restrict its use as a sweetener. The legally allowed uses and maximum dosage of the extracts and derived products vary widely from country to country.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28153", "revid": "47406457", "url": "https://en.wikipedia.org/wiki?curid=28153", "title": "Search for extraterrestrial intelligence", "text": "Effort to find civilizations not from Earth\nThe search for extraterrestrial intelligence (usually shortened as SETI) is an expression that refers to the diverse efforts and scientific projects intended to detect extraterrestrial signals, or any evidence of intelligent life beyond Earth. \nResearchers use methods such as monitoring electromagnetic radiation, searching for optical signals, and investigating potential extraterrestrial artifacts for any signs of transmission from civilizations present on other planets. Some initiatives have also attempted to send messages to hypothetical alien civilizations, such as NASA's Golden Record.\nModern SETI research began in the early 20th century after the advent of radio, expanding with projects like Project Ozma, the Wow! signal detection, and the Breakthrough Listen initiative; a $100 million, 10-year attempt to detect signals from nearby stars, announced in 2015 by Stephen Hawking and Yuri Milner. Since the 1980s, international efforts have been ongoing, with community led projects such as SETI@home and Project Argus, engaging in analyzing data. While SETI remains a respected scientific field, it often gets compared to conspiracy theory, UFO research, bringing unwarranted skepticism from the public, despite its reliance on rigorous scientific methods and verifiable data and research. Similar studies on unidentified aerial phenomena (UAP) such as the Avi Loeb's Galileo Project have brought further attention to SETI research.\nDespite decades of searching, no confirmed evidence of alien intelligence has been found, bringing criticism onto SETI for being 'overly hopeful'. Critics argue that SETI is speculative and unfalsifiable, while supporters see it as a crucial step in addressing the Fermi paradox and understanding extraterrestrial technosignature.\nHistory.\nEarly work.\nThere have been many earlier searches for extraterrestrial intelligence within the Solar System. In 1896, Nikola Tesla suggested that an extreme version of his wireless electrical transmission system could be used to contact beings on Mars. In 1899, while conducting experiments at his Colorado Springs experimental station, he thought he had detected a signal from Mars since an odd repetitive static signal seemed to cut off when Mars set in the night sky. Analysis of Tesla's research has led to a range of explanations including: \nIn the early 1900s, Guglielmo Marconi, Lord Kelvin and David Peck Todd also stated their belief that radio could be used to contact Martians, with Marconi stating that his stations had also picked up potential Martian signals.\nOn August 21\u201323, 1924, Mars entered an opposition closer to Earth than at any time in the century before or the next 80 years. In the United States, a \"National Radio Silence Day\" was promoted during a 36-hour period from August 21\u201323, with all radios quiet for five minutes on the hour, every hour. At the United States Naval Observatory, a radio receiver was lifted above the ground in a dirigible tuned to a wavelength between 8 and 9\u00a0km, using a \"radio-camera\" developed by Amherst College and Charles Francis Jenkins. The program was led by David Peck Todd with the military assistance of Admiral Edward W. Eberle (Chief of Naval Operations), with William F. Friedman (chief cryptographer of the United States Army), assigned to translate any potential Martian messages.\nA 1959 paper by Philip Morrison and Giuseppe Cocconi first pointed out the possibility of searching the microwave spectrum. It proposed frequencies and a set of initial targets.\nIn 1960, Cornell University astronomer Frank Drake performed the first modern SETI experiment, named \"Project Ozma\" after the Queen of Oz in L. Frank Baum's fantasy books. Drake used a radio telescope in diameter at Green Bank, West Virginia, to examine the stars Tau Ceti and Epsilon Eridani near the 1.420 gigahertz marker frequency, a region of the radio spectrum dubbed the \"water hole\" due to its proximity to the hydrogen and hydroxyl radical spectral lines. A 400 kilohertz band around the marker frequency was scanned using a single-channel receiver with a bandwidth of 100 hertz. He found nothing of interest.\nSoviet scientists took a strong interest in SETI during the 1960s and performed a number of searches with omnidirectional antennas in the hope of picking up powerful radio signals. Soviet astronomer Iosif Shklovsky wrote the pioneering book in the field, \"Universe, Life, Intelligence\" (1962), which was expanded upon by American astronomer Carl Sagan as the best-selling book \"Intelligent Life in the Universe\" (1966).\nIn the March 1955 issue of \"Scientific American\", John D. Kraus described an idea to scan the cosmos for natural radio signals using a flat-plane radio telescope equipped with a parabolic reflector. Within two years, his concept was approved for construction by Ohio State University. With a total of US$71,000 ()\nin grants from the National Science Foundation, construction began on an plot in Delaware, Ohio. This Ohio State University Radio Observatory telescope was called \"Big Ear\". Later, it began the world's first continuous SETI program, called the Ohio State University SETI program.\nIn 1971, NASA funded a SETI study that involved Drake, Barney Oliver of Hewlett-Packard Laboratories, and others. The resulting report proposed the construction of an Earth-based radio telescope array with 1,500 dishes known as \"Project Cyclops\". The price tag for the Cyclops array was US$10 billion. Cyclops was not built, but the report formed the basis of much SETI work that followed.\nThe Ohio State SETI program gained fame on August 15, 1977, when Jerry Ehman, a project volunteer, witnessed a startlingly strong signal received by the telescope. He quickly circled the indication on a printout and scribbled the exclamation \"Wow!\" in the margin. Dubbed the \"Wow! signal\", it is considered by some to be the best candidate for a radio signal from an artificial, extraterrestrial source ever discovered, but it has not been detected again in several additional searches.\nOn 24 May 2023, a test extraterrestrial signal, in the form of a \"coded radio signal from Mars\", was transmitted to radio telescopes on Earth, according to a report in \"The New York Times\".\nSentinel, META, and BETA.\nIn 1980, Carl Sagan, Bruce Murray, and Louis Friedman founded the U.S. Planetary Society, partly as a vehicle for SETI studies.\nIn the early 1980s, Harvard University physicist Paul Horowitz took the next step and proposed the design of a spectrum analyzer specifically intended to search for SETI transmissions. Traditional desktop spectrum analyzers were of little use for this job, as they sampled frequencies using banks of analog filters and so were restricted in the number of channels they could acquire. However, modern integrated-circuit digital signal processing (DSP) technology could be used to build autocorrelation receivers to check far more channels. This work led in 1981 to a portable spectrum analyzer named \"Suitcase SETI\" that had a capacity of 131,000 narrow band channels. After field tests that lasted into 1982, Suitcase SETI was put into use in 1983 with the Harvard/Smithsonian radio telescope at Oak Ridge Observatory in Harvard, Massachusetts. This project was named \"Sentinel\" and continued into 1985.\nEven 131,000 channels were not enough to search the sky in detail at a fast rate, so Suitcase SETI was followed in 1985 by Project \"META\", for \"Megachannel Extra-Terrestrial Assay\". The META spectrum analyzer had a capacity of 8.4 million channels and a channel resolution of 0.05 hertz. An important feature of META was its use of frequency Doppler shift to distinguish between signals of terrestrial and extraterrestrial origin. The project was led by Horowitz with the help of the Planetary Society, and was partly funded by movie maker Steven Spielberg. A second such effort, META II, was begun in Argentina in 1990, to search the southern sky, receiving an equipment upgrade in 1996\u20131997.\nThe follow-on to META was named \"BETA\", for \"Billion-channel Extraterrestrial Assay\", and it commenced observation on October 30, 1995. The heart of BETA's processing capability consisted of 63 dedicated fast Fourier transform (FFT) engines, each capable of performing a 222-point complex FFTs in two seconds, and 21 general-purpose personal computers equipped with custom digital signal processing boards. This allowed BETA to receive 250 million simultaneous channels with a resolution of 0.5 hertz per channel. It scanned through the microwave spectrum from 1.400 to 1.720 gigahertz in eight hops, with two seconds of observation per hop. An important capability of the BETA search was rapid and automatic re-observation of candidate signals, achieved by observing the sky with two adjacent beams, one slightly to the east and the other slightly to the west. A successful candidate signal would first transit the east beam, and then the west beam and do so with a speed consistent with Earth's sidereal rotation rate. A third receiver observed the horizon to veto signals of obvious terrestrial origin. On March 23, 1999, the 26-meter radio telescope on which Sentinel, META and BETA were based was blown over by strong winds and seriously damaged. This forced the BETA project to cease operation.\nMOP and Project Phoenix.\nIn 1978, the NASA SETI program had been heavily criticized by Senator William Proxmire, and funding for SETI research was removed from the NASA budget by Congress in 1981; however, funding was restored in 1982, after Carl Sagan talked with Proxmire and convinced him of the program's value. In 1992, the U.S. government funded an operational SETI program, in the form of the NASA Microwave Observing Program (MOP). MOP was planned as a long-term effort to conduct a general survey of the sky and also carry out targeted searches of 800 specific nearby stars. MOP was to be performed by radio antennas associated with the NASA Deep Space Network, as well as the radio telescope of the National Radio Astronomy Observatory at Green Bank, West Virginia and the radio telescope at the Arecibo Observatory in Puerto Rico. The signals were to be analyzed by spectrum analyzers, each with a capacity of 15 million channels. These spectrum analyzers could be grouped together to obtain greater capacity. Those used in the targeted search had a bandwidth of 1 hertz per channel, while those used in the sky survey had a bandwidth of 30 hertz per channel.\nMOP drew the attention of the United States Congress, where the program met opposition and canceled one year after its start. SETI advocates continued without government funding, and in 1995 the nonprofit SETI Institute of Mountain View, California resurrected the MOP program under the name of Project \"Phoenix\", backed by private sources of funding. In 2012 it cost around $2 million per year to maintain SETI research at the SETI Institute and around 10 times that to support different SETI activities globally. Project Phoenix, under the direction of Jill Tarter, was a continuation of the targeted search program from MOP and studied roughly 1,000 nearby Sun-like stars until approximately 2015. From 1995 through March 2004, Phoenix conducted observations at the Parkes radio telescope in Australia, the radio telescope of the National Radio Astronomy Observatory in Green Bank, West Virginia, and the radio telescope at the Arecibo Observatory in Puerto Rico. The project observed the equivalent of 800 stars over the available channels in the frequency range from 1200 to 3000\u00a0MHz. The search was sensitive enough to pick up transmitters with 1\u00a0GW EIRP to a distance of about 200 light-years.\nOngoing radio searches.\nMany radio frequencies penetrate Earth's atmosphere quite well, and this led to radio telescopes that investigate the cosmos using large radio antennas. Furthermore, human endeavors emit considerable electromagnetic radiation as a byproduct of communications such as television and radio. These signals would be easy to recognize as artificial due to their repetitive nature and narrow bandwidths. Earth has been sending radio waves from broadcasts into space for over 100 years. These signals have reached over 1,000 stars, most notably Vega, Aldebaran, Barnard's Star, Sirius, and Proxima Centauri. If intelligent alien life exists on any planet orbiting these nearby stars, these signals could be heard and deciphered, even though some of the signal is garbled by the Earth's ionosphere.\nMany international radio telescopes are currently being used for radio SETI searches, including the Low Frequency Array (LOFAR) in Europe, the Murchison Widefield Array (MWA) in Australia, and the Lovell Telescope in the United Kingdom.\nAllen Telescope Array.\nThe SETI Institute collaborated with the Radio Astronomy Laboratory at the Berkeley SETI Research Center to develop a specialized radio telescope array for SETI studies, similar to a mini-cyclops array. Formerly known as the One Hectare Telescope (1HT), the concept was renamed the \"Allen Telescope Array\" (ATA) after the project's benefactor, Paul Allen. Its sensitivity is designed to be equivalent to a single large dish more than 100 meters in diameter, if fully completed. Presently, the array has 42 operational dishes at the Hat Creek Radio Observatory in rural northern California.\nThe full array (ATA-350) is planned to consist of 350 or more offset-Gregorian radio dishes, each in diameter. These dishes are the largest producible with commercially available satellite television dish technology. The ATA was planned for a 2007 completion date, at a cost of US$25 million. The SETI Institute provided money for building the ATA while University of California, Berkeley designed the telescope and provided operational funding. The first portion of the array (ATA-42) became operational in October 2007 with 42 antennas. The DSP system planned for ATA-350 is extremely ambitious. Completion of the full 350 element array will depend on funding and the technical results from ATA-42.\nATA-42 (ATA) is designed to allow multiple observers simultaneous access to the interferometer output at the same time. Typically, the ATA snapshot imager (used for astronomical surveys and SETI) is run in parallel with a beamforming system (used primarily for SETI). ATA also supports observations in multiple synthesized pencil beams at once, through a technique known as \"multibeaming\". Multibeaming provides an effective filter for identifying false positives in SETI, since a very distant transmitter must appear at only one point on the sky.\nSETI Institute's Center for SETI Research (CSR) uses ATA in the search for extraterrestrial intelligence, observing 12 hours a day, 7 days a week. From 2007 to 2015, ATA identified hundreds of millions of technological signals. So far, all these signals have been assigned the status of noise or radio frequency interference because a) they appear to be generated by satellites or Earth-based transmitters, or b) they disappeared before the threshold time limit of ~1 hour. Researchers in CSR are working on ways to reduce the threshold time limit, and to expand ATA's capabilities for detection of signals that may have embedded messages.\nBerkeley astronomers used the ATA to pursue several science topics, some of which might have transient SETI signals, until 2011, when the collaboration between the University of California, Berkeley and the SETI Institute was terminated.\nCNET published an article and pictures about the Allen Telescope Array (ATA) on December 12, 2008.\nIn April 2011, the ATA entered an 8-month \"hibernation\" due to funding shortfalls. Regular operation of the ATA resumed on December 5, 2011.\nIn 2012, the ATA was revitalized with a $3.6 million donation by Franklin Antonio, co-founder and Chief Scientist of QUALCOMM Incorporated. This gift supported upgrades of all the receivers on the ATA dishes to have (2\u00d7 to 10\u00d7 over the range 1\u20138\u00a0GHz) greater sensitivity than before and supporting observations over a wider frequency range from 1\u201318\u00a0GHz, though initially the radio frequency electronics only go to 12\u00a0GHz. As of July 2013, the first of these receivers was installed and proven, with full installation on all 42 antennas being expected for June 2017. ATA is well suited to the search for extraterrestrial intelligence (SETI) and to discovery of astronomical radio sources, such as heretofore unexplained non-repeating, possibly extragalactic, pulses known as fast radio bursts or FRBs.\nSERENDIP.\nSERENDIP (Search for Extraterrestrial Radio Emissions from Nearby Developed Intelligent Populations) is a SETI program launched in 1979 by the Berkeley SETI Research Center. SERENDIP takes advantage of ongoing \"mainstream\" radio telescope observations as a \"piggy-back\" or \"commensal\" program, using large radio telescopes including the NRAO 90m telescope at Green Bank and, formerly, the Arecibo 305m telescope. Rather than having its own observation program, SERENDIP analyzes deep space radio telescope data that it obtains while other astronomers are using the telescopes. The most recently deployed SERENDIP spectrometer, SERENDIP VI, was installed at both the Arecibo Telescope and the Green Bank Telescope in 2014\u20132015.\nBreakthrough Listen.\n\"Breakthrough Listen\" is a ten-year initiative with $100 million funding begun in July 2015 to actively search for intelligent extraterrestrial communications in the universe, in a substantially expanded way, using resources that had not previously been extensively used for the purpose. It has been described as the most comprehensive search for alien communications to date. The science program for Breakthrough Listen is based at Berkeley SETI Research Center, located in the Astronomy Department at the University of California, Berkeley.\nAnnounced in July 2015, the project is observing for thousands of hours every year on two major radio telescopes, the Green Bank Observatory in West Virginia, and the Parkes Observatory in Australia. Previously, only about 24 to 36 hours of telescope time per year were used in the search for alien life. Furthermore, the Automated Planet Finder at Lick Observatory is searching for optical signals coming from laser transmissions. The massive data rates from the radio telescopes (24 GB/s at Green Bank) necessitated the construction of dedicated hardware at the telescopes to perform the bulk of the analysis. Some of the data are also analyzed by volunteers in the SETI@home volunteer computing network. Founder of modern SETI Frank Drake was one of the scientists on the project's advisory committee.\nIn October 2019, Breakthrough Listen started a collaboration with scientists from the TESS team (Transiting Exoplanet Survey Satellite) to look for signs of advanced extraterrestrial life. Thousands of new planets found by TESS will be scanned for technosignatures by Breakthrough Listen partner facilities across the globe. Data from TESS monitoring of stars will also be searched for anomalies.\nFAST.\nChina's 500 meter Aperture Spherical Telescope (FAST) lists \"detecting interstellar communication signals\" as part of its science mission. It is funded by the National Development and Reform Commission (NDRC) and managed by the National Astronomical observatories (NAOC) of the Chinese Academy of Sciences (CAS). FAST is the first radio observatory built with SETI as a core scientific goal. FAST consists of a fixed diameter spherical dish constructed in a natural depression sinkhole caused by karst processes in the region. It is the world's largest filled-aperture radio telescope.\nAccording to its website, FAST can search to 28 light-years, and is able to reach 1,400 stars. If the transmitter's radiated power were to be increased to 1,000,000 MW, FAST would be able to reach one million stars. This is compared to the former Arecibo 305 meter telescope detection distance of 18 light-years.\nOn 14 June 2022, astronomers, working with China's FAST telescope, reported the possibility of having detected artificial (presumably alien) signals, but cautioned that further studies were required to determine if a natural radio interference may be the source. More recently, on 18 June 2022, Dan Werthimer, chief scientist for several SETI-related projects, reportedly noted, \"These signals are from radio interference; they are due to radio pollution from earthlings, not from E.T.\".\nUCLA.\nSince 2016, University of California Los Angeles (UCLA) undergraduate and graduate students have been participating in radio searches for technosignatures with the Green Bank Telescope. Targets include the Kepler field, TRAPPIST-1, and solar-type stars. The search is sensitive to Arecibo-class transmitters located within 420 light years of Earth and to transmitters that are 1,000 times more powerful than Arecibo located within 13,000 light years of Earth.\nCommunity SETI projects.\nSETI@home.\nThe SETI@home project used volunteer computing to analyze signals acquired by the SERENDIP project.\nSETI@home was conceived by David Gedye along with Craig Kasnoff and is a popular volunteer computing project that was launched by the Berkeley SETI Research Center at the University of California, Berkeley, in May 1999. It was originally funded by The Planetary Society and Paramount Pictures, and later by the state of California. The project is run by director David P. Anderson and chief scientist Dan Werthimer. Any individual could become involved with SETI research by downloading the Berkeley Open Infrastructure for Network Computing (BOINC) software program, attaching to the SETI@home project, and allowing the program to run as a background process that uses idle computer power. The SETI@home program itself ran signal analysis on a \"work unit\" of data recorded from the central 2.5\u00a0MHz wide band of the SERENDIP IV instrument. After computation on the work unit was complete, the results were then automatically reported back to SETI@home servers at University of California, Berkeley. By June 28, 2009, the SETI@home project had over 180,000 active participants volunteering a total of over 290,000 computers. These computers gave SETI@home an average computational power of 617 teraFLOPS. In 2004 radio source SHGb02+14a set off speculation in the media that a signal had been detected but researchers noted the frequency drifted rapidly and the detection on three SETI@home computers fell within random chance.\nBy 2010, after 10 years of data collection, SETI@home had listened to that one frequency at every point of over 67 percent of the sky observable from Arecibo with at least three scans (out of the goal of nine scans), which covers about 20 percent of the full celestial sphere. On March 31, 2020, with 91,454 active users, the project stopped sending out new work to SETI@home users, bringing this particular SETI effort to an indefinite hiatus.\nSETI Net.\nSETI Network was the only fully operational private search system. The SETI Net station consisted of off-the-shelf, consumer-grade electronics to minimize cost and to allow this design to be replicated as simply as possible. It had a 3-meter parabolic antenna that could be directed in azimuth and elevation, an LNA that covered 100\u00a0MHz of the 1420\u00a0MHz spectrum, a receiver to reproduce the wideband audio, and a standard personal computer as the control device and for deploying the detection algorithms. The antenna could be pointed and locked to one sky location in Ra and DEC which enabling the system to integrate on it for long periods. The Wow! signal area was monitored for many long periods. All search data was collected and is available on the Internet archive.\nSETI Net started operation in the early 1980s as a way to learn about the science of the search, and developed several software packages for the amateur SETI community. It provided an astronomical clock, a file manager to keep track of SETI data files, a spectrum analyzer optimized for amateur SETI, remote control of the station from the Internet, and other packages.\nSETI Net went dark and was decommissioned on 2021-12-04. The collected data is available on their website.\nThe SETI League and Project Argus.\nFounded in 1994 in response to the United States Congress cancellation of the NASA SETI program, The SETI League, Incorporated is a membership-supported nonprofit organization with 1,500 members in 62 countries. This grass-roots alliance of amateur and professional radio astronomers is headed by executive director emeritus H. Paul Shuch, the engineer credited with developing the world's first commercial home satellite TV receiver. Many SETI League members are licensed radio amateurs and microwave experimenters. Others are digital signal processing experts and computer enthusiasts.\nThe SETI League pioneered the conversion of backyard satellite TV dishes in diameter into research-grade radio telescopes of modest sensitivity. The organization concentrates on coordinating a global network of small, amateur-built radio telescopes under Project Argus, an all-sky survey seeking to achieve real-time coverage of the entire sky. Project Argus was conceived as a continuation of the all-sky survey component of the late NASA SETI program (the targeted search having been continued by the SETI Institute's Project Phoenix). There are currently 143 Project Argus radio telescopes operating in 27 countries. Project Argus instruments typically exhibit sensitivity on the order of 10\u221223 Watts/square metre, or roughly equivalent to that achieved by the Ohio State University Big Ear radio telescope in 1977, when it detected the landmark \"Wow!\" candidate signal.\nThe name \"Argus\" derives from the mythical Greek guard-beast who had 100 eyes, and could see in all directions at once. In the SETI context, the name has been used for radio telescopes in fiction (Arthur C. Clarke, \"Imperial Earth\"; Carl Sagan, \"Contact\"), was the name initially used for the NASA study ultimately known as \"Cyclops,\" and is the name given to an omnidirectional radio telescope design being developed at the Ohio State University.\nOptical experiments.\nWhile most SETI sky searches have studied the radio spectrum, some SETI researchers have considered the possibility that alien civilizations might be using powerful lasers for interstellar communications at optical wavelengths. The idea was first suggested by R. N. Schwartz and Charles Hard Townes in a 1961 paper published in the journal \"Nature\" titled \"Interstellar and Interplanetary Communication by Optical Masers\". However, the 1971 Cyclops study discounted the possibility of optical SETI, reasoning that construction of a laser system that could outshine the bright central star of a remote star system would be too difficult. In 1983, Townes published a detailed study of the idea in the United States journal \"Proceedings of the National Academy of Sciences\", which was met with interest by the SETI community.\nThere are two problems with optical SETI. The first problem is that lasers are highly \"monochromatic\", that is, they emit light only on one frequency, making it troublesome to figure out what frequency to look for. However, emitting light in narrow pulses results in a broad spectrum of emission; the spread in frequency becomes higher as the pulse width becomes narrower, making it easier to detect an emission.\nThe other problem is that while radio transmissions can be broadcast in all directions, lasers are highly directional. Interstellar gas and dust is almost transparent to near infrared, so these signals can be seen from greater distances, but the extraterrestrial laser signals would need to be transmitted in the direction of Earth in order to be detected.\nOptical SETI supporters have conducted paper studies of the effectiveness of using contemporary high-energy lasers and a ten-meter diameter mirror as an interstellar beacon. The analysis shows that an infrared pulse from a laser, focused into a narrow beam by such a mirror, would appear thousands of times brighter than the Sun to a distant civilization in the beam's line of fire. The Cyclops study proved incorrect in suggesting a laser beam would be inherently hard to see.\nSuch a system could be made to automatically steer itself through a target list, sending a pulse to each target at a constant rate. This would allow targeting of all Sun-like stars within a distance of 100 light-years. The studies have also described an automatic laser pulse detector system with a low-cost, two-meter mirror made of carbon composite materials, focusing on an array of light detectors. This automatic detector system could perform sky surveys to detect laser flashes from civilizations attempting contact.\nSeveral optical SETI experiments are now in progress. A Harvard-Smithsonian group that includes Paul Horowitz designed a laser detector and mounted it on Harvard's optical telescope. This telescope is currently being used for a more conventional star survey, and the optical SETI survey is \"piggybacking\" on that effort. Between October 1998 and November 1999, the survey inspected about 2,500 stars. Nothing that resembled an intentional laser signal was detected, but efforts continue. The Harvard-Smithsonian group is now working with Princeton University to mount a similar detector system on Princeton's 91-centimeter (36-inch) telescope. The Harvard and Princeton telescopes will be \"ganged\" to track the same targets at the same time, with the intent being to detect the same signal in both locations as a means of reducing errors from detector noise.\nThe Harvard-Smithsonian SETI group led by Professor Paul Horowitz built a dedicated all-sky optical survey system along the lines of that described above, featuring a 1.8-meter (72-inch) telescope. The new optical SETI survey telescope is being set up at the Oak Ridge Observatory in Harvard, Massachusetts.\nThe University of California, Berkeley, home of SERENDIP and SETI@home, is also conducting optical SETI searches and collaborates with the NIROSETI program. The optical SETI program at Breakthrough Listen was initially directed by Geoffrey Marcy, an extrasolar planet hunter, and it involves examination of records of spectra taken during extrasolar planet hunts for a continuous, rather than pulsed, laser signal. This survey uses the Automated Planet Finder 2.4-m telescope at the Lick Observatory, situated on the summit of Mount Hamilton, east of San Jose, California. The other Berkeley optical SETI effort is being pursued by the Harvard-Smithsonian group and is being directed by Dan Werthimer of Berkeley, who built the laser detector for the Harvard-Smithsonian group. This survey uses a 76-centimeter (30-inch) automated telescope at Leuschner Observatory and an older laser detector built by Werthimer.\nThe SETI Institute also runs a program called 'Laser SETI' with an instrument composed of several cameras that continuously survey the entire night sky searching for millisecond singleton laser pulses of extraterrestrial origin.\nIn January 2020, two Pulsed All-sky Near-infrared Optical SETI (PANOSETI) project telescopes were installed in the Lick Observatory Astrograph Dome. The project aims to commence a wide-field optical SETI search and continue prototyping designs for a full observatory. The installation can offer an \"all-observable-sky\" optical and wide-field near-infrared pulsed technosignature and astrophysical transient search for the northern hemisphere.\nIn May 2017, astronomers reported studies related to laser light emissions from stars, as a way of detecting technology-related signals from an alien civilization. The reported studies included Tabby's Star (designated KIC 8462852 in the Kepler Input Catalog), an oddly dimming star in which its unusual starlight fluctuations may be the result of interference by an artificial megastructure, such as a Dyson swarm, made by such a civilization. No evidence was found for technology-related signals from KIC 8462852 in the studies.\nQuantum communications.\nIn a 2020 paper, Berera examined sources of decoherence in the interstellar medium and made the observation that quantum coherence \nof photons in certain frequency bands could be sustained to interstellar distances. \nIt was suggested this would allow for quantum communication at these distances.\nIn a 2021 preprint, astronomer Michael Hipke described for the first time how one could search for quantum communication transmissions sent by ETI using existing telescope and receiver technology. He also provides arguments for why future searches of ETI should also target interstellar quantum communication networks.\nA 2022 paper by Arjun Berera and Jaime Calder\u00f3n-Figueroa noted that interstellar quantum communication by other civilizations could be possible and may be advantageous, identifying some potential challenges and factors for detecting technosignatures. They may, for example, use X-ray photons for remotely established quantum communication and quantum teleportation as the communication mode.\nSearch for extraterrestrial artifacts.\nThe possibility of using interstellar messenger probes in the search for extraterrestrial intelligence was first suggested by Ronald N. Bracewell in 1960 (see Bracewell probe), and the technical feasibility of this approach was demonstrated by the British Interplanetary Society's starship study Project Daedalus in 1978. Starting in 1979, Robert Freitas advanced arguments for the proposition that physical space-probes are a superior mode of interstellar communication to radio signals (see Voyager Golden Record).\nIn recognition that any sufficiently advanced interstellar probe in the vicinity of Earth could easily monitor the terrestrial Internet, 'Invitation to ETI' was established by Allen Tough in 1996, as a Web-based SETI experiment inviting such spacefaring probes to establish contact with humanity. The project's 100 signatories includes prominent physical, biological, and social scientists, as well as artists, educators, entertainers, philosophers and futurists. H. Paul Shuch, executive director emeritus of The SETI League, serves as the project's Principal Investigator.\nInscribing a message in matter and transporting it to an interstellar destination can be enormously more energy efficient than communication using electromagnetic waves if delays larger than light transit time can be tolerated. That said, for simple messages such as \"hello,\" radio SETI could be far more efficient. If energy requirement is used as a proxy for technical difficulty, then a solarcentric Search for Extraterrestrial Artifacts (SETA) may be a useful supplement to traditional radio or optical searches.\nMuch like the \"preferred frequency\" concept in SETI radio beacon theory, the Earth-Moon or Sun-Earth libration orbits might therefore constitute the most universally convenient parking places for automated extraterrestrial spacecraft exploring arbitrary stellar systems. A viable long-term SETI program may be founded upon a search for these objects.\nIn 1979, Freitas and Valdes conducted a photographic search of the vicinity of the Earth-Moon triangular libration points L4 and L5, and of the solar-synchronized positions in the associated halo orbits, seeking possible orbiting extraterrestrial interstellar probes, but found nothing to a detection limit of about 14th magnitude. The authors conducted a second, more comprehensive photographic search for probes in 1982 that examined the five Earth-Moon Lagrangian positions and included the solar-synchronized positions in the stable L4/L5 libration orbits, the potentially stable nonplanar orbits near L1/L2, Earth-Moon L3, and also L2 in the Sun-Earth system. Again no extraterrestrial probes were found to limiting magnitudes of 17\u201319th magnitude near L3/L4/L5, 10\u201318th magnitude for L1/L2, and 14\u201316th magnitude for Sun-Earth L2.\nIn June 1983, Valdes and Freitas used the 26 m radiotelescope at Hat Creek Radio Observatory to search for the tritium hyperfine line at 1516\u00a0MHz from 108 assorted astronomical objects, with emphasis on 53 nearby stars including all visible stars within a 20 light-year radius. The tritium frequency was deemed highly attractive for SETI work because (1) the isotope is cosmically rare, (2) the tritium hyperfine line is centered in the SETI water hole region of the terrestrial microwave window, and (3) in addition to beacon signals, tritium hyperfine emission may occur as a byproduct of extensive nuclear fusion energy production by extraterrestrial civilizations. The wideband- and narrowband-channel observations achieved sensitivities of 5\u201314\u00d710\u221221\u00a0W/m2/channel and 0.7\u20132\u00d710\u221224\u00a0W/m2/channel, respectively, but no detections were made.\nOthers have speculated that we might find traces of past civilizations in our very own Solar System, on planets like Venus or Mars, although the traces would be found most likely underground.\nTechnosignatures.\nTechnosignatures, including all signs of technology, are a recent avenue in the search for extraterrestrial intelligence. Technosignatures may originate from various sources, from megastructures such as Dyson spheres and space mirrors or space shaders to the atmospheric contamination created by an industrial civilization, or city lights on extrasolar planets, and may be detectable in the future with large hypertelescopes.\nTechnosignatures can be divided into three broad categories: astroengineering projects, signals of planetary origin, and spacecraft within and outside the Solar System.\nAn astroengineering installation such as a Dyson sphere, designed to convert all of the incident radiation of its host star into energy, could be detected through the observation of an infrared excess from a solar analog star, or by the star's apparent disappearance in the visible spectrum over several years. After examining some 100,000 nearby large galaxies, a team of researchers has concluded that none of them display any obvious signs of highly advanced technological civilizations.\nAnother hypothetical form of astroengineering, the Shkadov thruster, moves its host star by reflecting some of the star's light back on itself, and would be detected by observing if its transits across the star abruptly end with the thruster in front. Asteroid mining within the Solar System is also a detectable technosignature of the first kind.\nIndividual extrasolar planets can be analyzed for signs of technology. Avi Loeb of the Center for Astrophysics | Harvard &amp; Smithsonian has proposed that persistent light signals on the night side of an exoplanet can be an indication of the presence of cities and an advanced civilization. In addition, the excess infrared radiation and chemicals produced by various industrial processes or terraforming efforts may point to intelligence.\nLight and heat detected from planets need to be distinguished from natural sources to conclusively prove the existence of civilization on a planet. However, as argued by the Colossus team, a civilization heat signature should be within a \"comfortable\" temperature range, like terrestrial urban heat islands, i.e., only a few degrees warmer than the planet itself. In contrast, such natural sources as wild fires, volcanoes, etc. are significantly hotter, so they will be well distinguished by their maximum flux at a different wavelength.\nOther than astroengineering, technosignatures such as artificial satellites around exoplanets, particularly such in geostationary orbit, might be detectable even with today's technology and data, and would allow, similar to fossils on Earth, to find traces of extrasolar life from long ago.\nExtraterrestrial craft are another target in the search for technosignatures. Magnetic sail interstellar spacecraft should be detectable over thousands of light-years of distance through the synchrotron radiation they would produce through interaction with the interstellar medium; other interstellar spacecraft designs may be detectable at more modest distances. In addition, robotic probes within the Solar System are also being sought with optical and radio searches.\nFor a sufficiently advanced civilization, hyper energetic neutrinos from Planck scale accelerators should be detectable at a distance of many Mpc.\nFermi paradox.\nItalian physicist Enrico Fermi suggested in the 1950s that if technologically advanced civilizations are common in the universe, then they should be detectable in one way or another. According to those who were there, Fermi either asked \"Where are they?\" or \"Where is everybody?\"\nThe Fermi paradox is commonly understood as asking why extraterrestrials have not visited Earth, but the same reasoning applies to the question of why signals from extraterrestrials have not been heard. The SETI version of the question is sometimes referred to as \"the Great Silence\".\nThe Fermi paradox can be stated more completely as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The size and age of the universe incline us to believe that many technologically advanced civilizations must exist. However, this belief seems logically inconsistent with our lack of observational evidence to support it. Either (1) the initial assumption is incorrect and technologically advanced intelligent life is much rarer than we believe, or (2) our current observations are incomplete, and we simply have not detected them yet, or (3) our search methodologies are flawed and we are not searching for the correct indicators, or (4) it is the nature of intelligent life to destroy itself.\nThere are multiple explanations proposed for the Fermi paradox, ranging from analyses suggesting that intelligent life is rare (the \"Rare Earth hypothesis\"), to analyses suggesting that although extraterrestrial civilizations may be common, they would not communicate with us, would communicate in a way we have not discovered yet, could not travel across interstellar distances, or destroy themselves before they master the technology of either interstellar travel or communication.\nThe German astrophysicist and radio astronomer Sebastian von Hoerner suggested that the average duration of civilization was 6,500 years. After this time, according to him, it disappears for external reasons (the destruction of life on the planet, the destruction of only rational beings) or internal causes (mental or physical degeneration). According to his calculations, on a habitable planet (one in three million stars) there is a sequence of technological species over a time distance of hundreds of millions of years, and each of them \"produces\" an average of four technological species. With these assumptions, the average distance between civilizations in the Milky Way is 1,000 light years.\nScience writer Timothy Ferris has posited that since galactic societies are most likely only transitory, an obvious solution is an interstellar communications network, or a type of library consisting mostly of automated systems. They would store the cumulative knowledge of vanished civilizations and communicate that knowledge through the galaxy. Ferris calls this the \"Interstellar Internet\", with the various automated systems acting as network \"servers\". If such an Interstellar Internet exists, the hypothesis states, communications between servers are mostly through narrow-band, highly directional radio or laser links. Intercepting such signals is, as discussed earlier, very difficult. However, the network could maintain some broadcast nodes in hopes of making contact with new civilizations.\nAlthough somewhat dated in terms of \"information culture\" arguments, not to mention the obvious technological problems of a system that could work effectively for billions of years and requires multiple lifeforms agreeing on certain basics of communications technologies, this hypothesis is actually testable (see below).\nDifficulty of detection.\nA significant problem is the vastness of space. Despite piggybacking on the world's most sensitive radio telescope, astronomer and initiator of SERENDIP Charles Stuart Bowyer noted the then world's largest instrument could not detect random radio noise emanating from a civilization like ours, which has been leaking radio and TV signals for less than 100 years. For SERENDIP and most other SETI projects to detect a signal from an extraterrestrial civilization, the civilization would have to be beaming a powerful signal directly at us. It also means that Earth civilization will only be detectable within a distance of 100 light-years.\nPost-detection disclosure protocol.\nThe International Academy of Astronautics (IAA) has a long-standing SETI Permanent Study Group (SPSG, formerly called the IAA SETI Committee), which addresses matters of SETI science, technology, and international policy. The SPSG meets in conjunction with the International Astronautical Congress (IAC), held annually at different locations around the world, and sponsors two SETI Symposia at each IAC. In 2005, the IAA established the SETI: Post-Detection Science and Technology Taskgroup (chairman, Professor Paul Davies) \"to act as a Standing Committee to be available to be called on at any time to advise and consult on questions stemming from the discovery of a putative signal of extraterrestrial intelligent (ETI) origin.\"\nHowever, the protocols mentioned apply only to radio SETI rather than for METI (Active SETI). The intention for METI is covered under the SETI charter \"Declaration of Principles Concerning Sending Communications with Extraterrestrial Intelligence\".\nIn October 2000 astronomers Iv\u00e1n Alm\u00e1r and Jill Tarter presented a paper to The SETI Permanent Study Group in Rio de Janeiro, Brazil which proposed a scale (modelled after the Torino scale) which is an ordinal scale between zero and ten that quantifies the impact of any public announcement regarding evidence of extraterrestrial intelligence; the Rio scale has since inspired the 2005 San Marino Scale (in regard to the risks of transmissions from Earth) and the 2010 London Scale (in regard to the detection of extraterrestrial life). The Rio scale itself was revised in 2018.\nThe SETI Institute does not officially recognize the Wow! signal as of extraterrestrial origin as it was unable to be verified, although in a 2020 Twitter post the organization stated that \"an astronomer might have pinpointed the host star\". The SETI Institute has also publicly denied that the candidate signal Radio source SHGb02+14a is of extraterrestrial origin. Although other volunteering projects such as Zooniverse credit users for discoveries, there is currently no crediting or early notification by SETI@Home following the discovery of a signal.\nSome people, including Steven M. Greer, have expressed cynicism that the general public might not be informed in the event of a genuine discovery of extraterrestrial intelligence due to significant vested interests. Some, such as Bruce Jakosky have also argued that the official disclosure of extraterrestrial life may have far reaching and as yet undetermined implications for society, particularly for the world's religions.\nActive SETI.\nActive SETI, also known as messaging to extraterrestrial intelligence (METI), consists of sending signals into space in the hope that they will be detected by an alien intelligence.\nRealized interstellar radio message projects.\nIn November 1974, a largely symbolic attempt was made at the Arecibo Observatory to send a message to other worlds. Known as the Arecibo Message, it was sent towards the globular cluster M13, which is 25,000 light-years from Earth. Further IRMs Cosmic Call, Teen Age Message, Cosmic Call 2, and A Message From Earth were transmitted in 1999, 2001, 2003 and 2008 from the Evpatoria Planetary Radar.\nDebate.\nWhether or not to attempt to contact extraterrestrials has attracted significant academic debate in the fields of space ethics and space policy. Physicist Stephen Hawking, in his book \"A Brief History of Time\", suggests that \"alerting\" extraterrestrial intelligences to our existence is foolhardy, citing humankind's history of treating its own kind harshly in meetings of civilizations with a significant technology gap, e.g., the extermination of Tasmanian aborigines. He suggests, in view of this history, that we \"lay low\". In one response to Hawking, in September 2016, astronomer Seth Shostak sought to allay such concerns. Astronomer Jill Tarter also disagrees with Hawking, arguing that aliens developed and long-lived enough to communicate and travel across interstellar distances would have evolved a cooperative and less violent intelligence. She however thinks it is too soon for humans to attempt active SETI and that humans should be more advanced technologically first but keep listening in the meantime.\nCriticism.\nAs various SETI projects have progressed, some have criticized early claims by researchers as being too \"euphoric\". For example, Peter Schenkel, while remaining a supporter of SETI projects, wrote in 2006 that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nCritics claim that the existence of extraterrestrial intelligence has no good Popperian criteria for falsifiability, as explained in a 2009 editorial in \"Nature\", which said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Seti... has always sat at the edge of mainstream astronomy. This is partly because, no matter how scientifically rigorous its practitioners try to be, SETI can't escape an association with UFO believers and other such crackpots. But it is also because SETI is arguably not a falsifiable experiment. Regardless of how exhaustively the Galaxy is searched, the null result of radio silence doesn't rule out the existence of alien civilizations. It means only that those civilizations might not be using radio to communicate.\n\"Nature\" added that SETI was \"marked by a hope, bordering on faith\" that aliens were aiming signals at us, that a hypothetical alien SETI project looking at Earth with \"similar faith\" would be \"sorely disappointed\", despite our many untargeted radar and TV signals, and our few targeted Active SETI radio signals denounced by those fearing aliens, and that it had difficulties attracting even sympathetic working scientists and government funding because it was \"an effort so likely to turn up nothing\".\nHowever, \"Nature\" also added, \"Nonetheless, a small SETI effort is well worth supporting, especially given the enormous implications if it did succeed\" and that \"happily, a handful of wealthy technologists and other private donors have proved willing to provide that support\".\nSupporters of the Rare Earth Hypothesis argue that advanced lifeforms are likely to be very rare, and that, if that is so, then SETI efforts will be futile. However, the Rare Earth Hypothesis itself faces many criticisms.\nIn 1993, Roy Mash stated that \"Arguments favoring the existence of extraterrestrial intelligence nearly always contain an overt appeal to big numbers, often combined with a covert reliance on generalization from a single instance\" and concluded that \"the dispute between believers and skeptics is seen to boil down to a conflict of intuitions which can barely be engaged, let alone resolved, given our present state of knowledge\". In response, in 2012, Milan M. \u0106irkovi\u0107, then research professor at the Astronomical Observatory of Belgrade and a research associate of the Future of Humanity Institute at the University of Oxford, said that Mash was unrealistically over-reliant on excessive abstraction that ignored the empirical information available to modern SETI researchers.\nGeorge Basalla, Emeritus Professor of History at the University of Delaware, is a critic of SETI who argued in 2006 that \"extraterrestrials discussed by scientists are as imaginary as the spirits and gods of religion or myth\", and was in turn criticized by Milan M. \u0106irkovi\u0107 for, among other things, being unable to distinguish between \"SETI believers\" and \"scientists engaged in SETI\", who are often sceptical (especially about quick detection), such as Freeman Dyson and, at least in their later years, Iosif Shklovsky and Sebastian von Hoerner, and for ignoring the difference between the knowledge underlying the arguments of modern scientists and those of ancient Greek thinkers.\nMassimo Pigliucci, Professor of Philosophy at CUNY \u2013 City College, asked in 2010 whether SETI is \"uncomfortably close to the status of pseudoscience\" due to the lack of any clear point at which negative results cause the hypothesis of Extraterrestrial Intelligence to be abandoned, before eventually concluding that SETI is \"almost-science\", which is described by Milan M. \u0106irkovi\u0107 as Pigliucci putting SETI in \"the illustrious company of string theory, interpretations of quantum mechanics, evolutionary psychology and history (of the 'synthetic' kind done recently by Jared Diamond)\", while adding that his justification for doing so with SETI \"is weak, outdated, and reflecting particular philosophical prejudices similar to the ones described above in Mash and Basalla\".\nRichard Carrigan, a particle physicist at the Fermi National Accelerator Laboratory near Chicago, Illinois, suggested that passive SETI could also be dangerous and that a signal released onto the Internet could act as a computer virus. Computer security expert Bruce Schneier dismissed this possibility as a \"bizarre movie-plot threat\".\nUfology.\n Ufologist Stanton Friedman has often criticized SETI researchers for, among other reasons, what he sees as their unscientific criticisms of Ufology, but, unlike SETI, Ufology has generally not been embraced by academia as a scientific field of study, and it is usually characterized as a partial or total pseudoscience. In a 2016 interview, Jill Tarter pointed out that it is still a misconception that SETI and UFOs are related. She states, \"SETI uses the tools of the astronomer to attempt to find evidence of somebody else's technology coming from a great distance. If we ever claim detection of a signal, we will provide evidence and data that can be independently confirmed. UFOs\u2014none of the above.\" The Galileo Project headed by Harvard astronomer Avi Loeb is one of the few scientific efforts to study UFOs or UAPs. Loeb criticized that the study of UAP is often dismissed and not sufficiently studied by scientists and should shift from \"occupying the talking points of national security administrators and politicians\" to the realm of science. The Galileo Project's position after the publication of the 2021 UFO Report by the U.S. Intelligence community is that the scientific community needs to \"systematically, scientifically and transparently look for potential evidence of extraterrestrial technological equipment\".\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28154", "revid": "70", "url": "https://en.wikipedia.org/wiki?curid=28154", "title": "Sextans", "text": "Constellation on the celestial equator\nSextans is a faint, minor constellation on the celestial equator which was introduced in 1687 by Polish astronomer Johannes Hevelius. Its name is Latin for the astronomical sextant, an instrument that Hevelius made frequent use of in his observations.\nCharacteristics.\nSextans is a medium sized constellation bordering Leo to the north, touching on Hydra to the southwest, and Crater to the southeast. The recommended three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"Sex\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a square. In the equatorial coordinate system, the right ascension coordinates of these borders lie between 09h 41m and 10h 51m, while the declination coordinates are between +6.43\u00b0 and \u221211.7\u00b0. Since it is close to the ecliptic plane, the Moon and planets regularly cross the constellation, especially its northeastern corner.\nNotable features.\nStars.\nJohn Flamsteed labeled 41 stars for the constellation. Francis Baily intended to give Bayer designations to some of the stars but because none of them were above magnitude 4.5, he left them unlettered. Rather, it was Benjamin Apthorp Gould who lettered some of the stars. He labeled the five brightest stars using Greek letters Alpha (\u03b1) to Epsilon (\u03b5) in his \"Uranometria Argentina\". All together, there are 38 stars that are brighter than or equal to apparent magnitude 6.5.\nMultiple star systems.\nSextans contains a few notable multiple star systems within its boundaries.\n35 Sextantis is a triple star system consisting of two evolved K-type giants of equal mass, with both stars being twice as massive as the Sun. The secondary is itself a single-lined spectroscopic binary consisting of a 0.58\u00a0M\u2609 companion and itself. The system is located approximately 700 light years away. The outer pair has a separation of 6.8\" and both stars take roughly 23,000 years to orbit each other while the B subsystem takes 1,528 days to circle each other in a relatively eccentric orbit.\nThere are a few notable variable stars, including 25, 23 Sextantis, and LHS 292. NGC 3115, an edge-on lenticular galaxy, is the only noteworthy deep-sky object. It also lies near the ecliptic, which causes the Moon, and some of the planets to occasionally pass through it for brief periods of time.\nThe constellation is the location of the field studied by the COSMOS project, undertaken by the Hubble Space Telescope.\nCOSMOS project.\nSextans B is a fairly bright dwarf irregular galaxy at magnitude 6.6, 4.3 million light-years from Earth. It is part of the Local Group of galaxies.\nCL J1001+0220 is as of 2016 the most distant-known galaxy cluster at redshift z=2.506, 11.1 billion light-years from Earth.\nIn June 2015, astronomers reported evidence for population III stars in the Cosmos Redshift 7 galaxy (at \"z\" = 6.60) found in Sextans. Such stars are likely to have existed in the very early universe (i.e., at high redshift), and may have started the production of chemical elements heavier than hydrogen that are needed for the later formation of planets and life as we know it.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28155", "revid": "41195652", "url": "https://en.wikipedia.org/wiki?curid=28155", "title": "Sculptor", "text": ""}
{"id": "28156", "revid": "372290", "url": "https://en.wikipedia.org/wiki?curid=28156", "title": "Salem al-Hazmi", "text": "Saudi terrorist and 9/11 hijacker (1981\u20132001)\nSalem Muhammed al-Hazmi (; February 2, 1981\u00a0\u2013 September 11, 2001) was a Saudi terrorist hijacker who was one of the five hijackers who assisted in the hijacking of American Airlines Flight 77 as part of the September 11 attacks. The aircraft was deliberately crashed into the Pentagon near Washington, D.C., killing everyone aboard the flight, including al-Hazmi.\nAl-Hazmi had a relatively long history with al-Qaeda before being selected for the attacks. He obtained a tourist visa through the Visa Express program and arrived in the United States in June 2001 where he would settle in New Jersey with other American 77 hijackers up until the attacks.\nOn September 11, 2001, al-Hazmi boarded Flight 77 alongside four accomplices, his older brother Nawaf al-Hazmi included. He helped subdue the passengers and crew, allowing the team's suicide pilot Hani Hanjour to take control of the plane. Al-Hazmi had turned 20 that same year, making him the youngest of the nineteen terrorists to perpetrate the attacks.\nBiography.\nSalem Muhammed al-Hazmi was born on February 2, 1981, to Muhammad Salim al-Hazmi, a grocer, in Mecca, Saudi Arabia. His father described Salem as a quarrelsome teenager who had problems with alcohol and petty theft. However, he stopped drinking and began to attend the mosque about three months before he left his family.\nThere are reports that he fought in Afghanistan with his brother, Nawaf al-Hazmi, and other reports say the two fought together in Chechnya. Salem al-Hazmi was an al-Qaeda veteran by the time he was selected for participation in the 9/11 attacks. U.S. intelligence learned of al-Hazmi's involvement with al-Qaeda as early as 1999, but he was not placed on any watchlists.\nKnown as \"Bilal\" during the preparations, both he and Ahmed al-Ghamdi flew to Beirut in November 2000, though on separate flights.\nAlong with Nawaf al-Hazmi and several other future hijackers, Salem al-Hazmi may have attended the 2000 al-Qaeda Summit in Kuala Lumpur, Malaysia. It was there that the details of the 9/11 attacks were decided upon.\nIn the United States.\nAccording to the FBI and the 9/11 Commission report, al-Hazmi first entered the United States on June 29, 2001, although there are numerous unconfirmed reports that he was living in San Antonio, Texas, with fellow hijacker Satam al-Suqami much earlier. Al-Hazmi used the controversial Visa Express program to gain entry into the country.\nAl-Hazmi moved to Paterson, New Jersey, where he lived with Hani Hanjour. Both were among the five hijackers who applied for Virginia identity cards at the Arlington office of the Virginia Department of Motor Vehicles on August 2, 2001, although Salem al-Hazmi already held an NJ identity card.\nOn August 27, brothers Nawaf and Salem al-Hazmi purchased flight tickets through Travelocity.com using the former's Visa card.\nWith the four other Flight 77 hijackers, he worked out at a Gold's Gym in Greenbelt, Maryland, from September 2 to September 6 of the same year.\nAttacks.\nOn September 11, 2001, al-Hazmi boarded American Airlines Flight 77. Airport surveillance video from Dulles International Airport in Northern Virginia shows two of the five hijackers, including Salem al-Hazmi, being pulled aside to undergo additional scrutiny after setting off metal detectors.\nThe flight was scheduled to depart at 08:10, but ended up departing 10\u00a0minutes late from Gate\u00a0D26 at Dulles. The last normal radio communications from the aircraft to air traffic control occurred at 08:50:51. At 08:54, Flight\u00a077 began to deviate from its normal, assigned flight path and turned south, and then hijackers set the flight's autopilot heading for Washington, D.C. Passenger Barbara Olson called her husband, United States Solicitor General Theodore Olson, and reported that the plane had been hijacked and that the assailants had box cutters and knives. At 09:37, American Airlines Flight 77 crashed into the west facade of the Pentagon, killing all 64 aboard (including the hijackers), along with 125 on the ground in the Pentagon. In the recovery process at the Pentagon, remains of all five Flight\u00a077 hijackers were identified through a process of elimination, as not matching any DNA samples for the victims, and put into custody of the FBI. Forensics teams confirmed that it seemed two of the hijackers were brothers, based on their DNA similarities.\nMistaken identity allegations.\nShortly after the attacks, several sources reported that Salem al-Hazmi, 26, was alive and working at a petrochemical plant in Yanbu, Saudi Arabia. He claimed that his passport had been stolen by a pickpocket in Cairo three years before, and that the pictures and details such as date of birth released to the public by the FBI were his own. He also stated that he had never visited the United States, but volunteered to fly to the U.S. to prove his innocence. On September 19, \"Al-Sharq Al-Awsat\" published his photograph alongside Badr al-Hazmi's, who they claimed was the actual hijacker who had stolen his identity.\nAfter some confusion and doubt Saudi Arabia admitted that in fact the names of the hijackers were correct. \"The names that we got confirmed that,\" Interior Minister Prince Nayef said in an interview with The Associated Press. \"Their families have been notified.\" Nayef said the Saudi leadership was shocked to learn 15 of the hijackers were from Saudi Arabia and said it was natural that the kingdom had not noticed their involvement beforehand.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28157", "revid": "40778474", "url": "https://en.wikipedia.org/wiki?curid=28157", "title": "Satsuma Province", "text": "Former province of Japan\n was an old province of Japan that is now the western half of Kagoshima Prefecture on the island of Ky\u016bsh\u016b. Its abbreviation was .\nHistory.\nSatsuma's provincial capital was Satsumasendai. During the Sengoku period, Satsuma was a fief of the Shimazu \"daimy\u014d\", who ruled much of southern Ky\u016bsh\u016b from their castle at Kagoshima city. They were the initial patrons of Satsuma ware, which was later widely exported to the West.\nIn 1871, with the abolition of feudal domains and the establishment of prefectures after the Meiji Restoration, the provinces of Satsuma and \u014csumi were combined to eventually establish Kagoshima Prefecture.\nSatsuma was one of the main provinces that rose in opposition to the Tokugawa shogunate in the mid 19th century. Because of this, the oligarchy that came into power after the Meiji Restoration of 1868 had a strong representation from the Satsuma province, with leaders such as \u014ckubo Toshimichi and Saig\u014d Takamori taking up key government positions.\nSatsuma is well known for its production of sweet potatoes, known in Japan as \u85a9\u6469\u828b (Satsuma-Imo or \"Satsuma potato\"). Satsuma mandarins (known as \"mikan\" in Japan) do not specifically originate from Satsuma but were imported into the West through this province in the Meiji era.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28159", "revid": "45051833", "url": "https://en.wikipedia.org/wiki?curid=28159", "title": "Scottish", "text": "Scottish usually refers to something of, from, or related to Scotland, including:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "28161", "revid": "50732016", "url": "https://en.wikipedia.org/wiki?curid=28161", "title": "List of brightest stars", "text": "Stars sorted by apparent magnitude\nThis is a list of stars arranged by their apparent magnitude \u2013 their brightness as observed from Earth. It includes all stars brighter than magnitude +2.50 in visible light, measured using a \"V\"-band filter in the UBV photometric system. Stars in binary systems (or other multiples) are listed by their \"total\" or \"combined\" brightness if they appear as a single star to the naked eye, or listed separately if they do not. As with all magnitude systems in astronomy, the scale is logarithmic and inverted i.e. lower/more negative numbers are brighter.\nMost stars on this list appear bright from Earth because they are nearby, not because they are intrinsically luminous. For a list which compensates for the distances, converting the \"apparent\" magnitude to the \"absolute\" magnitude, see the list of most luminous stars.\nMeasurement.\nThe Sun is the brightest star as viewed from Earth, at \u221226.78\u00a0mag. The second brightest is Sirius at \u22121.46\u00a0mag. For comparison, the brightest non-stellar objects in the Solar System have maximum brightnesses of:\nAny exact order of the visual brightness of stars is not perfectly defined for four reasons:\nNomenclature.\nAll of these stars have multiple valid names or catalogue designations. The table lists their Bayer designation and the most common proper name. Most of the proper names have been approved by the Working Group on Star Names of the International Astronomical Union (IAU). Popular names which have not been approved by the IAU are omitted.\nTable.\nThe source of magnitudes cited in this list is the linked Wikipedia articles. This basic list is a catalog of what Wikipedia itself documents. References can be found in the individual articles.\n&lt;templatestyles src=\"template:sticky header/styles.css\"/&gt;\nBrightest star by galaxy.\n&lt;templatestyles src=\"template:sticky header/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28162", "revid": "38557371", "url": "https://en.wikipedia.org/wiki?curid=28162", "title": "List of nearest stars", "text": "This list covers all known stars, white dwarfs, brown dwarfs, and sub-brown dwarfs/rogue planets within of the Sun. So far, 131 such objects have been found. Only 22 are bright enough to be visible without a telescope, for which the star's visible light needs to reach or exceed the dimmest brightness visible to the naked eye from Earth, which is typically around 6.5 apparent magnitude.\nThe known 131 objects are bound in 94 stellar systems. Of those, 103 are main sequence stars: 80 red dwarfs and 23 \"typical\" stars having greater mass. Additionally, astronomers have found 6 white dwarfs (stars that have exhausted all fusible hydrogen), 21 brown dwarfs, as well as 1 sub-brown dwarf, WISE 0855\u22120714 (possibly a rogue planet). The closest system is Alpha Centauri, with Proxima Centauri as the closest star in that system, at 4.2465 light-years from Earth. The brightest, most massive and most luminous object among those 131 is Sirius A, which is also the brightest star in Earth's night sky; its white dwarf companion Sirius B is the hottest object among them. The largest object within the 20 light-years is Procyon.\nThe Solar System, and the other stars/dwarfs listed here, are currently moving within (or near) the Local Interstellar Cloud, roughly across. The Local Interstellar Cloud is, in turn, contained inside the Local Bubble, a cavity in the interstellar medium about across. It contains Ursa Major and the Hyades star cluster, among others. The Local Bubble also contains the neighboring G-Cloud, which contains the stars Alpha Centauri and Altair. In the galactic context, the Local Bubble is a small part of the Orion Arm, which contains most stars that we can see without a telescope. The Orion Arm is one of the spiral arms of our Milky Way galaxy.\nAstrometrics.\nThe easiest way to determine stellar distance to the Sun for objects at these distances is parallax, which measures how much stars appear to move against background objects over the course of Earth's orbit around the Sun. As a parsec (parallax-second) is defined by the distance of an object that would appear to move exactly one second of arc against background objects, stars less than 5 parsecs away will have measured parallaxes of over 0.2 arcseconds, or 200 milliarcseconds. Determining past and future positions relies on accurate astrometric measurements of their parallax and total proper motions (how far they move across the sky due to their actual velocity relative to the Sun), along with spectroscopically determined radial velocities (their speed directly towards or away from us, which combined with proper motion defines their true movement through the sky relative to the Sun). Both of these measurements are subject to increasing and significant errors over very long time spans, especially over the several thousand-year time spans it takes for stars to noticeably move relative to each other.\nBased on results from the Gaia telescope's second data release from April 2018, an estimated 694 stars will approach the Solar System to less than 5 parsecs in the next 15 million years. Of these, 26 have a good probability to come within and another 7 within . This number is likely much higher, due to the sheer number of stars needed to be surveyed; a star approaching the Solar System 10 million years ago, moving at a typical Sun-relative 20\u2013200 kilometers per second, would be 600\u20136,000 light-years from the Sun at present day, with millions of stars closer to the Sun. The closest encounter to the Sun so far predicted is the low-mass orange dwarf star Gliese 710 / HIP 89825 with roughly 60% the mass of the Sun. It is currently predicted to pass ( au) from the Sun in million years from the present, close enough to significantly disturb the Solar System's Oort cloud.\nList.\nThe classes of the stars and brown dwarfs are shown in the color of their spectral types (these colors are derived from conventional names for the spectral types and do not necessarily represent the star's observed color). Many brown dwarfs are not listed by visual magnitude but are listed by near-infrared J band apparent magnitude due to how dim (and often invisible) they are in visible color bands (U, B or V). Absolute magnitude (with electromagnetic wave, 'light' band denoted in subscript) is a measurement at a 10-parsec distance across imaginary empty space devoid of all its sparse dust and gas. Some of the parallaxes and resultant distances are rough measurements.\n&lt;templatestyles src=\"template:sticky header/styles.css\"/&gt;&lt;templatestyles src=\"Template:Sort under/styles.css\" /&gt;&lt;templatestyles src=\"template:row hover highlight/styles.css\"/&gt;\nDistant future and past encounters.\nOver long periods of time, the slow independent motion of stars change in both relative position and in their distance from the observer. This can cause other currently distant stars to fall within a stated range, which may be readily calculated and predicted using accurate astrometric measurements of parallax and total proper motions, along with spectroscopically determined radial velocities. Although extrapolations can be made into the past or future, they are subject to increasingly significant cumulative errors over very long periods. Inaccuracies of these measured parameters make determining the true minimum distances of any encountering stars or brown dwarfs fairly difficult.\nOne of the first stars known to approach the Sun particularly close is Gliese 710. The star, whose mass is roughly half that of the Sun, is currently 62 light-years from the Solar System. It was first noticed in 1999 using data from the Hipparcos satellite, and was estimated to pass less than from the Sun in 1.4 million years. With the release of \"Gaia\"'s observations of the star, it has since been refined to a much closer , close enough to significantly disturb objects in the Oort cloud, which extends from the Sun.\n\"Gaia\"'s third data release has provided updated values for many of the candidates in the table below.\n&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;&lt;templatestyles src=\"Template:Sort under/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28163", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=28163", "title": "Sagitta", "text": "Constellation in the northern celestial hemisphere\nSagitta is a dim but distinctive constellation in the northern sky. Its name is Latin for 'arrow', not to be confused with the significantly larger constellation Sagittarius 'the archer'. It was included among the 48 constellations listed by the 2nd-century astronomer Ptolemy, and it remains one of the 88 modern constellations defined by the International Astronomical Union. Although it dates to antiquity, Sagitta has no star brighter than 3rd magnitude and has the third-smallest area of any constellation.\nGamma Sagittae is the constellation's brightest star, with an apparent magnitude of 3.47. It is an aging red giant star 90% as massive as the Sun that has cooled and expanded to a radius 54 times greater than it. Delta, Epsilon, Zeta, and Theta Sagittae are each multiple stars whose components can be seen in small telescopes. V Sagittae is a cataclysmic variable\u2014a binary star system composed of a white dwarf accreting mass of a donor star that is expected to go nova and briefly become the most luminous star in the Milky Way and one of the brightest stars in our sky around the year 2083. Two star systems in Sagitta are known to have Jupiter-like planets, while a third\u201415 Sagittae\u2014has a brown dwarf companion.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\nThe ancient Greeks called Sagitta 'the arrow', and it was one of the 48 constellations described by Ptolemy. It was regarded as the weapon that Hercules used to kill the eagle () of Jove that perpetually gnawed Prometheus' liver. Sagitta is located beyond the north border of Aquila, the Eagle. An amateur naturalist, polymath Richard Hinckley Allen proposed that the constellation could represent the arrow shot by Hercules towards the adjacent Stymphalian birds (which feature in Hercules' sixth labour) who had claws, beaks, and wings of iron, and who lived on human flesh in the marshes of Arcadia\u2014denoted in the sky by the constellations Aquila the Eagle, Cygnus 'the Swan', and Lyra 'the Vulture'\u2014and still lying between them, whence the title Herculea. Greek scholar Eratosthenes claimed it as the arrow with which Apollo exterminated the Cyclopes. The Romans named it Sagitta. In Arabic, it became \"al-sahm\" 'arrow', though this name became \"Sham\" and was transferred to Alpha Sagittae only. The Greek name has also been mistranslated as 'the loom' and thus in Arabic \"al-nawl\". It was also called \"al-'anaza\" 'pike/javelin'.\nCharacteristics.\nThe four brightest stars make up an arrow-shaped asterism located due north of the bright star Altair. Covering 79.9 square degrees and hence 0.194% of the sky, Sagitta ranks 86th of the 88 modern constellations by area. Only Equuleus and Crux are smaller. Sagitta is most readily observed from the late spring to early autumn to northern hemisphere observers, with midnight culmination occurring on 17 July. Its position in the Northern Celestial Hemisphere means that the whole constellation is visible to observers north of 69\u00b0S. Sagitta is bordered by Vulpecula to the north, Hercules to the west, Aquila to the south, and Delphinus to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"Sge\"; American astronomer Henry Norris Russell, who devised the code, had to resort to using the genitive form of the name to come up with a letter to include ('e') that was not in the name of the constellation Sagittarius. The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of twelve segments (\"illustrated in infobox\"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between 18h 57.2m and 20h 20.5m, while the declination coordinates are between 16.08\u00b0 and 21.64\u00b0.\nNotable features.\nStars.\nCelestial cartographer Johann Bayer gave Bayer designations to eight stars, labelling them Alpha to Theta. English astronomer John Flamsteed added the letters x, mistaken as Chi (\u03c7), y and z to 13, 14, and 15 Sagittae in his \"Catalogus Britannicus\". All three were dropped by later astronomers John Bevis and Francis Baily.\nBright stars.\nPtolemy saw the constellation's brightest star Gamma Sagittae as marking the arrow's head, while Bayer saw Gamma, Eta, and Theta as depicting the arrow's shaft. Gamma Sagittae is a red giant of spectral type M0\u00a0III, and magnitude 3.47. It lies at a distance of from Earth. With around 90% of the Sun's mass, it has a radius 54 times that of the Sun and is 575 times as bright. It is most likely on the red-giant branch of its evolutionary lifespan, having exhausted its core hydrogen and now burning it in a surrounding shell.\nDelta Sagittae is the second-brightest star in the constellation and is a binary. Delta and Zeta depicted the spike according to Bayer. The Delta Sagittae system is composed of a red supergiant of spectral type M2\u00a0II that has 3.9 times the Sun's mass and 152 times its radius and a blue-white B9.5V main sequence star that is 2.9 times as massive as the Sun. The two orbit each other every ten years. Zeta Sagittae is a triple star system, approximately from Earth. The primary and secondary are A-type stars.\nIn his \"Uranometria\", Bayer depicted Alpha, Beta, and Epsilon Sagittae as the fins of the arrow. Also known as Sham, Alpha is a yellow bright giant star of spectral class G1\u00a0II with an apparent magnitude of 4.38, which lies at a distance of from Earth. Four times as massive as the Sun, it has swollen and brightened to 21\u00a0times the Sun's radius and 340\u00a0times its luminosity. Also of magnitude 4.38, Beta is a G-type giant located distant from Earth. Estimated to be around 129\u00a0million years old, it is 4.33\u00a0times as massive as the Sun, and has expanded to roughly 27 times its radius. Epsilon Sagittae is a double star whose component stars can be seen in a small telescope. With an apparent magnitude of 5.77, the main star is a 331-million-year-old yellow giant of spectral type G8\u00a0III around 3.09\u00a0times as massive as the Sun, that has swollen to its radius. It is distant. The visual companion of magnitude 8.35 is 87.4\u00a0arcseconds distant, but is an unrelated blue supergiant around distant from Earth.\nEta Sagittae is an orange giant of spectral class K2\u00a0III with a magnitude of 5.09. Located from Earth, it has a 61.1% chance of being a member of the Hyades\u2013Pleiades stream of stars that share a common motion through space. Theta Sagittae is a double star system, with components 12 arcseconds apart visible in a small telescope. At magnitude 6.5, the brighter is a yellow-white main sequence star of spectral type F3\u00a0V, located from Earth. The 8.8-magnitude fainter companion is a main sequence star of spectral type G5\u00a0V. A 7.4-magnitude orange giant of spectral type K2\u00a0III is also visible from the binary pair, located away.\nVariable stars.\nVariable stars are popular targets for amateur astronomers, their observations providing valuable contributions to understanding star behaviour. R Sagittae is a member of the rare RV Tauri variable class of star. It ranges in magnitude from 8.2 to 10.4. It is around distant. It has a radius times that of the Sun, and is as luminous, yet most likely is less massive than the Sun. An aging star, it has moved on from the asymptotic giant branch of stellar evolution and is on its way to becoming a planetary nebula. FG Sagittae is a \"born again\" star, a highly luminous star around distant from Earth. It reignited fusion of a helium shell shortly before becoming a white dwarf, and has expanded first to a blue supergiant and then to a K-class supergiant in less than 100 years. It is surrounded by a faint (visual magnitude 23) planetary nebula, Henize 1\u20135, that formed when FG Sagittae first left the asymptotic giant branch.\nS Sagittae is a classical Cepheid that varies from magnitude 5.24 to 6.04 every 8.38\u00a0days. It is a yellow-white supergiant that pulsates between spectral types F6\u00a0Ib and G5\u00a0Ib. Around 6 or 7 times as massive and 3,500 times as luminous as the Sun, it is located around from Earth. HD 183143 is a remote highly luminous star around away, that has been classified as a blue hypergiant. Infrared bands of ionised buckminsterfullerene molecules have also been found in its spectrum. WR 124 is a Wolf\u2013Rayet star moving at great speed surrounded by a nebula of ejected gas.\nU Sagittae is an eclipsing binary that varies between magnitudes 6.6 and 9.2 over 3.4\u00a0days, making it a suitable target for enthusiasts with small telescopes. There are two component stars\u2014a blue-white star of spectral type B8\u00a0V and an ageing star that has cooled and expanded into a yellow subgiant of spectral type G4\u00a0III-IV. They orbit each other close enough that the cooler subgiant has filled its Roche lobe and is passing material to the hotter star, and hence it is a semidetached binary system. The system is distant. Near U Sagittae is X Sagittae, a semiregular variable ranging between magnitudes 7.9 and 8.4 over 196\u00a0days. A carbon star, X Sagittae has a surface temperature of .\nLocated near 18 Sagittae is V Sagittae, the prototype of the V Sagittae variables, cataclysmic variables that are also super soft X-ray sources. It is expected to become a luminous red nova when the two stars merge around the year 2083, and briefly become the most luminous star in the Milky Way and one of the brightest stars in Earth's sky. WZ Sagittae is another cataclysmic variable, composed of a white dwarf that has about 85% the mass of the Sun, and low-mass star companion that has been calculated to be a brown dwarf of spectral class L2 that is only 8% as massive as the Sun. Normally a faint object dimmer than magnitude 15, it flared up in 1913, 1946 and 1978 to be visible in binoculars. The black widow pulsar (B1957+20) is the second millisecond pulsar ever discovered. It is a massive neutron star that is ablating its brown dwarf-sized companion which causes the pulsar's radio signals to attenuate as they pass through the outflowing material.\nStars with exoplanets.\nHD 231701 is a yellow-white main sequence star hotter and larger than the Sun, with a Jupiter-like planet that was discovered in 2007 by the radial velocity technique. The planet orbits at a distance of from the star with a period of 141.6\u00a0days. It has a mass of at least 1.13 Jupiter masses. \nHAT-P-34 is a star times as massive as the Sun with times its radius and times its luminosity. With an apparent magnitude of 10.4, it is distant. A planet times as massive as Jupiter was discovered transiting it in 2012. With a period of 5.45\u00a0days and a distance of from its star, it has an estimated surface temperature of . \n15 Sagittae is a solar analog\u2014a star similar to the Sun, with times its mass, times its radius and times its luminosity. It has an apparent magnitude of 5.80. It has an L4 brown dwarf substellar companion that is around the same size as Jupiter but 69 times as massive with a surface temperature of between 1,510 and , taking around 73.3\u00a0years to complete an orbit around the star. The system is estimated to be billion years old.\nDeep-sky objects.\nThe band of the Milky Way and the Great Rift within it pass though Sagitta, with Alpha, Beta and Epsilon Sagittae marking the Rift's border. Located between Beta and Gamma Sagittae is Messier 71, a very loose globular cluster mistaken for some time for a dense open cluster. At a distance of about from Earth, it was first discovered by the French astronomer Philippe Loys de Ch\u00e9seaux in the year 1745 or 1746. The loose globular cluster has a mass of around 53,000\u00a0M\u2609 and a luminosity of approximately 19,000 L\u2609.\nThere are two notable planetary nebulae in Sagitta: NGC 6886 is composed of a hot central post-AGB star that has 55% of the Sun's mass yet times its luminosity, with a surface temperature of , and surrounding nebula estimated to have been expanding for between 1,280 and 1,600 years, The nebula was discovered by Ralph Copeland in 1884. The Necklace Nebula\u2014originally a close binary, one component of which swallowed the other as it expanded to become a giant star. The smaller star remained in orbit inside the larger, whose rotation speed increased greatly, resulting in it flinging its outer layers off into space, forming a ring with knots of bright gas formed from clumps of stellar material. It was discovered in 2005 and is around 2 light-years wide. It has a size of . Both nebulae are around from Earth.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28164", "revid": "11096", "url": "https://en.wikipedia.org/wiki?curid=28164", "title": "Simon Ockley", "text": "Simon Ockley (1678\u00a0\u2013 9 August 1720) was a British Orientalist.\nBiography.\nOckley was born at Exeter. He was educated at Queens' College, Cambridge, and graduated B.A. in 1697, MA. in 1701, and B.D. in 1710. He became a fellow of Jesus College and vicar of Swavesey, and in 1711, was chosen Adams Professor of Arabic in the university. He had a large family, and his latter days were embittered by pecuniary embarrassments, which form the subject of a chapter in Isaac D'Israeli's \"Calamities of Authors\". The preface to the second volume of his \"History of the Saracens\" is dated from Cambridge Castle, where he lay a prisoner for debt.\nOckley maintained that a knowledge of Oriental literature was essential to the proper study of theology, and in the preface to his first book, the \"Introductio ad linguas orientales\" (1706), he urges the importance of the study.\nHe died at Swavesey.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28165", "revid": "1311866952", "url": "https://en.wikipedia.org/wiki?curid=28165", "title": "Sharable Content Object Reference Model", "text": "Standard for e-learning\nSharable Content Object Reference Model (SCORM) is a collection of standards and specifications for web-based electronic educational technology (also called e-learning). It defines communications between client side content and a host system (called \"the run-time environment\"), which is commonly supported by a learning management system. SCORM also defines how content may be packaged into a transferable ZIP file called \"Package Interchange Format.\"\nSCORM is a specification of the Advanced Distributed Learning (ADL) Initiative from the Office of the United States Secretary of Defense.\nSCORM 2004 introduced a complex idea called sequencing, which is a set of rules that specifies the order in which a learner may experience content objects. In simple terms, they constrain a learner to a fixed set of paths through the training material, permit the learner to \"bookmark\" their progress when taking breaks, and assure the acceptability of test scores achieved by the learner. The standard uses XML, and it is based on the results of work done by AICC, IEEE LTSC, and Ariadne.\nTechnology.\nSCORM was designed to be web-based and utilizes JavaScript to facilitate communication between the client side content and the run-time environment. Each SCORM version specifies the methods that the run-time environment should support and how those methods should behave. Content launched by the run time environment can then call those methods utilizing JavaScript.\nVersions.\nSCORM 1.1.\nIt was the first version of SCORM. These early adoptions revealed that the SCORM idea was workable, but it needed to be sufficiently robust for widespread implementation.\nSCORM 1.2.\nThis was the first version that was widely used. It is still widely used and is supported by most Learning Management Systems.\nSCORM 2004.\nThis is the current version. It is based on new standards for API and content object-to-runtime environment communication, with many ambiguities of previous versions resolved. Includes ability to specify adaptive sequencing of activities that use the content objects. Includes ability to share and use information about the success status for multiple learning objectives or competencies across content objects and across courses for the same learner within the same learning management system. A more robust test suite helps ensure good interoperability. \nExperience API (Tin Can API).\nThe Experience API (also known as xAPI or Tin Can API) was finalized to version 1.0 in April 2013. The Experience API solves many of the problems inherent with older versions of SCORM. Just like SCORM, ADL is the steward of the Experience API. AICC with their cmi5 planned to use xAPI as their transport standard, but AICC membership decided to dissolve the organization and transferred cmi5 to ADL.\nThe Experience API (Tin Can API) is a web service that allows software clients to read and write experiential data in the form of \"statement\" objects. In their simplest form, statements are in the form of \"I did this\", or more generally \"actor verb object\". More complex statement forms can be used. There is also a built-in query API to help filter recorded statements, and a state API that allows for a sort of \"scratch space\" for consuming applications. Experience API statements are stored in a data store called a Learning Record Store, which can exist on its own or within a Learning Management System.\nCompatible software.\nServer software\nContent editing software\nCurrent limitations and user experiences.\nAs of early 2025, many users describe SCORM as outdated due to its limited tracking capabilities (complete/incomplete only) and lack of support for modern analytics standards. Despite this, SCORM remains popular because of the existing ecosystem and investment in legacy content and platforms. \nSome users report that large SCORM packages (e.g. &gt;\u202f500\u202fMB ZIP files) can cause LMS upload failures or exceed suspend_data limits, particularly in SCORM 1.2. Switching to SCORM 2004 or using file size reduction techniques can help mitigate these issues.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28167", "revid": "51011256", "url": "https://en.wikipedia.org/wiki?curid=28167", "title": "Sejm", "text": "Lower house of the parliament of Poland\nThe Sejm (), officially known as the Sejm of the Republic of Poland (), is the lower house of the bicameral parliament of Poland. \nThe Sejm has been the highest governing body of the Third Polish Republic since the transition of government in 1989. Along with the upper house of parliament, the Senate, it forms the national legislature in Poland known as National Assembly (). The Sejm comprises 460 deputies (singular , rarely ), elected every four years by universal ballot. The Sejm is presided over by a speaker, the Marshal of the Sejm ().\nIn the Kingdom of Poland, the term \"Sejm\" referred to the entire bicameral parliament, comprising the Chamber of Deputies () and the Senate, with the King presiding. It was thus a three-estate parliament. The 1573 Henrician Articles strengthened the assembly's jurisdiction, making Poland a constitutional elective monarchy. Since the Second Polish Republic (1918\u20131939), \"Sejm\" has referred only to the lower house of parliament.\nDuring the existence of the Polish People's Republic, the Sejm, then a unicameral parliament, was the supreme organ of state power in the country. It was the only government branch in the state, and per the principle of unified power, all state organs were subservient to it. However, in practice it was widely considered to be a rubber stamp legislature which existed to approve decisions made by the ruling party, the Polish United Workers' Party (PZPR) as a formality, and which had little or no real power of its own. After the collapse of communism in 1989, the \"Sejm\" was restored as a bicameral, democratically elected parliament under the current Third Polish Republic.\nHistory.\nKingdom of Poland.\n\"Sejm\" (an ancient Proto-Lechitic word meaning \"gathering\" or \"meeting\") traces its roots to the King's Councils \u2013 \"wiece\" \u2013 which gained authority during the time of Poland's fragmentation (1146-1295). The 1180 Sejm in \u0141\u0119czyca (known as the 'First Polish parliament') was the most notable, in that it established laws constraining the power of the ruler. It forbade arbitrary sequestration of supplies in the countryside and takeover of bishopric lands after the death of a bishop. These early \"Sejm\"s only convened at the King's behest.\nFollowing the 1493 \"Sejm\" in Piotrk\u00f3w, it became a regularly convening body, to which indirect elections were held every two years. The bicameral system was also established; the \"Sejm\" then comprised two chambers: the \"Senat\" (Senate) of 81 bishops and other dignitaries; and the Chamber of Deputies, made up of 54 envoys elected by smaller local \"sejmik\" (assemblies of landed nobility) in each of the Kingdom's provinces. At the time, Poland's nobility, which accounted for around 10% of the state's population (then the highest amount in Europe), was becoming particularly influential, and with the eventual development of the Golden Liberty, the \"Sejm\"'s powers increased dramatically.\nPolish\u2013Lithuanian Commonwealth.\n Over time, the envoys in the lower chamber grew in number and power as they pressed the king for more privileges. The \"Sejm\" eventually became even more active in supporting the goals of the privileged classes when the King ordered that the landed nobility and their estates (peasants) be drafted into military service. \nThe Union of Lublin in 1569, united the Kingdom of Poland and the Grand Duchy of Lithuania as one single state, the Polish\u2013Lithuanian Commonwealth, and thus the \"Sejm\" was supplemented with new envoys from among the Lithuanian nobility. The Commonwealth ensured that the state of affairs surrounding the three-estates system continued, with the \"Sejm\", Senate and King forming the estates and supreme deliberating body of the state. In the first few decades of the 16th century, the Senate had established its precedence over the \"Sejm\"; however, from the mid-1500s onwards, the \"Sejm\" became a very powerful representative body of the \"szlachta\" (\"middle nobility\"). Its chambers reserved the final decisions in legislation, taxation, budget, and treasury matters (including military funding), foreign policy, and the confirment of nobility.\nThe 1573 Warsaw Confederation saw the nobles of the \"Sejm\" officially sanction and guarantee religious tolerance in Commonwealth territory, ensuring a refuge for those fleeing the ongoing Reformation and Counter-Reformation wars in Europe.\nUntil the end of the 16th century, unanimity was not required, and the majority-voting process was the most commonly used system for voting. Later, with the rise of the Polish magnates and their increasing power, the unanimity principle was re-introduced with the institution of the nobility's right of \"liberum veto\" (Latin: \"free veto\"). Additionally, if the envoys were unable to reach a unanimous decision within six weeks (the time limit of a single session), deliberations were declared void and all previous acts passed by that \"Sejm\" were annulled. From the mid-17th century onward, any objection to a \"Sejm\" resolution, by either an envoy or a senator, automatically caused the rejection of other, previously approved resolutions. This was because all resolutions passed by a given session of the \"Sejm\" formed a whole resolution, and, as such, was published as the annual \"constituent act\" of the \"Sejm\", e.g. the \"\"Anno Domini\" 1667\" act. In the 16th century, no single person or small group dared to hold up proceedings, but, from the second half of the 17th century, the \"liberum veto\" was used to virtually paralyze the \"Sejm\", and brought the Commonwealth to the brink of collapse.\nThe \"liberum veto\" was abolished with the adoption of the Constitution of 3 May 1791, a piece of legislation which was passed as the \"Government Act\", and for which the \"Sejm\" required four years to propagate and adopt. The constitution's acceptance, and the possible long-term consequences it may have had, is arguably the reason that the powers of Habsburg Austria, Russia and Prussia then decided to partition the Polish\u2013Lithuanian Commonwealth, thus putting an end to over 300 years of Polish parliamentary continuity. It is estimated that between 1493 and 1793, a \"Sejm\" was held 240 times, the total debate-time sum of which was 44 years.\nPartitions.\nAfter the fall of the Duchy of Warsaw, which existed as a Napoleonic client state between 1807 and 1815, and its short-lived \"Sejm\" of the Duchy of Warsaw, the \"Sejm\" of Congress Poland was established in Congress Poland of the Russian Empire; it was composed of the king (the Russian emperor), the upper house (Senate), and the lower house (Chamber of Deputies). Overall, during the period from 1795 until the re-establishment of Poland's sovereignty in 1918, little power was actually held by any Polish legislative body and the occupying powers of Russia, Prussia (later united Germany) and Austria propagated legislation for their own respective formerly-Polish territories at a national level.\nCongress Poland.\nThe Chamber of Deputies, despite its name, consisted not only of 77 envoys (sent by local assemblies) from the hereditary nobility, but also of 51 deputies, elected by the non-noble population. All deputies were covered by Parliamentary immunity, with each individual serving for a term of office of six years, with third of the deputies being elected every two years. Candidates for deputy had to be able to read and write, and have a certain amount of wealth. The legal voting age was 21, except for those citizens serving in the military, the personnel of which were not allowed to vote. Parliamentary sessions were initially convened every two years, and lasted for (at least) 30 days. However, after many clashes between liberal deputies and conservative government officials, sessions were later called only four times (1818, 1820, 1826, and 1830, with the last two sessions being secret). The \"Sejm\" had the right to call for votes on civil and administrative legal issues, and, with permission from the king, it could also vote on matters related to the fiscal policy and the military. It had the right to exercise control over government officials, and to file petitions. The 64-member Senate on the other hand, was composed of \"voivodes\" and \"kasztelans\" (both types of provincial governors), Russian envoys, diplomats or princes, and nine bishops. It acted as the Parliamentary Court, had the right to control \"citizens' books\", and had similar legislative rights as did the Chamber of Deputies.\nGermany and Austria-Hungary.\nIn the Free City of Cracow (1815\u20131846), a unicameral Assembly of Representatives was established, and from 1827, a unicameral provincial \"sejm\" existed in the Grand Duchy of Pozna\u0144. Poles were elected to and represented the majority in both of these legislatures; however, they were largely powerless institutions and exercised only very limited power. After numerous failures in securing legislative sovereignty in the early 19th century, many Poles simply gave up trying to attain a degree of independence from their foreign master-states. In the Austrian partition, a relatively powerless \"Sejm\" of the Estates operated until the time of the Spring of Nations. After this, in the mid to late 19th century, only in autonomous Galicia (1861\u20131914) was there a unicameral and functional National \"Sejm\", the \"Sejm\" of the Land. It is recognised today as having played a major and overwhelming positive role in the development of Polish national institutions.\nIn the second half of the 19th century, Poles were able to become members of the parliaments of Austria, Prussia and Russia, where they formed Polish Clubs. Deputies of Polish nationality were elected to the Prussian \"Landtag\" from 1848, and then to the German Empire's \"Reichstag\" from 1871. Polish Deputies were members of the Austrian State Council (from 1867), and from 1906 were also elected to the Russian Imperial State \"Duma\" (lower chamber) and to the State Council (upper chamber).\nSecond Polish Republic.\nAfter the First World War and re-establishment of Polish independence, the convocation of parliament, under the democratic electoral law of 1918, became an enduring symbol of the new state's wish to demonstrate and establish continuity with the 300-year Polish parliamentary traditions established before the time of the partitions. Maciej Rataj emphatically paid tribute to this with the phrase: \"There is Poland there, and so is the \"Sejm\".\nDuring the interwar period of Poland's independence, the first Legislative \"Sejm\" of 1919, a Constituent Assembly, passed the Small Constitution of 1919, which introduced a parliamentary republic and proclaimed the principle of the \"Sejm\"'s sovereignty. This was then strengthened, in 1921, by the March Constitution, one of the most democratic European constitutions enacted after the end of World War I. The constitution established a political system which was based on Montesquieu's doctrine of separation of powers, and which restored the bicameral \"Sejm\" consisting of a chamber of deputies (to which alone the name of \"Sejm\"\" was from then on applied) and the Senate. In 1919, Roza Pomerantz-Meltzer, a member of the Zionist party, became the first woman ever elected to the \"Sejm\".\nThe legal content of the March Constitution allowed for \"Sejm\" supremacy in the system of state institutions at the expense of the executive powers, thus creating a parliamentary republic out of the Polish state. An attempt to strengthen executive powers in 1926 (through the August Amendment) proved too limited and largely failed in helping avoid legislative grid-lock which had ensued as a result of too-great parliamentary power in a state which had numerous diametrically-opposed political parties sitting in its legislature. In 1935, the parliamentary republic was weakened further when, by way of, J\u00f3zef Pi\u0142sudski's May Coup, the president was forced to sign the April Constitution of 1935, an act through which the head of state assumed the dominant position in legislating for the state and the Senate increased its power at the expense of the \"Sejm\".\nOn 2 September 1939, the \"Sejm\" held its final pre-war session, during which it declared Poland's readiness to defend itself against invading German forces. On 2 November 1939, the President dissolved the \"Sejm\" and the Senate, which were then, according to plan, to resume their activity within two months after the end of the Second World War; this, however, never happened. During wartime, the National Council (1939\u20131945) was established to represent the legislature as part of the Polish Government in Exile. Meanwhile, in Nazi-occupied Poland, the Council of National Unity was set up; this body functioned from 1944 to 1945 as the parliament of the Polish Underground State. With the cessation of hostilities in 1945, and subsequent rise to power of the Communist-backed Provisional Government of National Unity, the Second Polish Republic legally ceased to exist.\nPolish People's Republic.\nThe \"Sejm\" in the Polish People's Republic had 460 deputies throughout most of its history. At first, this number was declared to represent one deputy per 60,000 citizens (425 were elected in 1952), but, in 1960, as the population grew, the declaration was changed: The constitution then stated that the deputies were representative \"of\" the people and could be recalled \"by\" the people, but this article was never used, and, instead of the \"five-point electoral law\", a non-proportional, \"four-point\" version was used. Legislation was passed with majority voting.\nUnder the 1952 Constitution, the Sejm was defined as \"the highest organ of State authority\" in Poland, as well as \"the highest spokesman of the will of the people in town and country.\" On paper, it was vested with great lawmaking and oversight powers. For instance, it was empowered with control over \"the functioning of other organs of State authority and administration,\" and ministers were required to answer questions posed by deputies within seven days. In practice, it did little more than rubber-stamp decisions already made by the Communist Polish United Workers Party and its executive bodies. This was standard practice in nearly all Communist regimes due to the principle of democratic centralism.\nThe \"Sejm\" voted on the budget and on the periodic national plans that were a fixture of communist economies. The \"Sejm\" deliberated in sessions that were ordered to convene by the State Council.\nThe \"Sejm\" also chose a \"Prezydium\" (\"presiding body\") from among its members. The \"Prezydium\" was headed by the speaker, or Marshal, who was always a member of the United People's Party. In its preliminary session, the \"Sejm\" also nominated the Prime Minister, the Council of Ministers of Poland, and members of the State Council. It also chose many other government officials, including the head of the Supreme Chamber of Control and members of the State Tribunal and the Constitutional Tribunal, as well as the Ombudsman (the last three bodies of which were created in the 1980s).\nWhen the Sejm was not in session, the State Council had the power to issue decrees that had the force of law. However, those decrees had to be approved by the Sejm at its next session. In practice, the principles of democratic centralism meant that such approval was only a formality.\nThe Senate was abolished by the referendum in 1946, after which the \"Sejm\" became the sole legislative body in Poland. Even though the \"Sejm\" was largely subservient to the Communist party, one deputy, Romuald Bukowski (an independent) voted against the imposition of martial law in 1982.\nThird Polish Republic.\nAfter the end of communism in 1989, the Senate was reinstated as the second house of a bicameral national assembly, while the \"Sejm\" remained the first house. The \"Sejm\" is now composed of 460 deputies elected by proportional representation every four years.\nBetween 7 and 20 deputies are elected from each constituency using the d'Hondt method (with one exception, in 2001, when the Sainte-Lagu\u00eb method was used), their number being proportional to their constituency's population. Additionally, a threshold is used, so that candidates are chosen only from parties that gained at least 5% of the nationwide vote (candidates from ethnic-minority parties are exempt from this threshold).\nStanding committees.\nThe Sejm has several standing committees with responsibilities in particular areas.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;Permanent committees\n&lt;br&gt;\nExtraordinary committees\n&lt;br&gt;\nInvestigative committees\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28168", "revid": "44120587", "url": "https://en.wikipedia.org/wiki?curid=28168", "title": "Stock exchange", "text": "Organization that provides services for stock brokers and traders to trade securities\nA stock exchange, securities exchange, or bourse is an exchange where stockbrokers and traders can buy and sell securities, such as shares of stock, bonds and other financial instruments. Stock exchanges may also provide facilities for the issue and redemption of such securities and instruments and capital events including the payment of income and dividends. Securities traded on a stock exchange include stock issued by listed companies, unit trusts, derivatives, pooled investment products and bonds. Stock exchanges often function as \"continuous auction\" markets with buyers and sellers consummating transactions via open outcry at a central location such as the floor of the exchange or by using an electronic system to process financial transactions.\nTo be able to trade a security on a particular stock exchange, the security must be listed there. Usually, there is a central location for record keeping, but trade is increasingly less linked to a physical place as modern markets use electronic communication networks, which give them advantages of increased speed and reduced cost of transactions. Trade on an exchange is restricted to brokers who are members of the exchange. In recent years, various other trading venues such as electronic communication networks, alternative trading systems and \"dark pools\" have taken much of the trading activity away from traditional stock exchanges.\nInitial public offerings of stocks and bonds to investors is done in the primary market and subsequent trading is done in the secondary market. A stock exchange is often the most important component of a stock market. Supply and demand in stock markets are driven by various factors that, as in all free markets, affect the price of stocks (see stock valuation).\nThere is usually no obligation for stock to be issued through the stock exchange itself, nor must stock be subsequently traded on an exchange. Such trading may be \"off-exchange\" or over-the-counter. This is the usual way that derivatives and bonds are traded. Increasingly, stock exchanges are part of a global securities market. Stock exchanges also serve an economic function in providing liquidity to shareholders in providing an efficient means of disposing of shares. In recent years, as the ease and speed of exchanging stocks over digital platforms has increased, volatility in the day-to-day market has increased, too.\nHistory.\nThe beginnings of lending were in Italy in the late Middle Ages. In the 14th century, Venetian lenders would carry slates with information on the various issues for sale and meet with clients, much like a broker does today. Venetian merchants introduced the principle of exchanging debts between moneylenders; a lender looking to unload a high-risk, high-interest loan might exchange it for a different loan with another lender. These lenders also bought government debt issues. As the natural evolution of their business continued, the lenders began to sell debt issues to the first individual investors. The Venetians were the leaders in the field and the first to start trading securities from other governments, yet did not embark on private trade with India. Nor did the Italians connect on land with the Chinese Silk Road. Along the potential overland trade route, Holy Roman Emperor Frederick II repulsed advances by Mongol Batu Kahn (Golden Horde) in 1241. There is little consensus among scholars as to when corporate stock was first traded. Some view the key event as the Dutch East India Company's founding in 1602, while others point to much earlier developments (Bruges, Antwerp in 1531 and in Lyon in 1548). The first book in history of securities exchange, the Confusion of Confusions, was written by the Dutch-Jewish trader Joseph de la Vega and the Amsterdam Stock Exchange is often considered the oldest \"modern\" securities market in the world. On the other hand, economist Ulrike Malmendier of the University of California at Berkeley argues that a share market existed as far back as ancient Rome, that derives from Etruscan \"Argentari\". In the Roman Republic, which existed for centuries before the Empire was founded, there were \"societates publicanorum\", organizations of contractors or leaseholders who performed temple-building and other services for the government. One such service was the feeding of geese on the Capitoline Hill as a reward to the birds after their honking warned of a Gallic invasion in 390\u00a0B.C. Participants in such organizations had \"partes\" or shares, a concept mentioned various times by the statesman and orator Cicero. In one speech, Cicero mentions \"shares that had a very high price at the time\". Such evidence, in Malmendier's view, suggests the instruments were tradable, with fluctuating values based on an organization's success. The \"societas\" declined into obscurity in the time of the emperors, as most of their services were taken over by direct agents of the state.\nTradable bonds as a commonly used type of security were a more recent innovation, spearheaded by the Italian city-states of the late medieval and early Renaissance periods.\nJoseph de la Vega, also known as Joseph Penso de la Vega and by other variations of his name, was an Amsterdam trader from a Spanish Jewish family and a prolific writer as well as a successful businessman in 17th-century Amsterdam. His 1688 book \"Confusion of Confusions\" explained the workings of the city's stock market. It was the earliest book about stock trading and inner workings of a stock market, taking the form of a dialogue between a merchant, a shareholder and a philosopher, the book described a market that was sophisticated but also prone to excesses, and de la Vega offered advice to his readers on such topics as the unpredictability of market shifts and the importance of patience in investment.\nIn England, London's first stockbrokers were barred from the old commercial center known as the Royal Exchange, reportedly because of their rude manners, in the late 17th century. Instead, the new trade was conducted from coffee houses along Exchange Alley. By 1698, a broker named John Castaing, operating out of Jonathan's Coffee House, was posting regular lists of stock and commodity prices. Those lists mark the beginning of the London Stock Exchange.\n18th century.\nOne of history's greatest financial bubbles occurred around 1720. At the center of it were the South Sea Company, set up in 1711 to conduct English trade with South America, and the Mississippi Company, focused on commerce with France's Louisiana colony and touted by transplanted Scottish financier John Law, who was acting in effect as France's central banker. Investors snapped up shares in both, and whatever else was available. In 1720, at the height of the mania, there was even an offering of \"a company for carrying out an undertaking of great advantage, but nobody to know what it is\".\nBy the end of that same year, share prices had started collapsing, as it became clear that expectations of imminent wealth from the Americas were overblown. In London, Parliament passed the Bubble Act, which stated that only royally chartered companies could issue public shares. In Paris, Law was stripped of office and fled the country. Stock trading was more limited and subdued in subsequent decades. Yet the market survived, and by the 1790s shares were being traded in the young United States. On May 17, 1792, the New York Stock Exchange opened under a \"Platanus occidentalis\" (buttonwood tree) in New York City, as 24 stockbrokers signed the Buttonwood Agreement, agreeing to trade five securities under that buttonwood tree.\n19th century onwards.\nBombay Stock Exchange was started by Premchand Roychand in 1875. While BSE Limited is now synonymous with Dalal Street, it was not always so. In the 1850s, five stock brokers gathered together under a Banyan tree in front of Mumbai Town Hall, where Horniman Circle is now situated. A decade later, the brokers moved their location to another leafy setting, this time under banyan trees at the junction of Meadows Street and what was then called Esplanade Road, now Mahatma Gandhi Road. With a rapid increase in the number of brokers, they had to shift places repeatedly. At last, in 1874, the brokers found a permanent location, the one that they could call their own. The brokers group became an official organization known as \"The Native Share &amp; Stock Brokers Association\" in 1875.\nThe Bombay Stock Exchange continued to operate out of a building near the Town Hall until 1928. The present site near Horniman Circle was acquired by the exchange in 1928, and a building was constructed and occupied in 1930. The street on which the site is located came to be called \"Dalal Street\" in Hindi (meaning \"Broker Street\") due to the location of the exchange.\nOn 31 August 1957, the BSE became the first stock exchange to be recognized by the Indian Government under the Securities Contracts Regulation Act. Construction of the present building, the Phiroze Jeejeebhoy Towers at Dalal Street, Fort area, began in the late 1970s and was completed and occupied by the BSE in 1980. Initially named the \"BSE Towers\", the name of the building was changed soon after occupation, in memory of Sir Phiroze Jamshedji Jeejeebhoy, chairman of the BSE since 1966, following his death.\nIn 1986, the BSE developed the S&amp;P BSE SENSEX index, giving the BSE a means to measure the overall performance of the exchange. In 2000, the BSE used this index to open its derivatives market, trading S&amp;P BSE SENSEX futures contracts. The development of S&amp;P BSE SENSEX options along with equity derivatives followed in 2001 and 2002, expanding the BSE's trading platform.\nHistorically an open outcry floor trading exchange, the Bombay Stock Exchange switched to an electronic trading system developed by Cmc ltd. in 1995. It took the exchange only 50 days to make this transition. This automated, screen-based trading platform called BSE On-Line Trading (BOLT) had a capacity of 8 million orders per day. Now BSE has raised capital by issuing shares and as on 3 May 2017 the BSE share which is traded in NSE only closed with \u20b9999.\nRoles.\nStock exchanges have multiple roles in the economy. This may include the following:\nRaising capital for businesses.\nBesides the borrowing capacity provided to an individual or firm by the banking system, in the form of credit or a loan, a stock exchange provides companies with the facility to raise capital for expansion through selling shares to the investing public.\nCapital intensive companies, particularly high tech companies, typically need to raise high volumes of capital in their early stages. For this reason, the public market provided by the stock exchanges has been one of the most important funding sources for many capital intensive startups. In the 1990s and early 2000s, hi-tech listed companies experienced a boom and bust in the world's major stock exchanges. Since then, it has been much more demanding for the high-tech entrepreneur to take his/her company public, unless either the company is already generating sales and earnings, or the company has demonstrated credibility and potential from successful outcomes: clinical trials, market research, patent registrations, etc. This shift in market expectations has led to an increased reliance on private equity and venture capital funding in the early stages of high-tech companies. This is quite different from the situation of the 1990s to early-2000s period, when a number of companies (particularly Internet boom and biotechnology companies) went public in the most prominent stock exchanges around the world in the total absence of sales, earnings, or any type of well-documented promising outcome. Though it is not as common, it still happens that highly speculative and financially unpredictable hi-tech startups are listed for the first time in a major stock exchange. Additionally, there are smaller, specialized entry markets for these kind of companies with stock indexes tracking their performance (examples include the Alternext, CAC Small, SDAX, TecDAX).\nAlternatives to stock exchanges for raising capital.\nAlternative investment funds refer to funds that include hedge funds, venture capital, private equity, angel funds, real estate, commodities, collectibles, structured products, etc. Alternative investment funds are an alternative to traditional investment options (stocks, bonds, and cash).\nResearch and Development limited partnerships.\nCompanies have also raised significant amounts of capital through R&amp;D limited partnerships. Tax law changes that were enacted in 1987 in the United States changed the tax deductibility of investments in R&amp;D limited partnerships. In order for a partnership to be of interest to investors today, the cash on cash return must be high enough to entice investors.\nVenture capital.\nA general source of capital for startup companies has been venture capital. This source remains largely available today, but the maximum statistical amount that the venture company firms in aggregate will invest in any one company is not limitless (it was approximately $15 million in 2001 for a biotechnology company).\nCorporate partners.\nAnother alternative source of cash for a private company is a corporate partner, usually an established multinational company, which provides capital for the smaller company in return for marketing rights, patent rights, or equity. Corporate partnerships have been used successfully in a large number of cases.\nMobilizing savings for investment.\nWhen people draw their savings and invest in shares (through an initial public offering or the seasoned equity offering of an already listed company), it usually leads to rational allocation of resources because funds, which could have been consumed, or kept in idle deposits with banks, are mobilized and redirected to help companies' management boards finance their organizations. This may promote business activity with benefits for several economic sectors such as agriculture, commerce and industry, resulting in stronger economic growth and higher productivity levels of firms.\nFacilitating acquisitions.\nCompanies view acquisitions as an opportunity to expand product lines, increase distribution channels, hedge against volatility, increase their market share, or acquire other necessary business assets. A takeover bid or mergers and acquisitions through the stock market is one of the simplest and most common ways for a company to grow by acquisition or fusion.\nFacilitating company growth.\nBy going public and listing on a stock exchange, companies gain access to a broader pool of investors, which can provide the necessary funds for expansion, research and development, and other growth initiatives. Additionally, being listed on a stock exchange enhances a company's visibility and credibility, making it more attractive to potential partners, customers, and employees. According to a report by the World Federation of Exchanges (WFE), stock exchanges contribute to economic growth by enabling companies to access long-term capital, thereby fostering innovation and job creation.\nRedistribution of wealth.\nWhile stock exchanges are not designed to be platforms for the redistribution of wealth, they play a significant role in allowing both casual and professional stock investors to partake in the wealth generated by profitable businesses. This is achieved through the distribution of dividends and the potential for stock price increases leading to capital gains. As a result, individuals who invest in stocks have the opportunity to share in the prosperity of successful companies, effectively participating in a form of wealth redistribution through their investment activities. Thus, while not the primary purpose of stock exchanges, the opportunity for individuals to benefit from the success of businesses can be seen as a form of wealth redistribution within the financial markets.\nProfit sharing.\nBoth casual and professional stock investors, as large as institutional investors or as small as an ordinary middle-class family, through dividends and stock price increases that may result in capital gains, share in the wealth of profitable businesses. Unprofitable and troubled businesses may result in capital losses for shareholders.\nCorporate governance.\nBy having a wide and varied scope of owners, companies generally tend to improve management standards and efficiency to satisfy the demands of these shareholders and the more stringent rules for public corporations imposed by public stock exchanges and the government. This improvement can be attributed in some cases to the price mechanism exerted through shares of stock, wherein the price of the stock falls when management is considered poor (making the firm vulnerable to a takeover by new management) or rises when management is doing well (making the firm less vulnerable to a takeover). In addition, publicly listed shares are subject to greater transparency so that investors can make informed decisions about a purchase. Consequently, it is alleged that public companies (companies that are owned by shareholders who are members of the general public and trade shares on public exchanges) tend to have better management records than privately held companies (those companies where shares are not publicly traded, often owned by the company founders, their families and heirs, or otherwise by a small group of investors).\nDespite this claim, some well-documented cases are known where it is alleged that there has been considerable slippage in corporate governance on the part of some public companies, particularly in the cases of accounting scandals. The policies that led to the dot-com bubble in the late 1990s and the subprime mortgage crisis in 2007\u201308 are also examples of alleged corporate mismanagement. The alleged mismanagement of companies such as Pets.com (2000), Enron (2001), One.Tel (2001), Sunbeam Products (2001), Webvan (2001), Adelphia Communications Corporation (2002), MCI WorldCom (2002), Parmalat (2003), American International Group (2008), Bear Stearns (2008), Lehman Brothers (2008), General Motors (2009) and Satyam Computer Services (2009) all received plenty of media attention.\nMany banks and companies worldwide utilize securities identification numbers (ISIN) to identify, uniquely, their stocks, bonds and other securities. Adding an ISIN code helps to distinctly identify securities and the ISIN system is used worldwide by funds, companies, and governments.\nHowever, when poor financial, ethical or managerial records become public, stock investors tend to lose money as the stock and the company tend to lose value. In the stock exchanges, shareholders of underperforming firms are often penalized by significant share price decline, and they tend as well to dismiss incompetent management teams.\nCreating investment opportunities for small investors.\nAs opposed to other businesses that require huge capital outlay, investing in shares is open to both the large and small stock investors as minimum investment amounts are minimal. Therefore, the stock exchange provides the opportunity for small investors to own shares of the same companies as large investors.\nAs opposed to other businesses that require huge capital outlay, investing in shares is open to both the large and small stock investors as minimum investment amounts are minimal. Therefore, the stock exchange provides the opportunity for small investors to own shares of the same companies as large investors.\nGovernment capital-raising for development projects.\nGovernments at various levels may decide to borrow money to finance infrastructure projects such as sewage and water treatment works or housing estates by selling another category of securities known as bonds. These bonds can be raised through the stock exchange whereby members of the public buy them, thus loaning money to the government. The issuance of such bonds can obviate, in the short term, direct taxation of citizens to finance development\u2014though by securing such bonds with the full faith and credit of the government instead of with collateral, the government must eventually tax citizens or otherwise raise additional funds to make any regular coupon payments and refund the principal when the bonds mature.\nBarometer of the economy.\nAt the stock exchange, share prices rise and decreases depending, largely, on economic forces. Share prices tend to rise or remain stable when companies and the economy in general show signs of stability and growth. A recession, depression, or financial crisis could eventually lead to a stock market crash. Therefore, the movement of share prices and in general of the stock indexes can be an indicator of the general trend in the economy.\nEmployment opportunities.\nStock exchanges offer employment opportunities to various individuals such as jobbers and other members who perform activities within the stock exchange. This makes the stock exchange a source of employment, not only for investors but also for the members and their employees. The diverse range of roles within the stock exchange, including trading, analysis, compliance, and administrative functions, creates an ecosystem of employment opportunities that support the operations and functions of the exchange. Additionally, the stock exchange's role in facilitating capital formation and investment in businesses also indirectly contributes to job creation and economic growth, making it a significant player in the employment landscape.\nRegulation of companies.\nThe stock exchange plays a role in regulating companies by exerting a significant influence on their management practices. To be listed on a stock exchange, a company is required to adhere to a set of rules and regulations established by the exchange itself. These regulations serve as a framework for corporate governance, financial transparency, and accountability, thereby ensuring that listed companies operate in a manner that is conducive to investor confidence and market stability. By imposing these standards, stock exchanges contribute to the overall integrity and reliability of the financial markets, fostering an environment where companies are held accountable for their actions and decisions, ultimately benefiting both investors and the broader economy.\nListing requirements.\nEach stock exchange imposes its own listing requirements upon companies that want to be listed on that exchange. Such conditions may include minimum number of shares outstanding, minimum market capitalization, and minimum annual income.\nExamples.\nThe listing requirements imposed by some stock exchanges include:\nOwnership.\nStock exchanges originated as mutual organizations, owned by its member stockbrokers. However, the major stock exchanges have \"demutualized\", where the members sell their shares in an initial public offering. In this way the mutual organization becomes a corporation, with shares that are listed on a stock exchange. Examples are Australian Securities Exchange (1998), Euronext (merged with New York Stock Exchange), NASDAQ (2002), Bursa Malaysia (2004), the New York Stock Exchange (2005), , and the S\u00e3o Paulo Stock Exchange (2007).\nThe Shenzhen Stock Exchange and Shanghai Stock Exchange can be characterized as quasi-state institutions insofar as they were created by government bodies in China and their leading personnel are directly appointed by the China Securities Regulatory Commission.\nAnother example is Tashkent Stock Exchange established in 1994, three years after the collapse of the Soviet Union, mainly state-owned but has a form of a public corporation (joint-stock company). Korea Exchange (KRX) owns 25% less one share of the Tashkent Stock Exchange.\nIn 2018, there were 15 licensed stock exchanges in the United States, of which 13 actively traded securities. All of these exchanges were owned by three publicly traded multinational companies, Intercontinental Exchange, Nasdaq, Inc., and Cboe Global Markets, except one, IEX. In 2019, a group of financial corporations announced plans to open a members owned exchange, MEMX, an ownership structure similar to the mutual organizations of earlier exchanges.\nStock market capitalization ranking.\nTop ten traditional stock exchanges by total market capitalization (as of November 2025)\nOther types of exchanges.\nIn the 19th century, exchanges were opened to trade forward contracts on commodities. Exchange traded forward contracts are called futures contracts. These \"commodity markets\" later started offering future contracts on other products, such as interest rates and shares, as well as options contracts. They are now generally known as futures exchanges.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nLists:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28170", "revid": "50702340", "url": "https://en.wikipedia.org/wiki?curid=28170", "title": "Son of God", "text": "Religious title\nHistorically, many rulers have assumed titles such as the son of God, the son of a god or the son of heaven.\nThe term \"Son of God\" is used in the Hebrew Bible as another way to refer to humans who have a special relationship with God. In Exodus, the nation of Israel is called God's firstborn son. Solomon is also called \"son of God\" (2 Samuel 7:14, 1 Chronicles 28:6). Angels, just and pious men, and the kings of Israel are all called \"sons of God\" (Genesis 6:2-4, Job 1:6, 2:1, 38:7).\nIn the New Testament of the Christian Bible, \"Son of God\" is applied to Jesus on many occasions. On two occasions, Jesus is recognized as the Son of God by a voice which speaks from Heaven. Jesus explicitly and implicitly describes himself as the Son of God and he is also described as the Son of God by various individuals who appear in the New Testament. Jesus is called the \"Son of God,\" and followers of Jesus are called, \"Christians.\" As applied to Jesus, the term is a reference to his role as the Messiah, or Christ, the King chosen by God. The contexts and ways in which Jesus' title, Son of God, means something more or something other than the title Messiah remain the subject of ongoing scholarly study and discussion.\nThe term \"Son of God\" should not be confused with the term \"God the Son\" (), the second person of the Trinity in Christian theology. The doctrine of the Trinity identifies Jesus as God the Son, identical in essence but distinct in person with regard to God the Father and God the Holy Spirit (the First and Third Persons of the Trinity). Nontrinitarian Christians accept the application to Jesus of the term \"Son of God\", which is found in the New Testament.\nRulers and imperial titles.\nThroughout history, emperors and rulers ranging from the Western Zhou dynasty (c. 1000 BC) in China to Alexander the Great (c. 360 BC) to the Emperor of Japan (c. 600 AD) have assumed titles that reflect a filial relationship with deities.\nThe title \"Son of Heaven\" i.e. \u5929\u5b50 (from \u5929 meaning sky/heaven/god and \u5b50 meaning child) was first used in the Western Zhou dynasty (c. 1000 BC). It is mentioned in the Shijing book of songs, and reflected the Zhou belief that as Son of Heaven (and as its delegate) the Emperor of China was responsible for the well-being of the whole world by the Mandate of Heaven. This title may also be translated as \"son of God\" given that the word \"Ti\u0101n\" in Chinese may either mean sky or god. The Emperor of Japan was also called the Son of Heaven (\u5929\u5b50 \"tenshi\") starting in the early 7th century.\nAmong the Eurasian nomads, there was also a widespread use of \"Son of God/Son of Heaven\" for instance, in the third century BC, the ruler was called Chany\u00fc and similar titles were used as late as the 13th century by Genghis Khan.\nExamples of kings being considered the son of god are found throughout the Ancient Near East. Egypt in particular developed a long lasting tradition. Egyptian pharaohs are known to have been referred to as the son of a particular god and their begetting in some cases is even given in sexually explicit detail. Egyptian pharaohs did not have full parity with their divine fathers but rather were subordinate. Nevertheless, in the first four dynasties, the pharaoh was considered to be the embodiment of a god. Thus, Egypt was ruled by direct theocracy, wherein \"God himself is recognized as the head\" of the state. During the later Amarna Period, King Amenhotep IV/Akhenaten redefined the pharaoh's godship. He taught \"there was only one god and only one person who now knew the god: Akhenaten himself\" and assumed position of the \u1e25m ntr tpy (first servant of god). He eventually eliminated all representation on his behalf by the priests of Amun as he also eliminated the god Amun, to solely lead worship identifying as the Son of the God he called Father, the latter which he recognized through the aten (sun), the vehicle through which the power of the God manifested to him. Within a few years of his first epiphany and becoming king, King Akhenaten had dropped the priestly title of \u1e25m ntr tpy, but remained serving as the sole cleric and son of the Father in his rule of the Two Lands. Later still, the closest Egypt came to the Jewish variant of theocracy was during the reign of Herihor. He took on the role of ruler not as a god but rather as a high-priest and king.\nAccording to the Bible, several kings of Damascus took the title son of Hadad. From the archaeological record a stela erected by Bar-Rakib for his father Panammuwa II contains similar language. The son of Panammuwa II a king of Sam'al referred to himself as a son of Rakib. Rakib-El is a god who appears in Phoenician and Aramaic inscriptions. Panammuwa II died unexpectedly while in Damascus. However, his son the king Bar-Rakib was not a native of Damascus but rather the ruler of Sam'al it is unknown if other rules of Sam'al used similar language.\nIn Greek mythology, Heracles (son of Zeus) and many other figures were considered to be sons of gods through union with mortal women. From around 360 BC onwards Alexander the Great may have implied he was a demigod by using the title \"Son of Ammon\u2013Zeus\".\nIn 42 BC, Julius Caesar was formally deified as \"the divine Julius\" (\"divus Iulius\") after his assassination. His adopted son, Octavian (better known as Augustus, a title given to him 15 years later, in 27 BC) thus became known as \"divi Iuli filius\" (son of the divine Julius) or simply \"divi filius\" (son of the god). As a daring and unprecedented move, Augustus used this title to advance his political position in the Second Triumvirate, finally overcoming all rivals for power within the Roman state.\nThe word which was applied to Julius Caesar when he was deified was \"divus\", not the distinct word \"deus\". Thus, Augustus called himself \"Divi filius\", not \"Dei filius\". The line between been god and god-like was at times less than clear to the population at large, and Augustus seems to have been aware of the necessity of keeping the ambiguity. As a purely semantic mechanism, and to maintain ambiguity, the court of Augustus sustained the concept that any worship given to an emperor was paid to the \"position of emperor\" rather than the person of the emperor. However, the subtle semantic distinction was lost outside Rome, where Augustus began to be worshiped as a deity. The inscription DF thus came to be used for Augustus, at times unclear which meaning was intended. The assumption of the title \"Divi filius\" by Augustus meshed with a larger campaign by him to exercise the power of his image. Official portraits of Augustus made even towards the end of his life continued to portray him as a handsome youth, implying that miraculously, he never aged. Given that few people had ever seen the emperor, these images sent a distinct message.\nLater, Tiberius (emperor from 14 to 37 AD) came to be accepted as the son of \"divus Augustus\" and Hadrian as the son of \"divus Trajan\". By the end of the 1st century, the emperor Domitian was being called \"dominus et deus\" (i.e. master and god).\nOutside the Roman Empire, the 2nd-century Kushan King Kanishka I used the title \"devaputra\" meaning \"son of God\".\nBah\u00e1\u02bc\u00ed Faith.\nIn the writings of the Bah\u00e1\u02bc\u00ed Faith, the term \"Son of God\" is applied to Jesus, but does not indicate a literal physical relationship between Jesus and God. It is symbolic and is used to indicate the very strong spiritual relationship between Jesus and God and the source of his authority. Shoghi Effendi, the head of the Bah\u00e1\u02bc\u00ed Faith in the first half of the 20th century, also noted that the term does not indicate that the station of Jesus is superior to other prophets and messengers that Bah\u00e1\u02bc\u00eds name Manifestation of God, including Buddha, Muhammad and Baha'u'llah among others. Shoghi Effendi notes that, since all Manifestations of God share the same intimate relationship with God and reflect the same light, the term Sonship can in a sense be attributable to all the Manifestations.\nChristianity.\nIn Christianity, the title \"Son of God\" refers to the status of Jesus as the divine son of God the Father. It derives from several uses in the New Testament and early Christian theology. The term is used in all four gospels, the Acts of the Apostles, and the Pauline and Johannine literature.\nAnother interpretation stems from the Judaic understanding of the title, which describes all human beings as being Sons of God. In parts of the Old Testament, historical figures like Jacob and Solomon are referred to as Sons of God, referring to their descent from Adam. Biblical scholars use this title as a way of affirming Jesus' humanity, that he is fully human, but also sent from his father who is God almighty alone as mentioned in John 3:16.\nIslam.\nIn Islam, Jesus is known as \"\u012as\u0101 ibn Maryam\" (), and is understood to be a prophet and messenger of God (Allah) and \"al-Masih\", the Arabic term for Messiah (Christ), sent to guide the tribe of Israel (\"ban\u012b isr\u0101'\u012bl\" in Arabic) with a new revelation, the \"al-Inj\u012bl\" (Arabic for \"the gospel\").\nIslam rejects any kinship between God and any other being, including a son. Thus, rejecting the belief that Jesus is the begotten son of God, God himself or another god. As in Christianity, Islam believes Jesus had no earthly father. In Islam Jesus is believed to be born due to the command of God \"be\". God ordered the angel Jibr\u012bl (Gabriel) to \"blow\" the soul of Jesus into Mary and so she gave birth to Jesus.\nJudaism.\nAlthough references to \"sons of God\", \"son of God\" and \"son of the LORD\" are occasionally found in Jewish literature, they never refer to physical descent from God. There are two instances where Jewish kings are figuratively referred to as a god. These terms are often used in the general sense in which the Jewish people were referred to as \"children of the LORD your God\".\nWhen it was used by the rabbis, the term referred to Israel in particular or it referred to human beings in general, it was not used as a reference to the Jewish mashiach. In Judaism the term \"mashiach\" has a broader meaning and usage and can refer to a wide range of people and objects, not necessarily related to the Jewish eschaton.\nGabriel's Revelation.\nGabriel's Revelation, also called the Vision of Gabriel or the Jeselsohn Stone, is a three-foot-tall (one metre) stone tablet with 87 lines of Hebrew text written in ink, containing a collection of short prophecies written in the first person and dated to the late 1st century BC. It is a tablet described as a \"Dead Sea scroll in stone\".\nThe text seems to talk about a messianic figure from Ephraim who broke evil before righteousness by three days. Later the text talks about a \"prince of princes\" a leader of Israel who was killed by the evil king and not properly buried. The evil king was then miraculously defeated. The text seems to refer to Jeremiah Chapter 31. The choice of Ephraim as the lineage of the messianic figure described in the text seems to draw on passages in Jeremiah, Zechariah and Hosea. This leader was referred to as a son of God.\nThe text seems to be based on a Jewish revolt recorded by Josephus dating from 4 BC. Based on its dating the text seems to refer to Simon of Peraea, one of the three leaders of this revolt.\nDead Sea Scrolls.\nIn some versions of Deuteronomy the Dead Sea Scrolls refer to the sons of God rather than the sons of Israel, probably in reference to angels. The Septuagint reads similarly.\n4Q174 is a midrashic text in which God refers to the Davidic messiah as his son.\n4Q246 refers to a figure who will be called the son of God and son of the Most High. It is debated if this figure represents the royal messiah, a future evil gentile king or something else.\nIn 11Q13 Melchizedek is referred to as god the divine judge. Melchizedek in the bible was the king of Salem. At least some in the Qumran community seemed to think that at the end of days Melchizedek would reign as their king. The passage is based on Psalm 82.\nPseudepigrapha.\nIn Joseph and Aseneth and the related text The Story of Asenath, Joseph is referred to as the son of God. In the Prayer of Joseph both Jacob and the angel are referred to as angels and the sons of God.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "28171", "revid": "39276444", "url": "https://en.wikipedia.org/wiki?curid=28171", "title": "SA", "text": "Sa, SA, S.A. or s.a. may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "28172", "revid": "49416358", "url": "https://en.wikipedia.org/wiki?curid=28172", "title": "Saint Boniface", "text": "Anglo-Saxon missionary and saint (died 754)\nBoniface (born Wynfreth; c. 675 \u20135 June 754) was an English Benedictine monk and leading figure in the Anglo-Saxon mission to the Germanic parts of Francia during the eighth century. He organised significant foundations of the church in Germany and was made Archbishop of Mainz by Pope Gregory III. He was martyred in Frisia in 754, along with 52 others, and his remains were returned to Fulda, where they rest in a sarcophagus which remains a site of Christian pilgrimage.\nBoniface's life and death as well as his work became widely known, there being a wealth of material available\u00a0\u2013 a number of , especially the near-contemporary , legal documents, possibly some sermons, and above all his correspondence. He is venerated as a saint in the Christian church and became the patron saint of Germania, known as the \"Apostle to the Germans\".\nNorman Cantor notes the three roles Boniface played that made him \"one of the truly outstanding creators of the first Europe, as the apostle of Germania, the reformer of the Frankish Church, and the chief fomentor of the alliance between the papacy and the Carolingian family.\" Through his efforts to reorganize and regulate the church of the Franks, he helped shape the Latin Church in Europe, and many of the dioceses he proposed remain today. After his martyrdom, he was quickly hailed as a saint in Fulda and other areas in Germania and in England. He is still venerated strongly today by Catholics in Germany and throughout the German diaspora. Boniface is celebrated as a missionary; he is regarded as a unifier of Europe, and he is regarded by German Roman Catholics as a national figure.\nIn 2019 Devon County Council, with the support of the Anglican Diocese of Exeter, the Roman Catholic Diocese of Plymouth, and local Devon leaders of the Orthodox, Methodist, and Congregational churches, officially recognised St Boniface as the Patron Saint of Devon.\nEarly life.\nThe earliest Bonifacian vita does not indicate his place of birth but says that at an early age he attended a monastery ruled by Abbot Wulfhard in , or \"Examchester\", which seems to denote Exeter, and may have been one of many built by local landowners and churchmen; nothing else is known of it outside the Bonifacian . This monastery is believed to have occupied the site of the Church of St Mary Major in the City of Exeter, demolished in 1971, next to which was later built Exeter Cathedral. Later tradition places his birth at Crediton, but the earliest mention of Crediton in connection to Boniface is from the early fourteenth century, in John Grandisson's \"Legenda Sanctorum: The Proper Lessons for Saints' Days according to the use of Exeter\". In one of his letters Boniface mentions he was \"born and reared...[in] the synod of London\", but he may have been speaking metaphorically. His English name is recorded as being Winfrid or Winfred.\nAccording to the , Winfrid was of a respected and prosperous family. Against his father's wishes he devoted himself at an early age to the monastic life. He received further theological training in the Benedictine monastery and minster of Nhutscelle (Nursling), not far from Winchester, which under the direction of abbot Winbert had grown into an industrious centre of learning in the tradition of Aldhelm. Winfrid taught in the abbey school and at the age of 30 became a priest; in this time, he wrote a Latin grammar, the , besides a treatise on verse and some Aldhelm-inspired riddles. While little is known about Nursling outside Boniface's , it seems clear that the library there was significant. To supply Boniface with the materials he needed, it would have contained works by Donatus, Priscian, Isidore, and many others. Around 716, when his abbot Wynberth of Nursling died, he was invited (or expected) to assume his position\u2014it is possible that they were related, and the practice of hereditary right among the early Anglo-Saxons would affirm this. Winfrid, however, declined the position and in 716 set out on a missionary expedition to Frisia.\nEarly missionary work in Frisia and Germania.\nBoniface first left for the continent in 716. He traveled to Utrecht, where Willibrord, the \"Apostle to the Frisians\", had been working since the 690s. He spent a year with Willibrord, preaching in the countryside, but their efforts were frustrated by the war then being carried on between Charles Martel and Radbod, King of the Frisians. Willibrord fled to the abbey he had founded in Echternach (in modern-day Luxembourg) while Boniface returned to Nursling.\nBoniface returned to the continent the next year and went straight to Rome, where Pope Gregory II renamed him \"Boniface\", after the (legendary) fourth-century martyr Boniface of Tarsus, and appointed him missionary bishop for Germania\u2014he became a bishop without a diocese for an area that lacked any church organization. He would never return to England, though he remained in correspondence with his countrymen and kinfolk throughout his life.\nAccording to the \"vitae\" Boniface felled the Donar Oak, Latinized by Willibald as \"Jupiter's oak\", near the present-day town of Fritzlar in northern Hesse. According to his early biographer Willibald, Boniface started to chop the oak down, when suddenly a great wind, by miracle, blew the ancient oak over. When the gods did not strike him down, the people were amazed and converted to Christianity. He built a church from its wood at the site\u2014the church was the beginning of the monastery in Fritzlar. This account from the \"vita\" is stylised to portray Boniface as a singular character who alone acts to root out paganism. Lutz von Padberg and others claim that what the \"vitae\" leave out is that the action was most likely well-prepared and widely publicized in advance for maximum effect, and that Boniface had little reason to fear for his personal safety since the Frankish fortified settlement of B\u00fcraburg was nearby. According to Willibald, Boniface later had a church with an attached monastery built in Fritzlar, on the site of the previously built chapel, according to tradition.\nBoniface and the Carolingians.\nThe support of the Frankish mayors of the palace, and later the early Pippinids and the Carolingian dynasty, was essential for Boniface's work. Boniface had been under the protection of Charles Martel from 723 onwards. The Christian Frankish leaders desired to defeat their rival power, the pagan Saxons, and to incorporate the Saxon lands into their own growing empire. Boniface's campaign of destruction of indigenous Germanic pagan sites may have benefited the Franks in their campaign against the Saxons.\nIn 732, Boniface traveled again to Rome to report, and Pope Gregory III conferred upon him the pallium as archbishop with jurisdiction over what is now Germany. Boniface again set out for the German lands and continued his mission, but also used his authority to work on the relations between the papacy and the Frankish church. Rome wanted more control over that church, which it felt was much too independent and which, in the eyes of Boniface, was subject to worldly corruption. Charles Martel, after having defeated the forces of the Umayyad Caliphate during the Battle of Tours (732), had rewarded many churches and monasteries with lands, but typically his supporters who held church offices were allowed to benefit from those possessions. Boniface would have to wait until the 740s before he could try to address this situation, in which Frankish church officials were essentially sinecures, and the church itself paid little heed to Rome. During his third visit to Rome in 737\u201338, he was made papal legate for Germany.\nAfter Boniface's third trip to Rome, Charles Martel established four dioceses in Bavaria (Salzburg, Regensburg, Freising, and Passau) and gave them to Boniface as archbishop and metropolitan over all Germany east of the Rhine. In 745, he was granted Mainz as metropolitan see. In 742, one of his disciples, Sturm (also known as Sturmi, or Sturmius), founded the abbey of Fulda not far from Boniface's earlier missionary outpost at Fritzlar. Although Sturm was the founding abbot of Fulda, Boniface was very involved in the foundation. The initial grant for the abbey was signed by Carloman, the son of Charles Martel, and a supporter of Boniface's reform efforts in the Frankish church. Boniface himself explained to his old friend, Daniel of Winchester, that without the protection of Charles Martel he could \"neither administer his church, defend his clergy, nor prevent idolatry\".\nAccording to German historian Gunther Wolf, the high point of Boniface's career was the Concilium Germanicum, organized by Carloman in an unknown location in April 743. Although Boniface was not able to safeguard the church from property seizures by the local nobility, he did achieve one goal, the adoption of stricter guidelines for the Frankish clergy, who often hailed directly from the nobility. After Carloman's resignation in 747 he maintained a sometimes turbulent relationship with the king of the Franks, Pepin the Short; the claim that he would have crowned Pepin at Soissons in 751 is now generally discredited.\nBoniface balanced this support and attempted to maintain some independence, however, by attaining the support of the papacy and of the Agilolfings of Bavaria. In Frankish, Hessian, and Thuringian territory, he established the diocese of W\u00fcrzburg (741). By appointing his own followers as bishops, he was able to retain some independence from the Carolingians, who most likely were content to give him leeway as long as Christianity was imposed on the Saxons and other Germanic tribes.\nLast mission to Frisia.\nAccording to the , Boniface had never relinquished his hope of converting the Frisians, and in 754 he set out with a retinue for Frisia. He baptized a great number and summoned a general meeting for confirmation at a place not far from Dokkum, between Franeker and Groningen. However, instead of his converts, a group of armed robbers appeared and slew the aged archbishop. The mention that Boniface persuaded his (armed) comrades to lay down their arms: \"Cease fighting. Lay down your arms, for we are told in Scripture not to render evil for evil but to overcome evil by good.\"\nHaving killed Boniface and his company, the Frisian bandits ransacked their possessions but found that the company's luggage did not contain the riches they had hoped for: \"they broke open the chests containing the books and found, to their dismay, that they held manuscripts instead of gold vessels, pages of sacred texts instead of silver plates.\" They attempted to destroy these books, the earliest already says, and this account underlies the status of the Ragyndrudis Codex, now held as a Bonifacian relic in Fulda, and supposedly one of three books found on the field by the Christians who inspected it afterward. Of those three books, the Ragyndrudis Codex shows incisions that could have been made by sword or axe; its story appears confirmed in the Utrecht hagiography, the , which reports that an eye-witness saw that the saint at the moment of death held up a gospel as spiritual protection. The story was later repeated by Otloh's ; at that time, the Ragyndrudis Codex seems to have been firmly connected to the martyrdom.\nBoniface's remains were moved from the Frisian countryside to Utrecht, and then to Mainz, where sources contradict each other regarding the behavior of Lullus, Boniface's successor as archbishop of Mainz. According to Willibald's Lullus allowed the body to be moved to Fulda, while the (later) , a hagiography of Sturm by Eigil of Fulda, Lullus attempted to block the move and keep the body in Mainz.\nHis remains were eventually buried in the abbey church of Fulda after resting for some time in Utrecht, and they are entombed within a shrine beneath the high altar of Fulda Cathedral, previously the abbey church.\nThere is good reason to believe that the Gospel he held up was the 56, which shows damage to the upper margin, which has been cut back as a form of repair.\nVeneration.\nFulda.\nVeneration of Boniface in Fulda began immediately after his death; his grave was equipped with a decorative tomb around ten years after his burial, and the grave and relics became the center of the abbey. Fulda monks prayed for newly elected abbots at the grave site before greeting them, and every Monday the saint was remembered in prayer, the monks prostrating themselves and reciting Psalm 50. After the abbey church was rebuilt to become the Ratgar Basilica (dedicated 791), Boniface's remains were translated to a new grave: since the church had been enlarged, his grave, originally in the west, was now in the middle; his relics were moved to a new apse in 819. From then on Boniface, as patron of the abbey, was regarded as both spiritual intercessor for the monks and legal owner of the abbey and its possessions, and all donations to the abbey were done in his name. He was honored on the date of his martyrdom, 5 June (with a mass written by Alcuin), and (around the year 1000) with a mass dedicated to his appointment as bishop, on 1 December.\nDokkum.\nWillibald's describes how a visitor on horseback came to the site of the martyrdom, and a hoof of his horse got stuck in the mire. When it was pulled loose, a well sprang up. By the time of the (9th century), there was a church on the site, and the well had become a \"fountain of sweet water\" used to sanctify people. The , a hagiographical account of the work of Ludger, describes how Ludger himself had built the church, sharing duties with two other priests. According to James Palmer, the well was of great importance since the saint's body was hundreds of miles away; the physicality of the well allowed for an ongoing connection with the saint. In addition, Boniface signified Dokkum's and Frisia's \"connect[ion] to the rest of (Frankish) Christendom\".\nMemorials.\nSaint Boniface's feast day is celebrated on 5 June in the Roman Catholic Church, the Lutheran Church, the Anglican Communion and the Eastern Orthodox Church.\nA famous statue of Saint Boniface stands on the grounds of Mainz Cathedral, seat of the archbishop of Mainz. A more modern rendition stands facing St. Peter's Church of Fritzlar.\nThe UK National Shrine is located at the Catholic church at Crediton, Devon, which has a bas-relief of the felling of Thor's Oak, by sculptor Kenneth Carter. The sculpture was unveiled by Princess Margaret in his native Crediton, located in Newcombes Meadow Park. There is also a series of paintings there by Timothy Moore. There are quite a few churches dedicated to St. Boniface in the United Kingdom: Bunbury, Cheshire; Chandler's Ford and Southampton Hampshire; Adler Street, London; Papa Westray, Orkney; St Budeaux, Plymouth (now demolished); Bonchurch, Isle of Wight; Cullompton, Devon.\nSt Boniface Down, the highest point in the Isle of Wight, is named after him.\nBishop George Errington founded St Boniface's Catholic College, Plymouth in 1856. The school celebrates Saint Boniface on 5 June each year.\nIn 1818, Father Norbert Provencher founded a mission on the east bank of the Red River in what was then Rupert's Land, building a log church and naming it after St. Boniface. The log church was consecrated as Saint Boniface Cathedral after Provencher was himself consecrated as a bishop and the diocese was formed. The community that grew around the cathedral eventually became the city of Saint Boniface, which merged into the city of Winnipeg in 1971. In 1844, four Grey Nuns arrived by canoe in Manitoba, and in 1871, built Western Canada's first hospital: St. Boniface Hospital, where the Assiniboine and Red Rivers meet. Today, St. Boniface is regarded as Winnipeg's main French-speaking district and the centre of the Franco-Manitobain community, and St. Boniface Hospital is the second-largest hospital in Manitoba.\nBoniface (Wynfrith) of Crediton is remembered in the Church of England with a Lesser Festival on 5 June.\nLegends.\nSome traditions credit Saint Boniface with the invention of the Christmas tree. It is mentioned on a BBC-Devon website, in an account which places Geismar in Bavaria, and in a number of educational books, including \"St. Boniface and the Little Fir Tree\", \"The Brightest Star of All: Christmas Stories for the Family\", \"The American normal readers\", and a short story by Henry van Dyke, \"The First Christmas Tree\".\nSources and writings.\nThe earliest \"Life\" of Boniface was written by a certain Willibald, an Anglo-Saxon priest who came to Mainz after Boniface's death, around 765. Willibald's biography was widely dispersed; Levison lists some forty manuscripts. According to his lemma, a group of four manuscripts including 1086 are copies directly from the original.\nListed second in Levison's edition is the entry from a late ninth-century Fulda document: Boniface's status as a martyr is attested by his inclusion in the \"Fulda Martyrology\" which also lists, for instance, the date (1 November) of his translation in 819, when the Fulda Cathedral had been rebuilt. A was written in Fulda in the ninth century, possibly by Candidus of Fulda, but is now lost.\nThe next , chronologically, is the , which originates in the Bishopric of Utrecht, and was probably revised by Radboud of Utrecht (899\u2013917). Mainly agreeing with Willibald, it adds an eye-witness who presumably saw the martyrdom at Dokkum. The likewise originates in Utrecht. It is dated between 917 (Radboud's death) and 1075, the year Adam of Bremen wrote his , which used the .\nA later , written by Otloh of St. Emmeram (1062\u20131066), is based on Willibald's and a number of other as well as the correspondence, and also includes information from local traditions.\nCorrespondence.\nBoniface engaged in regular correspondence with fellow churchmen all over Western Europe, including the three popes he worked with, and with some of his kinsmen back in England. Many of these letters contain questions about church reform and liturgical or doctrinal matters. In most cases, what remains is one half of the conversation, either the question or the answer. The correspondence as a whole gives evidence of Boniface's widespread connections; some of the letters also prove an intimate relationship especially with female correspondents.\nThere are 150 letters in what is generally called the Bonifatian correspondence, though not all them are by Boniface or addressed to him. They were assembled by order of archbishop Lullus, Boniface's successor in Mainz, and were initially organized into two parts, a section containing the papal correspondence and another with his private letters. They were reorganized in the eighth century, in a roughly chronological ordering. Otloh of St. Emmeram, who worked on a new of Boniface in the eleventh century, is credited with compiling the complete correspondence as we have it. Much of this correspondence comprises the first part of the Vienna Boniface Codex, also known as .\nThe correspondence was edited and published already in the seventeenth century, by Nicolaus Serarius. Stephan Alexander W\u00fcrdtwein's 1789 edition, , was the basis for a number of (partial) translations in the nineteenth century. The first version to be published by (MGH) was the edition by Ernst D\u00fcmmler (1892); the most authoritative version until today is Michael Tangl's 1912 , published by MGH in 1916. This edition is the basis of Ephraim Emerton's selection and translation in English, \"The Letters of Saint Boniface\", first published in New York in 1940; it was republished most recently with a new introduction by Thomas F.X. Noble in 2000.\nIncluded among his letters and dated to 716 is one to Abbess Edburga of Minster-in-Thanet containing the \"Vision of the Monk of Wenlock\". This otherworld vision describes how a violently ill monk is freed from his body and guided by angels to a place of judgment, where angels and devils fight over his soul as his sins and virtues come alive to accuse and defend him. He sees a hell of purgation full of pits vomiting flames. There is a bridge over a pitch-black boiling river. Souls either fall from it or safely reach the other side cleansed of their sins. This monk even sees some of his contemporary monks and is told to warn them to repent before they die. This vision bears signs of influence by the Apocalypse of Paul, the visions from the \"Dialogues\" of Gregory the Great, and the visions recorded by Bede.\nSermons.\nSome fifteen preserved sermons are traditionally associated with Boniface, but that they were actually his is not generally accepted.\nGrammar and poetry.\nEarly in his career, before he left for the continent, Boniface wrote the , a grammatical treatise presumably for his students in Nursling. Helmut Gneuss reports that one manuscript copy of the treatise originates from (the south of) England, mid-eighth century; it is now held in Marburg, in the Hessisches Staatsarchiv. He also wrote a treatise on verse, the , and a collection of twenty acrostic riddles, the , influenced greatly by Aldhelm and containing many references to works of Vergil (the \"Aeneid\", the \"Georgics\", and the \"Eclogues\"). The riddles fall into two sequences of ten poems. The first, ('on the virtues'), comprises: 1. /truth; 2. /the Catholic faith; 3. /hope; 4. /compassion; 5. /love; 6. /justice; 7. /patience; 8. /true, Christian peace; 9. /Christian humility; 10. /virginity. The second sequence, ('on the vices'), comprises: 1. /carelessness; 2. /hot temper; 3. /greed; 4. /pride; 5. /intemperance; 6. /drunkenness; 7. /fornication; 8. /envy; 9. /ignorance; 10. /vainglory.\nThree octosyllabic poems written in clearly Aldhelmian fashion (according to Andy Orchard) are preserved in his correspondence, all composed before he left for the continent.\nAdditional materials.\nA letter by Boniface charging Aldebert and Clement with heresy is preserved in the records of the Roman Council of 745 that condemned the two. Boniface had an interest in the Irish canon law collection known as , and a late eighth/early ninth-century manuscript in W\u00fcrzburg contains, besides a selection from the , a list of rubrics that mention the heresies of Clemens and Aldebert. The relevant folios containing these rubrics were most likely copied in Mainz, W\u00fcrzburg, or Fulda\u2014all places associated with Boniface. Michael Glatthaar suggested that the rubrics should be seen as Boniface's contribution to the agenda for a synod.\nAnniversary and other celebrations.\nBoniface's death (and birth) has given rise to a number of noteworthy celebrations. The dates for some of these celebrations have undergone some changes: in 1805, 1855, and 1905 (and in England in 1955) anniversaries were calculated with Boniface's death dated in 755, according to the \"Mainz tradition\"; in Mainz, Michael Tangl's dating of the martyrdom in 754 was not accepted until after 1955. Celebrations in Germany centered on Fulda and Mainz, in the Netherlands on Dokkum and Utrecht, and in England on Crediton and Exeter.\nCelebrations in Germany: 1805, 1855, 1905.\nThe first German celebration on a fairly large scale was held in 1805 (the 1,050th anniversary of his death), followed by a similar celebration in a number of towns in 1855; both of these were predominantly Catholic affairs emphasizing the role of Boniface in German history. But if the celebrations were mostly Catholic, in the first part of the 19th century the respect for Boniface in general was an ecumenical affair, with both Protestants and Catholics praising Boniface as a founder of the German nation, in response to the German nationalism that arose after the Napoleonic era came to an end. The second part of the 19th century saw increased tension between Catholics and Protestants; for the latter, Martin Luther had become the model German, the founder of the modern nation, and he and Boniface were in direct competition for the honor. In 1905, when strife between Catholic and Protestant factions had eased (one Protestant church published a celebratory pamphlet, Gerhard Ficker's ), there were modest celebrations and a publication for the occasion on historical aspects of Boniface and his work, the 1905 by Gregor Richter and Carl Scherer. In all, the content of these early celebrations showed evidence of the continuing question about the meaning of Boniface for Germany, though the importance of Boniface in cities associated with him was without question.\n1954 celebrations.\nIn 1954, celebrations were widespread in England, Germany, and the Netherlands, and a number of these celebrations were international affairs. Especially in Germany, these celebrations had a distinctly political note to them and often stressed Boniface as a kind of founder of Europe, such as when Konrad Adenauer, the (Catholic) German chancellor, addressed a crowd of 60,000 in Fulda, celebrating the feast day of the saint in a European context: (\"What we have in common in Europe comes from the same source\").\n1980 papal visit.\nWhen Pope John Paul II visited Germany in November 1980, he spent two days in Fulda (17 and 18 November). He celebrated Mass in Fulda Cathedral with 30,000 gathered on the square in front of the building, and met with the German Bishops' Conference (held in Fulda since 1867). The pope next celebrated mass outside the cathedral, in front of an estimated crowd of 100,000, and hailed the importance of Boniface for German Christianity: (\"The holy Boniface, bishop and martyr, 'signifies' the beginning of the gospel and the church in your country\"). A photograph of the pope praying at Boniface's grave became the centerpiece of a prayer card distributed from the cathedral.\n2004 celebrations.\nIn 2004, anniversary celebrations were held throughout Northwestern Germany and Utrecht, and Fulda and Mainz\u2014generating a great amount of academic and popular interest. The event occasioned a number of scholarly studies, esp. biographies (for instance, by Auke Jelsma in Dutch, Lutz von Padberg in German, and Klaas Bruinsma in Frisian), and a fictional completion of the Boniface correspondence (Lutterbach, ). A German musical proved a great commercial success, and in the Netherlands an opera was staged.\nScholarship on Boniface.\nThere is an extensive body of literature on the saint and his work. At the time of the various anniversaries, edited collections were published containing essays by some of the best-known scholars of the time, such as the 1954 collection and the 2004 collection . In the modern era, Lutz von Padberg published a number of biographies and articles on the saint focusing on his missionary praxis and his relics. The most authoritative biography remains Theodor Schieffer's (1954).\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28174", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=28174", "title": "Data storage", "text": "Recording of information in a storage medium\nData storage is the recording (storing) of information (data) in a storage medium. Handwriting, phonographic recording, magnetic tape, and optical discs are all examples of storage media. Biological molecules such as RNA and DNA are considered by some as data storage. Recording may be accomplished with virtually any form of energy. Electronic data storage requires electrical power to store and retrieve data. \nData storage in a digital, machine-readable medium is sometimes called \"digital data\". Computer data storage is one of the core functions of a general-purpose computer. Electronic documents can be stored in much less space than paper documents. Barcodes and magnetic ink character recognition (MICR) are two ways of recording machine-readable data on paper.\nRecording media.\nA recording medium is a physical material that holds information. Newly created information is distributed and can be stored in four storage media\u2013print, film, magnetic, and optical\u2013and seen or heard in four information flows\u2013telephone, radio and TV, and the Internet as well as being observed directly. Digital information is stored on electronic media in many different recording formats.\nWith electronic media, the data and the recording media are sometimes referred to as \"software\" despite the more common use of the word to describe computer software. With (traditional art) static media, art materials such as crayons may be considered both equipment and medium as the wax, charcoal or chalk material from the equipment becomes part of the surface of the medium.\nSome recording media may be temporary, either by design or by nature. Volatile organic compounds may be used to preserve the environment or to purposely make data expire over time. Data such as smoke signals or skywriting are temporary by nature. Depending on the volatility, a gas (e.g., atmosphere, smoke) or a liquid surface such as a lake would be considered a temporary recording medium if at all.\nGlobal capacity, digitization, and trends.\nA 2003 UC Berkeley report estimated that about five exabytes of new information were produced in 2002 and that 92% of this data was stored on hard disk drives. This was about twice the data produced in 2000. The amount of data transmitted over telecommunications systems in 2002 was nearly 18 exabytes\u2014three and a half times more than was recorded on non-volatile storage. Telephone calls constituted 98% of the telecommunicated information in 2002. The researchers' highest estimate for the growth rate of newly stored information (uncompressed) was more than 30% per year.\nIn a more limited study, the International Data Corporation estimated that the total amount of digital data in 2007 was 281 exabytes and that the total amount of digital data produced exceeded the global storage capacity for the first time.\nA 2011 \"Science Magazine\" article estimated that the year 2002 was the beginning of the digital age for information storage: an age in which more information is stored on digital storage devices than on analog storage devices. In 1986, approximately 1% of the world's capacity to store information was in digital format; this grew to 3% by 1993, to 25% by 2000, and to 97% by 2007. These figures correspond to less than three compressed exabytes in 1986, and 295 compressed exabytes in 2007. The quantity of digital storage doubled roughly every three years.\nIt is estimated that around 120 zettabytes of data will be generated in 2023[ [update]], an increase of 60x from 2010, and that it will increase to 181 zettabytes generated in 2025.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28175", "revid": "50984550", "url": "https://en.wikipedia.org/wiki?curid=28175", "title": "Sinn F\u00e9in", "text": "Irish political party\nSinn F\u00e9in ( ; ; lit.\u2009'[We] Ourselves') is an Irish republican and democratic socialist political party active in both the Republic of Ireland and Northern Ireland.\nThe original Sinn F\u00e9in organisation was founded in 1905 by Arthur Griffith. Its members founded the revolutionary Irish Republic and its parliament, the First D\u00e1il, and many of them were active in the Irish War of Independence, during which the party was associated with the Irish Republican Army (1919\u20131922). The party split before the Irish Civil War and again in its aftermath, giving rise to the two traditionally dominant parties of Irish politics: Fianna F\u00e1il, and Cumann na nGaedheal (which merged with smaller groups to form Fine Gael). For several decades the remaining Sinn F\u00e9in organisation was small and often without parliamentary representation. It continued its association with the Irish Republican Army. Another split in 1970 at the start of the Troubles led to the modern Sinn F\u00e9in party, with the other faction eventually becoming the Workers' Party.\nDuring the Troubles, Sinn F\u00e9in was associated with the Provisional Irish Republican Army. For most of that conflict, it was affected by broadcasting bans in the Irish and British media. Although the party sat on local councils, it maintained a policy of abstentionism for the British House of Commons and the Irish D\u00e1il \u00c9ireann, standing for election to those legislatures but pledging not to take their seats if elected. After Gerry Adams became party leader in 1983, electoral politics were prioritised increasingly. In 1986, the party dropped its abstentionist policy for the D\u00e1il; some members formed Republican Sinn F\u00e9in in protest. In the 1990s, Sinn F\u00e9in\u2014under the leadership of Adams and Martin McGuinness\u2014was involved in the Northern Ireland peace process. This led to the Good Friday Agreement and created the Northern Ireland Assembly, and saw Sinn F\u00e9in become part of the power-sharing Northern Ireland Executive. In 2006, it co-signed the St Andrews Agreement and agreed to support the Police Service of Northern Ireland.\nSinn F\u00e9in is the largest party in the Northern Ireland Assembly, having won the largest share of first-preference votes and the most seats in the 2022 election, the first time an Irish nationalist party has done so. Since 2024, Michelle O'Neill has served as the first ever Irish nationalist First Minister of Northern Ireland. From 2007 to 2022, Sinn F\u00e9in was the second-largest party in the Assembly, after the Democratic Unionist Party (DUP), and its nominees served as Deputy First Minister in the Northern Ireland Executive.\nIn the House of Commons of the United Kingdom, Sinn F\u00e9in has held seven of Northern Ireland's seats since the 2024 election; it continues its policy of abstentionism at Westminster. In D\u00e1il \u00c9ireann it is the main opposition, having won the second largest number of seats in the 2024 election. The current president of Sinn F\u00e9in is Mary Lou McDonald, who succeeded Gerry Adams in 2018.\nName.\nThe phrase \"Sinn F\u00e9in\" is Irish for \"Ourselves\" or \"We Ourselves\", although it is frequently mistranslated as \"ourselves alone\" (from \"Sinn F\u00e9in Amh\u00e1in\", an early-20th-century slogan). The name is an assertion of Irish national sovereignty and self-determination, i.e., the Irish people governing themselves, rather than being part of a political union with Great Britain under the Westminster Parliament.\nA split in January 1970, mirroring a split in the IRA, led to the emergence of two groups calling themselves Sinn F\u00e9in. The majority group, under the continued leadership of Tom\u00e1s Mac Giolla, became known as \"Official Sinn F\u00e9in\" or \"Sinn F\u00e9in (Gardiner Place)\". The minority group, led by Ruair\u00ed \u00d3 Br\u00e1daigh, became known as \"Provisional Sinn F\u00e9in\" or \"Sinn F\u00e9in (Kevin Street)\". \"Official Sinn F\u00e9in\" changed its name to \"Sinn F\u00e9in-The Workers' Party\" in 1977, and in 1982 it changed its name to \"The Workers' Party\". As the \"Official\" group had dropped all mention of Sinn F\u00e9in from its name in 1982, the term \"Provisional Sinn F\u00e9in\" fell out of use, and in 1987 \"Provisional Sinn F\u00e9in\" registered as a political party in the Republic of Ireland under the name \"Sinn F\u00e9in\".\nSinn F\u00e9in members have been referred to colloquially as \"Shinners\", a term intended as a pejorative.\nHistory.\n1905\u20131922.\nSinn F\u00e9in was founded on 28 November 1905, when, at the first annual Convention of the National Council, Arthur Griffith outlined the Sinn F\u00e9in policy, \"to establish in Ireland's capital a national legislature endowed with the moral authority of the Irish nation\". Its initial political platform was both conservative and monarchist, advocating for an Anglo-Irish dual monarchy unified with the British Crown (inspired by the Austro-Hungarian Compromise of 1867). The party contested the 1908 North Leitrim by-election, where it secured 27% of the vote. Thereafter, both support and membership fell. At its 1910 (party conference) attendance was poor, and there was difficulty finding members willing to take seats on the executive.\nIn 1914, Sinn F\u00e9in members, including Griffith, joined the anti-Redmond Irish Volunteers, which was referred to by Redmondites and others as the \"Sinn F\u00e9in Volunteers\". Although Griffith himself did not take part in the Easter Rising of 1916, many Sinn F\u00e9in members who were members of the Volunteers and the Irish Republican Brotherhood did. Government and newspapers dubbed the Rising \"the Sinn F\u00e9in Rising\". After the Rising, republicans came together under the banner of Sinn F\u00e9in, and at the 1917 \"ard fheis\" the party committed itself for the first time to the establishment of an Irish Republic. In the 1918 general election, Sinn F\u00e9in won 73 of Ireland's 105 seats, and in January 1919, its MPs assembled in Dublin and proclaimed themselves D\u00e1il \u00c9ireann, the parliament of Ireland. Sinn F\u00e9in candidate Constance Markievicz became the first woman elected to the United Kingdom House of Commons. However, in line with Sinn F\u00e9in abstentionist policy, she did not take her seat in the House of Commons.\nThe party supported the Irish Republican Army during the War of Independence, and members of the D\u00e1il government negotiated the Anglo-Irish Treaty with the British government in 1921. In the D\u00e1il debates that followed, the party divided on the Treaty. The pro-Treaty and anti-Treaty components (led by Michael Collins and \u00c9amon de Valera respectively) managed to agree on a \"Coalition Panel\" of Sinn F\u00e9in candidates to stand in the 1922 general election. After the election, anti-Treaty members walked out of the D\u00e1il, and pro- and anti-Treaty members took opposite sides in the ensuing Civil War.\n1923\u20131970.\nPro-Treaty D\u00e1il deputies and other Treaty supporters formed a new party, Cumann na nGaedheal, on 27 April 1923 at a meeting in Dublin, where delegates agreed on a constitution and political programme. Cumann na nGaedheal went on to govern the new Irish Free State for nine years (it merged with two other organisations to form Fine Gael in 1933). Anti-Treaty Sinn F\u00e9in members continued to boycott the D\u00e1il. At a special \"Ard Fheis\" in March 1926, de Valera proposed that elected members be allowed to take their seats in the D\u00e1il if and when the controversial Oath of Allegiance was removed. When his motion was defeated, de Valera resigned from Sinn F\u00e9in; on 16 May 1926, he founded his own party, Fianna F\u00e1il, which was dedicated to republicanising the Free State from within its political structures. He took most Sinn F\u00e9in Teachta\u00ed D\u00e1la (TDs) with him. De Valera's resignation meant also the loss of financial support from America. The rump Sinn F\u00e9in party could field no more than fifteen candidates, and won only five seats in the June 1927 general election, a decline in support not seen since before 1916. Vice-president and leader Mary MacSwiney announced that the party simply did not have the funds to contest the second election called that year, declaring \"no true Irish citizen can vote for any of the other parties\". Fianna F\u00e1il came to power at the 1932 general election (to begin what would be an unbroken 16-year spell in government) and went on to long dominate politics in the independent Irish state.\nAn attempt in the 1940s to access funds that had been put in the care of the High Court led to the Sinn F\u00e9in Funds case, which the party lost and in which the judge ruled that it was not the legal successor to the Sinn F\u00e9in of 1917.\nBy the late 1940s, two decades removed from the Fianna F\u00e1il split and now the Sinn F\u00e9in funds lost, the party was little more than a husk. The emergence of a popular new republican party, led by former IRA members, in Clann na Poblachta, threatened to void any remaining purpose Sinn F\u00e9in had left. However, it was around this same time that the IRA leadership once again sought to have a political arm (the IRA and Sinn F\u00e9in had effectively no formal ties following the civil war). Following an IRA army convention in 1948, IRA members were instructed to join Sinn F\u00e9in en masse and by 1950 they had successfully taken total control of the party, with IRA army council member Paddy McLogan named as the new president of the party. As part of this rapprochement, it was later made clear by the army council that the IRA would dictate to Sinn F\u00e9in, and not the other way around.\nAt the 1955 United Kingdom general election, two Sinn F\u00e9in candidates were elected to Westminster, and likewise, four members of Sinn F\u00e9in were elected to Leinster House in the 1957 Irish general election. In December 1956, at the beginning of the IRA's Border Campaign (Operation Harvest), the Northern Ireland Government banned Sinn F\u00e9in under the Special Powers Act; it would remain banned until 1974. By the end of the Border campaign five years later, the party had once again lost all national representation. Through the 1960s, some leading figures in the movement, such as Cathal Goulding, Se\u00e1n Garland, Billy McMillen and Tom\u00e1s Mac Giolla, moved steadily to the left, even to Marxism, as a result of their own reading and thinking and contacts with the Irish and international left. This angered more traditional republicans, who wanted to stick to the national question and armed struggle. The Garland Commission was set up in 1967, to investigate the possibility of ending abstentionism. Its report angered the already disaffected traditional republican element within the party, notably Se\u00e1n Mac St\u00edof\u00e1in and Ruair\u00ed \u00d3 Br\u00e1daigh, who viewed such a policy as treason against the Irish Republic.\n1970\u20131975.\nSinn F\u00e9in split in two at the beginning of 1970. On 11 January, the proposal to end abstentionism and take seats, if elected, in the D\u00e1il, the Parliament of Northern Ireland and the Parliament of the United Kingdom was put before the members at the party's \"Ard Fheis\". A similar motion had been adopted at an IRA convention the previous month, leading to the formation of a Provisional Army Council by Mac St\u00edof\u00e1in and other members opposed to the leadership. When the motion was put to the \"Ard Fheis\", it failed to achieve the necessary two-thirds majority. The Executive attempted to circumvent this by introducing a motion in support of IRA policy, at which point the dissenting delegates walked out of the meeting. These members reconvened at Kevin Barry Hall in Parnell Square, where they appointed a Caretaker Executive with Ruair\u00ed \u00d3 Br\u00e1daigh as chairman. The Caretaker Executive's first act was to pass a resolution pledging allegiance to the 32-county Irish Republic and the Provisional Army Council. It also declared itself opposed to the ending of abstentionism, the drift towards \"extreme forms of socialism\", the failure of the leadership to defend the nationalist people of Belfast during the 1969 Northern Ireland riots, and the expulsion of traditional republicans by the leadership during the 1960s.\nAt its October 1970 \"Ard Fheis\", delegates were informed that an IRA convention had been held and had regularised its structure, bringing to an end the \"provisional\" period. By then, however, the label \"Provisional\" or \"Provo\" was already being applied to them by the media. The opposing, anti-abstentionist party became known as \"Official Sinn F\u00e9in\". It changed its name in 1977 to \"Sinn F\u00e9in\u2014The Workers' Party\", and in 1982 to \"The Workers' Party\".\nBecause the \"Provisionals\" were committed to military rather than political action, Sinn F\u00e9in's initial membership was largely confined, in Danny Morrison's words, to men \"over military age or women\". A Sinn F\u00e9in organiser of the time in Belfast described the party's role as \"agitation and publicity\". New \"cumainn\" (branches) were established in Belfast, and a new newspaper, \"Republican News\", was published. Sinn F\u00e9in took off as a protest movement after the introduction of internment in August 1971, organising marches and pickets. The party launched its platform, \"\u00c9ire Nua\" (\"a New Ireland\") at the 1971 \"Ard Fheis\". In general, however, the party lacked a distinct political philosophy. In the words of Brian Feeney, \"\u00d3 Br\u00e1daigh would use Sinn F\u00e9in \"ard fheiseanna\" (party conferences) to announce republican policy, which was, in effect, IRA policy, namely that Britain should leave the North or the 'war' would continue\".\nIn May 1974, a few months after the Sunningdale Agreement, the ban on Sinn F\u00e9in was lifted by the UK Secretary of State for Northern Ireland. Sinn F\u00e9in was given a concrete presence in the community when the IRA declared a ceasefire in 1975. 'Incident centres', manned by Sinn F\u00e9in members, were set up to communicate potential confrontations to the British authorities.\nFrom 1976, there was a broadcasting ban on Sinn F\u00e9in representatives in the Republic of Ireland, after the Minister for Posts and Telegraphs, Conor Cruise O'Brien, amended Section 31 of the Broadcasting Act. This prevented RT\u00c9 interviewing Sinn F\u00e9in spokespersons under any circumstances, even where the subject was not related to the Northern Ireland conflict. This lasted until 1994.\n1976\u20131983.\nPolitical status for prisoners became an issue after the ending of the truce. Rees released the last of the internees, and ended 'Special Category Status' for all prisoners convicted after 1 March 1976. This led first to the blanket protest, and then to the dirty protest. Around the same time, Gerry Adams began writing for \"Republican News\", calling for Sinn F\u00e9in to become more involved politically. Over the next few years, Adams and those aligned with him would extend their influence throughout the republican movement and slowly marginalise \u00d3 Br\u00e1daigh, part of a general trend of power in both Sinn F\u00e9in and the IRA shifting north. In particular, \u00d3 Br\u00e1daigh's part in the 1975 IRA ceasefire had damaged his reputation in the eyes of northern republicans.\nThe prisoners' protest climaxed with the 1981 hunger strike, during which striker Bobby Sands was elected Member of Parliament for Fermanagh and South Tyrone as an Anti H-Block candidate. After his death on hunger strike, his seat was held, with an increased vote, by his election agent, Owen Carron. Two other Anti H-Block candidates were elected to D\u00e1il \u00c9ireann in the general election in the Republic. These successes convinced republicans that they should contest every election. Danny Morrison expressed the mood at the 1981 \"Ard Fheis\" when he said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThis was the origin of what became known as the Armalite and ballot box strategy. \u00d3 Br\u00e1daigh's chief policy, a plan for a federalised Irish state dubbed \"\u00c9ire Nua\", was dropped in 1982, and the following year \u00d3 Br\u00e1daigh stepped down as president, and was replaced by Adams.\n1983\u20131998.\nUnder Adams' leadership electoral politics became increasingly important. In 1983 Alex Maskey was elected to Belfast City Council, the first Sinn F\u00e9in member to sit on that body. Sinn F\u00e9in polled over 100,000 votes in the Westminster elections that year, and Adams won the West Belfast seat that had been held by the Social Democratic and Labour Party (SDLP). By 1985 it had 59 seats on seventeen of the 26 Northern Ireland councils, including seven on Belfast City Council.\nThe party began a reappraisal of the policy of abstention from the D\u00e1il. At the 1983 \"Ard Fheis\" the constitution was amended to remove the ban on the discussion of abstentionism to allow Sinn F\u00e9in to run a candidate in the forthcoming European elections. However, in his address, Adams said, \"We are an abstentionist party. It is not my intention to advocate change in this situation.\" A motion to permit entry into the D\u00e1il was allowed at the 1985 \"Ard Fheis\", but did not have the active support of the leadership, and it failed narrowly. By October of the following year an IRA Convention had indicated its support for elected Sinn F\u00e9in TDs taking their seats. Thus, when the motion to end abstention was put to the \"Ard Fheis\" on 1 November 1986, it was clear that there would not be a split in the IRA as there had been in 1970. The motion was passed with a two-thirds majority. \u00d3 Br\u00e1daigh and about twenty other delegates walked out, and met in a Dublin hotel with hundreds of supporters to re-organise as Republican Sinn F\u00e9in.\nIn October 1988, the British Conservative government followed the Republic in banning broadcasts of Sinn F\u00e9in representatives. Prime Minister Margaret Thatcher said it would \"deny terrorists the oxygen of publicity\". Broadcasters quickly found ways around the ban, mainly by using actors to dub the voices of banned speakers. The legislation did not apply during election campaigns and under certain other circumstances. The ban lasted until 1994.\nTentative negotiations between Sinn F\u00e9in and the British government led to more substantive discussions with the SDLP in the 1990s. Multi-party negotiations began in 1994 in Northern Ireland, without Sinn F\u00e9in. The Provisional IRA declared a ceasefire in August 1994. Sinn F\u00e9in then joined the talks, but the Conservative government under John Major soon came to depend on unionist votes to remain in power. It suspended Sinn F\u00e9in from the talks, and began to insist that the IRA decommission all of their weapons before Sinn F\u00e9in be re-admitted to the talks; this led to the IRA calling off its ceasefire. The new Labour government of Tony Blair was not reliant on unionist votes and re-admitted Sinn F\u00e9in, leading to another, permanent, ceasefire.\nThe talks led to the Good Friday Agreement of 10 April 1998, which set up an inclusive devolved government in Northern Ireland, and altered the Dublin government's constitutional claim to the whole island in Articles 2 and 3 of the Constitution of Ireland. Republicans opposed to the direction taken by Sinn F\u00e9in in the peace process formed the 32 County Sovereignty Movement in the late 1990s.\n1998\u20132017.\nAt the 1997 Irish general election, Caoimhgh\u00edn \u00d3 Caol\u00e1in was elected to the D\u00e1il. In doing so, he became the first person under the \"Sinn F\u00e9in\" banner to be elected to Leinster House since 1957, and the first since 1922 to take their seat. \u00d3 Caol\u00e1in's entry to the D\u00e1il marked the beginning of a continuous Sinn F\u00e9in presence in the Republic of Ireland's national political bodies.\nThe party expelled Denis Donaldson, a party official, in December 2005, with him stating publicly that he had been in the employ of the British government as an agent since the 1980s. Donaldson told reporters that the British security agencies who employed him were behind the collapse of the Assembly and set up Sinn F\u00e9in to take the blame for it, a claim disputed by the British government. Donaldson was found fatally shot in his home in County Donegal on 4 April 2006, and a murder inquiry was launched. In April 2009, the Real IRA released a statement taking responsibility for the killing.\nWhen Sinn F\u00e9in and the Democratic Unionist Party (DUP) became the largest parties, by the terms of the Good Friday Agreement no deal could be made without the support of both parties. They nearly reached a deal in November 2004, but the DUP insisted on photographic or video evidence that decommissioning of IRA weapons had been carried out, which was unacceptable to Sinn F\u00e9in.\nIn April 2006, a number of members of Sinn F\u00e9in who believed the party was not committed enough to socialism split from the party and formed a new group called \u00c9ir\u00edg\u00ed, which later became a (minor) political party in its own right.\nOn 2 September 2006, Martin McGuinness publicly stated that Sinn F\u00e9in would refuse to participate in a shadow assembly at Stormont, asserting that his party would only take part in negotiations that were aimed at restoring a power-sharing government. This development followed a decision on the part of members of Sinn F\u00e9in to refrain from participating in debates since the Assembly's recall the previous May. The relevant parties to these talks were given a deadline of 24 November 2006 to decide upon whether or not they would ultimately form the executive.\nThe 86-year Sinn F\u00e9in boycott of policing in Northern Ireland ended on 28 January 2007, when the \"Ard Fheis\" voted overwhelmingly to support the Police Service of Northern Ireland (PSNI). Sinn F\u00e9in members began to sit on Policing Boards and join District Policing Partnerships. There was opposition to this decision within Sinn F\u00e9in, and some members left, including elected representatives. The most well-known opponent was former IRA prisoner Gerry McGeough, who stood in the 2007 Assembly election against Sinn F\u00e9in in the constituency of Fermanagh and South Tyrone, as an Independent Republican. He polled 1.8% of the vote. Others who opposed this development left to found the Republican Network for Unity.\nSinn F\u00e9in supported a no vote in the referendum on the Twenty-eighth Amendment of the Constitution Bill 2008.\nImmediately after the June 2017 UK general election, where the Conservatives won 49% of seats but not an overall majority, so that non-mainstream parties could have significant influence, Gerry Adams announced for Sinn F\u00e9in that their elected MPs would continue the policy of not swearing allegiance to the Queen, as would be required for them to take their seats in the Westminster Parliament.\nIn 2017 and 2018, there were allegations of bullying within the party, leading to a number of resignations and expulsions of elected members.\nAt the \"Ard Fheis\" on 18 November 2017, Gerry Adams announced he would stand down as president of Sinn F\u00e9in in 2018, and would not stand for re-election as TD for Louth.\n2018\u2013present.\nOn 10 February 2018, Mary Lou McDonald was announced as the new president of Sinn F\u00e9in at a special Ard Fheis in Dublin. Michelle O'Neill was also elected as vice president of the party.\nSinn F\u00e9in were opposed to Northern Ireland leaving the European Union together with the rest of the United Kingdom, with Martin McGuinness suggesting a referendum on the reunification of Ireland immediately after the 2016 United Kingdom European Union membership referendum results were announced, a stance later reiterated by McDonald as a way of resolving the border issues raised by Brexit.\nSinn F\u00e9in's first elections under McDonald resulted in the party performing well under its own expectations during the 2018 Irish presidential election that October, and similarly, the party's performance was labelled \"disastrous\" during the concurrent May 2019 European Parliament election in Ireland and 2019 Irish local elections. In the European elections, Sinn F\u00e9in lost 2 MEPs and dropped their vote share by 7.8%, while in the local elections the party lost 78 (almost half) of their local councillors and dropped their vote share by 5.7%. McDonald stated \"It was a really bad day out for us. But sometimes that happens in politics, and it's a test for you. I mean it's a test for me personally, obviously, as the leader\".\nHowever, in the 2020 Irish general election, Sinn F\u00e9in received the greatest number of first preference votes nationally, making it the best result for any incarnation of Sinn F\u00e9in since the 1922 election. Fianna F\u00e1il, Fine Gael and the Green Party formed a coalition government in June 2020. Although second on seats won at the election, Sinn F\u00e9in became the largest party in the D\u00e1il when Marc MacSharry resigned from Fianna F\u00e1il in September 2021, which, with Se\u00e1n \u00d3 Feargha\u00edl sitting as Ceann Comhairle, left Sinn F\u00e9in the largest party by one seat. Sinn F\u00e9in lost their numerical advantage in February 2022 following the resignation of Violet-Anne Wynne.\nIn November 2020, the national chairman of Sinn F\u00e9in Declan Kearney contacted several dissident republican political parties such as Saoradh, Republican Network for Unity and the Irish Republican Socialist Party about creating a united republican campaign to call for a referendum on Irish unification. This information did not become publicly known until 2022 and the move was criticised in some quarters on the basis that it would be wrong for Sinn F\u00e9in to work with dissident republican groups which do not repudiate violence by paramilitaries. Sinn F\u00e9in retorted that engaging with dissident republicans draws them into the democratic process and political solutions instead of violent ones.\nSinn F\u00e9in won 29% of the first-preference votes in the 2022 Northern Ireland Assembly election, the highest share of any party. With 27 out of 90 seats, they became the largest party in Stormont for the first time ever. \"Today ushers in a new era\", O'Neill said shortly before the final results were announced. \"Irrespective of religious, political or social backgrounds, my commitment is to make politics work.\"\nFollowing the 2023 Northern Ireland local elections, Sinn F\u00e9in became the largest party in local government for the first time. Then, in the local elections in the Republic of Ireland in 2024, Sinn F\u00e9in increased their vote share, however, significantly fell short of the polls, showcasing a divide between the party's leadership and grassroots over immigration, with disgruntled Sinn F\u00e9in voters voting instead for small right-wing parties. However, following the 2024 United Kingdom general election, Sinn F\u00e9in became the single largest party representing Northern Ireland in Westminster.\nPast links with Republican paramilitaries.\nSinn F\u00e9in is the largest Irish republican political party, and was historically associated with the Irish Republican Army, while also having been associated with the Provisional Irish Republican Army in the party's modern incarnation. The Irish government alleged that senior members of Sinn F\u00e9in have held posts on the IRA Army Council. However, the SF leadership has denied these claims.\nA republican document of the early 1980s stated: \"Both Sinn F\u00e9in and the IRA play different but converging roles in the war of national liberation. The Irish Republican Army wages an armed campaign... Sinn F\u00e9in maintains the propaganda war and is the public and political voice of the movement\". Robert White states at that time Sinn F\u00e9in was the junior partner in the relationship with the IRA, and they were separate organisations despite there being some overlapping membership.\nBecause of the party's links to the Provisional IRA, the U.S. Department of State barred its members along with IRA volunteers from entering the U.S. since the early 1970s in accordance with the Immigration and Nationality Act on the grounds that they were associated with the IRA waging war against a legitimate government.\nThe British government stated in 2005 that \"we had always said all the way through we believed that Sinn F\u00e9in and the IRA were inextricably linked and that had obvious implications at leadership level\".\nThe Northern Bank robbery of \u00a326.5\u00a0million in Belfast in December 2004 further delayed a political deal in Northern Ireland. The IRA were widely blamed for the robbery, although Sinn F\u00e9in denied this and stated that party officials had not known of the robbery nor sanctioned it. Because of the timing of the robbery, it is considered that the plans for the robbery must have been laid whilst Sinn F\u00e9in was engaged in talks about a possible peace settlement. This undermined confidence among unionists about the sincerity of republicans towards reaching agreement. In the aftermath of the row over the robbery, a further controversy erupted when, on RT\u00c9's \"Questions and Answers\" programme, the chairman of Sinn F\u00e9in, Mitchel McLaughlin, insisted that the IRA's controversial killing of a mother of ten young children, Jean McConville, in the early 1970s though \"wrong\", was not a crime, as it had taken place in the context of the political conflict. Politicians from the Republic, along with the Irish media, strongly attacked McLaughlin's comments.\nOn 10 February 2005, the government-appointed Independent Monitoring Commission reported that it firmly supported the PSNI and Garda S\u00edoch\u00e1na assessments that the IRA was responsible for the Northern Bank robbery and that certain senior members of Sinn F\u00e9in were also senior members of the IRA and would have had knowledge of and given approval to the carrying out of the robbery. Sinn F\u00e9in has argued that the IMC is not independent, and that the inclusion of former Alliance Party leader John Alderdice and a British security head was proof of this. The IMC recommended further financial sanctions against Sinn F\u00e9in members of the Northern Ireland Assembly. The British government responded by saying it would ask MPs to vote to withdraw the parliamentary allowances of the four Sinn F\u00e9in MPs elected in 2001.\nGerry Adams responded to the IMC report by challenging the Irish government to have him arrested for IRA membership\u2014a crime in both jurisdictions\u2014and for conspiracy.\nOn 20 February 2005, the Irish Minister for Justice, Equality and Law Reform Michael McDowell publicly accused three of the Sinn F\u00e9in leadership, Gerry Adams, Martin McGuinness and Martin Ferris (TD for Kerry North) of being on the seven-man IRA Army Council; they later denied this.\nOn 27 February 2005, a demonstration against the murder of Robert McCartney on 30 January 2005 was held in east Belfast. Alex Maskey, a former Sinn F\u00e9in Lord Mayor of Belfast, was told by relatives of McCartney to \"hand over the 12\" IRA members involved. The McCartney family, although formerly Sinn F\u00e9in voters themselves, urged witnesses to the crime to contact the PSNI. Three IRA men were expelled from the organisation, and a man was charged with McCartney's murder.\nIrish Taoiseach Bertie Ahern subsequently called Sinn F\u00e9in and the IRA \"both sides of the same coin\". In February 2005 D\u00e1il \u00c9ireann passed a motion condemning the party's alleged involvement in illegal activity. The Bush Administration did not invite Sinn F\u00e9in or any other Northern Irish political party to the annual St Patrick's Day celebrations at the White House, choosing instead to invite the family of Robert McCartney. Senator Ted Kennedy, a regular sponsor of Gerry Adams' visits to the US during the peace process, also refused to meet Adams and hosted the McCartney family instead.\nOn 10 March 2005, the House of Commons in London passed without significant opposition a motion, introduced by the British government, to withdraw the allowances of the four Sinn F\u00e9in MPs for one year, in response to the Northern Bank Robbery. This measure cost the party approximately \u00a3400,000. However, the debate prior to the vote mainly surrounded the more recent events connected with the murder of Robert McCartney. Conservatives and unionists put down amendments to have the Sinn F\u00e9in MPs evicted from their offices at the House of Commons but these were defeated.\nIn March 2005, Mitchell Reiss, the United States Special Envoy for Northern Ireland, condemned the party's links to the IRA, saying \"it is hard to understand how a European country in the year 2005 can have a private army associated with a political party\".\nThe October 2015 Assessment on Paramilitary Groups in Northern Ireland concluded that the Provisional IRA still existed \"in a much reduced form\", and that some IRA members believed its Army Council oversaw both the IRA and Sinn F\u00e9in, although it believed that the leadership \"remains committed to the peace process and its aim of achieving a united Ireland by political means\".\nOrganisation and structure.\nSinn F\u00e9in operates under the principle of democratic centralism; the concept that policy should be debated internally within the party, and once a decision is made, all members must support the chosen policy publicly or be disciplined. Once a decision has been made, it cannot be revisited or altered for a prolonged period of time.\nDecision-making within Sinn F\u00e9in is controlled by two bodies; the national officer board and the \u00c1rd Comhairle (national executive). The national officer board consists of 7 members, made up of the President of Sinn F\u00e9in, the Vice President, the chairperson, the General Secretary, the Director of Publicity and two treasurers. Policy will be debated amongst the national officer board before next being brought before the \u00c1rd Comhairle.\nSinn F\u00e9in's \u00c1rd Comhairle consists of 47 members. Members of the national officer board are automatically members, while the rest of the membership is made up of officers elected at Sinn F\u00e9in's annual national conference (Ard Fheis). Members of the \u00c1rd Comhairle must already be members of the Comhairl\u00ed Limist\u00e9ir (Area councils), which are based county or constituency boundaries. As of 2023[ [update]], despite the fact that the bulk majority of Sinn F\u00e9in's membership and elected representatives come from the Republic of Ireland, the majority of the \u00c1rd Comhairle is from Northern Ireland. For every 2 TDs on the \u00c1rd Comhairle, there are 3 MLAs. Some members of the \u00c1rd Comhairle hold no public office and are former members of the Provisional IRA.\nWhen a decision is made by the \u00c1rd Comhairle, all members of Sinn F\u00e9in must abide by it without dissent, including the President. In 2020, all of Sinn F\u00e9in's candidates in the 2020 Irish general election were required to sign a pledge stating \"in all matters pertaining to the duties and functions of an elected representative, I will be guided by and hold myself amenable to all directions and instructions issued to me by An Ard Chomhairle of Sinn F\u00e9in\".\nWithin the \u00c1rd Comhairle, there is a further subdivision, called the Coiste Seasta (Standing Committee), made up of 8 members, who act as a Central Committee. Unlike other Teachta\u00ed D\u00e1la from other parties, Sinn F\u00e9in TDs are not allowed to hire their own staff and instead the Coiste Seasta chooses staff for them. Some Sinn F\u00e9in TDs have complained of these staff members handing them scripts to read publicly which they had no input into writing.\nSome critics inside Sinn F\u00e9in have opined that decision-making in the party rests with the officer board and that the \u00c1rd Comhairle serves merely to rubberstamp decisions that have already been made. External critics have called Sinn F\u00e9in's organisation and structure \"opaque\", \"hierarchical\", \"confusing\" and \"undemocratic\". Former Sinn F\u00e9in TD Peadar T\u00f3ib\u00edn claimed in 2020 that Sinn F\u00e9in TDs have \"zero influence\" over party policy, and that all decisions ultimately rested with the national officer board. It was also in 2020 that both Fine Gael and Fianna F\u00e1il criticised Sinn F\u00e9in's organisation, with Patrick O'Donovan of Fine Gael stating \"the fact that Sinn F\u00e9in reps sign a pledge which says they will be guided by their Ard Chomhairle, a council of people not elected by the public, rather than those who elect them, is an outright affront to democracy\". In 2022 the left-wing political magazine \"Village\" opined that while all major political parties in Ireland are influenced by unelected individuals, Sinn F\u00e9in is disproportionally controlled by a \"backroom regime\", and alleged that the Coiste Seasta, made up of unelected Northerners and former IRA members, holds the power to influence the decisions of TDs.\nSinn F\u00e9in denies the allegations that its structure is undemocratic and has compared its organisation to other Irish political parties such as Fianna F\u00e1il. Sinn F\u00e9in maintains it is a bottom-up, not a top-down organisation and that, ultimately, decision-making comes from its annual Ard Fh\u00e9is and the votes of ordinary members. In 2020 Mary Lou McDonald dismissed suggestions that Sinn F\u00e9in, including herself, were controlled by \"shadowy figures\" as an idea rooted in sexism. In 2020 she stated \"I have a strong sense that there is at least an undertone of sexism and misogyny in suggesting that our strings are pulled. I'm very stubborn. I'm very willful. I know my own mind and God help anybody who tries to pull my strings or tell me what to do\". while in 2021 she stated that people needed to get over the \"sexist\" idea that \"this woman couldn't possibly be really the leader of Sinn F\u00e9in. Well guess what? I really am, boys\".\nIdeology and policies.\nSinn F\u00e9in is an Irish republican, democratic socialist and left-wing party. In the European Parliament, the party aligns itself with The Left in the European Parliament - GUE/NGL parliamentary group. Categorised as \"populist socialist\" in literature, in 2014 leading party strategist and ideologue Eoin \u00d3 Broin described Sinn F\u00e9in's entire political project as unashamedly populist. The party has been classed as left-wing nationalist and left-wing populist in academia, noting that while Sinn F\u00e9in engages in the \"us vs them\" dynamic of populism, it does so by engaging in the language of \"the people vs elites\" without resorting to using anti-immigrant rhetoric.\nSocial and cultural.\nSinn F\u00e9in's main political goal is a united Ireland. Other key policies from their most recent election manifesto are listed below:\nSinn F\u00e9in believes in immigration, both to fill up vacancies in employment, if the system can properly integrate new immigrants and has the resources to do so, and also to \"protect people fleeing persecution and war\", but not in \"open borders\". The party also believes in faster application processing times for refugees, and in abolishing the direct provision system.\nEconomy.\nAt the 2020 election in the Republic of Ireland, Sinn F\u00e9in committed to:\nAs of January 2022, Sinn F\u00e9in in Northern Ireland have committed to:\nHealth.\nAt the 2020 election in the Republic of Ireland, Sinn F\u00e9in committed to:\nAbortion.\nUntil at least 2007, the party was not in favour of the extension of legalised abortion (British 1967 Act) to Northern Ireland; Assembly member John O'Dowd said that they were \"opposed to the attitudes and forces in society, which pressurise women to have abortions, and criminalise those who make this decision\", adding that \"in cases of rape, incest or sexual abuse, or where a woman's life and health is at risk or in grave danger, we accept that the final decision must rest with the woman.\" It voted for the Protection of Life During Pregnancy Act 2013, which allowed for termination in cases where a pregnancy endangered a woman's life. It voted to support termination, in those limited circumstances, at the 2015 , but stopped short of supporting abortion on demand. In the 2018 Irish abortion referendum, the party campaigned for a \"Yes\" vote, while remaining opposed to abortion without restriction up to 12 weeks. At its in June 2018, the month after the \"yes\" vote in the abortion referendum, the party committed itself to supporting abortion, including without restriction up to 12 weeks. This allowed it not only to support abortion legislation in the Republic, but also to campaign for provision of abortion in Northern Ireland. Sinn F\u00e9in TD Peadar T\u00f3ib\u00edn, who was suspended from the party for voting against abortion legislation, left to form a new party: Aont\u00fa.\nSinn F\u00e9in have been accused of hypocrisy over their positions on abortion in Northern Ireland. In 2021, Sinn F\u00e9in abstained on a Stormont vote on restricting abortion access in the case of fetal abnormalities or disabilities, attracting criticism from both anti-abortion and pro-choice groups, with the Abortion Rights Campaign saying they \"let down abortion seekers\" and Eamonn McCann accusing them of being \"impaled on the fence on the issue\", but with anti-abortion politicians such as Peadar T\u00f3ib\u00edn accusing them of \"speaking out of both sides of their mouth\" on the issue. Later in the year, Amnesty International made a public statement calling on the party to \"support full abortion rights across the island of Ireland\".\nTransgender health care.\nHistorically the party has supported access to gender affirming healthcare for transgender individuals. However, in 2024 after the UK's Conservative Party enacted a ban on puberty blockers following the Cass Review, Sinn F\u00e9in allowed the ban to be extended to Northern Ireland, closing what some considered a \"loophole\" regarding access to such treatments in the UK.\nInternational relations.\nSinn F\u00e9in has longstanding fraternal ties with the African National Congress and was described by Nelson Mandela as an \"old friend and ally in the anti-apartheid struggle\". Sinn F\u00e9in supports the independence of Catalonia from Spain, Palestine in the Israeli\u2013Palestinian conflict, and the right to self-determination regarding independence of the Basque Country from Spain and France. Sinn F\u00e9in opposes the United States embargo against Cuba and has called for a normalisation of relations between the two countries. In 2016, the Sinn F\u00e9in party president, Gerry Adams was invited by the Cuban government to attend the state funeral of Fidel Castro whom Adams described as a \"freedom fighter\" and a \"friend of Ireland's struggle\". Sinn F\u00e9in is opposed to NATO membership.\nEuropean Union.\nHistorically, Sinn F\u00e9in has been considered to be Eurosceptic. The party campaigned for a \"No\" vote in the Irish referendum on joining the European Economic Community in 1972. Sinn F\u00e9in was on the same side of the debate as the DUP and most of the Ulster Unionist Party (UUP) in that they wanted to pull out when UK had its referendum in 1975. The party was critical of the supposed need for an EU constitution as proposed in 2002, and urged a \"No\" vote in the 2008 referendum on the Lisbon Treaty, although Mary Lou McDonald said that there was \"no contradiction in being pro-Europe, but anti-treaty\". In its manifesto for the 2015 UK general election, Sinn F\u00e9in pledged that the party would campaign for the UK to stay within the European Union (EU), with Martin McGuinness saying that an exit \"would be absolutely economically disastrous\". Gerry Adams said that, if there were to be a referendum on the question, there ought to be a separate and binding referendum for Northern Ireland. Its policy of a \"Europe of Equals\", and its critical engagement after 2001, together with its engagement with the European Parliament, marks a change from the party's previous opposition to the EU. The party expresses, on one hand, \"support for Europe-wide measures that promote and enhance human rights, equality and the all-Ireland agenda\", and on the other a \"principled opposition\" to a European superstate. This has led political commentators to define the party as soft Eurosceptic since the 21st century.\nSince moving to this \"soft Euroscepticism\" position, Sinn F\u00e9in support a policy of \"critical engagement with the EU\", and have a \"principled opposition\" to a European superstate. It opposes an EU constitution because it would reduce the sovereignty of the member states. It also critiques the EU on grounds of neoliberalism. Sinn F\u00e9in MEP Matt Carthy says \"the European Union must become a cooperative union of nation states committed to working together on issues such as climate change, migration, trade, and using our common strengths to improve the lives of citizens. If it does not, EU disintegration becomes a real possibility\". The party supported continued UK membership of the European Union in the UK's 2016 EU referendum and in April 2022, Mary Lou McDonald said in the D\u00e1il that \"We strongly support the Ukrainian people's stated desire to join the European Union\".\nMinisters and spokespeople.\nRepublic of Ireland.\nP\u00e1draig Mac Lochlainn serves as the party's Chief Whip in the D\u00e1il.\nElection results.\nNorthern Ireland.\nTrends.\nSinn F\u00e9in returned to Northern Ireland elections at the 1982 Assembly elections, winning five seats with 64,191 votes (10.1%). The party narrowly missed winning additional seats in Belfast North and Fermanagh and South Tyrone. In the 1983 UK general election eight months later, Sinn F\u00e9in increased its support, breaking the six-figure vote barrier in Northern Ireland for the first time by polling 102,701 votes (13.4%). Gerry Adams won the Belfast West constituency, and Danny Morrison fell only 78 votes short of victory in Mid Ulster.\nThe 1984 European elections proved to be a disappointment, with Sinn F\u00e9in's candidate Danny Morrison polling 91,476 (13.3%) and falling well behind the SDLP candidate John Hume.\nBy the beginning of 1985, Sinn F\u00e9in had won its first representation on local councils, owing to three by-election wins in Omagh (Seamus Kerr, May 1983) and Belfast (Alex Maskey in June 1983 and Sean McKnight in March 1984). Three sitting councillors also defected to Sinn F\u00e9in in Dungannon, Fermanagh and Derry (the last defecting from the SDLP). Sinn F\u00e9in succeeded in winning 59 seats in the 1985 local government elections, after it had predicted winning only 40 seats. However, the results continued to show a decline from the peak of 1983, as the party won 75,686 votes (11.8%). The party failed to gain any seats in the 1986 by-elections caused by the resignation of unionist MPs in protest at the Anglo-Irish Agreement. While this was partly due to an electoral pact between unionist candidates, the SF vote fell in the four constituencies they contested.\nIn the 1987 general election, Gerry Adams held his Belfast West seat, but the party failed to make breakthroughs elsewhere and overall polled 83,389 votes (11.4%). The same year saw the party contest the D\u00e1il election in the Republic of Ireland; however, it failed to win any seats and polled less than 2%.\nThe 1989 local government elections saw a drop in support for Sinn F\u00e9in. Defending 58 seats (the 59 won in 1985, plus two 1987 by-election gains in West Belfast, minus three councillors who had defected to Republican Sinn F\u00e9in in 1986), the party lost 15 seats. In the aftermath of the election, Mitchell McLaughlin admitted that recent IRA activity had affected the Sinn F\u00e9in vote.\nIn the 1989 European election, Danny Morrison again failed to win a seat, polling at 48,914 votes (9%).\nThe nadir for SF in this period came in 1992, with Gerry Adams losing his Belfast West seat to the SDLP, and the SF vote falling in the other constituencies that they had contested relative to 1987.\nIn the 1997 UK general election, Adams regained Belfast West. Martin McGuinness also won a seat in Mid Ulster. In the Irish general election the same year the party won its first seat since 1957, with Caoimhgh\u00edn \u00d3 Caol\u00e1in gaining a seat in the Cavan\u2013Monaghan constituency. In the Irish local elections of 1999 the party increased its number of councillors from 7 to 23.\nThe party overtook its nationalist rival, the Social Democratic and Labour Party, as the largest nationalist party in the local elections and UK general election of 2001, winning four Westminster seats to the SDLP's three. The party continues to subscribe, however, to an abstentionist policy towards the Westminster British parliament, on account of opposing that parliament's jurisdiction in Northern Ireland, as well as its oath to the King.\nSinn F\u00e9in increased its share of the nationalist vote in the 2003, 2007, and 2011 Assembly elections, with Martin McGuinness, former Minister for Education, taking the post of Deputy First Minister in the Northern Ireland power-sharing Executive Committee. The party has three ministers in the Executive.\nIn the 2010 general election, the party retained its five seats, and for the first time topped the poll at a Westminster election in Northern Ireland, winning 25.5% of the vote. All Sinn F\u00e9in MPs increased their share of the vote and with the exception of Fermanagh and South Tyrone, increased their majorities. In Fermanagh and South Tyrone, Unionist parties agreed a joint candidate, this resulted in the closest contest of the election, with Sinn F\u00e9in MP Michelle Gildernew holding her seat by 4 votes after 3 recounts and an election petition challenging the result.\nSinn F\u00e9in lost some ground in the 2016 Assembly election, dropping one seat to finish with 28, ten behind the DUP. In the snap election eight months later caused by the resignation of McGuinness as Deputy First Minister, however, the party surged, winning 27.9% of the popular vote to 28.1% for the DUP, and 27 seats to the DUP's 28 in an Assembly reduced by 18 seats. The withdrawal of the DUP party whip from Jim Wells in May 2018 meant that Sinn F\u00e9in became the joint-largest party in the Assembly alongside the DUP, with 27 seats each.\nRepublic of Ireland.\nD\u00e1il \u00c9ireann elections.\nThe party had five TDs elected in the 2002 Irish general election, an increase of four from the previous election. At the general election in 2007 the party had expectations of substantial gains, with poll predictions that they would gain five to ten seats. However, the party lost one of its seats to Fine Gael. Se\u00e1n Crowe, who had topped the poll in Dublin South-West fell to fifth place, with his first preference vote reduced from 20.28% to 12.16%.\nOn 26 November 2010, Pearse Doherty won a seat in the Donegal South-West by-election. It was the party's first by-election victory in the Republic of Ireland since 1925. After negotiations with the left-wing Independent TDs Finian McGrath and Maureen O'Sullivan, a Technical Group was formed in the D\u00e1il to give its members more speaking time.\nIn the 2011 Irish general election the party made significant gains. All its sitting TDs were returned, with Se\u00e1n Crowe regaining the seat he had lost in 2007 in Dublin South-West. In addition to winning long-targeted seats such as Dublin Central and Dublin North-West, the party gained unexpected seats in Cork East and Sligo\u2013North Leitrim. It ultimately won 14 seats, the best performance at the time for the party's current incarnation. The party went on to win three seats in the Seanad election which followed their success at the general election. In the 2016 election it made further gains, finishing with 23 seats and overtaking the Labour Party as the third-largest party in the D\u00e1il It ran seven candidates in the Seanad election, all of whom were successful.\nThe party achieved their greatest contemporary result in the 2020 Irish general election, topping the first-preference votes with 24.5% and winning 37 seats. Due to poor results in the 2019 local elections and elections to the European Parliament, the party ran only 42 candidates and did not compete in Cork North-West. The party achieved unexpected success in the early counting, with 27 candidates being elected on the first count. Party leader Mary Lou McDonald called the result a \"revolution\" and announced she would pursue the formation of a government including Sinn F\u00e9in. Ultimately negotiations to form a new government led to Fianna F\u00e1il, Fine Gael and the Green Party agreeing to enter a majority coalition government in June. Sinn F\u00e9in pledged to be a strong opposition to the new coalition.\nLocal government elections.\nSinn F\u00e9in is represented on most county and city councils. It made large gains in the local elections of 2004, increasing its number of councillors from 21 to 54, and replacing the Progressive Democrats as the fourth-largest party in local government. At the local elections of June 2009, the party's vote fell by 0.95% to 7.34%, with no change in the number of seats. Losses in Dublin and urban areas were balanced by gains in areas such as Limerick, Wicklow, Cork, Tipperary and Kilkenny and the border counties . However, three of Sinn F\u00e9in's seven representatives on Dublin City Council resigned within six months of the June 2009 elections, one of them defecting to the Labour Party.\nEuropean Parliament elections.\nIn the 2004 European Parliament election, Bairbre de Br\u00fan won Sinn F\u00e9in's first seat in the European Parliament, at the expense of the SDLP. She came in second behind Jim Allister of the DUP. In the 2009 election, de Br\u00fan was re-elected with 126,184 first preference votes, the only candidate to reach the quota on the first count. This was the first time since elections began in 1979 that the DUP failed to take the first seat, and was the first occasion Sinn F\u00e9in topped a poll in any Northern Ireland election.\nSinn F\u00e9in made a breakthrough in the Dublin constituency in 2004. The party's candidate, Mary Lou McDonald, was elected on the sixth count as one of four MEPs for Dublin. In the 2009 election, when Dublin's representation was reduced to three MEPs, she failed to hold her seat. In the South constituency their candidate, Councillor Toir\u00e9asa Ferris, managed to nearly double the number of first preference votes, lying third after the first count, but failed to get enough transfers to win a seat. In the 2014 election, Martina Anderson topped the poll in Northern Ireland, as did Lynn Boylan in Dublin. Liadh N\u00ed Riada was elected in the South constituency, and Matt Carthy in Midlands\u2013North-West. In the 2019 election, Carthy was re-elected, but Boylan and N\u00ed Riada lost their seats. Anderson also held her Northern Ireland seat until early 2020 when her term was cut short by Brexit.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral and cited sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "28176", "revid": "41625025", "url": "https://en.wikipedia.org/wiki?curid=28176", "title": "Willis Tower", "text": "Skyscraper in Chicago, Illinois\nThe Willis Tower, formerly and still commonly referred to as the Sears Tower, is a 110-story, skyscraper in the Loop community area of Chicago in Illinois, United States. Designed by architect Bruce Graham and engineer Fazlur Rahman Khan of Skidmore, Owings &amp; Merrill (SOM), it opened in 1973 as the world's tallest building, a title that it held for nearly 25 years. It is the third-tallest building in the Western Hemisphere, as well as the 23rd-tallest in the world. Each year, more than 1.7 million people visit the Skydeck, the highest observation deck in the United States, making it one of Chicago's most popular tourist destinations. Due to its height and location, the tower is visible from a great distance. The building has appeared in numerous films and television shows set in Chicago.\nThe building occupies a site bound by Franklin Street, Jackson Boulevard, Wacker Drive, and Adams Street. Graham and Khan designed the building as nine square \"tubes\", clustered in a 3\u00d73 matrix; seven of the tubes set back at upper floors. The tower has 108 stories as counted by standard methods, though the building's owners count the main roof as 109 and the mechanical penthouse roof as 110. The facade is made of anodized aluminum and black glass. The base of the building contains a retail complex known as the Catalog. The lower half of the tower was originally occupied by retail company Sears, which had its headquarters there until 1994, while the upper stories were rented out.\nThe structure was known as the Sears Tower from its construction until the naming rights were included in a 2009 lease with the Willis Group. Local area residents still refer to the building by its old name. As of \u00a02018[ [update]], the building's largest tenant is United Airlines, which occupies around 20 floors. Other major tenants include the building's namesake Willis Towers Watson, and law firms ArentFox Schiff and Seyfarth Shaw. Morgan Stanley became the building's fourth-largest tenant in 2017.\nHistory.\nPlanning.\nSite selection.\nSears, Roebuck &amp; Co. had occupied an office complex on Chicago's west side since 1906. The existing offices were inadequate by 1966, prompting Sears executives to begin searching for a new site. By 1969, Sears was the largest retailer in the world, with about 350,000 employees. Sears executives quickly determined that a new headquarters complex in the suburbs was infeasible, since it would require relocating about 7,000 employees. Instead, Sears executives decided to consolidate the thousands of employees in offices distributed throughout the Chicago area into one building on the western edge of Chicago's Loop.\nSears asked its outside counsel, Arnstein, Gluck, Weitzenfeld &amp; Minow (now known as Saul Ewing LLP) to suggest a location. The firm consulted with local and federal authorities and the applicable law, then offered Sears two options. The first option was the Goose Island area northwest of the Loop, but Sears's vice president of real estate, Matthew J. Stacom, rejected this proposal. The other was a two-block area in the Loop, bounded by Franklin Street on the east, Jackson Boulevard on the south, Wacker Drive on the west, and Adams Street on the north. Though the site was more centrally located, it was also relatively small, with about . Bernard Feinberg, Albert I. Rubenstein, and Philip Teinowitz had assembled that site over the previous five years, but they had failed to acquire a neighboring lot from bus company Greyhound Lines.\nFeinberg, Rubenstein, and Teinowitz then bought options for three adjacent lots. Under the terms of each option, unless the three men were able to acquire at least one of the lots within 90 days, all three options would be forfeited. Ultimately, Sears acquired the Loop site in 1970. Sears then obtained permits to close down one block of Quincy Street, which bisected the site from east to west. Attorneys from the Arnstein firm, headed by Andrew Adsit, began buying the properties parcel by parcel. Sears purchased 15 buildings from 100 owners and paid the government of Chicago $2.7 million (equivalent to $ in 2024) for the block of Quincy Street that was to be closed down.\nDesign process.\nSears executives estimated that their new building would need about , split into 70 stories with each or 60 stories with each. Sears commissioned architecture firm Skidmore, Owings &amp; Merrill (SOM) to design the tower. SOM was also the lead structural engineer, and Jaros, Baum &amp; Bolles provided MEP engineering.\nSears planned to move its merchandise group into the building initially, renting out the remaining space to other tenants until needed. Sears executives were accustomed to large floor areas of at least , but SOM architects raised concerns that the large floors would be unattractive to smaller tenants. A subsequent proposal called for two buildings connected by a footbridge, which would respectively contain and on each floor, but this was also infeasible.\nSome floors were designed with smaller footprints to attract prospective lessees, so the building's height was increased to meet Sears's floor-area requirements. Architect Bruce Graham and structural engineer Fazlur Rahman Khan, both of whom were partners with SOM, proposed a tower with floors in the lower part of the building, as well as a series of setbacks with gradually tapering floor plates, giving the tower its distinctive look. During the design process, one of the architects reportedly pulled out nine cigars and staggered them vertically until the pair both agreed to the arrangement. This allowed Sears to occupy the large lower stories, while providing more conventional office space that could be rented out on the upper stories. The firm of Saphier, Lerner, Schindler was responsible for determining Sears's space requirements and designing furniture for the company. It conducted a year-long study to determine how 16 of the company's departments should be laid out within the building.\nAs Sears continued to offer optimistic growth projections, the height of the proposed tower also increased. Under Chicago's relatively lax zoning laws, the site could theoretically accommodate a 300-story building with . In practice, most potential tenants did not want excessively high offices. Additionally, the Federal Aviation Administration (FAA) restricted the height of structures in the area to protect air traffic. FAA officials publicly denied that they had imposed a height limit; however, the area's minimum safe altitude would need to be raised by if the building was just taller. Plans for the tower were announced on July 27, 1970. The building would contain 109 stories as measured from Wacker Drive and 110 stories as measured from Franklin Street. This would make Sears's new tower the tallest in the world, as measured by roof height, although New York City's under-construction World Trade Center Twin Towers would have a taller antenna. Although the Sears Tower would contain of space, only about would be used as offices.\nConstruction.\nEarly construction.\nWork on the building's foundation commenced in August 1970. Contractors excavated the lot to a depth of , and they removed of dirt from the site. By that November, Spencer, White &amp; Prentis Inc. was excavating a trench around the site, measuring deep and across. The contractors then built a slurry wall within the trench, made of concrete and reinforced steel. Workers used steel bracing to prevent the slurry wall from collapsing inward, then used caissons to drill 201 holes into the ground. They also rerouted a sewer that had run underneath Quincy Street, which was to be closed permanently as part of the tower's construction.\nThe Diesel Construction Company was hired as the Sears Tower's general contractor. Sears, Roebuck &amp; Co. chairman Gordon M. Metcalf installed the building's first steel beam at a ceremony on June 7, 1971. The project employed 2,000 workers. To accelerate the building's construction, a concrete plant was built in the building's basement, allowing workers to pour one-third of a concrete floor every day. Contractors built two temporary kitchens on the site for workers, and telephone and loudspeaker systems were installed on every floor to allow workers to communicate. In addition, contractors installed temporary generators that could supply up to simultaneously; during the winter, most of this electricity was used to heat the exposed steel beams on the lowest five floors.\nBroadcast-signal controversy.\nBy late 1971, Chicagoland residents and broadcasters had raised concerns that the new Sears Tower would disrupt television broadcasts. According to one estimate, the building would obstruct television signals for 15 percent of Chicagoans and cause \"double images\" for another 20 percent, primarily affecting communities to the northwest and southeast. The same year, officials of the village of Skokie, northwest of Chicago, threatened to request an injunction to prevent further construction. In response to these concerns, Sears started researching methods to reduce the tower's effect on broadcast signals. \"Variety\" magazine stated that the Sears Tower did not interfere with broadcasts on its own, since several shorter towers in the Loop also interfered with broadcast signals. Nonetheless, the Illinois Citizens' Committee for Broadcasting filed a formal complaint with the Federal Communications Commission (FCC) in February 1972.\nThe first lawsuit against the building was filed by the state attorney in neighboring Lake County on March 17, 1972. A second suit was filed on March 28 in Cook County Circuit Court by the villages of Skokie, Northbrook, and Deerfield, Illinois. Sears filed motions to dismiss the Lake and Cook County lawsuits, which both sought to cap the building at 67 stories. Sears studied the possibility of erecting antennas atop its tower in April 1972, and the tower's construction continued, even as decisions on both lawsuits were delayed. At the end of the month, the company applied for permission to increase the building's height limit by and install a new antenna, although eight of Chicago's ten television stations criticized the plan. On May 17, 1972, Judge LaVerne Dickson, Chief of the Lake County Circuit Court, dismissed the suit, saying, \"I find nothing that gives television viewers the right to reception without interference.\" By then, the building had reached the 58th story. The Lake County attorney appealed to the Illinois Supreme Court. In his decision on June 12, Judge Charles R. Barrett contended the plaintiffs did not have a right to undistorted television reception.\nMeanwhile, the FCC declined to act on the height dispute on the grounds it did not have jurisdiction. The FAA approved the antennas atop the tower in June 1972, and the Illinois Supreme Court affirmed the previous rulings by Lake and Cook County circuit courts at the end of the month. Work was temporarily paused that July due to a labor strike. The next month, Sears formally announced plans for broadcast antennas on the tower's roof, and the company offered to spend $5 million (equivalent to $ in 2024) to help relocate broadcast stations to the Sears Tower. The United States Court of Appeals for the Seventh Circuit upheld the FCC's decision in September, and the United States Supreme Court refused to hear an appeal of the Seventh Circuit's decision that November.\nTopping-out and completion.\nIn November 1972, the Sears Tower became Chicago's tallest building, surpassing the Standard Oil Building, which had held the record for one month. At the time, the Sears project employed 1,600 workers in three shifts; one worker had been killed during the project so far. The building's final completion had been delayed significantly due to labor strikes and bad weather. The concrete work had reached the 77th floor, while the steel superstructure had reached the 84th floor; the remainder of the steelwork would be difficult to construct because of high winds at higher altitudes. Local television stations WTTW and WLS-TV were planning to install temporary broadcast antennas atop the tower when the steel frame was completed. The tower's superstructure had reached the 100th floor in February 1973, at which point it was taller than the Empire State Building in New York City.\nThe building was topped out on May 3, 1973. The day before the event, the \"Chicago Tribune\"'s editorial board wrote: \"Move aside, New York. After tomorrow, when schoolchildren dream of big buildings, they'll no longer think of you and the Empire State Building and the World Trade Center.\" The frame was still not technically complete, as three to four stories remained to be built. One week after the ceremony, four workers died after an elevator shaft caught fire. A fifth worker died after falling from the tower in an unrelated incident four days later. Work was halted again that June due to a labor strike, and Sears began moving furniture into the building that month. The construction cost was about US$150\u00a0million, (equivalent to $ in 2024). Despite the size of the project, Sears executives said the building could not accommodate Sears' annual shareholder meetings, and the company continued to rent space in other structures.\n20th century.\nOpening and early years.\nThe first Sears employees began moving into the tower during the weekend of September 9, 1973. Flashing beacons on the building's roof, the first to be installed at any building in Chicago, were activated the same month. Upon the tower's opening, broadcasters at the John Hancock Center, Chicago's second-tallest building, had to decide whether to relocate to the Sears Tower. Two television stations decided to relocate. Six other stations remained at the John Hancock Center, citing a study which showed that relocating to the Sears Tower would provide only minimal benefits. Documents released in late 1973 indicated that the Sears Tower would cause much more interference than either Sears or the television stations had disclosed. WLS-TV moved to the Sears Tower in February 1974, followed by WTTW the next month.\nBy March 1974, three-fourths of the space in the building was occupied; Sears had leased the upper stories to tenants such as Goldman Sachs, Northwest Industries, and Schiff Hardin. A mobile sculpture by Alexander Calder was dedicated in the lobby in October 1974. Sears' optimistic growth projections were not realized; instead, in late 1974, the company fired 500 workers, about seven percent of the 7,000 Sears employees that worked in the tower. Competition beyond its traditional rivals such as Montgomery Ward arose from emerging retail giants including Kmart, Kohl's, and Walmart. As a result of a surplus of office space that emerged in the 1980s, the tower did not draw as many tenants as projected and so stood half-vacant for a decade.\nRenovation and relocation.\nIn February 1984, Sears announced that it would renovate the building to attract visitors to the lower floors. At the time, 6,500 Sears employees occupied more than half of the building, taking up the lowest 48 stories. The remainder of the tower was occupied by 5,500 employees from about 70 companies. As part of the project, the main entrance was covered with a four-story glass dome, and the first four stories were converted into a shopping atrium. In addition, a visitor center for the building's Skydeck was constructed. The renovations, designed by SOM, were completed in mid-1985. Paul Gapp of the \"Chicago Tribune\" wrote that SOM had \"scaled the new entrance skillfully, in keeping with the main building's height\" and that the new atrium \"relieves the formerly cramped feeling from just inside the Franklin entrance\".\nSears announced in 1988 that it would sell the tower and relocate its merchandising division from the lower half of the building. The company wanted to earn at least $1 billion from the sale of the Sears Tower, so it offered multiple concessions to potential buyers, including a guarantee that Sears would continue to pay rent on the lower half of the building until tenants were found for these stories. Four large firms were negotiating to buy the tower by July 1989. The company had difficulties finding a buyer, in part because the lower stories were too large for many potential tenants. Sears nearly sold the tower to Canadian company Olympia &amp; York, but the deal was canceled in September 1989 because the two firms could not agree on who would pay the property taxes. In November 1989, Sears decided to instead refinance the building. The next year, Sears took out a mortgage loan on the tower for $850\u00a0million from MetLife and AEW Capital Management, with MetLife as the holder of the mortgage note; the loan would mature in 2005.\nIn 1990, the law firm of Keck, Mahin &amp; Cate decided to move into a development that would become 77 West Wacker Drive, rebuffing Sears' attempts to entice the firm to stay. Just two years later, Sears began moving its own offices out of the building to a new campus in Hoffman Estates, Illinois, which was completed in 1995. As the maturation of the mortgage approached, Sears renegotiated the loan in 1994. The negotiations resulted in an agreement where Sears would no longer be liable for the $850\u00a0million loan, although it would only nominally own the building, while AEW and MetLife effectively had total control. As part of the 1994 agreement, AEW and MetLife would be able to take official ownership of the building in 2003. In 1997, Toronto-based TrizecHahn, at the time the lessee of the CN Tower, acquired AEW's holdings in the building for $110\u00a0million, assuming $4\u00a0million in liabilities and a $734\u00a0million mortgage.\n21st century.\nTrizec had projected that the Sears Tower would quickly reach a value of $1\u00a0billion. These projections were not met, with the tower facing the same vacancy and other problems it saw under Sears, although Trizec made somewhat successful efforts to attract new tenants. Following the September 11 attacks, two of the largest tenants, Goldman Sachs and Merrill Lynch, immediately announced plans for vacating 300,000\u00a0ft2 of space. In 2003, Trizec sold its holdings of the tower to MetLife for $9\u00a0million.\nSyndicate ownership.\nIn March 2004, MetLife announced that it would sell the building to a group of investors, including Joseph Chetrit, Joseph Moinian, Lloyd Goldman, Joseph Cayre, and Jeffrey Feil of New York, as well as American Landmark Properties of Skokie, Illinois. The quoted price was $840\u00a0million, with $825\u00a0million held in a mortgage. Two years later, in February 2007, the Sears Tower's owners obtained a $780\u00a0million loan from UBS. At the time, UBS valued the tower at $1.2\u00a0billion.\nSince 2007, the owners had considered plans for the construction of a hotel on the north side of Jackson Boulevard, between Wacker Drive and Franklin Street, close to the entrance of the observation deck, above the tower's underground parking garage. According to the tower's owners, the second building was considered in the original design. The plan was eventually cancelled as city zoning did not permit construction of such a tall building in that location. In February 2009, the owners announced they were considering a plan to paint the structure silver, an idea that was later abandoned. It was hoped that a new, silver, paint-job would \"rebrand\" the building and highlight its advances in energy efficiency for an estimated cost of $50\u00a0million.\nAlthough Sears' naming rights expired in 2003, the building continued to be called the Sears Tower for several years, despite multiple changes in ownership. In March 2009, London-based insurance broker Willis Group Holdings agreed to lease a portion of the building and obtained the naming rights. On July 16, 2009, the building was officially renamed the Willis Tower. By 2011, the building's owners were considering selling a partial ownership stake, or even the entire building, to an investor. The next year, United Airlines announced it would move its corporate headquarters from 77 West Wacker Drive to the Willis Tower.\nBlackstone ownership.\nBy March 2015, the Willis Tower was being marketed at a price of $1.5\u00a0billion. The same month, the Blackstone Group purchased the tower for a reported $1.3\u00a0billion, the highest price ever paid for a property in the U.S. outside of New York City. Blackstone announced a $500 million renovation in January 2017, which would include the construction of the Catalog, a six-story commercial complex, replacing a plaza on Jackson Boulevard and the entrance on Wacker Drive. Architectural firm Gensler designed the renovation. A rooftop terrace was built atop the Catalog, and the building's HVAC systems were overhauled. Most of the building's elevators, excluding those that served the Skydeck, were also renovated for the first time in the tower's history. The new elevators would be faster than the original elevators and would use 35 percent less energy. The building's owners installed artwork by Olafur Eliasson, Jacob Hashimoto, and other artists.\nTo fund these improvements, in February 2017, Blackstone obtained a $1\u00a0billion loan from a group of banks including Goldman Sachs. The new loan replaced $750\u00a0million of CMBS debt that was maturing. The following year, because of the increasing costs of the renovation, Blackstone received a new $1.3\u00a0billion loan from Deutsche Bank and Barclays. The Wacker Drive \"Lunchbox\" entrance was demolished in early 2018 to make way for the Catalog. A steel globe next to the entrance, manufactured by the Poblocki Sign Company and installed in 2010, was relocated to Elmhurst, Illinois. A private club on the 66th and 67th stories opened in June 2018. The club included a restaurant named Craftsman and a lounge named Frame, both of which exclusively served the tower's tenants, as well as a public restaurant known as the East Room. That September, Urbanspace announced that it would operate a food hall on the lower stories.\nIn 2020, insurance company Aon had proposed acquiring Willis Towers Watson (which had succeeded the Willis Group as the building's owner), prompting speculation that the building could be renamed again. The planned merger was canceled in 2021 following an antitrust lawsuit from the United States Department of Justice. The building's renovation was completed in May 2022. At the time, although the Willis Tower was nearly 85 percent leased, the number of tenants and visitors entering the building had decreased significantly since 2019, in part because of the COVID-19 pandemic in Chicago. In April 2023, \"The New York Times\" reported that Blackstone had written down the value of its investment in the tower by $119 million.\nIncidents.\nIn June 2006, seven men were arrested by the FBI and charged with plotting to destroy the tower. Deputy FBI Director John Pistole described their plot as \"more aspirational than operational\". The case went to court in October 2007. After three trials, five of the suspects were convicted and two acquitted. The alleged leader of the group, Narseal Batiste, was sentenced to &lt;templatestyles src=\"Fraction/styles.css\" /&gt;13+1\u20442 years in prison. In response to the perceived threat of an attack, the building's largest tenant at this time, Ernst &amp; Young, moved to North Wacker Drive in early 2009.\nIn May 2020, heavy rains caused three of the basement levels to flood, knocking out power to the building. This also resulted in many TV and radio stations going off the air.\nArchitecture.\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;\nThe Willis Tower was designed by architect Bruce Graham and structural engineer Fazlur Rahman Khan of Skidmore, Owings and Merrill. Graham and Khan designed the building as nine square \"tubes\", clustered in a 3\u00d73 matrix forming a square base with sides. The building's rentable area is . The structure was intended to accommodate 16,500 employees.\nForm and facade.\nEach of the \"tubes\" is a column-free module measuring , which set back at different stories. There are setbacks at the 50th, 66th, and 90th floors. The lowest 50 stories contain nine tubes and cover each. The northwest and southeast tubes terminate at the 50th floor. The 51st through 66th floors each span , above which the northeast and southwest tubes end. From the 67th to 90th floors, each story is shaped like a cross, covering . The north, east, and south tubes end at the 90th floor; the remaining west and center tubes reach 108 floors, with an area of on each of the top stories.\nThe Sears Tower was the first building to use this innovative design. It was both structurally efficient and economic: at 1,450 feet, it provided more space and rose higher than the Empire State Building and cost much less per unit area. The system would prove highly influential in skyscraper construction and has been used in most supertall buildings since, including the world's current tallest building, the Burj Khalifa. In February 1982, two television antennas were added to the structure, increasing its total height to . The western antenna was later extended, bringing the overall height to on June 5, 2000, to improve reception of local NBC station WMAQ-TV.\nThe perimeter of the Willis Tower contains columns that are spaced apart on their centers. The facade is made of anodized aluminum and black glass. Alcoa manufactured of aluminum sheeting for the building's facade. Black bands appear on the tower around the 29th\u201332nd, 64th\u201365th, 88th\u201389th, and 104th\u2013108th floors. These elements are louvers to ventilate the building's environmental support systems and obscure its belted trusses. The rest of the facade is made of 16,000 rectangular windows. all of which measure and are tinted with bronze.\nOutside the building, there was originally a plaza made of pink granite. In the late 2010s, a three-level wing was built along the western and southern sides of the tower replacing the plaza. The roof garden above the annex spans . The annex contains a facade of black steel and aluminum, similar to in the original building. The Jackson Boulevard facade of the annex contains an artwork by Olafur Eliasson, entitled \"Atmospheric wave wall\". The work, measuring across, comprises almost 2,000 blue-and-green steel tiles, which are decorated with hexagonal motifs. The wall is backlit at night.\nStructural and mechanical features.\nThe interior includes of steel, of aluminum, and of concrete flooring. The building contains diagonal columns only on the two stories immediately below each of the setbacks, thus reducing shear stress. The interior of the building could not contain diagonal beams, since these would have obstructed the connections between each of the \"tubes\". Therefore, the columns and the horizontal beams on each story are connected by rigid joints. The superstructure was designed to withstand wind gusts of , which on average would occur once every hundred years. According to the \"Chicago Tribune\", the top of the building would be able to bend by as much as , returning to its normal position within 7.2 seconds.\nThe Willis Tower's basement extends deep, resting on a concrete slab. The ground directly beneath the building was largely made of clay; the underlying layer of limestone was as much as beneath ground level. As a result, the foundation was excavated using 201 caissons, of which 114 reached the underlying limestone. The caissons created holes that measured up to across. Some holes at the northwestern and northeastern corners of the site filled up with groundwater and had to be drained. Workers next placed steel tubes into the holes, then poured concrete around the tubes.\nDuring the Sears Tower's construction, SOM and Chicago government officials considered adding \"smoke free and fire free\" areas to the building, as well as a complete sprinkler system serving all floors. Neither of these features had previously been used in a structure in Chicago. Even though regulations did not require a fire sprinkler system, the building was equipped with one from the beginning. There are around 40,000 sprinkler heads in the building, installed at a cost of $4 million. When it was completed, the Sears Tower was heated electrically, unlike older structures that used gas heating. It included 145,000 light fixtures and a cooling system capable of 17,000 tons of refrigeration. Furthermore, the tower contained fire-suppression and communications systems for emergency use, which were powered by diesel generators. If there was a fire in one section of the building, the building's smoke-detection system would close off the fresh-air intake openings in that section, discharging smoke outdoors.\nFifteen above-ground stories, as well as three of the basement levels, contain mechanical equipment. Above the Skydeck on the 103rd floor is a seven-story mechanical penthouse.\nElevators and escalators.\nThe Sears Tower was planned with 103 elevators, including 14 double-deck elevators. The office stories are served by 97 elevator cabs; due to the presence of the double-deck elevators, these occupy 83 shafts. As designed, one bank of single-deck elevators connected the lobby to the lowest 28 stories. Banks of double-deck elevators traveled to \"sky lobbies\" at the 33rd/34th and 66th/67th floors, where passengers could transfer to local elevators. The 34th through 103rd stories were served by local elevators that operated from the sky lobbies. Two elevators also ran directly from the lobby to the Skydeck on the 103rd floor. As of 2018[ [update]], the elevators carried 5.8 million passengers per year.\nSix of the elevators are used for freight. One of the freight elevators served all stories, traveling to a height of . During a fire or another emergency, this elevator would be reserved for the Chicago Fire Department. Other elevators would be controlled from the 33rd floor. During a fire, elevators would be dispatched to the affected floors to assist with evacuation.\nThe building also had 16 escalators, including a set of double-height escalators that traveled from the main lobby to the lower mezzanine. Another set of escalators connects the 33rd and 34th stories.\nInterior.\nBase.\nWhen the building was completed, the main entrance was on Wacker Drive to the west. There was a plaza on the south side of the building, sloping upward toward Franklin Street to the east. The Franklin Street side of the building was lower than the Wacker Drive entrance, so the entrances on Franklin Street were actually below the plaza, leading to the building's lower mezzanine. Below ground level are three basement levels with a total area of . The basements included a 1,200-seat cafeteria, commercial space, service areas, and a loading dock for 17 trucks. The basement also contained a 150-spot parking garage.\nAs of 2022[ [update]], the building's base covers and contains two lobbies for tenants. The building's tenants primarily enter from Wacker Drive and Franklin Street. Shoppers, restaurant patrons, and visitors to the Skydeck observation deck use the southern entrance on Jackson Boulevard. The Wacker Drive lobby contains \"In the Heart of this Infinite Particle of Galactic Dust\", a 2019 artwork by Jacob Hashimoto. It consists of over 7,000 rice-paper and resin disks that are hung from the ceiling. To honor Khan's contributions to skyscraper engineering design, the Structural Engineers Association of Illinois also commissioned a sculpture of him for the lobby of the Willis Tower.\nThe commercial complex at the building's lowest stories is known as the Catalog, a reference to Sears' mail-order catalogs. The six-story complex includes numerous restaurants. It extends into three of the building's basement levels, as well as the three-story annex to the south and west of the tower. The roof of the annex includes a curved skylight with 240 glass panes, and the northern section of the annex's roof is supported by black columns that resemble those in the original tower. The Catalog also contains decorative details, such as handrails and staircase landings, which are inspired by elements of Chicago's \"built environment\". The third story of the Catalog contains a 30,000-square-foot coworking space operated by Convene.\nSkydeck.\nThe Willis Tower observation deck, called the Skydeck, opened on June 22, 1974. Located on the 103rd floor, above ground level, it is the highest observation deck in the United States and one of Chicago's most famous tourist attractions. Tourists can experience how the building sways in wind and see far over the plains of Illinois and across Lake Michigan to Indiana, Michigan, and Wisconsin in clear conditions. Elevators reach the top in about 60 seconds, allowing occupants to feel the change in pressure as they ascend. Some 1.7\u00a0million tourists visit annually as of 2018[ [update]]. There is also an event venue on the 99th floor.\nIn April 2000, the Skydeck received a $4\u00a0million renovation, featuring multimedia exhibits with interactive effects and murals. Kiosks were scattered around the Skydeck, offering information in six languages. Dellmont Leisure Design, the primary firm involved in the renovation of the Top of the World observation deck at the World Trade Center, created the design.\nIn January 2009, a major renovation of the Skydeck began, including the installation of retractable glass balconies which extend approximately from the facade of the 103rd floor, overlooking South Wacker Drive. The all-glass boxes, informally dubbed \"The Ledge\", allow visitors to see the street below. The boxes, which can accommodate , opened to the public on July 2, 2009. On May 29, 2014, the laminated glass flooring of one of the boxes cracked while visitors were inside, but there were no injuries. The flooring of the same box cracked again on June 12, 2019. In May 2022 a fifth glass ledge opened on the west facade overlooking South Wacker Drive.\nHeight.\nWhen completed, the Sears Tower was the world's tallest building but not the world's tallest structure. Toronto's CN Tower was about taller, although the Council on Tall Buildings and Urban Habitat (CTBUH) does not consider the CN Tower to be a building, since it does not have floors from the ground up. The Willis Tower remains the third tallest building in the Americas and in the Western Hemisphere (after One World Trade Center and Central Park Tower in New York City). With a pinnacle height of , it is the third-tallest freestanding structure in the Americas. It is the 16th-tallest freestanding structure in the world by pinnacle height.\nWhen the Petronas Twin Towers in Kuala Lumpur, Malaysia, was completed in 1998, it claimed to be the tallest building in the world, measuring tall including decorative spires. Chicagoans objected to this claim on the basis that the Sears Tower's top floor was higher than that of either of the Petronas Towers. In the ensuing controversy, four categories of \"tallest building\" were created. Of these, Petronas was the tallest in the category of height to the top of architectural elements, meaning spires but not antennas. Taipei 101 in Taiwan claimed the record in three of the four categories in 2004, surpassing the Petronas Twin Towers in spire height and the Sears Tower in roof height and highest occupied floor. People suggested that Sears add cosmetics atop its tower to surpass Taipei 101, but this did not materialize. On August 12, 2007, the Burj Khalifa in Dubai was reported by its developers to have surpassed the tower in all height categories. Upon completion, One World Trade Center in New York City surpassed the Willis Tower through its structural and pinnacle heights, but not by roof, observation deck elevation, or highest occupied floor.\nUntil 2000, the tower did not hold the record for being the tallest building by pinnacle height. From 1969 to 1978, this record was held by John Hancock Center, whose antenna reached a height of , taller than the Sears Tower's original height. One World Trade Center became taller by pinnacle height with the addition of a 359-foot (109.4-meter) antenna, bringing its total height to . In 1982, two antennas were installed which brought its total height to , making it taller than the John Hancock Center but not One World Trade Center. However, the extension of the tower's western antenna in June 2000 to allowed it to just barely claim the title of tallest building by pinnacle height.\nThe lowest level of the Willis Tower is below the elevation of Franklin Street.\nClimbing.\nOn May 25, 1981, Dan Goodwin, wearing a homemade Spider-Man suit while using suction cups, camming devices, and sky hooks, and despite several attempts by the Chicago Fire Department to stop him, made the first successful outside ascent of the tower. Goodwin was arrested at the top after the seven-hour climb and was later charged with trespassing. Goodwin stated that the reason he made the climb was to call attention to shortcomings in high-rise rescue and firefighting techniques. After a lengthy interrogation by Chicago's District Attorney and Fire Commissioner, Goodwin was officially released from jail.\nIn August 1999, French urban climber Alain \"Spiderman\" Robert, using only his bare hands and bare feet, scaled the building's exterior glass and steel wall all the way to the top. A thick fog settled in near the end of his climb, making the last 20 stories of the building's glass and steel exterior slippery.\nAnnually, since 2009, the Willis Tower has hosted SkyRise Chicago, the world's tallest indoor stair climb, as a charity event benefiting Shirley Ryan AbilityLab, where participants can (legally) climb the Willis Tower's 103-story staircase.\nNaming rights.\nSears sold the tower in 1994 and vacated it by 1995, but retained naming rights through 2003. The new owners were rebuffed in renaming deals with CDW Corp in 2005 and the U.S. Olympic Committee in 2008. British insurance broker Willis Group Holdings leased more than of space on three floors in 2009. A Willis spokesman said the naming rights were obtained as part of the negotiations at no cost to Willis and the building was renamed the Willis Tower on July 16, 2009. The naming rights are valid for 15 years.\nThe \"Chicago Tribune\" joked that the building's new name reminded them of the oft-repeated \"What you talkin' 'bout, Willis?\" catchphrase from the American television sitcom \"Diff'rent Strokes\" and considered the name-change ill-advised in \"a city with a deep appreciation of tradition and a healthy ego, where some Chicagoans still mourn the switch from Marshall Field's to Macy's\". This feeling was confirmed in a July 16, 2009, CNN article in which some Chicago-area residents expressed reluctance to accept the Willis Tower name, and in an article that appeared in the October 2010 issue of \"Chicago\" magazine that ranked the building among Chicago's 40 most important, the author pointedly refused to acknowledge the name change and referred to the building as the \"Sears Tower\". \"Time\" magazine called the name change one of the top 10 worst corporate name changes and pointed to negative press coverage by local news outlets and online petitions from angry residents. The naming rights issue continued into 2013, when Eric Zorn noted in the \"Chicago Tribune\" that \"We're stubborn about such things. This month marked four years since the former Sears Tower was re-christened Willis Tower, and the new name has yet to stick.\"\nBroadcasting.\nMany broadcast station transmitters are located at the top of the Willis Tower. Each list is ranked by height from the top down. Stations at the same height on the same mast indicate the use of a diplexer into the same shared antenna. Due to its extreme height, FM stations (all class B) are very limited in power output.\nRadio stations.\nNOAA Weather Radio station KWO39 transmits off the tower at 162.550\u00a0MHz. Programmed by the National Weather Service Weather Forecast Office in Chicago, it is equipped with Specific Area Message Encoding (SAME), which sets off a siren on specially programmed weather radios to alert of an impending hazard.\nCultural depictions.\nThe building has appeared in numerous films and television shows set in Chicago such as \"Ferris Bueller's Day Off\", where Ferris and company visit the observation deck. \"Late Night with Conan O'Brien\" introduced a character called The Sears Tower Dressed In Sears Clothing when the show visited Chicago in 2006. The building is also featured in History Channel's \"Life After People\", in which it and other human-made landmarks suffer from neglect without humans around, collapsing two hundred years after people are gone.\nIn the 2008 film \"The Dark Knight\", it is part of Gotham City. In the 2011 film \"\", it is featured in a number of scenes. In the 2013 film \"Man of Steel\", the tower is the location of the offices of the \"Daily Planet\".\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28177", "revid": "1307737502", "url": "https://en.wikipedia.org/wiki?curid=28177", "title": "Simony", "text": "Act of selling church offices and roles\nSimony () is the act of selling church offices and roles or sacred things. It is named after Simon Magus, who is described in the Acts of the Apostles as having offered two disciples of Jesus payment in exchange for their empowering him to impart the power of the Holy Spirit to anyone on whom he would place his hands. The term extends to other forms of trafficking for money in \"spiritual things\".\nOrigin.\nThe earliest church legislation against simony may be that of the forty-eighth canon of the Synod of Elvira (c.\u2009305), against the practice of making a donation following a baptism.\nFollowing the Edict of Milan (313), the increased power and wealth of the church hierarchy attracted simony. There are several accusations of simony (not by that name) against Arians, from Athanasius of Alexandria, Hilary of Poitiers, Pope Liberius and Gregory of Nazianzus. Many Church Fathers, such as Ambrose, spoke out against the selling of ministries.\nAnti-simony provisions in Church Council canons (and papal bulls) became common: the First Council of Nicaea (325), the Synod of Antioch (341), and the Councils of Serdica (343\u2013344), Chalcedon (451), and the Council of Orl\u00e9ans in 533.\nThe purchase or sale of ecclesiastical office was associated with the figure of Simon Magus in the Acts of the Apostles and his name came into use as a term. Important in popularizing the word 'Simony' was Pope Gregory I (590\u2013604), who called such exchanges the \"simoniac heresy\".\nIn the Middle Ages.\nAlthough considered a serious offense against canon law, simony is thought to have become widespread in the Catholic Church during the 9th and 10th centuries. In the eleventh century, it was the focus of a great deal of debate. Central to this debate was the validity of simoniacal orders: that is, whether a cleric who had obtained their office through simony was validly ordained.\nThe , the and the Decretals of Gregory IX all dealt with the subject. The offender, whether (the perpetrator of a simoniacal transaction) or (the beneficiary of a simoniacal transaction), was liable to deprivation of his benefice and deposition from orders if a secular priest, or to confinement in a stricter monastery if a regular. No distinction seems to have been drawn between the sale of an immediate and of a reversionary interest. The innocent was, apart from dispensation, liable to the same penalties as though he were guilty.\nIn 1494, a member of the Carmelite order, Adam of Genoa, was found murdered in his bed with twenty wounds after preaching against the practice of simony.\nIn literature.\nIn the 14th century, Dante Alighieri depicted the punishment of many \"clergymen, and popes and cardinals\" in hell for being avaricious or miserly.\nHe also criticised certain popes and other simoniacs:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nIn the Catholic Church.\nSimony remains prohibited in Roman Catholic canon law. In the Code of Canon Law, Canon 149.3 notes that \"Provision of an office made as a result of simony is invalid by the law itself.\"\nChurch of England.\nThe Church of England struggled with the practice after its separation from Rome. For the purposes of English law, simony is defined by William Blackstone as \"obtain[ing] orders, or a licence to preach, by money or corrupt practices\" or, more narrowly, \"the corrupt presentation of any one to an ecclesiastical benefice for gift or reward\". While English law recognized simony as an offence, it treated it as merely an ecclesiastical matter, rather than a crime, for which the punishment was forfeiture of the office or any advantage from the offence and severance of any patronage relationship with the person who bestowed the office. Both Edward VI and Elizabeth I promulgated statutes against simony, in the latter case through the Simony Act 1588 (31 Eliz. 1. c. 6) and Simony Act 1688. The cases of Bishop of St. David's Thomas Watson in 1699 and of Dean of York William Cockburn in 1841 were particularly notable.\nBy the Benefices Act 1892, a person guilty of simony is guilty of an offence for which he may be proceeded against under the Clergy Discipline Act 1892 (55 &amp; 56 Vict. c. 32). An innocent clerk is under no disability, as he might be by the canon law. Simony may be committed in three ways \u2013 in promotion to orders, in presentation to a benefice, and in resignation of a benefice. The common law (with which the canon law is incorporated, as far as it is not contrary to the common or statute law or the prerogative of the Crown) has been considerably modified by statute. Where no statute applies to the case, the doctrines of the canon law may still be of authority.\nAs of 2011[ [update]], simony remains an offence. An unlawfully bestowed office can be declared void by the Crown, and the offender can be disabled from making future appointments and fined up to \u00a31,000. Clergy are no longer required to make a declaration as to simony on ordination, but offences are now likely to be dealt with under the Clergy Discipline Measure 2003 (No. 3).\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral and cited references.\nAttribution:"}
{"id": "28178", "revid": "36370945", "url": "https://en.wikipedia.org/wiki?curid=28178", "title": "September 26", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearSeptember 26 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28179", "revid": "51018556", "url": "https://en.wikipedia.org/wiki?curid=28179", "title": "Samaritans", "text": "Ethnoreligious group native to the Levant\nSamaritans (; ; ; ), often preferring to be called Israelite Samaritans, are an ethnoreligious group originating from the Hebrews and Israelites of the ancient Near East. They are indigenous to Samaria, a historical region of ancient Israel and Judah that comprises the northern half of the West Bank in Palestine. They are adherents of Samaritanism, an Abrahamic, monotheistic, and ethnic religion that developed alongside Judaism.\nAccording to their tradition, the Samaritans' ancestors, the Israelites, settled in Canaan in the 17th century BCE. The Samaritans claim descent from the Israelites who, unlike the Ten Lost Tribes of the Twelve Tribes of Israel, were not subject to the Assyrian captivity after the northern Kingdom of Israel was destroyed and annexed by the Neo-Assyrian Empire around 720 BCE.\nAttributions.\nRegarding the Samaritan Pentateuch as the unaltered Torah, the Samaritans view Judaism as a closely related faith, but claim that Judaism fundamentally alters the original Israelite religion. The most notable theological divide between Jewish and Samaritan doctrine concerns the holiest site, which the Jews believe is the Temple Mount in Jerusalem and which Samaritans identify as Mount Gerizim near modern Nablus and ancient Shechem in the Samaritan version of Deuteronomy 16:6. Both Jews and Samaritans assert that the Binding of Isaac occurred at their respective holy sites, identifying them as Moriah.\nSamaritans attribute their schism with the Jews to Eli, who was the penultimate Israelite shophet and a priest in Shiloh in 1 Samuel 1; in Samaritan belief, he is accused of establishing a worship site in Shiloh with himself as High Priest in opposition to the one on Mount Gerizim.\nOnce a large community, the Samaritan population shrank significantly in the wake of the Samaritan revolts, which were brutally suppressed by the Byzantine Empire in the 6th century. Their numbers were further reduced by Christianization under the Byzantines and later by Islamization following the Arab conquest of the Levant. In the 12th century, the Jewish explorer and writer Benjamin of Tudela estimated that only around 1,900 Samaritans remained in Palestine and Syria.\nAs of 2024,[ [update]] the Samaritan community numbered around 900 people, split between Israel (some 460 in Holon) and the West Bank (some 380 in Kiryat Luza). The Samaritans in Kiryat Luza speak South Levantine Arabic, while those in Holon primarily speak Modern Hebrew. For liturgical purposes, they also use Samaritan Hebrew and Samaritan Aramaic, both of which are written in the Samaritan script. According to Samaritan tradition, the position of the community's leading Samaritan High Priest has continued without interruption for the last 3600 years, beginning with the Hebrew prophet Aaron. Since 2013, the 133rd Samaritan High Priest has been Aabed-El ben Asher ben Matzliach.\nIn censuses, Israeli law classifies the Samaritans as a distinct religious community. However, Rabbinic literature rejected the Samaritans' Halakhic Jewishness because they refused to renounce their belief that Mount Gerizim was the historical holy site of the Israelites. All Samaritans in both Holon and Kiryat Luza have Israeli citizenship, but those in Kiryat Luza also hold Palestinian citizenship; the latter group are not subject to mandatory conscription.\nAround the world, there are significant and growing numbers of communities, families, and individuals who, despite not being part of the Samaritan community, identify with and observe the tenets and traditions of the Samaritans' ethnic religion. The largest community outside the Levant, the \"Shomrey HaTorah\" of Brazil (generally known as \"Neo-Samaritans Worldwide\"), had approximately hundreds of members as of February 2020[ [update]].\nEtymology and terminology.\nInscriptions from the Samaritan diaspora in Delos, dating as early as 150\u201350 BCE, provide the \"oldest known self-designation\" for Samaritans, indicating that they called themselves \"Bene Israel\" in Hebrew (English: \"Children of Israel\", i.e. literally the descendants of the biblical prophet Israel, also known as Jacob, more commonly \"Israelites\").\nIn their own language, Samaritan Hebrew, the Samaritans call themselves \"Israel\", \"B'nai Israel\", and, alternatively, \"Shamerim\" (\u05e9\u05b7\u05de\u05b6\u05e8\u05b4\u05d9\u05dd), meaning \"Guardians/Keepers/Watchers\", and in Arabic \"al-S\u0101miriyy\u016bn\" (). The term is cognate with the Biblical Hebrew term \"\u0160omerim\", and both terms reflect a Semitic root \u05e9\u05de\u05e8, which means \"to watch, guard\".\nHistorically, Samaritans were concentrated in Samaria. In Modern Hebrew, the Samaritans are called \"Shomronim\" (\u05e9\u05d5\u05de\u05e8\u05d5\u05e0\u05d9\u05dd), which means \"inhabitants of Samaria\", literally, \"Samaritans\". In modern English, Samaritans refer to themselves as Israelite Samaritans.\nThat the meaning of their name signifies \"Guardians/Keepers/Watchers [of the Law/Samaritan Pentateuch]\", rather than being a toponym referring to the inhabitants of the region of Samaria, was remarked on by a number of Christian Church Fathers, including Epiphanius of Salamis in the \"Panarion\", Jerome and Eusebius in the \"Chronicon,\" and Origen in \"The Commentary on Saint John's Gospel.\" The historian Josephus uses several terms for the Samaritans, which he appears to use interchangeably. Among them is a reference to \"Khuthaioi\", a designation employed to denote peoples in Media and Persia putatively sent to Samaria to replace the exiled Israelite population. These Khouthaioi were in fact Hellenistic Phoenicians/Sidonians. \"Samareis\" (\u03a3\u03b1\u03bc\u03b1\u03c1\u03b5\u1fd6\u03c2) may refer to inhabitants of the region of Samaria, or of the city of that name, though some texts use it to refer specifically to Samaritans.\nOrigins.\nThe origins of the Samaritans have long been disputed between their own tradition and that of the Jews. Ancestrally, Samaritans affirm that they descend from the tribes of Ephraim and Manasseh in ancient Samaria. Samaritan tradition associates the split between them and the Judean-led southern Israelites to the time of the biblical priest Eli, described as a \"false\" high priest who usurped the priestly office from its occupant, Uzzi, and established a rival shrine at Shiloh, thereby preventing southern pilgrims from Judah and the territory of Benjamin from attending the shrine at Gerizim. Eli is also held to have created a duplicate of the Ark of the Covenant, which eventually made its way to the Judahite sanctuary in Jerusalem.\nIn contrast, Jewish Orthodox tradition\u2014based on material in the Bible, Josephus and the Talmud\u2014dates their presence much later, to the beginning of the Babylonian captivity. In Rabbinic Judaism, for example in the Tosefta Berakhot, the Samaritans are called \"Cuthites\" or Cutheans (, \"Kutim\"), referring to the ancient city of Kutha, geographically located in what is today Iraq. Josephus in both the \"Wars of the Jews\" and the \"Antiquities of the Jews\", in writing of the destruction of the temple on Mt. Gerizim by John Hyrcanus, also refers to the Samaritans as the Cuthaeans. In the biblical account, however, Kuthah was one of several cities from which people were brought to Samaria.\nThe similarities between Samaritans and Jews were such that the rabbis of the Mishnah found it impossible to draw a clear distinction between the two groups. Attempts to date when the schism among Israelites took place\u2014which engendered the division between Samaritans and Judaeans\u2014vary greatly, from the time of Ezra down to the siege of Jerusalem (70 CE) and the Bar Kokhba revolt (132\u2013136 CE). The emergence of a distinctive Samaritan identity, the outcome of a mutual estrangement between them and Jews, was something that developed over several centuries. Generally, a decisive rupture is believed to have taken place in the Hasmonean period.\nSamaritan version.\nThe Samaritan traditions of their history are contained in the \"Kitab al-Ta'rikh\" compiled by Abu'l-Fath in 1355. According to this, a text which Magnar Kartveit identifies as a \"fictional\" apologia drawn from earlier sources (including Josephus but perhaps also from ancient traditions) a civil war erupted among the Israelites when Eli, son of Yafni, the treasurer of the sons of Israel, sought to usurp the High Priesthood of Israel from the heirs of Phinehas. Gathering disciples and binding them by an oath of loyalty, he sacrificed on the stone altar without using salt, a rite which made High Priest Ozzi rebuke and disown him. Eli and his acolytes revolted and shifted to Shiloh, where he built an alternative temple and an altar, a replica of the original on Mount Gerizim. Eli's sons Hophni and Phinehas had intercourse with women and feasted on the meats of the sacrifice inside the Tabernacle. Thereafter, Israel was split into three factions: the original Mount Gerizim community of loyalists, the breakaway group under Eli, and heretics worshipping idols associated with Hophni and Phinehas. Judaism emerged later with those who followed the example of Eli.\nMount Gerizim was the original Holy Place of the Israelites from the time that Joshua conquered Canaan and the tribes of Israel settled the land. The reference to Mount Gerizim derives from the biblical story of Moses ordering Joshua to take the Twelve Tribes of Israel to the mountains by Shechem (Nablus) and place half of the tribes, six in number, on Mount Gerizim\u2014the Mount of the Blessing\u2014and the other half on Mount Ebal\u2014the Mount of the Curse.\nBiblical versions.\nAccording to the Hebrew Bible, they were temporarily united under a United Monarchy, but after the death of King Solomon, the kingdom split in two, the northern Kingdom of Israel with its last capital city Samaria and the southern Kingdom of Judah with its capital Jerusalem. The Deuteronomistic history, written in Judah, portrays Israel as a sinful kingdom, divinely punished for its idolatry and iniquity by being destroyed by the Neo-Assyrian Empire in 720\u00a0BCE. The tensions continued in the post-exilic period. The Books of Kings is more inclusive than Ezra\u2013Nehemiah since the ideal is of one Israel with twelve tribes, whereas the Books of Chronicles concentrate on the Kingdom of Judah and ignore the Kingdom of Israel. Accounts of Samaritan origins in respectively 2 Kings 17:6,24 and Chronicles, together with statements in both Ezra and Nehemiah differ in important degrees, suppressing or highlighting narrative details according to the various intentions of their authors. The narratives in Genesis about the rivalries among the 12 sons of Jacob, and other stories of brotherly discord, are viewed by historian Diklah Zohar as describing tensions between north and south, always resolving them in a symbolically favourable way for the Kingdom of Judah rather than Israel.\nThe emergence of the Samaritans as an ethnic and religious community distinct from other Levant peoples appears to have occurred at some point after the Assyrian conquest of the Kingdom of Israel in approximately 721\u00a0BCE. The annals of Sargon II of Assyria indicate that he deported 27,290 inhabitants of the former kingdom. Jewish tradition affirms the Assyrian deportations and replacement of the previous inhabitants by forced resettlement by other peoples but claims a different ethnic origin for the Samaritans. The Talmud accounts for a people called \"Cuthim\" on a number of occasions, mentioning their arrival by the hands of the Assyrians. According to 2 Kings 17:6, 24 and Josephus, the people of Israel were removed by the king of the Assyrians (Sargon II) to Halah, to Gozan on the Khabur River and to the towns of the Medes. The king of the Assyrians then brought people from Babylon, Kutha, Avva, Hamath and Sepharvaim to place in Samaria. Because God sent lions among them to kill them, the king of the Assyrians sent one of the priests from Bethel to teach the new settlers about God's ordinances. The eventual result was that the new settlers worshipped both the God of the land and their own gods from the countries from which they came.\nIn the Chronicles, following Samaria's destruction King Hezekiah is depicted as endeavouring to draw the Ephraimites, Zebulonites, Asherites and Manassites closer to Judah. Temple repairs at the time of Josiah were financed by money from all \"the remnant of Israel\" in Samaria, including from Manasseh, Ephraim, and Benjamin. Jeremiah likewise speaks of people from Shechem, Shiloh, and Samaria who brought offerings of frankincense and grain to the House of YHWH. Chronicles makes no mention of an Assyrian resettlement. Yitzakh Magen argues that the version of Chronicles is perhaps closer to the historical truth and that the Assyrian settlement was unsuccessful; he asserts that a notable Israelite population remained in Samaria, part of which (following the conquest of Judah) fled south and settled there as refugees. Adam Zertal dates the Assyrian onslaught at 721\u00a0BCE to 647\u00a0BCE. From a pottery type he identifies as Mesopotamian clustering around the Menasheh lands of Samaria, he infers that there were three waves of imported settlers. Furthermore, to this day the Samaritans claim descent from the tribe of Joseph.\nThe \"Encyclopaedia Judaica\" (under \"Samaritans\") summarizes both past and present views on the Samaritans' origins. It says:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Until the middle of the 20th century it was customary to believe that the Samaritans originated from a mixture of the people living in Samaria and other peoples at the time of the conquest of Samaria by Assyria (722\u2013721 BCE). The biblical account in II Kings 17 had long been the decisive source for the formulation of historical accounts of Samaritan origins. Reconsideration of this passage, however, has led to more attention being paid to the Chronicles of the Samaritans themselves. With the publication of Chronicle II (Sefer ha-Yamim), the fullest Samaritan version of their own history became available: the chronicles, and a variety of non-Samaritan materials.\nAccording to the former, the Samaritans are the direct descendants of the Joseph tribes, Ephraim and Manasseh, and until the 17th century CE they possessed a high priesthood descending directly from Aaron through Eleazar and Phinehas. They claim to have continuously occupied their ancient territory and to have been at peace with other Israelite tribes until the time when Eli disrupted the Northern cult by moving from Shechem to Shiloh and attracting some northern Israelites to his new followers there. For the Samaritans, this was the \"schism\" par excellence.\u2014\u200a\nJosephus's version.\nJosephus, a key source, has long been considered a prejudiced witness hostile to the Samaritans. He displays an ambiguous attitude, calling them both a distinct, opportunistic ethnos and, alternatively, a Jewish sect.\nDead Sea scrolls.\nThe Dead Sea scrolls' proto-Esther fragment 4Q550c has an obscure phrase about the possibility of a \"Kutha(ean)\"(\"Kuti\") man returning but the reference remains obscure. 4Q372 records hopes that the northern tribes will return to the land of Joseph. The current dwellers in the north are referred to as fools, an enemy people. However, they are not referred to as foreigners. It goes on to say that the Samaritans mocked Jerusalem and built a temple on a high place to provoke Israel.\nModern scholarship.\nContemporary scholarship confirms that deportations occurred both before and after the Assyrian conquest of the Kingdom of Israel in 722\u2013720 BCE, with varying impacts across Galilee, Transjordan, and Samaria. During the earlier Assyrian invasions, Galilee and Transjordan experienced significant deportations, with entire tribes vanishing; the tribes of Reuben, Gad, Dan, and Naphtali are never again mentioned. Archaeological evidence from these regions shows that a large depopulation process took place there in the late 8th century BCE, with numerous sites being destroyed, abandoned, or feature a long occupation gap. In contrast, some scholars argue that Samaria\u2014a larger and more populated area\u2014presents a more mixed picture. While some sites were destroyed or abandoned during the Assyrian invasion, major cities such as Samaria and Megiddo remained largely intact, and other sites show a continuity of occupation. Other scholars argue that archaeological findings from Samaria show that the territory as a whole\u2014except for a few small areas\u2014was devastated following the Assyrian conquest. The Assyrians settled exiles from Babylonia, Elam, and Syria in places including Gezer, Hadid, and villages north of Shechem and Tirzah. However, even if the Assyrians deported 30,000 people, as they claimed, many would have remained in the area. Based on changes in material culture, Adam Zertal estimated that only 10% of the Israelite population in Samaria was deported, while the number of imported settlers was likely no more than a few thousand, indicating that most Israelites continued to reside in Samaria.\nGary N. Knoppers described the demography shifts in Samaria following the Assyrian conquest as: \"... not the wholesale replacement of one local population by a foreign population, but rather the diminution of the local population\", which he attributed to deaths from war, disease and starvation, forced deportations, and migrations to other regions, particularly south to the Kingdom of Judah. The state-sponsored immigrants who had been forcibly brought into Samaria appear to have generally assimilated into the local population. Nevertheless, the Book of Chronicles records that King Hezekiah of Judah invited members of the tribes of Ephraim, Zebulun, Asher, Issachar and Manasseh to Jerusalem to celebrate Passover after the destruction of Israel. In light of this, it has been suggested that the bulk of those who survived the Assyrian invasions remained in the region. Per this interpretation, the Samaritan community of today is thought to be predominantly descended from those who remained.\nThe Israeli biblical scholar Shemaryahu Talmon has supported the Samaritan tradition that they are mainly descended from the tribes of Ephraim and Manasseh who remained in Israel after the Assyrian conquest. He states that the description of them at 2 Kings 17:24 as foreigners is tendentious and intended to ostracize the Samaritans from those Israelites who returned from the Babylonian exile in 520\u00a0BCE. He further states that 2 Chronicles 30:1 could be interpreted as confirming that a large fraction of the tribes of Ephraim and Manasseh (i.e., Samaritans) remained in Israel after the Assyrian exile. E. Mary Smallwood wrote that the Samaritans \"were the survivors of the pre-Exilic northern kingdom of Israel, diluted by intermarriage with alien settlers,\" and that they broke away from mainstream Judaism in the 4th century BCE. Archaeologist Eric Cline takes an intermediate view. He believes only 10\u201320% of the Israelite population (i.e. 40,000 Israelites) were deported to Assyria in 720 BCE. About 80,000 Israelites fled to Judah whilst between 100,000 and 230,000 Israelites remained in Samaria. The latter intermarried with the foreign settlers, thus forming the Samaritans.\nThe religion of this remnant community is likely distorted by the account recorded in the Books of Kings, which claims that the local Israelite religion was perverted with the injection of foreign customs by Assyrian colonists. In reality, the surviving Samaritans continued to practice Yahwism. This explains why they did not resist Judean kings, such as Hezekiah and Josiah, imposing their religious reforms in Samaria. Magnar Kartveit argues that the people who later became known as Samaritans likely had diverse origins and lived in Samaria and other areas, and it was the temple project on Mount Gerizim that provided the unifying characteristic that allows them to be identified as Samaritans.\nModern genetic studies support the Samaritan narrative that they descend from indigenous Israelites. Shen et al. (2004) formerly speculated that outmarriage with foreign women may have taken place. Most recently the same group came up with genetic evidence that Samaritans are closely linked to Cohanim, and therefore can be traced back to an Israelite population prior to the Assyrian invasion. This correlates with expectations from the fact that the Samaritans retained endogamous and biblical patrilineal marriage customs, and that they remained a genetically isolated population.\nHistory.\nPersian period.\nAccording to Chronicles 36:22\u201323, the Persian emperor Cyrus the Great (reigned 559\u2013530 BCE) permits the return of the exiles to their homeland and orders the rebuilding of the Temple (Zion). The prophet Isaiah identifies Cyrus as \"the LORD's Messiah\". As the Babylonian captivity had primarily affected the lowlands of Judea, the Samarian populations had likely avoided the casualties of the crisis of exile and in fact showed signs of widespread prosperity.\nThe books of Ezra\u2013Nehemiah detail a lengthy political struggle between Nehemiah, governor of the new Persian province of Yehud Medinata, and Sanballat the Horonite, the governor of Samaria, centered around the refortification of the destroyed Jerusalem. Despite this political discourse, the text implies that relationships between the Jews and Samaritans were otherwise quite amicable, as intermarriage between the two seems commonplace, even to the point that the High Priest Joiada married Sanballat's daughter. Some theologians believe Nehemiah 11:3 describes other Israelite tribes returning to Judah with the Judeans. The former lived in the cities of Judah whilst the latter lived in Jerusalem. Benjamites also lived with Judeans in Jerusalem.\nDuring Achaemenid rule, material evidence suggests significant overlap between Jews and proto-Samaritans, with the two groups sharing a common language and script, eschewing the claim that the schism had taken form by this time. However, onomastic evidence suggests the existence of a distinct northern culture. Some inhabitants of Samaria during this period identified with Israelite heritage. This connection is evidenced in two ways: first, through biblical accounts of local officials' involvement with the Jerusalem Temple, and second, through naming patterns. Many names recorded in the Wadi Daliyeh documents and on Samaritan coins feature Israelite elements. Sanballat's sons bore the theophoric Israelite names Delaiah and Shelemiah, while the name \"Jeroboam\", used by northern Israelite kings during the monarchic period, also appears on Samaritan coins.\nThe archaeological evidence can find no sign of habitation in the Assyrian and Babylonian periods at Mount Gerizim but indicates the existence of a sacred precinct on the site in the Persian period by the 5th century BCE. This is not to be interpreted as signaling a precipitous schism between the Jews and Samaritans, as the Gerizim temple was not the only Yahwistic temple outside of Judea. According to most modern scholars, the split between the Jews and Samaritans was a gradual historical process extending over several centuries rather than a single schism at a given point in time.\nHellenistic period.\nForeign rule.\nThe Macedonian Empire conquered the Levant in the 330s BCE, resulting in both Samaria and Judea coming under Greek rule as the province of Coele-Syria. Samaria was by-and-large devastated by the Macedonian conquest and subsequent colonization efforts, though its southern lands were spared the broader consequences of the invasion and continued to thrive. Matters were further complicated in 331 BCE when the Samaritans rose up in rebellion and murdered the Macedonian-appointed prefect Andromachus, resulting in a brutal reprisal by the army. Following the death of Alexander the Great, the area became part of the Ptolemaic Kingdom, which, in one of several wars, was eventually conquered by the neighboring Seleucid Empire.\nThough the temple on Mount Gerizim had existed since the 5th century BCE, evidence shows that its sacred precinct experienced an extravagant expansion during the early Hellenistic era, indicating its status as the preeminent place of Samaritan worship had begun to crystallize. By the time of Antiochus III the Great, the temple \"town\" had reached 30 dunams in size. The presence of a flourishing cult centered around Gerizim is documented by the sudden resurgence of Yahwistic and Hebrew names in contemporary correspondence, suggesting that the Samaritan community had officially been established by the 2nd century BCE. Overall, the Samaritans were generally more populous and wealthier than the Judeans in Palestine, until 164 BC.\nAntiochus IV Epiphanes and Hellenization.\nAntiochus IV Epiphanes was on the throne of the Seleucid Empire from 175 to 163\u00a0BCE. His policy was to Hellenize his entire kingdom and standardize religious observance. According to 1 Maccabees 1:41-50 he proclaimed himself the incarnation of the Greek god Zeus and mandated death to anyone who refused to worship him. In the 2nd century BCE, a series of events led to a revolution by a faction of Judeans against Antiochus IV.\nAnderson notes that during the reign of Antiochus IV:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;the Samaritan temple was renamed either Zeus Hellenios (willingly by the Samaritans according to Josephus) or, more likely, Zeus Xenios, (unwillingly in accord with 2 Macc. 6:2).\u2014\u200a\nJosephus quotes the Samaritans as saying:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We therefore beseech thee, our benefactor and saviour, to give order to Apollonius, the governor of this part of the country, and to Nicanor, the procurator of thy affairs, to give us no disturbances, nor to lay to our charge what the Jews are accused for, since we are aliens from their nation and from their customs, but let our temple which at present hath no name at all, be named the Temple of Jupiter Hellenius.\u2014\u200a\nIn the letter, defended as genuine by E. Bickerman and M. Stern, the Samaritans assert their distinction from the Judeans based on both race (\u03b3\u03ad\u03bd\u03bf\u03c2) and in customs (\u1f14\u03b8\u03bf\u03c2).\nAccording to II Maccabees:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Shortly afterwards, the Greek king sent Gerontes the Athenian to force the Jews of Israel to violate their ancestral customs and live no longer by the laws of God; and to profane the Temple in Jerusalem and dedicate it to Olympian Zeus, and the one on Mount Gerizim to Zeus, Patron of Strangers, as the inhabitants of the latter place had requested.\u2014\u200a\nDestruction of the temple.\nDuring the Hellenistic period, Samaria was largely divided between a Hellenizing faction based in Samaria (Sebastia) and a pious faction in Shechem and surrounding rural areas, led by the High Priest. Samaria was a largely autonomous state nominally dependent on the Seleucid Empire until around 110\u00a0BCE, when the Hasmonean ruler John Hyrcanus destroyed the Samaritan temple on Mount Gerizim and devastated Samaria. Only a few stone remnants of the temple exist today.\nHyrcanus' campaign of destruction was the watershed moment which confirmed hostile relations between Jews and Samaritans. The actions of the Hasmonean dynasty resulted in widespread Samaritan resentment of, and alienation from, their Judean brethren, resulting in the deterioration of relations between the two that lasted centuries, if not millennia.\nRoman period.\nUnder the Roman Empire, Samaria became a part of the Herodian Tetrarchy, and with the deposition of Herod Archelaus in the early 1st century CE Samaria became a part of the province of Judaea. Samaritans appear briefly in the Christian gospels, most notably in the account of the Samaritan woman at the well and the parable of the Good Samaritan. In the former, it is noted that a substantial number of Samaritans accepted Jesus through the woman's testimony to them, and Jesus stayed in Samaria for two days before returning to Cana. In the latter, it is only the Samaritan who helps the man stripped of clothing, beaten, and left on the road half dead, his Abrahamic covenantal circumcision implicitly evident. A priest and a Levite walk past, but the Samaritan helps the naked man regardless of his nakedness (itself religiously offensive to the priest and Levite), his self-evident poverty, or to which Hebrew sect he belongs.\nDuring the First Jewish\u2013Roman War in 67 CE a significant Samaritan uprising gathered on Mt. Gerizim. In response, Roman general Vespasian dispatched a relatively small force under the command of Cerialis. Although some Samaritans surrendered, most fought, resulting in heavy casualties. According to Josephus, 11,600 Samaritans were killed. There is no evidence of Samaritan involvement in later phases of the revolt. In 72/73 CE, Vespasian established Flavia Neapolis on the site of \"Mabartha\", near Shechem. While some scholars argue this was to counter Samaritan influence and aspirations, others contend it was primarily a geo-strategic decision. The new city was designed as a polis and included both Samaritan and pagan populations, becoming a major urban center for the Samaritans. Despite its Hellenistic character, the city maintained local traditions, as reflected in its coins which avoided pagan symbols.\nThe possibility of Samaritan involvement in the Bar Kokhba revolt (132\u2013136 CE) alongside the Jews against the Romans remains uncertain. Some Jewish sources, such as the Genesis Rabbah and the Jerusalem Talmud, depict the Samaritans as obstructing Jewish efforts, including the construction of the Temple and the defense of Betar, leading to interpretations of possible Samaritan collaboration with the Romans. However, these sources are considered legendary or anachronistic. Additionally, later Samaritan chronicles referring to the Hadrianic period do not connect events from this time to the Bar Kokhba revolt. Consequently, Mor concludes that there is no concrete evidence of cooperation between Jews and Samaritans during the revolt.\nThe defeat of the Jews in the Bar Kokhba revolt, along with the depopulation and destruction of Judea, allowed the Samaritans to expand into former Jewish areas, particularly in northern Judea, establishing themselves in places such as Emmaus and Sha'alavim. Samaritans also settled in the Beit She'an Valley and in coastal cities like Caesarea. In the ensuing years, the synagogue gained prominence as the central religious institution for the Samaritan community. According to later Samaritan chronicles, synagogues faced episodes of suppression during the second and third centuries CE. Under Commodus (180\u2013192 CE) they were said to have been closed, and during the reign of an emperor called Alexander, identified either as Caracalla (211\u2013217 CE) or Severus Alexander (222\u2013235 CE), synagogues were reported to have been destroyed.\nThe 4th century witnessed a Samaritan cultural revival, marked by the development of a distinct Samaritan alphabet derived from the ancient Paleo-Hebrew script, as well as the composition of new religious works. During this period, much of the liturgy was organized and formalized under the high priest Baba Rabba. Later Samaritan chronicles also credit him with the construction of synagogues in several villages, including Awarta, Salem, Namara, Qaryat Haja, Qarawa, Tira Luza, Dabarin, and Beit Jan. Samaritan chronicles also report that the high priest 'Aqbun, possibly during the reign of Emperor Valens (364\u2013378/9 CE), rebuilt the synagogue in Nablus, which later sources say was confiscated under the Byzantines and again following the Muslim conquest.\nArchaeological and literary evidence indicates that by late antiquity, Samaritans established diaspora communities across the Mediterranean. In Asia Minor, Palladius recorded a Samaritan synagogue in Tarsus around 407/408 CE, while a bilingual Samaritan-Greek inscription from Thessaloniki, dated to the 4th\u20136th centuries CE, points to organized communal life there. In Rome, a letter of King Theoderic the Great (early 6th century) refers to a Samaritan synagogue. In Sicily, Pope Gregory I's correspondence attests to Samaritans in Syracuse at the end of the 6th century, complementing epigraphic evidence of a synagogue there from the 3rd\u20134th century CE.\nByzantine period.\nAccording to Samaritan sources, the Eastern Roman emperor Zeno (r. 474\u2013491), whom they refer to as \"Zait the King of Edom,\" persecuted the Samaritans. He is said to have travelled to Neapolis (Shechem), summoned the elders, and demanded their conversion to Christianity. When they refused, many were killed, and the local synagogue was rebuilt as a church. Zeno also appropriated Mount Gerizim, where he constructed several buildings, including a tomb for his recently deceased son. A cross was placed on the tomb so that Samaritans, in bowing before God, would also bow before it. By 484 the Samaritans rose in revolt. They attacked Neapolis, burning five churches erected on former Samaritan holy sites and mutilating Bishop Terebinthus, who was officiating at Pentecost. The rebels elected Justa (also rendered Justasa or Justasus) as their king and moved to Caesarea, where a noteworthy Samaritan community lived. There, several Christians were killed and the church of Saint Sebastian was destroyed. Justa celebrated the victory with games in the circus. According to the \"Chronicon Paschale\", the \"dux Palaestinae\", Asclepiades, supported by the Caesarea-based Arcadiani of Rheges, defeated the rebels, killed Justa, and sent his head to Zeno. Procopius adds that Bishop Terebinthus appealed directly to Zeno for revenge, the emperor personally went to Samaria to quell the rebellion.\nSome modern historians believe that the order of the facts preserved by Samaritan sources should be inverted, with the persecution of Zeno as a consequence of the rebellion rather than its cause, and should have happened after 484, around 489. Zeno rebuilt the church of St. Procopius in Neapolis, and the Samaritans were banned from Mount Gerizim, on whose top a signaling tower was built to alert in case of civil unrest.\nAccording to an anonymous biography of Mesopotamian monk Barsauma, whose pilgrimage to the region in the early 5th century was accompanied by clashes with locals and the forced conversion of non-Christians, Barsauma managed to convert Samaritans by conducting demonstrations of healing. Jacob, an ascetic healer living in a cave near Porphyrion, Mount Carmel in the 6th century CE, attracted admirers including Samaritans who later converted to Christianity. Under growing government pressure, many Samaritans who refused to convert to Christianity in the 6th century may have preferred paganism and even Manicheism.\nUnder a charismatic, messianic figure named Julianus ben Sabar (or ben Sahir), the Samaritans of Palaestina launched a war to create their own independent state in 529. With the help of the Ghassanids, Emperor Justinian I crushed the revolt; tens of thousands of Samaritans died or were enslaved. The Samaritan faith, which had previously enjoyed the status of \"religio licita\", was virtually outlawed thereafter by the Christian Byzantine Empire; from a population once at least in the hundreds of thousands, the Samaritan community dwindled to tens of thousands.\nThe Byzantine response to the revolts, described by the archaeologist Claudine Dauphin as an act of ethnic cleansing, decimated five successive generations of the Samaritan population, destroyed their religious center, stripped their rights, and left them politically insignificant. Nevertheless, the Samaritan population in Samaria did survive. During a pilgrimage to the Holy Land in 570 CE, an anonymous Christian pilgrim from Piacenza travelled through Samaria and recorded the following: \"From there we went up past a number of places belonging to Samaria and Judaea to the city of Sebaste, the resting-place of the Prophet Elisha. There were several Samaritan cities and villages on our way down through the plains, and wherever we passed along the streets they burned away our footprints with straw, whether we were Christians or Jews, they have such a horror of both\". The same pilgrim also mentions a place called \"Castra Samaritanorum\" near Shikmona.\nAccording to Menachem Mor, the decline of the Samaritan population between the 5th and 6th centuries was mostly due to the ongoing Christianization of Palestine's inhabitants, rather than the uprisings against the Byzantines. Mor argues that a large number of Samaritans in the cities and towns converted to Christianity, some under pressure and some of their own free will. He claims that both Samaritan and Christian sources preferred to conceal this phenomenon. The Samaritans preferred to attribute their numerical decrease on their resistance to coerced conversion, while the Christians were not willing to admit that the Samaritans were coerced into accepting Christianity and instead preferred to claim that many Samaritans were killed because of their rebellious nature. A change in the local population's identity throughout the Byzantine period is not indicated by the archeological findings.\nEarly Islamic period.\nBy the time of the Muslim conquest of the Levant, apart from Jund Filastin, small dispersed communities of Samaritans were living in Muslim Egypt, Syria, and Muslim Iran. According to Milka Levy-Rubin, many Samaritans were forced to convert under Abbasid and Tulunid rule (878\u2013905 CE), having been subjected to hardships such as droughts, earthquakes, persecution by local governors, high taxes on religious minorities, and anarchy.\nLike other non-Muslims in the empire, such as Jews, Samaritans were often considered to be People of the Book and were guaranteed religious freedom. Their minority status was protected by the Muslim rulers, and they had the right to practice their religion, but as dhimmi, adult males had to pay the jizya or \"protection tax\". This however changed during late Abbasid period, with increasing persecution targeting the Samaritan community and considering them infidels which must convert to Islam.\nAnarchy overtook Palestine during the early years of Abbasid Caliph al-Ma'mun (813\u2013833 CE), when his rule was challenged by internal strife. According to the Chronicle of Abu l-Fath, during this time, many clashes took place, the locals suffered from famine and even fled their homes out of fear, and \"many left their faith\". An exceptional case is of ibn Fir\u0101sa, a rebel who arrived in Palestine in 830 and was said to have loathed Samaritans and persecuted them. He punished them, forced them to convert to Islam, and filled the prisons with Samaritan men, women, and children, keeping them there until many of them perished from hunger and thirst. He had also demanded payment for enabling them to circumcise their sons on the eighth day. As a result of the persecution, many Samaritans abandoned their religion at that time. The revolt was put down, but caliph al-Mu'tasim then increased taxes on the rebels, which sparked a second uprising. Rebel forces captured Nablus, where they set fire to synagogues belonging to the Samaritan and Dosithian (Samaritan sect) faiths. The community's situation briefly improved when this uprising was put down by Abbasid forces, and High Priest Pinhas ben Netanel resumed worship in the Nablus synagogue. Under the reign of al-W\u0101thiq bi-ll\u0101h, Abu-Harb Tamim, who had the support of Yaman tribes, led yet another uprising. He captured Nablus and caused many to flee, the Samaritan High Priest was injured and later died of his wounds in Hebron. The Samaritans could not go back to their homes until Abu-Harb tamim was vanquished and captured (842 CE).\nA number of restrictions on the dhimmi were reinstituted during the reign of the Abbasid Caliph al-Mutawakkil (847\u2013861 CE), prices increased once more, and many people experienced severe poverty. \"Many people lost faith as a result of the terrible price increases and because they became weary of paying the jizya. There were many sons and families who left their faith and became lost\". The tradition of men wearing a red tarboosh may also go back to an order by al-Mutawakkil, that required non-Muslims to be distinguished from Muslims. However, this is disputed because praying while wearing a tarboosh was easier for Muslims, because they put their heads to the ground during Salah (daily prayers).\nThe numerous instances of Samaritans converting to Islam that are mentioned in the Chronicle of Abu l-Fath are all connected to economic difficulties that led to widespread poverty among the Samaritan population, anarchy that left Samaritans defenseless against Muslim attackers, and attempts by those people and others to force conversion on the Samaritans. It is crucial to keep in mind that the Samaritan community was the smallest among the other dhimmi communities and that it was also situated in Samaria, where Muslim settlement continued to expand as evidenced by the text; by the ninth century, villages such as Sinjil and Jinsafut were already Muslim. This makes it possible to assume that the Samaritans were more vulnerable than other \"dhimmi\", what greatly broadened the extent of their Islamization.\nArchaeological data demonstrates that during the 8th and 9th centuries, winepresses west of Samaria stopped operating, but the villages to which they belonged persisted. Such sites could be securely identified as Samaritan in some of those cases, and it is likely in others. According to one theory, the local Samaritans who converted to Islam kept their villages going but were barred by Islamic law from making wine. These findings date to the Abbasid period, and are in accordance with the Islamization process as described in the historical sources.\nAs time goes on, more information from recorded sources refers to Nablus and less to the vast agricultural regions that the Samaritans had previously inhabited. Hence, the Abbasid era marks the disappearance of Samaritan rural habitation in Samaria. By the end of the period, Samaritans were mainly centered in Nablus, while other communities persisted in Caesarea, Cairo, Damascus, Aleppo, Sarepta, and Ascalon. The Samaritans transitioned from speaking Aramaic and Arabic to exclusively speaking Arabic starting from the 11th century onward.\nCrusader period.\nDuring the Crusades, the Franks took over Nablus, where the majority of Samaritans lived. Massacres took place in Samaritan maritime communities in Arsuf, Caesarea, Acre and perhaps Ascalon. During the initial razzia in Nablus the invading Franks destroyed Samaritan buildings and sometime later tore down their ritual bath and synagogue on Mt. Gerizim. Christians bearing crosses successfully pleaded for a calm transition. The calamities that befell them during the Frankish reign came from Muslims such as the commander of the Dasmascene army, Bazw\u0203dj, who raided Nablus in 1137 and abducted 500 Samaritan men, women and children back to Damascus.\nAyyubid and Mamluk rule.\nTwo hundred Samaritans were reportedly forced to convert to Islam in the village of Immatain by Saladin, according to a tradition recalled by a Samaritan High Priest in the 20th century; however, written sources make no reference to this event.\nOttoman rule.\nAccording to the Ottoman censuses of 1525\u20131526, 25 Samaritan families lived in Gaza, and 29 families lived in Nablus. In 1548\u20131549, there were 18 families in Gaza and 34 in Nablus. In 1596\u20131597, there were 8 families in Gaza, 20 in Nablus and 5 in Safed.\nThe Samaritan community in Egypt shrank as a result of Ottoman persecution of Samaritans who worked for the Mamluk government, with the majority of them converting to Islam. In Damascus, the majority of the Samaritan community was massacred or converted to Islam during the reign of the Ottoman Pasha Mardam Beqin in the early 17th century. The remainder of the Samaritan community there, in particular the Danafi family, which is still influential today, moved back to Nablus in the 17th century. The Matari family relocated from Gaza to Nablus at about the same time that the Marhiv family moved back from Sarafand, Lebanon. There were no longer any Samaritans in either Gaza or Damascus; only a handful remained in Gaza.\nThe Nablus community endured because most of the surviving diaspora returned, and they have maintained a tiny presence there to this day. In 1624, the last Samaritan High Priest of the line of Eleazar son of Aaron died without issue, but according to Samaritan tradition, descendants of Aaron's other son, Ithamar, remained and took over the office. Following the death of High Priest Shelamia ben Pinhas, Muslim persecution of Samaritans intensified, and they became the target of violent riots that led to many of them converting to Islam. In 1624, access to Mount Gerizim's summit was outlawed for the survivors, and they were only permitted to make Passover sacrifices on the mountain's eastern slopes. By the middle of the 17th century, very small Samaritan communities survived in Nablus, Gaza, and Jaffa.\nThe status of the Samaritan community of Nablus greatly improved in the early 18th century because one of them, Ibrahim al-Danafi, who was also a poet and an author, worked for the Tuqan family, which then dominated the city. Al-Danafi also bought the hill of Pinehas and the plot on Mount Gerizim's summit to be used by the community, but the favorable conditions that were necessary for the community's recovery did not last. The 1759 earthquake, the endemic that followed, and the other restrictions placed on the Samaritans limited the growth of their community, and by the end of the 18th century, there were only 200 people living there and living off of trade, brokerage, and tax collection.\nThe majority of Samaritan families in the 19th century lived in \"Harat el-Somra\", a crowded neighborhood in Nablus' southwest. During this time, the modest Samaritan synagogue, \"el-Kanis\", served as the center of the community's cultural, religious, and social life. Some Samaritans worked as clerks for the municipal authorities, while others worked in local small business and crafts in Nablus and its vicinity. Some were forced to collect alms from the growing numbers of tourists and other visitors. To keep their households and organizations functioning, the Samaritan community sometimes even turned to selling ancient manuscripts.\nDuring the 1840s, the ulama of Nablus began asserting that the Samaritans may not be considered \"People of the Book\" and therefore have the same status as pagans and must convert to Islam or be executed. As a result, locals attempted to force the conversion of two children of a Samaritan widow who had a Muslim lover in 1841. Her young daughter died from fear, but her 14-year-old boy converted to Islam. Another Samaritan was later coerced into converting to Islam. Appealing to the King of France did not help. The Samaritan people were eventually helped by the Jewish Hakham Bashi Chaim Abraham Gagin, who decreed that the Samaritans are \"a branch of the children of Israel, who acknowledge the truth of the Torah,\" and as such should be protected as a \"People of the Book\". As a result, the ulama ceased their preaching against Samaritans. The Samaritans also paid bribes to the Arab Muslims, totaling approximately 1000 GBP, and eventually came out of their hiding places. However, they were prohibited from offering Passover sacrifices on Mount Gerizim until 1849. By the late Ottoman period, the Samaritan community dwindled to its lowest. In the 19th century, with pressure of conversion and persecution from the local rulers, the community fell to just over 100 persons.\nMandatory Palestine.\nThe situation of the Samaritan community improved significantly during the British Mandate of Palestine. At that time, they began to work in the public sector, like many other groups. With better medical care and Samaritan men marrying Jewish women, the demographic status of the community improved throughout the Mandatory period. The censuses of 1922 and 1931 recorded 163 and 182 Samaritans in Palestine, respectively. 147 lived in Nablus, 12 resided in Tulkarm, 12 in Jaffa, and 6 in As-Salt, Transjordan. Later some moved to Ramat Gan and even to Haifa.\nDuring the 1929 Palestine riots, Arab rioters attacked Samaritans who were performing the Passover sacrifice on Mount Gerizim and flung stones at them as well as their guests. The Palestine Police Force got involved and prevented any potential fatalities.\nIsraeli, Jordanian and Palestinian rule.\nAfter the establishment of the State of Israel, some of the Samaritans who were living in Jaffa emigrated to Samaria and lived in Nablus. By the late 1950s, around 100 Samaritans left the West Bank for Israel under an agreement with the Jordanian authorities in the West Bank. In 1954, Israeli President Yitzhak Ben-Zvi fostered a Samaritan enclave in Holon, Israel, located in 15a Ben Amram Street. During Jordanian rule in the West Bank, Samaritans from Holon were permitted to visit Mount Gerizim only once a year, on Passover.\nIn 1967, Israel conquered the West Bank during the Six-Day War, and the Samaritans there came under Israeli rule. Until the 1990s, most of the Samaritans in the West Bank resided in Nablus. They relocated to Mount Gerizim near the Israeli settlement of Har Brakha as a result of violence during the First Intifada (1987\u20131990). Consequently, all that is left of the Samaritan community in Nablus is an abandoned synagogue. The Israeli army maintains a presence in the area. The Samaritans of Nablus relocated to the village of Kiryat Luza. In the mid-1990s, the Samaritans of Kiryat Luza were granted Israeli citizenship. They also became citizens of the Palestinian Authority following the Oslo Accords. As a result, they are the only people to possess dual Israeli-Palestinian citizenship. \nToday, Samaritans in Israel are fully integrated into society and serve in the Israel Defense Forces. The Samaritans of the West Bank seek good relations with their Palestinian neighbors while maintaining their Israeli citizenship, tend to be fluent in Hebrew and Arabic, and use both a Hebrew and Arab name. Some of them hold political office in Nablus.\nGenetic studies.\nSamaritan lineages.\nDemographic investigations of the Samaritan community were carried out in the 1960s. Detailed pedigrees of the last 13 generations show that the Samaritans comprise four lineages:\nY-DNA and mtDNA comparisons.\nRecently several genetic studies on the Samaritan population were made using haplogroup comparisons as well as wide-genome genetic studies. Of the 12 Samaritan males used in the analysis, 10 (83%) had Y chromosomes belonging to haplogroup J, which includes three of the four Samaritan families. The Joshua-Marhiv family belongs to Haplogroup J-M267 (formerly \"J1\"), while the Danafi and Tsedakah families belong to haplogroup J-M172 (formerly \"J2\"), and can be further distinguished by the M67 SNP\u2014the derived allele of which has been found in the Danafi family\u2014and the PF5169 SNP found in the Tsedakah family. However the biggest and most important Samaritan family, the Cohen family (Tradition: Tribe of Levi), was found to belong to haplogroup E.\nA 2004 article on the genetic ancestry of the Samaritans by Shen \"et al.\" concluded from a sample comparing Samaritans to several Jewish populations, all currently living in Israel\u2014representing the Beta Israel, Ashkenazi Jews, Iraqi Jews, Libyan Jews, Moroccan Jews, and Yemenite Jews, as well as Israeli Druze and Palestinians\u2014that \"the principal components analysis suggested a common ancestry of Samaritan and Jewish patrilineages. Most of the former may be traced back to a common ancestor in what is today identified as the paternally inherited Israelite high priesthood (Cohanim) with a common ancestor projected to the time of the Assyrian conquest of the kingdom of Israel.\" The mitochondrial lineages of Samaritans were closest to Iraqi Jewish and Palestinian mtDNA sequences.\nAutosomal DNA.\nAutosomally, the Samaritans cluster with other Levantine populations. The Samaritans also resemble other Levantine groups in terms of their admixture, but they do not have much of the sub-Saharan African admixture found in small amounts in their Arab neighbours. They also show significant genetic drift that distinguishes them from others.\nDemographics.\nFigures.\nAn estimated 1\u00a0million Samaritans lived during biblical times, but in recent times the numbers are smaller. There were 100 in 1786 and 141 in 1919, then 150 in 1967. This grew to 745 in 2011, 751 in 2012, 756 in 2013, 760 in 2014, 777 in 2015, 785 in 2016, 796 in 2017, 810 in 2018 and 820 in 2019. The Samaritan community dropped in numbers during the various periods of Muslim rule in the region. The Samaritans could not rely on foreign assistance as much as the Christians did, nor on a large number of diaspora immigrants as did the Jews. The once-flourishing community declined over time, either through emigration or conversion to Islam among those who remained.Today, half reside in modern homes at Kiryat Luza on Mount Gerizim, which is sacred to them, and the rest in Holon. There are also four Samaritan families residing in Binyamina-Giv'at Ada, Matan, and Ashdod. As a small community physically divided between neighbors in a hostile region, Samaritans have been hesitant to overtly take sides in the Arab\u2013Israeli conflict, fearing that doing so could lead to negative repercussions. Samaritans who are Israeli citizens are drafted into the military, along with the Jewish citizens of Israel.\nRelations of Samaritans with Israeli Jews, Muslim and Christian Palestinians in neighboring areas have been mixed. Samaritans living in both Israel and in the West Bank have Israeli citizenship.\nSamaritans in the Palestinian Authority-ruled territories are a minority in the midst of a Muslim majority. They had a reserved seat in the Palestinian Legislative Council in the election of 1996, but they no longer have one. Samaritans living in the West Bank have been granted passports by both Israel and the Palestinian Authority.\nCommunity survival.\nOne of the biggest problems facing the community today is the issue of continuity. With such a small population, divided into only four families or houses (Cohen, Tsedakah, Danafi, and Marhiv, with the Matar family dying out in 1968), and a general refusal to accept converts, it is common for Samaritans to marry within their extended families, even first cousins. There has been a history of genetic disorders within the group due to the small gene pool. To counter this, the Holon Samaritan community has allowed men from the community to marry non-Samaritan (primarily Israeli Jewish) women, provided that the women agree to follow Samaritan religious practices. There is a six-month trial period before officially joining the Samaritan community to see whether this is a commitment that the woman would like to take. This often poses a problem for the women, who are typically less than eager to adopt the strict interpretation of biblical (Levitical) laws regarding menstruation, by which they must live in a separate dwelling during their periods and after childbirth. There have been a few instances of intermarriage. In addition, all marriages within the Samaritan community are first approved by a geneticist at Tel HaShomer Hospital, in order to prevent the spread of genetic disorders. In meetings arranged by \"international marriage agencies\", a small number of women from Russia and Ukraine who agree to observe Samaritan religious practices have been allowed to marry into the Qiryat Luza Samaritan community in an effort to expand the gene pool. Polygamy is reported to have been practiced among Samaritans up until sometime in the 19th century. Today it is practically unheard of, due to the low availability of women and, among those Samaritans living within Israeli territory, it being illegal.\nThe Samaritan community in Israel also faces demographic challenges as some young people leave the community and convert to Judaism. A notable example is Israeli television presenter Sofi Tsedaka, who has made a documentary about her leaving the community at age 18.\nThe head of the community is the Samaritan High Priest, who is the 133rd generation since Ithamar, a son of Aaron the priest's line from 1624\u00a0CE onward; before then, the line of priesthood went through Elazar, son of Aaron the priest. The current high priest is Aabed-El ben Asher ben Matzliach who assumed the office on 19 April 2013. The High Priest of every generation is selected by the eldest in age from the priestly family and resides on Mount Gerizim.\nSamaritan origins of Palestinian Muslims in Nablus and its vicinity.\nMuch of the local Palestinian population of Nablus is believed to be descended from Samaritans who converted to Islam. Traditions of Samaritan ancestry were also recorded in villages in the vicinity, such as Hajjah. Even today, certain Nabulsi family names such as Al-Amad, Al-Samri, Maslamani, Yaish, and Shakhsheer among others, are associated with Samaritan ancestry. The Yaish family of Nablus, for example, is said to be descended from the Samaritan Mitawiyah family of the Tribe of Manasseh, founded by Mitwayyah, who himself descended from Magged, a person who lived in the 7th century.\nAccording to the historian Fayyad Altif, large numbers of Samaritans converted due to persecution under various Muslim rulers, and because the monotheistic nature of Islam made it easy for them to accept it. During the Abbasid period, economic hardships, social disorder, and pressure from Muslim attackers, drove many Samaritans to convert to Islam. Later, the al-Hakim Edict issued by the Fatimid Caliphate in 1021, ordering Jews and Christians in the Southern Levant to convert to Islam or leave, along with another forced conversion by the rebel ibn Fir\u0101sa, hastened the Samaritans' rapid decline and nearly led to their extinction as a distinct religious community. The Samaritans themselves describe the Ottoman period as the worst period in their modern history, as many Samaritan families were forced to convert to Islam during that time. As a result, the Samaritans decreased from nearly a million and a half in late Roman (Byzantine) times to 146 people by the end of the Ottoman period.\nSamaritan historian Benyamim Tsedaka noted that many Samaritans who converted to Islam retained their original surnames, passing them on to future generations. Consequently, in most villages with names of Hebrew origin, but altered by Arabic pronunciation, Arab families still bear the surnames of their Samaritan ancestors. In Nablus itself, he notes, some Muslims openly acknowledge their Samaritan ancestry. For instance, in 1968, Fatah militant Naser Sharshir suggested the possibility of having Samaritan blood in his lineage, tracing back to his great-grandfather.\nIn 1940, Israeli historian and future president Yitzhak Ben-Zvi wrote an article in which he stated that two thirds of the residents of Nablus and the surrounding neighboring villages were of Samaritan origin. He mentioned the name of several Palestinian Muslim families as having Samaritan origins, including the Al-Amad, Al-Samri, Buwarda and Kasem families, who protected Samaritans from Muslim persecution in the 1850s. Additionally, he wrote that these families had written records testifying to their Samaritan ancestry, which were maintained by their priests and elders.\nSamaritanism.\nSamaritanism is centered on the Samaritan Pentateuch, which Samaritans believe to be the original and unaltered version of the Torah that was given to Moses and the Israelites on Mount Sinai. The Samaritan Pentateuch contains some differences from the Masoretic version of the Torah used in Judaism; according to Samaritan tradition, key parts of the Jewish text were fabricated by Ezra. The Samaritan version of the Book of Joshua also differs from the Jewish version, which focuses on Shiloh. According to Samaritan tradition, Joshua built a temple (\"al-haikal\") on Mount Gerizim and placed therein a tabernacle (\"al-ma\u0161kan\") in the second year of the Israelites' entry into the land of Canaan.\nAccording to Samaritan scripture and tradition, Mount Gerizim, located near the Biblical city of Shechem (on the southern side of modern-day Nablus, West Bank), has been venerated as the holiest place for the Israelites since the conquest of Canaan by Joshua, long before the Temple in Jerusalem was established under Davidic and Solomonic rule over the United Kingdom of Israel. This view differs from Jewish belief which views the Temple Mount in Jerusalem as the holiest site in the world to worship God. It is commonly taught in Samaritan tradition that there are 13 references to Mount Gerizim in the Torah to prove their claim of holiness in contrast to Judaism, which relies solely on the later Jewish prophets and writings to back their claims of the holiness of Jerusalem.\nOther Samaritan tradition books include the \"Memar Marqah\" ('The teaching of Marqah'), the Samaritan liturgy known as \"the Defter\", and Samaritan law codes and biblical commentaries.\nSamaritans outside the Holy Land observe most Samaritan practices and rituals such as the Sabbath, ritual purity, and all festivals of Samaritanism with the exception of the Passover sacrifice, which can only be observed at Mount Gerizim.\nLocation of sacrifice.\nAccording to Samaritans, it was on Mount Gerizim that Abraham was commanded by God to offer his son Isaac as a sacrifice. God then causes the sacrifice to be interrupted, explaining that this was the ultimate test of Abraham's obedience, as a result of which all the world would be blessed.\nThe Torah mentions the place where God chooses to establish his name (Deuteronomy 12:5), and Judaism believes this refers to Jerusalem. In contrast, the Samaritan text speaks of the place where God has chosen to establish his name, and Samaritans identify it as Mount Gerizim, making it the focus of their spiritual values.\nThe legitimacy of the Judaic versus Samaritan belief was argued by Jewish scholar Andronicus ben Meshullam in the 2nd century BCE at the court of King Ptolemy VI Philometor.\nIn the New Testament, the Gospel of John describes an encounter between a Samaritan woman and Jesus. When the woman realizes that Jesus is the Messiah, she asks Him whether Mount Gerizim or Jerusalem is where God commanded Abraham to bind Isaac. Jesus affirms the Judaic belief, saying \"You [the Samaritans] worship what you do not know\", although he also says: \"a time is coming when you will worship the Father neither on this mountain nor in Jerusalem.\" (BSB)\nReligious beliefs.\nThe Samaritans have retained an offshoot of the Ancient Hebrew script, a High Priesthood, the slaughtering and eating of lambs on Passover eve, and the celebration of the first month's beginning around springtime as the New Year. Yom Teru'ah (the biblical name for \"Rosh Hashanah\"), at the beginning of Tishrei, is not considered a New Year as it is in Rabbinic Judaism. The Samaritan Pentateuch differs from the Jewish Masoretic Text as well. Some differences are doctrinal: for example, the Samaritan Torah explicitly states that Mount Gerizim is \"the place that God has chosen\" to establish his name, as opposed to the Jewish Torah that refers to \"the place that God chooses\". Other differences are minor and seem more or less accidental.\nRelationship to Rabbinic Judaism.\nSamaritans refer to themselves as \"Benai Yisrael\" (\"Children of Israel\"), which is a term used by all Jewish denominations as a name for the Jewish people as a whole. They, however, do not refer to themselves as \"Yehudim\" (literally \"Judeans\"), the standard Hebrew name for Jews.\nThe Talmudic attitude expressed in tractate Kutim is that they are to be treated as Jews in matters where their practice coincides with Rabbinic Judaism but as non-Jews where their practice differs. Some claim that since the 19th century, Rabbinic Judaism has regarded the Samaritans as a Jewish sect and the term \"Samaritan Jews\" has been used for them.\nReligious texts.\nSamaritan law is not the same as Halakha (Rabbinic Jewish law). The Samaritans have several groups of religious texts, which correspond to Jewish Halakha. A few examples of such texts are:\nChristian sources: New Testament.\nSamaria or Samaritans are mentioned in the New Testament books of Matthew, Luke, John and Acts. The Gospel of Mark contains no mention of Samaritans or Samaria. The best known reference to the Samaritans is the Parable of the Good Samaritan, found in the Gospel of Luke. The following references are found:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\nMedia"}
{"id": "28180", "revid": "50997834", "url": "https://en.wikipedia.org/wiki?curid=28180", "title": "Seneca Lake (New York)", "text": "Lake in New York, United States of America\nSeneca Lake is a Finger Lake in central New York state. Spanning four counties - Schuyler, Seneca, Yates, and Ontario - it is the largest of the eleven lake glacial chain, and the deepest glacial lake entirely within the state.\nSeneca Lake is long, has a surface area of , a maximum depth of over , and holds the most water of all the Finger Lakes (estimated at , roughly half that of the entire chain).\nSeneca is celebrated as the lake trout capital of the world and hosts the National Lake Trout Derby. Its significant depth and accessibility enable the US Navy to conduct testing and evaluation of range on equipment such as sonar. \nThe lake takes its name from the Seneca people, who inhabited the land until driven off it by westward colonial expansion. At the north end is the city of Geneva, home of Hobart and William Smith Colleges and the New York State Agricultural Experiment Station, a division of Cornell University. At the south end of the lake is the village of Watkins Glen, famed for auto racing (hosting Watkins Glen International racetrack) and waterfalls.\nSeneca Lake's unique macroclimate makes it home to over 50 wineries, many of them farm wineries, and is the location of the Seneca Lake AVA and the Seneca Lake wine trail.\nDescription.\nAt long, it is the second longest of the Finger Lakes and has the largest volume, estimated at , roughly half of the water in all the Finger Lakes. It has an average depth of , a maximum depth of , and a surface area of .\nFor comparison, Scotland's famous Loch Ness is long, wide, has a surface area of , an average depth of , a maximum depth of , and total volume of of water.\nSeneca's two main inlets are Catharine Creek at the southern end and the Keuka Lake Outlet. Seneca Lake drains into the Seneca River/ Cayuga-Seneca Canal, which joins Seneca and Cayuga Lakes at their northern ends.\nIt is fed by underground springs and replenished at a rate of per minute. These springs keep the water moving in a circular motion, giving it little chance to freeze over. Because of Seneca Lake's great depth temperature near the bottom remains remain a near-constant .\nEcology.\nSeneca lake has a typical aquatic population for large deep lakes in the northeast, with coldwater fish such as lake trout and Landlocked Atlantic salmon inhabiting the deeper waters, and warmwater fish such as smallmouth bass and yellow perch inhabiting shallower areas. The lake is also home to a robust population of \"sawbellies,\" the local term for alewife shad.\nHistory.\nSeneca Lake was formed at least two million years ago by glacial carving of streams and valleys. Originally it was a part of a series of rivers that flowed northward. Around this time many continental glaciers moved into the area and started the Pleistocene glaciation also known as the Ice Age. It is presumed that the Finger Lakes were created by many advances and retreats of massive glaciers that were up to thick.\nOver 200 years ago, there were Iroquois villages on Seneca Lake's surrounding hillsides. During the American Revolutionary War, their villages, including Kanadaseaga (\"Seneca Castle\"), were wiped out during the 1779 Sullivan Expedition.\nAfter the war, the Iroquois were forced to cede their land when Britain was defeated. Their millions of acres were sold and some lands in this area were granted to veterans of the army in payment for their military service. A slow stream of European-American settlers began to arrive circa 1790. Initially the settlers were without a market nearby or a way to get their crops to market. The settlers' isolation ended in 1825 with the opening of the Erie Canal.\nThe canal linked the Finger Lakes Region to the outside world. Steamships, barges and ferries quickly plied the lake. The earlier, short Crooked Lake Canal linked Seneca Lake to Keuka Lake.\nNumerous canal barges sank during operations and rest on the bottom of the lake. A collection of barges at the southwest end of the lake, near the village of Watkins Glen, are being preserved and made accessible for scuba diving by the Finger Lakes Underwater Preserve Association.\nRecreation.\nFishing.\nThe lake is a popular fishing destination. Fish species in the lake include lake trout, rainbow trout, brown trout, landlocked salmon, largemouth bass, smallmouth bass, northern pike, pickerel, and yellow perch.\nFolklore.\nSea serpent.\nIn July 1900, newspaper reports carried reports that on the evening of 14 July 1899, the steamboat Otetiani, carrying several dozen passengers, encountered a 25-foot-long sea monster with \"two rows of sharp, white teeth.\" The steamer is said to have given chase to the creature and deliberately rammed it at full speed. The creature was struck by the ship's paddle wheel midway between head and tail, it spine broken. It raised its four-foot-long head, then gave a gasp as it died. The ship attempted to rope the monster and tow it back to shore, but it sank to the bottom of Seneca Lake. A report sometime later in the \"Geneva Gazette\" suggested that the incident was a hoax.\nPainted rocks.\nHighly visible painted rocks located at the southern end of the lake on the eastern cliff face depicting an American flag, teepee, and several Native Americans painted in 1929 during the Sullivan Sesquicentennial, celebrating the 150th anniversary of the Sullivan Expedition that drove Native Americans off their land. They contain the errors that peoples in the Seneca Region used longhouses and not tee-pees, and is unfurled to the left, which is never portrayed that way for exhibition.\nSome older paintings located on the bottom of the cliff were done somewhat earlier, for tourists on Seneca Lake boat tours, who were given the mythology that they had been done in 1779 after the Senecas escaped from the Sullivan Campaign. Historian Barbara Bell, has cleared this up in her 2005 book.\nSeneca Guns.\nSeneca Lake is also the site of strange and currently unexplained cannon-like booms and shakes that are heard and felt in the surrounding area. They are known locally as the Seneca Guns, Lake Drums, or Lake Guns, and these types of phenomena are known elsewhere as skyquakes. The term \"lake guns\" originated in the short story \"The Lake Gun\" by James Fenimore Cooper in 1851. While there is no explanation that takes into account sounds the Iroquois heard before Cooper's time, it is possible sonic booms have been mistaken for natural sounds in modern days.\nSampson Navy and Air Force bases.\nThe east side of Seneca Lake was once home to Sampson Naval Base, a military training ground primarily used during World War II. It became Sampson Air Force Base during the Korean War and was used for basic training. After Sampson AFB closed, the airfield remained as Seneca Army Airfield until closed in 2000. The training grounds of Sampson have since been converted to a civilian picnic area called Sampson State Park.\nThe Naval Undersea Warfare Center (NUWC) Sonar test facility is a US Navy facility on the west side of the lake. A scale model of the sonar section of the nuclear submarine USS Seawolf (SSN 21) was tested during the ship's development, leading to its launch in June 1995.\nWater quality.\nThere is a YSI EMM-2500 Buoy Platform located in the north end of Seneca Lake roughly in the center. Its coordinates are: latitude: 42\u00b041'49.99\"N, longitude: 76\u00b055'29.93\"W. The buoy has cellular modem communications and measures wind speed and direction, relative humidity, air temperature, barometric pressure, light intensity, and the water's depth and temperature, conductivity, turbidity, and chlorophyll-a levels.\nThe buoy was initially deployed in June 2006. The water depth where it is located is about .\nOn June 30, 2022, the New York State Department of Environmental Conservation denied a request for an air permit for a natural gas power plant owned by Greenidge Generation, a bitcoin mining company, on the lake used for powering an 8,000-machine operation which the company argued had no legal basis and would challenge in court in a press statement.\nWine.\nViticulture and winemaking in the area date back to the 1866 foundation of the Seneca Lake Wine Company, the first major local winery. Modern wine production began in the 1970s with the establishment of several wineries and the passage of the New York Farm Winery Act of 1976. The region was established as an American Viticultural Area in 1988.\nThe Seneca Lake Wine Trail hosts many events on and around the lake, including the annual winter 'Deck the Halls' event showcasing local wineries' vintages.\nTransport.\nThe Elmira &amp; Seneca Lake Railway opened for operation on 19 June 1900 from Horseheads, New York, to Seneca Lake. An active railroad track still runs along the west side of the lake from Watkins Glen to Geneva and beyond, operated by Finger Lakes Railway.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28181", "revid": "24902", "url": "https://en.wikipedia.org/wiki?curid=28181", "title": "Strait of Gibraltar", "text": "Strait connecting the Atlantic to the Mediterranean\nThe Strait of Gibraltar, also known as the Straits of Gibraltar, is a narrow strait that connects the Atlantic Ocean to the Mediterranean Sea and separates Europe from Africa.\nThe two continents are separated by 7.7 nautical miles (14.2 kilometers, 8.9 miles) at its narrowest point. Ferries cross between the two continents every day in as little as 35 minutes. The Strait's depth ranges between .\nThe strait lies in the territorial waters of Morocco, Spain, and the British overseas territory of Gibraltar. Under the United Nations Convention on the Law of the Sea, foreign vessels and aircraft have the freedom of navigation and overflight to cross the strait of Gibraltar in case of continuous transit.\nNames and etymology.\nThe name comes from the Rock of Gibraltar, which in turn originates from the Arabic (meaning \"Tariq's Mount\"), named after Tariq ibn Ziyad. It is also known as the Straits of Gibraltar, the Gut of Gibraltar (although this is mostly archaic), the STROG (STRait Of Gibraltar) in naval use.\nAnother Arabic name is \"B\u0101b al-\"maghrib\"\" (), meaning \"Gate of the West\" or \"Gate of the sunset\", and furthermore \"Gate of the Maghreb\" or \"Gate of Morocco\". In the Middle Ages it was called in Arabic ( 'the Passage'), or ( 'the passage sea') and by the Romans (Strait of C\u00e1diz).\nIn Latin it has been called , based on the name from antiquity \"Pillars of Hercules\" (), referring to the mountains as pillars, such as Gibraltar, flanking the strait.\nLocation.\nOn the northern side of the Strait are Spain and Gibraltar (a British overseas territory in the Iberian Peninsula). On the southern side are Morocco and Ceuta (a Spanish autonomous city in northern Africa).\nDue to its location, the Strait is commonly used for illegal immigration from Africa to Europe.\nExtent.\nThe International Hydrographic Organization defines the limits of the Strait of Gibraltar as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nGeology.\nThe seabed of the Strait is composed of synorogenic Betic-Rif clayey flysch covered by Pliocene and/or Quaternary calcareous sediments, sourced from thriving cold water coral communities. Exposed bedrock surfaces, coarse sediments and local sand dunes attest to the strong bottom current conditions at the present time.\nAround 5.97\u00a0million years ago, the connection between the Mediterranean Sea and the Atlantic Ocean along the Betic and Rifan Corridor was progressively restricted until its total closure, effectively causing the salinity of the Mediterranean to rise periodically within the gypsum and salt deposition range, during what is known as the Messinian salinity crisis. In this water chemistry environment, dissolved mineral concentrations, temperature and stilled water currents combined and occurred regularly to precipitate many mineral salts in layers on the seabed. The resultant accumulation of various huge salt and mineral deposits about the Mediterranean basin are directly linked to this era. It is believed that this process took a short time, by geological standards, lasting around 640,000 years.\nIt is estimated that, were the Strait closed even at today's higher sea level, most water in the Mediterranean basin would evaporate within a thousand years, as it is believed to have done then, and such an event would lay down mineral deposits like the salt deposits now found under the sea floor all over the Mediterranean.\nAfter a lengthy period of restricted intermittent or no water exchange between the Atlantic Ocean and Mediterranean basin, approximately 5.33 million years ago, the Atlantic\u2013Mediterranean connection was completely reestablished through the Strait of Gibraltar by the Zanclean flood, and has remained open ever since. The erosion produced by the incoming waters seems to be the main cause for the present depth of the Strait ( at the narrows, at the Camarinal Sill). The Strait is expected to close again as the African Plate moves northward relative to the Eurasian Plate, but on geological rather than human timescales.\nBiodiversity.\nThe Strait has been identified as an Important Bird Area by BirdLife International because of the hundreds of thousands of seabirds which use it every year to migrate between the Mediterranean and the Atlantic, including significant numbers of Scopoli's and Balearic shearwaters, Audouin's and lesser black-backed gulls, razorbills, and Atlantic puffins.\nA resident orca pod of some 36 individuals lives around the Strait, one of the few that are left in Western European waters. The pod may be facing extinction in the coming decades due to long term effects of PCB pollution.\nHistory.\nEvidence of the first human habitation of the area by Neanderthals dates back to 125,000 years ago. It is believed that the Rock of Gibraltar may have been one of the last outposts of Neanderthal habitation in the world, with evidence of their presence there dating to as recently as 24,000 years ago. Archaeological evidence of \"Homo sapiens\" habitation of the area dates back c.\u200940,000 years.\nThe relatively short distance between the two shores has served as a quick crossing point for various groups and civilizations throughout history, including Carthaginians campaigning against Rome, Romans travelling between the provinces of Hispania and Mauritania, Vandals raiding south from Germania through Western Rome and into North Africa in the 5th century, Moors and Berbers in the 8th\u201311th centuries, and Spain and Portugal in the 16th century.\nBeginning in 1492, the Strait began to play a certain cultural role in acting as a barrier against cross-channel conquest and the flow of culture and language that would naturally follow such a conquest. In that year, the last Muslim government north of the Strait was overthrown by a Spanish force. Since that time, the Strait has come to foster the development of two very distinct and varied cultures on either side of it after sharing much the same culture for over 500 years from the 8th century to the early 13th century.\nOn the northern side, Christian-European culture has remained dominant since the expulsion of the last Muslim kingdom in 1492, along with the Romance Spanish language, while on the southern side, Muslim-Arabic/Mediterranean has been dominant since the spread of Islam into North Africa in the 700s, along with the Arabic language.\nThe small British enclave of the city of Gibraltar presents a third cultural group found in the Strait. This enclave was ceded in perpetuity to Britain in the Peace of Utrecht. Gibraltar has since been used by the United Kingdom to act as a surety for control of the sea lanes into and out of the Mediterranean.\nFollowing the Spanish coup of July 1936 the Spanish Republican Navy tried to blockade the Strait of Gibraltar to hamper the transport of Army of Africa troops from Spanish Morocco to Peninsular Spain. On 5 August 1936 the so-called Convoy de la Victoria was able to bring at least 2,500 men across the Strait, breaking the republican blockade.\nCommunications.\nThe Strait is an important shipping route from the Mediterranean to the Atlantic. Ferries operate between Spain and Morocco across the Strait, as well as between Spain and Ceuta and Gibraltar to Tangier. Proposals exist for a Strait of Gibraltar crossing by bridge or tunnel.\nTunnel across the Strait.\nDiscussion between Spain and Morocco of a tunnel under the strait began in the 1980s. In December 2003, both countries agreed to explore the construction of an undersea rail tunnel to connect their rail systems across the Strait. The gauge of the rail would be to match the proposed construction and conversion of significant parts of the existing broad gauge system to standard gauge. While the project remained in a planning phase, Spanish and Moroccan officials met to discuss it occasionally, including in 2012. Those talks led to nothing constructive happening, but in April 2021 ministers from both countries agreed to a joint intergovernmental meeting to be held in Casablanca in the coming months. This was in order to resume discussions on a tunnel. Earlier, in January 2021, the UK government had studied plans for a tunnel to link Gibraltar with Tangiers that would replace the Spanish-Moroccan project that until then had had no tangible results after over 40 years of discussions.\nSpecial flow and wave patterns.\nThe Strait of Gibraltar links the Atlantic Ocean directly to the Mediterranean Sea. This direct linkage creates certain unique flow and wave patterns. These unique patterns are created due to the interaction of various regional and global evaporative forces, water temperatures, tidal forces, and wind forces.\nInflow and outflow.\nWater flows through the Strait more or less continuously, both eastwards and westwards. A smaller amount of deeper, saltier and therefore denser waters continually flow westwards (the Mediterranean outflow), while a larger amount of surface waters with lower salinity and density continually flow eastwards (the Mediterranean inflow). These general flow tendencies may be occasionally interrupted for brief periods by temporary tidal flows, depending on various lunar and solar alignments. The balance of the water flow is eastwards, since the evaporation rate within the Mediterranean basin is higher than the combined inflow of all the rivers that empty into it, plus the total precipitation of rain or snow that falls on it. At the Strait's far western end is the Camarinal Sill, the Strait's shallowest point which limits mixing between the cold, less saline Atlantic water and the warmer, more saline Mediterranean waters.\nThe Mediterranean waters are so much saltier than the Atlantic waters that they sink below the constantly incoming water and form a highly saline (\"thermohaline\", both warm and salty) layer of bottom water. This layer of bottom-water constantly works its way out into the Atlantic as the Mediterranean outflow. On the Atlantic side of the Strait, a density boundary separates the Mediterranean outflow waters from the rest at about depth. These waters flow out and down the continental slope, losing salinity, until they begin to mix and equilibrate more rapidly, much farther out at a depth of about . The Mediterranean outflow water layer can be traced for thousands of kilometres west of the Strait, before completely losing its identity.\nDuring the Second World War, German U-boats used the currents to pass into the Mediterranean Sea without detection, by maintaining silence with engines off. From September 1941 to May 1944 Germany managed to send 62 U-boats into the Mediterranean. All these boats had to navigate the British-controlled Strait of Gibraltar where nine U-boats were sunk while attempting passage and 10 more had to break off their run due to damage.\nInternal waves.\nInternal waves (waves at the density boundary layer) are often produced by the Strait. Like traffic merging on a highway, the water flow is constricted in both directions because it must pass over the Camarinal Sill. When large tidal flows enter the Strait and the high tide relaxes, internal waves are generated at the Camarinal Sill and proceed eastwards. Even though the waves may occur down to great depths, occasionally the waves are almost imperceptible at the surface, at other times they can be seen clearly in satellite imagery. These \"internal waves\" continue to flow eastward and to refract around coastal features. They can sometimes be traced for as much as , and sometimes create interference patterns with refracted waves.\nTerritorial waters.\nExcept for its far eastern end, the Strait lies within the territorial waters of Spain and Morocco. The United Kingdom claims around Gibraltar on the northern side of the Strait, putting part of it inside British territorial waters. As this is less than the maximum, it means, according to the British claim, that part of the Strait lies in international waters. The ownership of Gibraltar and its territorial waters is disputed by Spain. Similarly, Morocco disputes Spanish sovereignty over Ceuta on the southern coast. There are several islets, such as the disputed Isla Perejil, that are claimed by both Morocco and Spain.\nUnder the United Nations Convention on the Law of the Sea, vessels passing through the strait do so under the regime of transit passage, rather than the more limited innocent passage allowed in most territorial waters. Therefore, a vessel or aircraft has the freedom of navigation or overflight for the purpose of crossing the strait of Gibraltar.\nPower generation.\nSome studies have proposed the possibility of erecting tidal power generating stations within the Strait, to be powered from the predictable current at the Strait.\nIn the 1920s and 1930s, the Atlantropa project proposed damming the Strait to generate large amounts of electricity and lower the sea level of the Mediterranean by several hundreds of meters to create large new lands for settlement. This proposal would however have devastating effects on the local climate and ecology and would dramatically change the strength of the West African Monsoon.\nHistory of Strait crossings.\nSome adventurers crossed the Strait of Gibraltar by swimming, powered paragliding and paddleboarding.\nBy swimming.\nMercedes Gleitze was the first known person to swim across the Strait of Gibraltar on 6 April 1928. It took her 12 hours and 50 minutes to cross the stretch of water. This was her sixth attempt to swim the Strait of Gibraltar, her first having been made in December 1927.\nBy powered paraglider.\nFrancesco Stipo was the first known person to cross the Strait of Gibraltar with a powered paraglider on 11 July 1995.\nAccording to Spanish newspaper Europa Sur, Stipo crossed the Strait from Tarifa to Ceuta in less than one hour, followed by the Red Cross boat \"Salvamar Tarifa\", and landed on a street near the Port of Ceuta.\nBy stand up paddleboard.\nChris Ziaja and Nik Benner were the first known people to cross the Strait of Gibraltar with a stand up paddleboard on 4 October 2010. They set out from Punta Carnero and reached Ceuta four and a half hours later.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28182", "revid": "49402000", "url": "https://en.wikipedia.org/wiki?curid=28182", "title": "Social epistemology", "text": "Field of study in analytic philosophy\nSocial epistemology refers to a broad set of approaches that can be taken in epistemology (the study of knowledge) that construes human knowledge as a collective achievement. Another way of characterizing social epistemology is as the evaluation of the social dimensions of knowledge or information. \nAs a field of inquiry in analytic philosophy, social epistemology deals with questions about knowledge in social contexts, meaning those in which knowledge attributions cannot be explained by examining individuals in isolation from one another. The most common topics discussed in contemporary social epistemology are testimony (e.g. \"When does a belief that x is true which resulted from being told 'x is true' constitute knowledge?\"), peer disagreement (e.g. \"When and how should I revise my beliefs in light of other people holding beliefs that contradict mine?\"), and group epistemology (e.g. \"What does it mean to attribute knowledge to groups rather than individuals, and when are such knowledge attributions appropriate?\"). Social epistemology also examines the social justification of belief.\nOne of the enduring difficulties with defining \"social epistemology\" that arises is the attempt to determine what the word \"knowledge\" means in this context. There is also a challenge in arriving at a definition of \"social\" which satisfies academics from different disciplines. Social epistemologists may exist working in many of the disciplines of the humanities and social sciences, most commonly in philosophy and sociology. In addition to marking a distinct movement in traditional and analytic epistemology, social epistemology is associated with the interdisciplinary field of science and technology studies (STS).\nHistory of the term.\nThe consideration of social dimensions of knowledge in relation to philosophy started in 380 B.C.E with Plato\u2019s dialogue: \"Charmides\". This dialogue included Socrates' argument about whether anyone is capable of examining if another man's claim that he knows something, is true or not. In it he questions the degree of certainty an unprofessional in a field can have towards a person\u2019s claim to be a specialist in that same field. Charmides also explored the tendency of the utopian vision of social relations to degenerate into dystopian fantasy. As the exploration of a dependence on authoritative figures constitutes a part of the study of social epistemology, it confirms the existence of the ideology in minds long before it was given its label. \nIn 1936, Karl Mannheim turned Karl Marx\u2018s theory of ideology (which interpreted the \u201csocial\u201d aspect in epistemology to be of a political or sociological nature) into an analysis of how the human society develops and functions in this respect. Particularly, this Marxist analysis prompted Mannheim to write Ideology and Utopia, which investigated the classical sociology of knowledge and the construct of ideology. \nThe term \u201csocial epistemology\u201d was first coined by the library scientists Margaret Egan. and Jesse Shera in a Library Quarterly paper at the University of Chicago Graduate Library School in the 1950s. The term was used by Robert K. Merton in a 1972 article in the American Journal of Sociology and then by Steven Shapin in 1979. However, it was not until the 1980s that the current sense of \u201csocial epistemology\u201d began to emerge. \nThe rise of social epistemology.\nIn the 1980s, there was a powerful growth of interest amongst philosophers in topics such as epistemic value of testimony, the nature and function of expertise, proper distribution of cognitive labor and resources among individuals in the communities and the status of group reasoning and knowledge.\nIn 1987, the philosophical journal \"Synthese\" published a special issue on social epistemology which included two authors that have since taken the branch of epistemology in two divergent directions: Alvin Goldman and Steve Fuller. Fuller founded a journal called \"Social Epistemology: A journal of knowledge, culture, and policy\" in 1987 and published his first book, \"Social Epistemology\", in 1988. Goldman\u2019s \"Knowledge in a Social World\" came out in 1999. Goldman advocates for a type of epistemology which is sometimes called \u201cveritistic epistemology\u201d because of its large emphasis on truth. This type of epistemology is sometimes seen to side with \u201cessentialism\u201d as opposed to \u201cmulticulturalism\u201d. But Goldman has argued that this association between veritistic epistemology and essentialism is not necessary. He describes Social Epistemology as knowledge derived from one\u2019s interactions with another person, group or society. \nGoldman looks into one of the two strategies of the socialization of epistemology. This strategy includes the evaluation of social factors that impact knowledge formed on true belief. In contrast, Fuller takes preference for the second strategy that defines knowledge influenced by social factors as collectively accepted belief. The difference between the two can be simplified with exemplars e.g.: the first strategy means analyzing how your degree of wealth (a social factor) influences what information you determine to be valid whilst the second strategy occurs when an evaluation is done on wealth\u2019s influence upon your knowledge acquired from the beliefs of the society in which you find yourself.\nFuller's position supports the conceptualization that social epistemology is a critique of context, particularly in his approach to \"knowledge society\" and the \"university\" as integral contexts of modern learning. It is said that this articulated a reformulation of the Duhem-Quine thesis, which covers the underdetermination of theory by data. It explains that the problem of context will assume this form: \"knowledge is determined by its context\". In 2012, on the occasion of the 25th anniversary of \"Social Epistemology\", Fuller reflected upon the history and the prospects of the field, including the need for social epistemology to re-connect with the larger issues of knowledge production first identified by Charles Sanders Peirce as \u2018\u2019cognitive economy\u2019\u2019 and nowadays often pursued by library and information science. As for the \u201canalytic social epistemology\u201d, to which Goldman has been a significant contributor, Fuller concludes that it has \u201cfailed to make significant progress owing, in part, to a minimal understanding of actual knowledge practices, a minimised role for philosophers in ongoing inquiry, and a focus on maintaining the status quo of epistemology as a field.\u201d\nKuhn, Foucault, and the sociology of scientific knowledge.\nThe basic view of knowledge that motivated the emergence of social epistemology as it is perceived today can be traced to the work of Thomas Kuhn and Michel Foucault, which gained acknowledgment at the end of the 1960s. Both brought historical concerns directly to bear on problems long associated with the philosophy of science. Perhaps the most notable issue here was the nature of truth, which both Kuhn and Foucault described as a relative and contingent notion. On this background, ongoing work in the sociology of scientific knowledge (SSK) and the history and philosophy of science (HPS) was able to assert its epistemological consequences, leading most notably to the establishment of the strong programme at the University of Edinburgh. In terms of the two strands of social epistemology, Fuller is more sensitive and receptive to this historical trajectory (if not always in agreement) than Goldman, whose \u201cveritistic\u201d social epistemology can be reasonably read as a systematic rejection of the more extreme claims associated with Kuhn and Foucault.\nSocial epistemology as a field.\nIn the standard sense of the term today, social epistemology is a field within analytic philosophy. It focuses on the social aspects of how knowledge is created and disseminated. What precisely these social aspects are, and whether they have beneficial or detrimental effects upon the possibilities to create, acquire and spread knowledge is a subject of continuous debate. The most common topics discussed in contemporary social epistemology are testimony (e.g. \"When does a belief that 'x is true' which resulted from being told that 'x is true' constitute knowledge?\"), peer disagreement (e.g. \"When and how should I revise my beliefs in light of other people holding beliefs that contradict mine?\"), and group epistemology (e.g. \"What does it mean to attribute knowledge to groups rather than individuals, and when are such knowledge attributions appropriate?\").\nWithin the field, \"the social\" is approached in two complementary and not mutually exclusive ways: \"the social\" character of knowledge can either be approached through inquiries in \"inter-individual\" epistemic relations or through inquiries focusing on epistemic \"communities\". The inter-individual approach typically focuses on issues such as testimony, epistemic trust as a form of trust placed by one individual in another, epistemic dependence, epistemic authority, etc. The community approach typically focuses on issues such as community standards of justification, community procedures of critique, diversity, epistemic justice, and collective knowledge.\nSocial epistemology as a field within analytic philosophy has close ties to, and often overlaps with philosophy of science. While parts of the field engage in abstract, normative considerations of knowledge creation and dissemination, other parts of the field are \"naturalized epistemology\" in the sense that they draw on empirically gained insights---which could mean natural science research from, e.g., cognitive psychology, be that qualitative or quantitative social science research. (For the notion of \"naturalized epistemology\" see Willard Van Orman Quine.) And while parts of the field are concerned with analytic considerations of rather general character, case-based and domain-specific inquiries in, e.g., knowledge creation in collaborative scientific practice, knowledge exchange on online platforms or knowledge gained in learning institutions play an increasing role.\nImportant academic journals for social epistemology as a field within analytic philosophy are, e.g., \"Episteme\", \"Social Epistemology\", and \"Synthese\". However, major works within this field are also published in journals that predominantly address philosophers of science and psychology or in interdisciplinary journals which focus on particular domains of inquiry (such as, e.g., \"Ethics and Information Technology\").\nPresent and future concerns.\nIn both stages, both varieties of social epistemology remain largely \"academic\" or \"theoretical\" projects. Yet both emphasize the social significance of knowledge and therefore the cultural value of social epistemology itself. A range of journals publishing social epistemology welcome papers that include a policy dimension. \nMore practical applications of social epistemology can be found in the areas of library science, academic publishing, guidelines for scientific authorship and collaboration, knowledge policy and debates over the role of the Internet in knowledge transmission and creation.\nSocial epistemology is still considered a relatively new addition to philosophy, with its problems and theories still fresh and in rapid movement. Of increasing importance is social epistemology developments within transdisciplinarity as manifested by media ecology.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28184", "revid": "5846", "url": "https://en.wikipedia.org/wiki?curid=28184", "title": "Sound card", "text": "Expansion card that provides input and output of audio signals\nA sound card (also known as an audio card) is an internal expansion card that provides input and output of audio signals to and from a computer under the control of computer programs. The term \"sound card\" is also applied to external audio interfaces used for professional audio applications.\nSound functionality can also be integrated into the motherboard, using components similar to those found on plug-in cards. The integrated sound system is often still referred to as a \"sound card\". Sound processing hardware is also present on modern video cards with HDMI to output sound along with the video using that connector; previously they used a S/PDIF connection to the motherboard or sound card.\nTypical uses of sound cards or sound card functionality include providing the audio component for multimedia applications such as music composition, editing video or audio, presentation, education and entertainment (games) and video projection. Sound cards are also used for computer-based communication such as voice over IP and teleconferencing.\nGeneral characteristics.\nSound cards use a digital-to-analog converter (DAC), which converts recorded or generated digital signal data into an analog format. The output signal is connected to an amplifier, headphones, or external device using standard interconnects, such as a TRS phone connector.\nA common external connector is the microphone connector. Input through a microphone connector can be used, for example, by speech recognition or voice over IP applications. Most sound cards have a line in connector for an analog input from a sound source that has higher voltage levels than a microphone. In either case, the sound card uses an analog-to-digital converter (ADC) to digitize this signal.\nSome cards include a sound chip to support the production of synthesized sounds, usually for real-time generation of music and sound effects using minimal data and CPU time.\nThe card may use direct memory access to transfer the samples to and from main memory, from where a recording and playback software may read and write it to the hard disk for storage, editing, or further processing.\nSound channels and polyphony.\nAn important sound card characteristic is polyphony, which refers to its ability to process and output multiple independent voices or sounds simultaneously. These distinct channels are seen as the number of audio outputs, which may correspond to a speaker configuration such as 2.0 (stereo), 2.1 (stereo and sub woofer), 5.1 (surround), or other configurations. Sometimes, the terms \"voice\" and \"channel\" are used interchangeably to indicate the degree of polyphony, not the output speaker configuration. For example, much older sound chips could accommodate three voices, but only one output audio channel (i.e., a single mono output), requiring all voices to be mixed together. Later cards, such as the AdLib sound card, had a 9-voice polyphony combined in 1 mono output channel.\nEarly PC sound cards had multiple FM synthesis voices (typically 9 or 16) which were used for MIDI music. The full capabilities of advanced cards are often not fully used; only one (mono) or two (stereo) voice(s) and channel(s) are usually dedicated to playback of digital sound samples, and playing back more than one digital sound sample usually requires a software downmix at a fixed sampling rate. Modern low-cost integrated sound cards (i.e., those built into motherboards) such as audio codecs like those meeting the AC'97 standard and even some lower-cost expansion sound cards still work this way. These devices may provide more than two sound output channels (typically 5.1 or 7.1 surround sound), but they usually have no actual hardware polyphony for either sound effects or MIDI reproduction\u00a0\u2013 these tasks are performed entirely in software. This is similar to the way inexpensive softmodems perform modem tasks in software rather than in hardware.\nIn the early days of wavetable synthesis, some sound card manufacturers advertised polyphony solely on the MIDI capabilities alone. In this case, typically, the card is only capable of two channels of digital sound and the polyphony specification solely applies to the number of MIDI instruments the sound card is capable of producing at once.\nModern sound cards may provide more flexible \"audio accelerator\" capabilities which can be used in support of higher levels of polyphony or other purposes such as hardware acceleration of 3D sound, positional audio and real-time DSP effects.\nList of sound card standards.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nColor codes.\nConnectors on the sound cards are color-coded as per the PC System Design Guide. They may also have symbols of arrows, holes and soundwaves that are associated with each jack position.\nHistory of sound cards for the IBM PC architecture.\nSound cards for IBM PC\u2013compatible computers were very uncommon until 1988. For the majority IBM PC users, the internal PC speaker was the only way for early PC software to produce sound and music. The speaker hardware was typically limited to square waves. The resulting sound was generally described as \"beeps and boops\" which resulted in the common nickname \"beeper\". Several companies, most notably Access Software, developed techniques for digital sound reproduction over the PC speaker like RealSound. The resulting audio, while functional, suffered from the heavily distorted output and low volume, and usually required all other processing to be stopped while sounds were played. Other home computers of the 1980s like the Commodore 64 included hardware support for digital sound playback or music synthesis, leaving the IBM PC at a disadvantage when it came to multimedia applications. Early sound cards for the IBM PC platform were not designed for gaming or multimedia applications, but rather on specific audio applications, such as music composition with the AdLib Personal Music System, IBM Music Feature Card, and Creative Music System, or on speech synthesis like Digispeech \"DS201\", Covox Speech Thing, and Street Electronics \"Echo\".\nIn 1988, a panel of computer-game CEOs stated at the Consumer Electronics Show that the PC's limited sound capability prevented it from becoming the leading home computer, that it needed a $49\u201379 sound card with better capability than current products, and that once such hardware was widely installed, their companies would support it. Sierra On-Line, which had pioneered supporting EGA and VGA video, and 3-1/2\" disks, promised that year to support the AdLib, IBM Music Feature, and Roland MT-32 sound cards in its games. A 1989 \"Computer Gaming World\" survey found that 18 of 25 game companies planned to support AdLib, six Roland and Covox, and seven Creative Music System/Game Blaster.\nHardware manufacturers.\nOne of the first manufacturers of sound cards for the IBM PC was AdLib, which produced a card based on the Yamaha YM3812 sound chip, also known as the OPL2. The AdLib had two modes: A 9-voice mode where each voice could be fully programmed, and a less frequently used \"percussion\" mode with 3 regular voices producing 5 independent percussion-only voices for a total of 11.\nCreative Labs also marketed a sound card called the Creative Music System (C/MS) at about the same time. Although the C/MS had twelve voices to AdLib's nine and was a stereo card while the AdLib was mono, the basic technology behind it was based on the Philips SAA1099 chip which was essentially a square-wave generator. It sounded much like twelve simultaneous PC speakers would have except for each channel having amplitude control, and failed to sell well, even after Creative renamed it the Game Blaster a year later, and marketed it through RadioShack in the US. The Game Blaster retailed for under $100 and was compatible with many popular games, such as Silpheed.\nA large change in the IBM PC-compatible sound card market happened when Creative Labs introduced the Sound Blaster card. Recommended by Microsoft to developers creating software based on the Multimedia PC standard, the Sound Blaster cloned the AdLib and added a sound coprocessor for recording and playback of digital audio. The card also included a game port for adding a joystick, and the capability to interface to MIDI equipment using the game port and a special cable. With AdLib compatibility and more features at nearly the same price, most buyers chose the Sound Blaster. It eventually outsold the AdLib and dominated the market.\nRoland also made sound cards in the late 1980s such as the MT-32 and LAPC-I. Roland cards sold for hundreds of dollars. Many games, such as Silpheed and Police Quest II, had music written for their cards. The cards were often poor at sound effects such as laughs, but for music were by far the best sound cards available until the mid-nineties. Some Roland cards, such as the SCC, and later versions of the MT-32 were made to be less expensive.\nBy 1992, one sound card vendor advertised that its product was \"Sound Blaster, AdLib, Disney Sound Source and Covox Speech Thing Compatible!\" Responding to readers complaining about an article on sound cards that unfavorably mentioned the Gravis Ultrasound, \"Computer Gaming World\" stated in January 1994 that, \"The de facto standard in the gaming world is Sound Blaster compatibility ... It would have been unfair to have recommended anything else.\" The magazine that year stated that \"Wing Commander II\" was \"Probably the game responsible\" for making it the standard card. The Sound Blaster line of cards, together with the first inexpensive CD-ROM drives and evolving video technology, ushered in a new era of multimedia computer applications that could play back CD audio, add recorded dialogue to video games, or even reproduce full motion video (albeit at much lower resolutions and quality in early days). The widespread decision to support the Sound Blaster design in multimedia and entertainment titles meant that future sound cards such as Media Vision's Pro Audio Spectrum and the Gravis Ultrasound had to be Sound Blaster compatible if they were to sell well. Until the early 2000s, when the AC'97 audio standard became more widespread and eventually usurped the SoundBlaster as a standard due to its low cost and integration into many motherboards, Sound Blaster compatibility was a standard that many other sound cards supported to maintain compatibility with many games and applications released.\nIndustry adoption.\nWhen game company Sierra On-Line opted to support add-on music hardware in addition to built-in hardware such as the PC speaker and built-in sound capabilities of the IBM PCjr and Tandy 1000, what could be done with sound and music on the IBM PC changed dramatically. Two of the companies Sierra partnered with were Roland and AdLib, opting to produce in-game music for King's Quest 4 that supported the MT-32 and AdLib Music Synthesizer. The MT-32 had superior output quality, due in part to its method of sound synthesis as well as built-in reverb. Since it was the most sophisticated synthesizer they supported, Sierra chose to use most of the MT-32's custom features and unconventional instrument patches, producing background sound effects (e.g., chirping birds, clopping horse hooves, etc.) before the Sound Blaster brought digital audio playback to the PC. Many game companies also supported the MT-32, but supported the Adlib card as an alternative because of the latter's higher market base. The adoption of the MT-32 led the way for the creation of the MPU-401, Roland Sound Canvas and General MIDI standards as the most common means of playing in-game music until the mid-1990s.\nFeature evolution.\nEarly ISA bus sound cards were half-duplex, meaning they could not record and play digitized sound simultaneously. Later, ISA cards like the SoundBlaster AWE series and Plug-and-play Soundblaster clones supported simultaneous recording and playback, but at the expense of using up two IRQ and DMA channels instead of one. Conventional PCI bus cards generally do not have these limitations and are mostly full-duplex.\nSound cards have evolved in terms of digital audio sampling rate (starting from 8-bit 11025 Hz, to 32-bit, 192 kHz that the latest solutions support). Along the way, some cards started offering wavetable synthesis, which provides superior MIDI synthesis quality relative to the earlier Yamaha OPL based solutions, which uses FM synthesis. Some higher-end cards (such as Sound Blaster AWE32, Sound Blaster AWE64 and Sound Blaster Live!) introduced their own RAM and processor for user-definable sound samples and MIDI instruments as well as to offload audio processing from the CPU. Later, the integrated audio (AC'97 and later HD Audio) prefer the use of a software MIDI synthesizer, for example, Microsoft GS Wavetable SW Synth in Microsoft Windows.\nWith some exceptions, for years, sound cards, most notably the Sound Blaster series and their compatibles, had only one or two channels of digital sound. Early games and MOD-players needing more channels than a card could support had to resort to mixing multiple channels in software. Even today, the tendency is still to mix multiple sound streams in software, except in products specifically intended for gamers or professional musicians.\nCrippling of features.\nAs of 2024, sound cards are not commonly programmed with the audio loopback systems commonly called \"stereo mix\", \"wave out mix\", \"mono mix\" or \"what u hear\", which previously allowed users to digitally record output otherwise only accessible to speakers.\nLenovo and other manufacturers fail to implement the feature in hardware, while other manufacturers disable the driver from supporting it. In some cases, loopback can be reinstated with driver updates. Alternatively, software such as virtual audio cable applications can be purchased to enable the functionality. According to Microsoft, the functionality was hidden by default in Windows Vista to reduce user confusion, but is still available, as long as the underlying sound card drivers and hardware support it. \nUltimately, the user can use the analog loophole and connect the line out directly to the line in on the sound card. However, in laptops, manufacturers have gradually moved from providing 3 separate jacks with TRS connectors\u00a0\u2013 usually for line in, line out/headphone out and microphone\u00a0\u2013 into just a single combo jack with TRRS connector that combines inputs and outputs.\nOutputs.\nThe number of physical sound channels has also increased. The first sound card solutions were mono. Stereo sound was introduced in the early 1980s, and quadraphonic sound came in 1989. This was shortly followed by 5.1 channel audio. The latest sound cards support up to 8 audio channels for the 7.1 speaker setup.\nA few early sound cards had sufficient power to drive unpowered speakers directly\u00a0\u2013 for example, two watts per channel. With the popularity of amplified speakers, sound cards no longer have a power stage, though in many cases they can adequately drive headphones.\nProfessional sound cards.\nProfessional sound cards are sound cards optimized for high-fidelity, low-latency multichannel sound recording and playback. Their drivers usually follow the Audio Stream Input/Output protocol for use with professional sound engineering and music software.\nProfessional sound cards are usually described as \"audio interfaces\", and sometimes have the form of external rack-mountable units using USB, FireWire, or an optical interface, to offer sufficient data rates. The emphasis in these products is, in general, on multiple input and output connectors, direct hardware support for multiple input and output sound channels, as well as higher sampling rates and fidelity as compared to the usual consumer sound card.\nOn the other hand, certain features of consumer sound cards such as support for 3D audio, hardware acceleration in video games, or real-time ambiance effects are secondary, nonexistent or even undesirable in professional audio interfaces.\nThe typical consumer-grade sound card is intended for generic home, office, and entertainment purposes with an emphasis on playback and casual use, rather than catering to the needs of audio professionals. In general, consumer-grade sound cards impose several restrictions and inconveniences that would be unacceptable to an audio professional. Consumer sound cards are also limited in the \"effective\" sampling rates and bit depths they can actually manage and have lower numbers of less flexible input channels. Professional studio recording use typically requires more than the two channels that consumer sound cards provide, and more accessible connectors, unlike the variable mixture of internal\u2014and sometimes virtual\u2014and external connectors found in consumer-grade sound cards.\nSound devices other than expansion cards.\nIntegrated sound hardware on PC motherboards.\nIn 1984, the first IBM PCjr had a rudimentary 3-voice sound synthesis chip (the SN76489) which was capable of generating three square-wave tones with variable amplitude, and a pseudo-white noise channel that could generate primitive percussion sounds. The Tandy 1000, initially a clone of the PCjr, duplicated this functionality, with the Tandy 1000 TL/SL/RL models adding digital sound recording and playback capabilities. Many games during the 1980s that supported the PCjr's video standard (described as \"Tandy-compatible\", \"Tandy graphics\", or \"TGA\") also supported PCjr/Tandy 1000 audio.\nIn the late 1990s, many computer manufacturers began to replace plug-in sound cards with an audio codec chip (a combined audio AD/DA-converter) integrated into the motherboard. Many of these used Intel's AC'97 specification. Others used inexpensive ACR slot accessory cards.\nFrom around 2001, many motherboards incorporated full-featured sound cards, usually in the form of a custom chipset, providing something akin to full Sound Blaster compatibility and relatively high-quality sound. However, these features were dropped when AC'97 was superseded by Intel's HD Audio standard, which was released in 2004, again specified the use of a codec chip, and slowly gained acceptance. As of 2011, most motherboards have returned to using a codec chip, albeit an HD Audio compatible one, and the requirement for Sound Blaster compatibility relegated to history.\nIntegrated sound on other platforms.\nMany home computers have their own motherboard-integrated sound devices: Commodore 64, Amiga, PC-88, FM-7, FM Towns, Sharp X1, X68000, BBC Micro, Electron, Archimedes, Atari 8-bit computers, Atari ST, Atari Falcon, Amstrad CPC, later revisions of the ZX Spectrum, MSX, Mac, and Apple IIGS. Workstations from Sun, Silicon Graphics and NeXT do as well. In some cases, most notably in those of the Macintosh, IIGS, Amiga, C64, SGI Indigo, X68000, MSX, Falcon, Archimedes, FM-7 and FM Towns, they provide very advanced capabilities (as of the time of manufacture), in others they are only minimal capabilities. Some of these platforms have also had sound cards designed for their bus architectures that cannot be used in a standard PC.\nSeveral Japanese computer platforms, including the MSX, X1, X68000, FM Towns and FM-7, have built-in FM synthesis sound from Yamaha by the mid-1980s. By 1989, the FM Towns computer platform featured built-in PCM sample-based sound and supported the CD-ROM format.\nThe custom sound chip on Amiga, named Paula, has four digital sound channels (2 for the left speaker and 2 for the right) with 8-bit resolution for each channel and a 6-bit volume control per channel. Sound playback on Amiga was done by reading directly from the chip RAM without using the main CPU.\nMost arcade video games have integrated sound chips. In the 1980s it was common to have a separate microprocessor for handling communication with the sound chip.\nSound cards on other platforms.\nThe earliest known sound card used by computers was the Gooch Synthetic Woodwind, a music device for PLATO terminals, and is widely hailed as the precursor to sound cards and MIDI. It was invented in 1972.\nCertain early arcade machines made use of sound cards to achieve playback of complex audio waveforms and digital music, despite being already equipped with onboard audio. An example of a sound card used in arcade machines is the Digital Compression System card, used in games from Midway. For example, \"Mortal Kombat II\" on the Midway T-Unit hardware. The T-Unit hardware already has an onboard YM2151 OPL chip coupled with an OKI 6295 DAC, but said game uses an added-on DCS card instead. The card is also used in the arcade version of Midway and Aerosmith's Revolution X for complex looping music and speech playback.\nMSX computers, while equipped with built-in sound capabilities, also relied on sound cards to produce better-quality audio. The card, known as Moonsound, uses a Yamaha OPL4 sound chip. Prior to the Moonsound, there were also sound cards called \"MSX Music\" and \"MSX Audio\" for the system, which uses OPL2 and OPL3 chipsets.\nThe Apple II computers, which did not have sound capabilities beyond rapidly clicking a speaker until the IIGS, could use plug-in sound cards from a variety of manufacturers. The first, in 1978, was ALF's Apple Music Synthesizer, with 3 voices; two or three cards could be used to create 6 or 9 voices in stereo. Later ALF created the Apple Music II, a 9-voice model. The most widely supported card, however, was the Mockingboard. Sweet Micro Systems sold the Mockingboard in various models. Early Mockingboard models ranged from 3 voices in mono, while some later designs had 6 voices in stereo. Some software supported use of two Mockingboard cards, which allowed 12-voice music and sound. A 12-voice, single-card clone of the Mockingboard called the Phasor was made by Applied Engineering.\nThe ZX Spectrum that initially only had a beeper had some sound cards made for it. Examples include TurboSound Other examples are the Fuller Box, and Zon X-81.\nThe Commodore 64, while having an integrated SID (Sound Interface Device) chip, also had sound cards made for it. For example, the Sound Expander, which added on an OPL FM synthesizer.\nThe PC-98 series of computers, like their IBM PC cousins, also do not have integrated sound contrary to popular belief, and their default configuration is a PC speaker driven by a timer. Sound cards were made for the C-Bus expansion slots that these computers had, most of which used Yamaha's FM and PSG chips and made by NEC themselves, although aftermarket clones can also be purchased, and Creative did release a C-Bus version of the SoundBlaster line of sound cards for the platform.\nExternal sound devices.\nDevices such as the Covox Speech Thing could be attached to the parallel port of an IBM PC and fed 6- or 8-bit PCM sample data to produce audio. Also, many types of professional sound cards take the form of an external FireWire or USB unit, usually for convenience and improved fidelity.\nSound cards using the PC Card interface were available before laptop and notebook computers routinely had onboard sound. Most of these units were designed for mobile DJs, providing separate outputs to allow both playback and monitoring from one system, however, some also target mobile gamers.\nUSB sound cards.\nUSB sound \"cards\" are external devices that plug into the computer via USB. They are often used in studios and on stage by electronic musicians including live PA performers and DJs. DJs who use DJ software typically use sound cards integrated into DJ controllers or specialized DJ sound cards. DJ sound cards sometimes have inputs with phono preamplifiers to allow turntables to be connected to the computer to control the software's playback of music files with vinyl emulation.\nThe USB specification defines a standard interface, the USB audio device class, allowing a single driver to work with the various USB sound devices and interfaces on the market. Mac OS X, Windows, and Linux support this standard. However, some USB sound cards do not conform to the standard and require proprietary drivers from the manufacturer.\nCards meeting the older USB 1.1 specification are capable of high-quality sound with a limited number of channels, but USB 2.0 or later is more capable with their higher bandwidths.\nUses.\nThe main function of a sound card is to play audio, usually music, with varying formats (monophonic, stereophonic, various multiple speaker setups) and degrees of control. The source may be a CD or DVD, a file, streamed audio, or any external source connected to a sound card input. Audio may be recorded. Sometimes sound card hardware and drivers do not support recording a source that is being played.\nNon-sound uses.\nSound cards can be used to generate (output) arbitrary electrical waveforms, as any digital waveform \"played\" by the soundcard is converted to the desired output within the bounds of its capabilities. In other words, sound cards are consumer-grade arbitrary waveform generators. A number of free and commercial software allow sound cards to act like function generators by generating desired waveforms from functions; there are also online services that generate audio files for any desired waveforms, playable through a sound card.\nSound cards can also be used to record electrical waveforms, in the same way it records an analog audio input. The recording can be displayed by special or general-purpose audio-editing software (acting as an oscilloscope) or further transformed and analyzed. A protection circuit should be used to keep the input voltage within acceptable bounds.\nAs general-purpose waveform generators and analyzers, sound cards are bound by several design and physical limitations.\nSound cards have been used to analyze and generate the following types of signals:\nDriver architecture.\nTo use a sound card, the operating system (OS) typically requires a specific device driver, a low-level program that handles the data connections between the physical hardware and the operating system. Some operating systems include the drivers for many cards; for cards not so supported, drivers are supplied with the card, or available for download.\nList of notable sound card manufacturers.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28186", "revid": "50188061", "url": "https://en.wikipedia.org/wiki?curid=28186", "title": "Symmetry group", "text": "Group of transformations under which the object is invariant\nIn group theory, the symmetry group of a geometric object is the group of all transformations under which the object is invariant, endowed with the group operation of composition. Such a transformation is an invertible mapping of the ambient space which takes the object to itself, and which preserves all the relevant structure of the object. A frequent notation for the symmetry group of an object \"X\" is \"G\" = Sym(\"X\").\nFor an object in a metric space, its symmetries form a subgroup of the isometry group of the ambient space. This article mainly considers symmetry groups in Euclidean geometry, but the concept may also be studied for more general types of geometric structure.\nIntroduction.\nWe consider the \"objects\" possessing symmetry to be geometric figures, images, and patterns, such as a wallpaper pattern. For symmetry of physical objects, one may also take their physical composition as part of the pattern. (A pattern may be specified formally as a scalar field, a function of position with values in a set of colors or substances; as a vector field; or as a more general function on the object.) The group of isometries of space induces a group action on objects in it, and the symmetry group Sym(\"X\") consists of those isometries which map \"X\" to itself (as well as mapping any further pattern to itself). We say \"X\" is \"invariant\" under such a mapping, and the mapping is a \"symmetry\" of \"X\".\nThe above is sometimes called the full symmetry group of \"X\" to emphasize that it includes orientation-reversing isometries (reflections, glide reflections and improper rotations), as long as those isometries map this particular \"X\" to itself. The subgroup of orientation-preserving symmetries (translations, rotations, and compositions of these) is called its proper symmetry group. An object is chiral when it has no orientation-reversing symmetries, so that its proper symmetry group is equal to its full symmetry group.\nAny symmetry group whose elements have a common fixed point, which is true if the group is finite or the figure is bounded, can be represented as a subgroup of the orthogonal group O(\"n\") by choosing the origin to be a fixed point. The proper symmetry group is then a subgroup of the special orthogonal group SO(\"n\"), and is called the rotation group of the figure.\nIn a discrete symmetry group, the points symmetric to a given point do not accumulate toward a limit point. That is, every orbit of the group (the images of a given point under all group elements) forms a discrete set. All finite symmetry groups are discrete.\nDiscrete symmetry groups come in three types: (1) finite point groups, which include only rotations, reflections, inversions and rotoinversions \u2013 i.e., the finite subgroups of O(\"n\"); (2) infinite lattice groups, which include only translations; and (3) infinite space groups containing elements of both previous types, and perhaps also extra transformations like screw displacements and glide reflections. There are also continuous symmetry groups (Lie groups), which contain rotations of arbitrarily small angles or translations of arbitrarily small distances. An example is O(3), the symmetry group of a sphere. Symmetry groups of Euclidean objects may be completely classified as the subgroups of the Euclidean group E(\"n\") (the isometry group of R\"n\").\nTwo geometric figures have the same \"symmetry type\" when their symmetry groups are \"conjugate\" subgroups of the Euclidean group: that is, when the subgroups \"H\"1, \"H\"2 are related by \"H\"1 = \"g\"\u22121\"H\"2\"g\" for some \"g\" in E(\"n\"). For example:\nIn the following sections, we only consider isometry groups whose orbits are topologically closed, including all discrete and continuous isometry groups. However, this excludes for example the 1D group of translations by a rational number; such a non-closed figure cannot be drawn with reasonable accuracy due to its arbitrarily fine detail.\nOne dimension.\nThe isometry groups in one dimension are:\nTwo dimensions.\nUp to conjugacy the discrete point groups in two-dimensional space are the following classes:\nC1 is the trivial group containing only the identity operation, which occurs when the figure is asymmetric, for example the letter \"F\". C2 is the symmetry group of the letter \"Z\", C3 that of a triskelion, C4 of a swastika, and C5, C6, etc. are the symmetry groups of similar swastika-like figures with five, six, etc. arms instead of four.\nD1 is the 2-element group containing the identity operation and a single reflection, which occurs when the figure has only a single axis of bilateral symmetry, for example the letter \"A\".\nD2, which is isomorphic to the Klein four-group, is the symmetry group of a non-equilateral rectangle. This figure has four symmetry operations: the identity operation, one twofold axis of rotation, and two nonequivalent mirror planes.\nD3, D4 etc. are the symmetry groups of the regular polygons.\nWithin each of these symmetry types, there are two degrees of freedom for the center of rotation, and in the case of the dihedral groups, one more for the positions of the mirrors.\nThe remaining isometry groups in two dimensions with a fixed point are:\nNon-bounded figures may have isometry groups including translations; these are:\nThree dimensions.\nUp to conjugacy the set of three-dimensional point groups consists of 7 infinite series, and 7 other individual groups. In crystallography, only those point groups are considered which preserve some crystal lattice (so their rotations may only have order 1, 2, 3, 4, or 6). This crystallographic restriction of the infinite families of general point groups results in 32 crystallographic point groups (27 individual groups from the 7 series, and 5 of the 7 other individuals).\nThe continuous symmetry groups with a fixed point include those of:\nFor objects with scalar field patterns, the cylindrical symmetry implies vertical reflection symmetry as well. However, this is not true for vector field patterns: for example, in cylindrical coordinates with respect to some axis, the vector field \nformula_1 has cylindrical symmetry with respect to the axis whenever formula_2 and formula_3 have this symmetry (no dependence on formula_4); and it has reflectional symmetry only when formula_5.\nFor spherical symmetry, there is no such distinction: any patterned object has planes of reflection symmetry.\nThe continuous symmetry groups without a fixed point include those with a screw axis, such as an infinite helix. See also subgroups of the Euclidean group.\nSymmetry groups in general.\nIn wider contexts, a symmetry group may be any kind of transformation group, or automorphism group. Each type of mathematical structure has invertible mappings which preserve the structure. Conversely, specifying the symmetry group can define the structure, or at least clarify the meaning of geometric congruence or invariance; this is one way of looking at the Erlangen programme.\nFor example, objects in a hyperbolic non-Euclidean geometry have Fuchsian symmetry groups, which are the discrete subgroups of the isometry group of the hyperbolic plane, preserving hyperbolic rather than Euclidean distance. (Some are depicted in drawings of Escher.) Similarly, automorphism groups of finite geometries preserve families of point-sets (discrete subspaces) rather than Euclidean subspaces, distances, or inner products. Just as for Euclidean figures, objects in any geometric space have symmetry groups which are subgroups of the symmetries of the ambient space.\nAnother example of a symmetry group is that of a combinatorial graph: a graph symmetry is a permutation of the vertices which takes edges to edges. Any finitely presented group is the symmetry group of its Cayley graph; the free group is the symmetry group of an infinite tree graph.\nGroup structure in terms of symmetries.\nCayley's theorem states that any abstract group is a subgroup of the permutations of some set \"X\", and so can be considered as the symmetry group of \"X\" with some extra structure. In addition, many abstract features of the group (defined purely in terms of the group operation) can be interpreted in terms of symmetries.\nFor example, let \"G\" = Sym(\"X\") be the finite symmetry group of a figure \"X\" in a Euclidean space, and let \"H\" \u2282 \"G\" be a subgroup. Then \"H\" can be interpreted as the symmetry group of \"X\"+, a \"decorated\" version of \"X\". Such a decoration may be constructed as follows. Add some patterns such as arrows or colors to \"X\" so as to break all symmetry, obtaining a figure \"X\"# with Sym(\"X\"#) = {1}, the trivial subgroup; that is, \"gX\"# \u2260 \"X\"# for all non-trivial \"g\" \u2208 \"G\". Now we get:\nformula_6\nNormal subgroups may also be characterized in this framework. \nThe symmetry group of the translation \"gX\" + is the conjugate subgroup \"gHg\"\u22121. Thus \"H\" is normal whenever:\nformula_7\nthat is, whenever the decoration of \"X\"+ may be drawn in any orientation, with respect to any side or feature of \"X\", and still yield the same symmetry group \"gHg\"\u22121 = \"H\".\nAs an example, consider the dihedral group \"G\" = \"D\"3 = Sym(\"X\"), where \"X\" is an equilateral triangle. We may decorate this with an arrow on one edge, obtaining an asymmetric figure \"X\"#. Letting \u03c4 \u2208 \"G\" be the reflection of the arrowed edge, the composite figure \"X\"+ = \"X\"# \u222a \u03c4\"X\"# has a bidirectional arrow on that edge, and its symmetry group is \"H\" = {1, \u03c4}. This subgroup is not normal, since \"gX\"+ may have the bi-arrow on a different edge, giving a different reflection symmetry group.\nHowever, letting H = {1, \u03c1, \u03c12} \u2282 \"D\"3 be the cyclic subgroup generated by a rotation, the decorated figure \"X\"+ consists of a 3-cycle of arrows with consistent orientation. Then \"H\" is normal, since drawing such a cycle with either orientation yields the same symmetry group \"H\"."}
{"id": "28187", "revid": "40242174", "url": "https://en.wikipedia.org/wiki?curid=28187", "title": "Singular they", "text": "Gender-neutral English pronoun\nSingular \"they\", along with its inflected or derivative forms, \"them\", \"their\", \"theirs\", and \"themselves\" (also \"themself\" and \"theirself\"), is a gender-neutral third-person pronoun derived from plural they. It typically occurs with an indeterminate antecedent, to refer to an unknown person, or to refer to every person of some group, in sentences such as:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Somebody\" left \"their\" umbrella in the office. Could you please let \"them\" know where \"they\" can get it?\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"My personal rule is to never trust \"anyone\" who says that \"they\" had a good time in high school.\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"The patient\" should be told at the outset how much \"they\" will be required to pay.\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"But \"a journalist\" should not be forced to reveal \"their\" sources.\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Everybody\" can make good pastry if \"they\" have the 'know-how'.\"\nThis use of singular \"they\" had emerged by the 14th century, about a century after the plural \"they\". Singular \"they\" has been criticized since the mid-18th century by prescriptive commentators who consider it an error. Its continued use in modern standard English has become more common and formally accepted with the move toward gender-neutral language. Some early-21st-century style guides described it as colloquial and less appropriate in formal writing. However, by 2020, most style guides accepted the singular \"they\" as a personal pronoun.\nIn the early 21st century, use of singular \"they\" with known individuals emerged for non-binary people, as in, for example, \"This is my friend, \"Jay\". I met \"them\" at work.\" \"They\" in this context was named \"Word of the Year\" for 2015 by the American Dialect Society, and for 2019 by Merriam-Webster. In 2020, the American Dialect Society also selected it as \"Word of the Decade\" for the 2010s.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nInflected forms and derivative pronouns.\nLike the \"singular \"you\"\", \"singular \"they\"\" permits a singular antecedent, but is used with the same verb forms as plural \"they\", and has the same inflected forms as plural \"they\" (i.e. \"them\", \"their\", and \"theirs\"), except that in the reflexive form, \"themself\" is sometimes used instead of \"themselves\".\n\"Themself\" is attested from the 14th to 16th centuries. Its use has been increasing since the 1970s or 1980s, though it is sometimes still classified as \"a minority form\". In 2002, Payne and Huddleston, in \"The Cambridge Grammar of the English Language\", called its use in standard dialect \"rare and acceptable only to a minority of speakers\" but \"likely to increase with the growing acceptance of \"they\" as a singular pronoun\". It is useful when referring to a single person of indeterminate gender, where the plural form \"themselves\" might seem incongruous, as in:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"It is not an actor pretending to be Reagan or Thatcher, it is, in grotesque form, the person themself.\"\u2014\u200a\nRegional preferences.\nThe Canadian government recommends \"themselves\" as the reflexive form of singular \"they\" for use in Canadian federal legislative texts and advises against using \"themself\".\nUsage.\n\"They\" with a singular antecedent goes back to the Middle English of the 14th century (slightly younger than \"they\" with a plural antecedent, which was borrowed from Old Norse in the 13th century), and has remained in use for centuries in spite of its proscription by traditional grammarians beginning in the mid-18th century.\nInformal spoken English exhibits universal use of the singular \"they\". An examination by J\u00fcrgen Gerner of the British National Corpus published in 1998 found that British speakers, regardless of social status, age, sex, or region, used the singular \"they\" more often than the gender-neutral \"he\" or other options in the context of being anaphors after indefinite pronouns like \"everybody\" and \"anybody\".\nPrescription of generic \"he\".\n\"He\" has been used with antecedents of indeterminate gender since the Old English period, as in the following:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"If \"any one\" did not know it, it was \"his\" own fault.\"\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"\"Every person\" who turns this page has \"his\" own little diary.\"\u2014\u200a\nThe earliest known explicit recommendation by a grammarian to use the generic \"he\" rather than \"they\" in formal English is Ann Fisher's mid-18th century \"A New Grammar\" assertion that \"The \"Masculine Person\" answers to the \"general Name\", which comprehends both \"Male\" and \"Female\"; as, \"any Person who knows what he says.\"\" (Ann Fisher as quoted by Ostade)\nNineteenth-century grammarians insisted on \"he\" as a gender-neutral pronoun on the grounds of number agreement, while rejecting \"he or she\" as clumsy, and this was widely adopted: e.g. in 1850, the British Parliament passed an act which provided that, when used in acts of Parliament \"words importing the masculine gender shall be deemed and taken to include females\". Baskervill and Sewell mention the common use of the singular \"they\" in their \"An English Grammar for the Use of High School, Academy and College Class\" of 1895, but prefer the generic \"he\" on the basis of number agreement.\nBaskervill gives a number of examples of recognized authors using the singular \"they\", including:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"\"Every one\" must judge according to \"their\" own feelings.\"\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Had the Doctor been contented to take my dining tables as \"any body\" in \"their\" senses would have done\u00a0...\"\u2014\u200a\nIt has been argued that the real motivation for promoting the \"generic\" \"he\" was an androcentric world view, with the default sex of humans being male\u00a0\u2013 and the default gender therefore being masculine. There is some evidence for this: Wilson wrote in 1560:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"...\u00a0let us keepe a naturall order, and set the man before the woman for manners sake.\"\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"...\u00a0the worthier is preferred and set before. As a man is set before a woman\u00a0...\"\u2014\u200a\nAnd Poole wrote in 1646:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"The Masculine gender is more worthy than the Feminine.\"\u2014\u200a\nIn spite of continuous attempts on the part of educationalists to proscribe singular \"they\" in favour of \"he\", this advice was ignored; even writers of the period continued to use \"they\" (though the proscription may have been observed more by American writers). Use of the purportedly gender-neutral \"he\" remained acceptable until at least the 1960s, though some uses of \"he\" were later criticized as being awkward or silly, for instance when referring to:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"The ideal that \"every boy and girl\" should be so equipped that \"he\" shall not be handicapped in \"his\" struggle for social progress\u00a0...\"\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"She and Louis had a game\u00a0\u2013 who could find the ugliest photograph of himself.\"\u2014\u200a\nContemporary use of \"he\" to refer to a generic or indefinite antecedent.\n\"He\" is still sometimes found in contemporary writing when referring to a generic or indeterminate antecedent. In some cases, it is clear from the situation that the persons potentially referred to are likely to be male, as in:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"The patient should be informed of his therapeutic options.\"\u2014\u200a\nIn some cases the antecedent may refer to persons who are only \"probably\" male or to occupations traditionally thought of as male:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"It wouldn't be as if \"the lone astronaut\" would be completely by \"himself\".\" (2008)\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Kitchen table issues\u00a0... are ones \"the next president\" can actually do something about if \"he\" actually cares about it. More likely if she cares about it!\"\u2014\u200a\nIn other situations, the antecedent may refer to an indeterminate person of either sex:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Now, a writer is entitled to have a Roget on \"his\" desk.\"\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"A Member of Parliament should always live in \"his\" constituency.\"\nIn 2010, Choy and Clark still recommend the use of generic \"he\" \"in formal speech or writing\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"...\u00a0when indefinite pronouns are used as antecedents, they require \"singular\" subject, object, and possessive pronouns\u00a0...\"&lt;br&gt;\n\"\"Everyone\" did as \"he\" pleased\"\u2014\u200a\nIn informal spoken English, plural pronouns are often used with indefinite pronoun antecedents. However, this construction is generally not considered appropriate in formal speech or writing.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Informal: \"Somebody\" should let you borrow \"their\" book.\nFormal: \"Somebody\" should let you borrow \"his\" book.\u2014\u200a\nIn 2015, \"Fowler's Dictionary of Modern English Usage\" calls this \"the now outmoded use of \"he\" to mean 'anyone'\", stating:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;From the earliest times until about the 1960s it was unquestionably acceptable to use the pronoun \"he\" (and \"him\", \"himself\", \"his\") with indefinite reference to denote a person of either sex, especially after indefinite pronouns and determiners such as \"anybody\", \u00a0... \"every\", etc., after gender-neutral nouns such as \"person\"\u00a0... [but] alternative devices are now usually resorted to. When a gender-neutral pronoun or determiner\u00a0... is needed, the options usually adopted are the plural forms \"they\", \"their\", \"themselves\", etc., or \"he or she\" (\"his or her\", etc.)\nIn 2016, \"Garner's Modern English Usage\" calls the generic use of masculine pronouns \"the traditional view, now widely assailed as sexist\".\nRise of gender-neutral language.\nThe earliest known attempt to create a new gender-neutral pronoun in English dates back to 1792, when Scottish economist James Anderson of Hermiston advocated for an indeterminate pronoun \"ou\".\nIn 1808, poet Samuel Taylor Coleridge suggested \"it\" and \"which\" as neutral pronouns for the word \"person\":\nIn the second half of the 20th century, people expressed more widespread concern at the use of male-oriented language. This included criticism of the use of \"man\" as a generic term to include men and women and of the use of \"he\" to refer to any human, regardless of sex (social gender).\nIt was argued that \"he\" could not sensibly be used as a generic pronoun understood to include men and women. William Safire in his \"On Language\" column in \"The New York Times\" approved of the use of generic \"he\", mentioning the mnemonic phrase \"the male embraces the female\". C. Badendyck from Brooklyn wrote to \"The New York Times\" in a reply:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The average American needs the small routines of getting ready for work. As he shaves or blow-dries his hair or pulls on his panty-hose, he is easing himself by small stages into the demands of the day.\nBy 1980, the movement toward gender-neutral language had gained wide support, and many organizations, including most publishers, had issued guidelines on the use of gender-neutral language, but stopped short of recommending \"they\" to be third-person singular with a non-indeterminate, singular antecedent.\nContemporary usage.\nThe use of masculine generic nouns and pronouns in written and spoken language has decreased since the 1970s.\nIn a corpus of spontaneous speech collected in Australia in the 1990s, singular \"they\" had become the most frequently used generic pronoun (rather than generic \"he\" or \"he or she\"). Similarly, a study from 2002 looking at a corpus of American and British newspapers showed a preference for \"they\" to be used as a singular epicene pronoun.\nThe increased use of singular \"they\" may owe in part to an increasing desire for gender-neutral language. A solution in formal writing has often been to write \"he or she\", or something similar, but this is often considered awkward or overly politically correct, particularly when used excessively. In 2016, the journal \"American Speech\" published a study by Darren K. LaScotte investigating the pronouns used by native English speakers in informal written responses to questions concerning a subject of unspecified gender, finding that 68% of study participants chose singular \"they\" to refer to such an antecedent. Some participants noted that they found constructions such as \"he or she\" inadequate as they do not include people who identify as neither male nor female.\nUse with a pronoun antecedent.\nThe singular antecedent can be a pronoun such as \"someone\", \"anybody\", or \"everybody\", or an interrogative pronoun such as \"who\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"I feel that if \"someone\" is not doing \"their\" job it should be called to \"their\" attention.\"\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"If \"anyone\" tells you that America's best days are behind her, then \"they\"'re looking the wrong way.\" President George H. W. Bush, 1991 State of the Union Address; quoted by Garner\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"\"Anyone\" can set \"themselves\" up as an acupuncturist.\"\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"If \"anybody\" calls, take \"their\" name and ask \"them\" to call again later.\" Example given by Swan\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"It will be illegal for \"anyone\" to donate an organ to \"their\" wife, husband, adopted child, adopted parent or close friend.\"\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"\"No one\" put \"their\" hand up.\" Example given by Huddleston et al.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"\"No one\" felt \"they\" had been misled.\" Example given by Huddleston et al.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"\"Who\" thinks \"they\" can solve the problem?\". Example given by Huddleston et al.; \"The Cambridge Grammar of the English Language\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"\"Everyone\" promised to behave \"themselves\".\" Example given by Huddleston et al.\nNotional plurality or pairwise relationships.\nAlthough the pronouns \"everybody\", \"everyone\", \"nobody\", and \"no one\" are singular in form and are used with a singular verb, these pronouns have an \"implied plurality\" that is somewhat similar to the implied plurality of collective or group nouns such as \"crowd\" or \"team\", and in some sentences where the antecedent is one of these \"implied plural\" pronouns, the word \"they\" cannot be replaced by generic \"he\", suggesting a \"notional plural\" rather than a \"bound variable\" interpretation &lt;templatestyles src=\"Crossreference/styles.css\" /&gt;. This is in contrast to sentences that involve multiple pairwise relationships and singular \"they\", such as:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Everyone\" loves \"their\" mother.\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Everyone\" doubts \"themselves\"/\"themself\" at one time or another.\"\nThere are examples where the antecedent pronoun (such as \"everyone\") may refer to a collective, with no necessary implication of pairwise relationships. These are examples of plural \"they\":\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"At first \"everyone\" in the room was singing; then \"they\" began to laugh.\" Example given by Kolln.\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Everybody\" was crouched behind the furniture to surprise me, and \"they\" tried to. But I already knew \"they\" were there.\" Example given by Garner.\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Nobody\" was late, were \"they\"?\" Example given by Swan.\nWhich are apparent because they do not work with a generic \"he\" or \"he or she\":\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"At first \"everyone\" in the room was singing; then \"he or she\" began to laugh.\" Example given by Kolln.\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Everybody\" was crouched behind the furniture to surprise me, and \"he\" tried to. But I already knew \"he\" was there.\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Nobody\" was late, was \"he\"?\"\nIn addition, for these \"notional plural\" cases, it would not be appropriate to use \"themself\" instead of \"themselves\" as in:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Everybody\" was crouched behind the furniture to surprise me, but \"they\" instead surprised \"themself\".\"\nUse with a generic noun as antecedent.\nThe singular antecedent can also be a noun such as \"person\", \"patient\", or \"student\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"cognitive dissonance: \"a concept in psychology [that] describes the condition in which \"a person's\" attitudes conflict with \"their\" behaviour\".\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"A starting point would be to give more support to \"the company secretary\". \"They\" are, or should be, privy to the confidential deliberations and secrets of the board and the company.\u2014\u200a\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"I had to decide: Is \"this person\" being irrational or is he right? Of course, \"they\" were often right.\"\nEven when referring to a class of persons of known sex, \"they\" is sometimes used:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"I swear more when I'm talking to \"a boy\", because I'm not afraid of shocking \"them\"\". From an interview.\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"No mother\" should be forced to testify against \"their\" child\".\n\"They\" may also be used with antecedents of mixed genders:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"Let me know if \"your father or your mother\" changes \"their\" mind.\" Example given by Huddleston et al.\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"Either \"the husband or the wife\" has perjured \"themself\".\" Here \"themself\" might be acceptable to some, \"themselves\" seems less acceptable, and \"himself\" is unacceptable. Example given by Huddleston et al.\nEven for a definite known person of known sex, \"they\" may be used in order to ignore or conceal the sex.\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"I had \"a friend\" in Paris, and \"they\" had to go to hospital for a month.\" (definite person, not identified)\nThe word \"themself\" is also sometimes used when the antecedent is known or believed to be a single person.\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Someone\" has apparently locked \"themself\" in the office.\"[acceptability questionable]\nUse for specific, known people, including non-binary people.\nKnown individuals may be referred to as \"they\" if the individual's gender is unknown to the speaker.\nA known individual may also be referred to as \"they\" if the individual is non-binary or genderqueer and considers \"they\" and derivatives as appropriate pronouns. Several social media applications permit account holders to choose to identify their gender using one of a variety of non-binary or genderqueer options, such as \"non-binary\", \"genderfluid\", \"agender\", or \"bigender\", and to designate pronouns, including \"they\"/\"them\", which they wish to be used when referring to them. Explicitly designating one's pronouns as \"they\"/\"them\" increases the chance that people will interpret \"they\" as singular. Though \"singular \"they\"\" has long been used with antecedents such as \"everybody\" or generic persons of unknown gender, this use, which may be chosen by an individual, is recent. The earliest recorded usage of this sense documented by the \"Oxford English Dictionary\" is in a tweet from 2009; the journal \"American Speech\" documents an example from 2008 in an article in the journal \"Women's Studies Quarterly\". As of 2020, singular \"they\" is the most popular pronoun set used by non-binary people. Approximately 80% consider it appropriate for themselves.\nThe singular \"they\" in the meaning \"gender-neutral singular pronoun for a known person, as a non-binary identifier\" was chosen by the American Dialect Society as their \"Word of the Year\" for 2015. In 2016, the American Dialect Society wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"While editors have increasingly moved to accepting singular they when used in a generic fashion, voters in the Word of the Year proceedings singled out its newer usage as an identifier for someone who may identify as non-binary in gender terms.\"\nThe vote followed the previous year's approval of this use by \"The Washington Post\" style guide, when Bill Walsh, the \"Post\"'s copy editor, said that the singular \"they\" is \"the only sensible solution to English's lack of a gender-neutral third-person singular personal pronoun\".\nIn 2019, the non-binary \"they\" was added to Merriam-Webster's dictionary and was named as that year's \"Word of the Year\". On January 4, 2020, the American Dialect Society announced they had crowned \"they\", again in this context, Word of the Decade for the 2010s.\nThe first non-binary main character on North American television appeared on the Showtime drama series \"Billions\" in 2017, with Asia Kate Dillon playing Taylor Mason. Both actor and character use singular \"they\".\nAcceptability and prescriptive guidance.\nThough both generic \"he\" and generic \"they\" have long histories of use, and both are still used, both are also systematically avoided by particular groups.\nStyle guides that avoid expressing a preference for either approach sometimes recommend recasting a problem sentence, for instance replacing generic expressions with plurals to avoid the criticisms of either party.\nSources differ about whether singular \"they\" is more accepted in British or American English, with \"Garner's Modern English Usage\" stating British English and \"A Comprehensive Grammar of the English Language\" stating American English.\nUsage guidance in American style guides.\n\"Garner's Modern American Usage\".\n\"Garner's Modern American Usage\" (4th ed., 2016) recommends cautious use of singular \"they\", and avoidance where possible because its use is stigmatized.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Where noun\u2013pronoun disagreement can be avoided, avoid it. Where it can't be avoided, resort to it cautiously because some people may doubt your literacy\".\nGarner suggests that use of singular \"they\" is more acceptable in British English:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nand apparently regrets the resistance by the American language community:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"That it sets many literate Americans' teeth on edge is an unfortunate obstacle to what promises to be the ultimate solution to the problem.\"\nHe regards the trend toward using singular \"they\" with antecedents like \"everybody\", \"anyone\" and \"somebody\" as inevitable:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Disturbing though these developments may be to purists, they're irreversible. And nothing that a grammarian says will change them.\"\nGarner also notes that \"resistance to the singular \"they\" is fast receding\" in all national varieties of English.\n\"The Chicago Manual of Style\".\nIn the 14th edition (1993) of \"The Chicago Manual of Style\", the University of Chicago Press explicitly recommended using singular \"they\" and \"their\", noting a \"revival\" of this usage and citing \"its venerable use by such writers as Addison, Austen, Chesterfield, Fielding, Ruskin, Scott, and Shakespeare.\"\nFrom the 15th edition (2003), this was changed. In Chapter 5 of the 17th edition (2017), now written by Bryan A. Garner, the recommendations were:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Normally, a singular antecedent requires a singular pronoun. But because \"he\" is no longer universally accepted as a generic pronoun referring to a person of unspecified gender, people commonly (in speech and in informal writing) substitute the third-person-plural pronouns \"they\", \"them\", \"their\", and \"themselves\" (or the nonstandard singular \"themself\"). While this usage is accepted in those spheres, it is only lately showing signs of gaining acceptance in formal writing, where Chicago recommends avoiding its use. When referring specifically to a person who does not identify with a gender-specific pronoun, however, \"they\" and its forms are often preferred.\nHowever, this was revised in the 18th edition (2024):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Traditionally, a singular antecedent requires a singular pronoun. But even before the movement away from \"he\", \"him\", \"his\", and \"himself\" as generic pronouns referring to a person of unspecified gender, people had long substituted the third-person-plural pronouns \"they\", \"them\", \"their\", and \"themselves\" (or possibly \"themself\") as generic singular forms\u2014especially in speech and informal prose {somebody forgot their coat}. In recent years this usage has become accepted in more formal contexts, and Chicago now endorses it.\n\"Publication Manual of the American Psychological Association\".\nThe 7th edition of the American Psychological Association's \"Publication Manual\", released in October 2019, advises using singular \"they\" when gender is unknown or irrelevant, and gives the following example:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For instance, rather than writing \"I don't know who wrote this note, but he or she has good handwriting,\" you might write something like \"I don't know who wrote this note, but they have good handwriting.\"\nAPA style also endorses using \"they\"/\"them\" if it is someone's (for example, a non-binary person's) preferred pronoun set.\nStrunk &amp; White's \"The Elements of Style\".\nWilliam Strunk Jr. &amp; E. B. White, the original authors of \"The Elements of Style\", found use of \"they\" with a singular antecedent unacceptable and advised use of the singular pronoun (\"he\"). In the 3rd edition (1979), the recommendation was still:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;They. Not to be used when the antecedent is a distributive expression, such as \"each\", \"each one\". \"everybody\", \"every one\", \"many a man\". Use the singular pronoun.\u00a0... A similar fault is the use of the plural pronoun with the antecedent \"anybody\", \"anyone\", \"somebody\", \"someone\"\u00a0...\nThe assessment, in 1979, was that:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The use of \"he\" as pronoun for nouns embracing both genders is a simple, practical convention rooted in the beginnings of the English language. \"He\" has lost all suggestion of maleness in these circumstances.\u00a0... It has no pejorative connotation; it is never incorrect.\nIn the 4th edition (2000), use of singular \"they\" was still proscribed against, but use of generic \"he\" was no longer recommended.\nJoseph M. Williams's \"The Basics of Clarity and Grace\" (2009).\nJoseph M. Williams, who wrote a number of books on writing with \"\", discusses the advantages and disadvantages of various solutions when faced with the problem of referring to an antecedent such as \"someone\", \"everyone\", \"no one\" or a noun that does not indicate gender and suggests that this will continue to be a problem for some time. He \"suspect[s] that eventually we will accept the plural \"they\" as a correct singular\" but states that currently \"formal usage requires a singular pronoun\".\n\"Purdue Online Writing Lab\".\nThe \"Purdue Online Writing Lab\" (\"OWL\") states that \"grammar shifts and changes over time\", that the use of singular \"they\" is acceptable, and that singular \"they\" as a replacement for \"he\" or \"she\" is more inclusive:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When individuals whose gender is neither male nor female (e.g. nonbinary, agender, genderfluid, etc.) use the singular they to refer to themselves, they are using the language to express their identities. Adopting this language is one way writers can be inclusive of a range of people and identities.\u2014\u200a\n\"The Washington Post\".\n\"The Washington Post\"'s stylebook, as of 2015, recommends trying to \"write around the problem, perhaps by changing singulars to plurals, before using the singular they as a last resort\" and specifically permits use of \"they\" for a \"gender-nonconforming person\".\n\"Associated Press Stylebook\".\nThe \"Associated Press Stylebook\", as of 2017, recommends: \"\"they\"/\"them\"/\"their\" is acceptable in limited cases as a singular and-or gender-neutral pronoun, when alternative wording is overly awkward or clumsy. However, rewording usually is possible and always is preferable.\"\n\"The Handbook of Nonsexist Writing\".\nIn \"The Handbook of Nonsexist Writing\", Casey Miller and Kate Swift accept or recommend singular uses of \"they\" in cases where there is an element of semantic plurality expressed by a word such as \"everyone\" or where an indeterminate \"person\" is referred to, citing examples of such usage in formal speech. They also suggest rewriting sentences to use a plural \"they\", eliminating pronouns, or recasting sentences to use \"one\" or (for babies) \"it\".\nUsage guidance in British style guides.\nIn the first edition of \"A Dictionary of Modern English Usage\" (published in 1926) use of the generic \"he\" is recommended. It is stated that singular \"they\" is disapproved of by grammarians. Numerous examples of its use by eminent writers in the past are given, but it is stated that \"few good modern writers would flout [grammarians] so conspicuously as Fielding and Thackeray\", whose sentences are described as having an \"old-fashioned sound\".\nThe second edition, \"Fowler's Modern English Usage\" (edited by Sir Ernest Gowers and published in 1965) continues to recommend use of the generic \"he\"; use of the singular \"they\" is called \"the popular solution\", which \"sets the literary man's teeth on edge\". It is stated that singular \"they\" is still disapproved of by grammarians but common in colloquial speech.\nAccording to the third edition, \"The New Fowler's Modern English Usage\" (edited by Robert Burchfield and published in 1996) singular \"they\" has not only been widely used by good writers for centuries, but is now generally accepted, except by some conservative grammarians, including the Fowler of 1926, who, it is argued, ignored the evidence:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Over the centuries, writers of standing have used \"they\", \"their\", and \"them\" with anaphoric reference to a singular noun or pronoun, and the practice has continued in the 20C. to the point that, traditional grammarians aside, such constructions are hardly noticed any more or are not widely felt to lie in a prohibited zone. Fowler (1926) disliked the practice\u00a0... and gave a number of unattributed \"faulty' examples\u00a0... The evidence presented in the \"OED\" points in another direction altogether.\n\"The Complete Plain Words\" was originally written in 1948 by Ernest Gowers, a civil servant, in an attempt by the British civil service to improve \"official English\". A second edition, edited by Sir Bruce Fraser, was published in 1973. It refers to \"they\" or \"them\" as the \"equivalent of a singular pronoun of common sex\" as \"common in speech and not unknown in serious writing \" but \"stigmatized by grammarians as usage grammatically indefensible. The book's advice for \"official writers\" (civil servants) is to avoid its use and not to be tempted by its \"greater convenience\", though \"necessity may eventually force it into the category of accepted idiom\".\nA new edition of \"Plain Words\", revised and updated by Gowers's great-granddaughter, Rebecca Gowers, was published in 2014.\nIt notes that singular \"they\" and \"them\" have become much more widespread since Gowers' original comments, but still finds it \"safer\" to treat a sentence like 'The reader may toss their book aside' as incorrect \"in formal English\", while rejecting even more strongly sentences like\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"There must be opportunity for the individual boy or girl to go as far as his keenness and ability will take him.\"\n\"The Times Style and Usage Guide\" (first published in 2003 by \"The Times\" of London) recommends avoiding sentences like\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"If someone loves animals, they should protect them.\"\nby using a plural construction:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"If people love animals, they should protect them.\"\n\"The Cambridge Guide to English Usage\" (2004, Cambridge University Press) finds singular \"they\" \"unremarkable\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For those listening or reading, it has become unremarkable\u00a0\u2013 an element of common usage.\nIt expresses several preferences.\n\"The Economist Style Guide\" refers to the use of \"they\" in sentences like\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"We can't afford to squander anyone's talents, whatever colour their skin is.\"\nas \"scrambled syntax that people adopt because they cannot bring themselves to use a singular pronoun\".\n\"New Hart's Rules\" (Oxford University Press, 2012) is aimed at those engaged in copy editing, and the emphasis is on the formal elements of presentation including punctuation and typeface, rather than on linguistic style, although\u00a0\u2013 like \"The Chicago Manual of Style\"\u00a0\u2013 it makes occasional forays into matters of usage. It advises against use of the purportedly gender-neutral \"he\", and suggests cautious use of \"they\" where \"he or she\" presents problems.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...\u00a0it is now regarded\u00a0... as old-fashioned or sexist to use \"he\" in reference to a person of unspecified sex, as in \"every child needs to know that he is loved.\" The alternative \"he or she\" is often preferred, and in formal contexts probably the best solution, but can become tiresome or long-winded when used frequently. Use of \"they\" in this sense (\"everyone needs to feel that they matter\") is becoming generally accepted both in speech and in writing, especially where it occurs after an indefinite pronoun such as \"everyone\" or \"someone\", but should not be imposed by an editor if an author has used \"he or she\" consistently.\nThe 2011 edition of the \"New International Version Bible\" uses singular \"they\" instead of the traditional \"he\" when translating pronouns that apply to both genders in the original Greek or Hebrew. This decision was based on research by a commission that studied modern English usage and determined that singular \"they\" (\"them\"/\"their\") was by far the most common way that English-language speakers and writers today refer back to singular antecedents such as \"whoever\", \"anyone\", \"somebody\", \"a person\", \"no one\", and the like.\"\nThe British edition of \"The Handbook of Nonsexist Writing\", modified in some respects from the original US edition to conform to differences in culture and vocabulary, preserved the same recommendations, allowing singular \"they\" with semantically plural terms like \"everyone\" and indeterminate ones like \"person\", but recommending a rewrite to avoid.\nAustralian usage guidance.\nThe Australian \"Federation Press Style Guide for Use in Preparation of Book Manuscripts\" recommends \"gender-neutral language should be used\", stating that use of \"they\" and \"their\" as singular pronouns is acceptable.\nUsage guidance in English grammars.\n\"The Cambridge Grammar of the English Language\" discusses the prescriptivist argument that \"they\" is a plural pronoun and that the use of \"they\" with a singular \"antecedent\" therefore violates the rule of agreement between antecedent and pronoun, but takes the view that \"they\", though \"primarily\" plural, can also be singular in a secondary \"extended\" sense, comparable to the purportedly extended sense of \"he\" to include female gender.\nUse of singular \"they\" is stated to be \"particularly common\", even \"stylistically neutral\" with antecedents such as \"everyone\", \"someone\", and \"no one\", but more restricted when referring to common nouns as antecedents, as in\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"The patient\" should be told at the outset how much \"they\" will be required to pay.\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"A friend of mine\" has asked me to go over and help \"them\"\u00a0...\"\nUse of the pronoun \"themself\" is described as being \"rare\" and \"acceptable only to a minority of speakers\", while use of the morphologically plural \"themselves\" is considered problematic when referring to \"someone\" rather than \"everyone\" (since only the latter implies a plural set).\nThere are also issues of grammatical acceptability when reflexive pronouns refer to singular noun phrases joined by \"or\", the following all being problematic:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"Either the husband or the wife has perjured \"himself\".\" [ungrammatical]\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"Either the husband or the wife has perjured \"themselves\".\" [of questionable grammaticality]\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"Either the husband or the wife has perjured \"themself\".\" [typically used by only some speakers of Standard English].\nOn the motivation for using singular \"they\", \"A Student's Introduction to English Grammar\" states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;this avoidance of \"he\" can't be dismissed just as a matter of political correctness. The real problem with using \"he\" is that it unquestionably colours the interpretation, sometimes inappropriately\u00a0... \"he\" doesn't have a genuinely sex-neutral sense.\nThe alternative \"he or she\" can be \"far too cumbersome\", as in:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Everyone\" agreed that he or she would bring his or her lunch with \"him or her\".\nor even \"flatly ungrammatical\", as in\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Everyone's\" here, isn't \"he or she\"?\n\"Among younger speakers\", use of singular \"they\" even with definite noun-phrase antecedents finds increasing acceptance, \"sidestepping any presumption about the sex of the person referred to\", as in:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"You should ask \"your partner\" what \"they\" think.\"\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"\"The person\" I was with said \"they\" hated the film.\" Example given by Huddleston et al.\nOlder style guides (not newly published after 2000).\nAccording to \"A Comprehensive Grammar of the English Language\" (1985):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The pronoun \"they\" is commonly used as a 3rd person singular pronoun that is neutral between masculine and feminine\u00a0... At one time restricted to informal usage. it is now increasingly accepted in formal usage, especially in [American English].\n\"The Little, Brown Handbook\" (1992).\nAccording to \"The Little, Brown Handbook\", most experts\u00a0\u2013 and some teachers and employers\u00a0\u2013 find use of singular \"they\" unacceptable:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Although some experts accept \"they\", \"them\", and \"their\" with singular indefinite words, most do not, and many teachers and employers regard the plural as incorrect. To be safe, work for agreement between singular indefinite words and the pronouns that refer to them\u00a0...\nIt recommends using \"he or she\" or avoiding the problem by rewriting the sentence to use a plural or omit the pronoun.\nThe American Heritage Book of English Usage (1996).\nAccording to \"The American Heritage Book of English Usage\" and its usage panel of selected writers, journalism professors, linguists, and other experts, many Americans avoid use of \"they\" to refer to a singular antecedent out of respect for a \"traditional\" grammatical rule, despite use of singular \"they\" by modern writers of note and mainstream publications:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Most of the Usage Panel rejects the use of \"they\" with singular antecedents as ungrammatical, even in informal speech. Eighty-two percent find the sentence \"The typical student in the program takes about six years to complete their course work\" unacceptable\u00a0... panel members seem to make a distinction between singular nouns, such as \"the typical student\" and \"a person\", and pronouns that are grammatically singular but semantically plural, such as \"anyone\", \"everyone\" and \"no one\". Sixty-four percent of panel members accept the sentence \"No one is willing to work for those wages anymore, are they?\"\nGrammatical and logical analysis.\nNotional agreement.\n\"Notional agreement\" is the idea that some uses of \"they\" might refer to a grammatically singular antecedent seen as semantically plural:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"\"No man\" goes to battle to be killed.\"\u00a0... \"But \"they\" do get killed.\"\u2014\u200a\nAccording to \"notional agreement\", in the Shakespeare quotation \"a mother\" is syntactically singular, but stands for all mothers; and in the Shaw quotation \"no man\" is syntactically singular (taking the singular form \"goes\"), but is semantically plural (\"all\" go [to kill] not to be killed), hence idiomatically requiring \"they\". Such use, which goes back a long way, includes examples where the sex is known, as in the above examples.\nDistribution.\nDistributive constructions apply a \"single\" idea to \"multiple\" members of a group.\nThey are typically marked in English by words like \"each\", \"every\" and \"any\". The simplest examples are applied to groups of two, and use words like \"either\" and \"or\"\u00a0\u2013 \"Would you like tea or coffee?\". Since distributive constructions apply an idea relevant to each individual in the group, rather than to the group as a whole, they are most often conceived of as singular, and a singular pronoun is used:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"England expects that every man will do his duty.\"\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"Every dog hath his day.\"\u2014\u200a\nHowever, many languages, including English, show ambivalence in this regard. Because distribution also requires a group with more than one member, plural forms are sometimes used.\nReferential and non-referential anaphors.\nThe singular \"they\", which uses the same verb form that plurals do, is typically used to refer to an indeterminate antecedent, for example:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"The \"person\" you mentioned, are \"they\" coming?\"\nIn some sentences, typically those including words like \"every\" or \"any\", the morphologically singular antecedent does not refer to a single entity but is \"anaphorically linked\" to the associated pronoun to indicate a set of pairwise relationships, as in the sentence:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Everyone\" returned to \"their\" seats.\" (where each person is associated with one seat)\nLinguists like Steven Pinker and Rodney Huddleston explain sentences like this (and others) in terms of bound variables, a term borrowed from logic. Pinker prefers the terms \"quantifier\" and \"bound variable\" to \"antecedent\" and \"pronoun\". He suggests that pronouns used as \"variables\" in this way are more appropriately regarded as homonyms of the equivalent referential pronouns.\nThe following shows different types of anaphoric reference, using various pronouns, including \"they\":\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"Your \"wife\" phoned but \"she\" didn't leave a message.\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"One of your \"girlfriends\" phoned, but \"she\" didn't leave a message.\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"One of your \"boyfriends\" phoned, but \"he\" didn't leave a message.\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"One of your \"friends\" phoned, but \"they\" didn't leave a message.\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"If you had an unemployed \"daughter\", what would you think if \"she\" wanted to accept work as a mercenary?\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"If you had an unemployed \"child\", what would you think if \"they\" wanted to accept work as a mercenary?\"\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"No one\" put \"their\" hand up.\" [approximately: \"There is no person \"x\" such that \"x\" put \"x\"'s hand up.\"]\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\"\"Every car\" had \"its\" windscreen broken.\" [approximately: \"For every car \"x\", \"x\" had \"x\"'s windscreen broken.\"]\nCognitive efficiency.\nA study of whether \"singular \"they\"\" is more \"difficult\" to understand than gendered pronouns found that \"singular \"they\" is a cognitively efficient substitute for generic \"he\" or \"she\", particularly when the antecedent is nonreferential\" (e.g. \"anybody\", \"a nurse\", or \"a truck driver\") rather than referring to a specific person (e.g. \"a runner I knew\" or \"my nurse\"). Clauses with singular \"they\" were read \"just as quickly as clauses containing a gendered pronoun that matched the stereotype of the antecedent\" (e.g. \"she\" for a nurse and \"he\" for a truck driver) and \"much more quickly than clauses containing a gendered pronoun that went against the gender stereotype of the antecedent\".\nOn the other hand, when the pronoun \"they\" was used to refer to known individuals (\"referential antecedents, for which the gender was presumably known\", e.g. \"my nurse\", \"that truck driver\", \"a runner I knew\"), reading was slowed when compared with use of a gendered pronoun consistent with the \"stereotypic gender\" (e.g. \"he\" for a specific truck driver).\nThe study concluded that \"the increased use of singular \"they\" is not problematic for the majority of readers\".\nA 2024 study by Arnold, Venkatesh, and Vig stated that two-thirds of people used an incorrect pronoun at least once in speaking about someone who used singular \"they\", versus never when speaking about someone who used \"he\" or \"she\", suggesting that singular \"they\" caused some difficulty, but the rate of errors was low (9%). They wrote that whereas people may repeat a name to avoid using the pronoun \"they\" in writing, in speech people used singular \"they\" at least as frequently as binary pronouns, \"suggesting that any difficulty does not result in pronoun avoidance\" in speech.\nComparison with other pronouns.\nThe singular and plural use of \"they\" can be compared with the pronoun \"you\", which had been both a plural and polite singular, but by the 18th century replaced \"thou\" for singular referents. For \"you\", the singular reflexive pronoun (\"yourself\") is different from its plural reflexive pronoun (\"yourselves\"); with \"they\" one can hear either \"themself\" or \"themselves\" for the singular reflexive pronoun.\nSingular \"they\" has also been compared to nosism (such as the \"royal we\"), when a single person uses first-person plural in place of first-person singular pronouns. Similar to singular \"you\", its singular reflexive pronoun (\"ourself\") is different from the plural reflexive pronoun (\"ourselves\").\nWhile the pronoun set derived from \"it\" is primarily used for inanimate objects, \"it\" is frequently used in an impersonal context when someone's identity is unknown or established on a provisional basis, e.g. \"Who is \"it\"?\" or \"With this new haircut, no one knows \"it\" is me.\" \"It\" is also used for infants of unspecified gender but may be considered dehumanizing and is therefore more likely in a clinical context. Otherwise, in more personal contexts, the use of \"it\" to refer to a person might indicate antipathy or other negative emotions.\n\"It\" can also be used for non-human animals of unspecified sex, though \"they\" is common for pets and other domesticated animals of unspecified sex, especially when referred to by a proper name (e.g. \"Rags\", \"Snuggles\"). Normally, birds and mammals with a known sex are referred to by their respective male or female pronoun (\"he\" and \"she\"; \"him\" and \"her\").\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\nSources of original examples\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "28189", "revid": "1216158", "url": "https://en.wikipedia.org/wiki?curid=28189", "title": "Space Shuttle", "text": "Partially reusable launch system and space plane\nThe Space Shuttle is a retired, partially reusable low Earth orbital spacecraft system operated from 1981 to 2011 by the U.S. National Aeronautics and Space Administration (NASA) as part of the Space Shuttle program. Its official program name was the Space Transportation System (STS), taken from the 1969 plan led by U.S. vice president Spiro Agnew for a system of reusable spacecraft where it was the only item funded for development.\nThe first (STS-1) of four orbital test flights occurred in 1981, leading to operational flights (STS-5) beginning in 1982. Five complete Space Shuttle orbiter vehicles were built and flown on a total of 135 missions from 1981 to 2011. They launched from the Kennedy Space Center (KSC) in Florida. Operational missions launched numerous satellites, interplanetary probes, and the Hubble Space Telescope (HST), conducted science experiments in orbit, participated in the Shuttle-\"Mir\" program with Russia, and participated in the construction and servicing of the International Space Station (ISS). The Space Shuttle fleet's total mission time was 1,323 days.\nSpace Shuttle components include the Orbiter Vehicle (OV) with three clustered Rocketdyne RS-25 main engines, a pair of recoverable solid rocket boosters (SRBs), and the expendable external tank (ET) containing liquid hydrogen and liquid oxygen. The Space Shuttle was launched vertically, like a conventional rocket, with the two SRBs operating in parallel with the orbiter's three main engines, which were fueled from the ET. The SRBs were jettisoned before the vehicle reached orbit, while the main engines continued to operate, and the ET was jettisoned after main engine cutoff and just before orbit insertion, which used the orbiter's two Orbital Maneuvering System (OMS) engines. At the conclusion of the mission, the orbiter fired its OMS to deorbit and reenter the atmosphere. The orbiter was protected during reentry by its thermal protection system tiles, and it glided as a spaceplane to a runway landing, usually to the Shuttle Landing Facility at KSC, Florida, or to Rogers Dry Lake in Edwards Air Force Base, California. If the landing occurred at Edwards, the orbiter was flown back to the KSC atop the Shuttle Carrier Aircraft (SCA), a specially modified Boeing 747 designed to carry the shuttle above it.\nThe first orbiter, \"Enterprise\", was built in 1976 and used in Approach and Landing Tests (ALT), but had no orbital capability. Four fully operational orbiters were initially built: \"Columbia\", \"Challenger\", \"Discovery\", and \"Atlantis\". Of these, two were lost in mission accidents: \"Challenger\" in 1986 and \"Columbia\" in 2003, with a total of 14 astronauts killed. A fifth operational (and sixth in total) orbiter, \"Endeavour\", was built in 1991 to replace \"Challenger\". The three surviving operational vehicles were retired from service following \"Atlantis\"'s final flight on July 21, 2011. The U.S. relied on the Russian Soyuz spacecraft to transport astronauts to the ISS from the last Shuttle flight until the launch of the Crew Dragon Demo-2 mission in May 2020.\nDesign and development.\nHistorical background.\nIn the late 1930s, the German government launched the \"Amerikabomber\" (English: America bomber) project, and Eugen S\u00e4nger's idea, together with mathematician Irene Bredt, was a winged rocket called the Silbervogel (German for \"silver bird\"). During the 1950s, the United States Air Force proposed using a reusable piloted glider to perform military operations such as reconnaissance, satellite attack, and air-to-ground weapons employment. In the late 1950s, the Air Force began developing the partially reusable X-20 Dyna-Soar. The Air Force collaborated with NASA on the Dyna-Soar and began training six pilots in June 1961. The rising costs of development and the prioritization of Project Gemini led to the cancellation of the Dyna-Soar program in December 1963. In addition to the Dyna-Soar, the Air Force had conducted a study in 1957 to test the feasibility of reusable boosters. This became the basis for the aerospaceplane, a fully reusable spacecraft that was never developed beyond the initial design phase in 1962\u20131963.\nBeginning in the early 1950s, NASA and the Air Force collaborated on developing lifting bodies to test aircraft that primarily generated lift from their fuselages instead of wings, and tested the NASA M2-F1, Northrop M2-F2, Northrop M2-F3, Northrop HL-10, Martin Marietta X-24A, and the Martin Marietta X-24B. The program tested aerodynamic characteristics that would later be incorporated in design of the Space Shuttle, including unpowered landing from a high altitude and speed.\nDesign process.\nOn September 24, 1966, as the Apollo space program neared its design completion, NASA and the Air Force released a joint study concluding that a new vehicle was required to satisfy their respective future demands and that a partially reusable system would be the most cost-effective solution. The head of the NASA Office of Manned Space Flight, George Mueller, announced the plan for a reusable shuttle on August 10, 1968. NASA issued a request for proposal (RFP) for designs of the Integral Launch and Reentry Vehicle (ILRV) on October 30, 1968. Rather than award a contract based upon initial proposals, NASA announced a phased approach for the Space Shuttle contracting and development; Phase A was a request for studies completed by competing aerospace companies, Phase B was a competition between two contractors for a specific contract, Phase C involved designing the details of the spacecraft components, and Phase D was the production of the spacecraft.\nIn December 1968, NASA created the Space Shuttle Task Group to determine the optimal design for a reusable spacecraft, and issued study contracts to General Dynamics, Lockheed, McDonnell Douglas, and North American Rockwell. In July 1969, the Space Shuttle Task Group issued a report that determined the Shuttle would support short-duration crewed missions and space station, as well as the capabilities to launch, service, and retrieve satellites. The report also created three classes of a future reusable shuttle: Class I would have a reusable orbiter mounted on expendable boosters, Class II would use multiple expendable rocket engines and a single propellant tank (stage-and-a-half), and Class III would have both a reusable orbiter and a reusable booster. In September 1969, the Space Task Group, under the leadership of U.S. vice president Spiro Agnew, issued a report calling for the development of a space shuttle to bring people and cargo to low Earth orbit (LEO), as well as a space tug for transfers between orbits and the Moon, and a reusable nuclear upper stage for deep space travel.\nAfter the release of the Space Shuttle Task Group report, many aerospace engineers favored the Class III, fully reusable design because of perceived savings in hardware costs. Max Faget, a NASA engineer who had worked to design the Mercury capsule, patented a design for a two-stage fully recoverable system with a straight-winged orbiter mounted on a larger straight-winged booster. The Air Force Flight Dynamics Laboratory argued that a straight-wing design would not be able to withstand the high thermal and aerodynamic stresses during reentry, and would not provide the required cross-range capability. Additionally, the Air Force required a larger payload capacity than Faget's design allowed. In January 1971, NASA and Air Force leadership decided that a reusable delta-wing orbiter mounted on an expendable propellant tank would be the optimal design for the Space Shuttle.\nAfter they established the need for a reusable, heavy-lift spacecraft, NASA and the Air Force determined the design requirements of their respective services. The Air Force expected to use the Space Shuttle to launch large satellites, and required it to be capable of lifting to an eastward LEO or into a polar orbit. The satellite designs also required that the Space Shuttle have a payload bay. NASA evaluated the F-1 and J-2 engines from the Saturn rockets, and determined that they were insufficient for the requirements of the Space Shuttle; in July 1971, it issued a contract to Rocketdyne to begin development on the RS-25 engine.\nNASA reviewed 29 potential designs for the Space Shuttle and determined that a design with two side boosters should be used, and the boosters should be reusable to reduce costs. NASA and the Air Force elected to use solid-propellant boosters because of the lower costs and the ease of refurbishing them for reuse after they landed in the ocean. In January 1972, President Richard Nixon approved the Shuttle, and NASA decided on its final design in March. The development of the Space Shuttle Main Engine (SSME) remained the responsibility of Rocketdyne, and the contract was issued in July 1971, and updated SSME specifications were submitted to Rocketdyne that\u00a0April. The following August, NASA awarded the contract to build the orbiter to North American Rockwell, which had by then constructed a full-scale mock-up, later named \"Inspiration\". In August 1973, NASA awarded the external tank contract to Martin Marietta, and in November the solid-rocket booster contract to Morton Thiokol.\nDevelopment.\nOn June 4, 1974, Rockwell began construction on the first orbiter, OV-101, dubbed Constitution, later to be renamed \"Enterprise\". \"Enterprise\" was designed as a test vehicle, and did not include engines or heat shielding. Construction was completed on September 17, 1976, and \"Enterprise\" was moved to the Edwards Air Force Base to begin testing. Rockwell constructed the Main Propulsion Test Article (MPTA)-098, which was a structural truss mounted to the ET with three RS-25 engines attached. It was tested at the National Space Technology Laboratory (NSTL) to ensure that the engines could safely run through the launch profile. Rockwell conducted mechanical and thermal stress tests on Structural Test Article (STA)-099 to determine the effects of aerodynamic and thermal stresses during launch and reentry.\nThe beginning of the development of the RS-25 Space Shuttle Main Engine was delayed for nine months while Pratt &amp; Whitney challenged the contract that had been issued to Rocketdyne. The first engine was completed in March 1975, after issues with developing the first throttleable, reusable engine. During engine testing, the RS-25 experienced multiple nozzle failures, as well as broken turbine blades. Despite the problems during testing, NASA ordered the nine RS-25 engines needed for its three orbiters under construction in May 1978.\nNASA experienced significant delays in the development of the Space Shuttle's thermal protection system. Previous NASA spacecraft had used ablative heat shields, but those could not be reused. NASA chose to use ceramic tiles for thermal protection, as the shuttle could then be constructed of lightweight aluminum, and the tiles could be individually replaced as needed. Construction began on \"Columbia\" on March 27, 1975, and it was delivered to the KSC on March 25, 1979. At the time of its arrival at the KSC, \"Columbia\" still had 6,000 of its 30,000 tiles remaining to be installed. However, many of the tiles that had been originally installed had to be replaced, requiring two years of installation before \"Columbia\" could fly.\nOn January 5, 1979, NASA commissioned a second orbiter. Later that month, Rockwell began converting STA-099 to OV-099, later named \"Challenger\". On January 29, 1979, NASA ordered two additional orbiters, OV-103 and OV-104, which were named \"Discovery\" and \"Atlantis\". Construction of OV-105, later named \"Endeavour\", began in February 1982, but NASA decided to limit the Space Shuttle fleet to four orbiters in 1983. After the loss of \"Challenger\", NASA resumed production of \"Endeavour\" in September 1987.\nTesting.\nAfter it arrived at Edwards AFB, \"Enterprise\" underwent flight testing with the Shuttle Carrier Aircraft, a Boeing 747 that had been modified to carry the orbiter. In February 1977, \"Enterprise\" began the Approach and Landing Tests (ALT) and underwent captive flights, where it remained attached to the Shuttle Carrier Aircraft for the duration of the flight. On August 12, 1977, \"Enterprise\" conducted its first glide test, where it detached from the Shuttle Carrier Aircraft and landed at Edwards AFB. After four additional flights, \"Enterprise\" was moved to the Marshall Space Flight Center (MSFC) on March 13, 1978. \"Enterprise\" underwent shake tests in the Mated Vertical Ground Vibration Test, where it was attached to an external tank and solid rocket boosters, and underwent vibrations to simulate the stresses of launch. In April 1979, \"Enterprise\" was taken to the KSC, where it was attached to an external tank and solid rocket boosters, and moved to LC-39. Once installed at the launch pad, the Space Shuttle was used to verify the proper positioning of the launch complex hardware. \"Enterprise\" was taken back to California in August 1979, and later served in the development of the SLC-6 at Vandenberg AFB in 1984.\nOn November 24, 1980, \"Columbia\" was mated with its external tank and solid-rocket boosters, and was moved to LC-39 on December\u00a029. The first Space Shuttle mission, STS-1, would be the first time NASA performed a crewed first-flight of a spacecraft. On April 12, 1981, the Space Shuttle launched for the first time, and was piloted by John Young and Robert Crippen. During the two-day mission, Young and Crippen tested equipment on board the shuttle, and found several of the ceramic tiles had fallen off the top side of the \"Columbia\". NASA coordinated with the Air Force to use satellites to image the underside of \"Columbia\", and determined there was no damage. \"Columbia\" reentered the atmosphere and landed at Edwards AFB on April 14.\nNASA conducted three additional test flights with \"Columbia\" in 1981 and 1982. On July 4, 1982, STS-4, flown by Ken Mattingly and Henry Hartsfield, landed on a concrete runway at Edwards AFB. President Ronald Reagan and his wife Nancy met the crew, and delivered a speech. After STS-4, NASA declared its Space Transportation System (STS) operational.\nDescription.\nThe Space Shuttle was the first operational orbital spacecraft designed for reuse. Each Space Shuttle orbiter was designed for a projected lifespan of 100 launches or ten years of operational life, although this was later extended. At launch, it consisted of the orbiter, which contained the crew and payload, the external tank (ET), and the two solid rocket boosters (SRBs).\nResponsibility for the Space Shuttle components was spread among multiple NASA field centers. The KSC was responsible for launch, landing, and turnaround operations for equatorial orbits (the only orbit profile actually used in the program). The U.S. Air Force at the Vandenberg Air Force Base was responsible for launch, landing, and turnaround operations for polar orbits (though this was never used). The Johnson Space Center (JSC) served as the central point for all Shuttle operations and the MSFC was responsible for the main engines, external tank, and solid rocket boosters. The John C. Stennis Space Center handled main engine testing, and the Goddard Space Flight Center managed the global tracking network.\nOrbiter.\nThe orbiter had design elements and capabilities of both a rocket and an aircraft to allow it to launch vertically and then land as a glider. Its three-part fuselage provided support for the crew compartment, cargo bay, flight surfaces, and engines. The rear of the orbiter contained the Space Shuttle Main Engines (SSME), which provided thrust during launch, as well as the Orbital Maneuvering System (OMS), which allowed the orbiter to achieve, alter, and exit its orbit once in space. Its double-delta wings were long, and were swept 81\u00b0 at the inner leading edge and 45\u00b0 at the outer leading edge. Each wing had an inboard and outboard elevon to provide flight control during reentry, along with a flap located between the wings, below the engines to control pitch. The orbiter's vertical stabilizer was swept backwards at 45\u00b0 and contained a rudder that could split to act as a speed brake. The vertical stabilizer also contained a two-part drag parachute system to slow the orbiter after landing. The orbiter used retractable landing gear with a nose landing gear and two main landing gear, each containing two tires. The main landing gear contained two brake assemblies each, and the nose landing gear contained an electro-hydraulic steering mechanism.\nCrew.\nThe Space Shuttle crew varied per mission. They underwent rigorous testing and training to meet the qualification requirements for their roles. The crew was divided into three categories: Pilots, Mission Specialists, and Payload Specialists. Pilots were further divided into two roles: the Space Shuttle Commander, who would seat in the forward left seat and the Space Shuttle Pilot who would seat in the forward right seat. The test flights, STS-1 through STS-4 only had two members each, the commander and pilot. The commander and the pilot were both qualified to fly and land the orbiter. The on-orbit operations, such as experiments, payload deployment, and EVAs, were conducted primarily by the mission specialists who were specifically trained for their intended missions and systems. Early in the Space Shuttle program, NASA flew with payload specialists, who were typically systems specialists who worked for the company paying for the payload's deployment or operations. The final payload specialist, Gregory B. Jarvis, flew on STS-51-L, and future non-pilots were designated as mission specialists. An astronaut flew as a crewed spaceflight engineer on both STS-51-C and STS-51-J to serve as a military representative for a National Reconnaissance Office payload. A Space Shuttle crew typically had seven astronauts, with STS-61-A flying with eight.\nCrew compartment.\nThe crew compartment comprised three decks and was the pressurized, habitable area on all Space Shuttle missions. The flight deck consisted of two seats for the commander and pilot, as well as an additional two to four seats for crew members. The mid-deck was located below the flight deck and was where the galley and crew bunks were set up, as well as three or four crew member seats. The mid-deck contained the airlock, which could support two astronauts on an extravehicular activity (EVA), as well as access to pressurized research modules. An equipment bay was below the mid-deck, which stored environmental control and waste management systems.\nOn the first four Shuttle missions, astronauts wore modified U.S. Air Force high-altitude full-pressure suits, which included a full-pressure helmet during ascent and descent. From the fifth flight, STS-5, until the loss of \"Challenger\", the crew wore one-piece light blue nomex flight suits and partial-pressure helmets. After the \"Challenger\" disaster, the crew members wore the Launch Entry Suit (LES), a partial-pressure version of the high-altitude pressure suits with a helmet. In 1994, the LES was replaced by the full-pressure Advanced Crew Escape Suit (ACES), which improved the safety of the astronauts in an emergency situation. \"Columbia\" originally had modified SR-71 zero-zero ejection seats installed for the ALT and first four missions, but these were disabled after STS-4 and removed after STS-9.\nThe flight deck was the top level of the crew compartment and contained the flight controls for the orbiter. The commander sat in the front left seat, and the pilot sat in the front right seat, with two to four additional seats set up for additional crew members. The instrument panels contained over 2,100 displays and controls, and the commander and pilot were both equipped with a heads-up display (HUD) and a Rotational Hand Controller (RHC) to gimbal the engines during powered flight and fly the orbiter during unpowered flight. Both seats also had rudder controls, to allow rudder movement in flight and nose-wheel steering on the ground. The orbiter vehicles were originally installed with the Multifunction CRT Display System (MCDS) to display and control flight information. The MCDS displayed the flight information at the commander and pilot seats, as well as at the aft seating location, and also controlled the data on the HUD. In 1998, \"Atlantis\" was upgraded with the Multifunction Electronic Display System (MEDS), which was a glass cockpit upgrade to the flight instruments that replaced the eight MCDS display units with 11 multifunction colored digital screens. MEDS was flown for the first time in May 2000 on STS-101, and the other orbiter vehicles were upgraded to it. The aft section of the flight deck contained windows looking into the payload bay, as well as an RHC to control the Remote Manipulator System during cargo operations. Additionally, the aft flight deck had monitors for a closed-circuit television to view the cargo bay.\nThe mid-deck contained the crew equipment storage, sleeping area, galley, medical equipment, and hygiene stations for the crew. The crew used modular lockers to store equipment that could be scaled depending on their needs, as well as permanently installed floor compartments. The mid-deck contained a port-side hatch that the crew used for entry and exit while on Earth.\nAirlock.\nThe airlock is a structure installed to allow movement between two spaces with different gas components, conditions, or pressures. Continuing on the mid-deck structure, each orbiter was originally installed with an internal airlock in the mid-deck. The internal airlock was installed as an external airlock in the payload bay on \"Discovery\", \"Atlantis\", and \"Endeavour\" to improve docking with Mir and the ISS, along with the Orbiter Docking System. The airlock module can be fitted in the mid-bay, or connected to it but in the payload bay.81 With an internal cylindrical volume of diameter and in length, it can hold two suited astronauts. It has two D-shaped hatchways long (diameter), and wide.82\nFlight systems.\nThe orbiter was equipped with an avionics system to provide information and control during atmospheric flight. Its avionics suite contained three microwave scanning beam landing systems, three gyroscopes, three TACANs, three accelerometers, two radar altimeters, two barometric altimeters, three attitude indicators, two Mach indicators, and two Mode\u00a0C transponders. During reentry, the crew deployed two air data probes once they were traveling slower than Mach 5. The orbiter had three inertial measuring units (IMU) that it used for guidance and navigation during all phases of flight. The orbiter contains two star trackers to align the IMUs while in orbit. The star trackers are deployed while in orbit, and can automatically or manually align on a star. In 1991, NASA began upgrading the inertial measurement units with an inertial navigation system (INS), which provided more accurate location information. In 1993, NASA flew a GPS receiver for the first time aboard STS-51. In 1997, Honeywell began developing an integrated GPS/INS to replace the IMU, INS, and TACAN systems, which first flew on STS-118 in August 2007.\nWhile in orbit, the crew primarily communicated using one of four S band radios, which provided both voice and data communications. Two of the S\u00a0band radios were phase modulation transceivers, and could transmit and receive information. The other two S\u00a0band radios were frequency modulation transmitters and were used to transmit data to NASA. As S\u00a0band radios can operate only within their line of sight, NASA used the Tracking and Data Relay Satellite System and the Spacecraft Tracking and Data Acquisition Network ground stations to communicate with the orbiter throughout its orbit. Additionally, the orbiter deployed a high-bandwidth Ku\u00a0band radio out of the cargo bay, which could also be utilized as a rendezvous radar. The orbiter was also equipped with two UHF radios for communications with air traffic control and astronauts conducting EVA.\nThe Space Shuttle's fly-by-wire control system was entirely reliant on its main computer, the Data Processing System (DPS). The DPS controlled the flight controls and thrusters on the orbiter, as well as the ET and SRBs during launch. The DPS consisted of five general-purpose computers (GPC), two magnetic tape mass memory units (MMUs), and the associated sensors to monitor the Space Shuttle components. The original GPC used was the IBM AP-101B, which used a separate central processing unit (CPU) and input/output processor (IOP), and non-volatile solid-state memory. From 1991 to 1993, the orbiter vehicles were upgraded to the AP-101S, which improved the memory and processing capabilities, and reduced the volume and weight of the computers by combining the CPU and IOP into a single unit. Four of the GPCs were loaded with the Primary Avionics Software System (PASS), which was Space Shuttle-specific software that provided control through all phases of flight. During ascent, maneuvering, reentry, and landing, the four PASS GPCs functioned identically to produce quadruple redundancy and would error check their results. In case of a software error that would cause erroneous reports from the four PASS GPCs, a fifth GPC ran the Backup Flight System, which used a different program and could control the Space Shuttle through ascent, orbit, and reentry, but could not support an entire mission. The five GPCs were separated in three separate bays within the mid-deck to provide redundancy in the event of a cooling fan failure. After achieving orbit, the crew would switch some of the GPCs functions from guidance, navigation, and control (GNC) to systems management (SM) and payload (PL) to support the operational mission. The Space Shuttle was not launched if its flight would run from December to January, as its flight software would have required the orbiter vehicle's computers to be reset at the year change. In 2007, NASA engineers devised a solution so Space Shuttle flights could cross the year-end boundary.\nSpace Shuttle missions typically brought a portable general support computer (PGSC) that could integrate with the orbiter vehicle's computers and communication suite, as well as monitor scientific and payload data. Early missions brought the Grid Compass, one of the first laptop computers, as the PGSC, but later missions brought Apple and Intel laptops.\nPayload bay.\nThe payload bay comprised most of the orbiter vehicle's fuselage, and provided the cargo-carrying space for the Space Shuttle's payloads. It was long and wide, and could accommodate cylindrical payloads up to in diameter. Two payload bay doors hinged on either side of the bay, and provided a relatively airtight seal to protect payloads from heating during launch and reentry. Payloads were secured in the payload bay to the attachment points on the longerons. The payload bay doors served an additional function as radiators for the orbiter vehicle's heat, and were opened upon reaching orbit for heat rejection.\nThe orbiter could be used in conjunction with a variety of add-on components depending on the mission. This included orbital laboratories, boosters for launching payloads farther into space, the Remote Manipulator System (RMS), and optionally the EDO pallet to extend the mission duration. To limit the fuel consumption while the orbiter was docked at the ISS, the Station-to-Shuttle Power Transfer System (SSPTS) was developed to convert and transfer station power to the orbiter. The SSPTS was first used on STS-118, and was installed on \"Discovery\" and \"Endeavour\".\nRemote Manipulator System.\nThe Remote Manipulator System (RMS), also known as Canadarm, was a mechanical arm attached to the cargo bay. It could be used to grasp and manipulate payloads, as well as serve as a mobile platform for astronauts conducting an EVA. The RMS was built by the Canadian company Spar Aerospace and was controlled by an astronaut inside the orbiter's flight deck using their windows and closed-circuit television. The RMS allowed for six degrees of freedom and had six joints located at three points along the arm. The original RMS could deploy or retrieve payloads up to , which was later improved to .\nSpacelab.\nThe Spacelab module was a European-funded pressurized laboratory that was carried within the payload bay and allowed for scientific research while in orbit. The Spacelab module contained two segments that were mounted in the aft end of the payload bay to maintain the center of gravity during flight. Astronauts entered the Spacelab module through a tunnel that connected to the airlock. The Spacelab equipment was primarily stored in pallets, which provided storage for both experiments as well as computer and power equipment. Spacelab hardware was flown on 28 missions through 1999 and studied subjects including astronomy, microgravity, radar, and life sciences. Spacelab hardware also supported missions such as Hubble Space Telescope (HST) servicing and space station resupply. The Spacelab module was tested on STS-2 and STS-3, and the first full mission was on STS-9.\nRS-25 engines.\nThree RS-25 engines, also known as the Space Shuttle Main Engines (SSME), were mounted on the orbiter's aft fuselage in a triangular pattern. The engine nozzles could gimbal \u00b110.5\u00b0 in pitch, and \u00b18.5\u00b0 in yaw during ascent to change the direction of their thrust to steer the Shuttle. The titanium alloy reusable engines were independent of the orbiter vehicle and would be removed and replaced in between flights. The RS-25 is a staged-combustion cycle cryogenic engine that used liquid oxygen and hydrogen and had a higher chamber pressure than any previous liquid-fueled rocket. The original main combustion chamber operated at a maximum pressure of . The engine nozzle is tall and has an interior diameter of . The nozzle is cooled by 1,080 interior lines carrying liquid hydrogen and is thermally protected by insulative and ablative material.\nThe RS-25 engines had several improvements to enhance reliability and power. During the development program, Rocketdyne determined that the engine was capable of safe reliable operation at 104% of the originally specified thrust. To keep the engine thrust values consistent with previous documentation and software, NASA kept the originally specified thrust at 100%, but had the RS-25 operate at higher thrust. RS-25 upgrade versions were denoted as Block I and Block II. 109% thrust level was achieved with the Block II engines in 2001, which reduced the chamber pressure to , as it had a larger throat area. The normal maximum throttle was 104 percent, with 106% or 109% used for mission aborts.\nOrbital Maneuvering System.\nThe Orbital Maneuvering System (OMS) consisted of two aft-mounted AJ10-190 engines and the associated propellant tanks. The AJ10 engines used monomethylhydrazine (MMH) oxidized by dinitrogen tetroxide (N2O4). The pods carried a maximum of of MMH and of N2O4. The OMS engines were used after main engine cut-off (MECO) for orbital insertion. Throughout the flight, they were used for orbit changes, as well as the deorbit burn prior to reentry. Each OMS engine produced of thrust, and the entire system could provide of velocity change.\nThermal protection system.\nThe orbiter was protected from heat during reentry by the thermal protection system (TPS), a thermal soaking protective layer around the orbiter. In contrast with previous US spacecraft, which had used ablative heat shields, the reusability of the orbiter required a multi-use heat shield. During reentry, the TPS experienced temperatures up to , but had to keep the orbiter vehicle's aluminum skin temperature below . The TPS primarily consisted of four types of tiles. The nose cone and leading edges of the wings experienced temperatures above , and were protected by reinforced carbon-carbon tiles (RCC). Thicker RCC tiles were developed and installed in 1998 to prevent damage from micrometeoroid and orbital debris, and were further improved after RCC damage caused in the \"Columbia\" disaster. Beginning with STS-114, the orbiter vehicles were equipped with the wing leading edge impact detection system to alert the crew to any potential damage. The entire underside of the orbiter vehicle, as well as the other hottest surfaces, were protected with tiles of high-temperature reusable surface insulation, made of borosilicate glass-coated silica fibers that trapped heat in air pockets and redirected it out. Areas on the upper parts of the orbiter vehicle were coated in tiles of white low-temperature reusable surface insulation with similar composition, which provided protection for temperatures below . The payload bay doors and parts of the upper wing surfaces were coated in reusable Nomex felt surface insulation or in beta cloth, as the temperature there remained below .\nExternal tank.\nThe Space Shuttle external tank (ET) carried the propellant for the Space Shuttle Main Engines, and connected the orbiter vehicle with the solid rocket boosters. The ET was tall and in diameter, and contained separate tanks for liquid oxygen and liquid hydrogen. The liquid oxygen tank was housed in the nose of the ET, and was tall. The liquid hydrogen tank comprised the bulk of the ET, and was tall. The orbiter vehicle was attached to the ET at two umbilical plates, which contained five propellant and two electrical umbilicals, and forward and aft structural attachments. The exterior of the ET was covered in orange spray-on foam to allow it to survive the heat of ascent.421\u2013422\nThe ET provided propellant to the Space Shuttle Main Engines from liftoff until main engine cutoff. The ET separated from the orbiter vehicle 18 seconds after engine cutoff and could be triggered automatically or manually. At the time of separation, the orbiter vehicle retracted its umbilical plates, and the umbilical cords were sealed to prevent excess propellant from venting into the orbiter vehicle. After the bolts attached at the structural attachments were sheared, the ET separated from the orbiter vehicle. At the time of separation, gaseous oxygen was vented from the nose to cause the ET to tumble, ensuring that it would break up upon reentry. The ET was the only major component of the Space Shuttle system that was not reused, and it would travel along a ballistic trajectory into the Indian or Pacific Ocean.\nFor the first two missions, STS-1 and STS-2, the ET was covered in of white fire-retardant latex paint to provide protection against damage from ultraviolet radiation. Further research determined that the orange foam itself was sufficiently protected, and the ET was no longer covered in latex paint beginning on STS-3. A light-weight tank (LWT) was first flown on STS-6, which reduced tank weight by . The LWT's weight was reduced by removing components from the hydrogen tank and reducing the thickness of some skin panels. In 1998, a super light-weight ET (SLWT) first flew on STS-91. The SLWT used the 2195 aluminum-lithium alloy, which was 40% stronger and 10% less dense than its predecessor, 2219 aluminum-lithium alloy. The SLWT weighed less than the LWT, which allowed the Space Shuttle to deliver heavy elements to ISS's high inclination orbit.\nSolid Rocket Boosters.\nThe Solid Rocket Boosters (SRB) provided 71.4% of the Space Shuttle's thrust during liftoff and ascent, and were the largest solid-propellant motors ever flown. Each SRB was tall and wide, weighed , and had a steel exterior approximately thick. The SRB's subcomponents were the solid-propellant motor, nose cone, and rocket nozzle. The solid-propellant motor comprised the majority of the SRB's structure. Its casing consisted of 11 steel sections which made up its four main segments. The nose cone housed the forward separation motors and the parachute systems that were used during recovery. The rocket nozzles could gimbal up to 8\u00b0 to allow for in-flight adjustments.\nThe rocket motors were each filled with a total of solid rocket propellant (APCP+PBAN), and joined in the Vehicle Assembly Building (VAB) at KSC. In addition to providing thrust during the first stage of launch, the SRBs provided structural support for the orbiter vehicle and ET, as they were the only system that was connected to the mobile launcher platform (MLP). At the time of launch, the SRBs were armed at T\u22125\u00a0minutes, and could only be electrically ignited once the RS-25 engines had ignited and were without issue. They each provided of thrust, which was later improved to beginning on STS-8. After expending their fuel, the SRBs were jettisoned approximately two minutes after launch at an altitude of approximately . Following separation, they deployed drogue and main parachutes, landed in the ocean, and were recovered by the crews aboard the ships MV \"Freedom Star\" and MV \"Liberty Star\". Once they were returned to Cape Canaveral, they were cleaned and disassembled. The rocket motor, igniter, and nozzle were then shipped to Thiokol to be refurbished and reused on subsequent flights.\nThe SRBs underwent several redesigns throughout the program's lifetime. STS-6 and STS-7 used SRBs lighter due to walls that were thinner, but were determined to be too thin to fly safely. Subsequent flights until STS-26 used cases that were thinner than the standard-weight cases, which reduced . After the \"Challenger\" disaster as a result of an O-ring failing at low temperature, the SRBs were redesigned to provide a constant seal regardless of the ambient temperature.\nSupport vehicles.\nThe Space Shuttle's operations were supported by vehicles and infrastructure that facilitated its transportation, construction, and crew access. The crawler-transporters carried the MLP and the Space Shuttle from the VAB to the launch site. The Shuttle Carrier Aircraft (SCA) were two modified Boeing 747s that could carry an orbiter on its back. The original SCA (N905NA) was first flown in 1975, and was used for the ALT and ferrying the orbiter from Edwards AFB to the KSC on all missions prior to 1991. A second SCA (N911NA) was acquired in 1988, and was first used to transport \"Endeavour\" from the factory to the KSC. Following the retirement of the Space Shuttle, N905NA was put on display at the JSC, and N911NA was put on display at the Joe Davies Heritage Airpark in Palmdale, California. The Crew Transport Vehicle (CTV) was a modified airport jet bridge that was used to assist astronauts to egress from the orbiter after landing, where they would undergo their post-mission medical checkups. The Astrovan transported astronauts from the crew quarters in the Operations and Checkout Building to the launch pad on launch day. The NASA Railroad comprised three locomotives that transported SRB segments from the Florida East Coast Railway in Titusville to the KSC.\nMission profile.\nLaunch preparation.\nThe Space Shuttle was prepared for launch primarily in the VAB at the KSC. The SRBs were assembled and attached to the external tank on the MLP. The orbiter vehicle was prepared at the Orbiter Processing Facility (OPF) and transferred to the VAB, where a crane was used to rotate it to the vertical orientation and mate it to the external tank. Once the entire stack was assembled, the MLP was carried for to Launch Complex 39 by one of the crawler-transporters. After the Space Shuttle arrived at one of the two launchpads, it would connect to the Fixed and Rotation Service Structures, which provided servicing capabilities, payload insertion, and crew transportation. The crew was transported to the launch pad at T\u22123\u00a0hours and entered the orbiter vehicle, which was closed at T\u22122\u00a0hours. Liquid oxygen and hydrogen were loaded into the external tank via umbilicals that attached to the orbiter vehicle, which began at T\u22125\u00a0hours\u00a035\u00a0minutes. At T\u22123\u00a0hours\u00a045\u00a0minutes, the hydrogen fast-fill was complete, followed 15\u00a0minutes later by the oxygen tank fill. Both tanks were slowly filled up until the launch as the oxygen and hydrogen evaporated.\nThe launch commit criteria considered precipitation, temperatures, cloud cover, lightning forecast, wind, and humidity. The Space Shuttle was not launched under conditions where it could have been struck by lightning, as its exhaust plume could have triggered lightning by providing a current path to ground after launch, which occurred on Apollo\u00a012. The NASA Anvil Rule for a Shuttle launch stated that an anvil cloud could not appear within a distance of . The Shuttle Launch Weather Officer monitored conditions until the final decision to scrub a launch was announced. In addition to the weather at the launch site, conditions had to be acceptable at one of the Transatlantic Abort Landing sites and the SRB recovery area.\nLaunch.\nThe mission crew and the Launch Control Center (LCC) personnel completed systems checks throughout the countdown. Two built-in holds at T\u221220\u00a0minutes and T\u22129\u00a0minutes provided scheduled breaks to address any issues and additional preparation. After the built-in hold at T\u22129\u00a0minutes, the countdown was automatically controlled by the Ground Launch Sequencer (GLS) at the LCC, which stopped the countdown if it sensed a critical problem with any of the Space Shuttle's onboard systems. At T\u22123\u00a0minutes\u00a045\u00a0seconds, the engines began conducting gimbal tests, which were concluded at T\u22122\u00a0minutes\u00a015\u00a0seconds. The ground Launch Processing System handed off the control to the orbiter vehicle's GPCs at T\u221231\u00a0seconds. At T\u221216\u00a0seconds, the GPCs armed the SRBs, the sound suppression system (SPS) began to drench the MLP and SRB trenches with of water to protect the orbiter vehicle from damage by acoustical energy and rocket exhaust reflected from the flame trench and MLP during lift-off. At T\u221210\u00a0seconds, hydrogen igniters were activated under each engine bell to quell the stagnant gas inside the cones before ignition. Failure to burn these gases could trip the onboard sensors and create the possibility of an overpressure and explosion of the vehicle during the firing phase. The hydrogen tank's prevalves were opened at T\u22129.5\u00a0seconds in preparation for engine start.\nBeginning at T\u22126.6\u00a0seconds, the main engines were ignited sequentially at 120-millisecond intervals. All three RS-25 engines were required to reach 90% rated thrust by T\u22123\u00a0seconds, otherwise the GPCs would initiate an RSLS abort. If all three engines indicated nominal performance by T\u22123\u00a0seconds, they were commanded to gimbal to liftoff configuration and the command would be issued to arm the SRBs for ignition at T\u22120. Between T\u22126.6\u00a0seconds and T\u22123\u00a0seconds, while the RS-25 engines were firing but the SRBs were still bolted to the pad, the offset thrust would cause the Space Shuttle to pitch down measured at the tip of the external tank; the 3-second delay allowed the stack to return to nearly vertical before SRB ignition. This movement was nicknamed the \"twang.\" At T\u22120, the eight frangible nuts holding the SRBs to the pad were detonated, the final umbilicals were disconnected, the SSMEs were commanded to 100% throttle, and the SRBs were ignited. By T+0.23\u00a0seconds, the SRBs built up enough thrust for liftoff to commence, and reached maximum chamber pressure by T+0.6\u00a0seconds. At T\u22120, the JSC Mission Control Center assumed control of the flight from the LCC.\nAt T+4\u00a0seconds, when the Space Shuttle reached an altitude of , the RS-25 engines were throttled up to 104.5%. At approximately T+7\u00a0seconds, the Space Shuttle rolled to a heads-down orientation at an altitude of , which reduced aerodynamic stress and provided an improved communication and navigation orientation. Approximately 20\u201330\u00a0seconds into ascent and an altitude of , the RS-25 engines were throttled down to 65\u201372% to reduce the maximum aerodynamic forces at Max Q. Additionally, the shape of the SRB propellant was designed to cause thrust to decrease at the time of Max Q. The GPCs could dynamically control the throttle of the RS-25 engines based upon the performance of the SRBs.\nAt approximately T+123\u00a0seconds and an altitude of , pyrotechnic fasteners released the SRBs, which reached an apogee of before parachuting into the Atlantic Ocean. The Space Shuttle continued its ascent using only the RS-25 engines. On earlier missions, the Space Shuttle remained in the heads-down orientation to maintain communications with the tracking station in Bermuda, but later missions, beginning with STS-87, rolled to a heads-up orientation at T+6\u00a0minutes for communication with the tracking and data relay satellite constellation. The RS-25 engines were throttled at T+7\u00a0minutes\u00a030\u00a0seconds to limit vehicle acceleration to 3 \"g\". At 6\u00a0seconds prior to main engine cutoff (MECO), which occurred at T+8\u00a0minutes\u00a030\u00a0seconds, the RS-25 engines were throttled down to 67%. The GPCs controlled ET separation and dumped the remaining liquid oxygen and hydrogen to prevent outgassing while in orbit. The ET continued on a ballistic trajectory and broke up during reentry, with some small pieces landing in the Indian or Pacific Ocean.\nEarly missions used two firings of the OMS to achieve orbit; the first firing raised the apogee while the second circularized the orbit. Missions after STS-38 used the RS-25 engines to achieve the optimal apogee, and used the OMS engines to circularize the orbit. The orbital altitude and inclination were mission-dependent, and the Space Shuttle's orbits varied from .\nIn orbit.\nThe type of mission the Space Shuttle was assigned dictated the type of orbit that it entered. The initial design of the reusable Space Shuttle envisioned an increasingly cheap launch platform to deploy commercial and government satellites. Early missions routinely ferried satellites, which determined the type of orbit that the orbiter vehicle would enter. Following the \"Challenger\" disaster, many commercial payloads were moved to expendable commercial rockets, such as the Delta II. While later missions still launched commercial payloads, Space Shuttle assignments were routinely directed towards scientific payloads, such as the Hubble Space Telescope, Spacelab, and the Galileo spacecraft. Beginning with STS-71, the orbiter vehicle conducted dockings with the Mir space station. In its final decade of operation, the Space Shuttle was used for the construction of the International Space Station. Most missions involved staying in orbit several days to two weeks, although longer missions were possible with the Extended Duration Orbiter pallet. The 17 day 15 hour STS-80 mission was the longest Space Shuttle mission duration.\nRe-entry and landing.\nApproximately four hours prior to deorbit, the crew began preparing the orbiter vehicle for reentry by closing the payload doors, radiating excess heat, and retracting the Ku\u00a0band antenna. The orbiter vehicle maneuvered to an upside-down, tail-first orientation and began a 2\u20134\u00a0minute OMS burn approximately 20\u00a0minutes before it reentered the atmosphere. The orbiter vehicle reoriented itself to a nose-forward position with a 40\u00b0 angle-of-attack, and the forward reaction control system (RCS) jets were emptied of fuel and disabled prior to reentry. The orbiter vehicle's reentry was defined as starting at an altitude of , when it was traveling at approximately Mach 25. The orbiter vehicle's reentry was controlled by the GPCs, which followed a preset angle-of-attack plan to prevent unsafe heating of the TPS. During reentry, the orbiter's speed was regulated by altering the amount of drag produced, which was controlled by means of angle of attack, as well as bank angle. The latter could be used to control drag without changing the angle of attack. A series of roll reversals were performed to control azimuth while banking. The orbiter vehicle's aft RCS jets were disabled as its ailerons, elevators, and rudder became effective in the lower atmosphere. At an altitude of , the orbiter vehicle opened its speed brake on the vertical stabilizer. At 8\u00a0minutes\u00a044\u00a0seconds prior to landing, the crew deployed the air data probes, and began lowering the angle-of-attack to 36\u00b0. The orbiter's maximum glide ratio/lift-to-drag ratio varied considerably with speed, ranging from 1.3 at hypersonic speeds to 4.9 at subsonic speeds. The orbiter vehicle flew to one of the two Heading Alignment Cones, located away from each end of the runway's centerline, where it made its final turns to dissipate excess energy prior to its approach and landing. Once the orbiter vehicle was traveling subsonically, the crew took over manual control of the flight.\nThe approach and landing phase began when the orbiter vehicle was at an altitude of and traveling at . The orbiter followed either a -20\u00b0 or -18\u00b0 glideslope and descended at approximately . The speed brake was used to keep a continuous speed, and crew initiated a pre-flare maneuver to a -1.5\u00b0 glideslope at an altitude of . The landing gear was deployed 10\u00a0seconds prior to touchdown, when the orbiter was at an altitude of and traveling . A final flare maneuver reduced the orbiter vehicle's descent rate to , with touchdown occurring at , depending on the weight of the orbiter vehicle. After the landing gear touched down, the crew deployed a drag chute out of the vertical stabilizer, and began wheel braking when the orbiter was traveling slower than . After the orbiter's wheels stopped, the crew deactivated the flight components and prepared to exit.\nLanding sites.\nThe primary Space Shuttle landing site was the Shuttle Landing Facility at KSC, where 78 of the 133 successful landings occurred. In the event of unfavorable landing conditions, the Shuttle could delay its landing or land at an alternate location. The primary alternate was Edwards AFB, which was used for 54 landings. STS-3 landed at the White Sands Space Harbor in New Mexico and required extensive post-processing after exposure to the gypsum-rich sand, some of which was found in \"Columbia\" debris after STS-107. Landings at alternate airfields required the Shuttle Carrier Aircraft to transport the orbiter back to Cape Canaveral.\nIn addition to the pre-planned landing airfields, there were 85 agreed-upon emergency landing sites to be used in different abort scenarios, with 58 located in other countries. The landing locations were chosen based upon political relationships, favorable weather, a runway at least long, and TACAN or DME equipment. Additionally, as the orbiter vehicle only had UHF radios, international sites with only VHF radios would have been unable to communicate directly with the crew. Facilities on the east coast of the US were planned for East Coast Abort Landings, while several sites in Europe and Africa were planned in the event of a Transoceanic Abort Landing. The facilities were prepared with equipment and personnel in the event of an emergency shuttle landing but were never used.\nPost-landing processing.\nAfter the landing, ground crews approached the orbiter to conduct safety checks. Teams wearing self-contained breathing gear tested for the presence of hydrogen, hydrazine, monomethylhydrazine, nitrogen tetroxide, and ammonia to ensure the landing area was safe. Air conditioning and Freon lines were connected to cool the crew and equipment and dissipate excess heat from reentry. A flight surgeon boarded the orbiter and performed medical checks of the crew before they disembarked. \nOnce the orbiter was secured, it was towed to the OPF to be inspected, repaired, and prepared for the next mission. The processing included:\nSpace Shuttle program.\nThe Space Shuttle flew from April 12, 1981, until July 21, 2011. Throughout the program, the Space Shuttle had 135 missions, of which 133 returned safely. Throughout its lifetime, the Space Shuttle was used to conduct scientific research, deploy commercial, military, and scientific payloads, and was involved in the construction and operation of Mir and the ISS. During its tenure, the Space Shuttle served as the only U.S. vehicle to launch astronauts, of which there was no replacement until the launch of Crew Dragon Demo-2 on May 30, 2020.\nBudget.\nThe overall NASA budget of the Space Shuttle program has been estimated to be $221\u00a0billion (in 2012 dollars). The developers of the Space Shuttle advocated for reusability as a cost-saving measure, which resulted in higher development costs for presumed lower costs-per-launch. During the design of the Space Shuttle, the Phase B proposals were not as cheap as the initial Phase A estimates indicated; Space Shuttle program manager Robert Thompson acknowledged that reducing cost-per-pound was not the primary objective of the further design phases, as other technical requirements could not be met with the reduced costs. Development estimates made in 1972 projected a per-pound cost of payload as low as $1,109 (in 2012) per pound, but the actual payload costs, not to include the costs for the research and development of the Space Shuttle, were $37,207 (in 2012) per pound. Per-launch costs varied throughout the program and were dependent on the rate of flights as well as research, development, and investigation proceedings throughout the Space Shuttle program. In 1982, NASA published an estimate of $260\u00a0million (in 2012) per flight, which was based on the prediction of 24 flights per year for a decade. The per-launch cost from 1995 to 2002, when the orbiters and ISS were not being constructed and there was no recovery work following a loss of crew, was $806\u00a0million. NASA published a study in 1999 that concluded that costs were $576\u00a0million (in 2012) if there were seven launches per year. In 2009, NASA determined that the cost of adding a single launch per year was $252\u00a0million (in 2012), which indicated that much of the Space Shuttle program costs are for year-round personnel and operations that continued regardless of the launch rate. Accounting for the entire Space Shuttle program budget, the per-launch cost was $1.642\u00a0billion (in 2012).\nDisasters.\nOn January 28, 1986, STS-51-L disintegrated 73 seconds after launch, due to the failure of the right SRB, killing all seven astronauts on board \"Challenger\". The disaster was caused by the low-temperature impairment of an O-ring, a mission-critical seal used between segments of the SRB casing. Failure of the O-ring allowed hot combustion gases to escape from between the booster sections and burn through the adjacent ET, leading to a sequence of catastrophic events which caused the orbiter to disintegrate. Repeated warnings from design engineers voicing concerns about the lack of evidence of the O-rings' safety when the temperature was below had been ignored by NASA managers.\nOn February 1, 2003, \"Columbia\" disintegrated during re-entry, killing all seven of the STS-107 crew, because of damage to the carbon-carbon leading edge of the wing caused during launch. Ground control engineers had made three separate requests for high-resolution images taken by the Department of Defense that would have provided an understanding of the extent of the damage, while NASA's chief TPS engineer requested that astronauts on board \"Columbia\" be allowed to leave the vehicle to inspect the damage. NASA managers intervened to stop the Department of Defense's imaging of the orbiter and refused the request for the spacewalk, and thus the feasibility of scenarios for astronaut repair or rescue by \"Atlantis\" were not considered by NASA management at the time.\nCriticism.\nThe partial reusability of the Space Shuttle was one of the primary design requirements during its initial development. The technical decisions that dictated the orbiter's return and re-use reduced the per-launch payload capabilities. The original intention was to compensate for this lower payload by lowering the per-launch costs and a high launch frequency. However, the actual costs of a Space Shuttle launch were higher than initially predicted, and the Space Shuttle did not fly the intended 24 missions per year as initially predicted by NASA.\nThe Space Shuttle was originally intended as a launch vehicle to deploy satellites, which it was primarily used for on the missions prior to the \"Challenger\" disaster. NASA's pricing, which was below cost, was lower than expendable launch vehicles; the intention was that the high volume of Space Shuttle missions would compensate for early financial losses. The improvement of expendable launch vehicles and the transition away from commercial payloads on the Space Shuttle resulted in expendable launch vehicles becoming the primary deployment option for satellites. A key customer for the Space Shuttle was the National Reconnaissance Office (NRO) responsible for spy satellites. The existence of NRO's connection was classified through 1993, and secret considerations of NRO payload requirements led to lack of transparency in the program. The proposed Shuttle-Centaur program, cancelled in the wake of the \"Challenger\" disaster, would have pushed the spacecraft beyond its operational capacity.\nThe fatal \"Challenger\" and \"Columbia\" disasters demonstrated the safety risks of the Space Shuttle that could result in the loss of the crew. The spaceplane design of the orbiter limited the abort options, as the abort scenarios required the controlled flight of the orbiter to a runway or to allow the crew to egress individually, rather than the abort escape options on the Apollo and Soyuz space capsules. Early safety analyses advertised by NASA engineers and management predicted the chance of a catastrophic failure resulting in the death of the crew as ranging from 1 in 100 launches to as rare as 1 in 100,000. Following the loss of two Space Shuttle missions, the risks for the initial missions were reevaluated, and the chance of a catastrophic loss of the vehicle and crew was found to be as high as 1 in 9. NASA management was criticized afterwards for accepting increased risk to the crew in exchange for higher mission rates. Both the \"Challenger\" and \"Columbia \" reports explained that NASA culture had failed to keep the crew safe by not objectively evaluating the potential risks of the missions.\nRetirement.\nThe Space Shuttle retirement was announced in January 2004. President George W. Bush announced his Vision for Space Exploration, which called for the retirement of the Space Shuttle once it completed construction of the ISS. To ensure the ISS was properly assembled, the contributing partners determined the need for 16 remaining assembly missions in March 2006. One additional Hubble Space Telescope servicing mission was approved in October 2006. Originally, STS-134 was to be the final Space Shuttle mission. However, the \"Columbia\" disaster resulted in additional orbiters being prepared for launch on need in the event of a rescue mission. As \"Atlantis\" was prepared for the final launch-on-need mission, the decision was made in September 2010 that it would fly as STS-135 with a four-person crew that could remain at the ISS in the event of an emergency. STS-135 launched on July 8, 2011, and landed at the KSC on July 21, 2011, at 5:57\u00a0a.m.\u00a0EDT (09:57\u00a0UTC). From then until the launch of Crew Dragon Demo-2 on May 30, 2020, the US launched its astronauts aboard Russian Soyuz spacecraft.\nFollowing each orbiter's final flight, it was processed to make it safe for display. The OMS and RCS systems used presented the primary dangers due to their toxic hypergolic propellant, and most of their components were permanently removed to prevent any dangerous outgassing. \"Atlantis\" is on display at the Kennedy Space Center Visitor Complex in Florida, \"Discovery\" is on display at the Steven F. Udvar-Hazy Center in Virginia, \"Endeavour\" is on display at the California Science Center in Los Angeles, and \"Enterprise\" is displayed at the \"Intrepid\" Museum in New York. Components from the orbiters were transferred to the US Air Force, ISS program, and Russian and Canadian governments. The engines were removed to be used on the Space Launch System, and spare RS-25 nozzles were attached for display purposes.\nFor many Artemis program missions, the Space Launch System's two solid rocket boosters' engines and casings and four main engines and the Orion spacecraft's main engine will all be previously flown Space Shuttle main engines, solid rocket boosters, and Orbital Maneuvering System engines. They are refurbished legacy engines from the Space Shuttle program, some of which even date back to the early 1980s. For example, Artemis I had components that flew on 83 of the 135 Space Shuttle missions. From Artemis I to Artemis IV recycled Shuttle main engines will be used before manufacturing new engines. From Artemis I to Artemis III recycled Shuttle solid rocket boosters' engines and steel casings are to be used before building new ones. From Artemis I to Artemis VI the Orion main engine will use six previously flown Space Shuttle OMS engines.\nSee also.\nSimilar spacecraft\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28191", "revid": "461300", "url": "https://en.wikipedia.org/wiki?curid=28191", "title": "Snow", "text": "Precipitation in the form of ice crystal flakes\nSnow consists of individual ice crystals that grow while suspended in the atmosphere\u2014usually within clouds\u2014and then fall, accumulating on the ground where they undergo further changes. It consists of frozen crystalline water throughout its life cycle, starting when, under suitable conditions, the ice crystals form in the atmosphere, increase to millimeter size, precipitate and accumulate on surfaces, then metamorphose in place, and ultimately melt, slide, or sublimate away.\nSnowstorms organize and develop by feeding on sources of atmospheric moisture and cold air. Snowflakes nucleate around particles in the atmosphere by attracting supercooled water droplets, which freeze in hexagonal-shaped crystals. Snowflakes take on a variety of shapes, basic among these are platelets, needles, columns, and rime. As snow accumulates into a snowpack, it may blow into drifts. Over time, accumulated snow metamorphoses, by sintering, sublimation, and freeze-thaw. Where the climate is cold enough for year-to-year accumulation, a glacier may form. Otherwise, snow typically melts seasonally, causing runoff into streams and rivers and recharging groundwater.\nMajor snow-prone areas include the polar regions, the northernmost half of the Northern Hemisphere, and mountainous regions worldwide with sufficient moisture and cold temperatures. In the Southern Hemisphere, snow is confined primarily to mountainous areas, apart from Antarctica.\nSnow affects such human activities as transportation: creating the need for keeping roadways, wings, and windows clear; agriculture: providing water to crops and safeguarding livestock; sports such as skiing, snowboarding, and snowmachine travel; and warfare. Snow affects ecosystems, as well, by providing an insulating layer during winter under which plants and animals are able to survive the cold.\nPrecipitation.\nSnow develops in clouds that themselves are part of a larger weather system. The physics of snow crystal development in clouds results from a complex set of variables that include moisture content and temperatures. The resulting shapes of the falling and fallen crystals can be classified into a number of basic shapes and combinations thereof. Occasionally, some plate-like, dendritic and stellar-shaped snowflakes can form under clear sky with a very cold temperature inversion present.\nCloud formation.\nSnow clouds usually occur in the context of larger weather systems, the most important of which is the low-pressure area, which typically incorporates warm and cold fronts as part of its circulation. Two additional and locally productive sources of snow are lake-effect (also sea-effect) storms and elevation effects, especially in mountains.\nLow-pressure areas.\nMid-latitude cyclones are low-pressure areas which are capable of producing anything from cloudiness and mild snow storms to heavy blizzards. During a hemisphere's fall, winter, and spring, the atmosphere over continents can be cold enough through the depth of the troposphere to cause snowfall. In the Northern Hemisphere, the northern side of the low-pressure area produces the most snow. \nFronts.\nA cold front, the leading edge of a cooler mass of air, can produce frontal snowsqualls\u2014an intense frontal convective line (similar to a rainband), when temperature is near freezing at the surface. The strong convection that develops has enough moisture to produce whiteout conditions at places which the line passes over as the wind causes intense blowing snow. This type of snowsquall generally lasts less than 30 minutes at any point along its path, but the motion of the line can cover large distances. Frontal squalls may form a short distance ahead of the surface cold front or behind the cold front where there may be a deepening low-pressure system or a series of trough lines which act similar to a traditional cold frontal passage.\nA warm front can produce snow for a period as warm, moist air overrides below-freezing air and creates precipitation at the boundary. Often, snow transitions to rain in the warm sector behind the front.\nLake and ocean effects.\nLake-effect snow is produced during cooler atmospheric conditions when a cold air mass moves across long expanses of warmer lake water, warming the lower layer of air which picks up water vapor from the lake, rises up through the colder air above, freezes, and is deposited on the leeward (downwind) shores.\nThe same effect occurring over bodies of salt water is termed \"ocean-effect\" or \"bay-effect snow\". The effect is enhanced when the moving air mass is uplifted by the orographic influence of higher elevations on the downwind shores. This uplifting can produce narrow but very intense bands of precipitation which may deposit at a rate of many inches of snow each hour, often resulting in a large amount of total snowfall.\nThe areas affected by lake-effect snow are called snowbelts. These include areas east of the Great Lakes, the west coasts of northern Japan, the Kamchatka Peninsula in Russia, and areas near the Great Salt Lake, Black Sea, Caspian Sea, Baltic Sea, and parts of the northern Atlantic Ocean.\nMountain effects.\nOrographic or relief snowfall is created when moist air is forced up the windward side of mountain ranges by a large-scale wind flow. The lifting of moist air up the side of a mountain range results in adiabatic cooling, and ultimately condensation and precipitation. Moisture is gradually removed from the air by this process, leaving drier and warmer air on the descending, or leeward, side. The resulting enhanced snowfall, along with the decrease in temperature with elevation, combine to increase snow depth and seasonal persistence of snowpack in snow-prone areas.\nMountain waves have also been found to help enhance precipitation amounts downwind of mountain ranges by enhancing the lift needed for condensation and precipitation.\nCloud physics.\nA snowflake consists of roughly 1019 water molecules which are added to its core at different rates and in different patterns depending on the changing temperature and humidity within the atmosphere that the snowflake falls through on its way to the ground. As a result, snowflakes differ from each other though they follow similar patterns.\nSnow crystals form when tiny supercooled cloud droplets (about 10\u00a0\u03bcm in diameter) freeze. These droplets are able to remain liquid at temperatures lower than , because to freeze, a few molecules in the droplet need to get together by chance to form an arrangement similar to that in an ice lattice. The droplet freezes around this \"nucleus\". In warmer clouds, an aerosol particle or \"ice nucleus\" must be present in (or in contact with) the droplet to act as a nucleus. Ice nuclei are very rare compared to cloud condensation nuclei on which liquid droplets form. Clays, desert dust, and biological particles can be nuclei. Artificial nuclei include particles of silver iodide and dry ice, and these are used to stimulate precipitation in cloud seeding.\nOnce a droplet has frozen, it grows in the supersaturated environment\u2014one where air is saturated with respect to ice when the temperature is below the freezing point. The droplet then grows by diffusion of water molecules in the air (vapor) onto the ice crystal surface where they are collected. Because water droplets are so much more numerous than the ice crystals, the crystals are able to grow to hundreds of micrometers or millimeters in size at the expense of the water droplets by the Wegener\u2013Bergeron\u2013Findeisen process. These large crystals are an efficient source of precipitation, since they fall through the atmosphere due to their mass, and may collide and stick together in clusters, or aggregates. These aggregates are snowflakes, and are usually the type of ice particle that falls to the ground. Although the ice is clear, scattering of light by the crystal facets and hollows/imperfections mean that the crystals often appear white in color due to diffuse reflection of the whole spectrum of light by the small ice particles.\nClassification of snowflakes.\nMicrography of thousands of snowflakes from 1885 onward, starting with Wilson Alwyn Bentley, revealed the wide diversity of snowflakes within a classifiable set of patterns. Closely matching snow crystals have been observed.\nUkichiro Nakaya developed a crystal morphology diagram, relating crystal shapes to the temperature and moisture conditions under which they formed, which is summarized in the following table.\nNakaya discovered that the shape is also a function of whether the prevalent moisture is above or below saturation. Forms below the saturation line tend more toward solid and compact while crystals formed in supersaturated air tend more toward lacy, delicate, and ornate. Many more complex growth patterns also form, which include side-planes, bullet-rosettes, and planar types, depending on the conditions and ice nuclei. If a crystal has started forming in a column growth regime at around and then falls into the warmer plate-like regime, plate or dendritic crystals sprout at the end of the column, producing so called \"capped columns\".\nMagono and Lee devised a classification of freshly formed snow crystals that includes 80 distinct shapes. They documented each with micrographs.\nAccumulation.\nSnow accumulates from a series of snow events, punctuated by freezing and thawing, over areas that are cold enough to retain snow seasonally or perennially. Major snow-prone areas include the Arctic and Antarctic, the Northern Hemisphere, and alpine regions. The liquid equivalent of snowfall may be evaluated using a snow gauge or with a standard rain gauge, adjusted for winter by removal of a funnel and inner cylinder. Both types of gauges melt the accumulated snow and report the amount of water collected. At some automatic weather stations an ultrasonic snow depth sensor may be used to augment the precipitation gauge.\nEvent.\nSnow flurry, snow shower, snow storm and blizzard describe snow events of progressively greater duration and intensity. A blizzard is a weather condition involving snow and has varying definitions in different parts of the world. In the United States, a blizzard occurs when two conditions are met for a period of three hours or more: a sustained wind or frequent gusts to , and sufficient snow in the air to reduce visibility to less than . In Canada and the United Kingdom, the criteria are similar. While heavy snowfall often occurs during blizzard conditions, falling snow is not a requirement, as blowing snow can create a ground blizzard.\nSnowstorm intensity may be categorized by visibility and depth of accumulation. Snowfall's intensity is determined by visibility, as follows:\nSnowsqualls may deposit snow in bands that extend from bodies of water as lake-event weather or result from the passage of an upper-level front.&lt;ref name=\"popsci/nasa-snowstorm\"&gt;&lt;/ref&gt;&lt;ref name=\"weather/bandedsnowfall\"&gt;&lt;/ref&gt;&lt;ref name=\"nbcmontana/snow-bands\"&gt;&lt;/ref&gt;\nThe \"International Classification for Seasonal Snow on the Ground\" defines \"height of new snow\" as the depth of freshly fallen snow, in centimeters as measured with a ruler, that accumulated on a snowboard during an observation period of 24 hours, or other observation interval. After the measurement, the snow is cleared from the board and the board is placed flush with the snow surface to provide an accurate measurement at the end of the next interval. Melting, compacting, blowing and drifting contribute to the difficulty of measuring snowfall.\nDistribution.\nGlaciers with their permanent snowpacks cover about 10% of the earth's surface, while seasonal snow covers about nine percent, mostly in the Northern Hemisphere, where seasonal snow covers about , according to a 1987 estimate. A 2007 estimate of snow cover over the Northern Hemisphere suggested that, on average, snow cover ranges from a minimum extent of each August to a maximum extent of each January or nearly half of the land surface in that hemisphere. A study of Northern Hemisphere snow cover extent for the period 1972\u20132006 suggests a reduction of over the 35-year period.\nRecords.\nThe following are world records regarding snowfall and snowflakes:\nThe cities (more than 100,000 inhabitants) with the highest annual snowfall are Aomori (792\u00a0cm), Sapporo (485\u00a0cm) and Toyama (363\u00a0cm) in Japan, followed by St. John's (332\u00a0cm) and Quebec City (315\u00a0cm) in Canada, and Syracuse, NY (325\u00a0cm).\nMetamorphism.\nAccording to the International Association of Cryospheric Sciences, \"snow metamorphism\" is \"the transformation that the snow undergoes in the period from deposition to either melting or passage to glacial ice\". Starting as a powdery deposition, snow becomes more granular when it begins to compact under its own weight, be blown by the wind, sinter particles together and commence the cycle of melting and refreezing. Water vapor plays a role as it deposits ice crystals, known as hoar frost, during cold, still conditions. During this transition, snow \"is a highly porous, sintered material made up of a continuous ice structure and a continuously connected pore space, forming together the snow microstructure\". Almost always near its melting temperature, a snowpack is continually transforming these properties wherein all three phases of water may coexist, including liquid water partially filling the pore space. After deposition, snow progresses on one of two paths that determine its fate, either by \"ablation\" (mostly by melting) from a snowfall or seasonal snowpack, or by transitioning from firn (multi-year snow) into \"glacier ice\".\nSeasonal.\nOver the course of time, a snowpack may settle under its own weight until its density is approximately 30% of water. Increases in density above this initial compression occur primarily by melting and refreezing, caused by temperatures above freezing or by direct solar radiation. In colder climates, snow lies on the ground all winter. By late spring, snow densities typically reach a maximum of 50% of water. Snow that persists into summer evolves into n\u00e9v\u00e9, granular snow, which has been partially melted, refrozen and compacted. N\u00e9v\u00e9 has a minimum density of , which is roughly half of the density of liquid water.\nFirn.\nFirn is snow that has persisted for multiple years and has been recrystallized into a substance denser than n\u00e9v\u00e9, yet less dense and hard than glacial ice. Firn resembles caked sugar and is very resistant to shovelling. Its density generally ranges from , and it can often be found underneath the snow that accumulates at the head of a glacier. The minimum altitude that firn accumulates on a glacier is called the \"firn limit\", \"firn line\" or \"snowline\".\nMovement.\nThere are four main mechanisms for movement of deposited snow: \"drifting\" of unsintered snow, \"avalanches\" of accumulated snow on steep slopes, \"snowmelt\" during thaw conditions, and the \"movement of glaciers\" after snow has persisted for multiple years and metamorphosed into glacier ice.\nDrifting.\nWhen powdery snow drifts with the wind from the location where it originally fell, forming deposits with a depth of several meters in isolated locations. After attaching to hillsides, blown snow can evolve into a snow slab, which is an avalanche hazard on steep slopes.\nAvalanche.\nAn avalanche (also called a snowslide or snowslip) is a rapid flow of snow down a sloping surface. Avalanches are typically triggered in a starting zone from a mechanical failure in the snowpack (slab avalanche) when the forces on the snow exceed its strength but sometimes only with gradually widening (loose snow avalanche). After initiation, avalanches usually accelerate rapidly and grow in mass and volume as they entrain more snow. If the avalanche moves fast enough some of the snow may mix with the air forming a powder snow avalanche, which is a type of gravity current. They occur in three major mechanisms:\nMelting.\nMany rivers originating in mountainous or high-latitude regions receive a significant portion of their flow from snowmelt. This often makes the river's flow highly seasonal resulting in periodic flooding during the spring months and at least in dry mountainous regions like the mountain West of the US or most of Iran and Afghanistan, very low flow for the rest of the year. In contrast, if much of the melt is from glaciated or nearly glaciated areas, the melt continues through the warm season, with peak flows occurring in mid to late summer.\nGlaciers.\nGlaciers form where the accumulation of snow and ice exceeds ablation. The area in which an alpine glacier forms is called a cirque (corrie or cwm), a typically armchair-shaped geological feature, which collects snow and where the snowpack compacts under the weight of successive layers of accumulating snow, forming n\u00e9v\u00e9. Further crushing of the individual snow crystals and reduction of entrapped air in the snow turns it into glacial ice. This glacial ice will fill the cirque until it overflows through a geological weakness or an escape route, such as the gap between two mountains. When the mass of snow and ice is sufficiently thick, it begins to move due to a combination of surface slope, gravity and pressure. On steeper slopes, this can occur with as little as of snow-ice.\nScience.\nScientists study snow at a wide variety of scales that include the physics of chemical bonds and clouds; the distribution, accumulation, metamorphosis, and ablation of snowpacks; and the contribution of snowmelt to river hydraulics and ground hydrology. In doing so, they employ a variety of instruments to observe and measure the phenomena studied. Their findings contribute to knowledge applied by engineers, who adapt vehicles and structures to snow, by agronomists, who address the availability of snowmelt to agriculture, and those, who design equipment for sporting activities on snow. Scientists develop and others employ snow classification systems that describe its physical properties at scales ranging from the individual crystal to the aggregated snowpack. A sub-specialty is avalanches, which are of concern to engineers and outdoor sports people, alike.\nSnow science addresses how snow forms, its distribution, and processes affecting how snowpacks change over time. Scientists improve storm forecasting, study global snow cover and its effect on climate, glaciers, and water supplies around the world. The study includes physical properties of the material as it changes, bulk properties of in-place snow packs, and the aggregate properties of regions with snow cover. In doing so, they employ on-the-ground physical measurement techniques to establish ground truth and remote sensing techniques to develop understanding of snow-related processes over large areas.\nMeasurement and classification.\nIn the field, snow scientists often excavate a snow pit within which to make basic measurements and observations. Observations can describe features caused by wind, water percolation, or snow unloading from trees. Water percolation into a snowpack can create flow fingers and ponding or flow along capillary barriers, which can refreeze into horizontal and vertical solid ice formations within the snowpack. Among the measurements of the properties of snowpacks that the \"International Classification for Seasonal Snow on the Ground\" includes are: snow height, snow water equivalent, snow strength, and extent of snow cover. Each has a designation with a code and detailed description. The classification extends the prior classifications of Nakaya and his successors to related types of precipitation and are quoted in the following table:\n\"All are formed in cloud, except for rime, which forms on objects exposed to supercooled moisture.\"\nIt also has a more extensive classification of deposited snow than those that pertain to airborne snow. The categories include both natural and man-made snow types, descriptions of snow crystals as they metamorphose and melt, the development of hoar frost in the snow pack and the formation of ice therein. Each such layer of a snowpack differs from the adjacent layers by one or more characteristics that describe its microstructure or density, which together define the snow type, and other physical properties. Thus, at any one time, the type and state of the snow forming a layer have to be defined because its physical and mechanical properties depend on them. Physical properties include microstructure, grain size and shape, snow density, liquid water content, and temperature.\nWhen it comes to measuring snow cover on the ground, typically three variables are measured: the snow cover extent (SCE) \u2014 the land area covered by snow, snow cover duration (SD) \u2014 how long a particular area is covered by snow, and the snow accumulation, often expressed as snow water equivalent (SWE), which expresses how much water the snow would be if it were all melted: this last one is a measurement of the volume of the snowpack. To measure these variables a variety of techniques are used: surface observations, remote sensing, land surface models and reanalysis products. These techniques are often combined to form the most complete datasets.\nSatellite data.\nRemote sensing of snowpacks with satellites and other platforms typically includes multi-spectral collection of imagery. Multi-faceted interpretation of the data obtained allows inferences about what is observed. The science behind these remote observations has been verified with ground-truth studies of the actual conditions.\nSatellite observations record a decrease in snow-covered areas since the 1960s, when satellite observations began. In some regions such as China, a trend of increasing snow cover was observed from 1978 to 2006. These changes are attributed to global climate change, which may lead to earlier melting and less coverage area. In some areas, snow depth increases because of higher temperatures in latitudes north of 40\u00b0. For the Northern Hemisphere as a whole the mean monthly snow-cover extent has been decreasing by 1.3% per decade.\nThe most frequently used methods to map and measure snow extent, snow depth and snow water equivalent employ multiple inputs on the visible\u2013infrared spectrum to deduce the presence and properties of snow. The National Snow and Ice Data Center (NSIDC) uses the reflectance of visible and infrared radiation to calculate a normalized difference snow index, which is a ratio of radiation parameters that can distinguish between clouds and snow. Other researchers have developed decision trees, employing the available data to make more accurate assessments. One challenge to this assessment is where snow cover is patchy, for example during periods of accumulation or ablation and also in forested areas. Cloud cover inhibits optical sensing of surface reflectance, which has led to other methods for estimating ground conditions underneath clouds. For hydrological models, it is important to have continuous information about the snow cover. Passive microwave sensors are especially valuable for temporal and spatial continuity because they can map the surface beneath clouds and in darkness. When combined with reflective measurements, passive microwave sensing greatly extends the inferences possible about the snowpack.\nSatellite measurements show that snow cover has been decreasing in many areas of the world since 1978.\nModels.\nSnow science often leads to predictive models that include snow deposition, snow melt, and snow hydrology\u2014elements of the Earth's water cycle\u2014which help describe global climate change.\nGlobal climate change models (GCMs) incorporate snow as a factor in their calculations. Some important aspects of snow cover include its albedo (reflectivity of incident radiation, including light) and insulating qualities, which slow the rate of seasonal melting of sea ice. As of 2011, the melt phase of GCM snow models were thought to perform poorly in regions with complex factors that regulate snow melt, such as vegetation cover and terrain. These models typically derive snow water equivalent (SWE) in some manner from satellite observations of snow cover. The \"International Classification for Seasonal Snow on the Ground\" defines SWE as \"the depth of water that would result if the mass of snow melted completely\".\nGiven the importance of snowmelt to agriculture, hydrological runoff models that include snow in their predictions address the phases of accumulating snowpack, melting processes, and distribution of the meltwater through stream networks and into the groundwater. Key to describing the melting processes are solar heat flux, ambient temperature, wind, and precipitation. Initial snowmelt models used a degree-day approach that emphasized the temperature difference between the air and the snowpack to compute snow water equivalent, SWE. More recent models use an energy balance approach that take into account the following factors to compute \"Qm\", the energy available for melt. This requires measurement of an array of snowpack and environmental factors to compute six heat flow mechanisms that contribute to \"Qm\".\nEffects on civilization.\nSnow routinely affects civilization in four major areas: transportation, agriculture, structures, and sports. Most transportation modes are impeded by snow on the travel surface. Agriculture often relies on snow as a source of seasonal moisture. Structures may fail under snow loads. Humans find a wide variety of recreational activities in snowy landscapes. It also affects the conduct of warfare.\nTransportation.\nSnow affects the rights of way of highways, airfields and railroads. The snowplow is common to all workers, though roadways take anti-icing chemicals to prevent bonding of ice and airfields may not; railroads rely on abrasives for track traction.\nHighway.\nIn the late 20th century, an estimated $2 billion was spent annually in North America on roadway winter maintenance, owing to snow and other winter weather events, according to a 1994 report by Kuemmel. The study surveyed the practices of jurisdictions within 44 US states and nine Canadian provinces. It assessed the policies, practices, and equipment used for winter maintenance. It found similar practices and progress to be prevalent in Europe.\nThe dominant effect of snow on vehicle contact with the road is diminished friction. This can be improved with the use of snow tires, which have a tread designed to compact snow in a manner that enhances traction. The key to maintaining a roadway that can accommodate traffic during and after a snow event is an effective anti-icing program that employs both chemicals and plowing. The Federal Highway Administration \"Manual of Practice for an Effective Anti-icing Program\" emphasizes \"anti-icing\" procedures that prevent the bonding of snow and ice to the road. Key aspects of the practice include: understanding anti-icing in light of the level of service to be achieved on a given roadway, the climatic conditions to be encountered, and the different roles of deicing, anti-icing, and abrasive materials and applications, and employing anti-icing \"toolboxes\", one for operations, one for decision-making and another for personnel. The elements to the toolboxes are:\nThe manual offers matrices that address different types of snow and the rate of snowfall to tailor applications appropriately and efficiently.\nSnow fences, constructed upwind of roadways control snow drifting by causing windblown, drifting snow to accumulate in a desired place. They are also used on railways. Additionally, farmers and ranchers use snow fences to create drifts in basins for a ready supply of water in the spring.\nAviation.\nIn order to keep airports open during winter storms, runways and taxiways require snow removal. Unlike roadways, where chloride chemical treatment is common to prevent snow from bonding to the pavement surface, such chemicals are typically banned from airports because of their strong corrosive effect on aluminum aircraft. Consequently, mechanical brushes are often used to complement the action of snow plows. Given the width of runways on airfields that handle large aircraft, vehicles with large plow blades, an echelon of plow vehicles or rotary snowplows are used to clear snow on runways and taxiways. Terminal aprons may require or more to be cleared.\nProperly equipped aircraft are able to fly through snowstorms under instrument flight rules. Prior to takeoff, they require deicing fluid during snowstorms to prevent accumulation and freezing of snow and other precipitation on wings and fuselages, which may compromise the safety of the aircraft and its occupants. In flight, aircraft rely on a variety of mechanisms to avoid rime and other types of icing in clouds, these include pulsing pneumatic boots, electro-thermal areas that generate heat, and fluid deicers that bleed onto the surface.\nRail.\nRailroads have traditionally employed two types of snow plows for clearing track: the wedge plow, which casts snow to both sides, and the rotary snowplow, which is suited for addressing heavy snowfall and casting snow far to one side or the other. Prior to the invention of the rotary snowplow ca. 1865, it required multiple locomotives to drive a wedge plow through deep snow. After clearing the track with such plows, a \"flanger\" is used to clear snow from between the rails that are below the reach of the other types of plows. Where icing may affect the steel-to-steel contact of locomotive wheels on track, abrasives (typically sand) have been used to provide traction on steeper uphills.\nRailroads employ snow sheds\u2014structures that cover the track\u2014to prevent the accumulation of heavy snow or avalanches to cover tracks in snowy mountainous areas, such as the Alps and the Rocky Mountains.\nConstruction.\nSnow can be compacted to form a snow road and be part of a winter road route for vehicles to access isolated communities or construction projects during the winter. Snow can also be used to provide the supporting structure and surface for a runway, as with the Phoenix Airfield in Antarctica. The snow-compacted runway is designed to withstand approximately 60 wheeled flights of heavy-lift military aircraft a year.\nAgriculture.\nSnowfall can be beneficial to agriculture by serving as a thermal insulator, conserving the heat of the Earth and protecting crops from subfreezing weather. Some agricultural areas depend on an accumulation of snow during winter that will melt gradually in spring, providing water for crop growth, both directly and via runoff through streams and rivers, which supply irrigation canals. The following are examples of rivers that rely on meltwater from glaciers or seasonal snowpack as an important part of their flow on which irrigation depends: the Ganges, many of whose tributaries rise in the Himalayas and which provide much irrigation in northeast India, the Indus River, which rises in Tibet and provides irrigation water to Pakistan from rapidly retreating Tibetan glaciers, and the Colorado River, which receives much of its water from seasonal snowpack in the Rocky Mountains and provides irrigation water to some .\nStructures.\nSnow is an important consideration for loads on structures. To address these, European countries employ \"Eurocode 1: Actions on structures - Part 1-3: General actions - Snow loads\". In North America, ASCE \"Minimum Design Loads for Buildings and Other Structures\" gives guidance on snow loads. Both standards employ methods that translate maximum expected ground snow loads onto design loads for roofs.\nRoofs.\nSnow loads and icings are two principal issues for roofs. Snow loads are related to the climate in which a structure is sited. Icings are usually a result of the building or structure generating heat that melts the snow that is on it.\n\"Snow loads\" \u2013 The \"Minimum Design Loads for Buildings and Other Structures\" gives guidance on how to translate the following factors into roof snow loads:\nIt gives tables for ground snow loads by region and a methodology for computing ground snow loads that may vary with elevation from nearby, measured values. The \"Eurocode 1\" uses similar methodologies, starting with ground snow loads that are tabulated for portions of Europe.\n\"Icings\" \u2013 Roofs must also be designed to avoid ice dams, which result from meltwater running under the snow on the roof and freezing at the eave. Ice dams on roofs form when accumulated snow on a sloping roof melts and flows down the roof, under the insulating blanket of snow, until it reaches below freezing temperature air, typically at the eaves. When the meltwater reaches the freezing air, ice accumulates, forming a dam, and snow that melts later cannot drain properly through the dam. Ice dams may result in damaged building materials or in damage or injury when the ice dam falls off or from attempts to remove ice dams. The melting results from heat passing through the roof under the highly insulating layer of snow.\nUtility lines.\nIn areas with trees, utility distribution lines on poles are less susceptible to snow loads than they are subject to damage from trees falling on them, felled by heavy, wet snow. Elsewhere, snow can accrete on power lines as \"sleeves\" of rime ice. Engineers design for such loads, which are measured in kg/m (lb/ft) and power companies have forecasting systems that anticipate types of weather that may cause such accretions. Rime ice may be removed manually or by creating a sufficient short circuit in the affected segment of power lines to melt the accretions.\nSports and recreation.\nSnow figures into many winter sports and forms of recreation, including skiing and sledding. Common examples include cross-country skiing, Alpine skiing, snowboarding, snowshoeing, and snowmobiling. The design of the equipment used, e.g. skis and snowboards, typically relies on the bearing strength of snow and contends with the coefficient of friction bearing on snow.\nSkiing is by far the largest form of winter recreation. As of 1994, of the estimated 65\u201375 million skiers worldwide, there were approximately 55 million who engaged in Alpine skiing, the rest engaged in cross-country skiing. Approximately 30 million skiers (of all kinds) were in Europe, 15 million in the US, and 14 million in Japan. As of 1996, there were reportedly 4,500 ski areas, operating 26,000 ski lifts and enjoying 390 million skier visits per year. The preponderant region for downhill skiing was Europe, followed by Japan and the US.\nIncreasingly, ski resorts are relying on snowmaking, the production of snow by forcing water and pressurized air through a snow gun on ski slopes. Snowmaking is mainly used to supplement natural snow at ski resorts. This allows them to improve the reliability of their snow cover and to extend their ski seasons from late autumn to early spring. The production of snow requires low temperatures. The threshold temperature for snowmaking increases as humidity decreases. Wet-bulb temperature is used as a metric since it takes air temperature and relative humidity into account. Snowmaking is a relatively expensive process in its energy consumption, thereby limiting its use.\nSki wax enhances the ability of a ski (or other runner) to slide over snow by reducing its coefficient of friction, which depends on both the properties of the snow and the ski to result in an optimum amount of lubrication from melting the snow by friction with the ski\u2014too little and the ski interacts with solid snow crystals, too much and capillary attraction of meltwater retards the ski. Before a ski can slide, it must overcome the maximum value static friction. Kinetic (or dynamic) friction occurs when the ski is moving over the snow.\nWarfare.\nSnow affects warfare conducted in winter, alpine environments or at high latitudes. The main factors are \"impaired visibility\" for acquiring targets during falling snow, \"enhanced visibility\" of targets against snowy backgrounds for targeting, and mobility for both mechanized and infantry troops. Snowfall can severely inhibit the logistics of supplying troops, as well. Snow can also provide cover and fortification against small-arms fire. Noted winter warfare campaigns where snow and other factors affected the operations include:\nEffects on plants and animals.\nPlants and animals endemic to snowbound areas develop ways to adapt. Among the adaptive mechanisms for plants are freeze-adaptive chemistry, dormancy, seasonal dieback, survival of seeds; and for animals are hibernation, insulation, anti-freeze chemistry, storing food, drawing on reserves from within the body, and clustering for mutual heat.\nSnow interacts with vegetation in two principal ways: vegetation can influence the deposition and retention of snow and, conversely, the presence of snow can affect the distribution and growth of vegetation. Tree branches, especially of conifers intercept falling snow and prevent accumulation on the ground. Snow suspended in trees ablates more rapidly than that on the ground, owing to its greater exposure to sun and air movement. Trees and other plants can also promote snow retention on the ground, which would otherwise be blown elsewhere or melted by the sun. Snow affects vegetation in several ways, the presence of stored water can promote growth, yet the annual onset of growth is dependent on the departure of the snowpack for those plants that are buried beneath it. Furthermore, avalanches and erosion from snowmelt can scour terrain of vegetation.\nSnow supports a wide variety of animals both on the surface and beneath. Many invertebrates thrive in snow, including spiders, wasps, beetles, snow scorpionflies and springtails. Such arthropods are typically active at temperatures down to . Invertebrates fall into two groups, regarding surviving subfreezing temperatures: freezing-resistant and those that avoid freezing because they are freeze-sensitive. The first group may be cold hardy owing to the ability to produce antifreeze agents in their body fluids that allows survival of long exposure to sub-freezing conditions. Some organisms fast during the winter, which expels freezing-sensitive contents from their digestive tracts. The ability to survive the absence of oxygen in ice is an additional survival mechanism.\nSmall vertebrates are active beneath the snow. Among vertebrates, alpine salamanders are active in snow at temperatures as low as ; they burrow to the surface in springtime and lay their eggs in melt ponds. Among mammals, those that remain active are typically smaller than . Omnivores are more likely to enter a torpor or be hibernators, whereas herbivores are more likely to maintain food caches beneath the snow. Voles store up to of food and pikas up to . Voles also huddle in communal nests to benefit from one another's warmth. On the surface, wolves, coyotes, foxes, lynx, and weasels rely on these subsurface dwellers for food and often dive into the snowpack to find them.\nOutside of Earth.\nExtraterrestrial \"snow\" includes water-based precipitation, but also precipitation of other compounds prevalent on other planets and moons in the Solar System. Examples are:\nSee also.\nLexicon\nNotable snow events\nRecreation\nRelated concepts\nScience and scientists\nSnow structures\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "28192", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=28192", "title": "Seek time", "text": ""}
{"id": "28195", "revid": "36449898", "url": "https://en.wikipedia.org/wiki?curid=28195", "title": "Symbolics", "text": "Defunct American computer manufacturer (1980\u20131996)\nSymbolics, Inc. is a privately held American computer software maker that acquired the assets of the former manufacturing company of the identical name and continues to sell and maintain the Open Genera Lisp system and the Macsyma computer algebra system.\nThe symbolics.com domain was originally registered on 15 March 1985, making it the first .com-domain in the world. In August 2009, it was sold to napkin.com (formerly XF.com) Investments.\nHistory.\nSymbolics, Inc. was a computer manufacturer headquartered in Cambridge, Massachusetts, and later in Concord, Massachusetts, with manufacturing facilities in Chatsworth, Los Angeles. Robert P. Adams (an MIT graduate) was Symbolics\u2019 first President and co-founder along with Russell Noftsker, and in fact, the name \u201cSymbolics\u201d was coined by Robert Adams while the company was initially being formed in his home in Santa Monica, California. Its first CEO, chairman, and co-founder was Russell Noftsker. Symbolics designed and manufactured a line of Lisp machines, single-user computers optimized to run the programming language Lisp. Symbolics also made significant advances in software technology, and offered one of the premier software development environments of the 1980s and 1990s, now sold commercially as Open Genera for Tru64 UNIX on the Hewlett-Packard (HP) Alpha.\nSymbolics was a spinoff from the MIT AI Lab, one of two companies to be founded by AI Lab staffers and associated hackers for the purpose of manufacturing Lisp machines. The other was Lisp Machines, Inc., although Symbolics attracted most of the hackers, and more funding.\nSymbolics' initial product, the LM-2, introduced in 1981, was a repackaged version of the MIT CADR Lisp machine design. The operating system and software development environment, over 500,000 lines, was written in Lisp from the microcode up, based on MIT's Lisp Machine Lisp.\nThe software bundle was later renamed ZetaLisp, to distinguish the Symbolics' product from other vendors who had also licensed the MIT software. Symbolics' Zmacs text editor, a variant of Emacs, was implemented in a text-processing package named \"ZWEI\", an acronym for \"Zwei was Eine initially\", with \"Eine\" being an acronym for \"Eine Is Not Emacs\". Both are recursive acronyms and puns on the German words for \"one\" (\"eins\", \"eine\") and \"two\" (\"zwei\").\nThe Lisp Machine system software was then copyrighted by MIT, and was licensed to both Symbolics and LMI. Until 1981, Symbolics shared all its copyrighted enhancements to the source code with MIT and kept it on an MIT server. According to Richard Stallman, Symbolics engaged in a business tactic in which it forced MIT to make all Symbolics' copyrighted fixes and improvements to the Lisp Machine OS available only to Symbolics (and MIT but not to Symbolics competitors), and thereby choke off its competitor LMI, which at that time had insufficient resources to independently maintain or develop the OS and environment.\nSymbolics felt that they no longer had sufficient control over their product. At that point, Symbolics began using their own copy of the software, located on their company servers, while Stallman says that Symbolics did that to prevent its Lisp improvements from flowing to Lisp Machines, Inc. From that base, Symbolics made extensive improvements to every part of the software, and continued to deliver almost all the source code to their customers (including MIT). However, the policy prohibited MIT staff from distributing the Symbolics version of the software to others. With the end of open collaboration came the end of the MIT hacker community. As a reaction to this, Stallman initiated the GNU project to make a new community. Eventually, Copyleft and the GNU General Public License would ensure that a hacker's software could remain free software. In this way, Symbolics played a key, albeit adversarial, role in instigating the free software movement.\nThe 3600 series.\nIn 1983, a year later than planned, Symbolics introduced the 3600 family of Lisp machines. Code-named the \"L-machine\" internally, the 3600 family was an innovative new design, inspired by the CADR architecture but sharing few of its implementation details. The main processor had a 36-bit word (divided up as 4 or 8 bits of tags, and 32 bits of data or 28 bits of memory address). Memory words were 44 bits, the additional 8 bits being used for error-correcting code (ECC). The instruction set was that of a stack machine. The 3600 architecture provided 4,096 hardware registers, of which half were used as a cache for the top of the control stack; the rest were used by the microcode and time-critical routines of the operating system and Lisp run-time environment. Hardware support was provided for virtual memory, which was common for machines in its class, and for garbage collection, which was unique.\nThe original 3600 processor was a microprogrammed design like the CADR, and was built on several large circuit boards from standard TTL integrated circuits, both features being common for commercial computers in its class at the time. Central processing unit (CPU) clock speed varied depending on which instruction was being executed, but was typically around 5\u00a0MHz. Many Lisp primitives could be executed in a single clock cycle. Disk input/output (I/O) was handled by multitasking inside of the microcode level. A 68000 processor (termed the \"front-end processor\", (FEP)) started the main computer up, and handled the slower peripherals during normal operation. An Ethernet interface was standard equipment, replacing the Chaosnet interface of the LM-2.\nThe 3600 was roughly the size of a household refrigerator. This was partly due to the size of the processor (the cards were widely spaced to allow wire-wrap prototype cards to fit without interference) and partly due to the size of disk drive technology in the early 1980s. At the 3600's introduction, the smallest disk that could support the ZetaLisp software was wide (most 3600s shipped with the 10\u00bd-inch Fujitsu Eagle). The 3670 and 3675 were slightly shorter in height, but were essentially the same machine packed a little tighter. The advent of , and later , disk drives that could hold hundreds of megabytes led to the introduction of the 3640 and 3645, which were roughly the size of a two-drawer file cabinet.\nLater versions of the 3600 architecture were implemented on custom integrated circuits, reducing the five cards of the original processor design to two, at a large manufacturing cost savings and with performance slightly better than the old design. The 3650, first of the \"G machines\", as they were known within the company, was housed in a cabinet derived from the 3640s. Denser memory and smaller disk drives enabled the introduction of the 3620, about the size of a modern full-size tower PC. The 3630 was a \"fat 3620\" with room for more memory and video interface cards. The 3610 was a lower priced variant of the 3620, essentially identical in every way except that it was licensed for application deployment rather than general development.\nThe various models of the 3600 family were popular for artificial intelligence (AI) research and commercial applications throughout the 1980s. The AI commercialization boom of the 1980s led directly to Symbolics' success during the decade. Symbolics computers were widely believed to be the best platform available for developing AI software. The LM-2 used a Symbolics-branded version of the complex space-cadet keyboard, while later models used a simplified version (at right), known simply as the \"&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Symbolics keyboard\". The Symbolics keyboard featured the many modifier keys used in Zmacs, notably Control/Meta/Super/Hyper in a block, but did not feature the complex symbol set of the space-cadet keyboard.\nAlso contributing to the 3600 series' success was a line of bit-mapped graphics color video interfaces, combined with extremely powerful animation software. Symbolics' Graphics Division, headquartered in Westwood, Los Angeles, California, near to the major Hollywood movie and television studios, made its S-Render and S-Paint software into industry leaders in the animation business and its 24 fps lock displays were featured in Star Trek movies.\nSymbolics developed the first workstations able to process high-definition television (HDTV) quality video, which enjoyed a popular following in Japan. A 3600, with the standard black-and-white monitor, made a cameo appearance in the movie \"Real Genius\". The company was also referenced in Michael Crichton's novel \"Jurassic Park\".\nSymbolics' Graphics Division was sold to Nichimen Trading Company in the early 1990s, and the S-Graphics software suite (S-Paint, S-Geometry, S-Dynamics, S-Render) ported to Franz Allegro Common Lisp on Silicon Graphics (SGI) and PC computers running Windows NT. Today it is sold as Mirai by Izware LLC, and continues to be used in major motion pictures (most famously in New Line Cinema's \"The Lord of the Rings\"), video games, and military simulations.\nSymbolics' 3600-series computers were also used as the first front end \"controller\" computers for the Connection Machine massively parallel computers manufactured by Thinking Machines Corporation, another MIT spinoff based in Cambridge, Massachusetts. The Connection Machine ran a parallel variant of Lisp and, initially, was used primarily by the AI community, so the Symbolics Lisp machine was a particularly good fit as a front-end machine.\nFor a long time, the operating system didn't have a name, but was finally named \"Genera\" around 1984. The system included several advanced dialects of Lisp. Its heritage was Maclisp on the PDP-10, but it included more data types, and multiple-inheritance object-oriented programming features. This Lisp dialect was called Lisp Machine Lisp at MIT. Symbolics used the name ZetaLisp. Symbolics later wrote new software in \"Symbolics Common Lisp\", its version of the Common Lisp standard.\nIvory and Open Genera.\nIn the late 1980s (2 years later than planned), the Ivory family of single-chip Lisp Machine processors superseded the G-Machine 3650, 3620, and 3630 systems. The Ivory 390k transistor VLSI implementation designed in Symbolics Common Lisp using NS, a custom Symbolics Hardware Design Language (HDL), addressed a 40-bit word (8 bits tag, 32 bits data/address). Since it only addressed full words and not bytes or half-words, this allowed addressing of 4 Gigawords (GW) or 16 gigabytes (GB) of memory; the increase in address space reflected the growth of programs and data as semiconductor memory and disk space became cheaper. The Ivory processor had 8 bits of ECC attached to each word, so each word fetched from external memory to the chip was actually 48 bits wide. Each Ivory instruction was 18 bits wide and two instructions plus a 2-bit CDR code and 2-bit Data Type were in each instruction word fetched from memory. Fetching two instruction words at a time from memory enhanced the Ivory's performance. Unlike the 3600's microprogrammed architecture, the Ivory instruction set was still microcoded, but was stored in a 1200 \u00d7 180-bit ROM inside the Ivory chip. The initial Ivory processors were fabricated by VLSI Technology Inc in San Jose, California, on a 2 \u03bcm CMOS process, with later generations fabricated by Hewlett-Packard in Corvallis, Oregon, on 1.25\u00a0\u03bcm and 1\u00a0\u03bcm CMOS processes. The Ivory had a stack architecture and operated a 4-stage pipeline: Fetch, Decode, Execute and Write Back. Ivory processors were marketed in stand-alone Lisp Machines (the XL400, XL1200, and XL1201), headless Lisp Machines (NXP1000), and on add-in cards for Sun Microsystems (UX400, UX1200) and Apple Macintosh (MacIvory I, II, III) computers. The Lisp Machines with Ivory processors operated at speeds that were between two and six times faster than a 3600 depending on the model and the revision of the Ivory chip.\nThe Ivory instruction set was later emulated in software for microprocessors implementing the 64-bit Alpha architecture. The \"Virtual Lisp Machine\" emulator, combined with the operating system and software development environment from the XL machines, is sold as Open Genera.\nSunstone.\nSunstone was a processor similar to a reduced instruction set computer (RISC), that was to be released shortly after the Ivory. It was designed by Ron Lebel's group at the Symbolics Westwood office. However, the project was canceled the day it was supposed to tape out.\nEndgame.\nAs quickly as the commercial AI boom of the mid-1980s had propelled Symbolics to success, the \"AI Winter\" of the late 1980s and early 1990s, combined with the slowdown of the Ronald Reagan administration's Strategic Defense Initiative, popularly termed \"Star Wars\", missile defense program, for which the \"Defense Advanced Research Projects Agency\" (DARPA) had invested heavily in AI solutions, severely damaged Symbolics. An internal war between Noftsker and the CEO the board had hired in 1986, Brian Sear, over whether to follow Sun's suggested lead and focus on selling their software, or to re-emphasize their superior hardware, and the ensuing lack of focus when both Noftsker and Sear were fired from the company caused sales to plummet. This, combined with some ill-advised real estate deals by company management during the boom years (they had entered into large long-term lease obligations in California), drove Symbolics into bankruptcy. Rapid evolution in mass market microprocessor technology (the \"PC revolution\"), advances in Lisp compiler technology, and the economics of manufacturing custom microprocessors severely diminished the commercial advantages of purpose-built Lisp machines. By 1995, the Lisp machine era had ended, and with it Symbolics' hopes for success.\nSymbolics continued as an enterprise with very limited revenues, supported mainly by service contracts on the remaining MacIvory, UX-1200, UX-1201, and other machines still used by commercial customers. Symbolics also sold Virtual Lisp Machine (VLM) software for DEC, Compaq, and HP Alpha-based workstations (AlphaStation) and servers (AlphaServer), refurbished MacIvory IIs, and Symbolics keyboards.\nIn July 2005, Symbolics closed its Chatsworth, California, maintenance facility. The reclusive owner of the company, Andrew Topping, died the same year. The current legal status of Symbolics software is uncertain. An assortment of Symbolics hardware was still available for purchase as of August\u00a02007[ [update]]. In 2011, the United States Department of Defense awarded Symbolics a 5 year contract for maintenance work, ending in September 2016.\nFirst .com domain.\nOn 15 March 1985, symbolics.com became the first (and currently, since it is still registered, the oldest) registered .com domain of the Internet. The symbolics.com domain was purchased by Napkin.com in 2009.\nNetworking.\nGenera also featured the most extensive networking interoperability software seen to that point. A local area network system called Chaosnet had been invented for the Lisp Machine (predating the commercial availability of Ethernet). The Symbolics system supported Chaosnet, but also had one of the first TCP/IP implementations. It also supported DECnet and IBM's SNA network protocols. A Dialnet protocol used phone lines and modems. Genera would, using hints from its distributed \"namespace\" database (somewhat similar to Domain Name System (DNS), but more comprehensive, like parts of Xerox's Grapevine), automatically select the best protocol combination to use when connecting to network service. An application program (or a user command) would only specify the name of the host and the desired service. For example, a host name and a request for \"Terminal Connection\" might yield a connection over TCP/IP using the Telnet protocol (although there were many other possibilities). Likewise, requesting a file operation (such as a Copy File command) might pick NFS, FTP, NFILE (the Symbolics network file access protocol), or one of several others, and it might execute the request over TCP/IP, Chaosnet, or whatever other network was most suitable.\nApplication programs.\nThe most popular application program for the Symbolics Lisp Machine was the ICAD computer-aided engineering system. One of the first networked multi-player video games, a version of Spacewar, was developed for the Symbolics Lisp Machine in 1983. Electronic CAD software on the Symbolics Lisp Machine was used to develop the first implementation of the Hewlett-Packard Precision Architecture (PA-RISC).\nContributions to computer science.\nSymbolics' research and development staff (first at MIT, and then later at the company) produced several major innovations in software technology:\nSymbolics Graphics Division.\nThe Symbolics Graphics Division (SGD, founded in 1982, sold to Nichimen Graphics in 1992) developed the S-Graphics software suite (S-Paint, S-Geometry, S-Dynamics, S-Render) for Symbolics Genera.\nMovies.\nThis software was also used to create a few computer-animated movies and was used for some popular movies.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n* "}
