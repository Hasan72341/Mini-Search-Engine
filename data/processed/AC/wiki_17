{"id": "21885", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=21885", "title": "Nim", "text": "Game of strategy\nNim is a mathematical combinatorial game in which two players take turns removing (or \"nimming\") objects from distinct heaps or piles. On each turn, a player must remove at least one object, and may remove any number of objects provided they all come from the same heap or pile. Depending on the version being played, the goal of the game is either to avoid taking the last object or to take the last object.\nNim is fundamental to the Sprague\u2013Grundy theorem, which essentially says that every impartial game is equivalent to a nim game with a single pile.\nHistory.\nVariants of nim have been played since ancient times. The game is said to have originated in China\u2014it closely resembles the Chinese game of (), or \"picking stones\"\u2014but the origin is uncertain; the earliest European references to nim are from the beginning of the 16th century. Its current name was coined by Charles L. Bouton of Harvard University, who also developed the complete theory of the game in 1901, but the origins of the name were never fully explained. The \"Oxford English Dictionary\" derives the name from the German verb , meaning \"take\".\nAt the 1939 New York World's Fair, Westinghouse displayed a machine, the Nimatron, that played nim. From May\u00a011 to October\u00a027, 1940, only a few people were able to beat the machine in that six-month period; if they did, they were presented with a coin that said \"Nim Champ\". It was also one of the first-ever electronic computerized games. Ferranti built a nim-playing computer which was displayed at the Festival of Britain in 1951. In 1952, Herbert Koppel, Eugene Grant and Howard Baller, engineers from the W. L. Maxson Corporation, developed a machine weighing which played nim against a human opponent and regularly won. A nim playing machine has been described made from tinkertoys.\nThe game of nim was the subject of Martin Gardner's February 1958 Mathematical Games column in \"Scientific American\". A version of nim is played\u2014and has symbolic importance\u2014in the French New Wave film \"Last Year at Marienbad\" (1961).\nGame play and illustration.\nNim is typically played as a mis\u00e8re game, in which the player to take the last object loses. Nim can also be played as a \"normal play\" game whereby the player taking the last object wins. In either normal play or a mis\u00e8re game, when there is exactly one heap with at least two objects, the player who takes next can easily win. If this removes either all or all but one objects from the heap that has two or more, then no heaps will have more than one object, so the players are forced to alternate removing exactly one object until the game ends. If the player leaves an even number of non-zero heaps (as the player would do in normal play), the player takes last; if the player leaves an odd number of heaps (as the player would do in mis\u00e8re play), then the other player takes last.\nThe normal game is between two players and is played with three heaps of any number of objects. The two players alternate taking any number of objects from any one of the heaps. The goal is to be the last to take an object. In mis\u00e8re play, the goal is instead to ensure that the opponent is forced to take the last remaining object.\nThe following example of a normal game is played between fictional players Bob and Alice, who start with heaps of three, four and five objects.\nWinning positions.\nThe practical strategy to win at the game of nim is for a player to get the other into one of the following positions, and every successive turn afterwards they should be able to make one of the smaller positions. Only the last move changes between mis\u00e8re and normal play.\nFor the generalisations, \"n\" and \"m\" can be any value &gt;\u00a00, and they may be the same.\nMathematical theory.\nNormal-play nim (or more precisely the system of nimbers) is fundamental to the Sprague\u2013Grundy theorem, which essentially says that in normal play every impartial game is equivalent to a nim heap that yields the same outcome when played in parallel with other normal play impartial games (see disjunctive sum).\nWhile all normal-play impartial games can be assigned a nim value, that is not the case under the mis\u00e8re convention. Only tame games can be played using the same strategy as mis\u00e8re nim.\nNim is a special case of a poset game where the poset consists of disjoint chains (the heaps).\nThe evolution graph of the game of nim with three heaps is the same as three branches of the evolution graph of the Ulam\u2013Warburton automaton.\nNim has been mathematically solved for any number of initial heaps and objects, and there is an easily calculated way to determine which player will win and which winning moves are open to that player.\nThe key to the theory of the game is the binary digital sum of the heap sizes, i.e., the sum (in binary), neglecting all carries from one digit to another. This operation is also known as \"bitwise xor\" or \"vector addition over GF(2)\" (bitwise addition modulo 2). Within combinatorial game theory it is usually called the nim-sum, as it will be called here. The nim-sum of \"x\" and \"y\" is written \"x\" \u2295 \"y\" to distinguish it from the ordinary sum, \"x\" + \"y\". An example of the calculation with heaps of size 3, 4, and 5 is as follows:\n Binary Decimal\n 0112 310 Heap A\n 1002 410 Heap B\n 1012 510 Heap C\n 0102 210 The nim-sum of heaps A, B, and C, 3 \u2295 4 \u2295 5 = 2\nAn equivalent procedure, which is often easier to perform mentally, is to express the heap sizes as sums of distinct powers of 2, cancel pairs of equal powers, and then add what is left:\n 3 = 0 + 2 + 1 = 2 1 Heap A\n 4 = 4 + 0 + 0 = 4 Heap B\n 5 = 4 + 0 + 1 = 4 1 Heap C\n 2 = 2 What is left after canceling 1s and 4s\nIn normal play, the winning strategy is to finish every move with a nim-sum of 0. This is always possible if the nim-sum is not zero before the move. If the nim-sum is zero, then the next player will lose if the other player does not make a mistake. To find out which move to make, let X be the nim-sum of all the heap sizes. Find a heap where the nim-sum of X and heap-size is less than the heap-size; the winning strategy is to play in such a heap, reducing that heap to the nim-sum of its original size with X. In the example above, taking the nim-sum of the sizes is \"X\" = 3 \u2295 4 \u2295 5 = 2. The nim-sums of the heap sizes A=3, B=4, and C=5 with X=2 are\n \"A\" \u2295 \"X\" = 3 \u2295 2 = 1 [Since (011) \u2295 (010) = 001 ]\n \"B\" \u2295 \"X\" = 4 \u2295 2 = 6\n \"C\" \u2295 \"X\" = 5 \u2295 2 = 7\nThe only heap that is reduced is heap A, so the winning move is to reduce the size of heap A to 1 (by removing two objects).\nAs a particular simple case, if there are only two heaps left, the strategy is to reduce the number of objects in the bigger heap to make the heaps equal. After that, no matter what move the opponent makes, the player can make the same move on the other heap, guaranteeing that they take the last object.\nWhen played as a mis\u00e8re game, nim strategy is different only when the normal play move would leave only heaps of size one. In that case, the correct move is to leave an odd number of heaps of size one (in normal play, the correct move would be to leave an even number of such heaps).\nThese strategies for normal play and a mis\u00e8re game are the same until the number of heaps with at least two objects is exactly equal to one. At that point, the next player removes either all objects (or all but one) from the heap that has two or more, so no heaps will have more than one object (in other words, so all remaining heaps have exactly one object each), so the players are forced to alternate removing exactly one object until the game ends. In normal play, the player leaves an even number of non-zero heaps, so the same player takes last; in mis\u00e8re play, the player leaves an odd number of non-zero heaps, so the other player takes last.\nIn a mis\u00e8re game with heaps of sizes three, four and five, the strategy would be applied like this:\nProof of the winning formula.\nThe soundness of the optimal strategy described above was demonstrated by C. Bouton.\nTheorem. In a normal nim game, the player making the first move has a winning strategy if and only if the nim-sum of the sizes of the heaps is not zero. Otherwise, the second player has a winning strategy.\n\"Proof:\" Notice that the nim-sum (\u2295) obeys the usual associative and commutative laws of addition (+) and also satisfies an additional property, \"x\"\u00a0\u2295\u00a0\"x\"\u00a0=\u00a00.\nLet \"x\"1, ..., \"xn\" be the sizes of the heaps before a move, and \"y\"1,\u00a0...,\u00a0\"yn\" the corresponding sizes after a move. Let \"s\"\u00a0=\u00a0\"x\"1\u00a0\u2295\u00a0...\u00a0\u2295\u00a0\"xn\" and \"t\"\u00a0=\u00a0\"y\"1\u00a0\u2295\u00a0...\u00a0\u2295\u00a0\"yn\". If the move was in heap \"k\", we have \"xi\"\u00a0=\u00a0\"yi\" for all \"i\" \u2260 \"k\", and \"xk\"\u00a0&gt;\u00a0\"yk\". By the properties of \u2295 mentioned above, we have\nformula_1\nThat is, to update the total nim sum formula_2 after updating the formula_3 heap, we need to cancel it from formula_2 by nim summing with formula_3, and then nim sum in formula_6.\nThe theorem follows by induction on the length of the game from these two lemmas.\nLemma 1. If \"s\" = 0, then \"t\" \u2260 0 no matter what move is made.\n\"Proof:\" If there is no possible move, then the lemma is vacuously true (and the first player loses the normal play game by definition). Otherwise, any move in heap \"k\" will produce \"t\"\u00a0=\u00a0\"xk\"\u00a0\u2295\u00a0\"yk\" from (*). This number is nonzero, since \"xk\"\u00a0\u2260\u00a0\"yk\".\nLemma 2. If \"s\" \u2260 0, it is possible to make a move so that \"t\" = 0.\n\"Proof:\" Let \"d\" be the position of the leftmost (most significant) nonzero bit in the binary representation of \"s\", and choose \"k\" such that the \"d\"th bit of \"xk\" is also nonzero. (Such a \"k\" must exist, since otherwise the \"d\"th bit of \"s\" would be 0.)\nThen letting \"yk\"\u00a0=\u00a0\"s\"\u00a0\u2295\u00a0\"xk\", we claim that \"yk\"\u00a0&lt;\u00a0\"xk\": all bits to the left of \"d\" are the same in \"xk\" and \"yk\", bit \"d\" decreases from 1 to 0 (decreasing the value by 2\"d\"), and any change in the remaining bits will amount to at most 2\"d\"\u22121. The first player can thus make a move by taking \"xk\"\u00a0\u2212\u00a0\"yk\" objects from heap \"k\", then\n \"t\" = \"s\" \u2295 \"xk\" \u2295 \"yk\" (by (*))\n = \"s\" \u2295 \"xk\" \u2295 (\"s\" \u2295 \"xk\")\n = 0.\nThe modification for mis\u00e8re play is demonstrated by noting that the modification first arises in a position that has only one heap of size 2 or more. Notice that in such a position \"s\" \u2260 0, and therefore this situation has to arise when it is the turn of the player following the winning strategy. The normal play strategy is for the player to reduce this to size 0 or 1, leaving an even number of heaps with size 1, and the mis\u00e8re strategy is to do the opposite. From that point on, all moves are forced.\nVariations.\nThe subtraction game.\nIn another game which is commonly known as nim (but is better called the subtraction game), an upper bound is imposed on the number of objects that can be removed in a turn. Instead of removing arbitrarily many objects, a player can only remove 1 or 2 or ... or \"k\" at a time. This game is commonly played in practice with only one heap.\nBouton's analysis carries over easily to the general multiple-heap version of this game. The only difference is that as a first step, before computing the nim-sums we must reduce the sizes of the heaps modulo \"k\"\u00a0+\u00a01. If this makes all the heaps of size zero (in mis\u00e8re play), the winning move is to take \"k\" objects from one of the heaps. In particular, in ideal play from a single heap of \"n\" objects, the second player can win if and only if\nThis follows from calculating the nim-sequence of \"S\"(1, 2, ..., \"k\"),\nformula_7\nfrom which the strategy above follows by the Sprague\u2013Grundy theorem.\nThe 21 game.\nThe game \"21\" is played as a mis\u00e8re game with any number of players who take turns saying a number. The first player says \"1\" and each player in turn increases the number by 1, 2, or 3, but may not exceed 21; the player forced to say \"21\" loses. This can be modeled as a subtraction game with a heap of 21 \u2212 \"n\" objects. The winning strategy for the two-player version of this game is to always say a multiple of 4; it is then guaranteed that the other player will ultimately have to say 21; so in the standard version, wherein the first player opens with \"1\", they start with a losing move.\nThe 21 game can also be played with different numbers, e.g., \"Add at most 5; lose on 34\".\nA sample game of 21 in which the second player follows the winning strategy:\nThe 100 game.\nA similar version is the \"100 game\": Two players start from 0 and alternately add a number from 1 to 10 to the sum. The player who reaches 100 wins. The winning strategy is to reach a number in which the digits are subsequent (e.g., 01, 12, 23, 34...) and control the game by jumping through all the numbers of this sequence. Once a player reaches 89, the opponent can only choose numbers from 90 to 99, and the next answer can in any case be 100.\nA multiple-heap rule.\nIn another variation of nim, besides removing any number of objects from a single heap, one is permitted to remove the same number of objects from each heap.\nCircular nim.\nYet another variation of nim is \"circular nim\", wherein any number of objects are placed in a circle and two players alternately remove one, two or three adjacent objects. For example, starting with a circle of ten objects,\nthree objects are taken in the first move\n _ . . . . . . . _ _\nthen another three\n _ . _ _ _ . . . _ _\nthen one\n _ . _ _ _ . . _ _ _\nbut then three objects cannot be taken out in one move.\nGrundy's game.\nIn Grundy's game, another variation of nim, a number of objects are placed in an initial heap and two players alternately divide a heap into two nonempty heaps of different sizes. Thus, six objects may be divided into piles of 5+1 or 4+2, but not 3+3. Grundy's game can be played as either mis\u00e8re or normal play.\nGreedy nim.\nGreedy nim is a variation wherein the players are restricted to choosing stones from only the largest pile. It is a finite impartial game. Greedy nim mis\u00e8re has the same rules as greedy nim, but the last player able to make a move loses.\nLet the largest number of stones in a pile be \"m\" and the second largest number of stones in a pile be \"n\". Let \"p\"\"m\" be the number of piles having \"m\" stones and \"p\"\"n\" be the number of piles having \"n\" stones. Then there is a theorem that game positions with \"p\"\"m\" even are \"P\" positions. This theorem can be shown by considering the positions where \"p\"\"m\" is odd. If \"p\"\"m\" is larger than 1, all stones may be removed from this pile to reduce \"p\"\"m\" by 1 and the new \"p\"\"m\" will be even. If \"p\"\"m\" = 1 (i.e., the largest heap is unique), there are two cases:\nThus, there exists a move to a state where \"p\"\"m\" is even. Conversely, if \"p\"\"m\" is even, if any move is possible (\"p\"\"m\" \u2260 0), then it must take the game to a state where \"p\"\"m\" is odd. The final position of the game is even (\"p\"\"m\" = 0). Hence, each position of the game with \"p\"\"m\" even must be a \"P\" position.\nIndex-\"k\" nim.\nA generalization of multi-heap nim was called \"nimformula_8\" or \"index-\"k\"\" nim by E. H. Moore, who analyzed it in 1910. In index-\"k\" nim, instead of removing objects from only one heap, players can remove objects from at least one but up to \"k\" different heaps. The number of elements that may be removed from each heap may be either arbitrary or limited to at most \"r\" elements, like in the \"subtraction game\" above.\nThe winning strategy is as follows: Like in ordinary multi-heap nim, one considers the binary representation of the heap sizes (or heap sizes modulo \"r\"\u00a0+\u00a01). In ordinary nim one forms the XOR-sum (or sum modulo 2) of each binary digit, and the winning strategy is to make each XOR sum zero. In the generalization to index-\"k\" nim, one forms the sum of each binary digit modulo \"k\"\u00a0+\u00a01.\nAgain, the winning strategy is to move such that this sum is zero for every digit. Indeed, the value thus computed is zero for the final position, and given a configuration of heaps for which this value is zero, any change of at most \"k\" heaps will make the value non-zero. Conversely, given a configuration with non-zero value, one can always take from at most \"k\" heaps, carefully chosen, so that the value will become zero.\nBuilding nim.\nBuilding nim is a variant of nim wherein the two players first construct the game of nim. Given \"n\" stones and \"s\" empty piles, the players, alternating turns, place exactly one stone into a pile of their choice. Once all the stones are placed, a game of Nim begins, starting with the next player that would move. This game is denoted \"BN(n,s)\".\nHigher-dimensional nim.\n\"n\"-d nim is played on a formula_9 board, whereon any number of continuous pieces can be removed from any hyper-row. The starting position is usually the full board, but other options are allowed.\nGraph nim.\nThe starting board is a disconnected graph, and players take turns to remove adjacent vertices.\nCandy nim.\nCandy nim is a version of normal-play nim in which players try to achieve two goals at the same time: taking the last object (in this case, candy) and taking the maximum number of candies by the end of the game.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21886", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=21886", "title": "Ninon de l'Enclos", "text": "French author and courtesan (1620\u20131705)\nAnne \"Ninon\" de l'Enclos, also spelled Ninon de Lenclos and Ninon de Lanclos (10 November 1620 \u2013 17 October 1705), was a French writer, courtesan and patron of the arts.\nEarly life.\nBorn Anne de l'Enclos in Paris on 10 November 1620, she was nicknamed \"Ninon\" at an early age by her father, Henri de l'Enclos, a lutenist and published composer, who taught her to sing and play the lute. In 1632, he was exiled from France after a duel. When Ninon's mother, Marie Barbe , died ten years later, the unmarried Ninon entered a convent, only to leave the next year. For the remainder of her life she was determined to remain unmarried and independent.\nLife as a courtesan and author.\nReturning to Paris, she became a popular figure in the salons, and her own drawing room became a centre for the discussion and consumption of the literary arts. In her early thirties she was responsible for encouraging the young Moli\u00e8re, and when she died she left money for the son of her notary, a nine-year-old named Fran\u00e7ois-Marie Arouet, later to become known as Voltaire, so he could buy books.\nIt was during this period that her life as a courtesan began. Ninon took a succession of notable and wealthy lovers, including the king's cousin the Great Cond\u00e9 and Gaston de Coligny. These men did not support her, however; she prided herself on her independent income. Saint-Simon wrote: \"Ninon always had crowds of adorers but never more than one lover at a time, and when she tired of the present occupier, she said so frankly and took another. Yet such was the authority of this wanton, that no man dared fall out with his successful rival; he was only too happy to be allowed to visit as a familiar friend.\" In 1652, Ninon took up with Louis de Mornay, the marquis de Villarceaux, by whom she had a son, also named Louis. She lived with the marquis until 1655, when she returned to Paris. When she would not return to him, the marquis fell into a fever; to console him, Ninon cut her hair and sent the shorn locks to him, starting a vogue for bobbed hair \"\u00e0 la Ninon\".\nThis life (less acceptable in her time than it would become in later years) and her opinions on organised religion caused her some trouble, and she was imprisoned in the Madelonnettes Convent in 1656 at the behest of Anne of Austria, Queen of France and regent for her son Louis XIV. Not long after, however, she was visited by Christina, former queen of Sweden. Impressed, Christina wrote to Cardinal Mazarin on Ninon's behalf and arranged for her release.\nIn response, as an author she defended the possibility of living a good life in the absence of religion, notably in 1659's \"La coquette veng\u00e9e\" (\"The Flirt Avenged\"). She was also noted for her wit; among her numerous sayings and quips are \"Much more genius is needed to make love than to command armies\" and \"We should take care to lay in a stock of provisions, but not of pleasures: these should be gathered day by day.\" An \"admirable sketch\" of Ninon, under the name of Damo, occurs in Mlle. de Scud\u00e9ry's novel \"Cl\u00e9lie\" (1654\u20131661).\nStarting in the late 1660s she retired from her courtesan lifestyle and concentrated more on her literary friends \u2013 from 1667, she hosted her gatherings at \"l'h\u00f4tel Sagonne\", which was considered \"the\" location of the salon of Ninon de l'Enclos despite other locales in the past. During this time she was a friend of Jean Racine, the great French playwright. Later she would become a close friend with the devout Fran\u00e7oise d'Aubign\u00e9, better known as Madame de Maintenon, the lady-in-waiting who would later become the second wife of Louis XIV. Saint-Simon wrote that \"The lady did not like her to be mentioned in her presence, but dared not disown her, and wrote cordial letters to her from time to time, to the day of her death\". Ninon eventually died at the age of 84, as a very wealthy woman. To the end, she \"was convinced that she had no soul, and never abandoned that conviction, not even in advanced old age, not even at the hour of her death.\"\nLegacy.\nImmanuel Kant, in his \"Observations on the Feeling of the Beautiful and Sublime\", uses Lenclos's life to emphasize how the most bitter reproach for an eighteenth-century woman was to be called unchaste: \"The maiden Ninon Lenclos made not the least claims to the honor of chastity, and nevertheless she would have been implacably offended if one of her lovers had gone so far in his judgment.\" Kant underscored the sexist moral double-standard during Lenclos' life and during Kant's life time.\nNinon de l'Enclos is a relatively obscure figure in the English-speaking world, but is much better known in France, where her name is synonymous with wit and beauty. Saint-Simon noted \"Ninon made friends among the great in every walk of life, had wit and intelligence enough to keep them, and, what is more, to keep them friendly with one another.\"\nEdgar Allan Poe mentioned her in his short story \"The Spectacles\", as did Rudyard Kipling in \"Venus Annodomini\". Edwin Arlington Robinson used Ninon as a symbol of aging beauty in his poem \"Veteran Sirens\". Dorothy Parker wrote the poem \"Ninon de l'Enclos on Her Last Birthday\" and also referred to Ninon in another of her poems, \"Words of Comfort to Be Scratched on a Mirror\". L'Enclos is the eponymous heroine of Charles Lecocq's 1896 \"op\u00e9ra comique\" \"Ninette\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n The 1911 edition of Encyclop\u00e6dia Britannica lists her date of birth being in November 1615."}
{"id": "21888", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=21888", "title": "National Institute of Standards and Technology", "text": "Measurement standards laboratory in the United States\nThe National Institute of Standards and Technology (NIST) is an agency of the United States Department of Commerce whose mission is to promote American innovation and industrial competitiveness. NIST's activities are organized into physical science laboratory programs that include nanoscale science and technology, engineering, information technology, neutron research, material measurement, and physical measurement. From 1901 to 1988, the agency was named the National Bureau of Standards.\nHistory.\nBackground.\nThe Articles of Confederation, ratified by the colonies in 1781, provided:\nThe United States in Congress assembled shall also have the sole and exclusive right and power of regulating the alloy and value of coin struck by their own authority, or by that of the respective states\u2014fixing the standards of weights and measures throughout the United States.\nArticle 1, section 8, of the Constitution of the United States, ratified in 1789, granted these powers to the new Congress: \"The Congress shall have power ... To coin money, regulate the value thereof, and of foreign coin, and fix the standard of weights and measures\".\nIn January 1790, President George Washington, in his first annual message to Congress, said, \"Uniformity in the currency, weights, and measures of the United States is an object of great importance, and will, I am persuaded, be duly attended to.\"\nOn October 25, 1791, Washington again appealed to Congress:\nA uniformity of the weights and measures of the country is among the important objects submitted to you by the Constitution and if it can be derived from a standard at once invariable and universal, must be no less honorable to the public council than conducive to the public convenience.\nIn 1821, President John Quincy Adams declared, \"Weights and measures may be ranked among the necessities of life to every individual of human society.\". Nevertheless, it was not until 1838 that the United States government adopted a uniform set of standards.\nFrom 1830 until 1901, the role of overseeing weights and measures was carried out by the Office of Standard Weights and Measures, which was part of the Survey of the Coast\u2014renamed the United States Coast Survey in 1836 and the United States Coast and Geodetic Survey in 1878\u2014in the United States Department of the Treasury.\nBureau of Standards (1901\u20131988).\nIn 1901, in response to a bill proposed by Congressman James H. Southard (R, Ohio), the Bureau of Standards was founded with the mandate to provide standard weights and measures, and to serve as the national physical laboratory for the United States. Southard had previously sponsored a bill for metric conversion of the United States.\nPresident Theodore Roosevelt appointed Samuel W. Stratton as the first director. The budget for the first year of operation was $40,000. The Bureau took custody of the copies of the kilogram and meter bars that were the standards for US measures, and set up a program to provide metrology services for United States scientific and commercial users. A laboratory site was constructed in Washington, DC, and instruments were acquired from the national physical laboratories of Europe. In addition to weights and measures, the Bureau developed instruments for electrical units and for measurement of light. In 1905 a meeting was called that would be the first \"National Conference on Weights and Measures\".\nInitially conceived as purely a metrology agency, the Bureau of Standards was directed by Herbert Hoover to set up divisions to develop commercial standards for materials and products. Some of these standards were for products intended for government use, but product standards also affected private-sector consumption. Quality standards were developed for products including some types of clothing, automobile brake systems and headlamps, antifreeze, and electrical safety. During World War I, the Bureau worked on multiple problems related to war production, even operating its own facility to produce optical glass when European supplies were cut off.\nBetween the wars, Harry Diamond of the Bureau developed a blind approach radio aircraft landing system. During World War II, military research and development was carried out, including development of radio propagation forecast methods, the proximity fuze and the standardized airframe used originally for Project Pigeon, and shortly afterwards the autonomously radar-guided Bat anti-ship guided bomb and the Kingfisher family of torpedo-carrying missiles.\nIn 1948, financed by the United States Air Force, the Bureau began design and construction of SEAC, the Standards Eastern Automatic Computer. The computer went into operation in May 1950 using a combination of vacuum tubes and solid-state diode logic. About the same time the Standards Western Automatic Computer, was built at the Los Angeles office of the NBS by Harry Huskey and used for research there. A mobile version, DYSEAC, was built for the Signal Corps in 1954.\nNational Institute of Standards and Technology (from 1988).\nDue to a changing mission, the \"National Bureau of Standards\" became the \"National Institute of Standards and Technology\" in 1988. Following the September 11, 2001 attacks, under the National Construction Safety Team Act (NCST), NIST conducted the official investigation into the collapse of the World Trade Center buildings. Following the 2021 Surfside condominium building collapse, NIST sent engineers to the site to investigate the cause of the collapse.\nIn 2019, NIST launched a program named NIST on a Chip to decrease the size of instruments from lab machines to chip size. Applications include aircraft testing, communication with satellites for navigation purposes, and temperature and pressure.\nIn 2023, the Biden administration began plans to create a U.S. AI Safety Institute within NIST to coordinate AI safety matters. According to \"The Washington Post\", NIST is considered \"notoriously underfunded and understaffed\", which could present an obstacle to these efforts.\nConstitution.\nNIST, known between 1901 and 1988 as the National Bureau of Standards (NBS), is a measurement standards laboratory, also known as the National Metrological Institute (NMI), which is a non-regulatory agency of the United States Department of Commerce. The institute's official mission is to:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve our quality of life.\u2014\u200a\nNIST had an operating budget for fiscal year 2007 (October 1, 2006\u00a0\u2013 September 30, 2007) of about $843.3 million. NIST's 2009 budget was $992 million, and it also received $610 million as part of the American Recovery and Reinvestment Act. NIST employs about 2,900 scientists, engineers, technicians, and support and administrative personnel. About 1,800 NIST associates (guest researchers and engineers from American companies and foreign countries) complement the staff. NIST partners with 1,400 manufacturing specialists and staff at nearly 350 affiliated centers around the country. NIST publishes the Handbook 44 that provides the \"Specifications, tolerances, and other technical requirements for weighing and measuring devices\".\nMetric system.\nThe Congress of 1866 made use of the metric system in commerce a legally protected activity through the passage of Metric Act of 1866. In May 1875, 17 out of 20 countries signed a document known as the \"Metric Convention\" or the \"Treaty of the Meter\", which established the International Bureau of Weights and Measures under the control of an international committee elected by the General Conference on Weights and Measures.\nOrganization.\nNIST is headquartered in Gaithersburg, Maryland, and operates a facility in Boulder, Colorado, which was dedicated by President Eisenhower in\u00a01954. NIST's activities are organized into laboratory programs and extramural programs. Effective October 2010, NIST was realigned by reducing the number of NIST laboratory units from ten to six. NIST Laboratories include:\nExtramural programs include:\n NIST's Boulder laboratories are best known for NIST\u2011F1, which houses an atomic clock. NIST\u2011F1 serves as the source of the nation's official time. From its measurement of the natural resonance frequency of cesium\u2014which defines the second\u2014NIST broadcasts time signals via longwave radio station WWVB near Fort Collins, Colorado, and shortwave radio stations WWV and WWVH, located near Fort Collins and Kekaha, Hawaii, respectively.\nNIST also operates a neutron science user facility: the NIST Center for Neutron Research (NCNR). The NCNR provides scientists access to a variety of neutron scattering instruments, which they use in many research fields (materials science, fuel cells, biotechnology, etc.).\nThe SURF III Synchrotron Ultraviolet Radiation Facility is a source of synchrotron radiation, in continuous operation since 1961. SURF III now serves as the US national standard for source-based radiometry throughout the generalized optical spectrum. All NASA-borne, extreme-ultraviolet observation instruments have been calibrated at SURF since the 1970s, and SURF is used for the measurement and characterization of systems for extreme ultraviolet lithography.\nThe Center for Nanoscale Science and Technology (CNST) performs research in nanotechnology, both through internal research efforts and by running a user-accessible cleanroom nanomanufacturing facility. This \"NanoFab\" is equipped with tools for lithographic patterning and imaging (e.g., electron microscopes and atomic force microscopes).\nCommittees.\nNIST has seven standing committees:\nProjects.\nMeasurements and standards.\nAs part of its mission, NIST supplies industry, academia, government, and other users with over 1,300 Standard Reference Materials (SRMs). These artifacts are certified as having specific characteristics or component content, used as calibration standards for measuring equipment and procedures, quality control benchmarks for industrial processes, and experimental control samples.\n\"Handbook 44\".\nNIST publishes the \"Handbook 44\" each year after the annual meeting of the National Conference on Weights and Measures (NCWM). Each edition is developed through cooperation of the Committee on Specifications and Tolerances of the NCWM and the Weights and Measures Division (WMD) of NIST. The purpose of the book is a partial fulfillment of the statutory responsibility for \"cooperation with the states in securing uniformity of weights and measures laws and methods of inspection\".\nNIST has been publishing various forms of what is now the \"Handbook 44\" since 1918 and began publication under the current name in 1949. The 2010 edition conforms to the concept of the primary use of the SI (metric) measurements recommended by the Omnibus Foreign Trade and Competitiveness Act of 1988.\nHomeland security.\nNIST is developing government-wide identity document standards for federal employees and contractors to prevent unauthorized persons from gaining access to government buildings and computer systems.\nWorld Trade Center collapse investigation.\nIn 2002, the National Construction Safety Team Act mandated NIST to conduct an investigation into the collapse of the World Trade Center buildings 1 and 2 and the 47-story 7 World Trade Center. The \"World Trade Center Collapse Investigation\", directed by lead investigator Shyam Sunder, covered three aspects, including a technical building and fire safety investigation to study the factors contributing to the probable cause of the collapses of the WTC Towers (WTC 1 and 2) and WTC 7. NIST also established a research and development program to provide the technical basis for improved building and fire codes, standards, and practices, and a dissemination and technical assistance program to engage leaders of the construction and building community in implementing proposed changes to practices, standards, and codes.\nNIST also is providing practical guidance and tools to better prepare facility owners, contractors, architects, engineers, emergency responders, and regulatory authorities to respond to future disasters. In November 2008, the investigation portion of the response plan was completed, with the release of the final report on 7 World Trade Center. The final report on the WTC Towers\u2014including 30 recommendations for improving building and occupant safety\u2014was released in October 2005.\nElection technology.\nNIST works in conjunction with the Technical Guidelines Development Committee of the Election Assistance Commission to develop the Voluntary Voting System Guidelines for voting machines and other election technology.\nCybersecurity Framework.\nIn February 2014, NIST published the NIST Cybersecurity Framework that serves as voluntary guidance for organizations to manage and reduce cybersecurity risk. It was later amended and Version 1.1 was published in April 2018. Executive Order 13800, Strengthening the Cybersecurity of Federal Networks and Critical Infrastructure, made the Framework mandatory for U.S. federal government agencies. An extension to the NIST Cybersecurity Framework is the Cybersecurity Maturity Model (CMMC) which was introduced in 2019 (though the origin of CMMC began with Executive Order 13556). On August 25, 2025, the 48 CFR CMMC rule cleared regulatory review. According to ISI, it published on September 10, 2025.\nIt emphasizes the importance of implementing Zero-trust architecture (ZTA) which focuses on protecting resources over the network perimeter. ZTA utilizes zero trust principles which include \"never trust, always verify\", \"assume breach\" and \"least privileged access\" to safeguard users, assets, and resources. Since ZTA holds no implicit trust to users within the network perimeter, authentication and authorization are performed at every stage of a digital transaction. This reduces the risk of unauthorized access to resources.\nNIST released a draft of the CSF 2.0 for public comment to November 4, 2023. NIST decided to update the framework to make it more applicable to small and medium size enterprises that use the framework, as well as to accommodate the constantly changing nature of cybersecurity.\nIn August 2024, NIST released a final set of encryption tools designed to withstand the attack of a quantum computer. These post-quantum encryption standards secure a wide range of electronic information, from confidential email messages to e-commerce transactions that propel the modern economy.\nMoonlight Calibration Initiative.\nIn May 2025, NIST announced the Moonlight data project to enhance satellite calibration. By providing precise measurements of the Moon's brightness, the initiative aims to improve the accuracy of Earth observation satellites, supporting applications such as agriculture, meteorology, and environmental monitoring.\nPeople.\nFour scientific researchers at NIST have been awarded Nobel Prizes for work in physics: William Daniel Phillips in 1997, Eric Allin Cornell in 2001, John Lewis Hall in 2005 and David Jeffrey Wineland in 2012, which is the largest number for any US government laboratory. All four were recognized for their work related to laser cooling of atoms, which is directly related to the development and advancement of the atomic clock.\nIn 2011, Dan Shechtman was awarded the Nobel Prize in chemistry for his work on quasicrystals in the Metallurgy Division from 1982 to 1984. John Werner Cahn was awarded the 2011 Kyoto Prize for Materials Science. The National Medal of Science has been awarded to NIST researchers Cahn (1998) and Wineland (2007). Other notable people who have worked at NBS or NIST include:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDirectors.\nSince 1989, the director of NIST has been a Presidential appointee and is confirmed by the United States Senate. Since 1989, the average tenure of NIST directors has fallen from 11 years to 2 years in duration. Since the 2011 reorganization of NIST, the director also holds the title of Under Secretary of Commerce for Standards and Technology. Seventeen individuals have officially held the position, in addition to seven acting directors who have served on a temporary basis.\nPatents.\nNIST holds patents on behalf of the Federal government of the United States, with at least one of them being custodial to protect public domain use, such as one for a Chip-scale atomic clock, developed by a NIST team as part of a DARPA competition.\nControversy regarding NIST standard SP 800-90.\nIn September 2013, both \"The Guardian\" and \"The New York Times\" reported that NIST allowed the National Security Agency (NSA) to insert a cryptographically secure pseudorandom number generator called Dual EC DRBG into NIST standard SP 800-90 that had a kleptographic backdoor that the NSA can use to covertly predict the future outputs of this pseudorandom number generator thereby allowing the surreptitious decryption of data. Both papers report that the NSA worked covertly to get its own version of SP 800-90 approved for worldwide use in 2006.\nThe whistle-blowing document states that \"eventually, NSA became the sole editor\". The reports confirm suspicions and technical grounds publicly raised by cryptographers in 2007 that the EC-DRBG could contain a kleptographic backdoor (perhaps placed in the standard by NSA).\nNIST responded to the allegations, stating that \"NIST works to publish the strongest cryptographic standards possible\" and that it uses \"a transparent, public process to rigorously vet our recommended standards\". The agency stated that \"there has been some confusion about the standards development process and the role of different organizations in it...The National Security Agency (NSA) participates in the NIST cryptography process because of its recognized expertise. NIST is also required by statute to consult with the NSA.\"\nRecognizing the concerns expressed, the agency reopened the public comment period for the SP800-90 publications, promising that \"if vulnerabilities are found in these or any other NIST standards, we will work with the cryptographic community to address them as quickly as possible\". Due to public concern of this cryptovirology attack, NIST rescinded the EC-DRBG algorithm from the NIST SP 800-90 standard.\nPublications.\nIn addition to these journals, NIST, and the National Bureau of Standards before it, has a robust technical reports publishing arm. NIST technical reports are published in several dozen series, which cover a wide range of topics, from computer technology to construction to aspects of standardization including weights, measures and reference data. In addition to technical reports, NIST scientists publish many journal and conference papers each year; an database of these, along with more recent technical reports, can be found on the NIST website.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21891", "revid": "1320219373", "url": "https://en.wikipedia.org/wiki?curid=21891", "title": "NATO reporting name", "text": "NATO code name for military equipment of purported opponents\nNATO uses a system of code names, called reporting names, to denote military aircraft and other equipment used by post-Soviet states, former Warsaw Pact countries, China, and other countries. The system assists military communications by providing short, one- or two-syllable names, as alternatives to the precise proper names, which may be easily confused under operational conditions or are unknown in the Western world.\nThe assignment of reporting names is managed by the Five Eyes Air Force Interoperability Council (AFIC), previously known as the Air Standardization Coordinating Committee (ASCC), which is separate from NATO. Based in Washington DC, AFIC comprises representatives from the militaries of three NATO members (Canada, the United Kingdom and United States) and two non-NATO countries (Australia and New Zealand).\nWhen the system was introduced in the 1950s, reporting names also implicitly designated potentially hostile aircraft. However, since the end of the Cold War, some NATO air forces have operated various aircraft types with reporting names (e.g., \"Fulcrum\" for the Mikoyan MiG-29).\nAmerican variations.\nThe United States Department of Defense (DoD) expands on the NATO reporting names in some cases. NATO refers to surface-to-air missile systems mounted on ships or submarines with the same names as the corresponding land-based systems, but the DoD assigns a different series of numbers with a different prefix (i.e., SA-N- versus SA-) for these systems. The names are kept the same as a convenience. Where there is no corresponding system, a new name is devised.\nSoviet nicknames.\nThe Soviet Union did not always assign official \"popular names\" to its aircraft, but unofficial nicknames were common as in any air force. Generally, Soviet pilots did not use the NATO names, preferring a native Russian nickname. An exception was that Soviet airmen appreciated the MiG-29's codename \"Fulcrum\", as an indication of its pivotal role in Soviet air defence.\nNomenclature.\nTo reduce the risk of confusion, unusual or made-up names are allocated, the idea being that the names chosen are unlikely to occur in normal conversation and are easier to memorise.\nFor fixed-wing aircraft, the number of syllables indicates the type of the aircraft's engine. Single-syllable code names denote reciprocating engine or turboprop, while two-syllable code names denote jet engine.\nBombers have names starting with the letter \"B\", and names like \"Badger\" (Tupolev Tu-16), \"Blackjack\" (Tupolev Tu-160) and \"Bear\" (Tupolev Tu-95) have been used. \"Frogfoot\", the reporting name for the Sukhoi Su-25, references the aircraft's close air support role. Transports have names starting with \"C\" (for \"cargo\"), resulting in names like \"Condor\" for the Antonov An-124 or \"Candid\" for the Ilyushin Il-76.\nLists of NATO reporting names.\nMissiles.\nThe initial letter of the name indicates the use of that equipment. The alphanumeric designations (e.g. AA-2) are assigned by the U.S. Department of Defense.\nAircraft.\nThe first letter indicates the type of aircraft, e.g., \"Bear\" for a bomber aircraft refers to the Tupolev Tu-95, or \"Fulcrum\" for the Mikoyan-Gurevich MiG-29 fighter aircraft. For fixed-wing aircraft, one-syllable names are used for propeller aircraft and two-syllable names for aircraft with jet engines. This distinction is not made for helicopters.\nSubmarines.\nBefore the 1980s, reporting names for submarines were taken from the NATO spelling alphabet. Modifications of existing designs were given descriptive terms, such as \"Whiskey Long Bin\". From the 1980s, new designs were given names derived from Russian words, such as \"Akula\", or \"shark\". These names did not correspond to the Soviet names. Coincidentally, \"Akula\", which was assigned to an attack submarine by NATO, was the actual Soviet name for the ballistic missile submarine NATO named \"Typhoon-class\". The NATO names for submarines of the People's Republic of China are taken from Chinese dynasties.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21892", "revid": "14751539", "url": "https://en.wikipedia.org/wiki?curid=21892", "title": "List of NATO reporting names for surface-to-surface missiles", "text": "NATO reporting name for SS series surface-to-surface missiles, with Soviet or Chinese designations:\nSoviet Union/Russia.\nShip-launched.\nUS DoD designations for SS-N series naval surface-to-surface missiles (fired from ships and submarines), with Soviet designations:\nSee also.\nNATO reporting name\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21893", "revid": "751903", "url": "https://en.wikipedia.org/wiki?curid=21893", "title": "List of NATO reporting names for air-to-air missiles", "text": "NATO reporting name for AA series air-to-air missile\nSoviet Union.\nNATO designation for Soviet / Russia missiles:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21894", "revid": "44623097", "url": "https://en.wikipedia.org/wiki?curid=21894", "title": "List of NATO reporting names for air-to-surface missiles", "text": "NATO reporting name for AS series air-to-surface missiles, with Soviet designations:\nNote: The Soviet / Russian designation is a Cyrillic letter \"\u0425\", which is translated as \"Kh\" or \"H\". Also, sometimes a combination (\"complex\") of a missile with its aircraft is marked with a letter \"K\" (for example, a missile Kh-22 with an aircraft is a \"complex K-22\"). The Cyrillic \"X\" (read \"Kh\") in the designation of Soviet ASMs is in fact a Latin \"X\" (\"ecks\") for Xperimental, as used by the design bureau. With passing time, however, this was ignored and used in Soviet/Russian as well as foreign literature as the Cyrillic Kh.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21895", "revid": "42522270", "url": "https://en.wikipedia.org/wiki?curid=21895", "title": "List of NATO reporting names for anti-tank missiles", "text": "NATO reporting name for AT series anti-tank guided missiles, with Soviet designations:"}
{"id": "21896", "revid": "26871134", "url": "https://en.wikipedia.org/wiki?curid=21896", "title": "List of NATO reporting names for surface-to-air missiles", "text": "NATO reporting name corresponding to US DoD SA series surface-to-air missiles, with Soviet designations or Chinese designations:\nTo differentiate Russian missiles from similarly named Chinese ones, \"RS\" prefix was added to the US DoD reporting name. For example, SA-N-7 became RS-SA-N-7.\nSoviet Union.\nU.S. DoD designations for SA-N series naval surface-to-air missiles, with Soviet designations. Note that these are not standard NATO names, NATO uses the regular SA series for naval SAMS also, however the US DoD refers to them by these names:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21897", "revid": "26442336", "url": "https://en.wikipedia.org/wiki?curid=21897", "title": "List of NATO reporting names for bomber aircraft", "text": "This is a list of NATO reporting name/ASCC names for bombers, with Soviet Union and Chinese designations. Bombers had names starting with the letter \"B\"; single-syllable words denoted propeller driven aircraft (piston and turboprop engines), while two syllable words were used for jets. Three syllable words are for propfans.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21898", "revid": "45383859", "url": "https://en.wikipedia.org/wiki?curid=21898", "title": "List of NATO reporting names for fighter aircraft", "text": "The Five Eyes Air Force Interoperability Council (AFIC) assigns codenames for fighters and other military aircraft originating in, or operated by, the air forces of the former Warsaw Pact, including Russia, and the People's Republic of China. \nWhen the system began the names were assigned by the Air Standardization Coordinating Committee (ASCC), made up of the English-speaking allies of the Second World War, the United States, United Kingdom, Canada and two non-NATO countries, Australia and New Zealand. The ASCC names were adopted by the U.S. Department of Defense and then NATO. They have also become known as \"NATO reporting names\". The ASCC became the Five Eyes Air Force Interoperability Council and no longer has responsibility for generating reporting names. \nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21899", "revid": "42522270", "url": "https://en.wikipedia.org/wiki?curid=21899", "title": "List of NATO reporting names for helicopters", "text": "Helicopters, NATO/ASCC names:"}
{"id": "21900", "revid": "10434788", "url": "https://en.wikipedia.org/wiki?curid=21900", "title": "List of NATO reporting names for transport aircraft", "text": "NATO reporting name/ASCC names for transport aircraft and their Soviet, Russian and Chinese designations:"}
{"id": "21901", "revid": "41205403", "url": "https://en.wikipedia.org/wiki?curid=21901", "title": "List of NATO reporting names for miscellaneous aircraft", "text": "NATO reporting name/Air Standardization Coordinating Committee (ASCC) names for miscellaneous aircraft, with Soviet and Chinese designations, sorted by reporting name:\nSoviet Union/Russia.\nNATO reporting name/ASCC names for miscellaneous aircraft, with Soviet designations, sorted by Soviet designation:"}
{"id": "21902", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=21902", "title": "List of NATO reporting names for hunter-killer and experimental submarines", "text": ""}
{"id": "21903", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=21903", "title": "List of NATO reporting names for guided missile submarines", "text": ""}
{"id": "21904", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=21904", "title": "List of NATO reporting names for submarines", "text": "NATO code names for Russian and Chinese submarines\nNATO has a system of reporting names for non-Western submarines. During the Cold War, NATO introduced a system of internal code names for classes of Soviet and Chinese submarines. This served to provide standard names where the official designation of a Soviet/Chinese designations of vessels were unknown. The system was influenced by a pre-existing, separate system for reporting non-Western aircraft.\nUntil the 1980s, reporting names for submarines were taken from the NATO spelling alphabet. Modifications of existing designs were given descriptive terms, such as \"Whiskey Long Bin\". From the 1980s onwards, new designs were given names derived from Russian words, such as \"Akula\" (\"Shark\"). These names did not correspond to the Soviet names. Coincidentally, \"Akula\", which was assigned to an attack submarine by NATO, was the actual Soviet name for another, ballistic missile submarine class, which NATO designated \"Typhoon\". \nThe names for Chinese submarines are taken from Chinese dynasties.\nList of reporting names for Soviet/Russian vessels.\nThe code names are followed by official Soviet Navy/Russian Navy designations.\nList of People's Republic of China submarines.\nThe NATO names for Chinese submarines are taken from Chinese dynasties.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21907", "revid": "28427534", "url": "https://en.wikipedia.org/wiki?curid=21907", "title": "Seven Laws of Noah", "text": "Universal moral laws in Judaism\nIn Judaism, the Seven Laws of Noah (, \"Sheva Mitzvot B'nei Noach\"), otherwise referred to as the Noahide Laws or the Noachian Laws (from the Hebrew pronunciation of \"Noah\"), are a set of universal moral laws which, according to the Talmud, were given by God as a covenant with Noah and with the \"sons of Noah\"\u2014that is, all of humanity.\nThe Seven Laws of Noah include prohibitions against worshipping idols, cursing God, murder, adultery and sexual immorality, theft, eating flesh torn from a living animal, as well as the obligation to establish courts of justice.\nAccording to Jewish law, non-Jews (Gentiles) are not obligated to convert to Judaism, but they are required to observe the Seven Laws of Noah to be assured of a place in the World to Come (\"Olam Ha-Ba\"), the final reward of the righteous. The non-Jews that choose to follow the Seven Laws of Noah are regarded as \"Righteous Gentiles\" (, \"Chassiddei Umot ha-Olam\": \"Pious People of the World\").\nList.\nThe Seven Laws of Noah as traditionally enumerated in the Babylonian Talmud (\"Sanhedrin\" 56a-b) and Tosefta (\"Avodah Zarah\" 9:4), are the following:\nAccording to the Talmud, the seven Noahide laws were given first to Adam and subsequently to Noah. The Tannaitic and Amoraitic rabbinic sages (1st\u20136th centuries CE) disagreed on the exact number of Noahide laws that were originally given to Adam. Six of the seven laws were exegetically derived from passages in the Book of Genesis, with the seventh being the establishment of courts of justice. The earliest complete rabbinic version of the seven Noahide laws can be found in the Tosefta:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Seven commandments were commanded of the sons of Noah:\nOrigins.\nHebrew Bible.\nThe universal morality of the Noahide covenant for Gentiles (non-Jews) was already affirmed in the Torah and was subsequently highlighted in the Book of Genesis (e.g., relating to Melchizedek in Genesis 14:18-20), the Book of Job, and the Book of Jonah (showing that God would be known and his call for repentance responded to even by the evil Ninevites, making them acceptable to God), showing that God directly related to every person regardless of their culture or religion, and would save all \"Righteous Gentiles\" who conformed to the Seven Laws of Noah.\nBook of Jubilees.\nThe Book of Jubilees, generally dated to the 1st century BCE, may include a substantially different list of six commandments at verses 7:20\u201325:\n(1) to observe righteousness;\n(2) to cover the shame of their flesh;\n(3) to bless their creator;\n(4) to honor their parents;\n(5) to love their neighbor; and\n(6) to guard against fornication, uncleanness, and all iniquity.\nModern analysis.\nRabbinical.\nThe Talmudic tractate \"Sanhedrin\" 105a named and excluded certain specific Jewish and non-Jewish groups of the distant past from salvation, but thereby implied, as explicitly stated there, that all other non-Jews of past or present could be righteous and would be saved as they were, without Gentiles needing to undergo conversion to Judaism. Following Moses Maimonides' analysis of Islam, medieval Jewish rabbis affirmed that Islam as an entire religion, despite its perceived errors and cruelties towards the Jews, could still be considered as a Noahide faith, and the 13th\u201314th century Catalan rabbi Menachem ben Solomon Ha-Meiri fully extended much the same status to Christianity itself.\nThe Talmud has some striking accounts illustrating how far God's lovingkindness and mercies might extend, giving ultimate salvation even to persons who had led notoriously evil lives: some said that if those persons had done only one truly selfless, kind and good deed in their entire lives God would accept them for the sake of that precious act into Paradise, either immediately at death (if their death was the result of an extraordinarily generous, self-sacrificing, or courageous deed) or after they had atoned for their sins in Purgatory\u2014so it is evident that full observance of the Noahide covenant itself was not always obligatory for salvation after all, even if it remained the chief guide to lives of spiritual loftiness and nobility. This led the 18th-century Italian Jewish Kabbalist and rabbi Moshe Chaim Luzzatto to emphasize and explain at length that God would end up accepting all humanity, good and evil alike, into the World to Come (\"Olam Ha-Ba\")\u2014the evil ones, however, would of course need to purify themselves in Purgatory first, but there will be no eternal punishment for them.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For this reason you will find that the Noachian and the Mosaic laws, though differing in matters of detail, as we shall see, agree in the general matters which come from the giver. They both existed at the same time. While the Mosaic law existed in Israel, all the other nations had the Noachian law, and the difference was due to geographical diversity, Israel being different from the other lands, and to national diversity, due to difference in ancestry. And there is no doubt that the other nations attained human happiness through the Noachian law, since it is divine; though they could not reach the same degree of happiness as that attained by Israel through the Torah. The rabbis say: \"The pious men of the other nations have a share in the world to come\". This shows that there may be two divine laws existing at the same time among different nations, and that each one leads those who live by it to attain human happiness; though there is a difference in the degree of happiness attainable by the two laws. This difference in the laws can not concern fundamental or derivative principles. Therefore the examination of the law itself is always of the same kind. But the examination relating to the messenger may undergo change. At all events the verification must be direct, though the verification of one religion may be different from that of another.\u2014\u200a\nDuring the 1860s in Western Europe, a resurgence of Noahide faith as the universal moral religion for Gentiles (non-Jews) was developed by the 19th-century Italian Jewish Kabbalist and rabbi Elijah Benamozegh. Between the years 1920s\u20131930s, French writer\u00a0Aim\u00e9 Palli\u00e8re adopted the Seven Laws of Noah at the suggestion of his teacher Elijah Benamozegh; afterwards, Palli\u00e8re spread Benamozegh's doctrine in Europe and never formally converted to Judaism. Modern historians argue that Benamozegh's role in the debate on Jewish universalism in the history of Jewish philosophy was focused on the Noahide laws for Gentiles as the means subservient to the shift of Jewish ethics from particularism to universalism, although the arguments that he used to support his universalistic viewpoint were neither original nor unheard in the history of this debate. According to Cl\u00e9mence Boulouque, Carl and Bernice Witten Associate Professor of Jewish and Israel Studies at Columbia University in the City of New York, Benamozegh ignored the ethnocentric biases contained in the Noahide laws, whereas some contemporary right-wing Jewish political movements have embraced them.\nThe \"Encyclopedia Talmudit\", edited by the 20th-century Belarusian Hasidic rabbi Shlomo Yosef Zevin, states that after the giving of the Torah, the Jewish people were no longer included in the category of the sons of Noah. Maimonides (\"Mishneh Torah\", \"Hilkhot Melakhim\" 9:1) indicates that the seven commandments are also part of the Torah, and the Babylonian Talmud (\"Sanhedrin\" 59a, see also Tosafot ad. loc.) states that Jews are obligated in all things that Gentiles are obligated in, albeit with some differences in the details. According to the \"Encyclopedia Talmudit\", most medieval Jewish authorities considered that all the seven commandments were given to Adam, although Maimonides (\"Mishneh Torah\", \"Hilkhot Melakhim\" 9:1) considered the dietary law to have been given to Noah.\nMenachem Mendel Schneerson, the Lubavitcher Rebbe, published and spoke about the Seven Laws of Noah many times. According to Schneerson's view, based on a detailed reading of Maimonides' tractate \"Hilkhot Melakhim\" in the \"Mishneh Torah\", the Talmud, and the Hebrew Bible, the seven commandments originally given to Noah were given yet again, through Moses at Sinai, and it's exclusively through the giving of the Torah that the seven commandments derive their current force. What has changed with the giving of the Torah is that now, it is the duty of the Jewish people to bring the rest of the world to fulfill the Seven Laws of Noah.\nAcademic and secular.\nAccording to Michael S. Kogan, professor of Philosophy and Religious studies at Montclair State University, the Seven Laws of Noah are not explicitly mentioned in the Torah but were exegetically extrapolated from the Book of Genesis by 2nd-century rabbis, which wrote them down in the Tosefta.\nAccording to Adam J. Silverstein, professor of Middle Eastern studies and Islamic studies at the Hebrew University of Jerusalem, Jewish theologians started to rethink the relevance and applicability of the Seven Laws of Noah during the Middle Ages, primarily due to the precarious living conditions of the Jewish people under the Medieval Christian kingdoms and the Islamic world (see Jewish\u2013Christian relations and Jewish\u2013Islamic relations), since both Christians and Muslims recognize the patriarch Abraham as the unifying figure of the Abrahamic tradition, alongside the monotheistic conception of God. Silverstein states that Jewish theology came to include concepts and frameworks that would permit certain types of non-Jews to be recognized as righteous and deserving of life in the Hereafter due to the \"Noachide Law\". He sees there being two \"Torahs\": one for Jews, the other for the gentile \"Children of Noah\". Whilst theoretically the Noachide Law should be universal, its prohibitions against blasphemy and idolatry mean that in practice it only really applied to non-idolatrous theists. Therefore, Jews normally considered Christians and/or Muslims when discussing this concept.\nDavid Novak, professor of Jewish theology and ethics at the University of Toronto, presents a range of theories regarding the sources from which the Seven Laws of Noah originated, including the Hebrew Bible itself, Hittite laws, the Maccabean period, and the Roman period. Regarding the modern Noahide movement, he denounced it by stating that \"If Jews are telling Gentiles what to do, it's a form of imperialism\".\nJudaism.\nTalmud.\nAccording to the Babylonian Talmud, the Seven Laws of Noah laws apply to all of humanity. In Judaism, the term \"B'nei Noach\" (, \"Sons of Noah\") refers to all mankind. The Talmud also states: \"Righteous people of all nations have a share in the world to come\". Any non-Jew who lives according to these laws is regarded as one of the Righteous among the Gentiles. According to the Talmud, the Noahide covenant was given first to Adam and subsequently to Noah. Six of the seven laws were exegetically derived from passages in the Book of Genesis, with the seventh being the establishment of courts of justice.\nThe Talmudic sages expanded the concept of universal morality within the Noahide laws and added several other laws beyond the seven listed in the Talmud and Tosefta which are attributed to different rabbis, such as prohibitions against committing incest, cruelty to animals, pairing animals of different species, grafting trees of different kinds, castration, emasculation, homosexuality, pederasty, and sorcery among others, with some of the sages, such as Ulla, going so far as to make a list of 30 laws. The Talmud expands the scope of the seven laws to cover about 100 of the 613 mitzvot.\nPunishment.\nIn practice, Jewish law makes it very difficult to apply the Jewish death penalty. No record exists of a Gentile having been put to death for violating the seven Noahide laws. Some of the categories of capital punishment recorded in the Talmud are recorded as having never been carried out. It is thought that the rabbis included discussion of them in anticipation of the coming Messianic Age.\nAccording Sanhedrin 56a, for Noahides convicted of a capital crime, the only sanctioned method of execution is decapitation, considered one of the lightest capital punishments. Other sources state that the execution is to be by stoning if he has intercourse with a Jewish betrothed woman, or by strangulation if the Jewish woman has completed the marriage ceremonies, but had not yet consummated the marriage. In Jewish law, the only form of blasphemy which is punishable by death is blaspheming the Ineffable Name (). Some Talmudic rabbis held that only those offences for which a Jew would be executed, are forbidden to gentiles. The Talmudic rabbis discuss which offences and sub-offences are capital offences and which are merely forbidden.\nMaimonides states that anyone who does not accept the seven Noahide laws is to be executed, as God compelled the world to follow these laws. For the other prohibitions such as the grafting of trees and bestiality he holds that the sons of Noah are not to be executed. Maimonides adds a universalism lacking from earlier Jewish sources. The Talmud differs from Maimonides in that it considers the seven laws enforceable by Jewish authorities on non-Jews living within a Jewish nation. Nahmanides disagrees with Maimonides' reasoning. He limits the obligation of enforcing the seven laws to non-Jewish authorities, thus taking the matter out of Jewish hands. The Tosafot seems to agree with Nahmanides' reasoning. According to some opinions, punishment is the same whether the individual transgresses with knowledge of the law or is ignorant of the law.\nSome authorities debate whether non-Jewish societies may decide to modify the Noahide laws of evidence (for example, by requiring more witnesses before punishment, or by permitting circumstantial evidence) if they consider that to be more just. Whilst Jewish law requires two witnesses, Noachide law, as recorded by Rambam, Hilkhot Melakhim 9:14, can accept the testimony of a single eyewitness as sufficient for use of the death penalty. Whilst a confession of guilt is not admissible as evidence before a Jewish court, it is a matter of considerable dispute as to whether or not it constitutes sufficient grounds for conviction in Noachide courts.\nThere is also some debate as to whether the ideal punishment for violation of these laws is the death penalty, or if it is up to the court's discretion to decide which punishment is most fitting. While a simple reading of the Talmud might suggest that the ideal punishment is the death penalty, a number of prominent commentators, including Rav Yosef Eliyahu Henkin, have argued that it is up to the courts to decide.\nSubdivisions.\nVarious rabbinic sources have different positions on the way the seven laws are to be subdivided in categories. Maimonides, in his \"Mishneh Torah\", included the grafting of trees. Like the Talmud, he interpreted the prohibition against homicide as including a prohibition against abortion. David ben Solomon ibn Abi Zimra, a commentator on Maimonides, expressed surprise that he left out castration and sorcery which were also listed in the Talmud.\nThe Talmudist Ulla wrote of 30 laws which the sons of Noah took upon themselves. He only lists three, namely the three that the gentiles follow: not to create a Ketubah between males, not to sell carrion or human flesh in the market and to respect the Torah. The rest of the laws are not listed. Though the authorities seem to take it for granted that Ulla's thirty commandments included the original seven, an additional thirty laws are also possible from the reading. Two different lists of the 30 laws exist. Both lists include an additional twenty-three mitzvot which are subdivisions or extensions of the seven laws. One from the 16th-century work \"Asarah Maamarot\" by Rabbi Menahem Azariah da Fano and a second from the 10th century Samuel ben Hofni which was recently published from his Judeo-Arabic writings after having been found in the Cairo Geniza. Rabbi Zvi Hirsch Chajes suggests Menahem Azariah of Fano enumerated commandments are not related to the first seven, nor based on the written Torah, but instead were passed down by oral tradition.\n\"Ger toshav\" (resident alien).\nDuring biblical times, a Gentile living in the Land of Israel who did not want to convert to Judaism but accepted the Seven Laws of Noah as binding upon himself was granted the legal status of \"ger toshav\" (, \"ger\": \"foreigner\" or \"alien\" + \"toshav\": \"resident\", lit. \"resident alien\"). A \"ger toshav\" is therefore commonly deemed a \"Righteous Gentile\" (, \"Chassid Umot ha-Olam\": \"Pious People of the World\"), and is assured of a place in the World to Come (\"Olam Ha-Ba\").\nThe rabbinic regulations regarding Jewish\u2013Gentile relations are modified in the case of a \"ger toshav\". The accepted halakhic opinion is that the \"ger toshav\" must accept the seven Noahide laws in the presence of three \"haberim\" (men of authority), or, according to the rabbinic tradition, before a \"beth din\" (Jewish rabbinical court). He will receive certain legal protection and privileges from the Jewish community, and there is an obligation to render him aid when in need. The restrictions on having a Gentile do work for a Jew on the Shabbat are also greater when the Gentile is a \"ger toshav\".\nAccording to the Jewish philosopher and professor Menachem Kellner's study on Maimonidean texts (1991), a \"ger toshav\" could be a transitional stage on the way to becoming a \"righteous alien\" (, \"ger tzedek\"), i.e. a full convert to Judaism. He conjectures that, according to Maimonides, only a full \"ger tzedek\" would be found during the Messianic era. Furthermore, Kellner criticizes the assumption within Orthodox Judaism that there is an \"ontological divide between Jews and Gentiles\", which he believes is contrary to what Maimonides thought and the Torah teaches, stating that \"Gentiles as well as Jews are fully created in the image of God\".\nAccording to Christine Hayes, an American scholar of ancient Judaism and early Christianity serving as the Sterling Professor of Religious Studies in Classical Judaica at Yale University, the \"gerim\" were not necessarily Gentile converts in the Hebrew Bible, whether in the modern or rabbinic sense. Nonetheless, they were granted many rights and privileges when they lived in the Land of Israel. For example, they could offer sacrifices, actively participate in Israelite politics, keep their distinct ethnic identity for many generations, inherit tribal allotments, etc.\nMaimonides' view and his critics.\nDuring the Golden Age of Jewish culture in the Iberian Peninsula, the medieval Jewish philosopher and rabbi Maimonides (1135\u20131204) wrote in the halakhic legal code \"Mishneh Torah\" (tractate \"Hilkhot Melakhim\") that Gentiles must perform exclusively the Seven Laws of Noah and refrain from studying the Torah or performing any Jewish commandment, including resting on the Shabbat. He also states that if Gentiles willingly perform any Jewish commandment besides the Seven Laws of Noah according to the correct halakhic procedure, they are not prevented from doing so. According to Maimonides, teaching non-Jews to follow the Seven Laws of Noah is incumbent on all Jews, a commandment in and of itself. Nevertheless, the majority of rabbinic authorities over the centuries have rejected Maimonides' opinion, and the dominant halakhic consensus has always been that Jews are not required to spread the Noahide laws to non-Jews.\nMaimonides held that Gentiles may have a part in the World to Come (\"Olam Ha-Ba\") just by observing the Seven Laws of Noah and accepting them as divinely revealed to Moses. According to Maimonides, such non-Jews achieve the status of \"Chassid Umot Ha-Olam\" (\"Pious People of the World\"), and are different from those which solely keep the Noahide laws out of moral/ethical reasoning alone. He wrote in \"Hilkhot M'lakhim\":\"\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Anyone who accepts upon himself and carefully observes the Seven Commandments is of the Righteous of the Nations of the World and has a portion in the World to Come. This is as long as he accepts and performs them because (he truly believes that) it was the Holy One, Blessed Be He, Who commanded them in the Torah, and that it was through Moses our Teacher we were informed that the Sons of Noah had already been commanded to observe them. But if he observes them because he convinced himself, then he is not considered a Resident Convert and is not of the Righteous of the Nations of the World, but merely one of their wise.\nSome later editions of the \"Mishneh Torah\" differ by one letter and read \"Nor one of their wise men\"; the latter reading is narrower. In either reading, Maimonides appears to exclude philosophical Noahides from being \"Righteous Gentiles\". According to him, a truly \"Righteous Gentile\" follows the seven laws because they are divinely revealed, and thus are followed out of obedience to God.\nThe 15th-century Sephardic Orthodox rabbi Yosef Caro, one of the early Acharonim and author of the \"Shulchan Aruch\", rejected Maimonides' denial of the access to the World to Come to the Gentiles who obey the Noahide laws guided only by their reason as anti-rationalistic and unfounded, asserting that there is not any justification to uphold such a view in the Talmud. The 17th-century Sephardic Dutch philosopher Baruch Spinoza read Maimonides as saying \"nor one of their wise men\", and accused him of being narrow and particularistic. Other Jewish philosophers influenced by Spinoza, such as Moses Mendelssohn and Hermann Cohen, also have formulated more inclusive and universal interpretations of the Seven Laws of Noah.\nThe 18th-century Ashkenazi German philosopher Moses Mendelssohn, one of the leading exponents of the Jewish Enlightenment (\"Haskalah\"), strongly disagreed with Maimonides' formulation of the subject in the \"Mishneh Torah\" (tractate \"Hilkhot Melakhim\") citing a letter sent by Maimonides to the Jewish translator Abraham ben Samuel ibn Hasdai ha-Levi of Barcelona, and instead contended that, in conformity to the letter itself, Gentiles which observe the seven Noahide laws out of ethical, moral, or philosophical reasoning, without necessarily believing in the Jewish monotheistic conception of God, retained the status of \"Righteous Gentiles\" and would still achieve salvation. According to Steven Schwarzschild, Maimonides' position has its source in his adoption of Aristotle's skeptical attitude towards the ability of reason to arrive at moral truths, and \"many of the most outstanding spokesmen of Judaism themselves dissented sharply from\" this position, which is \"individual and certainly somewhat eccentric\" in comparison to other Jewish thinkers.\nA novel understanding of Maimonides' position in the 20th century, advanced by the Ashkenazi Orthodox rabbi Abraham Isaac Kook, is that a non-Jew who follows the commandments due to philosophical conviction rather than revelation (what Maimonides calls \"one of their wise men\") \"also\" merits the World to Come; this would be in line with Maimonides' general approach that following philosophical wisdom advances a person more than following revelatory commands.\nModern Noahide movement.\nMenachem Mendel Schneerson encouraged his followers on many occasions to preach the Seven Laws of Noah, devoting some of his addresses to the subtleties of this code. Since the 1990s, Orthodox Jewish rabbis from Israel, most notably those affiliated to Chabad-Lubavitch and religious Zionist organizations, including The Temple Institute, have set up a modern Noahide movement. These Noahide organizations, led by religious Zionist and Orthodox rabbis, are aimed at non-Jews to proselytize among them and commit them to follow the Noahide laws. These religious Zionist and Orthodox rabbis that guide the modern Noahide movement, who are often affiliated with the Third Temple movement, are accused of expounding a racist and supremacist ideology which consists in the belief that the Jewish people are God's chosen nation and racially superior to non-Jews, and mentor Noahides because they believe that the Messianic era will begin with the rebuilding of the Third Temple on the Temple Mount in Jerusalem to re-institute the Jewish priesthood along with the practice of ritual sacrifices, and the establishment of a Jewish theocracy in Israel, supported by communities of Noahides. In 1990, Meir Kahane, a convicted terrorist and founder of the Israeli ultra-nationalist political party Kach, was the keynote speaker at the First International Conference of the Descendants of Noah, the first Noahide gathering, in Fort Worth, Texas. After the assassination of Meir Kahane that same year, The Temple Institute, which advocates rebuilding the Third Jewish Temple on the Temple Mount in Jerusalem, started to promote the Noahide laws as well.\nPublic recognition.\nIn the 1980s, rabbi Menachem Mendel Schneerson urged his followers to actively engage in activities to inform non-Jews about the Noahide laws, which had not been done in previous generations. The Chabad-Lubavitch movement has been one of the most active in Noahide outreach, believing that there is spiritual and societal value for non-Jews in at least simply acknowledging the Noahide laws.\nIn 1982, Chabad-Lubavitch had a reference to the Noahide laws enshrined in a U.S. Presidential proclamation: the \"Proclamation 4921\", signed by the then-U.S. President Ronald Reagan. The United States Congress, recalling House Joint Resolution 447 and in celebration of Schneerson's 80th birthday, proclaimed 4 April 1982, as a \"National Day of Reflection\".\nIn 1989 and 1990, Chabad-Lubavitch had another reference to the Noahide laws enshrined in a U.S. presidential proclamation: the \"Proclamation 5956\", signed by then-U.S. President George H. W. Bush. The United States Congress, recalling House Joint Resolution 173 and in celebration of Schneerson's 87th birthday, proclaimed 16 April 1989, and 6 April 1990, as \"Education Day, U.S.A.\"\nIn January 2004, the spiritual leader of the Druze community in Israel, Sheikh Mowafak Tarif, met with a representative of Chabad-Lubavitch to sign a declaration calling on all non-Jews in Israel to observe the Noahide laws; the mayor of the Arab city of Shefa-'Amr (Shfaram) \u2013 where Muslim, Christian, and Druze communities live side-by-side \u2013 also signed the document.\nIn March 2016, the Sephardic Chief Rabbi of Israel, Yitzhak Yosef, declared during a sermon that Jewish law requires that only non-Jews who follow the Noahide laws are allowed to live in Israel: \"According to Jewish law, it's forbidden for a non-Jew to live in the Land of Israel \u2013 unless he has accepted the seven Noahide laws, [...] If the non-Jew is unwilling to accept these laws, then we can send him to Saudi Arabia, ... When there will be full, true redemption, we will do this.\" Yosef further added: \"non-Jews shouldn't live in the land of Israel. ... If our hand were firm, if we had the power to rule, then non-Jews must not live in Israel. But, our hand is not firm. [...] Who, otherwise be the servants? Who will be our helpers? This is why we leave them in Israel.\" Yosef's sermon sparked outrage in Israel and was fiercely criticized by several human rights associations, NGOs and members of the Knesset; Jonathan Greenblatt, Anti-Defamation League's CEO and national director, and Carole Nuriel, Anti-Defamation League's Israel Office acting director, issued a strong denunciation of Yosef's sermon:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The statement by Chief Rabbi Yosef is shocking and unacceptable. It is unconscionable that the Chief Rabbi, an official representative of the State of Israel, would express such intolerant and ignorant views about Israel's non-Jewish population \u2013 including the millions of non-Jewish citizens.As a spiritual leader, Rabbi Yosef should be using his influence to preach tolerance and compassion towards others, regardless of their faith, and not seek to exclude and demean a large segment of Israelis.We call upon the Chief Rabbi to retract his statements and apologize for any offense caused by his comments.\nContemporary status.\nHistorically, some rabbinic opinions consider non-Jews not only not obliged to adhere to all the remaining laws of the Torah, but actually forbidden from observing them.\nNoahide law differs radically from Roman law for gentiles (\"Jus Gentium\"), if only because the latter was enforceable judicial policy. Rabbinic Judaism has never adjudicated any cases under the Noahide laws, and Jewish scholars disagree about whether the Noahide laws are a functional part of the \"Halakha\" (Jewish law).\nSome modern views hold that penalties are a detail of the Noahide Laws and that Noahides themselves must determine the details of their own laws for themselves. According to this school of thought \u2013 see N. Rakover, \"Law and the Noahides\" (1998); M. Dallen, \"The Rainbow Covenant\" (2003) \u2013 the Noahide laws offer humankind a set of absolute values and a framework for righteousness and justice, while the detailed laws that are currently on the books of the world's states and nations are presumptively valid.\nIn recent years, the term \"Noahide\" has come to refer to non-Jews who strive to live in accord with the seven Noahide Laws; the terms \"observant Noahide\" or \"Torah-centered Noahides\" would be more precise but these are infrequently used. Support for the use of \"Noahide\" in this sense can be found with the Ritva, who uses the term \"Son of Noah\" to refer to a gentile who keeps the seven laws, but is not a \"ger toshav\".\nEarly Christianity.\nIn the history of Christianity, the Apostolic Decree recorded in Acts 15 is commonly seen as a parallel to the Seven Laws of Noah, and thus be a commonality rather than a differential. Some modern scholars dispute the connection between Acts 15 and the seven Noahide laws. The Apostolic Decree is still observed by the Eastern Orthodox Church and includes some food restrictions.\nThe \"Jewish Encyclopedia\" article on Paul of Tarsus states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;According to , , , [...], Paul began working along the traditional Jewish line of proselytizing in the various synagogues where the proselytes of the gate [e.g., ] and the Jews met; and only because he failed to win the Jews to his views, encountering strong opposition and persecution from them, did he turn to the gentile world after he had agreed at a council with the apostles at Jerusalem to admit the gentiles into the Church only as proselytes of the gate, that is, after their acceptance of the Noachian laws ()\".\nThe article on the New Testament states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For great as was the success of Barnabas and Paul in the heathen world, the authorities in Jerusalem insisted upon circumcision as the condition of admission of members into the Church, until, on the initiative of Peter, and of James, the head of the Jerusalem church, it was agreed that acceptance of the Noachian Laws\u2014namely, regarding avoidance of idolatry, fornication, and the eating of flesh cut from a living animal\u2014should be demanded of the heathen desirous of entering the Church.\nThe 18th-century rabbi Jacob Emden hypothesized that Jesus, and Paul after him, intended to convert the gentiles to the Seven Laws of Noah while calling on the Jews to keep the full Law of Moses.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21909", "revid": "25859633", "url": "https://en.wikipedia.org/wiki?curid=21909", "title": "Nazis", "text": ""}
{"id": "21911", "revid": "244263", "url": "https://en.wikipedia.org/wiki?curid=21911", "title": "Naturism", "text": "Practice and advocacy of social nudity\nNaturism is a lifestyle of practicing non-sexual social nudity in private and in public; the word also refers to the cultural movement which advocates and defends that lifestyle. Both may alternatively be called nudism. Though the two terms are broadly interchangeable, \"nudism\" emphasizes the practice of nudity, whilst \"naturism\" highlights an attitude favoring harmony with nature and respect for the environment, into which that practice is integrated. That said, naturists come from a range of philosophical and cultural backgrounds; there is no single naturist ideology.\nEthical or philosophical nudism has a long history, with many advocates of the benefits of enjoying nature without clothing. At the turn of the 20th century, organizations emerged to promote social nudity and to establish private campgrounds and resorts for that purpose. Since the 1960s, with the acceptance of public places for clothing-optional recreation, individuals who do not identify themselves as naturists or nudists have been able to casually participate in nude activities. Nude recreation opportunities vary widely around the world, from isolated places known mainly to locals through officially designated nude beaches and parks, and on to public spaces and buildings in some jurisdictions.\nDefinition and lexicology.\nThe XIV Congress of the International Naturist Federation (INF) held at Agde, France in 1974 defined naturism as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;...a way of life in harmony with nature characterised by the practice of communal nudity with the intention of encouraging self-respect, respect for others and for the environment.\nMany contemporary naturists and naturist organisations advocate that the practice of social nudity should not be linked with sexual activity. Some recent studies show that naturism can help grow self-esteem, and thus have a positive impact on having a well-balanced sexuality, too. For various sociocultural and historical reasons, the lay public, the media, and many contemporary naturists and their organisations have, or present, a simplified view of the relationship between naturism and sexuality. As of 2009[ [update]], research has begun to explore this complex relationship.\nThe International Naturist Federation explains:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Each country has its own kind of naturism, and even each club has its own special character, for we too, human beings, have each our own character which is reflected in our surroundings.\nThe usage and definition of these terms varies geographically and historically. Naturism and nudism have the same meaning in the United States, but there is a clear distinction between the two terms in Great Britain.\nIn naturist parlance, the terms \"textile\" or \"textilist\" refer to non-naturist persons, behaviours or facilities (e.g. \"the textile beach starts at the flag\", \"they are a mixed couple\u00a0\u2013 he is naturist, she is textile\"). \"Textile\" is the predominant term used in the UK (\"textilist\" is unknown in British naturist magazines, including \"H&amp;E naturist\"), but some naturists avoid using this term due to perceived negative or derogatory connotations. \"Textilist\" is said to be used interchangeably with \"textile\", but no dictionary definition to this effect exists, nor are there any equivalent examples of use in mainstream literature such as those for \"textile\".\nNaturist places and events.\nNaturist facilities.\nAt naturist-organised events or venues, clothing is usually optional. At naturist swimming pools or sunbathing places, however, complete nudity is expected (weather permitting). This rule is sometimes a source of controversy among naturists. Staff at a naturist facility are usually required to be clothed due to health and safety regulations.\nFacilities for naturists are classified in various ways. A landed or members' naturist club is one that owns its own facilities. Non-landed (or travel) clubs meet at various locations, such as private residences, swimming pools, hot springs, landed clubs and resorts, or rented facilities. Landed clubs can be run by members on democratic lines or by one or more owners who make the rules. In either case, they can determine membership criteria and the obligations of members. This usually involves sharing work necessary to maintain or develop the site.\nThe international naturist organizations were mainly composed of representatives of landed clubs. \"Nudist colony\" is no longer a favored term, but can be used by naturists to address landed clubs that have rigid non-inclusive membership criteria.\nA holiday centre is a facility that specializes in providing apartments, chalets and camping pitches for visiting holidaymakers. A center is run commercially, and visitors are not members and have no say in the management. Most holiday centers expect visitors to hold an INF card (that is, to belong to an INF-affiliated organization), but some have relaxed this requirement, relying on the carrying of a trade card. Holiday centers vary in size. Larger holiday centres may have swimming pools, sports pitches, an entertainment program, kids' clubs, restaurants and supermarkets. Some holiday centres allow regular visitors to purchase their own chalets, and generations of the same families may visit each year. Holiday centres are more tolerant of clothing than members-only clubs; total nudity is usually compulsory in the swimming pools and may be expected on the beaches, while on the football pitches, or in the restaurants in the evening, it is rare.\nA naturist resort is, to a European, a private property with accommodation and facilities where naturism is the norm. Centre Helio-Marin in Vendays Montalivet, France (the first naturist resort, established in 1950); the naturist village of Charco del Palo on Lanzarote, Canary Islands; Vera Playa in Spain; and Vritomartis Resort in Greece are examples.\nIn US usage, a naturist resort can mean a holiday centre. Freik\u00f6rperkultur (FKK)\u2014literally translated as 'free body culture'\u2014is the name for the general movement in Germany. The abbreviation is recognised outside of Germany and can be found on informal signs indicating the direction to a remote naturist beach.\nNude beaches.\nIn some European countries, such as Denmark, all beaches are clothing optional, and in others like Germany (and experimentally in France) there are naturist sunbathing areas in public parks (e.g., in Munich and Berlin). Beaches in some holiday destinations, such as Crete, are clothing optional except some central urban beaches. There are two centrally located clothes-optional beaches in Barcelona. Sweden allows nudity on all beaches.\nIn a survey by \"The Daily Telegraph\", Germans and Austrians were most likely to have visited a nude beach (28%), followed by Norwegians (18%), Spaniards (17%), Australians (17%), and New Zealanders (16%). Of the nationalities surveyed, the Japanese (2%) were the least likely to have visited a nude beach. This result may indicate the lack of nude beaches in Japan; however, the Japanese are open with regard to family bathing nude at home and at onsens (hot springs).\nFestival naturism.\nFrom Woodstock to Edinburgh, and Nambassa in the southern hemisphere, communal nudity can be seen at music and counterculture festivals.\nThe Nambassa hippie festivals held in New Zealand in the late 1970s were examples of non-sexual naturism. Of the 75,000 patrons who attended the 1979 Nambassa three-day festival, an estimated 35% of attendees spontaneously chose to remove their clothing, preferring complete or partial nudity.\nSome nudist festivals are held to celebrate particular days of the year, and activities may include nude bodypainting. One example is the Neptune Day Festival held in Koktebel, Crimea to depict mythological events. Another is the Festival Nudista Zipolite organized by the Federaci\u00f3n Nudista de M\u00e9xico (Mexican Nudist Federation) held annually since 2016 on the first weekend of February.\nA few camps organize activities in the nude, such as oil wrestling by camp Gymnasium.\nSummer naturism.\nNaturism tends to be more common during the warmer summer months. \nSome regions host first-time naturists and people who have recently started to practice the naturist lifestyle.\nOne study noted that some of these people are seasonal naturists who wear clothes during other times of the year.\nHistory.\nNudity in social contexts has been practised in various forms by many cultures and in all time periods. In modern Western society, social nudity is most frequently encountered in the contexts of bathing, swimming and using saunas, but throughout history and in many contemporary tropical cultures, nudity is a norm at many sports events and competitions.\nThe first known use of the word occurred in 1778. A French-speaking Belgian, Jean Baptiste Luc Planchon (1734\u20131781), used the term to advocate nudism as a means of improving the or healthy living.\nThe earliest known naturist club in the western sense of the word was established in British India in 1891. The Fellowship of the Naked Trust was founded by Charles Edward Gordon Crawford, a widower who was a District and Sessions Judge for the Bombay Civil Service. The commune was based in Matheran and had just three members at the beginning: Crawford and two sons of an Anglican missionary, Andrew and Kellogg Calderwood. The commune fell apart when Crawford was transferred to Ratnagiri; he died soon after in 1894.\nIn 1902, a series of philosophical papers was published in Germany by Dr. Heinrich Pudor under the pseudonym Heinrich Scham, who coined the term (Nude Culture). In 1906, he wrote a three-volume treatise with this term as its title, which discussed the benefits of nudity in co-education and advocated participating in sports while being free of cumbersome clothing. Richard Ungewitter (\"Nacktheit\", 1906, \"Nackt\", 1908, etc.) proposed that combining physical fitness, sunlight, and fresh-air bathing with the nudist philosophy contributed to mental and psychological fitness, good health, and an improved moral-life view. Major promoters of these ideas included Adolf Koch and Hans Sur\u00e9n, who was an instructor and manager at the German Army School of Military Physical Education in W\u00fcnsdorf. Germany published the first journal of nudism from 1902 to 1932, during which time it evolved and became known as \"Freik\u00f6rperkultur\" (FKK), the free body culture movement.\nThe wide publication of those papers, and others, contributed to an explosive worldwide growth of nudism in which nudists participated in various social, recreational, and physical fitness activities in the nude. The first organized club for nudists on a large scale, (Open-Air Park), was opened near Hamburg in 1903 by Paul Zimmerman.\nIn 1919, German doctor Kurt Huldschinsky discovered that exposure to sunlight helped to cure rickets in many children, causing sunlight to be associated with improved health.\nIn France in the early 20th century, the brothers Gaston and Andr\u00e9 Durville, both physicians, studied the effects of psychology, nutrition, and environment on health and healing. They became convinced of the importance of natural foods and the natural environment on human well-being and health. They named this concept . The profound effect of clean air and sunlight on human bodies became evident to them and so nudity became a part of their naturism.\nNaturism became a more widespread phenomenon in the 1920s in Germany, the United Kingdom, France and other European countries and spread to the United States, where it became established in the 1930s. In Brazil, nudist magazines were already published in the 1930. In mid 50s, there were several of such publications and some editors were persecuted by police and sued by authorities under the charge of \"indecent exposure\".\nBy 1951, the various national federations united to form the International Naturist Federation. Some naturists preferred not to join clubs, and after 1945, pressure arose to designate beaches for naturist use. From the middle of the 20th century, with changing leisure patterns, commercial organisations began opening holiday resorts to attract naturists who expected the same\u00a0\u2013 or better\u00a0\u2013 standards of comfort and amenity offered to non-naturists. More recently, naturist holiday options have expanded to include cruises.\nIn the early 21st century, many organised clubs saw a decline in attendance by young people, which worried many naturists about the future of the movement. The clubs' aging memberships may have put younger people off. A rise in social conservatism, re-asserting a nudity taboo, also may have contributed to the decline. However, since tolerance for nudity in general is increasing over time, and is higher among younger generations, an alternative hypothesis is that younger naturists no longer feel they need to join a club or visit a resort in order to practise naturism. Active recruitment of younger members is being pursued by some organisations. The phenomenon varies by country, with, for example, naturism in France experiencing steady growth in a younger demographic during the 2010s. A similar trend is seen in Germany, with young people eager to depart from social norms and beauty standards.\nWriters.\nNaturism was part of a literary movement in the late 19th century (see the writings of Andr\u00e9 Gide) that also influenced the art movements of the time, specifically Henri Matisse and other Fauve painters. This movement was based on the French concept of \"joie de vivre\", the idea of reveling freely in physical sensations and direct experiences and a spontaneous approach to life.\nHealth.\nNaturist activities can have positive psychological benefits including greater life satisfaction, more positive body image, and higher self-esteem. Social nudity leads to acceptance in spite of differences in age, body shape, fitness, and health.\nReligion.\nChristian naturism includes various members associated with most denominations. Although beliefs vary, a common theme is that much of Christianity has misinterpreted the events regarding the Garden of Eden, and that God was displeased with Adam and Eve for covering their bodies with fig leaves.\nControversy.\nNaturism is usually promoted as not being sexual, but there are resorts where social nudity is practised alongside exhibitionism, voyeurism, and other alternative lifestyles like swinging. Mainstream discourse around naturism sometimes conflates sexual and non-sexual variations, though family-oriented naturism organisations try to resist this stigma. Some naturist clubs have shifted to catering to swingers, and as a result may be expelled from mainstream naturist organizations, whilst some naturist villages, notably Cap d'Agde, have been successfully overtaken by swingers and \"libertines\". Others struggle with wanting to maintain a family image while being lax in behavior enforcements for fear of losing revenue and no longer being financially viable. Attempts have been made to legislate naturist activity, such as children's summer camps.\nMany films and published materials in the middle decades of the 20th century were presented as documentaries of the naturist lifestyle. In fact this was largely a pretext to exploit a loophole in censorship laws restricting the exhibition of nudity. Additionally, child pornography has been distributed under the guise of naturist media. Precisely defining the distinction has proved challenging for law enforcers, as it depends on the subjective question of whether the purpose of the production is sexual. Court cases attempting to differentiate naturist publications from pornography reach back almost a century.\nAfrica.\nSouth Africa.\nMpenjati beach in KwaZulu-Natal province of South Africa has nude-beach status.\nEurope.\nIn most European countries, nudity is not explicitly forbidden. Whether it is tolerated on beaches which are not marked as official nudist beaches varies greatly. The only country with substantially different laws is Denmark, where beach nudity is explicitly allowed on all beaches, except for two in the far west of the country.\nBelgium.\nOrganized naturism in Belgium began in 1924 when engineer Joseph-Paul Swenne founded the Belgian League of Heliophilous Propaganda (usually abbreviated to ) in Uccle. This was followed four years later by , founded by Jozef Geertz and hosted on the country estate of entrepreneur Oswald Johan de Schampelaere. Belgian naturism was influenced in equal part by French naturism and German . Belgian naturists are represented by the (FBN).\nCroatia.\nCroatia is world famous for naturism, which accounts for about 15% of its tourism industry. It was also the first European country to develop commercial naturist resorts. During a 1936 Adriatic cruise, King Edward VIII and Wallis Simpson stopped at a beach on the island of Rab where King Edward obtained special permission from the local government to swim naked. This event marked the beginning of nudist tourism in Croatia.\nFinland.\nIn Finnish culture, nudism is considered to be a relatively normal way to live. It is not uncommon to see entire families spending time together naked. Families may be naked while bathing, in a sauna, swimming in a pool, or playing on a beach, and it is not unusual to see children playing naked in a family yard for example. Nudity as a whole is considered less taboo than in many other countries.\nFrance.\nMarcel Kienn\u00e9 de Mongeot is credited with starting naturism in France in 1920. His family had suffered from tuberculosis, and he saw naturism as a cure and a continuation of the traditions of the ancient Greeks. In 1926, he started the magazine (later titled ) and the first French naturist club, , at Garambouville, near \u00c9vreux. The court action that he initiated established that nudism was legal on private property that was fenced and screened.\nDrs. Andr\u00e9 and Gaston Durville bought on the \u00cele du Levant where they established the village of H\u00e9liopolis, which was open to the public. In 1925, Dr. Fran\u00e7ois Fougerat de David de Lastours wrote a thesis on heliotherapy, and in that year, he opened the . In 1936, the naturist movement was officially recognised.\nAlbert and Christine Lecocq were active members of many of these clubs, but they left after disagreements, and in 1944, they founded the with members in 84 cities. Four years later, they founded the F\u00e9d\u00e9ration Fran\u00e7aise de Naturisme (FFN); in 1949, they started the magazine , and in 1950, they opened the CHM Montalivet, the world's first naturist holiday centre, where the INF was formed.\nHenri Zisly was another prominent figure and primitivist in the French naturism movement who wrote on a return to lifestyles based on self-sufficiency.\nGermany.\nGerman naturism (, FKK) was part of the movement and the youth movement of 1896, from Steglitz, Berlin, which promoted ideas of fitness and vigour. At the same time, doctors of the (Natural Healing Movement) were using heliotherapy, treating diseases such as tuberculosis, rheumatism, and scrofula with exposure to sunlight.\n, a term coined in 1903 by Heinrich Pudor, connected nudity, vegetarianism and social reform, and was practised in a network of 200 members clubs. The movement gained prominence in the 1920s by offering a health-giving lifestyle with Utopian ideals. Germany published the first naturist journal from 1902 to 1932, but it became politicised by radical socialists who believed it would lead to classlessness and a breakdown of society. It eventually became associated with pacificism.\nIn 1926, Adolf Koch established a school of naturism in Berlin, encouraging a mixing of the sexes, open air exercises, and a programme of \"sexual hygiene\". In 1929 the Berlin school hosted the first International Congress on Nudity.\nAfter World War II, East Germans were free to practice naturism, chiefly at beaches rather than clubs (private organizations were regarded as potentially subversive). Naturism became a large element in DDR politics. The subsection of the Workers Sports Organisation had 60,000 members. Since reunification there are many clubs, parks and beaches open to naturists, though nudity has become less common in the former eastern zone. Germans are typically the most commonly seen visitors at nude beaches in France and around Europe.\nGreece.\nThere are no official nude beaches, however there are unofficial nude beaches on the islands frequented by tourists, like Crete, Mykonos or Karpathos, and on smaller islands like Skopelos or Skiathos where nudity is tolerated, usually at the more remote ends or secluded areas of beaches.\nToplessness also is widely practiced by locals and tourists alike as there are no cultural taboos against it.\nIn 2015, a court in Thessaloniki, Greece's second largest city, acquitted nudist activists who were charged for wandering naked in the city as part of their activist actions for promoting the urban nudism. In its ruling, the court deemed these acts to be \"not lewd or lascivious\", and vindicated the activists, thus recognizing their right to be naked publicly.\nItaly.\nFull nudity is allowed in Italy in the official naturist beaches and places of the country, and in many other places where there is an established tradition of naturist attendance, as confirmed by a recent absolution sentence. In all other public places, full nudity is generally prohibited by civil law and could be punished with fines that have been recently reduced (minimum \u20ac51 to maximum \u20ac309).\nIn the last decades, six regions have created laws to promote naturist tourism, and actually there are more than 20 official naturist beaches in Italy, where naturism is recognised and guaranteed by administrative acts, and more than 30 beaches with a long tradition of naturist attendance where nudity is accepted. Naturist accommodations are located in most of the regions and it is estimated that the number of nudists and naturists in Italy is about 500,000 people. Since the 1960s, there have been naturist associations in many regions, and a naturist federation on a national level.\nFemale toplessness is allowed, in a nonsexual context, in all the beaches of the country. On March 20, 2000, the Supreme Court of Cassation through sentence No. 3557 has determined that the exposure of the nude female breast since some decades is considered a \"commonly accepted behavior\" and therefore has \"entered into the social custom\". Since then, local government regulations forbidding toplessness are extremely rare.\nNetherlands.\nThe oldest Dutch naturist association is ('Sun and Life'), founded in 1946 with the aim of promoting healthy physical and mental development and a natural way of life. The national association is (NFN), which in 2017 adopted the name ('Simply Naked') in an effort to become more accessible to casual naturists and strengthen the acceptance of nude recreation.\nIn general, Dutch people are very tolerant of beach nudity, as long as it does not impact others, or involve inappropriate staring or sexual behaviour. Topless sunbathing is permitted on most beaches except where prohibited by signage.\nPortugal.\nThe (Portuguese Naturist Federation) or FPN was founded on 1 March 1977 in Lisbon. In the 21st century, naturism is considered a tolerated practice, whereas there are many officially designated nudist beaches.\nPoland.\nIn modern-day Poland, naturism is practiced in a number of seaside and inland beaches. Most Polish beaches of this type are actually clothing-optional rather than naturist. One such beach is Mi\u0119dzyzdroje-Lubiewo.\nSpain.\nPublic nudity in Spain is not illegal since there is no law banning its practice. Spanish legislation foresees felony for exhibitionism but restricts its scope to obscene exposure in front of children or mentally impaired individuals, i.e. with sexual connotation. There are, however, some municipalities (like San Pedro del Pinatar) where public nudity has been banned by means of by-laws. Other municipalities (like Barcelona, Salou, Platja de Palma and Sant Antoni de Portmany) have used similar provisions to regulate partial nudity, requiring people to cover their torsos on the streets. Some naturist associations have appealed these by-laws on the grounds that a fundamental right (freedom of expression, as they understand nudism to be self-expression) cannot be regulated with such a mechanism. Some courts have ruled in favour of nudist associations. Nudism in Spain is normally practised by the seaside, on beaches or small coves with a tradition of naturism. In Vera, Spain, there is a wide residential area formed by nudist urbanisations. Nudist organisations may organise some activities elsewhere in inner territory.\nResearch was done on the island of Menorca, where naturism is practiced at small, isolated beaches apart from the island's developed resorts. Not everyone on these beaches, even within a group, is nude, and both types of participants were interviewed. Most were white heterosexuals between the ages of 25 and 40 who live in cities such as Madrid or Barcelona. For them, being nude on a beach is about bodily sensations of sun, sea, and sand directly on the skin, not about cultural meanings or performance of bodily appearance. The behaviors that support the non-sexual definition of the situation work by downplaying the visual, most of all by not staring at others. It is also unacceptable for a person to actively seek the gaze of others. Naturists may see the decision not to be nude is holding on to the visual, and non-naturists may see beach nudity as a form of exhibitionism.\nLegal provisions regarding partial nudity (or toplessness) are analogous to those regarding full nudity, but social tolerance towards toplessness is higher. The law does not require women to cover their breasts in public swimming, or on any beach in Spain. The governments of the municipalities of Galdakao and L'Ametlla del Vall\u00e8s legalized female toplessness on their public pools in March 2016 and June 2018, respectively.\nNaturists were a prominent affinity group among Spanish anarcho-syndicalists.\nUnited Kingdom.\nIn the United Kingdom, the first official nudist club was established in Wickford, Essex, in 1924. According to Michael Farrar, writing for British Naturism, the club adopted the name \"Moonella Group\" from the name of the owner of the ground and called its site The Camp. Moonella, who was still living in 1965 but whose identity remains to be discovered, had inherited a house with land in 1923 and made it available to certain members of the New Gymnosophy Society. This society was founded a few years before by H.C. Booth, M.H. Sorensen and Rex Wellbye under the name of the English Gymnosophical Society. It met for discussions at the Minerva Cafe at 144 High Holborn in London, the headquarters of the Women's Freedom League. Those who were permitted to join the Moonella Group were carefully selected, and the club was run by a leadership of the original members, all of whom had club names to preserve their anonymity. The club closed in 1926 because of construction on adjacent land.\nBy 1943, there were a number of \"sun clubs\", and together they formed the British Sun Bathers Association, or BSBA. In 1954, a group of clubs unhappy with the way the BSBA was being run, split to form the Federation of British Sun Clubs, or FBSC. In 1961, the BSBA Annual Conference agreed that the term nudist was inappropriate and should be discarded in favour of naturist. The two organisations rivalled each other before eventually coming together again in 1964 as the Central Council for British Naturism, or CCBN. This organisational structure has remained much the same but as of 2011[ [update]] it is called British Naturism or BN.\nThe first official nude beach was opened at Fairlight Glen in Covehurst Bay near Hastings in 1978 (not to be confused with Fairlight Cove, which is to the east), followed later by the beaches at Brighton and Fraisthorpe. Bridlington opened in April 1980.\nOceania.\nAustralia.\nAustralia's first naturist club was founded in Sydney in 1931 by the French-born anarchist and pacifist Kleber Claux. In 1975, the southern half of Maslin Beach, south of Adelaide, was declared Australia's first official nude beach. The beach is almost long, so the area reserved for nude bathing is away from other beach users.\nAlso in South Australia, Sunland nudist holiday village was established in 1974, on of beachfront property on the south coast, near the town of Robe, South Australia.\nThe Australian Naturist Federation (ANF) represents naturists in Australia. Many naturist clubs, resorts and other organisations are Affiliate members of the ANF. Individual membership is also available to naturists who wish to support the organisation, and have access to member-only online events and forums.\nQueensland Naturist Association (QNA) is a non-profit advocacy group committed to fostering positive changes in clothing-optional recreation in Queensland, Australia. QNA organises naturist events, such as parties and nude cruises..\nNew Zealand.\nNudist clubs (called \"sun clubs\") were established in Dunedin and Auckland in early 1938; the Auckland Sun Group went into recess shortly afterwards due to the outbreak of World War II. In 1958 the allied nudist clubs of New Zealand established the New Zealand Sunbathing Association, later renamed the New Zealand Naturist Federation. The Federation includes 17 affiliated clubs with a total membership (in 2012) of 1,600 people. In 2016 the Federation, in conjunction with Tourism New Zealand, hosted the World Congress of the International Naturist Federation at the Wellington Naturist Club, marking the second time the Congress had ever been held in the Southern Hemisphere.\nOutside formal naturist organizations, social nudity is practised in a variety of contexts in New Zealand culture. It is a feature of many summer music festivals, including Convergence, Kiwiburn, Luminate, Rhythm &amp; Vines, and Splore, in a tradition going back to Nambassa in the late 1970s. It is also associated with the culture of rugby, most prominently in the nude rugby match held in Dunedin each winter from 2002 to 2014 (and sporadically thereafter) as pre-match entertainment for the first professional rugby game of the season, and in the mock public holiday \"National Nude Day\", an event in which viewers of the talk show \"SportsCafe\" were invited \u2013 chiefly by former rugby player Marc Ellis, the show's most irrepressibly comic presenter \u2013 to send in photos and video of themselves performing daily activities in the nude.\nWhile a large proportion of New Zealanders are tolerant of nudity, especially on beaches, there remains a contingent who consider it obscene. Naturists who engage in casual public nudity, even in places where this is lawful, risk being reported to police by disapproving people. Legally, nudity is permissible on any beach where it is \"known to occur\", in consequence of which New Zealand has no official nude beaches. The indecent exposure provision of the Summary Offences Act is, in practice, reserved for cases of public sexual gratification, but public nudity may still be prosecuted under the \"offensive behaviour\" provision.\nNorth America.\nCanada.\nIn Canada, individuals around the country became interested in nudism, skinny-dipping, and physical culture in the early part of the 20th century. \"Sunbathing &amp; Health\", a magazine targeted toward Canadian naturists and which occasionally carried local news, began publication after 1940. There were scattered groups of naturists in several cities during the 1930s and 1940s, and some of these groups attracted enough interest to form clubs on private land. The most significant clubs were the Van Tan Club, formed in 1939, which is still operating in North Vancouver, BC, and the Sun Air Club, in Ontario.\nCanadians who served in the military during the Second World War met like-minded souls from across the country, and often visited clubs while in Europe. They were a ready pool of recruits for post-war organizers. A few years later, the wave of post-war immigration brought many Europeans with their own extensive experience, and they not only swelled the ranks of membership, but often formed their own clubs, helping to expand nudism from coast to coast.\nMost clubs eventually united in the Canadian Sunbathing Association, which affiliated with the American Sunbathing Association in 1954. Several disagreements between eastern and western members of the CSA resulted in its division into the Western Canadian Sunbathing Association (WCSA) and the Eastern Canadian Sunbathing Association (ECSA) in 1960. The ECSA endured much in-fighting over the next fifteen years, which led to its official demise in 1978. The WCSA changed its name to the American Association for Nude Recreation \u2013 Western Canadian Region, a region of the American Association for Nude Recreation (AANR), which itself was formerly known as the ASA.\nIn 1977 the (FQN) was founded in Quebec by Michel Va\u00efs, who had experienced European naturism at Montalivet. In 1985 the Federation of Canadian Naturists (FCN) was formed with the support of the FQN. In 1988 the FQN and FCN formed the FQN-FCN Union as the official Canadian representative in the International Naturist Federation.\nCuba.\nNaturism was a major component of the Cuban anarchist movement, alongside anarchist communism and anarcho-syndicalism, as an alternative health and lifestyle movement. Adri\u00e1n del Valle in particular advocated for the emancipatory\" function of naturism in a society.\nMexico.\nFederaci\u00f3n Nudista de M\u00e9xico is a members organization with both individual and organization members. It promotes social nudity in Mexico, and it is recognized by the International Naturist Federation as the official national naturist organization in that country.\nAs of 2016[ [update]], Playa Zipolite is Mexico's first and only legal public nude beach. A free beach and unofficially nudist for more than 50 years, this beach is reputed to be the best place for nudism in the country. The numerous nude sunbathers, and the long tradition, make it safe for nudism and naturism. Annually since 2016, on the first weekend of February, Zipolite has hosted Festival Nudista Zipolite that in 2019 attracted 7,000\u20138,000 visitors.\nUnited States.\nKurt Barthel founded the American League for Physical Culture in 1929 and organized the first nudist event. In about 1930 they organized the American Gymnosophical Association. Barthel founded America's first official nudist camp, Sky Farm in New Jersey, in May, 1932. Around 1932, the AGA established the Rock Lodge Club as a nudist facility in Stockholm, New Jersey and Ilsley Boone, a Dutch Reformed minister, formed the Christian naturism movement. Naturism began to expand nationwide.\nThe American Association for Nude Recreation (AANR) is the national naturist organization. Arnd Kr\u00fcger compared nudists in Germany and the United States and came to the conclusion that in Germany the racial aspects () were important for the breakthrough (e.g. the Commanding General of the Army served as patron for nudists events), while in the U.S. nudism was far more commercial and had thus more difficulties.\nIn 2008, Florida Young Naturists held its first Naked Bash, which has been repeated multiple times per year and has grown into one of the larger young naturist gatherings in the world.\nIn 2009, a campaign to promote nudism in the United States occurred with an effort by the AANR to record the largest simultaneous skinny dip at several U.S. clubs and beaches, which occurred on July 11 of that year.\nIn 2010, an organization formed called Young Naturists America, which was mostly focused on the younger generation, as well as social issues, such as body image. Young Naturists and Nudists America closed in 2017.\nAsia.\nIndonesia.\nIn the 1970s, nudity on Bali's remote and deserted beaches was common, but with the massive growth of tourism this practice has disappeared. In 2002, nudity was declared illegal on Petitenget Beach, the last beach in Seminyak that tolerated discreet nudity. Individuals began to practice nudity in private villas and resorts. Laki Uma Villa, the first naturist facility to open, was for gay men only. Bali au Naturel, the first adult-only nudist resort for both genders, opened its doors in 2004. It subsequently expanded from 3 to 15 rooms and added two more swimming pools.\nIndonesia has an underground naturist community who defy the laws against public nudity.\nThailand.\nNudism was introduced in 2012 by The Thailand Naturist Association in Pattaya (Chan Resort), and five more nudist resorts have been created across Thailand: Barefeet Resort in Bangkok, Lemon Tree Resort in Phuket City, Oriental Village in Chiangmai, Phuan Naturist Village in Pattaya, and Peace Blue Naturist Resort in Phuket.\nSince 2020 during the worldwide pandemic, Lemon Tree Resort in Phuket, Oriental Village in Chiangmai, and Phuan Naturist Village in Pattaya have closed.\nDragonfly Naturist Village in Pattaya (a member of American Association for Nude Recreation) has opened and expanded its property as the largest naturist resort in Thailand.\nSouth America.\nArgentina.\nNaturism is allowed in the official nude beaches of Puerto Escondido, located near Miramar, and Playa Querand\u00ed, located in Villa Gesell. Total nudity is permitted in some private naturist resorts.\nBrazil.\nIn general, public nudity tends to be condemned by the Brazilian authorities, which commonly see it as indecent exposure. However, the country has the highest number of official nude beaches in Latin America, being eight in total, and this number partially is explained by the fact that the Brazilian territory has more than of ocean coast. Moreover, there are a few private naturist clubs throughout the country where full nudity is accepted as well. Naturism in Brazil is regulated by the Brazilian Naturism Federation (in Portuguese: \"Federa\u00e7\u00e3o Brasileira de Naturismo\", abbreviated as \"FBrN\").\nChile.\nThe first nude beach in the country, called Playa Luna, was legalized in 2000, and there are unofficial restricted areas that were created in Playa Luna Norte (Tarapac\u00e1), Playa Luna Sur (Coliumo), Playa Escondida (Antofagasta), Playa Blanca (Tongoy) and Pichilemu.\nUruguay.\nThere are two official nude beaches where the practice of naturism is allowed: Chihuahua, located in the resort of the same name, and La Sirena, located in the resort of Aguas Dulces.\nNaturist media.\nMagazines.\nMagazines published by, for or purportedly about naturists can be grouped into the following:\nMagazines in the second and, occasionally, third groups feature naturist editorial and advertising. While some naturists argue over which magazines belong in which of these categories, these views may change as publishers and editors change. Many clubs and groups have benefited from magazines which, while not exclusively or even predominantly naturist in character, made naturist information available to many who would not otherwise have been aware of it. The information and advertising provided online, along with the wide availability of free online pornography, has meant the disappearance of old-style \"skin\" magazines presenting significant glamour content masquerading as, or alongside, naturist content. Naturist magazines have to appeal strongly to naturists to succeed; they cannot sit on the fence between naturism and glamour. Some naturists feel that the worthwhile editorial content in some magazines is not a fair balance for the disapproved-of photographic content.\nPhotography, films and videos.\nAlthough photographing others when they are nude in a public place may not violate their rights to privacy, individuals retain the personality rights to their own image in many countries. If so, recognizable photographs of any person cannot be published without permission.\nSome naturist clubs have been willing to allow filming by the media on their grounds, though content that proved not to be of genuine naturism can end up being parodied by the media.\nSome commercial 'naturist' DVDs are dominated by imagery of naked children. Such material can be marketed in ways that appear to appeal directly to pedophile inclinations, and ownership of these DVDs (and their earlier video cassette incarnations) has resulted in successful British prosecutions for possession of indecent images of children. One case was appealed, unsuccessfully, to the European Court of Human Rights.\nPhoto shoots, including major high-profile works by Spencer Tunick, are done in public places including beaches.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nBooks.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nJournal articles.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFilm documentaries.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nNewspaper articles.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nWebsites.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21913", "revid": "39118987", "url": "https://en.wikipedia.org/wiki?curid=21913", "title": "Nudist", "text": ""}
{"id": "21914", "revid": "39118987", "url": "https://en.wikipedia.org/wiki?curid=21914", "title": "Naturist", "text": ""}
{"id": "21915", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=21915", "title": "Neo-Paganism", "text": ""}
{"id": "21916", "revid": "7716227", "url": "https://en.wikipedia.org/wiki?curid=21916", "title": "Nordea", "text": "Nordic financial institution\nNordea Bank Abp, commonly referred to as Nordea, is a Nordic financial services group operating in northern Europe with headquarters in Helsinki, Finland. The name is a blend of the words \"Nordic\" and \"idea\". The Nordic countries are considered Nordea's home market, having finalised the sales of their Polish bank in 2014, Baltic operations in 2019 and completed the exit from Russia in early 2022 following a 2019 decision to close the business there. Nordea is listed on Nasdaq Nordic exchanges in Helsinki (its primary listing), Copenhagen, and Stockholm and Nordea ADR is listed in the US.\nNordea serves 9.3 million private and 530,000 active corporate customers, including 2,650 large corporates and institutions. Nordea's credit portfolio is distributed across Finland (21%), Denmark (26%), Norway (21%), and Sweden (30%). There are four Business Areas (BAs) at Nordea, Personal Banking, Business Banking, Large Corporates &amp; Institutions, and Asset &amp; Wealth Management. Assets under Management (AUM) were \u20ac411 billion in December 2021.\nNordea has been designated as a Significant Institution since the entry into force of European Banking Supervision in late 2014, first as the Finnish arm of the Stockholm-based group and since 2017 as a financial holding company. As a consequence, it is directly supervised by the European Central Bank.\nThe company has been embroiled in numerous scandals involving money laundering and tax evasion. In 2024, Danish authorities indicted the bank for the most extensive violation by a bank of Denmark\u2019s anti-money laundering act in the country's history.\nHistory.\nNordea's roots date to 1820 and Sparekassen for Kj\u00f8benhavn og Omegn in Denmark, and a complete family tree of around 300 banks including some of the oldest banks in the Nordic region. This includes Wermlandsbanken of Sweden (founded 1832), Christiania Kreditkasse of Norway (founded 1848) and Union Bank of Finland (UBF) of Finland (founded 1862). Between 1997 and 2001, the Finnish, Swedish, Danish, and Norwegian banks of Merita Bank, Nordbanken, Unidanmark, and Christiania Bank og Kreditkasse merged into the present day Nordea.\nMerita Group was formed in 1995, when UBF and Kansallis-Osake-Pankki (KOP) merged. UBF was established, in 1862, at a time when there were no Limited Liability Companies Act or banking laws in Finland. Therefore, it was modelled after banking standards in other countries. UBF eventually merged with rivals Nordiska Aktiebanken in 1919 and Helsingin Osakepankki (HOP) in 1986. KOP was originally founded in 1890 with its first branch at Aleksanterinkatu 17, in Helsinki. By 1913, KOP had become the second largest commercial bank in Finland. The two banks, KOP and UBF, competed for the title of the largest bank in Finland for decades. KOP suffered large credit losses as a result of the Finnish banking crisis in the early 1990s. On 1 April 1995 it became a subsidiary (51%) of Merita Group in a direct share issue.\nNordbanken was formed in 1986 by a merger of two smaller private local banks, Uplandsbanken and Sundsvallsbanken, though it was the product of numerous original institutions. The oldest of the original Nordbanken constituent banks was Wermlandsbanken, which was founded in 1832. Nordbanken came under Swedish government control in 1992, following the Swedish banking crisis in the early 1990s, with the sale of its non-performing loans to the Swedish government and significant reduction in personnel. Bad debts were transferred to the asset-management company Securum, which sold off the assets. At the time, the approach of establishing \"good\" and \"bad\" banks composed of corresponding assets was a novel resolution approach.\nMerita Group merged with Nordbanken in 1997 forming MeritaNordbanken. The Solo internet-based banking operation of MeritaNordbanken was a global pioneer and leader providing mobile and internet banking access in 1999. The bank reached 1 million internet banking customers during 1999 with 3 million log-ins and 3.7 million payments per month. Housing loans via Solo were introduced in 1999. MeritaNordbanken agreed to buy Unidanmark, Denmark's second-largest bank, in early 2000 creating the Nordic region's biggest financial institution with \u20ac186 billion in assets. The merged group had a banking market share of 20% in Sweden, 25% in Denmark and 40% in Finland and a combined workforce of 28,050. By end 2000, MeritaNordbanken had further merged with Christiania Bank og Kreditkasse of Norway, a process started in 1999 and changed its name to Nordea. Christiania Bank had also been impacted severely during the banking crisis in the early 1990s, with Nordea acquiring the bank from the Norwegian Government Bank Investment Fund with a 35% share.\nNordea expanded into Poland, the Baltics and Russia in the early 2000s, with 2% of total revenues from the Poland and Baltics region. Nordea divested its Polish banking operations in 2013, with the sale to PKO Bank Polski for \u20ac694 million but retains a presence in Poland via operations and IT units supporting the Nordic banks. By end 2014, lending in the Baltics was \u20ac8.2 billion and in Russia \u20ac4.5 billion. During the period 2013-2017 exposure to the Russian market was reduced by 63%. In 2016, Luminor was formed by a merger of Nordea's and DNB's operations in Estonia, Latvia and Lithuania creating the third largest Baltic regional bank with assets of \u20ac15 billion and a market share of 16.4%. Luminor was sold to Blackstone, with Nordea and DNB retaining each initially a 20% share. However, the full divestment was completed in 2019. Exit from the Russian, Baltic and Polish markets were part of Nordea's de-risking strategy, which also included reduced exposures to some sectors (e.g. Shipping, Oil &amp; Offshore and Agriculture in Denmark). Nordea was one of the Nordic banks, including Danske Bank, SEB and Swedbank, allegedly involved in the money laundering scandal, involving ex-Soviet states, that emerged in 2017.\nNordea announced plans to move its corporate headquarters from Stockholm, Sweden to Helsinki, Finland in September 2017. Nordea cited the Swedish socialist government\u2019s unpredictable tax hikes as the primary reason for its decision to relocate. Nordea estimated that relocation would save the bank a billion euros. The re-domiciliation of Nordea to Finland put it within the supervision of the European Central Bank and within the European Union's banking union. In October 2018, Nordea completed the move of its corporate headquarters to Helsinki, Finland.\nPerformance and ownership.\nNordea\u2019s market capitalisation was \u20ac36.8 billion at the end of 2024, making it the seventh largest company in the Nordic region and among the 15 largest European financial services groups. Between 2000 \u2013 when Nordea was formed by the merger of MeritaNordbanken and Unidanmark \u2013 and 2024, the share price of Nordea appreciated by 159%, outperforming the STOXX Europe 600 Banks Index (-37%).\nAs of June 2025, Nordea\u2019s 10 largest shareholders were:\nBusiness areas.\nThere are four Business Areas (BAs) at Nordea, Personal Banking, Business Banking, Large Corporates &amp; Institutions, and Asset &amp; Wealth Management.\nScandals.\nNordea was the subject of an online phishing scam in 2007. The company estimated 8 million kr ($1.1 million) was stolen. Customers were targeted over a period of 15 months with phishing emails containing a trojan horse. Nordea refunded affected customers.\nThe largest financial group in the Nordic region, Nordea was, despite warnings from the Swedish Financial Supervisory Authority (FI) active in using offshore companies in tax havens according to the Panama papers. Other Swedish banks were mentioned in the documents, but mention of Nordea occurred 10,902 times and the second-most mentioned bank has 764 matches. In 2012, Nordea asked Mossack Fonseca to change documents retroactively so that three Danish customers power of attorney documents had been in force since 2010. Nordea bank loaned billions of euros to shipping companies that own vessels in secrecy jurisdictions such as Bermuda, Cyprus, Panama, BVI, the Cayman Islands and the Isle of Man. In the Paradise Papers, Nordea was shown to have lent a significant amount of money to customers based in tax havens. As a consequence of the leaked documents, the Swedish Financial Supervisory Authority (FI) stated on 4 April 2016 that it had started an investigation into the conduct of Nordea.\nThe Nordea section in Luxembourg, between the years 2004 and 2014, founded nearly 400 offshore companies in Panama and the British Virgin Islands for its customers. The Swedish Financial Supervisory Authority (FI) pointed out that there are \"serious deficiencies\" in how Nordea monitors money laundering, and gave the bank two warnings. In 2015, Nordea paid the largest possible fine - over 5\u00a0million EUR. Stefan L\u00f6fven, Prime Minister of Sweden, said in 2016 that he was very critical of the conduct of Nordea and its role, and said: \"They are on the list of shame too\". The Swedish minister of Finance Magdalena Andersson characterized the conduct of Nordea as \"a crime\" and \"totally unacceptable\". The director for Nordea Private banking Thorben Sanders admits that before 2009 they did not screen for customers that tried to evade tax. \"At the end of 2009 we decided that our bank should not be a means of tax evasion\" says Thorben Sanders. Nordea CEO Casper von Koskull stated that he was disappointed with the shortcomings within Nordea's operating principles, saying that \"this cannot be tolerated\".\nIn 2013, \"Politiken\", a Danish newspaper, revealed that Nordea's Copenhagen branch was instrumental in establishing approximately 100 offshore companies for Russian and other nationals, despite warnings about suspicious activities. In 2024, the Danish authorities indicted Nordea for violating anti-money laundering laws by allowing $3.7 billion of suspicious transactions by the Russian clients. According to the Danish authorities, it was most extensive moneylaundering ever committed by a financial company in the country.\nIn March 2019, public service broadcasting company, Yle, aired a program that revealed money laundering allegations against Nordea. The company was the biggest Nordic lender allegedly involved in the multi-million-dollar money laundering scheme, according to Bloomberg.\nIn July 2024, Nordea Bank was taken to court in Denmark over allegations of failing to prevent money laundering linked to Russian clients. The charges stem from transactions worth \u20ac3.8 billion, where Nordea is accused of neglecting proper oversight and ignoring red flags. Despite setting aside \u20ac95 million for potential fines, the actual penalty could be significantly higher, possibly approaching $1 billion.\nIn August 2024, Nordea agreed to pay $35 million to settle a money-laundering investigation by the New York State Department of Financial Services, linked to the Panama Papers scandal. The probe revealed the bank's failure to prevent illegal activities, including inadequate screening of clients from 2008 to 2019.\nSubsidiaries.\nFollowing a major structural reorganisation, Nordea consolidated its Nordic operations into branches of the parent company. The following is a list of former subsidiaries and other historical entities.\nNordea Bank Abp (Finland) \u2013 headquartered in Helsinki\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21918", "revid": "13974845", "url": "https://en.wikipedia.org/wiki?curid=21918", "title": "Normal subgroup", "text": "Subgroup invariant under conjugation\nIn abstract algebra, a normal subgroup (also known as an invariant subgroup or self-conjugate subgroup) is a subgroup that is invariant under conjugation by members of the group of which it is a part. In other words, a subgroup formula_1 of the group formula_2 is normal in formula_2 if and only if formula_4 for all formula_5 and formula_6 The usual notation for this relation is formula_7\nNormal subgroups are important because they (and only they) can be used to construct quotient groups of the given group. Furthermore, the normal subgroups of formula_2 are precisely the kernels of group homomorphisms with domain formula_9 which means that they can be used to internally classify those homomorphisms.\n\u00c9variste Galois was the first to realize the importance of the existence of normal subgroups.\nDefinitions.\nA subgroup formula_1 of a group formula_2 is called a normal subgroup of formula_2 if it is invariant under conjugation; that is, the conjugation of an element of formula_1 by an element of formula_2 is always in formula_15 The usual notation for this relation is formula_7\nEquivalent conditions.\nFor any subgroup formula_1 of formula_9 the following conditions are equivalent to formula_1 being a normal subgroup of formula_20 Therefore, any one of them may be taken as the definition.\nExamples.\nFor any group formula_9 the trivial subgroup formula_70 consisting of just the identity element of formula_2 is always a normal subgroup of formula_20 Likewise, formula_2 itself is always a normal subgroup of formula_20 (If these are the only normal subgroups, then formula_2 is said to be simple.) Other named normal subgroups of an arbitrary group include the center of the group (the set of elements that commute with all other elements) and the commutator subgroup formula_76 More generally, since conjugation is an isomorphism, any characteristic subgroup is a normal subgroup.\nIf formula_2 is an abelian group then every subgroup formula_1 of formula_2 is normal, because formula_80 More generally, for any group formula_2, every subgroup of the \"center\" formula_82 of formula_2 is normal in formula_2. (In the special case that formula_2 is abelian, the center is all of formula_2, hence the fact that all subgroups of an abelian group are normal.) A group that is not abelian but for which every subgroup is normal is called a Hamiltonian group.\nA concrete example of a normal subgroup is the subgroup formula_87 of the symmetric group formula_88 consisting of the identity and both three-cycles. In particular, one can check that every coset of formula_1 is either equal to formula_1 itself or is equal to formula_91 On the other hand, the subgroup formula_92 is not normal in formula_93 since formula_94 This illustrates the general fact that any subgroup formula_95 of index two is normal.\nAs an example of a normal subgroup within a matrix group, consider the general linear group formula_96 of all invertible formula_97 matrices with real entries under the operation of matrix multiplication and its subgroup formula_98 of all formula_97 matrices of determinant 1 (the special linear group). To see why the subgroup formula_98 is normal in formula_96, consider any matrix formula_102 in formula_98 and any invertible matrix formula_104. Then using the two important identities formula_105 and formula_106, one has that formula_107, and so formula_108 as well. This means formula_98 is closed under conjugation in formula_96, so it is a normal subgroup.\nIn the Rubik's Cube group, the subgroups consisting of operations which only affect the orientations of either the corner pieces or the edge pieces are normal.\nThe translation group is a normal subgroup of the Euclidean group in any dimension. This means: applying a rigid transformation, followed by a translation and then the inverse rigid transformation, has the same effect as a single translation. By contrast, the subgroup of all rotations about the origin is \"not\" a normal subgroup of the Euclidean group, as long as the dimension is at least 2: first translating, then rotating about the origin, and then translating back will typically not fix the origin and will therefore not have the same effect as a single rotation about the origin.\nProperties.\nLattice of normal subgroups.\nGiven two normal subgroups, formula_1 and formula_158 of formula_9 their intersection formula_160and their product formula_161 are also normal subgroups of formula_20 \nThe normal subgroups of formula_2 form a lattice under subset inclusion with least element, formula_164 and greatest element, formula_20 The meet of two normal subgroups, formula_1 and formula_158 in this lattice is their intersection and the join is their product.\nThe lattice is complete and modular.\nNormal subgroups, quotient groups and homomorphisms.\nIf formula_1 is a normal subgroup, we can define a multiplication on cosets as follows: \nformula_169\nThis relation defines a mapping formula_170 To show that this mapping is well-defined, one needs to prove that the choice of representative elements formula_171 does not affect the result. To this end, consider some other representative elements formula_172 Then there are formula_173 such that formula_174 It follows that formula_175where we also used the fact that formula_1 is a normal subgroup, and therefore there is formula_177 such that formula_178 This proves that this product is a well-defined mapping between cosets.\nWith this operation, the set of cosets is itself a group, called the quotient group and denoted with formula_179 There is a natural homomorphism, formula_180 given by formula_181 This homomorphism maps formula_1 into the identity element of formula_183 which is the coset formula_184 that is, formula_185\nIn general, a group homomorphism, formula_186 sends subgroups of formula_2 to subgroups of formula_137 Also, the preimage of any subgroup of formula_111 is a subgroup of formula_20 We call the preimage of the trivial group formula_70 in formula_111 the kernel of the homomorphism and denote it by formula_193 As it turns out, the kernel is always normal and the image of formula_194 is always isomorphic to formula_195 (the first isomorphism theorem). In fact, this correspondence is a bijection between the set of all quotient groups of formula_196 and the set of all homomorphic images of formula_2 (up to isomorphism). It is also easy to see that the kernel of the quotient map, formula_180 is formula_1 itself, so the normal subgroups are precisely the kernels of homomorphisms with domain formula_20\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21919", "revid": "49566734", "url": "https://en.wikipedia.org/wiki?curid=21919", "title": "Munkar and Nakir", "text": "Islamic eschatological angels\nMunkar and Nakir () (English translation: \"The Denied and The Denier\") in Islamic eschatology, are angels who test the faith of the dead in their graves.\nScripture.\nThere is no reference to Munkar and Nakir in the Quran. Their names are first mentioned by Tirmidhi in the hadith tradition. However, the Quran alludes to them.\n\"And if you could but see when the angels take the souls of those who disbelieved... They are striking their faces and their backs and [saying], \"Taste the punishment of the Burning Fire.\" \u2014 Saheeh International\nAnd if you could but see when the wrongdoers are in the overwhelming pangs of death while the angels extend their hands,1 [saying], \"Discharge your souls! Today you will be awarded the punishment of [extreme] humiliation for what you used to say against All\u0101h other than the truth and [that] you were, toward His verses, being arrogant. \u2014 Saheeh International\nDescription.\nAl-Suyuti quoted from Ibn Abi al-Dunya, Al-Bayhaqi, and Musnad al-Bazzar that when Munkar and Nakir spoke, tongues of fire come from their mouths. If one answers their questions incorrectly, one is beaten every day, other than Friday, until God (Allah) gives permission for the beating to stop. Al-Suyuti also mentioned from the hadith about Munkar and Nakir digging through the earth to reach the dead person using their teeth, and that their hair reaches their feet. Meanwhile, Al-Suyuti described from Hadith recorded Al-Hakim al-Nishapuri and from Sunan Abu Dawood Munkar and Nakir carrying hammers \"so large, that [they] cannot be moved even if whole of mankind unite to lift [them]\".\nQuestionings in the grave.\nMuslims believe that after a person dies, his soul passes through a stage called barzakh, where it exists in the grave. The questioning will begin when the funeral and burial is over. Nakir and Munkar prop the deceased soul upright in the grave and ask three questions:\nA righteous believer will respond correctly, saying that their Lord is Allah, that Islam is their religion, and that Muhammad is their prophet. If the deceased answers correctly, the time spent awaiting the resurrection is pleasant and they may enter heaven. Those who do not answer as described above are chastised until the day of judgment. There is a belief that the fire of Hell can already be seen in barzakh and that the spiritual pain caused by this can lead to purification of the soul.\nShia theologian al-Mufid reports that the angels ask about one's \"iman.\" The correct answer appears to be the Quran.199\nThe questioning of the grave is part of the Islamic Creed according to Ash'ari.\nMuslims believe that a person will correctly answer the questions not by remembering the answers before death but by their iman (faith) and deeds such as salat (prayer) and shahadah (the Islamic profession of faith).\nCultural interpretations.\nMunkar and Nakir bear some similarity to Zoroastrian divinities. Some of these, such as Mithra, Sraosha and Rashnu have a role in the judgement of souls. Rashnu is described as a figure who holds a set of scales, like some angels of the grave. E.G. Brown has suggested that a continuity exists between Rashnu and Munkar and Nakir. Sebastian G\u00fcnther also points out it. He writes that \"the image and function of Munkar and Nak\u012br carries certain echoes of the Zoroastrian concept of the angels Sr\u014dsh (\u201cObedience\u201d) and \u0100tar (\u201cFire\u201d)\". A mythical figure in Mandaean religion, Abathur Muzania is similar to Rashnu. He has the same position in the world of the dead and he holds a set of scales. \"Muzania\" means scales (mizan) in Aramaic.\nAccording to a recent research, it is hypothesized that Munkar and Nakir were derived from astrological figures that originally associated with the Mesopotamian astral god Nergal. This is based on idea that the Mesopotamian god Nergal has almost the same characteristics as Munkar and Nakir. First of all, Assyrian nakru which means 'enemy', was an epithet of Nergal. The Assyrian \"nakru\", like the names Munkar and Nakir, comes from the same root, that is, it comes from the proto-Semitic NKR which derived some negative terms. Some scholars use a different spelling; \"nakuru,\" which is almost the same as Nakir. Moreover, Nergal is a lord of the Underworld and the grave (Assyrian \"qabru\": grave). Like Munkar and Nakir, he has a terrifying voice that can cause panic among men and gods. He holds a shining mace and his breath can burn his enemies. Because he is related to fire, most scholars suggest that he was originally a sun god. Furthermore, he is identified with the celestial twins (\"Gemini\") in the Babylonian astral mythology, which forms a direct link to Munkar and Nakir.\nThe Mesopotamians still believed in the sun god Shamash, as well as Nergal and several other Babylonian gods at the time Islam was introduced. Thus, Nergal the god of the Underworld who is symbolized by the planet Mars, is a possible prototype for Munkar and Nakir. Astrologically, Munkar and Nakir share more clues in their Martian characteristics which connect them to Nergal.\nIn stark contrast, scholar A. J. Wensinck found the association of Munkar and Nakir to the root NKR to be unlikely. Similarly, scholar John MacDonald believes the names of the two angels have not been satisfactorily explained, although given that they are in the passive form, they may be understood as \"unknown\" or \"disguised\", much in the same way how angels visit graves in disguise in Judaism. Rabbinic literature offers many traditions about punishing angels, chastising the dead.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21920", "revid": "50976247", "url": "https://en.wikipedia.org/wiki?curid=21920", "title": "Napalm", "text": "Gelled incendiary mixture\nNapalm is an incendiary mixture of a gelling agent and a volatile petrochemical (usually gasoline or diesel fuel). The name is a portmanteau of two of the constituents of the original thickening and gelling agents: coprecipitated aluminium salts of \"na\"phthenic acid and \"palm\"itic acid. A team led by chemist Louis Fieser originally developed napalm for the US Chemical Warfare Service in 1942 in a secret laboratory at Harvard University. Of immediate first interest was its viability as an incendiary device to be used in American fire bombing campaigns during World War II; its potential to be coherently projected into a solid stream that would carry for distance (instead of the bloomy fireball of pure gasoline) resulted in widespread adoption in infantry and tank/boat mounted flamethrowers as well.\nNapalm burns at temperatures ranging from . It burns longer than gasoline, is more easily dispersed, and adheres to its targets. These traits make it both effective and controversial. It has been widely used from the air and from the ground, the largest use having been via airdropped bombs in World War II in the incendiary attacks on Japanese cities in 1945. It was used also for close air support roles by the U.S military in the Korean War, the Vietnam War, and various others. Napalm has also fueled most of the flamethrowers (tank-, ship-, and infantry-based) used since World War II, giving them much greater range.\nDevelopment.\nThe development of napalm was precipitated by the use of jellied gasoline mixtures by the Allied forces during World War II. Latex, used in these early forms of incendiary devices, became scarce, since natural rubber was almost impossible to obtain after the Japanese army captured the rubber plantations in Malaya, Indonesia, Vietnam, and Thailand.\nThis shortage of natural rubber prompted chemists at US companies such as DuPont and Standard Oil of New Jersey, and researchers at Harvard University, to develop factory-made alternatives: artificial rubber for all uses, including vehicle tires, tank tracks, gaskets, hoses, medical supplies and rain clothing. A team of chemists led by Louis Fieser at Harvard University was the first to develop synthetic napalm during 1942. \"The production of napalm was first entrusted to Nuodex Products, and by the middle of April 1942 they had developed a brown, dry powder that was not sticky by itself, but when mixed with gasoline turned into an extremely sticky and flammable substance.\" One of Fieser's colleagues suggested adding phosphorus to the mix which increased the \"ability to penetrate deeply [...] into the musculature, where it would continue to burn day after day.\"\nOn 4 July 1942, the first test occurred on the football field near the Harvard Business School. Tests under operational conditions were carried out at Jefferson Proving Ground on condemned farm buildings and subsequently at Dugway Proving Ground on buildings designed and constructed to represent those to be found in German and Japanese villages. This new mixture of chemicals was first approved for use on the front lines in 1943.\nMilitary use.\nWorld War II.\nThe first use of napalm in combat was in August 1943 during the Allied invasion of Sicily, when American troops, using napalm-fueled flamethrowers, burned down a wheat field where German forces were believed to be hiding. Napalm incendiary bombs were first used the following year, although the exact date and battle are disputed.\nTwo-thirds of napalm bombs produced during WWII were used in the Pacific War. Napalm was often deployed against Japanese fortifications on Saipan, Iwo Jima, the Philippines, and Okinawa, where deeply dug-in Japanese troops refused to surrender. Following a shortage of conventional thermite bombs, General Curtis LeMay, among other high-ranking servicemen, ordered air raids on Japan to start using napalm instead. A 1946 report by the National Defense Research Council claims that 40,000 tons of M69s were dropped on Japan throughout the war, damaging 64 cities and causing more deaths than the atomic bombings of Hiroshima and Nagasaki.\nGerman fortifications and transportation hubs were targeted with napalm during both Operation Overlord and the Battle of the Bulge, sometimes in conjunction with artillery. During the Allied siege of La Rochelle, napalm was dropped on the outskirts of the Royan pocket, inadvertently killing French civilians.\nThe Royal Air Force (RAF) used napalm to a limited extent in both the Pacific War and the European Theater.\nKorean War.\nNapalm was widely used by the United States during the Korean War. The ground forces in South Korea holding defensive positions were often outnumbered by Chinese and North Koreans, but US Air Force and Navy aviators had control of the air over nearly all of the Korean Peninsula. Hence, the American and other United Nations aviators used napalm for close air support of the ground troops. Napalm was used most notably at the beginning of the Battle of Outpost Harry.\nEighth Army chemical officer Donald Bode reported that, on an \"average good day,\" UN pilots used (70,000 US gal; ) of napalm, with approximately (60,000 US gal; ) of this thrown by US forces. The \"New York Herald Tribune\" hailed \"Napalm, the No. 1 Weapon in Korea.\" British Prime Minister Winston Churchill privately criticized the use of napalm in Korea, writing that it was \"very cruel,\" as US and UN forces, he wrote, were \"splashing it all over the civilian population,\" \"tortur[ing] great masses of people.\" He conveyed these sentiments to US Chairman of the Joint Chiefs of Staff Omar Bradley, who \"never published the statement.\u201d Publicly, Churchill allowed Bradley \"to issue a statement that confirmed U.K. support for U.S. napalm attacks.\"\nVietnam War.\nNapalm became an intrinsic element of US military action during the Vietnam War as forces made increasing use of it for its tactical and psychological effects. Reportedly about (388,000 short tons; ) of US napalm bombs were dropped in the region between 1963 and 1973. The US Air Force and US Navy used napalm with great effect against all kinds of targets, such as troops, tanks, buildings, jungles, and even railroad tunnels. The effect was not always purely physical as its destructive effects and ability to spread uncontrolled had psychological effects on Vietnamese forces and civilians as well. \nOthers.\nDuring the Greek Civil War, after the capture of Mount Vitsi during Operation Pyrsos, the Hellenic Air Force bombed Mount Grammos \u2013 a stronghold for the opposing Democratic Army of Greece \u2013 with US-supplied napalm.\nThe French Air Force regularly used napalm for close air support of ground operations in both the First Indochina War and the Algerian War. At first, the canisters were simply pushed out the cargo doors of transport planes, such as the Amiot AAC.1; later mostly B-26 bombers were used.\nPeruvian forces employed napalm throughout the 1960s against both communist insurgents and the Mats\u00e9s indigenous group; four prominent Mats\u00e9s villages were bombed during the Mats\u00e9s massacre in 1964.\nFrom 1968\u20131978, Rhodesia produced a variant of napalm for use in the Rhodesian Bush War, nicknamed \"Frantan\" (short for \"frangible tank\"). Around the same time, its ally South Africa targeted guerrilla bases in Angola with napalm during the South African Border War.\nIn 1974, Turkey used napalm in both phases of the invasion of Cyprus. In 2018, Turkey was accused of using napalm in Operation Olive Branch against Kurdish nationalist groups.\nAntipersonnel effects.\nWhen used as a part of an incendiary weapon, napalm causes severe burns. During combustion, napalm deoxygenates the available air and generates carbon monoxide and carbon dioxide, so asphyxiation, loss of consciousness, and death are also possible. One napalm firebomb released from a low-flying plane can damage an area of . Napalm is lethal even for dug-in enemy personnel, as it flows into foxholes, tunnels, and bunkers, and drainage and irrigation ditches and other improvised troop shelters. Even people in undamaged shelters can be killed by hyperthermia, radiant heat, dehydration, asphyxiation, smoke exposure, or carbon monoxide poisoning. Crews of armored fighting vehicles are also vulnerable, due to the intense heat conducted through the armor. Even in the case of a near miss, the heat can be enough to disable a vehicle.\nInternational law.\nInternational law does not specifically prohibit the use of napalm or other incendiaries against military targets, but use against civilian populations was banned under Protocol III of the United Nations Convention on Certain Conventional Weapons in 1980, which entered into force as international law in December 1983. 126 countries have ratified Protocol III.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21921", "revid": "27229483", "url": "https://en.wikipedia.org/wiki?curid=21921", "title": "Northern Crusades", "text": "12th/13th century crusades around the Baltic Sea\nThe Northern Crusades or Baltic Crusades were military campaigns undertaken by Catholic Christian military orders and kingdoms in an effort to Christianize the pagan Baltic, Finnic, and West Slavic peoples around the southern and eastern shores of the Baltic Sea. In some cases, such as with the Wendish Crusade, the campaign was partly motivated to control the rich resources found in the lands.\nThe most notable of these campaigns were the Livonian and Prussian Crusades. Some of these wars were explicitly regarded, during the Middle Ages, \"as\" crusades; for example, the military venture against the Estonians\u2014and the \"other pagans in those parts\"\u2014authorized by Pope Alexander III's 1171 crusade bull, \"Non parum animus noster\". However, others\u2014such as the (possibly mythical) 12th-century First Swedish Crusade and several subsequent incursions, undertaken by Scandinavian Christians against the then-pagan Finns\u2014were dubbed \"crusades\" only in the 19th century, by romantic nationalist historians.\nBackground.\nAt the outset of the northern crusades, Christian monarchs across northern Europe commissioned forays into territories that comprise modern-day Estonia, Finland, Latvia, Lithuania, Poland, and Russia. The indigenous populations of Pagans suffered forced baptisms and the ravages of military occupation. Spearheading, but by no means monopolizing these incursions, the ascendant Teutonic Order profited immensely from the crusades, as did German merchants who fanned out along trading routes traversing the Baltic frontier.\nThe official starting point for the Northern Crusades was Pope Celestine III's call in 1195, but the Catholic kingdoms of Scandinavia, Poland, and the Holy Roman Empire had begun moving to subjugate their pagan neighbors even earlier (see Christianization of Pomerania). The non-Christian people who were objects of the campaigns at various dates included:\nArmed conflict between the Finnic peoples, Balts, and Slavs who lived by the Baltic shores, and their Saxon and Danish neighbors to the north and south, had been common for several centuries before the crusade. The previous battles had largely been caused by attempts to destroy castles and sea trade routes to gain an economic advantage in the region, and the crusade basically continued this pattern of conflict, albeit now inspired and prescribed by the Pope and undertaken by Papal knights and armed monks.\nWendish Crusade.\nThe campaigns started with the 1147 Wendish Crusade against the Polabian Slavs (or \"Wends\") of what is now northern and eastern Germany. The crusade occurred parallel to the Second Crusade to the Holy Land, and continued irregularly until the 16th century.\nSwedish Crusades.\nThe Swedish crusades were campaigns by Sweden against Finns, Tavastians, and Karelians during the period from 1150 to 1293. The wars with the Eastern Orthodox Novgorod Republic also had a religious aspect.\nDanish Crusades.\nThe Danes are known to have made at least three crusades to Finland. The first mention of these crusades is from 1187, when crusader Esbern Snare mentioned\u2014in his Christmas-feast speech\u2014a major victory over the Finns. The next known crusades were made in 1191 and in 1202; the latter was led by the Bishop of Lund, Anders Sunesen, with his brother.\nJournalist Matts Dumell explains that there was a rivalry between the churches in Denmark and Sweden. This led them to compete, which amongst other things took the form of conquests, gaining of adherents to Christianity and propaganda wins against the other. The possibility that Finland was part of Sweden in the mid-1100's to early 1200's is virtually impossible due to this and Sweden saw civil strife from within in this period as well, which took the form of several battles, assassinations between several strongmen from House of Sverker and House of Erik. Only in 1216, would the Pope change his preference that the Finnish areas should not be part of the Danish king, but now be under the Swedish king's 'protection'. However, only in 1165 did the Roman Catholic Church start to \"expect\" bigger territorial gains and adherents from the Danes in missionary work Finland and Estonia, this despite Finland had seen some conversion to Christianity before 1165 already. There is scholarly debate over how successful the Danes were in the end and if they gained any permanent foothold or territory in Finland before the Swedes begun their efforts. Dumell debates if places like an fort in Saxby near Porvoo could be a product of this Danish presence, possibly built during their crusade in 1191.\nDumell lists several possible crusades by Denmark to Finland:\nLivonian Crusade.\nBy the 12th century, the peoples inhabiting the lands now known as Estonia, Latvia, and Lithuania formed a pagan wedge between increasingly powerful rival Christian states \u2013 the Orthodox Church to their east and the Catholic Church to their west. The difference in creeds was one of the reasons they were able to resist being forcibly converted to a different religion. During a period of more than 150 years leading up to the arrival of German crusaders in the region, Estonia was attacked thirteen times by Russian principalities, and by Denmark and Sweden as well. Estonians for their part made raids upon Denmark and Sweden. There were peaceful attempts by some Catholics to convert the Estonians, starting with missions dispatched by Adalbert, Archbishop of Bremen, in 1045\u20131072. However, these peaceful efforts seem to have had limited success.\nCampaign against the Livonians (1198\u20131212).\nMoving in the wake of German merchants who were now following the old trading routes of the Vikings, a canon named Meinhard landed at the mouth of the Daugava river in present-day Latvia in 1180 and was made bishop in 1186. Pope Celestine III proclaimed a crusade against the Baltic pagans in 1195, which was reiterated by Pope Innocent III, and a crusading expedition led by Meinhard's successor, Bishop Berthold of Hanover, landed in Livonia (part of present-day Latvia, surrounding the Gulf of Riga) in 1198. Although the crusaders won their first battle, Bishop Berthold was mortally wounded and the crusaders were repelled.\nIn 1199, Albert of Buxhoeveden was appointed by the Archbishop Hartwig II of Bremen to Christianise the Baltic countries. By the time Albert died 30 years later, the conquest and formal Christianisation of present-day Estonia and northern Latvia was complete. Albert began his task by touring the Empire, preaching a Crusade against the Baltic countries, and was assisted in this by a papal bull which declared that fighting against the Baltic heathens was of the same rank as participating in a crusade to the Holy Land. Although he landed in the mouth of the Daugava in 1200 with only 23 ships and 500 soldiers, the bishop's efforts ensured that a constant flow of recruits followed. The first crusaders usually arrived to fight during the spring and returned to their homes in the autumn. To ensure a permanent military presence, the Livonian Brothers of the Sword were founded in 1202. The founding by Bishop Albert of the market at Riga in 1201 attracted citizens from the Empire and economic prosperity ensued. At Albert's request, Pope Innocent III dedicated the Baltic countries to the Virgin Mary to popularize recruitment to his army and the name \"Mary's Land\" has survived up to modern times. This is noticeable in one of the names given to Livonia at the time, Terra Mariana (Land of Mary).\nIn 1206, the crusaders subdued the Livonian stronghold in Turaida on the right bank of Gauja River, the ancient trading route to the Northwestern Rus. In order to gain control over the left bank of Gauja, the stone castle was built in Sigulda before 1210. By 1211, the Livonian province of Metsepole (now Limba\u017ei district) and the mixed Livonian\u2013Latgallian inhabited county of Idumea (now Straupe) was converted to the Roman Catholic faith. The last battle against the Livonians was the siege of Satezele hillfort near to Sigulda in 1212. The Livonians, who had been paying tribute to the East Slavic Principality of Polotsk, had at first considered the Germans useful allies. The first prominent Livonian to be christened was their leader Caupo of Turaida. As the German grip tightened, the Livonians rebelled against the crusaders and the christened chief but were put down. Caupo of Turaida remained an ally of the crusaders until his death in the Battle of St. Matthew's Day in 1217.\nThe German crusaders enlisted newly baptised Livonian warriors to participate in their campaigns against Latgallians and Selonians (1208\u20131209), Estonians (1208\u20131227), and against Semigallians, Samogitians, and Curonians (1219\u20131290).\nCampaign against the Latgallians and Selonians (1208\u20131224).\nAfter the subjugation of the Livonians, the crusaders turned their attention to the Latgallian principalities to the east, along the Gauja and Daugava rivers. The military alliance in 1208 and later conversion from Greek Orthodoxy to Roman Catholicism of the Principality of T\u0101lava was the only peaceful subjugation of the Baltic tribes during the Nordic crusades. The ruler of T\u0101lava, T\u0101livaldis (), became the most loyal ally of German crusaders against the Estonians, and he died a Catholic martyr in 1215. The war against the Latgallian and Selonian countries along the Daugava waterway started in 1208 with the occupation of the Orthodox Principality of Koknese and the Selonian S\u0113lpils hillfort. The campaign continued in 1209 with an attack on the Orthodox Principality of Jersika (known as ), accused by crusaders of being in alliance with Lithuanian pagans. After the defeat, the king of Jersika, Visvaldis, became the vassal of the Bishop of Livonia and received part of his country (southern Latgale) as a fiefdom. The Selonian stronghold of S\u0113lpils was briefly the seat of a Selonian diocese (1218\u20131226), and then came under the rule of the Livonian Order (and eventually the stone castle of Selburg was built in its place). Only in 1224, with the division of T\u0101lava and Adzele counties between the Bishop of Riga and the Order of the Swordbearers, did Latgallian countries finally become the possession of German conquerors. The territory of the former Principality of Jersika was divided between the Bishop of Riga and the Livonian Order in 1239.\nCampaign against the Estonians (1208\u20131224).\nBy 1208, the Germans were strong enough to begin operations against the Estonians, who were at that time divided into eight major and several smaller counties led by elders with limited cooperation between them. In 1208\u20131227, war parties of the different sides rampaged through the Livonian, Northern Latgallian, and Estonian counties, with Livonians and Latgallians normally as allies of the Crusaders, and the Principalities of Polotsk and Pskov appearing as allies of different sides at different times. Hillforts, which were the key centres of Estonian counties, were besieged and captured a number of times. A truce between the war-weary sides was established for three years (1213\u20131215) and proved generally more favourable to the Germans, who consolidated their political position, while the Estonians were unable to develop their system of loose alliances into a centralised state. The Livonian leader Kaupo was killed in battle near Viljandi (Fellin) on 21 September 1217, but the battle was a crushing defeat for the Estonians, whose leader Lembitu was also killed. Since 1211, his name had come to the attention of the German chroniclers as a notable Estonian elder, and he had become the central figure of the Estonian resistance.\nThe Christian kingdoms of Denmark and Sweden were also greedy for conquests on the Eastern shores of the Baltic. While the Swedes made only one failed foray into western Estonia in 1220, the Danish Fleet, headed by King Valdemar II of Denmark, had landed at the Estonian town of Lindanisse (present-day Tallinn) in 1219. After the Battle of Lindanise, the Danes established a fortress, which was besieged by Estonians in 1220 and 1223, but held out. Eventually, the whole of northern Estonia came under Danish control.\nWars against Saaremaa (1206\u20131261).\nThe last Estonian county to hold out against the invaders was the island county of Saaremaa (\u00d6sel), whose war fleets had raided Denmark and Sweden during the years of fighting against the German crusaders.\nIn 1206, a Danish army led by the king Valdemar II and Andreas, the Bishop of Lund, landed on Saaremaa and attempted to establish a stronghold without success. In 1216, the Livonian Brothers of the Sword and the bishop Theodorich joined forces and invaded Saaremaa over the frozen sea. In return, the Oeselians raided the territories in Latvia that were under German rule the following spring. In 1220, the Swedish army led by king John I of Sweden and the bishop Karl of Link\u00f6ping conquered Lihula in Rotalia in Western Estonia. Oeselians attacked the Swedish stronghold the same year, conquered it, and killed the entire Swedish garrison, including the Bishop of Link\u00f6ping.\nIn 1222, the Danish king Valdemar II attempted the second conquest of Saaremaa, this time establishing a stone fortress housing a strong garrison. The Danish stronghold was besieged and surrendered within five days, with the Danish garrison being returned to Revel, leaving bishop Albert of Riga's brother Theodoric, and few others, behind as hostages for peace. The castle was razed to the ground by the Oeselians.\nA 20,000 strong army under Papal legate William of Modena crossed the frozen sea while the Saaremaa fleet was icebound, in January 1227. After the surrender of two major Oeselian strongholds, Muhu and Valjala, the Oeselians formally accepted Christianity.\nIn 1236, after the defeat of the Livonian Brothers of the Sword in the Battle of Saule, military action on Saaremaa broke out again. In 1261, warfare continued as the Oeselians had once more renounced Christianity and killed all the Germans on the island. A peace treaty was signed after the united forces of the Livonian Order, the Bishopric of \u00d6sel-Wiek, and Danish Estonia, including mainland Estonians and Latvians, defeated the Oeselians by conquering their stronghold at Kaarma. Soon thereafter, the Livonian Order established a stone fort at P\u00f6ide.\nWars against the Curonians and Semigallians (1201\u20131290).\nAlthough the Curonians had attacked Riga in 1201 and 1210, Albert of Buxhoeveden, considering Courland a tributary of Valdemar II of Denmark, had been reluctant to conduct a large scale campaign against them. After Albert's death in 1229, the crusaders secured the peaceful submission of Vanemane (a county with a mixed Livonian, Oselian, and Curonian population in the northeastern part of Courland) by treaty in 1230. In the same year, the papal vice-legate Baldouin of Alnea annulled this agreement and concluded an agreement with the ruler () of Bandava in the central Courland Lammekinus, delivering his kingdom into the hands of the papacy. Baldouin became the popes's delegate in Courland and bishop of Semigallia; however, the Germans complained about him to the Roman Curia, and in 1234, Pope Gregory IX removed Baldouin as his delegate.\nAfter their decisive defeat in the Battle of Saule by the Samogitians and Semigallians, the remnants of the Sword Brothers were reorganized in 1237 as a subdivision of the Teutonic Order, and became known as the Livonian Order. In 1242, under the leadership of the master of the Livonian Order Andrew of Groningen, the crusaders began the military conquest of Courland. They defeated the Curonians as far south as Emb\u016bte, near the contemporary border with Lithuania, and founded their main fortress at Kuld\u012bga. In 1245, Pope Innocent IV allotted two-thirds of conquered Courland to the Livonian Order, and one third to the Bishopric of Courland.\nAt the Battle of Durbe in 1260, a force of Samogitians and Curonians overpowered the united forces of the Livonian and Teutonic Orders; over the following years, however, the Crusaders gradually subjugated the Curonians, and in 1267, concluded the peace treaty stipulating the obligations and the rights of their defeated rivals. The unconquered southern parts of their territories (Ceklis and Megava) were united under the rule of the Grand Duchy of Lithuania.\nThe conquest of Semigallian counties started in 1219 when crusaders from Riga occupied Me\u017eotne, the major port on the Lielupe waterway, and founded the Bishopric of Semigallia. After several unsuccessful campaigns against the pagan Semigallian duke Viestards and his Samogitian kinsfolk, the Roman Curia decided in 1251 to abolish the Bishopric of Semigallia, and divided its territories between the Bishopric of Riga and the Order of Livonia. In 1265, a stone castle was built at Jelgava, on the Lielupe, and became the main military base for crusader attacks against the Semigallians. In 1271, the capital hillfort of T\u0113rvete was conquered, but Semigallians, under the Duke Nameisis, rebelled in 1279, and the Lithuanians under Traidenis defeated Livonian Order forces in the Battle of Aizkraukle. Duke Nameisis' warriors unsuccessfully attacked Riga in 1280, in response to which around 14,000 crusaders besieged Turaida castle in 1281. To conquer the remaining Semigallian hillforts, the Order's master Villekin of Endorpe built a castle called (lit.\u2009'Saints' Hill') right next to the T\u0113rvete castle in 1287. The same year, the Semigallians made another attempt to conquer Riga, but again failed to take it. On their return home, Livonian knights attacked them, but were defeated at the Battle of Garoza, in which the Orders' master Villekin and at least 35 knights lost their lives. The new master of the Order Konrad von Hattstein organised the last campaigns against the Semigallians in 1289 and 1290; the hillforts of Dobele, Rakte, and Sidabre were conquered, and most of the Semigallian warriors joined the Samogitian and Lithuanian forces.\nPrussia and Lithuania.\nCampaigns of Boles\u0142aw the Curly and Konrad of Masovia.\nFrom 1147, the Polish Duke of Mazovia, Boleslaw the Curly, led many expeditions against pagan Prussia, with some of them being successful and resulting in the conquest of parts of the Prussian territories.\nKonrad I, the Polish Duke of Masovia, unsuccessfully attempted to conquer pagan Prussia in crusades in 1219 and 1222. Taking the advice of the first Bishop of Prussia, Christian of Oliva, Konrad founded the crusading Order of Dobrzy\u0144 (or \"Dobrin\") in 1220. However, this order was largely ineffective, and Konrad's campaigns against the Old Prussians were answered by incursions into the already captured territory of Culmerland (Che\u0142mno Land). Subjected to constant Prussian counter-raids, Konrad wanted to stabilize the north of the Duchy of Masovia in this fight over the border area of Che\u0142mno Land. Masovia became part of Poland in the 10th century, but native Prussians, Yotvingians, and Lithuanians were still living in the territories north of Masovia, where no settled borders existed. Konrad asked in 1226 the Roman Catholic monastic order of the Teutonic Knights to come to Prussia and suppress the Old Prussians. Duke Konrad supported Teutonic Knights financially, supplies and militarily.\nCampaigns of Boles\u0142aw the Chaste and Leszek the Black.\nCampaigns against Yotvingians and Lithuanians were also conducted in the years 1248\u20131282 by princes Boles\u0142aw the Chaste, Siemowit and Leszek the Black. They defeated the forces of pagans invading Mazovia, Kujawy, and the Lublin region. They also carried out several expeditions to Yotvingian territories.\nTeutonic Order in Livonia and Votia (1237\u20131410).\nThe Northern Crusades provided both the rationale and the opportunity for the growth and expansion of the Teutonic Order, a German military religious order founded as a hospital in Acre around 1190 and established as a military order in 1198. Duke Konrad I of Masovia, a region in east-central Poland, appealed to the Teutonic Knights to defend his borders and subdue the pagan Old Prussians in 1226. In 1234, a significant expedition began in which Polish forces, allied with the Teutonic Knights, defeated the Old Prussians in a battle on the Dzierzgo\u0144 river. While engaged in the decades-long subjugation of the Prussians, the Teutonic Knights also entered into conflict with the Grand Duchy of Lithuania.\nWhen the Livonian Brothers of the Sword were heavily defeated by Samogitians and Semigallians at the Battle of Saule in 1236, coinciding with Estonian revolts, the remnants of the order were incorporated into the Teutonic Order in 1237, becoming its autonomous Livonian branch. This allowed the Teutonic Order, through its Livonian branch, to exercise political control over large territories in the Baltic region. Mindaugas, the ruler of Lithuania, was baptised with his wife around 1251 and crowned King in 1253 with papal approval, hoping this would help stop Crusader attacks, although it ultimately did not prevent further conflict. The Teutonic Knights failed to subdue Lithuania. The country began its official conversion to Catholic Christianity following the marriage of Grand Duke Jogaila to Jadwiga, the young ruling Queen (crowned as King) of Poland, and Jogaila's own baptism in 1386; the formal Christianization of Lithuania commenced in 1387. However, even after Lithuania's official conversion, the conflict persisted, culminating in the pivotal Battle of Grunwald (also known as Tannenberg or \u017dalgiris) in 1410. In this battle, the allied forces of Poland and Lithuania, supported by Tatar, Moldovan, Ruthenian, and Czech contingents, decisively defeated the Teutonic Knights.\nIn 1221, Pope Honorius III expressed concern about conflicts in the Finnish region involving Novgorod, after receiving alarming information from the Archbishop of Uppsala. He authorized the Bishop of Finland to establish a trade embargo against the \"barbarians\" described as threatening Christianity in Finland. The specific identity or origin of these \"barbarians\", presumably cited from the Archbishop's letter, remains unclear and may not have been known precisely, even by the Pope. However, when the call for an embargo was renewed around 1229, it specifically targeted Russians (Novgorodians). Based on Papal letters from that year, the Bishop of Finland requested that the Pope, Gregory IX, authorize or call for a trade embargo against Novgorodians to be implemented by Baltic Sea ports, including Visby, Riga, and L\u00fcbeck. In the following decade (specifically around 1232\u20131237), Pope Gregory IX also requested the Livonian Brothers of the Sword send troops to protect Finland from Novgorod incursions. Whether any knights were actually dispatched remains unknown.\nThe Teutonic Order's attempts to conquer Orthodox Russian lands (particularly the Republics of Pskov and Novgorod), an enterprise endorsed by Pope Gregory IX, were a component of the Northern Crusades. One of the major setbacks for the eastward expansion into Russian principalities was the Battle of the Ice in 1242, where forces of Novgorod defeated the Livonian branch of the Teutonic Order. Separately, with or without explicit papal blessing for every campaign, Sweden also undertook several crusades against Orthodox Novgorod.\nMissionary work and crusading activity in Estonia by the Livonian Order and other Catholic powers led to conflicts with Novgorod, which had its own interests in the region, including attempts to subjugate, raid, or convert the pagan Estonians. The Estonians, in turn, sometimes sought alliances with Novgorod against the Crusaders.\nIntermittent warfare between Novgorod and the crusader states in Livonia continued. These conflicts ultimately halted the eastward expansion of the Livonian Order, while Novgorodian attempts to gain control over Estonia and Livonia also failed. The region (Terra Mariana) remained under the complex political control of the Livonian Confederation, primarily the Livonian Order and powerful Prince-Bishops.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21922", "revid": "42775548", "url": "https://en.wikipedia.org/wiki?curid=21922", "title": "Neoteny", "text": "Retaining juvenile features into adulthood\nNeoteny (), also called juvenilization, is the delaying or slowing of the physiological, or somatic, development of an organism, typically an animal. Neoteny in modern humans is more significant than in other primates. In progenesis or paedogenesis, sexual development is accelerated.\nBoth neoteny and progenesis result in paedomorphism (as having the form typical of children) or paedomorphosis (changing towards forms typical of children), a type of heterochrony. It is the retention in adults of traits previously seen only in the young. Such retention is important in evolutionary biology, domestication, and evolutionary developmental biology. Some authors define paedomorphism as the retention of larval traits, as seen in salamanders.\nHistory and etymology.\nJulius Kollmann created the term \"neoteny\" in 1885 after he described the axolotl's maturation while remaining in a tadpole-like aquatic stage complete with gills, unlike other adult amphibians like frogs and toads.\nThe word \"neoteny\" is borrowed from the German \"Neotenie\", the latter constructed by Kollmann from the Greek \u03bd\u03ad\u03bf\u03c2 (\"neos\", \"young\") and \u03c4\u03b5\u03af\u03bd\u03b5\u03b9\u03bd (\"te\u00ednein\", \"to stretch, to extend\"). The adjective is either \"neotenic\" or \"neotenous\". For the opposite of \"neotenic\", different authorities use either \"gerontomorphic\" or \"peramorphic\". Bogin points out that Kollmann had intended the meaning to be \"retaining youth\", but had evidently confused the Greek \"te\u00ednein\" with the Latin \"tenere\", which had the meaning he wanted, \"to retain\", so that the new word would mean \"the retaining of youth (into adulthood)\".\nIn 1926, Louis Bolk described neoteny as the major process in humanization. In his 1977 book \"Ontogeny and Phylogeny\", Stephen Jay Gould noted that Bolk's account constituted an attempted justification for \"scientific\" racism and sexism, but acknowledged that Bolk had been right in the core idea that humans differ from other primates in becoming sexually mature in an infantile stage of body development.\nIn humans.\nNeoteny in humans is the slowing or delaying of body development, compared to non-human primates, resulting in features such as a large head, a flat face, and relatively short arms. These neotenic changes may have been brought about by sexual selection in human evolution. In turn, they may have permitted the development of human capacities such as emotional communication. Some evolutionary theorists have proposed that neoteny was a key feature in human evolution. J. B. S. Haldane states a \"major evolutionary trend in human beings\" is \"greater prolongation of childhood and retardation of maturity.\" Delbert D. Thiessen said that \"neoteny becomes more apparent as early primates evolved into later forms\" and that primates have been \"evolving toward flat face.\" Doug Jones argued that human evolution's trend toward neoteny may have been caused by sexual selection in human evolution for neotenous facial traits in women by men with the resulting neoteny in male faces being a \"by-product\" of sexual selection for neotenous female faces.\nIn domestic animals.\nNeoteny is seen in domesticated animals such as dogs and mice. This is because there are more resources available, less competition for those resources, and with the lowered competition the animals expend less energy obtaining those resources. This allows them to mature and reproduce more quickly than their wild counterparts. The environment that domesticated animals are raised in determines whether or not neoteny is present in those animals. Evolutionary neoteny can arise in a species when those conditions occur, and a species becomes sexually mature ahead of its \"normal development\". Another explanation for the neoteny in domesticated animals can be the selection for certain behavioral characteristics. Behavior is linked to genetics which therefore means that when a behavioral trait is selected for, a physical trait may also be selected for due to mechanisms like linkage disequilibrium. Often, juvenile behaviors are selected for in order to more easily domesticate a species; aggressiveness in certain species comes with adulthood when there is a need to compete for resources. If there is no need for competition, then there is no need for aggression. Selecting for juvenile behavioral characteristics can lead to neoteny in physical characteristics because, for example, with the reduced need for behaviors like aggression, there is no need for developed traits that would help in that area. Traits that may become neotenized due to decreased aggression may be a shorter muzzle and smaller general size among the domesticated individuals. Some common neotenous physical traits in domesticated animals (mainly rabbits, dogs, pigs, ferrets, cats, and even foxes) include floppy ears, changes in the reproductive cycle, curly tails, piebald coloration, fewer or shortened vertebra, large eyes, rounded forehead, large ears, and shortened muzzle.\nWhen the role of dogs expanded from just being working dogs to also being companions, humans started selective breeding dogs for morphological neoteny, and this selective breeding for \"neoteny or paedomorphism\" \"strengthened the human-canine bond.\" Humans bred dogs to have more \"juvenile physical traits\" as adults, such as short snouts and wide-set eyes which are associated with puppies because people usually consider these traits to be more attractive. Some breeds of dogs with short snouts and broad heads such as the Komondor, Saint Bernard and Maremma Sheepdog are more morphologically neotenous than other breeds of dogs. Cavalier King Charles spaniels are an example of selection for neoteny because they exhibit large eyes, pendant-shaped ears and compact feet, giving them a morphology similar to puppies as adults.\nIn 2004, a study that used 310 wolf skulls and over 700 dog skulls representing 100 breeds concluded that the evolution of dog skulls can generally not be described by heterochronic processes such as neoteny, although some pedomorphic dog breeds have skulls that resemble the skulls of juvenile wolves. By 2011, the findings by the same researcher were simply \"Dogs are not paedomorphic wolves.\"\nIn other animals.\nNeoteny has been observed in many other species. It is important to note the difference between partial and full neoteny when looking at other species, to distinguish between juvenile traits which are advantageous in the short term and traits which are beneficial throughout the organism's life; this might provide insight into the cause of neoteny in a species. Partial neoteny is the retention of the larval form beyond the usual age of maturation, with possible sexual development (progenesis) and eventual maturation into the adult form; this is seen in the frog \"Lithobates clamitans\". Full neoteny is seen in \"Ambystoma mexicanum\" and some populations of \"Ambystoma tigrinum\", which remain in larval form throughout their lives. \"Lithobates clamitans\" is partially neotenous; it delays maturation during the winter as fewer resources are available; it can find resources more easily in its larval form. This encompasses both of the main causes of neoteny; the energy required to survive in the winter as a newly-formed adult is too great, so the organism exhibits neotenous characteristics until it can better survive as an adult. \"Ambystoma tigrinum\" retains its neoteny for a similar reason; however, the retention is permanent due to the lack of available resources throughout its lifetime. This is another example of an environmental cause of neoteny. Several avian species, such as the manakins \"Chiroxiphia linearis\" and \"Chiroxiphia caudata\", exhibit partial neoteny. The males of both species retain juvenile plumage into adulthood, losing it when they are fully mature. \nNeoteny is commonly seen in flightless insects, such as the females of the order Strepsiptera. Flightlessness in insects has evolved separately a number of times; factors which may have contributed to the separate evolution of flightlessness are high altitude, geographic isolation (islands), and low temperatures. Under these environmental conditions, dispersal would be disadvantageous; heat is lost more rapidly through wings in colder climates. The females of certain insect groups become sexually mature without metamorphosis, and some do not develop wings. Flightlessness in some female insects has been linked to higher fecundity. Aphids are an example of insects which may never develop wings, depending on their environment. If resources are abundant on a host plant, there is no need to grow wings and disperse. If resources become diminished, their offspring may develop wings to disperse to other host plants.\nTwo environments which favor neoteny are high altitudes and cool temperatures, because neotenous individuals have more fitness than individuals which metamorphose into an adult form. The energy required for metamorphosis detracts from individual fitness, and neotenous individuals can utilize available resources more easily. This trend is seen in a comparison of salamander species at lower and higher altitudes; in a cool, high-altitude environment, neotenous individuals survive more and are more fecund than those which metamorphose into adult form. Insects in cooler environments tend to exhibit neoteny in flight because wings have a high surface area and lose heat quickly; it is disadvantageous for insects to metamorphose into adults.\nMany species of salamander, and amphibians in general, exhibit environmental neoteny. Axolotl and olm are perennibranchiate salamander species which retain their juvenile aquatic form throughout adulthood, examples of full neoteny. Gills are a common juvenile characteristic in amphibians which are kept after maturation; examples are the tiger salamander and rough-skinned newt, both of which retain gills into adulthood.\nBonobos share many physical characteristics with humans, including neotenous skulls. The shape of their skull does not change into adulthood (only increasing in size), due to sexual dimorphism and an evolutionary change in the timing of development. \nIn some groups, such as the insect families Gerridae, Delphacidae and Carabidae, energy costs result in neoteny; many species in these families have small, neotenous wings or none at all. Some cricket species shed their wings in adulthood; in the genus \"Ozopemon\", males (thought to be the first example of neoteny in beetles) are significantly smaller than females due to inbreeding. In the termite \"Kalotermes flavicollis\", neoteny is seen in molting females.\nIn other species, such as the northwestern salamander (\"Ambystoma gracile\"), environmental conditions\u00a0\u2013 high altitude, in this case\u00a0\u2013 cause neoteny. Neoteny is also found in a few species of the crustacean family Ischnomesidae, which live in deep ocean water.\nNeoteny is an ancient, pervasive phenomenon. In urodeles, many extant taxa are neotenic, and both morphological and histological data suggest that the Middle Jurassic taxon \"Marmorerpeton\" was neotenic.\nSubcellular neoteny.\nNeoteny is usually used to describe animal development; however, neoteny is also seen in the cell organelles. It was suggested that subcellular neoteny could explain why sperm cells have atypical centrioles. One of the two sperm centrioles of fruit fly exhibit the retention of \"juvenile\" centriole structure, which can be described as centriolar \"neoteny\". This neotenic, atypical centriole is known as the Proximal Centriole-Like. Typical centrioles form via a step by step process in which a cartwheel forms, then develops to become a procentriole, and further matures into a centriole. The neotenic centriole of fruit fly resembles an early procentriole.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21923", "revid": "274535", "url": "https://en.wikipedia.org/wiki?curid=21923", "title": "National Rail", "text": "Brand name for the passenger rail services operated in Great Britain\nNational Rail (NR) is the trading name licensed for use by the Rail Delivery Group, a group representing passenger train operating companies (TOCs) of England, Scotland, and Wales.\nThe British Railways Board ran passenger services using the brand name British Rail from 1965 until 1997, when it was privatised and services were transferred to private train operating companies. (Northern Ireland, which is bordered by the Republic of Ireland, has a different system.)\nNational Rail services share a ticketing structure and inter-availability that generally do not extend to services which were not part of British Rail. The brand has a dedicated website (see below) referred to as nationalrail.co.uk. Its brand name used to be 'National Rail Enquiries' denoted by the nomenclature 'NRE'. While today it is more commonly referred to as 'National Rail' by news and media, it is still known by the initials 'NRE'.\nNational Rail and Network Rail.\n\"National\" Rail should not be confused with \"Network\" Rail. National Rail is a brand used to promote passenger railway services, and providing some harmonisation for passengers in ticketing, while Network Rail is the organisation which owns and manages most of the fixed assets of the railway network, including tracks, stations and signals.\nHowever, the National Rail website is managed by The Rail Delivery Group on behalf of UK based train operating companies. According to their own website, they are a \"membership organisation that works on behalf of the rail industry to create a simpler, better railway for everyone in Britain\".\nThe two generally coincide where passenger services are run. Most major Network Rail lines also carry freight traffic and some lines are freight only. There are some scheduled passenger services on privately managed, non-Network Rail lines, for example Chiltern Railways which runs on both Network Rail track and tracks owned by London Underground. Although the London Underground uses its own tracks in the majority of its network, it also runs on Network Rail tracks and shares tracks with National Rail services, both on its own tracks and on Network Rail tracks.\nTrain operating companies (TOCs).\nTwenty-five privately owned train operating companies were each franchised for a defined term by government in 1996\u201397. They operated passenger trains in Great Britain. However, franchises have ceased to exist and are being replaced by operating contracts, which do not involve significant commercial risk for the operators. The Rail Delivery Group is the trade association representing the TOCs, which includes both franchised and open access operators, and provides core services, including the provision of the National Rail Enquiries service. It also runs Rail Settlement Plan, which formerly allocated ticket revenue to the various TOCs, and Rail Staff Travel, which manages travel facilities for railway staff. It does not compile the national timetable, which is the joint responsibility of the Office of Rail and Road (allocation of paths) and Network Rail (timetable production and publication). Since March 2020 all ticket revenue has been collected by the Department for Transport, which also pays the operators' costs.\nDesign and marketing.\nFollowing the privatisation of British Rail there was no longer a single approach to railway corporate design. The look and feel of signage, liveries and marketing material was largely the preserve of the individual TOCs. However, railway reforms which are currently in progress will restore the pre-privatisation position, with design responsibilities for the whole network resting with the new 'guiding mind', Great British Railways.\nHowever, National Rail continues to use BR's famous double-arrow symbol, designed by Gerald Burney of the Design Research Unit. It has been incorporated in the National Rail logotype and is displayed on tickets, the National Rail website and other publicity. The trademark rights to the double arrow symbol remain state-owned, being vested in the Secretary of State for Transport.\nThe double arrow symbol is also a generic symbol for a railway station across Great Britain, and is used to indicate a railway station on British traffic signs.\nCorporate identity.\nThe National Rail (NR) logo was introduced by ATOC in 1999 (previously the British Rail logo as used from 1965), and was used on the Great Britain public timetable for the first time in the edition valid from 26 September in that year. Rules for its use are set out in the Corporate Identity Style Guidelines published by the Rail Delivery Group, available on its website. \"In 1964 the Design Research Unit\u2014Britain's first multi-disciplinary design agency founded in 1943 by Misha Black, Milner Gray and Herbert Read\u2014was commissioned to breathe new life into the nation's neglected railway industry\". The NR title is sometimes described as a \"brand\". As it was used by British Rail, the single operator before franchising, its use also maintains continuity and public familiarity; and it avoids the need to replace signage.\nThe lettering used in the National Rail logotype is a modified form of the typeface Sassoon Bold. Some train operating companies continue to use the former British Rail Rail Alphabet lettering to varying degrees in station signage, although its use is no longer universal; however it remains compulsory (under Railway Group Standards) for safety signage in trackside areas and is still common (although not universal) on rolling stock.\nThe British Rail typefaces of choice from 1965 were Helvetica and Univers, with others (particularly Frutiger) coming into use during the sectorisation period after 1983. TOCs may use what they like: examples include Futura (Stagecoach Group), Helvetica (FirstGroup and National Express), Johnston (London Overground and Elizabeth line), Frutiger (Arriva Trains Wales), Bliss (CrossCountry), and a modified version of Precious by London Midland.\nOther passenger rail operators in Great Britain.\nSeveral conurbations have their own metro or tram systems, most of which are not part of National Rail. These include the London Underground, Docklands Light Railway, London Tramlink, Blackpool Tramway, Glasgow Subway, Tyne and Wear Metro, Manchester Metrolink, Sheffield Supertram, West Midlands Metro and Nottingham Express Transit. On the other hand, the largely self-contained Merseyrail system is part of the National Rail network, and urban rail networks around Birmingham, Cardiff, Glasgow and West Yorkshire consist entirely of National Rail services.\nLondon Overground and the Elizabeth line (formerly TfL Rail) are hybrids: Their services are operated via a concession awarded by Transport for London (TfL). They are part of National Rail as train operating companies, where tickets can be used in the same way as other operators, and shown in the National Rail timetable. However, under Transport for London, they are considered as separate networks. They are listed separately in all materials produced by TfL than National Rail, stations serving London Overground or the Elizabeth line only do not have the National Rail logo shown on either the station themselves or the tube map, and fares on these two networks are priced as TfL services, the same as London Underground, rather than National Rail services. The National Rail service status web page by TfL also does not list these two systems.\nLondon Overground also owns some infrastructure in its own right, following the reopening of the former London Underground East London line and the extension to Barking Riverside.\nEurostar is also not part of the National Rail network despite sharing of tracks and stations (along High Speed 1). Northern Ireland Railways were never part of British Rail, which was limited to England, Scotland and Wales.\nThere are many privately owned or heritage railways in Great Britain which are not part of the National Rail network and mostly operate for heritage or pleasure purposes rather than as public transport, but some have connections to National Rail track.\nTicketing.\nNational Rail services have a common ticketing structure inherited from British Rail. Through tickets are available between any pair of stations on the network, and can be bought from any station ticket office. Most tickets are inter-available between the services of all operators on routes appropriate to the journey being made. Operators on some routes offer operator-specific tickets that are cheaper than the inter-available ones.\nThrough tickets involving London Underground, or to some ferry services (\"RailSail\" tickets) are also available. Oyster pay-as-you-go can be used on National Rail in Greater London from 2 January 2010. These same areas can also be journeyed to using a contactless debit/credit card. Contactless also covers some areas that Oyster does not, such as the Elizabeth line to Reading, or the Thameslink station at Oakleigh Park.\nThe most common types of tickets available include 'advance' tickets, that specify a specific route and timing between two destinations, 'off-peak' tickets, either as a single or a return, that allow a passenger to use a train at hours where the service is not busy, and 'anytime' tickets, which can be used on any train. Season tickets, which offer unlimited travel between two stations for a specified period, are also available. A 'rover' travel card ticket also exists that allows unlimited travel in a set area or on services of certain operators, for a certain period of time. Rovers which allow unlimited travel for only one day are sometimes referred to as \"ranger\" tickets, and are usually available for smaller areas.\nPassengers without a valid ticket boarding a train at a station where ticket-buying facilities are available are required to pay the full Open Single or Return fare. On some services penalty fares apply \u2013 a ticketless passenger may be charged the greater of \u00a320 or twice the full single fare to the next stop. Penalty Fares can be collected only by authorised Revenue Protection Inspectors, not by ordinary Guards.\nNational Rail distributes a number of technical manuals on which travel on the railways in Great Britain is based, such as the National Rail Conditions of Travel, via their website.\nTimetables.\nPocket timetables for individual operators or routes are available free at staffed stations. The last official printed timetable with up to 3000 pages was published in 2007. Now the only complete print edition is published by Middleton Press (as of October 2016). A digital version of the full timetable is available as a pdf file without charge on the Network Rail website; however, passengers are recommended to obtain their timetables from the individual train companies.\nNational Rail website.\nThe National Rail website, previously called National Rail Enquiries, handles an average of 2.5 million journey planning enquiries every weekday through its website, apps and contact centre, and through information services supplied to third parties (such as open access data feeds).\nIt is Britain's largest and most accurate travel information website, peaking at more than 10 million visitors per day, more than its nearest competitors. It is considered the official authority for rail travel in Britain and regularly cited by the BBC and other large media outlets. Some train companies are not linked to for commercial reasons such as the Caledonian Sleeper but it cites National Rail's website as \"the best place to find information on any temporary limits on accessibility\".\nThe National Rail website includes a journey planner, fare and live departure information. The site is designed to complement the myriad different websites of Britain's privatised rail companies, so when users have selected which tickets they wish to buy, they are redirected to the most relevant train company website, where they can buy their tickets without booking fees.\nIn 2012 the website was joined by a mobile app mirroring its functionality. The app is available for iPhone and Android.\nIn June 2020, a real time personalised messaging service, Alert Me, was launched, providing real-time disruption and crowding information via Messenger. This was followed in September 2021 by a similar service made available through WhatsApp. The service was closed in June 2023 leaving only a simple SMS based messaging service in place for customers. Both services were provided by a British transport technology company Zipabout.\nIn April 2021 the National Rail website turned from colour to greyscale in a tribute to Prince Philip, Duke of Edinburgh, who had recently died. The gesture however backfired after users highlighted accessibility issues and complained they could no longer use the website. The website was quickly reverted back to its original design the same day following customer accessibility feedback.\nIn July 2021 the Department of Transport published the world\u2019s first 'greenprint' to decarbonise all modes of domestic transport by 2050 in the UK. It was published two months before the climate summit COP26, and planned to provide a world-leading 'greenprint' to cut emissions from \"seas and skies, roads and railways\". The nationalrail.co.uk website also signed up to the same carbon commitment, which was referred to as 'The Green Travel Pledge' and was cited on its website and via Rail Delivery Group media.\nIn June 2023 the website was completely overhauled with an entirely new frontend retaining little of the old designs but the brand logo remained. The website is quoted as saying its website is, \"cleaner, more modern, and full of better information\". In addition, its original mobile website which was a sub-domain (m.nationalrail.co.uk now redirects) was switched off.\nEarlier in 2024 National Rail's digital journey planner was also switched off and redirected to the new version. Online Journey Planner (OJP) was the engine used to plan routes, calculate fares and establish ticket availability. The OJP accesses real-time information directly from Darwin, meaning all journey plans take account of delays, schedule changes and train cancellations. The OJP data feed APIs are available for use under licence. Darwin is the data system that powers all the real-time information which customers use to check the status of train journeys. In 2024 Darwin celebrated its 20th anniversary.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21926", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=21926", "title": "Naked singularity", "text": "Hypothetical phenomenon\nIn general relativity, a naked singularity is a hypothetical gravitational singularity without an event horizon.\nWhen there exists at least one causal geodesic that, in the future, extends either to an observer at infinity or to an observer comoving with the collapsing cloud, and in the past terminates at the gravitational singularity, then that singularity is referred to as a naked singularity. In a black hole, the singularity is completely enclosed by a boundary known as the event horizon, inside which the curvature of spacetime caused by the singularity is so strong that light cannot escape. Hence, objects inside the event horizon\u2014including the singularity itself\u2014cannot be observed directly. In contrast, a naked singularity would be observable.\nThe theoretical existence of naked singularities is important because their existence would mean that it would be possible to observe the collapse of an object to \"infinite density\". It would also cause foundational problems for general relativity, because general relativity cannot make predictions about the evolution of spacetime near a singularity. In generic black holes, this is not a problem, as an outside viewer cannot observe the spacetime within the event horizon.\nNaked singularities have not been observed in nature. Astronomical observations of black holes indicate that their rate of rotation falls below the threshold to produce a naked singularity (spin parameter 1). GRS 1915+105 comes closest to the limit, with a spin parameter of 0.82-1.00. It is hinted that GRO J1655\u221240 could be a naked singularity.\nAccording to the cosmic censorship hypothesis, gravitational singularities may not be observable. If loop quantum gravity is correct, naked singularities may be possible in nature.\nPredicted formation.\nWhen a massive star undergoes a gravitational collapse due to its own immense gravity, the ultimate outcome of this persistent collapse can manifest as either a black hole or a naked singularity. This holds true across a diverse range of physically plausible scenarios allowed by general relativity. The Oppenheimer\u2013Snyder\u2013Datt (OSD) model illustrates the collapse of a spherical cloud composed of homogeneous dust (pressureless matter). In this scenario, all the matter converges into the spacetime singularity simultaneously in terms of comoving time. Notably, the event horizon emerges before the singularity, effectively covering it. By allowing an inhomogeneous initial density profile, one can demonstrate a significant alteration in the behavior of the horizon. This leads to two distinct potential outcomes arising from the collapse of generic dust: the formation of a black hole, characterized by the horizon preceding the singularity; or the emergence of a naked singularity, where the horizon is delayed. In the case of a naked singularity, this delay enables null geodesics or light rays to escape the central singularity, where density and curvatures diverge, reaching distant observers. In exploring more realistic scenarios of collapse, one avenue involves incorporating pressures into the model. The consideration of gravitational collapse with non-zero pressures and various models including a realistic equation of state, delineating the specific relationship between the density and pressure within the cloud, has been thoroughly examined and investigated by numerous researchers over the years. They all result in either a black hole or a naked singularity depending on the initial data.\nFrom concepts drawn from rotating black holes, it is shown that a singularity, spinning rapidly, can become a ring-shaped object. This results in two event horizons, as well as an ergosphere, which draw closer together as the spin of the singularity increases. When the outer and inner event horizons merge, they shrink toward the rotating singularity and eventually expose it to the rest of the universe.\nA singularity rotating fast enough might be created by the collapse of dust or by a supernova of a fast-spinning star. Studies of pulsars and some computer simulations (Choptuik, 1997) have been performed. Intriguingly, it is recently reported that some spinning white dwarfs could realistically transmute into rotating naked singularities or black holes with a wide range of near- and sub-solar-mass values by capturing asymmetric dark matter particles.\nSimilarly, spinning neutron stars could also be transmuted to slowly spinning near\u2013solar-mass naked singularities by capturing asymmetric dark matter particles, if the accumulated cloud of dark matter particles in the core of a neutron star can be modeled as an anisotropic fluid. In general, the precession of a gyroscope and the precession of orbits of matter falling into a rotating black hole or a naked singularity can be used to distinguish these exotic objects.\nMathematician Demetrios Christodoulou, a winner of the Shaw Prize, has shown that contrary to what had been expected, singularities which are not hidden in a black hole could also occur. However, he then showed that such \"naked singularities\" are unstable.\nMetrics.\nDisappearing event horizons exist in the Kerr metric, which is a spinning black hole in a vacuum. Specifically, if the angular momentum is high enough, the event horizons could disappear. Transforming the Kerr metric to Boyer\u2013Lindquist coordinates, it can be shown that the formula_1 coordinate (which is not the radius) of the event horizon is\nformula_2\nwhere formula_3, and formula_4. In this case, \"event horizons disappear\" means that the solutions are complex for formula_5, or formula_6. However, this corresponds to a case where formula_7 exceeds formula_8 (or in Planck units, formula_9), i.e. the spin exceeds what is normally viewed as the upper limit of its physically possible values.\nDisappearing event horizons can also be seen with the Reissner\u2013Nordstr\u00f6m geometry of a charged black hole. In this metric, it can be shown that the horizons occur at\nformula_10\nwhere formula_3, and formula_12. Of the three possible cases for the relative values of formula_13 and formula_14, the case where formula_15 causes both formula_16 to be complex. This means the metric is regular for all positive values of formula_1, or in other words, the singularity has no event horizon. However, this corresponds to a case where formula_18 exceeds formula_19 (or in Planck units, formula_20), i.e. the charge exceeds what is normally viewed as the upper limit of its physically possible values.\nSee Kerr\u2013Newman metric for a spinning, charged ring singularity.\nTypes.\nGlobally and locally naked singularities.\nNaked singularities can either be globally or locally naked. A globally naked singularity is visible from infinity, while a locally naked singularity is not due to being hidden behind a horizon. In other words, a globally naked singularity can have causal effects on asymptotic regions of spacetime, while a locally naked singularity can only affect a finite region. Globally and locally naked singularities are the focuses of Penrose's weak and strong cosmic censorship hypotheses respectively, which theorize that such singularities do not exist. In 2017, mathematicians Mihalis Dafermos and Jonathan Luk mathematically verified that spacetime continues beyond the inner Cauchy horizon of a black hole, beyond which a locally naked BKL singularity lies, providing a counterexample to the strong version of the cosmic censorship conjecture by mathematically proving a generic condition under which a locally naked singularity could form.\nStrongly and weakly naked singularities.\nNaked singularities can be strongly or weakly naked. A weakly naked singularity is contained within at least one photon sphere, while a strongly naked singularity is not. The strength of a naked singularity is determined by its scalar charge to mass ratio. When formula_21, where formula_14 is the singularity's charge and formula_23 is its mass, the singularity is weakly naked. When formula_24, the singularity is strongly naked. When formula_25, the singularity is marginally strongly naked and has similar properties to a weakly naked singularity.\nLight is lensed differently near a weakly vs strongly naked singularity. Similarly to a Schwarzschild black hole, light around a weakly naked singularity travels around the photon sphere many times, generating many relativistic images around it. On the other hand, having no photon sphere, a strongly naked singularity does not create any lensed relativistic images. Additionally, like a Schwarzschild black hole, a weakly naked singularity has one Einstein ring and no radial critical curve, while a strongly naked singularity has either zero or two Einstein rings and does have a radial critical curve.\nEffects.\nA naked singularity could allow scientists to observe an infinitely dense material, which would under normal circumstances be impossible according to the cosmic censorship hypothesis. That is, without an event horizon of any kind, naked singularities could actually emit light.\nCosmic censorship hypothesis.\nThe cosmic censorship hypothesis says that every gravitational singularity will remain hidden by its event horizon. LIGO events, including GW150914, are consistent with these predictions. Although data anomalies would have resulted in the case of a singularity, the nature of those anomalies remains unknown.\nSome research has suggested that if loop quantum gravity is correct, then naked singularities could exist in nature, implying that the cosmic censorship hypothesis does not hold. Numerical calculations and some other arguments have also hinted at this possibility.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21927", "revid": "50907572", "url": "https://en.wikipedia.org/wiki?curid=21927", "title": "National Party of Australia", "text": "Australian political party\nThe National Party of Australia, commonly known as the Nationals or simply the Nats, is a right-wing and agrarian political party in Australia. Traditionally representing graziers, farmers, and rural voters generally, it began as the Australian Country Party in 1920 at a federal level. \nIn 1975, it adopted the name National Country Party, before taking its current name in 1982.\nEnsuring support for farmers, either through government grants and subsidies or through community appeals, is a major focus of National Party policy. The process for obtaining these funds has come into question in recent years, such as during the Sports Rorts Affair. According to Ian McAllister, the Nationals are the only remaining party from the \"wave of agrarian socialist parties set up around the Western world in the 1920s\".\nFederally, the Nationals are the junior party in a centre-right grouping known in Australian politics as the Coalition, accompanied by the Liberal Party, which is predominantly an urban-based party. When in government the National Party leader has usually served as Deputy Prime Minister. The coalition has occasionally been dissolved on various occasions following electoral defeats, though the splits have not been permanent. The coalition arrangement varies in each state and territory. \nDue to the closeness and integration of the two parties, as well as the declining vote of the Nationals in recent years, it has been proposed several times that the Liberals and the Nationals formally merge. In Queensland, for instance, the Country Party (later National Party) was the senior coalition party between 1925 and 2008, after which it merged with the junior Liberal Party to form the Liberal National Party of Queensland.\nThe current leader of the National Party is David Littleproud, who represents the Queensland electorate of Maranoa. He replaced Barnaby Joyce following a leadership spill in May 2022, after the Coalition's defeat in the 2022 federal election. The party's deputy leader since May 2025 is Kevin Hogan, who represents the electorate of Page in New South Wales.\nHistory.\n \nThe Country Party was formally founded in 1913 in Western Australia, and nationally in 1920, from a number of state-based parties such as the Victorian Farmers' Union (VFU) and the Farmers' and Settlers' Association of New South Wales. Australia's first Country Party was founded in 1912 by Harry J. Stephens, editor of \"The Farmer &amp; Settler\", but, under fierce opposition from rival newspapers, failed to gain momentum.\nThe VFU won a seat in the House of Representatives at the Corangamite by-election held in December 1918, with the help of the newly introduced preferential voting system. At the 1919 federal election the state-based Country Parties won federal seats in New South Wales, Victoria and Western Australia. They also began to win seats in state parliaments. In 1920 the Country Party was established as a national party led by William McWilliams from Tasmania. In his first speech as leader, McWilliams laid out the principles of the new party, stating \"we crave no alliance, we spurn no support but we intend drastic action to secure closer attention to the needs of primary producers\" McWilliams was deposed as party leader in favour of Earle Page in April 1921, following instances where McWilliams voted against the party line. McWilliams later left the Country Party to sit as an Independent.\nAccording to historian B. D. Graham (1959), the graziers who operated the sheep stations were politically conservative. They disliked the Labor Party, which represented their workers, and feared that Labor governments would pass unfavorable legislation and listen to foreigners and communists. The graziers were satisfied with the marketing organisation of their industry, opposed any change in land tenure and labour relations, and advocated lower tariffs, low freight rates, and low taxes. On the other hand, Graham reports, the small farmers, not the graziers, founded the Country party. The farmers advocated government intervention in the market through price support schemes and marketing pools. The graziers often politically and financially supported the Country party, which in turn made the Country party more conservative.\nThe Country Party's first election as a united party, in 1922, saw it in an unexpected position of power. It won enough seats to deny the Nationalists an overall majority. It soon became apparent that the price for Country support would be a full-fledged coalition with the Nationalists. However, Page let it be known that his party would not serve under Hughes, and forced his resignation. Page then entered negotiations with the Nationalists' new leader, Stanley Bruce, for a coalition government. Page wanted five seats for his Country Party in a cabinet of 11, including the Treasurer portfolio and the second rank in the ministry for himself. These terms were unusually stiff for a prospective junior coalition partner in a Westminster system, and especially so for such a new party. With no other politically realistic coalition partner available, Bruce agreed, and the \"Bruce-Page Ministry\" was formed. This began the tradition of the Country Party leader ranking second in Coalition cabinets. The party has never had a coalition government with Labor as of 2025[ [update]].\nPage remained dominant in the party until 1939, and briefly served as caretaker prime minister between the death of Joseph Lyons and the election of Robert Menzies as his successor. However, Page gave up the leadership rather than serve under Menzies. The coalition was re-formed under Archie Cameron in 1940, and continued until October 1941 despite the election of Arthur Fadden as leader after the 1940 election. Fadden was well regarded within conservative circles and proved to be a loyal deputy to Menzies in the difficult circumstances of 1941. When Menzies was forced to resign as prime minister, the UAP was so bereft of leadership that Fadden briefly succeeded him (despite the Country Party being the junior partner in the governing coalition). However, the two independents who had been propping up the government rejected Fadden's budget and brought the government down. Fadden stood down in favour of Labor leader John Curtin.\nThe Fadden-led Coalition made almost no headway against Curtin, and was severely defeated in the 1943 election. After that loss, Fadden became deputy leader of the opposition under Menzies, a role that continued after Menzies folded the UAP into the Liberal Party of Australia in 1944. Fadden remained a loyal partner of Menzies, though he was still keen to assert the independence of his party. Indeed, in the lead up to the 1949 federal election, Fadden played a key role in the defeat of the Chifley Labor government, frequently making inflammatory claims about the \"socialist\" nature of the Labor Party, which Menzies could then \"clarify\" or repudiate as he saw fit, thus appearing more \"moderate\". In 1949, Fadden became Treasurer in the second Menzies government and remained so until his retirement in 1958. His successful partnership with Menzies was one of the elements that sustained the coalition, which remained in office until 1972 (Menzies himself retired in 1966).\nFadden's successor, Trade Minister John McEwen, took the then unusual step of declining to serve as treasurer, believing he could better ensure that the interests of Australian primary producers were safeguarded. Accordingly, McEwen personally supervised the signing of the first post-war trade treaty with Japan, new trade agreements with New Zealand and Britain, and Australia's first trade agreement with the USSR (1965). In addition to this, he insisted on developing an all-encompassing system of tariff protection that would encourage the development of those secondary industries that would \"value add\" Australia's primary produce. His success in this endeavour is sometimes dubbed \"McEwenism\". This was the period of the Country Party's greatest power, as was demonstrated in 1962 when McEwen was able to insist that Menzies sack a Liberal minister who claimed that Britain's entry into the European Economic Community was unlikely to severely impact the Australian economy as a whole.\nMenzies retired in 1966 and was succeeded by Harold Holt. McEwen thus became the longest-tenured member of the government, with the informal right to veto government policy. The most significant instance in which McEwen exercised this right came when Holt disappeared in December 1967. John Gorton became the new Liberal prime minister in January 1968. McEwen was sworn in as interim prime minister pending the election of the new Liberal leader. Logically, the Liberals' deputy leader, William McMahon, should have succeeded Holt. However, McMahon was a staunch free-trader, and there were also rumours that he was homosexual. As a result, McEwen told the Liberals that he and his party would not serve under McMahon. McMahon stood down in favour of John Gorton. It was only after McEwen announced his retirement that McMahon was able to successfully challenge Gorton for the Liberal leadership. McEwen's reputation for political toughness led to him being nicknamed \"Black Jack\" by his allies and enemies alike.\nAt the state level, from 1957 to 1989, the Country Party under Frank Nicklin and Joh Bjelke-Petersen dominated governments in Queensland\u2014for the last six of those years ruling in its own right, without the Liberals. This was due to the bjelkemander, a malapportionment in electorates which gave rural voters twice the voting power compared to voters within the city. It also took part in governments in New South Wales, Victoria, and Western Australia.\nHowever, successive electoral redistributions after 1964 indicated that the Country Party was losing ground electorally to the Liberals as the rural population declined, and the nature of some parliamentary seats on the urban and rural fringe changed. A proposed merger with the Democratic Labor Party (DLP) under the banner of \"National Alliance\" was rejected when it failed to find favour with voters at the 1974 state election.\nAlso in 1974, the Northern Territory members of the party joined with its Liberal party members to form the independent Country Liberal Party. This party continues to represent both parent parties in that territory. A separate party, the Joh-inspired NT Nationals, competed in the 1987 election with former chief minister Ian Tuxworth retaining his seat of Barkly by a small margin. However, this splinter group was not endorsed by the national executive and soon disappeared from the political scene.\nNational Country Party and National Party.\nThe National Party was confronted by the impact of demographic shifts from the 1970s: between 1971 and 1996, the population of Sydney and surrounds grew by 34%, with even larger growth in coastal New South Wales, while more remote rural areas grew by a mere 13%, further diminishing the National Party's base. At the federal convention held on 2 May 1975 in Canberra, the Country Party changed its name to the National Country Party of Australia as part of a strategy to expand into urban areas. This had some success in Queensland under Joh Bjelke-Petersen, but nowhere else. The party briefly walked out of the coalition agreement in Western Australia in May 1975, returning within the month. However, the party split in two over the decision and other factors in late 1978, with a new National Party forming and becoming independent, holding three seats in the Western Australian lower house, while the National Country Party remained in coalition and also held three seats. They reconciled after the Burke Labor government came to power in 1983.\nThe 1980s were dominated by the feud between Bjelke-Petersen and the federal party leadership under Ian Sinclair. Bjelke-Petersen briefly triumphed in 1987, forcing the Nationals to tear up the Coalition agreement and support his bid to become prime minister. The \"Joh for Canberra\" campaign backfired spectacularly when a large number of three-cornered contests allowed Labor to win a third term under Bob Hawke; however, in 1987 the National Party won a bump in votes and recorded its highest vote in more than four decades, but it also recorded a new low in the proportion of seats won. The collapse of the Joh for Canberra campaign also proved to be the Queensland Nationals' last hurrah; Bjelke-Petersen was forced into retirement a few months after the federal election, and his party was heavily defeated in 1989. The federal National Party were badly defeated at the 1990 election, losing five seats including that of leader Charles Blunt, who had ousted Sinclair months earlier.\nBlunt's successor as leader, Tim Fischer, recovered two seats at the 1993 election, but lost an additional 1.2% of the vote from its 1990 result. In 1996, as the Coalition won a significant victory over Paul Keating's Labor government, the National Party recovered another two seats, and Fischer became deputy prime minister under John Howard.\nThe Nationals experienced difficulties in the late 1990s from two fronts \u2013 firstly from the Liberal Party, who were winning seats on the basis that the Nationals were not seen to be a sufficiently separate party, and from the One Nation Party riding a swell of rural discontent with many of the policies such as multiculturalism and gun control embraced by all of the major parties. The rise of Labor in formerly safe National-held areas in rural Queensland, particularly on the coast, has been the biggest threat to the Queensland Nationals.\nAt the 1998 Federal election, the National Party recorded only 5.3% of the vote in the House of Representatives, its lowest ever, and won only 16 seats, at 10.8% its second lowest proportion of seats.\nThe National Party under Fischer and his successor, John Anderson, rarely engaged in public disagreements with the Liberal Party, which weakened the party's ability to present a separate image to rural and regional Australia. In 2001 the National Party recorded its second-worst result at 5.6% winning 13 seats, and its third lowest at 5.9% at the 2004 election, winning only 12 seats.\nAustralian psephologist Antony Green argues that two important trends have driven the National Party's decline at a federal level: \"the importance of the rural sector to the health of the nation's economy\" and \"the growing chasm between the values and attitudes of rural and urban Australia\". Green has suggested that the result has been that \"Both have resulted in rural and regional voters demanding more of the National Party, at exactly the time when its political influence has declined. While the National Party has never been the sole representative of rural Australia, it is the only party that has attempted to paint itself as representing rural voters above all else\".\nIn June 2005, party leader John Anderson announced that he would resign from the ministry and as leader of the Nationals due to a benign prostate condition, he was succeeded by Mark Vaile. At the following 2007 election, the Nationals vote declined further, with the party winning a mere 5.4% of the vote and securing only 10 seats. Vaile announced his resignation as party leader which surprised his colleagues, as he had been expected to be re-elected unopposed following the election. He had planned the party leadership to go to Peter McGauran but the latter declined to stand. Warren Truss and Nigel Scullion were then elected unopposed as leader and deputy leader.\nIn 2010, under the leadership of Truss, the party received its lowest vote to date, at only 3.4%, however they secured a slight increase in seats from 10 to 12. At the following election in 2010 the national Party's fortunes improved slightly with a vote of 4.2% and an increase in seats from 12 to 15.\nAt the 2016 double dissolution election, under the leadership of Barnaby Joyce the party secured 4.6% of the vote and 16 seats. In 2018, reports emerged that the National Party leader and deputy prime minister, Barnaby Joyce was expecting a child with his former communications staffer Vikki Campion. Joyce resigned after revelations that he had been engaged in an extramarital affair. Later in the same year it was revealed that the NSW National party and its youth wing, the Young Nationals had been infiltrated by neo-Nazis with more than 30 members being investigated for alleged links to neo-Nazism. Leader Michael McCormack denounced the infiltration, and several suspected neo-Nazis were expelled from the party and its youth wing.\nAt the 2019 Australian federal election, despite severe drought, perceived inaction over the plight of the Murray\u2013Darling Basin, a poor performance in the New South Wales state election and sex scandals surrounding the member for Mallee, Andrew Broad and former party leader Barnaby Joyce, the National Party saw only a small decline in vote, down 0.10% to attain 4.51% of the primary vote.\nFollowing the 2025 federal election, the Nationals decided not to sign a new Coalition agreement with the Liberals. This resulted in the two parties operating separately for the first time since the 1980s, and thus reducing the Nationals to third party status in the Australian Parliament, sitting on the crossbench. The split lasted only eight days, following agreement on several policy areas that the Nationals had advocated, and a new shadow ministry was revealed.\nState and territory parties.\nThe official state and territorial party organisations (or equivalents) of the National Party are:\nPolitical role.\nThe Nationals see their main role as giving a voice to Australians who live outside the country's metropolitan areas.\nTraditionally, the leader of the National Party serves as Deputy Prime Minister when there is a coalition agreement with the Liberal Party, and the two form Government. This tradition dates back to the creation of the office in 1968.\nThe National Party's support base and membership are closely associated with the agricultural community. Historically anti-union, the party has vacillated between state support for primary industries (\"agrarian socialism\") and free agricultural trade and has opposed tariff protection for Australia's manufacturing and service industries. It is usually in favor of industrial development, opposing green politics.\n\"Countrymindedness\" was a slogan that summed up the ideology of the Country Party from 1920 through the early 1970s. It was an ideology that was physiocratic, populist, and decentralist; it fostered rural solidarity and justified demands for government subsidies. \"Countrymindedness\" grew out of the failure of the country areas to participate in the rapid economic and population expansions that occurred after 1890. The growth of the ideology into urban areas came as most country people migrated to jobs in the cities. Its decline was due mainly to the reduction of real and psychological differences between country and city brought about by the postwar expansion of the Australian urban population and to the increased affluence and technological changes that accompanied it.\nThe Nationals vote is in decline and its traditional supporters are turning instead to prominent independents such as Bob Katter, Tony Windsor and Peter Andren in Federal Parliament and similar independents in the Parliaments of New South Wales, Queensland and Victoria, many of whom are former members of the National Party. In fact since the 2004 Federal election, National Party candidates have received fewer first preference votes than the Australian Greens.\nDemographic changes are not helping, with fewer people living and employed on the land or in small towns, the continued growth of the larger provincial centres, and, in some cases, the arrival of left-leaning \"city refugees\" in rural areas. The Liberals have also gained support as the differences between the coalition partners on a federal level have become invisible. This was highlighted in January 2006, when Nationals Senator Julian McGauran defected to the Liberals, saying that there was \"no longer any real distinguishing policy or philosophical difference\".\nIn Queensland, Nationals leader Lawrence Springborg advocated merger of the National and Liberal parties at a state level in order to present a more effective opposition to the Labor Party. Previously this plan had been dismissed by the Queensland branch of the Liberal party, but the idea received in-principle support from the Liberals. Federal leader Mark Vaile stated the Nationals will not merge with the Liberal Party at a federal level. The plan was opposed by key Queensland Senators Ron Boswell and Barnaby Joyce, and was scuttled in 2006. After suffering defeat in the 2006 Queensland poll, Lawrence Springborg was replaced by Jeff Seeney, who indicated he was not interested in merging with the Liberal Party until the issue is seriously raised at a Federal level.\nIn September 2008, Joyce replaced CLP Senator and Nationals deputy leader Nigel Scullion as leader of the Nationals in the Senate, and stated that his party in the upper house would no longer necessarily vote with their Liberal counterparts in the upper house, which opened up another possible avenue for the Rudd Labor government to get legislation through. Joyce was elected leader in a party-room ballot on 11 February 2016, following the retirement of former leader and Deputy Prime Minister Warren Truss. Joyce was one of five politicians disqualified from parliament in October 2017 for holding dual citizenship, along with former deputy leader, Fiona Nash.\nThe 1987 Australian federal election was the last time the National party received over 10% of the vote and the 2007 Australian federal election was the last time the National party received over 5% of the vote for the House of Representatives.\nQueensland Liberal/National merger.\nMerger plans came to a head in May 2008, when the Queensland state Liberal Party gave an announcement not to wait for a federal blueprint but instead to merge immediately. The new party, the Liberal National Party, was founded in July 2008.\nElectoral performance.\nHouse of Representatives.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nLeadership.\nList of Senate leaders.\nThe Country Party's first senators began their terms in 1926, but the party had no official leader in the upper chamber until 1935. Instead, the party nominated a \"representative\" or \"liaison officer\" where necessary \u2013 usually William Carroll. This was so that its members \"were first and foremost representatives of their states, able to enjoy complete freedom of action and speech in the Senate and not beholden to the dictates of [...] a party Senate leader\". On 3 October 1935, Charles Hardy was elected as Carroll's replacement and began using the title \"Leader of the Country Party in the Senate\". This usage was disputed by Carroll and Bertie Johnston, but a subsequent party meeting on 10 October confirmed Hardy's position. However, after Hardy's term ended in 1938 (due to his defeat at the 1937 election), the party did not elect another Senate leader until 1949 \u2013 apparently due to its small number of senators.\nUnlike the leader in the House of Representatives, the Senate leader has not always been a member of the ministry or shadow ministry at all times. \nPast heads of government and opposition leaders.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nDonors.\nFor the 2015\u20132016 financial year, the top ten disclosed donors to the National Party were: Manildra Group ($182,000), Ognis Pty Ltd ($100,000), Trepang Services ($70,000), Northwake Pty Ltd ($65,000), Hancock Prospecting ($58,000), Bindaree Beef ($50,000), Mowburn Nominees ($50,000), Retail Guild of Australia ($48,000), CropLife International ($43,000) and Macquarie Group ($38,000).\nThe National Party also receives undisclosed funding through several methods, such as \"associated entities\". John McEwen House, Pilliwinks and Doogary are entities which have been used to funnel donations to the National Party without disclosing the source.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21930", "revid": "48769440", "url": "https://en.wikipedia.org/wiki?curid=21930", "title": "Northern blot", "text": "Molecular biology technique\nThe northern blot, or RNA blot, is a technique used in molecular biology research to study gene expression by detection of RNA (or isolated mRNA) in a sample.\nWith northern blotting it is possible to observe cellular control over structure and function by determining the particular gene expression rates during differentiation and morphogenesis, as well as in abnormal or diseased conditions. Northern blotting involves the use of electrophoresis to separate RNA samples by size, and detection with a hybridization probe complementary to part of or the entire target sequence. Strictly speaking, the term 'northern blot' refers specifically to the capillary transfer of RNA from the electrophoresis gel to the blotting membrane. However, the entire process is commonly referred to as northern blotting. The northern blot technique was developed in 1977 by James Alwine, David Kemp, and George Stark at Stanford University. Northern blotting takes its name from its similarity to the first blotting technique, the Southern blot, named for biologist Edwin Southern. The major difference is that RNA, rather than DNA, is analyzed in the northern blot.\nProcedure.\nA general blotting procedure starts with extraction of total RNA from a homogenized tissue sample or from cells. Eukaryotic mRNA can then be isolated through the use of oligo (dT) cellulose chromatography to isolate only those RNAs with a poly(A) tail. RNA samples are then separated by gel electrophoresis. Since the gels are fragile and the probes are unable to enter the matrix, the RNA samples, now separated by size, are transferred to a nylon membrane through a capillary or vacuum blotting system. A nylon membrane with a positive charge is the most effective for use in northern blotting since the negatively charged nucleic acids have a high affinity for them. The transfer buffer used for the blotting usually contains formamide because it lowers the annealing temperature of the probe-RNA interaction, thus eliminating the need for high temperatures, which could cause RNA degradation. Once the RNA has been transferred to the membrane, it is immobilized through covalent linkage to the membrane by UV light or heat. After a probe has been labeled, it is hybridized to the RNA on the membrane. Experimental conditions that can affect the efficiency and specificity of hybridization include ionic strength, viscosity, duplex length, mismatched base pairs, and base composition. The membrane is washed to ensure that the probe has bound specifically and to prevent background signals from arising. The hybrid signals are then detected by X-ray film and can be quantified by densitometry. To create controls for comparison in a northern blot, samples not displaying the gene product of interest can be used after determination by microarrays or RT-PCR.\nGels.\nThe RNA samples are most commonly separated on agarose gels containing formaldehyde as a denaturing agent for the RNA to limit secondary structure. The gels can be stained with ethidium bromide (EtBr) and viewed under UV light to observe the quality and quantity of RNA before blotting. Polyacrylamide gel electrophoresis with urea can also be used in RNA separation but it is most commonly used for fragmented RNA or microRNAs. An RNA ladder is often run alongside the samples on an electrophoresis gel to observe the size of fragments obtained but in total RNA samples the ribosomal subunits can act as size markers. Since the large ribosomal subunit is 28S (approximately 5kb) and the small ribosomal subunit is 18S (approximately 2kb) two prominent bands appear on the gel, the larger at close to twice the intensity of the smaller.\nProbes.\nProbes for northern blotting are composed of nucleic acids with a complementary sequence to all or part of the RNA of interest. They can be DNA, RNA, or oligonucleotides with a minimum of 25 complementary bases to the target sequence. RNA probes (riboprobes) that are transcribed in vitro are able to withstand more rigorous washing steps preventing some of the background noise. Commonly cDNA is created with labelled primers for the RNA sequence of interest to act as the probe in the northern blot. The probes must be labelled either with radioactive isotopes (32P) or with chemiluminescence in which alkaline phosphatase or horseradish peroxidase (HRP) break down chemiluminescent substrates producing a detectable emission of light. The chemiluminescent labelling can occur in two ways: either the probe is attached to the enzyme, or the probe is labelled with a ligand (e.g. biotin) for which the ligand (e.g., avidin or streptavidin) is attached to the enzyme (e.g. HRP). X-ray film can detect both the radioactive and chemiluminescent signals and many researchers prefer the chemiluminescent signals because they are faster, more sensitive, and reduce the health hazards that go along with radioactive labels. The same membrane can be probed up to five times without a significant loss of the target RNA.\nApplications.\nNorthern blotting allows one to observe a particular gene's expression pattern between tissues, organs, developmental stages, environmental stress levels, pathogen infection, and over the course of treatment. The technique has been used to show overexpression of oncogenes and downregulation of tumor-suppressor genes in cancerous cells when compared to 'normal' tissue, as well as the gene expression in the rejection of transplanted organs. If an upregulated gene is observed by an abundance of mRNA on the northern blot the sample can then be sequenced to determine if the gene is known to researchers or if it is a novel finding. The expression patterns obtained under given conditions can provide insight into the function of that gene. Since the RNA is first separated by size, if only one probe type is used variance in the level of each band on the membrane can provide insight into the size of the product, suggesting alternative splice products of the same gene or repetitive sequence motifs. The variance in size of a gene product can also indicate deletions or errors in transcript processing. By altering the probe target used along the known sequence it is possible to determine which region of the RNA is missing.\nAdvantages and disadvantages.\nAnalysis of gene expression can be done by several different methods including RT-PCR, RNase protection assays, microarrays, RNA-Seq, serial analysis of gene expression (SAGE), as well as northern blotting. Microarrays are quite commonly used and are usually consistent with data obtained from northern blots; however, at times northern blotting is able to detect small changes in gene expression that microarrays cannot. The advantage that microarrays have over northern blots is that thousands of genes can be visualized at a time, while northern blotting is usually looking at one or a small number of genes.\nA problem in northern blotting is often sample degradation by RNases (both endogenous to the sample and through environmental contamination), which can be avoided by proper sterilization of glassware and the use of RNase inhibitors such as DEPC (diethylpyrocarbonate). The chemicals used in most northern blots can be a risk to the researcher, since formaldehyde, radioactive material, ethidium bromide, DEPC, and UV light are all harmful under certain exposures. Compared to RT-PCR, northern blotting has a low sensitivity, but it also has a high specificity, which is important to reduce false positive results.\nThe advantages of using northern blotting include the detection of RNA size, the observation of alternate splice products, the use of probes with partial homology, the quality and quantity of RNA can be measured on the gel prior to blotting, and the membranes can be stored and reprobed for years after blotting.\nFor northern blotting for the detection of acetylcholinesterase mRNA the nonradioactive technique was compared to a radioactive technique and found as sensitive as the radioactive one, but requires no protection against radiation and is less time-consuming.\nReverse northern blot.\nResearchers occasionally use a variant of the procedure known as the reverse northern blot. In this procedure, the substrate nucleic acid (that is affixed to the membrane) is a collection of isolated DNA fragments, and the probe is RNA extracted from a tissue and radioactively labelled.\nThe use of DNA microarrays that have come into widespread use in the late 1990s and early 2000s is more akin to the reverse procedure, in that they involve the use of isolated DNA fragments affixed to a substrate, and hybridization with a probe made from cellular RNA. Thus the reverse procedure, though originally uncommon, enabled northern analysis to evolve into gene expression profiling, in which many (possibly all) of the genes in an organism may have their expression monitored.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21932", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=21932", "title": "Narrow-gauge railway", "text": "Railway line with a width less than the standard\nA narrow-gauge railway (narrow-gauge railroad in the US) is a railway with a track gauge (distance between the rails) narrower than . Most narrow-gauge railways are between and .\nSince narrow-gauge railways are usually built with tighter curves, smaller structure gauges, and lighter rails, they can be less costly to build, equip, and operate than standard- or broad-gauge railways (particularly in mountainous or difficult terrain). Lower-cost narrow-gauge railways are often used in mountainous terrain, where engineering savings can be substantial. Lower-cost narrow-gauge railways are often built to serve industries as well as sparsely populated communities where the traffic potential would not justify the cost of a standard- or broad-gauge line. Narrow-gauge railways have specialised use in mines and other environments where a small structure gauge necessitates a small loading gauge.\nIn some countries, narrow gauge is the standard: Japan, Indonesia, Taiwan, New Zealand, South Africa, and the Australian states of Queensland, Western Australia and Tasmania have a gauge, whereas Vietnam, Malaysia and Thailand have metre-gauge railways. Narrow-gauge trams, particularly metre-gauge, are common in Europe. Non-industrial, narrow-gauge mountain railways are (or were) common in the Rocky Mountains of the United States and the Pacific Cordillera of Canada, Mexico, Switzerland, Bulgaria, the former Yugoslavia, Greece, and Costa Rica.\nNomenclature.\nA narrow-gauge railway is one where the distance between the inside edges of the rails is less than . Historically, the term was sometimes used to refer to what are now standard-gauge railways, to distinguish them from broad-gauge railways, but this use no longer applies.\nHistory.\nEarly hand-worked lines.\nThe earliest recorded railway appears in Georgius Agricola's 1556 \"De re metallica\", which shows a mine in Bohemia with a railway of about gauge. During the 16th century, railways were primarily restricted to hand-pushed, narrow-gauge lines in mines throughout Europe. In the 17th century, mine railways were extended to provide transportation above ground. These lines were industrial, connecting mines with nearby transportation points (usually canals or other waterways). These railways were usually built to the same narrow gauge as the mine railways from which they developed.\nIntroduction of steam.\nThe world's first steam locomotive, built in 1802 by Richard Trevithick for the Coalbrookdale Company, ran on a plateway. The first commercially successful steam locomotive was Matthew Murray's Salamanca built in 1812 for the Middleton Railway in Leeds. Salamanca was also the first rack-and-pinion locomotive. During the 1820s and 1830s, a number of industrial narrow-gauge railways in the United Kingdom used steam locomotives. In 1842, the first narrow-gauge steam locomotive outside the UK was built for the -gauge Antwerp-Ghent Railway in Belgium. The first use of steam locomotives on a public, passenger-carrying narrow-gauge railway was in 1865, when the Ffestiniog Railway introduced passenger service after receiving its first locomotives two years earlier.\nIndustrial use.\nMany narrow-gauge railways were part of industrial enterprises and served primarily as industrial railways, rather than general carriers. Common uses for these industrial narrow-gauge railways included mining, logging, construction, tunnelling, quarrying, and conveying agricultural products. Extensive narrow-gauge networks were constructed in many parts of the world; 19th-century mountain logging operations often used narrow-gauge railways to transport logs from mill to market. Significant sugarcane railways still operate in Cuba, Fiji, Java, the Philippines, and Queensland, and narrow-gauge railway equipment remains in common use for building tunnels.\nIntroduction of internal combustion.\nIn 1897, a manganese mine in the Lahn valley in Germany was using two benzine-fueled locomotives with single cylinder internal combustion engines on the 500mm gauge tracks of their mine railway; these locomotives were made by the Deutz Gas Engine Company (\"Gasmotorenfabrik Deutz\"), now Deutz AG. Another early use of internal combustion was to power a narrow-gauge locomotive was in 1902. F. C. Blake built a 7\u00a0hp petrol locomotive for the Richmond Main Sewerage Board sewage plant at Mortlake. This gauge locomotive was probably the third petrol-engined locomotive built.\nFirst World War and later.\nExtensive narrow-gauge rail systems served the front-line trenches of both sides in World War I. They were a short-lived military application, and after the war the surplus equipment created a small boom in European narrow-gauge railway building.\nImprovements.\nHeavy-duty tracks.\nThe heavy-duty narrow-gauge railways in Australia (Queensland, South Australia, Western Australia. Tasmania), New Zealand, South Africa, Japan, Taiwan, Indonesia and the Philippines demonstrate that if track is built to a heavy-duty standard, performance almost as good as a standard-gauge line is possible.\nTwo-hundred-car trains operate on the Sishen\u2013Saldanha railway line in South Africa, and high-speed Tilt Trains run in Queensland. In South Africa and New Zealand, the loading gauge is similar to the restricted British loading gauge; in New Zealand, some British Rail Mark 2 carriages have been rebuilt with new bogies for use by Tranz Scenic (Wellington-Palmerston North service), Tranz Metro (Wellington-Masterton service), and Auckland One Rail (Auckland suburban services).\nAnother example of a heavy-duty narrow-gauge line is Brazil's EFVM. At gauge, it has over-100-pound rail () and a loading gauge almost as large as US non-excess-height lines. The line has a number of locomotives and 200-plus-car trains.\nFastest trains.\nNarrow gauge's reduced stability means that its trains cannot run at speeds as high as on broader gauges. For example, if a curve with standard-gauge rail (1435 mm) can allow speed up to , the same curve with narrow-gauge rail (1067mm) can only allow speed up to .\nIn Japan and Queensland, recent permanent-way improvements have allowed trains on gauge tracks to exceed . Queensland Rail's Electric Tilt Train, the fastest train in Australia and the fastest gauge train in the world, set a record of . The speed record for narrow-gauge rail is , set in South Africa in 1978.\nA special gauge railcar was built for the Otavi Mining and Railway Company with a design speed of .\nCurve radius is also important for high speeds: narrow-gauge railways allow sharper curves, but these limit a vehicle's safe speed.\nGauges.\nMany narrow gauges, from gauge to gauge, are in present or former use. They fall into several broad categories:\n4 ft 6 in gauge.\n track gauge (also known as Scotch gauge) was adopted by early 19th-century railways, primarily in the Lanarkshire area of Scotland. lines were also constructed, and both were eventually converted to standard gauge.\nAround 4 ft gauge.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n3 ft 6 in gauge.\n between the inside of the rail heads, its name and classification vary worldwide and it has about of track.\nMetre gauge and Italian metre gauge.\nAs its name implies, metre gauge is a track gauge of . It has about of track.\nAccording to Italian law, track gauges in Italy were defined from the centre of each rail rather than the inside edges of the rails. This gauge, measured between the edges of the rails, is known as Italian metre gauge.\n3 ft, 900 mm, and Swedish three-foot gauge.\nThere were a number of large railroad systems in North America; notable examples include the Denver &amp; Rio Grande and Rio Grande Southern in Colorado; the Texas and St. Louis Railway in Texas, Arkansas and Missouri; and, the South Pacific Coast, White Pass and Yukon Route and West Side Lumber Co of California. was also a common track gauge in South America, Ireland and on the Isle of Man. was a common gauge in Europe. Swedish three-foot-gauge railways () are unique to that country and were once common all over the country. Today the only 891\u00a0mm line that remains apart from heritage railways is Roslagsbanan, a commuter line that connects Stockholm to its northeastern suburbs.\n2 ft 9 in gauge.\nA few railways and tramways were built to gauge, including Nankai Main Line (later converted to ), Ocean Pier Railway at Atlantic City, Seaton Tramway (converted from ) and Waiorongomai Tramway.\n800 mm, 2 ft 6 in, Bosnian and 750 mm gauge.\n gauge railways are commonly used for rack railways. Imperial gauge railways were generally constructed in the former British colonies. Bosnian gauge and railways are predominantly found in Russia and Eastern Europe.\nBetween and gauge.\nGauges such as , and were used in parts of the UK, particularly for railways in Wales and the borders, with some industrial use in the coal industry. Some sugar cane lines in Cuba were .\n2 ft and 600 mm gauges.\n gauge railways were generally constructed in the former British colonies. The US had a number of railways of that gauge, including several in the state of Maine such as the Wiscasset, Waterville and Farmington Railway. , and were used in Europe.\nMinimum gauge.\nGauges below were rare. Arthur Percival Heywood developed gauge estate railways in Britain and Decauville produced a range of industrial railways running on and tracks, most commonly in restricted environments such as underground mine railways, parks and farms, in France. Several gauge railways were built in Britain to serve ammunition depots and other military facilities, particularly during World War I.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21933", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=21933", "title": "Neutron activation analysis", "text": "Method used for determining the concentrations of elements in many materials\nNeutron activation analysis (NAA) is a nuclear process used for determining the concentrations of elements in many materials. NAA allows discrete sampling of elements as it disregards the chemical form of a sample, and focuses solely on atomic nuclei. The method is based on neutron activation and thus requires a neutron source. The sample is bombarded with neutrons, causing its constituent elements to form radioactive isotopes. The radioactive emissions and radioactive decay paths for each element have long been studied and determined. Using this information, it is possible to study spectra of the emissions of the radioactive sample, and determine the concentrations of the various elements within it. A particular advantage of this technique is that it does not destroy the sample, and thus has been used for the analysis of works of art and historical artifacts. NAA can also be used to determine the activity of a radioactive sample.\nIf NAA is conducted directly on irradiated samples it is termed instrumental neutron activation analysis (INAA). In some cases, irradiated samples are subjected to chemical separation to remove interfering species or to concentrate the radioisotope of interest; this technique is known as radiochemical neutron activation analysis (RNAA).\nNAA can perform non-destructive analyses on solids, liquids, suspensions, slurries, and gases with no or minimal preparation. Due to the penetrating nature of incident neutrons and resultant gamma rays, the technique provides a true bulk analysis. As different radioisotopes have different half-lives, counting can be delayed to allow interfering species to decay eliminating interference. Until the introduction of ICP-AES and PIXE, NAA was the standard analytical method for performing multi-element analyses with minimum detection limits in the sub-ppm range. Accuracy of NAA is in the region of 5%, and relative precision is often better than 0.1%. There are two noteworthy drawbacks to the use of NAA; even though the technique is essentially non-destructive, the irradiated sample will remain radioactive for many years after the initial analysis, requiring handling and disposal protocols for low-level to medium-level radioactive material; also, the number of suitable activation nuclear reactors is declining; with a lack of irradiation facilities, the technique has declined in popularity and become more expensive.\nOverview.\nNeutron activation analysis is a sensitive multi-element analytical technique used for both qualitative and quantitative analysis of major, minor, trace and rare elements. NAA was discovered in 1936 by Hevesy and Levi, who found that samples containing certain rare-earth elements became highly radioactive after exposure to a source of neutrons. This observation led to the use of induced radioactivity for the identification of elements. NAA is significantly different from other spectroscopic analytical techniques in that it is based not on electronic transitions but on nuclear transitions. To carry out an NAA analysis, the specimen is placed into a suitable irradiation facility and bombarded with neutrons. This creates artificial radioisotopes of the elements present. Following irradiation, the artificial radioisotopes decay with emission of particles or, more importantly gamma rays, which are characteristic of the element from which they were emitted.\nFor the NAA procedure to be successful, the specimen or sample must be selected carefully. In many cases small objects can be irradiated and analysed intact without the need of sampling. But, more commonly, a small sample is taken, usually by drilling in an inconspicuous place. About 50\u00a0mg (one-twentieth of a gram) is a sufficient sample, so damage to the object is minimised. It is often good practice to remove two samples using two different drill bits made of different materials. This will reveal any contamination of the sample from the drill bit material itself. The sample is then encapsulated in a vial made of either high purity linear polyethylene or quartz. These sample vials come in many shapes and sizes to accommodate many specimen types. The sample and a standard are then packaged and irradiated in a suitable reactor at a constant, known neutron flux. A typical reactor used for activation uses uranium fission, providing a high neutron flux and the highest available sensitivities for most elements. The neutron flux from such a reactor is in the order of 1012 neutrons cm\u22122 s\u22121. The type of neutrons generated are of relatively low kinetic energy (KE), typically less than 0.5 eV. These neutrons are termed thermal neutrons. Upon irradiation, a thermal neutron interacts with the target nucleus via a non-elastic collision, causing neutron capture. This collision forms a compound nucleus which is in an excited state. The excitation energy within the compound nucleus is formed from the binding energy of the thermal neutron with the target nucleus. This excited state is unfavourable and the compound nucleus will almost instantaneously de-excite (transmutate) into a more stable configuration through the emission of a prompt particle and one or more characteristic prompt gamma photons. In most cases, this more stable configuration yields a radioactive nucleus. The newly formed radioactive nucleus now decays by the emission of both particles and one or more characteristic delayed gamma photons. This decay process is at a much slower rate than the initial de-excitation and is dependent on the unique half-life of the radioactive nucleus. These unique half-lives are dependent upon the particular radioactive species and can range from fractions of a second to several years. Once irradiated, the sample is left for a specific decay period, then placed into a detector, which will measure the nuclear decay according to either the emitted particles, or more commonly, the emitted gamma rays.\nVariations.\nNAA can vary according to a number of experimental parameters. The kinetic energy of the neutrons used for irradiation will be a major experimental parameter. The above description is of activation by slow neutrons, slow neutrons are fully moderated within the reactor and have KE &lt;0.5 eV. Medium KE neutrons may also be used for activation, these neutrons have been only partially moderated and have KE of 0.5 eV to 0.5 MeV, and are termed epithermal neutrons. Activation with epithermal neutrons is known as Epithermal NAA (ENAA). High KE neutrons are sometimes used for activation, these neutrons are unmoderated and consist of primary fission neutrons. High KE or fast neutrons have a KE &gt;0.5 MeV. Activation with fast neutrons is termed Fast NAA (FNAA).\nAnother major experimental parameter is whether nuclear decay products (gamma rays or particles) are measured during neutron irradiation (prompt gamma), or at some time after irradiation (delayed gamma, DGNAA). PGNAA is generally performed by using a neutron stream tapped off the nuclear reactor via a beam port. Neutron fluxes from beam ports are the order of 106 times weaker than inside a reactor. This is somewhat compensated for by placing the detector very close to the sample reducing the loss in sensitivity due to low flux. PGNAA is generally applied to elements with extremely high neutron capture cross-sections; elements which decay too rapidly to be measured by DGNAA; elements that produce only stable isotopes; or elements with weak decay gamma ray intensities. PGNAA is characterised by short irradiation times and short decay times, often in the order of seconds and minutes.\nDGNAA is applicable to the vast majority of elements that form artificial radioisotopes. DG analyses are often performed over days, weeks or even months. This improves sensitivity for long-lived radionuclides as it allows short-lived radionuclide to decay, effectively eliminating interference. DGNAA is characterised by long irradiation times and long decay times, often in the order of hours, weeks or longer.\nNeutron sources.\nA range of different sources can be used:\nReactors.\nSome reactors are used for the neutron irradiation of samples for radioisotope production for a range of purposes. The sample can be placed in an irradiation container which is then placed in the reactor; if epithermal neutrons are required for the irradiation then cadmium can be used to filter out the thermal neutrons.\nFusors.\nA relatively simple Farnsworth\u2013Hirsch fusor can be used to generate neutrons for NAA experiments. The advantages of this kind of apparatus is that it is compact, often benchtop-sized, and that it can simply be turned off and on. A disadvantage is that this type of source will not produce the neutron flux that can be obtained using a reactor.\nIsotope sources.\nFor many workers in the field, a reactor is an item which is too expensive; instead, it is common to use a neutron source which uses a combination of an alpha emitter and beryllium. These sources tend to be much weaker than reactors.\nGas discharge tubes.\nThese can be used to create pulses of neutrons, they have been used for some activation work where the decay of the target isotope is very rapid. For instance in oil wells.\nDetectors.\nThere are a number of detector types and configurations used in NAA. Most are designed to detect the emitted gamma radiation. The most common types of gamma detectors encountered in NAA are the gas ionisation type, scintillation type and the semiconductor type. Of these the scintillation and semiconductor type are the most widely employed. There are two detector configurations utilised, they are the planar detector, used for PGNAA and the well detector, used for DGNAA. The planar detector has a flat, large collection surface area and can be placed close to the sample. The well detector \u2018surrounds\u2019 the sample with a large collection surface area.\nScintillation-type detectors use a radiation-sensitive crystal, most commonly thallium-doped sodium iodide (NaI(Tl)), which emits light when struck by gamma photons. These detectors have excellent sensitivity and stability, and a reasonable resolution.\nSemiconductor detectors utilise the semiconducting element germanium. The germanium is processed to form a p-i-n (positive-intrinsic-negative) diode, and when cooled to ~77 K by liquid nitrogen to reduce dark current and detector noise, produces a signal which is proportional to the photon energy of the incoming radiation. There are two types of germanium detector, the lithium-drifted germanium or Ge(Li) (pronounced \u2018jelly\u2019), and the high-purity germanium or HPGe.\nThe semiconducting element silicon may also be used but germanium is preferred, as its higher atomic number makes it more efficient at stopping and detecting high energy gamma rays. Both Ge(Li) and HPGe detectors have excellent sensitivity and resolution, but Ge(Li) detectors are unstable at room temperature, with the lithium drifting into the intrinsic region ruining the detector. The development of undrifted high purity germanium has overcome this problem.\nParticle detectors can also be used to detect the emission of alpha (\u03b1) and beta (\u03b2) particles which often accompany the emission of a gamma photon but are less favourable, as these particles are only emitted from the surface of the sample and are often absorbed or attenuated by atmospheric gases requiring expensive vacuum conditions to be effectively detected. Gamma rays, however, are not absorbed or attenuated by atmospheric gases, and can also escape from deep within the sample with minimal absorption.\nAnalytical capabilities.\nNAA can detect up to 74 elements depending upon the experimental procedure, with minimum detection limits ranging from 0.1 to 1 million ng/g depending on element under investigation. Heavier elements have larger nuclei, therefore they have a larger neutron capture cross-section and are more likely to be activated. Some nuclei can capture a number of neutrons and remain relatively stable, not undergoing transmutation or decay for many months or even years. Other nuclei decay instantaneously or form only stable isotopes and can only be identified by PGNAA.\nApplications.\nNeutron Activation Analysis has a wide variety of applications including within the fields of archaeology, soil science, geology, forensics, and the semiconductor industry. Forensically, hairs subjected to a detailed forensic neutron analysis to determine whether they had sourced from the same individuals was first used in the trial of John Norman Collins.\nArchaeologists use NAA in order to determine the elements that comprise certain artifacts. This technique is used because it is nondestructive and it can relate an artifact to its source by its chemical signature. This method has proven to be very successful at determining trade routes, particularly for obsidian, with the ability of NAA to distinguish between chemical compositions. In agricultural processes, the movement of fertilizers and pesticides is influenced by surface and subsurface movement as it infiltrates the water supplies. In order to track the distribution of the fertilizers and pesticides, bromide ions in various forms are used as tracers that move freely with the flow of water while having minimal interaction with the soil. Neutron activation analysis is used to measure bromide so that extraction is not necessary for analysis. NAA is used in geology to aid in researching the processes that formed the rocks through the analysis of the rare-earth elements and trace elements. It also assists in locating ore deposits and tracking certain elements. Neutron activation analysis is also used to create standards in the semiconductor industry. Semiconductors require a high level of purity, with contamination significantly reducing the quality of the semiconductor. NAA is used to detect trace impurities and establish contamination standards, because it involves limited sample handling and high sensitivity."}
{"id": "21935", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=21935", "title": "Nondeterministic Turing machine", "text": "Theoretical model of computation\nIn theoretical computer science, a nondeterministic Turing machine (NTM) is a theoretical model of computation whose governing rules specify more than one possible action when in some given situations. That is, an NTM's next state is \"not\" completely determined by its action and the current symbol it sees, unlike a deterministic Turing machine.\nNTMs are sometimes used in thought experiments to examine the abilities and limits of computers. One of the most important open problems in theoretical computer science is the P versus NP problem, which (among other equivalent formulations) concerns the question of how difficult it is to simulate nondeterministic computation with a deterministic computer.\nBackground.\nIn essence, a Turing machine is imagined to be a simple computer that reads and writes symbols one at a time on an endless tape by strictly following a set of rules. It determines what action it should perform next according to its internal \"state\" and \"what symbol it currently sees\". An example of one of a Turing Machine's rules might thus be: \"If you are in state 2 and you see an 'A', then change it to 'B', move left, and switch to state 3.\"\nDeterministic Turing machine.\nIn a deterministic Turing machine (DTM), the set of rules prescribes at most one action to be performed for any given situation.\nA deterministic Turing machine has a \"transition function\" that, for a given state and symbol under the tape head, specifies three things: \nFor example, an X on the tape in state 3 might make the DTM write a Y on the tape, move the head one position to the right, and switch to state 5.\nDescription.\nIn contrast to a deterministic Turing machine, in a nondeterministic Turing machine (NTM) the set of rules may prescribe more than one action to be performed for any given situation. For example, an X on the tape in state 3 might allow the NTM to:\nor\nBecause there can be multiple actions that can follow from a given situation, there can be multiple possible sequences of steps that the NTM can take starting from a given input. If at least one of these possible sequences leads to an \"accept\" state, the NTM is said to accept the input. While a DTM has a single \"computation path\" that it follows, an NTM has a \"computation tree\".\nFormal definition.\nA nondeterministic Turing machine can be formally defined as a six-tuple formula_1, where\nThe difference with a standard (deterministic) Turing machine is that, for deterministic Turing machines, the transition relation is a function rather than just a relation.\nConfigurations and the \"yields\" relation on configurations, which describes the possible actions of the Turing machine given any possible contents of the tape, are as for standard Turing machines, except that the \"yields\" relation is no longer single-valued. (If the machine is deterministic, the possible computations are all prefixes of a single, possibly infinite, path.)\nThe input for an NTM is provided in the same manner as for a deterministic Turing machine: the machine is started in the configuration in which the tape head is on the first character of the string (if any), and the tape is all blank otherwise.\nAn NTM accepts an input string if and only if \"at least one\" of the possible computational paths starting from that string puts the machine into an accepting state. When simulating the many branching paths of an NTM on a deterministic machine, we can stop the entire simulation as soon as \"any\" branch reaches an accepting state.\nAlternative definitions.\nAs a mathematical construction used primarily in proofs, there are a variety of minor variations on the definition of an NTM, but these variations all accept equivalent languages.\nThe head movement in the output of the transition relation is often encoded numerically instead of using letters to represent moving the head Left (-1), Stationary (0), and Right (+1); giving a transition function output of formula_11. It is common to omit the stationary (0) output, and instead insert the transitive closure of any desired stationary transitions.\nSome authors add an explicit \"reject\" state,\nwhich causes the NTM to halt without accepting. This definition still retains the asymmetry that \"any\" nondeterministic branch can accept, but \"every\" branch must reject for the string to be rejected.\nComputational equivalence with DTMs.\nAny computational problem that can be solved by a DTM can also be solved by a NTM, and vice versa. However, it is believed that in general the time complexity may not be the same.\nDTM as a special case of NTM.\nNTMs include DTMs as special cases, so every computation that can be carried out by a DTM can also be carried out by the equivalent NTM.\nDTM simulation of NTM.\nIt might seem that NTMs are more powerful than DTMs, since they can allow trees of possible computations arising from the same initial configuration, accepting a string if any one branch in the tree accepts it. However, it is possible to simulate NTMs with DTMs, and in fact this can be done in more than one way.\nMultiplicity of configuration states.\nOne approach is to use a DTM of which the configurations represent multiple configurations of the NTM, and the DTM's operation consists of visiting each of them in turn, executing a single step at each visit, and spawning new configurations whenever the transition relation defines multiple continuations.\nMultiplicity of tapes.\nAnother construction simulates NTMs with 3-tape DTMs, of which the first tape always holds the original input string, the second is used to simulate a particular computation of the NTM, and the third encodes a path in the NTM's computation tree. The 3-tape DTMs are easily simulated with a normal single-tape DTM.\nTime complexity and P versus NP.\nIn the second construction, the constructed DTM effectively performs a breadth-first search of the NTM's computation tree, visiting all possible computations of the NTM in order of increasing length until it finds an accepting one. Therefore, the length of an accepting computation of the DTM is, in general, exponential in the length of the shortest accepting computation of the NTM. This is believed to be a general property of simulations of NTMs by DTMs. The P = NP problem, the most famous unresolved question in computer science, concerns one case of this issue: whether or not every problem solvable by a NTM in polynomial time is necessarily also solvable by a DTM in polynomial time.\nBounded nondeterminism.\nAn NTM has the property of bounded nondeterminism. That is, if an NTM always halts on a given input tape \"T\" then it halts in a bounded number of steps, and therefore can only have a bounded number of possible configurations.\nComparison with quantum computers.\nBecause quantum computers use quantum bits, which can be in superpositions of states, rather than conventional bits, there is sometimes a misconception that quantum computers are NTMs. However, it is believed by experts (but has not been proven) that the power of quantum computers is, in fact, incomparable to that of NTMs; that is, problems likely exist that an NTM could efficiently solve that a quantum computer cannot and vice versa. In particular, it is likely that NP-complete problems are solvable by NTMs but not by quantum computers in polynomial time.\nIntuitively speaking, while a quantum computer can indeed be in a superposition state corresponding to all possible computational branches having been executed at the same time (similar to an NTM), the final measurement will collapse the quantum computer into a randomly selected branch. This branch then does not, in general, represent the sought-for solution, unlike the NTM, which is allowed to pick the right solution among the exponentially many branches.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21936", "revid": "50236370", "url": "https://en.wikipedia.org/wiki?curid=21936", "title": "Notus", "text": "South wind god in Greek mythology\nIn Greek mythology and religion, Notus () is the god of the south wind and one of the Anemoi (wind-gods), sons of the dawn goddess Eos and the star-god Astraeus. A desiccating wind of heat, Notus was associated with the storms of late summer and early autumn, wetness, mist, and was seen as a rain-bringer. Unlike his two more notable brothers, Boreas (the god of the north wind) and Zephyrus (the god of the west wind), Notus has little to no unique mythology of his own.\nEtymology.\nThe Greek noun refers both to the south cardinal direction and the south wind that blows from it. Its ultimate etymology remains unknown, although a pre-Greek origin seems to be the most likely origin.\nFamily.\nIn Hesiod's \"Theogony\", Notus is the son of Eos, the goddess of the dawn, and Astraeus, her husband. He is the sibling of the other winds, who Hesiod lists as Zephyrus and Boreas. Thus, he is brother to the stars and the justice goddess Astraea, and half-brother to the mortals Memnon and Emathion, sons of his mother Eos by the Trojan prince Tithonus. Notus has no known consorts, lovers or offspring.\nThe ancient Greeks distinguished the three types of wind blowing from the south; the first was notos (the one Notus mostly represents) which blew from various directions in winter and was seen as the rain-bringer that obscured visibility, the second was leukonotos (\"white notus\") which was milder and cleared up the sky, and the third was the hot bringer of dust, identified with sirocco.\nMythology.\nNotus is one of the three wind-gods mentioned by Hesiod, alongside his brothers Boreas and Zephyrus, the three wind gods seen as beneficial by the ancient Greeks. Unlike his two more prominent brothers however, Notus has very little mythology, and mostly appears in conjugation with his brothers, with too few unique appearances to differentiate him from the rest. In his few appearances in mythology, Notus is usually paired with his full brother Eurus, the god and personification of the east wind.\nIn his preparation for the Great Deluge, Zeus locked up Boreas and the other cloud-blowing gales, and let Notus free, to rain upon the earth, who let it pour all over the globe, drowning almost everyone.\nIn the \"Odyssey\" the winds seem to dwell on the island of Aeolia, as Zeus has made Aeolus keeper of the winds. Aeolus receives Odysseus and his crew, and keeps them as guests for a month. As they part, Aeolus gives Odysseus a bag containing all the winds, except for Zephyrus; although warned not to open the bag, Odysseus's crewmates however foolishly open the bag, thinking it to contain some treasure, and set free Notus along with all the other winds as well, who then blow the ships back to Aeolia. Much later, he and Eurus strand Odysseus on Thrinacia, the island of the sun-god Helios, for an entire month.\nIn the \"Dionysiaca\" meanwhile, he and his brothers live with their father Astraeus; Notus serves water from a jug when Demeter pays a visit. In the \"Iliad\", Notus dined together with his brothers in a far away land as Iris visited to summon Boreas and Zephyrus.\nIn one of his few defining appearances, Notus features in two of the \"Dialogues of the Sea Gods\", a satirical work by Lucian of Samosata. In the first, he and Zephyrus discuss the woes of the Argive princess Io at the hands of Zeus and Hera, while in the second Zephyrus enthusiastically describes the marvellous scene of the abduction of Europa by the bull, while Notus admits in disappointment having seen nothing of note.\nIconography.\nNotus appears rarely in ancient Greek or Roman art. In the Pergamon Altar, which depicts the battle of the gods against the Giants, Notus and the other three wind gods are shown as horse-shaped deities who pull Hera's chariot; their equine form is also found in Quintus Smyrnaeus's works, where they pull Zeus instead. In the Tower of the Winds, a Roman-era octagonal clock tower in Athens, Notus is depicted in middle relief as a beardless young man emptying a water-filled pointed amphora, symbolizing rain.\nAuster.\nFor the Romans, Notus was identified with the god Auster (\"south\"), closely associated with the sirocco wind. Like Notus himself, Auster has no big role in mythology. The name, Auster, means south and is the root of words such as Australia, literally \"south land.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21937", "revid": "14650386", "url": "https://en.wikipedia.org/wiki?curid=21937", "title": "Nitrogen narcosis", "text": "Narcotic effects of respiratory nitrogen\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nNitrogen narcosis (also known as narcosis while diving, inert gas narcosis, raptures of the deep, Martini effect) is a reversible alteration in consciousness that occurs while diving at depth. It is caused by the anesthetic effect of certain gases at high partial pressure. The Greek word (nark\u014dsis), \"the act of making numb\", is derived from (nark\u0113), \"numbness, torpor\", a term used by Homer and Hippocrates. Narcosis produces a state similar to drunkenness (alcohol intoxication), or nitrous oxide inhalation. It can occur during shallow dives, but does not usually become noticeable at depths less than .\nExcept for helium and probably neon, all gases that can be breathed have a narcotic effect, although widely varying in degree. The effect is consistently greater for gases with a higher lipid solubility, and although the mechanism of this phenomenon is still not fully clear, there is good evidence that the two properties are mechanistically related. As depth increases, the mental impairment may become hazardous. Divers can learn to cope with some of the effects of narcosis, but it is impossible to develop a tolerance. Narcosis can affect all ambient pressure divers, although susceptibility varies widely among individuals and from dive to dive. The main modes of underwater diving that deal with its prevention and management are scuba diving and surface-supplied diving at depths greater than . \nNarcosis may be completely reversed in a few minutes by ascending to a shallower depth, with no long-term effects. Thus narcosis while diving in open water rarely develops into a serious problem as long as the divers are aware of its symptoms, and are able to ascend to manage it. Diving much beyond is generally considered outside the scope of recreational diving. To dive at greater depths, as narcosis and oxygen toxicity become critical risk factors, gas mixtures such as trimix or heliox are used. These mixtures prevent or reduce narcosis by replacing some or all of the inert fraction of the breathing gas with non-narcotic helium.\nThere is a synergy between carbon dioxide toxicity and inert gas narcosis which is recognised but not fully understood. Conditions where high work of breathing due to gas density occur tend to exacerbate this effect.\nClassification.\nNarcosis results from breathing gases under elevated pressure, and may be classified by the principal gas involved. The noble gases, except helium and probably neon, as well as nitrogen, oxygen and hydrogen cause a decrement in mental function, but their effect on psychomotor function (processes affecting the coordination of sensory or cognitive processes and motor activity) varies widely. The effect of carbon dioxide is a consistent diminution of mental and psychomotor function. The noble gases argon, krypton, and xenon are more narcotic than nitrogen at a given pressure, and xenon has so much anesthetic activity that it is a usable anesthetic at 80% concentration and normal atmospheric pressure. Xenon has historically been too expensive to be used very much in practice, but it has been successfully used for surgical operations, and xenon anesthesia systems are still being proposed and designed.\nSigns and symptoms.\nDue to its perception-altering effects, the onset of narcosis may be hard to recognize. At its most benign, narcosis results in relief of anxiety\u00a0\u2013 a feeling of tranquillity and mastery of the environment. These effects are essentially identical to various concentrations of nitrous oxide. They also resemble (though not as closely) the effects of alcohol and the familiar benzodiazepine drugs such as diazepam and alprazolam. Such effects are not harmful unless they cause some immediate danger to go unrecognized and unaddressed. Once stabilized, the effects generally remain the same at a given depth, only worsening if the diver ventures deeper.\nThe most dangerous aspects of narcosis are the impairment of judgement, multi-tasking and coordination, and the loss of decision-making ability and focus. Other effects include vertigo and visual or auditory disturbances. The syndrome may cause exhilaration, giddiness, extreme anxiety, depression, or paranoia, depending on the individual diver and the diver's medical or personal history. When more serious, the diver may feel overconfident, disregarding normal safe diving practices. Slowed mental activity, as indicated by increased reaction time and increased errors in cognitive function, are effects which increase the risk of a diver mismanaging an incident. Narcosis reduces both the perception of cold discomfort and shivering and thereby affects the production of body heat and consequently allows a faster drop in the core temperature in cold water, with reduced awareness of the developing problem.\nThe relation of depth to narcosis is sometimes informally known as \"Martini's law\", the idea that narcosis results in the feeling of one martini for every below depth. This is a rough guide to give new divers a comparison with a situation they may be more familiar with.\nReported signs and symptoms are summarized against typical depths in meters and feet of sea water in the following table, closely adapted from \"Deeper into Diving\" by Lippman and Mitchell:\nCauses.\nThe cause of narcosis is related to the increased solubility of gases in body tissues, as a result of the elevated pressures at depth (Henry's law). It has been suggested that inert gases dissolving in the lipid bilayer of cell membranes cause narcosis. More recently, researchers have been looking at neurotransmitter receptor protein mechanisms as a possible cause of narcosis. The breathing gas mix entering the diver's lungs will have the same pressure as the surrounding water, known as the ambient pressure. After a change of depth, the partial pressure of inert gases in the blood passing through the brain catches up with ambient pressure within a minute or two, which results in a delayed change in narcotic effect after descending to a new depth. Rapid compression potentiates narcosis owing to carbon dioxide retention.\nA divers' cognition may be affected on dives as shallow as , but the changes are not usually noticeable. There is no reliable method to predict the depth at which narcosis becomes noticeable, or the severity of the effect on an individual diver, as it may vary from dive to dive even on the same day.\nSignificant impairment due to narcosis is an increasing risk below depths of about , corresponding to an ambient pressure of about . Most sport scuba training organizations recommend depths of no more than because of the risk of narcosis. When breathing air at depths of \u00a0\u2013 an ambient pressure of about \u00a0\u2013 narcosis in most divers leads to hallucinations, loss of memory, and unconsciousness. A number of divers have died in attempts to set air depth records below . Because of these incidents, \"Guinness World Records\" no longer reports on this figure.\nNarcosis has been compared with altitude sickness regarding its variability of onset (though not its symptoms); its effects depend on many factors, with variations between individuals. Thermal cold, stress, heavy work, fatigue, and carbon dioxide retention all increase the risk and severity of narcosis. Carbon dioxide has a high narcotic potential and also causes increased blood flow to the brain, increasing the effects of other gases. Increased risk of narcosis results from increasing the amount of carbon dioxide retained through heavy exercise, shallow or skip breathing, high work of breathing, or because of poor gas exchange in the lungs.\nNarcosis is known to be additive to even minimal alcohol intoxication. Other sedative and analgesic drugs, such as opiate narcotics and benzodiazepines, add to narcosis.\nMechanism.\nThe precise mechanism is not well understood, but it appears to be the direct effect of gas dissolving into nerve membranes and causing temporary disruption in nerve transmissions. While the effect was first observed with air, other gases including argon, krypton and hydrogen cause very similar effects at higher than atmospheric pressure. Some of these effects may be due to antagonism at NMDA receptors and potentiation of GABAA receptors, similar to the mechanism of nonpolar anesthetics such diethyl ether or ethylene. However, their reproduction by the very chemically inactive gas argon makes them unlikely to be a strictly chemical bonding to receptors in the usual sense of a chemical bond. An indirect physical effect\u00a0\u2013 such as a change in membrane volume\u00a0\u2013 would therefore be needed to affect the ligand-gated ion channels of nerve cells. Trudell \"et al.\" have suggested non-chemical binding due to the attractive van der Waals force between proteins and inert gases.\nSimilar to the mechanism of ethanol's effect, the increase of gas dissolved in nerve cell membranes may cause altered ion permeability properties of the neural cells' lipid bilayers. The partial pressure of a gas required to cause a measured degree of impairment correlates well with the lipid solubility of the gas: the greater the solubility, the less partial pressure is needed.\nAn early theory, the Meyer-Overton hypothesis, suggested that narcosis happens when the gas penetrates the lipids of the brain's nerve cells, causing direct mechanical interference with the transmission of signals from one nerve cell to another. More recently, specific types of chemically gated receptors in nerve cells have been identified as being involved with anesthesia and narcosis. However, the basic and most general underlying idea, that nerve transmission is altered in many diffuse areas of the brain as a result of gas molecules dissolved in the nerve cells' fatty membranes, remains largely unchallenged.\nDiagnosis and management.\nThe symptoms of narcosis may be caused by other factors during a dive: ear problems causing disorientation or nausea; early signs of oxygen toxicity causing visual disturbances; carbon dioxide toxicity caused by rebreather scrubber malfunction, excessive work of breathing, or inappropriate breathing pattern, or hypothermia causing rapid breathing and shivering. Nevertheless, the presence of any of these symptoms can imply narcosis. Alleviation of the effects upon ascending to a shallower depth will confirm the diagnosis. Given the setting, other likely conditions do not produce reversible effects. In the event of misdiagnosis when another condition is causing the symptoms, the initial management\u00a0\u2013 ascending to a shallower depth\u00a0\u2013 is still beneficial in most cases, as it is also the appropriate response for most of the alternative causes for the symptoms. \nThe management of inert gas narcosis is usually simply to ascend to shallower depths, where much of the effect disappears within minutes. Divers carrying multiple gas mixtures will usually switch to a mixture with more helium before significant narcosis is noticeable during descent. In the event of complications or other conditions being present, ascending remains the correct initial response unless it would violate decompression obligations. Should problems persist, it may be necessary to abort the dive. The decompression schedule can and should still be followed unless other conditions require emergency assistance.\nInert gas narcosis can follow a gas switch to a decompression gas with higher nitrogen fraction during ascent, which may be confused with symptoms of decompression sickness, in a rare example of a situation in which it is not advisable to ascend immediately. If this is suspected to be the problem, it is better to switch back to the less narcotic gas if practicable, and adjust the decompression schedule to suit. This problem can be aggravated by the possibility of inert gas counterdiffusion, which is most likely to affect the inner ear, and can usually be avoided by a better selection of gas mixtures and switching depths.\nPrevention.\nThe most straightforward way to avoid nitrogen narcosis is for a diver to limit the depth of dives. The other main preventive measure is properly informed selection/choice of which gas to use for the particular dive under consideration.\nSince narcosis becomes more severe as depth increases, a diver keeping to shallower depths can avoid serious narcosis. Most recreational training agencies will only certify entry level divers to depths of , and at these depths narcosis does not present a significant risk. Further training is normally required for certification up to on air, and this training should include a discussion of narcosis, its effects, and management. Some diver training agencies offer specialized training to prepare recreational divers to go to depths of , often consisting of further theory and some practice in deep dives under close supervision. Scuba organizations that train for diving beyond recreational depths, may exclude diving with gases that cause too much narcosis at depth in the average diver (such as the typical widely used nitrox mixtures used for most recreational diving), and strongly encourage the use of other breathing gas mixes containing helium in place of some or all of the nitrogen in air\u00a0\u2013 such as trimix and heliox\u00a0\u2013 because helium has no narcotic effect. The use of these gases is considered to be technical diving and requires further training and certification.\nWhile the individual diver cannot predict exactly at what depth the onset of narcosis will occur on a given day, the first symptoms of narcosis for any given diver are often more predictable and personal. For example, one diver may have trouble with eye focus (close accommodation for middle-aged divers), another may experience feelings of euphoria, and another feelings of claustrophobia. Some divers report that they have hearing changes, and that the sound their exhaled bubbles make becomes different. Specialist training may help divers to identify these personal onset signs, which may then be used as a signal to ascend to avoid the narcosis, although severe narcosis may interfere with the judgement necessary to take preventive action.\nDeep dives should be made only after a gradual work-up to test the individual diver's sensitivity to increasing depths, taking note of reactions. Scientific evidence does not show that a diver can develop a resistance to the effects of narcosis at a given depth or become tolerant of it.\nEquivalent narcotic depth (END) is a commonly used way of expressing the narcotic effect of different breathing gases. The National Oceanic and Atmospheric Administration (NOAA) Diving Manual now states that oxygen and nitrogen should be considered equally narcotic. Standard tables, based on relative lipid solubilities, list conversion factors for narcotic effect of other gases. For example, hydrogen at a given pressure has a narcotic effect equivalent to nitrogen at 0.55 times that pressure, so in principle it should be usable at more than twice the depth. Argon, however, has 2.33 times the narcotic effect of nitrogen, and is a poor choice as a breathing gas for diving (it is used as a drysuit inflation gas, owing to its low thermal conductivity). Some gases have other dangerous effects when breathed at pressure; for example, high-pressure oxygen can lead to oxygen toxicity. Although helium is the least intoxicating of the breathing gases, at greater depths it can cause high-pressure nervous syndrome, a still mysterious but apparently unrelated phenomenon. Inert gas narcosis is only one factor influencing the choice of gas mixture; the risks of decompression sickness and oxygen toxicity, work of breathing, cost, and other factors are also important.\nBecause of similar and additive effects, divers should avoid sedating medications and drugs, such as cannabis and alcohol before any dive. A hangover, combined with the reduced physical capacity that goes with it, makes nitrogen narcosis more likely. Experts recommend total abstinence from alcohol for at least 12 hours before diving, and longer for other drugs.\nPrognosis and epidemiology.\nNarcosis is potentially one of the most dangerous conditions to affect the scuba diver below about . Except for occasional amnesia of events at depth, the effects of narcosis are entirely removed on ascent and therefore pose no problem in themselves, even for repeated, chronic or acute exposure. Nevertheless, the severity of narcosis is unpredictable and it can be fatal while diving, as the result of inappropriate behavior in a dangerous environment.\nTests have shown that all divers are affected by nitrogen narcosis, though some experience lesser effects than others. Even though it is possible that some divers can manage better than others because of learning to cope with the subjective impairment, the underlying behavioral effects remain. These effects are particularly dangerous because a diver may feel they are not experiencing narcosis, yet still be affected by it.\nHistory.\nFrench researcher Victor T. Junod was the first to describe symptoms of narcosis in 1834, noting \"the functions of the brain are activated, imagination is lively, thoughts have a peculiar charm and, in some persons, symptoms of intoxication are present.\" Junod suggested that narcosis resulted from pressure causing increased blood flow and hence stimulating nerve centers. Walter Moxon (1836\u20131886), a prominent Victorian physician, hypothesized in 1881 that pressure forced blood to inaccessible parts of the body and the stagnant blood then resulted in emotional changes. The first report of anesthetic potency being related to lipid solubility was published by Hans H. Meyer in 1899, entitled \"Zur Theorie der Alkoholnarkose\". Two years later a similar theory was published independently by Charles Ernest Overton. What became known as the Meyer-Overton hypothesis may be illustrated by a graph comparing narcotic potency with solubility in oil.\nIn 1939, Albert R. Behnke and O. D. Yarborough demonstrated that gases other than nitrogen also could cause narcosis. For an inert gas the narcotic potency was found to be proportional to its lipid solubility. As hydrogen has only 0.55 the solubility of nitrogen, deep diving experiments using hydrox were conducted by Arne Zetterstr\u00f6m between 1943 and 1945. Jacques-Yves Cousteau in 1953 famously described it as \"l'ivresse des grandes profondeurs\" or the \"rapture of the deep\".\nFurther research into the possible mechanisms of narcosis by anesthetic action led to the \"minimum alveolar concentration\" concept in 1965. This measures the relative concentration of different gases required to prevent motor response in 50% of subjects in response to stimulus, and shows similar results for anesthetic potency as the measurements of lipid solubility. The (NOAA) Diving Manual was revised to recommend treating oxygen as if it were as narcotic as nitrogen, following research by Christian J. Lambertsen \"et al.\" in 1977 and 1978, but this hypothesis has been challenged by more recent work.\nA study on the effects of the environment on inert gas narcosis published by Laf\u00e8re et al. in 2016 concluded that pressure and gas composition may be the only significant external factors influencing inert gas narcosis. It also found that the onset of narcosis follows a short period of raised alertness during descent, and some of the effects persist for at least 30 minutes after the dive.\nAs of about 2020, research using critical flicker fusion frequency (CFFF) and EEG functional connectivity has shown sensitivity to nitrogen narcosis, but is not sensitive to helium partial pressure, in laboratory trials.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21938", "revid": "34387623", "url": "https://en.wikipedia.org/wiki?curid=21938", "title": "Neoproterozoic", "text": "Third and last era of the Proterozoic Eon\nThe Neoproterozoic is the last of the three geologic eras of the Proterozoic eon, spanning from 1 billion to million years ago, and is the last era of the Precambrian \"supereon\". It is preceded by the Mesoproterozoic era and succeeded by the Paleozoic era of the Phanerozoic eon, and is further subdivided into three periods, the Tonian, Cryogenian and Ediacaran.\nOne of the most severe glaciation events known in the geologic record occurred during the Cryogenian period of the Neoproterozoic, when global ice sheets may have reached the equator and created a \"Snowball Earth\" lasting about 100\u00a0million years. The earliest fossils of complex life are found in the Tonian period in the form of \"Otavia\", a primitive sponge, and the earliest fossil evidence of metazoan radiation are found in the Ediacaran period, which included the namesaked Ediacaran biota as well as the oldest definitive cnidarians and bilaterians in the fossil record.\nAccording to Rino and co-workers, the sum of the continental crust formed in the Pan-African orogeny and the Grenville orogeny makes the Neoproterozoic the period of Earth's history that has produced most continental crust.\nGeology.\nAt the onset of the Neoproterozoic the supercontinent Rodinia, which had assembled during the late Mesoproterozoic, straddled the equator. During the Tonian, rifting commenced which broke Rodinia into a number of individual land masses.\nPossibly as a consequence of the low-latitude position of most continents, several large-scale glacial events occurred during the Neoproterozoic Era including the Sturtian and Marinoan glaciations of the Cryogenian Period.\nThese glaciations are believed to have been so severe that there were ice sheets at the equator\u2014a state known as the \"Snowball Earth\".\nSubdivisions.\nNeoproterozoic time is subdivided into the Tonian (1000\u2013720 Ma), Cryogenian (720\u2013635 Ma) and Ediacaran (635\u2013538.8 Ma) periods.\nRussian regional timescale.\nIn the regional timescale of Russia, the Tonian and Cryogenian correspond to the Late Riphean; the Ediacaran corresponds to the Early to middle Vendian. Russian geologists divide the Neoproterozoic of Siberia into the Mayanian (from 1000 to 850 Ma) followed by the Baikalian (from 850 to 650 Ma).\nPaleobiology.\nThe idea of the Neoproterozoic Era was introduced in the 1960s. Nineteenth-century paleontologists set the start of multicellular life at the first appearance of hard-shelled arthropods called trilobites and archeocyathid sponges at the beginning of the Cambrian Period. In the early 20th century, paleontologists started finding fossils of multicellular animals that predated the Cambrian. A complex fauna was found in South West Africa in the 1920s but was inaccurately dated. Another fauna was found in South Australia in the 1940s, but it was not thoroughly examined until the late 1950s. Other possible early animal fossils were found in Russia, England, Canada, and elsewhere (see Ediacaran biota). Some were determined to be pseudofossils, but others were revealed to be members of rather complex biotas that remain poorly understood. At least 25 regions worldwide have yielded metazoan fossils older than the classical Precambrian\u2013Cambrian boundary (which is currently dated at https://\u00a0million years ago).\nA few of the early animals appear possibly to be ancestors of modern animals. Most fall into ambiguous groups of frond-like organisms; discoids that might be holdfasts for stalked organisms (\"medusoids\"); mattress-like forms; small calcareous tubes; and armored animals of unknown provenance.\nThese were most commonly known as Vendian biota until the formal naming of the Period, and are currently known as Ediacaran Period biota. Most were soft bodied. The relationships, if any, to modern forms are obscure. Some paleontologists relate many or most of these forms to modern animals. Others acknowledge a few possible or even likely relationships but feel that most of the Ediacaran forms are representatives of unknown animal types.\nIn addition to Ediacaran biota, two other types of biota were discovered in China. The Doushantuo Formation (of Ediacaran age) preserves fossils of microscopic marine organisms in great detail. The Huainan biota (of late Tonian age) consists of small worm-shaped organisms.\nMolecular phylogeny suggests that animals may have emerged even earlier in the Neoproterozoic (early Tonian), but physical evidence for such animal life is lacking. Possible keratose sponge fossils have been reported in reefs dated to c. 890 million years before the present, but remain unconfirmed.\nThe widespread proliferation of marine algae during the Neoproterozoic caused an increased flux of algal particulate matter to benthic environments, stimulating the evolution of microbial eukaryotic predators.\nTerminal period.\nThe nomenclature for the terminal period of the Neoproterozoic Era has been unstable. Russian and Nordic geologists referred to the last period of the Neoproterozoic as the Vendian, while Chinese geologists referred to it as the Sinian, and most Australians and North Americans used the name Ediacaran.\nHowever, in 2004, the International Union of Geological Sciences ratified the Ediacaran Period to be a geological age of the Neoproterozoic, ranging from to (at the time to 542) million years ago. The Ediacaran Period boundaries are the only Precambrian boundaries defined by biologic Global Boundary Stratotype Section and Points, rather than the absolute Global Standard Stratigraphic Ages.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21939", "revid": "6326132", "url": "https://en.wikipedia.org/wiki?curid=21939", "title": "National Security Agency", "text": "U.S. signals intelligence organization\nThe National Security Agency (NSA) is an intelligence agency of the United States Department of Defense, under the authority of the director of national intelligence (DNI). The NSA is responsible for global monitoring, collection, and processing of information and data for global intelligence and counterintelligence purposes, specializing in a discipline known as signals intelligence (SIGINT). The NSA is also tasked with the protection of U.S. communications networks and information systems. The NSA relies on a variety of measures to accomplish its mission, the majority of which are clandestine. The NSA has roughly 32,000 employees.\nOriginating as a unit to decipher coded communications in World War II, it was officially formed as the NSA by President Harry S. Truman in 1952. Between then and the end of the Cold War, it became the largest of the U.S. intelligence organizations in terms of personnel and budget. Still, information available as of 2013 indicates that the Central Intelligence Agency (CIA) pulled ahead in this regard, with a budget of $14.7 billion. The NSA currently conducts worldwide mass data collection and has been known to physically bug electronic systems as one method to this end. The NSA is also alleged to have been behind such attack software as Stuxnet, which severely damaged Iran's nuclear program. The NSA, alongside the CIA, maintains a physical presence in many countries across the globe; the CIA/NSA joint Special Collection Service (a highly classified intelligence team) inserts eavesdropping devices in high-value targets (such as presidential palaces or embassies). SCS collection tactics allegedly encompass \"close surveillance, burglary, wiretapping, [and] breaking\".\nUnlike the CIA and the Defense Intelligence Agency (DIA), both of which specialize primarily in foreign human espionage, the NSA does not publicly conduct human intelligence gathering. The NSA is entrusted with assisting with and coordinating SIGINT elements for other government organizations\u2014which Executive Order prevents from engaging in such activities on their own. As part of these responsibilities, the agency has a co-located organization called the Central Security Service (CSS), which facilitates cooperation between the NSA and other U.S. defense cryptanalysis components. To further ensure streamlined communication between the signals intelligence community divisions, the NSA director simultaneously serves as the Commander of the United States Cyber Command and as Chief of the Central Security Service.\nThe NSA's actions have been a matter of political controversy on several occasions, including its role in providing intelligence during the Gulf of Tonkin incident, which contributed to the escalation of U.S. involvement in the Vietnam War. Declassified documents later revealed that the NSA misinterpreted or overstated signals intelligence, leading to reports of a second North Vietnamese attack that likely never occurred. The agency has also received scrutiny for spying on anti\u2013Vietnam War leaders and the agency's participation in economic espionage. In 2013, the NSA had many of its secret surveillance programs revealed to the public by Edward Snowden, a former NSA contractor. According to the leaked documents, the NSA intercepts and stores the communications of over a billion people worldwide, including United States citizens. The documents also revealed that the NSA tracks hundreds of millions of people's movements using cell phone metadata. Internationally, research has pointed to the NSA's ability to surveil the domestic Internet traffic of foreign countries through \"boomerang routing\".\nHistory.\nFormation.\nThe origins of the National Security Agency can be traced back to April 28, 1917, three weeks after the U.S. Congress declared war on Germany in World War I. A code and cipher decryption unit was established as the Cable and Telegraph Section, which was also known as the Cipher Bureau. It was headquartered in Washington, D.C., and was part of the war effort under the executive branch without direct congressional authorization. During the war, it was relocated in the army's organizational chart several times. On July 5, 1917, Herbert O. Yardley was assigned to head the unit. At that point, the unit consisted of Yardley and two civilian clerks. It absorbed the Navy's cryptanalysis functions in July 1918. World War I ended on November 11, 1918, and the army cryptographic section of Military Intelligence (MI-8) moved to New York City on May 20, 1919, where it continued intelligence activities as the Code Compilation Company under the direction of Yardley.\nThe Black Chamber.\nAfter the disbandment of the U.S. Army cryptographic section of military intelligence known as MI-8, the U.S. government created the Cipher Bureau, also known as Black Chamber, in 1919. The Black Chamber was the United States' first peacetime cryptanalytic organization. Jointly funded by the Army and the State Department, the Cipher Bureau was disguised as a New York City commercial code company; it produced and sold such codes for business use. Its true mission, however, was to break the communications (chiefly diplomatic) of other nations. At the Washington Naval Conference, it aided American negotiators by providing them with the decrypted traffic of many of the conference delegations, including the Japanese. The Black Chamber successfully persuaded Western Union, the largest U.S. telegram company at the time, as well as several other communications companies, to illegally give the Black Chamber access to cable traffic of foreign embassies and consulates. Soon, these companies publicly discontinued their collaboration. Despite the Chamber's initial successes, it was shut down in 1929 by U.S. Secretary of State Henry L. Stimson, who defended his decision by stating, \"Gentlemen do not read each other's mail.\"\nWorld War II and its aftermath.\nDuring World War II, the Signal Intelligence Service (SIS) was created to intercept and decipher the communications of the Axis powers. When the war ended, the SIS was reorganized as the Army Security Agency (ASA), and it was placed under the leadership of the Director of Military Intelligence.\nOn May 20, 1949, all cryptologic activities were centralized under a national organization called the Armed Forces Security Agency (AFSA). This organization was originally established within the U.S. Department of Defense under the command of the Joint Chiefs of Staff. The AFSA was tasked with directing the Department of Defense communications and electronic intelligence activities, except those of U.S. military intelligence units. However, the AFSA was unable to centralize communications intelligence and failed to coordinate with civilian agencies that shared its interests, such as the Department of State, the Central Intelligence Agency (CIA) and the Federal Bureau of Investigation (FBI). In December 1951, President Harry S. Truman ordered a panel to investigate how AFSA had failed to achieve its goals. The results of the investigation led to improvements and its redesignation as the National Security Agency.\nThe National Security Council issued a memorandum of October 24, 1952, that revised National Security Council Intelligence Directive (NSCID) 9. On the same day, Truman issued a second memorandum that called for the establishment of the NSA. The actual establishment of the NSA was done by a November 4 memo by Robert A. Lovett, the Secretary of Defense, changing the name of the AFSA to the NSA, and making the new agency responsible for all communications intelligence. Since President Truman's memo was a classified document, the existence of the NSA was not known to the public at that time. Due to its ultra-secrecy, the U.S. intelligence community referred to the NSA as \"No Such Agency\".\nVietnam War.\nIn the 1960s, the NSA played a key role in expanding American commitment to the Vietnam War by providing evidence of a North Vietnamese attack on the American Naval destroyer during the Gulf of Tonkin incident. A secret operation, code-named \"MINARET\", was set up by the NSA to monitor the phone communications of Senators Frank Church and Howard Baker, as well as key leaders of the civil rights movement, including Martin Luther King Jr., and prominent U.S. journalists and athletes who criticized the Vietnam War. However, the project turned out to be controversial, and an internal review by the NSA concluded that its Minaret program was \"disreputable if not outright illegal\".\nThe NSA has mounted a major effort to secure tactical communications among U.S. armed forces during the war with mixed success. The NESTOR family of compatible secure voice systems it developed was widely deployed during the Vietnam War, with about 30,000 NESTOR sets produced. However, a variety of technical and operational problems limited their use, allowing the North Vietnamese to exploit and intercept U.S. communications.\nChurch Committee hearings.\nIn the aftermath of the Watergate scandal, a congressional hearing in 1975 led by Senator Frank Church revealed that the NSA, in collaboration with Britain's SIGINT intelligence agency, Government Communications Headquarters (GCHQ), had routinely intercepted the international communications of prominent anti-Vietnam war leaders such as Jane Fonda and Dr. Benjamin Spock. The NSA tracked these individuals in a secret filing system that was destroyed in 1974. Following the resignation of President Richard Nixon, there were several investigations into suspected misuse of FBI, CIA and NSA facilities. Senator Frank Church uncovered previously unknown activity, such as a CIA plot (ordered by the administration of President John F. Kennedy) to assassinate Fidel Castro. The investigation also uncovered NSA's wiretaps on targeted U.S. citizens. After the Church Committee hearings, the Foreign Intelligence Surveillance Act of 1978 was passed. This was designed to limit the practice of mass surveillance in the United States.\n1980s to 1990s.\nIn 1986, the NSA intercepted the communications of the Libyan government during the immediate aftermath of the Berlin discotheque bombing. The White House asserted that the NSA interception had provided \"irrefutable\" evidence that Libya was behind the bombing, which U.S. President Ronald Reagan cited as a justification for the 1986 United States bombing of Libya.\nIn 1999, a multi-year investigation by the European Parliament highlighted the NSA's role in economic espionage in a report entitled 'Development of Surveillance Technology and Risk of Abuse of Economic Information'. That year, the NSA founded the NSA Hall of Honor, a memorial at the National Cryptologic Museum in Fort Meade, Maryland. The memorial is a, \"tribute to the pioneers and heroes who have made significant and long-lasting contributions to American cryptology\". NSA employees must be retired for more than fifteen years to qualify for the memorial.\nNSA's infrastructure deteriorated in the 1990s as defense budget cuts resulted in maintenance deferrals. On January 24, 2000, NSA headquarters suffered a total network outage for three days caused by an overloaded network. Incoming traffic was successfully stored on agency servers, but it could not be directed and processed. The agency carried out emergency repairs for $3\u00a0million to get the system running again (some incoming traffic was also directed instead to Britain's GCHQ for the time being). Director Michael Hayden called the outage a \"wake-up call\" for the need to invest in the agency's infrastructure.\nIn the 1990s the defensive arm of the NSA\u2014the Information Assurance Directorate (IAD)\u2014started working more openly; the first public technical talk by an NSA scientist at a major cryptography conference was J. Solinas' presentation on efficient Elliptic Curve Cryptography algorithms at Crypto 1997. The IAD's cooperative approach to academia and industry culminated in its support for a transparent process for replacing the outdated Data Encryption Standard (DES) by an Advanced Encryption Standard (AES). Cybersecurity policy expert Susan Landau attributes the NSA's harmonious collaboration with industry and academia in the selection of the AES in 2000\u2014and the Agency's support for the choice of a strong encryption algorithm designed by Europeans rather than by Americans\u2014to Brian Snow, who was the Technical Director of IAD and represented the NSA as cochairman of the Technical Working Group for the AES competition, and Michael Jacobs, who headed IAD at the time.\nAfter the terrorist attacks of September 11, 2001, the NSA believed that it had public support for a dramatic expansion of its surveillance activities. According to Neal Koblitz and Alfred Menezes, the period when the NSA was a trusted partner with academia and industry in the development of cryptographic standards started to come to an end when, as part of the change in the NSA in the post-September 11 era, Snow was replaced as Technical Director, Jacobs retired, and IAD could no longer effectively oppose proposed actions by the offensive arm of the NSA.\nWar on terror.\nIn the aftermath of the September 11 attacks, the NSA created new IT systems to deal with the flood of information from new technologies like the Internet and cell phones. ThinThread contained advanced data mining capabilities. It also had a \"privacy mechanism\"; surveillance was stored encrypted; decryption required a warrant. The research done under this program may have contributed to the technology used in later systems. ThinThread was canceled when Michael Hayden chose Trailblazer, which did not include ThinThread's privacy system.\nTrailblazer Project ramped up in 2002 and was worked on by Science Applications International Corporation (SAIC), Boeing, Computer Sciences Corporation, IBM, and Litton Industries. Some NSA whistleblowers complained internally about major problems surrounding Trailblazer. This led to investigations by Congress and the NSA and DoD Inspectors General. The project was canceled in early 2004. Turbulence started in 2005. It was developed in small, inexpensive \"test\" pieces, rather than one grand plan like Trailblazer. It also included offensive cyber-warfare capabilities, like injecting malware into remote computers. Congress criticized Turbulence in 2007 for having similar bureaucratic problems as Trailblazer. It was to be a realization of information processing at higher speeds in cyberspace.\nGlobal surveillance program disclosures.\nThe massive extent of the NSA's spying, both foreign and domestic, was revealed to the public in a series of detailed disclosures of internal NSA documents beginning in June 2013. Most of the disclosures were leaked by former NSA contractor Edward Snowden. On 4 September 2020, the NSA's surveillance program was ruled unlawful by the US Court of Appeals. The court also added that the US intelligence leaders, who publicly defended it, were not telling the truth.\nMission.\nNSA's eavesdropping mission includes radio broadcasting, both from various organizations and individuals, the Internet, telephone calls, and other intercepted forms of communication. Its secure communications mission includes military, diplomatic, and all other sensitive, confidential, or secret government communications.\nAccording to a 2010 article in \"The Washington Post\", \"every day, collection systems at the National Security Agency intercept and store 1.7\u00a0 billion e-mails, phone calls and other types of communications. The NSA sorts a fraction of those into 70 separate databases.\"\nBecause of its listening task, NSA/CSS has been heavily involved in cryptanalytic research, continuing the work of predecessor agencies which had broken many World War II codes and ciphers (see, for instance, Purple, Venona project, and JN-25). In 2004, NSA Central Security Service and the National Cyber Security Division of the Department of Homeland Security (DHS) agreed to expand the NSA Centers of Academic Excellence in Information Assurance Education Program.\nAs part of the National Security Presidential Directive 54/Homeland Security Presidential Directive 23 (NSPD 54), signed on January 8, 2008, by President Bush, the NSA became the lead agency to monitor and protect all of the federal government's computer networks from cyber-terrorism. A part of the NSA's mission is to serve as a combat support agency for the Department of Defense.\nOperations.\nOperations by the National Security Agency can be divided into three types:\nCollection overseas.\nEchelon.\n\"Echelon\" was created in the incubator of the Cold War. Today it is a legacy system, and several NSA stations are closing. NSA/CSS, in combination with the equivalent agencies in the United Kingdom (Government Communications Headquarters), Canada (Communications Security Establishment), Australia (Australian Signals Directorate), and New Zealand (Government Communications Security Bureau), otherwise known as the UKUSA group, was reported to be in command of the operation of the so-called ECHELON system. Its capabilities were suspected to include the ability to monitor a large proportion of the world's transmitted civilian telephone, fax, and data traffic.\nDuring the early 1970s, the first of what became more than eight large satellite communications dishes were installed at Menwith Hill. Investigative journalist Duncan Campbell reported in 1988 on the \"ECHELON\" surveillance program, an extension of the UKUSA Agreement on global signals intelligence SIGINT, and detailed how the eavesdropping operations worked. On November 3, 1999, the BBC reported that they had confirmation from the Australian Government of the existence of a powerful \"global spying network\" code-named Echelon, that could \"eavesdrop on every single phone call, fax or e-mail, anywhere on the planet\" with Britain and the United States as the chief protagonists. They confirmed that Menwith Hill was \"linked directly to the headquarters of the US National Security Agency (NSA) at Fort Meade in Maryland\". NSA's United States Signals Intelligence Directive 18 (USSID 18) strictly prohibited the interception or collection of information about \"... U.S. persons, entities, corporations or organizations...\" without explicit written legal permission from the United States Attorney General when the subject is located abroad, or the Foreign Intelligence Surveillance Court when within U.S. borders. Alleged Echelon-related activities, including its use for motives other than national security, including political and industrial espionage, received criticism from countries outside the UKUSA alliance.\nOther SIGINT overseas operations.\nThe NSA was also involved in planning to blackmail people with \"SEXINT\", intelligence gained about a potential target's sexual activity and preferences. Those targeted had not committed any apparent crime nor were they charged with one. To support its facial recognition program, the NSA is intercepting \"millions of images per day\". The Real Time Regional Gateway is a data collection program introduced in 2005 in Iraq by the NSA during the Iraq War that consisted of gathering all electronic communication, storing it, then searching and otherwise analyzing it. It was effective in providing information about Iraqi insurgents who had eluded less comprehensive techniques. This \"collect it all\" strategy introduced by NSA director, Keith B. Alexander, is believed by Glenn Greenwald of \"The Guardian\" to be the model for the comprehensive worldwide mass archiving of communications which NSA is engaged in as of 2013.\nA dedicated unit of the NSA locates targets for the CIA for extrajudicial assassination in the Middle East. The NSA has also spied extensively on the European Union, the United Nations, and numerous governments including allies and trading partners in Europe, South America, and Asia. In June 2015, WikiLeaks published documents showing that NSA spied on French companies. WikiLeaks also published documents showing that NSA spied on federal German ministries since the 1990s. Even Germany's Chancellor Angela Merkel's cellphones and phones of her predecessors had been intercepted.\nBoundless Informant.\nIn June 2013, Edward Snowden revealed that between 8 February and 8 March 2013, the NSA collected about 124.8 billion telephone data items and 97.1 billion computer data items throughout the world, as was displayed in charts from an internal NSA tool codenamed Boundless Informant. Initially, it was reported that some of these data reflected eavesdropping on citizens in countries like Germany, Spain, and France, but later on, it became clear that those data were collected by European agencies during military missions abroad and were subsequently shared with NSA.\nBypassing encryption.\nIn 2013, reporters uncovered a secret memo that claims the NSA created and pushed for the adoption of the Dual EC DRBG encryption standard that contained built-in vulnerabilities in 2006 to the United States National Institute of Standards and Technology (NIST), and the International Organization for Standardization (aka ISO). This memo appears to give credence to previous speculation by cryptographers at Microsoft Research. Edward Snowden claims that the NSA often bypasses the encryption process altogether by lifting information before encryption or after decryption.\nXKeyscore rules (as specified in a file xkeyscorerules100.txt, sourced by German TV stations NDR and WDR, who claim to have excerpts from its source code) reveal that the NSA tracks users of privacy-enhancing software tools, including Tor; an anonymous email service provided by the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) in Cambridge, Massachusetts; and readers of the \"Linux Journal\".\nSoftware backdoors.\nLinus Torvalds, the founder of Linux kernel, joked during a LinuxCon keynote on September 18, 2013, that the NSA, who is the founder of SELinux, wanted a backdoor in the kernel. However, later, Linus' father, a Member of the European Parliament (MEP), revealed that the NSA actually did this.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When my oldest son was asked the same question: \"Has he been approached by the NSA about backdoors?\" he said \"No\", but at the same time he nodded. Then he was sort of in the legal free. He had given the right answer, everybody understood that the NSA had approached him.\u2014\u200a IBM Notes was the first widely adopted software product to use public key cryptography for client-server and server\u2013server authentication and encryption of data. Until US laws regulating encryption were changed in 2000, IBM and Lotus were prohibited from exporting versions of Notes that supported symmetric encryption keys that were longer than 40 bits. In 1997, Lotus negotiated an agreement with the NSA that allowed the export of a version that supported stronger keys with 64 bits, but 24 of the bits were encrypted with a special key and included in the message to provide a \"workload reduction factor\" for the NSA. This strengthened the protection for users of Notes outside the US against private-sector industrial espionage, but not against spying by the US government.\nBoomerang routing.\nWhile it is assumed that foreign transmissions terminating in the U.S. (such as a non-U.S. citizen accessing a U.S. website) subject non-U.S. citizens to NSA surveillance, recent research into boomerang routing has raised new concerns about the NSA's ability to surveil the domestic Internet traffic of foreign countries. Boomerang routing occurs when an Internet transmission that originates and terminates in a single country transits another. Research at the University of Toronto has suggested that approximately 25% of Canadian domestic traffic may be subject to NSA surveillance activities as a result of the boomerang routing of Canadian Internet service providers.\nImplanting hardware equipment.\nA document included in the NSA files released with Glenn Greenwald's book \"No Place to Hide\" details how the agency's Tailored Access Operations (TAO) and other NSA units gained access to hardware equipment. They intercepted routers, servers, and other network hardware equipment being shipped to organizations targeted for surveillance and installing covert implant firmware onto them before they are delivered. This was described by an NSA manager as \"some of the most productive operations in TAO because they preposition access points into hard target networks around the world.\"\nComputers that were seized by the NSA due to interdiction are often modified with a physical device known as Cottonmouth. It is a device that can be inserted at the USB port of a computer to establish remote access to the targeted machine. According to the NSA's Tailored Access Operations (TAO) group implant catalog, after implanting Cottonmouth, the NSA can establish a network bridge \"that allows the NSA to load exploit software onto modified computers as well as allowing the NSA to relay commands and data between hardware and software implants.\"\nDomestic collection.\nNSA's mission, as outlined in Executive Order 12333 in 1981, is to collect information that constitutes \"foreign intelligence or counterintelligence\" while \"not\" \"acquiring information concerning the domestic activities of United States persons\". NSA has declared that it relies on the FBI to collect information on foreign intelligence activities within the borders of the United States while confining its activities within the United States to the embassies and missions of foreign nations.\nThe appearance of a 'Domestic Surveillance Directorate' of the NSA was soon exposed as a hoax in 2013. NSA's domestic surveillance activities are limited by the requirements imposed by the Fourth Amendment to the U.S. Constitution. The Foreign Intelligence Surveillance Court for example held in October 2011, citing multiple Supreme Court precedents, that the Fourth Amendment prohibitions against unreasonable searches and seizures apply to the contents of all communications, whatever the means, because \"a person's private communications are akin to personal papers.\" However, these protections do not apply to non-U.S. persons located outside of U.S. borders, so the NSA's foreign surveillance efforts are subject to far fewer limitations under U.S. law. The specific requirements for domestic surveillance operations are contained in the Foreign Intelligence Surveillance Act of 1978 (FISA), which does not extend protection to non-U.S. citizens located outside of U.S. territory.\nPresident's Surveillance Program.\nGeorge W. Bush, president during the 9/11 terrorist attacks, approved the Patriot Act shortly after the attacks to take anti-terrorist security measures. Titles 1, 2, and 9 specifically authorized measures that would be taken by the NSA. These titles granted enhanced domestic security against terrorism, surveillance procedures, and improved intelligence, respectively. On March 10, 2004, there was a debate between President Bush and White House Counsel Alberto Gonzales, Attorney General John Ashcroft, and Acting Attorney General James Comey. The Attorneys General were unsure if the NSA's programs could be considered constitutional. They threatened to resign over the matter, but ultimately the NSA's programs continued. On March 11, 2004, President Bush signed a new authorization for mass surveillance of Internet records, in addition to the surveillance of phone records. This allowed the president to be able to override laws such as the Foreign Intelligence Surveillance Act, which protected civilians from mass surveillance. In addition to this, President Bush also signed that the measures of mass surveillance were also retroactively in place.\nOne such surveillance program, authorized by the U.S. Signals Intelligence Directive 18 of President George Bush, was the Highlander Project undertaken for the National Security Agency by the U.S. Army 513th Military Intelligence Brigade. NSA relayed telephone (including cell phone) conversations obtained from ground, airborne, and satellite monitoring stations to various U.S. Army Signal Intelligence Officers, including the 201st Military Intelligence Battalion. Conversations of citizens of the U.S. were intercepted, along with those of other nations. Proponents of the surveillance program claim that the President has executive authority to order such action, arguing that laws such as FISA are overridden by the President's Constitutional powers. In addition, some argued that FISA was implicitly overridden by a subsequent statute, the Authorization for Use of Military Force, although the Supreme Court's ruling in \"Hamdan v. Rumsfeld\" deprecates this view.\nThe PRISM program.\n Under the PRISM program, which started in 2007, NSA gathers Internet communications from foreign targets from nine major U.S. Internet-based communication service providers: Microsoft, Yahoo, Google, Facebook, PalTalk, AOL, Skype, YouTube and Apple. Data gathered include email, videos, photos, VoIP chats such as Skype, and file transfers.\nFormer NSA director General Keith Alexander claimed that in September 2009 the NSA prevented Najibullah Zazi and his friends from carrying out a terrorist attack. However, no evidence has been presented demonstrating that the NSA has ever been instrumental in preventing a terrorist attack.\nThe FASCIA database.\nFASCIA is a database created and used by the U.S. National Security Agency that contains trillions of device-location records that are collected from a variety of sources. Its existence was revealed during the 2013 global surveillance disclosure by Edward Snowden.\nThe FASCIA database stores various types of information, including Location Area Codes (LACs), Cell Tower IDs (CeLLIDs), Visitor Location Registers (VLRs), International Mobile Station Equipment Identity (IMEIs) and MSISDNs (Mobile Subscriber Integrated Services Digital Network-Numbers). Over about seven months, more than 27 terabytes of location data were collected and stored in the database.\nCommercial Solutions for Classified (CSfC).\nCommercial Solutions for Classified (CSfC) is a key component of the NSA's commercial cybersecurity strategy. CSfC-validated commercial products are proven to meet rigorous security requirements for protection of classified National Security Systems (NSS) data. Once validated, the Department of Defense (DoD), Intelligence Community, Military Services, and other U.S. government agencies are able to implement these commercial hardware and software technologies into their data protection and cybersecurity solutions.\nHacking operations.\nBesides the more traditional ways of eavesdropping to collect signals intelligence, the NSA is also engaged in hacking computers, smartphones, and their networks. A division that conducts such operations is the Tailored Access Operations (TAO) division, which has been active since at least circa 1998.\nAccording to the \"Foreign Policy\" magazine, \"... the Office of Tailored Access Operations, or TAO, has successfully penetrated Chinese computer and telecommunications systems for almost 15 years, generating some of the best and most reliable intelligence information about what is going on inside the People's Republic of China.\" In an interview with \"Wired\" magazine, Edward Snowden said the Tailored Access Operations division accidentally caused Syria's internet blackout in 2012.\nOrganizational structure.\nThe NSA is led by the Director of the National Security Agency (DIRNSA), who also serves as Chief of the Central Security Service (CHCSS) and Commander of the United States Cyber Command (USCYBERCOM) and is the highest-ranking military official of these organizations. He is assisted by a Deputy Director, who is the highest-ranking civilian within the NSA/CSS. NSA also has an Inspector General, head of the Office of the Inspector General (OIG); a General Counsel, head of the Office of the General Counsel (OGC); and a Director of Compliance, who is head of the Office of the Director of Compliance (ODOC). The National Security Agency Office of Inspector General has worked on cases in collaboration with the United States Department of Justice and the Central Intelligence Agency Office of Inspector General. Unlike other intelligence organizations such as the CIA or DIA, the NSA has always been particularly reticent concerning its internal organizational structure.\nAs of the mid-1990s, the National Security Agency was organized into five Directorates:\nEach of these directorates consisted of several groups or elements, designated by a letter. There were for example the A Group, which was responsible for all SIGINT operations against the Soviet Union and Eastern Europe, and the G Group, which was responsible for SIGINT related to all non-communist countries. These groups were divided into units designated by an additional number, like unit A5 for breaking Soviet codes, and G6, being the office for the Middle East, North Africa, Cuba, and Central and South America.\nDirectorates.\nAs of 2013[ [update]], NSA has about a dozen directorates, which are designated by a letter, although not all of them are publicly known.\nIn the year 2000, a leadership team was formed consisting of the director, the deputy director, and the directors of the Signals Intelligence (SID), the Information Assurance (IAD) and the Technical Directorate (TD). The chiefs of other main NSA divisions became associate directors of the senior leadership team. After President George W. Bush initiated the President's Surveillance Program (PSP) in 2001, the NSA created a 24-hour Metadata Analysis Center (MAC), followed in 2004 by the Advanced Analysis Division (AAD), with the mission of analyzing content, Internet metadata and telephone metadata. Both units were part of the Signals Intelligence Directorate.\nIn 2016, a proposal combined the Signals Intelligence Directorate with the Information Assurance Directorate into a Directorate of Operations.\nNSANet.\nNSANet stands for National Security Agency Network and is the official NSA intranet. It is a classified network, for information up to the level of TS/SCI to support the use and sharing of intelligence data between NSA and the signals intelligence agencies of the four other nations of the Five Eyes partnership. The management of NSANet has been delegated to the Central Security Service Texas (CSSTEXAS).\nNSANet is a highly secured computer network consisting of fiber-optic and satellite communication channels that are almost completely separated from the public Internet. The network allows NSA personnel and civilian and military intelligence analysts anywhere in the world to have access to the agency's systems and databases. This access is tightly controlled and monitored. For example, every keystroke is logged, activities are audited at random, and downloading and printing of documents from NSANet are recorded. In 1998, NSANet, along with NIPRNet and SIPRNet, had \"significant problems with poor search capabilities, unorganized data, and old information\". In 2004, the network was reported to have used over twenty commercial off-the-shelf operating systems. Some universities that do highly sensitive research are allowed to connect to it. The thousands of Top Secret internal NSA documents that were taken by Edward Snowden in 2013 were stored in \"a file-sharing location on the NSA's intranet site\"; so, they could easily be read online by NSA personnel. Everyone with a TS/SCI clearance had access to these documents. As a system administrator, Snowden was responsible for moving accidentally misplaced highly sensitive documents to safer storage locations.\nWatch centers.\nThe NSA maintains at least two watch centers:\nNSA Police.\nThe NSA has its law enforcement team, known as the \"NSA Police\" (and formerly as \"NSA Security Protective Force\") which provides law enforcement services, emergency response, and physical security to its officials and properties.\nNSA Police are armed federal officers. NSA Police has a K9 division, which generally conducts explosive detection screening of mail, vehicles, and cargo entering NSA grounds. They use marked vehicles to carry out patrols.\nEmployees.\nThe number of NSA employees is officially classified but there are several sources providing estimates.\nIn 1961, the NSA had 59,000 military and civilian employees, which grew to 93,067 in 1969, of which 19,300 worked at the headquarters at Fort Meade. In the early 1980s, NSA had roughly 50,000 military and civilian personnel. By 1989 this number had grown again to 75,000, of which 25,000 worked at the NSA headquarters. Between 1990 and 1995 the NSA's budget and workforce were cut by one-third, which led to a substantial loss of experience.\nIn 2012, the NSA said more than 30,000 employees worked at Fort Meade and other facilities. In 2012, John C. Inglis, the deputy director, said that the total number of NSA employees is \"somewhere between 37,000 and one billion\" as a joke, and stated that the agency is \"probably the biggest employer of introverts.\" In 2013 \"Der Spiegel\" stated that the NSA had 40,000 employees. More widely, it has been described as the world's largest single employer of mathematicians. Some NSA employees form part of the workforce of the National Reconnaissance Office (NRO), the agency that provides the NSA with satellite signals intelligence. As of 2013 about 1,000 system administrators work for the NSA.\nPersonnel security.\nThe NSA received criticism early on in 1960 after two agents had defected to the Soviet Union. Investigations by the House Un-American Activities Committee and a special subcommittee of the United States House Committee on Armed Services revealed severe cases of ignorance of personnel security regulations, prompting the former personnel director and the director of security to step down and leading to the adoption of stricter security practices. Nonetheless, security breaches reoccurred only a year later when in an issue of \"Izvestia\" of July 23, 1963, a former NSA employee published several cryptologic secrets. The very same day, an NSA clerk-messenger committed suicide as ongoing investigations disclosed that he had sold secret information to the Soviets regularly. The reluctance of congressional houses to look into these affairs prompted a journalist to write, \"If a similar series of tragic blunders occurred in any ordinary agency of Government an aroused public would insist that those responsible be officially censured, demoted, or fired.\" David Kahn criticized the NSA's tactics of concealing its doings as smug and the Congress' blind faith in the agency's right-doing as shortsighted and pointed out the necessity of surveillance by the Congress to prevent abuse of power.\nEdward Snowden's leaking of the existence of PRISM in 2013 caused the NSA to institute a \"two-man rule\", where two system administrators are required to be present when one accesses certain sensitive information. Snowden claims he suggested such a rule in 2009.\nPolygraphing.\nThe NSA conducts polygraph tests of employees. For new employees, the tests are meant to discover enemy spies who are applying to the NSA and to uncover any information that could make an applicant pliant to coercion. As part of the latter, historically \"EPQs\" or \"embarrassing personal questions\" about sexual behavior had been included in the NSA polygraph. The NSA also conducts five-year periodic reinvestigation polygraphs of employees, focusing on counterintelligence programs. In addition, the NSA conducts periodic polygraph investigations to find spies and leakers; those who refuse to take them may receive \"termination of employment\", according to a 1982 memorandum from the director of the NSA.\nThere are also \"special access examination\" polygraphs for employees who wish to work in highly sensitive areas, and those polygraphs cover counterintelligence questions and some questions about behavior. NSA's brochure states that the average test length is between two and four hours. A 1983 report of the Office of Technology Assessment stated that \"It appears that the NSA [National Security Agency] (and possibly CIA) use the polygraph not to determine deception or truthfulness per se, but as a technique of interrogation to encourage admissions.\" Sometimes applicants in the polygraph process confess to committing felonies such as murder, rape, and selling of illegal drugs. Between 1974 and 1979, of the 20,511 job applicants who took polygraph tests, 695 (3.4%) confessed to previous felony crimes; almost all of those crimes had been undetected.\nIn 2010 the NSA produced a video explaining its polygraph process. The video, ten minutes long, is titled \"The Truth About the Polygraph\" and was posted to the Web site of the Defense Security Service. Jeff Stein of \"The Washington Post\" said that the video portrays \"various applicants, or actors playing them\u2014it's not clear\u2014describing everything bad they had heard about the test, the implication being that none of it is true.\" AntiPolygraph.org argues that the NSA-produced video omits some information about the polygraph process; it produced a video responding to the NSA video. George Maschke, the founder of the Web site, accused the NSA polygraph video of being \"Orwellian\".\nIn 2013, an article indicated that after Edward Snowden revealed his identity in 2013, the NSA began requiring polygraphing of employees once per quarter.\nArbitrary firing.\nThe number of exemptions from legal requirements has been criticized. When in 1964 Congress was hearing a bill giving the director of the NSA the power to fire at will any employee, \"The Washington Post\" wrote: \"This is the very definition of arbitrariness. It means that an employee could be discharged and disgraced based on anonymous allegations without the slightest opportunity to defend himself.\" Yet, the bill was accepted by an overwhelming majority. Also, every person hired to a job in the US after 2007, at any private organization, state or federal government agency, \"must\" be reported to the New Hire Registry, ostensibly to look for child support evaders, \"except\" that employees of an intelligence agency may be excluded from reporting if the director deems it necessary for national security reasons.\nFacilities.\nHeadquarters.\nHistory of headquarters.\nWhen the agency was first established, its headquarters and cryptographic center were in the Naval Security Station in Washington, D.C. The COMINT functions were located in Arlington Hall in Northern Virginia, which served as the headquarters of the U.S. Army's cryptographic operations. Because the Soviet Union had detonated a nuclear bomb and because the facilities were crowded, the federal government wanted to move several agencies, including the AFSA/NSA. A planning committee considered Fort Knox, but Fort Meade, Maryland, was ultimately chosen as NSA headquarters because it was far enough away from Washington, D.C. in case of a nuclear strike and was close enough so its employees would not have to move their families.\nConstruction of additional buildings began after the agency occupied buildings at Fort Meade in the late 1950s, which they soon outgrew. In 1963 the new headquarters building, nine stories tall, opened. NSA workers referred to the building as the \"Headquarters Building\" and since the NSA management occupied the top floor, workers used \"Ninth Floor\" to refer to their leaders. COMSEC remained in Washington, D.C., until its new building was completed in 1968. In September 1986, the Operations 2A and 2B buildings, both copper-shielded to prevent eavesdropping, opened with a dedication by President Ronald Reagan. The four NSA buildings became known as the \"Big Four.\" The NSA director moved to 2B when it opened.\nHeadquarters for the National Security Agency is located at in Fort George G. Meade, Maryland, although it is separate from other compounds and agencies that are based within this same military installation. Fort Meade is about southwest of Baltimore, and northeast of Washington, D.C. The NSA has two dedicated exits off Baltimore\u2013Washington Parkway. The Eastbound exit from the Parkway (heading toward Baltimore) is open to the public and provides employee access to its main campus and public access to the National Cryptology Museum. The Westbound side exit, (heading toward Washington) is labeled \"NSA Employees Only\". The exit may only be used by people with the proper clearances, and security vehicles parked along the road guard the entrance.\nNSA is the largest employer in the state of Maryland, and two-thirds of its personnel work at Fort Meade. Built on of Fort Meade's , the site has 1,300 buildings and an estimated 18,000 parking spaces.\nThe main NSA headquarters and operations building is what James Bamford, author of \"Body of Secrets\", describes as \"a modern boxy structure\" that appears similar to \"any stylish office building.\" The building is covered with one-way dark glass, which is lined with copper shielding to prevent espionage by trapping in signals and sounds. It contains , or more than , of floor space; Bamford said that the U.S. Capitol \"could easily fit inside it four times over.\"\nThe facility has over 100 watchposts, one of them being the visitor control center, a two-story area that serves as the entrance. At the entrance, a white pentagonal structure, visitor badges are issued to visitors and security clearances of employees are checked. The visitor center includes a painting of the NSA seal.\nThe OPS2A building, the tallest building in the NSA complex and the location of much of the agency's operations directorate is accessible from the visitor center. Bamford described it as a \"dark glass Rubik's Cube\". The facility's \"red corridor\" houses non-security operations such as concessions and the drug store. The name refers to the \"red badge\" which is worn by someone without a security clearance. The NSA headquarters includes a cafeteria, a credit union, ticket counters for airlines and entertainment, a barbershop, and a bank. NSA headquarters has its own post office, fire department, and police force.\nThe employees at the NSA headquarters reside in various places in the Baltimore-Washington area, including Annapolis, Baltimore, and Columbia in Maryland and the District of Columbia, including the Georgetown community. The NSA maintains a shuttle service from the Odenton station of MARC to its Visitor Control Center and has done so since 2005.\nEnergy consumption.\nFollowing a major power outage in 2000, in 2003, and follow-ups through 2007, \"The Baltimore Sun\" reported that the NSA was at risk of electrical overload because of insufficient internal electrical infrastructure at Fort Meade to support the amount of equipment being installed. This problem was apparently recognized in the 1990s but not made a priority, and \"now the agency's ability to keep its operations going is threatened.\"\nOn August 6, 2006, \"The Baltimore Sun\" reported that the NSA had completely maxed out the grid and that Baltimore Gas &amp; Electric (BGE, now Constellation Energy) was unable to sell them any more power. NSA decided to move some of its operations to a new satellite facility. BGE provided NSA with 65 to 75 megawatts at Fort Meade in 2007 and expected that an increase of 10 to 15 megawatts would be needed later that year. In 2011, the NSA was Maryland's largest consumer of power. In 2007, as BGE's largest customer, NSA bought as much electricity as Annapolis, the capital city of Maryland. One estimate put the potential for power consumption by the new Utah Data Center at US$40\u00a0million per year.\nComputing assets.\nIn 1995, \"The Baltimore Sun\" reported that the NSA is the owner of the single largest group of supercomputers. NSA held a groundbreaking ceremony at Fort Meade in May 2013 for its High-Performance Computing Center 2, expected to open in 2016. Called Site M, the center has a 150-megawatt power substation, 14 administrative buildings and 10 parking garages. It cost 3.2\u00a0billion and covers . The center is and initially uses 60 megawatts of electricity. Increments II and III are expected to be completed by 2030 and would quadruple the space, covering with 60 buildings and 40 parking garages. Defense contractors are also establishing or expanding cybersecurity facilities near the NSA and around the Washington metropolitan area.\nNational Computer Security Center.\nThe DoD Computer Security Center was founded in 1981 and renamed the National Computer Security Center (NCSC) in 1985. NCSC was responsible for computer security throughout the federal government. NCSC was part of NSA, and during the late 1980s and the 1990s, NSA and NCSC published Trusted Computer System Evaluation Criteria in a six-foot high Rainbow Series of books that detailed trusted computing and network platform specifications. The Rainbow books were replaced by the Common Criteria, however, in the early 2000s.\nOther facilities.\nNSA had facilities at Friendship Annex (FANX) in Linthicum, Maryland, which is a 20 to 25-minute drive from Fort Meade; the Aerospace Data Facility at Buckley Space Force Base in Aurora, Colorado; NSA Texas in the Texas Cryptology Center at Lackland Air Force Base in San Antonio, Texas; NSA Georgia, Georgia Cryptologic Center, Fort Gordon, Augusta, Georgia; NSA Hawaii, Hawaii Cryptologic Center in Honolulu; the Multiprogram Research Facility in Oak Ridge, Tennessee, and elsewhere.\nIn 2009, to protect its assets and access more electricity, NSA sought to decentralize and expand its existing facilities in Fort Meade and Menwith Hill, the latter expansion expected to be completed by 2015.\nOn January 6, 2011, a groundbreaking ceremony was held to begin construction on the NSA's first Comprehensive National Cyber-security Initiative (CNCI) Data Center, known as the \"Utah Data Center\" for short. The $1.5B data center is being built at Camp Williams, Utah, located south of Salt Lake City, and will help support the agency's National Cyber-security Initiative. It is expected to be operational by September 2013. Construction of Utah Data Center finished in May 2019.\nIn 2012, NSA collected intelligence from four geostationary satellites. Satellite receivers were at Roaring Creek Station in Catawissa, Pennsylvania and Salt Creek Station in Arbuckle, California. It operated ten to twenty taps on U.S. telecom switches. NSA had installations in several U.S. states and from them observed intercepts from Europe, the Middle East, North Africa, Latin America, and Asia. The \"Yakima Herald-Republic\" cited Bamford, saying that many of NSA's bases for its Echelon program were a legacy system, using outdated, 1990s technology. In 2004, NSA closed its operations at Bad Aibling Station (Field Station 81) in Bad Aibling, Germany. In 2012, NSA began to move some of its operations at Yakima Research Station, Yakima Training Center, in Washington state to Colorado, planning to leave Yakima closed. During 2013, NSA also intended to close operations at Sugar Grove, West Virginia.\nGlobal stations.\nFollowing the UKUSA Agreement between the Five Eyes that cooperated on signals intelligence and ECHELON, NSA stations were built at GCHQ Bude in Morwenstow, United Kingdom; Geraldton, Pine Gap and Shoal Bay, Australia; Leitrim and Ottawa, Ontario, Canada; Misawa, Japan; and Waihopai and Tangimoana, New Zealand.\nNSA operates RAF Menwith Hill in North Yorkshire, United Kingdom, which was, according to BBC News in 2007, the largest electronic monitoring station in the world. Planned in 1954, and opened in 1960, the base covered in 1999. The agency's European Cryptologic Center (ECC), with 240 employees in 2011, is headquartered at a US military compound in Griesheim, near Frankfurt in Germany. A 2011 NSA report indicates that the ECC is responsible for the \"largest analysis and productivity in Europe\" and focuses on various priorities, including Africa, Europe, the Middle East, and counterterrorism operations.\nSince the mid-1980s, the NSA and Taiwan's National Security Bureau have jointly operated a signals intelligence (SIGINT) listening station at Yangmingshan.\nIn 2013, a new Consolidated Intelligence Center, also to be used by NSA, is being built at the headquarters of the United States Army Europe in Wiesbaden, Germany. NSA's partnership with Bundesnachrichtendienst (BND), the German foreign intelligence service, was confirmed by BND president Gerhard Schindler.\nThailand.\nThailand is a \"3rd party partner\" of the NSA along with nine other nations. These are non-English-speaking countries that have made security agreements for the exchange of SIGINT raw material and end product reports. Thailand is the site of at least two US SIGINT collection stations. One is at the US Embassy in Bangkok, an NSA-CIA Joint Special Collection Service (JSCS) unit. It presumably eavesdrops on foreign consulates, embassies, governmental communications, and other targets of opportunity.\nThe second installation is a FORNSAT (foreign satellite interception) station in the Thai city of Khon Kaen. It is codenamed INDRA, but has also been referred to as LEMONWOOD. The station is approximately in size and consists of a large 3,700\u20134,600 m2 (40,000\u201350,000\u00a0ft2) operations building on the west side of the ops compound and four radome-enclosed parabolic antennas. Possibly two of the radome-enclosed antennas are used for SATCOM intercept and two antennas are used for relaying the intercepted material back to the NSA. There is also a PUSHER-type circularly-disposed antenna array (CDAA) just north of the ops compound. NSA activated Khon Kaen in October 1979. Its mission was to eavesdrop on the radio traffic of Chinese army and air force units in southern China, especially in and around the city of Kunming in Yunnan Province. In the late 1970s, the base consisted only of a small CDAA antenna array that was remote-controlled via satellite from the NSA listening post at Kunia, Hawaii, and a small force of civilian contractors from Bendix Field Engineering Corp. whose job it was to keep the antenna array and satellite relay facilities up and running 24/7. According to the papers of the late General William Odom, the INDRA facility was upgraded in 1986 with a new British-made PUSHER CDAA antenna as part of an overall upgrade of NSA and Thai SIGINT facilities whose objective was to spy on the neighboring communist nations of Vietnam, Laos, and Cambodia. The base fell into disrepair in the 1990s as China and Vietnam became more friendly towards the US, and by 2002 archived satellite imagery showed that the PUSHER CDAA antenna had been torn down, perhaps indicating that the base had been closed. At some point in the period since 9/11, the Khon Kaen base was reactivated and expanded to include a sizeable SATCOM intercept mission. It is likely that the NSA presence at Khon Kaen is relatively small, and that most of the work is done by civilian contractors.\nResearch and development.\nNSA has been involved in debates about public policy, both indirectly as a behind-the-scenes adviser to other departments, and directly during and after Vice Admiral Bobby Ray Inman's directorship. NSA was a major player in the debates of the 1990s regarding the export of cryptography in the United States. Restrictions on export were reduced but not eliminated in 1996. Its secure government communications work has involved the NSA in numerous technology areas, including the design of specialized communications hardware and software, production of dedicated semiconductors at the Ft. Meade chip fabrication plant), and advanced cryptography research. For 50 years, the NSA designed and built most of its in-house computer equipment, but from the 1990s until about 2003 (when the U.S. Congress curtailed the practice), the agency contracted with the private sector in the fields of research and equipment.\nData Encryption Standard.\nNSA was embroiled in some controversy concerning its involvement in the creation of the Data Encryption Standard (DES), a standard and public block cipher algorithm used by the U.S. government and banking community. During the development of DES by IBM in the 1970s, NSA recommended changes to some details of the design. There was suspicion that these changes had weakened the algorithm sufficiently to enable the agency to eavesdrop if required, including speculation that a critical component\u2014the so-called S-boxes\u2014had been altered to insert a \"backdoor\" and that the reduction in key length might have made it feasible for NSA to discover DES keys using massive computing power. It has since been observed that the S-boxes in DES are particularly resilient against differential cryptanalysis, a technique that was not publicly discovered until the late 1980s but known to the IBM DES team.\nAdvanced Encryption Standard.\nThe involvement of the NSA in selecting a successor to the Data Encryption Standard (DES), the Advanced Encryption Standard (AES), was limited to hardware performance testing (see AES competition). NSA has subsequently certified AES for protection of classified information when used in NSA-approved systems.\nNSA encryption systems.\nThe NSA is responsible for the encryption-related components in these legacy systems:\nThe NSA oversees encryption in the following systems that are in use today:\nThe NSA has specified Suite A and Suite B cryptographic algorithm suites to be used in U.S. government systems; the Suite B algorithms are a subset of those previously specified by NIST and are expected to serve for most information protection purposes, while the Suite A algorithms are secret and are intended for especially high levels of protection.\nSHA.\nThe widely used SHA-1 and SHA-2 hash functions were designed by NSA. SHA-1 is a slight modification of the weaker SHA-0 algorithm, also designed by NSA in 1993. This small modification was suggested by the NSA two years later, with no justification other than the fact that it provides additional security. An attack for SHA-0 that does not apply to the revised algorithm was indeed found between 1998 and 2005 by academic cryptographers. Because of weaknesses and key length restrictions in SHA-1, NIST deprecates its use for digital signatures and approves only the newer SHA-2 algorithms for such applications from 2013 on.\nA new hash standard, SHA-3, has recently been selected through the competition concluded on October 2, 2012, with the selection of Keccak as the algorithm. The process to select SHA-3 was similar to the one held in choosing the AES, but some doubts have been cast over it, since fundamental modifications have been made to Keccak to turn it into a standard. These changes potentially undermine the cryptanalysis performed during the competition and reduce the security levels of the algorithm.\nClipper chip.\nBecause of concerns that widespread use of strong cryptography would hamper government use of wiretaps, the NSA proposed the concept of key escrow in 1993 and introduced the Clipper chip that would offer stronger protection than DES but would allow access to encrypted data by authorized law enforcement officials. The proposal was strongly opposed and key escrow requirements ultimately went nowhere. However, NSA's Fortezza hardware-based encryption cards, created for the Clipper project, are still used within government, and NSA ultimately declassified and published the design of the Skipjack cipher used on the cards.\nDual EC DRBG random number generator crypto trojan.\nNSA promoted the inclusion of a random number generator called Dual EC DRBG in the U.S. National Institute of Standards and Technology's 2007 guidelines. This led to speculation of a backdoor which would allow NSA access to data encrypted by systems using that pseudorandom number generator (PRNG).\nThis is now deemed to be plausible based on the fact that output of next iterations of PRNG can provably be determined if relation between two internal Elliptic Curve points is known. Both NIST and RSA are now officially recommending against the use of this PRNG.\nPerfect Citizen.\nPerfect Citizen is a program to perform vulnerability assessment by the NSA in the American critical infrastructure. It was originally reported to be a program to develop a system of sensors to detect cyber attacks on critical infrastructure computer networks in both the private and public sector through a network monitoring system named \"Einstein\". It is funded by the Comprehensive National Cybersecurity Initiative and thus far Raytheon has received a contract for up to $100\u00a0million for the initial stage.\nAcademic research.\nThe NSA has invested many millions of dollars in academic research under grant code prefix \"MDA904\", resulting in over 3,000 papers as of \u00a011, 2007.[ [update]] The NSA publishes its documents through various publications.\nDespite this, the NSA/CSS has, at times, attempted to restrict the publication of academic research into cryptography; for example, the Khufu and Khafre block ciphers were voluntarily withheld in response to an NSA request to do so. In response to a FOIA lawsuit, in 2013 the NSA released the 643-page research paper titled, \"Untangling the Web: A Guide to Internet Research\", written and compiled by NSA employees to assist other NSA workers in searching for information of interest to the agency on the public Internet.\nPatents.\nNSA can file for a patent from the U.S. Patent and Trademark Office under gag order. Unlike normal patents, these are not revealed to the public and do not expire. However, if the Patent Office receives an application for an identical patent from a third party, they will reveal the NSA's patent and officially grant it to the NSA for the full term on that date.\nOne of NSA's published patents describes a method of geographically locating an individual computer site in an Internet-like network, based on the latency of multiple network connections. Although no public patent exists, NSA is reported to have used a similar locating technology called trilateralization that allows real-time tracking of an individual's location, including altitude from ground level, using data obtained from cellphone towers.\nInsignia and memorials.\nThe heraldic insignia of NSA consists of an eagle inside a circle, grasping a key in its talons. The eagle represents the agency's national mission. Its breast features a shield with bands of red and white, taken from the Great Seal of the United States and representing Congress. The key is taken from the emblem of Saint Peter and represents security.\nWhen the NSA was created, the agency had no emblem and used that of the Department of Defense. The agency adopted its first of two emblems in 1963. The current NSA insignia has been in use since 1965, when then-Director, LTG Marshall S. Carter (USA) ordered the creation of a device to represent the agency. The NSA's flag consists of the agency's seal on a light blue background.\nCrews associated with NSA missions have been involved in several dangerous and deadly situations. The USS \"Liberty\" incident in 1967 and USS \"Pueblo\" incident in 1968 are examples of the losses endured during the Cold War. The National Security Agency/Central Security Service Cryptologic Memorial honors and remembers the fallen personnel, both military and civilian, of these intelligence missions. It is made of black granite, and has 171 names carved into it, as of 2013.[ [update]] It is located at NSA headquarters. A tradition of declassifying the stories of the fallen was begun in 2001.\nConstitutionality, legality, and privacy concerning operations.\nIn the United States, at least since 2001, there has been legal controversy over what signal intelligence can be used for and how much freedom the National Security Agency has to use signal intelligence. In 2015, the government made slight changes in how it uses and collects certain types of data, specifically phone records. The government was not analyzing the phone records as of early 2019. The surveillance programs were deemed unlawful in September 2020 in a court of appeals case.\nWarrantless surveillance.\nOn December 16, 2005, \"The New York Times\" reported that under White House pressure and with an executive order from President George W. Bush, the National Security Agency, in an attempt to thwart terrorism, had been tapping phone calls made to persons outside the country, without obtaining warrants from the United States Foreign Intelligence Surveillance Court, a secret court created for that purpose under the Foreign Intelligence Surveillance Act (FISA).\nEdward Snowden.\nEdward Snowden is a former American intelligence contractor who revealed in 2013 the existence of secret wide-ranging information-gathering programs conducted by the National Security Agency (NSA). More specifically, Snowden released information that demonstrated how the United States government was gathering immense amounts of personal communications, emails, phone locations, web histories and more of American citizens without their knowledge. One of Snowden's primary motivators for releasing this information was fear of a surveillance state developing as a result of the infrastructure being created by the NSA. As Snowden recounts, \"I believe that, at this point in history, the greatest danger to our freedom and way of life comes from the reasonable fear of omniscient State powers kept in check by nothing more than policy documents... It is not that I do not value intelligence, but that I oppose .\u2009.\u2009. omniscient, automatic, mass surveillance. .\u2009.\u2009. That seems to me a greater threat to the institutions of free society than missed intelligence reports, and unworthy of the costs.\"\nIn March 2014, Army General Martin Dempsey, Chairman of the Joint Chiefs of Staff, told the House Armed Services Committee, \"The vast majority of the documents that Snowden ... exfiltrated from our highest levels of security ... had nothing to do with exposing government oversight of domestic activities. The vast majority of those were related to our military capabilities, operations, tactics, techniques, and procedures.\" When asked in a May 2014 interview to quantify the number of documents Snowden stole, retired NSA director Keith Alexander said there was no accurate way of counting what he took, but Snowden may have downloaded more than a million documents.\nOther surveillance programs.\nOn January 17, 2006, the Center for Constitutional Rights filed a lawsuit, CCR v. Bush, against the George W. Bush presidency. The lawsuit challenged the National Security Agency's (NSA's) surveillance of people within the U.S., including the interception of CCR emails without securing a warrant first.\nIn the August 2006 case \"ACLU v. NSA\", U.S. District Court Judge Anna Diggs Taylor concluded that NSA's warrantless surveillance program was both illegal and unconstitutional. On July 6, 2007, the 6th Circuit Court of Appeals vacated the decision because the ACLU lacked standing to bring the suit.\nIn September 2008, the Electronic Frontier Foundation (EFF) filed a class action lawsuit against the NSA and several high-ranking officials of the Bush administration, charging an \"illegal and unconstitutional program of dragnet communications surveillance,\" based on documentation provided by former AT&amp;T technician Mark Klein.\nAs a result of the USA Freedom Act passed by Congress in June 2015, the NSA had to shut down its bulk phone surveillance program on November 29 of the same year. The USA Freedom Act forbids the NSA to collect metadata and content of phone calls unless it has a warrant for terrorism investigation. In that case, the agency must ask the telecom companies for the record, which will only be kept for six months. The NSA's use of large telecom companies to assist it with its surveillance efforts has caused several privacy concerns.\nAT&amp;T Internet monitoring.\nIn May 2008, Mark Klein, a former AT&amp;T employee, alleged that his company had cooperated with NSA in installing Narus hardware to replace the FBI Carnivore program, to monitor network communications including traffic between U.S. citizens.\nData mining.\nNSA was reported in 2008 to use its computing capability to analyze \"transactional\" data that it regularly acquires from other government agencies, which gather it under their jurisdictional authorities.\nA 2013 advisory group for the Obama administration, seeking to reform NSA spying programs following the revelations of documents released by Edward J. Snowden, mentioned in 'Recommendation 30' on page 37, \"...that the National Security Council staff should manage an interagency process to review regularly the activities of the US Government regarding attacks that exploit a previously unknown vulnerability in a computer application.\" Retired cybersecurity expert Richard A. Clarke was a group member and stated on April 11, 2014, that NSA had no advance knowledge of Heartbleed.\nIllegally obtained evidence.\nIn August 2013 it was revealed that a 2005 IRS training document showed that NSA intelligence intercepts and wiretaps, both foreign and domestic, were being supplied to the Drug Enforcement Administration (DEA) and Internal Revenue Service (IRS) and were illegally used to launch criminal investigations of US citizens. Law enforcement agents were directed to conceal how the investigations began and recreate a legal investigative trail by re-obtaining the same evidence by other means.\nObama administration.\nIn the months leading to April 2009, the NSA intercepted the communications of U.S. citizens, including a congressman, although the Justice Department believed that the interception was unintentional. The Justice Department then took action to correct the issues and bring the program into compliance with existing laws. United States Attorney General Eric Holder resumed the program according to his understanding of the Foreign Intelligence Surveillance Act amendment of 2008, without explaining what had occurred.\nPolls conducted in June 2013 found divided results among Americans regarding NSA's secret data collection. Rasmussen Reports found that 59% of Americans disapprove, Gallup found that 53% disapprove, and Pew found that 56% are in favor of NSA data collection.\nSection 215 metadata collection.\nOn April 25, 2013, the NSA obtained a court order requiring Verizon's Business Network Services to provide metadata on all calls in its system to the NSA \"on an ongoing daily basis\" for three months, as reported by \"The Guardian\" on June 6, 2013. This information includes \"the numbers of both parties on a call\u00a0... location data, call duration, unique identifiers, and the time and duration of all calls\" but not \"[t]he contents of the conversation itself\". The order relies on the so-called \"business records\" provision of the Patriot Act.\nIn August 2013, following the Snowden leaks, new details about the NSA's data mining activity were revealed. Reportedly, the majority of emails into or out of the United States are captured at \"selected communications links\" and automatically analyzed for keywords or other \"selectors\". Emails that do not match are deleted. The utility of such a massive metadata collection in preventing terrorist attacks is disputed. Many studies reveal the dragnet-like system to be ineffective. One such report, released by the New America Foundation concluded that after an analysis of 225 terrorism cases, the NSA \"had no discernible impact on preventing acts of terrorism.\"\nDefenders of the program said that while metadata alone cannot provide all the information necessary to prevent an attack, it assures the ability to \"connect the dots\" between suspect foreign numbers and domestic numbers with a speed only the NSA's software is capable of. One benefit of this is quickly being able to determine the difference between suspicious activity and real threats. As an example, NSA director General Keith B. Alexander mentioned at the annual Cybersecurity Summit in 2013, that metadata analysis of domestic phone call records after the Boston Marathon bombing helped determine that rumors of a follow-up attack in New York were baseless. In addition to doubts about its effectiveness, many people argue that the collection of metadata is an unconstitutional invasion of privacy. As of 2015[ [update]], the collection process remained legal and grounded in the ruling from \"Smith v. Maryland\" (1979). A prominent opponent of the data collection and its legality is U.S. District Judge Richard J. Leon, who issued a report in 2013 in which he stated: \"I cannot imagine a more 'indiscriminate' and 'arbitrary invasion' than this systematic and high tech collection and retention of personal data on virtually every single citizen for purposes of querying and analyzing it without prior judicial approval...Surely, such a program infringes on 'that degree of privacy' that the founders enshrined in the Fourth Amendment\".\nAs of May 7, 2015, the United States Court of Appeals for the Second Circuit ruled that the interpretation of Section 215 of the Patriot Act was wrong and that the NSA program that has been collecting Americans' phone records in bulk is illegal. It stated that Section 215 cannot be interpreted to allow government to collect national phone data and, as a result, expired on June 1, 2015. This ruling \"is the first time a higher-level court in the regular judicial system has reviewed the NSA phone records program.\" The replacement law known as the USA Freedom Act, which will enable the NSA to continue to have bulk access to citizens' metadata but with the stipulation that the data will now be stored by the companies themselves. This change will not have any effect on other Agency procedures\u2014outside of metadata collection\u2014which have purportedly challenged Americans' Fourth Amendment rights, including Upstream collection, a mass of techniques used by the Agency to collect and store American's data/communications directly from the Internet backbone.\nUnder the Upstream collection program, the NSA paid telecommunications companies hundreds of millions of dollars in order to collect data from them. While companies such as Google and Yahoo! claim that they do not provide \"direct access\" from their servers to the NSA unless under a court order, the NSA had access to emails, phone calls, and cellular data users. Under this new ruling, telecommunications companies maintain bulk user metadata on their servers for at least 18 months, to be provided upon request to the NSA. This ruling made the mass storage of specific phone records at NSA datacenters illegal, but it did not rule on Section 215's constitutionality.\nFourth Amendment encroachment.\nIn a declassified document it was revealed that 17,835 phone lines were on an improperly permitted \"alert list\" from 2006 to 2009 in breach of compliance, which tagged these phone lines for daily monitoring. Eleven percent of these monitored phone lines met the agency's legal standard for \"reasonably articulable suspicion\" (RAS).\nThe NSA tracks the locations of hundreds of millions of cell phones per day, allowing it to map people's movements and relationships in detail. The NSA has been reported to have access to all communications made via Google, Microsoft, Facebook, Yahoo, YouTube, AOL, Skype, Apple and Paltalk, and collects hundreds of millions of contact lists from personal email and instant messaging accounts each year. It has also managed to weaken much of the encryption used on the Internet (by collaborating with, coercing, or otherwise infiltrating numerous technology companies to leave \"backdoors\" into their systems) so that the majority of encryption is inadvertently vulnerable to different forms of attack.\nDomestically, the NSA has been proven to collect and store metadata records of phone calls, including over 120\u00a0million US Verizon subscribers, as well as intercept vast amounts of communications via the internet (Upstream). The government's legal standing had been to rely on a secret interpretation of the Patriot Act whereby the entirety of US communications may be considered \"relevant\" to a terrorism investigation if it is expected that even a tiny minority may relate to terrorism. The NSA also supplies foreign intercepts to the DEA, IRS and other law enforcement agencies, who use these to initiate criminal investigations. Federal agents are then instructed to \"recreate\" the investigative trail via parallel construction.\nThe NSA also spies on influential Muslim societies to obtain information that could be used to discredit them, such as their use of pornography. The targets, both domestic and abroad, are not suspected of any crime but hold religious or political views deemed \"radical\" by the NSA. According to a report in \"The Washington Post\" in July 2014, relying on information provided by Snowden, 90% of those placed under surveillance in the U.S. are ordinary Americans and are not the intended targets. The newspaper said it had examined documents including emails, text messages, and online accounts that support the claim.\nCongressional oversight.\n The Intelligence Committees of the US House and Senate exercise primary oversight over the NSA; other members of Congress have been denied access to materials and information regarding the agency and its activities. The United States Foreign Intelligence Surveillance Court, the secret court charged with regulating the NSA's activities is, according to its chief judge, incapable of investigating or verifying how often the NSA breaks even its own secret rules. It has since been reported that the NSA violated its own rules on data access thousands of times a year, many of these violations involving large-scale data interceptions. NSA officers have even used data intercepts to spy on love interests; \"most of the NSA violations were self-reported, and each instance resulted in administrative action of termination.\"\nThe NSA has \"generally disregarded the special rules for disseminating United States person information\" by illegally sharing its intercepts with different law enforcement agencies. A March 2009 FISA Court opinion, which the court released, states that protocols restricting data queries had been \"so frequently and systemically violated that it can be fairly said that this critical element of the overall ... regime has never functioned effectively.\" In 2011 the same court noted that the \"volume and nature\" of the NSA's bulk foreign Internet intercepts was \"fundamentally different from what the court had been led to believe\". Email contact lists (including those of US citizens) are collected at numerous foreign locations to work around the illegality of doing so on US soil.\nLegal opinions on the NSA's bulk collection program have differed. In mid-December 2013, U.S. District Judge Richard Leon ruled that the \"almost-Orwellian\" program likely violates the Constitution, and wrote, \"I cannot imagine a more 'indiscriminate' and 'arbitrary invasion' than this systematic and high-tech collection and retention of personal data on virtually every single citizen for purposes of querying and analyzing it without prior judicial approval. Surely, such a program infringes on 'that degree of privacy' that the Founders enshrined in the Fourth Amendment. Indeed, I have little doubt that the author of our Constitution, James Madison, who cautioned us to beware 'the abridgment of the freedom of the people by gradual and silent encroachments by those in power,' would be aghast.\"\nLater that month, U.S. District Judge William Pauley ruled that the NSA's collection of telephone records is legal and valuable in the fight against terrorism. In his opinion, he wrote, \"a bulk telephony metadata collection program [is] a wide net that could find and isolate gossamer contacts among suspected terrorists in an ocean of seemingly disconnected data\" and noted that a similar collection of data before 9/11 might have prevented the attack.\nOfficial responses.\nAt a March 2013 Senate Intelligence Committee hearing, Senator Ron Wyden asked the Director of National Intelligence James Clapper, \"Does the NSA collect any type of data at all on millions or hundreds of millions of Americans?\" Clapper replied \"No, sir. ... Not wittingly. There are cases where they could inadvertently perhaps collect, but not wittingly.\" This statement came under scrutiny months later, in June 2013, when details of the PRISM surveillance program were published, showing that \"the NSA apparently can gain access to the servers of nine Internet companies for a wide range of digital data.\" Wyden said that Clapper had failed to give a \"straight answer\" in his testimony. Clapper, in response to criticism, said, \"I responded in what I thought was the most truthful, or least untruthful manner.\" Clapper added, \"There are honest differences on the semantics of what\u2014when someone says 'collection' to me, that has a specific meaning, which may have a different meaning to him.\"\nNSA whistle-blower Edward Snowden additionally revealed the existence of XKeyscore, a top-secret surveillance program that allows the N.S.A for searching vast databases of \"the metadata as well as the content of emails and other internet activity, such as browser history,\" with the capability to search by \"name, telephone number, IP address, keywords, the language in which the internet activity was conducted or the type of browser used.\" XKeyscore \"provides the technological capability, if not the legal authority, to target even US persons for extensive electronic surveillance without a warrant provided that some identifying information, such as their email or IP address, is known to the analyst.\"\nRegarding the necessity of these NSA programs, Alexander stated on June 27, 2013, that the NSA's bulk phone and Internet intercepts had been instrumental in preventing 54 terrorist \"events\", including 13 in the US, and in all but one of these cases had provided the initial tip to \"unravel the threat stream\". On July 31 NSA Deputy Director John Inglis conceded to the Senate that these intercepts had not been vital in stopping any terrorist attacks, but were \"close\" to vital in identifying and convicting four San Diego men for sending US$8,930 to Al-Shabaab, a militia that conducts terrorism in Somalia. The U.S. government has aggressively sought to dismiss and challenge Fourth Amendment cases raised against it, and has granted retroactive immunity to ISPs and telecoms participating in domestic surveillance.\nThe U.S. military has acknowledged blocking access to parts of \"The Guardian\" website for thousands of defense personnel across the country, and blocking the entire \"Guardian\" website for personnel stationed throughout Afghanistan, the Middle East, and South Asia. In October 2014, the United Nations report condemned mass surveillance programs carried out by the U.S. intelligence communities and other nations as violating multiple global treaties and conventions that guaranteed core privacy rights.\nResponsibility for global ransomware attack.\nAn exploit dubbed EternalBlue, created by the NSA, was used in the WannaCry ransomware attack in May 2017. The exploit had been leaked online by a hacking group, The Shadow Brokers, nearly a month before the attack. Several experts have pointed the finger at the NSA's non-disclosure of the underlying vulnerability, and their loss of control over the EternalBlue attack tool that exploited it. Edward Snowden said that if the NSA had \"privately disclosed the flaw used to attack hospitals when they found it, not when they lost it, [the attack] might not have happened\". Wikipedia co-founder, Jimmy Wales, stated that he joined \"with Microsoft and the other leaders of the industry in saying this is a huge screw-up by the government ... the moment the NSA found it, they should have notified Microsoft so they could quietly issue a patch and really chivvy people along, long before it became a huge problem.\"\nActivities of previous employees.\nFormer employee David Evenden, who had left the NSA to work for US defense contractor Cyperpoint at a position in the United Arab Emirates, was tasked with hacking UAE neighbor Qatar in 2015 to determine if they were funding terrorist group Muslim Brotherhood. He quit the company after learning his team had hacked Qatari Sheikha Moza bint Nasser's email exchanges with Michelle Obama, just before she visited Doha. Upon Evenden's return to the US, he reported his experiences to the FBI. The incident highlights a growing trend of former NSA employees and contractors leaving the agency to start up their firms, and then hiring out to countries like Turkey, Sudan, and even Russia, a country involved in numerous cyberattacks against the US.\n2021 Denmark-NSA collaborative surveillance.\nIn May 2021, it was reported that the Danish Defence Intelligence Service collaborated with the NSA to wiretap on fellow EU members and leaders, leading to wide backlash among EU countries and demands for explanation from Danish and American governments.\nBuying data without a warrant.\nNSA director Paul Nakasone disclosed in a letter to Representative Ron Wyden that the NSA buys data without a warrant.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21941", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=21941", "title": "Nuremburg Trials", "text": ""}
{"id": "21943", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=21943", "title": "Nervous System", "text": ""}
{"id": "21944", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=21944", "title": "Nervous system", "text": "Part of an animal that coordinates actions and senses\nIn biology, the nervous system is the highly complex part of an animal that coordinates its actions and sensory information by transmitting signals to and from different parts of its body. The nervous system detects environmental changes that impact the body, then works in tandem with the endocrine system to respond to such events. Nervous tissue first arose in wormlike organisms about 550 to 600 million years ago. In vertebrates, it consists of two main parts, the central nervous system (CNS) and the peripheral nervous system (PNS). The CNS consists of the brain and spinal cord. The PNS consists mainly of nerves, which are enclosed bundles of the long fibers, or axons, that connect the CNS to every other part of the body. Nerves that transmit signals from the brain are called motor nerves (efferent), while those nerves that transmit information from the body to the CNS are called sensory nerves (afferent). The PNS is divided into two separate subsystems, the somatic and autonomic nervous systems. The autonomic nervous system is further subdivided into the sympathetic, parasympathetic and enteric nervous systems. The sympathetic nervous system is activated in cases of emergencies to mobilize energy, while the parasympathetic nervous system is activated when organisms are in a relaxed state. The enteric nervous system functions to control the gastrointestinal system. Nerves that exit from the brain are called cranial nerves while those exiting from the spinal cord are called spinal nerves.\nThe nervous system consists of nervous tissue which, at a cellular level, is defined by the presence of a special type of cell, called the neuron. Neurons have special structures that allow them to send signals rapidly and precisely to other cells. They send these signals in the form of electrochemical impulses traveling along thin fibers called axons, which can be directly transmitted to neighboring cells through electrical synapses or cause chemicals called neurotransmitters to be released at chemical synapses. A cell that receives a synaptic signal from a neuron may be excited, inhibited, or otherwise modulated. The connections between neurons can form neural pathways, neural circuits, and larger networks that generate an organism's perception of the world and determine its behavior. Along with neurons, the nervous system contains other specialized cells called glial cells (or simply glia), which provide structural and metabolic support. Many of the cells and vasculature channels within the nervous system make up the neurovascular unit, which regulates cerebral blood flow in order to rapidly satisfy the high energy demands of activated neurons.\nNervous systems are found in most multicellular animals, but vary greatly in complexity. The only multicellular animals that have no nervous system at all are sponges, placozoans, and mesozoans, which have very simple body plans. The nervous systems of the radially symmetric organisms ctenophores (comb jellies) and cnidarians (which include anemones, hydras, corals and jellyfish) consist of a diffuse nerve net. All other animal species, with the exception of a few types of worm, have a nervous system containing a brain, a central cord (or two cords running in parallel), and nerves radiating from the brain and central cord. The size of the nervous system ranges from a few hundred cells in the simplest worms, to around 300 billion cells in African elephants.\nThe central nervous system functions to send signals from one cell to others, or from one part of the body to others and to receive feedback. Malfunction of the nervous system can occur as a result of genetic defects, physical damage due to trauma or toxicity, infection, or simply senescence. The medical specialty of neurology studies disorders of the nervous system and looks for interventions that can prevent or treat them. In the peripheral nervous system, the most common problem is the failure of nerve conduction, which can be due to different causes including diabetic neuropathy and demyelinating disorders such as multiple sclerosis and amyotrophic lateral sclerosis. Neuroscience is the field of science that focuses on the study of the nervous system.\nStructure.\nThe nervous system derives its name from nerves, which are cylindrical bundles of fibers (the axons of neurons), that emanate from the brain and spinal cord, and branch repeatedly to innervate every part of the body. Nerves are large enough to have been recognized by the ancient Egyptians, Greeks, and Romans, but their internal structure was not understood until it became possible to examine them using a microscope. The author Michael Nikoletseas wrote:\n\"It is difficult to believe that until approximately year 1900 it was not known that neurons are the basic units of the brain (Santiago Ram\u00f3n y Cajal). Equally surprising is the fact that the concept of chemical transmission in the brain was not known until around 1930 (Henry Hallett Dale and Otto Loewi). We began to understand the basic electrical phenomenon that neurons use in order to communicate among themselves, the action potential, in the 1950s (Alan Lloyd Hodgkin, Andrew Huxley and John Eccles). It was in the 1960s that we became aware of how basic neuronal networks code stimuli and thus basic concepts are possible (David H. Hubel and Torsten Wiesel). The molecular revolution swept across US universities in the 1980s. It was in the 1990s that molecular mechanisms of behavioral phenomena became widely known (Eric Richard Kandel).\" A microscopic examination shows that nerves consist primarily of axons, along with different membranes that wrap around them and segregate them into fascicles. The neurons that give rise to nerves do not lie entirely within the nerves themselves\u2014their cell bodies reside within the brain, spinal cord, or peripheral ganglia.\nAll animals more advanced than sponges have nervous systems. However, even sponges, unicellular animals, and non-animals such as slime molds have cell-to-cell signalling mechanisms that are precursors to those of neurons. In radially symmetric animals such as the jellyfish and hydra, the nervous system consists of a nerve net, a diffuse network of isolated cells. In bilaterian animals, which make up the great majority of existing species, the nervous system has a common structure that originated early in the Ediacaran period, over 550 million years ago.\nCells.\nThe nervous system contains two main categories or types of cells: neurons and glial cells.\nNeurons.\nThe nervous system is defined by the presence of a special type of cell\u2014the neuron (sometimes called \"neurone\" or \"nerve cell\"). Neurons can be distinguished from other cells in a number of ways, but their most fundamental property is that they communicate with other cells via synapses, which are membrane-to-membrane junctions containing molecular machinery that allows rapid transmission of signals, either electrical or chemical. Many types of neuron possess an axon, a protoplasmic protrusion that can extend to distant parts of the body and make thousands of synaptic contacts; axons typically extend throughout the body in bundles called nerves.\nEven in the nervous system of a single species such as humans, hundreds of different types of neurons exist, with a wide variety of morphologies and functions. These include sensory neurons that transmute physical stimuli such as light and sound into neural signals, and motor neurons that transmute neural signals into activation of muscles or glands; however in many species the great majority of neurons participate in the formation of centralized structures (the brain and ganglia) and they receive all of their input from other neurons and send their output to other neurons.\nGlial cells.\nGlial cells (named from the Greek for \"glue\") are non-neuronal cells that provide support and nutrition, maintain homeostasis, form myelin, and participate in signal transmission in the nervous system. In the human brain, it is estimated that the total number of glia roughly equals the number of neurons, although the proportions vary in different brain areas. Among the most important functions of glial cells are to support neurons and hold them in place; to supply nutrients to neurons; to insulate neurons electrically; to destroy pathogens and remove dead neurons; and to provide guidance cues directing the axons of neurons to their targets. A very important type of glial cell (oligodendrocytes in the central nervous system, and Schwann cells in the peripheral nervous system) generates layers of a fatty substance called myelin that wraps around axons and provides electrical insulation which allows them to transmit action potentials much more rapidly and efficiently. Recent findings indicate that glial cells, such as microglia and astrocytes, serve as important resident immune cells within the central nervous system.\nAnatomy in vertebrates.\nThe nervous system of vertebrates (including humans) is divided into the central nervous system (CNS) and the peripheral nervous system (PNS).\nThe CNS is the major division, and consists of the brain and the spinal cord. The spinal canal contains the spinal cord, while the cranial cavity contains the brain. The CNS is enclosed and protected by the meninges, a three-layered system of membranes, including a tough, leathery outer layer called the dura mater. The brain is also protected by the skull, and the spinal cord by the vertebrae.\nThe peripheral nervous system (PNS) is a collective term for the nervous system structures that do not lie within the CNS. The large majority of the axon bundles called nerves are considered to belong to the PNS, even when the cell bodies of the neurons to which they belong reside within the brain or spinal cord. The PNS is divided into somatic and visceral parts. The somatic part consists of the nerves that innervate the skin, joints, and muscles. The cell bodies of somatic sensory neurons lie in dorsal root ganglia of the spinal cord. The visceral part, also known as the autonomic nervous system, contains neurons that innervate the internal organs, blood vessels, and glands. The autonomic nervous system itself consists of two parts: the sympathetic nervous system and the parasympathetic nervous system. Some authors also include sensory neurons whose cell bodies lie in the periphery (for senses such as hearing) as part of the PNS; others, however, omit them.\nThe vertebrate nervous system can also be divided into areas called gray matter and white matter. Gray matter (which is only gray in preserved tissue, and is better described as pink or light brown in living tissue) contains a high proportion of cell bodies of neurons. White matter is composed mainly of myelinated axons, and takes its color from the myelin. White matter includes all of the nerves, and much of the interior of the brain and spinal cord. Gray matter is found in clusters of neurons in the brain and spinal cord, and in cortical layers that line their surfaces. There is an anatomical convention that a cluster of neurons in the brain or spinal cord is called a nucleus, whereas a cluster of neurons in the periphery is called a ganglion. There are, however, a few exceptions to this rule, notably including the part of the forebrain called the basal ganglia.\nComparative anatomy and evolution.\nNeural precursors in sponges.\nSponges have no cells connected to each other by synaptic junctions, that is, no neurons, and therefore no nervous system. They do, however, have homologs of many genes that play key roles in synaptic function. Recent studies have shown that sponge cells express a group of proteins that cluster together to form a structure resembling a postsynaptic density (the signal-receiving part of a synapse). However, the function of this structure is currently unclear. Although sponge cells do not show synaptic transmission, they do communicate with each other via calcium waves and other impulses, which mediate some simple actions such as whole-body contraction.\nRadiata.\nJellyfish, comb jellies, and related animals have diffuse nerve nets rather than a central nervous system. In most jellyfish the nerve net is spread more or less evenly across the body; in comb jellies it is concentrated near the mouth. The nerve nets consist of sensory neurons, which pick up chemical, tactile, and visual signals; motor neurons, which can activate contractions of the body wall; and intermediate neurons, which detect patterns of activity in the sensory neurons and, in response, send signals to groups of motor neurons. In some cases groups of intermediate neurons are clustered into discrete ganglia.\nThe development of the nervous system in radiata is relatively unstructured. Unlike bilaterians, radiata only have two primordial cell layers, endoderm and ectoderm. Neurons are generated from a special set of ectodermal precursor cells, which also serve as precursors for every other ectodermal cell type.\nBilateria.\nThe vast majority of existing animals are bilaterians, meaning animals with left and right sides that are approximate mirror images of each other. All bilateria are thought to have descended from a common wormlike ancestor that appear as fossils beginning in the Ediacaran period, 550\u2013600 million years ago. The fundamental bilaterian body form is a tube with a hollow gut cavity running from mouth to anus, and a nerve cord with an enlargement (a \"ganglion\") for each body segment, with an especially large ganglion at the front, called the \"brain\".\nEven mammals, including humans, show the segmented bilaterian body plan at the level of the nervous system. The spinal cord contains a series of segmental ganglia, each giving rise to motor and sensory nerves that innervate a portion of the body surface and underlying musculature. On the limbs, the layout of the innervation pattern is complex, but on the trunk it gives rise to a series of narrow bands. The top three segments belong to the brain, giving rise to the forebrain, midbrain, and hindbrain.\nBilaterians can be divided, based on events that occur very early in embryonic development, into two groups (superphyla) called protostomes and deuterostomes. Deuterostomes include vertebrates as well as echinoderms, hemichordates (mainly acorn worms), and Xenoturbellidans. Protostomes, the more diverse group, include arthropods, molluscs, and numerous phyla of \"worms\". There is a basic difference between the two groups in the placement of the nervous system within the body: protostomes possess a nerve cord on the ventral (usually bottom) side of the body, whereas in deuterostomes the nerve cord is on the dorsal (usually top) side. In fact, numerous aspects of the body are inverted between the two groups, including the expression patterns of several genes that show dorsal-to-ventral gradients. Most anatomists now consider that the bodies of protostomes and deuterostomes are \"flipped over\" with respect to each other, a hypothesis that was first proposed by Geoffroy Saint-Hilaire for insects in comparison to vertebrates. Thus insects, for example, have nerve cords that run along the ventral midline of the body, while all vertebrates have spinal cords that run along the dorsal midline.\nWorms.\nWorms are the simplest bilaterian animals, and reveal the basic structure of the bilaterian nervous system in the most straightforward way. As an example, earthworms have dual nerve cords running along the length of the body and merging at the tail and the mouth. These nerve cords are connected by transverse nerves like the rungs of a ladder. These transverse nerves help coordinate the two sides of the animal. Two ganglia at the head (the \"nerve ring\") end function similar to a simple brain. Photoreceptors on the animal's eyespots provide sensory information on light and dark.\nThe nervous system of one very small roundworm, the nematode \"Caenorhabditis elegans\", has been completely mapped out in a connectome including its synapses. Every neuron and its cellular lineage has been recorded and most, if not all, of the neural connections are known. In this species, the nervous system is sexually dimorphic; the nervous systems of the two sexes, males and female hermaphrodites, have different numbers of neurons and groups of neurons that perform sex-specific functions. In \"C. elegans\", males have exactly 383 neurons, while hermaphrodites have exactly 302 neurons.\nArthropods.\nArthropods, such as insects and crustaceans, have a nervous system made up of a series of ganglia, connected by a ventral nerve cord made up of two parallel connectives running along the length of the belly. Typically, each body segment has one ganglion on each side, though some ganglia are fused to form the brain and other large ganglia. The head segment contains the brain, also known as the supraesophageal ganglion. In the insect nervous system, the brain is anatomically divided into the protocerebrum, deutocerebrum, and tritocerebrum. Immediately behind the brain is the subesophageal ganglion, which is composed of three pairs of fused ganglia. It controls the mouthparts, the salivary glands and certain muscles. Many arthropods have well-developed sensory organs, including compound eyes for vision and antennae for olfaction and pheromone sensation. The sensory information from these organs is processed by the brain.\nIn insects, many neurons have cell bodies that are positioned at the edge of the brain and are electrically passive\u2014the cell bodies serve only to provide metabolic support and do not participate in signalling. A protoplasmic fiber runs from the cell body and branches profusely, with some parts transmitting signals and other parts receiving signals. Thus, most parts of the insect brain have passive cell bodies arranged around the periphery, while the neural signal processing takes place in a tangle of protoplasmic fibers called neuropil, in the interior.\n\"Identified\" neurons.\nA neuron is called \"identified\" if it has properties that distinguish it from every other neuron in the same animal\u2014properties such as location, neurotransmitter, gene expression pattern, and connectivity\u2014and if every individual organism belonging to the same species has one and only one neuron with the same set of properties. In vertebrate nervous systems very few neurons are \"identified\" in this sense\u2014in humans, there are believed to be none\u2014but in simpler nervous systems, some or all neurons may be thus unique. In the roundworm \"C. elegans\", whose nervous system is the most thoroughly described of any animal's, every neuron in the body is uniquely identifiable, with the same location and the same connections in every individual worm. One notable consequence of this fact is that the form of the \"C. elegans\" nervous system is completely specified by the genome, with no experience-dependent plasticity.\nThe brains of many molluscs and insects also contain substantial numbers of identified neurons. In vertebrates, the best known identified neurons are the gigantic Mauthner cells of fish. Every fish has two Mauthner cells, in the bottom part of the brainstem, one on the left side and one on the right. Each Mauthner cell has an axon that crosses over, innervating neurons at the same brain level and then travelling down through the spinal cord, making numerous connections as it goes. The synapses generated by a Mauthner cell are so powerful that a single action potential gives rise to a major behavioral response: within milliseconds the fish curves its body into a C-shape, then straightens, thereby propelling itself rapidly forward. Functionally this is a fast escape response, triggered most easily by a strong sound wave or pressure wave impinging on the lateral line organ of the fish. Mauthner cells are not the only identified neurons in fish\u2014there are about 20 more types, including pairs of \"Mauthner cell analogs\" in each spinal segmental nucleus. Although a Mauthner cell is capable of bringing about an escape response individually, in the context of ordinary behavior other types of cells usually contribute to shaping the amplitude and direction of the response.\nMauthner cells have been described as command neurons. A command neuron is a special type of identified neuron, defined as a neuron that is capable of driving a specific behavior individually. Such neurons appear most commonly in the fast escape systems of various species\u2014the squid giant axon and squid giant synapse, used for pioneering experiments in neurophysiology because of their enormous size, both participate in the fast escape circuit of the squid. The concept of a command neuron has, however, become controversial, because of studies showing that some neurons that initially appeared to fit the description were really only capable of evoking a response in a limited set of circumstances.\nFunction.\nAt the most basic level, the function of the nervous system is to send signals from one cell to others, or from one part of the body to others. There are multiple ways that a cell can send signals to other cells. One is by releasing chemicals called hormones into the internal circulation, so that they can diffuse to distant sites. In contrast to this \"broadcast\" mode of signaling, the nervous system provides \"point-to-point\" signals\u2014neurons project their axons to specific target areas and make synaptic connections with specific target cells. Thus, neural signaling is capable of a much higher level of specificity than hormonal signaling. It is also much faster: the fastest nerve signals travel at speeds that exceed 100 meters per second.\nAt a more integrative level, the primary function of the nervous system is to control the body. It does this by extracting information from the environment using sensory receptors, sending signals that encode this information into the central nervous system, processing the information to determine an appropriate response, and sending output signals to muscles or glands to activate the response. The evolution of a complex nervous system has made it possible for various animal species to have advanced perception abilities such as vision, complex social interactions, rapid coordination of organ systems, and integrated processing of concurrent signals. In humans, the sophistication of the nervous system makes it possible to have language, abstract representation of concepts, transmission of culture, and many other features of human society that would not exist without the human brain.\nNeurons and synapses.\nMost neurons send signals via their axons, although some types are capable of dendrite-to-dendrite communication. (In fact, the types of neurons called amacrine cells have no axons, and communicate only via their dendrites.) Neural signals propagate along an axon in the form of electrochemical waves called action potentials, which produce cell-to-cell signals at points where axon terminals make synaptic contact with other cells.\nSynapses may be electrical or chemical. Electrical synapses make direct electrical connections between neurons, but chemical synapses are much more common, and much more diverse in function. At a chemical synapse, the cell that sends signals is called presynaptic, and the cell that receives signals is called postsynaptic. Both the presynaptic and postsynaptic areas are full of molecular machinery that carries out the signalling process. The presynaptic area contains large numbers of tiny spherical vessels called synaptic vesicles, packed with neurotransmitter chemicals. When the presynaptic terminal is electrically stimulated, an array of molecules embedded in the membrane are activated, and cause the contents of the vesicles to be released into the narrow space between the presynaptic and postsynaptic membranes, called the synaptic cleft. The neurotransmitter then binds to receptors embedded in the postsynaptic membrane, causing them to enter an activated state. Depending on the type of receptor, the resulting effect on the postsynaptic cell may be excitatory, inhibitory, or modulatory in more complex ways. For example, release of the neurotransmitter acetylcholine at a synaptic contact between a motor neuron and a muscle cell induces rapid contraction of the muscle cell. The entire synaptic transmission process takes only a fraction of a millisecond, although the effects on the postsynaptic cell may last much longer (even indefinitely, in cases where the synaptic signal leads to the formation of a memory trace).\nPostsynaptic density\nVoltage-gated Ca++ channel\nSynaptic vesicle\nNeurotransmitter transporter\nReceptor\nNeurotransmitter\nAxon terminal\nSynaptic cleft\nDendrite\n Structure of a typical chemical synapse\nThere are literally hundreds of different types of synapses. In fact, there are over a hundred known neurotransmitters, and many of them have multiple types of receptors. Many synapses use more than one neurotransmitter\u2014a common arrangement is for a synapse to use one fast-acting small-molecule neurotransmitter such as glutamate or GABA, along with one or more peptide neurotransmitters that play slower-acting modulatory roles. Molecular neuroscientists generally divide receptors into two broad groups: chemically gated ion channels and second messenger systems. When a chemically gated ion channel is activated, it forms a passage that allows specific types of ions to flow across the membrane. Depending on the type of ion, the effect on the target cell may be excitatory or inhibitory. When a second messenger system is activated, it starts a cascade of molecular interactions inside the target cell, which may ultimately produce a wide variety of complex effects, such as increasing or decreasing the sensitivity of the cell to stimuli, or even altering gene transcription.\nAccording to a rule called Dale's principle, which has only a few known exceptions, a neuron releases the same neurotransmitters at all of its synapses. This does not mean, though, that a neuron exerts the same effect on all of its targets, because the effect of a synapse depends not on the neurotransmitter, but on the receptors that it activates. Because different targets can (and frequently do) use different types of receptors, it is possible for a neuron to have excitatory effects on one set of target cells, inhibitory effects on others, and complex modulatory effects on others still. Nevertheless, it happens that the two most widely used neurotransmitters, glutamate and GABA, each have largely consistent effects. Glutamate has several widely occurring types of receptors, but all of them are excitatory or modulatory. Similarly, GABA has several widely occurring receptor types, but all of them are inhibitory. Because of this consistency, glutamatergic cells are frequently referred to as \"excitatory neurons\", and GABAergic cells as \"inhibitory neurons\". Strictly speaking, this is an abuse of terminology\u2014it is the receptors that are excitatory and inhibitory, not the neurons\u2014but it is commonly seen even in scholarly publications.\nOne very important subset of synapses are capable of forming memory traces by means of long-lasting activity-dependent changes in synaptic strength. The best-known form of neural memory is a process called long-term potentiation (abbreviated LTP), which operates at synapses that use the neurotransmitter glutamate acting on a special type of receptor known as the NMDA receptor. The NMDA receptor has an \"associative\" property: if the two cells involved in the synapse are both activated at approximately the same time, a channel opens that permits calcium to flow into the target cell. The calcium entry initiates a second messenger cascade that ultimately leads to an increase in the number of glutamate receptors in the target cell, thereby increasing the effective strength of the synapse. This change in strength can last for weeks or longer. Since the discovery of LTP in 1973, many other types of synaptic memory traces have been found, involving increases or decreases in synaptic strength that are induced by varying conditions, and last for variable periods of time. The reward system, that reinforces desired behaviour for example, depends on a variant form of LTP that is conditioned on an extra input coming from a reward-signalling pathway that uses dopamine as neurotransmitter. All these forms of synaptic modifiability, taken collectively, give rise to neural plasticity, that is, to a capability for the nervous system to adapt itself to variations in the environment.\nNeural circuits and systems.\nThe basic neuronal function of sending signals to other cells includes a capability for neurons to exchange signals with each other. Networks formed by interconnected groups of neurons are capable of a wide variety of functions, including feature detection, pattern generation and timing, and there are seen to be countless types of information processing possible. Warren McCulloch and Walter Pitts showed in 1943 that even artificial neural networks formed from a greatly simplified mathematical abstraction of a neuron are capable of universal computation.\nHistorically, for many years the predominant view of the function of the nervous system was as a stimulus-response associator. In this conception, neural processing begins with stimuli that activate sensory neurons, producing signals that propagate through chains of connections in the spinal cord and brain, giving rise eventually to activation of motor neurons and thereby to muscle contraction, i.e., to overt responses. Descartes believed that all of the behaviors of animals, and most of the behaviors of humans, could be explained in terms of stimulus-response circuits, although he also believed that higher cognitive functions such as language were not capable of being explained mechanistically. Charles Sherrington, in his influential 1906 book \"The Integrative Action of the Nervous System\", developed the concept of stimulus-response mechanisms in much more detail, and behaviorism, the school of thought that dominated psychology through the middle of the 20th century, attempted to explain every aspect of human behavior in stimulus-response terms.\nHowever, experimental studies of electrophysiology, beginning in the early 20th century and reaching high productivity by the 1940s, showed that the nervous system contains many mechanisms for maintaining cell excitability and generating patterns of activity intrinsically, without requiring an external stimulus. Neurons were found to be capable of producing regular sequences of action potentials, or sequences of bursts, even in complete isolation. When intrinsically active neurons are connected to each other in complex circuits, the possibilities for generating intricate temporal patterns become far more extensive. A modern conception views the function of the nervous system partly in terms of stimulus-response chains, and partly in terms of intrinsically generated activity patterns\u2014both types of activity interact with each other to generate the full repertoire of behavior.\nReflexes and other stimulus-response circuits.\nThe simplest type of neural circuit is a reflex arc, which begins with a sensory input and ends with a motor output, passing through a sequence of neurons connected in series. This can be shown in the \"withdrawal reflex\" causing a hand to jerk back after a hot stove is touched. The circuit begins with sensory receptors in the skin that are activated by harmful levels of heat: a special type of molecular structure embedded in the membrane causes heat to change the electrical field across the membrane. If the change in electrical potential is large enough to pass the given threshold, it evokes an action potential, which is transmitted along the axon of the receptor cell, into the spinal cord. There the axon makes excitatory synaptic contacts with other cells, some of which project (send axonal output) to the same region of the spinal cord, others projecting into the brain. One target is a set of spinal interneurons that project to motor neurons controlling the arm muscles. The interneurons excite the motor neurons, and if the excitation is strong enough, some of the motor neurons generate action potentials, which travel down their axons to the point where they make excitatory synaptic contacts with muscle cells. The excitatory signals induce contraction of the muscle cells, which causes the joint angles in the arm to change, pulling the arm away.\nIn reality, this straightforward schema is subject to numerous complications. Although for the simplest reflexes there are short neural paths from sensory neuron to motor neuron, there are also other nearby neurons that participate in the circuit and modulate the response. Furthermore, there are projections from the brain to the spinal cord that are capable of enhancing or inhibiting the reflex.\nAlthough the simplest reflexes may be mediated by circuits lying entirely within the spinal cord, more complex responses rely on signal processing in the brain. For example, when an object in the periphery of the visual field moves, and a person looks toward it many stages of signal processing are initiated. The initial sensory response, in the retina of the eye, and the final motor response, in the oculomotor nuclei of the brainstem, are not all that different from those in a simple reflex, but the intermediate stages are completely different. Instead of a one or two step chain of processing, the visual signals pass through perhaps a dozen stages of integration, involving the thalamus, cerebral cortex, basal ganglia, superior colliculus, cerebellum, and several brainstem nuclei. These areas perform signal-processing functions that include feature detection, perceptual analysis, memory recall, decision-making, and motor planning.\nFeature detection is the ability to extract biologically relevant information from combinations of sensory signals. In the visual system, for example, sensory receptors in the retina of the eye are only individually capable of detecting \"points of light\" in the outside world. Second-level visual neurons receive input from groups of primary receptors, higher-level neurons receive input from groups of second-level neurons, and so on, forming a hierarchy of processing stages. At each stage, important information is extracted from the signal ensemble and unimportant information is discarded. By the end of the process, input signals representing \"points of light\" have been transformed into a neural representation of objects in the surrounding world and their properties. The most sophisticated sensory processing occurs inside the brain, but complex feature extraction also takes place in the spinal cord and in peripheral sensory organs such as the retina.\nIntrinsic pattern generation.\nAlthough stimulus-response mechanisms are the easiest to understand, the nervous system is also capable of controlling the body in ways that do not require an external stimulus, by means of internally generated rhythms of activity. Because of the variety of voltage-sensitive ion channels that can be embedded in the membrane of a neuron, many types of neurons are capable, even in isolation, of generating rhythmic sequences of action potentials, or rhythmic alternations between high-rate bursting and quiescence. When neurons that are intrinsically rhythmic are connected to each other by excitatory or inhibitory synapses, the resulting networks are capable of a wide variety of dynamical behaviors, including attractor dynamics, periodicity, and even chaos. A network of neurons that uses its internal structure to generate temporally structured output, without requiring a corresponding temporally structured stimulus, is called a central pattern generator.\nInternal pattern generation operates on a wide range of time scales, from milliseconds to hours or longer. One of the most important types of temporal pattern is circadian rhythmicity\u2014that is, rhythmicity with a period of approximately 24 hours. All animals that have been studied show circadian fluctuations in neural activity, which control circadian alternations in behavior such as the sleep-wake cycle. Experimental studies dating from the 1990s have shown that circadian rhythms are generated by a \"genetic clock\" consisting of a special set of genes whose expression level rises and falls over the course of the day. Animals as diverse as insects and vertebrates share a similar genetic clock system. The circadian clock is influenced by light but continues to operate even when light levels are held constant and no other external time-of-day cues are available. The clock genes are expressed in many parts of the nervous system as well as many peripheral organs, but in mammals, all of these \"tissue clocks\" are kept in synchrony by signals that emanate from a master timekeeper in a tiny part of the brain called the suprachiasmatic nucleus.\nMirror neurons.\nA mirror neuron is a neuron that fires both when an animal acts and when the animal observes the same action performed by another. Thus, the neuron \"mirrors\" the behavior of the other, as though the observer were itself acting. Such neurons have been directly observed in primate species. Birds have been shown to have imitative resonance behaviors and neurological evidence suggests the presence of some form of mirroring system. In humans, brain activity consistent with that of mirror neurons has been found in the premotor cortex, the supplementary motor area, the primary somatosensory cortex and the inferior parietal cortex. The function of the mirror system is a subject of much speculation. Many researchers in cognitive neuroscience and cognitive psychology consider that this system provides the physiological mechanism for the perception/action coupling (see the common coding theory). They argue that mirror neurons may be important for understanding the actions of other people, and for learning new skills by imitation. Some researchers also speculate that mirror systems may simulate observed actions, and thus contribute to theory of mind skills, while others relate mirror neurons to language abilities. However, to date, no widely accepted neural or computational models have been put forward to describe how mirror neuron activity supports cognitive functions such as imitation. There are neuroscientists who caution that the claims being made for the role of mirror neurons are not supported by adequate research.\nDevelopment.\nIn vertebrates, landmarks of embryonic neural development include the birth and differentiation of neurons from stem cell precursors, the migration of immature neurons from their birthplaces in the embryo to their final positions, outgrowth of axons from neurons and guidance of the motile growth cone through the embryo towards postsynaptic partners, the generation of synapses between these axons and their postsynaptic partners, and finally the lifelong changes in synapses which are thought to underlie learning and memory.\nAll bilaterian animals at an early stage of development form a gastrula, which is polarized, with one end called the animal pole and the other the vegetal pole. The gastrula has the shape of a disk with three layers of cells, an inner layer called the endoderm, which gives rise to the lining of most internal organs, a middle layer called the mesoderm, which gives rise to the bones and muscles, and an outer layer called the ectoderm, which gives rise to the skin and nervous system.\nIn vertebrates, the first sign of the nervous system is the appearance of a thin strip of cells along the center of the back, called the neural plate. The inner portion of the neural plate (along the midline) is destined to become the central nervous system (CNS), the outer portion the peripheral nervous system (PNS). As development proceeds, a fold called the neural groove appears along the midline. This fold deepens, and then closes up at the top. At this point the future CNS appears as a cylindrical structure called the neural tube, whereas the future PNS appears as two strips of tissue called the neural crest, running lengthwise above the neural tube. The sequence of stages from neural plate to neural tube and neural crest is known as neurulation.\nIn the early 20th century, a set of famous experiments by Hans Spemann and Hilde Mangold showed that the formation of nervous tissue is \"induced\" by signals from a group of mesodermal cells called the \"organizer region\". For decades, though, the nature of neural induction defeated every attempt to figure it out, until finally it was resolved by genetic approaches in the 1990s. Induction of neural tissue requires inhibition of the gene for a so-called bone morphogenetic protein, or BMP. Specifically the protein BMP4 appears to be involved. Two proteins called Noggin and Chordin, both secreted by the mesoderm, are capable of inhibiting BMP4 and thereby inducing ectoderm to turn into neural tissue. It appears that a similar molecular mechanism is involved for widely disparate types of animals, including arthropods as well as vertebrates. In some animals, however, another type of molecule called Fibroblast Growth Factor or FGF may also play an important role in induction.\nInduction of neural tissues causes formation of neural precursor cells, called neuroblasts. In \"Drosophila\", neuroblasts divide asymmetrically, so that one product is a \"ganglion mother cell\" (GMC), and the other is a neuroblast. A GMC divides once, to give rise to either a pair of neurons or a pair of glial cells. In all, a neuroblast is capable of generating an indefinite number of neurons or glia.\nAs shown in a 2008 study, one factor common to all bilateral organisms (including humans) is a family of secreted signaling molecules called neurotrophins which regulate the growth and survival of neurons. Zhu et al. identified DNT1, the first neurotrophin found in flies. DNT1 shares structural similarity with all known neurotrophins and is a key factor in the fate of neurons in \"Drosophila\". Because neurotrophins have now been identified in both vertebrate and invertebrates, this evidence suggests that neurotrophins were present in an ancestor common to bilateral organisms and may represent a common mechanism for nervous system formation.\nPathology.\nThe central nervous system is protected by major physical and chemical barriers. Physically, the brain and spinal cord are surrounded by tough meningeal membranes, and enclosed in the bones of the skull and vertebral column, which combine to form a strong physical shield. Chemically, the brain and spinal cord are isolated by the blood\u2013brain barrier, which prevents most types of chemicals from moving from the bloodstream into the interior of the CNS. These protections make the CNS less susceptible in many ways than the PNS; the flip side, however, is that damage to the CNS tends to have more serious consequences.\nAlthough nerves tend to lie deep under the skin except in a few places such as the ulnar nerve near the elbow joint, they are still relatively exposed to physical damage, which can cause pain, loss of sensation, or loss of muscle control. Damage to nerves can also be caused by swelling or bruises at places where a nerve passes through a tight bony channel, as happens in carpal tunnel syndrome. If a nerve is completely transected, it will often regenerate, but for long nerves this process may take months to complete. In addition to physical damage, peripheral neuropathy may be caused by many other medical problems, including genetic conditions, metabolic conditions such as diabetes, inflammatory conditions such as Guillain\u2013Barr\u00e9 syndrome, vitamin deficiency, infectious diseases such as leprosy or shingles, or poisoning by toxins such as heavy metals. Many cases have no cause that can be identified, and are referred to as idiopathic. It is also possible for nerves to lose function temporarily, resulting in numbness as stiffness\u2014common causes include mechanical pressure, a drop in temperature, or chemical interactions with local anesthetic drugs such as lidocaine.\nPhysical damage to the spinal cord may result in loss of sensation or movement. If an injury to the spine produces nothing worse than swelling, the symptoms may be transient, but if nerve fibers in the spine are actually destroyed, the loss of function is usually permanent. Experimental studies have shown that spinal nerve fibers attempt to regrow in the same way as nerve fibers, but in the spinal cord, tissue destruction usually produces scar tissue that cannot be penetrated by the regrowing nerves.\nNeurological practice draws heavily on the fields of neuroscience and psychiatry to treat diseases of the nervous system using various techniques of neurotherapy.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21945", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=21945", "title": "Nicholas of Myra", "text": ""}
{"id": "21946", "revid": "525927", "url": "https://en.wikipedia.org/wiki?curid=21946", "title": "Nutcracker", "text": "Mechanical device for cracking nuts\nA nutcracker is a tool designed to open nuts by cracking their shells. There are many designs, including levers, screws, and ratchets. The lever version is also used for cracking lobster and crab shells.\nA decorative version, a nutcracker doll, portrays a person whose mouth forms the jaws of the nutcracker.\nFunctions.\nNuts were historically opened using a hammer and anvil, often made of stone. Some nuts such as walnuts can also be opened by hand, by holding the nut in the palm of the hand and applying pressure with the other palm or thumb, or using another nut.\nManufacturers produce modern functional nutcrackers usually somewhat resembling pliers, but with the pivot point at the end beyond the nut, rather than in the middle. These are also used for cracking the shells of crab and lobster to make the meat inside available for eating. Hinged lever nutcrackers, often called a \"pair of nutcrackers\", may date back to Ancient Greece. By the 14th century in Europe, nutcrackers were documented in England, including in the \"Canterbury Tales\", and in France. The lever design may derive from blacksmiths' pincers. Materials included metals such as silver, cast-iron and bronze, and wood including boxwood, especially those from France and Italy. More rarely, porcelain was used. Many of the wooden carved nutcrackers were in the form of people and animals.\nDuring the Victorian era, fruit and nuts were presented at dinner and ornate and often silver-plated nutcrackers were produced to accompany them on the dinner table. Nuts have long been a popular choice for desserts, particularly throughout Europe. The nutcrackers were placed on dining tables to serve as a fun and entertaining center of conversation while diners awaited their final course. At one time, nutcrackers were actually made of metals such as brass, and it was not until the 1800s in Germany that the popularity of wooden ones began to spread.\nThe late 19th century saw two shifts in nutcracker production: the rise in figurative and decorative designs, particularly from the Alps where they were sold as souvenirs, and a switch to industrial manufacture, including availability in mail-order catalogues, rather than artisan production. After the 1960s, the availability of pre-shelled nuts led to a decline in ownership of nutcrackers and a fall in the tradition of nuts being put in children's Christmas stockings.\nAlternative designs.\nIn the 17th century, screw nutcrackers were introduced that applied more gradual pressure to the shell, some like a vise. The spring-jointed nutcracker was patented by Henry Quackenbush in 1913. A ratchet design, similar to a car jack, that gradually increases pressure on the shell to avoid damaging the kernel inside is used by the Crackerjack, patented in 1947 by Cuthbert Leslie Rimes of Morley, Leeds and exhibited at the Festival of Britain. Unshelled nuts are still popular in China, where a key device is inserted into the crack in walnuts, pecans, and macadamias and twisted to open the shell.\nScrew nutcrackers are still commonly used to crack macadamia nuts, since their shell is too hard to be cracked with an ordinary nutcracker.\nFor crustaceans.\nA crab cracker (also known as a lobster cracker or crab claw cracker) is a specialized food utensil, similar in construction (and sometimes appearance) to certain types of nutcrackers, used to crack the hard shells of crabs and lobsters by pulling the two handles together to access the flesh inside, while preparing or eating them.\nDecorative.\nNutcrackers in the form of wood carvings of a soldier, knight, king, or other profession have existed since at least the 15th century. Figurative nutcrackers are a good luck symbol in Germany, and a folktale recounts that a puppet-maker won a nutcracking challenge by creating a doll with a mouth for a lever to crack the nuts. These nutcrackers portray a person with a large mouth which the operator opens by lifting a lever in the back of the figurine. Originally one could insert a nut in the big-toothed mouth, press down and thereby crack the nut. Modern nutcrackers in this style serve mostly for decoration, mainly at Christmas time, a season of which they have long been a traditional symbol. Pyotr Ilyich Tchaikovsky's ballet \"The Nutcracker\", based on a story by E. T. A. Hoffmann, derives its name from this festive holiday decoration.\nThe carving of nutcrackers\u2014as well as of religious figures and of cribs\u2014developed as a cottage industry in forested rural areas of Germany. The most famous nutcracker carvings come from Sonneberg in Thuringia (also a center of dollmaking) and Seiffen, as part of the industry of wooden toymaking in the Ore Mountains. Wood-carving usually provided the only income for the people living there. Today the travel industry supplements their income by bringing visitors to the remote areas. Carvings by famous names like Junghanel, Klaus Mertens, Karl, Olaf Kolbe, Petersen, Christian Ulbricht and especially the Steinbach nutcrackers have become collector's items.\nDecorative nutcrackers became popular in the United States after the Second World War, following the first US production of \"The Nutcracker\" ballet in 1940 and the exposure of US soldiers to the dolls during the war. In the United States, few of the decorative nutcrackers are now functional, though expensive working designs are still available. Many of the woodworkers in Germany were in Erzgebirge, in the Soviet zone after the end of the war, and they mass-produced poorly-made designs for the US market. With the increase in pre-shelled nuts, the need for functionality was also lessened. After the 1980s, Chinese and Taiwanese imports that copied the traditional German designs took over. The recreated \"Bavarian village\" of Leavenworth, Washington, features a nutcracker museum. Many other materials also serve to make decorated nutcrackers, such as porcelain, silver, and brass; the museum displays samples. The United States Postal Service (USPS) issued four stamps in October 2008 with custom-made nutcrackers made by Richmond, Virginia artist Glenn Crider.\nOther uses.\nSome artists, among them the multi-instrumentalist Mike Oldfield, have used the sound nutcrackers make in music.\nAn old belief among the Malay people in Southeast Asia states that an areca nutcracker (\"kacip pinang\") can be placed under a baby's pillow to prevent any harm from paranormal creatures.\nIn animals.\nMany animals shell nuts to eat them, including using tools. The Capuchin monkey is a fine example. Parrots use their beaks as natural nutcrackers, in much the same way smaller birds crack seeds. In this case, the pivot point stands opposite the nut, at the jaw, or the beak.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21949", "revid": "50022150", "url": "https://en.wikipedia.org/wiki?curid=21949", "title": "Nicolai Abildgaard", "text": "Danish painter, sculptor and architect (1743\u20131809)\nNicolai Abraham Abildgaard (11 September 1743\u00a0\u2013 4 June 1809) was a Danish neoclassical and royal history painter, sculptor, architect, and professor of painting, mythology, and anatomy at the New Royal Danish Academy of Art in Copenhagen, Denmark. Many of his works were in the royal Christiansborg Palace (some destroyed by fire 1794), Fredensborg Palace, and Levetzau Palace at Amalienborg.\nBiography.\nNicolai Abraham Abildgaard was born in Copenhagen, Denmark, as the son of Anne Margrethe (n\u00e9e Bastholm) and S\u00f8ren Abildgaard, a noted antiquarian draughtsman.\nAbildgaard was trained by a painting master before he joined the Royal Danish Academy of Art (\"Det Kongelige Danske Kunstakademi\") in Copenhagen, where he studied under the guidance of Johan Edvard Mandelberg and Johannes Wiedewelt. He won a series of medallions at the Academy for his brilliance from 1764 to 1767. The Large Gold Medallion from the Academy won in 1767 included a travel stipend, which he waited five years to receive. He assisted Professor Johan Mandelberg of the Academy as an apprentice around 1769 and for painting decorations for the royal palace at Fredensborg. These paintings are classical, influenced by French classical artists such as Claude Lorrain and Nicolas Poussin. Mandelberg had studied in Paris under Fran\u00e7ois Boucher.\nStudent travels.\nAlthough artists of that time usually journeyed to Paris for further studies, Abildgaard chose to travel to Rome, where he stayed from 1772 to 1777. He took a side trip to Naples in 1776 with Jens Juel. His ambitions focused in the genre of history painting. While in Rome, he studied Annibale Carracci's frescoes at the Palazzo Farnese and the paintings of Rafael, Titian, and Michelangelo. In addition he studied various other artistic disciplines (sculpture, architecture, decoration, wall paintings) and developed his knowledge of mythology, antiquities, anatomy, and perspective.\nIn the company of Swedish sculptor Johan Tobias Sergel and painter Johann Heinrich F\u00fcssli, he began to move away from the classicism he had learned at the Academy. He developed an appreciation for the literature of Shakespeare, Homer, and Ossian (the putative Gaelic poet). He worked with themes from Greek as well as Norse mythology, which placed him at the forefront of Nordic romanticism. He left Rome in June 1777 with the hope of becoming professor at the Academy in Copenhagen. He stopped for a stay in Paris and arrived in Denmark in December of the same year.\nAn academic and artistic career.\nIn 1778, soon after joining the Academy, he was appointed to a professorship. He taught mythology and anatomy in addition to painting of the neoclassical style. Beyond his position at the Academy, he was very productive as an artist from 1777 to 1794. He produced not only monumental works, but also smaller pieces such as vignettes and illustrations. He designed Old Norse costumes. He illustrated the works of Socrates and Ossian. Additionally he did some sculpting, etching, and authoring. He was interested in all manners of mythological, biblical, and literary allusion.\nHe taught some famous painters, including Asmus Jacob Carstens, sculptor Bertel Thorvaldsen, and painters J. L. Lund and Christoffer Wilhelm Eckersberg. After his death, Lund and Eckersberg went on to become his successors as Academy professors. Eckersberg, referred to as the \"Father of Danish painting,\" went on to lay the foundation for the period of art known as the Golden Age of Danish Painting, as professor at the same Academy.\nAs royal historical painter, Abildgaard was commissioned around 1780 by the Danish government to paint large monumental pieces, a history of Denmark, to decorate the entirety of the Knights' Room (\"Riddersal)\" at Christiansborg Palace. It was a prestigious and lucrative assignment. The paintings combined historical depictions with allegorical and mythological elements that glorified and flattered the government. The door pieces depicted, in allegory, four historical periods in Europe's history. Abilgaard used pictorial allegory like ideograms, to communicate ideas and transmit messages through symbols to a refined public who was initiated into this form of symbology. Abildgaard's professor Johan Edvard Mandelberg supplied the decorations to the room.\nHe made a failed attempt to be elected to the post of Academy Director in 1787 and was unanimously elected to the post two years later, serving as director during the period 1789\u20131791. He had the reputation for being a tyrant and for taking as many of the academy's monumental assignments as possible for himself.\nAbilgaard was also known as a religious freethinker and an advocate of political reform. In spite of his service to (and in his artwork the glorification of) the government, he was hardly a great supporter of the monarchy or of the state church. He supported the emancipation of the farmers and participated in the collection of monies for the Freedom Monument (\"Frihedsst\u00f8tten\") in 1792. He contributed a design for the monument, as well as for two of the reliefs at its base. He got drawn into controversies at the end of the 18th century because of his provocative statements and satirical drawings. He was inspired by the French Revolution, and in 1789\u20131790 he tried to incorporate these revolutionary ideals into the Knights' Room at Christiansborg Palace. However, the King rejected his designs.\nHis showdowns with the establishment culminated in 1794, when his allegorical painting \"Jupiter Weighs the Fate of Mankind\" (\"Jupiter vejer menneskenes sk\u00e6bne\") was exhibited at the Salon. He was politically isolated and cut out of the public debate by censors.\nThe fire at Christiansborg Palace, in February 1794, also had a dampening effect on his career, for seven of the ten monumental paintings of the grandiose project were destroyed in that accident. The project was stopped and so were his earnings. However, after that devastating fire accident, he started getting decorative assignments and also got the opportunity to practice as an architect. He decorated the Levetzau Palace (now known as Christian VIII's Palace) at Amalienborg (1794\u20131798), recently occupied home of King Christian VII of Denmark's half-brother Frederik. His prot\u00e9g\u00e9 Bertel Thorvaldsen headed the sculptural efforts. He also planned for rebuilding the Christiansborg Palace, but he could not get the assignment.\nAt the start of the 19th century, his interest in painting was restored when he painted four scenes from Terence's comedy \"Andria.\" In 1804 he received a commission for a series of paintings for the throne room in the new palace, but disagreements between the artist and the crown prince put a halt to this project. He continued, however, to provide the court with designs for furniture and room decorations.\nHe was once again selected to serve as the Academy's director from 1801 until his death.\nPersonal life.\nAbildgaard married Anna Marie \"Nancy\" Christiane Oxholm (1762\u20131822) in 1781. She gave birth to his son Marcus Aurelius the same year. However, he lived only to 4 years of age.\nWhen Abildgaard found out his wife was unfaithful with Reinhard von Eppingen, chamberlain at the Danish court, he forced the pair to flee in disgrace across the Sound to Helsingborg, Sweden, getting a divorce. His second marriage in 1803 was to Juliane Marie Ottesen (1777\u20131848). He had a further two sons and a daughter from this marriage. He died at Frederiksdal House in 1809. Nicolai Abraham Abildgaard is buried in Copenhagen's Assistens Cemetery.\nLegacy.\nThough Nicolai Abildgaard won immense fame in his own generation and helped lead the way to the period of art known as the Golden Age of Danish Painting, his works are scarcely known outside of Denmark. His style was classical, though with a romantic trend. According to the \"Encyclop\u00e6dia Britannica Eleventh Edition\", \"he was a cold theorist, inspired not by nature but by art. He had a keen sense of color. As a technical painter, he attained remarkable success, his tone being very harmonious and even, but the effect to a foreigner's eye is rarely interesting.\" A portrait of him painted by Jens Juel was made into a medallion by his friend Johan Tobias Sergel. August Vilhelm Saabye sculpted a statue of him in 1868, based on contemporary portraits.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21950", "revid": "48475498", "url": "https://en.wikipedia.org/wiki?curid=21950", "title": "Khyber Pakhtunkhwa", "text": "Province of Pakistan\nKhyber Pakhtunkhwa, commonly abbreviated KP or KPK and formerly known as the North-West Frontier Province (NWFP), is a province of Pakistan. Located in the northwestern region of the country, Khyber Pakhtunkhwa is the fourth largest province of Pakistan by land area and the third-largest province by population. It is bordered by Balochistan to the south; Punjab, Islamabad Capital Territory, and Azad Kashmir to the east; and Gilgit-Baltistan to the north and northeast. It shares an international border with Afghanistan to the west. Khyber Pakhtunkhwa has a varied geography of rugged mountain ranges, valleys, rolling foothills, and dense agricultural farms.\nThe history of the present province of Khyber Pakhtunkhwa is characterized by frequent invasions by various empires, largely due to its geographical proximity to the historically important Khyber Pass. It was the site of the ancient Gandhara, and was historically a stronghold of Buddhism. Islam became dominant in the region after the 11th-century conquest of the Hindu Shahi kingdom by the Ghaznavids. The predecessor of the present province was constituted in 1901, under the British Raj, when the North-West Frontier Province was created by bifurcating the northwestern districts of the erstwhile Punjab Province.\nAlthough it is colloquially known by a variety of other names, the name \"Khyber Pakhtunkhwa\" was brought into effect for the North-West Frontier Province in April 2010, following the enactment of the 18th Constitutional Amendment. On 24 May 2018, the National Assembly of Pakistan voted in favour of the 25th Constitutional Amendment, which merged the FATA as well as the Provincially Administered Tribal Areas into Khyber Pakhtunkhwa.\nWhile it is the third-largest Pakistani province in terms of both its population and its economy, it is geographically the smallest. Khyber Pakhtunkhwa's share of Pakistan's GDP has historically comprised 10.5%, amounting to over US$ 30 billion. The population of the province forms 16.9% of Pakistan's total population and is multiethnic, with the main ethnic groups being the Pashtuns, Hindkowans, Saraikis, and Chitralis, among others.\nEtymology.\n\"Khyber Pakhtunkhwa\" means the \"Khyber side of the land of the Pashtuns\", where the word \"Pakhtunkhwa\" means \"Land of the Pashtuns\", while according to some scholars, it refers to \"Pashtun culture and society\". The province has had various names throughout history. Other names used or proposed for the province include Gandhara, Afghania, Pashtunistan, Pathanistan, Sarhad, Abaseen, Khyber,&lt;ref name=\"Khan/Toosi\"&gt;&lt;/ref&gt; or a combination of names, such as Hazara-Pakhtunkhwa.\nWhen the British established it as a province, they called it \"North West Frontier Province\" (abbreviated as NWFP) due to its relative location being in the northwest of the British Indian Empire. After the creation of Pakistan, Pakistan continued with this name but a Pashtun political party, Awami National Party based in the province demanded that the province name be changed to \"Pakhtunkhwa\". Their logic behind that demand was that Punjabi people, Sindhi people and Baloch people have their provinces named after their ethnicities but that is not the case for Pashtun people.\nPakistan Muslim League (N), the largest opposition party at the time was ready to change the province's name by supporting the ruling Pakistan Peoples Party and ANP, in a constitutional amendment but wanted to name the province something which does not carry an exclusively Pashtun identity in it as they argued that there were other minor communities living in the province especially the Hazarewals of the Hazara region who spoke Hindko thus the word \"Khyber\" was introduced with the name because it is the name of a major pass which connects Pakistan to Afghanistan.\nNorth-West Frontier Province.\nFor over a hundred years after its founding as a province of British Raj in 1901, it was known as the North-West Frontier Province (abbreviated as NWFP) until 2010 due to its relative location being in the northwest of the nation. Unofficially, it was known as \"Sarhad\" (), derived from the province's Urdu name given to it by the Mughals, which means \"frontier\".\nFor most of the history of the North-West Frontier Province (NWFP), there were efforts to change its name. The name \"Afghania\" was proposed first by the founding leaders of the Muslim League in 1933 and was at least partly chosen to represent the first \"a\" in \"Pakistan\". The need for a change was explained by the man who named Pakistan in his \"Now or Never\" pamphlet, Choudhary Rahmat Ali Khan, as:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"North-West Frontier Province\" is semantically non-descript and socially wrongful. It is non-descript because it merely indicates their geographical situation as a province of old \"British India\" [which no longer exists]. It is wrongful because it suppresses the social entity of these people. In fact, it suppresses that entity so completely that when composing the name \"Pakistan\" for our homelands, I had to call the North-West Frontier Province the Afghan Province.\nSuggestions for new names came and went. Although some of the names were ethnically neutral, most proposals emphasised the province's Pashtun ethnic identity. The renaming issue was an emotional one which often crossed party lines and not all supporters of a renaming agreed on the name Pakhtunkhwa.\n20th-century proposals.\nBy the late 20th century, President Muhammad Zia-ul-Haq agreed with Khan Abdul Ghaffar Khan to change the name to \"Pashtunistan\" but he contended that the term Pashtunistan had become controversial and was being politicized by Afghanistan. Ghaffar Khan suggested Pakhtunkhwa, but Zia-ul-Haq asked Ghaffar Khan to suggest an alternative.\nThe name Pakhtunkhwa was approved by the democratically elected constitutional assembly of the province in 1997 by majority vote. However, the PML (N) parliamentary party of NWFP rejected the ANP demand but called for Prime Minister Nawaz Sharif to suggest another \"non-controversial\" name. PML (N) members noted that Sarhad was a good name for the province but, if a change was needed, then it should be named Khyber or Abasin. The NWFP chief minister, Sardar Mehtab Ahmed Khan, called for a referendum on the issue as a way of determining the name. These offers were rejected by the ANP leadership and the ANP withdrew from both the federal and provincial governments.\n21st-century proposals.\nThe lack of support for a name change by the PML (N) was defended as opposition to the nationalistic politics being pursued by the ANP.\nIn May 2008, to accommodate a demand by the people of NWFP who voted for the ANP, the PPP proposed that the name of the North-West Frontier Province be changed to Pakhtunkhwa, however the Muslim League Nawaz which had considerable support in the Hindko-speaking Hazara region of the province announced it might oppose the name change because of it \"being on ethnic grounds\" because of opposition by its provincial leadership.\nThe name \"Pakhtunkhwa\" was mentioned for the first time in the United Nation's General Assembly by Pakistani President Asif Zardari on 26 September 2008.\nKhyber Pakhtunkhwa.\nThe Pashtun nationalist Awami National Party based in the province demanded that the province name be changed to \"Pakhtunkhwa\". Their logic behind that demand was that Punjabi people, Sindhi people and Baloch people have their provinces named after their ethnicities but that is not the case for Pashtun people.\nPakistan Muslim League (N), the largest opposition party at the time was ready to change the province's name by supporting the ruling Pakistan Peoples Party and ANP, in a constitutional amendment but wanted to name the province something other than which does not carry only the Pashtun identity in it as they argued that there were other minor communities living in the province especially the Hazarewals of the Hazara region who spoke Hindko thus the word \"Khyber\" was introduced with the name because it is the name of a major pass which connects Pakistan to Afghanistan.\nIn early 2010, the process of renaming proceeded and the Pakistani Senate confirmed the name change to \"Khyber Pakhtunkhwa\" in the 18th amendment to the Constitution of Pakistan with a unanimous 90 votes on 15 April 2010.\nRenaming controversy.\nThe name change of the province was met with strong opposition from the people of Hazara region and protests erupted in the region with wheel and shutter jam strikes. Abbottabad became the nerve center of the movement. On 10 April, the Khyber Pakhtunkhwa Police fired at unarmed protesters, leaving 7 dead and dozens injured. Allegedly, the firing was ordered by the coalition government of Khyber Pakhtunkhwa, led by the Awami National Party. This is one of the earliest incidents of police brutality in Pakistan in recent years, occurring before the Model Town Lahore incident, whose FIR has not been registered still today.\nArif Nizami, former editor of \"The Nation\", said, \"This has actually opened a Pandora's box, because of Pakistan's very tenuous polity. Now, on one side, there are identity issues and ethnic issues and provincial autonomy issues. The other side is religious issues and terrorism. It's a very explosive situation.\"\nAlternative proposed names.\nMany alternative names were proposed for the province. Many of these were designed to avoid or balance the ethnic connotations of Pakhtunkhwa.\nGandhara.\nThe name Gandh\u0101ra was proposed by Pakistan Muslim League (N), as a neutral name for the province. Gandhara was an ancient Indo-Aryan civilization centered in the present-day province. The core of the region of Gandhara was the Peshawar valley and Swat valley, though the cultural influence of \"Greater Gandhara\" extended across the Indus river to the Taxila region in Potohar Plateau and westwards into the Kabul valley in Afghanistan, and northwards up to the Karakoram range.\nIt was attested in the Rigveda, and it was one of the 16 Mahajanapadas of the second urbanisation. The region was a major centre for Greco-Buddhism under the Indo-Greeks and Gandharan Buddhism under later dynasties, including Indo-Scythians, Indo-Parthians and Kushans. Gandhara was also a central location for the spread of Buddhism to Central Asia and East Asia.\nG\u0101ndh\u0101r\u012b, an Indo-Aryan language written in Kharosthi script, acted as lingua franca of the region. Famed for its unique Gandharan style of art which is influenced by the classical Hellenistic styles, Gandhara attained its height from the 1st century to the 5th century CE under the Kushan Empire, who had their capital at Peshawar (\"Puru\u1e63apura\").\nHazara-Pakhtunkhwa.\nSome Hazara residents said that the new name should be Hazara-Pakhtunkhwa (in reference to the Hazara region where Hindko-speakers are dominant as compared to the Pashto-speakers elsewhere in the province), and others said the name should not be changed since the people were accustomed to North-West Frontier Province.\nHistory.\nEarly history.\nDuring the times of Indus Valley Civilisation (3300 BCE \u2013 1700 BCE) the Khyber Pass through Hindu Kush provided a route to other neighbouring empires and was used by merchants on trade excursions. From 1500 BCE, Indo-Iranian peoples started to enter in the region from Central Asia after having passed the Khyber Pass.\nThe region of Gandhara, which was primarily based in the area of modern-day Khyber Pakhtunkhwa features prominently in the Rigveda (c.\u20091500\u00a0\u2013 c.\u20091200 BCE), as well as the Zoroastrian Avesta, which mentions it as \"Va\u0113k\u0259r\u0259ta\", the sixth most beautiful place on earth created by Ahura Mazda. It was one of the 16 Mahajanapadas of Vedic era. It was the centre of Vedic and later forms of Hinduism. Gandhara was frequently mentioned in Vedic epics, including Rig Veda, Ramayana and Mahabharata. It was the home of Gandhari, the princess of Gandhara Kingdom.\nAlexander's conquests.\nIn the spring of 327 BC Alexander the Great crossed the Hindu Kush and advanced to Nicaea, where Omphis, king of Taxila and other chiefs joined him. Alexander then dispatched part of his force through the valley of the Kabul River, while he himself advanced into Bajaur and Swat with his light troops. Craterus was ordered to fortify and repopulate Arigaion, probably in Bajaur, which its inhabitants had burnt and deserted. Having defeated the Aspasians, from whom he took 40,000 prisoners and 230,000 oxen, Alexander crossed the Gouraios (Panjkora) and entered the territory of the Assakenoi and laid siege to Massaga, which he took by storm. Ora and Bazira (possibly Bazar) soon fell. The people of Bazira fled to the rock Aornos, but Alexander made Embolima (possibly Amb) his base, and attacked the rock from there, which was captured after a desperate resistance. Meanwhile, Peukelaotis (in Hashtnagar, north-west of Peshawar) had submitted, and Nicanor, a Macedonian, was appointed satrap of the country west of the Indus.\nMauryan rule.\nMauryan rule began with Chandragupta Maurya displacing the Nanda Empire, establishing the Mauryan Empire. A while after, Alexander's general Seleucus had attempted to once again invade the subcontinent from the Khyber pass hoping to take lands that Alexander had conquered, but never fully absorbed into this empire. Seleucus was defeated and the lands of Aria, Arachosia, Gandhara, and Gedrosia were ceded to the Mauryans in exchange for a matrimonial alliance and 500 elephants. With the defeat of the Greeks, the land was once more under Hindu rule. Chandragupta's son Bindusara further expanded the empire. However, it was Chandragupta's grandson Ashoka, who converted to Buddhism and made it the official state religion in Gandhara and also Pakhli, the modern Hazara, as evidenced by rock-inscriptions at Shahbazgarhi and Mansehra.\nAfter Ashoka's death the Mauryan empire fell to pieces, just as in the west the Seleucid power was waning.\nIndo-Greeks.\nThe Indo-Greek king Menander I (reigned 155\u2013130 BCE) drove the Greco-Bactrians out of Gandhara and beyond the Hindu Kush, becoming king shortly after his victory.\nHis empire survived him in a fragmented manner until the last independent Greek king, Strato II, disappeared around 10 CE. Around 125 BCE, the Greco-Bactrian king Heliocles, son of Eucratides, fled from the Yuezhi invasion of Bactria and relocated to Gandhara, pushing the Indo-Greeks east of the Jhelum River. The last known Indo-Greek ruler was Theodamas, from the Bajaur area of Gandhara, mentioned on a 1st-century CE signet ring, bearing the Kharo\u1e63\u1e6dh\u012b inscription \"Su Theodamasa\" (\"Su\" was the Greek transliteration of the Kushan royal title \"Shau\" (\"Shah\" or \"King\")).\nIt is during this period that the fusion of Hellenistic and South Asian mythological, artistic and religious elements becomes most apparent, especially in the region of Gandhara.\nLocal Greek rulers still exercised a feeble and precarious power along the borderland, but the last vestige of the Greco-Indian rulers were finished by a people known to the old Chinese as the Yeuh-Chi.\nIndo-Scythian Kingdom.\nThe Indo-Scythians were descended from the Sakas (Scythians) who migrated from Central Asia into South Asia from the middle of the 2nd century BCE to the 1st century BCE. They displaced the Indo-Greeks and ruled a kingdom that stretched from Gandhara to Mathura. The first Indo-Scythian king Maues established Saka hegemony by conquering Indo-Greek territories. The power of the Saka rulers declined after the defeat to Chandragupta II of the Gupta Empire in the 4th century.\nIndo-Parthian Kingdom.\nThe Indo-Parthian Kingdom was ruled by the Gondopharid dynasty, named after its first ruler Gondophares. For most of their history, the leading Gondopharid kings held Taxila (in the present Punjab province of Pakistan) as their residence, but during their last few years of existence the capital shifted between Kabul and Peshawar. These kings have traditionally been referred to as Indo-Parthians, as their coinage was often inspired by the Arsacid dynasty, but they probably belonged to a wider groups of Iranic tribes who lived east of Parthia proper, and there is no evidence that all the kings who assumed the title \"Gondophares\", which means \"Holder of Glory\", were even related.\nKushan Empire.\nThe Yuezhi nomads had driven the Sakas from the highlands of Central Asia, and were themselves forced southwards by the nomadic Xiongnu. One group, known as the Kushan, took the lead, and its chief, Kadphises I, seized vast territories extending south to the Kabul valley. His son Kadphises II conquered North-Western India, which he governed through his generals. His immediate successors were the fabled Hindu kings: Kanishka, Huvishka, and Vasushka or Vasudeva, of whom the first reigned over a territory which extended as far east as Benares, far south as Malwa, and also including Bactria and the Kabul valley. Their dates are still a matter of dispute, but it is beyond question that they reigned early in the Christian era. To this period may be ascribed the fine statues and bas-reliefs found in Gandhara and Udyana. Under Huvishka's successor, Vasushka, the dominions of the Kushan kings shrank.\nShahi dynasties.\nThe Turk Shahis ruled Gandhara until 870, when they were overthrown by the Hindu Shahis. The Hindu Shahis are believed to belong to the U\u1e0di/O\u1e0di tribe, namely the people of Oddiyana (modern Swat) in Gandhara, although they are also variously stated to be Br\u0101hm\u0101ns or Ksh\u0101triyas.\nThe first king Kallar had moved the capital into Udabandhapura from Kabul, in the modern village of Hund for its new capital. At its zenith, the kingdom stretched over the Kabul Valley, Gandhara and western Punjab under Jayapala. Jayapala saw a danger in the consolidation of the Ghaznavids and invaded their capital city of Ghazni both in the reign of Sebuktigin and in that of his son Mahmud, which initiated the Muslim Ghaznavid and Hindu Shahi struggles. Sebuk Tigin, however, defeated him, and he was forced to pay an indemnity. Jayapala defaulted on the payment and took to the battlefield once more. Jayapala however, lost control of the entire region between the Kabul Valley and Indus River.\nIn the year 1001, soon after Sultan Mahmud came to power and was occupied with the Qarakhanids north of the Hindu Kush, Jaipal attacked Ghazni once more and upon suffering yet another defeat by the powerful Ghaznavid forces, near present-day Peshawar. After the Battle of Peshawar, he died because of regretting as his subjects brought disaster and disgrace to the Shahi dynasty.\nJayapala was succeeded by his son Anandapala, who along with other succeeding generations of the Shahiya dynasty took part in various unsuccessful campaigns against the advancing Ghaznvids but were unsuccessful. The Hindu rulers eventually exiled themselves to the Kashmir Siwalik Hills.\nGhaznavids.\nAfter the battle of Peshawar, Mahmud of Ghazni had secured controlled over southern regions of Pakhtunkhwa. He also (1024 and 1025) raided the Pashtuns. His descendants reigned till 1179, when Muhammad of Ghor took Peshawar, making it part of his expanding Ghurid Empire.\nDelhi sultanate.\nFollowing the invasion by the Ghurids, five unrelated heterogeneous dynasties ruled over the Delhi Sultanate sequentially: the Mamluk dynasty (1206\u20131290), the Khalji dynasty (1290\u20131320), the Tughlaq dynasty (1320\u20131414), the Sayyid dynasty (1414\u20131451), and the Lodi dynasty (1451\u20131526).\nMeanwhile, the Pashtuns now appeared as a political factor. At the close of the fourteenth century they were firmly established in their present-day demographics south of Kohat, and in 1451 Bahlol Lodi's accession to the throne of Delhi gave them a dominant position in Northern India. Yusufzai tribes from the Kabul and Jalalabad valleys began migrating to the Valley of Peshawar beginning in the 15th century, and displaced the Swatis of the Bhittani confederation and Dilazak Pashtun tribes across the Indus River to Hazara Division.\nMughal empire.\nMughal suzerainty over the Khyber Pakhtunkhwa region was partially established after Babar, the founder of the Mughal Empire, invaded the region in 1505 CE via the Khyber Pass. The Mughal Empire noted the importance of the region as a weak point in their empire's defences, and determined to hold Peshawar and Kabul at all cost against any threats from the Uzbek \"Shaybanids\".\nHe was forced to retreat westwards to Kabul but returned to defeat the Lodis in July 1526, when he captured Peshawar from Daulat Khan Lodi, though the region was never considered to be fully subjugated to the Mughals.\nUnder the reign of Babar's son, Humayun, a direct Mughal rule was briefly challenged with the rise of the Pashtun Emperor, Sher Shah Suri, who began construction of the famous Grand Trunk Road \u2013 which links Kabul, Afghanistan with Chittagong, Bangladesh over 2000 miles to the east. Later, local rulers once again pledged loyalty to the Mughal emperor.\nYusufzai tribes rose against Mughals during the Yusufzai Revolt of 1667, and engaged in pitched-battles with Mughal battalions in Peshawar and Attock. Afridi tribes resisted Aurangzeb rule during the Afridi Revolt of the 1670s. The Afridis massacred a Mughal battalion in the Khyber Pass in 1672 and shut the pass to lucrative trade routes. Following another massacre in the winter of 1673, Mughal armies led by Emperor Aurangzeb himself regained control of the entire area in 1674, and enticed tribal leaders with various awards in order to end the rebellion.\nReferred to as the \"Father of Pashto Literature\" and hailing from the city of Akora Khattak, the warrior-poet Khushal Khan Khattak actively participated in the revolt against the Mughals and became renowned for his poems that celebrated the rebellious Pashtun warriors.\nOn 18 November 1738, Peshawar was captured from the Mughal governor Nawab Nasir Khan by the Afsharid armies during the Persian invasion of the Mughal Empire under Nader Shah.\nDurrani Empire.\nThe area fell subsequently under the rule of Ahmad Shah Durrani, founder of the Durrani Empire, following a grand nine-day long assembly of leaders, known as the \"loya jirga\". In 1749, the Mughal ruler was induced to cede Sindh, the Punjab region and the important trans Indus River to Ahmad Shah in order to save his capital from the Durrani attack. Ahmad Shah invaded the remnants of the Mughal Empire a third time, and then a fourth, consolidating control over the Kashmir and Punjab regions. In 1757, he captured Delhi and sacked Mathura, but permitted the Mughal dynasty to remain in nominal control of the city as long as the ruler acknowledged Ahmad Shah's suzerainty over Punjab, Sindh, and Kashmir. Leaving his second son Timur Shah to safeguard his interests, Ahmad Shah left India to return to Afghanistan.\nTheir rule was interrupted by a brief invasion of the Hindu Marathas, who ruled over the region following the 1758 Battle of Peshawar for eleven months till early 1759 when the Durrani rule was re-established.\nUnder the reign of Timur Shah, the Mughal practice of using Kabul as a summer capital and Peshawar as a winter capital was reintroduced, Peshawar's Bala Hissar Fort served as the residence of Durrani kings during their winter stay in Peshawar.\nMahmud Shah Durrani became king, and quickly sought to seize Peshawar from his half-brother, Shah Shujah Durrani. Shah Shujah was then himself proclaimed king in 1803, and recaptured Peshawar while Mahmud Shah was imprisoned at Bala Hissar fort until his eventual escape. In 1809, the British sent an emissary to the court of Shah Shujah in Peshawar, marking the first diplomatic meeting between the British and Afghans. Mahmud Shah allied himself with the \"Barakzai\" Pashtuns, and amassed an army in 1809, and captured Peshawar from his half-brother, Shah Shujah, establishing Mahmud Shah's second reign, which lasted under 1818.\nSikh Empire.\nRanjit Singh invaded Peshawar in 1818 and captured it from the Durrani Empire. The Sikh Empire based in Lahore did not immediately secure direct control of the Peshawar region, but rather paid nominal tribute to Jehandad Khan of Khattak, who was nominated by Ranjit Singh to be ruler of the region.\nAfter Ranjit Singh's departure from the region, Khattak's rule was undermined and power seized by Yar Muhammad Khan. In 1823, Ranjit Singh returned to capture Peshawar, and was met by the armies of Azim Khan at Nowshera. Following the Sikh victory at the Battle of Nowshera, Ranjit Singh re-captured Peshawar. Rather than re-appointing Jehandad Khan of Khattak, Ranjit Singh selected Yar Muhammad Khan to once again rule the region.\nThe Sikh Empire annexed the lower parts of Khyber Pakhtunkhwa region following advances from the armies of Hari Singh Nalwa. An 1835 attempt by Dost Muhammad Khan to re-occupy Peshawar failed when his army declined to engage in combat with the Dal Khalsa. Dost Muhammad Khan's son, Mohammad Akbar Khan engaged with Sikh forces the Battle of Jamrud of 1837, in which prominent sikh commander Hari Singh was killed.\nDuring Sikh rule, an Italian named Paolo Avitabile was appointed an administrator of Peshawar in 1838, and is remembered for having unleashed a reign of fear there. The city's famous Mahabat Khan, built in 1630 in the Jeweller's Bazaar, was badly damaged and desecrated by the Sikhs, who also rebuilt the Bala Hissar fort during their occupation of Peshawar.\nBritish Raj.\nBritish East India Company defeated the Sikhs during the Second Anglo-Sikh War in 1849, and incorporated small parts of the region into the Province of Punjab. While Peshawar was the site of a small revolt against British during the Mutiny of 1857, local Pashtun tribes throughout the region generally remained neutral or supportive of the British as they detested the Sikhs, in contrast to other parts of British India which rose up in revolt against the British. However, British control of parts of the region was routinely challenged by Wazir tribesmen in Waziristan and other Pashtun tribes, who resisted any foreign occupation until Pakistan was created. By the late 19th century, the official boundaries of Khyber Pakhtunkhwa region still had not been defined as the region was still claimed by the Kingdom of Afghanistan. It was only in 1893 The British demarcated the boundary with Afghanistan under a treaty agreed to by the Afghan king, Abdur Rahman Khan, following the Second Anglo-Afghan War. Several princely states within the boundaries of the region were allowed to maintain their autonomy under the terms of maintaining friendly ties with the British. As the British war effort during World War One demanded the reallocation of resources from British India to the European war fronts, some tribesmen from Afghanistan crossed the Durand Line in 1917 to attack British posts in an attempt to gain territory and weaken the legitimacy of the border. The validity of the Durand Line, however, was re-affirmed in 1919 by the Afghan government with the signing of the Treaty of Rawalpindi, which ended the Third Anglo-Afghan War \u2013 a war in which Waziri tribesmen allied themselves with the forces of Afghanistan's King Amanullah in their resistance to British rule. The Wazirs and other tribes, taking advantage of instability on the frontier, continued to resist British occupation until 1920 \u2013 even after Afghanistan had signed a peace treaty with the British.\nBritish campaigns to subdue tribesmen along the Durand Line, as well as three Anglo-Afghan wars, made travel between Afghanistan and the densely populated heartlands of Khyber Pakhtunkhwa increasingly difficult. The two regions were largely isolated from one another from the start of the Second Anglo-Afghan War in 1878 until the start of World War II in 1939 when conflict along the Afghan frontier largely dissipated. Concurrently, the British continued their large public works projects in the region, and extended the Great Indian Peninsula Railway into the region, which connected the modern Khyber Pakhtunkhwa region to the plains of India to the east. Other projects, such as the Attock Bridge, Islamia College University, Khyber Railway, and establishment of cantonments in Peshawar, Kohat, Mardan, and Nowshera further cemented British rule in the region. In 1901, the British carved out the northwest portions of Punjab Province to create the Northwest Frontier Province (NWFP), which was renamed \"Khyber Pakhtunkhwa\" in 2010.\nDuring this period, North-West Frontier Province was a \"scene of repeated outrages on Hindus.\" During the independence period there was a Congress-led ministry in the province, which was led by secular Pashtun leaders, including Bacha Khan, who preferred joining India instead of Pakistan. The secular Pashtun leadership was also of the view that if joining India was not an option then they should espouse the cause of an independent ethnic Pashtun state rather than Pakistan. In June 1947, Mirzali Khan, Bacha Khan, and other Khudai Khidmatgars declared the Bannu Resolution, demanding that the Pashtuns be given a choice to have an independent state of Pashtunistan composing all Pashtun majority territories of British India, instead of being made to join the new state of Pakistan. However, the British Raj refused to comply with the demand of this resolution, as their departure from the region required regions under their control to choose either to join India or Pakistan, with no third option. By 1947 Pashtun nationalists were advocating for a united India, and no prominent voices advocated for a union with Afghanistan.\nThe secular stance of Bacha Khan had driven a wedge between the ulama of the otherwise pro-Congress (and pro-Indian unity) Jamiat Ulema Hind (JUH) and Bacha Khan's Khudai Khidmatgars.\nThere were other tensions in the area as well, particularly those that involved agitations by Pashtun tribesmen against the Imperial government. For example, in 1936, a British Indian court ruled against the marriage of a Hindu girl allegedly converted to Islam in Bannu, after the girl's family filed a case of abduction and forced conversion. The ruling was based on the fact that the girl was a minor and was asked to make her decision of conversion and marriage after she reaches the age of majority, till then she was asked to live with a third party. After the girl's family filed a case, the court ruled in the family's favour, angering the local Muslims who had later gone on to lead attacks against the Bannu Brigade.\nSuch controversies stirred up anti-Hindu sentiments amongst the province's Muslim population. By 1947 the majority of the ulama in the province began supporting the Muslim League's idea of Pakistan.\nImmediately prior to 1947 Partition of India, the British held a referendum in the NWFP to allow voters to choose between joining India or Pakistan. The polling began on 6 July 1947 and the referendum results were made public on 20 July 1947. According to the official results, there were 572,798 registered voters, out of which 289,244 (99.02%) votes were cast in favour of Pakistan, while 2,874 (0.98%) were cast in favour of India. The Muslim League declared the results as valid since over half of all eligible voters backed the merger with Pakistan.\nThe then Chief Minister Dr. Khan Sahib, along with his brother Bacha Khan and the Khudai Khidmatgars, boycotted the referendum, citing that it did not have the options of the NWFP becoming independent or joining Afghanistan.\nTheir appeal for boycott had an effect, as according to an estimate, the total turnout for the referendum was 15% lower than the total turnout in the 1946 elections, although over half of all eligible voters backed merger with Pakistan.\nBacha Khan pledged allegiance to the new state of Pakistan in 1947, and thereafter abandoned his goals of an independent Pashtunistan and a united India in favour of supporting increased autonomy for the NWFP within Pakistan. He was subsequently arrested several times for his opposition to the strong centralized rule. He later claimed that \"Pashtunistan was never a reality\". The idea of Pashtunistan never helped Pashtuns and it only caused suffering for them. He further claimed that the \"successive governments of Afghanistan only exploited the idea for their own political goals\".\nPost-independence.\nThere had been tensions between Pakistan and Afghanistan ever since Afghanistan voted against Pakistan's inclusion in the United Nations in 1948. After the creation of Pakistan in 1947, Afghanistan was the sole member of the United Nations to vote against Pakistan's accession to the UN because of Kabul's claim to the Pashtun territories on the Pakistani side of the Durand Line. Afghanistan's loya jirga of 1949 declared the Durand Line invalid. This led to border tensions with Pakistan. Afghanistan's governments have periodically refused to recognize Pakistan's inheritance of British treaties regarding the region. As had been agreed to by the Afghan governments following the Second Anglo-Afghan War, and after the treaty ending Third Anglo-Afghan War, no option was available to cede the territory to the Afghans, even though Afghanistan continued to claim the entire region as it was part of the Durrani Empire prior the conquest of the region by the Sikhs in 1818.\nDuring the 1950s, Afghanistan supported the Pushtunistan Movement, a secessionist movement that failed to gain substantial support amongst the tribes of the North-West Frontier Province. Afghanistan's refusal to recognize the Durrand Line, and its subsequent support for the Pashtunistan Movement has been cited as the main cause of tensions between the two countries that have existed since Pakistan's independence.\nAfter the Afghan-Soviet War, Khyber Pakhtunkhwa has become one of the areas of top focus for the War against Terror. The province has been reported to struggle with the issues of crumbling schools, non-existent healthcare, and lack of any sound infrastructure while areas such as Islamabad and Rawalpindi receive priority funding.\nIn 2010, the name of the province changed to \"Khyber Pakhtunkhwa\". Protests arose among the locals of the Hazara division due to this name change, as they began to demand their own province. Seven people were killed and 100 injured in protests on 11 April 2011.\nThe Provincial Assembly of Khyber Pakhtunkhwa approved a bill on 28 May 2018 to merge the FATA as well as the Provincially Administered Tribal Areas into Khyber Pakhtunkhwa following the approval of the Twenty-fifth Amendment to the Constitution of Pakistan by the national legislature; it was signed into law on 31 May by then President of Pakistan Mamnoon Hussain, which officially completed the administrative merger process.\nGeography.\nKhyber Pakhtunkhwa sits primarily on the Iranian plateau and comprises the junction where the slopes of the Hindu Kush mountains on the Eurasian Plate give way to the Indus-watered hills approaching South Asia. This situation has led to seismic activity in the past. The famous Khyber Pass links the province to Afghanistan, while the Kohalla Bridge in Circle Bakote Abbottabad is a major crossing point over the Jhelum River in the east.\nGeographically the province could be divided into two zones: the northern zone extending from the ranges of the Hindu Kush to the borders of the Peshawar basin and the southern zone extending from Peshawar to the Derajat basin.\nThe northern zone is cold and snowy in winters with heavy rainfall and pleasant summers with the exception of the Peshawar basin, which is hot in summer and cold in winter. It has moderate rainfall.\nThe southern zone is arid with hot summers and relatively cold winters and scanty rainfall. The Sheikh Badin Hills, a spur of clay and sandstone hills that stretch east from the Sulaiman Mountains to the Indus River, separates Dera Ismail Khan District from the \"Marwat\" plains of the Lakki Marwat. The highest peak in the range is the limestone Sheikh Badin Mountain, which is protected by the Sheikh Badin National Park. Near the Indus River, the terminus of the Sheikh Badin Hills is a spur of limestone hills known as the \"Kafir Kot\" hills, where the ancient Hindu complex of Kafir Kot is located.\nThe major rivers that criss-cross the province are Kabul, Swat, Chitral, Kunar, Siran, Panjkora, Bara, Kurram, Dor, Haroo, Gomal, and Zhob.\nIts snow-capped peaks and lush green valleys of unusual beauty have enormous potential for tourism.\nClimate.\nThe climate of Khyber Pakhtunkhwa varies immensely for a region of its size, encompassing most of the many climate types found in Pakistan. The province stretching southwards from the Baroghil Pass in the Hindu Kush covers almost six degrees of latitude; it is mainly a mountainous region. Dera Ismail Khan is one of the hottest places in South Asia while in the mountains to the north the weather is mild in the summer and intensely cold in the winter. The air is generally very dry; consequently, the daily and annual range of temperature is quite large.\nRainfall also varies widely. Although large parts of Khyber Pakhtunkhwa are typically dry, the province also contains the wettest parts of Pakistan in its eastern fringe especially in monsoon season from mid-June to mid-September.\nUpper and Lower Chitral Districts.\nUpper Chitral District and Lower Chitral District, due to their location, are completely sheltered from the monsoon that controls the weather in eastern Pakistan, owing to its relatively westerly location and the shielding effect of the Nanga Parbat massif. In many ways, they have more in common regarding climate with Central Asia than South Asia. The winters are generally cold even in the valleys, and heavy snow during the winter blocks passes and isolates the region. In the valleys, however, summers can be hotter than on the windward side of the mountains due to lower cloud cover: Chitral can reach frequently during this period. However, the humidity is extremely low during these hot spells and, as a result, the summer climate is less torrid than in the rest of the Indian subcontinent.\nMost precipitation falls as thunderstorms or snow during winter and spring, so that the climate at the lowest elevations is classed as Mediterranean (\"Csa\"), continental Mediterranean (\"Dsa\") or semi-arid (\"BSk\"). Summers are extremely dry in the north of Chitral district and receive only a little rain in the south around Drosh.\nAt elevations above , as much as a third of the snow which feeds the large Karakoram and Hindukush glaciers comes from the monsoon since these elevations are too high to be shielded from its moisture.\nCentral Khyber Pakhtunkhwa.\nOn the southern flanks of Nanga Parbat and in Upper and Lower Dir Districts, rainfall is much heavier than further north because moist winds from the Arabian Sea are able to penetrate the region. When they collide with the mountain slopes, winter depressions provide heavy precipitation. The monsoon, although short, is generally powerful. As a result, the southern slopes of Khyber Pakhtunkhwa are the wettest part of Pakistan. Annual rainfall ranges from around in the most sheltered areas to as much as in parts of Abbottabad and Mansehra Districts.\nThis region's climate is classed at lower elevations as humid subtropical (\"Cfa\" in the west; \"Cwa\" in the east); whilst at higher elevations with a southerly aspect, it becomes classed as humid continental (\"Dfb\"). However, accurate data for altitudes above are practically nonexistent here, in Chitral, or in the south of the province.\nThe seasonality of rainfall in central Khyber Pakhtunkhwa shows very marked gradients from east to west. At Dir, March remains the wettest month due to frequent frontal cloud bands, whereas in Hazara more than half the rainfall comes from the monsoon. This creates a unique situation characterized by a bimodal rainfall regime, which extends into the southern part of the province described below.\nSince cold air from the Siberian High loses its chilling capacity upon crossing the vast Karakoram and Himalaya ranges, winters in central Khyber Pakhtunkhwa are somewhat milder than in Chitral. Snow remains very frequent at high altitudes but rarely lasts long on the ground in the major towns and agricultural valleys. Outside of winter, temperatures in central Khyber Pakhtunkhwa are not so hot as in Chitral. \nSignificantly higher humidity when the monsoon is active means that heat discomfort can be greater. However, even during the most humid periods the high altitudes typically allow for some relief from the heat overnight.\nSouthern Khyber Pakhtunkhwa.\nAs one moves further away from the foothills of the Himalaya and Karakoram ranges, the climate changes from the humid subtropical climate of the foothills to the typically arid climate of Sindh, Balochistan and southern Punjab. As in central Khyber Pakhtunkhwa, the seasonality of precipitation shows a very sharp gradient from west to east, but the whole region very rarely receives significant monsoon rainfall. Even at high elevations, annual rainfall is less than and in some places as little as .\nTemperatures in southern Khyber Pakhtunkhwa are extremely hot: Dera Ismail Khan in the southernmost district of the province is known as one of the hottest places in the world with temperatures known to have reached . In the cooler months, nights can be cold and frosts remain frequent; snow is very rare, and daytime temperatures remain comfortably warm with abundant sunshine.\nNational parks.\nThere are about 37 national parks in Pakistan, 8 out of these are in Khyber Pakhtunkhwa.\nDemographics.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nThe province is home to 16.9 percent of Pakistan's total population. It had a population of 40.9 million at the time of the 2023 Census of Pakistan. About 85% of the population lived in rural areas.\nEthnicity.\nThe largest ethnic group are the Pashtuns, who have been living in the region for centuries. It has been estimated that up to one-third of the province's population is non-Pashtun, mainly concentrated in the northern areas. Hindkowans are the second largest ethnic group in the province, mainly settled in the Hazara region in northeast (particularly the districts of Abbottabad, Haripur and Mansehra) where they are known as Hazarewals. They also form a significant urban population in the cities of Peshawar and Kohat, although their historical influence has weakened in recent decades due to the rural to urban migration and the influx of Afghan refugees.\nOther notable minority ethnic groups include Kohistanis in Kohistan and Kho as well as Kalashas in Chitral. The southern district of Dera Ismail Khan has a Saraiki majority. Around 1.5 million Afghan refugees also remain in the province, the majority of whom are Pashtuns. Despite having lived in the province for over two decades, they are registered as citizens of Afghanistan.\nThe Pashtuns of Khyber Pakhtunkhwa observe tribal code of conduct called Pashtunwali which has four high value components called \"nang\" (honour), \"badal\" (revenge), \"melmastiya\" (hospitality) and \"nanawata\" (rights to refuge).\nLanguage.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nAccording to the 2023 census, the most widely spoken language is Pashto, native to 81% of the population and spoken throughout the province. Other languages with significant numbers of speakers include Hindko (9.39%), Saraiki (3.17%) and Kohistani languages (2.45%). Hindko is primarily spoken in the Hazara division in the northeast, and Saraiki-speakers are found in Dera Ismail Khan district in the far south of the province. Urdu, being the national and official language, serves as a lingua franca for inter-ethnic communications, and sometimes Pashto and Urdu are the second and third languages among communities that speak other ethnic languages. Kohistani languages is an umbrella term encompassing several languages spoken in the north of the province, including Indus Kohistani, Bateri, Chilisso, Gawri, Gawro, Torwali, and Mankiyali. Around 1 million of the population selected \"Other\" category, largely referring to Khowar in the mountainous northwest Chitral.\nIn 2011 the provincial government approved in principle the introduction of Pashto, Saraiki, Hindko, Khowar and Kohistani as compulsory subjects for schools in the areas where they are spoken.\nReligion.\nThe overwhelming majority of the residents of the Khyber Pakhtunkhwa follows and professes the Sunni Islam while there is a significant amount of shia Muslims in areas such as Kurram, Kohat, Hangu, Orakzai, Dera Ismail khan, Mardan, and many other districts throughout central-southern kpk. Apart from Twelver Shias there are Isma'ilis in the Chitral district. The tribe of Kalasha in southern Chitral still retain an ancient form of Polytheism mixed with Animism, a faith once dominant in the mountainous upper northeast of the district. There are very small numbers of residents who are the adherents of Roman Catholicism denomination of Christianity, Hinduism and Sikhism, mainly living in Peshawar and other urban centres.\nGovernment and politics.\nPolitical leanings and the legislative branch.\nThe Provincial Assembly is a unicameral legislature, which consists of 145 members elected to serve for a constitutionally bounded term of five years. Historically, the province perceived to be a stronghold of the Awami National Party (ANP); a pro-Russian, by procommunist, left-wing and nationalist party. Since the 1970s, the Pakistan Peoples Party (PPP) also enjoyed considerable support in the province due to its socialist agenda. Khyber Pakhtunkhwa was thought to be another leftist region of the country after Sindh.\nAfter the nationwide general elections held in 2002, a plurality voting swing in the province elected one of Pakistan's only religiously based provincial governments led by the ultra-conservative Muttahida Majlis-e-Amal (MMA) during the administration of President Pervez Musharraf. The American involvement in neighbouring Afghanistan contributed towards the electoral victory of the Islamic coalition led by Jamaat-e-Islami Pakistan (JeI) whose social policies made the province a ground-swell of anti-Americanism. The electoral victory of MMA was also in context of guided democracy in the Musharraff administration that barred the mainstream political parties, the leftist Pakistan Peoples Party and the centre-right Pakistan Muslim League (N) (PML(N)), whose chairmen and presidents having been barred from participation in the elections.\nPolicy enforcement of a range of social restrictions, though the implementation of strict Shariah was introduced by the Muttahida Majlis-e-Amal government the law was never fully enacted due to objections of the Governor of Khyber Pakhtunkhwa backed by the Musharraff administration. Restrictions on public musical performances were introduced, as well as a ban prohibiting music to be played in public places as part of the \"Prohibition of Dancing and Music Bill, 2005\" \u2013 which led to the creation of a thriving underground music scene in Peshawar. The Islamist government also attempted to enforce compulsory \"hijab\" on women, and wished to enforce gender segregation in the province's educational institutions. The coalition further tried to prohibit male doctors from performing ultrasounds on women, and tried to close the province's cinemas. In 2005, the coalition successfully passed the \"Prohibition of Use of Women in Photograph Bill, 2005,\" leading to the removal of all public advertisements that featured women.\nAt the height of Taliban insurgency in Pakistan, the religious coalition lost its grip in the general elections held in 2008, and the religious coalition was swept out of power by the leftist Awami National Party which also witnessed the resignation of President Musharraf in 2008. The ANP government eventually led the initiatives to repeal the major Islamist's social programs, with the backing of the federal government led by PPP in Islamabad. Public disapproval of ANP's leftist program integrated in civil administration with the sounded allegations of corruption as well as popular opposition against religious program promoted by the MMA swiftly shifted the province's leniency away from the left in 2012. In 2013, the provincial politics shifted towards populism and nationalism when the PTI, led by Imran Khan, was able to form the minority government in coalition with the JeI; the province now serves as the stronghold of the PTI and is perceived as one of the more right wing areas of the country. After the 2018 election, PTI increased their seat share and formed a majority government.\nIn non-Pashtun areas, such as Abbottabad, and Hazara Division, the PML(N), the centre-right party, enjoys considerable public support over economical and public policy issues and has a substantial vote bank.\nExecutive branch.\nThe executive branch of the Kyber Pakhtunkhwa is led by the Chief Minister elected by popular vote in the Provincial assembly while the Governor, a ceremonial figure representing the federal government in Islamabad, is appointed from the necessary advice of the Prime Minister of Pakistan by the President of Pakistan.\nThe provincial cabinet is then appointed by the Chief Minister who takes the Oath of office from the Governor. In matters of civil administration, the Chief Secretary assists the Chief Minister on executing its right to ensure the writ of the government and the constitution.\nJudicial branch.\nThe Peshawar High Court is the province's highest court of law whose judges are appointed by the approval of the Supreme Judicial Council in Islamabad, interpreting the laws and overturn those they find unconstitutional.\nAdministrative divisions and districts.\nKhyber Pakhtunkhwa is divided into seven divisions \u2013 Bannu, Dera Ismail Khan, Hazara, Kohat, Malakand, Mardan, and Peshawar. Each division is split up into anywhere between two and nine districts, and there are 38 districts in the entire province. Following is a list showing each district ordered by alphabetical order. A full list showing different characteristics of each district, such as their population, area, and a map showing their location can be found at the main article.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nMajor cities.\nPeshawar is the capital and largest city of Khyber Pakhtunkhwa. The city is the most populous and comprises more than one-eighth of the province's population.\n&lt;templatestyles src=\"Template:Largest_cities/styles.css\" /&gt;\nEconomy.\nKhyber Pakhtunkhwa has the third largest provincial economy in Pakistan. Khyber Pakhtunkhwa's share of Pakistan's GDP has historically comprised 10.5%, although the province accounts for 11.9% of Pakistan's total population. The part of the economy that Khyber Pakhtunkhwa dominates is forestry, where its share has historically ranged from a low of 34.9% to a high of 81%, giving an average of 61.56%. Currently, Khyber Pakhtunkhwa accounts for 10% of Pakistan's GDP, 20% of Pakistan's mining output and, since 1972, it has seen its economy grow in size by 3.6 times.\nAgriculture remains important and the main cash crops include wheat, maize, tobacco (in Swabi), rice, sugar beets, as well as fruits are grown in the province.\nSome manufacturing and high-tech investments in Peshawar have helped improve job prospects for many locals, while trade in the province involves nearly every product. The bazaars in the province are renowned throughout Pakistan. Unemployment has been reduced due to the establishment of industrial zones.\nWorkshops throughout the province support the manufacture of small arms and weapons. The province accounts for at least 78% of the marble production in Pakistan.\nInfrastructure.\nThe Sharmai Hydropower Project is a proposed power generation project located in the Upper Dir District of Khyber Pakhtunkhwa on the Panjkora River with an installed capacity of 150MW.\nSocial issues.\nThe Awami National Party sought to rename the province \"Pakhtunkhwa\", which translates to \"Land of Pakhtuns\" in the Pashto language. This was opposed by some non-Pashtuns in the province and political parties such as the Pakistan Muslim League-N (PML-N) and Muttahida Majlis-e-Amal (MMA), due to the PML-N deriving its support in the province from primarily non-Pashtun Hazara regions.\nIn 2010, the announcement that the province would have a new name led to a wave of protests in the Hazara region. On 15 April 2010, Pakistan's senate officially named the province \"Khyber Pakhtunkhwa\" with 80 senators in favour and 12 opposed. The MMA, who until the elections of 2008 had a majority in the Khyber Pakhtunkhwa government, had proposed \"Afghania\" as a compromise name.\nAfter the 2008 general election, the Awami National Party formed a coalition provincial government with the Pakistan Peoples Party. The Awami National Party has its strongholds in the Pashtun areas of Pakistan, particularly in the Peshawar valley, while Karachi in Sindh has one of the largest Pashtun populations in the world\u2014around 7 million by some estimates. In the 2008 election, the ANP won two Sindh assembly seats in Karachi. The Awami National Party has been instrumental in fighting the Taliban. In the 2013 general election Pakistan Tehreek-e-Insaf won a majority in the provincial assembly and has now formed their government in coalition with Jamaat-e-Islami Pakistan.\nNon-government organisations.\nThe following is a list of some of the major NGOs working in Khyber Pakhtunkhwa:\nFolk music and culture.\nMusic.\nPashto folk music is popular in Khyber Pakhtunkhwa and has a rich tradition going back hundreds of years. The main instruments are the rubab, mangey and harmonium. Khowar folk music is popular in Chitral and northern Swat. The tunes of Khowar music are very different from those of Pashto, and the main instrument is the Chitrali sitar. A form of band music composed of clarinets (Surnai) and drums is popular in Chitral. It is played at polo matches and dances. The same form of band music is played in the neighbouring Northern Areas.\nLiterature.\nThere is an important literature produced in the province, mainly in Pashto but also in Urdu and in Hindko, and in 2022 more than 25,000 books were published in these three languages.\nEducation.\nAs FATA became part of KPK, all the literacy rates are recalculated by combining literacy rates of both regions.\nSources:\nKhyber Pakhtunkhwa has traditionally had a very low literacy rate, although this is changing in recent times. As of the 2017 census, the literacy rate for Khyber Pakhtunkhwa (including FATA) is 51.66%. In rural areas, the literacy rate is 48.44% of the population while in urban areas it is 66.86%. Khyber Pakhtunkhwa has a huge gap in literacy rate between sexes \u2013 for men it is 66.67% while the female literacy rate is 34.58%, just over half the male literacy rate. This gap is particularly prominent in the overwhelmingly-Pashto rural areas, where traditional gender norms have generally limited education of women. As of 2021, Khyber Pakhtunkhwa (KP) has the highest literacy growth rate in the whole country (Pakistan).\nSports.\nCricket is the main sport played in Khyber Pakhtunkhwa. It has produced world-class sportsmen like Shahid Afridi, Younis Khan, Khushdil Shah, Fakhar Zaman, Naseem Shah and Umar Gul. Besides producing cricket players, Khyber Pakhtunkhwa has the honour of being the birthplace of many world-class squash players, including greats like Hashim Khan, Qamar Zaman, Jahangir Khan and Jansher Khan. \nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21952", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=21952", "title": "Naiad (moon)", "text": "Moon of Neptune\nNaiad , (also known as Neptune III and previously designated as S/1989 N 6) named after the naiads of Greek legend, is the innermost satellite of Neptune and the nearest to the center of any gas giant with moons with a distance of 48,224 km from the planet's center. Its orbital period is less than a Neptunian day, resulting in tidal dissipation that will cause its orbit to decay. Eventually it will either crash into Neptune's atmosphere or break up to become a new ring.\nHistory.\nNaiad was discovered sometime before mid-September 1989 from the images taken by the \"Voyager 2\" probe. The last moon to be discovered during the flyby, it was designated S/1989 N 6. The discovery was announced on 29 September 1989, in the IAU Circular No. 4867, and mentions \"25 frames taken over 11 days\", implying a discovery date of sometime before 18 September. The name was given on 16 September 1991.\nPhysical characteristics.\nNaiad is irregularly shaped. It is likely that it is a rubble pile re-accreted from fragments of Neptune's original satellites, which were smashed up by perturbations from Triton soon after that moon's capture into a very eccentric initial orbit.\nOrbit.\nNaiad is in a 73:69 orbital resonance with the next outward moon, Thalassa, in a \"dance of avoidance\". As it orbits Neptune, the more inclined Naiad successively passes Thalassa twice from above and then twice from below, in a cycle that repeats every ~21.5 Earth days. The two moons are about 3540 km apart when they pass each other. Although their orbital radii differ by only 1850\u00a0km, Naiad swings ~2800 km above or below Thalassa's orbital plane at closest approach. Thus this resonance, like many such orbital correlations, serves to stabilize the orbits by maximizing separation at conjunction. However, the role of orbital inclination in maintaining this avoidance in a case where eccentricities are minimal is unusual.\nExploration.\nSince the \"Voyager 2\" flyby, the Neptune system has been extensively studied from ground-based observatories and the Hubble Space Telescope as well. In 2002\u201303 the Keck telescope observed the system using adaptive optics and detected easily the largest four inner satellites. Thalassa was found with some image processing, but Naiad was not located. Hubble has the ability to detect all the known satellites and possible new satellites even dimmer than those found by \"Voyager 2\". On 8 October 2013 the SETI Institute announced that Naiad had been located in archived Hubble imagery from 2004. The suspicion that the loss of positioning was due to considerable errors in Naiad's ephemeris proved correct as Naiad was ultimately located 80 degrees from its expected position.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21953", "revid": "2766075", "url": "https://en.wikipedia.org/wiki?curid=21953", "title": "Nilo-Saharan languages", "text": "Proposed family of African languages\nThe Nilo-Saharan languages are a proposed family of around 210 African languages spoken by somewhere around 70 million speakers, mainly in the upper parts of the Chari and Nile rivers, including historic Nubia, north of where the two tributaries of the Nile meet. The languages extend through 17 nations in the northern half of Africa: from Algeria to Benin in the west; from Libya to the Democratic Republic of the Congo in the centre; and from Egypt to Tanzania in the east.\nAs indicated by its hyphenated name, Nilo-Saharan is a family of the African interior, including the greater Nile Basin and the Central Sahara Desert. Most of its proposed constituent divisions are found in the modern countries of Sudan and South Sudan, through which the Nile River flows.\nIn his book \"The Languages of Africa\" (1963), Joseph Greenberg named the group and argued it was a genetic family. It contained all the languages that were not included in the Niger\u2013Congo, Afroasiatic or Khoisan families. Although some linguists have referred to the phylum as \"Greenberg's wastebasket\", into which he placed all the otherwise unaffiliated non-click languages of Africa, other specialists in the field have accepted it as a working hypothesis since Greenberg's classification. Linguists accept that it is a challenging proposal to demonstrate but contend that it looks more promising the more work is done.\nSome of the constituent groups of Nilo-Saharan are estimated to predate the African neolithic. For example, the unity of Eastern Sudanic is estimated to date to at least the 5th millennium BC. Nilo-Saharan genetic unity would thus be much older still and date to the late Upper Paleolithic. The earliest written language associated with the Nilo-Saharan family is Old Nubian, one of the oldest written African languages, attested in writing from the 8th to the 15th century AD.\nNilo-Saharan is not accepted by all linguists. \"Glottolog\" (2013), for example, a publication of the Max Planck Institute in Germany, does not recognise the unity of the Nilo-Saharan family or even of the Eastern Sudanic branch; Georgiy Starostin (2016) likewise does not accept a relationship between the branches of Nilo-Saharan, though he leaves open the possibility that some of them may prove to be related to each other once the necessary reconstructive work is done. According to G\u00fcldemann (2018), \"the current state of research is not sufficient to prove the Nilo-Saharan hypothesis.\"\nCharacteristics.\nThe constituent families of Nilo-Saharan are quite diverse. One characteristic feature is a tripartite singulative\u2013collective\u2013plurative number system, which Blench (2010) believes is a result of a noun-classifier system in the protolanguage. The distribution of the families may reflect ancient watercourses in a green Sahara during the African humid period before the 4.2-kiloyear event, when the desert was more habitable than it is today.\nMajor languages.\nWithin the Nilo-Saharan languages are a number of languages with at least a million speakers (most data from SIL's \"Ethnologue\" 16 (2009)). In descending order:\nSome other important Nilo-Saharan languages under 1 million speakers:\nThe total for all speakers of Nilo-Saharan languages according to \"Ethnologue\" 16 is 38\u201339 million people. However, the data spans a range from ca. 1980 to 2005, with a weighted median at ca. 1990. Given population growth rates, the figure in 2010 might be half again higher, or about 60 million.\nHistory of the proposal.\nThe Saharan family (which includes Kanuri, Kanembu, the Tebu languages, and Zaghawa) was recognized by Heinrich Barth in 1853, the Nilotic languages by Karl Richard Lepsius in 1880, the various constituent branches of Central Sudanic (but not the connection between them) by Friedrich M\u00fcller in 1889, and the Maban family by Maurice Gaudefroy-Demombynes in 1907. The first inklings of a wider family came in 1912, when Diedrich Westermann included three of the (still independent) Central Sudanic families within Nilotic in a proposal he called \"Niloto-Sudanic\"; this expanded Nilotic was in turn linked to Nubian, Kunama, and possibly Berta, essentially Greenberg's Macro-Sudanic (Chari\u2013Nile) proposal of 1954.\nIn 1920 G. W. Murray fleshed out the Eastern Sudanic languages when he grouped Nilotic, Nubian, Nera, Gaam, and Kunama. Carlo Conti Rossini made similar proposals in 1926, and in 1935 Westermann added Murle. In 1940 A. N. Tucker published evidence linking five of the six branches of Central Sudanic alongside his more explicit proposal for East Sudanic. In 1950 Greenberg retained Eastern Sudanic and Central Sudanic as separate families, but accepted Westermann's conclusions of four decades earlier in 1954 when he linked them together as \"Macro-Sudanic\" (later \"Chari\u2013Nile\", from the Chari and Nile Watersheds).\nGreenberg's later contribution came in 1963, when he tied Chari\u2013Nile to Songhai, Saharan, Maban, Fur, and Koman-Gumuz and coined the current name \"Nilo-Saharan\" for the resulting family. Lionel Bender noted that Chari\u2013Nile was an artifact of the order of European contact with members of the family and did not reflect an exclusive relationship between these languages, and the group has been abandoned, with its constituents becoming primary branches of Nilo-Saharan\u2014or, equivalently, Chari\u2013Nile and Nilo-Saharan have merged, with the name \"Nilo-Saharan\" retained. When it was realized that the Kadu languages were not Niger\u2013Congo, they were commonly assumed to therefore be Nilo-Saharan, but this remains somewhat controversial.\nProgress has been made since Greenberg established the plausibility of the family. Koman and Gumuz remain poorly attested and are difficult to work with, while arguments continue over the inclusion of Songhai. Blench (2010) believes that the distribution of Nilo-Saharan reflects the waterways of the wet Sahara 12,000 years ago, and that the protolanguage had noun classifiers, which today are reflected in a diverse range of prefixes, suffixes, and number marking.\nInternal relationships.\nDimmendaal (2008) notes that Greenberg (1963) based his conclusion on strong evidence and that the proposal as a whole has become more convincing in the decades since. Mikkola (1999) reviewed Greenberg's evidence and found it convincing. Roger Blench notes morphological similarities in all putative branches, which leads him to believe that the family is likely to be valid.\nKoman and Gumuz are poorly known and have been difficult to evaluate until recently. Songhay is markedly divergent, in part due to massive influence from the Mande languages. Also problematic are the Kuliak languages, which are spoken by hunter-gatherers and appear to retain a non-Nilo-Saharan core; Blench believes they might have been similar to Hadza or Dahalo and shifted incompletely to Nilo-Saharan.\nAnbessa Tefera and Peter Unseth consider the poorly attested Shabo language to be Nilo-Saharan, though unclassified within the family due to lack of data; Dimmendaal and Blench, based on a more complete description, consider it to be a language isolate on current evidence. Proposals have sometimes been made to add Mande (usually included in Niger\u2013Congo), largely due to its many noteworthy similarities with Songhay rather than with Nilo-Saharan as a whole, however this relationship is more likely due to a close relationship between Songhay and Mande many thousands of years ago in the early days of Nilo-Saharan, so the relationship is probably more one of ancient contact than a genetic link.\nThe extinct Meroitic language of ancient Kush has been accepted by linguists such as Rille, Dimmendaal, and Blench as Nilo-Saharan, though others argue for an Afroasiatic affiliation. It is poorly attested.\nWith the possible exception of Eastern Sudanic, there is little doubt that the constituent families of Nilo-Saharan\u2014of which only Eastern Sudanic and Central Sudanic show much internal diversity\u2014are valid groups. However, there have been several conflicting classifications in grouping them together. Each of the proposed higher-order groups has been rejected by other researchers: Greenberg's Chari\u2013Nile by Bender and Blench, and Bender's Core Nilo-Saharan by Dimmendaal and Blench. What remains are eight (Dimmendaal) to twelve (Bender) constituent families of no consensus arrangement.\nGreenberg 1963.\nJoseph Greenberg, in \"The Languages of Africa\", set up the family with the following branches. The Chari\u2013Nile core are the connections that had been suggested by previous researchers.\nGumuz was not recognized as distinct from neighbouring Koman; it was separated out (forming \"Komuz\") by Bender (1989).\nBender 1989, 1991.\nLionel Bender came up with a classification which expanded upon and revised that of Greenberg. He considered Fur and Maban to constitute a Fur\u2013Maban branch, added Kadu to Nilo-Saharan, removed Kuliak from Eastern Sudanic, removed Gumuz from Koman (but left it as a sister node), and chose to posit Kunama as an independent branch of the family. By 1991 he had added more detail to the tree, dividing Chari\u2013Nile into nested clades, including a Core group in which Berta was considered divergent, and coordinating Fur\u2013Maban as a sister clade to Chari\u2013Nile.\nBender revised his model of Nilo-Saharan again in 1996, at which point he split Koman and Gumuz into completely separate branches of Core Nilo-Saharan.\nEhret 1989, 2001.\nChristopher Ehret came up with a novel classification of Nilo-Saharan in 1989, though most of the evidence was not published until 2001. His classification, which was not accepted by other researchers, consists of two primary branches: Gumuz\u2013Koman, and a 'Sudanic' group containing the remainder of the families. Unusually, Songhay is nested within a core group and is coordinate with Maban in a 'Western Sahelian' clade, while Kadu is excluded in Nilo-Saharan. Note that 'Koman' in this classification is equivalent to Komuz, i.e. a family with Gumuz and Koman as primary branches, and Ehret renames the traditional Koman group 'Western Koman'.\nBender 2000.\nBy 2000 Bender had entirely abandoned the Chari\u2013Nile and Komuz branches. He also added Kunama back to the \"Satellite\u2013Core\" group and simplified the subdivisions therein. He retracted the inclusion of Shabo, stating that it could not yet be adequately classified but might prove to be Nilo-Saharan once sufficient research has been done. This tentative and somewhat conservative classification held as a sort of standard for the next decade.\nBlench 2006.\nNiger-Saharan, a language macrofamily linking the Niger-Congo and Nilo-Saharan phyla, was proposed by Blench (2006). It was not accepted by other linguists. Blench's (2006) internal classification of the Niger-Saharan macrophylum is as follows:\n&lt;templatestyles src=\"Tree list/styles.css\" /&gt;\nAccording to Blench (2006), typological features common to both Niger-Congo and Nilo-Saharan include:\nBlench 2010.\nWith a better understanding of Nilo-Saharan classifiers, and the affixes or number marking they have developed into in various branches, Blench believes that all of the families postulated as Nilo-Saharan belong together. He proposes the following tentative internal classification, with Songhai closest to Saharan, a relationship that had not previously been suggested:\n? Mimi of Decorse\nBlench 2015.\nBy 2015, and again in 2017, Blench had refined the subclassification of this model, linking Maban with Fur, Kadu with Eastern Sudanic, and Kuliak with the node that contained them, and added a tentative, extinct branch he names \"Plateau\" as to explain a possible Nilo-Saharan substrate in the Malian Dogon and Bangime languages, for the following structure:\nBlench (2021) concludes that Maban may be close to Eastern Sudanic.\nStarostin (2016).\nGeorgiy Starostin (2016), using lexicostatistics based on Swadesh lists, is more inclusive than \"Glottolog\", and in addition finds probable and possible links between the families that will require reconstruction of the proto-languages for confirmation. Starostin also does not consider Greenberg's Nilo-Saharan to be a valid, coherent clade.\nIn addition to the families listed in \"Glottolog\" (previous section), Starostin considers the following to be established:\nA relationship of Nyima with Nubian, Nara, and Tama (NNT) is considered \"highly likely\" and close enough that proper comparative work should be able to demonstrate the connection if it's valid, though it would fall outside NNT proper (see Eastern Sudanic languages).\nOther units that are \"highly likely\" to eventually prove to be valid families are:\nIn summary, at this level of certainty, \"Nilo-Saharan\" constitutes ten distinct and separate language families: Eastern Sudanic, Central Sudanic \u2013 Kadu, Maba\u2013Kunama, Komuz, Saharan, Songhai, Kuliak, Fur, Berta, and Shabo.\nPossible further \"deep\" connections, which cannot be evaluated until the proper comparative work on the constituent branches has been completed, are:\nThere are faint suggestions that Eastern and Central Sudanic may be related (essentially the old Chari\u2013Nile clade), though that possibility is \"unexplorable under current conditions\" and could be complicated if Niger\u2013Congo were added to the comparison. Starostin finds no evidence that the Komuz, Kuliak, Saharan, Songhai, or Shabo languages are related to any of the other Nilo-Saharan languages. Mimi-D and Meroitic were not considered, though Starostin had previously proposed that Mimi-D was also an isolate despite its slight similarity to Central Sudanic.\nIn a follow-up study published in 2017, Starostin reiterated his previous points as well as explicitly accepting a genetic relationship between Macro-East Sudanic and Macro-Central Sudanic. Starostin names this proposal \"Macro-Sudanic\". The classification is as follows.\n&lt;templatestyles src=\"Tree list/styles.css\" /&gt;\nStarostin (2017) finds significant lexical similarities between Kadu and Central Sudanic, while some lexical similarities also shared by Central Sudanic with Fur-Amdang, Berta, and Eastern Sudanic to a lesser extent.\nDimmendaal 2016, 2019.\nGerrit J. Dimmendaal suggests the following subclassification of Nilo-Saharan:\nDimmendaal et al. consider the evidence for the inclusion of Kadu and Songhay too weak to draw any conclusions at present, whereas there is some evidence that Koman and Gumuz belong together and may be Nilo-Saharan.\nThe large Northeastern division is based on several typological markers:\nBlench 2023.\nBy 2023, Blench had slightly revised the model for a deep primary split between Koman\u2013Gumuz and the rest. Kunama and Berta are \"provisionally\" placed as the next to branch off, because they only partially share the features that unite the rest of the family. However, it is not clear if this is because they actually diverged early, or if they might have lost those features at a later date. For example, Berta shares plausible lexical cognates with the Eastern Jebel languages (East Sudanic) and its system of grammatical number \"closely resembles\" those of the East Sudanic languages; Kunama could be divergent \"due to long-term interaction with Afroasiatic languages.\" Saharan\u2013Songhay (especially Songhay) have seen substantial erosion of key characteristics, but this appears to be a secondary development and not evidence of early branching. \"Core\" Nilo-Saharan (\"Central African\" in Blench 2015) thus appears to be a typological rather than genetic grouping, though Maban is treated as a divergent branch of Eastern Sudanic; Kadu also seems to be quite close. The resulting structure is as follows:\nBeyond the work of Colleen Ahland, Blench notes that the inclusion of Koman is buttressed by the work of Manuel Otero. The argument for Songhay is mostly lexical, especially the pronouns. Blench gives Greenberg credit for both East and Central Sudanic. Saharan and Songhay have some \"striking\" similarities in their lexicon, which Blench argues is genetic, though the absence of reliable proto-Sarahan and proto-Songhay reconstructions makes evaluation difficult.\n\"Glottolog\" 4.0 (2019).\nIn summarizing the literature to date, Hammarstr\u00f6m et al. in \"Glottolog\" do not accept that the following families are demonstrably related with current research:\nExternal relations.\nProposals for the external relationships of Nilo-Saharan typically center on Niger\u2013Congo: Gregersen (1972) grouped the two together as \"Kongo\u2013Saharan\". However, Blench (2011) proposed that the similarities between Niger\u2013Congo and Nilo-Saharan (specifically Atlantic\u2013Congo and Central Sudanic) are due to contact, with the noun-class system of Niger\u2013Congo developed from, or elaborated on the model of, the noun classifiers of Central Sudanic.\nPhonology.\nNilo-Saharan languages present great differences, being a highly diversified group. It has proven difficult to reconstruct many aspects of Proto-Nilo-Saharan. Two very different reconstructions of the proto-language have been proposed by Lionel Bender and Christopher Ehret.\nBender's reconstruction.\nThe consonant system reconstructed by Bender for Proto-Nilo-Saharan is:\nThe phonemes correspond to coronal plosives, the phonetic details are difficult to specify, but clearly, they remain distinct from and supported by many phonetic correspondences (another author, Cristopher Ehret, reconstructs for the coronal area the sound and which perhaps are closer to the phonetic detail of , see infra)\nBender gave a list of about 350 cognates and discussed in depth the grouping and the phonological system proposed by Ehret. Blench (2000) compares both systems (Bender's and Ehret's) and prefers the former because it is more secure and is based in more reliable data. For example, Bender points out that there is a set of phonemes including implosives , ejectives and prenasal constants , but it seems that they can be reconstructed only for core groups (E, I, J, L) and the collateral group (C, D, F, G, H), but not for Proto-Nilo-Saharan.\nEhret's reconstruction.\nChristopher Ehret used a less clear methodology and proposed a maximalist phonemic system:\nEhret's maximalist system has been criticized by Bender and Blench. These authors state that the correspondences used by Ehret are not very clear and because of this many of the sounds in the table may only be allophonic variations.\nMorphology.\nDimmendaal (2016) cites the following morphological elements as stable across Nilo-Saharan:\nComparative vocabulary.\nSample basic vocabulary in different Nilo-Saharan branches:\n\"Note\": In table cells with slashes, the singular form is given before the slash, while the plural form follows the slash.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21957", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=21957", "title": "Nuclear pore complex", "text": "Openings in nuclear envelope of eukaryotic cells\nThe nuclear pore complex (NPC), is a large protein complex giving rise to the nuclear pore. A great number of nuclear pores are studded throughout the nuclear envelope that surrounds the eukaryote cell nucleus. The pores enable the nuclear transport of macromolecules between the nucleoplasm of the nucleus and the cytoplasm of the cell. Small molecules can easily diffuse through the pores. Nuclear transport includes the transportation of RNA and ribosomal proteins from the nucleus to the cytoplasm, and the transport of proteins (such as DNA polymerase and lamins), carbohydrates, signaling molecules, and lipids into the nucleus. Each nuclear pore complex can actively mediate up to 1000 translocations per second.\nThe nuclear pore complex consists predominantly of a family of proteins known as nucleoporins (Nups). Each pore complex in the human cell nucleus is composed of about 1,000 individual protein molecules, from an evolutionarily conserved set of 35 distinct nucleoporins. The conserved sequences that code for nucleoporins regulate molecular transport through the nuclear pore. Nucleoporin-mediated transport does not entail direct energy expenditure but instead relies on concentration gradients associated with the RAN cycle (Ras-related nuclear protein cycle). In 2022 around 90% of the structure of the human NPC was elucidated in an open and a closed conformation, and published in a special issue of \"Science\", featured on the cover. In 2024 the structure of the nuclear basket was solved, finalising the completion of the structure of the nuclear pore complex.\nAbout half of the nucleoporins encompass solenoid protein domains, such as alpha solenoids or beta-propeller folds, and occasionally both as separate structural domains. Conversely, the remaining nucleoporins exhibit characteristics of \"natively unfolded\" or intrinsically disordered proteins, characterized by high flexibility and a lack of ordered tertiary structure. These disordered proteins, referred to as FG nucleoporins (FG-Nups), contain multiple phenylalanine\u2013glycine repeats (FG repeats) in their amino acid sequences. FG-Nups is one of three main types of nucleoporins found in the NPC. The other two are the transmembrane Nups and the scaffold Nups. The transmembrane Nups are made up of transmembrane alpha helices and play a vital part in anchoring the NPC to the nuclear envelope. The scaffold Nups are made up of alpha solenoid and beta-propeller folds, and create the structural framework of NPCs.\nThe count of nuclear pore complexes varies across cell types and different stages of the cell's life cycle, with approximately 1,000 NPCs typically found in vertebrate cells. The human nuclear pore complex is a substantial structure, with a molecular weight of 120 megadaltons (MDa). Each NPC comprises eight protein subunits encircling the actual pore, forming the outer ring. Additionally, these subunits project a spoke-shaped protein over the pore channel. The central region of the pore may exhibit a plug-like structure; however, its precise nature remains unknown, and it is yet undetermined whether it represents an actual plug or merely cargo transiently caught in transit.\nStructure.\nThe nuclear pore complex (NPC) is a crucial cellular structure with a diameter of approximately 120 nanometers in vertebrates. Its channel fuses the inner and outer membranes of the nuclear envelope and varies from 5.2 nanometers in humans to 10.7\u00a0nm in the frog \"Xenopus laevis\", with a depth of roughly 45\u00a0nm. Additionally, mRNA, being single-stranded, has a thickness ranging from 0.5 to 1\u00a0nm. The mammalian NPC has a molecular mass of about , comprising approximately 30 distinct protein components, each in multiple copies. The mammalian NPCs contain about 800 nucleoporins each that are organized into distinct NPC subcomplexes. Conversely, the yeast \"Saccharomyces cerevisiae\" possesses a smaller mass, estimated at only 66 MDa.\nNuclear transport.\nThe nuclear pore complex (NPC) serves as a highly regulated gateway for the transport of molecules between the nucleus and the cytoplasm. This intricate system enables the selective passage for molecules including proteins, RNA, and signaling molecules, ensuring proper cellular function and homeostasis. Small molecules such as proteins water and ions can diffuse through NPCs, but cargoes (&gt;40 KDa) such as RNA and protein require the participation of soluble transport receptors.\nThe largest family of nuclear transport receptors are karyopherins, that include importins or exportins. These are a superfamily of nuclear transport receptors that facilitate the translocation of proteins, RNAs, and ribonuclear particles across the NPC in a Ran GTP hydrolase-dependent process. This family is further subdivided to the karyopherin-\u03b1 and the karyopherin-\u03b2 subfamilies. Other nuclear transport receptors include NTF2 and some NTF2-like proteins.\nThree models have been suggested to explain the translocation mechanism:\nImport of proteins.\nNuclear proteins are synthesized in the cytoplasm and need to be imported through the NPCs into the nucleus. Import can be directed by various signals, of which nuclear localization signal (NLS) are best characterized. Several NLS sequences are known, generally containing a conserved sequence with basic residues such as PKKKRKV. Any material with an NLS will be taken up by importins to the nucleus.\nImportation begins with Importin-\u03b1 binding to the NLS sequence of cargo proteins, forming a complex. Importin-\u03b2 then attaches to Importin-\u03b1, facilitating transport towards the NPC.\nAs the complex reaches the NPC, it diffuses through the pore without the need for additional energy. Upon entry into nucleus, RanGTP binds to Importin-\u03b2 and displaces it from the complex. Then the \"cellular apoptosis susceptibility protein\" (CAS), an exportin which in the nucleus is bound to RanGTP, displaces Importin-\u03b1 from the cargo. The NLS-protein is thus free in the nucleoplasm. The Importin\u03b2-RanGTP and Importin\u03b1-CAS-RanGTP complex diffuses back to the cytoplasm where GTPs are hydrolyzed to GDP leading to the release of Importin\u03b2 and Importin\u03b1 which become available for a new NLS-protein import round.\nWhile translocation through the NPC is not energy-dependent, the overall import cycle needs the hydrolysis of two GTPs molecules, making it an active transport process. The import cycle is powered by the nucleo-cytoplasmic RanGTP gradient. This gradient arises from the exclusive nuclear localization of RanGEFs, proteins that exchange GDP to GTP on Ran molecules. Thus, there is an elevated RanGTP concentration in the nucleus compared to the cytoplasm.\nExport of proteins.\nIn addition to nuclear import, certain molecules and macromolecular complexes, such as ribosome subunits and messenger RNAs, require export from the nucleus to the cytoplasm. This export process mirrors the import mechanism in complexity and importance.\nIn a classical export scenario, proteins with a nuclear export sequence (NES) form a heterotrimeric complex with an exportin and RanGTP within the nucleus. Example of such an exportin is CRM1. This complex subsequently translocate to the cytoplasm, where GTP hydrolysis occurs, releasing the NES-containing protein. The resulting CRM1-RanGDP complex returns to the nucleus, where RanGEFs catalyze the exchange of GDP for GTP on Ran, replenishing the system's energy source. This entire process is energy-dependent and consumes one GTP molecule. Notably, the export activity mediated by CRM1 can be inhibited by compounds like leptomycin B.\nExport of RNA.\nDifferent export pathways through the NPC for various RNA classes. RNA export is signal-mediated, with nuclear export signals (NES) present in RNA-binding proteins, except for tRNA which lacks an adapter. It is notable that all viral RNAs and cellular RNAs (tRNA, rRNA, U snRNA, microRNA) except mRNA are dependent on RanGTP. Conserved mRNA export factors are necessary for mRNA nuclear export. Export factors are Mex67/Tap (large subunit) and Mtr2/p15 (small subunit).\nIn highest eukaryotes, mRNA export is believed to be spicling-dependent. Splicing recruits the TREX protein complex to spliced messages, serving as an adapter for TAP, a low-affinity RNA-binding protein However, there are alternative mRNA export pathways that do not rely on splicing for specialized messages such as histones. Recent work also suggest an interplay between splicing-dependent export and one of these alternative mRNA export pathways for secretory and mitochondrial transcripts.\nAssembly of the NPC.\nSince the NPC regulates genome access, its presence in significant quantities during cell cycle stages characterized by high transcription rates is crucial. For example, cycling mammalian and yeast cells double the amount of NPC in the nucleus between the G1 and G2 phase. Similarly, oocytes accumulate abundant NPCs in anticipation of the rapid mitotic activity during early development. Moreover, interphase cells must maintain NPC generation to sustain consistent NPC levels, as some may incur damage. Furthermore, certain cells can even increase the NPC numbers due to increased transcriptional demand.\nTheories of assembly.\nThere are several theories as to how NPCs are assembled. As the immunodepletion of certain protein complexes, such as the Nup 107\u2013160 complex, leads to the formation of poreless nuclei, it seems likely that the Nup complexes are involved in fusing the outer membrane of the nuclear envelope with the inner and not that the fusing of the membrane begins the formation of the pore. There are several ways that this could lead to the formation of the full NPC.\nDisassembly.\nDuring mitosis the NPC appears to disassemble in stages, except in lower eukaryotes like yeast, where NPC disassembly does not happen during mitosis. Peripheral nucleoporins, such as the Nup153 Nup98 and Nup214, disassociate from the NPC. The rest, which can be considered a scaffold proteins remain stable, as cylindrical ring complexes within the nuclear envelope. This disassembly of the NPC peripheral groups is largely thought to be phosphate driven, as several of these nucleoporins are phosphorylated during the stages of mitosis. However, the enzyme involved in the phosphorylation is unknown in vivo. In metazoans (which undergo open mitosis) the NE degrades quickly after the loss of the peripheral Nups. The reason for this may be due to the change in the NPC's architecture. This change may make the NPC more permeable to enzymes involved in the degradation of the NE such as cytoplasmic tubulin, as well as allowing the entry of key mitotic regulator proteins. In organisms that undergo a semi-open mitosis such as the filamentous fungus \"Aspergillus nidulans\", 14 out of the 30 nucleoporins disassemble from the core scaffold structure, driven by the activation of the NIMA and Cdk1 kinases that phosphorylate nucleoporins and open nuclear pores thereby widening the nuclear pore and allowing the entry of mitotic regulators.\nPreservation of integrity.\nIn fungi undergoing closed mitosis, where the nucleus remains intact, changes in the permeability barrier of the nuclear envelope are attributed to alterations within the NPC. These changes facilitate the entry of mitotic regulators into the nucleus. Studies in \"Aspergillys nidulans\" suggest that the NPC composition appears to be effected by the mitotic kinase NIMA. NIMA potentially phosphorylates nucleoporins Nup98 and Gle2/Rae1, leading to NPC remodeling. This remodeling allows the nuclear entry of the protein complex cdc2/cyclinB and various other proteins, including soluble tubulin. The NPC scaffold remains intact throughout the whole closed mitosis. This seems to preserve the integrity of the nuclear envelope.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21958", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=21958", "title": "Nucleolus", "text": "Largest structure in the nucleus of eukaryotic cells\nThe nucleolus (; pl.: nucleoli ) is the largest structure in the nucleus of eukaryotic cells. It is best known as the site of ribosome biogenesis. The nucleolus also participates in the formation of signal recognition particles and plays a role in the cell's response to stress. Nucleoli are made of proteins, DNA and RNA, and form around specific chromosomal regions called nucleolar organizing regions. Malfunction of the nucleolus is the cause of several human conditions called \"nucleolopathies\" and the nucleolus is being investigated as a target for cancer chemotherapy.\nHistory.\nThe nucleolus was identified by bright-field microscopy during the 1830s. Theodor Schwann in his 1839 treatise described that Schleiden had identified small corpuscles in nuclei, and named the structures \"Kernk\u00f6rperchen\". In a 1947 translation of the work to English, the structure was named \"nucleolus\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In addition to these peculiarities of the cytoblast, already made known by Brown and Meyen, Schleiden has discovered in its interior a small corpuscle (see plate I, fig. 1, 4,) which, in the fully-developed cytoblast, looks like a thick ring, or a thick-walled hollow globule. It appears, however, to present a different appearance in different cytoblasts. Sometimes only the external sharply-defined circle of this ring can be distinguished, with a dark point in the centre,\u2014occasionally, and indeed most frequently, only a sharply circumscribed spot. In other instances this spot is very small, and sometimes cannot be recognized at all. As it will frequently be necessary to speak of this body in the following treatise, I will for brevity's sake name it the \"nucleolus,\" (Kernkorperchen, 'nucleus-corpuscle.\")\u2014\u200a\nLittle was known about the function of the nucleolus until 1964, when a study of nucleoli by John Gurdon and Donald Brown in the African clawed frog \"Xenopus laevis\" generated increased interest in its function and detailed structure. They found that 25% of the frog eggs had no nucleolus, and that such eggs were not capable of life. Half of the eggs had one nucleolus and 25% had two. They concluded that the nucleolus had a function necessary for life. In 1966, Max L. Birnstiel and collaborators showed via nucleic acid hybridization experiments that DNA within nucleoli codes for ribosomal RNA.\nStructure.\nThree major components of the nucleolus are recognized: the fibrillar center (FC), the dense fibrillar component (DFC), and the granular component (GC). Transcription of the rDNA occurs in the FC. The DFC contains the protein fibrillarin, which is important in rRNA processing. The GC contains the protein nucleophosmin, (B23 in the external image), which is also involved in ribosome biogenesis.\nHowever, it has been proposed that this particular organization is only observed in higher eukaryotes and that it evolved from a bipartite organization with the transition from anamniotes to amniotes. Reflecting the substantial increase in the DNA intergenic region, an original fibrillar component would have separated into the FC and the DFC.\nAnother structure identified within many nucleoli (particularly in plants) is a clear area in the center of the structure referred to as a nucleolar vacuole.\nNucleoli of various plant species have been shown to have very high concentrations of iron in contrast to human and animal cell nucleoli.\nThe nucleolus ultrastructure can be seen through an electron microscope, while the organization and dynamics can be studied through fluorescent protein tagging and fluorescent recovery after photobleaching (FRAP). Antibodies against the PAF49 protein can also be used as a marker for the nucleolus in immunofluorescence experiments.\nAlthough usually only one or two nucleoli can be seen, a diploid human cell has ten nucleolus organizer regions (NORs) and could have more nucleoli. Most often multiple NORs participate in each nucleolus.\nFunction and ribosome assembly.\nIn ribosome biogenesis, two of the three eukaryotic RNA polymerases (Pol I and Pol III) are required, and these function in a coordinated manner. In an initial stage, the rRNA genes are transcribed as a single unit within the nucleolus by RNA polymerase I. In order for this transcription to occur, several pol I-associated factors and DNA-specific trans-acting factors are required. In yeast, the most important are: UAF (upstream activating factor), TBP (TATA-box binding protein), and core binding factor (CBF), which bind promoter elements and form the preinitiation complex (PIC), which is in turn recognized by RNA polymerase. In humans, a similar PIC is assembled with SL1, the promoter selectivity factor (composed of TBP and TBP-associated factors, or TAFs), transcription initiation factors, and UBF (upstream binding factor). RNA polymerase I transcribes most rRNA transcripts (28S, 18S, and 5.8S), but the 5S rRNA subunit (component of the 60S ribosomal subunit) is transcribed by RNA polymerase III.\nTranscription of rRNA yields a long precursor molecule (45S pre-rRNA), which still contains the internal transcribed spacer (ITS) and external transcribed spacer (ETS). Further processing is needed to generate the 18S RNA, 5.8S, and 28S RNA molecules. In eukaryotes, the RNA-modifying enzymes are brought to their respective recognition sites by interaction with guide RNAs, which bind these specific sequences. These guide RNAs belong to the class of small nucleolar RNAs (snoRNAs), which are complexed with proteins and exist as small-nucleolar-ribonucleoproteins (snoRNPs). Once the rRNA subunits are processed, they are ready to be assembled into larger ribosomal subunits. However, an additional rRNA molecule, the 5S rRNA, is also necessary. In yeast, the 5S rDNA sequence is localized in the intergenic spacer and is transcribed in the nucleolus by RNA polymerase.\nIn higher eukaryotes and plants, the situation is more complex, for the 5S DNA sequence lies outside the NOR and is transcribed by RNA Pol III in the nucleoplasm, after which it finds its way into the nucleolus to participate in the ribosome assembly. This assembly not only involves the rRNA, but also ribosomal proteins. The genes encoding these r-proteins are transcribed by Pol II in the nucleoplasm by a \"conventional\" pathway of protein synthesis (transcription, pre-mRNA processing, nuclear export of mature mRNA, and translation on cytoplasmic ribosomes). The mature r-proteins are then imported into the nucleus and, finally, the nucleolus. Association and maturation of rRNA and r-proteins result in the formation of the 40S (small) and 60S (large) subunits of the complete ribosome. These are exported through the nuclear pore complexes to the cytoplasm, where they remain free or become associated with the endoplasmic reticulum, forming the rough endoplasmic reticulum (RER).\nIn human endometrial cells, a network of nucleolar channels is sometimes formed. The origin and function of this network have not yet been clearly identified.\nSequestration of proteins.\nIn addition to its role in ribosomal biogenesis, the nucleolus is known to capture and immobilize proteins, a process known as nucleolar detention. Proteins that are detained in the nucleolus are unable to diffuse and to interact with their binding partners. Targets of this post-translational regulatory mechanism include VHL, PML, MDM2, POLD1, RelA, HAND1 and hTERT, among many others. It is now known that long noncoding RNAs originating from intergenic regions of the nucleolus are responsible for this phenomenon.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21960", "revid": "9092818", "url": "https://en.wikipedia.org/wiki?curid=21960", "title": "NSAID", "text": ""}
{"id": "21961", "revid": "16416757", "url": "https://en.wikipedia.org/wiki?curid=21961", "title": "Nucleon", "text": "Component of an atomic nucleus\nIn physics and chemistry, a nucleon is either a proton or a neutron, considered in its role as a component of an atomic nucleus. The number of nucleons in a nucleus defines the atom's mass number.\nUntil the 1960s, nucleons were thought to be elementary particles, not made up of smaller parts. Now they are understood as composite particles, made of three quarks bound together by the strong interaction. The interaction between two or more nucleons is called internucleon interaction or nuclear force, which is also ultimately caused by the strong interaction. (Before the discovery of quarks, the term \"strong interaction\" referred to just internucleon interactions.)\nNucleons sit at the boundary where particle physics and nuclear physics overlap. Particle physics, particularly quantum chromodynamics, provides the fundamental equations that describe the properties of quarks and of the strong interaction. These equations describe quantitatively how quarks can bind together into protons and neutrons (and all the other hadrons). However, when multiple nucleons are assembled into an atomic nucleus (nuclide), these fundamental equations become too difficult to solve directly (see lattice QCD). Instead, nuclides are studied within nuclear physics, which studies nucleons and their interactions by approximations and models, such as the nuclear shell model. These models can successfully describe nuclide properties, as for example, whether or not a particular nuclide undergoes radioactive decay.\nThe proton and neutron are in a scheme of categories being at once fermions, hadrons and baryons. The proton carries a positive net charge, and the neutron carries a zero net charge; the proton's mass is only about 0.13% less than the neutron's. Thus, they can be viewed as two states of the same nucleon, and together form an isospin doublet (\"I\" \n ). In isospin space, neutrons can be transformed into protons and conversely by SU(2) symmetries. These nucleons are acted upon equally by the strong interaction, which is invariant under rotation in isospin space. According to Noether's theorem, isospin is conserved with respect to the strong interaction.\nOverview.\nProperties.\nProtons and neutrons are best known in their role as nucleons, i.e., as the components of atomic nuclei, but they also exist as free particles. Free neutrons are unstable, with a half-life of around 13\u00a0minutes, but they have important applications (see neutron radiation and neutron scattering). Protons not bound to other nucleons are the nuclei of hydrogen atoms when bound with an electron or\u00a0\u2013 if not bound to anything\u00a0\u2013 are ions or cosmic rays.\nBoth the proton and the neutron are composite particles, meaning that each is composed of smaller parts, namely three quarks each; although once thought to be so, neither is an elementary particle. A proton is composed of two up quarks and one down quark, while the neutron has one up quark and two down quarks. Quarks are held together by the strong force, or equivalently, by gluons, which mediate the strong force at the quark level.\nAn up quark has electric charge \u00a0\"e\", and a down quark has charge \u00a0\"e\", so the summed electric charges of proton and neutron are +\"e\" and 0, respectively. Thus, the neutron has a charge of 0 (zero), and therefore is electrically neutral; indeed, the term \"neutron\" comes from the fact that a neutron is electrically neutral.\nThe masses of the proton and neutron are similar: for the proton it is (), while for the neutron it is (); the neutron is roughly 0.13% heavier. The similarity in mass can be explained roughly by the slight difference in masses of up quarks and down quarks composing the nucleons. However, a detailed description remains an unsolved problem in particle physics.\nThe spin of the nucleon is , which means that they are fermions and, like electrons, are subject to the Pauli exclusion principle: no more than one nucleon, e.g. in an atomic nucleus, may occupy the same quantum state.\nThe isospin and spin quantum numbers of the nucleon have two states each, resulting in four combinations in total. An alpha particle is composed of four nucleons occupying all four combinations, namely, it has two protons (having opposite spin) and two neutrons (also having opposite spin), and its net nuclear spin is zero. In larger nuclei constituent nucleons, by Pauli exclusion, are compelled to have relative motion, which may also contribute to nuclear spin via the orbital quantum number. They spread out into nuclear shells analogous to electron shells known from chemistry.\nBoth the proton and neutron have magnetic moments, though the nucleon magnetic moments are anomalous and were unexpected when they were discovered in the 1930s. The proton's magnetic moment, symbol \"\u03bc\"p, is , whereas, if the proton were an elementary Dirac particle, it should have a magnetic moment of . Here the unit for the magnetic moments is the nuclear magneton, symbol \"\u03bc\"N, an atomic-scale unit of measure. The neutron's magnetic moment is \"\u03bc\"n = , whereas, since the neutron lacks an electric charge, it should have no magnetic moment. The value of the neutron's magnetic moment is negative because the direction of the moment is opposite to the neutron's spin. The nucleon magnetic moments arise from the quark substructure of the nucleons. The proton magnetic moment is exploited for NMR / MRI scanning.\nStability.\nA neutron in free state is an unstable particle, with a half-life around ten minutes. It undergoes decay (a type of radioactive decay) by turning into a proton while emitting an electron and an electron antineutrino. This reaction can occur because the mass of the neutron is slightly greater than that of the proton (see \"neutron decay\"). In the Standard Model of particle physics, an isolated proton is predicted to be stable More speculative models like a grand unified theory predict protons should be unstable. This has led to experiments like Super-Kamiokande in Japan which attempt to measure proton decay. The failure to detect such decay has placed the lifetime of the proton above 1034 years.\nInside a nucleus, on the other hand, combined protons and neutrons (nucleons) can be stable or unstable depending on the nuclide, or nuclear species. Inside some nuclides, a neutron can turn into a proton (producing other particles) as described above; the reverse can happen inside other nuclides, where a proton turns into a neutron (producing other particles) through decay or electron capture. And inside still other nuclides, both protons and neutrons are stable and do not change form.\nAntinucleons.\nBoth nucleons have corresponding antiparticles: the antiproton and the antineutron, which have the same mass and opposite charge as the proton and neutron respectively, and they interact in the same way. (This is generally believed to be \"exactly\" true, due to CPT symmetry. If there is a difference, it is too small to measure in all experiments to date.) In particular, antinucleons can bind into an \"antinucleus\". So far, scientists have created antideuterium and antihelium-3 nuclei.\nTables of detailed properties.\nNucleons.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;^a The masses of the proton and neutron are known with far greater precision in daltons (Da) than in MeV/\"c\"2 due to the way in which these are defined. The conversion factor used is 1\u00a0Da\u00a0=\u00a0.\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;^b At least 1035 years. See \"proton decay\".\n&lt;templatestyles src=\"Citation/styles.css\"/&gt;^c For free neutrons; in most common nuclei, neutrons are stable.\nThe masses of their antiparticles are assumed to be identical, and no experiments have refuted this to date. Current experiments show any relative difference between the masses of the proton and antiproton must be less than and the difference between the neutron and antineutron masses is on the order of .\nNucleon resonances.\nNucleon resonances are excited states of nucleon particles, often corresponding to one of the quarks having a flipped spin state, or with different orbital angular momentum when the particle decays. Only resonances with a 3- or 4-star rating at the Particle Data Group (PDG) are included in this table. Due to their extraordinarily short lifetimes, many properties of these particles are still under investigation.\nThe symbol format is given as N(m) LIJ, where m is the particle's approximate mass, L is the orbital angular momentum (in the spectroscopic notation) of the nucleon\u2013meson pair, produced when it decays, and I and J are the particle's isospin and total angular momentum respectively. Since nucleons are defined as having isospin, the first number will always be 1, and the second number will always be odd. When discussing nucleon resonances, sometimes the N is omitted and the order is reversed, in the form LIJ (m); for example, a proton can be denoted as \"N(939) S11\" or \"S11 (939)\".\nThe table below lists only the base resonance; each individual entry represents 4\u00a0baryons: 2\u00a0nucleon resonances particles and their 2\u00a0antiparticles. Each resonance exists in a form with a positive electric charge (Q), with a quark composition of like the proton, and a neutral form, with a quark composition of like the neutron, as well as the corresponding antiparticles with antiquark compositions of and respectively. Since they contain no strange, charm, bottom, or top quarks, these particles do not possess strangeness, etc.\nThe table only lists the resonances with an isospin = . For resonances with isospin = , see the article on Delta baryons.\n\u2020 \"The P11(939) nucleon represents the excited state of a normal proton or neutron. Such a particle may be stable when in an atomic nucleus, e.g. in lithium-6.\"\nQuark model classification.\nIn the quark model with SU(2) flavour, the two nucleons are part of the ground-state doublet. The proton has quark content of \"uud\", and the neutron, \"udd\". In SU(3) flavour, they are part of the ground-state octet (8) of spin- baryons, known as the Eightfold way. The other members of this octet are the hyperons strange isotriplet , , the and the strange isodoublet . One can extend this multiplet in SU(4) flavour (with the inclusion of the charm quark) to the ground-state 20-plet, or to SU(6) flavour (with the inclusion of the top and bottom quarks) to the ground-state 56-plet.\nThe article on isospin provides an explicit expression for the nucleon wave functions in terms of the quark flavour eigenstates.\nModels.\nAlthough it is known that the nucleon is made from three quarks, as of 2006[ [update]], it is not known how to solve the equations of motion for quantum chromodynamics. Thus, the study of the low-energy properties of the nucleon are performed by means of models. The only first-principles approach available is to attempt to solve the equations of QCD numerically, using lattice QCD. This requires complicated algorithms and very powerful supercomputers. However, several analytic models also exist:\nSkyrmion models.\nThe skyrmion models the nucleon as a topological soliton in a nonlinear SU(2) pion field. The topological stability of the skyrmion is interpreted as the conservation of baryon number, that is, the non-decay of the nucleon. The local topological winding number density is identified with the local baryon number density of the nucleon. With the pion isospin vector field oriented in the shape of a hedgehog space, the model is readily solvable, and is thus sometimes called the \"hedgehog model\". The hedgehog model is able to predict low-energy parameters, such as the nucleon mass, radius and axial coupling constant, to approximately 30% of experimental values.\nMIT bag model.\nThe \"MIT bag model\" confines quarks and gluons interacting through quantum chromodynamics to a region of space determined by balancing the pressure exerted by the quarks and gluons against a hypothetical pressure exerted by the vacuum on all colored quantum fields. The simplest approximation to the model confines three non-interacting quarks to a spherical cavity, with the boundary condition that the quark vector current vanish on the boundary. The non-interacting treatment of the quarks is justified by appealing to the idea of asymptotic freedom, whereas the hard-boundary condition is justified by quark confinement.\nMathematically, the model vaguely resembles that of a radar cavity, with solutions to the Dirac equation standing in for solutions to the Maxwell equations, and the vanishing vector current boundary condition standing for the conducting metal walls of the radar cavity. If the radius of the bag is set to the radius of the nucleon, the bag model predicts a nucleon mass that is within 30% of the actual mass.\nAlthough the basic bag model does not provide a pion-mediated interaction, it describes excellently the nucleon\u2013nucleon forces through the 6\u00a0quark bag \"s\"-channel mechanism using the \"P\"-matrix.\nChiral bag model.\nThe \"chiral bag model\" merges the \"MIT bag model\" and the \"skyrmion model\". In this model, a hole is punched out of the middle of the skyrmion and replaced with a bag model. The boundary condition is provided by the requirement of continuity of the axial vector current across the bag boundary.\nVery curiously, the missing part of the topological winding number (the baryon number) of the hole punched into the skyrmion is exactly made up by the non-zero vacuum expectation value (or spectral asymmetry) of the quark fields inside the bag. As of 2017[ [update]], this remarkable trade-off between topology and the spectrum of an operator does not have any grounding or explanation in the mathematical theory of Hilbert spaces and their relationship to geometry.\nSeveral other properties of the chiral bag are notable: It provides a better fit to the low-energy nucleon properties, to within 5\u201310%, and these are almost completely independent of the chiral-bag radius, as long as the radius is less than the nucleon radius. This independence of radius is referred to as the \"Cheshire Cat principle\", after the fading of Lewis Carroll's Cheshire Cat to just its smile. It is expected that a first-principles solution of the equations of QCD will demonstrate a similar duality of quark\u2013meson descriptions.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nParticle listings.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21964", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=21964", "title": "Ninuki-renju", "text": ""}
{"id": "21965", "revid": "42713041", "url": "https://en.wikipedia.org/wiki?curid=21965", "title": "Niger\u2013Kordofanian languages", "text": ""}
{"id": "21966", "revid": "46006", "url": "https://en.wikipedia.org/wiki?curid=21966", "title": "Nicolas Chauvin", "text": "Legendary French soldier\nNicolas Chauvin (, ) is a legendary, possibly apocryphal or fictional French soldier and patriot who is supposed to have served in the First Army of the French Republic and later in \"La Grande Arm\u00e9e\" of Napoleon. His name is the eponym of \"chauvinism\", originally a term for excessive nationalistic fervor, but later used to refer to any form of bigotry or bias (e.g., \"male chauvinism\").\nAccording to the stories that developed about him, Chauvin was born in Rochefort around 1780. He enlisted at age 18, and he served honorably and well. He is said to have been wounded 17 times in his nation's service, resulting in his severe disfigurement and maiming. For his loyalty and dedication, Napoleon himself presented the soldier with a Sabre of Honor and a pension of 200 francs.\nChauvin's distinguished record of service and his love and devotion for Napoleon, which endured despite the price he willingly paid for them, is said to have earned him only ridicule and derision in Restoration France, when Bonapartism became increasingly unpopular.\nHistoricity.\nHistorical research has not identified any biographical details of a real Nicolas Chauvin, leading to the claim that he may have been a wholly fictional figure. Researcher G\u00e9rard Puym\u00e8ge concluded that Nicolas Chauvin did not exist, believing him to be a legend, which crystallized under the Restoration and July Monarchy, from the pen of songwriters, vaudeville and historians. He argues that the figure of Chauvin continues the long tradition of the mythological farmer-soldier or \"miles gloriosus\" (\"boastful soldier\") from ancient Roman theater, or the \"alazon\" of ancient Greek comedy. Chauvin was originally popularized by Cogniard brothers' \"The Tricolour Cockade\" (1831), where instead of a Napoleonic veteran he was a young naive soldier learning blindly aggressive patriotism during the Algerian campaign of 1830.\nWhen the Old Guard was surrounded and made its last stand at La Belle Alliance, he supposedly shouted in defiance to a call for their honorable surrender: \"The Old Guard dies but does not surrender!\", implying blind and unquestioned zealous devotion to one's country (or other group of reference). The apocryphal phrase was attributed to the Old Guard's commander, Pierre Cambronne, but Cambronne's actual reply was later asserted by other sources to be \"Merde!\" (\"Shit!\").\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21967", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=21967", "title": "Network layer firewall", "text": ""}
{"id": "21968", "revid": "50688647", "url": "https://en.wikipedia.org/wiki?curid=21968", "title": "Nicotinamide", "text": "Dietary supplement and medication\n&lt;templatestyles src=\"Infobox drug/styles.css\"/&gt;\nNicotinamide (INN, BAN UK) or niacinamide (USAN US) is a form of vitamin B3 found in food and used as a dietary supplement and medication. As a supplement, it is used orally (swallowed by mouth) to prevent and treat pellagra (niacin deficiency). While nicotinic acid (niacin) may be used for this purpose, nicotinamide has the benefit of not causing skin flushing. As a cream, it is used to treat acne, and has been observed in clinical studies to improve the appearance of aging skin by reducing hyperpigmentation and redness. It is a water-soluble vitamin.\nSide effects are minimal. At high doses, liver problems may occur. Normal amounts are safe for use during pregnancy. Nicotinamide is in the vitamin B family of medications, specifically the vitamin B3 complex. It is an amide of nicotinic acid. Foods that contain nicotinamide include yeast, meat, milk, and green vegetables.\nNicotinamide was discovered between 1935 and 1937. It is on the World Health Organization's List of Essential Medicines. Nicotinamide is available as a generic medication and over the counter. Commercially, nicotinamide is made from either nicotinic acid (niacin) or nicotinonitrile. In some countries, grains have nicotinamide added to them.\nExtra-terrestrial nicotinamide has been found in carbonaceous chondrite meteorites.\nMedical uses.\nNiacin deficiency.\nNicotinamide is the preferred treatment for pellagra, caused by niacin deficiency.\nAcne.\nNicotinamide cream is used as a treatment for acne. It has anti-inflammatory actions, which may benefit people with inflammatory skin conditions.\nNicotinamide increases the biosynthesis of ceramides in human keratinocytes in vitro and improves the epidermal permeability barrier in vivo. The application of 2% topical nicotinamide for 2 and 4 weeks has been found to be effective in lowering the sebum excretion rate. Nicotinamide has been shown to prevent \"Cutibacterium acnes\"-induced activation of toll-like receptor 2, which ultimately results in the down-regulation of pro-inflammatory interleukin-8 production.\nSkin cancer.\nNicotinamide at doses of 500 to 1000mg a day decreases the risk of skin cancers, other than melanoma, in those at high risk.\nSide effects.\nNicotinamide has minimal side effects. At very high doses above 3\u00a0g per day acute liver toxicity has been documented in at least one case. Normal doses are safe during pregnancy.\nChemistry.\nThe structure of nicotinamide consists of a pyridine ring to which a primary amide group is attached in the \"meta\" position. It is an amide of nicotinic acid. As an aromatic compound, it undergoes electrophilic substitution reactions and transformations of its two functional groups. Examples of these reactions reported in \"Organic Syntheses\" include the preparation of 2-chloronicotinonitrile by a two-step process via the \"N\"-oxide,\nfrom nicotinonitrile by reaction with phosphorus pentoxide, and from 3-aminopyridine by reaction with a solution of sodium hypobromite, prepared \"in situ\" from bromine and sodium hydroxide.\nIndustrial production.\nThe hydrolysis of nicotinonitrile is catalysed by the enzyme nitrile hydratase from \"Rhodococcus rhodochrous\" J1, producing 3500 tons per annum of nicotinamide for use in animal feed. The enzyme allows for a more selective synthesis as further hydrolysis of the amide to nicotinic acid is avoided. Nicotinamide can also be made from nicotinic acid. According to \"Ullmann's Encyclopedia of Industrial Chemistry\", worldwide 31,000 tons of nicotinamide were sold in 2014.\nBiochemistry.\nNicotinamide, as a part of the cofactor nicotinamide adenine dinucleotide (NADH / NAD+) is crucial to life. In cells, nicotinamide is incorporated into NAD+ and nicotinamide adenine dinucleotide phosphate (NADP+). NAD+ and NADP+ are cofactors in a wide variety of enzymatic oxidation-reduction reactions, most notably glycolysis, the citric acid cycle, and the electron transport chain. If humans ingest nicotinamide, it will likely undergo a series of reactions that transform it into NAD, which can then undergo a transformation to form NADP+. This method of creation of NAD+ is called a salvage pathway. However, the human body can produce NAD+ from the amino acid tryptophan and niacin without our ingestion of nicotinamide.\nNAD+ acts as an electron carrier that mediates the interconversion of energy between nutrients and the cell's energy currency, adenosine triphosphate (ATP). In oxidation-reduction reactions, the active part of the cofactor is the nicotinamide. In NAD+, the nitrogen in the aromatic nicotinamide ring is covalently bonded to adenine dinucleotide. The formal charge on the nitrogen is stabilized by the shared electrons of the other carbon atoms in the aromatic ring. When a hydride atom is added onto NAD+ to form NADH, the molecule loses its aromaticity, and therefore a good amount of stability. This higher energy product later releases its energy with the release of a hydride, and in the case of the electron transport chain, it assists in forming adenosine triphosphate.\nWhen one mole of NADH is oxidized, 158.2kJ of energy will be released.\nBiological role.\nNicotinamide occurs as a component of a variety of biological systems, including within the vitamin B family and specifically the vitamin B3 complex. It is also a critically important part of the structures of NADH and NAD+, where the \"N\"-substituted aromatic ring in the oxidised NAD+ form undergoes reduction with hydride attack to form NADH. The NADPH/NADP+ structures have the same ring, and are involved in similar biochemical reactions.\nNicotinamide can be methylated in the liver to biologically inactive 1-Methylnicotinamide when there are sufficient methyl donors.\nFood sources.\nNicotinamide occurs in trace amounts mainly in meat, fish, nuts, and mushrooms, as well as to a lesser extent in some vegetables. It is commonly added to cereals and other foods. Many multivitamins contain 20\u201330\u00a0mg of vitamin B3 and it is also available in higher doses.\nResearch.\nA 2015 trial found nicotinamide to reduce the rate of new nonmelanoma skin cancers and actinic keratoses in a group of people at high risk for the conditions.\nNicotinamide has been investigated for many additional disorders, including treatment of bullous pemphigoid and nonmelanoma skin cancers.\nNicotinamide may be beneficial in treating psoriasis.\nThere is tentative evidence for a potential role of nicotinamide in treating acne, rosacea, autoimmune blistering disorders, ageing skin, and atopic dermatitis. Nicotinamide also inhibits poly(ADP-ribose) polymerases (PARP-1), enzymes involved in the rejoining of DNA strand breaks induced by radiation or chemotherapy. ARCON (accelerated radiotherapy plus carbogen inhalation and nicotinamide) has been studied in cancer.\nResearch has suggested nicotinamide may play a role in the treatment of HIV.\nExtra-terrestrial occurrence.\nExtra-terrestrial nicotinamide has been found in carbonaceous chondrite meteorites. \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21970", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=21970", "title": "Virtual Boy", "text": "Video game console by Nintendo\nThe Virtual Boy is a 32-bit tabletop portable video game console developed and manufactured by Nintendo and released in 1995. Promoted as the first system capable of rendering stereoscopic 3D graphics, it featured a red monochrome display viewed through a binocular eyepiece, with games employing a parallax effect to simulate depth. The console struggled commercially, and its limited market performance led Nintendo to discontinue production and game development in 1996, following the release of only 22 games.\nThe Virtual Boy\u2019s development spanned four years under the codename VR32. Nintendo entered a licensing agreement with the U.S.-based company Reflection Technology to use its stereoscopic LED eyepiece technology that had been under development since the 1980s. In preparation for mass production, Nintendo constructed a dedicated manufacturing facility in China. Over the course of development, escalating production costs, health concerns related to the display, and the diversion of resources to the Nintendo 64 resulted in the downscaling of the project. Additionally, Nintendo's lead game designer, Shigeru Miyamoto, had minimal involvement in the development. The system was pushed to market in an unfinished state in 1995 to focus on the Nintendo 64.\nThe Virtual Boy was panned by critics and was a commercial failure, even after repeated price drops. Its failure has been attributed to its high retail price, unappealing red-and-black display, unimpressive stereoscopic effect, poor ergonomics, lack of true portability, and reports of adverse health effects such as headaches, dizziness, and eye strain. Stereoscopic technology in video game consoles was later successfully revived, notably including Nintendo's 3DS handheld console. It remains a notable outlier in Nintendo\u2019s hardware history, being by far the company\u2019s lowest-selling standalone console, with just 770,000 units sold; for comparison, the second-lowest selling console, the Wii U, sold 13.6 million units.\nHistory.\nDevelopment.\nSince 1985, a red LED eyepiece display technology called Scanned Linear Array was developed by Massachusetts-based Reflection Technology, Inc. (RTI). The company produced a stereoscopic head-tracking 12-inch display device prototype called \"Private Eye\", featuring a tank game. Seeking funding and partnerships by which to develop it into a commercial technology, RTI demonstrated Private Eye to the consumer electronics market, including Mattel and Hasbro. Sega declined the technology, due to its single-color display and concerns about motion sickness.\nNintendo enthusiastically received the Private Eye, as led by Gunpei Yokoi, the general manager of Nintendo's R&amp;D1 and the inventor of the Game &amp; Watch and Game Boy handheld consoles. He saw this as a unique technology that competitors would find difficult to emulate. Additionally, the resulting game console was intended to enhance Nintendo's reputation as an innovator and to \"encourage more creativity\" in games. Codenaming the project \"VR32\", Nintendo entered into an exclusive agreement with RTI to license its display technology. While Nintendo's Research &amp; Development 3 division (R&amp;D3) was focused on developing the Nintendo 64, the other two engineering units were free to experiment with new product ideas.\nSpending four years in development and eventually building a dedicated manufacturing plant in China, Nintendo worked to turn its VR32 vision into an affordable console design. Yokoi retained RTI's choice of red LED because it was the cheapest, and because unlike a backlit LCD, its perfect blackness could achieve a more immersive sense of infinite depth. RTI and Nintendo said a color LCD system would have been prohibitively expensive, retailing for more than US$. A color LCD system was also said to have caused \"jumpy images in tests\". With ongoing concerns about motion sickness, the risk of developing lazy eye conditions in young children, and Japan's new Product Liability Act of 1995, Nintendo eliminated the head tracking functionality and converted its headmounted goggle design into a stationary, heavy, precision steel-shielded, tabletop form factor conformant to the recommendation of the Schepens Eye Research Institute.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[W]e experimented with a color LCD screen, but the users did not see depth, they just saw double. Color graphics give people the impression that a game is high tech. But just because a game has a beautiful display does not mean that the game is fun to play. ... Red uses less battery and red is easier to recognize. That is why red is used for traffic lights.\nSeveral &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;technology demonstrations were used to show the Virtual Boy's capabilities. \"Driving Demo\" is one of the more advanced demos; its 30-second clip shows a first-person view of driving by road signs and palm trees. This demo was shown at E3 and CES in 1995. The startup screen of the Virtual Boy prototype was shown at Shoshinkai 1994. A \"very confident\" projection of \"sales in Japan of three million hardware units and 14 million software units as of March 1996\" was given to the press. The demo of what would have been a \"Star Fox\" game showed an Arwing doing various spins and motions. Cinematic camera angles were a key element, as they are in \"Star Fox 2\". It was shown at E3 and CES in 1995.\nAs a result of increasing competition for internal resources alongside the flagship Nintendo 64, and little involvement from lead game designer Shigeru Miyamoto, Virtual Boy software was developed without Nintendo's full attention. According to David Sheff's book \"Game Over\", the increasingly reluctant Yokoi never intended for the increasingly downscaled Virtual Boy to be released in its final form. However, Nintendo pushed it to market so that it could focus development resources on its next console, the Nintendo 64.\nRelease.\n\"The New York Times\" previewed the Virtual Boy on November 13, 1994. The console was officially announced via press release the next day, November 14. Nintendo promised that Virtual Boy would \"totally immerse players into their own private universe\". Initial press releases and interviews about the system focused on its technological capabilities, avoiding discussion of the actual games that would be released. The system was demonstrated the next day at Nintendo's Shoshinkai 1994 trade show. Nintendo of America showed the Virtual Boy at the Consumer Electronics Show on January 6, 1995.\nEven with cost-saving measures in place, Nintendo priced the Virtual Boy at a relatively high US$. Though slightly less expensive and significantly less powerful than a home console, this was considerably more costly than the Game Boy handheld. With seemingly more advanced graphics than Game Boy, the Virtual Boy was not intended to replace the handheld in Nintendo's product line, as use of the Virtual Boy requires a steady surface and completely blocks the player's peripheral vision. \"Design News\" described the Virtual Boy as the logical evolution of the View-Master 3D image viewer.\nThe Virtual Boy was released on July 21, 1995, in Japan and on August 14, 1995, in North America with the launch games \"Mario's Tennis\", \"Red Alarm\", \"Teleroboxer\", and \"Galactic Pinball\". It was not released in PAL markets. In North America, Nintendo shipped \"Mario's Tennis\" with every Virtual Boy sold, as a pack-in game. Nintendo had initially projected sales of three million consoles and 14 million games. The system arrived later than other 32-bit systems like PlayStation, 3DO, and Saturn, but at a lower price.\nAt the system's release, Nintendo of America projected hardware sales of 1.5 million units and software sales numbering 2.5 million by the end of the year. Nintendo had shipped 350,000 units of the Virtual Boy by December 1995, around three and a half months after its North American release. \nThe Virtual Boy had a short market timespan following its disappointing sales. The last game officially released for the Virtual Boy was \"3D Tetris\", released on March 22, 1996. More games were announced for the system at the Electronic Entertainment Expo in May 1996, but these games were never released. The Virtual Boy was discontinued on December 22, 1995, in Japan and August 1996 in North America without any announcement. In June 1996, Nintendo reported to \"Famitsu\" worldwide sales of 770,000 Virtual Boy units, including 140,000 in Japan. \"Next Generation\" reported that 13,000 Virtual Boy units were sold in December 1996. The system is number 5 on \"GamePro\"'s \"Top 10 Worst Selling Consoles of All Time\" list in 2007.\nPromotion.\nNintendo extensively advertised the Virtual Boy and claimed to have spent US$ on early promotional activities. Advertising promoted the system as a paradigm shift from past consoles; some pieces used cavemen to indicate a historical evolution, while others utilized psychedelic imagery. Nintendo targeted an older audience with advertisements for the Virtual Boy, shifting away from the traditional child-focused approach it had employed in the past. Nintendo portrayed the system as a type of virtual reality, as its name indicates. Nintendo also focused on the technological aspects of the new console in its press releases, neglecting to detail specific games.\nChallenged by showing three-dimensional gameplay on two-dimensional advertisements, the company partnered with Blockbuster and NBC. A $ campaign promoted NBC's late 1995 lineup alongside the Virtual Boy. American viewers were encouraged via television advertisements on NBC to rent the console for $10 at a local Blockbuster. This affordable demonstration provided 750,000 consoles for rent, some in a clamshell Blockbuster case. Upon returning the unit, renters received a coupon for $10 off its purchase from any store. The promotion included 3,000 Blockbuster locations, and sweepstakes with prizes including trips to see the taping of NBC shows. The popular rental system proved harmful to the Virtual Boy's long-term success, allowing gamers to see just how non-immersive the console was. By mid-1996, Blockbuster was selling its Virtual Boy units at $50 each. The marketing campaign overall was commonly thought of as a failure.\nHardware.\nThe CPU is an NEC V810 32-bit RISC chip, making the Virtual Boy Nintendo's first 32-bit system. The Virtual Boy system uses a pair of 1\u00d7224 linear arrays (one per eye) and rapidly scans the array across the eye's field of view using flat oscillating mirrors. These mirrors vibrate back and forth at a very high speed, thus the mechanical humming noise from inside the unit. Each Virtual Boy game cartridge has a yes/no option to automatically pause every 15\u201330 minutes so that the player may take a break before any injuries come to the eyes. One speaker per ear provides the player with stereo audio.\nDisplay.\nThe Virtual Boy is the first video game console capable of displaying stereoscopic 3D graphics, marketed as a form of virtual reality. Whereas most video games use monocular cues to achieve the illusion of three dimensions on a two-dimensional screen, the Virtual Boy creates an illusion of depth through the effect known as parallax. Like using a head-mounted display, the user looks into an eyeshade made of neoprene on the front of the machine, and then an eyeglass-style projector allows viewing of the monochromatic red image.\nThe display consists of two two-bit (four shade) monochrome red screens of 384\u00d7224 pixels and a frame rate of approximately 50.27 Hz. It uses an oscillating mirror to transform a single column of 224 red LEDs into a full field of pixels. Nintendo claimed that a color display would have made \"jumpy\" images and have been too expensive. A color display would have required red, green, and blue LEDs; blue LEDs were then considerably expensive. This, plus the other drawbacks, influenced the decision for monochrome.\nController.\nThe Virtual Boy is meant for the player to be seated at a table, and Nintendo promised but did not release a harness to wear while standing.\nThe Virtual Boy's heavy emphasis on three-dimensional movement requires the controller to operate along a Z-axis. Its controller is an attempt to implement dual digital D-pads to control elements in the 3D environment. The controller is M-shaped, reminiscent of the Nintendo 64 controller. The player holds onto either side of the controller which has a unique extendable power supply that slides onto the back, housing the system's six AA batteries. The batteries can be substituted with a wall adapter, via a \"slide-on\" attachment for constant power.\nIn more traditional two-dimensional games, the two directional pads are interchangeable. For others with a more 3D environment, like \"Red Alarm\", \"3D Tetris\", or \"Teleroboxer\", each pad controls a different feature. The symmetry of the controller also allows left-handed gamers to reverse the controls, as does the Atari Lynx.\nConnectivity.\nDuring development, Nintendo promised the ability to link systems for competitive play. A Virtual Boy link cable was being worked on at Nintendo as late as the third quarter of 1996. The system's EXT (extension) port, located on the underside of the system below the controller port, was never officially supported because no \"official\" multiplayer games were ever published. Two games were intended to use the EXT port for multiplayer play, but the multiplayer features were removed from \"Waterworld\" and \"Faceball\" was canceled.\nGames.\nNintendo initially showcased three launch games and planned two or three per month thereafter. Given the system's short lifespan, only 22 games were actually released. Of them, 19 games were released in the Japanese market, and 14 were released in North America. Third party support was extremely limited compared to previous Nintendo platforms. According to Gunpei Yokoi, Nintendo president Hiroshi Yamauchi had dictated that only a select few third-party developers be shown the Virtual Boy hardware before its formal unveiling, to limit the risk of poor-quality software appearing on the system.\nWhen asked if Virtual Boy games were going to be available for download on the Virtual Console for the Nintendo 3DS, Nintendo of America President Reggie Fils-Aim\u00e9 said he could not answer, as he was unfamiliar with the platform. He noted that, given his lack of familiarity, he would be hard-pressed to make the case for the inclusion of the games on the Virtual Console.\nThe hobbyist community at \"Planet Virtual Boy\" has developed Virtual Boy software. Two previously unreleased games, \"Bound High\" and \"Niko-Chan Battle\" (the Japanese version of \"Faceball\") were released.\nReception.\nThe Virtual Boy garnered negative critical reviews and was a commercial failure. It failed for several reasons including \"its high price, the discomfort caused by play [...] and what was widely judged to have been a poorly handled marketing campaign\".\nGamers who previewed the system at the Shoshinkai 1994 trade show complained that the \"Mario\" demo was not realistic enough, was not in full color, and didn't motion-track the image when players turn their heads. In the lead editorial of \"Electronic Gaming Monthly\" following the show, Ed Semrad predicted that the Virtual Boy would have poor launch sales due to the monochrome screen, lack of true portability, unimpressive lineup of games, and the price, which he argued was as low as it could get given the hardware but still too expensive for the experience. \"Next Generation\"'s editors were also dubious of the Virtual Boy's prospects after the show, and concluded their article on the system by commenting, \"But who will buy it? It's not portable, it's awkward to use, it's 100% antisocial (unlike multiplayer SNES/Genesis games), it's too expensive and \u2013 most importantly \u2013 the 'VR' (i.e. 3D effect) doesn't add to the game at all: it's just a novelty.\"\nFollowing its release, reviews of the Virtual Boy tended to praise its novelty but questioned its ultimate purpose and longtime viability. \"The Los Angeles Times\" described the gameplay as being \"at once familiar and strange\". The column praised the quality of motion and immersive graphics but considered the hardware tedious to use and non-portable. In a later column, the same reviewer found the system to be somewhat asocial, but held hope for its future. Reviewing the system shortly after its North American launch, \"Next Generation\" said, \"Unusual and innovative, the Virtual Boy can be seen as a gamble in the same way that the Game Boy was, but it's a lot harder to see the VB succeeding to the same world-conquering extent that the Game Boy did.\" They elaborated that while the sharp display and unique 3D effect are impressive, aspects such as the monochrome display and potential vision damage to young gamers severely limit the system's appeal. They added that the software library was decent, but failed to capitalize on Nintendo's best-selling franchises because games from \"The Legend of Zelda\" and \"Metroid\" were absent, the \"Mario\" games were not in the same style as the series's most successful installments, and it lacked a system seller to compare with the Game Boy's \"Tetris\".\nThough Nintendo had promised a virtual reality experience, the monochrome display limits the Virtual Boy's potential for immersion. Reviewers often considered the three-dimensional features a gimmick, added to games that were essentially two- or even one-dimensional. \"The Washington Post\" said that even when a game gives the impression of three-dimensionality, it suffers from \"hollow vector graphics\". Yokoi, the system's inventor, said the system did best with action and puzzle games, although those types of games provided only minimal immersion. Multiple critics lamented the absence of head-tracking in the Virtual Boy hardware. Critics found that, as a result, players were unable to immerse themselves in the game worlds of Virtual Boy games. Instead, they interacted simply via a controller, in the manner of any traditional two-dimensional game. Boyer said the console \"struggles to merge the two distinct media forms of home consoles and virtual reality devices\". Though the device employs some basic virtual reality techniques, it does so like the traditional home console with no bodily feedback incorporated into gameplay.\nMany reviewers complained of painful and frustrating physiological symptoms when playing the Virtual Boy. Bill Frischling, writing for \"The Washington Post\", experienced \"dizziness, nausea and headaches\". Reviewers attributed the problems to both the monochromatic display and uncomfortable ergonomics. Several prominent scientists concluded that the long-term side effects could be more serious, and articles published in magazines such as \"Electronic Engineering Times\" and CMP Media's \"TechWeb\" speculated that using any immersive headset such as the Virtual Boy could cause sickness, flashbacks, and even permanent brain damage. Nintendo, in the years after Virtual Boy's demise, has been frank about its failure. Howard Lincoln, chairman of Nintendo of America, said flatly that the Virtual Boy \"just failed\".\nLegacy.\nAccording to \"Game Over\", Nintendo blamed the machine's faults directly on its creator, Gunpei Yokoi. The commercial failure of the Virtual Boy was reportedly a contributing factor to Yokoi's withdrawal from Nintendo, although he had already planned to retire years prior and then finished the successful Game Boy Pocket, which was released shortly before his departure. According to his Nintendo and Koto colleague Yoshihiro Taki, Yokoi had originally decided to retire at age 50 to do as he pleased but had simply delayed it. Nintendo held that Yokoi's departure was \"absolutely coincidental\" to the market performance of any Nintendo hardware. \"The New York Times\" maintained that Yokoi kept a close relationship with Nintendo. After leaving Nintendo, Yokoi founded his own company, Koto, and collaborated with Bandai to create the WonderSwan, a handheld system competing with the Game Boy.\nThe console's focus on peripherals and haptic technology reemerged in later years. The original inventor, Reflection Technology, Inc., was reportedly financially \"devastated\" by the Virtual Boy's performance, with dwindling operations by 1997.\nThe Nintendo 3DS console was launched in 2011, as a handheld gaming console with autostereoscopic 3D visuals, without any special glasses. Prior to launch, Shigeru Miyamoto discussed the Virtual Boy. He said it renders wireframe graphics, but its effects are generally used for two-dimensional games with depth-separated planes. He stated that the graphics are not as appealing, and while developing the Nintendo 64, he had ruled out the use of wireframe graphics as too sparse to draw player characters. Finally, he stated that he perceived the Virtual Boy as a novelty that should not have used the Nintendo license so prominently.\nIn February 2016, Tatsumi Kimishima stated that Nintendo was \"looking into\" virtual reality but also explained that it would take more time and effort for them to assess the technology, and in a February 2017 interview with Nikkei, he stated that the company was \"studying\" VR, and would add it to the Nintendo Switch once it is figured out how users can play for long durations without any issues. Nintendo introduced a VR accessory for the Switch as part of Labo, a line of player-assembled cardboard toys leveraging the console's hardware and Joy-Con controllers. In this case, the console's screen is viewed through goggles containing stereoscopic lenses.\nHobbyists adapted Virtual Boy to other displays. Emulation enabled modern stereoscopic goggles such as Google Cardboard, Samsung Gear VR and Oculus Rift in 2016. In 2018, hobbyist Furrtek released a board that replaces the display circuitry, allowing the Virtual Boy to be played on a VGA monitor or television set. On February 25, 2024, a homebrew Virtual Boy emulator for the Nintendo 3DS was released, named \"Red Viper\", which made it possible to play the Virtual Boy library using stereoscopic 3D.\nNintendo has referenced the Virtual Boy in other games, such as \"Tomodachi Life\"\u2014where a trailer for the life simulation game includes a scene of several Mii characters humorously worshipping the Virtual Boy. In \"Luigi's Mansion 3\", Luigi uses a device by Professor E. Gadd known as the \"Virtual Boo\" to access maps and other information in-game (succeeding the use of devices referencing the Game Boy Color and first-generation Nintendo DS in previous installments). Its menus use a red and black color scheme, with E. Gadd optimistically boasting that the device would \"fly off the shelves\". As of 2024, Virtual Boy merchandise is sold at the Nintendo Museum in Kyoto, Japan.\nOn September 12, 2025, Nintendo announced that it would be re-releasing Virtual Boy games through the Nintendo Classics service, available to subscribers of the Nintendo Switch Online + Expansion Pack service for the Nintendo Switch and Nintendo Switch 2. Playing these games will require an enclosure that the Switch console is inserted into: either cardboard goggles not unlike the previous Labo kits, or alternatively an accessory based on the design of the Virtual Boy hardware. The first games are planned to launch on February 17, 2026, with 15 games planned to be added to the service over time (only 14 in non-Japanese regions).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21971", "revid": "1298209595", "url": "https://en.wikipedia.org/wiki?curid=21971", "title": "Nuclear", "text": "Nuclear may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nPhysics.\nRelating to the nucleus of the atom:\nBiology.\nRelating to the nucleus of the cell:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "21972", "revid": "1123690695", "url": "https://en.wikipedia.org/wiki?curid=21972", "title": "Neoplatonist", "text": ""}
{"id": "21973", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=21973", "title": "Nuclear Weapon", "text": ""}
{"id": "21974", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=21974", "title": "Network service access point address", "text": "Identifying label for a Service Access Point used in Open Systems Interconnection networking\nA network service access point address (NSAP address), defined in ISO/IEC 8348, is an identifying label for a service access point (SAP) used in OSI networking.\nThese are roughly comparable to IP addresses used in the Internet Protocol; they can specify a piece of equipment connected to an Asynchronous Transfer Mode (ATM) network. A specific stream, analogous to a TCP/IP port or socket, is specified by using a transport service access point (TSAP). ATM can also use a presentation (PSAP) and session (SSAP) access point, but these may also be unspecified; this is up to the application.\nAllocation and scope.\nNSAP addresses are allocated by the International Organization for Standardization (ISO), through a system of delegated authorities, which are generally national standards organizations. One of the schemes to generate NSAPs uses E.164 which is the addressing format describing telephone numbers.\nNSAP addresses do not specify where a network terminal is located. Routing equipment must translate NSAP addresses to subnetwork points of attachment (SNPAs) to route OSI packets; virtual circuit identifier (VCI) numbers are an example of a datalink layer SNPAs in ATM; when OSI packets are sent encapsulated in IP packets, the IP address is considered an SNPA.\nSynchronous Digital Hierarchy/Synchronous Optical Networking networks are a major part of the network infrastructure, and NSAPs are used extensively. They are usually assigned by the network management/network operations centre personnel and agreed upon within an organization to be unique (to that organization and based on geographical location using country code telephone prefixes) and are required before any operational connectivity is established at the commissioning stage.\nNSAP addresses are used in the following OSI-based network technologies: \nNSAP-style addresses are used in the IS-IS routing protocol.\nNetwork selector.\nThe network selector (NSEL) is a field in the NSAP address that identifies the network layer service to which a packet should be sent. This part of the address for a router will always be 0x00. In the IS-IS routing protocol, the field is sometimes referred to as the SEL field.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21975", "revid": "48911350", "url": "https://en.wikipedia.org/wiki?curid=21975", "title": "NSAP", "text": ""}
{"id": "21976", "revid": "1879095", "url": "https://en.wikipedia.org/wiki?curid=21976", "title": "American submarine NR-1", "text": "Experimental nuclear submarine\nDeep Submergence Vessel \"NR-1\" was a unique United States Navy nuclear-powered ocean engineering and research submarine built by the Electric Boat Division of General Dynamics at Groton, Connecticut. \"NR-1\" was launched on 25 January 1969, completed initial sea trials 19 August 1969, and was home-ported at Naval Submarine Base New London. She was the smallest nuclear submarine ever put into operation, casually known as \"Nerwin\" and never officially named or commissioned. The U.S. Navy is allocated a specific number of warships by Congress, but Admiral Hyman Rickover avoided using one of those allocations for the construction of \"NR-1\" in order to circumvent the oversight that a warship receives from various bureaus.\nHistory.\n\"NR-1\"'s missions included search, object recovery, geological survey, oceanographic research, and installation and maintenance of underwater equipment. \"NR-1\" had the unique capability to remain at one site and completely map or search an area with a high degree of accuracy, and this was a valuable asset on several occasions.\nIn the 1970s and 1980s, \"NR-1\" conducted numerous classified missions involving recovery of objects from the floor of the deep sea. These missions remain classified and few details have been made public. One publicly acknowledged mission in 1976 was to recover parts of an F-14 that were lost from the deck of an aircraft carrier and sank with at least one AIM-54A Phoenix air-to-air missile. The secrecy typical of USN submarine operations was heightened by Rickover's personal involvement, and he shared details of \"NR-1\" operations only on a need-to-know basis. Rickover envisioned building a small fleet of \"NR-1\" type submarines, but only one was built due to budget restrictions.\nFollowing the loss of the Space Shuttle \"Challenger\" in 1986, \"NR-1\" was used to search for, identify, and recover critical parts of the \"Challenger\" craft. It could remain on the sea floor without resurfacing frequently, and was a major tool for searching deep waters. \"NR-1\" remained submerged and on station even when heavy weather and rough seas hit the area and forced all other search and recovery ships into port.65\nIn October 1994, a survey was done by the \"NR-1\" off the Florida straits 65\u00a0km southwest of Key West where it encountered and explored an uncharted sink hole. On 2 December 1998, an advisory committee approved the name \"NR-1\" for the hole.\nIn 1995, Robert Ballard used the \"NR-1\" and its support ship to explore the wreck of , the sister ship of , which sank off the coast of Greece while serving as a hospital ship during World War I.\nOn 25 February 2007, \"NR-1\" arrived in Galveston, Texas, towed by \"Carolyn Chouest\", in preparation for an expedition to survey the Flower Garden Banks National Marine Sanctuary and other sites in the Gulf of Mexico.\n\"NR-1\" was deactivated on 21 November 2008 at the U.S. Navy submarine base at Groton, Connecticut, defuelled at Portsmouth Naval Shipyard in Kittery, Maine, then sent to Puget Sound Naval Shipyard to be scrapped. On 13 November 2013, the U.S. Navy announced that salvaged pieces of the sub would be put on display at the Submarine Force Library and Museum in Groton.\nCapabilities.\n\"NR-1\" performed underwater search and recovery, oceanographic research missions, and installation and maintenance of underwater equipment to a depth of almost half a nautical mile. Its features included extending bottoming wheels, three viewing ports, exterior lighting, television and still cameras for color photographic studies, an object recovery claw, a manipulator that could be fitted with various gripping and cutting tools, and a work basket that could be used in conjunction with the manipulator to deposit or recover items in the sea. Surface vision was provided by a television periscope permanently installed on a fixed mast in her sail area.6\n\"NR-1\" had sophisticated electronics, computers, and sonar systems that aided in navigation, communications, and object location and identification. It could maneuver or hold a steady position on or close to the seabed or underwater ridges, detect and identify objects at a considerable distance, and lift objects off the ocean floor.4\n\"NR-1\" was equipped with two electric motor-driven propellers and its maneuverability was enhanced by four ducted thrusters, two forward and two aft. The vehicle had diving planes mounted on the sail, and a conventional rudder.1\n\"NR-1\" could travel submerged at approximately for long periods, limited only by consumable supplies\u2014primarily food. It could study and map the ocean bottom, including temperature, currents, and other information for military, commercial, and scientific uses. Its nuclear propulsion provided independence from surface support ships and essentially unlimited endurance.3\n\"NR-1\"'s size limited its crew comforts. The crew of about 10 men could stay at sea for as long as a month, but had no kitchen or bathing facilities. They ate frozen TV dinners, bathed once a week with a bucket of water, and burned chlorate candles to produce oxygen. The sub was so slow that it was towed to sea by a surface vessel, and so tiny that the crew felt the push and pull of the ocean's currents. \"Everybody on \"NR-1\" got sick,\" said Allison J. Holifield, who commanded the sub in the mid-1970s. \"It was only a matter of whether you were throwing up or not throwing up.\"\n\"NR-1\" was generally towed to and from remote mission locations by an accompanying surface tender, which was also capable of conducting research in conjunction with the submarine. \"NR-1\"'s last mother ship was MV \"Carolyn Chouest\", which provided towing, communications, berthing, and direct mission support for all \"NR-1\" operations\u2014a versatile platform and an indispensable member of the \"NR-1\" deep submergence team. \"NR-1\" command was crewed with thirty-five Navy personnel and ten civilian contractor personnel. \"NR-1\" carried as many as thirteen persons (crew and specialists) at one time, including three of the four assigned officers. (The operations officer rode on \"Carolyn Chouest\"). All personnel who crewed \"NR-1\" were nuclear-trained and specifically screened and interviewed by the Director, Navy Nuclear Propulsion Program.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21977", "revid": "1306352", "url": "https://en.wikipedia.org/wiki?curid=21977", "title": "Neo Geo Pocket Color", "text": ""}
{"id": "21978", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=21978", "title": "Neil Kinnock", "text": "Welsh politician (born 1942)\nNeil Gordon Kinnock, Baron Kinnock (born 28 March 1942) is a Welsh politician who was Leader of the Opposition and Leader of the Labour Party from 1983 to 1992. He was a Member of Parliament (MP) from 1970 to 1995, first for Bedwellty and then for Islwyn. He was Vice-President of the European Commission from 1999 to 2004. Kinnock was positioned on the soft left of the Labour Party.\nBorn and raised in South Wales, Kinnock was first elected to the House of Commons in the 1970 general election. He became the Labour Party's shadow education minister after the Conservatives won power in the 1979 general election. After the party under Michael Foot suffered a landslide defeat to Margaret Thatcher in the 1983 election, Kinnock was elected Leader of the Labour Party and Leader of the Opposition. During his tenure as leader, Kinnock proceeded to fight the party's left wing, especially the Militant tendency, and he opposed NUM leader Arthur Scargill's methods in the 1984\u20131985 miners' strike. He led the party during most of the Thatcher government, which included its third successive election defeat when Thatcher won the 1987 general election. Although Thatcher had won another landslide, Labour regained sufficient seats for Kinnock to remain Leader of the Opposition following the election.\nKinnock led the Labour Party to a surprise fourth consecutive defeat at the 1992 general election, despite the party being ahead of John Major's Conservative government in most opinion polls, which had predicted either a narrow Labour victory or a hung parliament. Shortly afterwards, he resigned as Leader of the Labour Party; he was succeeded in the ensuing leadership election by John Smith. He left the House of Commons in 1995 to become a European commissioner. He went on to become Vice-President of the European Commission under Romano Prodi from 1999 to 2004, before being elevated to the House of Lords as Baron Kinnock in 2005. Until the summer of 2009, he was also the chairman of the British Council and the president of Cardiff University.\nEarly life.\nKinnock, an only child, was born in Tredegar, Wales on Saturday, 28 March 1942. His father, Gordon Herbert Kinnock, was a former coal miner who later worked as a labourer, whilst his mother, Mary Kinnock (n\u00e9e Howells), was a district nurse. The family lived in a terraced house in the mining town, where Kinnock grew up surrounded by the close-knit community typical of the South Wales Valleys. Gordon died of a heart attack in November 1971 at the age of 64, and Mary died the following month at 61.\nIn 1953, aged eleven, Kinnock began his secondary education at Lewis School, Pengam, once described by David Lloyd George as \u2018the Eton of the Valleys\u2019, but an institution Kinnock later criticised for its record on corporal punishment. The school was a direct grant grammar school that served pupils from across the Rhymney Valley and Monmouthshire, and Kinnock performed well academically, particularly in history and English. He went on to the University College of South Wales and Monmouthshire in Cardiff (now Cardiff University), where he graduated in 1965 with a degree in Industrial Relations and History. The following year, Kinnock obtained a postgraduate diploma in education. From August 1966 to May 1970, he worked as a tutor for a Workers' Educational Association (WEA).\nAt university, Kinnock was active in student politics and became involved with the Labour Party. He also participated in Campaign for Nuclear Disarmament activities and anti-apartheid protests. During his time at Cardiff, he met Glenys Parry, a fellow student studying education. Kinnock later recalled that his work with the WEA exposed him to the concerns of working-class communities across South Wales and helped develop his skills as a public speaker.\nHe married Glenys Kinnock on 25 March 1967. They have two children \u2013 son Stephen Kinnock (born January 1970, now a Labour MP), and daughter Rachel Nerys Helen Kinnock (born 11 December 1971).\nMember of Parliament.\nEarly parliamentary career (1970\u20131979).\nIn June 1969, Kinnock secured the Labour Party nomination for the Bedwellty constituency in South Wales, narrowly defeating an endorsed candidate of the National Union of Mineworkers (Great Britain) who was twice his age. The constituency was later redesignated as Islwyn before the 1983 general election. He was first elected to the House of Commons on 18 June 1970 with a majority of 22,000 votes, and held the seat by massive majorities throughout his parliamentary career. Upon his election as an MP, his father advised him: \"Remember Neil, MP stands not just for Member of Parliament, but also for Man of Principle.\"\nOn entering Parliament, Kinnock immediately aligned himself with the left wing of the parliamentary Labour Party, joining the Tribune Group. His maiden speech was an abrasive attack on the Conservative government during a debate on the National Health Service. In his first address to the Commons, he announced to the assembled MPs: \"I am the first male member of my family for about three generations who can have reasonable confidence in expecting that I will leave this earth with more or less the same number of fingers, hands, legs, toes and eyes as I had when I was born.\"\nDuring the 1970\u20131974 parliament, he spoke frequently in debates and conscientiously attended to the needs of his Bedwellty constituents. However, his parliamentary performance would later become controversial. Thereafter, his attendance in Parliament dropped off significantly; and by the early 1980s he had one of the ten worst attendance records of all contemporary MPs. This poor attendance record reflected his increasing focus on national political activities and media appearances rather than routine parliamentary business.\nKinnock's political views during the 1970s were characterised by firmly left-wing positions typical of the Tribune Group within the Labour Party. By 1974, he was described as a vocal advocate of the standard left-wing position on nuclear weapons, the Common Market, public ownership, incomes policy, and arms embargoes to South Africa, Chile, and El Salvador. During the 1970s, Kinnock was a fierce critic of the Labour governments of Harold Wilson and James Callaghan. He rejected offers of ministerial positions on ideological grounds, with one Conservative newspaper labelling him a \"left wing fanatic\" in 1978. In December 1974, he wrote an article on nationalisation in \"Labour Monthly\", delivering a bitter criticism of the capitalist system.\nFrom 1974 to 1975, Kinnock served as parliamentary private secretary to Michael Foot, who was then Secretary of State for Employment. This position gave him valuable experience of government operations and brought him into close contact with one of Labour's most prominent left-wing figures. Although he served briefly as Michael Foot's parliamentary private secretary, he turned down offers of ministerial positions in the Wilson and Callaghan governments, preferring to maintain his independence on the backbenches.\nDuring this period, Kinnock wrote two books that reflected his political thinking: \"Wales and the Common Market\" (1971) and \"As Nye Said\" (1980). The latter was a collection of speeches and writings by Aneurin Bevan, the Welsh Labour politician and health secretary during the government of prime minister Clement Attlee who had been Tredegar's MP before Kinnock.\nIn the 1975 referendum on Britain's membership of the European Communities, Kinnock campaigned for Britain to leave the Common Market. He led the Welsh opposition to legislation providing for limited self-government for Wales, arguing that the misfortunes of Welsh working people could best be redressed \"in a single [British] nation and in a single economic unit\". His stance was vindicated when Welsh voters overwhelmingly rejected the devolution proposals in the 1979 Welsh devolution referendum.\nIn the years from 1974 to 1979, Kinnock had gained a national following among the left wing of the Labour Party and in the country at large. He appeared frequently on television and spoke at many local Labour Party and trade union meetings. His reputation as a gifted orator grew during this period, and he became one of the most recognisable faces of Labour's left wing.\nThe SDP breakaway and Labour's internal crisis (1980\u20131983).\nThe late 1970s and early 1980s marked a period of profound crisis for the Labour Party that would fundamentally shape Kinnock's political trajectory. Following Labour's defeat at the 1979 general election, the party moved decisively to the left under new leader Michael Foot, adopting policies including unilateral nuclear disarmament and withdrawal from the European Economic Community. These leftward shifts, combined with organisational changes that increased the power of trade unions and constituency activists in selecting the party leader through a new electoral college system, alarmed many on the party's right wing.\nThe breaking point came in January 1981 with the Limehouse Declaration, when four former Labour Cabinet ministers\u2014Roy Jenkins, David Owen, Bill Rodgers, and Shirley Williams\u2014announced their intention to form the Social Democratic Party (SDP). In total, 28 Labour MPs would eventually defect to the new party, representing the most significant parliamentary split in British politics since the war. The SDP quickly formed an electoral alliance with the Liberal Party, creating a formidable centrist challenge that threatened to displace Labour as the main opposition to the Conservatives.\nKinnock found himself in a complex position during this crisis. As a member of the Tribune Group left, he was sympathetic to many of the policies that had driven the SDP defectors away, yet he was also increasingly aware of the electoral damage caused by Labour's internal divisions. In 1981, while still serving as Labour's education spokesman, Kinnock was alleged to have effectively scuppered Tony Benn's attempt to replace Denis Healey as Labour's Deputy Leader by first supporting the candidacy of the more traditionalist Tribunite John Silkin and then urging Silkin supporters to abstain on the second, run-off, ballot. This tactical manoeuvring demonstrated Kinnock's growing political sophistication and his determination to prevent the hard left from gaining complete control of the party leadership. In his opinion, the party \"needed the contest like we needed bubonic plague\".\nFollowing Labour's defeat in the general election of 1979, Kinnock's political orientation underwent an abrupt change. James Callaghan appointed Kinnock to the Shadow Cabinet as education spokesman, thus ending his years as a back-bench \"rebel\". His ambition was noted by parliamentary colleagues, with David Owen's opposition to electoral college reforms attributed to concerns that such changes would favour Kinnock's eventual succession to the leadership. Kinnock remained as education spokesman following the resignation of Callaghan as Leader of the Labour Party and the election of Michael Foot as his successor in late 1980.\nKinnock became a member of the National Executive Committee of the Labour Party in October 1978. As Shadow Education Secretary, Kinnock developed expertise in education policy and became a prominent critic of Conservative education reforms. He used his position to advocate for comprehensive education and oppose proposals for education vouchers and the restoration of grammar schools. His work in this role enhanced his profile within the party and demonstrated his ability to handle a major policy portfolio.\nThe existential threat posed by the SDP-Liberal Alliance became clear when the Alliance achieved remarkable success in early by-elections. Shirley Williams won Crosby in November 1981, achieving what was then the biggest reversal in by-election history, whilst Roy Jenkins narrowly won Glasgow Hillhead in March 1982. Opinion polls regularly showed the Alliance ahead of both main parties, raising the real possibility that Labour could be reduced to third-party status.\nKinnock was known as a left-winger, and gained prominence for his attacks on Margaret Thatcher's handling of the Falklands War in 1982. He questioned the government's conduct of the conflict and criticised what he saw as unnecessary military action, positions that reflected his anti-militarist stance but which proved unpopular with many voters who supported the war effort.\n1983 general election campaign.\nDuring the 1983 general election campaign, Kinnock delivered one of his most memorable speeches attacking the Conservative government's policies. Speaking in Bridgend just days before polling, his stark warning about the consequences of a Thatcher victory became emblematic of Labour's campaign message and helped establish Kinnock's reputation as a formidable orator:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If Margaret Thatcher wins on Thursday, I warn you not to be ordinary. I warn you not to be young. I warn you not to fall ill. And I warn you not to grow old. \nDespite such passionate campaigning, Labour suffered a devastating defeat, winning only 209 seats and securing just 27.6% of the vote\u2014its worst performance since 1935. The SDP-Liberal Alliance won 25.4% of the vote, coming within just 2% of Labour's total and highlighting the existential threat facing the party. Only the first-past-the-post electoral system saved Labour from complete meltdown, as the Alliance won just 23 seats despite their substantial vote share.\nThe party's poor performance was attributed to several factors: the continuing popularity of Margaret Thatcher following the Falklands War, the split in the anti-Conservative vote caused by the SDP-Liberal Alliance, and Labour's adoption of what many voters saw as extreme left-wing policies including unilateral nuclear disarmament and widespread nationalisation. The devastating result led to Michael Foot's resignation as leader, setting the stage for Kinnock's leadership bid later that year.\nNevertheless, it was Labour's defeat that provided the context for Kinnock's election as party leader in October 1983. He had been an unswerving supporter of Michael Foot, and, partially as a repayment for his loyalty, Foot let it be known following his resignation as leader that he wanted Kinnock to succeed him. At 41, Kinnock's relatively young age and his ability to articulate Labour's values with passion and conviction made him an attractive candidate to modernise the party and restore its electoral prospects against both the Conservatives and the continuing threat from the SDP-Liberal Alliance.\n1983 leadership election.\nFollowing Labour's landslide defeat at the 1983 general election, Michael Foot resigned as Leader of the Labour Party aged 69. The scale of the defeat (Labour's worst performance since 1935 with just 27.6% of the vote and 209 seats) created an immediate consensus that fundamental change was necessary. From the outset, it was expected that the much younger Kinnock would succeed him, with Foot himself privately indicating his preference for the Welsh MP to take over.\nThe leadership contest would be conducted under Labour's new electoral college system, introduced following the party's internal reforms of 1981. This system allocated 40% of the vote to affiliated trade unions, 30% to constituency Labour parties, and 30% to the Parliamentary Labour Party (a structure that had been bitterly contested during the party's period of internal warfare). The system had been designed to reduce the exclusive power of MPs to choose the leader, but it also meant that Kinnock would need to build a coalition across all three sections of the party to secure victory.\nKinnock announced his candidacy on 15 June 1983, immediately positioning himself as the unity candidate who could heal the party's divisions whilst maintaining its socialist principles. His main opponent was Roy Hattersley, the former Shadow Chancellor who represented the party's social democratic right wing. Eric Heffer, representing the hard left, and Peter Shore, a veteran Eurosceptic from the party's centre, also stood, though neither was expected to mount a serious challenge to the two front-runners. The contest highlighted the ideological tensions within the party, with Hattersley campaigning on a platform of immediate policy moderation whilst Kinnock argued for a more gradual approach that would maintain Labour's socialist identity whilst making the party electable.\nDespite his reputation as a fiery orator, he demonstrated considerable tactical acumen in building support across the party's various factions. Crucially, he secured the backing of several major trade unions, including the Transport and General Workers' Union led by Ron Todd, who saw in Kinnock a leader who could bridge the gap between left-wing principles and electoral pragmatism. The concurrent deputy leadership contest featured Roy Hattersley, Gwyneth Dunwoody, Denis Healey, and Michael Meacher, with the prospect of a Kinnock-Hattersley partnership being actively promoted as a \"dream ticket\" that could unite the party's left and right wings.\nKinnock was elected as Labour Party leader on 2 October 1983, securing 71.3% of the electoral college vote (a decisive mandate that exceeded expectations). His vote was distributed as follows: 49.3% from trade unions, 27.4% from constituency parties, and 23.3% from MPs, demonstrating broad-based support across all sections of the party. Roy Hattersley was elected as his deputy with 67.3% of the vote, completing the anticipated \"dream ticket\".\nAt 41, Kinnock became the youngest leader in Labour's history, inheriting a party that faced existential challenges on multiple fronts. The Social Democratic Party/Liberal Alliance had won 25.4% of the vote (just 2.2% behind Labour) and threatened to displace the party as the main opposition to the Conservatives. The Alliance's strong performance had raised serious questions about Labour's long-term viability as a major political force. Internally, the party remained riven by factional warfare between the Militant tendency and other elements, whilst organisationally it remained dominated by trade union influence and activist control that many voters found off-putting. The party's policy positions (including unilateral nuclear disarmament, withdrawal from the European Economic Community, and extensive nationalisation) were deeply unpopular with the electorate, as the election result had starkly demonstrated.\nThe election of the \"dream ticket\" was generally welcomed by the media and political commentators as offering Labour its best hope of recovery. \"The Guardian\" described Kinnock as possessing \"the energy and the vision to remake the Labour Party,\" whilst acknowledging the enormous task ahead. However, some observers questioned whether the partnership could hold together given the ideological differences between Kinnock and Hattersley, particularly on defence and economic policy. The Conservative reaction was notably sanguine, with Margaret Thatcher reportedly viewing Kinnock as less of a threat than other potential Labour leaders (an assessment that would prove premature as Kinnock transformed Labour into a formidable opposition force).\nKinnock's victory speech emphasised themes that would define his leadership: party unity, electability, and the need to reconnect with ordinary voters whilst maintaining Labour's core values. \"We have won the right to lead,\" he declared, \"now we must earn the right to govern.\"\nEarly leadership challenges (1983\u20131985).\nKinnock's leadership faced immediate challenges from two interconnected issues that would shape his early tenure and establish his approach to party management. The first was the ongoing influence of the Trotskyist Militant tendency, which had infiltrated the party organisation and controlled several key constituency parties and councils. The second was the 1984\u20131985 miners' strike led by Arthur Scargill, which threatened to associate Labour with industrial conflict in the public perception.\nShadow Cabinet appointments and early reforms.\nOn 31 October 1983, less than a month after becoming leader, Kinnock announced his first Shadow Cabinet. The appointments reflected his intention to balance the party's various factions whilst beginning the process of marginalising the most left-wing elements. Roy Hattersley became Deputy Leader and Shadow Chancellor, whilst veteran figures like Peter Shore (Shadow Leader of the House and Trade and Industry) and Denis Healey (Shadow Foreign Secretary) retained senior positions. Significantly, Kinnock appointed Gerald Kaufman as Shadow Home Secretary and John Silkin as Shadow Defence Secretary, both seen as moderating influences.\nThe new leader moved quickly to assert his authority over party organisation. In a notable early decision, he appointed Derek Foster, who had been serving as his Parliamentary Private Secretary, to contest the Chief Whip position. Foster's narrow victory over the favourite Norman Hogg by a single vote in 1985 demonstrated Kinnock's growing influence within the Parliamentary Labour Party.\nKinnock also began the process of modernising Labour's communications and public image. In 1985, he appointed Peter Mandelson as the party's Director of Communications, a crucial decision that would transform Labour's media strategy. Mandelson, who had previously worked as a television producer at London Weekend Television, brought professional media expertise to a party that had traditionally relied on amateur publicity efforts. Under his direction, Labour began to adopt more sophisticated campaigning techniques and a more disciplined approach to media relations.\nThe miners' strike and party tensions.\nAlthough Kinnock had come from the Tribune left wing of the party, he recognised that Labour's association with militant tactics was damaging to the party's electoral prospects. He was almost immediately placed in serious difficulty when Arthur Scargill led the National Union of Mineworkers (NUM) into a national strike without a nationwide ballot. Kinnock supported the aim of the strike\u2014which he dubbed the \"case for coal\"\u2014but, as an MP from a mining area, was bitterly critical of the tactics employed. When heckled at a Labour Party rally for referring to the killing of David Wilkie as \"an outrage\", Kinnock lost his temper and accused the hecklers of \"living like parasites off the struggle of the miners\" and implied that Scargill had lied to the striking miners.\nKinnock's criticism of Scargill's methods reflected a broader strategic calculation about Labour's electoral prospects. In 1985, he publicly criticised the strike's tactics at the Labour Party conference, arguing that the violence and the NUM leadership's attitude to court actions had been counterproductive:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The strike wore on. The violence built up because the single tactic chosen was that of mass picketing, and so we saw policing on a scale and with a system that has never been seen in Britain before. The court actions came, and by the attitude to the court actions, the NUM leadership ensured that they would face crippling damages as a consequence. To the question: \"How did this position arise?\", the man from the lodge in my constituency said: \"It arose because nobody really thought it out.\"\nThis willingness to criticise a major trade union leader marked a significant departure from traditional Labour Party solidarity and demonstrated Kinnock's determination to distance the party from actions he considered electorally damaging. His relationship with Scargill would remain deeply antagonistic, with Kinnock later stating: \"Oh I detest him. I did then, I do now, and it's mutual.\" Kinnock blamed Scargill for the failure of the strike.\nShadow Cabinet reshuffles and policy evolution.\nThe October 1984 Shadow Cabinet elections provided Kinnock with an opportunity to reshape his team. On 26 October 1984, he conducted a significant reshuffle that reflected his evolving strategy. Most notably, he transferred Trade and Industry from Peter Shore to John Smith, a rising figure from the party's centre-right, whilst John Prescott replaced Smith as Shadow Employment Secretary. Gwyneth Dunwoody took over as Shadow Transport Secretary, and significantly, Eric Heffer, a prominent left-wing figure, was dropped from the Shadow Cabinet entirely.\nThese appointments reflected Kinnock's strategic approach to party management. By promoting figures like Smith and Prescott - both seen as more pragmatic than the outgoing left-wing appointees - he began the gradual process of shifting the party's centre of gravity whilst maintaining representation for different factions. The exclusion of Heffer, who had been a vocal supporter of Militant and other left-wing causes, sent a clear signal about the direction of party policy.\nThe 1985 conference speech and confronting Militant.\nThe strike's defeat in March 1985 provided the backdrop for Kinnock's most decisive moment as leader. At the 1985 Labour Party conference, with the party's credibility damaged by association with both the failed strike and the chaotic behaviour of Militant-controlled Liverpool City Council, Kinnock delivered a devastating attack that would define his leadership and demonstrate his determination to reclaim the party from the Militant tendency.\nEarlier in 1985, left-wing councils had protested at Government restriction of their budgets by refusing to set budgets, with the Militant-dominated Liverpool City Council creating particular chaos by issuing 31,000 redundancy notices to its own workers. In his conference speech, Kinnock launched a furious assault on Militant's conduct:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I'll tell you what happens with impossible promises. You start with far-fetched resolutions. They are then pickled into a rigid dogma, a code, and you go through the years sticking to that, outdated, misplaced, irrelevant to the real needs, and you end in the grotesque chaos of a Labour council \u2013 a \"Labour\" council \u2013 hiring taxis to scuttle round a city handing out redundancy notices to its own workers ...\nI am telling you, no matter how entertaining, how fulfilling to short-term egos \u2013 you can't play politics with people's jobs and with people's services or with their homes.\nThe speech was an important moment in establishing Kinnock's authority within the party. Eric Heffer, a Liverpool MP and member of the National Executive Committee, walked off the conference stage in disgust, but Kinnock had demonstrated his determination to assert control over the party's direction. The process culminated in June 1986 with the expulsion of Derek Hatton, deputy leader of Liverpool council and high-profile Militant supporter.\nLeft-wing reaction and accusations of betrayal.\nKinnock's confrontational approach towards both Militant and the miners' strike generated intense criticism from the Labour left, who accused him of betraying the party's working-class base during a period of unprecedented Conservative assault on trade unions and industrial communities. The criticism was particularly painful for Kinnock given his own mining heritage - as he later reflected, \"nothing hurt so much as the pain inflicted when Arthur Scargill persuaded some of the mineworkers that Kinnock, the son and grandson of Welsh miners, had betrayed them\".\nThe miners' strike period represented \"probably the worst 12 months of Kinnock's life\". Critics from the left viewed his refusal to give unconditional support to the strike as tantamount to strikebreaking. At the 1984 Labour conference, Kinnock's attempt to appear even-handed by condemning violence \"of the stone-throwers and battering ram-carriers\" alongside \"the violence of cavalry charges, the truncheon groups and the shield-bangers\" was seen by many activists as a false equivalence that ignored the scale of state violence deployed against miners.\nLeft-wing critics argued that Kinnock was prioritising electoral respectability over solidarity with workers facing the most sustained attack on trade union rights since the 1920s. Tony Benn, who later came to view Kinnock as \"the great betrayer\", represented this perspective, arguing that the party was \"paying the price\" for \"soft-pedalling our advocacy for socialism\". The impact of Kinnock's 1985 conference speech against Militant was particularly traumatic for party activists. One observer noted that the conference emitted \"a curious sound as if it had been wounded\", with Tony Benn reduced to tears, comforting a young delegate whilst lamenting: \"I just can't understand what they've done to our party\".\nThis sense of betrayal was compounded by the timing of Kinnock's actions. Critics argued that whilst Margaret Thatcher was \"ripping like a hurricane through the labour movement's hard-won post-war gains - the welfare state, near-full employment, and trade union rights - Kinnock chose to lay into those within his own ranks desperately trying to mount some sort of defence\". Many on the left saw Kinnock as attacking the wrong enemy at the wrong time, focusing internal battles when the party should have been uniting against Conservative policies that were devastating industrial communities across Britain.\nThe left's criticism extended beyond specific tactical disagreements to fundamental questions about the direction of the Labour Party. Kinnock's willingness to distance himself from militant trade unionism and left-wing councils was seen as part of a broader accommodation with Thatcherism that would ultimately lead to the emergence of New Labour. Contemporary left-wing analyses suggested that Kinnock was laying the groundwork for Labour's eventual transformation into \"an overt party of big business\", sacrificing socialist principles for electoral acceptability.\nDespite these criticisms, Kinnock's strategy succeeded in establishing his authority within the party. By 1986, according to \"The Economist\", his personal dominance within the Labour Party had \"come to exceed that of any Labour Party leader since Clement Attlee in the 1940s and 1950s\". However, the cost of this authority - in terms of alienating substantial sections of the party's activist base and undermining Labour's connection to the trade union movement during its hour of greatest need - would continue to influence debates about Kinnock's legacy and the broader direction of the Labour Party for decades to come.\nParty modernisation and policy reform.\nHaving established his authority within the party, Kinnock embarked on a comprehensive modernisation programme designed to make Labour electable again. This involved both organisational reforms and fundamental policy changes that would distance the party from its left-wing image whilst maintaining its appeal to traditional supporters. The transformation was symbolised by Labour's adoption of a new logo\u2014a continental social democratic style red rose replacing the party's old Liberty logo\u2014under the direction of Kinnock's communications director Peter Mandelson.\nKinnock was determined to move the party's political standing to a more centrist position to improve its chances of winning a future general election. Under his leadership, the Labour Party began abandoning unpopular positions, particularly the wholesale nationalisation of industries, although this process would not be completed until Tony Blair revamped Clause IV in 1995. Kinnock stressed economic growth, which had broader appeal to the middle class than redistributive policies, and he accepted continued membership of the European Economic Community, reversing the party's previous commitment to immediate withdrawal.\nThe modernisation efforts showed early signs of success. By 1986, Labour was achieving excellent local election results and managed to seize the Fulham seat from the Conservatives at an April by-election. However, Labour still faced the persistent challenge of the SDP-Liberal Alliance, and many voters remained unconvinced by the party's transformation, particularly on defence policy where Labour maintained its commitment to unilateral nuclear disarmament.\n1987 general election.\nThe continuing threat from the SDP-Liberal Alliance became starkly apparent in early 1987 when Labour lost the Greenwich by-election to the SDP's Rosie Barnes on 26 February. This defeat raised the real possibility that Labour might finish third in the popular vote at the upcoming general election, potentially losing its status as Official Opposition. Coming after a series of impressive Alliance by-election victories, the Greenwich defeat confirmed that Labour's existential crisis remained unresolved after nearly four years of Kinnock's leadership.\nLabour responded with a professionally managed campaign under Peter Mandelson's direction. The party's new approach was evident in a party election broadcast directed by Hugh Hudson (of \"Chariots of Fire\" fame) and popularly known as \"Kinnock: The Movie\". The broadcast featured scenes of Kinnock and his wife Glenys walking on the Great Orme in Llandudno to Beethoven's \"Ode to Joy\", intended to present him as a family man whilst connecting with a broader Welsh identity beyond the mining communities of his upbringing. The broadcast included his speech to the Welsh Labour Party conference asking why he was the \"first Kinnock in a thousand generations\" to go to university. The broadcast led to a 16-point increase in Kinnock's personal popularity ratings.\nKinnock's campaign speeches focused on unemployment (which remained above 3 million despite recent falls), the underfunding of the NHS, and inequality in Thatcher's Britain. However, Labour's campaign faced significant difficulties over defence policy. When interviewed by David Frost on 24 May, Kinnock claimed that Labour's alternative defence strategy in the event of a Soviet attack would be \"using the resources you've got to make any occupation totally untenable\". Thatcher responded two days later, attacking Labour's defence policy as a programme for \"defeat, surrender, occupation, and finally, prolonged guerrilla fighting ... I do not understand how anyone who aspires to Government can treat the defence of our country so lightly\".\nThe Conservative campaign focused on lower taxes, a strong economy, and defence. The party noted that unemployment had fallen below 3 million for the first time since 1981, and that inflation was at 4% (its lowest level since the 1960s). [ell and Saatchi &amp; Saatchi produced attack advertisements, including a poster showing a British soldier's arms raised in surrender with the caption \"Labour's Policy On Arms\" (a reference to Labour's policy of unilateral nuclear disarmament). The national newspapers largely backed the Conservative government, particularly \"The Sun\", which published anti-Labour articles with headlines such as \"Why I'm backing Kinnock, by Stalin\".\nThe election results on 11 June reflected Kinnock's strategic focus on maintaining Labour's position as the main opposition. Labour secured 30.8% of the vote compared to the SDP-Liberal Alliance's 22.6%, a gap of 8.2 points that ended the Alliance's challenge to Labour's status. The Conservatives won 376 seats to Labour's 229, giving Thatcher a third consecutive victory with a majority of 102 seats. Labour gained 20 seats whilst remaining in opposition.\nThe election results revealed a geographically polarised Britain. The Conservatives dominated Southern England and gained additional seats from Labour in London, but performed poorly in Northern England, Scotland, and Wales, losing many seats they had won in previous elections. Labour made significant gains in Scotland and Wales but lost ground in key Southern constituencies, highlighting the electoral mountain they still needed to climb. Kinnock himself increased his share of the vote in Islwyn by almost 12%, demonstrating his continued strong personal support in Wales.\nThe election's significance for Labour lay in ending the SDP-Liberal Alliance as a threat to Labour's position. The Alliance's poor performance led to the merger of the SDP and Liberal parties into the Liberal Democrats in 1988, though this process involved the departure of David Owen and several other prominent SDP figures. Labour was now the undisputed main opposition party, setting up a binary choice against the Conservatives at future elections.\nKinnock acknowledged that whilst the result was disappointing, it had achieved the strategic objective of securing Labour's position as a major political force. The campaign had demonstrated the party's organisational competence, whilst the defeat of the Alliance ensured that Labour would face the Conservatives directly at the next election.\nPolicy review and organisational change (1987\u20131990).\nThe 1987 election result provided Kinnock with the mandate to accelerate Labour's transformation through comprehensive policy reform. The second phase of his leadership was dominated by the Policy Review, a wide-ranging study designed to formulate popular policies and move the party towards electability. On 14 September 1987, Tom Sawyer, chairman of Labour's home policy committee, put forward the Policy Review plan in a paper after consultation with Kinnock. Sawyer's recommendations included how Labour could win back the skilled working class and reviewed the party's policies on enterprise, wealth creation, taxation, and social security.\nThe process began with \"Labour Listens\" in autumn 1987, a series of public consultations that marked a break with the party's traditional approach of formulating policies internally. The home policy committee voted overwhelmingly in favour of Sawyer's three-year plan to produce a new statement of Labour's policies by 1990, and the Labour Party's annual conference endorsed the Policy Review on 28 September 1987. However, the initiative faced criticism from MPs on the party's left, with Tony Benn unsuccessfully proposing an alternative paper titled \"The Aims and Objectives of the Labour Party\" that included proposals for leaving NATO, ending nuclear power, and abolishing the House of Lords.\nThe first stage of the Policy Review reported on 25 May 1988, producing seven policy reports containing 40,000 words. Policies traditionally supported by the Labour left, including withdrawal from the European Economic Community and extensive nationalisation, were abandoned, as were very high income tax rates for top earners. By 1988, the party had produced a new statement of aims and values modelled on Anthony Crosland's social-democratic thinking, emphasising equality rather than public ownership. On 5 June 1988, Kinnock announced that Labour would not unilaterally abolish Britain's nuclear weapons but would use Trident as a bargaining chip to achieve multilateral nuclear disarmament.\nThe policy changes provoked significant internal opposition. Tony Benn launched an eight-month campaign challenging Kinnock for the leadership in 1988, calling it a \"campaign for socialism\" and arguing that the party was not electable if it pursued its current course. Benn's supporters launched their own manifesto, but the challenge lacked full support even from the party's left wing, with David Blunkett arguing that any challenge would certainly result in defeat and give Kinnock an air of \"omnipotence\". On 2 October 1988, Kinnock won the leadership contest with 89% of the electoral college vote, a result interpreted as an endorsement of the Policy Review. The day after Kinnock's victory, the Labour Party conference endorsed the Policy Review by a margin of 5 to 1.\nThe policy review coincided with a significant improvement in Labour's electoral fortunes, driven largely by the unpopular poll tax which was destroying Conservative support. The Community Charge, as it was officially known, replaced domestic rates with a flat-rate tax that proved deeply unpopular across all social classes. Introduced in Scotland in April 1989 and England and Wales in April 1990, the tax sparked widespread civil disobedience, with millions refusing to pay and mass demonstrations culminating in the Trafalgar Square riot of 31 March 1990. Kinnock initially criticised the violence, describing protesters as \"Toy Town revolutionaries\" whilst supporting Labour's opposition to the tax itself.\nIn December 1989, Kinnock completed another break with Labour's past by abandoning the party's support for closed shops, a decision that further distanced the party from its image of being controlled by trade unions. The abandonment of closed shops was particularly symbolic as it represented a rejection of one of the trade union movement's most cherished principles, demonstrating Kinnock's determination to modernise the party's relationship with organised labour.\nBy 1990, the Policy Review had transformed Labour's commitments in areas where the party seemed most out of line with voters, including nationalisation, trade union power, high taxation, and defence. The final stage of the review was completed in 1990 with the publication of \"Looking to the Future\", which laid out Labour's new policy framework. The document accepted most of the Conservative privatisations and abandoned plans for widespread re-nationalisation, whilst maintaining Labour's commitment to social justice through different means. The party also introduced constitutional reforms that reduced the influence of local party activists in policy-making and strengthened the leadership's control over party organisation and communications. However, Thatcher's departure removed a major electoral asset for Labour, as polling showed that Kinnock's personal ratings relative to Major were less favourable than they had been against Thatcher.\nThe transformation was not without significant opposition from the party's left wing, who viewed Kinnock's modernisation as a betrayal of Labour's socialist principles. Tony Benn, the standard-bearer of the Labour left, became increasingly critical of Kinnock's leadership, describing his interviews in 1984 as \"like processed cheese coming out of a mincing machine\". The left's anger intensified as Kinnock continued to distance himself from traditional socialist policies and confronted left-wing councils and trade unions. Many on the left felt that whilst Margaret Thatcher was dismantling the post-war consensus and attacking trade union rights, Kinnock was directing his fire against Labour's own supporters rather than the Conservative government.\nThe economic and social devastation of the period provided a stark backdrop to these political struggles. Coal mining employment, which had stood at 247,000 in 1976, fell dramatically to 44,000 by 1993. Between 1979 and 1990, Margaret Thatcher's government closed 115 coal mines, representing 80% of all mining jobs lost during her tenure. The closure programme accelerated following the miners' strike, devastating mining communities across South Wales, Yorkshire, and other traditional Labour heartlands. Kinnock, despite his own mining heritage, supported the principle that uneconomic pits should close whilst calling for proper consultation and support for affected communities.\nLabour's response to the continuing pit closures reflected the party's difficult position during the era of deindustrialisation. Whilst supporting miners' right to defend their livelihoods, Kinnock recognised that the party was caught between \"unstoppable economic restructuring and job losses that affected its traditional voters\". When Terry Fields, the Militant-supporting Labour MP, was imprisoned in July 1991 for refusing to pay the poll tax, Kinnock commented that \"law makers must not be law breakers\", further infuriating the left who saw this as abandoning a principled Labour MP. The left viewed such statements as evidence that Kinnock had completely abandoned Labour's working-class roots in favour of middle-class respectability.\nThe organisational changes were accompanied by broader shifts in party culture and approach. Under Kinnock's leadership, Labour adopted new campaigning techniques, developed its media relations under Peter Mandelson, and formulated policies designed to appeal to a wider electoral base whilst retaining the party's commitment to social justice. The period also saw Labour grappling with other major political developments, including the Gulf War of 1991, where Kinnock supported the international coalition whilst criticising the government's consultation of Parliament. By 1990, opinion polls showed Labour consistently ahead of the Conservatives, suggesting that the combination of policy modernisation and Conservative unpopularity had made the party electable.\n1992 general election.\nWhen Margaret Thatcher resigned in November 1990, Kinnock initially celebrated, describing it as \"very good news\" and demanding an immediate general election. However, the elevation of John Major as Conservative leader and Prime Minister transformed the political landscape. Major's more conciliatory style and his replacement of the poll tax with council tax neutralised many of the issues that had been driving support towards Labour. Despite the deepening recession, Labour's substantial poll leads evaporated, with some surveys showing the Conservatives ahead by 1991.\nAs 1992 dawned, the recession had still not ended and unemployment topped 2.5 million, but most opinion polls suggested either a hung parliament or a narrow Labour victory. Major called the election on 11 March 1992, as was widely expected, the day after Chancellor Norman Lamont had delivered the Budget. Parliament was dissolved on 16 March, with polling day set for 9 April. Labour entered the campaign confident, having gained four seats from the Conservatives in by-elections since 1987 and with the party transformed into what appeared to be a credible alternative government.\nThe campaign.\nThe parties campaigned on the familiar battlegrounds of taxation and healthcare. Major became known for delivering his speeches whilst standing on an upturned soapbox during public meetings, abandoning the overly cautious battle-plan of \"John Major in the round\" events limited to supporters. Starting in Luton on 28 March, Major's soapbox tour became the defining image of his campaign, allowing him to engage directly with voters including hecklers whilst projecting an image of ordinary accessibility that contrasted with the more stage-managed Labour events.\nThe Conservative campaign focused heavily on taxation, producing memorable attack advertisements including the \"Labour's Double-Whammy\" poster showing a boxer wearing gloves marked \"tax rises\" and \"inflation\". The party successfully exploited Labour's John Smith's \"shadow budget\", which proposed increases in National Insurance contributions on higher earners to fund improvements to child benefit and the state pension. The Conservatives presented this as a \"tax bombshell\" that would threaten the aspirations of Middle England voters.\nLabour suffered a significant early setback with the \"War of Jennifer's Ear\" controversy. On 24 March, Labour broadcast a party election broadcast about a five-year-old girl with glue ear who had waited a year for a simple operation, contrasting her case with that of a girl who received quick private treatment. The broadcast was intended to highlight alleged Conservative underfunding of the NHS, but when the girl was identified as Jennifer Bennett, a fierce political row erupted over the accuracy of the broadcast and the ethics of using a child's illness for political advantage. The controversy dominated news coverage for several days, derailing Labour's attempts to make healthcare a central campaign issue and forcing the party to largely avoid the subject thereafter.\nImmigration also became a contentious issue when Home Secretary Kenneth Baker made a controversial speech claiming that under Labour, \"the floodgates would be opened for immigrants from developing countries\". There was also confusion within Labour's Shadow Cabinet over the party's stance on proportional representation, with different spokespersons giving contradictory statements about potential electoral reform.\nThe Sheffield Rally.\nThe campaign's most notorious moment came with Labour's rally at Sheffield Arena on 1 April 1992. The event, in preparation for eighteen months and costing \u00a3100,000, was attended by 10,000 Labour Party members including the entire shadow cabinet. The rally was the brainchild of strategist Philip Gould, modelled on American presidential conventions with sound and light performances and celebrity endorsements. Kinnock was flown in by helicopter and the shadow cabinet paraded through the crowd to the stage, being introduced with titles such as \"The next Home Secretary\" and \"The next Prime Minister\".\nThe rally culminated with an emotional Kinnock taking the podium and shouting what was generally reported as \"We're all right!\" four times, though Kinnock later claimed he had shouted \"Well all right!\" in the manner of a rock and roll singer. Although Labour's internal polls suggested the event had little effect on the party's support, media commentators thought the rally appeared \"triumphalist\" to television viewers. Opinion polls on 1 April (dubbed \"Red Wednesday\") had shown a clear Labour lead, but this fell considerably in the following day's polls, with many observers blaming the Sheffield Rally for the decline.\nIn later interviews, Kinnock expressed regret about the event, particularly criticising the last-minute change of choreography that added to the triumphalist impression. \"There was a sort of tangible political heat coming off it,\" he reflected. \"So instead of modest competence, which is what I wanted to portray, and most of the campaign did, we had this entry into the arena.\" However, subsequent analysis has questioned whether the rally was genuinely decisive, with some arguing it merely provided a convenient explanation for Labour's defeat after the fact.\nMedia hostility and the final days.\nThe Conservative-supporting press maintained a hostile campaign against Labour throughout. \"The Sun\" ran a series of anti-Labour articles culminating on election day with the front-page headline \"If Kinnock wins today, will the last person to leave Britain please turn out the lights\", featuring Kinnock's head in a lightbulb. The \"Daily Mail\" and \"Daily Express\" carried tables and real-life cases purporting to show how much more ordinary people would pay under Labour's tax proposals, with focus groups finding that these tabloids were a key source of information for many floating voters.\nThe result and aftermath.\nThe Conservatives won a fourth consecutive term with a majority of 21 seats, confounding polls and commentators who had predicted either a hung parliament or narrow Labour victory. The party secured 14.1 million votes (the highest total ever recorded by any British party) and 41.9% of the vote, compared to Labour's 11.5 million votes and 34.4%. The result took many by surprise, leading to an inquiry into polling methodology and widespread analysis of what had gone wrong for Labour.\nPost-election polling found that 49% of voters thought they would be worse off under Labour's tax policies, compared to 30% who thought they would benefit. The Conservative tax campaign appeared to have been successful in \"rationalising Tory waverers' decision to vote Conservative\" whilst playing on broader fears about Labour's economic competence. The defeat was particularly crushing given Labour's expectations of victory and the widespread belief that after thirteen years of Conservative rule, it was time for change.\nKinnock resigned as party leader on 13 April 1992, ending a nine-year tenure that had transformed Labour from what some considered an unelectable protest movement into a credible party of government. In his resignation speech, he blamed \"The Sun\" and other right-wing media for Labour's defeat, though the following day's \"Sun\" headline \"It's The Sun Wot Won It\" was later described by Rupert Murdoch as \"tasteless and wrong\".\nPost-parliamentary career.\nKinnock announced his resignation as Leader of the Labour Party on 13 April 1992, ending nearly a decade in the role. John Smith, previously Shadow Chancellor, was elected on 18 July as his successor.\nKinnock remained on the Advisory Council of the Institute for Public Policy Research, which he helped set up in the 1980s.\nKinnock was an enthusiastic supporter of Ed Miliband's campaign for the Leadership of the Labour Party in 2010, and was reported as telling activists, when Miliband won, \"We've got our party back\" \u2013 although Miliband, like Kinnock, failed to lead the party back into government, and resigned after the Conservatives were re-elected with a small majority in 2015. Labour received their lowest seat tally under Miliband since the 1987 general election; when Kinnock was leader at that time.\nIn 2011, he participated in the Welsh family history television programme \"Coming Home\" where he discovered hitherto unknown information about his family.\nHe is a vice president of the Fabian Society.\nEuropean Union Commissioner.\nKinnock was appointed one of the UK's two members of the European Commission, which he served first as Transport Commissioner under President Jacques Santer, in early 1995; marking the end of his 25 years in the House of Commons. This appointment occurred less than a year after the death of his successor John Smith and Tony Blair's subsequent election as party leader.\nHe was obliged to resign as part of the forced, collective resignation of the Commission in 1999. He was re-appointed to the Commission under new President Romano Prodi. He now became one of the Vice-Presidents of the European Commission, with responsibility for Administrative Reform and the Audit, Linguistics and Logistics Directorates General. His term of office as a Commissioner was due to expire on 30 October 2004, but was delayed owing to the withdrawal of the new Commissioners. During his second Commission term, he oversaw the introduction of new staff regulations for EU officials, which included substantial salary reductions for staff employed after 1 May 2004, reduced pension entitlements for existing employees, and revised employment conditions. These reforms generated significant opposition among EU staff, though the budgetary pressures driving the changes had been mandated by Member States through the Council.\nIn February 2004, it was announced that with effect from 1 November 2004, Kinnock would become head of the British Council. Coincidentally, at the same time, his son Stephen became head of the British Council branch in Saint Petersburg, Russia. At the end of October, it was announced that he would become a Member of the House of Lords (intending to be a working peer), when he was able to leave his EU responsibilities. In 1977, he had remained in the House of Commons, with Dennis Skinner, while other MPs walked to the Lords to hear the Queen's speech opening the new parliament. He had dismissed going to the Lords in recent interviews. Kinnock explained his change of attitude, despite the continuing presence of ninety hereditary peers and appointment by patronage, by asserting that the Lords was a good base for campaigning.\nLife peerage.\nOn 28 January 2005, he was created a life peer as \"Baron Kinnock, of Bedwellty in the County of Gwent\", and was introduced to the House of Lords on 31 January 2005. On assuming his seat, he stated: \"I accepted the kind invitation to enter the House of Lords as a working peer for practical political reasons.\" When his peerage was first announced, he said: \"It will give me the opportunity ... to contribute to the national debate on issues like higher education, research, Europe and foreign policy.\"\nHis peerage meant that the Labour and Conservative parties were equal in numbers in the upper house of Parliament (subsequently the number of Labour members overtook the number of Conservative members for multiple years). Kinnock was a long-time critic of the House of Lords, and his acceptance of a peerage led him to be accused of hypocrisy, by Will Self, among others.\nViews.\nEarly political positions.\nKinnock's early political career was characterised by firmly left-wing positions typical of the Tribune Group within the Labour Party. Political observers described him as holding left-wing views on most matters and talking in the language of the radical post-Bevan left. By 1974, he was described as a vocal advocate of the standard left-wing position on nuclear weapons, the Common Market, public ownership, incomes policy, and arms embargoes to South Africa, Chile, and El Salvador.\nDuring the 1970s, Kinnock was a fierce critic of the Labour governments of Harold Wilson and James Callaghan. He rejected offers of ministerial positions on ideological grounds, with one Conservative newspaper labelling him a \"left wing fanatic\" in 1978. In December 1974, he wrote an article on nationalisation in \"Labour Monthly\", delivering a bitter criticism of the capitalist system. In 1978, at the Labour National Executive Committee, he advocated for reflation, increased spending on health, job-swap schemes, better housing, and ending stock relief for businesses.\nAfter the Labour government's defeat in 1979, Kinnock condemned it with the words: \"For the third time the Labour Party had saved capitalism, and lost.\" As late as October 1984, after becoming party leader, he was still describing the market system as short-sighted and speculative, arguing it would never produce the plenty necessary to meet human need.\nAnti-apartheid activism.\nKinnock was heavily involved in anti-apartheid activism from his university days. At Cardiff University, he organised protests against apartheid in South Africa and campaigned for the release of Nelson Mandela. This activism continued throughout his parliamentary career, and he was later awarded the Order of the Companions of O.R. Tambo by South Africa for his \"excellent contribution to constantly speaking the truth during the apartheid period\" and for fighting for Mandela's release whilst supporting those in exile.\nWelsh identity and devolution.\nKinnock is a supporter of Welsh devolution, with proposals for a Welsh Assembly included in the Labour Party's 1992 manifesto when he was leader. However, in the build up to the 1979 Welsh devolution referendum, the Labour government was in favour of devolution for Wales. Kinnock was among only six South Wales MPs who opposed devolution, supporting an amendment to the Wales Act requiring not merely a simple majority, but also support from 40% of the entire electorate. He later clarified that he supports devolution in principle, but found the proposed settlement at the time as failing to address the economic disparities in the UK, particularly following the closure of coal mines in Wales. In 2023, Kinnock supported a paper outlining an expanded devolution settlement by Centre Think Tank called \"Devolution Revolution\" which he described as offering a clear route map towards workable and fair devolution for the whole of the UK.\nKinnock has often referred to himself as a unionist.\nEvolution from left to centre.\nKinnock's political journey from the left wing to a more centrist position became evident during his leadership of the Labour Party. By October 1988, he was telling Labour Party conference delegates of his intention to work within the market economy, stating that even after years of Labour government implementation, there would still be a market economy. This represented a significant shift from his earlier position that the market system could never produce sufficient plenty to meet human needs.\nThe transformation accelerated with the Policy Review process after 1987, where Kinnock moved the party away from traditional socialist policies. He was instrumental in abandoning the party's commitment to widespread nationalisation and unilateral nuclear disarmament, instead embracing a social democratic approach modelled on Anthony Crosland's thinking, which emphasised equality rather than public ownership.\nKinnock was a member and frequent speaker for the Campaign for Nuclear Disarmament (CND) in his early political career. As Labour leader, he initially supported the party's policy of unilateral nuclear disarmament. However, by 1989 he had abandoned this position, later acknowledging that he had been misguided in his early support for the Campaign for Nuclear Disarmament. In 2015, he warned Jeremy Corbyn that the British people would not vote for unilateral disarmament.\nEconomic and taxation policy.\nKinnock has consistently advocated for progressive taxation, particularly wealth taxes. In 2025, he called for a 2% annual wealth tax on assets above \u00a310 million, which he argued would raise over \u00a312 billion annually. He has also suggested removing VAT exemptions on private healthcare to provide funding for public services.\nHowever, Kinnock has warned against raising income tax, arguing that this would burden people whose real incomes have stagnated over recent decades. On nationalisation, Kinnock has evolved from his early left-wing positions. In 2022, he described nationalisation as a means for operation rather than a political or economic end, and supported Gordon Brown's call for temporary nationalisation of energy firms unable to offer decreased prices, though he questioned the word \"temporary\".\nSocial policy and welfare.\nIn 2025, Kinnock called for the government to scrap the two-child limit, describing rising levels of child poverty as something that would make Charles Dickens furious. He suggested such measures could be funded by a wealth tax on the top 1% of earners, describing his approach as the economics of Robin Hood.\nImmigration and demographics.\nKinnock supports controlled immigration whilst recognising demographic realities. He argues that all countries must have effective control of their borders but emphasises that the UK's rapidly ageing population means extending welcome to people with relevant skills will be necessary for economic prosperity. He has criticised the inclusion of university students in immigration statistics, describing this practice as incompetent and misleading since most students return to their home countries or work elsewhere after graduation.\nOn the broader immigration debate, Kinnock has stated that whilst immigration is fundamental to addressing demographic challenges, open borders are impossible in a world unbalanced by climate change and asymmetrical economics, requiring managed migration balanced by the development of domestic skills.\nDefence and foreign policy.\nKinnock favours defence bonds to finance increased defence expenditure, citing their successful use in financing previous conflicts. He believes that the UK has been engaged in an undeclared technological and propaganda war waged by Russia and, to a considerable extent, China.\nBrexit.\nKinnock strongly opposed Brexit. In 2018, Kinnock stated that Britain could either take the risks and costs of leaving the EU or have the stability, growth and revenues vital for crucial public services like the NHS and social care, and argued for stopping Brexit to save the NHS or seeking European Economic Area membership.\nContemporary political strategy.\nKinnock has been highly critical of Labour's approach to combating Reform UK, describing elements within the party encouraging appeasement as fundamentally wrong. He argues that if people are offered two versions of a particular political brand, they will always choose the genuine one, and believes accomplishment in government is the best way to counter populist politics.\nPersonal life.\nKinnock met Glenys Kinnock (n\u00e9e Parry) in the early 1960s whilst studying at University College, Cardiff, where they were known as \"the power and the glory\" - with Glenys characterised as \"the power\" - and married on 25 March 1967. His wife was the UK's Minister for Africa and the United Nations from 2009\u20132010, and a Labour Member of the European Parliament (MEP) from 1994\u20132009. Her elevation to the peerage in 2009 made them among the few married couples to hold hereditary or life titles independently. Previously living together in Peterston-super-Ely, a village near the western outskirts of Cardiff, in 2008 they relocated to Tufnell Park, London, to be closer to their daughter and grandchildren. Glenys' death was announced on 3 December 2023.\nThey have a son, Stephen and a daughter, Rachel. Neil Kinnock, through his son Stephen, is also the father-in-law of Helle Thorning-Schmidt who was Prime Minister of Denmark from 2011 to 2015.\nOn 26 April 2006, Kinnock was given a six-month driving ban after being found guilty of two speeding offences along the M4 motorway, west of London.\nKinnock is a Cardiff City F.C. fan and regularly attends matches. He is also a follower of rugby union and supports London Welsh RFC at club level, regularly attending Wales games.\nHe was portrayed by both Chris Barrie and Steve Coogan in the satirical TV programme \"Spitting Image\", and by Euan Cuthbertson in the Scottish film \"In Search of La Che\".\nIn 2014, Lord Kinnock was painted by artist Edward Sutcliffe. The portrait was exhibited at the Royal Society of Portrait Painters Annual Exhibition that year.\nKinnock has been described as an agnostic and an atheist. He is a Patron of Humanists UK.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21979", "revid": "46799909", "url": "https://en.wikipedia.org/wiki?curid=21979", "title": "Netscape", "text": "American computer services company\nNetscape Communications Corporation (originally Mosaic Communications Corporation) was an American independent computer services company with headquarters in Mountain View, California, and then Dulles, Virginia. Its Netscape web browser was once dominant but lost to Internet Explorer and other competitors in the first browser war, with its market share falling from more than 90 percent in the mid-1990s to less than one percent in 2006. An early Netscape employee, Brendan Eich, created the JavaScript programming language, the most widely used language for client-side scripting of web pages. A founding engineer of Netscape, Lou Montulli, created HTTP cookies. The company also developed SSL which was used for securing online communications and was later renamed to TLS.\nNetscape stock traded from 1995 until 1999 when the company was acquired by AOL in a pooling-of-interests transaction ultimately worth US$10 billion. In February 1998, approximately one year before its acquisition by AOL, Netscape released the source code for its browser and created the Mozilla Organization to coordinate future development of its product. The Mozilla Organization rewrote the entire browser's source code based on the Gecko rendering engine, and all future Netscape releases were based on this rewritten code. When AOL scaled back its involvement with Mozilla Organization in the early 2000s, the Organization proceeded to establish the Mozilla Foundation in July 2003 to ensure its continued independence with financial and other assistance from AOL. The Gecko engine is used to power the Mozilla Foundation's Firefox browser.\nIn addition to browsers, Netscape developed a suite of award-winning server software, known as SuiteSpot, to power enterprise Internet and Intranet websites, forums, and email; e-commerce software; and a consumer web portal named Netcenter. Netscape's browser development continued until December 2007, when AOL announced that the company would stop supporting it by early 2008. As of 2024, AOL continues to use the Netscape brand to market a discount Internet service provider, which itself continues to provide a Chromium-based web browser called Netscape, developed by UK security firm SentryBay.\nHistory.\nEarly years.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nNetscape Communications wants you to forget all the highway metaphors you've ever heard about the Internet. Instead, think about an encyclopedia\u2014one with unlimited, graphically rich pages, connections to Email and files, and access to Internet newsgroups and online shopping.\n\u2014\"Netscape Navigator\", Macworld (May 1995) \nMosaic was developed at the tax payer funded National Center for Supercomputing Applications (NCSA) at the University of Illinois at Urbana\u2013Champaign beginning in late 1992. Mosaic became a private venture as Mosaic Communications Corporation on April 4, 1994, the brainchild of Jim Clark who had recruited Marc Andreessen as co-founder and Kleiner Perkins as investors. The first meeting between Clark and Andreessen was never truly about a software or service like Netscape, but more about a product that was similar to Nintendo. Clark recruited other early team members from SGI and NCSA Mosaic. Jim Barksdale came on board as CEO in January 1995. Jim Clark and Marc Andreessen created a 20-page concept pitch for an online gaming network to Nintendo for the Nintendo 64 console, but a deal was never reached. Marc Andreessen explains, \"If they had shipped a year earlier, we probably would have done that instead of Netscape.\"\nThe company's first product was the web browser, called \"Mosaic Netscape 0.9,\" released on October 13, 1994. Within four months of its release, it had already taken three-quarters of the browser market. It became the main browser for Internet users in such a short time due to its superiority over other competition, like Mosaic. This browser was subsequently renamed Netscape Navigator, and the company took the \"Netscape\" name (coined by employee Greg Sands, although it was also a trademark of Cisco Systems) on November 14, 1994, to avoid trademark ownership problems with NCSA, where the initial Netscape employees had previously created the NCSA Mosaic web browser. The Mosaic Netscape web browser did not use any NCSA Mosaic code. The internal codename for the company's browser was \"Mozilla\", which stood for \"Mosaic killer\", as the company's goal was to displace NCSA Mosaic as the world's number one web browser. A cartoon Godzilla-like lizard mascot was drawn by artist-employee Dave Titus, which went well with the theme of crushing the competition. The Mozilla mascot featured prominently on Netscape's website in the company's early years. However, the need to project a more \"professional\" image (especially towards corporate clients) led to this being removed.\nNetscape eventually became the first company to attempt to capitalize on the emerging World Wide Web.\nInitial public offering (IPO).\nOn August 9, 1995, Netscape made an extremely successful IPO, only sixteen months after the company was formed. The stock was set to be offered at US$14 per share, but a last-minute decision doubled the initial offering to US$28 per share. The stock's value soared to US$75 during the first day of trading, nearly a record for first-day gain. The stock closed at US$58.25, which gave Netscape a market value of US$2.9 billion. It was listed on the NASDAQ under the symbol NSCP. While it was somewhat unusual for a company to go public before becoming profitable, Netscape's revenues had, in fact, doubled every quarter in 1995. The success of this IPO subsequently inspired the use of the term \"Netscape moment\" to describe a high-visibility IPO that signals the dawn of a new industry. During this period, Netscape also pursued a publicity strategy (crafted by Rosanne Siino, then head of public relations), packaging Andreessen as the company's \"rock star.\" The events of this period ultimately landed Andreessen, barefoot, on the cover of \"Time\" magazine. The IPO also helped kickstart widespread investment in internet companies that created the dot-com bubble.\nIt is alleged that several Microsoft executives visited the Netscape campus in June 1995 to propose dividing the market (an allegation denied by Microsoft and, if true, would have breached antitrust laws), which would have allowed Microsoft to produce web browser software for Windows while leaving all other operating systems to Netscape. Netscape refused the proposition. Microsoft released version 1.0 of Internet Explorer as a part of the Windows 95 Plus Pack add-on. According to former Spyglass developer Eric Sink, Internet Explorer was based not on NCSA Mosaic as commonly believed, but on a version of Mosaic developed at Spyglass (which itself was based upon NCSA Mosaic). \nThis era would become known as the browser wars. Netscape Navigator was not free to the general public until January 1998, while Internet Explorer and Internet Information Server have always been free or came bundled with an operating system and/or other applications. Meanwhile, Netscape faced increasing criticism for \"featuritis\" \u2013 putting a higher priority on adding new features than on making their products work properly. Netscape experienced its first bad quarter at the end of 1997 and underwent a large round of layoffs in January 1998. Former Netscape executives Mike Homer and Peter Currie have described this period as \"hectic and crazy\" and that the company was undone by factors both internal and external. In January 1998, Netscape started the open source Mozilla project. Netscape publicly released the source code of Netscape Communicator 5.0 under the Netscape Public License, which was similar to the GNU General Public License but allowed Netscape to continue to publish proprietary work containing the publicly released code. \nThe United States Department of Justice filed an antitrust case against Microsoft in May 1998. Netscape was not a plaintiff in the case, though its executives were subpoenaed and it contributed much material to the case, including the entire contents of the 'Bad Attitude' internal discussion forum.\nAcquisition by America Online.\nOn November 24, 1998, America Online (AOL) announced it would acquire Netscape Communications in a tax-free stock swap valued at US$4.2 billion. By the time the deal closed on March 17, 1999, it was valued at US$10 billion. This merger was ridiculed by many who believed that the two corporate cultures could not possibly mesh; one of its most prominent critics was longtime Netscape developer Jamie Zawinski.\nDisbanding.\nDuring Netscape's acquisition by AOL, joint development and marketing of Netscape software products would occur through the Sun-Netscape Alliance. In the newly branded iPlanet, the software included \"messaging and calendar, collaboration, web, application, directory, and certificate servers\", as well as \"production-ready applications for e-commerce, including commerce exchange, procurement, selling, and billing.\" In March 2002, when the alliance was ended, \"iPlanet became a division of Sun... Sun retained the intellectual property rights for all products and the engineering\"\nOn July 15, 2003, Time Warner (formerly AOL Time Warner) disbanded Netscape. Most of the programmers were laid off, and the Netscape logo was removed from the building. However, the Netscape 7.2 web browser (developed in-house rather than with Netscape staff, with some work outsourced to Sun's Beijing development center) was released by AOL on August 18, 2004.\nAfter the Sun acquisition by Oracle in January 2010, Oracle continued to sell iPlanet-branded applications, which originated from Netscape.\nFinal release of the browser.\nThe Netscape brand name continued to be used extensively. The company once again had its own programming staff devoted to the development and support for the series of web browsers. Additionally, Netscape also maintained the Propeller web portal, which was a popular social-news site, similar to Digg, which was given a new look in June 2006. AOL marketed a discount ISP service under the Netscape brand name.\nA new version of the Netscape browser, Netscape Navigator 9, based on Firefox 2, was released in October 2007. It featured a green and grey interface. In November 2007, IE had 77.4% of the browser market, Firefox 16.0%, and Netscape 0.6%, according to Net Applications, an Internet metrics firm. On December 28, 2007, AOL announced that it would drop support for the Netscape web browser and would no longer develop new releases on February 1, 2008. The date was later extended to March 1 to allow a major security update and to add a tool to assist users in migrating to other browsers. These additional features were included in the final version of Netscape Navigator 9 (version 9.0.0.6), released on February 20, 2008.\nSoftware.\nClassic releases.\nNetscape Navigator (versions 0.9\u20134.08).\nNetscape Navigator was Netscape's web browser from versions 1.0 to 4.8. The first beta versions were released in 1994 and were called Mosaic and later Mosaic Netscape. Then, a legal challenge from the National Center for Supercomputing Applications (makers of NCSA Mosaic), which many of Netscape's founders used to develop, led to the name Netscape Navigator. The company's name also changed from Mosaic Communications Corporation to Netscape Communications Corporation.\nThe browser was easily the most advanced available and so was an instant success, becoming a market leader while still in beta. Netscape's feature count and market share continued to grow rapidly after version 1.0 was released. Version 2.0 added a full email reader called Netscape Mail, thus transforming Netscape from a single-purpose web browser to an Internet suite. The email client's main distinguishing feature was its ability to display HTML email. During this period, the entire suite was called Netscape Navigator.\nVersion 3.0 of Netscape (the first beta was codenamed \"Atlas\") was the first to face any serious competition in the form of Microsoft Internet Explorer 3.0. But Netscape remained the most popular browser at that time.\nNetscape also released a Gold version of Navigator 3.0 that incorporated WYSIWYG editing with drag and drop between web editor and email components.\nNetscape Communicator (versions 4.0\u20134.8).\nNetscape 4 addressed the problem of Netscape Navigator being used as both the name of the suite and the browser contained within it by renaming the suite to Netscape Communicator. After five preview releases in 1996\u20131997, Netscape released the final version of Netscape Communicator in June 1997. This version, more or less based on Netscape Navigator 3 Code, updated and added new features. The new suite was successful, despite increasing competition from Internet Explorer (IE) 4.0 and problems with the outdated browser core. IE was slow and unstable on the Mac platform until version 4.5. Despite this, Apple entered into an agreement with Microsoft to make IE the default browser on new Mac OS installations, a further blow to Netscape's prestige. The Communicator suite was made up of Netscape Navigator, Netscape Mail &amp; Newsgroups, Netscape Address Book and Netscape Composer (an HTML editor).\nOn January 22, 1998, Netscape Communications Corporation announced that all future versions of its software would be available free of charge and developed by an open source community, Mozilla. Netscape Communicator 5.0 was announced (codenamed \"Gromit\"). However, its release was greatly delayed, and meanwhile, there were newer versions of Internet Explorer, starting with version 4. These had more features than the old Netscape version, including better support of HTML 4, CSS, DOM, and ECMAScript; eventually, the more advanced Internet Explorer 5.0 became the market leader.\nIn October 1998, Netscape Communicator 4.5 was released. It featured various functionality improvements, especially in the Mail and Newsgroups component, but did not update the browser core, whose functionality was essentially identical to that of version 4.08. One month later, Netscape Communications Corporation was bought by AOL. In November, work on Netscape 5.0 was canceled in favor of developing a completely new program from scratch.\nMozilla-based releases.\nNetscape 6 (versions 6.0\u20136.2.3).\nIn 1998, an informal group called the Mozilla Organization was formed and largely funded by Netscape (the vast majority of programmers working on the code were paid by Netscape) to coordinate the development of Netscape 5 (codenamed \"Gromit\"), which would be based on the Communicator source code. However, the aging Communicator code proved difficult to work with, and the decision was taken to scrap Netscape 5 and rewrite the source code. The rewritten source code was in the form of the Mozilla web browser, on which, with a few additions, Netscape 6 was based.\nNetscape 7 (versions 7.0\u20137.2).\nNetscape 7.0 (based on Mozilla 1.0.1) was released in August 2002 as a direct continuation of Netscape 6 with very similar components. It picked up a few users, but was still very much a minority browser. It did, however, come with the popular Radio@Netscape Internet radio client. AOL had decided to deactivate Mozilla's pop-up blocker functionality in Netscape 7.0, which created outrage in the community. AOL reversed the decision and allowed Netscape to reinstate the pop-up blocker for Netscape 7.01. Netscape also introduced a new AOL-free version (without the usual AOL add-ons) of the browser suite. Netscape 7.1 (codenamed \"Buffy\" and based on Mozilla 1.4) was released in June 2003.\nIn 2003, AOL closed down its Netscape division and laid off or reassigned all of Netscape's employees. Mozilla.org continued, however, as the independent Mozilla Foundation, taking on many of Netscape's ex-employees. AOL continued to develop Netscape in-house (with help from Sun's Beijing development center), but, due to there being no staff committed to it, improvements were minimal. One year later, in August 2004, the last version based on Mozilla was released: Netscape 7.2, based on Mozilla 1.7.2.\nAfter an official poll posted on Netscape's community support board in late 2006, speculation arose of the Netscape 7 series of suites being fully supported and updated by Netscape's in-house development team.\nMozilla Firefox-based releases.\nNetscape Browser (version 8.0\u20138.1.3).\nBetween 2005 and 2007, Netscape's releases became known as \"Netscape Browser\". AOL chose to base Netscape Browser on the relatively successful Mozilla Firefox, a rewritten version of Mozilla produced by the Mozilla Foundation. This release is not a full Internet suite as before, but is solely a web browser.\nOther controversial decisions include the browser only being released for Microsoft Windows and featuring both the Gecko rendering engine of previous releases and the Trident engine used in Internet Explorer, and switching between them based on a \"compatibility list\" that came with the browser. This effectively exposed users to the security vulnerabilities in both and resulted in a completely different user experience based on which site they were on. Examples are handling of right-to-left or bi-directional text, user interface widgets, bugs, and web standards violations in Trident, etc. On top of this, Netscape Browser 8 even broke Internet Explorer's ability to open XML files by damaging a Windows Registry key, and would do so every time it was opened, even if the user fixed it manually.\nAOL's acquisition of Netscape Communications in November 1998 made it less of a surprise when the company laid off the Netscape team and outsourced development to Mercurial Communications. Netscape Browser 8.1.3 was released on April 2, 2007, and included general bug fixes identified in versions 8.0\u20138.1.2\nNetscape Navigator (version 9.0).\nNetscape Navigator 9's features were said to include newsfeed support and become more integrated with the Propeller Internet portal, alongside more enhanced methods of discussion, submission and voting on web pages. It also sees the browser return to multi-platform support across Windows, Linux and Mac OS X. Like Netscape version 8.x, the new release was based upon the popular Mozilla Firefox (version 2.0), and supposedly had full support of all Firefox add-ons and plugins, some of which Netscape was already providing. A beta of the program was first released on June 5, 2007. The final version was released on October 15, 2007. It was the first time the browser was produced in-house with its own programming staff since 2004.\nEnd of development and support.\nAOL officially announced that support for Netscape Navigator would end on March 1, 2008, and recommended that its users download either the Flock or Firefox browsers, both of which were based on the same technology.\nThe decision met mixed reactions from communities, with many arguing that the termination of product support is significantly belated. Internet security site \"Security Watch\" stated that a trend of infrequent security updates for AOL's Netscape caused the browser to become a \"security liability\", specifically the 2005\u20132007 versions, Netscape Browser 8. Asa Dotzler, one of Firefox's original bug testers, greeted the news with \"good riddance\" in his blog post, but praised the various members of the Netscape team over the years for enabling the creation of Mozilla in 1998. Others protested and petitioned AOL to continue providing vital security fixes to unknowing or loyal users of its software, as well as protection of a well-known brand.\nMozilla Thunderbird-based releases.\nNetscape Messenger 9.\nOn June 11, 2007, Netscape announced Netscape Mercury, a standalone email and news client that was to accompany Navigator 9. Mercury was based on Mozilla Thunderbird. The product was later renamed Netscape Messenger 9, and an alpha version was released. In December 2007, AOL announced it was canceling Netscape's development of Messenger 9 as well as Navigator 9.\nProduct list.\nInitial product line.\nNetscape's initial product line consisted of:\nLater Netscape products.\nNetscape's later products included:\nPropeller.\nBetween June 2006 and September 2007, AOL operated Netscape's website as a social news website similar to Digg. The format did not do well as traffic dropped 55.1 percent between November 2006 and August 2007. In September 2007, AOL reverted Netscape's website to a traditional news portal, and rebranded the social news portal as \"Propeller\", moving the site to the domain \"propeller.com.\" AOL shut down the Propeller website on October 1, 2010.\nNetscape Search.\nNetscape operated a search engine, Netscape Search, which now redirects to AOL Search (which itself now merely serves Bing (formerly Google) search results). Another version of Netscape Search was incorporated into Propeller.\nOther sites.\nNetscape also operated several country-specific Netscape portals, including Netscape Canada among others. The portal of Netscape Germany was shut down in June 2008.\nThe Netscape Blog was written by Netscape employees discussing the latest on Netscape products and services. Netscape NewsQuake (formerly \"Netscape Reports\") is Netscape's news and opinion blog, including video clips and discussions. As of January 2012[ [update]], no new posts have been made on either of these blogs since August 2008.\nNetscape technologies.\nNetscape created the JavaScript web page scripting language. It also pioneered the development of push technology, which effectively allowed websites to send regular updates of information (weather, stock updates, package tracking, etc.) directly to a user's desktop (aka \"webtop\"); Netscape's implementation of this was named Netcaster. However, businesses quickly recognized the use of push technology to deliver ads to users, which annoyed them, so Netcaster was short-lived.\nNetscape was notable for its cross-platform efforts. Its client software continued to be made available for Windows (3.1, 95, 98, NT), Macintosh, Linux, OS/2, BeOS, and many versions of Unix including DEC, Sun Solaris, BSDI, IRIX, IBM AIX, and HP-UX. Its server software was generally only available for Unix and Windows NT, though some of its servers were made available on Linux, and a version of Netscape FastTrack Server was made available for Windows 95/98. Today, most of Netscape's server offerings live on as the Sun Java System, formerly under the Sun ONE branding. Although Netscape Browser 8 was Windows only, multi-platform support exists in the Netscape Navigator 9 series of browsers.\nPrior services.\nNetscape Internet Service.\nNetscape ISP was a dial-up Internet service once offered at US$9.95 per month. The company served web pages in a compressed format to increase effective speeds up to 1300\u00a0kbit/s (average 500\u00a0kbit/s). The Internet service provider was later run by Verizon under the Netscape brand. The low-cost ISP was officially launched on January 8, 2004.\nOn November 30, 2025, Netscape ISP will be discontinued.\nNetscape.com.\nNetscape drove much traffic from various links included in the browser menus to its web properties. Some say it was very late to leverage this traffic for what would become the start of the major online portal wars. \nNetscape's exclusive features, such as the Netscape Blog, Netscape NewsQuake, Netscape Navigator, My Netscape and Netscape Community pages, are less accessible from the AOL Netscape designed portal and in some countries not accessible at all without providing a full URL or completing an Internet search. The new AOL Netscape site was originally previewed in August 2007 before moving the existing site in September 2007.\nNetscape.com now redirects to AOL's website, with no Netscape branding at all. Meanwhile, Netscape.co.uk now redirects to AOL Search, also with no Netscape branding at all.\nDMOZ.\nDMOZ (from directory.mozilla.org, its original domain name, also known as the Open Directory Project or ODP), was a multilingual open content directory of World Wide Web links owned by Netscape that was constructed and maintained by a community of volunteer editors. It closed in 2017.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21980", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=21980", "title": "Newfoundland and Labrador", "text": "Province of Canada\nNewfoundland and Labrador is the easternmost province of Canada, in the country's Atlantic region. The province comprises the island of Newfoundland and the continental region of Labrador, having a total size of . As of 2025 the population of Newfoundland and Labrador was estimated to be 549,911. The island of Newfoundland (and its smaller neighbouring islands) is home to around 94 per cent of the province's population, with more than half residing in the Avalon Peninsula. Labrador has a land border with both the province of Quebec, as well as a short border with the territory of Nunavut on Killiniq Island. The French overseas collectivity of Saint Pierre and Miquelon lies about west of the Burin Peninsula.\nAccording to the 2016 census, 97.0% of residents reported English as their native language, making Newfoundland and Labrador Canada's most linguistically homogeneous province. Much of the population is descended from English and Irish settlers, with the majority immigrating from the early 17th century to the late 19th century.\nSt. John's, the capital and largest city of Newfoundland and Labrador, is Canada's 22nd-largest census metropolitan area and home to about 40% of the province's population. St. John's is the seat of the House of Assembly of Newfoundland and Labrador as well as the province's highest court, the Newfoundland and Labrador Court of Appeal.\nUntil 1949, the Dominion of Newfoundland was a separate dominion in the British Empire. In 1933, the House of Assembly of the self-governing dominion voted to dissolve itself and to hand over administration of Newfoundland and Labrador to the British-appointed Commission of Government. This followed the suffering caused by the Great Depression and Newfoundland's participation in the First World War. On March 31, 1949, it became the tenth and most recent province to join the Canadian Confederation as \"Newfoundland\". On December 6, 2001, the Constitution of Canada was amended to change the province's name from \"Newfoundland\" to \"Newfoundland and Labrador\".\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nNames.\nThe name \"New founde lande\" was uttered by King Henry VII about the land explored by Sebastian and John Cabot. In Portuguese, it is (while the province's full name is ), which literally means \"new land\" and is also the French name for the province's island region (). The name \"Terra Nova\" is in wide use on the island (e.g. Terra Nova National Park). The influence of early Portuguese exploration is also reflected in the name of Labrador, which derives from the surname of the Portuguese navigator Jo\u00e3o Fernandes Lavrador.\nLabrador's name in the Inuttitut/Inuktitut language (spoken in Nunatsiavut) is (), meaning \"the big land\" (a common English nickname for Labrador). Newfoundland's Inuttitut/Inuktitut name is (), meaning \"place of many shoals\". Newfoundland and Labrador's Inuttitut / Inuktitut name is \"\".\n is the French name used in the Constitution of Canada. However, French is not widely spoken in Newfoundland and Labrador and is not an official language at the provincial level.\nOn April 29, 1999, the government of Brian Tobin passed a motion in the Newfoundland House of Assembly requesting the federal government amend the \"Newfoundland Act\" to change the province's name to \"Newfoundland and Labrador\". A resolution approving the name change was put forward in the House of Commons in October 2001, introduced by Tobin who had moved to federal politics. Premier Roger Grimes stated: \"The Government of Newfoundland and Labrador is firmly committed to ensuring official recognition of Labrador as an equal partner in this province, and a constitutional name change of our province will reiterate that commitment\". Following approval by the House of Commons and the Senate, Governor-General Adrienne Clarkson officially proclaimed the name change on December 6, 2001.\nGeography.\nNewfoundland and Labrador is the most easterly province in Canada, situated in the northeastern region of North America. The Strait of Belle Isle separates the province into two geographical parts: Labrador, connected to mainland Canada, and Newfoundland, an island in the Atlantic Ocean. The province also includes over 7,000 tiny islands. The highest point of the province is Mount Caubvick with the highest point on Newfoundland being Cabox.\nNewfoundland has a roughly triangular shape. Each side is about long, and its area is . Newfoundland and its neighbouring small islands (excluding French possessions) have an area of . Newfoundland extends between latitudes 46\u00b036\u2032N and 51\u00b038\u2032N.\nLabrador is also roughly triangular in shape: the western part of its border with Quebec is the drainage divide of the Labrador Peninsula. Lands drained by rivers that flow into the Atlantic Ocean are part of Labrador, and the rest belongs to Quebec. Most of Labrador's southern boundary with Quebec follows the 52nd parallel of latitude. Labrador's extreme northern tip, at 60\u00b022\u2032N, shares a short border with Nunavut on Killiniq Island. Labrador also has a maritime border with Greenland. Labrador's land area (including associated small islands) is . Together, Newfoundland and Labrador make up 4.06 per cent of Canada's area, with a total area of .\nGeology.\nLabrador is the easternmost part of the Canadian Shield, a vast area of ancient metamorphic rock making up much of northeastern North America. Colliding tectonic plates have shaped much of the geology of Newfoundland. Gros Morne National Park has a reputation as an outstanding example of tectonics at work, and as such has been designated a World Heritage Site. The Long Range Mountains on Newfoundland's west coast are the northeasternmost extension of the Appalachian Mountains.\nThe north-south extent of the province (46\u00b036\u2032N to 60\u00b022\u2032N), prevalent westerly winds, cold ocean currents and local factors such as mountains and coastline combine to create the various climates of the province.\nClimate.\nNewfoundland, in broad terms, has a cool summer subtype, with a humid continental climate attributable to its proximity to water \u2014 no part of the island is more than from the Atlantic Ocean. However, Northern Labrador is classified as a polar tundra climate, and southern Labrador has a subarctic climate. Newfoundland and Labrador contain a range of climates and weather patterns, including frequent combinations of high winds, snow, rain, and fog, conditions that regularly made travel by road, air, or ferry challenging or impossible.\nMonthly average temperatures, rainfall levels, and snowfall levels for four locations are shown in the attached graphs. St. John's represents the east coast, Gander the interior of the island, Corner Brook the west coast of the island and Wabush the interior of Labrador. Climate data for 56 places in the province is available from Environment Canada.\nThe data for the graphs is the average over 30 years. Error bars on the temperature graph indicate the range of daytime highs and night time lows. Snowfall is the total amount that fell during the month, not the amount accumulated on the ground. This distinction is particularly important for St. John's, where a heavy snowfall can be followed by rain, so no snow remains on the ground.\nSurface water temperatures on the Atlantic side reach a summer average of inshore and offshore to winter lows of inshore and offshore. Sea temperatures on the west coast are warmer than Atlantic side by 1\u20133\u00a0\u00b0C (approximately 2\u20135\u00a0\u00b0F). The sea keeps winter temperatures slightly higher and summer temperatures a little lower on the coast than inland. The maritime climate produces more variable weather, ample precipitation in a variety of forms, greater humidity, lower visibility, more clouds, less sunshine, and higher winds than a continental climate.\nHistory.\nEarly history and the Beothuks.\nDorset culture.\nHuman habitation in Newfoundland and Labrador can be traced back about 9,000 years. The Maritime Archaic peoples were sea-mammal hunters in the subarctic. They prospered along the Atlantic Coast of North America from about 7000\u00a0BC to 1500\u00a0BC. Their settlements included longhouses and boat-topped temporary or seasonal houses. They engaged in long-distance trade, using as currency white chert, a rock quarried from northern Labrador to Maine. The southern branch of these people was established on the north peninsula of Newfoundland by 5,000 years ago. The Maritime Archaic period is best known from a mortuary site in Newfoundland at Port au Choix.\nThe Maritime Archaic peoples were gradually displaced by people of the Dorset culture (Late Paleo-Eskimo) who also occupied Port au Choix. The number of their sites discovered on Newfoundland indicates they may have been the most numerous Aboriginal people to live there. They thrived from about 2000 BC to 800 AD. Many of their sites were on exposed headlands and outer islands. They were more oriented to the sea than earlier peoples, and had developed sleds and boats similar to kayaks. They burned seal blubber in soapstone lamps.\nMany of these sites, such as Port au Choix, recently excavated by Memorial archaeologist, Priscilla Renouf, are quite large and show evidence of a long-term commitment to place. Renouf has excavated huge amounts of harp seal bones at Port au Choix, indicating that this place was a prime location for the hunting of these animals.\nThe people of the Dorset culture (800 BC \u2013 1500 AD) were highly adapted to a cold climate, and much of their food came from hunting sea mammals through holes in the ice. The massive decline in sea ice during the Medieval Warm Period would have had a devastating effect upon their way of life.\nBeothuk settlement.\nThe appearance of the Beothuk culture is believed to be the most recent cultural manifestation of peoples who first migrated from Labrador to Newfoundland around 1 AD. The Inuit, found mostly in Labrador, are the descendants of what anthropologists call the Thule people, who emerged from western Alaska around 1000 AD and spread eastwards across the High Arctic tundra reaching Labrador around 1300\u20131500. Researchers believe the Dorset culture lacked the dogs, larger weapons and other technologies that gave the expanding Inuit an advantage.\nThe inhabitants eventually organized themselves into small bands of a few families, grouped into larger tribes and chieftainships. The Innu are the inhabitants of an area they refer to as \"Nitassinan\", i.e. most of what is now referred to as northeastern Quebec and Labrador. Their subsistence activities were historically centered on hunting and trapping caribou, deer and small game. Coastal clans also practiced agriculture, fished and managed maple sugar bush. The Innu engaged in tribal warfare along the coast of Labrador with Inuit groups that had large populations.\nThe Mi\ua78ckmaq of southern Newfoundland spent most of their time on the shores harvesting seafood; during the winter they would move inland to the woods to hunt. Over time, the Mi\ua78ckmaq and Innu divided their lands into traditional \"districts\". Each district was independently governed and had a district chief and a council. The council members were band chiefs, elders and other worthy community leaders. In addition to the district councils, the Mi\ua78ckmaq tribes also developed a Grand Council or \"Sant\u00e9 Mawi\u00f3mi\", which according to oral tradition was formed before 1600.\nEuropean contact.\nThe oldest confirmed accounts of European contact date from a thousand years ago as described in the Viking (Norse) Icelandic Sagas. Around the year 1001, the sagas refer to Leif Erikson landing in three places to the west, the first two being Helluland (possibly Baffin Island) and Markland (possibly Labrador). Leif's third landing was at a place he called Vinland (possibly Newfoundland). Archaeological evidence of a Norse settlement was found in L'Anse aux Meadows, Newfoundland, in the 1960s. It was declared a World Heritage Site by UNESCO in 1978.\nThere are several other unconfirmed accounts of European discovery and exploration, one tale of men from the Channel Islands being blown off course in the late 15th century into a strange land full of fish, and another from Portuguese maps that depict the Terra do Bacalhau, or land of codfish, west of the Azores. The earliest such account is the Voyage of Saint Brendan, the story of an Irish monk who made a sea voyage in the early 6th century.\nIn 1496, John Cabot obtained a charter from English King Henry VII to \"sail to all parts, countries and seas of the East, the West and of the North, under our banner and ensign and to set up our banner on any new-found-land\" and on June 24, 1497, landed in Cape Bonavista. Historians disagree on whether Cabot landed in Nova Scotia in 1497 or in Newfoundland, or possibly Maine, if he landed at all, but the governments of Canada and the United Kingdom recognise Bonavista as being Cabot's \"official\" landing place. In 1499 and 1500, Portuguese mariners Jo\u00e3o Fernandes Lavrador and Pero de Barcelos explored and mapped the coast, the former's name appearing as \"Labrador\" on topographical maps of the period.\nBased on the Treaty of Tordesillas, the Portuguese Crown claimed it had territorial rights in the area John Cabot visited in 1497 and 1498. Subsequently, in 1501 and 1502, the Corte-Real brothers, Miguel and Gaspar, explored Newfoundland and Labrador, claiming them as part of the Portuguese Empire. In 1506, king Manuel I of Portugal created taxes for the cod fisheries in Newfoundland waters. Jo\u00e3o \u00c1lvares Fagundes and Pero de Barcelos established seasonal fishing outposts in Newfoundland and Nova Scotia around 1521, and older Portuguese settlements may have existed. \nBy the time regular European contact with Newfoundland began in the early 16th century, the Beothuk were the only Indigenous group living permanently on the island. Unlike other groups in the Northeastern area of the Americas, the Beothuk never established sustained trading relations with European settlers. Their interactions were sporadic, and they largely attempted to avoid contact. The establishment of English fishing operations on the outer coastline of the island, and their later expansion into bays and inlets, cut off access for the Beothuk to their traditional sources of food.\nIn the 18th century, as the Beothuk were driven further inland by these encroachments, violence between Beothuk and settlers escalated, with each retaliating against the other in their competition for resources. By the early 19th century, violence, starvation, and exposure to tuberculosis had decimated the Beothuk population, and they were extinct by 1829.\nEuropean settlement and conflict.\nSometime before 1563, Basque fishermen, who had been fishing cod shoals off Newfoundland's coasts since the beginning of the sixteenth century, founded Plaisance (today Placentia), a seasonal haven which French fishermen later used. In the Newfoundland will of the Basque seaman Domingo de Luca, dated 1563 and now in an archive in Spain, he asks \"that my body be buried in this port of Plazen\u00e7ia in the place where those who die here are usually buried\". This will is the oldest-known civil document written in Canada.\nTwenty years later, in 1583, Newfoundland became England's first possession in North America and one of the earliest permanent English colonies in the New World when Sir Humphrey Gilbert, provided with letters patent from Queen Elizabeth I, landed in St. John's. European fishing boats had visited Newfoundland continuously since Cabot's second voyage in 1498 and seasonal fishing camps had existed for a century prior. Fishing boats originated from Basque country, England, France, and Portugal.\nIn 1585, during the initial stages of Anglo-Spanish War, Bernard Drake led a devastating raid on the Spanish and Portuguese fisheries. This provided an opportunity to secure the island and led to the appointment of Proprietary Governors to establish colonial settlements on the island from 1610 to 1728. John Guy became governor of the first settlement at Cuper's Cove. Other settlements included Bristol's Hope, Renews, New Cambriol, South Falkland and Avalon (which became a province in 1623). The first governor given jurisdiction over all of Newfoundland was Sir David Kirke in 1638.\nExplorers quickly realized the waters around Newfoundland had the best fishing in the North Atlantic. By 1620, 300 fishing boats worked the Grand Banks, employing some 10,000 sailors; many continuing to come from the Basque Country, Normandy, or Brittany. They dried and salted cod on the coast and sold it to Spain and Portugal. Heavy investment by Sir George Calvert, 1st Baron Baltimore, in the 1620s in wharves, warehouses, and fishing stations failed to pay off. French raids hurt the business, and the weather was terrible, so he redirected his attention to his other colony in Maryland. After Calvert left, small-scale entrepreneurs such as Sir David Kirke made good use of the facilities. Kirke became the first governor of Newfoundland in 1638.\nTriangular Trade.\nA triangular trade with New England, the West Indies, and Europe gave Newfoundland an important economic role. By the 1670s, there were 1,700 permanent residents and another 4,500 in the summer months.\nThis trade relied upon the labour of enslaved people of African descent. Salted cod from Newfoundland was used to feed the enslaved persons of African descent on plantations in the West Indies. Products typically associated with Newfoundland such as molasses and rum (Screech), were produced by the enslaved persons of African descent on plantations in the West Indies, and shipped to Newfoundland and England on merchant ships. Some merchants in Newfoundland enslaved persons of African descent such as St. John's merchant, Thomas Oxford. John Ryan, merchant and publisher of the Royal Gazette and Newfoundland Advertiser, who resided in New Brunswick and Newfoundland, freed his enslaved servant Dinah, upon his death in Newfoundland in 1847, notably after the Slavery Abolition Act in 1833.\nNotably, the Kirke brothers who were merchants in the triangular trade, brought Olivier Le Jeune to New France, where he was sold in 1629.\nIn 1655, France appointed a governor in Plaisance (Placentia), the former Basque fishing settlement, thus starting a formal French colonization period in Newfoundland as well as a period of periodic war and unrest between England and France in the region. The Mi\ua78ckmaq, as allies of the French, were amenable to limited French settlement in their midst and fought alongside them against the English. English attacks on Placentia provoked retaliation by New France explorer Pierre Le Moyne d'Iberville who during King William's War in the 1690s, destroyed nearly every English settlement on the island. The entire population of the English colony was either killed, captured for ransom, or sentenced to expulsion to England, with the exception of those who withstood the attack at Carbonear Island and those in the then remote Bonavista.\nAfter France lost political control of the area after the Siege of Port Royal in 1710, the Mi\ua78ckmaq engaged in warfare with the British throughout Dummer's War (1722\u20131725), King George's War (1744\u20131748), Father Le Loutre's War (1749\u20131755) and the French and Indian War (1754\u20131763). The French colonization period lasted until the Treaty of Utrecht of 1713, which ended the War of the Spanish Succession: France ceded to the British its claims to Newfoundland (including its claims to the shores of Hudson Bay) and to the French possessions in Acadia. Afterward, under the supervision of the last French governor, the French population of Plaisance moved to \u00cele Royale (now Cape Breton Island), part of Acadia which remained then under French control.\nIn the Treaty of Utrecht (1713), France had acknowledged British ownership of the island. However, in the Seven Years' War (1756\u20131763), control of Newfoundland once again became a major source of conflict between Britain, France and Spain, who all pressed for a share in the valuable fishery there. Britain's victories around the globe led William Pitt to insist nobody other than Britain should have access to Newfoundland. The Battle of Signal Hill was fought on September 15, 1762, and was the last battle of the North American theatre of the Seven Years' War. A British force under Lieutenant Colonel William Amherst recaptured St. John's, which the French had seized three months earlier in a surprise attack.\nFrom 1763 to 1767, James Cook made a detailed survey of the coasts of Newfoundland and southern Labrador while commander of . (The following year, 1768, Cook began his first circumnavigation of the world.) In 1796, a Franco-Spanish expedition again succeeded in raiding the coasts of Newfoundland and Labrador, destroying many of the settlements.\nBy the Treaty of Utrecht (1713), French fishermen gained the right to land and cure fish on the \"French Shore\" on the western coast. (They had a permanent base on the nearby St. Pierre and Miquelon islands; the French gave up their French Shore rights in 1904.) In 1783, the British signed the Treaty of Paris with the United States that gave American fishermen similar rights along the coast. These rights were reaffirmed by treaties in 1818, 1854 and 1871, and confirmed by arbitration in 1910.\nBritish colony.\nThe United Irish Conspiracy and Catholic Emancipation.\nThe founding proprietor of the Province of Avalon, George Calvert, 1st Baron Baltimore, intended that it should serve as a refuge for his persecuted Roman Catholic co-religionists. But like his other colony in the Province of Maryland on the American mainland, it soon passed out of the Calvert family's control. The majority Catholic population that developed, thanks to Irish immigration, in St. John's and the Avalon Peninsula, was subjected to the same disabilities that applied elsewhere under the British Crown. On visiting St. John's in 1786, Prince William Henry (the future King William IV) noted that \"there are ten Roman Catholics to one Protestant\", and he counselled against any measure of Catholic relief.\nFollowing news of rebellion in Ireland, in June 1798, Governor Vice-Admiral Waldegrave cautioned London that the English constituted but a \"small proportion\" of the locally raised Regiment of Foot. In an echo of an earlier Irish conspiracy during the French occupation of St. John's in 1762, in April 1800, the authorities had reports that upwards of 400 men had taken an oath as United Irishmen, and that eighty soldiers were committed to killing their officers and seizing their Anglican governors at Sunday service.\nThe abortive mutiny, for which eight men (denounced by Catholic Bishop James Louis O'Donel as \"favourers of the infidel French\") were hanged, may have been less a United Irish plot, than an act of desperation in the face of brutal living conditions and officer tyranny. Many of the Irish reserve soldiers were forced to remain on duty, unable to return to the fisheries that supported their families. Yet the Newfoundland Irish would have been aware of the agitation in the homeland for civil equality and political rights. There were reports of communication with United men in Ireland from before '98 rebellion; of Thomas Paine's pamphlets circulating in St. John's; and, despite the war with France, of hundreds of young County Waterford men still making a seasonal migration to the island for the fisheries, among them defeated rebels, said to have \"added fuel to the fire\" of local grievance.\nWhen news reached Newfoundland in May 1829 that the UK Parliament had finally conceded Catholic emancipation, the locals assumed that Catholics would now pass unhindered into the ranks of public office and enjoy equality with Protestants. There was a celebratory parade and mass in St. John's, and a gun salute from vessels in the harbour. But the attorney general and supreme court justices determined that as Newfoundland was a colony, and not a province of the United Kingdom, the Roman Catholic Relief Act did not apply. The discrimination was a matter of local ordinance.\nIt was not until May 1832 that the British Secretary of State for the Colonies formally stated that a new commission would be issued to Governor Cochrane to remove any and all Roman Catholic disabilities in Newfoundland. By then Catholic emancipation was bound up (as in Ireland) with the call for home rule.\nAchievement of home rule.\nAfter the end of the Napoleonic Wars in 1815, France and other nations re-entered the fish trade and an abundance of cod glutted international markets. Prices dropped, competition increased, and the colony's profits evaporated. A string of harsh winters between 1815 and 1817 made living conditions even more difficult, while fires at St. John's in 1817 left thousands homeless. At the same time a new wave of immigration from Ireland increased the Catholic population. In these circumstances much of the English and Protestant proprietor class tended to shelter behind the appointed, and Anglican, \"naval government\".\nA broad home-rule coalition of Irish community leaders and (Scottish and Welsh) Methodists formed in 1828. Expressing, initially, the concerns of a new middle class over taxation, it was led by William Carson, a Scottish physician, and Patrick Morris, an Irish merchant. In 1825, the British government granted Newfoundland and Labrador official colonial status and appointed Sir Thomas Cochrane as its first civil governor. Partly carried by the wave of reform in Britain, a colonial legislature in St. John's, together with the promise of Catholic emancipation, followed in 1832. Carson made his goal for Newfoundland clear: \"We shall rise into a national existence, having a national character, a nation's feelings, assuming that rank among our neighbours which the political situation and the extent of our island demand\".\nStanding as Liberals, the reformers sought to break the Anglican monopoly on government patronage and to tax the fisheries to fund the judiciary, road-building projects, and other expenses. They were opposed by the Conservatives (the \"Tories\"), who largely represented the Anglican establishment and mercantile interests. While Tories dominated the governor's appointed Executive Council, Liberals generally held the majority of seats in the elected House of Assembly.\nEconomic conditions remained harsh. As in Ireland, the potato which made possible a steady growth in population failed as a result of the \"Phytophthora infestans\" blight. The number of deaths from the 1846\u20131848 Newfoundland potato famine remains unknown, but there was pervasive hunger. Along with other half-hearted measures to relieve the distress, Governor John Gaspard Le Marchant declared a \"Day of Public Fasting and Humiliation\" in hopes the Almighty might pardon their sins and \"withdraw his afflicting hand.\" The wave of post-famine emigration from Ireland notably passed over Newfoundland.\nEra of responsible government.\nFisheries revived, and the devolution of responsibilities from London continued. In 1854, the British government established Newfoundland's first responsible government, an executive accountable to the colonial legislature. In 1855, with an Assembly majority, the Liberals under Philip Francis Little (the first Roman Catholic to practise law in St. John's) formed Newfoundland's first parliamentary government (1855\u20131858). Newfoundland rejected confederation with Canada in the 1869 general election. The Islanders were preoccupied with land issues\u2014the Escheat\u00a0movement with its call to suppress absentee landlordism in favour of the tenant farmer. Canada offered little in the way of solutions.\nFrom the 1880s, as cod fishery fell into severe decline, there was large-scale emigration. While some people, working abroad, left their homes on a seasonal or temporary basis more began to leave permanently. Most emigrants (largely Catholic and of Irish descent) moved to Canada, many to find work in the steel plants and coal mines of Nova Scotia. There was also a considerable outflow to the United States and, in particular, to New England.\nIn 1892, St. John's burned. The Great Fire left 12,000 homeless. In 1894, the two commercial banks in Newfoundland collapsed. These bankruptcies left a vacuum that was subsequently filled by Canadian chartered banks, a change that subordinated Newfoundland to Canadian monetary policies.\nNewfoundland lay outside the direct route of world traffic. St. John's, from Liverpool and about 1,000 miles from the east-coast American cities, was not a port of call for Atlantic liners. But with the co-ordination and extension of the railway system, new prospects for development opened in the interior. Paper and pulp mills were established by the Anglo-Newfoundland Development Co. at Grand Falls for the supply of the publishing empires in the UK of Lord Northcliffe and Lord Rothermere. Iron ore mines were established at Bell Island.\nBritish Dominion.\nReform and the Fisherman's Union.\nIn 1907, Newfoundland acquired dominion status, or self-government, within the British Empire or British Commonwealth. Government of Newfoundland was conducted mostly by a cabinet accountable solely to the legislature in St. John's, subject only to occasional policy changes from the British government, for example vetoing a trade agreement Newfoundland had negotiated with the United States. A new reform-minded government was formed under Edward Morris, a senior Catholic politician who had split from the Liberals to form the People's Party. It extended education provision, introduced old-age pensions, initiated agriculture and trade schemes and, with a trade union act, provided a legal framework for collective bargaining.\nThere had been unions seeking to negotiate wage rates in the shipbuilding trades since the 1850s. Those working the fishing boats were not wage earners but commodity producers, like farmers, reliant on merchant credit. Working in small, competitive, often family, units, scattered in isolated communities, they also had little occasion to gather in large numbers to discuss common concerns. These obstacles to organization were overcome from 1908 by a new co-operative movement, the Fishermen's Protective Union (FPU). Mobilizing more than 21,000 members in 206 councils across the island; more than half of Newfoundland's fishermen, the FPU challenged the economic control of the island's merchantocracy. Despite opposition from the Catholic Church which objected to the FPU's oath taking and alleged socialism, led by William Coaker the candidates for the FPU won 8 of 36 seats in the House of Assembly in the 1913 general election.\nAt the beginning of 1914, economic conditions seemed favourable to reform. In a little over a decade, exports, imports and state revenue had more than doubled. Schemes were afoot for the exploitation of coal and mineral resources, and for the utilisation of peat beds for fuel. Benefiting from the settlement of disputes over fishing rights with France in 1904, and with the New England states in 1910, the fishing industry was looking to develop new markets.\nFirst World War and its aftermath.\nIn August 1914, Britain declared war on Germany. Out of a total population of about 250,000, Newfoundland offered up some 12,000 men for Imperial service (including 3,000 who joined the Canadian Expeditionary Force). About a third of these were to serve in 1st Newfoundland Regiment, which after service in the Gallipoli Campaign, was nearly wiped out at Beaumont-Hamel on the first day on the Somme, July 1, 1916. The regiment, which the Dominion government had chosen to raise, equip, and train at its own expense, was resupplied and went on to serve with distinction in several subsequent battles, earning the prefix \"Royal\". The overall fatality and casualty rate for the regiment was high: 1,281 dead, 2,284 wounded.\nThe FPU members joined Edward Patrick Morris' wartime National Government of 1917, but their reputation suffered when they failed to abide by their promise not to support military conscription without a referendum. In 1919, the FPU joined with the Liberals to form the Liberal Reform Party whose success in the 1919 general election allowed Coaker to continue as Fisheries Minister. But there was little he could do to sustain the credibility of the FPU in the face of the post-war slump in fish prices, and the subsequent high unemployment and emigration. At the same time the Dominion's war debt due to the regiment and the cost of the trans-island railway, limited the government's ability to provide relief.\nIn the spring of 1918, in midst of disquiet over wartime inflation and profiteering, there had been protest. The Newfoundland Industrial Workers' Association (NIWA) struck both the rail and steamship operations of the Reid Newfoundland Company, effectively isolating the capital and threatening the annual seal hunt. Central to the eventual settlement were not only wage increases, but \"the great principle that employees are entitled to be heard in all matters connected with their welfare\".\nWhen in January 1919, Sinn F\u00e9in formed the D\u00e1il \u00c9ireann in Dublin, the Irish question and local sectarian tensions resurfaced in Newfoundland. In the course of 1920 many Catholics of Irish descent in St. John's joined the local branch of the Self-Determination for Ireland League (SDIL). Although tempered by expressions of loyalty to the Empire, the League's vocal support for Irish self-government was opposed by the local Orange Order. Claiming to represent 20,000 \"loyal citizens\", the Order was composed almost exclusively of Anglicans or Methodists of English descent. Tensions ran sufficiently high that Catholic Archbishop Edward Roche felt constrained to caution League organisers against the hazards of \"a sectarian war.\"\nSince the early 1800s, Newfoundland and Quebec (or Lower Canada) had been in a border dispute over the Labrador region. In 1927, the British Judicial Committee of the Privy Council ruled that the area known as modern-day Labrador was to be considered part of the Dominion of Newfoundland.\nCommission government.\nThe Great Depression and the return of colonial rule.\nFollowing the stock market crash in 1929, the international market for much of Newfoundland and Labrador's goods\u2014saltfish, pulp paper and minerals\u2014decreased dramatically. In 1930, the country earned $40 million from its exports; that number dropped to $23.3 million in 1933. The fishery suffered particularly heavy losses as salted cod that sold for $8.90 a quintal in 1929 fetched only half that amount by 1932. With this precipitous loss of export income, the level of debt Newfoundland carried from the Great War and from construction of the Newfoundland Railway proved unsustainable. In 1931, the Dominion defaulted. Newfoundland survived with assistance from the United Kingdom and Canada but, in the summer of 1933, faced with unprecedented economic problems at home, Canada decided against any further support.\nFollowing retrenchment in all the Dominion's major industries, the government laid off close to one third of its civil servants and cut the wages of those it retained. For the first time since the 1880s, malnutrition was facilitating the spread of beriberi, tuberculosis and other diseases.\nThe British had a stark choice: accept financial collapse in Newfoundland or pay the full cost of keeping the country solvent. The solution, accepted by the legislature in 1933, was to accept a de facto return to direct colonial rule. In exchange for loan guarantees by the Crown and a promise that self-government would in time be re-established, the legislature in St. John's voted itself out of existence. On February 16, 1934, the Commission of Government was sworn in, ending 79 years of responsible government. The Commission consisted of seven persons appointed by the British government. For 15 years, no elections took place, and no legislature was convened.\nBetween 1934 and 1939, the Commission of Government managed the situation but the underlying problem, world-wide depression, resisted solution. The dispirited state of the country is said to have been evident in \"'the lack of cheering and of visible enthusiasm' in the crowds that came out to see King George VI and Queen Elizabeth during their brief visit in June 1939.\"\nSecond World War.\nThe situation changed dramatically, after Newfoundland and Labrador, with no responsible government of its own, was automatically committed to war as a result of Britain's ultimatum to Germany in September 1939. Unlike in 1914\u20131918, when the Dominion government volunteered and financed a full expeditionary regiment, there would be no separate presence overseas and, by implication, no compulsory enlistment. Volunteers filled the ranks of Newfoundland units in both the Royal Artillery and the Royal Air Force, and of the largest single contingent of Newfoundlanders to go overseas, the Newfoundland Overseas Forestry Unit. As a result, and taking into account service in the Newfoundland Militia, and in the merchant marine, as in the First World War about 12,000 Newfoundlanders were at one time or another directly or indirectly involved in the war effort.\nIn June 1940, following the defeat of France and the German occupation of most of Western Europe, the Commission of Government, with British approval, authorized Canadian forces to help defend Newfoundland's air bases for the duration of the war. Canada's military commitment greatly increased in 1941 when German submarines began to attack the large numbers of merchant ships in the north-west Atlantic. In addition to reinforcing the bomber squadron at Gander, the Royal Canadian Air Force provided a further squadron of bombers that flew from a new airport Canada built at Torbay (the present St. John's airport). From November 1940, a new airbase at Gander became one of the so called \"sally-ports of freedom\" with U.S. manufactured aircraft flying in swarms to Britain.\nAlready, in March 1941, United Kingdom conceded the United States, then still officially neutral, what were effectively U.S. sovereign base rights. The Americans chose properties at St. John's, where they established an army base (Fort Pepperrell) and a dock facility; at Argentia/Marquise, where they built a naval air base and an army base (Fort McAndrew); and at Stephenville, where they built a large airfield (Ernest Harmon Airbase). As allies after December 1941, the Americans were also accommodated at Torbay, Goose Bay and Gander.\nThis garrisoning of Newfoundland had profound economic, political and social consequences. Enlistment for service abroad and the base building boom at home eliminated the chronic unemployment of the previous decades. By 1942, the country not only enjoyed full employment and could spend more on health, education and housing, it was making interest-free loans of Canadian dollars to the by-then hard-pressed British. At the same time, the presence of so many Canadians and Americans, complete with entertainment and consumer goods, promoted a taste for the more affluent consumerism that had been developing throughout North America.\nThe National Convention.\nWhen prosperity returned with the Second World War, agitation began to end the Commission and reinstate responsible government. Instead, the British government created the National Convention in 1946. Chaired by Judge Cyril J. Fox, the Convention consisted of 45 elected members from across the dominion and was formally tasked with advising on the future of Newfoundland.\nSeveral motions were made by Joey Smallwood \u2013 a convention member who later served as the first provincial premier of Newfoundland \u2013 to examine joining Canada by sending a delegation to Ottawa. The first motion was defeated, although the Convention later decided to send delegations to both London and Ottawa to explore alternatives. In January 1948, the National Convention voted against adding the issue of Confederation to the referendum 29 to 16, but the British, who controlled the National Convention and the subsequent referendum, overruled this move. Those who supported Confederation were extremely disappointed with the recommendations of the National Convention and organized a petition, signed by more than 50,000 Newfoundlanders, demanding that Confederation with Canada be placed before the people in the upcoming referendum. As most historians agree, the British government keenly wanted Confederation on the ballot and ensured its inclusion.\nCanadian province.\nThe referendums on confederation.\nThree main factions actively campaigned during the lead-up to the referendums on confederation with Canada:\nThe first referendum took place on June 3, 1948; 44.6 per cent of people voted for responsible government, 41.1 per cent voted for confederation with Canada, while 14.3 per cent voted for the Commission of Government. Since none of the choices had gained more than 50%, a second referendum with only the two more popular choices was held on July 22, 1948. The official outcome of that referendum was 52.3 per cent for confederation with Canada and 47.7 per cent for responsible (independent) government. After the referendum, the British governor named a seven-man delegation to negotiate Canada's offer on behalf of Newfoundland. After six of the delegation signed, the British government passed the British North America Act, 1949 through the Parliament of the United Kingdom. Newfoundland officially joined Canada at midnight on March 31, 1949.\nAs documents in British and Canadian archives became available in the 1980s, it became evident that both Canada and the United Kingdom had wanted Newfoundland to join Canada. Some have charged it was a conspiracy to manoeuvre Newfoundland into Confederation in exchange for forgiveness of Britain's war debt and for other considerations. Yet, most historians who have examined the relevant documents have concluded that, while Britain engineered the inclusion of a Confederation option in the referendum, Newfoundlanders made the final decision themselves, if by a narrow margin.\nFollowing the referendum, there was a rumour that the referendum had been narrowly won by the \"responsible government\" side, but that the result had been fixed by the British governor. Shortly after the referendum, several boxes of ballots from St. John's were burned by order of Herman William Quinton, one of only two commissioners who supported confederation. Some have argued that independent oversight of the vote tallying was lacking, though the process was supervised by respected Corner Brook Magistrate Nehemiah Short, who had also overseen elections to the National Convention.\n1959 Woodworkers' strike.\nIn 1959, a strike led by the International Woodworkers of America (IWA) that resulted the \"most bitter labour dispute in Newfoundland's history.\" Smallwood, although he had himself been an organizer in the lumber industry, feared that the strike would shut down what had become the province's largest employer. His government introduced emergency legislation that immediately decertified the IWA, prohibited secondary picketing, and made unions liable for illegal acts committed on their behalf.\nThe International Labour Organization, Canadian Labour Congress, and the Newfoundland Federation of Labour condemned the legislation, and Canadian Prime Minister John Diefenbaker refused to provide the province with additional police to enforce the legislation. But running out of food and money, the loggers eventually abandoned the strike, joined Smallwood's newly created Newfoundland Brotherhood of Wood Workers, and negotiated a settlement with the logging companies, ending the strike and effectively undermining the IWA.\nResettlement programs.\nFrom the early 1950s, the provincial government pursued a policy of population transfer by centralizing the rural population. A resettlement of the many isolated communities scattered along Newfoundland's coasts was seen as a way to save rural Newfoundland by moving people to what were referred to as \"growth centres\". It was believed this would allow the government to provide more and better public services such as education, health care, roads and electricity. The resettlement policy was also expected to create more employment opportunities outside of the fishery, or in spinoff industries, which meant a stronger and more modern fishing industry for those remaining in it.\nThree attempts of resettlement were initiated by the Government between 1954 and 1975 which resulted in the abandonment of 300 communities and nearly 30,000 people moved. Denounced as poorly resourced and as a historic injustice, resettlement has been viewed as possibly the most controversial government policy of the post-Confederation Newfoundland and Labrador.\nMany of the remaining small rural outports were hit by the 1992 cod moratorium. Loss of an important source of income caused widespread out-migration. In the 21st century, the Community Relocation Policy allows for voluntary relocation of isolated settlements. Eight communities have moved between 2002 and 2018. At the end of 2019, the decommissioning of ferry and hydroelectricity services ended settlement on the Little Bay Islands.\n21st century.\nClimate change.\nIn the new century, the provincial government is anticipating the challenges of global warming. Locally average annual temperatures are variously estimated to be already between 0.8\u00a0\u00b0C and 1.5\u00a0\u00b0C above historical norms and the frequency of hurricanes and tropical storms have doubled in comparison to the last century. As a result, the province is experiencing increased permafrost melt, flooding, and infrastructure damage, reduced sea ice, and greater risk from new invasive species and infectious diseases.\nThe government believes that in just fifty years (2000\u20132050), temperatures in Newfoundland will have risen by two and a half to three degrees in summer and three and a half to five degrees in winter, and that in Labrador warming will be even more severe. Under those conditions the winter season could shorten by as much as four to five weeks in some locations and that extreme storm events could result in an increase of precipitation by over 20% or more, enhancing the likelihood and magnitude of flooding. Meanwhile, sea levels are anticipated to rise by a half meter, putting coastal infrastructure at risk. Against these hazards, the government sets the province's \"vast renewable [wind, sea and hydro] energy resources\" with their potential to reduce carbon emissions in the province and elsewhere.\nIn April 2023, following years of delays and billions of dollars in cost overruns, a major hydro-generation project at Muskrat Falls, was declared complete with the final testing of the 1,100\u00a0km transmission link from the site in Labrador to a converter station outside St John's. Theoretically it could replace all the province's existing hydro-carbon sources of electricity. On the other hand, critics note that, in the decade to 2030, the government plans to double offshore oil production, significantly adding to emissions.\nOn January 17, 2020, the province experienced a large blizzard, nicknamed 'Snowmageddon', with winds up to . The communities of St. John's, Mount Pearl, Paradise, and Torbay declared a state of emergency. On January 18, 2020, Premier Dwight Ball said his request for aid from the Canadian Armed Forces was approved, and troops from the 2nd Battalion of the Royal Newfoundland Regiment, CFB Halifax, and CFB Gagetown would arrive in the province to assist with snow-clearing and emergency services. An avalanche hit a house in The Battery section of St. John's. St. John's mayor Danny Breen said the storm cost the city $7 million.\nThe COVID-19 pandemic.\nThe province announced its first presumptive case of COVID-19 on March 14, 2020, and declared a public health emergency on March 18. Health orders, including the closure of non-essential businesses and mandatory self-isolation for all travellers entering the province (including from within Canada), were enacted over the days that followed.\nThe emergency and all COVID-related restrictions ended in February 2022. There had been 18,464 recorded cases of persons testing positive for the virus, including 46 deaths.\nDemographics.\nPopulation.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nAs of October 1, 2021, Newfoundland and Labrador had a population of 521,758. More than half the population lives on the Avalon Peninsula of Newfoundland, site of the capital and historical early settlement. Since 2006, the population of the province has started to increase for the first time since the early 1990s. In the 2006 census, the population of the province decreased by 1.5% compared to 2001 and stood at 505,469. But, by the 2011 census, the population had risen by 1.8%.\nAt the beginning of 2021, Newfoundland and Labrador started accepting applications for a Priority Skills immigration program. Focusing on highly educated, highly skilled newcomers with specialized experience in areas where demand has outpaced local training and recruitment, such as technology and ocean sciences occupations, the government hopes the program will attract 2,500 new permanent residents annually.\nEthnicity.\nAccording to the 2001 Canadian census, the largest ethnic group in Newfoundland and Labrador is English (39.4%), followed by Irish (19.7%), Scots (6.0%), French (5.5%) and First Nations (3.2%). While half of all respondents also identified their ethnicity as \"Canadian\", 38 per cent report their ethnicity as \"Newfoundlander\" in a 2003 Statistics Canada Ethnic Diversity Survey.\nDuring the initial registration phase for the Qalipu Mi\ua78ckmaq First Nation Band in 2013, more than 100,000 Newfoundlanders applied for membership (equivalent to one-fifth of the total population). The subsequent process led to around 24,000 people being recognized as members of the Qalipu First Nation.\nLanguage.\nAs of the 2021 Canadian Census, the ten most spoken languages in the province included English (501,135 or 99.81%), French (26,130 or 5.2%), Arabic (2,195 or 0.44%), Spanish (2,085 or 0.42%), Innu (Montagnais) (1,925 or 0.38%), Tagalog (1,810 or 0.36%), Hindi (1,565 or 0.31%), Mandarin (1,170 or 0.23%), German (1,075 or 0.21%), and Punjabi (1,040 or 0.21%). The question on knowledge of languages allows for multiple responses.\nNewfoundland English is a term referring to any of several accents and dialects of the English language found in the province of Newfoundland and Labrador. Most of these differ substantially from the English commonly spoken elsewhere in neighbouring Canada and the North Atlantic. Many Newfoundland dialects are similar to the dialects of the West Country in England, particularly the city of Bristol and counties of Cornwall, Devon, Dorset, Hampshire and Somerset, while other Newfoundland dialects resemble those of Ireland's southeastern counties, particularly Waterford, Wexford, Kilkenny and Cork. Still others blend elements of both, and there is also a discernible influence of Scottish English. While the Scots came in smaller numbers than the English and Irish, they had a large influence on Newfoundland society.\nLocal place names in the Irish language include Newfoundland (\"Talamh an \u00c9isc\", \"Land of the Fish\") and St. John's (\"Baile She\u00e1in\") Ballyhack (\"Baile Hac\"), Cappahayden (\"Ceapach \u00c9id\u00edn\"), Kilbride and St. Bride's (\"Cill Bhr\u00edde\"), Duntara, Port Kirwan and Skibbereen (\"Scibir\u00edn\"). While the distinct local dialect of the Irish language in Newfoundland is now extinct, the language is still taught locally and the Gaelic revival organization remains active in the province. A distinct local dialect of Scots Gaelic was also once spoken in the Codroy Valley of Newfoundland, following the settlement there, from the middle of the 19th century, of Canadian Gaelic-speakers from Cape Breton, Nova Scotia. Some 150 years later, the language has not entirely disappeared, although it no longer has any fluent speakers. In Canadian Gaelic, the two main names for Newfoundland are \"Talamh an \u00c8isg\" and \"Eilein a' Trosg\".\nA community of Newfoundland French speakers still exists on the Port au Port Peninsula\u2014a remnant of the \"French Shore\" along the island's west coast.\nSeveral indigenous languages are spoken in the Province, representing the Algonquian (Mi\ua78ckmaq and Innu) and Eskimo-Aleut (Inuktitut) linguistic families.\nLanguages of the population \u2013 mother tongue (2011)\nReligion.\nAccording to the 2021 census, religious groups in Newfoundland and Labrador included:\nThe largest single religious denomination by number of adherents according to the 2011 National Household Survey was the Roman Catholic Church, at 35.8% of the province's population (181,590 members). The major Protestant denominations made up 57.3% of the population, with the largest groups being the Anglican Church of Canada at 25.1% of the total population (127,255 members), the United Church of Canada at 15.5% (78,380 members), and the Pentecostal churches at 6.5% (33,195 members), with other Protestant denominations in much smaller numbers. Non-Christians constituted only 6.8% of the population, with the majority of those respondents indicating \"no religious affiliation\" (6.2% of the population).\nThe Orange Order is a Protestant Christian fraternity, the lodge in Newfoundland is known as the Loyal Orange Lodge LOL #4 Municipal Heritage Building, it was built in 1907. The Heritage Foundation designated the Loyal Orange Association's Hall in Bonavista a Heritage Structure in May 1997. The lodge serves as a central hub for social life, particularly in rural outport communities. Members gather for meetings, dances, and social events. The Twelfth of July, also known as Orangemen's Day, is a provincial public holiday in Newfoundland and Labrador, and schools and most businesses are closed.\nEconomy.\nFor many years, Newfoundland and Labrador experienced a depressed economy. Following the collapse of the cod fishery during the early 1990s, the province suffered record unemployment rates and the population decreased by roughly 60,000. Due to a major energy and resources boom, the provincial economy has had a major turnaround since the turn of the 21st century. Unemployment rates decreased, the population stabilized and had moderate growth. The province has gained record surpluses, which has rid it of its status as a \"have not\" province.\nEconomic growth, gross domestic product (GDP), exports, and employment resumed in 2010, after suffering the effects of the late-2000s recession. In 2010, total capital investment in the province grew to C$6.2\u00a0billion, an increase of 23.0% compared to 2009. 2010 GDP reached $28.1\u00a0billion, compared to $25.0\u00a0billion in 2009.\nPrimary sector.\nOil production from offshore oil platforms on the Hibernia, White Rose and Terra Nova oil fields on the Grand Banks was of , which contributed to more than 15 per cent of the province's GDP in 2006. Total production from the Hibernia field from 1997 to 2006 was with an estimated value of $36\u00a0billion. This will increase with the inclusion of the latest project, Hebron. Remaining reserves are estimated at almost as of December 31, 2006. Exploration for new reserves is ongoing. On June 16, 2009, provincial premier Danny Williams announced a tentative agreement to expand the Hibernia oil field. The government negotiated a 10 per cent equity stake in the Hibernia South expansion, which will add an estimated $10\u00a0billion to Newfoundland and Labrador's treasury.\nThe mining sector in Labrador is still growing. The iron ore mine at Wabush/Labrador City, and the nickel mine in Voisey's Bay produced a total of $3.3\u00a0billion worth of ore in 2010. A mine at Duck Pond ( south of the now-closed mine at Buchans), started producing copper, zinc, silver and gold in 2007, and prospecting for new ore bodies continues. Mining accounted for 3.5% of the provincial GDP in 2006. The province produces 55% of Canada's total iron ore. Quarries producing dimension stone such as slate and granite, account for less than $10\u00a0million worth of material per year.\nThe fishing industry remains an important part of the provincial economy, employing roughly 20,000 and contributing over $440\u00a0million to the GDP. The combined harvest of fish such as cod, haddock, halibut, herring and mackerel was 92,961 tonnes in 2017, with a combined value of $141 million. Shellfish, such as crab, shrimp and clams, accounted for 101,922 tonnes in the same year, yielding $634 million. The value of products from the seal hunt was $1.9 million. In 2015, aquaculture produced over 22,000 tonnes of Atlantic salmon, mussels and steelhead trout worth over $161 million. Oyster production is also forthcoming.\nAgriculture in Newfoundland is limited to areas south of St. John's, Cormack, Wooddale, areas near Musgravetown and in the Codroy Valley. Potatoes, rutabagas, turnips, carrots and cabbage are grown for local consumption. Poultry, eggs, and dairy are also produced. Wild blueberries, partridgeberries (lingonberries) and bakeapples (cloudberries) are harvested commercially and used in jams and wine making.\nSecondary sector.\nNewsprint is produced by one paper mill in Corner Brook with a capacity of per year. The value of newsprint exports varies greatly from year to year, depending on the global market price. Lumber is produced by numerous mills in Newfoundland. Apart from seafood processing, paper manufacture and oil refining, manufacturing in the province consists of smaller industries producing food, brewing and other beverage production.\nTertiary sector.\nService industries accounted for the largest share of GDP, especially financial services, health care and public administration. Other significant industries are mining, oil production and manufacturing. The total labour force in 2018 was 261,400 people. Per capita GDP in 2017 was $62,573, higher than the national average and third only to Alberta and Saskatchewan out of Canadian provinces.\nTourism is also a significant contributor to the province's economy. In 2006, nearly 500,000 non-resident tourists visited Newfoundland and Labrador, spending an estimated $366\u00a0million. In 2017, non-resident tourists spent an estimated $575\u00a0million. Tourism is most popular throughout the months of June\u2013September, the warmest months of the year with the longest hours of daylight.\nGovernment and politics.\nNewfoundland and Labrador is governed by a parliamentary government within the construct of constitutional monarchy; the monarchy in Newfoundland and Labrador is the foundation of the executive, legislative, and judicial branches. The sovereign is King Charles III, who also serves as head of state of 14 other Commonwealth countries, each of Canada's nine other provinces and the Canadian federal realm; he resides in the United Kingdom. The King's representative in Newfoundland and Labrador is the Lieutenant Governor of Newfoundland and Labrador, presently Joan Marie Aylward.\nThe direct participation of the royal and viceroyal figures in governance is limited; in practice, their use of the executive powers is directed by the Executive Council, a committee of ministers of the Crown responsible to the unicameral, elected House of Assembly. The Council is chosen and headed by the Premier of Newfoundland and Labrador, the head of government. After each general election, the lieutenant governor will usually appoint as premier the leader of the political party that has a majority or plurality in the House of Assembly. The leader of the party with the second-most seats usually becomes the Leader of His Majesty's Loyal Opposition and is part of an adversarial parliamentary system intended to keep the government in check.\nEach of the 40 Members of the House of Assembly (MHA) is elected by simple plurality in an electoral district. General elections must be called by the lieutenant governor on the second Tuesday in October four years after the previous election, or may be called earlier, on the advice of the premier, should the government lose a confidence vote in the legislature. Traditionally, politics in the province have been dominated by both the Liberal Party and the Progressive Conservative Party. However, in the 2011 provincial election the New Democratic Party, which had only ever attained minor success, had a major breakthrough and placed second in the popular vote behind the Progressive Conservatives.\nCulture.\nArt.\nBefore 1950, the visual arts were a minor aspect of Newfoundland cultural life, compared with the performing arts such as music or theatre. Until about 1900, most art was the work of visiting artists, who included members of the Group of Seven, Rockwell Kent and Eliot O'Hara. Artists such as Newfoundland-born Maurice Cullen and Robert Pilot travelled to Europe to study art in prominent ateliers.\nBy the turn of the 20th century, amateur art was made by people living and working in the province. These artists included J.W. Hayward and his son Thomas B. Hayward, Agnes Marian Ayre, and Harold B. Goodridge, the last of whom worked on a number of mural commissions, notably one for the lobby of the Confederation Building in St. John's. Local art societies became prominent in the 1940s, particularly The Art Students Club, which opened in 1940.\nAfter Newfoundland and Labrador joined Canada in 1949, government grants fostered a supportive environment for visual artists, primarily painters. The visual arts of the province developed significantly in the second half of the century, with the return of young Newfoundland artists whom had studied abroad. Amongst the first were Rae Perlin, who studied at the Art Students League in New York, and Helen Parsons Shepherd and her husband Reginald Shepherd, who both graduated from the Ontario College of Art. The Shepherds established the province's first art school, the Newfoundland Academy of Art.\nNewfoundland-born painters Christopher Pratt and Mary Pratt returned to the province in 1961 to work at the newly established Memorial University Art Gallery as its first curator, later transitioning to painting full-time in Salmonier. David Blackwood graduated from the Ontario College of Art in the early 1960s and achieved acclaim with his images of Newfoundland culture and history. Newfoundland-born artist Gerald Squires returned in 1969.\nThe creation of The Memorial University Extension Services and St. Michael's Printshop in the 1960s and 1970s attracted a number of visual artists to the province to teach and create art. Similarly, the school in Hibb's Hole (now Hibb's Cove), established by painter George Noseworthy, brought professional artists such as Anne Meredith Barry to the province. A notable artist during this period is Marlene Creates.\nFrom 1980 to present, opportunities for artists continued to develop, as galleries such as the Art Gallery of Newfoundland and Labrador (which later became The Rooms Provincial Art Gallery), the Resource Centre for the Arts, and Eastern Edge were established. Fine arts education programs were established at post-secondary institutions such as Sir Wilfred Grenfell College in Corner Brook, the Western Community College (now College of the North Atlantic) in Stephenville, and the Anna Templeton Centre in St. John's.\nNewfoundland and Labrador's arts community is recognized nationally and internationally. The creation of Fogo Island Arts in 2008 on Fogo Island created a residency-based contemporary art program for artists, filmmakers, writers, musicians, curators, designers, and thinkers. In 2013 and 2015, the province was represented at the Venice Biennale as Official Collateral Projects. In 2015, Philippa Jones became the first Newfoundland and Labrador artist to be included in the National Gallery of Canada contemporary art biennial. Other notable contemporary artists who have received national and international attention include Will Gill, Kym Greeley, Ned Pratt and Peter Wilkins.\nAs of 2011, a study documented approximately 1,200 artists, representing 0.47% of the province's labour force.\nMusic.\nNewfoundland and Labrador has a folk musical heritage based on the Irish, English and Scottish traditions that were brought to its shores centuries ago. Though similar in its Celtic influence to neighbouring Nova Scotia and Prince Edward Island, Newfoundland and Labrador are more Irish than Scottish, and have more elements imported from English and French music than those provinces. Much of the region's music focuses on the strong seafaring tradition in the area, and includes sea shanties and other sailing songs. Some modern traditional musicians include Great Big Sea, The Ennis Sisters, The Dardanelles, Ron Hynes and Jim Payne.\nThe Newfoundland Symphony Orchestra began in St. John's in 1962 as a 20-piece string orchestra known as the St. John's Orchestra. A school of music at Memorial University schedules a variety of concerts and has a chamber orchestra and jazz band. Two members of its faculty, Nancy Dahn on violin and Timothy Steeves on piano, perform as Duo Concertante and are responsible for establishing an annual music festival in August, the Tuckamore Festival. Both the school of music and Opera on the Avalon produce operatic works. A leading institution for research in ethnomusicology, Memorial's Research Centre for the Study of Music, Media, and Place, offers academic lectures, scholarly residencies, conferences, symposia, and outreach activities to the province on music and culture.\nThe pre-confederation and current provincial anthem is the \"Ode to Newfoundland\", written by British colonial governor Sir Charles Cavendish Boyle in 1902. It was adopted as the official Newfoundland anthem on May 20, 1904. In 1980, the province re-adopted the song as an official provincial anthem. \"The Ode to Newfoundland\" is still sung at public events in Newfoundland and Labrador.\nLiterature.\nMargaret Duley (1894\u20131968) was Newfoundland's first novelist to gain an international audience. Her works include \"The Eyes of the Gull\" (1936), \"Cold Pastoral\" (1939) and \"Highway to Valour\" (1941). Other writers who wrote major works in the 20th century include Harold Horwood, author of \"Tomorrow Will Be Sunday\" (1966) and \"White Eskimo\" (1972); Percy Janes, author of \"House of Hate\" (1970); M. T. Dohaney, author of \"The Corrigan Women\" (1988); and Bernice Morgan, author of \"Random Passage\" (1992).\nIn the late 20th and early 21st century, a new generation of writers came to prominence. Michael Crummey's novel, \"River Thieves\" (2001), was a Canadian bestseller and his 2023 novel \"The Adversary\" won the International Dublin Literary Award. Wayne Johnston's fiction deals primarily with the province of Newfoundland and Labrador, often in a historical setting; His novels include \"The Story of Bobby O'Malley\", \"The Time of Their Lives\", \"The Divine Ryans\", and \"The Colony of Unrequited Dreams\", a historical portrayal of Newfoundland politician Joey Smallwood. Lisa Moore's first novel, \"Alligator\" (2005), is set in St. John's and incorporates her Newfoundland heritage. Others include Joel Thomas Hynes, author of \"We'll All Be Burnt in Our Beds Some Night\" (2017); Jessica Grant, author of \"Come Thou Tortoise\" (2009); Kenneth J. Harvey, author of \"The Town That Forgot How to Breathe\" (2003) and \"Blackstrap Hawco\" (2008); and Megan Gail Coles, author of \"Small Game Hunting at the Local Coward Gun Club\" (2019).\nThe earliest works of poetry in British North America, mainly written by visitors and targeted at a European audience, described the new territories in optimistic terms. One of the first works was Robert Hayman's \"Quodlibets\", a collection of verses composed in Newfoundland and published in 1628.\nIn the oral tradition of County Waterford, the Munster Irish poet Donnchadh Ruadh Mac Conmara, a former hedge school teacher, is said to have sailed for Newfoundland around 1743, allegedly to escape the wrath of a man whose daughter the poet had impregnated. During the 21st century, however, linguists discovered that several of Donnchadh Ruadh's poems in the Irish language contain multiple Gaelicized words and terms known to be unique to Newfoundland English. For this reason, Donnchadh Ruadh's poems are considered the earliest literature in the Irish language in Newfoundland.\nAfter the Second World War, Newfoundland poet E. J. Pratt described the struggle to make a living from the sea in poems about maritime life and the history of Canada, including in his 1923 \"breakthrough collection\" \"Newfoundland Verse\". Amongst more recent poets are Tom Dawe, Al Pittman, Mary Dalton, Agnes Walsh, Patrick Warner and John Steffler. Canadian poet Don McKay has resided in St. John's in recent years.\nIn 1967 the St. John's Arts and Culture Centre was opened along with the first all-Canadian Dominion Drama Festival: \nPlaywrights across Canada began writing, and this explosion was also felt in Newfoundland and Labrador. Subregional festivals saw Newfoundland plays compete\u2014\"Wreakers\" by Cassie Brown, \"Tomorrow Will Be Sunday\" by Tom Cahill, and \"Holdin' Ground\" by Ted Russell. Cahill's play went on to receive top honours and a performance at Expo 67 in Montreal. Joining Brown and Cahill in the seventies were Michael Cook and Al Pittman, both prolific writers.\nPerforming arts.\nRossleys, a \"vaudeville-style performance troupe\", put on blackface minstrelsy shows which were a popular source of entertainment in Newfoundland between 1911 and 1917. Modern theatre companies include the New Curtain Theatre Company in Clarenville and the New World Theatre Project in Cupids. Shakespeare by the Sea presents outdoor productions of the plays of William Shakespeare, as well as pieces related to the province and culture.\nDance in Newfoundland and Labrador comprises dances that are specific to the province, including performance and traditional, and Indigenous dance. The Kittiwake Dance Theatre, founded in 1987, is the oldest non-profit dance company in Newfoundland.\nOther.\nGeorge Street in St. John's is the location of an annual Mardi Gras celebration in October, but the largest celebration held there is the six-night George Street Festival in early August. The festival is rumoured to be the largest of its kind in North America with over 120,000 people making their way through the two block street during the six-day period.\nSymbols.\nNewfoundland and Labrador's present provincial flag, designed by Newfoundland artist Christopher Pratt, was officially adopted by the legislature on May 28, 1980, and first flown on \"Discovery Day\" that year. The blue is meant to represent the sea, the white represents snow and ice, the red represents the efforts and struggles of the people, and the gold represents the confidence of Newfoundlanders and Labradorians. The blue triangles are a tribute to the Union Flag, and represent the British heritage of the province. The two red triangles represent Labrador (the mainland portion of the province) and the island. In Pratt's words, the golden arrow points towards a \"brighter future\".\nWhat has commonly but mistakenly been called the Newfoundland tricolour \"Pink, White and Green\"(sic) is the flag of the Catholic Church affiliated Star of the Sea Association (SOSA). It originated in the late nineteenth century and enjoyed popularity among people who were under the impression that it was the Native Flag of Newfoundland which was created before 1852 by the Newfoundland Natives' Society. The true Native Flag (red-white-green tricolour) was widely flown into the late nineteenth century. Neither tricolour was ever adopted by the Newfoundland government. The \"Pink, White and Green\"(sic) has been adopted by some residents as a symbol of ties with Irish heritage and as a political statement. Many of the province's Protestants, who make up nearly 60% of the province's total population, may not identify with this heritage. At the same time, many of the province's Catholics, approximately 37% of the total population (with at least 22% of the population claiming Irish ancestry), think the current provincial flag does not satisfactorily represent them. But, a government-sponsored poll in 2005 revealed that 75% of Newfoundlanders rejected adoption of the Tricolour flag as the province's official flag.\nLabrador has its own unofficial flag, created in 1973 by Mike Martin, former Member of the Legislative Assembly for Labrador South.\nOn Newfoundland, as of 2024[ [update]] moose have become an increasingly adopted symbol of the island.\nSports.\nNewfoundland and Labrador has a somewhat different sports culture from the rest of Canada, owing in part to its long history separate from the rest of Canada and under British rule. Ice hockey, however, remains popular; though operations ceased in April 2024, a minor league professional team called the Newfoundland Growlers of the ECHL played at Mary Brown's Centre (formerly Mile One Centre) in St. John's from the 2018\u201319 to 2023\u201324 seasons. The area had an intermittent American Hockey League presence with the St. John's Maple Leafs then St. John's IceCaps until 2017, and the Newfoundland Senior Hockey League had teams around the island. After the departure of the St. John's Fog Devils in 2008, Newfoundland and Labrador has been the only province in Canada to not have a team in the major junior Canadian Hockey League. However, this is set to change in 2025, with the Acadie\u2013Bathurst Titan scheduled to relocate to St. John's to become Newfoundland Regiment in the QMJHL.\nHurling and other Gaelic games have a very long history in the Province and continue to be played.\nAssociation football (soccer) and rugby union are both more popular in Newfoundland and Labrador than the rest of Canada in general. Soccer is hosted at King George V Park, a 6,000-seat stadium built as Newfoundland's national stadium during the time as an independent dominion. Swilers Rugby Park is home of the Swilers RFC rugby union club, as well as the Atlantic Rock, one of the four regional teams in the Canadian Rugby Championship. Other sports facilities in Newfoundland and Labrador include Pepsi Centre, an indoor arena in Corner Brook; and St. Patrick's Park, a baseball park in St. John's.\nGridiron football, be it either American or Canadian, is almost non-existent; it is the only Canadian province other than Prince Edward Island to have never hosted a Canadian Football League or Canadian Interuniversity Sport game, and it was not until 2013 the province saw its first amateur teams form.\nCricket was once a popular sport. The earliest mention is in the \"Newfoundland Mercantile Journal\", Thursday September 16, 1824, indicating the St. John's Cricket Club was an established club at this time. The St. John's Cricket club was one of the first cricket clubs in North America. Other centres were at Harbour Grace, Twillingate and Trinity. The heyday of the game was the late nineteenth and early twentieth century, at which time there was league in St. John's, as well as an interschool tournament. John Shannon Munn is Newfoundland's most famous cricketer, having represented Oxford University. After the first World War, cricket declined in popularity and was replaced by soccer and baseball. However, with the arrival of immigrants from the Indian subcontinent, cricket is once again gaining interest in the province.\nIn 2024 Newfoundland and Labrador became the shirt sponsors of Barrow A.F.C., an association football (soccer) team located in North West England.\nTransportation.\nFerries.\nWithin the province, the Newfoundland and Labrador Department of Transportation and Works operates or sponsors 15 automobile, passenger and freight ferry routes which connect various communities along the province's significant coastline.\nA regular passenger and car ferry service, lasting about 90 minutes, crosses the Strait of Belle Isle, connecting the province's island of Newfoundland with the region of Labrador on the mainland. The ferry MV Qajaq W travels from St. Barbe, Newfoundland, on the Great Northern Peninsula, to the port town of Blanc-Sablon, Quebec, located on the provincial border and beside the town of L'Anse-au-Clair, Labrador. The MV \"Sir Robert Bond\" once provided seasonal ferry service between Lewisporte on the island and the towns of Cartwright and Happy Valley-Goose Bay in Labrador, but has not run since the completion of the Trans-Labrador Highway in 2010, allowing access from Blanc-Sablon, Quebec, to major parts of Labrador. Several smaller ferries connect numerous other coastal towns and offshore island communities around the island of Newfoundland and up the Labrador coast as far north as Nain. There are also two ferries, MV Legionnaire and MV Flanders, that operate between Bell Island and Portugal Cove\u2013St. Philips yearly, mainly used by those commuting to St. John's for work. The MV Veteran, a sister ship of MV Legionnaire, operates between Fogo Island, Change Islands, and Farewell.\nInter-provincial ferry services are provided by Marine Atlantic, a federal Crown corporation which operates auto-passenger ferries from North Sydney, Nova Scotia, to the towns of Port aux Basques and Argentia on the southern coast of Newfoundland island.\nAviation.\nThe St. John's International Airport (YYT) and the Gander International Airport (YQX) are the only airports in the province that are part of the National Airports System. The St. John's International Airport handles nearly 1.2 million passengers a year making it the busiest airport in the province and the fourteenth busiest airport in Canada. YYT airport underwent a major expansion of the terminal building which was completed in 2021. The Deer Lake Airport (YDF) handles over 300,000 passengers a year.\nRailway.\nThe Newfoundland Railway operated on the island of Newfoundland from 1898 to 1988. With a total track length of , it was the longest narrow-gauge railway system in North America. The railway ended on June 20, 1988, in the rails for roads deal.\nTshiuetin Rail Transportation operates passenger rail service on its Sept-\u00celes, Quebec, to Schefferville, Quebec route, passing through Labrador and stopping in several towns.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "21981", "revid": "42412221", "url": "https://en.wikipedia.org/wiki?curid=21981", "title": "New Oxford American Dictionary", "text": "Collection of American English words and their meanings\nThe New Oxford American Dictionary (NOAD) is a single-volume dictionary of American English compiled by American editors at the Oxford University Press.\n\"NOAD\" is based upon the \"New Oxford Dictionary of English\" (\"NODE\"), published in the United Kingdom in 1998, although with substantial editing, additional entries, and the inclusion of illustrations. It is based on a corpus linguistics analysis of Oxford's 200 million word database of contemporary American English.\n\"NOAD\" includes a diacritical respelling scheme to convey pronunciations, as opposed to the Gimson phonemic IPA system that is used in \"NODE\".\nEditions.\nFirst edition.\nPublished in September 2001, the first edition was edited by Elizabeth J. Jewell and Frank Abate.\nSecond edition.\nPublished in May 2005, the second edition was edited by Erin McKean. The edition added nearly 3,000 new words, senses, and phrases. It was in a large format, with 2096 pages, and was 8\u00bd\" by 11\" in size. It included a CD-ROM with the full text of the dictionary for Palm OS devices.\nSince 2005 Apple Inc.'s Mac OS X operating system has come bundled with a dictionary application and widget which credits as its source \"Oxford American Dictionaries\", and contains the full text of \"NOAD2\". The Amazon Kindle reading device also uses \"NOAD\" as its built-in dictionary, along with a choice for the \"Oxford Dictionary of English\".\nOxford University Press published \"NOAD2\" in electronic form in 2006 at the OxfordAmericanDictionary.com, and in 2010, along with the \"Oxford Dictionary of English\", as part of Oxford Dictionaries Online.\nThird edition.\nPublished in August 2010, the third edition was edited by Angus Stevenson and Christine A. Lindberg. This edition includes over 2,000 new words, senses, and phrases, and over 1,000(1225) illustrations; hundreds of new and revised explanatory notes, new \"Word Trends\" feature charts usage for rapidly changing words and phrases.\nFictitious entry.\nThe dictionary includes an entry for the word \"esquivalience\", which it defines as meaning \"the willful avoidance of one's official responsibilities\". This is a fictitious entry, intended to protect the copyright of the publication. The entry was invented by Christine Lindberg, one of the editors of the \"NOAD\".\nWith the publication of the second edition, a rumor circulated that the dictionary contained a fictitious entry in the letter 'e'. \"New Yorker\" contributing editor Henry Alford combed the section, and discussed several unusual entries he found with a group of American lexicographers. Most found \"esquivalience\" to be the most likely candidate, and when Alford approached \"NOAD\" editor in chief Erin McKean she confirmed it was a fake entry, which had been present since the first edition, in order to protect the copyright of the CD-ROM edition. Of the word, she said \"its inherent fakeitude is fairly obvious\".\nThe fake entry apparently ensnared Dictionary.com, which included an entry for it (that has since been removed) which it attributed to \"Webster's New Millennium Dictionary\", both of which are owned by the private company Lexico. Possibly due to its licensing of Oxford dictionaries, Google Dictionary included the word, listing three meanings and giving usage examples."}
{"id": "21983", "revid": "40153758", "url": "https://en.wikipedia.org/wiki?curid=21983", "title": "Neo-Latin", "text": "Form of the Latin language used from the 14th century to present\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nNeo-Latin (also known as New Latin and Modern Latin) is the style of written Latin used in original literary, scholarly, and scientific works, first in Italy during the Italian Renaissance of the fourteenth and fifteenth centuries, and then across northern Europe after about 1500, as a key feature of the humanist movement. Through comparison with Latin of the Classical period, scholars from Petrarch onwards promoted a standard of Latin closer to that of the ancient Romans, especially in grammar, style, and spelling. The term \"Neo-Latin\" was however coined much later, probably in Germany in the late eighteenth century, as \"Neulatein\", spreading to French and other languages in the nineteenth century. Medieval Latin had diverged quite substantially from the classical standard and saw notable regional variation and influence from vernacular languages. Neo-Latin attempts to return to the ideal of Golden Latinity in line with the Humanist slogan .\nThe new style of Latin was adopted throughout Europe, first through the spread of urban education in Italy, and then the rise of the printing press and of early modern schooling. Latin was learnt as a spoken language as well as written, as the vehicle of schooling and University education, while vernacular languages were still infrequently used in such settings. As such, Latin dominated early publishing, and made up a significant portion of printed works until the early nineteenth century.\nIn Neo-Latin's most productive phase, it dominated science, philosophy, law, and theology, and it was important for history, literature, plays, and poetry. Classical styles of writing, including approaches to rhetoric, poetical metres, and theatrical structures, were revived and applied to contemporary subject matter. It was a pan-European language for the dissemination of knowledge and communication between people with different vernaculars in the Republic of Letters . Even as Latin receded in importance after 1650, it remained vital for international communication of works, many of which were popularised in Latin translation, rather than as vernacular originals. This in large part explains the continued use of Latin in Scandinavian countries and Russia \u2013 places that had never belonged to the Roman Empire \u2013 to disseminate knowledge until the early nineteenth century.\nNeo-Latin includes extensive new word formation. Modern scholarly and technical nomenclature, such as in zoological and botanical taxonomy and international scientific vocabulary, draws extensively from this newly minted vocabulary, often in the form of classical or neoclassical compounds. Large parts of this new Latin vocabulary have seeped into English, French and several Germanic languages, particularly through Neo-Latin.\nIn the eighteenth century, Latin was increasingly being learnt as a written and read language, with less emphasis on oral fluency. While it still dominated education, its position alongside Greek was increasingly attacked and began to erode. In the nineteenth century, education in Latin (and Greek) focused increasingly on reading and grammar, and mutated into the 'classics' as a topic, although it often still dominated the school curriculum, especially for students aiming for entry to university. Learning moved gradually away from poetry composition and other written skills; as a language, its use was increasingly passive outside of classical commentaries and other specialised texts.\nLatin remained in active use in eastern Europe and Scandinavia for a longer period. In Poland, it was used as a vehicle of local government. This extended to those parts of Poland absorbed by Germany. Latin was used as a common tongue between parts of the Austrian Empire, particularly Hungary and Croatia, at least until the 1820s. Croatia maintained a Latin poetry tradition through the nineteenth century. Latin also remained the language of the Catholic Church and of oral debate at a high level in international conferences until the mid twentieth century.\nOver time, and especially in its later phases after its practical value had severely declined, education that included strong emphasis on Latin and Greek became associated with elitism and as a deliberate class barrier for entry to educational institutions.\nPost-classical Latin, including medieval, Renaissance and Neo-Latin, makes up the vast majority of extant Latin output, estimated as well over 99.99% of the totality. Given the size of output and importance of Latin, the lack of attention to it is surprising to many scholars. The trend is a long one, however, dating back to the late eighteenth and nineteenth centuries, as Neo-Latin texts became looked down on as non-classical. Reasons could include the rising belief during this period in the superiority of vernacular literatures, and the idea that only writing in one's first language could produce genuinely creative output, found in nationalism and Romanticism. More recently, the lack of trained Latinists has added to the barriers.\nMore academic attention has been given to Neo-Latin studies since 1970, and the role and influence of Latin output in this period has begun to be reassessed. Rather than being an adjunct to Classical Latin forms, or an isolated, derivative and now largely irrelevant cultural output, Neo-Latin literature is seen as a vital context for understanding the vernacular cultures in the periods when Latin was in widespread productive use. Additionally, Classical reception studies have begun to assess the differing ways that Classical culture was understood in different nations and times.\nExtent and characteristics.\nTime period.\nClassicists use the term \"Neo-Latin\" to describe the Latin that developed in Renaissance Italy as a result of renewed interest in classical civilization in the 14th and 15th centuries. Scientific nomenclatures sometimes prefer the term \"New Latin\", to show where their terms were coined in the same period.\nNeo-Latin describes the use of the Latin language for any purpose, scientific or literary, during and after the Renaissance. The beginning of the period cannot be precisely identified. The spread of secular education, the acceptance of humanistic literary norms, and the wide availability of Latin texts following the invention of printing, mark the transition to a new era of scholarship at the end of the 15th century, but there was no simple, decisive break with medieval traditions. Rather, there was a process of change in education, a choice of literary and stylistic models, and a move away from medieval techniques of language formation and argumentation.\nThe end of the Neo-Latin period is likewise indeterminate, but Latin as a regular vehicle of communicating ideas became rare following the dissolution of the Holy Roman Empire and after the Congress of Vienna, where French replaced Latin as the language of diplomacy. By 1900, Latin survived primarily in international scientific vocabulary and taxonomy, or more actively, in the upper echelons of the Catholic Church. The term \"Neo-Latin\" came into use during the 1800s among linguists and scientists.\nNeo-Latin can be said to be the current style of Latin writing, but different periods in its evolution can be seen. Neo-Latin writings were seen as less relevant and deserving of less attention than Classical Latin during the 1800s, as Classical models were asserted as the prime focus for study. Productive use of Latin for most purposes ended in the early 1800s.\nCharacter of Neo-Latin writing.\nWhile Latin remained an actively used language, the process of emulating Classical models did not become complete. For instance, Catholic traditions preserved some features of medieval Latin, given the continued influence of some aspects of medieval theology. In secular texts, such as scientific, legal and philosophical works, neologisms continued to be needed, so while Neo-Latin authors might choose new formulations, they might also continue to use customary medieval forms, but in either case, could not aim for a purified Classical Latin vocabulary. Recent study tends to identify a style of Latin that was closer to Classical Latin in grammar, sometimes influenced by vernaculars in syntax especially in more everyday writing, but eclectic in choice of vocabulary and generation of new words.\nSome authors including C. S. Lewis have criticised the Neo-Latin and classicising nature of humanistic Latin teaching for creating a dynamic for purification and ossification of Latin, and thus its decline from a more productive medieval background. Modern Neo-Latin scholars tend to reject this, as for instance word formation and even medieval uses continued; but some see a kernel of truth, in that the standards of Latin were set very high, making it hard to achieve the necessary confidence to use Latin. In any case, other factors are certainly at play, particularly the widening of education and its needs to address many more practical areas of knowledge, many of which were being written about for national audiences in the vernacular.\nCorpus.\nThe exact size of the Neo-Latin corpus is currently incalculable, but dwarfs that of Latin in all other periods combined. Material includes personal, unpublished, bureaucratic, educational, and academic output such as notes and theses. Given the extent of potential records, even regarding printed works, there is extensive basic work to be done in cataloguing what is available, as well as in digitisation and translation of important works.\nGeographical spread.\nNeo-Latin was, at least in its early days, an international language used throughout Catholic and Protestant Europe, as well as in the colonies of the major European powers. This area consisted of most of Europe, including Central Europe and Scandinavia; its southern border was the Mediterranean Sea, with the division more or less corresponding to the modern eastern borders of Finland, the Baltic states, Poland, Slovakia, Hungary and Croatia.\nRussia's acquisition of Kyiv in the later 17th century introduced the study of Latin to Russia. Russia relied on Latin for some time as a vehicle to exchange scientific knowledge. Nevertheless, the use of Latin in Orthodox eastern Europe did not reach pervasive levels due to their strong cultural links to the cultural heritage of Ancient Greece and Byzantium, as well as Greek and Old Church Slavonic languages.\nLatin was taught extensively in the US, during the colonial period on the European model of Latin medium education, but was among the first to allow this monopoly to recede. Both Latin and the Classics were very influential nevertheless, and supported an active Latin literature, especially in poetry.\nLatin played a strong role in education and writing in early colonial Mexico, Brazil and in other parts of Catholic Americas. Catholicism also brought Latin to India, China and Japan.\nHistory.\nBeginnings.\n Neo-Latin began in Italy with the rise of Renaissance Latin and humanist reform of Latin education, then brought to prominence in northern Europe by writers such as Erasmus, More, and Colet.\nMedieval Latin had been the practical working language of the Roman Catholic Church, and was taught throughout Europe to clerics through the medieval university system. It was a flexible language, with many neologisms. Changes in grammatical practices regarding syntax and other elements such as conjunctions had become established.\nThe Renaissance reinforced the position of Latin as a spoken and written language by the scholarship by the Renaissance Humanists. Although scholarship initially focused on Ancient Greek texts, Petrarch and others began to change their understanding of good style and their own usage of Latin as they explored the texts of the Classical Latin world. Skills of textual criticism evolved to create much more accurate versions of extant texts through the fifteenth and sixteenth centuries, and some important texts were rediscovered. Comprehensive versions of author's works were published by Isaac Casaubon, Joseph Scaliger and others. Nevertheless, despite the careful work of Petrarch, Politian and others, first the demand for manuscripts, and then the rush to bring works into print, led to the circulation of inaccurate copies for several centuries following.\nAs the humanist reformers sought both to purify Latin grammar and style, and to make Latin applicable to concerns beyond the ecclesiastical, they began to create a body of Latin literature outside the bounds of the Church. Nevertheless, studies and criticism of Biblical translations were a particular and important focus of early Humanism, in Italy and beyond.\nProminent Neo-Latin writers who were admired for their style in this early period included Pontano, Petrarch, Salutati, Bruni, Ficino, Pico della Mirandola in Italy; the Spaniard Juan Luis Vives; and in northern Europe, the German Celtis.\nIn the late 1400s, some schools in the Low Countries were using the new Italian standards of Latin. Erasmus and other pupils promoted the new learning and Latin standards. The Low Countries established itself as a leading centre of humanism and Neo-Latin; Rotterdam and Leuven were especially well known for these intellectual currents.\nNeo-Latin developed in advance of and in parallel with vernacular languages, but not necessarily in direct competition with them. Frequently the same people were codifying and promoting both Latin and vernacular languages, in a wider post-medieval process of linguistic standardisation. However, Latin was the first language that was available, fully formed, widely taught and used internationally across a wide variety of subjects. As such, it can be seen as the first \"modern European language\".\nIt should also be noted that for Italian reformers of written Latin, there was no clear divide between Italian and Latin; the latter was seen by Petrarch for example as an artificial and literary version of the spoken language. While Italian in this period also begins to be used as a separate written language, it was not always seen as wholly separate from Latin.\nHeight: 1500\u20131700.\nThe Protestant Reformation (1520\u20131580), though it removed Latin from the liturgies of the churches of Northern Europe, promoted the reform of the new secular Latin teaching.\nThe heyday of Neo-Latin was 1500\u20131700, when in the continuation of the Medieval Latin tradition, it served as the lingua franca of science, medicine, legal discourse, theology, education, and to some degree diplomacy in Europe. This coincided with the growth of printed literature; Latin dominated early publishing. Classic works such as Thomas More's were published. Other prominent writers of this period include Dutchmen Grotius and Secundus and Scotsman George Buchanan. Women, while rarely published, also wrote and composed poetry in Latin, Elizabeth Jane Weston being the most well known example.\nLatin in school education, 1500\u20131700.\nThroughout this period, Latin was a universal school subject, and indeed, the pre-eminent subject for elementary education in most of Europe and other places of the world that shared its culture. Schools were variously known as grammar schools in Britain, Latin schools in France, Germany, the Netherlands and colonial North America, and also Gymnasia in Germany and many other countries.\nLatin was frequently the normal medium of education, both for teaching the Latin language, and for other subjects. Fluency in spoken Latin was an objective as well as the ability to read and write; evidence of this includes the emphasis on use of diacritics to maintain understanding of vowel quantity, which is important orally, and also on the use of for children's learning, which would help to equip the learner with spoken vocabulary for common topics, such as play and games, home work and describing travel. In short, Latin was taught as a \"completely normal language\", to be used as any other. Colloquia would also contain moral education. At a higher level, Erasmus' Colloquia helped equip Latin speakers with urbane and polite phraseology, and means of discussing more philosophical topics.\n Changes to Latin teaching varied by region. In Italy, with more urbanised schools and Universities, and wider curricula aimed at professions rather than just theology, Latin teaching evolved more gradually, and earlier, in order to speed up the learning of Latin. For instance, initial learning of grammar in a basic Latin word order followed the practice of medieval schools. In both medieval and Renaissance schools, practice in Latin written skills would then extend to prose style composition, as part of 'rhetoric'. In Italy, for prose for instance, a pupil would typically be asked to convert a passage in to , that is from a natural to stylised word order. Unlike medieval schools, however, Italian Renaissance methods focused on Classical models of Latin prose style, reviving texts from that period, such as Cicero's \"De Inventione\" or Quintilian's .\nTeaching of specific, gradually harder Latin authors and texts followed rhetorical practice and learning. In Italy, during the medieval period, at different periods, Classical and Christian authors competed for attention, but the Renaissance and Neo-Latin period saw a decisive move back to authors from the Classical period, and away from non-Classical 'minor' authors such as Boethius, whose language was simpler.\n The changes to schooling in Northern Europe were more profound, as methods had not evolved as quickly. Adopting Italian innovations, changes to the teaching of grammar and rhetoric were promoted by reformers including Calvin, Melanchthon and Luther. Protestants needed Latin to promote and disseminate their ideas, so were heavily involved with the reform of Latin teaching. Among the most influential of these reformers was Calvin's Latin teacher and educational collaborator Corderius, whose bilingual colloquies were aimed at helping French-speaking children learn to speak Latin.\nAmong Latin schools, the rapid growth of Jesuit schools made them known for their dedication to high attainment in written and spoken Latin to educate future priests. This took place after the Catholic church affirmed their commitment to Latin in the liturgy and as a working language within the hierarchy at the Council of Trent in 1545\u201363. Jesuit schools were particularly well known for their production of Latin plays, exclusive use of spoken Latin and emphasis on classical written style.\nHowever, the standards ultimately achieved by the whole school system were uneven. Not all students would acquire Latin to a high standard. Even in this period, an excessive focus on grammar and poor teaching methods were seen by reformers as a barrier to the acquisition of Latin. Comenius for instance was credited with significant attempts to make Latin more accessible through use of parallel Latin and native language texts, and more interesting through acquisition of vocabulary and the use of modern and more relevant information in texts. Others worried whether it was appropriate to put so much emphasis on abstract language skills such as Latin poetry composition. As time went on, the difficulties with Latin teaching began to lead to calls to move away from an emphasis on spoken Latin and the introduction of more native-language-medium teaching.\nLatin in university education.\n At the beginning of the Renaissance, universities in northern Europe were still dominated by theology and related topics, while Italian universities were teaching a broader range of courses relating to urban professions such as law and medicine. All universities required Latin proficiency, obtained in local grammar schools, to obtain admittance as a student. Throughout the period, Latin was the dominant language of university education, where rules were enforced against the use of vernacular languages. Lectures and debates took place in Latin, and writing was in Latin, across the curriculum.\nMany universities hosted newly or recently-written Latin plays, which formed a significant body of literature before 1650. Plays included satires on student life, such as the play \"Studentes\" (Students), which went through many reprints.\nEnforcement of Latin-only rules tended to decline especially after 1650.\nLatin in academia, law, science and medicine.\nLatin dominated topics of international academic and scientific interest, especially at the level of abstract thought addressed to other specialists. To begin with, knowledge was already transmitted through Latin and it maintained specialised vocabularies not found in vernacular languages. This did not preclude scientific writings also existing in vernaculars; for example Galileo, some of whose scientific writings were in Latin, while others were in Italian, the latter less academic and intended to reach a wider audience using the same ideas with more practical applications.\nOver time, the use of Latin continued where international communication with specialist audiences was paramount. Later, where some of the discourse moved to French, English or German, translations into Latin would allow texts to cross language boundaries, while authors in countries with much smaller language populations or less known languages would tend to continue to compose in Latin.\nLatin was of course the major language of Christian theology. Both Catholic and Protestant writers published in Latin. While Protestant writers would also write in vernaculars, Latin was important for the international dissemination of ideas.\nLegal discourse, medicine, philosophy and sciences started from a strong Latin tradition, and continued as such. This began to change in the late seventeenth century, as philosophers and others began to write in their native language first, and translate into Latin for international audiences. Translations would tend to prioritise accuracy over style.\nLatin and religious usage.\n The Catholic Church made exclusive use of Latin in the liturgy, resisting attempts even in the New World and China to diverge from it. As noted above, Jesuit schools fuelled a high standard of Latinity, and this was also supported by the growth of seminaries, as part of the Counter Reformation's attempts to revitalise Catholic institutions.\nWhile in Protestant areas Latin was pushed out of the Church, this did not make Protestants hostile to Latin in education or universities. In fact, Latin remained a kind of bridge of communication across religious as well as linguistic divides in the .\nOne exception to the general rule of vernacular services in Protestant countries can be observed in the Anglican Church, where with the publication of the \"Book of Common Prayer\" of 1559, a Latin edition was published in 1560 for use in universities such as Oxford and the leading grammar and \"public schools\" (in the period, English schools established with charitable structures open to the general public; now a kind of private academy), where the liturgy was still permitted to be conducted in Latin.\nLatin as a literary vehicle.\nIn this period, it was common for poets and authors to write in Latin, either in place of or in addition to their native language. Latin was a language for \"high art\" in an \"eternal language\", that authors supposed might outlast contemporary vernacular writings. It allowed for an international readership that shared the same Classical and recent Latin cultural reference points.\nThe literature did not stand apart from vernaculars, as naturally allusions and the same reference points could flow across language boundaries. However, these dynamics have become less well understood, as academics and other readers are not as familiar with the Latin works of the period, sometimes resulting in simplistic notions of competition and replacement of Latin over time. The actual processes were more complicated and are now a focus of Neo-Latin studies. For instance, stylistic borrowings flowed from Latin to the Dutch vernacular, where models were lacking in the latter.\nOutputs included novels, poems, plays and occasional pieces, stretching across genres analogous to those found in vernacular writings of the period, such as tragedy, comedy, satire, history and political advice. Epistolary (letter) writing containing poems and prose, designed for publication rather than purely receipt, had Classical antecedents and often contained strong elements of self-promotion.\nSome of these genres are harder for modern readers to evaluate; for instance many poems were written for specific occasions, such as appointments or institutional events. To modern audiences, such poetry appears contrived at its inception, so it is easy for the reader to assume a lack of pathos or skill.\nAt the time that many of these works were written, writers viewed their Latin output as perhaps we do high art; a particularly refined and lofty activity, for the most educated audiences. Moreover, there was a hope of greater, international recognition, and that the works written in the \"Eternal language\" of Latin would outlast writings in the vernacular.\nSome very influential works written in Latin are not always commonly remembered, despite their ground-breaking nature. For example, \"Argenis\", by John Barclay was perhaps the first modern historical novel, and was popular across Europe.\nOpinions vary about the achievements of this literary movement, and also the extent to which it reached its goal of being \"classical\" in style. Modern critics sometimes claim that the output of Neo-Latinists was largely derivative and imitative of Classical authors. Latin authors themselves could recognise the dangers of imitation caused by the long training they were given in ingesting compositional techniques of Classical writers, and could struggle against it. From another perspective, the \"learned artifice\" of Neo-Latin writing styles requires that we understand that \"one of the most fundamental aspects of this artifice is imitation\". Different approaches to imitation can be discerned, from attempting to adopt the style and manner of a specific author, especially of Cicero, through to syntheses of Latin from good authors, as suggested by Angelo Poliziano, taking elements from a range, to provide what Tunberg calls an \"eclectic\" style that was \"new from the perspective of the whole creation\". The use of Latin exclusively as used by Cicero was heavily satirised by Erasmus who proposed a more flexible approach to Latin as a medium.\nOther critics have claimed that the expressive abilities of writers could not truly reach the same heights as in their native language; such concerns were sometimes expressed by contemporaries especially as time went on and vernaculars became more established. On the other hand, this criticism at the very least ignores the early age and intensity with which Latin was acquired.\nStandards of written Latin.\nNot all Latin aspired to be high literature, and whether it did or not, standards varied. Standards were most classical and writing more fluid in France and Italy. In England, among typically unpublished scholarly works such as dissertations through the sixteenth century, written Latin improved in morphological accuracy, but sentence construction and idiom often reflected the vernacular. Similar patterns have been found in Sweden, where academic Latin tended to be very accurate in terms of morphology, but less Classical in its sentence patterns. In vocabulary and spelling, usage tend to be quite eclectic, using medieval forms and re-using Classical terms with modern meanings. In any case, it was accepted that technical terms would require neologisms.\nThere are occasional differences between Classical and Neo-Latin, which can sometimes be assumed to be mistakes of the authors. However, careful analysis of available grammars often shows these differences to be based on the understanding of the grammar rules at the time. For instance, many grammarians believed that \"all\" names of rivers were masculine, even those ending in \"-a\".\nAdditionally, Neo-Latin authors tended to form new unattested words, such as or , by using Classical rules. Helander says:\nApparently the authors did not care whether these words existed in the preserved Latin literature, as long as they were regularly formed. As a rule, their judgement was very sound, and in most cases we will not as readers realize that we are dealing with neologisms ... A large number of them were probably on the lips of the ancient Romans, although they have not survived in the texts preserved to us. One might wonder whether we are right in calling such words \"neologisms\".\nThe words used derived from a wider set of authors than just the \"classical\" period, especially among authors aiming at a higher level of style. Similarly, some Classical words which were uncommonly used were in much greater currency, such as (glory).\nThe Latin used in scientific publications can be perceived as tending towards a simpler modern idiom, perhaps following the language patters of the writers' native language. Often it served a clear, less literary purpose, however, of providing an accurate international Latin text or translation.\nLatin as a spoken language.\n As a learnt language, levels of fluency would have varied. Discussions in specialised topics between specialists, or between educated people from different native language backgrounds would be preferred. Even among highly proficient Latin writers, sometimes spoken skills could be much lower, reflecting reticence for making mistakes in public, or simple lack of oral practice.\nAs noted below, an important feature of Latin in this period was that pronunciation tended to national or even local practice. This could make especially initial spoken communication difficult between Latinists from different backgrounds, English and French pronunciation being notably odd. In terms of status, the Italian pronunciation tended to have higher status and acceptability.\nFrom some time in the seventeenth century, Latin oral skills began to decline. Complaints about standards of oral Latin can be increasingly found from this time onwards.\nLatin as an official and diplomatic language.\n Official and diplomatic settings are specific cases where the use of oral and conversational Latin would have taken place, in legal settings, in Parliaments, or between negotiators. The use of Latin would extend of course also to set speeches and texts such as treaties, but would also be the medium in which details would be discussed and problems resolved.\nLatin was an official language of Poland, recognised and widely used. Between the 9th and 18th centuries, commonly used in foreign relations and popular as a second language among some of the nobility.\nThrough most of the 17th century, Latin was also supreme as an international language of diplomatic correspondence, used in negotiations between nations and the writing of treaties, e.g. the peace treaties of Osnabr\u00fcck and M\u00fcnster (1648). As an auxiliary language to the local vernaculars, Latin appeared in a wide variety of documents. The need to read such documents continued to be important for diplomats.\nThe use of Latin in diplomatic contexts was especially important for smaller nations which maintained Latin for a variety of international purposes, who therefore pressed for it even as French established itself as a more common medium for diplomacy.\nEighteenth century decline.\nAs languages like French, Italian, German, and English became more widely known, the use of an auxiliary language seemed less necessary. With greater readerships, many fields of literature became more national, and as vernaculars became better known, translation across language boundaries became more practical. In short, the utility of Latin in many areas decreased, and with it the output. Nevertheless, Latin continued to be important through the 1700s, especially in higher education, where it remained the dominant language of lectures. In particular fields, such as medicine, biology, law, and theology, Latin retained its grip more fully and for longer, and in some countries, particularly in Scandinavia and eastern Europe, Latin played a stronger role due to the small size of language communities or the need to work across such boundaries with a neutral, mutually acceptable medium.\nIn school education, Latin came under increasing attack as pupils needed time to study other more practical subjects, but it was not displaced from its dominant position, especially as a skill needed for university entry. Increasingly, even as Latin's relevance and pupils' attainment in it diminished, the language became associated with class boundaries, as a passport to a certain kind of education and social cachet, which were denied to those who were unable to dedicate the time to studying it.\nLatin in school education in the 1700s.\nIt became a widespread view in the 1700s that Latin and Ancient Greek lacked utility for all but a small minority. The use of Latin in education began to come under serious attack, as the need for education widened, while the relevance of Latin had diminished. However, these changes met resistance.\nIn the American colonies, calls for more practical education began to grow in the 1750s. In Poland, attempts to roll back the place of Latin were made in 1774, to make it a subject and to give up spoken Latin, but hit resistance and were withdrawn in 1778, when Latin was restored as a spoken medium. Attempts to introduce Italian and reduce Latin teaching in Piedmont in the 1790s also met with problems, not least due to the divergence between the local dialect and standard Italian; the changes were withdrawn, and children continued to learn and read and write in Latin before other languages.\nIn France, under the , teaching remained largely focused on Latin until the Revolution. Although some moves were made to teach Latin grammar in French, and to learn to read and write in French first, these tended to be limited to urban centres and state-founded colleges such as those in Paris. Children learnt to read and write in Latin before French in most of the countryside until the 1790s. Use of spoken Latin in schools, however, reduced through the century, particularly from the 1750s. Gradually Latin in schools moved from a language taught for usage and production to written comprehension.\nLatin in university education in the 1700s.\n At the academy, however, Latin retained its grip. At the Sorbonne, for instance, Latin remained the dominant language of tuition, with nearly all courses being delivered and examined in Latin. At Oxford, Latin-only rules remained in force, but there is clear evidence of a decline in spoken Latin standards, and it was no longer expected outside of classes. Elsewhere, courses in technical subjects tended to move towards the vernacular, while some were delivered in both Latin and vernaculars. Courses using Italian become more common from the 1750s, in subjects such as commerce and mathematics. In any case, even when courses were delivered in vernaculars, formal occasions such as inaugural lectures and ceremonies often remained in Latin.\nSciences and Academia.\nIn the early part of the 1700s, Latin was still making a significant contribution to academic publishing, but was no longer dominant. For example, over 50% of the works published in Oxford between 1690 and 1710 were in Latin, and 31% of the total publications mentioned in the French between 1728 and 1740.\nRegional and subject differences counted for a lot in the choice of language and audience. An example of the transition towards the vernacular in England can be seen in Newton's writing career, which began in Neo-Latin and ended in English (e.g. \"Opticks\", 1704). By contrast, while German philosopher Christian Wolff (1679\u20131754) popularized German as a language of scholarly instruction and research, and wrote some works in German, he continued to write primarily in Latin, so that his works could more easily reach an international audience (e.g., \"Philosophia moralis,\" 1750\u20131753).\nAround 20% of academic periodicals were in Latin. Latin was particularly well-used in the German-speaking world, where the vernacular was not as well established. Erudition, theology, science and medicine were topics that were often addressed in Latin, such as by the long-running medical journal printed from 1670 until 1791. Some periodicals were general in nature, such as the , from Prague, launched in 1744.\nLiterature and poetry.\nAs the 18th century progressed, the extensive literature in Latin being produced at the beginning slowly contracted. Latin literature tended to be produced in countries where the vernaculars were by themselves still likely to attract small readerships. Some well known, influential and popular Latin books were produced, for instance , a fantastical allegory in 1741.\nSpoken Latin in the 1700s.\nAs late as the 1720s, Latin was still used conversationally, and was serviceable as an international auxiliary language between people of different countries who had no other language in common. For instance, the Hanoverian king George I of Great Britain (reigned 1714\u20131727), who had no command of spoken English, communicated in Latin with his Prime Minister Robert Walpole.\nThere is also no shortage of recorded complaints about poor standards of spoken Latin in universities and similar settings. While there is also praise, it is clear that oral skills were in decline. In academia, lectures began to include a vernacular summary at the end. In some contexts, such as Poland, it was simply accepted that oral Latin did not need to be perfected as a working administrative language. In other contexts, it led to pressure for the oral use of Latin to be abandoned.\nLatin shifted towards increasingly being a written rather than spoken language. Evidence for this includes changes in the use of diacritics in texts, which ceased to be used.\nDiplomacy and official status.\n In the early 18th century, French replaced Latin as the dominant diplomatic language, due to the commanding presence in Europe of the France of Louis XIV. However, Latin continued to be preferred by some smaller nations such as Denmark and Sweden for some time.\nSome of the last major international treaties to be written in Latin include the Treaty of Vienna in 1738 and the Treaty of Belgrade in 1739; after the War of the Austrian Succession (1740\u201348) international diplomacy was conducted predominantly in French. Some more minor trade treaties were written in Latin in 1737 and 1756 between Denmark and the Sublime Porte.\nLatin retained a significant role in diplomatic correspondence beyond these dates. The Papacy, Holy Roman Empire, Sweden continued to prefer Latin for communications through the century. In any case, due to the need to consult prior historic agreements, Latin remained an important skill for diplomats and was provided for in their training.\nPrussia found Latin indispensable as late as 1798, for practical reasons in administering partitioned Poland from the 1770s onwards, where Latin remained the main administrative language. In central Europe, Latin retained an official status in Hungary and Croatia, as a neutral language.\nNineteenth century.\nBy 1800, Latin publications were far outnumbered, and often outclassed, by writings in the modern languages. Latin literature lasted longest in very specific fields (e.g. botany and zoology) where it had acquired a technical character, and where a literature available only to a small number of learned individuals could remain viable. By the end of the 19th century, Latin in some instances functioned less as a language than as a code capable of concise and exact expression, as for instance in physicians' prescriptions, or in a botanist's description of a specimen. In other fields (e.g. anatomy or law) where Latin had been widely used, it survived in technical phrases and terminology. The perpetuation of Ecclesiastical Latin in the Catholic Church through the 20th century can be considered a special case of the technicalizing of Latin, and the narrowing of its use to an elite class of readers.\nLatin and Classical education.\nDespite the trends in the 1700s towards lessening emphasis on Latin, study of the language alongside Greek was given a significant boost after 1800 through a revival of humanist education, especially for elite education in France, Germany, England and elsewhere.\nIn this model, Latin suffered in status against Ancient Greek, which was seen as the better aesthetic example, but both languages were deemed necessary for a \"Classical education\". Latin was still generally a requirement for University education. Composition skills were still needed for submission of theses, for instance, in the early part of the century.\nIn England, study of the Classics became more intense at institutions like Eton, or Charterhouse. In grammar schools, however, study of Latin had declined, stopped or become tokenistic in the majority of cases at the point of the Taunton Commission's enquiry in 1864, a situation which it helped to reverse in the coming decades.\nThe renewed emphasis on the study of Classical Latin as the spoken language of the Romans of the 1st centuries BC and AD, was similar to that of the Humanists but based on broader linguistic, historical, and critical studies of Latin literature. It led to the exclusion of Neo-Latin literature from academic studies in schools and universities (except for advanced historical language studies); to the abandonment of Neo-Latin neologisms; and to an increasing interest in the reconstructed Classical pronunciation, which displaced the several regional pronunciations in Europe in the early 20th century.\nCoincident with these changes in Latin instruction, and to some degree motivating them, came a concern about lack of Latin proficiency among students. Latin had already lost its privileged role as the core subject of elementary instruction; and as education spread to the middle and lower classes, it tended to be dropped altogether.\nLatin and the Classics were under pressure from the need for much broader, general education for the wider population. It was clearly not useful or appropriate for everyone to attain high levels of Latin or Greek. Nevertheless, as a requirement for University entry, it formed a barrier to access against people from less privileged backgrounds; this was even seen as good thing. In this way, education in Latin became increasingly associated with a kind of elitism, associated with the education of English \"gentlemen\" or the French bourgeoisie, and forming a common bond of references within these social classes.\nLatin and linguistics.\nAs academic study of languages in Germany and elsewhere intensified, so did knowledge of Latin. This manifested itself in the proposal for restoring Classical pronunciation, but also in further refining knowledge of vowel quantity, use of grammatical constructions and the meaning of particular words. Study of non-standard Latin began. Overall, this intensified the purification, standardisation and academisation of Latin. In education, this led to an increasingly grammar based approach to learning in many countries, reinforcing its reputation for being difficult and abstruse.\nUses of Latin in the late 1800s.\nBy 1900, creative Latin composition in many countries, for purely artistic purposes, had become rare. Authors such as Arthur Rimbaud and Max Beerbohm wrote Latin verse, but these texts were either school exercises or occasional pieces. However, the tradition was still strong enough in Holland, Croatia, Italy and elsewhere to sustain an annual Latin poetry competition, the , until 1978.\nClassicists themselves were the last redoubt for use of Latin in an academic context. Textual commentaries to Latin texts could be made in Latin, for instance. Academic papers in Classics journals could sometimes be published in Latin.\nSome of the last survivals of Neo-Latin to convey information appear in the use of Latin to cloak passages and expressions deemed too indecent to be read by children, the lower classes, or (most) women. Such passages appear in translations of foreign texts and in works on folklore, anthropology, and psychology. An example of this can be found in Krafft-Ebing's (1886).\nOfficial uses of Latin.\nA special case was the use of Latin in Hungary and Croatia, where it remained a language of government in the first half of the century. Papers were published in Latin in Hungary, and it was used as the language of Parliamentary debate. This was in large part a compromise between Hungarians and Croats, to both avoid the imposition of German, or their own languages, on each other. The legacy of the political situation meant that a strong Latin tradition continued in Croatia for some time afterwards, where Latin poetry continued to be produced for the remainder of the century.\nThe abolition of the Holy Roman Empire ended its use of Latin as an official language. Sweden continued to use Latin for diplomatic correspondence in the nineteenth century, as did the Vatican.\nLatin from 1900 onwards.\nLatin as a language held a place of educational pre-eminence until the second half of the 19th century in the English speaking world. At that point its value was increasingly questioned. In the 20th century, educational philosophies such as that of John Dewey, although not categorically opposed to the teaching of Latin, questioned the usefulness of \"drilling\" syntactical and grammatical structures\u2014especially when this happened in isolation from cultural and historical insight. At the same time, the philological study of Latin appeared to show that the traditional methods and materials for teaching Latin were dangerously out of date and ineffective.\nAcademic works in classical studies are still written in Latin. Such works, eg the prefaces for critical editions of ancient texts published by Teubner or Oxford Classical Texts, are however intended for international academic audiences speaking varied vernaculars who are already familiar with the language.\nRelics.\nEcclesiastical Latin, the form of Neo-Latin used in the Catholic Church, remained in use throughout the period and after. Until the Second Vatican Council of 1962\u20131965 all priests were expected to have competency in it, and it was studied in Catholic schools. It is today still the official language of the Church, and all Catholic priests of the Latin liturgical rites are required by canon law to have competency in the language.\nNeo-Latin is also the source of the biological system of binomial nomenclature and classification of living organisms devised by Carl Linnaeus, although the rules of the ICZN allow the construction of names that deviate considerably from historical norms. (See also classical compounds.) Another continuation is the use of Latin names for the surface features of planets and planetary satellites (planetary nomenclature), originated in the mid-17th century for selenographic toponyms. Neo-Latin has also contributed a vocabulary for specialized fields such as anatomy and law; some of these words have become part of the normal, non-technical vocabulary of various European languages.\nPronunciation.\nNeo-Latin had no single pronunciation, but a host of local variants or dialects, all distinct both from each other and from the historical pronunciation of Latin at the time of the Roman Republic and Roman Empire. As a rule, the local pronunciation of Latin used sounds identical to those of the dominant local language, the result of a concurrently evolving pronunciation in the living languages and the corresponding spoken dialects of Latin. Despite this variation, there are some common characteristics to nearly all of the dialects of Neo-Latin, for instance:\nThe regional dialects of Neo-Latin can be grouped into families, according to the extent to which they share common traits of pronunciation. The major division is between Western and Eastern family of Neo-Latin. The Western family includes most Romance-speaking regions (France, Spain, Portugal, Italy) and the British Isles; the Eastern family includes Central Europe (Germany and Poland), Eastern Europe (Russia and Ukraine) and Scandinavia (Denmark, Sweden).\nThe Western family is characterized, , by having a front variant of the letter \"g\" before the vowels \"\u00e6, e, i, \u0153, y\" and also pronouncing \"j\" in the same way (except in Italy). In the Eastern Latin family, \"j\" is always pronounced , and \"g\" had the same sound (usually ) in front of both front and back vowels; exceptions developed later in some Scandinavian countries.\nThe following table illustrates some of the variation of Neo-Latin consonants found in various countries of Europe, compared to the Classical Latin pronunciation of the 1st centuries BC to AD. In Eastern Europe, the pronunciation of Latin was generally similar to that shown in the table below for German, but usually with for \"z\" instead of .\nOrthography.\nNeo-Latin texts are primarily found in early printed editions, which present certain features of spelling and the use of diacritics distinct from the Latin of antiquity, medieval Latin manuscript conventions, and representations of Latin in modern printed editions.\nCharacters.\nIn spelling, Neo-Latin, in all but the earliest texts, distinguishes the letter \"u\" from \"v\" and \"i\" from \"j\". In older texts printed down to c.\u20091630, \"v\" was used in initial position (even when it represented a vowel, e.g. in \"vt\", later printed \"ut\") and \"u\" was used elsewhere, e.g. in \"nouus\", later printed \"novus\". By the mid-17th century, the letter \"v\" was commonly used for the consonantal sound of Roman V, which in most pronunciations of Latin in the Neo-Latin period was (and not ), as in \"vulnus\" \"wound\", \"corvus\" \"crow\". Where the pronunciation remained , as after \"g\", \"q\" and \"s\", the spelling \"u\" continued to be used for the consonant, e.g. in \"lingua\", \"qualis\", and \"suadeo\".\nThe letter \"j\" generally represented a consonantal sound (pronounced in various ways in different European countries, e.g. , , , ). It appeared, for instance, in \"jam\" \"already\" or \"jubet\" \"he/she orders\" (earlier spelled \"iam\" and \"iubet\").\nIt was also found between vowels in the words \"ejus\", \"hujus\", \"cujus\" (earlier spelled \"eius, huius, cuius\"), and pronounced as a consonant; likewise in such forms as \"major\" and \"pejor\". \"J\" was also used when the last in a sequence of two or more \"i\"'s, e.g. \"radij\" (now spelled \"radii\") \"rays\", \"alijs\" \"to others\", \"iij\", the Roman numeral 3; however, \"ij\" was for the most part replaced by \"ii\" by 1700.\nIn common with texts in other languages using the Roman alphabet, Latin texts down to c.\u20091800 used the letter-form \"\u017f\" (the \"long s\") for \"s\" in positions other than at the end of a word; e.g. \"ip\u017fi\u017f\u017fimus\".\nThe digraphs \"ae\" and \"oe\" were typically written using the ligatures \"\u00e6\" and \"\u0153\" (e.g. \"C\u00e6sar\", \"p\u0153na\") except when part of a word in all capitals, such as in titles, chapter headings, or captions. More rarely (and usually in 16th- to early 17th-century texts) the e caudata was used as a substitute for the digraphs.\nDiacritics.\nThree kinds of diacritic were in common use: the acute accent \u00b4, the grave accent `, and the circumflex accent \u02c6. These were normally only marked on vowels (e.g. \u00ed, \u00e8, \u00e2); but see below regarding \"que\".\nThe acute accent marked a stressed syllable, but was usually confined to those where the stress was not in its normal position, as determined by vowel length and syllabic weight. In practice, it was typically found on the vowel in the syllable immediately preceding a final clitic, particularly \"que\" \"and\", \"ve\" \"or\" and \"ne\", a question marker; e.g. \"id\u00e9mque\" \"and the same (thing)\". Some printers, however, put this acute accent over the \"q\" in the enclitic \"que\", e.g. \"eorumq\u0301ue\" \"and their\". The acute accent fell out of favor by the 19th century.\nThe grave accent had various uses, none related to pronunciation or stress. It was always found on the preposition \"\u00e0\" (variant of \"ab\" \"by\" or \"from\") and likewise on the preposition \"\u00e8\" (variant of \"ex\" \"from\" or \"out of\"). It might also be found on the interjection \"\u00f2\" \"O\". Most frequently, it was found on the last (or only) syllable of various adverbs and conjunctions, particularly those that might be confused with prepositions or with inflected forms of nouns, verbs, or adjectives. Examples include \"cert\u00e8\" \"certainly\", \"ver\u00f2\" \"but\", \"prim\u00f9m\" \"at first\", \"p\u00f2st\" \"afterwards\", \"c\u00f9m\" \"when\", \"ade\u00f2\" \"so far, so much\", \"un\u00e0\" \"together\", \"qu\u00e0m\" \"than\". In some texts the grave was found over the clitics such as \"que\", in which case the acute accent did not appear before them.\nThe circumflex accent represented metrical length (generally not distinctively pronounced in the Neo-Latin period) and was chiefly found over an \"a\" representing an ablative singular case, e.g. \"e\u00e2dem form\u00e2\" \"with the same shape\". It might also be used to distinguish two words otherwise spelled identically, but distinct in vowel length; e.g. \"h\u00eec\" \"here\" differentiated from \"hic\" \"this\", \"fug\u00eare\" \"they have fled\" (=\"f\u016bg\u0113runt\") distinguished from \"fugere\" \"to flee\", or \"senat\u00fbs\" \"of the senate\" distinct from \"senatus\" \"the senate\". It might also be used for vowels arising from contraction, e.g. \"n\u00f4sti\" for \"novisti\" \"you know\", \"imper\u00e2sse\" for \"imperavisse\" \"to have commanded\", or \"d\u00ee\" for \"dei\" or \"dii\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21984", "revid": "43096562", "url": "https://en.wikipedia.org/wiki?curid=21984", "title": "New Latin", "text": ""}
{"id": "21986", "revid": "50086806", "url": "https://en.wikipedia.org/wiki?curid=21986", "title": "Naive Set Theory (book)", "text": "1960 mathematics textbook by Paul Halmos\n\"See also Naive set theory for the mathematical topic.\"\nNaive Set Theory is a mathematics textbook by Paul Halmos providing an undergraduate introduction to set theory. Originally published by \"Van Nostrand\" in 1960, it was reprinted in the Springer-Verlag Undergraduate Texts in Mathematics series in 1974. \nIt is on the list of 173 books essential for undergraduate math libraries.\nWhile the title states that the set theory presented is 'naive', which is usually taken to mean without formal axioms, the book does introduce a system of axioms equivalent to that of ZFC set theory except the Axiom of foundation. It also gives correct and rigorous definitions for many basic concepts. Where it differs from a \"true\" axiomatic set theory book is its character: there are no discussions of axiomatic minutiae, and there is next to nothing about advanced topics such as large cardinals or forcing. Instead, it tries to be intelligible to someone who has never thought about set theory before.\nHalmos later stated that it was the fastest book he wrote, taking about six months, and that the book \"wrote itself\".\nAxioms used in the book.\nThe statements of the axioms given below are as they appear in the book, with section references, and with explanatory commentary on each one. The \"principal primitive (undefined) concept of \"belonging\"\" (that is, set membership) is the starting point, where \"formula_1 belongs to formula_2\" is written in the usual notation as formula_3. Here formula_1 and formula_2 are both sets, with the notational distinction of upper/lower case a purely stylistic choice. The axioms govern the properties of this relation between sets.\n1. Axiom of Extension (Section 1): two sets are equal if and only if they have the same elements.\nThis guarantees that the membership and (logical) equality relations interact appropriately.\n2. Axiom of Specification (Section 2): To every set formula_2 and every condition formula_7 there corresponds a set formula_8 whose elements are precisely those elements of formula_2 for which formula_7 holds.\nThis is more properly an axiom schema (that is, each condition formula_7 gives rise to an axiom). \"Condition\" here means a \"sentence\" in which the variable formula_1 (ranging over all sets) is a free variable. \"Sentences\" are defined as being built up from smaller sentences using first order logical operations (and, or, not), including quantifiers (\"there exists\", \"for all\"), and with atomic (i.e. basic starting) sentences formula_3 and formula_14.\nThis schema is used in 4.-7. below to cut down the set that is stated to exist to the set containing precisely the intended elements, rather than some larger set with extraneous elements. For example, the axiom of pairing applied to the sets formula_2 and formula_8 only guarantees there is \"some\" set formula_17 such that formula_18 and formula_19. Specification can be used to then construct the set formula_20 with \"just\" those elements.\n3. Set existence (Section 3): There exists a set.\nNot specified as an named axiom, but instead stated to be \"officially assumed\". This assumption is not necessary once the axiom of infinity is adopted later, which also specifies the existence of a set (with a certain property). The existence of any set at all is used to show the empty set exists using the axiom of specification.\n4. Axiom of pairing (Section 3): For any two sets there exists a set that they both belong to.\nThis is used to show that the singleton formula_21 containing a given set formula_2 exists.\n5. Axiom of unions (Section 4): For every collection of sets there exists a set that contains all the elements that belong to at least one set of the given collection.\nIn Section 1 Halmos writes that \"to avoid terminological monotony, we shall sometimes say \"collection\" instead of set.\" Hence this axiom is equivalent to the usual form of the axiom of unions (given the axiom of specification, as noted above).\nFrom the axioms so far Halmos gives a construction of intersections of sets, and the usual Boolean operations on sets are described and their properties proved.\n6. Axiom of powers (Section 5): For each set there exists a collection of sets that contains among its elements all the subsets of the given set.\nAgain (noting that \"collection\" means \"set\") using the axiom (schema) of specification we can cut down to get the power set formula_23 of a set formula_2, whose elements are precisely the subsets of formula_2. The axioms so far are used to construct the cartesian product of sets.\n7. Axiom of infinity (Section 11): There exists a set containing 0 and containing the successor of each of its elements.\nThe set formula_26. The \"successor\" of a set formula_1 is defined to be the set formula_28. For example: formula_29. This axiom ensures the existence of a set containing formula_30 and hence formula_31, and hence formula_32 and so on. This implies that there is a set containing all the elements of the first infinite von Neumann ordinal formula_33. And another application of the axiom (schema) of specification means formula_33 itself is a set.\n8. Axiom of choice (Section 15): The Cartesian product of a non-empty family of non-empty sets is non-empty.\nThis is one of many equivalents to the axiom of choice. Note here that \"family\" is defined to be a function formula_35, with the intuitive idea that the sets of the family are the sets formula_36 for formula_37 ranging over the set formula_38, and in usual notation this axiom says that there is at least one element in formula_39, as long as formula_40 for all formula_41.\n9. Axiom of substitution (Section 19): If formula_42 is a sentence such that for each formula_43 in a set formula_2 the set formula_45 can be formed, then there exists a function formula_46 with domain formula_2 such that formula_48 for each formula_43 in formula_2.\nA function formula_51 is defined to be a functional relation (i.e. a certain subset of formula_52), not as a certain type of set of ordered pairs, as in ZFC, for instance.\nThis 'axiom' is essentially the axiom schema of collection, which, given the other axioms, is equivalent to the axiom schema of replacement. It is the collection schema rather than replacement, because 1) formula_42 is a class \"relation\" instead of a class function and 2) the function formula_46 is not specified to have codomain precisely the set formula_55, but merely some set formula_56.\nThis axiom is used in the book to a) construct limit von Neumann ordinals after the first infinite ordinal formula_33, and b) prove that every well-ordered set is order isomorphic to a unique von Neumann ordinal.\nRelation to other axiom systems for set theory.\nNote that axioms 1.-9. are equivalent to the axiom system of ZFC-Foundation (that is ZFC without the Foundation axiom), since as noted above, Halmos' axiom (schema) of substitution is equivalent to the axiom schema of replacement, in the presence of the other axioms. \nAdditionally, axioms 1.-8. are nearly exactly those of Zermelo set theory ZC; the only difference being that the set existence assumption is replaced in ZC by the existence of the empty set, and the existence of singletons is stated outright for ZC, rather than proved, as above. Additionally, the infinite set that is asserted to exist by the axiom of infinity is not the one that Zermelo originally postulated,[a] but Halmos' version is sometimes silently substituted for it in treatments of Zermelo set theory.\nThat the axiom (schema) of substitution is stated last and so late in the book is testament to how much elementary set theory\u2014and indeed mathematics more generally\u2014can be done without it. As a very simple example of what is \"is\" needed for, the von Neumann ordinal formula_58 (that is, the second limit ordinal) cannot be proved to be a set using only axioms 1.-8., even though sets with well-orderings with this order type can be constructed from these axioms. For instance formula_59, with an ordering placing all elements of the first copy of formula_33 less than the second. Working with von Neumann ordinals in place of generic well-orderings has technical advantages, not least the fact every well-ordering is order isomorphic to a \"unique\" von Neumann ordinal.\nAs noted above, the book omits the Axiom of Foundation (also known as the Axiom of Regularity). Halmos repeatedly dances around the issue of whether or not a set can contain itself.\nBut Halmos does let us prove that there are certain sets that cannot contain themselves.\n - In fact given the rest of the axioms, neither of the original Zermelo axiom of infinity, nor Halmos' axiom of infinity, can be proven from the other, even if one adds in the axiom of foundation. That is, one cannot construct the infinite set Halmos' axiom asserts exists, from the infinite set Zermelo's original axioms assert exists, and vice versa. The axiom schema of Replacement, on the other hand, \"does\" allow the construction of either of these infinite sets from the other.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21987", "revid": "9092818", "url": "https://en.wikipedia.org/wiki?curid=21987", "title": "Nootropics", "text": ""}
{"id": "21989", "revid": "43819313", "url": "https://en.wikipedia.org/wiki?curid=21989", "title": "Nitrogen fixation", "text": "Conversion of molecular nitrogen into biologically accessible nitrogen compounds\nNitrogen fixation is a chemical process by which molecular dinitrogen (N2) is converted into ammonia (NH3). It occurs both biologically and abiologically in chemical industries. Biological nitrogen fixation or \"diazotrophy\" is catalyzed by enzymes called nitrogenases. These enzyme complexes are encoded by the \"Nif\" genes (or \"Nif\" homologs) and contain iron, often with a second metal (usually molybdenum, but sometimes vanadium).\nSome nitrogen-fixing bacteria have symbiotic relationships with plants, especially legumes, mosses and aquatic ferns such as \"Azolla\". Looser non-symbiotic relationships between diazotrophs and plants are often referred to as associative, as seen in nitrogen fixation on rice roots. Nitrogen fixation occurs between some termites and fungi. It occurs naturally in the air by means of NOx production by lightning.\nFixed nitrogen is essential to life on Earth. Organic compounds such as DNA and proteins contain nitrogen. Industrial nitrogen fixation underpins the manufacture of all nitrogenous industrial products, which include fertilizers, pharmaceuticals, textiles, dyes and explosives.\nHistory.\nBiological nitrogen fixation was discovered by Jean-Baptiste Boussingault in 1838. Later, in 1880, the process by which it happens was discovered by German agronomist Hermann Hellriegel and Hermann Wilfarth and was fully described by Dutch microbiologist Martinus Beijerinck.\n\"The protracted investigations of the relation of plants to the acquisition of nitrogen begun by de Saussure, Ville, Lawes, Gilbert and others, and culminated in the discovery of symbiotic fixation by Hellriegel and Wilfarth in 1887.\"\n\"Experiments by Bossingault in 1855 and Pugh, Gilbert &amp; Lawes in 1887 had shown that nitrogen did not enter the plant directly. The discovery of the role of nitrogen fixing bacteria by Herman Hellriegel and Herman Wilfarth in 1886\u20131888 would open a new era of soil science.\"\nIn 1901, Beijerinck showed that \"Azotobacter chroococcum\" was able to fix atmospheric nitrogen. This was the first known species of the \"Azotobacter\" genus, so-named by him. It is also the first known diazotroph, species that use diatomic nitrogen as a step in the complete nitrogen cycle.\nBiological.\nBiological nitrogen fixation (BNF) occurs when atmospheric nitrogen is converted to ammonia by a nitrogenase enzyme. The overall reaction for BNF is:\nThe process is coupled to the hydrolysis of 16 equivalents of ATP and is accompanied by the co-formation of one equivalent of H2. The conversion of N2 into ammonia occurs at a metal cluster called FeMoco, an abbreviation for the iron-molybdenum cofactor. The mechanism proceeds via a series of protonation and reduction steps wherein the FeMoco active site hydrogenates the N2 substrate. In free-living diazotrophs, nitrogenase-generated ammonia is assimilated into glutamate through the glutamine synthetase/glutamate synthase pathway. The microbial nif genes required for nitrogen fixation are widely distributed in diverse environments.\nNitrogenases are rapidly degraded by oxygen. For this reason, many bacteria cease production of the enzyme in the presence of oxygen. Many nitrogen-fixing organisms exist only in anaerobic conditions, respiring to draw down oxygen levels, or binding the oxygen with a protein such as leghemoglobin.\nImportance of nitrogen.\nAtmospheric nitrogen cannot be metabolized by most organisms, because its triple covalent bond is very strong. Most take up fixed nitrogen from various sources. For every 100 atoms of carbon, roughly 2 to 20 atoms of nitrogen are assimilated. The atomic ratio of carbon (C) : nitrogen (N) : phosphorus (P) observed on average in planktonic biomass was originally described by Alfred Redfield, who determined the stoichiometric relationship between C:N:P atoms, The Redfield Ratio, to be 106:16:1.\nNitrogenase.\nThe protein complex nitrogenase is responsible for catalyzing the reduction of nitrogen gas (N2) to ammonia (NH3). In cyanobacteria, this enzyme system is housed in a specialized cell called the heterocyst. The production of the nitrogenase complex is genetically regulated, and the activity of the protein complex is dependent on ambient oxygen concentrations, and intra- and extracellular concentrations of ammonia and oxidized nitrogen species (nitrate and nitrite). Additionally, the combined concentrations of both ammonium and nitrate are thought to inhibit NFix, specifically when intracellular concentrations of 2-oxoglutarate (2-OG) exceed a critical threshold. The specialized heterocyst cell is necessary for the performance of nitrogenase as a result of its sensitivity to ambient oxygen.\nNitrogenase consist of two proteins, a catalytic iron-dependent protein, commonly referred to as MoFe protein and a reducing iron-only protein (Fe protein). Three iron-dependent proteins are known: molybdenum-dependent, vanadium-dependent, and iron-only, with all three nitrogenase protein variations containing an iron protein component. Molybdenum-dependent nitrogenase is most common. The different types of nitrogenase can be determined by the specific iron protein component. Nitrogenase is highly conserved. Gene expression through DNA sequencing can distinguish which protein complex is present in the microorganism and potentially being expressed. Most frequently, the \"nif\"H gene is used to identify the presence of molybdenum-dependent nitrogenase, followed by closely related nitrogenase reductases (component II) \"vnf\"H and \"anf\"H representing vanadium-dependent and iron-only nitrogenase, respectively. In studying the ecology and evolution of nitrogen-fixing bacteria, the \"nifH\" gene is the biomarker most widely used. \"nif\"H has two similar genes \"anf\"H and vnfH that also encode for the nitrogenase reductase component of the nitrogenase complex.\nEvolution of nitrogenase.\nNitrogenase is thought to have evolved sometime between 1.5-2.2 billion years ago (Ga), although there is some isotopic support for nitrogenase evolution as early as around 3.2 Ga. Nitrogenase appears to have evolved from maturase-like proteins, although the function of the preceding protein is currently unknown.\nNitrogenase has three different forms (\"Nif, Anf, and Vnf\") that correspond with the metal found in the active site of the protein (molybdenum, iron, and vanadium respectively). Marine metal abundances over Earth's geologic timeline are thought to have driven the relative abundance of which form of nitrogenase was most common. Currently, there is no conclusive agreement on which form of nitrogenase arose first.\nMicroorganisms.\nDiazotrophs are widespread within domain Bacteria including cyanobacteria (e.g. the highly significant \"Trichodesmium\" and \"Cyanothece\"), green sulfur bacteria, purple sulfur bacteria, Azotobacteraceae, rhizobia and \"Frankia.\" Several obligately anaerobic bacteria fix nitrogen including many (but not all) \"Clostridium\" spp. Some archaea such as \"Methanosarcina acetivorans\" also fix nitrogen, and several other methanogenic taxa, are significant contributors to nitrogen fixation in oxygen-deficient soils.\nCyanobacteria, commonly known as blue-green algae, inhabit nearly all illuminated environments on Earth and play key roles in the carbon and nitrogen cycle of the biosphere. In general, cyanobacteria can use various inorganic and organic sources of combined nitrogen, such as nitrate, nitrite, ammonium, urea, or some amino acids. Several cyanobacteria strains are also capable of diazotrophic growth, an ability that may have been present in their last common ancestor in the Archean eon. Nitrogen fixation not only naturally occurs in soils but also aquatic systems, including both freshwater and marine. Indeed, the amount of nitrogen fixed in the ocean is at least as much as that on land. The colonial marine cyanobacterium \"Trichodesmium\" is thought to fix nitrogen on such a scale that it accounts for almost half of the nitrogen fixation in marine systems globally. Marine surface lichens and non-photosynthetic bacteria belonging in Proteobacteria and Planctomycetes fixate significant atmospheric nitrogen. Species of nitrogen fixing cyanobacteria in fresh waters include: \"Aphanizomenon\" and \"Dolichospermum\" (previously Anabaena). Such species have specialized cells called heterocytes, in which nitrogen fixation occurs via the nitrogenase enzyme.\nAlgae.\nOne type of organelle, originating from cyanobacterial endosymbionts called UCYN-A2, can turn nitrogen gas into a biologically available form. This nitroplast was discovered in algae, particularly in the marine algae Braarudosphaera bigelowii.\nDiatoms in the family \"Rhopalodiaceae\" also possess cyanobacterial endosymbionts called spheroid bodies or diazoplasts. These endosymbionts have lost photosynthetic properties, but have kept the ability to perform nitrogen fixation, allowing these diatoms to fix atmospheric nitrogen. Other diatoms in symbiosis with nitrogen-fixing cyanobacteria are among the genera \"Hemiaulus\", \"Rhizosolenia\" and \"Chaetoceros\".\nRoot nodule symbioses.\nLegume family.\nPlants that contribute to nitrogen fixation include those of the legume family\u2014Fabaceae\u2014 with taxa such as kudzu, clover, soybean, alfalfa, lupin, peanut and rooibos. They contain symbiotic rhizobia bacteria within nodules in their root systems, producing nitrogen compounds that help the plant to grow and compete with other plants. When the plant dies, the fixed nitrogen is released, making it available to other plants; this helps to fertilize the soil. The great majority of legumes have this association, but a few genera (e.g., \"Styphnolobium\") do not. In many traditional farming practices, fields are rotated through various types of crops, which usually include one consisting mainly or entirely of clover.\nFixation efficiency in soil is dependent on many factors, including the legume and air and soil conditions. For example, nitrogen fixation by red clover can range from .\nNon-leguminous.\nThe ability to fix nitrogen in nodules is present in actinorhizal plants such as alder and bayberry, with the help of \"Frankia\" bacteria. They are found in 25 genera in the orders Cucurbitales, Fagales and Rosales, which together with the Fabales form a \"nitrogen-fixing clade\" of eurosids. The ability to fix nitrogen is not universally present in these families. For example, of 122 Rosaceae genera, only four fix nitrogen. Fabales were the first lineage to branch off this nitrogen-fixing clade; thus, the ability to fix nitrogen may be plesiomorphic and subsequently lost in most descendants of the original nitrogen-fixing plant; however, it may be that the basic genetic and physiological requirements were present in an incipient state in the most recent common ancestors of all these plants, but only evolved to full function in some of them.\nIn addition, \"Trema\" (\"Parasponia\"), a tropical genus in the family Cannabaceae, is unusually able to interact with rhizobia and form nitrogen-fixing nodules.\nOther plant symbionts.\nSome other plants live in association with a cyanobiont (cyanobacteria such as \"Nostoc\") which fix nitrogen for them:\nSome symbiotic relationships involving agriculturally-important plants are:\nIndustrial processes.\nHistorical.\nA method for nitrogen fixation was first described by Henry Cavendish in 1784 using electric arcs reacting nitrogen and oxygen in air. This method was implemented in the Birkeland\u2013Eyde process of 1903. The fixation of nitrogen by lightning is a very similar natural occurring process.\nThe possibility that atmospheric nitrogen reacts with certain chemicals was first observed by M. Desfosses, a pharmacist from Besan\u00e7on, in 1828. He observed that mixtures of alkali metal oxides and carbon react with nitrogen at high temperatures. With the use of barium carbonate as starting material, the first commercial process became available in the 1860s, developed by Margueritte and Sourdeval. The resulting barium cyanide reacts with steam, yielding ammonia. In 1898 Frank and Caro developed what is known as the Frank\u2013Caro process to fix nitrogen in the form of calcium cyanamide. The process was eclipsed by the Haber process, which was discovered in 1909.\nHaber process.\nThe dominant industrial method for producing ammonia is the Haber process also known as the Haber-Bosch process in 1909. Fertilizer production is now the largest source of human-produced fixed nitrogen in the terrestrial ecosystem. Ammonia is a required precursor to fertilizers, explosives, and other products. The Haber process requires high pressures (around 200 atm) and high temperatures (at least 400\u00a0\u00b0C), which are routine conditions for industrial catalysis. This process uses natural gas as a hydrogen source and air as a nitrogen source. The ammonia product has resulted in an intensification of nitrogen fertilizer globally and is credited with supporting the expansion of the human population from around 2 billion in the early 20th century to roughly 8 billion people now.\nHomogeneous catalysis.\nMuch research has been conducted on the discovery of catalysts for nitrogen fixation, often with the goal of lowering energy requirements. However, such research has thus far failed to approach the efficiency and ease of the Haber process. Many compounds react with atmospheric nitrogen to give dinitrogen complexes. The first dinitrogen complex to be reported was Ru(NH3)5(N2)2+. Some soluble complexes do catalyze nitrogen fixation.\nLightning.\nNitrogen can be fixed by lightning converting nitrogen gas (N2) and oxygen gas (O2) in the atmosphere into nitrogen oxides (). The N2 molecule is highly stable and nonreactive due to the triple bond between the nitrogen atoms. Lightning produces enough energy and heat to break this bond allowing nitrogen atoms to react with oxygen, forming . These compounds cannot be used by plants, but as this molecule cools, it reacts with oxygen to form nitrogen dioxide (NO2), which in turn reacts with water to produce nitrous acid (HNO2) or nitric acid (HNO3). When these acids seep into the soil, they produce nitrate (NO3\u2212), which is of use to plants.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21994", "revid": "6727347", "url": "https://en.wikipedia.org/wiki?curid=21994", "title": "Navigation research", "text": ""}
{"id": "21995", "revid": "37443495", "url": "https://en.wikipedia.org/wiki?curid=21995", "title": "Naguib Mahfouz", "text": "Egyptian writer (1911\u20132006)\nNaguib Mahfouz Abdelaziz Ibrahim Ahmed Al-Basha (, ; 11 December 1911 \u2013 30 August 2006) was an Egyptian writer who won the 1988 Nobel Prize in Literature. In awarding the prize, the Swedish Academy described him as a writer \"who, through works rich in nuance \u2013 now clear-sightedly realistic, now evocatively ambiguous \u2013 has formed an Arabian narrative art that applies to all mankind\". Mahfouz is regarded as one of the first contemporary writers in Arabic literature, along with Taha Hussein, to explore themes of existentialism. He is the only Egyptian to win the Nobel Prize in Literature. He published 35 novels, over 350 short stories, 26 screenplays, hundreds of op-ed columns for Egyptian newspapers, and seven plays over a 70-year career, from the 1930s until 2004. All of his novels are set in Egypt, and always mention the concept of \"the lane\" as a microcosm of the world. His most famous works include \"The Cairo Trilogy\" and \"Children of Gebelawi\". Many of Mahfouz's works have been adapted into Egyptian and international films; Making him one of the most widely adapted Arab authors. While Mahfouz's literature is classified as realist literature, existential themes appear in it.\nEarly life and education.\nMahfouz was born in a lower middle-class Muslim Egyptian family in Old Cairo in 1911. The first part of his compound given name was chosen in appreciation of the well-known obstetrician, Naguib Pasha Mahfouz, who oversaw his difficult birth. Mahfouz was the seventh and the youngest child, with four brothers and two sisters, all of them much older than him. (Experientially, he grew up an \"only child\".) The family lived in two popular districts of Cairo: first, in the Bayt al-Qadi neighborhood in the Gamaleya quarter in the old city, from where they moved in 1924 to Abbaseya, then a new Cairo suburb north of the old city, locations that would provide the backdrop for many of Mahfouz's later writings. His father, Abdel-Aziz Ibrahim, whom Mahfouz described as having been \"old-fashioned\", was a civil servant, and Mahfouz eventually followed in his footsteps in 1934. Mahfouz's mother, Fatimah, was the daughter of Mustafa Qasheesha, an Al-Azhar sheikh, and although illiterate herself, took the boy Mahfouz on numerous excursions to cultural locations such as the Egyptian Museum and the Pyramids.\nThe Mahfouz family were devout Muslims and Mahfouz had a strict Islamic upbringing. In an interview, he elaborated on the stern religious climate at home during his childhood. He stated, \"You would never have thought that an artist would emerge from that family.\"\nThe Egyptian Revolution of 1919 had a strong effect on Mahfouz, although he was at the time only seven years old. From the window he saw British soldiers firing at the demonstrators in an effort to disperse them. According to Mahfouz, \"You could say ... that the one thing which most shook the security of my childhood was the 1919 revolution\", he later said.\nIn his early years, Mahfouz read extensively and was influenced by Hafiz Najib, Taha Hussein and Salama Moussa, the Fabian intellectual.\nAfter completing his secondary education, Mahfouz was admitted in 1930 to the Egyptian University (now Cairo University), where he studied philosophy, graduating in 1934. By 1936, having spent a year working on an M.A. in philosophy, he decided to discontinue his studies and become a professional writer. He published his first work in \"Al Majalla Al Jadida\", a magazine started by Salama Musa in 1929. Mahfouz then worked as a journalist for \"Arrissalah\", and contributed short stories to \"Al-Hilal\" and \"Al-Ahram\".\nCivil service.\nAfter receiving his bachelor's degree in philosophy from Cairo University in 1934, Mahfouz joined the Egyptian civil service, where he continued to work in various positions and ministries until retirement in 1971. He served first as a clerk at Cairo University, then, in 1938, in the Ministry of Islamic Endowments (Awqaf) as parliamentary secretary to the Minister of Islamic Endowments. In 1945, he requested a transfer to the al-Ghuri Mausoleum library, where he interviewed residents of his childhood neighborhood as part of the \"Good Loans Project\". In the 1950s, he worked as Director of Censorship in the Bureau of Arts, as Director of the Foundation for the Support of the Cinema, and finally as a consultant to the Ministry of Culture.\nWriting career.\nMahfouz published 34 novels, over 350 short stories, dozens of screenplays, and five plays over a 70-year career. Possibly his most famous work, \"The Cairo Trilogy\", depicts the lives of three generations of different families in Cairo from World War I until after the 1952 military coup that overthrew King Farouk. He was a board member of the publisher \"Dar el-Ma'aref\". Many of his novels were serialized in \"Al-Ahram\", and his writings also appeared in his weekly column, \"Point of View\". Before the Nobel Prize only a few of his novels had appeared in the West.\nWriting style and themes.\nMost of Mahfouz's early works were set in Cairo. \"Abath Al-Aqdar (Mockery of the Fates)\" (1939), \"Rhadopis\" (1943), and \"Kifah Tibah (The Struggle of Thebes)\" (1944) were historical novels written as part of a larger unfulfilled 30-novel project. Inspired by Sir Walter Scott (1771\u20131832), Mahfouz planned to cover the entire history of Egypt in a series of books. However, following the third volume, his interest shifted to current settings and issues, as well as the psychological impact of social change on ordinary people.\nMahfouz's prose is characterised by the blunt expression of his ideas. His written works cover a broad range of topics, including the controversial and taboo such as socialism, homosexuality, and God. Writing about some of these subjects was prohibited in Egypt.\nMahfouz's works often deal with Egypt's development during the 20th century, and combined intellectual and cultural influences from both East and West. His own exposure to foreign literature began in his youth with the enthusiastic consumption of Western detective stories, Russian classics, and modernist writers as Marcel Proust, Franz Kafka and James Joyce. Mahfouz's stories are almost always set in the heavily populated urban quarters of Cairo, where his characters, usually ordinary people, try to cope with the modernization of society and the temptations of Western values.\nMahfouz's central work in the 1950s was the \"Cairo Trilogy\", which he completed before the July Revolution. The novels were titled with the street names \"Palace Walk\", \"Palace of Desire\", and \"Sugar Street\". Mahfouz set the story in the parts of Cairo where he grew up. The novels depict the life of the patriarch el-Sayyed Ahmed Abdel Gawad and his family over three generations, from World War I until 1944. Mahfouz stopped writing for some years after finishing the trilogy.\nDisappointed in the Nasser r\u00e9gime, which had overthrown the monarchy in 1952, he started publishing again in 1959, now prolifically pouring out novels, short stories, journalism, memoirs, essays, and screenplays. He stated in a 1998 interview that he \"long felt that Nasser was one of the greatest political leaders in modern history. I only began to fully appreciate him after he nationalized the Suez Canal.\" His non-fiction, including his journalism and essays and his writing on literature and philosophy, were published in four volumes from 2016.\nHis 1966 novel \"Tharthara Fawq Al-N\u012bl\" (Adrift on the Nile) is one of his most popular works. It was later made into a film called \"Chitchat on the Nile\" during the r\u00e9gime of Anwar al-Sadat. The story criticizes the decadence of Egyptian society during the Nasser era. It was banned by Sadat to avoid provoking Egyptians who still loved former president Nasser. Copies of the banned book were hard to find prior to the late 1990s.\nThe \"Children of Gebelawi\" (1959, also known as \"Children of the Alley\"), one of Mahfouz's best known works, portrayed the patriarch Gebelaawi and his children, average Egyptians living the lives of Cain and Abel, Moses, Jesus, and Mohammed. Gebelawi builds a mansion in an oasis in the middle of a barren desert; his estate becomes the scene of a family feud that continues for generations. \"Whenever someone is depressed, suffering or humiliated, he points to the mansion at the top of the alley at the end opening out to the desert, and says sadly, 'That is our ancestor's house, we are all his children, and we have a right to his property. Why are we starving? What have we done?'\" The book was banned throughout the Arab world except in Lebanon until 2006 when it was first published in Egypt. The work was prohibited because of its alleged blasphemy through the allegorical portrayal of God and the monotheistic Abrahamic faiths of Judaism, Christianity, and Islam.\nIn the 1960s, Mahfouz further developed the theme that humanity is moving further away from God in his existentialist novels. In \"The Thief and the Dogs\" (1961) he depicted the fate of a Marxist thief who has been released from prison and plans revenge.\nIn the 1960s and 1970s, Mahfouz began to construct his novels more freely and often used interior monologues. In \"Miramar\" (1967) he employed a form of multiple First-person narratives. Four narrators, among them a Socialist and a Nasserite opportunist, represent different political views. In the center of the story is an attractive servant girl. In \"Arabian Nights and Days\" (1979) and in \"The Journey of Ibn Fatouma\" (1983) he drew on traditional Arabic narratives as subtexts. \"Akhenaten: Dweller in Truth\" (1985) deals with conflict between old and new religious truths.\nMany of his novels were first published in serialized form, including \"Children of Gebelawi\" and \"Midaq Alley\" which was also adapted into a Mexican film starring Salma Hayek called \"El callej\u00f3n de los milagros\".\nPolitical influence.\nMost of Mahfouz's writings deal mainly with politics, a fact he acknowledged: \"In all my writings, you will find politics. You may find a story which ignores love or any other subject, but not politics; it is the very axis of our thinking\".\nHe espoused Egyptian nationalism in many of his works, and expressed sympathies for the post-World-War-era Wafd Party. He was also attracted to socialist and democratic ideals early in his youth. The influence of socialist ideals is strongly reflected in his first two novels, \"Al-Khalili\" and \"New Cairo\", as well as many of his later works. Parallel to his sympathy for socialism and democracy was his antipathy towards Islamic extremism.\nIn his youth, Mahfouz had personally known Sayyid Qutb when Qutb was showing a greater interest in literary criticism than in Islamic fundamentalism; Qutb later became a significant influence on the Muslim Brotherhood. In the mid-1940s, Qutb was one of the first critics to recognize Mahfouz's talent, and by the 1960s, near the end of Qutb's life, Mahfouz even visited him in the hospital. But later, in the semi-autobiographical novel \"Mirrors\", Mahfouz drew a negative portrait of Qutb. He was disillusioned with the 1952 revolution and by Egypt's defeat in the 1967 Six-Day War. He had supported the principles of the revolution, but became disenchanted, saying that the practices failed to live up to the original ideals.\nMahfouz's writing influenced a new generation of Egyptian lawyers, including Nabil Mounir and Reda Aslan.\nReception.\nMahfouz's translated works received praise from American critics:\n\"The alleys, the houses, the palaces and mosques and the people who live among them are evoked as vividly in Mahfouz's work as the streets of London were conjured by Dickens.\"\n\u2014\"Newsweek\"\n\"Throughout Naguib Mahfouz's fiction there is a pervasive sense of metaphor, of a literary artist who is using his fiction to speak directly and unequivocally to the condition of his country. His work is imbued with love for Egypt and its people, but it is also utterly honest and unsentimental.\"\n\u2014\"Washington Post\"\n\"Mahfouz's work is freshly nuanced and hauntingly lyrical. The Nobel Prize acknowledges the universal significance of [his] fiction.\"\n\u2014\"Los Angeles Times\"\n\"Mr. Mahfouz embodied the essence of what makes the bruising, raucous, chaotic human anthill of Cairo possible.\"\n\u2014\"The Economist\"\nNobel Prize for Literature.\nMahfouz was awarded the 1988 Nobel Prize in Literature, the only Arab writer to have won the award. Shortly after winning the prize Mahfouz was quoted as saying:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The Nobel Prize has given me, for the first time in my life, the feeling that my literature could be appreciated on an international level. The Arab world also won the Nobel with me. I believe that international doors have opened, and that from now on, literate people will consider Arab literature also. We deserve that recognition.\nThe Swedish letter to Mahfouz praised his \"rich and complex work\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[It] invites us to reconsider the fundamental things in life. Themes like the nature of time and love, society and norms, knowledge and faith recur in a variety of situations and are presented in thought-provoking, evocative, and clearly daring ways. And the poetic quality of your prose can be felt across the language barrier. In the prize citation you are credited with the forming of an Arabian narrative art that applies to all mankind.\nBecause Mahfouz found traveling to Sweden difficult at his age, he did not attend the award ceremony.\nPolitical involvement.\nMahfouz did not shrink from controversy outside of his work. As a consequence of his support for Sadat's Camp David peace treaty with Israel in 1978, his books were banned in many Arab countries until after he won the Nobel Prize. Like many Egyptian writers and intellectuals, Mahfouz was on an Islamic fundamentalist \"death list\".\nHe defended British-Indian writer Salman Rushdie after Ayatollah Ruhollah Khomeini condemned Rushdie to death in a 1989 fatwa, but also criticized Rushdie's novel \"The Satanic Verses\" as \"insulting\" to Islam. Mahfouz believed in freedom of expression, and, although he did not personally agree with Rushdie's work, he spoke out against the \"fatwa\" condemning him to death for it.\nIn 1989, after Ayatollah Khomeini's \"fatwa\" calling for Rushdie and his publishers to be killed, Mahfouz called Khomeini a terrorist. Shortly after, Mahfouz joined 80 other intellectuals in declaring that \"no blasphemy harms Islam and Muslims so much as the call for murdering a writer.\"\nAssassination attempt and aftermath.\nThe publication of \"The Satanic Verses\" revived the controversy surrounding Mahfouz's novel \"Children of Gebelawi\". Death threats against Mahfouz followed, including one from the \"blind sheikh\", Egyptian-born Omar Abdel-Rahman. Mahfouz was given police protection, but in 1994 an extremist succeeded in attacking the 82-year-old novelist by stabbing him in the neck outside his Cairo home.\nHe survived, permanently affected by damage to nerves of his right upper limb. Sixteen people were put on a military trial, and two of them received death penalty and eventually hanged. After the incident, Mahfouz was unable to write for more than a few minutes a day and consequently produced fewer and fewer works. Subsequently, he lived under constant bodyguard protection. Finally, in the beginning of 2006, the novel was published in Egypt with a preface written by Ahmad Kamal Aboul-Magd. After the threats, Mahfouz stayed in Cairo with his lawyer, Nabil Mounir Habib. Mahfouz and Mounir would spend most of their time in Mounir's office; Mahfouz used Mounir's library as a reference for most of his books. Mahfouz stayed with Mounir until his death.\nPersonal life.\nMahfouz remained a bachelor until age 43 because he believed that, with its numerous restrictions and limitations, marriage would hamper his literary future. \"I was afraid of marriage . . . especially when I saw how busy my brothers and sisters were with social events because of it. This one went to visit people, that one invited people. I had the impression that married life would take up all my time. I saw myself drowning in visits and parties. No freedom.\"\nHowever, in 1954, he quietly married a Coptic Orthodox woman from Alexandria, Atiyyatallah Ibrahim, with whom he had two daughters, Fatima and Umm Kalthum. The couple initially lived on a houseboat in the Agouza section of Cairo on the west bank of the Nile, then moved to an apartment along the river in the same area. Mahfouz avoided public exposure, especially inquiries into his private life, which might have become, as he put it, \"a silly topic in journals and radio programs.\"\nMahfouz distinctly did not like to travel. Belgrade was one of the few cities to which he gladly went and he expressed great respect for Serbia.\nLegacy.\nMahfouz's legacy is considered a cornerstone of Modern Egyptian culture. His books are frequently republished, and the Cairo International Book Fair celebrated Mahfouz more than once. \nHis books continue to be adapted into films and TV series, both in Egypt and internationally, such as Mexican adaptation of Midaq Alley starring Salma Hayek in 1995, and Egyptian TV series Afrah AlQoba, Bayn El Samaa Wa El Ard and Hadith Alsabah wa Almassaa among others. \nIn 2019, Egyptian Ministry of Culture opened the Naguib Mahfouz museum located in Old Cairo near Wikala of al-Ghuri, Muzz Street and Azhar mosque, where most of Mahfouz novels take place. the museum has different artifacts from Mahfouz's life such as his hat, desk, photographs and his awards including his Nobel Medal.\nIn 2021, Egyptian actor Ahmed Helmy announced plans to star in a biographical Television series about Mahfouz's life, written by Abdelreheem Kamal.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "21996", "revid": "220894", "url": "https://en.wikipedia.org/wiki?curid=21996", "title": "Norddeutscher Bund", "text": ""}
{"id": "21999", "revid": "14703151", "url": "https://en.wikipedia.org/wiki?curid=21999", "title": "Nomenklatura", "text": "High bureaucrats/ruling class in Eastern Bloc countries\nThe nomenklatura (; from , system of names) were a category of people within the Soviet Union and other Eastern Bloc countries who held various key administrative positions in the bureaucracy, running all spheres of those countries' activity: government, industry, agriculture, education, etc., whose positions were granted only with approval by the communist party of each country or region. While in the Russian language the term \u043d\u043e\u043c\u0435\u043d\u043a\u043b\u0430\u0442\u0443\u0440\u0430 has the same generic meaning as \"nomenclature\", in the context of the politics of the Soviet Union it refers to the \"party and state nomenklatura\", lists of persons vetted for key management, or \"nomenklatura lists\".\nDescription.\nVirtually all members of the nomenklatura were members of a communist party. Critics of Stalin, such as Milovan Djilas, critically defined them as a \"new class\". Richard Pipes, a Harvard historian, claimed that the nomenklatura system mainly reflected a continuation of the old Tsarist regime, as many former Tsarist officials or \"careerists\" joined the Bolshevik government during and after the Russian Civil War of 1917\u20131922.\nThe \"nomenklatura\" formed a \"de facto\" elite of public powers in the former Eastern Bloc; one may compare them to the Western \"establishment\" holding or controlling both private and public powers (for example, in media, finance, trade, industry, the state and institutions).\nIndividuals with a nomenklatura background have continued to dominate economic and political life in Russia since the end of the Cold War. According to one 2022 estimate, 60% of elites in the Vladimir Putin administration had nomenklatura backgrounds.\nThe nomenklatura referred to the Communist Party's governance to make appointments to key positions throughout the governmental system, as well as throughout the party's own hierarchy. Specifically, the nomenklatura consisted of two separate lists: one was for key positions, appointments to which were made by authorities within the party; the other was for persons who were potential candidates for appointment to those positions. The Politburo, as part of its nomenklatura authority, maintained a list of ministerial and ambassadorial positions that it had the power to fill, as well as a separate list of potential candidates to occupy those positions.\nThe nomenklatura system arose early in Soviet history. Vladimir Lenin wrote that appointments were to take the following criteria into account: reliability, political attitude, qualifications, and administrative ability. Joseph Stalin, who was the first general secretary of the party, was also known as \"Comrade File Cabinet\" (Tovarishch Kartotekov) for his assiduous attention to the details of the party's appointments. Seeking to make appointments in a more systematic fashion, Stalin built the party's patronage system and used it to distribute his clients throughout the party bureaucracy.\nIn 1922, Lenin allied with Leon Trotsky against the party's growing bureaucratisation and the influence of Joseph Stalin. Under Stalin's direction in 1922, the party created departments of the Central Committee and other organs at lower levels that were responsible for the registration and appointment of party officials. Known as uchraspred, these organs supervised appointments to important party posts. According to American Sovietologist Seweryn Bialer, after Leonid Brezhnev's accession to power in October 1964, the party considerably expanded its appointment authority. However, in the late 1980s, some official statements indicated that the party intended to reduce its appointment authority, particularly in the area of economic management, in line with Mikhail Gorbachev's reform efforts.\nAt the all-union level, the Party Building and Cadre Work Department supervised party nomenklatura appointments. This department maintained records on party members throughout the country, made appointments to positions on the all-union level, and approved nomenklatura appointments on the lower levels of the hierarchy. The head of this department sometimes was a member of the Secretariat and was often a prot\u00e9g\u00e9 of the general secretary.\nEvery party committee and party organizational department, from the all-union level in Moscow to the district and city levels, prepared two lists according to their needs. The basic list (\"osnovnoi spisok\") detailed positions in the political, administrative, economic, military, cultural, and educational bureaucracies that the committee and its department had responsibility for filling. The registration list (\"uchyotny spisok\") enumerated the persons suitable for these positions.\n\"The New Class\".\nYugoslav politician Milovan \u0110ilas, a critic of Stalin, wrote of the nomenklatura as the \"new class\" in his book \"\", and he claimed that it was seen by ordinary citizens as a bureaucratic elite that enjoyed special privileges and had supplanted the earlier wealthy capitalist elites.\nChina's nomenklatura.\nChina adopted the \"nomenklatura\" system from the Soviet Union in the 1960s and is still using this system of governance to this day. According to scholar Hon Chan, it establishes China's \"party and governmental leadership\" and is a \"key instrument of Communist Party control.\" For China, it is not just the party that \"nomenklatura\" has control over but \"the government, judicial system, schools, and universities, enterprises, research establishments, religious organizations, museums, libraries, hospitals\" are all things that fall under the domain as well. Despite there being \"elected\" officials, \"\"all\" positions of real importance fall under the CCP\u2019s \"nomenklatura\".\" The cadres higher up on the political ladder were able to control those under them. John Burns, a scholar of China's Nomenklatura, highlights the different classes inside the party. Level \"A\" is the highest level of cadres, including heads of party central departments. Level \"B\" consisted of the lesser ranked officials. In 1983 a plan was presented to decentralize the control that personnel management had. The authorities suggested to halve the number of cadres from 13,000 to 7,000. The Central Committee, who previously had control over the majority of posts, was drastically reduced in its areas of management. It had previously controlled all high-level appointments and ensured party control over critical positions in government. The aim of this reform was to redistribute power to the lower levels and to make personnel management more efficient. Since 1984, the Central Committee's control over appointments has been divided into two lists:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22000", "revid": "5435919", "url": "https://en.wikipedia.org/wiki?curid=22000", "title": "Neural Darwinism", "text": "Theory in neurology\nNeural Darwinism is a biological, and more specifically Darwinian and selectionist, approach to understanding global brain function, originally proposed by American biologist, researcher and Nobel-Prize recipient Gerald Maurice Edelman (July 1, 1929 \u2013 May 17, 2014). Edelman's 1987 book \"Neural Darwinism\" introduced the public to the \"theory of neuronal group selection\" (TNGS), a theory that attempts to explain global brain function.\nTNGS (also referred to as the \"theory of neural Darwinism\") has roots going back to Edelman and Mountcastle's 1978 book, \"The Mindful Brain \u2013 Cortical Organization and the Group-selective Theory of Higher Brain Function,\" which describes the columnar structure of the cortical groups within the neocortex, and argues for selective processes operating among degenerate primary repertoires of neuronal groups. The development of neural Darwinism was deeply influenced by work in the fields of immunology, embryology, and neuroscience, as well as Edelman's methodological commitment to the idea of selection as the unifying foundation of the biological sciences.\nIntroduction to neural Darwinism.\nNeural Darwinism is really the neural part of the natural philosophical and explanatory framework Edelman employs for much of his work \u2013 Somatic selective systems. Neural Darwinism is the backdrop for a comprehensive set of biological hypotheses and theories Edelman, and his team, devised that seek to reconcile vertebrate and mammalian neural morphology, the facts of developmental and evolutionary biology, and the theory of natural selection into a detailed model of real-time neural and cognitive function that is biological in its orientation. It is built from the bottom-up utilizing the variation that shows up in nature. This is in contrast to computational and algorithmic approaches that view variation as noise in a system of logic circuits with point-to-point connectivity.\nThe book, \"Neural Darwinism \u2013 The Theory of Neuronal Group Selection\" (1987), is the first in a trilogy of books that Edelman wrote to delineate the scope and breadth of his ideas on how a biological theory of consciousness and animal body plan evolution could be developed in a bottom-up fashion. In accordance with principles of population biology and Darwin's theory of natural selection \u2013 as opposed to the top-down algorithmic and computational approaches that dominated a nascent cognitive psychology at the time.\nThe other two volumes are \"Topobiology \u2013 An Introduction to Molecular Embryology\" (1988) with its morpho-regulatory hypothesis of animal body plan development and evolutionary diversification via differential expression of cell surface molecules during development; and \"The Remembered Present \u2013 A Biological Theory of Consciousness\" (1989) \u2013 a novel biological approach to understanding the role and function of \"consciousness\" and its relation to cognition and behavioral physiology.\nEdelman would write four more books for the general lay public, explaining his ideas surrounding how the brain works and consciousness arises from the physical organization of the brain and body \u2013 \"Bright Air, Brilliant Fire \u2013 On the Matter of the Mind\" (1992), \"A Universe of Consciousness \u2013 How Matter Becomes Imagination\" (2000) with Giulio Tononi, \"Wider Than The Sky \u2013 The Phenomenal Gift of Consciousness\" (2004), and \"Second Nature \u2013 Brain Science and Human Knowledge\" (2006).\nNeural Darwinism is an exploration of biological thought and philosophy as well as fundamental science; Edelman being well-versed in the history of science, natural philosophy &amp; medicine, as well as robotics, cybernetics, computing &amp; artificial intelligence. In the course of laying out the case for neural Darwinism, or more properly TNGS, Edelman delineates a set of concepts for rethinking the problem of nervous system organization and function \u2013 all-the-while, demanding a rigorously scientific criteria for building the foundation of a properly Darwinian, and therefore biological, explanation of neural function, perception, cognition, and global brain function capable of supporting primary and higher-order consciousness.\nPopulation thinking \u2013 somatic selective systems.\nEdelman was inspired by the successes of fellow Nobel laureate Frank MacFarlane Burnet and his clonal selection theory (CST) of acquired antigen immunity by differential amplification of pre-existing variation within the finite pool of lymphocytes in the immune system. The population of variant lymphocytes within the body mirrored the variant populations of organisms in the ecology. Pre-existing diversity is the engine of adaption in the evolution of populations.\n\"It is clear from both evolutionary and immunological theory that in facing an unknown future, the fundamental requirement for successful adaption is preexisting diversity\". \u2013 Gerald M. Edelman (1978)\nEdelman recognizes the explanatory range of Burnet's utilization of Darwinian principles in describing the operations of the immune system - and, generalizes the process to all cell populations of the organism. He also comes to view the problem as one of recognition and memory from a biological perspective, where the distinction and preservation of self vs. non-self is vital to organismal integrity.\nNeural Darwinism, as TNGS, is a theory of neuronal group selection that retools the fundamental concepts of Darwin and Burnet's theoretical approach. Neural Darwinism describes the development and evolution of the mammalian brain and its functioning by extending the Darwinian paradigm into the body and nervous system.\nAntibodies and NCAM \u2013 the emerging understanding of somatic selective systems.\nEdelman was a medical researcher, physical chemist, immunologist, and aspiring neuroscientist when he was awarded the 1972 Nobel Prize in Physiology or Medicine (shared with Rodney Porter of Great Britain). Edelman's part of the prize was for his work revealing the chemical structure of the vertebrate antibody by cleaving the covalent disulfide bridges that join the component chain fragments together, revealing a pair of two-domain light chains and four-domain heavy chains. Subsequent analysis revealed the terminal domains of both chains to be variable domains responsible for antigen recognition.\nThe work of Porter and Edelman revealed the molecular and genetic foundations underpinning how antibody diversity was generated within the immune system. Their work supported earlier ideas about pre-existing diversity in the immune system put forward by the pioneering Danish immunologist Niels K. Jerne (December 23, 1911 \u2013 October 7, 1994); as well as supporting the work of Frank MacFarlane Burnet describing how lymphocytes capable of binding to specific foreign antigens are differentially amplified by clonal multiplication of the selected preexisting variants following antigen discovery.\nEdelman would draw inspiration from the mechano-chemical aspects of antigen/antibody/lymphocyte interaction in relation to recognition of self-nonself; the degenerate population of lymphocytes in their physiological context; and the bio-theoretical foundations of this work in Darwinian terms.\nBy 1974, Edelman felt that immunology was firmly established on solid theoretical grounds descriptively, was ready for quantitative experimentation, and could be an ideal model for exploring evolutionary selection processes within an observable time period.\nHis studies of immune system interactions developed in him an awareness of the importance of the cell surface and the membrane-embedded molecular mechanisms of interactions with other cells and substrates. Edelman would go on to develop his ideas of topobiology around these mechanisms \u2013 and, their genetic and epigenetic regulation under the environmental conditions.\nDuring a foray into molecular embryology and neuroscience, in 1975, Edelman and his team went on to isolate the first neural cell-adhesion molecule (N-CAM), one of the many molecules that hold the animal nervous system together. N-CAM turned out to be an important molecule in guiding the development and differentiation of neuronal groups in the nervous system and brain during embryogenesis. To the amazement of Edelman, genetic sequencing revealed that N-CAM was the ancestor of the vertebrate antibody produced in the aftermath of a set of whole genome duplication events at the origin of vertebrates that gave rise to the entire super-family of immunoglobulin genes.\nEdelman reasoned that the N-CAM molecule which is used for self-self recognition and adherence between neurons in the nervous system gave rise to their evolutionary descendants, the antibodies, who evolved self-nonself recognition via antigen-adherence at the origins of the vertebrate antibody-based immune system. If clonal selection was the way the immune system worked, perhaps it was ancestral and more general \u2013 and, operating in the embryo and nervous system.\nVariation in biological systems \u2013 degeneracy, complexity, robustness, and evolvability.\nDegeneracy, and its relationship to variation, is a key concept in neural Darwinism. The more we deviate from an ideal form, the more we are tempted to describe the deviations as imperfections. Edelman, on the other hand, explicitly acknowledges the structural and dynamic variability of the nervous system. He likes to contrast the differences between redundancy in an engineered system and degeneracy in a biological system. He proceeds to demonstrate how the \"noise\" of the computational and algorithmic approach is actually beneficial to a somatic selective system by providing a wide, and degenerate, array of potential recognition elements.\nEdelman's argument is that in an engineered system,\nTo insure the robustness of the solution, critical components are replicated as exact copies. Redundancy provides a fail-safe backup in the event of catastrophic failure of an essential component but it is the same response to the same problem once the substitution has been made.\nIf the problem is predictable and known ahead of time, redundancy works optimally. But biological systems face an open and unpredictable arena of spacetime events of which they have no foreknowledge of. In this arena, redundancy fails - a response might be designed to the wrong problem.\nVariation fuels degeneracy; degeneracy provides somatic selective systems with more than one way to solve a problem and the propensity to reuse a solution on other problems. This property of degeneracy makes the system more adaptively robust in the face of unforeseen contingencies: When one particular solution fails unexpectedly, there are other unaffected pathways that can be engaged in pursuit of the same end. Early on, Edelman spends considerable time contrasting degeneracy vs. redundancy, bottom-up vs. top-down processes, and selectionist vs. instructionist explanations of biological phenomena.\nRejection of computational models, codes, and point-to-point wiring.\nEdelman was well aware of the earlier debate in immunology between the instructionists, who believed the lymphocytes of the immune system learned or was instructed about the antigen and then devised a response; and the selectionists, who believed that the lymphocytes already contained the response to the antigen within the existing population that was differentially amplified within the population upon contact with the antigen. And, he was well aware that the selectionist had the evidence on their side.\nEdelman's theoretical approach in \"Neural Darwinism\" was conceived of in opposition to top-down algorithmic, computational, and instructionist approaches to explaining neural function. Edelman seeks to turn the problems of that paradigm to advantage instead; thereby highlighting the difference between bottom-up processes like we see in biology vis a vis top-down processes like we see in engineering algorithms. He sees neurons as living organisms working in cooperative and competitive ways within their local ecology and rejects models that see the brain in terms of computer chips or logic gates in an algorithmically organized machine.\nEdelman's commitment to the Darwinian underpinnings of biology, his emerging understanding of the evolutionary relationships between the two molecules he had worked with, and his background in immunology lead him to become increasingly critical and dissatisfied with attempts to describe the operation of the nervous system and brain in computational or algorithmic terms.\nEdelman explicitly rejects computational approaches to explaining biology as non-biological. Edelman acknowledges that there is a conservation of phylogenetic organization and structure within the vertebrate nervous system, but also points out that locally natural diversity, variation and degeneracy abound. This variation within the nervous system is disruptive for theories based upon strict point-to-point connectivity, computation, or logical circuits based upon codes. Attempts to understand this \"noise\" present difficulties for top-down algorithmic approaches \u2013 and, deny the fundamental facts of the \"biological\" nature of the problem.\nEdelman perceived that the problematic and annoying noise of the computational circuit-logic paradigm could be reinterpreted from a population biology perspective \u2013 where that variation in the signal or architecture was actually the engine of ingenuity and robustness from a selectionist perspective.\nCompleting Darwin's program \u2013 the problems of evolutionary and developmental morphology.\nIn \"Topobiology\", Edelman reflects upon Darwin's search for the connections between morphology and embryology in his theory of natural selection. He identifies four unresolved problems in the development and evolution of morphology that Darwin thought important:\nLater, In \"Bright Air, Brilliant Fire\", Edelman describes what he calls Darwin's Program for obtaining a complete understanding of the rules of behavior and form in evolutionary biology. He identifies four necessary requirements:\nIt is important to notice that these requirements are not directly stated in terms of genes, but heredity instead. This is understandable considering that Darwin himself appears to not be directly aware of the importance Mendelian genetics. Things had changed by the early 1900s, the Neodarwinian synthesis had unified the population biology of Mendelian inheritance with Darwinian natural selection. By the 1940s, the theories had been shown to be mutually consistent and coherent with paleontology and comparative morphology. The theory came to be known as the \"modern synthesis\" on the basis of the title of the 1942 book \"Evolution: The Modern Synthesis\" by Julian Huxley.\nThe modern synthesis really took off with the discovery of the structural basis of heredity in the form of DNA. The modern synthesis was greatly accelerated and expanded with the rise of the genomic sciences, molecular biology, as well as, advances in computational techniques and the power to model population dynamics. But, for evolutionary-developmental biologists, there was something very important missing... \u2013 and, that was the incorporation of one of the founding branches of biology, embryology. A clear understanding of the pathway from germ to zygote to embryo to juvenile and adult was the missing component of the synthesis. Edelman, and his team, were positioned in time and space to fully capitalize on these technical developments and scientific challenges \u2013 as his research progressed deeper and deeper into the cellular and molecular underpinnings of the neurophysiological aspects of behavior and cognition from a Darwinian perspective.\nEdelman reinterprets the goals of \"Darwin's program\" in terms of the modern understanding about genes, molecular biology, and other sciences that weren't available to Darwin. One of his goals is reconciling the relationships between genes in a population (genome) which lie in the germ line (sperm, egg, and fertilized egg); and the individuals in a population who develop degenerate phenotypes (soma) as they transform from an embryo into an adult who will eventually procreate if adaptive. Selection acts on phenotypes (soma), but evolution occurs within the species genome (germ).\nEdelman follows the work of the highly influential American geneticist and evolutionary biologist Richard Lewontin (March 29, 1929 \u2013 July 4, 2021), drawing particular inspiration from his 1974 book, \"The Genetic Basis of Evolutionary Change\". Edelman, like Lewontin, seeks a complete description of the transformations (T) that take us from:\nLewontin's exploration of these transformations between genomic and phenotypic spaces was in terms of key selection pressures that sculpt the organism over geological evolutionary time scales; but, Edelmans approach is more mechanical, and in the here and now \u2013 focusing on the genetically constrained mechano-chemistry of the selection processes that guide epigenetic behaviors on the part of cells within the embryo and adult over developmental time.\nMechano-chemistry, mesenchyme, and epithelia \u2013 CAMs &amp; SAMs in morphoregulatory spacetime.\nEdelman's isolation of NCAM lead him to theorize on the role of cell adhesion molecules (CAMs) and substrate adhesion molecules (SAMs) in the formation of the animal bodyplan in both realtime and over evolutionary time. Topobiology is primarily dedicated to this issue that is foundational to the understanding of neural Darwinism and the formation of the primary repertoire of TNGS.\nIn his \"regulator hypothesis\", Edelman hypothesizes about the role of cell surface molecules in embryogenesis and how shifting expression of these molecules in time and place within the embryo can guide the development of pattern. Later, he will expand the hypothesis into the \"morpho-regulatory hypothesis.\" He describes the embryonic cell populations as either organized as mesenchyme or epetheilia.\nEdelman characterizes the two population types as follows:\nHe envisages a CAM, and SAM, driven cycle where cell populations transform back and forth between mesenchyme and epithelia via epithelial-mesenchymal transformations, as the development of the embryo proceeds through to the fetal stage. The expression of the CAMs and SAMs is under genetic control, but the distribution of these molecules on the cell membrane and extracellular matrix is historically contingent upon epigenetic events, serving as one of the primary bases for generating pre-existing diversity within the nervous system and other tissues.\nThe developmental genetic question.\nThere are many developmental questions to be considered, but Edelman is able to succinctly summarize the problem in a way that will show a clear explanatory path forward for him. The \"developmental genetic question\" defines the problem \u2013 and, the theoretical approach for him.\n\"How does a one-dimensional genetic code specify a three-dimensional animal?\" \u2013 Gerald M. Edelman, from the glossary of \"Topobiology\"\nBy 1984, Edelman would be ready to answer this question and combine it with his earlier ideas on degeneracy and somatic selection in the nervous system. Edelman would revisit this issue in \"Topobiology\" and combine it with an evolutionary approach, seeking a comprehensive theory of body plan formation and evolution.\nThe regulator hypothesis.\nIn 1984, Edelman published his \"regulator hypothesis\" of CAM and SAM action in the development and evolution of the animal body plan.\nEdelman would reiterate this hypothesis in his \"Neural Darwinism\" book in support of the mechanisms for degenerate neuronal group formation in the primary repertoire. The regulator hypothesis was primarily concerned with the action of CAMs. He would later expand the hypothesis in \"Topobiology\" to include a much more diverse and inclusive set of morphoregulatory molecules.\nThe evolutionary question.\nEdelman realized that in order to truly complete Darwin's program, he would need to link the developmental question to the larger issues of evolutionary biology.\n\"How is an answer to the developmental genetic question (q.v.) reconciled with the relatively rapid changes in form occurring in relatively short evolutionary times?\" \u2013 Gerald M. Edelman, from the glossary of \"Topobiology\"\nThe morphoregulator hypothesis.\nShortly after publishing his \"regulator hypothesis\", Edelman expanded his vision of pattern formation during embryogenesis - and, sought to link it to a broader evolutionary framework. His first and foremost goal is to answer the \"developmental genetic question\" followed by the \"evolutionary question\" in a clear, consistent, and coherent manner.\nTNGS \u2013 the theory of neuronal group selection.\nEdelman's motivation for developing the theory of neuronal group selection (TNGS) was to resolve \"a number of apparent inconsistencies in our knowledge of the development, anatomy, and physiological function of the central nervous system.\" A pressing issue for Edelman was explaining perceptual categorization without reference to a central observing \"homunculus\" or \"assuming that the world is prearranged in an informational fashion.\"\nTo free himself of the demands, requirements, and contradictions of information processing model; Edelman proposes that perceptual categorization operates by the selection of neuronal groups organized into variant networks that are differentially amplified of their responses in conjunction with hedonic feedback over the course of experience, from within a massive population of neuronal groups being confronted by a chaotic array of sensory input of differing degrees of significance and relevance to the organism.\nEdelman outright rejects the notion of a \"homunculus\", describing it as a \"close cousin of the developmental electrician and the neural decoder\", artifacts of the observer-centralized top-down design logic of information processing approaches. Edelman properly points out that \"it is probably a safe guess that most neurobiologists would view the homunculus as well as dualist solutions (Popper and Eccles 1981) to the problems of subjective report as being beyond scientific consideration.\"\nNecessary criteria for a selectionist theory of higher brain function.\nEdelman's first theoretical contribution to neural Darwinism came in 1978, when he proposed his \"group selection and phasic reentrant signalling\". Edelman lays out five necessary requirements that a biological theory of higher brain function must satisfy.\nOrganization of the TNGS theory.\n\"Neural Darwinism\" organizes the explanation of TNGS into three parts \u2013 somatic selection, epigenetic mechanisms, and global functions. The first two parts are concerned with how variation emerges through the interaction of genetic and epigenetic events at the cellular level in response to events occurring at the level of the developing animal nervous system. The third part attempts to build a temporally coherent model of globally unitary cognitive function and behavior that emerges from the bottom up through the interactions of the neuronal groups in real-time.\nEdelman organized key ideas of the TNGS theory into three main tenets:\nThe primary repertoire is formed during the period from the beginning of neurulation to the end of apoptosis. The secondary repertoire extends over the period synaptogenesis and myelination, but will continue to demonstrate developmental plasticity throughout life, albeit in a diminished fashion compared to early development.\nThe two repertoires deal with the issue of the relationship between genetic and epigenetic processes in determining the overall architecture of the neuroanatomy \u2013 seeking to reconcile nature, nurture, and variability in the forming the final phenotype of any individual nervous system.\nThere is no point-to-point wiring that carries a neural code through a computational logic circuit that delivers the result to the brain because\nVariation is the inevitable outcome of developmental dynamics.\nReentrant signalling is an attempt to explain how \"coherent temporal correlations of the responses of sensory receptor sheets, motor ensembles, and interacting neuronal groups in different brain regions occur\".\nPrimary repertoire- developmental selection.\nThe first tenet of TNGS concerns events that are embryonic and run up to the neonatal period. This part of the theory attempts to account for the unique anatomical diversification of the brain even between genetically identical individuals. The first tenet proposes the development of a primary repertoire of degenerate neuronal groups with diverse anatomical connections are established via the historical contingencies of the primary processes of development. It seeks to provide an explanation of how the diversity of neuronal group phenotypes emerge from the organism's genotype via genetic and epigenetic influences that manifest themselves mechano-chemically at the cell surface and determine connectivity.\nEdelman list the following as vital to the formation of the primary repertoire of neuronal groups but, also contributing to their anatomical diversification and variation:\nTwo key questions with respect to this issue that Edelman is seeking to answer \"in terms of developmental genetic and epigenetic events\" are:\nSecondary repertoire \u2013 experiential selection.\nThe second tenet of TNGS regards postnatal events that govern the development of a secondary repertoire of synaptic connectivity between higher-order populations of neuronal groups whose formation is driven by behavioral or experiential selection acting on synaptic populations within and between neuronal groups. Edelman's notion of the secondary repertoire heavily borrows from work of Jean-Pierre Changeux, and his associates Philippe Courr\u00e8ge and Antoine Danchin \u2013 and, their theory of selective stabilization of synapses.\nSynaptic modification.\nOnce the basic variegated anatomical structure of the primary repertoire of neuronal groups is laid down, it is more or less fixed. But given the numerous and diverse collection of neuronal group networks, there are bound to be functionally equivalent albeit anatomically non-isomorphic neuronal groups and networks capable of responding to certain sensory input. This creates a competitive environment where neuronal groups proficient in their responses to certain inputs are \"differentially amplified\" through the enhancement of the synaptic efficacies of the selected neuronal group network. This leads to an increased probability that the same network will respond to similar or identical signals at a future time. This occurs through the strengthening of neuron-to-neuron synapses. These adjustments allow for neural plasticity along a fairly quick timetable.\nReentry.\nThe third, and final, tenet of TNGS is reentry. Reentrant signalling \"is based on the existence of reciprocally connected neural maps.\" These topobiological maps maintain and coordinate the real-time responses of multiple responding secondary repertoire networks, both unimodal and multimodal \u2013 and their reciprocal reentrant connections allow them to \"maintain and sustain the spatiotemporal continuity in response to real-world signals.\"\nThe last part of the theory attempts to explain how we experience spatiotemporal consistency in our interaction with environmental stimuli. Edelman called it \"reentry\" and proposes a model of reentrant signaling whereby a disjunctive, multimodal sampling of the same stimulus event correlated in time that make possible sustained physiological entrainment of distributed neuronal groups into temporally stable global behavioral units of action or perception. Put another way, multiple neuronal groups can be used to sample a given stimulus set in parallel and communicate between these disjunctive groups with incurred latency.\nThe extended theory of neuronal group selection \u2013 the dynamic core hypothesis.\nIn the aftermath of his publication of \"Neural Darwinism\", Edelman continued to develop and extend his TNGS theory as well as his regulator hypothesis. Edelman would deal with the morphological issues in \"Topobiology\" and begin to extend the TNGS theory in \"The Remembered Present\". Periodically over the intervening years, Edelman would release a new update on his theory and the progress made.\nIn \"The Remembered Present\", Edelman would observe that the mammalian central nervous system seemed to have two distinct morphologically organized systems \u2013 one the limbic-brain stem system which is primarily dedicated to \"appetitive, consumatory, and defensive behavior\"; The other system is the highly reentrant thalamocortical system, consisting of the thalamus along with the \"primary and secondary sensory areas and association cortex\" which are \"linked strongly to exteroceptors and is closely and extensively mapped in a polymodal fashion.\"\nThe limbic-brain stem system \u2013 the interior world of signals.\nThe neural anatomy of the hedonic feedback system resides in the brain stem, autonomic, endocrine, and limbic systems. This system communicates its evaluation of the visceral state to the rest of the central nervous system. Edelman calls this system the \"limbic-brain stem system\".\nThe thalamocortical system - the exterior world of signals.\nThe thalamus is the gateway to the neocortex for all senses except olfactory. The spinothalamic tracts bring sensory information from the periphery to the thalamus, where multimodal sensory information is integrated and triggers the fast response subcortical reflexive motor responses via the amygdala, basal ganglia, hypothalamus and brainstem centers. Simultaneously, each sensory modality is also being sent to the cortex in parallel, for higher-order reflective analysis, multimodal sensorimotor association, and the engagement of the slow modulatory response that will fine-tune the subcortical reflexes.\nThe cortical appendages \u2013 the organs of succession.\nIn \"The Remembered Present\", Edelman acknowledges the limits of his TNGS theory to model the temporal succession dynamics of motor behavior and memory. His early attempts at replication automata proved inadequate to the task of explaining the realtime sequencing and integration of the neuronal group interactions with other systems of the organism. \"Neither the original theory nor simulated recognition automata deal in satisfactory detail with the successive ordering of events in time mediated by the several major brain components that contribute to memory, particularly as it relates to consciousness.\" This problem lead him to focus on what he called the organs of succession; the cerebellum, basal ganglia, and hippocampus.\nReception.\nAn early review of the book \"Neural Darwinism\" in \"The New York Review of Books\" by Israel Rosenfield invited a lively response on the part of the neurosciences community. Edelman's views would be seen as an attack on the dominant paradigm of computational algorithms in cognitive psychology and computational neuroscience \u2013 inviting criticism from many corners.\nThere would be copious complaints about the language difficulty. Some would see Edelman coming across as arrogant, or an interloper into the field of neuroscience, from neighboring molecular biology. There were legitimate arguments raised as to how much experimental and observational data had been gathered in support of the theory at that time. Or, if the theory was even original or not.\nBut more often, rather than dealing with Edelman's critique of computational approaches, the criticism would be centered around whether Edelman's system was a truly proper Darwinian explanation. Nonetheless, \"Neural Darwinism\", both the book and the concept, received fairly broad critical acclaim.\nOne of the most famous critiques of \"Neural Darwinism\" would be the 1989 critical review by Francis Crick, \"Neural Edelmanism\". Francis Crick based his criticism on the basis that neuronal groups are instructed by the environment rather than undergoing blind variation. In 1988, the neurophysiologist William Calvin had proposed true replication in the brain, whereas Edelman opposed the idea of true replicators in the brain. Stephen Smoliar published another review in 1989.\nEngland, and its neuroscience community, would have to rely on bootleg copies of the book until 1990, but once the book arrived on English shores, the British social commentator and neuroscientist Steven Rose was quick to offer both praise and criticism of its ideas, writing style, presumptions and conclusions. The \"New York Times\" writer George Johnson published \"Evolution Between the Ears\", a critical review of Gerald Edelman's 1992 book \"Brilliant Air, Brilliant Fire\". In 2014, John Horgan wrote to Gerald Edelman in \"Scientific American\", highlighting both his arrogance, brilliance, and idiosyncratic approach to science.\nIt has been suggested by Chase Herrmann-Pillath that Friedrich Hayek had earlier proposed a similar idea in his book \"The Sensory Order: An Inquiry into the Foundations of Theoretical Psychology\", published in 1952. Other leading proponents of a selectionist proposals include Jean-Pierre Changeux (1973, 1985), Daniel Dennett, and Linda B. Smith. Reviews of Edelman's work would continue to be published as his ideas spread.\nA recent review by Fernando, Szathmary and Husbands explains why Edelman's neural Darwinism is not Darwinian because it does not contain units of evolution as defined by John Maynard Smith. It is selectionist in that it satisfies the Price equation, but there is no mechanism in Edelman's theory that explains how information can be transferred between neuronal groups. A recent theory called \"evolutionary neurodynamics\" being developed by Eors Szathmary and Chrisantha Fernando has proposed several means by which true replication may take place in the brain.\nThese neuronal models have been extended by Fernando in a later paper. In the most recent model, three plasticity mechanisms i) multiplicative STDP, ii) LTD, and iii) Heterosynaptic competition, are responsible for copying of connectivity patterns from one part of the brain to another. Exactly the same plasticity rules can explain experimental data for how infants do causal learning in the experiments conducted by Alison Gopnik. It has also been shown that by adding Hebbian learning to neuronal replicators the power of neuronal evolutionary computation may actually be greater than natural selection in organisms.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22003", "revid": "8125662", "url": "https://en.wikipedia.org/wiki?curid=22003", "title": "Neil Peart", "text": "Canadian and American drummer (1952\u20132020)\nNeil Ellwood Peart ( ; September 12, 1952 \u2013 January 7, 2020) was a Canadian and American musician and author, known as the drummer, percussionist, and primary lyricist of the rock band Rush. He was known to fans by the nickname \"the Professor\", derived from the \"Gilligan's Island\" character of the same name. His drumming was renowned for its technical proficiency and his live performances for their exacting nature and stamina. Peart earned numerous awards for his musical performances, including an induction into the \"Modern Drummer\" Readers Poll Hall of Fame in 1983 at the age of 30, making him the youngest person ever so honoured.\nPeart was born in Hamilton, Ontario, and grew up in Port Dalhousie (now part of St. Catharines). During adolescence, he floated between regional bands in pursuit of a career as a full-time drummer. After a discouraging stint in England, Peart returned home to concentrate on music where he joined Rush, a Toronto band, in mid-1974, six years after its formation. Together they released 19 studio albums, with 10 exceeding a million copies sold in the United States. \"Billboard\" lists the band third in \"most consecutive gold or platinum albums by a rock band\".\nEarly in his career, Peart's performance style was deeply rooted in hard rock. He drew most of his inspiration from drummers such as Keith Moon, Ginger Baker and John Bonham, players who at the time were at the forefront of the British hard rock scene. As time passed, he began to emulate jazz and big band musicians Gene Krupa and Buddy Rich. In 1994, Peart became a friend and pupil of jazz instructor Freddie Gruber. It was during this time that Peart revamped his playing style by incorporating jazz and swing components.\nIn addition to serving as Rush's primary lyricist, Peart published several memoirs about his travels. His lyrics for Rush addressed universal themes and diverse subjects including science fiction, fantasy, and philosophy, as well as secular, humanitarian, and libertarian themes. Peart wrote a total of seven non-fiction books focused on his travels and personal stories. He also co-authored with Kevin J. Anderson three steampunk fantasy novels based on Rush's final album, \"Clockwork Angels\". The two also wrote a dark fantasy novella, \"Drumbeats\", inspired by Peart's travels in Africa.\nPeart announced his retirement from touring in an interview with \"Drumhead Magazine\" in December 2015. In January 2018, bandmate Alex Lifeson confirmed that Rush had disbanded also due to Peart's health issues. During his last years Peart lived in Santa Monica, California, with his wife, Carrie Nuttall, and daughter. After a three-and-a-half-year illness, Peart died of glioblastoma on January 7, 2020, at age 67.\nBiography.\nEarly childhood.\nPeart was born on September 12, 1952, to Glen and Betty Peart and lived his early years on his family's farm in Hagersville, Ontario, on the outskirts of Hamilton. The first child of four, his brother Danny and sisters Judy and Nancy were born after the family moved to St. Catharines when Peart was two years old. At this time his father became parts manager for Dalziel Equipment, an International Harvester farm machinery dealer. In 1956 the family moved to the Port Dalhousie area of the town. Peart attended Gracefield School and later Lakeport Secondary School, and described his childhood as happy; he stated he experienced a warm family life. By early adolescence he became interested in music and acquired a transistor radio, which he would use to tune into popular music stations broadcasting from Toronto, Hamilton, Welland, and Buffalo.\nPeart's first exposure to musical training came in the form of piano lessons; he later said in his instructional video \"A Work in Progress\" that these lessons did not have much influence on him. He had a penchant for drumming on various objects around the house with a pair of chopsticks, so for his 13th birthday his parents bought him a pair of drum sticks, a practice drum, and some lessons, with the promise that if he stuck with it for a year they would buy him a kit.\nPeart fulfilled his promise and his parents bought him a drum kit for his 14th birthday; furthermore, he began taking lessons from Don George at the Peninsula Conservatory of Music. His stage debut took place that year at the school's Christmas pageant in St. John's Anglican Church Hall in Port Dalhousie. His next appearance was at Lakeport High School with his first group, The Eternal Triangle. This performance contained an original number titled \"LSD Forever\". At this show he performed his first solo.\nPeart got a job in Lakeside Park, in Port Dalhousie on the shores of Lake Ontario, which later inspired a song of the same name on the Rush album \"Caress of Steel\". He worked on the Bubble Game and Ball Toss, but his tendency to take it easy when business was slack resulted in his termination. By his late teens, Peart had played in local bands such as Mumblin' Sumpthin', and the Majority. These bands practiced in basement recreation rooms and garages and played church halls, high schools, and skating rinks in towns across Southern Ontario such as Mitchell, Seaforth, and Elmira. They also played in the Northern Ontario city of Timmins. Tuesday nights were filled with jam sessions at the Niagara Theatre Centre.\nEarly career.\nAt 18 years old (and after struggling to achieve success as a drummer in Canada), Peart travelled to London, England, hoping to further his career as a professional musician. Despite playing in several bands and picking up occasional session work, he was forced to support himself by selling jewellery at a shop called The Great Frog on Carnaby Street.\nWhile in London, he came across the writings of novelist and philosopher Ayn Rand. Rand's writings became a significant early philosophical influence on Peart, as he found many of her writings on individualism and Objectivism inspiring. References to Rand's philosophy can be found in his early lyrics, most notably \"Anthem\" from 1975's \"Fly by Night\" and \"2112\" from 1976's \"2112\".\nAfter 18 months, Peart became disillusioned by his lack of progress in the music business; he placed his aspiration of becoming a professional musician on hold and returned to Canada. Upon returning to St. Catharines, he worked for his father selling tractor parts at Dalziel Equipment.\nJoining Rush.\nAfter returning to Canada, Peart was recruited to play drums for a St. Catharines band known as Hush, who played on the Southern Ontario bar circuit. Soon after, a mutual acquaintance convinced Peart to audition for the Toronto-based band Rush, which needed a replacement for its original drummer John Rutsey. Geddy Lee and Alex Lifeson oversaw the audition. His future bandmates describe his arrival that day as somewhat humorous, as he arrived in shorts, driving a battered old Ford Pinto with his drums stored in trashbags. Peart felt the entire audition was a complete disaster. Lee later remarked that he was instantly mesmerized by the way Peart played triplets, also hitting it off on a personal level (with similar tastes in books and music); meanwhile, Lifeson had a less favourable impression of Peart and still wanted to tryout one last drummer.\nAfter some discussion between Lee and Lifeson, Peart officially joined the band on July 29, 1974, two weeks before the group's first US tour. Peart procured a silver Slingerland kit which he played at his first gig with the band, opening for Uriah Heep and Manfred Mann's Earth Band in front of over 11,000 people at the Civic Arena in Pittsburgh on August 14, 1974.\nPeart soon settled into his new position, also becoming the band's primary lyricist. Before joining Rush he had written a few songs, but, with the other members largely uninterested in writing lyrics, Peart's previously underutilised writing became as noticed as his musicianship. The band were working hard to establish themselves as a recording act, and Peart, along with the rest of the band, began to undertake extensive touring.\nHis first recording with the band, 1975's \"Fly by Night\", was fairly successful, winning the Juno Award for most promising new act, but the follow-up, \"Caress of Steel\", for which the band had high hopes, was greeted with hostility by both fans and critics. In response to this negative reception, most of which was aimed at the B-side-spanning epic \"The Fountain of Lamneth\", Peart responded by penning \"2112\" on their next album of the same name in 1976. The album, despite record company indifference, became their breakthrough and gained a following in the United States. The supporting tour culminated in a three-night stand at Massey Hall in Toronto, a venue Peart had dreamed of playing in his days on the Southern Ontario bar circuit and where he was introduced as \"The Professor on the drum kit\" by Lee.\nPeart returned to England for Rush's Northern European Tour and the band stayed in the United Kingdom to record the next album, 1977's \"A Farewell to Kings\", in Rockfield Studios in Wales. They returned to Rockfield to record the follow-up, \"Hemispheres\", in 1978, which they wrote entirely in the studio. The recording of five studio albums in four years, coupled with as many as 300 gigs a year, convinced the band to take a different approach thereafter. Peart has described his time in the band up to this point as \"a dark tunnel\".\nPlaying style reinvention.\nIn 1991, Peart was invited by Buddy Rich's daughter, Cathy Rich, to play at the Buddy Rich Memorial Scholarship Concert in New York City. Peart accepted and performed for the first time with the Buddy Rich Big Band. Peart remarked that he had little time to rehearse, and noted that he was embarrassed to find the band played a different arrangement of the song than the one he had learned. Feeling that his performance left much to be desired, Peart produced and played on two Buddy Rich tribute albums titled \"\" in 1994 and 1997 in order to regain his aplomb.\nWhile producing the first Buddy Rich tribute album, Peart was struck by the tremendous improvement in ex-Journey drummer Steve Smith's playing, and asked him his \"secret\". Smith responded he had been studying with drum teacher Freddie Gruber.\nIn early 2007, Peart and Cathy Rich discussed another Buddy tribute concert. At the recommendation of bassist Jeff Berlin, Peart once again augmented his swing style with formal drum lessons, this time under the tutelage of another pupil of Freddie Gruber, Peter Erskine, himself an instructor of Steve Smith. On October 18, 2008, Peart once again performed at the Buddy Rich Memorial Concert at New York's Hammerstein Ballroom. The concert has since been released on DVD.\nFamily deaths and recovery.\nOn August 10, 1997, soon after Rush's Test for Echo Tour, Peart's 19-year-old daughter (at the time his only child) Selena Taylor was killed in a single-car crash on Highway 401 near the town of Brighton, Ontario. His common-law wife of 23 years, Jacqueline Taylor, subsequently died of cancer on June 20, 1998. Peart attributed her death to the result of a \"broken heart\" and called it \"a slow suicide by apathy. She just didn't care.\"\nIn his book \"\", Peart wrote that he told his bandmates at Jacqueline's funeral, \"consider me retired\". Peart took a long sabbatical to mourn and reflect, and travelled extensively throughout North and Central America on his motorcycle, covering . After his journey, Peart returned to the band. Peart wrote the book as a chronicle of his geographical and emotional journey.\nPeart was introduced to photographer Carrie Nuttall in Los Angeles by longtime Rush photographer Andrew MacNaughtan. They married on September 9, 2000. In early 2001, Peart announced to his bandmates that he was ready to return to recording and performing. The product of the band's return was the 2002 album \"Vapor Trails\". At the start of the ensuing tour in support of the album, the band members decided that Peart would not take part in the daily grind of press interviews and \"meet and greet\" sessions upon their arrival in a new city that typically monopolise a touring band's daily schedule. Peart always shied away from these types of in-person encounters, and it was decided that exposing him to a lengthy stream of questions about the tragic events of his life was not necessary.\nAfter the release of \"Vapor Trails\" and his reunion with bandmates, Peart returned to work as a full-time musician. In the June 2009 edition of Peart's website's \"News, Weather, and Sports\", titled \"Under the Marine Layer\", he announced that he and Nuttall were expecting their first child. Olivia Louise Peart was born later that year.\nIn 2014, Peart acquired U.S. citizenship.\nRetirement.\nPeart described himself as a \"retired drummer\" in an interview in December 2015:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Lately Olivia has been introducing me to new friends at school as 'My dad\u2014He's a retired drummer.' True to say\u2014funny to hear. And it does not pain me to realize that, like all athletes, there comes a time to ... take yourself out of the game. I would rather set it aside than face the predicament described in our song \"Losing It\" ... Peart had been suffering from chronic tendinitis and shoulder problems.\nGeddy Lee clarified his bandmate was quoted out of context, and suggested Peart was simply taking a break, \"explaining his reasons for not wanting to tour, with the toll that it's taking on his body.\" However, in January 2018, Alex Lifeson confirmed that Rush was \"basically done\". Peart remained friends with his former bandmates.\nDeath.\nPeart died from glioblastoma, an aggressive form of brain cancer, on January 7, 2020, in Santa Monica, California. He had been diagnosed three and a half years earlier, and the illness was a closely guarded secret in Peart's inner circle until his death. His family made the announcement on January 10.\nFrom the official Rush website:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It is with broken hearts and the deepest sadness that we must share the terrible news that on Tuesday our friend, soul brother and band mate of over 45 years, Neil, has lost his incredibly brave three and a half year battle with brain cancer (Glioblastoma). We ask that friends, fans and media alike understandably respect the family's need for privacy and peace at this extremely painful and difficult time. Those wishing to express their condolences can choose a cancer research group or charity of their choice and make a donation in Neil's name.\nPeart's death was widely lamented by fans and fellow musicians alike, who considered it a substantial loss for popular music.\nPeart's father Glen died of cancer on June 12, 2021. Peart's brother Danny died of glioblastoma on March 17, 2025.\nMusicianship.\nStyle and influences.\nPeart's drumming skill and technique are well-regarded by fans, fellow musicians, and music journalists. His influences were eclectic, ranging from Pete Thomas, John Bonham, Carl Palmer, Michael Giles, Ginger Baker, Phil Collins, Chris Sharrock, Steve Gadd, Warren Cann, Stewart Copeland, Michael Shrieve and Keith Moon, to fusion and jazz drummers Billy Cobham, Buddy Rich, Bill Bruford and Gene Krupa. The Who was the first group that inspired him to write songs and play the drums.\nPeart had long played matched grip but shifted to traditional as part of his style reinvention in the mid-1990s under the tutelage of jazz coach Freddie Gruber. He played traditional grip throughout his first instructional DVD \"A Work in Progress\" and on Rush's \"Test for Echo\" studio album. Peart went back to using primarily matched, though he continued to switch to traditional at times when playing songs from \"Test for Echo\" and during moments when traditional grip felt more appropriate, such as during the rudimental snare drum section of his drum solo. He discussed the details of these switches in the DVD \"Anatomy of a Drum Solo\".\n\"Variety\" wrote: \"Widely considered one of the most innovative drummers in rock history, Peart was famous for his state-of-the-art drum kits\u2014more than 40 different drums were not out of the norm\u2014precise playing style and on stage showmanship.\"\n\"USA Today\"'s writers compared him favourably with other top-shelf rock drummers. He was \"considered one of the best rock drummers of all time, alongside John Bonham of Led Zeppelin; Ringo Starr of The Beatles; Keith Moon of The Who; Ginger Baker of Cream and Stewart Copeland of The Police.\" Noting that Peart was \"known for his technical proficiency\", the Modern Drummer Hall of Fame inducted him in 1983.\nMusic critic Amanda Petrusich in \"The New Yorker\" wrote: \"Watching Peart play the drums gave the impression that he might possess several phantom limbs. The sound was merciless.\"\nEquipment.\nWith Rush, Peart played Slingerland, Tama, Ludwig, and Drum Workshop drums, in that order. From \"2112\" to \"Counterparts\", he used a 5 1/2 \u00d7 14 inch Slingerland \"Artist\" snare model (3-ply shell with 8 lugs). For the recording of \"Presto\", he used a Ludwig and Solid Percussion piccolo snare drum.\nPeart played Zildjian A-series cymbals and Wuhan china cymbals until the early 2000s, when he switched to Paragon, a line created for him by Sabian. In concert starting in 1984 on the Grace Under Pressure Tour, Peart used an elaborate 360-degree drum kit that would rotate as he played different sections of the kit.\nDuring the late 1970s, Peart augmented his acoustic setup with diverse percussion instruments, including orchestra bells, tubular bells, wind chimes, crotales, timbales, timpani, gong, temple blocks, bell tree, triangle, and melodic cowbells. From the mid-1980s, Peart replaced several of these pieces with MIDI trigger pads. This was done in order to trigger sounds sampled from various pieces of acoustic percussion that would otherwise consume far too much stage area. Some purely electronic non-instrumental sounds were also used. One classic MIDI pad used is the MalletKAT Express, which is a two-octave electronic MIDI device that resembles a xylophone or piano. The MalletKAT Express is composed of rubber pads for the \"keys\" so that any stick can be used. Beginning with 1984's \"Grace Under Pressure\", he used Simmons electronic drums in conjunction with Akai digital samplers. Peart performed several songs primarily using the electronic portion of his drum kit. (e.g. \"Red Sector A\", \"Closer to the Heart\" on \"A Show of Hands\" and \"Mystic Rhythms\" on \"\".)\nShortly after making the choice to include electronic drums and triggers, Peart added what became another trademark of his kit: a rotating drum riser. During live Rush shows, the riser allowed Peart to swap the prominent portions of the kit (traditional acoustic in front, electronic in back). A staple of Peart's live drum solos was the in-performance rotation-and-swap of the front and back kits as part of the solo, a special effect that provided a symbolic transition of drum styles within the solo.\nIn the early 2000s, Peart began taking full advantage of the advances in electronic drum technology, primarily incorporating Roland V-Drums and continued use of samplers with his existing set of acoustic percussion. His digitally sampled library of both traditional and exotic sounds expanded over the years with his music.\nIn April 2006, Peart took delivery of his third Drum Workshop set, configured similarly to the R30 set, in a Tobacco Sunburst finish over curly maple exterior ply, with chrome hardware. He referred to this set, which he used primarily in Los Angeles, as the \"West Coast kit\". Besides using it on recordings with Vertical Horizon, he played it while composing parts for Rush's album \"Snakes &amp; Arrows\". It featured a custom 23-inch bass drum; all other sizes remained the same as the R30 kit.\nOn March 20, 2007, Peart revealed that Drum Workshop prepared a new set of red-painted maple shells with black hardware and gold \"Snakes &amp; Arrows\" logos for him to play on the Snakes &amp; Arrows Tour.\nPeart also designed his own signature series drumstick with Pro-Mark, the Promark PW747W, Neil Peart Signature drumsticks, made of Japanese Shira Kashi white oak.\nDuring the 2010\u201311 Time Machine Tour, Peart used a new Drum Workshop kit; the kit was outfitted with copper-plated hardware and time machine designs to match the tour's steampunk themes. Matching Paragon cymbals with clock imagery were also used.\nSolos.\nPeart was noted for his distinctive in-concert drum solos, characterised by exotic percussion instruments and long, intricate passages in odd time signatures. His complex arrangements sometimes result in complete separation of upper- and lower-limb patterns; an ostinato dubbed \"The Waltz\" is a typical example. His solos were featured on every live album released by the band. On the early live albums (\"All the World's a Stage\" and \"Exit... Stage Left\"), the drum solo was included as part of a song. On all subsequent live albums through \"\", the drum solo has been included as a separate track. The \"Clockwork Angels Tour\" album includes three short solos instead of a single long one: two interludes played during other songs and one standalone. Similarly, the \"R40 Live\" album includes two short solos performed as interludes.\nA studio recording of Peart's solo \"Pieces of Eight\" was released as a flexi disc exclusive in the May 1987 issue of \"Modern Drummer\" magazine. Peart's instructional DVD \"Anatomy of a Drum Solo\" (2005) is an in-depth examination of how he constructs a solo that is musical rather than indulgent, using his solo from the 2004 R30 30th anniversary tour as an example.\nLyricism.\nPeart was the main lyricist for Rush. Literature heavily influenced his writings. In his early days with Rush, much of his lyrical output was influenced by fantasy, science fiction, mythology, and philosophy.\nThe 1980 album \"Permanent Waves\" saw Peart cease to use fantasy and mythological themes. 1981's \"Moving Pictures\" showed that Peart was still interested in heroic, mythological figures, but now placed firmly in a modern, realistic context. The song \"Limelight\" from the same album is an autobiographical account of Peart's reservations regarding his own popularity and the pressures associated with fame. From \"Permanent Waves\" onward, most of Peart's lyrics revolved around social, emotional, and humanitarian issues, usually from an objective standpoint and employing the use of metaphors and symbolic representation.\nReleased in 1984, \"Grace Under Pressure\" strung together such despondent topics as the Holocaust (\"Red Sector A\") and the death of close friends (\"Afterimage\"). With 1987's \"Hold Your Fire\", 1989's \"Presto\", 1991's \"Roll the Bones\", and 1993's \"Counterparts\", Peart continued to explore diverse lyrical motifs, even addressing the topics of love and relationships (\"Open Secrets\", \"Ghost of a Chance\", \"Speed of Love\", \"Cold Fire\", \"Alien Shore\"), subjects which he purposefully avoided in the past out of fear of using clich\u00e9s. 2002's \"Vapor Trails\" was heavily devoted to Peart's personal issues, along with other humanitarian topics such as the 9/11 terrorist attacks (\"Peaceable Kingdom\"). The album \"Snakes &amp; Arrows\" dealt primarily and vociferously with Peart's opinions regarding faith and religion.\nThe song suite \"2112\" focuses on the struggle of an individual against the collectivist forces of a totalitarian state. This became the band's breakthrough release, but also brought unexpected criticism, mainly because of the credit of inspiration Peart gave to Ayn Rand in the liner notes. \"There was a remarkable backlash, especially from the English press, this being the late seventies, when collectivism was still in style, especially among journalists\", Peart said. \"They were calling us 'Junior fascists' and 'Hitler lovers'. It was a total shock to me\".\nIn a 1993 interview for a fan newsletter, Peart stated: \"For a start, the extent of my influence by the writings of Ayn Rand should not be overstated. I am no one's disciple.\" The lyrics of \"Faithless\" exhibit a life stance which has been closely identified with secular humanism. Peart explicitly discussed his religious views in \"The Masked Rider: Cycling in West Africa\", in which he wrote: \"I'm a linear thinking agnostic, but not an atheist, folks.\"\nIn 2007, Peart was ranked No. 2 (after Sting) on the now defunct magazine \"Blender\"'s list of \"worst lyricists in rock\". In contrast, AllMusic called him \"one of rock's most accomplished lyricists\".\nPolitical views.\nFor most of his career, Peart had never publicly identified with any political party or organisation in Canada or the United States. Even so, his political and philosophical views have often been analysed through his work with Rush and through other sources. In October 1993, shortly before that year's Canadian federal election, Peart appeared with then-Liberal Party leader Jean Chr\u00e9tien in an interview broadcast in Canada on MuchMusic, but stated in that interview that he was an undecided voter.\nPeart has often been categorised as an Objectivist and an admirer of Ayn Rand. This is largely based on his work with Rush in the 1970s, particularly the song \"Anthem\" and the album \"2112\"; the latter specifically credited Rand's work. However, in his 1994 \"Rush Backstage Club Newsletter\", while contending the \"individual is paramount in matters of justice and liberty,\" Peart specifically distanced himself from a strictly Objectivist line. In a June 2012 \"Rolling Stone\" interview, when asked if Rand's words still speak to him, Peart replied, \"Oh, no. That was 40 years ago. But it was important to me at the time in a transition of finding myself and having faith that what I believed was worthwhile.\"\nAlthough Peart was sometimes assumed to be a \"Conservative\" or \"Republican\" rock star, he criticised the U.S. Republican Party by stating that the philosophy of the party is \"absolutely opposed to Christ's teachings.\" In 2005, he described himself as a \"left-leaning libertarian\", and is often cited as a libertarian celebrity.\nIn a 2015 interview with \"Rolling Stone\", Peart stated that he saw the U.S. Democratic Party as the lesser evil: \"For a person of my sensibility, you're only left with the Democratic party.\"\nPeart was a member of the Canadian charity Artists Against Racism and worked with them on a radio public service announcement.\nWritten works.\nNonfiction.\nPeart authored seven non-fiction books during his lifetime, the last of which was released in 2016.\nPeart's first book, titled \"\", was written in 1996 about a month-long bicycling tour through Cameroon in November 1988. The book details Peart's travels through towns and villages with four fellow riders. The original had a limited print run, but after the critical and commercial success of Peart's second book, \"Masked Rider\" was re-issued by ECW Press and remains in print.\nAfter losing his wife and (at the time) only daughter, Peart embarked on a lengthy motorcycle road trip spanning North America. His experiences were penned in \"\". Peart and the rest of the band were always able to keep his private life at a distance from his public image in Rush. However, \"Ghost Rider\" is a first-person narrative of Peart on the road on a BMW R1100GS motorcycle, in an effort to put his life back together as he embarked on an extensive journey.\nYears later, after his marriage to Nuttall, Peart took another road trip, this time by car. In his third book, \"\", he reflects on his life, his career, his family, and music. As with his previous two books, it is a first-person narrative.\nThree decades after Peart joined Rush, the band found itself on its . Released in September 2006, \"Roadshow: Landscape with Drums \u2013 A Concert Tour by Motorcycle\" details the tour both from behind Peart's drum kit and on his BMW R1150GS and R1200GS motorcycles.\nPeart's next book, \"Far and Away: A Prize Every Time\", was published by ECW Press in May 2011. This book, which he worked on for two years, is formed around his travelling in North and South America. It tells how he found in a Brazilian town a unique combination of West African and Brazilian music. In 2014, a follow-up book, \"Far and Near: On Days like These\", was published by ECW. It covers travels in North America and Europe. His last book, \"Far and Wide: Bring That Horizon to Me!\", was published in 2016 and is based on his travels between stops on the R40 Live Tour of 2015.\nNonfiction works include:\nFiction.\nPeart worked with science fiction author Kevin J. Anderson to develop a novelisation of Rush's 2012 album \"Clockwork Angels\"; the book was published by ECW Press and debuted at #18 on \"The New York Times\" hardcover fiction best seller. The two collaborated again on a loose sequel, \"Clockwork Lives\", published in 2015, which won the 2016 Colorado Book Award in the science fiction category. Snippets of the band's lyrics can be found throughout both stories. Graphic novels of the first two \"Clockwork\" stories were created in 2015 and 2019, respectively. Peart worked with Anderson on a third and final novel during the last years of his life; after his death, his widow gave Anderson permission to continue the project. The book, \"Clockwork Destiny\", was published by ECW Press in June 2022; like the first two novels, it incorporates portions of lyrics from Rush songs.\nFiction works include:\nSide projects.\nPeart had a brief cameo in the 2007 film \"Aqua Teen Hunger Force Colon Movie Film for Theaters\", in which samples of his drumming were played.\nPeart also had a brief cameo in the 2008 film \"Adventures of Power\" and in the DVD extra does a drum-off competition.\nPeart appeared in concert with Rush in the 2009 film \"I Love You, Man\", as well as a \"Funny or Die\" web short in which the film's main characters sneak into the band's dressing room.\nDVDs.\nApart from Rush's video releases as a band, Peart has released the following DVDs (the first originally in VHS tape format) as an individual:\nAwards and honours.\nPeart received the following awards in the \"Modern Drummer\" magazine\nreaders' poll:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n(* \u2013 As a member of the Honor Roll in these categories, he is no longer eligible for votes in the above categories.)\nPeart received the following awards from \"DRUM!\" magazine:\nOther honours and awards\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22005", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=22005", "title": "Nicene creed", "text": ""}
{"id": "22007", "revid": "25571102", "url": "https://en.wikipedia.org/wiki?curid=22007", "title": "North Atlantic Treaty", "text": "1949 treaty forming the basis of NATO\nThe North Atlantic Treaty, also known as the Washington Treaty, forms the legal basis of, and is implemented by, the North Atlantic Treaty Organization (NATO). The treaty was signed in Washington, D.C., on 4 April 1949.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nBackground.\nThe treaty was signed in Washington, D.C., on 4 April 1949 by a committee which was chaired by US diplomat Theodore Achilles. Earlier secret talks had been held at the Pentagon between 22 March and 1 April 1948, of which Achilles said:\nThe talks lasted about two weeks and by the time they finished, it had been secretly agreed that there would be a treaty, and I had a draft of one in the bottom drawer of my safe. It was never shown to anyone except Jack [Hickerson]. I wish I had kept it, but when I left the Department in 1950, I dutifully left it in the safe and I have never been able to trace it in the archives. It drew heavily on the Rio Treaty, and a bit of the Brussels Treaty, which had not yet been signed, but of which we were being kept heavily supplied with drafts. The eventual North Atlantic Treaty had the general form, and a good bit of the language of my first draft, but with a number of important differences.\nAccording to Achilles, another important author of the treaty was John D. Hickerson:\nMore than any human being Jack was responsible for the nature, content, and form of the Treaty...It was a one-man Hickerson treaty.\nAs a fundamental component of NATO, the North Atlantic Treaty is a product of the US' desire to avoid overextension at the end of World War II, and consequently pursue multilateralism in Europe. It is part of the US' collective defense arrangement with Western European powers, following a long and deliberative process. The treaty was created with an armed attack by the Soviet Union against Western Europe in mind, although the mutual self-defense clause was never invoked during the Cold War.\nBy signing the North Atlantic Treaty, parties are \"determined to safeguard the freedom, common heritage and civilization of the peoples, founded on the principles of democracy, individual liberty and the rule of law.\"\nMembers.\nFounding members.\nThe following twelve states signed the treaty and thus became the founding members of NATO. The following leaders signed the agreement as plenipotentiaries of their countries in Washington, D.C., on 4 April 1949:\nNon-founding members who joined before the dissolution of the Soviet Union.\nThe following four states joined the treaty after the 12 founding states, but before the dissolution of the Soviet Union:\nMembers who joined after the dissolution of the Soviet Union.\nThe following 16 states joined the treaty after the dissolution of the Soviet Union:\nWithdrawal.\nNo state has rescinded its membership, but some dependencies and jurisdictions of member states that had prior NATO mutual defense protection under Article 6 have not requested membership after becoming independent or handed over to non-NATO states:\nProvisions.\nArticle 1.\nArticle 1 of the treaty states that member parties \"settle any international disputes in which they may be involved by peaceful means in such a manner that international peace and security, and justice, are not endangered, and to refrain in their international relations from the threat or use of force in any manner inconsistent with the purposes of the United Nations.\"\nMembers seek to promote stability and well-being in the North Atlantic area through preservation of peace and security in accordance with the Charter of the United Nations.\nArticle 2.\nArticle 2 of the treaty stipulates that \"The Parties will contribute toward the further development of peaceful and friendly international relations by strengthening their free institutions, by bringing about a better understanding of the principles upon which these institutions are founded, and by promoting conditions of stability and well-being. They will seek to eliminate conflict in their international economic policies and will encourage economic collaboration between any or all of them.\" This is sometimes referred to as the Canada Clause after Pearson pushed for its inclusion in the treaty. This included proposals for a trade council, cultural program, technological sharing, and an information program. Of those, only the latter two were passed. Nonetheless, it has been brought up by observers commenting on trade disputes between members.\nArticle 3.\nArticle 3 of the treaty states that \"In order more effectively to achieve the objectives of this Treaty, the Parties, separately and jointly, by means of continuous and effective self-help and mutual aid, will maintain and develop their individual and collective capacity to resist armed attack.\"\nThis was interpreted in 2022 as the basis for the target for a 2% GDP expenditure rule, which was established as a loose guideline in 2006. This metric was confirmed again during the 2014 Wales summit.\nIt has also been used as a core concept for a mandate to strengthen member resilience: the ability to resist and recover from major disasters, failures in infrastructure, or traditional armed attack. This commitment was first accepted during the 2016 Warsaw summit, and further reiterated and clarified due to the COVID-19 pandemic in 2021. In accordance with NATO documents, this has been understood to include seven key areas:\nArticle 4.\nArticle 4 is generally considered the starting point for major NATO operations, and therefore is intended for either emergencies or situations of urgency. It officially calls for consultation over military matters when \"the territorial integrity, political independence or security of any of the parties is threatened.\" Upon its invocation, the issue is discussed in the North Atlantic Council, and can formally lead into a joint decision or action (logistic, military, or otherwise) on behalf of the Alliance.\nInvocations.\nIt has been invoked nine times as of 19 September 2025.\nThreatened invocations.\nThere have also been instances where Article 4 was not formally invoked, but instead threatened. In fact, this was viewed as one of the original intentions for Article 4: as a means to elevate issues and provide member nations a means of deterrence. For example, in November 2021, the Polish foreign ministry\u2014along with Estonia, Lithuania, and Latvia\u2014briefly considered triggering Article 4 due to the Belarusian migrant crisis, but it was not formally requested. On 28 December 2024, Swedish member of parliament and former minister of defense, Peter Hultqvist wanted the government to activate Article 4 in response to the 2024 Baltic Sea submarine cable disruptions and in September 2025, Denmark also considered it after unauthorised drone flights over airports and military bases in the country.\nArticle 5.\nThe key section of the treaty is Article 5. Its commitment clause defines the \"casus foederis\". It commits each member state to consider an armed attack against one member state, in the areas defined by Article 6, to be an armed attack against them all. Upon such attack, each member state is to assist by taking \"such action as [the member state] deems necessary, including the use of armed force, to restore and maintain the security of the North Atlantic area.\" The article has only been invoked once, but considered in a number of other cases.\nInvocations.\nSeptember 11 attacks.\nArticle 5 has been invoked only once in NATO history, after the September 11 attacks on the United States in 2001. Following the September 11 attacks, the Secretary General of NATO, George Robertson telephoned Colin Powell and said that declaring an Article 5 contingency would be a useful political statement for NATO to make. The United States indicated it had no interest in making such a request itself; however, it would not object to the council taking such action on its own.\nArticle 6.\nArticle 6 states that Article 5 covers only member states' territories in Europe, North America, Turkey, and islands in the Atlantic north of the Tropic of Cancer.\nA clarification regarding the territories to which Article 5 applies was issued by Article 2 of the Protocol to the North Atlantic Treaty on the accession of Greece and Turkey signed on 22 October 1951. Subsequent expansions, such as to West Germany in 1955, were treated in the same way. A further clarification was made in a NAC meeting on July 3, 1962 that Algeria (which was explicitly included in the original text as \"Algerian departments \"of France\"\") was no longer included.\nIn 1954, following India's annexation of Dadra and Nagar Haveli, the Portuguese government was precluded from invoking Article 5 due to Article 6, but it was understood at the time that Article 4 could be invoked.\nIt was the opinion in August 1965 of the US State Department, the US Defense Department, and the legal division of NATO that an attack on the North Pacific U.S. island state of Hawaii would not trigger the treaty, but an attack on the other 49 would. The Aleutian Islands in the North Pacific are not treated in the same manner by NATO as Hawaii is, since they are politically part of Alaska rather than their own state like Hawaii, and considered geographically part of the North American continent, while Hawaii is not. Similarly, Mediterranean islands like Sicily, Corsica, the Baleares, etc. are considered geographically part of Europe, and therefore under Article 6. However, even though islands like Puerto Rico are considered part of North America, they do not fall under NATO because specifically those islands that are in the Atlantic have to be north of the Tropic of Cancer. The Spanish cities of Ceuta and Melilla on the North African shore are not under NATO protection in spite of Moroccan claims to them. Legal experts have interpreted that other articles could cover the Spanish North African cities but this take has not been tested in practice. This is also why events such as the Balyun airstrikes did not trigger Article 5, as the Turkish troops that were attacked were in Syria, not Turkey. As well as why the 1982 invasion of the Falkland Islands by Argentina did not trigger Article 5, as the Falkland Islands are in the South Atlantic, south of the Tropic of Cancer, and not within the geographic area covered by Article 6.\nOn 16 April 2003, NATO agreed to take command of the International Security Assistance Force (ISAF) in Afghanistan, which includes troops from 42 countries. The decision came at the request of Germany and the Netherlands, the two states leading ISAF at the time of the agreement, and all nineteen NATO ambassadors approved it unanimously. The handover of control to NATO took place on 11 August, and marked the first time in NATO's history that it took charge of a mission outside of the area delineated by Article 6.\nArticle 7.\nArticle 7 states that the North Atlantic Treaty shall not be interpreted as affecting in any way the rights and obligations of member countries under the charter of the United Nations, or the primary responsibility of the United Nations Security Council for the maintenance of international peace and security.\nArticle 8.\nArticle 8 is one of the more rarely referenced provisions of the North Atlantic Treaty. It regulates the relationship between the obligations of the NATO members under the treaty and other obligations of the allied nations (among themselves or with third parties). According to Article 8, members should not have any international commitments in conflict with the treaty, and undertake not to enter into any international \"engagement\" in conflict with the treaty. The following is a list of such active, intra-NATO military treaties.\nArticle 9.\nEstablishes the North Atlantic Council, and is the only NATO body that derives its authority directly from the treaty. Its primary objectives as stated in the treaty is the enforcement of Article 3 and Article 5.\nArticle 10.\nArticle 10 dictates the process by which other countries may join NATO, which is by unanimous agreement by current NATO members. Further, new NATO members can only consist of other European nations. In practice, this has turned into a set of action plans which an aspiring nation must follow in order to become a member, including the Membership Action Plan (MAP) mechanism and Intensified Dialogue formula.\nArticle 11.\nArticle 11 indicated the process of the initial ratification of the treaty. Each signatory nation was required to ratify the treaty through their respective constitutional processes. In order to come into force, the treaty had to be ratified by Belgium, Canada, France, Luxembourg, the Netherlands, the United Kingdom, and the United States.\nArticle 12.\nArticle 12 states the process by which the treaty may be amended, provided such amendments still affect the North Atlantic area and do not violate the Charter of the United Nations. In practice, this has only been used to clearly delineate which territories are under the purview of NATO.\nArticle 13.\nArticle 13 delimits the process by which a member leaves NATO, which simply consists of a one-year notice by the member nation to the U.S. government in its role as the treaty depositary, which then promulgates the notice to the other member nations. This has been contemplated by a number of member nations, but so far has not happened aside from withdrawals due to independence of former territories or dependencies (namely, Algeria, Malta, and Cyprus).\nOtherwise, the next closest option for a member nation is to instead withdraw from NATO's military command structure, but not from NATO entirely. This happened with France in 1966, which rejoined in 2009; and with Greece in 1974, which rejoined in 1980 after the new Turkish military government ended its objections to Greek re-entry.\nArticle 14.\nArticle 14 notes the official languages of NATO as English and French, and that the United States government shall promulgate copies of the treaty to the other member nations.\nChanges since signing.\nThree official footnotes have been released to reflect the changes made since the treaty was written:\nRegarding Article 6:\nRegarding Article 6:\nRegarding Article 11:\nPotential military conflict between NATO members.\nFull-scale war between two or more NATO members has never occurred, and is not allowed by Article 1. Should conflict occur, there is not a well-established procedure as to what would happen. One argument is that by Article 8, the two members fall under abeyance of the Treaty; or that due to Article 5, NATO allies would thus enter into war against the aggressor party.\nThere have been several militarised disputes between NATO allies that have threatened this:\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22009", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=22009", "title": "Nitronium ion", "text": "Polyatomic ion\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nThe nitronium ion, , is a cation. It is an onium ion because its nitrogen atom has +1 charge, similar to ammonium ion . It is created by the removal of an electron from the paramagnetic nitrogen dioxide molecule , or the protonation of nitric acid (with removal of ).\nIt is stable enough to exist in normal conditions, but it is generally reactive and used extensively as an electrophile in the nitration of other substances. The ion is generated \"in situ\" for this purpose by mixing concentrated sulfuric acid and concentrated nitric acid according to the equilibrium:\nStructure.\nThe nitronium ion is isoelectronic with carbon dioxide and has the same linear structure and bond angle of 180\u00b0. For this reason it has a similar vibrational spectrum to carbon dioxide. Historically, the nitronium ion was detected by Raman spectroscopy, because its symmetric stretch is Raman-active but infrared-inactive. The Raman-active symmetrical stretch was first used to identify the ion in nitrating mixtures.\nSalts.\nA few stable nitronium salts with anions of weak nucleophilicity can be isolated. These include nitronium perchlorate , nitronium tetrafluoroborate , nitronium hexafluorophosphate , nitronium hexafluoroarsenate , and nitronium hexafluoroantimonate . These are all very hygroscopic compounds.\nThe solid form of dinitrogen pentoxide, , actually consists of nitronium and nitrate ions, so it is an ionic compound, nitronium nitrate , not a molecular solid. However, dinitrogen pentoxide in liquid or gaseous state is molecular and does not contain nitronium ions.\nRelated species.\nThe compounds nitryl fluoride, , and nitryl chloride, , are not nitronium salts but molecular compounds, as shown by their low boiling points (\u221272\u00a0\u00b0C and \u22126\u00a0\u00b0C respectively) and short nitrogen\u2013halogen bond lengths (N\u2013F 135 pm, N\u2013Cl 184 pm).\nAddition of one electron forms the neutral nitryl radical, ; in fact, this is fairly stable and known as the compound nitrogen dioxide.\nThe related negatively charged species is , the nitrite ion.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22010", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=22010", "title": "Neopet", "text": ""}
{"id": "22011", "revid": "1121468", "url": "https://en.wikipedia.org/wiki?curid=22011", "title": "Neo Geo", "text": "Arcade system and home video game console\nThe , stylized as NEO\u2022GEO, is a video game platform released in 1990 by Japanese game company SNK Corporation. It was initially released in two ROM cartridge-based formats: an arcade system board (Multi Video System; MVS) and a home video game console (Advanced Entertainment System; AES). A CD-ROM-based home console iteration, the Neo Geo CD, was released in 1994. The arcade system can hold multiple cartridges that can be exchanged out, a unique feature that contrasted to the dedicated single-game arcade cabinets of its time, making it popular with arcade operators.\nThe Neo Geo was marketed as the first 24-bit system; its CPU is actually a 16/32-bit 68000 with an 8-bit Z80 coprocessor, while its GPU chipset has a 24-bit graphics data bus. It was a very powerful system when released, more so than any video game console at the time, and many arcade systems such as rival Capcom's CPS, which did not surpass it until the CP System II in 1993.\nThe Neo Geo AES was originally released solely as a rental console for video game stores in Japan called the \"Neo Geo Rental System\", with its high manufacturing costs causing SNK not to release it for retail sale. This was later reversed due to high demand and it was released at retail as a luxury console. Adjusted for inflation, it was the most expensive home video game console ever released, costing US$. The AES had identical hardware to the MVS, allowing home users to play the games exactly as they were in the arcades; however, cartridges are not inter-compatible due to different physical sizes, meaning that software releases differed for the two systems. \nThe Neo Geo MVS was a success during the 1990s due to the cabinet's low cost, multiple cartridge slots, and compact size. Several successful video game series were released for the platform, such as \"Fatal Fury\", \"Art of Fighting\", \"Samurai Shodown\", \"World Heroes\", \"The King of Fighters\", \"Twinkle Star Sprites\" and \"Metal Slug\"; game software production lasted until 2004, making Neo Geo the longest-supported arcade system of all time. The AES had a very niche market in Japan, though sales were very low in the U.S. due to its high price for both the hardware and software, but it has since gained a cult following and is now considered a collectable. Worldwide, one million Neo Geo MVS units have been shipped and 980,000 Neo Geo AES and CD units combined.\nHistory.\nDevelopment.\nThe Neo Geo hardware was an evolution of an older SNK/Alpha Denshi M68000 arcade platform that was used in \"Time Soldiers\" in 1987, further developed in the SNK M68000 hardware platform as used for \"\" in 1988. Contrary to other popular arcade hardware of the time, the SNK/Alpha Denshi hardware used sprite strips instead of the more common tilemap-based backgrounds. The Neo Geo hardware was essentially developed by Alpha Denshi's Eiji Fukatsu, adding sprite scaling through the use of scaling tables stored in ROM as well as support for a much higher amount of data on cartridges and better sound hardware. The system's hardware specifications were finalized in December 1989.\nTakashi Nishiyama left Capcom, where he had created the fighting game \"Street Fighter\" (1987), to join SNK after they invited him to join the company. There, he was involved in developing the Neo Geo. He proposed the concept of an arcade system that uses ROM cartridges like a game console, and also proposed a home console version of the system. His reasons for these proposals were to make the system cheaper for markets such as China, Hong Kong, Taiwan, Southeast Asia, Central America, and South America, where it was difficult to sell dedicated arcade games due to piracy. Nishiyama also created the \"Fatal Fury\" fighting game franchise, as a spiritual successor to the original \"Street Fighter\". He also worked on the fighting game franchises \"Art of Fighting\" and \"The King of Fighters\", as well as the run and gun video game series \"Metal Slug\".\nRelease.\nThe Neo Geo was announced and demonstrated on January 31, 1990, in Osaka, Japan. SNK exhibited several Neo Geo games at Japan's Amusement Machine Operators' Union (AOU) show in February 1990, including \"NAM-1975\", \"Magician Lord\", \"Baseball Stars Professional\", \"Top Player's Golf\" and \"Riding Hero\". The Neo Geo then made its overseas debut at Chicago's American Coin Machine Exposition (ACME) in March 1990, with several games demonstrated. The system was then released in Japan on April 26, 1990. Initially, the AES home system was only available for rent to commercial establishments, such as hotel chains, bars and restaurants. When customer response indicated that some gamers were willing to buy a US$ console, SNK expanded sales and marketing into the home console market in 1991.The Neo Geo's graphics and sound are largely superior to other contemporary home consoles, computers (such as the X68000) and even some arcade systems. Unlike earlier systems, the Neo Geo AES was intended to reproduce the same quality of the game as the arcade MVS system. The MVS was one of the most powerful arcade units at the time, allowing the game ROM to be loaded from interchangeable cartridges instead of using custom, dedicated hardware for each game.\nIn the United States, the console's debut price was planned to be US$ and included two joystick controllers and a game: either \"Baseball Stars Professional\" or \"NAM-1975\". However, the price was raised and its American launch debuted as the Gold System at US$ (). Later, the Gold System was bundled with \"Magician Lord\" and \"Fatal Fury\". The Silver System package, launched at US$, included one joystick controller and no pack-in game. Other games were launched at about US$ and up. At double or quadruple the price of the competition, the console and its games were accessible only to a niche market. However, its full compatibility meant that no additional money was being spent on porting or marketing for the AES, since the MVS' success was automatically feeding the AES, making the console profitable for SNK.\nLifetime and discontinuation.\nIn January 1991, Romstar released an arcade conversion kit version of the Neo Geo in the United States, allowing the conversion of an arcade cabinet into a Neo Geo system. The same month, the Neo Geo home console version made its North American debut at the Consumer Electronics Show (CES). SNK also announced that there would generally be a roughly six-month gap between the arcade and home releases of Neo Geo games.\nWhen real-time 3D graphics became the norm in the arcade industry, the Neo Geo's 2D hardware was unable to produce them. Despite this, Neo Geo arcade games retained profitability through the mid-1990s, and the system was one of three 1995 recipients of the American Amusement Machine Association's Diamond Awards (which are based strictly on sales achievements). SNK developed a new home console in 1994, called the Neo Geo CD. A new arcade system was also made in 1997, called Hyper Neo Geo 64. However, these two systems had low popularity and only a few games.\nWhile it ceased manufacturing home consoles by the end of 1997, SNK continued making software for the original 2D Neo Geo. Despite being very aged by the end of the decade, the Neo Geo continued getting popular releases, such as the critically acclaimed \"The King of Fighters 2002\". The last official game by SNK for the Neo Geo system, \"Samurai Shodown V Special\", was released in 2004, 14 years after the system's introduction.\nOn August 31, 2007, SNK stopped offering maintenance and repairs to Neo Geo home consoles, handhelds, and games.\nTechnical specifications.\nEach joystick controller is 280 mm (width) \u00d7 190 mm (depth) \u00d7 95 mm (height) (11 \u00d7 8 \u00d7 2.5 in.) and contains the same four-button layout as the arcade MVS cabinet.\nThe arcade machines have a memory card system by which a player could save a game to return to at a later time and could also be used to continue play on the SNK home console of the same name.\nThe arcade version of the video game hardware is often referred to as the \"MVS\", or Multi Video System (available in 1-slot, 2-slot, 4-slot, and 6-slot variations, differing in the amount of game cartridges loaded into the machine at the time), with its console counterpart referred to as the \"AES\", or Advanced Entertainment System. Early motherboard revisions contain daughterboards, used to enhance the clarity of the video output.\nThe MVS and AES hardware can execute identical machine code. Owners can move EPROMs from one type to the other, and the game will still run. The program specifics for both MVS and AES game options are contained on every game ROM, whether the cartridge is intended for home or arcade use. However, the arcade and home cartridges do have a different pinout. They were designed this way to prevent arcade operators from buying the cheaper home carts and then using them in arcades. In a few home version games, the arcade version of the game can be unlocked by inputting a special code.\nROM sizes and startup screens.\nThe original specification for ROM size is up to 330 megabits, hence the system displaying \"Max 330 Mega Pro-Gear Spec\" upon startup. While no technical advances were required to achieve it, some games over 100 megabits, such as \"Top Hunter\", followed this screen by displaying an animation proclaiming \"The 100Mega Shock!\". The original ROM size specification was later enhanced on cartridges with bank switching memory technology, increasing the maximum cartridge size to around 716 megabits. These new cartridges also cause the system to display \"Giga Power Pro-Gear Spec\" upon startup or during attract mode, indicating this enhancement.\nThe system uses seven different specialist processors, which divide the workload for the visuals, audio and gameplay.\nMemory.\nRAM: 214 KB SRAM\nOn-board ROM: 512 KB\nDisplay.\nThe SNK custom video chipset allows the system to draw sprites in vertical strips of tiles (blocks of 16x16 pixels) that can be 32 tiles tall (total of 512 pixels); it can draw up to 380 sprites on the screen at a time, with the limitation of 96 sprites per scanline. Each tile can be assigned a palette, which defines 15 colors (+ transparency). Allowing up to 256 palettes at the same time, the system can display 3840 colors simultaneously. Unlike most other video game consoles of its time, the Neo Geo does not use scrolling tilemap background layers. Instead, it has a single non-scrolling tilemap layer called the fix layer, while any scrolling layers rely exclusively on drawing sprites to create the scrolling backgrounds (like the Sega Y Board). By laying multiple sprites side by side, the system can simulate a tilemap background layer. The Neo Geo sprite system represents a step between conventional sprites and tilemaps.\nSound.\nThe onboard Yamaha YM2610 sound chip provides 14 channels of sound.\nReception.\nThe Neo Geo MVS was a worldwide commercial success upon release in arcades, becoming one of the highest-earning machines at various arcades across markets such as North America and Australia in 1990. In North America, three Neo Geo games were later among the ten top-grossing arcade software conversion kits in December 1992: \"Art of Fighting\" at number one, \"World Heroes\" at number two, and \"King of the Monsters 2\" at number ten. The Neo Geo MVS received Diamond awards from the American Amusement Machine Association (AAMA) two years in a row, for being among America's top four best-selling arcade machines of 1992 (with ', \"Mortal Kombat\" and ') and 1993. In 1994, the Neo Geo MVS was best-selling arcade printed circuit board (PCB) worldwide.\nIn the 1990 \"Gamest\" Awards, the Neo Geo received the Special Award. At the 1991 AMOA Awards held by the Amusement &amp; Music Operators Association (AMOA), the Neo Geo won the \"Most Innovative New Technology\" award.\nIn a 1993 review, \"GamePro\" gave the Neo Geo a \"thumbs up\". Though they voiced several criticisms, noting that the system was not as powerful as the soon-to-launch 3DO and had few releases which were not fighting games, they generally praised both the hardware and games library and recommended that gamers who could not afford the console (which was still priced at $649.99) play the games in the arcade.\nLegacy.\nThe Neo Geo is the first home game console to feature a removable memory card for saved games.\nThe GameTap subscription service has included a Neo Geo emulator and a small library of Neo Geo games. In 2007, Nintendo announced that Neo Geo games would appear on the Wii's Virtual Console, in partnership with D4 Enterprise, starting with ', \"Art of Fighting\", \"The King of Fighters '94\", and \"World Heroes\". Neo Geo games were released through Xbox Live Arcade and PlayStation Network (for the PlayStation 3, the service was called NEOGEO Station), including \"Fatal Fury Special\", \"Samurai Shodown II\", \"Metal Slug 3\", ' and \"The King of Fighters '98\". Many Neo Geo games were released on the PlayStation 4, Xbox One, Windows, and Nintendo Switch through the \"Arcade Archives\" service under the \"ACA Neo Geo\" label. In 2019, Antstream Arcade also runs Neo Geo games during the gaming platform's early lifespan.\nHomebrew activity began after the console's discontinuation, both by noncommercial hobbyists and commercially.\nThe Neo Geo has a community of collectors. Because of the limited production runs received by cartridges amongst the sizable available arcade library, some of the rarest Neo Geo games can sell for well over $1,000. The most valuable game is the European AES version of \"\". The MVS market provides a cheaper alternative to the expensive and rare home cartridges, and complete arcade kits are priced at a premium. It is also possible to play the MVS cartridges, which generally cost much less, on the AES home system through the use of adapters.\nIn 2009, the Neo Geo was ranked 19th out of the 25 best video game consoles of all time by video game website IGN.\nRecreated hardware.\nSince the 2010s, SNK have revived the Neo Geo in new form factors with built-in games, created both by themselves and by officially licensed third-parties.\nNeo Geo X.\nThe Neo Geo X, an officially licensed device with a collection of Neo Geo games pre-installed, was first released in 2012 by TOMMO Inc. After just one year and a lukewarm reception due to its price and poor quality of the emulation, on October 2, 2013, SNK Playmore terminated the license agreement and demanded an immediate cease and desist of distribution and sales of all licensed products.\nNeo Geo Mini.\nOn June 9, 2018, SNK announced the Neo Geo Mini, a miniature sized semi-portable arcade cabinet loosely resembling the appearance of a Japanese Neo Geo MVS, which features 40 built-in SNK titles, and was released on July 24, 2018, in Japan to celebrate SNK's 40th anniversary. The games on the system are the AES home console versions with limited continues; however, the Neo Geo Mini features a save/load state system which allows players to save and load the game at any time to continue the game and has up to four save files per game. In addition to its 320x224 pixel display, it can be connected to a TV via an HDMI cable and it has two ports for external Neo Geo Mini control pads based on the Neo Geo CD controllers.\nSNK also released an international version of the Neo Geo Mini, which was released outside Japan on October 15, 2018, and later in Japan on November 15, 2018. The international version contains the same features as the Japanese Neo Geo Mini but 14 out of the 40 titles are different (including all of the \"Metal Slug\" games) and a different interface. As such, both versions have 54 different SNK titles in total. On July 19, 2019, SNK announced the discontinuation of the original Neo Geo Mini and the international version.\nIn December 2018, a limited edition Christmas themed Neo Geo Mini was released, featuring nine games previously unreleased on the other two versions. On June 27, 2019, a limited edition called \"Samurai Shodown\" was released, in three colors; white, red, and blue, with a black edition being released later on. This edition has 40 games, featuring all of the \"Samurai Shodown\" games, including three new games that have never been included in prior versions. Another limited edition was released exclusively in Japan on September 30, 2019, called \"Samurai Spirits Kuroko\", with 48 games.\nNeo Geo Arcade Stick Pro.\nIn September 2019, SNK announced the release of the Neo Geo Arcade Stick Pro. Resembling a large white arcade stick complete with joystick and 8 buttons, it has 20 built-in games as well as HDMI output for TVs. It can also be used on any of the Neo Geo Mini units via an included adapter and is also backwards compatible with the game pads released for the Mini. The initial 20 built-in games were all fighting games, but more games were added by SNK through software updates to make a total of 40.\nIn November 2020, a special limited Christmas edition of the Neo Geo Arcade Stick Pro was released. The package includes a Neo Geo CD style control pad, a cover for the arcade stick, an arcade stick ball cover, a sticker sheet and a Neo Geo 30th anniversary artbook. All 40 games are included, unlocked from the start.\nUnico.\nIn August 2020, the company Unico announced the Neo Geo MVSX, an arcade table top system capable of playing MVS and AES titles that are pre-installed on the system itself, with 2 player support with a 17-inch screen, and pre-loaded with 50 games. Also available is a 32-inch stand to allow it to work as a free-standing unit resembling a vintage MVS cabinet. It was released in November 2020 in North America.\nIn late 2023, Unico released another Neo Geo Mini, this one in the style of an MVS arcade cabinet. It could be purchased with or without an additional Unico red controller, modelled the same way as the pre-existing Neo Geo Mini controllers and an HDMI cable. It comes pre-loaded with 45 games, most of them are the same as those found on the MVSX, but with five games removed from the line up.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22012", "revid": "69423", "url": "https://en.wikipedia.org/wiki?curid=22012", "title": "Neo Geo CD", "text": "Home video game console\nThe is a home video game console produced by SNK Corporation, released on September 9, 1994. The system is the same platform as the cartridge-based Neo Geo released four years earlier, but converted to the cheaper CD media format which retailed at per title compared to up to $300 for the equivalent cartridge.\nThe Neo Geo CD was launched with a bundled control pad instead of a joystick like the AES version of the Neo Geo came with; however, the system was compatible with controllers from the AES. The Neo Geo CD met with limited success due to it being plagued with long loading times that could vary from 30 to 60 seconds, depending on the game, and its lack of 3D graphics capabilities at a time when 3D graphics were becoming ubiquitous in the video game industry. As of September 30, 1997, there had been 570,000 Neo Geo CD units sold worldwide; production of all Neo Geo hardware was discontinued in 1997, while new software continued to be released until 2004.\nHistory.\nThe Neo Geo CD was first unveiled at the 1994 Tokyo Toy Show. The console uses the same CPU set-up as the arcade and cartridge-based Neo Geo systems, facilitating conversions. SNK planned to release Neo Geo CD versions of every Neo Geo game still in the arcades.\nThe system was originally priced at US$.\nIn response to criticism of the Neo Geo CD's long load times, SNK planned to produce a model with a double speed CD-ROM drive for North America, compared to the single speed drive of the Japanese and European models. However, the system missed its planned North American launch date of October 1995, and while SNK declined to give a specific reason for the delay, in their announcement of the new January 1996 launch date they stated that they had decided against using a double speed drive. Their Japanese division had produced an excess number of single speed units and found that modifying these units to double speed was more expensive than they had initially thought, so SNK opted to sell them as they were, postponing production of a double speed model until they had sold off the stock of single speed units.\nIn response to reader inquiries about Neo Geo CD software, \"GamePro\" reported in an issue cover dated May 1997 that SNK had quietly discontinued the console by this time.\nReception.\nCriticism of the system's generally long loading times began even before launch; a report in \"Electronic Gaming Monthly\" on the Neo Geo CD's unveiling noted, \"At the show, they were showing a demo of \"Fatal Fury 2\". The prototype of the machine that they showed was single speed, and the load time was 14-28 seconds between rounds. You can see that the screen[shot] on the right is a load screen.\"\nApproximately one month after launch, SNK reported that they had sold the Neo Geo CD's entire initial shipment of 50,000 units.\nReviewing the Neo Geo CD in late 1995, \"Next Generation\" noted SNK's reputation for fun games but argued that their failure to upgrade the Neo Geo system with 3D capabilities would keep them from producing any truly \"cutting edge\" games, and limit the console to the same small cult following as the Neo Geo AES system in spite of the games being less expensive. They gave it 1 1/2 out of 5 stars.\nHardware.\nTechnical specifications.\nThe system is also capable of reading Redbook standard compact disc audio.\nIn addition to the multi-AV port (nearly identical to the one used on the Sega Genesis model 1, though they are not interchangeable), all Neo Geo CD models had composite RCA A/V and S-Video out jacks on the rear of the console.\nThe CD system's 56 Mbit / 7 MB of RAM was split accordingly:\nModels.\nThree versions of the Neo Geo CD were released:\nThe front loader is the original console design, while the top loader version was developed shortly before the Neo Geo CD launch as a smaller, cheaper alternative model.\nThe CDZ was released on December 29, 1995, as the Japanese market replacement for the top loader unit. The system's technical specs are identical to the previous models except that it includes a double-speed CD-ROM drive, and different CD controller circuitry.\nAll three versions of the system have no region lock, but they are region aware, and some games will display English or Japanese depending on the console's region setting. The system can also play Audio CDs.\nSoftware.\nWhile the Neo Geo CD library consists primarily of ports of MVS and AES titles, there are a few MVS arcade games which were not officially released for the Neo Geo AES and ported instead to the Neo Geo CD. These include \"Puzzle Bobble\", \"Janshin Densetsu: Quest of Jongmaster\" (a Mahjong game also released for the PC Engine), \"Power Spikes II\", \"Neo Drift Out: New Technology\", and \"\" (\"Futsal: 5-on-5 Mini Soccer\").\nA few games which were unreleased in MVS and AES formats were also released exclusively for the Neo Geo CD. These include \"Ironclad: Tessh\u014d Rusha\" (\"Ch\u014dtetsu Buriking\u0101\", \"BRIKIN'GER\"), \"Crossed Swords II\", \"ZinTrick\" (\"Oshidashi Zintorikku\"), \"ADK World\", \"Neo Geo CD Special\", \"The King of Fighters '96 Neo Collection\", \"Samurai Shodown RPG\" (\"Shinsetsu Samurai Spirits: Bushid\u014d Retsuden\"; an RPG spin-off of the \"Samurai Shodown\" series that was also released for the Sony PlayStation and Sega Saturn), and \"Idol-Mahjong Final Romance 2\" (an arcade game which is not an MVS game, but was ported directly to the Neo Geo CD).\nTwo prototype games were in development:\n\"Bang\u00b2 Busters\" [\"Bang Bang Busters\"] (Made by Visco in 2000. Released in 2010 for Neo Geo CD by N.C.I.) and \n\"Treasure of the Caribbean\" [\"Caribe no Zaih\u014d\"] (Made by Face in 1994. Released in 2011 for Neo Geo CD by N.C.I./Le Cortex).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "22013", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=22013", "title": "Neo Geo Gold", "text": ""}
{"id": "22014", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=22014", "title": "Neo Geo CDZ", "text": ""}
{"id": "22015", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=22015", "title": "Neopets", "text": "Virtual pet site\nNeopets is a free-to-play virtual pet browser game. First launched in 1999, the game allows users to own virtual pets (\"Neopets\") and explore a virtual world called \"Neopia.\" Players can earn one of two virtual currencies. One currency, called Neopoints, can be obtained for free through on-site features like games, events, and contests. The other, Neocash (NC), is purchased with real-world money and can be exchanged for wearable items for pets.\nPlayers can buy digital food, toys, and other items for their Neopets to keep them happy. They can also customize the appearance of their Neopets by applying different colors, clothing, accessories, and styles. Additionally, users can train their Neopets to fight in the \"Battledome,\" which offers both PvP and PvE battles. Players interact with others through social features like message boards and guilds, or by buying, selling, and trading items with each other.\nHistory and development.\nCreation and growth (1999\u20132005).\n\"Neopets\" was conceived in 1997 by Adam Powell, a British student at the University of Nottingham at the time. He shared this idea with Donna Williams and the two started work on the site in September 1999, with Powell responsible for the programming and the database and Williams the web design and art. Their original office was located in Guildford. With the help of two friends, the site launched on 15 November 1999. Powell stated that the original goal was to \"keep university students entertained, and possibly make some cash from banner advertising\". The site contained popular culture references, such as a Neopet that was simply a picture of entertainer Bruce Forsyth, and another that was a cartoon version of singer Macy Gray.\nThe user base grew by word of mouth and by Christmas 1999, \"Neopets\" was logging 600,000 page views daily and sought investors to cover the high cost of running the site. Later in the month, American businessman Doug Dohring was introduced to the creators of the site and, along with other investors, bought a majority share in January of the following year. Neopets, Inc. was incorporated by Dohring in February 2000, and began business on 28 April. Dohring used Scientology's Org Board to manage the company. Powell and Williams were unaware of the Scientology connections until searching the employees at the newly formed company six months later but did not address this until the company hired a woman to introduce Scientology to \"Neopets\". Powell and Williams stopped the addition of any Scientology education to \"Neopets\" and ensured such content never made it into anything site-related.\nWith the new company, intellectual property that did not belong to \"Neopets\" was removed but the site kept the British spellings. The website made money from the first paying customers using an advertising method trademarked as \"immersive advertising\". In 2004, \"Neopets\" released a premium version and started showing advertisements on the basic site that were not shown to premium members.\nIn the 2000s, \"Neopets\" was consistently noted as one of the \"stickiest\" sites for children's entertainment. A press release from \"Neopets\" in 2001 stated that Neopets.com led in site \"stickiness\" in May and June, with the average user spending 117\u00a0minutes a week. \"Neopets\" also led in the average number of hours spent per user per month in December 2003 with an average of 4 hours and 47\u00a0minutes. A 2004 article stated that Nielsen//NetRatings reported that people were spending around three hours a month on \"Neopets\", more than any other site in its Nielsen category. By May 2005, a \"Neopets\"-affiliated video game producer cited about 35 million unique users, 11 million unique IP addresses per month, and 4 billion web page views per month. This producer also described 20% of the users as 18 or older, with the median of the remaining 80% at about 14.\nViacom (2005\u20132014).\nViacom, the American conglomerate that owns Nickelodeon, purchased Neopets, Inc. on 20 June 2005 for $160 million and announced plans to focus more on the use of banner ads over the site's existing immersive advertising. Founders Powell and Williams left Neopets, Inc. shortly after the purchase due to creative differences. The following year, a gaming event called The Altador Cup was released to improve interactivity between users and to coincide with the 2006 FIFA World Cup; it had 10.4 million participants in its first year. 2006 also saw the release of \"Neopets Mobile\", a T-Mobile exclusive premium service which allowed users to visit the new land of Lutari Island. The service was discontinued on 30 June 2009, leaving the island completely inaccessible. \"Neopets\" was consistently ranked among the top ten \"stickiest\" sites by both Nielsen//NetRatings and comScore Media Metrix in 2005 and 2006.\nThe game website was redesigned on 27 April 2007 and included changes to the user interface and the ability to customise Neopets. In June, Viacom promoted \"Neopets\" through minishows on its Nickelodeon channel. Promotions included the second Altador Cup and led to an increase in traffic through the site. However, according to Nielsen//NetRatings, in 2007, \"Neopets\" lost about 15% of its audience over the previous year. On 17 July, the NC Mall was launched in a partnership with Korean gaming company Nexon Corporation. It allows users to use real money to purchase Neocash to buy exclusive virtual items. In February 2008, comScore ranked it as the stickiest kids entertainment site with the average user spending 2 hours and 45\u00a0minutes per month. On 17 June 2008, Viacom formed the Nickelodeon Kids &amp; Family Virtual Worlds Group to \"encompass all paid and subscription gaming initiatives across all relevant platforms\", including \"Neopets\". By June 2011, \"Neopets\" announced that the website had logged 1 trillion page views since its creation.\nJumpStart and NetDragon (2014\u20132023).\nJumpStart Games acquired the Neopets property from Viacom in March 2014. Server migration began in September. JumpStart-owned Neopets was immediately characterized by glitches and site lag. On 6 March 2015, much of the Neopets Team remaining from Viacom were laid off. Then-CEO of JumpStart David Lord assured the community that there were no plans to shut down Neopets, and instead resources were allocated to develop new \"events and stories\" and address site stability and overall performance on mobile platforms, with plans to expand to additional platforms including Facebook.\nDuring the weekend of 27\u201328 June 2015, the site's chat filters stopped working. The site's forums were flooded with age-inappropriate messages. In a statement on Facebook, JumpStart apologized, explaining that the issue was due to a \"facility move,\" and that during that move, the moderation team was not able to access the Neopets community.\nIn January 2017, Neopets then-JumpStart CEO David Lord estimated 100,000 active daily users. On 3 July 2017, Chinese company NetDragon acquired JumpStart Games. The Neopets team started developing in-universe plots again in 2017 for the first time since the JumpStart acquisition, with the first such event going live in late 2017. In January 2020, Neopets logged 3.4 million views per month, a significant decline from its peak. With support for Adobe Flash ending in 2020, the Neopets Team announced in 2019 that it planned to transition Flash elements of the site to HTML5 by the end of 2020. The team prioritized converting popular features, and some parts of the site were left non-functional when Flash support ended. The Neopets Team also announced the development of a mobile app for the site, which was later scrapped in favor of a \"mobile-friendly\" browser version of the site which launched via an open beta on 9 June 2020. In June 2020, JumpStart CEO Jim Czulewicz estimated Neopets had 100,000 daily active users and 1.5 million monthly active players.\nOn 13 June 2023, JumpStart announced it would be closing on 30 June.\nMetaverse.\nOn 22 September 2021, the Neopets Metaverse NFT project was announced in collaboration with JumpStart, Cherrypicks, Raydium, and Moonvault. The Neopets Metaverse was to feature a \"modernised 3D remake of the classic Neopets game\" where players would be required to own Neopets NFTs to play. Prior to the official launch of the metaverse, the project put 20,000 Neopets NFTs up for sale but only 4,225 were purchased. A unique visual glitch revealed that at least one of the promotional images on the Neopets Metaverse website advertising these NFTs was generated using the Neopets fan site Dress to Impress; the image was replaced shortly after it was noticed. The project received a significant amount of criticism from within the Neopets community and it was formally canceled in July 2023.\nWorld of Neopia (2023\u2013present).\nOn 17 July 2023, it was announced that Neopets had been purchased from NetDragon through a management buyout deal led by Neopets Chief Metaverse Officer Dominic Law, the former Director of New Markets at both NetDragon and Cherrypicks. The resulting independent company, World of Neopia Inc., is composed of team members from both Neopets and Neopets Metaverse, including Dominic Law as CEO. It was also stated that the site had operated at a loss for over a decade and it announced that Neopets had received $4 million in investment funding in early 2023. Additional funding from the management buyout is said to equip World of Neopia, Inc. to make \"meaningful changes in pursuit of a Neopian renaissance.\" The changes include a homepage revamp and plans to create a mobile app. Following the transition, it was reported that the site achieved its highest revenue stream in 2023 since 2017 (which was the same year Netdragon acquired Jumpstart), and had tripled its monthly active userbase from 100,000 to 300,000 users by April 2024. Dominic Law also claimed that the company was on track to be profitable by the end of 2024. It was also reported that the site demographics had shifted to be significantly older compared to when the website was at its peak, with the majority of users now being over the age of 18 with 40% being reported to between the ages of 25 and 34, and 26% of users being between the ages of 18 and 24, which was reportedly due to many users of the site now being drawn to use Neopets due to nostalgia reasons.\nGameplay.\n\"Neopets\" allows users to create and care for digital pets called \"Neopets\" and explore the virtual world of Neopia. There is no set objective for the users, but they are expected to feed and care for their Neopets when they grow hungry or ill. Neopets will not die if neglected, but their health can limit their gameplay.\nNeopets come in a variety of species and colors and users can create or adopt their own. Users can obtain items to interact with their Neopet, such as books to read and toys to play with them. Neopets can be customised with certain clothing items, paintbrushes, morphing potions, and accessories. Neopets themselves can have pets of their own called Petpets.\nUsers can build a customisable Neohome for their Neopets and furnish it with furniture, wallpaper, and flooring. Neopets can battle against other Neopets or non-player characters in the Battledome but they cannot die there.\nNeopia is a virtual planet with fantasy lands inhabited by Neopets and other virtual creatures. Each land has a different theme, such as pirates or prehistory, and their own shops, games, and attractions. Neopia follows its own calendar and time zone, which runs concurrent with real-world Pacific Time, and has tie-ins with certain real-world holidays such as Halloween and Christmas.\nIt has its own economy and trade markets based on Neopoints. Users can earn Neopoints through various means including playing games and selling items, which can be invested or used to buy various virtual goods and services.\nThe site is regularly updated with features like new games, items, and content. Occasionally, the Neopets team release interactive storylines to expand the in-universe lore. In addition to the site content updated by the Neopets team, users also contribute content to the site. User contributions come in the form of prescreened submissions and readily editable content that is automatically filtered, such as the site's weekly electronic newspaper \"The Neopian Times\". There are different types of submissions that will be accepted.\nGames.\nUsers can earn Neopoints from playing games. Games come in many different genres, which include action, puzzles, and chance. Most games have set maximum earnings or playtime. Players may also earn trophies and other awards from games if they score high enough or perform better than other users. Both single-player and multiplayer browser games are available.\nThe site houses over 100 games; the earliest games released were simple browser-based PHP games. Most of the site's games run on Adobe Flash Player, while a handful of others use Adobe Shockwave Player. In April 2020, in anticipation of the discontinuation of Adobe Flash, \"Neopets\" released HTML5 versions of seven of these games, followed by the release of an additional three in October 2021. In January 2021, Adobe Flash was discontinued, making most of the original Adobe Flash games impossible to play without workarounds. In July 2023, most of the original Flash games were restored via the site's integration with the Ruffle Adobe Flash emulator, with some games experiencing compatibility issues.\nUsers can also participate in contests and spotlights judged by staff to showcase the users' talents. Quests to retrieve items may also be performed for specific NPCs. Challenges may be made against other players or random players in a \"World Challenge\" for a prize piece and Neopoints from the jackpot for certain web games. Monthly competitions also exist for multiplayer games with four week-long elimination rounds.\nEconomy.\nThe economy is based on Neopoints. Users can also exchange real money for Neocash, used exclusively for the NC Mall. Users can earn Neopoints through playing games, selling items, and other transactions. Once earned, they can be saved in the bank, used to buy items from other users or non-player character (NPC) shops, used to buy and sell stocks in the Neopian stock market called the NEODAQ (a parody of the NASDAQ), or used to buy various other things. Items can be bought from shops found throughout the world of Neopia that are run by NPCs who may allow bargaining. Users can open their own shops to sell items, sometimes after obtaining those items at a lower price from sources such as other shops or charities. Items may also be exchanged through trading or auctions.\nBlack market.\nIn 2021, it was reported that a black market had arisen on the site, mainly driven around unconverted Neopets that had become unavailable for new users after the art style for default Neopets changed in 2007. As not all Neopets were converted during the art style change, unconverted Neopets had become valuable. A number of these unconverted Neopets were stolen from users by others who used them in both on and offsite transactions and sold for real money. This black market had reportedly existed for years without intervention until 2024. In January 2024, \"Neopets\" announced the launch of the Styling Studio and Style Tokens. By using NeoCash, users can purchase Styling Studio Supplies which can then be used to obtain Style Tokens. These tokens allow for the toggling and use of old and alternative pet art.\nCommunity.\n\"Neopets\" has a community for users to chat with and contact other users. Each user has their own profile they can edit with HTML and CSS and are represented by avatars provided by the website, as users cannot upload their own. Most avatars must be \"unlocked\" by completing certain in-game tasks, such as winning a contest or getting a high score on a game.\nUsers may request other users to be \"Neofriends\" or block other users from contacting them. To comply with COPPA, users under 13 years of age cannot access any of the site's communication features without sending in parental consent via fax. The main features include:\nDiscussions through these features are restricted and may not involve topics such as dating and romance or controversial topics like politics and religion. Continuous moderation is performed by paid \"Neopets\" staff members, and users can help moderate the site by reporting messages they believe are inappropriate or offensive. Messages are also automatically filtered to prevent users from posting messages with profanity or lewd content.\nReception.\nDescribed as an online cross of \"Pok\u00e9mon\" and \"Tamagotchi\", \"Neopets\" has received both praise and criticism. It has been praised for having educational content. Children can learn HTML to edit their own pages. They can also learn how to handle money by participating in the economy. Reviews from About.com and MMO Hut considered the multitude of possible activities a positive aspect. Most of the users are female, higher than in other massively multiplayer online games (MMOGs) but equivalent to social-networking-driven communities. Lucy Bradshaw, a vice president of Electronic Arts, attributes the popularity among girls to the openness of the site and said, \"Games that have a tendency to satisfy on more than one dimension have a tendency to have a broader appeal and attract girls\".\nLuck &amp; chance games draw criticism from parents as they introduce children to gambling. In Australia, a cross-promotion with McDonald's led to controversy with \"Neopets\"' luck/chance games in October 2004. Australian tabloid television show \"Today Tonight\" featured a nine-year-old boy who claimed the site requires one to gamble in order to earn enough Neopoints to feed one's Neopet or else it would be sent to the pound. While gambling is not required, nor are pets sent to the pound if unfed, the website includes games of chance based on real games such as blackjack and lottery scratchcards. After this incident, \"Neopets\" prohibited users under the age of 13 from playing Neopets's casino-style games.\nImmersive advertising.\nImmersive advertising is a trademarked term for the way \"Neopets\" displayed advertisements to generate profit after Doug Dohring bought the site. Unlike pop-up and banner ads, immersive ads integrate advertisements into the site's content in interactive forms, including games and items. Players could earn Neopoints from them by playing advergames and taking part in online marketing surveys. Prior to the arrival of the NC Mall, it contributed to 60% of the revenue from the site with paying Fortune 1000 companies including Disney, General Mills, and McDonald's.\nIt was a contentious issue with the site with regard to the ethics of marketing to children. It drew criticism from parents, psychologists, and consumer advocates who argued that children may not know that they are being advertised to, as it blurred the line between site content and advertisement. Children under eight had difficulty recognizing ads and half a million of the 25 million users were under the age of eight in 2005. Dohring responded to such criticism stating that of the 40 percent of users twelve and younger, very few were seven or eight years old and that preschoolers were not their target audience.\nOthers criticised the functionality of the site. Susan Linn, another psychologist and author of \"Consuming Kids: The Hostile Takeover of Childhood\" considered the purpose of this site was to keep children in front of advertisements. Kalle Lasn, editor-in-chief and co-founder of \"Adbusters\" magazine, said the site encouraged kids to spend hours in front of a screen and recruited them to consumerism. \"Neopets\" executives stated that paid content constituted less than 1% of the site's total content. Children were not required to play or use sponsor games and items, and all ads were marked as such.\nCustomer security.\nIn July 2009, it was reported that the \"Neopets\" site was the target of an identity theft scheme that attempted to trick users into clicking a link that would install malware onto the user's computer. According to reports, the scheme was aimed not at child players' \"Neopets\" accounts, but at using the malware to steal the financial data and identities of their parents. Viacom stated that it was investigating the issue, and that the reports referred to a version of social engineering rather than an \"indictment of Neopets security practices\". In an on-site newsletter, \"Neopets\" claimed that the site's security measures prevented the posting of such links.\nIn 2016, Motherboard reported that the account information of an alleged 70 million of Neopets accounts had been compromised. The hack contained usernames, passwords, email addresses, birth dates, gender, and country from 2012 (prior to JumpStart's acquisition), but did not contain credit card information or physical addresses. Neopets responded by sending emails to all affected players.\nOn 20 July 2022, Neopets confirmed that it had suffered a data breach the day prior. The data breach exposed Neopets' entire database schema, including usernames, emails and passwords of its 69 million users. Neopets responded by forcing a password reset for all users on 1 August 2022, causing some players to be locked out as they no longer had access to the e-mail addresses linked to their accounts. On 29 August 2022 Neopets sent an e-mail to users detailing the results of their subsequent investigation.\nMerchandise.\nThe popularity of \"Neopets\" spawned real-world merchandise including clothing, jewelry, stickers, books, cereals, video games and more, sold at mainstream outlets and online retailers. \"Neopets\" merchandise often contains a code which can be redeemed on the site for an in-game reward. In 2003, Doug Dohring said that \"Neopets\" had always planned to \"bring the online and offline worlds together in ways that have never been done before\".\nNeopets, Inc. signed various licensing deals with companies such as Viacom Consumer Products, Thinkway Toys, and Jakks Pacific over the years. \"Neopets: The Official Magazine\" was a bi-monthly magazine launched in September 2003; it was replaced in 2008 by \"Beckett Plushie Pals\", which featured \"Neopets\" news as well as other companies' products such as Webkinz. Wizards of the Coast released the \"Neopets Trading Card Game\" in September 2003, which was promoted in three of General Mills \"Big G\" cereals and ten Simon Property Group malls. It received two different nominations for \"Toy of the Year\" as well as other recognitions before being discontinued in 2006. In June 2024, Upper Deck Company released a new trading card game called the \"Neopets Battledome Trading Card Game\".\nIn 2005, it was announced that a \"Neopets\" feature film was in production. It was to be written by Rob Lieber and produced by Dylan Sellers and John A. Davis for Warner Bros., but the project was later cancelled. On 10 February 2020, Blue Ant Media's Beach House Pictures announced that a \"Neopets\" animated television series was in development and was set to air in 2021, though there have been no recent updates.\nVideo games.\nIn 2005, \"Neopets\" expanded to video game deals. Two video games were released by Sony Computer Entertainment, ' for the PlayStation 2 in 2005 and ' for the PlayStation Portable in 2006. In 2007, MumboJumbo developed the match-3 PC game \"Neopets: Codestone Quest\". In 2008, \"Neopets Puzzle Adventure\" was released for Nintendo DS, Wii, and PC. The following year, the handheld game \"Neopets: Quizara's Curse\" was released for the LeapFrog Didj. In August 2011, \"Neopets\" launched the tie-in game \"Treasure Keepers\" on Facebook, but it was discontinued in December of that year.\nA number of \"Neopets\" mobile games for Android and iOS have also been released. In 2015, \"Neopets\" released the match-3 game \"Ghoul Catchers\". In 2019, \"Neopets\" released the puzzle game \"Legends and Letters\". Both \"Ghoul Catchers\" and \"Legends and Letters\" were discontinued in May 2020. In May 2022, \"Neopets\" released the construction simulation game \"Island Builders\". In December 2022, \"Neopets\" released the match-3 game \"Faerie's Hope\". In Spring 2024, \"Island Builders\" was relaunched under the new name \"Tales of Dacardia\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
