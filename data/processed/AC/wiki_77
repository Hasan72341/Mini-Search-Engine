{"id": "27706", "revid": "50714273", "url": "https://en.wikipedia.org/wiki?curid=27706", "title": "Satanism", "text": "Religious, ideological, or philosophical beliefs based on Satan\nSatanism refers to a group of religious, ideological, or philosophical beliefs based on Satan\u2014particularly his worship or veneration. Because of the ties to the historical Abrahamic religious figure, Satanism\u2014as well as other religious, ideological, or philosophical beliefs that align with Satanism\u2014is considered a countercultural Abrahamic religion.\nThe phenomenon of Satanism shares \"historical connections and family resemblances\" with the Left Hand Path milieu of other occult figures such as Asmodeus, Beelzebub, Hecate, Lilith, Lucifer, Mephistopheles, Pan, Prometheus, Samael, and Set. Self-identified Satanism is a relatively modern phenomenon, largely attributed to the 1966 founding of the Church of Satan by Anton LaVey in the United States\u2014an atheistic group that does not believe in a supernatural Satan.\nAccusations of groups engaged in \"devil worship\" have echoed throughout much of Christian history. During the Middle Ages, the Inquisition led by the Catholic Church alleged that various heretical Christian sects and groups, such as the Knights Templar and the Cathars, performed secret Satanic rituals. In the subsequent Early Modern period, belief in a widespread Satanic conspiracy of witches resulted in the trials and executions of tens of thousands of alleged witches across Europe and the North American colonies, peaking between 1560 and 1630. The terms \"Satanist\" and \"Satanism\" emerged during the Reformation and Counter-Reformation (1517\u20131700), as both Catholics and Protestants accused each other of intentionally being in league with Satan.\nSince the 19th century various small religious groups have emerged that identify as Satanist or use Satanic iconography. While the groups that appeared after the 1960s differed greatly, they can be broadly divided into nontheistic Satanism and theistic Satanism. Those venerating Satan as a supernatural deity are unlikely to ascribe omnipotence, instead relating to Satan as a patriarch. Nontheistic Satanists regard Satan as a symbol of certain human traits, a useful metaphor without ontological reality. Contemporary religious Satanism is predominantly an American phenomenon, although the rise of globalization and the Internet have seen these ideas spread to other parts of the world.\nEtymology and definitions.\nEtymology.\nThe term \"Satan\" has evolved from a Hebrew term for \"adversary\" or \"to oppose\", into the Christian figure of a fallen angel who tempts mortals into sin. The word \"Satan\" was not originally a proper name, but rather an ordinary noun that means \"adversary\". In this context, it appears at several points in the Old Testament. For instance, in the Book of Samuel, David is presented as the satan (\"adversary\") of the Philistines, while in the Book of Numbers, the term appears as a verb, when Jehovah sent an angel to satan (\"to oppose\") Balaam.\nPrior to the composition of the New Testament, the idea developed within Jewish communities that Satan was the name of an angel who had rebelled against Jehovah and had been cast out of Heaven along with his followers; this account would be incorporated into contemporary texts such as the Book of Enoch. This Satan was then featured in parts of the New Testament, where he was presented as a figure who tempts humans to commit sin; in the Book of Matthew and the Book of Luke, he attempted to tempt Jesus of Nazareth as the latter fasted in the wilderness.\nWhile the early Christian idea of the Devil was not well developed, it gradually adapted and expanded through the creation of folklore, art, theological treatises, and morality tales, thus providing the character with a range of extra-Biblical associations. Beginning in the early middle ages, the concept developed in Christianity of the devil as \"archrepresentative of evil\", and of the Satanist \"as malign mirror image of the good Christian\".\nThe word \"Satanism\" was adopted into English from the French \"satanisme\". The terms \"Satanism\" and \"Satanist\" are first recorded as appearing in the English and French languages during the 16th century, when they were used by Christian groups to attack other, rival Christian groups. In a Roman Catholic tract of 1565, the author condemns the \"heresies, blasphemies, and sathanismes [sic]\" of the Protestants. In an Anglican work of 1559, Anabaptists and other Protestant sects are condemned as \"swarmes of Satanistes [sic]\". As used in this manner, the term \"Satanism\" was not used to claim that people literally worshipped Satan, but instead that they deviated from true Christianity, and thus were serving the will of Satan. During the 19th century, the term \"Satanism\" began to be used to describe those considered to lead a broadly immoral lifestyle, and it was only in the late 19th century that it came to be applied in English to individuals who were believed to consciously and deliberately venerate Satan. This latter meaning had appeared earlier in the Swedish language; the Lutheran Bishop Laurentius Paulinus Gothus had described devil-worshipping sorcerers as \"Sathanister\" in his \"Ethica Christiana\", produced between 1615 and 1630.\nDefinitions.\nSome definitions of Satanism:\n1) the worship of the character in the Bible whose name is Satan or Lucifer,\n2) the organization of these \"Satanists\" into a group with at least some kind of organization and hierarchy, and ...\n3) and has some kind of ritual or liturgical practices [...]\nwhether the group with these characteristics perceives Satan as personal or impersonal, real or symbolic, does not matter.\nBut these definitions of Satanism are limited to \n... excluding \nAccording to Laycock, excluding the second group, you leave out most of the history of Satanism.\nIf you \"do\" include both groups, you have two sides with very different views on who or what Satan was/is and represented. The accusers usually follow the Christian idea of Satan as an irredeemably evil fallen angel who seeks the destruction of both God and humanity, but who, along with his followers, is doomed to fail and to suffer eternal punishment. While the self-identified Satanists often do not believe that Satan actually exists as a being (they believe he is a symbol and a \"Promethean figure\", \"an esoteric symbol of a vital force that permeates the universe\"), let alone is trying to destroy humanity.\nDefinitions that would include the \"satanism\" of heresy crusades and moral panics is:\nIn their study of Satanism, the religious studies scholars Asbj\u00f8rn Dyrendal, James R. Lewis, and Jesper Aa. Petersen stated that the term \"Satanism\" \"has a history of being a designation made by people against those whom they dislike; it is a term used for 'othering'\". \nEugene Gallagher noted that Satanism was usually \"a polemical, not a descriptive term\".\nSimilar to the way certain Christian denominations accuse each other of heresy, different satanic groups\u2014mainly the Church of Satan (CoS), the Temple of Set (ToS), the Order of Nine Angles (ONA), and The Satanic Temple (TST)\u2014often accuse one another of being fraudulent Satanists and/or ignorant of true Satanism.\nRelated terms.\nBecause the original concept of Satan came from Judaism and was embraced by Christianity, and because Satanists, almost by definition, oppose the teachings of those religions, people drawn to Satanism will often move on to \"post-Satanism\", i.e. to a religion that does not declare itself \"Satanic\", but includes elements of Satanism (e.g. Temple of Set). Others may regards themselves as Satanists but promote mythological figures and traditions outside of Christianity or Judaism. These religions are sometimes called Satanic and sometimes post-Satanic.\nDiane E. Taub and Lawrence D. Nelson complain that Satanism \"is frequently defined either too broadly or too narrowly\", with accusers sometimes including non-satanic groups such as Santeria, Witchcraft, Eastern religions as well as Freemasonry; and academics (for example Carlson and Larue) and others sometimes restricting its definition to \"recognized Satanic churches and their members\", excluding those who \"believes in a literal Satan\". Taub and Nelson define Satanism as \"the literal or symbolic worship of Satan, the enemy of the Judeo-Christian God\".\nDevil in society.\nHistorical and anthropological research suggests that nearly all societies have developed the idea of a sinister and anti-human force that can hide itself within society. This commonly involves a belief in witches, a group of individuals who invert the norms of their society and seek to harm their community, for instance by engaging in incest, murder, and cannibalism. Allegations of witchcraft may have different causes and serve different functions within a society. For instance, they may serve to uphold social norms, to heighten the tension in existing conflicts between individuals, or to scapegoat certain individuals for various social problems.\nAnother contributing factor to the idea of Satanism is the concept that there is an agent of misfortune and evil who operates on a cosmic scale, something usually associated with a strong form of ethical dualism that divides the world clearly into forces of good and forces of evil. The earliest such entity known is Angra Mainyu, a figure that appears in the Persian religion of Zoroastrianism. This concept was also embraced by Judaism and early Christianity, and although it was soon marginalized within Jewish thought, it gained increasing importance within early Christian understandings of the cosmos.\nThe Native South American terrible god Tiw is traditionally honored with the syncretic dance and parade \"Diablada\" ('Dance of the Devils') that was opposed to the Catholic Church in origin.\nAccusations of Satanism.\nAccording to author Arthur Lyons, \"Satanic religions are as old as monotheism and have their origins in Persia of the sixth century\",\nand Joe Carter of the conservative ecumenical journal \"First Things\" writes that \"real satanism has been around since the beginning of history, selling an appealing message: Your eyes will be opened, and you will be like God.\"\nOn the other hand, religious scholar Joseph Laycock writes that the \"available evidence suggests\" that Satanism began as \"an imaginary religion Christians invented to demonize their opponents\".\nConfessions of worship of Satan came only after torture or other forms of coercion in early modern Europe. While early stories of satanic activity have been commonly labeled and regarded as propaganda based on falsehood, they also partially shaped the beliefs of what would become modern religious Satanism. Those who absorbed and accepted the tales sometimes began to imitate them (celebrating Black Masses for example), a process known to folklorists as \"ostension\".\nMedieval and Early Modern Christendom.\nAs Christianity expanded throughout the Middle East, North Africa, and Europe, it came into contact with a variety of other religions, which it regarded as \"pagan\". Christianity being a monotheist religion, Christian theologians believed that since there was only one God (the God of Christianity) the gods and goddesses with supernatural powers venerated by these \"pagans\" could not be genuine divinities but must actually be demons. However, they did not believe that \"pagans\" were deliberately worshipping devils, but were instead simply misguided and unaware of the \"true\" God.\nThose Christian groups regarded as heretics by the Roman Catholic Church were treated differently, with theologians arguing that they were deliberately worshipping the Devil. This was accompanied by claims that such individuals engaged in acts of evil\u2014incestuous sexual orgies, the murder of infants, and cannibalism\u2014all stock accusations that had previously been leveled at Christians themselves in the Roman Empire. In Christian iconography, the Devil and demons were given the physical traits of figures from classical mythology, such as the god Pan, fauns, and satyrs.\nThe first recorded example of such an accusation being made within Western Christianity took place in Toulouse in 1022, when two clerics were tried for allegedly venerating a demon. Throughout the Middle Ages, this accusation would be applied to a wide range of Christian heretical groups, including the Paulicians, Bogomils, Cathars, Waldensians, and the Hussites. The Knights Templar were accused of worshipping an idol known as Baphomet, with Lucifer having appeared at their meetings in the form of a cat. As well as these Christian groups, these claims were also made about Europe's Jewish community. In the 13th century, there were also references made to a group of \"Luciferians\" led by a woman named Lucardis which hoped to see Satan rule in Heaven. References to this group continued into the 14th century, although historians studying the allegations concur that these Luciferians were probably a fictitious invention.\nWithin Christian thought, the idea developed that certain individuals could make a pact with Satan. This may have emerged after observing that pacts with gods and goddesses played a role in various pre-Christian belief systems, or that such pacts were also made as part of the Christian cult of saints. Another possibility is that it derives from a misunderstanding of Augustine of Hippo's condemnation of augury in his \"On Christian Doctrine\", written in the late 4th century. Here, he stated that people who consulted augurs were entering \"quasi pacts\" (covenants) with demons. The idea of the diabolical pact made with demons was popularized across Europe in the story of Faust, probably based in part on the real life Johann Georg Faust.\nAs the late medieval gave way to the early modern period, European Christendom experienced a schism between the established Roman Catholic Church and the breakaway Protestant movement. In the ensuing Reformation and Counter-Reformation (1517\u20131700 CE), both Catholics and Protestants accused each other of deliberately being in league with Satan. It was in this context that the terms \"Satanist\" and \"Satanism\" emerged.\nWitch trials.\nThe early modern period also saw fear of Satanists reach its \"historical apogee\" in the form of the witch trials of the fifteenth to the eighteenth centuries, when between 40,000 and 60,000 were executed, almost all in Europe. This came about as the accusations which had been leveled at medieval heretics, among them that of devil-worship, were applied to the pre-existing idea of the witch, or practitioner of malevolent magic. The idea of a conspiracy of Satanic witches was developed by educated elites, although the concept of malevolent witchcraft was a widespread part of popular belief, and folkloric ideas about the night witch, the wild hunt, and the dance of the fairies were incorporated into it. The earliest trials took place in Northern Italy and France, before spreading it out to other areas of Europe and to Britain's North American colonies, being carried out by the legal authorities in both Catholic and Protestant regions.\nMost historians agree that the majority of those persecuted in these witch trials were innocent of any involvement in Devil worship. Historian Darren Eldridge writes that claims that there actually was a cult of devil-worshippers being pursued by witch hunters \"have not survived the scrutiny of surviving trial records\" done by historians from 1962 to 2012.\nHowever, in their summary of the evidence for the trials, the historians Geoffrey Scarre and John Callow thought it \"without doubt\" that some of those accused in the trials had been guilty of employing magic in an attempt to harm their enemies and were thus genuinely guilty of witchcraft.\nAffair of the Poisons.\nIn a scandal starting with the poisoning of three people, prominent members of the French aristocracy, including members of the king's inner circle, were implicated and sentenced on charges of poisoning and witchcraft. Between 1677 and 1682, during the reign of King Louis XIV, 36 people were executed in Satanic panic known to history as the Affair of the Poisons. At least some of the accusers were implicated others under torture and in hopes of saving their lives. These highly unreliable reports include what \"may be the first report of a satanic mass using a woman as an altar\".\n18th- to 20th-century Christendom.\nThe Enlightenment and Scientific Revolution changed humanity's understanding of the world. The mathematics of Isaac Newton and psychology of John Locke \"left little space for the intervention of supernatural beings\". Charles Darwin's theory of evolution undermined the doctrine of the Fall in the Garden of Eden and the role of the diabolical serpent, while also providing an \"alternative account of human evil\" in the form of \"a residual effect of our animal nature\". The Industrial Revolution and urbanization disturbed traditional social relations and folk ideas to undermine belief in witchcraft and the devil. Understanding of disorders of the mind undercut demonic possession. But while the hunting and killing of alleged witches waned, belief in Satan did not disappear.\nDuring the 18th century, gentleman's social clubs became increasingly prominent in Britain and Ireland, among the most secretive of which were the Hellfire Clubs, which were first reported in the 1720s. The most famous of these groups was the Order of the Knights of Saint Francis, which was founded circa 1750 by the aristocrat Sir Francis Dashwood and which assembled first at his estate at West Wycombe and later in Medmenham Abbey. A number of contemporary press sources portrayed these as gatherings of atheist rakes where Christianity was mocked, and toasts were made to the Devil. Beyond these sensationalist accounts, which may not be accurate portrayals of actual events, little is known about the activities of the Hellfire Clubs. Introvigne suggested that they may have engaged in a form of \"playful Satanism\" in which Satan was invoked \"to show a daring contempt for conventional morality\" rather than to pay homage to him.\nThe French Revolution of 1789 dealt a blow to the hegemony of the Roman Catholic Church in parts of Europe, and soon a number of Catholic authors began making claims that it had been masterminded by a conspiratorial group of Satanists. Among the first to do so was French Catholic priest Jean-Baptiste Fiard, who publicly claimed that a wide range of individuals, from the Jacobins to tarot card readers, were part of a Satanic conspiracy. Fiard's ideas were furthered by Alexis-Vincent-Charles Berbiguier de Terre-Neuve du Thym (1765\u20131851), who devoted a lengthy book to this conspiracy theory; he claimed that Satanists had supernatural powers allowing them to curse people and to shapeshift into both cats and fleas. Although most of his contemporaries regarded Berbiguier as suffering from mental illness, his ideas gained credence among many occultists, including Stanislas de Guaita, a Cabalist who used them for the basis of his book, \"The Temple of Satan\".\nA reaction to this was the Taxil hoax in 1890s France, where an anti-clerical writer L\u00e9o Taxil (aka Marie Joseph Gabriel Antoine Jogand-Pag\u00e8s), publicly converted to Catholicism and then published several works alleging to expose the Satanic doings of Freemasons. In 1897, Taxil called a press conference promising to introduce a key character of his stories but instead announced that his revelations about the Freemasons were made up, and thanked the Catholic clergy for helping to publicize his stories. Nine years later he told an American magazine that at first he thought readers would recognize his tales as obvious nonsense, \"amusement pure and simple\", but when he realized they believed his stories and that there was \"lots of money\" to be made in publishing them, he continued to perpetrate the hoax. Around the same time, another convert to Catholicism Joris-Karl Huysmans, also helped promote the concept of active Satanist groups in his 1891 work \"L\u00e0-bas\" (Down There). Huysmans \"helped to cement\" the idea the black mass as Satanic rite and inversion of the Roman Catholic mass, with a naked woman for an altar. (Unlike Taxil, his conversion was apparently genuine and his book was published as fiction.)\nIn the early 20th century, the British novelist Dennis Wheatley produced a range of influential novels in which his protagonists battled Satanic groups. At the same time, non-fiction authors such as Montague Summers and Rollo Ahmed published books claiming that Satanic groups practicing black magic were still active across the world, although they provided no evidence that this was the case. During the 1950s, various British tabloid newspapers repeated such claims, largely basing their accounts on the allegations of one woman, Sarah Jackson, who claimed to have been a member of such a group. In 1973, the British Christian Doreen Irvine published \"From Witchcraft to Christ\", in which she claimed to have been a member of a Satanic group that gave her supernatural powers, such as the ability to levitate, before she escaped and embraced Christianity.\nIn the United States during the 1960s and 1970s, various Christian preachers\u2014the most famous being Mike Warnke in his 1972 book \"The Satan-Seller\"\u2014claimed that they had been members of Satanic groups who carried out sex rituals and animal sacrifices before discovering Christianity. According to Gareth Medway in his historical examination of Satanism, these stories were \"a series of inventions by insecure people and hack writers, each one based on a previous story, exaggerated a little more each time\".\nOther publications made allegations of Satanism against historical figures. The 1970s saw the publication of the Romanian Protestant preacher Richard Wurmbrand's book in which he argued\u2014without corroborating evidence\u2014that the socio-political theorist Karl Marx had been a Satanist.\nRitual abuse hysteria.\nAt the end of the 20th century, a moral panic arose from claims that a Devil-worshipping cult was committing sexual abuse, murder, and cannibalism in its rituals, and including children among the victims of its rites. Initially, the alleged perpetrators of such crimes were labeled \"witches\", although the term \"Satanist\" was soon adopted as a favored alternative, and the phenomenon itself came to be called \"the Satanism Scare\". Those active in the scare alleged that there was a conspiracy of organized Satanists who occupied prominent positions throughout society, from the police to politicians, and that they had been powerful enough to cover up their crimes.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nPreceded by some significant but isolated episodes in the 1970s, a great Satanism scare exploded in the 1980s in the United States and Canada and was subsequently exported towards England, Australia, and other countries. It was unprecedented in history. It surpassed even the results of Taxil's propaganda, and has been compared with the most virulent periods of witch hunting. The scare started in 1980 and declined slowly between 1990... and 1994, when official British and American reports denied the real existence of ritual satanic crimes. Particularly outside the U.S. and U.K., however, its consequences are still felt today.\nSociologist of religion Massimo Introvigne, 2016\nOne of the primary sources for the scare was \"Michelle Remembers\", a 1980 book by the Canadian psychiatrist Lawrence Pazder in which he detailed what he claimed were the repressed memories of his patient (and wife) Michelle Smith. Smith had claimed that as a child she had been abused by her family in Satanic rituals in which babies were sacrificed and Satan himself appeared. In 1983, allegations were made that the McMartin family\u2014owners of a preschool in California\u2014were guilty of sexually abusing the children in their care during Satanic rituals. The allegations resulted in a lengthy and expensive trial, in which all of the accused would eventually be cleared. The publicity generated by the case resulted in similar allegations being made in various other parts of the United States.\nA key claim by the \"anti-Satanists\" of the Satanic Scare was that any child's claim about Satanic ritual abuse must be true, because children do not lie. Although some involved in the anti-Satanism movement were from Jewish and secular backgrounds, a central part was played by fundamentalist and evangelical Christians, in particular Pentecostal Christians, with Christian groups holding conferences and producing books and videotapes to promote belief in the conspiracy. Various figures in law enforcement also came to be promoters of the conspiracy theory, with such \"cult cops\" holding various conferences to promote it. The scare was later imported to the United Kingdom through visiting evangelicals and became popular among some of the country's social workers, resulting in a range of accusations and trials across Britain.\nIn the late 1980s, the Satanic Scare had lost its impetus following increasing skepticism about such allegations, and a number of those who had been convicted of perpetrating Satanic ritual abuse saw their convictions overturned. In 1990, an agent of the U.S. Federal Bureau of Investigation, Ken Lanning, revealed that he had investigated 300 allegations of Satanic ritual abuse and found no evidence for Satanism or ritualistic activity in any of them. In the UK, the Department of Health commissioned the anthropologist Jean La Fontaine to examine the allegations of SRA. She noted that while approximately half did reveal evidence of genuine sexual abuse of children, none revealed any evidence that Satanist groups had been involved or that any murders had taken place. She noted three examples in which lone individuals engaged in child molestation had created a ritual performance to facilitate their sexual acts, with the intent of frightening their victims and justifying their actions, but that none of these child molesters were involved in wider Satanist groups.\nBy 1994, the Satanic ritual abuse hysteria had died down in the US and UK, and by the 21st century, hysteria about Satanism has waned in most Western countries, although allegations of Satanic ritual abuse continued to surface in parts of continental Europe and Latin America. In the United States SRA ideas persisted among much of the public even as law enforcement had grown tired of false leads. A 1994 survey for the women's magazine \"Redbook\" reported in 1994, \nQAnon.\nAnother Satanic conspiracy theory arose in the United States by 2017, with unsubstantiated allegations of organized Devil-worshippers in prominent positions committing sexual abuse, murder, and cannibalism. The source of such claims began within a far-right political movement, made by an anonymous individual or individuals known as \"Q\", which were relayed and developed by online communities and influencers. The central QAnon claim purports that a global child sex trafficking ring made up of Democratic politicians, Hollywood actors, high-ranking government officials, business tycoons, and medical experts, were kidnapping, sexually abusing and eating children, but that (then-President) Donald Trump would round up the cabal and bring them to justice in a climactic event known to supporters as \"the storm\". With the lack of any evidence of child abuse or harm, and failure of the prophesized \"storm\" to appear before the inauguration of a new president, the conspiracy has waned but not entirely disappeared.\nPrecursors of modern Satanism.\nLiterary.\nFrom the late 1600s through to the 1800s, the character of Satan was increasingly rendered unimportant in western philosophy, and ignored in Christian theology, while in folklore he came to be seen as a foolish rather than a menacing figure. The development of new values in the Age of Enlightenment (in particular, those of reason and individualism) contributed to a shift in many Europeans' concept of Satan. In this context, a number of individuals took Satan out of the traditional Christian narrative and reread and reinterpreted him in light of their own time and their own interests, in turn generating new and different portraits of Satan.\nThe shifting concept of Satan owes many of its origins to John Milton's epic poem \"Paradise Lost\" (1667), in which Satan features as the protagonist. Milton was a Puritan and had never intended for his depiction of Satan to be a sympathetic one. However, in portraying Satan as a victim of his own pride who rebelled against the Judeo-Christian god, Milton humanized him and also allowed him to be interpreted as a rebel against tyranny. In this vein, the 19th century saw the emergence of what has been termed \"literary Satanism\" or \"romantic Satanism\", where in poetry, plays, and novels, God is portrayed not as benevolent but using His omnipotent power for tyranny. Whereas in Christian doctrine Satan was an enemy of not only god but humanity, in the romantic portrayal he was a brave, noble, rebel against tyranny, a friend to other victims of the all powerful bully, i.e. humans. These writers saw Satan as a metaphor to criticize the power of churches and state and to champion the values of reason and liberty.\nThis was how Milton's Satan was understood by John Dryden and later readers such as the publisher Joseph Johnson, and the anarchist philosopher William Godwin, who reflected it in his 1793 book \"Enquiry Concerning Political Justice\". \"Paradise Lost\" gained a wide readership in the 18th century, both in Britain and in continental Europe, where it had been translated into French by Voltaire. Milton thus became \"a central character in rewriting Satanism\" and would be viewed by many later religious Satanists as a \"\"de facto\" Satanist\".\nAccording to Ruben van Luijk, this cannot be seen as a \"coherent movement with a single voice, but rather as a \"post factum\" identified group of sometimes widely divergent authors among whom a similar theme is found\". For the literary Satanists, Satan was depicted as a benevolent and sometimes heroic figure, with these more sympathetic portrayals proliferating in the art and poetry of many romanticist and decadent figures. For these individuals, Satanism was not a religious belief or ritual activity, but rather a \"strategic use of a symbol and a character as part of artistic and political expression\".\nAmong the romanticist poets to adopt this concept of Satan was the English poet Percy Bysshe Shelley, who had been influenced by Milton. In his poem \"Laon and Cythna\", Shelley praised the \"serpent\", a reference to Satan, as a force for good in the universe.\nAnother was Shelley's fellow British poet Lord Byron, who included Satanic themes in his 1821 play \"Cain\", which was a dramatization of the Biblical story of Cain and Abel. These more positive portrayals also developed in France; one example was the 1823 work \"Eloa\" by Alfred de Vigny. Satan was also adopted by the French poet Victor Hugo, who made the character's fall from Heaven a central aspect of his \"La Fin de Satan\", in which he outlined his own cosmogony.\nAlthough the likes of Shelley and Byron promoted a positive image of Satan in their work, there is no evidence that any of them performed religious rites to venerate him, and thus they cannot be considered to be religious Satanists.\nRadical left-wing political ideas had been spread by the American Revolution of 1775\u201383 and the French Revolution of 1789\u201399. The figure of Satan, who was seen as having rebelled against the tyranny imposed by Jehovah, was appealing to many of the radical leftists of the period. For them, Satan was \"a symbol for the struggle against tyranny, injustice, and oppression... a mythical figure of rebellion for an age of revolutions, a larger-than-life individual for an age of individualism, a free thinker in an age struggling for free thought\". The French anarchist Pierre-Joseph Proudhon, who was a staunch critic of Christianity, embraced Satan as a symbol of liberty in several of his writings. Another prominent 19th century anarchist, the Russian Mikhail Bakunin, similarly described the figure of Satan as \"the eternal rebel, the first freethinker and the emancipator of worlds\" in his book \"God and the State\". These ideas probably inspired the American feminist activist Moses Harman to name his anarchist periodical \"Lucifer the Lightbearer\". The idea of this \"Leftist Satan\" declined during the 20th century.\nOccult.\nIn 17th-century Sweden, a number of highway robbers and other outlaws living in the forests informed judges that they venerated Satan because he provided more practical assistance than Jehovah, practices now regarded as \"folkloric Satanism\".\nThe figure of \"Lucifer\" was taken up by the French ceremonial magician \u00c9liphas L\u00e9vi (1810\u20131875), who shocked convention by turning the traditional figure of evil into a brave rebel against tyranny. L\u00e9vi has been described as a \"Romantic Satanist\", a Romantic literary movement that formed no organizations and did not worship Satan, but did make a crucial break away from the traditional Christian figure of the \"Lord of Darkness\" doomed to failure and punishment for his wickedness. They reimagined Satan as an enemy of God the powerful, but not of the weak and mortal human race. In other words, a figure humans could sympathize with.\nAs L\u00e9vi moved toward political conservatism in later life, he retained the use of the term, but instead applied it to what he believed was a morally neutral facet of \"the absolute\".\nL\u00e9vi was not the only occultist who used the term \"Lucifer\" without adopting the term \"Satan\" in a similar way. The early Theosophical Society believed that \"Lucifer\" was a force that aided humanity's awakening to its own spiritual nature; the Society began publishing the journal \"Lucifer\" in 1887.\nThe first person to promote an explicitly \"Satanic\" philosophy was the Polish writer Stanis\u0142aw Przybyszewski (1868\u20131927), a \"decadent Bohemian\" who based his ideology on Social Darwinism of the 1890s, publishing \"The Synagogue of Satan\" in 1897.\nDanish occultist Carl William Hansen (1872\u20131936), who used the pen name Ben Kadosh, listed \"Luciferian\" as his religious affiliation in answer to the Danish national census (his wife and children were listed as Lutheran), making him among the earliest \"self-declared Satanists\". \nHansen sought to spread a cult of Satan/Lucifer, and was involved in a variety of esoteric groups, including Martinism, Freemasonry, and Ordo Templi Orientis, drawing on their ideas to establish his own philosophy. He provided a Luciferian interpretation of Freemasonry in a 1906 pamphlet, although his work had little influence outside of Denmark.\nThroughout his life British occultist Aleister Crowley (1875\u20131947) was widely described as a Satanist, usually by detractors. Crowley did not consider himself a Satanist, nor did he worship Satan, as he did not accept the Christian world view in which Satan was believed to exist. He nevertheless used imagery considered satanic, for instance, describing himself as \"the Beast 666\" and referring to the Whore of Babylon in his work, sending \"Antichristmas cards\" to his friends later in life. Crowley \"in many ways embodies the pre-Satanist esoteric discourse on Satan and Satanism through his lifestyle and his philosophy\", with his \"image and thought\" becoming an \"important influence\" on the later development of religious Satanism. Both Crowley and LaVey \"cultivated a sinister public image and sported shaved heads\".\nIn 1928, the Fraternitas Saturni (FS) was established in Germany; its founder, Eugen Grosche, published \"Satanische Magie\" (\"Satanic Magic\") that same year. The group connected Satan to Saturn, claiming that the planet related to the Sun in the same manner that Lucifer relates to the human world.\nMaria de Naglowska, a Russian occultist who had fled to France following the Russian Revolution, established the esoteric group Brotherhood of the Golden Arrow in Paris in 1932. She promoted a theology centered on what she called the Third Term of the Trinity consisting of Father, Son, and Sex, the last of which she deemed to be most important. Her early disciples, who underwent what she called \"Satanic Initiations\", included models and art students recruited from bohemian circles. The Golden Arrow disbanded after Naglowska abandoned it in 1936. Hers was \"a quite complicated Satanism, built on a complex philosophical vision of the world, of which little would survive its initiator\".\nHerbert Sloane claims Our Lady of Endor Coven, a Satanic group based in Toledo, Ohio, was founded in 1948. Describing his Satanic tradition as the Ophite Cultus Sathanas, the group first came to public attention in 1969. The group had a Gnostic doctrine about the world, in which the Judeo-Christian creator god is regarded as evil, and the Biblical serpent is presented as a force for good, who had delivered salvation to humanity in the Garden of Eden. Sloane's claim of a 1940s origin remain unproven: potentially fabricated to make his group appear older than the (1966) establishment of the Church of Satan.\nContemporary tendencies and groups.\n\"The intentional, religiously motivated veneration of Satan\" is the \"working definition\" of Satanism of historian of religion Ruben van Luijk, comes in different forms. Satanism has been called a \"new religious movement\", and other times judged too diffuse to merit that description and been called instead a \"milieu\" (Dyrendal, Lewis, and Petersen), united by \"family resemblance\", and the fact that most of them were self religions. Some of the resemblances in this Satanic milieu are: \nA minority of Satanists have some type of association with the political far-right.\nDyrendal, Lewis, and Petersen argue that the groups within the Satanic milieu can be divided into three groups: reactive Satanists, rationalist Satanists, and esoteric Satanists. \nDiane E. Taub and Lawrence D. Nelson (publishing in 1993, at the end of the \"Satanic panic\") divide Satanism into two: \nContemporary religious Satanism is predominantly an American phenomenon but has spread elsewhere via globalization and the Internet, allowing for intra-group communication and creation of a forum for Satanist disputes. Satanism started to reach Central and Eastern Europe in the 1990s\u2014in time with the fall of the Communist Bloc\u2014and most noticeably in Poland and Lithuania, predominantly Roman Catholic countries.\nNontheistic Satanism.\nLaVeyan Satanism and Church of Satan.\nSatanism as \"a self-declared religion\" began in 1966 with the founding of the Church of Satan (CoS) by Anton Szandor LaVey. Religious scholars have called the Church not only the oldest, continuous satanic organization but the most influential, with \"numerous imitator and breakaway groups\".\nThe church was founded in San Francisco, California, in an era when there was much public interest in the occult, witchcraft, and Satanism. A \"gigantic media circus\" developed around Anton LaVey, \"the Father of Satanism\" and his Satanic aesthetics. LaVey shaved his head, wore a goatee, performed Black Masses with nude women serving as altars. He was invited on national talk shows and mingled with celebrities attending his satanic parties. As an entrepreneur, he saw an opening for a new religion in the spiritual void of a secularizing post-Christian West.\nBut LaVey also promoted his ideas and his 1969 \"Satanic Bible\" as \"the best-known and most influential statement of Satanic theology\". It sold nearly a million copies. These had \"very little\" connection with \"either Satan or the worship of Satan\", but were based on the Romantic literary concept of Satan, not as a symbol of evil, but as a rebel anti-hero, defying God\u2019s tyranny with charisma and bravery. Together with the romanticism, \"humanism, hedonism, aspects of pop psychology and the human potential movement\" were woven together by LaVey, and publicized with \"a lot of showmanship\". Philosopher Ayn Rand, who argued that \"selfishness\" is a virtue in that \"unfettered self-interest is good and altruism is destructive\", was a major influence. According to both LaVey and sociologist of religion James R. Lewis, Ayn Rand's thought was a cornerstone of his philosophy, along with \"ceremony and ritual\" or \"ritual magic\".\nOther influences were Friedrich Nietzsche, who celebrated the Ubermensch, proclaimed \"God is dead\", and preached against the 'slave's morality' of mercy, charity, and helping the weak; English occultist Aleister Crowley, famous for the axiom \"Do what thou wilt shall be the whole of the [moral] Law\"; and Arthur Desmond, who strongly associated with Social Darwinism and the expression \"the survival of the fittest\".\nLaVey used Christianity as a \"negative mirror\" for his new faith, rejecting the basic principles, theology and values of Christian belief, along with other major religions and philosophies such as humanitarianism and liberal democracy\u2014which he saw as negative forces. Instead of idealism, humility, abstinence, self-denigration, obedience, herd behavior, spirituality, and irrationality; he praised the seven deadly sins (i.e. pride, greed, wrath, envy, lust, gluttony and sloth), as virtues, not vices. LaVey went beyond discouraging sexual inhibitions and feelings of guilt and shame over fetishes, calling for a celebration of, and indulgence in, humanity's animal nature and its desires, which Christianity sought to suppress. Human beings should seek out the carnal rather than the spiritual; satisfying the ego's desires enhanced an individual's pride, self-respect, and self-realization. Hate, and aggression were necessary and advantageous for survival, victims should not \"turn the other cheek\" but take an \"eye for an eye\".\nSatanists should be individualistic, non-conformist, contemptuous of \"colorless\" mainstream society. LaVey saw Satanism as something like a personality type as much as a belief, since Satanists \"are outsiders by their nature\", and \"born, not made\". Since gods are actually a creation of man and not the other way around, LaVey asked, \"'Why not really be honest and if you are going to create a god in your image, why not create that god as yourself'... every man is a god if he chooses to recognize himself as one.\" Not everyone would measure up to being a god however. Human social equality was a \"myth\", leading to \"mediocrity\" and support of the weak at the expense of the strong. \"Social stratification\" was part of LaVey and the Church's \"Five Point Program\".\nA \"true Satanic society\" was described in Lavey's church's periodical \"The Black Flame\" and highlighted by anthropologist Jean La Fontaine; it would be one in which the population consists of \"free-spirited, well-armed, fully-conscious, self-disciplined individuals, who will neither need nor tolerate any external entity 'protecting' them or telling them what they can and cannot do\". Another version of the Satanic society envisioned by LaVey was the breeding of an elite people \"superior\" in their creativity and nonconformity. These would live apart from the rest of the human \"herd\"\u2014who would be relegated into ghettoes, ideally \"space ghettoes\" located on other planets.\nLaVey's ideas were also said to \"seem contradictory\". According to CoS priest Gavin Baddeley, LaVey's church combined \"a love of life garbed in the symbols of death and fear\", and while LaVey himself pontificated on personal freedom, he \"micromanaged the lives of his followers\". Some doubted his atheist naturalism. LaVey insisted the church scoffed at the supernatural, but also told an interviewer he considered \"curses and hexes\" against enemies a form of human sacrifice \"by proxy\".\nContradictions in his thought have been explained by his wanting it to have as wide appeal as possible, balancing, in his words, \"nine parts\" of \"respectability\" to \"one part\" of \"outrageousness\". If Satanism was to be Satanic, it required some outrageous/anti-social elements, but if it was going to be a viable organization, these could not be allowed to frighten off potential congregants and attract unwanted attention.\nOne \"outrageous\" issue that LaVey was criticized for was his \"ambivalent relationship\" with far-right groups (United Klans of America, National Renaissance Party, and the American Nazi Party) that he neither endorsed nor rejected.\nLaVey died in 1997, but the church maintains a purist approach to his thought, insisting he and the church have \"codified\" Satanism as \"a religion and philosophy\", and dismisses other Satanist groups (atheistic or otherwise), as reverse-Christians, pseudo-Satanists or Devil worshipers.\nFirst Satanic Church.\nAfter LaVey's death in 1997, the Church of Satan was taken over by a new administration and its headquarters were moved to New York City. LaVey's daughter, the High Priestess Karla LaVey re-founded The First Satanic Church on 1999 in San Francisco. This church has been called \"a lot more exclusive\" than the original and as of late 2023 was known for producing a \"Black X-Mass concert\" in San Francisco \"every year for the last couple decades\".\nSatanic Reds.\nDiffering from other Satanic organizations, the Satanic Reds, founded in 1997 by Tani Jantsang, is a unique organization blending Marxist-communist politics with Lovecraftian occultism mixed with elements of Central Asian folklore and the advocacy of social welfare; the group became notable mainly for their online activism and usage of communist symbols merged with Satanist ones. However, the Satanic Reds claim to belong to the left-hand path but do not identify as theistic Satanists in the manner of believing in Satan as a god with a personality, since they conceive it as \"Sat\" and \"Tan\", \"Being and Becoming\", similarly to the fictional deity of chaos Nyarlathotep from Lovecraft's Cthulhu Mythos.\nThe Satanic Temple.\nThe Satanic Temple (TST), has been called the \"most prominent\" satanic organization \"in terms of both size and public activity\" (as of late 2023). Based in Salem, Massachusetts and active since 2012, it claims 700,000 members worldwide. Like the older Church of Satan, its congregants do not believe in a supernatural Satan, but if the CoS saw Satanism as a \"negative mirror\" of Christianity, reversing Christian principles of altruism (helping the downtrodden and community-mindedness) to selfishness, the Christian principles TST wants to reverse are politically conservative activist/fundamentalist ones\u2014the elimination of the right to abortion, of the teaching of evolution, of the separation of church and state, etc. This \"left-wing\", \"socially engaged Satanism\", involves activism, rather than the individualism and right-wing-oriented, \"getting what you want for yourself\", of the CoS.\nThey have been called \"rationalist, political pranksters\" (by Dyrendal, Lewis, and Petersen), with pranks designed to highlight religious hypocrisy and advance the cause of secularism. One such prank was performing a \"Pink Mass\" over the grave of the mother of the evangelical Christian and prominent anti-LGBTQ preacher Fred Phelps and claiming that the mass converted the spirit of Phelps' mother into a lesbian. The \"Seven Fundamental\" tenets of the temple on its website mention compassion, justice, freedom, inviolability of the human body, conforming to scientific understanding, human fallibility\u2014but say nothing about Satan. The Temple has been described as using the literary Satan as metaphor to promote pragmatic skepticism, rational reciprocity, personal autonomy, and curiosity; and as a symbol to represent \"the eternal rebel\" against arbitrary authority and social norms.\nThe temple has also demanded the privileges the government affords Christians, such as giving prayers before city council meetings, erecting (satanic) statues on government property, and distributing its materials in public schools. As the movement became bigger, its congregations volunteered to clean highways and help the homeless, at least in part to demonstrate they were civic minded and not evil. It has made efforts at lobbying, with a focus on the separation of church and state and using satire against Christian groups that it believes interfere with personal freedom.\nLucien Greaves has described the Satanic Temple as being a progressive and updated version of LaVey's Satanism, posted a fairly detailed refutation of LaVey's doctrines, accusing the CoS of fetishizing authoritarianism, and explaining how elements of Social Darwinism and Nietzscheanism within LaVeyan Satanism are incongruent with game theory, reciprocal altruism, and cognitive science. The Church of Satan, on the other hand, has declared the TST members as only \"masquerading\" as Satanists, being in violation of the \"five decades of a clearly defined belief system called Satanism expounded by a worldwide organization\" (i.e. LaVeyan Satanism).\nTheistic Satanism.\nTheistic Satanism, otherwise referred to as spiritual Satanism, or devil worship, is a form of Satanism with the primary belief that Satan is an actual deity or force to revere or worship. Other characteristics of theistic Satanism may include a belief in magic, which is manipulated through ritual, although that is not a defining criterion, and theistic Satanists may focus solely on devotion.\nFirst Church of Satan.\nThe First Church of Satan (FCoS), a splinter group that separated from LaVey's Church of Satan during the 1970s, attempts to rediscover the teachings of Aleister Crowley and believe that Anton LaVey actually was a \"magus\" in the early days of the Church of Satan but gradually renounced his powers, became isolated and embittered. Furthermore, the First Church of Satan strongly criticizes the current Church of Satan as a pale shadow of its former self, and they strive to \"maintain a Satanic organization that is not hostile or manipulative toward its own members\".\nTurku Society for the Spiritual Sciences.\nPekka Siitoin founded the satanist group called the Turku Society for the Spiritual Sciences (Turun Hengentieteen Seura) on September 1, 1971. The society stated its founding principles as \"promot[ing] nationalist patriotic activity [and] development of Aryan spirituality\". The society also stated opposition to capitalism, communism and \"the Jewish religion based on Jehovah's tyranny.\" Siitoin believed in neo-Gnosticism and Theosophy and combined these with antisemitism and satanism. The society allegedly performed satanic orgies which researcher of religion Pekka Iitti opined might not be \"far off from the truth\". Several of the perpetrators of the Kursiivi printing house arson in November 1977 were members of the society.\nOrder of Nine Angles.\nThe Order of Nine Angles, claiming to have been established in the 1960s, rose to public recognition in the early 1980. This movement expressed the idea that groups like Church of Satan were \"too benevolent and law-abiding\" to be true Satanists. This notion grew, particularly among musicians and fans of extreme heavy metal music, where being more extreme meant being more authentic. These antinomian and amoral Satanic (or post-Satanic) groups are sometimes called the \"sinister tradition\" of Satanism.\nThe O9A describe their occultism as \"Traditional Satanism\". The O9A's writings not only encourage human sacrifice, but insist it is required in Satanism, referring to their victims as \"opfers\". According to the Order's teachings, such opfers must demonstrate character faults that mark them out as being worthy of death. No O9A cell has admitted to carrying out a sacrifice in a ritualized manner, but rather, Order members have joined the police and military to carry out such killings.\nTemple of Set.\nThe Temple of Set is an occult left-hand path religious organization. It was founded in 1975 when Michael Aquino, the founder of a Church of Satan Grotto in Louisville, Kentucky, and editor of the Church's newsletter, \"The Cloven Hoof\", left the church, taking 28 members with him. Aquino's anger that LaVey had devalued his high level grade of \"magister\" in the church may have initiated his break, but Aquino also disagreed with LaVey's materialist philosophy, arguing that while the church might publicly be materialist, Satan as symbol was \"only part of the truth\". Aquino held a ritual to ask Satan \"where to lead\" his CoS defectors and, on the night of 21\u201322 June 1975, Satan allegedly told him to \"Reconsecrate my Temple and my Order in the true name of Set. No longer will I accept the bastard title of a Hebrew fiend.\" Thus Aquino came to believe that the name \"Satan\" was a corruption of the name \"Set\", the Egyptian god of darkness. The philosophy of the Temple of Set may be summed up as \"enlightened individualism\"\u2014enhancement and improvement of oneself by personal education, experiment, and initiation. This process is necessarily different and distinctive for each individual. The members do not agree on whether Set is real or symbolic, and they're not expected to.\nTemple of the Black Light.\nThe Temple of the Black Light, formerly known as the Misanthropic Luciferian Order, is a Satanic occult order founded in Sweden in 1995. The group espouses a philosophy known as \"Chaosophy\". Chaosophy asserts that the world that mankind lives in, and the universe that it lives in, all exist within the realm known as Cosmos. Cosmos is made of three spatial dimensions and one linear time dimension. Cosmos rarely ever changes and is a materialistic realm. Another realm that exists is known as Chaos. Chaos exists outside of the Cosmos and is made of infinite dimensions and unlike the Cosmos, it is always changing. Members of the TotBL believe that the realm of Chaos is ruled over by 11 dark gods, the highest of them being Satan, and all of said gods are considered manifestations of a higher being. This higher being is known as Azerate, the Dragon Mother, and is all of the 11 gods united as one. The TotBL believes that Azerate will resurrect one day and destroy the Cosmos and let Chaos consume everything. The group has been connected to the Swedish black/death metal band Dissection, particularly its front man Jon N\u00f6dtveidt. N\u00f6dtveidt was introduced to the group \"at an early stage\". The lyrics on the band's third album, \"Reinkaos\", are all about beliefs of the Temple of the Black Light. N\u00f6dtveidt committed suicide in 2006.\nTemple of Zeus.\nThe Temple of Zeus is a western esoteric occult organization that combines Satanism, the ancient alien astronaut \"hypothesis\", and antisemitism. It was originally founded as the Joy of Satan Ministries in the early 2000s by Maxine Dietrich (pseudonym of Andrea Maxine Dietrich), wife of the National Socialist Movement of the United States' co-founder and former leader Clifford Herrington. With its inception, spiritual Satanism was born\u2014a current that until recently was regarded only as \"theist\", but then defined into \"Spiritual Satanism\" by theistic Satanists who concluded that the term \"spiritual\" in Satanism represented the best answer to the world, considering it a \"moral slap\" toward the earlier carnal and materialistic LaVeyan Satanism, and instead focusing its attention upon spiritual evolution. Temple of Zeus presents a unique synthesis of theistic Satanism, Nazism, Gnosticism, neopaganism, Western esotericism, UFO conspiracy theories, and extraterrestrial hypotheses similar to those popularized by Zecharia Sitchin and David Icke.\nLuciferianism.\nLuciferians reportedly revere Lucifer not as the devil, but as a destroyer, guardian, liberator, light bringer, and/or guiding spirit to darkness, or even as the true god, as opposed to Jehovah.\nPersonal Satanism.\nIn contrast to the organized and doctrinal Satanist groups is the personal Satanism of individuals, who identify as Satanists due to their affinity for the general idea of Satan, including such characteristics as viciousness and/or subversion.\nDyrendal, Lewis, and Petersen used the term \"reactive Satanism\" to describe one form of modern Satanism. They described this as an adolescent and anti-social means of rebelling in a Christian society, by which an individual transgresses cultural boundaries. which tends to fall into two tendencies: \nThe researcher Gareth Medway noted that in 1995 he encountered a British woman who stated that she had been a practicing Satanist during her teenage years. She had grown up in a small mining village and had come to believe that she had psychic powers. After hearing about Satanism in some library books, she declared herself a Satanist and formulated a belief that Satan was the true god. After her teenage years she abandoned Satanism and became a chaos magickian.\nSome personal Satanists are teenagers or mentally disturbed individuals who have engaged in criminal activities. During the 1980s and 1990s, several groups of teenagers were apprehended after sacrificing animals and vandalizing both churches and graveyards with Satanic imagery. Introvigne stated that these incidents were \"more a product of juvenile deviance and marginalization than Satanism\". In a few cases, the crimes of these personal Satanists have included murder. \nDemographics.\nA survey in the Encyclopedia of Satanism found that people became involved with Satanism in many diverse ways and were found in many countries. The survey found that more Satanists were raised as Protestant Christians than Catholic.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nBeginning in the late 1960s, organized Satanism emerged out of the occult subculture with the formation of the Church of Satan. It was not long, however, before Satanism had expanded well beyond the Church of Satan. The decentralization of the Satanist movement was considerably accelerated when Anton LaVey disbanded the grotto system in the mid-1970s. At present, religious Satanism exists primarily as a decentralized subculture [...] Unlike traditional religions, and even unlike the early Satanist bodies such as the Church of Satan and the Temple of Set, contemporary Satanism is, for the most part, a decentralized movement. In the past, this movement has been propagated through the medium of certain popular books, especially LaVey's \"Satanic Bible\". In more recent years, the internet has come to play a significant role in reaching potential \"converts\", particularly among disaffected young people. \n\u2014 Religion scholar and researcher of new religious movements James R. Lewis \nDyrendal, Lewis, and Petersen observed that from surveys of Satanists conducted in the early 21st century, it was clear that the Satanic milieu was \"heavily dominated by young males\". They nevertheless noted that census data from New Zealand suggested that there may be a growing proportion of women becoming Satanists. In comprising more men than women, Satanism differs from most other religious communities, including most new religious communities. Most Satanists came to their religion through reading, either online or books, rather than through being introduced to it through personal contacts. Many practitioners do not claim that they converted to Satanism, but rather state that they were born that way, and only later in life confirmed that Satanism served as an appropriate label for their pre-existing worldviews. Others have stated that they had experiences with supernatural phenomena that led them to embracing Satanism.\nThe surveys revealed that atheistic Satanists appeared to be in the majority, although the numbers of theistic Satanists appeared to grow over time. Beliefs in the afterlife varied, although the most common beliefs about the afterlife were reincarnation and the idea that consciousness survives bodily death. The surveys also demonstrated that most recorded Satanists practiced magic, although there were differing opinions as to whether magical acts operated according to etheric laws or whether the effect of magic was purely psychological. A number of Satanists described performing cursing, in most cases as a form of vigilante justice. Most practitioners conduct their religious observances in a solitary manner, and never or rarely meet fellow Satanists for rituals. Rather, the primary interaction that takes place between Satanists is online, on websites or via email. From their survey data, Dyrendal, Lewis, and Petersen noted that the average length of involvement in the Satanic milieu was seven years. A Satanist's involvement in the movement tends to peak in their early twenties and drops off sharply in their thirties. A small proportion retain their allegiance to the religion into their elder years. When asked about their ideology, the largest proportion of Satanists identified as apolitical or non-aligned, while only a small percentage identified as conservative. A small minority of Satanists expressed support for Nazism; conversely, over two-thirds expressed opposition or strong opposition to it.\n2021 Canadian census.\nThe 2021 Canadian census states that 5,890 Canadians identify as Satanist, representing 0.02% of the population.\nCompared to the general population, Satanists are more likely to be male, aged in their 20s or 30s, and not a member of any recognized minority group, although the Japanese are an exception (with the Japanese comprising 0.3% of both Satanists and the population as a whole).\nLegal recognition.\nIn 2004, it was claimed that Satanism was allowed in the Royal Navy of the British Armed Forces, despite opposition from Christians. In 2016, under a Freedom of Information request, the Navy Command Headquarters stated that, \"we do not recognise satanism as a formal religion, and will not grant facilities or make specific time available for individual 'worship'.\"\nIn 2005, the Supreme Court of the United States debated in the case of \"Cutter v. Wilkinson\" over protecting minority religious rights of prison inmates after a lawsuit challenging the issue was filed to them. The court ruled that facilities that accept federal funds cannot deny prisoners accommodations that are necessary to engage in activities for the practice of their own religious beliefs.\nIn 2019, The Satanic Temple was granted religious IRS 501(c)(3) status.\nMetal and rock music.\nDuring the 1960s and 1970s, several rock bands\u2014 namely the American band Coven and the British band Black Widow, employed the imagery of Satanism and witchcraft in their work. References to Satan also appeared in the work of those rock bands which were pioneering the heavy metal genre in Britain during the 1970s. For example, the band Black Sabbath made mention of Satan in their lyrics, although some of the band's members were practicing Christians, and other lyrics affirmed the power of the Christian God over Satan. In the 1980s, greater use of Satanic imagery was made by heavy metal bands such as Slayer, Kreator, Sodom, and Destruction. Bands active in the subgenre of death metal\u2014among them Morbid Angel and Entombed, also adopted Satanic imagery, combining it with other morbid and dark imagery, such as that of zombies and serial killers.\nSatanism would come to be more closely associated with the subgenre of black metal, in which it was foregrounded over the other themes that had been used in death metal. A number of black metal performers incorporated self-injury into their act, framing this as a manifestation of Satanic devotion. The first black metal band, Venom, proclaimed themselves to be Satanists, although this was more an act of provocation than an expression of genuine devotion to the Devil. Satanic themes were also used by the black metal bands Bathory and Hellhammer. However, the first black metal act to more seriously adopt Satanism was Mercyful Fate, whose vocalist, King Diamond, joined the Church of Satan. More often than not musicians associating themselves with black metal say they do not believe in legitimate Satanic ideology and often profess to being atheists, agnostics, or religious skeptics.\nIn contrast to King Diamond, various black metal Satanists sought to distance themselves from LaVeyan Satanism, for instance by referring to their beliefs as \"devil worship\". These individuals regarded Satan as a literal entity, and in contrast to Anton LaVey, they associated Satanism with criminality, suicide, and terror. For them, Christianity was regarded as a plague which required eradication. Many of these individuals, most prominently Varg Vikernes and Euronymous, were involved in the early Norwegian black metal scene. Between 1992 and 1996, such people destroyed around fifty Norwegian churches in arson attacks. Within the black metal scene, a number of musicians later replaced Satanic themes with those deriving from Heathenry, a form of neopaganism.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27707", "revid": "1311986788", "url": "https://en.wikipedia.org/wiki?curid=27707", "title": "Socialist law", "text": "Type of legal system\nSocialist law or Soviet law are terms used in comparative legal studies for the general type of legal system which has been (and continues to be) used in communist and formerly communist states. It is based on the civil law system, with major modifications and additions from Marxist\u2013Leninist ideology. There is controversy as to whether socialist law ever constituted a separate legal system or not. If so, prior to the end of the Cold War, \"socialist law\" would be ranked among the major legal systems of the world.\nWhile civil law systems have traditionally put great pains in defining the notion of private property, how it may be acquired, transferred, or lost, socialist law systems provide for most property to be owned by the state or by agricultural co-operatives, and having special courts and laws for state enterprises.\nMany scholars argue that socialist law was not a separate legal classification. Although the command economy approach of the communist states meant that most types of property could not be owned, the Soviet Union always had a civil code, courts that interpreted this civil code, and a civil law approach to legal reasoning (thus, both legal process and legal reasoning were largely analogous to the French or German civil code system). Legal systems in all socialist states preserved the formal criteria of the Romano-Germanic civil law; for this reason, law theorists in post-socialist states usually consider the socialist law as a particular case of the Romano-Germanic civil law. Cases of development of common law into socialist law are unknown because of incompatibility of basic principles of these two systems (common law presumes the influential rule-making role of courts while courts in socialist states play a dependent role).\nAn article published in 2016 suggests that socialist law, at least from the perspective of public law and constitutional design, is a useful category. In the NYU \"Journal of International Law and Policy\", William Partlett and Eric Ip argue that socialist law helps to understand the \"Russo-Leninist transplants\" that currently operate in China's socialist law system. This helps to understand the \"distinctive public law institutions and approaches in China that have been ignored by many scholars\".\nSoviet legal theory.\nSoviet law displayed many special characteristics that derived from the socialist nature of the Soviet state and reflected Marxist\u2013Leninist ideology. Vladimir Lenin accepted the Marxist conception of the law and the state as instruments of coercion in the hands of the bourgeoisie and postulated the creation of popular, informal tribunals to administer revolutionary justice. One of the main theoreticians of Soviet socialist legality and proletarian law in this early phase was P\u0113teris Stu\u010dka. Other proponents of proletarian law included Dmitry Kursky and Nikolai Krylenko. \nAlongside this trend was one more critical of the concept of \"proletarian justice\", represented by Evgeny Pashukanis. A dictatorial trend developed that advocated the use of law and legal institutions to suppress all opposition to the regime. This trend reached its zenith under Joseph Stalin with the ascendancy of Andrey Vyshinsky, when the administration of justice was carried out mainly by the security police in special tribunals.\nDuring the de-Stalinization of the Nikita Khrushchev era, a new trend developed, based on socialist legality, that stressed the need to protect the procedural and statutory rights of citizens, while still calling for obedience to the state. New legal codes, introduced in 1960, were part of the effort to establish legal norms in administering laws. Although socialist legality remained in force after 1960, the dictatorial and utopian trends continued to influence the legal process. Persecution of political and religious dissenters continued, but at the same time there was a tendency to decriminalize lesser offenses by handing them over to people's courts and administrative agencies and dealing with them by education rather than by incarceration. By late 1986, the Mikhail Gorbachev era was stressing anew the importance of individual rights in relation to the state and criticizing those who violated procedural law in implementing Soviet justice. This signaled a resurgence of socialist legality as the dominant trend. Socialist legality itself still lacked features associated with Western jurisprudence.\nCharacteristic traits.\nSocialist law is similar to the civil law but with a greatly increased public law sector and decreased private law sector.\nA specific institution characteristic to Socialist law was the so-called burlaw court (or, verbally, \"court of comrades\", Russian \u0442\u043e\u0432\u0430\u0440\u0438\u0449\u0435\u0441\u043a\u0438\u0439 \u0441\u0443\u0434) which decided on minor offences.\nSocialist rule of law.\nAfter China's Reform and Opening Up, the Chinese Communist Party (CCP) emphasized the rule of law as a basic strategy and method for state management of society.110 General Secretary of the Chinese Communist Party Jiang Zemin first called for establishing a socialist rule of law at the Fifteenth Party Congress in 1997.110 In 2014, the CCP formally adopted a policy of constructing a \"socialist rule of law with Chinese characteristics.\"\nIn his writings on socialist rule of law, General Secretary of the Chinese Communist Party Xi Jinping has emphasized traditional Chinese concepts including people as the root of the state (\"mingben\"), \"the ideal of no lawsuit\" (\"tianxia wusong\"), \"respecting rite and stressing law\" (\"longli zhongfa\"), \"virtue first, penalty second\" (\"dezhu xingfu\"), and \"promoting virtue and being prudent in punishment\" (\"mingde shenfa\"). Xi states that the two fundamental aspects of the socialist rule of law are: (1) that the political and legal organs (including courts, the police, and the procuratorate) must believe in the law and uphold the law, and (2) all political and legal officials must follow the CCP.115\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27709", "revid": "23914831", "url": "https://en.wikipedia.org/wiki?curid=27709", "title": "Semiconductor", "text": "Material of moderate electrical conductivity\nA semiconductor is a material with electrical conductivity between that of a conductor and an insulator. Its conductivity can be modified by adding impurities (\"doping\") to its crystal structure. When two regions with different doping levels are present in the same crystal, they form a semiconductor junction. However the term \"semiconductors\" is sometimes used to refer to semiconductor devices such as microchips and computer processors, which work using the physical properties of semiconductors.\nThe behavior of charge carriers, which include electrons, ions, and electron holes, at these junctions is the basis of diodes, transistors, and most modern electronics. Some examples of semiconductors are silicon, germanium, gallium arsenide, and elements near the so-called \"metalloid staircase\" on the periodic table. After silicon, gallium arsenide is the second-most common semiconductor and is used in laser diodes, solar cells, microwave-frequency integrated circuits, and others. Silicon is a critical element for fabricating most electronic circuits.\nSemiconductor devices can display a range of different useful properties, such as passing current more easily in one direction than the other, showing variable resistance, and having sensitivity to light or heat. Because the electrical properties of a semiconductor material can be modified by doping and by the application of electrical fields or light, devices made from semiconductors can be used for amplification, switching, and energy conversion. The term semiconductor is also used to describe materials used in high capacity, medium- to high-voltage cables as part of their insulation, and these materials are often plastic XLPE (cross-linked polyethylene) with carbon black.\nThe conductivity of silicon can be increased by adding a small amount (of the order of 1 in 108) of pentavalent (antimony, phosphorus, or arsenic) or trivalent (boron, gallium, indium) atoms. This process is known as doping, and the resulting semiconductors are known as doped or extrinsic semiconductors. Apart from doping, the conductivity of a semiconductor can be improved by increasing its temperature. This is contrary to the behavior of a metal, in which conductivity decreases with an increase in temperature.\nThe modern understanding of the properties of a semiconductor relies on quantum physics to explain the movement of charge carriers in a crystal lattice. Doping greatly increases the number of charge carriers within the crystal. When a semiconductor is doped by Group V elements, they will behave like donors creating free electrons, known as \"n-type\" doping. When a semiconductor is doped by Group III elements, they will behave like acceptors creating free holes, known as \"p-type\" doping. The semiconductor materials used in electronic devices are doped under precise conditions to control the concentration and regions of p- and n-type dopants. A single semiconductor device crystal can have many p- and n-type regions; the p\u2013n junctions between these regions are responsible for the useful electronic behavior. Using a hot-point probe, one can determine quickly whether a semiconductor sample is p- or n-type.\nA few of the properties of semiconductor materials were observed throughout the mid-19th and first decades of the 20th century. The first practical application of semiconductors in electronics was the 1904 development of the cat's-whisker detector, a primitive semiconductor diode used in early radio receivers. Developments in quantum physics led in turn to the invention of the transistor in 1947 and the integrated circuit in 1958.\nProperties.\nVariable electrical conductivity.\nSemiconductors in their natural state are poor conductors because a current requires flow of electrons, and semiconductors have their valence bands filled, preventing the entire flow of new electrons. Several developed techniques allow semiconducting materials to behave like conducting materials, such as doping or gating. These modifications have two outcomes: n-type and p-type. These refer to the excess or shortage of electrons, respectively. A balanced number of electrons would cause a current to flow throughout the material.\nHomojunctions.\nHomojunctions occur when two differently doped semiconducting materials are joined. For example, a configuration could consist of p-doped and n-doped germanium. This results in an exchange of electrons and holes between the differently doped semiconducting materials. The n-doped germanium would have an excess of electrons, and the p-doped germanium would have an excess of holes. The transfer occurs until an equilibrium is reached by a process called recombination, which causes the migrating electrons from the n-type to come in contact with the migrating holes from the p-type. The result of this process is a narrow strip of immobile ions, which causes an electric field across the junction.\nExcited electrons.\nA difference in the electric potential on a semiconducting material would cause it to leave thermal equilibrium and create a non-equilibrium situation. This introduces electrons and holes to the system, which interact via a process called ambipolar diffusion. Whenever thermal equilibrium is disturbed in a semiconducting material, the number of holes and electrons changes. Such disruptions can occur as a result of a temperature difference or photons, which can enter the system and create electrons and holes. The processes that create or annihilate electrons and holes are called generation and recombination, respectively.\nLight emission.\nIn certain semiconductors, excited electrons can relax by emitting light instead of producing heat. Controlling the semiconductor composition and electrical current allows for the manipulation of the emitted light's properties. These semiconductors are used in the construction of light-emitting diodes and fluorescent quantum dots.\nHigh thermal conductivity.\nSemiconductors with high thermal conductivity can be used for heat dissipation and improving thermal management of electronics. They play a crucial role in electric vehicles, high-brightness LEDs and power modules, among other applications.\nThermal energy conversion.\nSemiconductors have large thermoelectric power factors making them useful in thermoelectric generators, as well as high thermoelectric figures of merit making them useful in thermoelectric coolers.\nMaterials.\nA large number of elements and compounds have semiconducting properties, including:\nThe most common semiconducting materials are crystalline solids, but amorphous and liquid semiconductors are also known. These include hydrogenated amorphous silicon and mixtures of arsenic, selenium, and tellurium in a variety of proportions. These compounds share with better-known semiconductors the properties of intermediate conductivity and a rapid variation of conductivity with temperature, as well as occasional negative resistance. Such disordered materials lack the rigid crystalline structure of conventional semiconductors such as silicon. They are generally used in thin film structures, which do not require material of higher electronic quality, being relatively insensitive to impurities and radiation damage.\nPreparation of semiconductor materials.\nAlmost all of today's electronic technology involves the use of semiconductors, with the most important aspect being the integrated circuit (IC), which are found in desktops, laptops, scanners, cell-phones, and other electronic devices. Semiconductors for ICs are mass-produced. To create an ideal semiconducting material, chemical purity is paramount. Any small imperfection can have a drastic effect on how the semiconducting material behaves due to the scale at which the materials are used.\nA high degree of crystalline perfection is also required, since faults in the crystal structure (such as dislocations, twins, and stacking faults) interfere with the semiconducting properties of the material. Crystalline faults are a major cause of defective semiconductor devices. The larger the crystal, the more difficult it is to achieve the necessary perfection. Current mass production processes use crystal ingots between in diameter, grown as cylinders and sliced into wafers. The round shape characteristic of these wafers comes from single-crystal ingots usually produced using the Czochralski method. Silicon wafers were first introduced in the 1940s.\nThere is a combination of processes that are used to prepare semiconducting materials for ICs. One process is called thermal oxidation, which forms silicon dioxide on the surface of the silicon. This is used as a gate insulator and field oxide. Other processes are called photomasks and photolithography. This process is what creates the patterns on the circuit in the integrated circuit. Ultraviolet light is used along with a photoresist layer to create a chemical change that generates the patterns for the circuit.\nThe etching is the next process that is required. The part of the silicon that was not covered by the photoresist layer from the previous step can now be etched. The main process typically used today is called plasma etching. Plasma etching usually involves an etch gas pumped in a low-pressure chamber to create plasma. A common etch gas is chlorofluorocarbon, or more commonly known Freon. A high radio-frequency voltage between the cathode and anode is what creates the plasma in the chamber. The silicon wafer is located on the cathode, which causes it to be hit by the positively charged ions that are released from the plasma. The result is silicon that is etched anisotropically.\nThe last process is called diffusion. This is the process that gives the semiconducting material its desired semiconducting properties. It is also known as doping. The process introduces an impure atom to the system, which creates the p\u2013n junction. To get the impure atoms embedded in the silicon wafer, the wafer is first put in a 1,100 degree Celsius chamber. The atoms are injected in and eventually diffuse with the silicon. After the process is completed and the silicon has reached room temperature, the doping process is done and the semiconducting wafer is almost prepared.\nPhysics of semiconductors.\nEnergy bands and electrical conduction.\nSemiconductors are defined by their unique electric conductive behavior, somewhere between that of a conductor and an insulator. The differences between these materials can be understood in terms of the quantum states for electrons, each of which may contain zero or one electron (by the Pauli exclusion principle). These states are associated with the electronic band structure of the material. Electrical conductivity arises due to the presence of electrons in states that are delocalized (extending through the material), however in order to transport electrons a state must be \"partially filled\", containing an electron only part of the time. If the state is always occupied with an electron, then it is inert, blocking the passage of other electrons via that state. The energies of these quantum states are critical since a state is partially filled only if its energy is near the Fermi level (see Fermi\u2013Dirac statistics).\nHigh conductivity in material comes from it having many partially filled states and much state delocalization.\nMetals are good electrical conductors and have many partially filled states with energies near their Fermi level.\nInsulators, by contrast, have few partially filled states, their Fermi levels sit within band gaps with few energy states to occupy. Importantly, an insulator can be made to conduct by increasing its temperature: heating provides energy to promote some electrons across the band gap, inducing partially filled states in both the band of states beneath the band gap (valence band) and the band of states above the band gap (conduction band). An (intrinsic) semiconductor has a band gap that is smaller than that of an insulator and at room temperature, significant numbers of electrons can be excited to cross the band gap.\nA pure semiconductor, however, is not very useful, as it is neither a very good insulator nor a very good conductor.\nHowever, one important feature of semiconductors (and some insulators, known as \"semi-insulators\") is that their conductivity can be increased and controlled by doping with impurities and gating with electric fields. Doping and gating move either the conduction or valence band much closer to the Fermi level and greatly increase the number of partially filled states.\nSome wider-bandgap semiconductor materials are sometimes referred to as semi-insulators. When undoped, these have electrical conductivity nearer to that of electrical insulators, however they can be doped (making them as useful as semiconductors). Semi-insulators find niche applications in micro-electronics, such as substrates for HEMT. An example of a common semi-insulator is gallium arsenide. Some materials, such as titanium dioxide, can even be used as insulating materials for some applications, while being treated as wide-gap semiconductors for other applications.\nCharge carriers (electrons and holes).\nThe partial filling of the states at the bottom of the conduction band can be understood as adding electrons to that band. The electrons do not stay indefinitely (due to the natural thermal recombination) but they can move around for some time. The actual concentration of electrons is typically very dilute, and so (unlike in metals) it is possible to think of the electrons in the conduction band of a semiconductor as a sort of classical ideal gas, where the electrons fly around freely without being subject to the Pauli exclusion principle. In most semiconductors, the conduction bands have a parabolic dispersion relation, and so these electrons respond to forces (electric field, magnetic field, etc.) much as they would in a vacuum, though with a different effective mass. Because the electrons behave like an ideal gas, one may also think about conduction in very simplistic terms such as the Drude model, and introduce concepts such as electron mobility.\nFor partial filling at the top of the valence band, it is helpful to introduce the concept of an electron hole. Although the electrons in the valence band are always moving around, a completely full valence band is inert, not conducting any current. If an electron is taken out of the valence band, then the trajectory that the electron would normally have taken is now missing its charge. For the purposes of electric current, this combination of the full valence band, minus the electron, can be converted into a picture of a completely empty band containing a positively charged particle that moves in the same way as the electron. Combined with the \"negative\" effective mass of the electrons at the top of the valence band, we arrive at a picture of a positively charged particle that responds to electric and magnetic fields just as a normal positively charged particle would do in a vacuum, again with some positive effective mass. This particle is called a hole, and the collection of holes in the valence band can again be understood in simple classical terms (as with the electrons in the conduction band).\nCarrier generation and recombination.\nWhen ionizing radiation strikes a semiconductor, it may excite an electron out of its energy level and consequently leave a hole. This process is known as \"electron-hole pair generation\". Electron-hole pairs are constantly generated from thermal energy as well, in the absence of any external energy source.\nElectron-hole pairs are also apt to recombine. Conservation of energy demands that these recombination events, in which an electron loses an amount of energy larger than the band gap, be accompanied by the emission of thermal energy (in the form of phonons) or radiation (in the form of photons).\nIn some states, the generation and recombination of electron\u2013hole pairs are in equipoise. The number of electron-hole pairs in the steady state at a given temperature is determined by quantum statistical mechanics. The precise quantum mechanical mechanisms of generation and recombination are governed by the conservation of energy and conservation of momentum.\nAs the probability that electrons and holes meet together is proportional to the product of their numbers, the product is in the steady-state nearly constant at a given temperature, providing that there is no significant electric field (which might \"flush\" carriers of both types, or move them from neighbor regions containing more of them to meet together) or externally driven pair generation. The product is a function of the temperature, as the probability of getting enough thermal energy to produce a pair increases with temperature, being approximately exp(\u2212\"E\"G/\"kT\"), where \"k\" is the Boltzmann constant, \"T\" is the absolute temperature and \"E\"G is bandgap.\nThe probability of meeting is increased by carrier traps\u00a0\u2013 impurities or dislocations which can trap an electron or hole and hold it until a pair is completed. Such carrier traps are sometimes purposely added to reduce the time needed to reach the steady-state.\nDoping.\nThe conductivity of semiconductors may easily be modified by introducing impurities into their crystal lattice. The process of adding controlled impurities to a semiconductor is known as doping. The amount of impurity, or dopant, added to an \"intrinsic\" (pure) semiconductor varies its level of conductivity. Doped semiconductors are referred to as \"extrinsic\". By adding impurity to the pure semiconductors, the electrical conductivity may be varied by factors of thousands or millions.\nA 1\u00a0cm3 specimen of a metal or semiconductor has the order of 1022 atoms. In a metal, every atom donates at least one free electron for conduction, thus 1\u00a0cm3 of metal contains on the order of 1022 free electrons, whereas a 1\u00a0cm3 sample of pure germanium at 20\u00b0C contains about atoms, but only free electrons and holes. The addition of 0.001% of arsenic (an impurity) donates an extra 1017 free electrons in the same volume and the electrical conductivity is increased by a factor of 10,000.\nThe materials chosen as suitable dopants depend on the atomic properties of both the dopant and the material to be doped. In general, dopants that produce the desired controlled changes are classified as either electron acceptors or donors. Semiconductors doped with \"donor\" impurities are called \"n-type\", while those doped with \"acceptor\" impurities are known as \"p-type\". The n and p type designations indicate which charge carrier acts as the material's majority carrier. The opposite carrier is called the minority carrier, which exists due to thermal excitation at a much lower concentration compared to the majority carrier.\nFor example, the pure semiconductor silicon has four valence electrons that bond each silicon atom to its neighbors. In silicon, the most common dopants are group III and group V elements. Group III elements all contain three valence electrons, causing them to function as acceptors when used to dope silicon. When an acceptor atom replaces a silicon atom in the crystal, a vacant state (an electron \"hole\") is created, which can move around the lattice and function as a charge carrier. Group V elements have five valence electrons, which allows them to act as a donor; substitution of these atoms for silicon creates an extra free electron. Therefore, a silicon crystal doped with boron creates a p-type semiconductor whereas one doped with phosphorus results in an n-type material.\nDuring manufacture, dopants can be diffused into the semiconductor body by contact with gaseous compounds of the desired element, or ion implantation can be used to accurately position the doped regions.\nAmorphous semiconductors.\nSome materials, when rapidly cooled to a glassy amorphous state, have semiconducting properties. These include B, Si, Ge, Se, and Te, and there are multiple theories to explain them.\nEarly history of semiconductors.\nThe history of the understanding of semiconductors begins with experiments on the electrical properties of materials. The properties of the time-temperature coefficient of resistance, rectification, and light-sensitivity were observed starting in the early 19th century.\nThomas Johann Seebeck was the first to notice that semiconductors exhibit special feature such that experiment concerning an Seebeck effect emerged with much stronger result when applying semiconductors, in 1821. In 1833, Michael Faraday reported that the resistance of specimens of silver sulfide decreases when they are heated. This is contrary to the behavior of metallic substances such as copper. In 1839, Alexandre Edmond Becquerel reported observation of a voltage between a solid and a liquid electrolyte, when struck by light, the photovoltaic effect. In 1873, Willoughby Smith observed that selenium resistors exhibit decreasing resistance when light falls on them. In 1874, Karl Ferdinand Braun observed conduction and rectification in metallic sulfides, although this effect had been discovered earlier by Peter Munck af Rosensch\u00f6ld () writing for the \"Annalen der Physik und Chemie\" in 1835; Rosensch\u00f6ld's findings were ignored. Simon Sze stated that Braun's research was the earliest systematic study of semiconductor devices. Also in 1874, Arthur Schuster found that a copper oxide layer on wires had rectification properties that ceased when the wires are cleaned. William Grylls Adams and Richard Evans Day observed the photovoltaic effect in selenium in 1876.\nA unified explanation of these phenomena required a theory of solid-state physics, which developed greatly in the first half of the 20th century. In 1878 Edwin Herbert Hall demonstrated the deflection of flowing charge carriers by an applied magnetic field, the Hall effect. The discovery of the electron by J.J. Thomson in 1897 prompted theories of electron-based conduction in solids. Karl Baedeker, by observing a Hall effect with the reverse sign to that in metals, theorized that copper iodide had positive charge carriers. Johan Koenigsberger classified solid materials like metals, insulators, and \"variable conductors\" in 1914 although his student Josef Weiss already introduced the term Halbleiter (a semiconductor in modern meaning) in his Ph.D. thesis in 1910. Felix Bloch published a theory of the movement of electrons through atomic lattices in 1928. In 1930, Bernhard Gudden stated that conductivity in semiconductors was due to minor concentrations of impurities. By 1931, the band theory of conduction had been established by Alan Herries Wilson and the concept of band gaps had been developed. Walter H. Schottky and Nevill Francis Mott developed models of the potential barrier and of the characteristics of a metal\u2013semiconductor junction. By 1938, Boris Davydov had developed a theory of the copper-oxide rectifier, identifying the effect of the p\u2013n junction and the importance of minority carriers and surface states.\nAgreement between theoretical predictions (based on developing quantum mechanics) and experimental results was sometimes poor. This was later explained by John Bardeen as due to the extreme \"structure sensitive\" behavior of semiconductors, whose properties change dramatically based on tiny amounts of impurities. Commercially pure materials of the 1920s containing varying proportions of trace contaminants produced differing experimental results. This spurred the development of improved material refining techniques, culminating in modern semiconductor refineries producing materials with parts-per-trillion purity.\nDevices using semiconductors were at first constructed based on empirical knowledge before semiconductor theory provided a guide to the construction of more capable and reliable devices.\nAlexander Graham Bell used the light-sensitive property of selenium to transmit sound over a beam of light in 1880. A working solar cell, of low efficiency, was constructed by Charles Fritts in 1883, using a metal plate coated with selenium and a thin layer of gold; the device became commercially useful in photographic light meters in the 1930s. Point-contact microwave detector rectifiers made of lead sulfide were used by Jagadish Chandra Bose in 1904; the cat's-whisker detector using natural galena or other materials became a common device in the development of radio. However, it was somewhat unpredictable in operation and required manual adjustment for best performance. In 1906, H.J. Round observed light emission when electric current passed through silicon carbide crystals, the principle behind the light-emitting diode. Oleg Losev observed similar light emission in 1922, but at the time the effect had no practical use. Power rectifiers, using copper oxide and selenium, were developed in the 1920s and became commercially important as an alternative to vacuum tube rectifiers.\nThe first semiconductor devices used galena, including German physicist Ferdinand Braun's crystal detector in 1874 and Indian physicist Jagadish Chandra Bose's radio crystal detector in 1901.\nIn the years preceding World War II, infrared detection and communications devices prompted research into lead-sulfide and lead-selenide materials. These devices were used for detecting ships and aircraft, for infrared rangefinders, and for voice communication systems. The point-contact crystal detector became vital for microwave radio systems since available vacuum tube devices could not serve as detectors above about 4000\u00a0MHz; advanced radar systems relied on the fast response of crystal detectors. Considerable research and development of silicon materials occurred during the war to develop detectors of consistent quality.\nEarly transistors.\nDetector and power rectifiers could not amplify a signal. Many efforts were made to develop a solid-state amplifier and were successful in developing a device called the point contact transistor which could amplify 20\u00a0dB or more. In 1922, Oleg Losev developed two-terminal, negative resistance amplifiers for radio, but he died in the Siege of Leningrad after successful completion. In 1926, Julius Edgar Lilienfeld patented a device resembling a field-effect transistor, but it was not practical. Rudolf Hilsch and R. W. Pohl in 1938 demonstrated a solid-state amplifier using a structure resembling the control grid of a vacuum tube; although the device displayed power gain, it had a cut-off frequency of one cycle per second, too low for any practical applications, but an effective application of the available theory. At Bell Labs, William Shockley and A. Holden started investigating solid-state amplifiers in 1938. The first p\u2013n junction in silicon was observed by Russell Ohl about 1941 when a specimen was found to be light-sensitive, with a sharp boundary between p-type impurity at one end and n-type at the other. A slice cut from the specimen at the p\u2013n boundary developed a voltage when exposed to light.\nThe first working transistor was a point-contact transistor invented by John Bardeen, Walter Houser Brattain, and William Shockley at Bell Labs in 1947. Shockley had earlier theorized a field-effect amplifier made from germanium and silicon, but he failed to build such a working device, before eventually using germanium to invent the point-contact transistor. In France, during the war, Herbert Matar\u00e9 had observed amplification between adjacent point contacts on a germanium base. After the war, Matar\u00e9's group announced their \"Transistron\" amplifier only shortly after Bell Labs announced the \"transistor\".\nIn 1954, physical chemist Morris Tanenbaum fabricated the first silicon junction transistor at Bell Labs. However, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27710", "revid": "9092818", "url": "https://en.wikipedia.org/wiki?curid=27710", "title": "Sir Isaac Newton", "text": ""}
{"id": "27711", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=27711", "title": "Starch", "text": "Glucose polymer used as energy store in plants\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nStarch or amylum is a polymeric carbohydrate consisting of numerous glucose units joined by glycosidic bonds. This polysaccharide is produced by most green plants for energy storage. Worldwide, it is the most common carbohydrate in human diets, and is contained in large amounts in staple foods such as wheat, potatoes, maize (corn), rice, and cassava (manioc).\nPure starch is a white, tasteless and odorless powder that is insoluble in cold water or alcohol. It consists of two types of molecules: the linear and helical amylose and the branched amylopectin. Depending on the plant, starch generally contains 20 to 25% amylose and 75 to 80% amylopectin by weight. Glycogen, the energy reserve of animals, is a more highly branched version of amylopectin.\nIn industry, starch is often converted into sugars, for example by malting. These sugars may be fermented to produce ethanol in the manufacture of beer, whisky and biofuel. In addition, sugars produced from processed starch are used in many processed foods.\nMixing most starches in warm water produces a paste, such as wheatpaste, which can be used as a thickening, stiffening or gluing agent. The principal non-food, industrial use of starch is as an adhesive in the papermaking process. A similar paste, clothing or laundry starch, can be applied to certain textile goods before ironing to stiffen them.\nEtymology.\nThe word \"starch\" is from a Germanic root with the meanings \"strong, stiff, strengthen, stiffen\". \nModern German \"St\u00e4rke\" (strength, starch) is related and refers to the main historical applications, its uses in textiles: sizing yarn for weaving, and starching linen. \nThe Greek term for starch, \"amylon\" (\u1f04\u03bc\u03c5\u03bb\u03bf\u03bd), which means \"not milled\", is also related. It provides the root \"amyl\", which is used as a prefix for several carbon compounds related to or derived from starch (e.g. amyl alcohol, amylose, amylopectin).\nHistory.\nStarch grains from the rhizomes of \"Typha\" (cattails, bullrushes) as flour have been identified from grinding stones in Europe dating back to 30,000 years ago. Starch grains from sorghum were found on grind stones in caves in Ngalue, Mozambique dating up to 100,000 years ago.\nPure extracted wheat starch paste was used in Ancient Egypt, possibly to glue papyrus. The extraction of starch is first described in the \"Natural History\" of Pliny the Elder around 77\u201379 CE. Romans used it also in cosmetic creams, to powder the hair and to thicken sauces. Persians and Indians used it to make dishes similar to gothumai wheat halva. Rice starch as surface treatment of paper has been used in paper production in China since 700 CE. In the mid eighth century production of paper that was sized with wheat starch started in the Arabic world. Laundry starch was first described in England in the beginning of the 15th century and was essential to make 16th century ruffed collars.\nEnergy store of plants.\nPlants produce glucose from carbon dioxide and water by photosynthesis. The glucose is used to generate the chemical energy required for general metabolism as well as a precursor to myriad organic building blocks such as nucleic acids, lipids, proteins, and structural polysaccharides such as cellulose. Most green plants store any extra glucose in the form of starch, which is packed into semicrystalline granules called starch granules or amyloplasts. Toward the end of the growing season, starch accumulates in twigs of trees near the buds. Fruit, seeds, rhizomes, and tubers store starch to prepare for the next growing season. Young plants live on this stored energy in their roots, seeds, and fruits until they can find suitable soil in which to grow. The starch is also consumed at night when photosynthesis is not occurring.\nGreen algae and land-plants store their starch in the plastids, whereas red algae, glaucophytes, cryptomonads, dinoflagellates and the parasitic apicomplexa store a similar type of polysaccharide called floridean starch in their cytosol or periplast.\nEspecially when hydrated, glucose takes up much space and is osmotically active. Starch, on the other hand, being insoluble and therefore osmotically inactive, can be stored much more compactly. The semicrystalline granules generally consist of concentric layers of amylose and amylopectin which can be made bioavailable upon cellular demand in the plant.\nAmylose consists of long chains derived from glucose molecules connected by \u03b1-1,4-glycosidic linkage. Amylopectin is highly branched but also derived from glucose interconnected by \u03b1-1,6-glycosidic linkages. The same type of linkage is found in the animal reserve polysaccharide glycogen. By contrast, many structural polysaccharides such as chitin, cellulose, and peptidoglycan are linked by \u03b2-glycosidic bonds, which are more resistant to hydrolysis.\nStructure of starch particles.\nWithin plants, starch is stored in semi-crystalline granules. Each plant species has a distinctive starch granular size: rice starch is relatively small (about 2\u00a0\u03bcm), potato starches have larger granules (up to 100\u00a0\u03bcm) while wheat and tapioca fall in-between. Unlike other botanical sources of starch, wheat starch has a bimodal size distribution, with both smaller and larger granules ranging from 2 to 55\u00a0\u03bcm.\nSome cultivated plant varieties have pure amylopectin starch without amylose, known as \"waxy starches\". The most used is waxy maize, others are glutinous rice and waxy potato starch. Waxy starches undergo less retrogradation, resulting in a more stable paste. A maize cultivar with a relatively high proportion of amylose starch, amylomaize, is cultivated for the use of its gel strength and for use as a resistant starch (a starch that resists digestion) in food products.\nBiosynthesis.\nPlants synthesize starch in two types of tissues. The first type is storage tissues, for example, cereal endosperm, and storage roots and stems such as cassava and potato. The second type is green tissue, for example, leaves, where many plant species synthesize transitory starch on a daily basis. In both tissue types, starch is synthesized in plastids (amyloplasts and chloroplasts).\nThe biochemical pathway involves conversion of glucose 1-phosphate to ADP-glucose using the enzyme glucose-1-phosphate adenylyltransferase. This step requires energy in the form of ATP. A number of starch synthases available in plastids then adds the ADP-glucose via \u03b1-1,4-glycosidic bond to a growing chain of glucose residues, liberating ADP. The ADP-glucose is almost certainly added to the non-reducing end of the amylose polymer, as the UDP-glucose is added to the non-reducing end of glycogen during glycogen synthesis. The small glucan chain, further agglomerate to form initials of starch granules. \nThe biosynthesis and expansion of granules represent a complex molecular event that can be subdivided into four major steps, namely, granule initiation, coalescence of small granules, phase transition, and expansion. Several proteins have been characterized for their involvement in each of these processes. For instance, a chloroplast membrane-associated protein, MFP1, determines the sites of granule initiation. Another protein named PTST2 binds to small glucan chains and agglomerates to recruit starch synthase 4 (SS4). Three other proteins, namely, PTST3, SS5, and MRC, are also known to be involved in the process of starch granule initiation. Furthermore, two proteins named ESV and LESV play a role in the aqueous-to-crystalline phase transition of glucan chains. Several catalytically active starch synthases, such as SS1, SS2, SS3, and GBSS, are critical for starch granule biosynthesis and play a catalytic role at each step of granule biogenesis and expansion.\nIn addition to above proteins, starch branching enzymes (BEs) introduces \u03b1-1,6-glycosidic bonds between the glucose chains, creating the branched amylopectin. The starch debranching enzyme (DBE) isoamylase removes some of these branches. Several isoforms of these enzymes exist, leading to a highly complex synthesis process.\nDegradation.\nThe starch that is synthesized in plant leaves during the day is transitory: it serves as an energy source at night. Enzymes catalyze release of glucose from the granules. The insoluble, highly branched starch chains require phosphorylation in order to be accessible for degrading enzymes. The enzyme glucan, water dikinase (GWD) installs a phosphate at the C-6 position of glucose, close to the chain's 1,6-alpha branching bonds. A second enzyme, phosphoglucan, water dikinase (PWD) phosphorylates the glucose molecule at the C-3 position. After the second phosphorylation, the first degrading enzyme, beta-amylase (BAM) attacks the glucose chain at its non-reducing end. Maltose is the main product released. If the glucose chain consists of three or fewer molecules, BAM cannot release maltose. A second enzyme, disproportionating enzyme-1 (DPE1), combines two maltotriose molecules. From this chain, a glucose molecule is released. Now, BAM can release another maltose molecule from the remaining chain. This cycle repeats until starch is fully degraded. If BAM comes close to the phosphorylated branching point of the glucose chain, it can no longer release maltose. In order for the phosphorylated chain to be degraded, the enzyme isoamylase (ISA) is required.\nThe products of starch degradation are predominantly maltose and smaller amounts of glucose. These molecules are exported from the plastid to the cytosol, maltose via the maltose transporter and glucose by the plastidic glucose translocator (pGlcT). These two sugars are used for sucrose synthesis. Sucrose can then be used in the oxidative pentose phosphate pathway in the mitochondria, to generate ATP at night.\nStarch industry.\nIn addition to starchy plants consumed directly, 66 million tonnes of starch were processed industrially in 2008. By 2011, production had increased to 73 million tons.\nIn the EU the starch industry produced about 11 million tonnes in 2011, with around 40% being used for industrial applications and 60% for food uses, most of the latter as glucose syrups. In 2017 EU production was 11 million ton of which 9,4 million ton was consumed in the EU and of which 54% were starch sweeteners.\nThe US produced about 27.5 million tons of starch in 2017, of which about 8.2 million tons was high fructose syrup, 6.2 million tons was glucose syrups, and 2.5 million tons were starch products. The rest of the starch was used for producing ethanol (1.6 billion gallons).\nIndustrial processing.\nThe starch industry extracts and refines starches from crops by wet grinding, washing, sieving and drying. Today, the main commercial refined starches are cornstarch, tapioca, arrowroot, and wheat, rice, and potato starches. To a lesser extent, sources of refined starch are sweet potato, sago and mung bean. To this day, starch is extracted from more than 50 types of plants.\nCrude starch is processed on an industrial scale to maltodextrin and glucose syrups and fructose syrups. These massive conversions are mediated by a variety of enzymes, which break down the starch to varying extents. Here breakdown involves hydrolysis, i.e. cleavage of bonds between sugar subunits by the addition of water. Some sugars are isomerized. The processes have been described as occurring in two phases: liquefaction and saccharification. The liquefaction converts starch into dextrins. Amylase is a key enzyme for producing dextrin. The saccharification converts dextrin into maltoses and glucose. Diverse enzymes are used in this second phase, including pullanase and other amylases.\nDextrinization.\nIf starch is subjected to dry heat, it breaks down to form dextrins, also called \"pyrodextrins\" in this context. This break down process is known as dextrinization. (Pyro)dextrins are mainly yellow to brown in color and dextrinization is partially responsible for the browning of toasted bread.\nFood.\nStarch is the most common carbohydrate in the human diet and is contained in many staple foods. The major sources of starch intake worldwide are the cereals (rice, wheat, and maize) and the root vegetables (potatoes and cassava). Many other starchy foods are grown, some only in specific climates, including acorns, arrowroot, arracacha, bananas, barley, breadfruit, buckwheat, canna, colocasia, cuckoo-pint, katakuri, kudzu, malanga, millet, oats, oca, polynesian arrowroot, sago, sorghum, sweet potatoes, rye, taro, chestnuts, water chestnuts, and yams, and many kinds of beans, such as favas, lentils, mung beans, peas, and chickpeas.\nBefore processed foods, people consumed large amounts of uncooked and unprocessed starch-containing plants, which contained high amounts of resistant starch. Microbes within the large intestine ferment or consume the starch, producing short-chain fatty acids, which are used as energy, and support the maintenance and growth of the microbes. Upon cooking, starch is transformed from an insoluble, difficult-to-digest granule into readily accessible glucose chains with very different nutritional and functional properties.\nIn current diets, highly processed foods are more easily digested and release more glucose in the small intestine\u2014less starch reaches the large intestine and more energy is absorbed by the body. It is thought that this shift in energy delivery (as a result of eating more processed foods) may be one of the contributing factors to the development of metabolic disorders of modern life, including obesity and diabetes.\nThe amylose/amylopectin ratio, molecular weight and molecular fine structure influences the physicochemical properties as well as energy release of different types of starches. In addition, cooking and food processing significantly impacts starch digestibility and energy release. Starch has been classified as rapidly digestible starch, slowly digestible starch and resistant starch, depending upon its digestion profile. Raw starch granules resist digestion by human enzymes and do not break down into glucose in the small intestine - they reach the large intestine instead and function as prebiotic dietary fiber. When starch granules are fully gelatinized and cooked, the starch becomes easily digestible and releases glucose quickly within the small intestine. When starchy foods are cooked and cooled, some of the glucose chains re-crystallize and become resistant to digestion again. Slowly digestible starch can be found in raw cereals, where digestion is slow but relatively complete within the small intestine. Widely used prepared foods containing starch are bread, pancakes, cereals, noodles, pasta, porridge and tortilla.\nDuring cooking with high heat, sugars released from starch can react with amino acids via the Maillard reaction, forming advanced glycation end-products (AGEs), contributing aromas, flavors and texture to foods. One example of a dietary AGE is acrylamide. Recent evidence suggests that the intestinal fermentation of dietary AGEs may be associated with insulin resistance, atherosclerosis, diabetes and other inflammatory diseases. This may be due to the impact of AGEs on intestinal permeability.\nStarch gelatinization during cake baking can be impaired by sugar competing for water, preventing gelatinization and improving texture.\nStarch sugars.\nStarch can be hydrolyzed into simpler carbohydrates by acids, various enzymes, or a combination of the two. The resulting fragments are known as dextrins. The extent of conversion is typically quantified by dextrose equivalent (DE), which is roughly the fraction of the glycosidic bonds in starch that have been broken.\nThese starch sugars are by far the most common starch based food ingredient and are used as sweeteners in many drinks and foods. They include:\nModified starches.\nThe modified food starches are E coded according to European Food Safety Authority and INS coded Food Additives according to the Codex Alimentarius:\nINS 1400, 1401, 1402, 1403 and 1405 are in the EU food ingredients without an E-number. Typical modified starches for technical applications are cationic starches, hydroxyethyl starch, carboxymethylated starches and thiolated starches.\nUse as food additive.\nAs an additive for food processing, food starches are typically used as thickeners and stabilizers in foods such as puddings, custards, soups, sauces, gravies, pie fillings, and salad dressings, and to make noodles and pastas. They function as thickeners, extenders, emulsion stabilizers and are exceptional binders in processed meats.\nGummed sweets such as jelly beans and wine gums are not manufactured using a mold in the conventional sense. A tray is filled with native starch and leveled. A positive mold is then pressed into the starch leaving an impression of 1,000 or so jelly beans. The jelly mix is then poured into the impressions and put onto a stove to set. This method greatly reduces the number of molds that must be manufactured.\nResistant starch.\nResistant starch is starch that escapes digestion in the small intestine of healthy individuals. High-amylose starch from wheat or corn has a higher gelatinization temperature than other types of starch, and retains its resistant starch content through baking, mild extrusion and other food processing techniques. It is used as an insoluble dietary fiber in processed foods such as bread, pasta, cookies, crackers, pretzels and other low moisture foods. It is also utilized as a dietary supplement for its health benefits. Published studies have shown that resistant starch helps to improve insulin sensitivity, reduces pro-inflammatory biomarkers interleukin 6 and tumor necrosis factor alpha and improves markers of colonic function.\nIt has been suggested that resistant starch contributes to the health benefits of intact whole grains.\nSynthetic starch.\nA cell-free chemoenzymatic process has been demonstrated to synthesize starch from CO2 and hydrogen. The chemical pathway of 11 core reactions was drafted by computational pathway design and converts CO2 to starch at a rate that is ~8.5-fold higher than starch synthesis in maize.\nNon-food applications.\nPapermaking.\nPapermaking is the largest non-food application for starches globally, consuming many millions of metric tons annually. In a typical sheet of copy paper for instance, the starch content may be as high as 8%. Both chemically modified and unmodified starches are used in papermaking. In the wet part of the papermaking process, generally called the \"wet-end\", the starches used are cationic and have a positive charge bound to the starch polymer. These starch derivatives associate with the anionic or negatively charged paper fibers / cellulose and inorganic fillers. Cationic starches together with other retention and internal sizing agents help to give the necessary strength properties to the paper web formed in the papermaking process (wet strength), and to provide strength to the final paper sheet (dry strength).\nIn the dry end of the papermaking process, the paper web is rewetted with a starch based solution. The process is called surface sizing. Starches used have been chemically, or enzymatically depolymerized at the paper mill or by the starch industry (oxidized starch). The size/starch solutions are applied to the paper web by means of various mechanical presses (size presses). Together with surface sizing agents the surface starches impart additional strength to the paper web and additionally provide water hold out or \"size\" for superior printing properties. Starch is also used in paper coatings as one of the binders for the coating formulations which include a mixture of pigments, binders and thickeners. Coated paper has improved smoothness, hardness, whiteness and gloss and thus improves printing characteristics.\nAdhesives.\nCorrugated board adhesives are the next largest application of non-food starches globally. Starch glues are mostly based on unmodified native starches, plus some additive such as borax and caustic soda. Part of the starch is gelatinized to carry the slurry of uncooked starches and prevent sedimentation. This opaque glue is called a SteinHall adhesive. The glue is applied on tips of the fluting. The fluted paper is pressed to paper called liner. This is then dried under high heat, which causes the rest of the uncooked starch in glue to swell/gelatinize. This gelatinizing makes the glue a fast and strong adhesive for corrugated board production.\nStarch is used in the manufacture of various adhesives or glues for book-binding, wallpaper adhesives, paper sack production, tube winding, gummed paper, envelope adhesives, school glues and bottle labeling. Starch derivatives, such as yellow dextrins, can be modified by addition of some chemicals to form a hard glue for paper work; some of those forms use borax or soda ash, which are mixed with the starch solution at to create a very good adhesive. Sodium silicate can be added to reinforce these formula.\nA related large non-food starch application is in the construction industry, where starch is used in the gypsum wall board manufacturing process. Chemically modified or unmodified starches are added to the stucco containing primarily gypsum. Top and bottom heavyweight sheets of paper are applied to the formulation, and the process is allowed to heat and cure to form the eventual rigid wall board. The starches act as a glue for the cured gypsum rock with the paper covering, and also provide rigidity to the board.\nChemical tests.\nA solution of triiodide (I3\u2212) (formed by mixing iodine and potassium iodide) can be used to test for starch. The colorless solution turns dark blue in the presence of starch. The strength of the resulting blue color depends on the amount of amylose present. Waxy starches with little or no amylose present will color red. Benedict's test and Fehling's test is also done to indicate the presence of starch.\nSafety.\nIn the US, the Occupational Safety and Health Administration (OSHA) has set the legal limit (Permissible exposure limit) for starch exposure in the workplace as 15\u00a0mg/m3 total exposure and 5\u00a0mg/m3 respiratory exposure over an eight-hour workday. The National Institute for Occupational Safety and Health (NIOSH) has set a Recommended exposure limit (REL) of 10\u00a0mg/m3 total exposure and 5\u00a0mg/m3 respiratory exposure over an eight-hour workday.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27712", "revid": "45366078", "url": "https://en.wikipedia.org/wiki?curid=27712", "title": "Sugar", "text": "Sweet-tasting, water-soluble carbohydrates\nSugar is the generic name for sweet-tasting, soluble carbohydrates, many of which are used in food. Simple sugars, also called monosaccharides, include glucose, fructose, and galactose. Compound sugars, also called disaccharides or double sugars, are molecules made of two bonded monosaccharides; common examples are sucrose (glucose + fructose), lactose (glucose + galactose), and maltose (two molecules of glucose). White sugar is almost pure sucrose. During digestion, compound sugars are hydrolysed into simple sugars.\nLonger chains of saccharides are not regarded as sugars, and are called oligosaccharides or polysaccharides. Starch is a glucose polymer found in plants \u2013 the most abundant source of energy in human food. Some other chemical substances, such as ethylene glycol, glycerol and sugar alcohols, may have a sweet taste, but are not classified as sugar.\nSugars are found in the tissues of most plants. Honey and fruits are abundant natural sources of simple sugars. Sucrose is especially concentrated in sugarcane and sugar beet, making them efficient for commercial extraction to make refined sugar. In 2016, the combined world production of those two crops was about two billion tonnes. Maltose may be produced by malting grain. Lactose is the only sugar that cannot be extracted from plants, as it occurs only in milk, including human breast milk, and in some dairy products. A cheap source of sugar is corn syrup, industrially produced by converting corn starch into sugars, such as maltose, fructose and glucose.\nSucrose is used in prepared foods (e.g., cookies and cakes), is sometimes added to commercially available ultra-processed food and beverages, and is sometimes used as a sweetener for foods (e.g., toast and cereal) and beverages (e.g., coffee and tea). Globally on average a person consumes about of sugar each year. North and South Americans consume up to , and Africans consume under .\nThe use of added sugar in food and beverage manufacturing is a concern for elevated calorie intake, which is associated with an increased risk of several diseases, such as obesity, diabetes, and cardiovascular disorders. In 2015, the World Health Organization recommended that adults and children reduce their intake of free sugars to less than 10% of their total energy intake, encouraging a reduction to below 5%.\nEtymology.\nThe etymology of \"sugar\" reflects the commodity's spread. From Sanskrit ', meaning \"ground or candied sugar\", came Persian ' and Arabic \"sukkar\". The Arabic word was borrowed in Medieval Latin as \"succarum\", whence came the 12th century French \"sucre\" and the English \"sugar\". Sugar was introduced into Europe by the Arabs in Sicily and Spain.\nThe English word \"jaggery\", a coarse brown sugar made from date palm sap or sugarcane juice, has a similar etymological origin: Portuguese ' from the Malayalam ', which is from the Sanskrit \"\".\nHistory.\nSugar was first produced from sugar cane in the Indian subcontinent. Diverse species of sugar cane seem to have originated from India (\"Saccharum barberi\" and \"S. edule\") and New Guinea (\"S. officinarum\"). Sugarcane is described in Chinese manuscripts dating to the 8th century BCE, which state that the use of sugarcane originated in India.\nNearchus, admiral of Alexander the Great, the Greek physician Pedanius Dioscorides and the Roman Pliny the Elder also described sugar. In the mid-15th century, sugar was introduced into Madeira and the Canary Islands, where it was mass produced. Christopher Columbus introduced it to the New World leading to sugar industries in Cuba and Jamaica by the 1520s. The Portuguese took sugar cane to Brazil. \nBeet sugar, the starting point for the modern sugar industry, was a German invention. Beet sugar was first produced industrially in 1801 in Cunern, Prussia.\nSugar became a household item by the 19th century, and this evolution of taste and demand for sugar as an essential food ingredient resulted in major economic and social changes. Demand drove, in part, the colonisation and industrialisation of previously under-developed lands. It was also intimately associated with slavery. World consumption increased more than 100 times from 1850 to 2000, led by the United Kingdom, where it increased from about 2 pounds per head per year in 1650 to 90 pounds by the early 20th century.\nChemistry.\nScientifically, \"sugar\" loosely refers to a number of compounds typically with the formula (CH2O)n. Some large classes of sugars, ranked in increasing order of molecular weight are monosaccharides, disaccharides, or oligosaccharides. \nMonosaccharides.\nMonosaccharides are also called \"simple sugars\", the most important being glucose. Most monosaccharides have a formula that conforms to CnH2nOn with n between 3 and 7 (deoxyribose being an exception). Glucose has the molecular formula C6H12O6. The names of typical sugars end with -\"ose\", as in \"glucose\" and \"fructose\". Such labels may also refer to any types of these compounds. Fructose, galactose, and glucose are all simple sugars, monosaccharides, with the general formula . They have five hydroxyl groups (\u2212OH) and a carbonyl group (C=O) and are cyclic when dissolved in water. They each exist as several isomers with dextro- and laevo-rotatory forms that cause polarized light to diverge to the right or the left.\nThe acyclic monosaccharides (and disaccharides) contain either aldehyde groups or ketone groups. These carbon-oxygen double bonds (C=O) are the reactive centers. All saccharides with more than one ring in their structure result from two or more monosaccharides joined by glycosidic bonds with the resultant loss of a molecule of water (H2O) per bond.\nDisaccharides.\nLactose, maltose, and sucrose are disaccharides, also called \"compound sugars\". The share the formula . They are formed by the condensation of two monosaccharide molecules with the expulsion of a molecule of water.\nPolysaccharides.\nLonger than disaccharides are oligosaccharides and polysaccharides. Cellulose and chitin are polymers, often crystalline, found in diverse plants and insects, respectively. Cellulose cannot be digested directly by animals. Starch is an amorphous polymer of glucose that is found in many plants and is widely used in the sugar industry.\nSources.\nThe sugar contents of common fruits and vegetables are presented in Table 1.\n &lt;templatestyles src=\"Citation/styles.css\"/&gt;^A The carbohydrate figure is calculated in the USDA database and does not always correspond to the sum of the sugars, the starch, and the dietary fiber.\n &lt;templatestyles src=\"Citation/styles.css\"/&gt;^B The fructose to fructose plus glucose ratio is calculated by including the fructose and glucose coming from the sucrose.\nProduction.\nDue to rising demand, sugar production in general increased some 14% over the period 2009 to 2018. The largest importers were China, Indonesia, and the United States.\nSugar.\nIn 2022\u20132023 world production of sugar was 186 million tonnes, and in 2023\u20132024 an estimated 194 million tonnes \u2014 a surplus of 5 million tonnes, according to Ragus.\nSugarcane.\n&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\nSugar cane accounted for around 21% of the global crop production over the 2000\u20132021 period. The Americas was the leading region in the production of sugar cane (52% of the world total).\nGlobal production of sugarcane in 2022 was 1.9\u00a0billion tonnes, with Brazil producing 38% of the world total and India 23% (table).\nSugarcane is any of several species, or their hybrids, of giant grasses in the genus \"Saccharum\" in the family Poaceae. They have been cultivated in tropical climates in the Indian subcontinent and Southeast Asia over centuries for the sucrose found in their stems.\nSugar cane requires a frost-free climate with sufficient rainfall during the growing season to make full use of the plant's substantial growth potential. The crop is harvested mechanically or by hand, chopped into lengths and conveyed rapidly to the processing plant (commonly known as a sugar mill) where it is either milled and the juice extracted with water or extracted by diffusion. The juice is clarified with lime and heated to destroy enzymes. The resulting thin syrup is concentrated in a series of evaporators, after which further water is removed. The resulting supersaturated solution is seeded with sugar crystals, facilitating crystal formation and drying. Molasses is a by-product of the process and the fiber from the stems, known as bagasse, is burned to provide energy for the sugar extraction process. The crystals of raw sugar have a sticky brown coating and either can be used as they are, can be bleached by sulfur dioxide, or can be treated in a carbonatation process to produce a whiter product. About of irrigation water is needed for every of sugar produced.\nSugar beet.\n&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\nIn 2022, global production of sugar beets was 260 million tonnes, led by Russia with 18.8% of the world total (table).\nSugar beet became a major source of sugar in the 19th century when methods for extracting the sugar became available. It is a biennial plant, a cultivated variety of \"Beta vulgaris\" in the family Amaranthaceae, the tuberous root of which contains a high proportion of sucrose. It is cultivated as a root crop in temperate regions with adequate rainfall and requires a fertile soil. The crop is harvested mechanically in the autumn and the crown of leaves and excess soil removed. The roots do not deteriorate rapidly and may be left in the field for some weeks before being transported to the processing plant where the crop is washed and sliced, and the sugar extracted by diffusion. Milk of lime is added to the raw juice with calcium carbonate. After water is evaporated by boiling the syrup under a vacuum, the syrup is cooled and seeded with sugar crystals. The white sugar that crystallizes can be separated in a centrifuge and dried, requiring no further refining.\nRefining.\nRefined sugar is made from raw sugar that has undergone a refining process to remove the molasses. Raw sugar is sucrose which is extracted from sugarcane or sugar beet. While raw sugar can be consumed, the refining process removes unwanted tastes and results in refined sugar or white sugar.\nThe sugar may be transported in bulk to the country where it will be used and the refining process often takes place there. The first stage is known as affination and involves immersing the sugar crystals in a concentrated syrup that softens and removes the sticky brown coating without dissolving them. The crystals are then separated from the liquor and dissolved in water. The resulting syrup is treated either by a carbonatation or by a phosphatation process. Both involve the precipitation of a fine solid in the syrup and when this is filtered out, many of the impurities are removed at the same time. Removal of color is achieved by using either a granular activated carbon or an ion-exchange resin. The sugar syrup is concentrated by boiling and then cooled and seeded with sugar crystals, causing the sugar to crystallize out. The liquor is spun off in a centrifuge and the white crystals are dried in hot air and ready to be packaged or used. The surplus liquor is made into refiners' molasses.\nThe International Commission for Uniform Methods of Sugar Analysis sets standards for the measurement of the purity of refined sugar, known as ICUMSA numbers; lower numbers indicate a higher level of purity in the refined sugar.\nRefined sugar is widely used for industrial needs for higher quality. Refined sugar is purer (ICUMSA below 300) than raw sugar (ICUMSA over 1,500). The level of purity associated with the colors of sugar, expressed by standard number ICUMSA, the smaller ICUMSA numbers indicate the higher purity of sugar.\nForms and uses.\nDensities.\nThe densities of culinary sugars varies owing to differences in particle size and inclusion of moisture:\nBrown sugars.\nBrown sugars are granulated sugars, either containing residual molasses, or with the grains deliberately coated with molasses to produce a light- or dark-colored sugar such as muscovado and turbinado. They are used in baked goods, confectionery, and toffees. Their darkness is due to the amount of molasses they contain. They may be classified based on their darkness or country of origin.\nBurnt sugars and caramels.\nHeating sugar to near 200 \u00b0C for several minutes yields a product called burnt sugar. Often additives are used to modify the resulting caramels, e.g. alkali or sulfites. Several volatile products evolve in the heating process including butanone, several furans (2-Acetylfuran, furanone, hydroxymethyl furfural), and levoglucosan and more.\nBecause sugars burn easily when exposed to flame, the handling of sugar powders risks dust explosion. The 2008 Georgia sugar refinery explosion, which killed 14 people and injured 36, and destroyed most of the refinery, was caused by the ignition of sugar dust.\nConsumption.\nWorldwide sugar provides 10% of the daily calories (based on a 2000 kcal diet). In 1750, the average Briton got 72 calories a day from sugar. In 1913, this had risen to 395. In 2015, sugar still provided around 14% of the calories in British diets. According to one source, per capita consumption of sugar in 2016 was highest in the United States, followed by Germany and the Netherlands.\nNutrition and flavor.\nBrown and white granulated sugar are 97% to nearly 100% carbohydrates, respectively, with less than 2% water, and no dietary fiber, protein or fat (table). Because brown sugar contains 5\u201310% molasses reintroduced during processing, its value to some consumers is a richer flavor than white sugar.\nHealth effects.\nThe World Health Organization and other clinical associations recommend that reducing the consumption of \"free sugar\" (sugar sources added during manufacturing) to less than 10% of total energy needs can help to lower disease risk. This amount of sugar consumption is equivalent to about or 12 teaspoons of added sugar per day. As of 2025[ [update]], the American Heart Association recommends that free sugar intake be limited to 6% of total daily energy needs, or (9 teaspoons) for adult males, and (6 teaspoons) for women. In many countries, the source and amount of added sugars can be viewed among ingredients on the labels of packaged foods. Added sugars provide no nutritional benefit, but are a source of excess calories that can lead to overweight and increased disease risk.\nObesity and metabolic syndrome.\nA 2003 technical report by the World Health Organization provided evidence that high intake of sugary drinks (including fruit juice) increases the risk of obesity by adding to overall energy intake. By itself, sugar is not a factor causing obesity and metabolic syndrome, but rather its excessive consumption adds to caloric burden, which meta-analyses showed could increase the risk of developing type 2 diabetes and metabolic syndrome in adults and children.\nCancer.\nSugar consumption does not directly cause cancer. Cancer Council Australia have stated that \"there is no evidence that consuming sugar makes cancer cells grow faster or cause cancer\". There is an indirect relationship between sugar consumption and obesity-related cancers through increased risk of excess body weight.\nThe American Institute for Cancer Research and World Cancer Research Fund recommend that people limit sugar consumption.\nThere is a popular misconception that cancer can be treated by reducing sugar and carbohydrate intake to supposedly \"starve\" tumours. In reality, the health of people with cancer is best served by maintaining a healthy diet.\nCognition.\nDespite some studies suggesting that sugar consumption causes hyperactivity, the quality of evidence is low and it is generally accepted within the scientific community that the notion of children's 'sugar rush' is a myth. A 2019 meta-analysis found that sugar consumption does not improve mood, but can lower alertness and increase fatigue within an hour of consumption. One review of low-quality studies of children consuming high amounts of energy drinks showed association with higher rates of unhealthy behaviors, including smoking and excessive alcohol use, and with hyperactivity and insomnia, although such effects could not be specifically attributed to sugar over other components of those drinks such as caffeine.\nTooth decay.\nThe WHO, Action on Sugar and the Scientific Advisory Committee on Nutrition (SACN) state dental caries, also known as tooth decay/cavities, \"can be prevented by avoiding dietary free sugars\". \nA review of human studies showed that the incidence of caries is lower when sugar intake is less than 10% of total energy consumed. Sugar-sweetened beverage consumption is associated with an increased risk of tooth decay.\nNutritional displacement.\nThe \"empty calories\" argument states that a diet high in added (or 'free') sugars will reduce consumption of foods that contain essential nutrients. This nutrient displacement occurs if sugar makes up more than 25% of daily energy intake, a proportion associated with poor diet quality and risk of obesity. Displacement may occur at lower levels of consumption.\nRecommended dietary intake.\nThe WHO recommends that both adults and children reduce the intake of free sugars to less than 10% of total energy intake. \"Free sugars\" include monosaccharides and disaccharides added to foods, and sugars found in fruit juice and concentrates, as well as in honey and syrups.\nOn 20 May 2016, the U.S. Food and Drug Administration announced changes to the Nutrition Facts panel displayed on all foods, to be effective by July 2018. New to the panel is a requirement to list \"added sugars\" by weight and as a percent of Daily Value (DV). For vitamins and minerals, the intent of DVs is to indicate how much should be consumed. For added sugars, the guidance is that 100% DV should not be exceeded. 100% DV is defined as 50 grams. For a person consuming 2000 calories a day, 50 grams is equal to 200 calories and thus 10% of total calories\u2014the same guidance as the WHO. To put this in context, most cans of soda contain 39 grams of sugar. In the United States, a government survey on food consumption in 2013\u20132014 reported that, for men and women aged 20 and older, the average total sugar intakes\u2014naturally occurring in foods and added\u2014were, respectively, 125 and 99 grams per day. The American Heart Association recommends even lower daily consumption of added sugars: 36 grams for men, and 25 grams for women.\nSociety and culture.\nManufacturers of sugary products, such as soft drinks and candy, and the Sugar Research Foundation have been accused of trying to influence consumers and medical associations in the 1960s and 1970s by creating doubt about the potential health hazards of sucrose overconsumption, while promoting saturated fat as the main dietary risk factor in cardiovascular diseases. In 2016, the criticism led to recommendations that diet policymakers emphasize the need for high-quality research that accounts for multiple biomarkers on development of cardiovascular diseases.\nOriginally, no sugar was white; anthropologist Sidney Mintz writes that white likely became understood as the ideal after groups who associated the color white with purity transferred their value to sugar. In India, sugar frequently appears in religious observances. For ritual purity, such sugar cannot be white.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n\u00a0This article incorporates text from a free content work. Licensed under CC BY-SA IGO 3.0 (https://). Text taken from https://, FAO, FAO. "}
{"id": "27715", "revid": "38001712", "url": "https://en.wikipedia.org/wiki?curid=27715", "title": "Saint Louis", "text": "Saint Louis, Saint-Louis or St. Louis commonly refers to:\nIt may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "27717", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=27717", "title": "Salma Hayek", "text": "Mexican and American actress (born 1966)\nSalma Valgarma Hayek Pinault ( , ; n\u00e9e\u00a0Hayek Jim\u00e9nez; born September 2, 1966) is a Mexican and American actress and film producer. She began her career in Mexico with starring roles in the telenovela \"Teresa\" (1989\u20131991) as well as the romantic drama \"Midaq Alley\" (1995). She soon established herself in Hollywood with appearances in films such as \"Desperado\" (1995), \"From Dusk till Dawn\" (1996), \"Wild Wild West\" (1999), and \"Dogma\" (1999).\nHayek's portrayal of painter Frida Kahlo in the biopic \"Frida\" (2002), which she also produced, made her the first Mexican actress to be nominated for the Academy Award for Best Actress. In subsequent years, Hayek focused more on producing while starring in the action-centered pictures \"Once Upon a Time in Mexico\" (2003), \"After the Sunset\" (2004) and \"Bandidas\" (2006). She achieved further commercial success with the comedies \"Grown Ups\" (2010), \"Grown Ups 2\" (2013) and \"The Hitman's Bodyguard\" (2017), and lent her voice for the animated \"Puss in Boots\" (2011), \"Sausage Party\" (2016) and \"\" (2022). She also earned critical acclaim for her performances in the dramas \"Tale of Tales\" (2015), \"Beatriz at Dinner\" (2017) and \"House of Gucci\" (2021). She played Ajak in the Marvel Cinematic Universe film \"Eternals\" (2021), which emerged as her highest-grossing live action film.\nHayek's directing, producing and acting work on television has earned her four Emmy Awards nominations. She won the Daytime Emmy Award for Outstanding Directing in a Children Special for \"The Maldonado Miracle\" (2004) and received two Primetime Emmy Award nominations, one for Outstanding Guest Actress in a Comedy Series and the other for Outstanding Comedy Series, for her work on the ABC television comedy-drama \"Ugly Betty\" (2006\u20132010). She also produced and played Minerva Mirabal in the Showtime film \"In the Time of the Butterflies\" (2001) and guest-starred on the NBC comedy series \"30 Rock\" (2009\u20132013).\nAs a public figure, Hayek has been cited as one of Hollywood's most powerful and influential Latina actresses as well as one of the world's most beautiful women by various media outlets. \"Time\" magazine named her one of the 100 most influential people in the world in 2023. In 2021, she was honored with a star on the Hollywood Walk of Fame. She is married to business magnate Fran\u00e7ois-Henri Pinault, with whom she has a daughter.\nEarly life.\nSalma Hayek was born in Coatzacoalcos, Veracruz, Mexico. Her father, Sami Hayek Dom\u00ednguez, is of Lebanese descent. His ancestors hail from the city of Baabdat, Lebanon, a city Salma and her father visited in 2015 to promote her movie \"Kahlil Gibran's The Prophet\". He owns an industrial-equipment firm and is an oil company executive in Mexico; he once ran for mayor of Coatzacoalcos. Her mother, Diana Jim\u00e9nez Medina, is an opera singer and talent scout; she is of Spanish descent. While visiting Madrid in an interview in 2015 with \"Un Nuevo D\u00eda\", Hayek described herself as fifty percent Lebanese and fifty percent Spanish, saying that her grandmother/maternal great-grandparents were from Spain. Her younger brother, Sami, is a furniture designer.\nHayek was raised in a wealthy, devout Catholic family, and at age 12 opted to study at the Academy of the Sacred Heart in Grand Coteau, Louisiana. In school, she was diagnosed with dyslexia. She attended university at the Universidad Iberoamericana studying international relations. In a 2011 interview with \"V\" magazine, Hayek mentioned that she had once been an illegal immigrant in the United States, although it was not for a long period of time.\nCareer.\nEarly roles in Mexico (1988\u20131994).\nHayek's first screen appearance was in the television series in \"Un Nuevo Amanecer\" (1988), which earned her the TVyNovelas Award for Best Debut Actress. Televisa subsequently selected Hayek, who was 23 at the time, to play the title role in \"Teresa\" (1989\u20131991), a successful Mexican telenovela that made her a star in Mexico. The series ran for two years and 125 episodes, and earned her the 1990 TVyNovelas Award for Best Female Revelation.\nDetermined to pursue a film career in Hollywood, Hayek moved to Los Angeles in 1991 following the conclusion of \"Teresa\". With limited fluency in English and dyslexia, she soon enrolled in English lessons and studied acting under Stella Adler. Hayek initially struggled with the lack of acting job offers after moving to the United States, recalling that \"there was no industry or parts for Latin women\", and was once even told that her accent would \"make moviegoers think of housekeepers\". During this period, she secured guest-spots in television series such as \"Dream On\" (1992) and \"The Sinbad Show\" (1993) as well as supporting roles in the drama \"Mi Vida Loca\" (1993), and the made-for-Showtime thriller \"Roadracers\" (1994), her first collaboration with director Robert Rodriguez.\nIn 1994, Hayek was cast as Alma, a poverty-stricken young woman who becomes a sex worker, in Jorge Fons's drama \"El callej\u00f3n de los milagros\" (\"Miracle Alley\"), which was based on the 1940s eponymous novel by Egyptian Naguib Mahfouz and translated from Cairo to Mexico City. The film was the subject of critical acclaim, reportedly won more awards than any other movie in the history of Mexican cinema, and earned Hayek a nomination for the Ariel Award for Best Actress. Hayek was one of the few actresses permitted to appear on both Televisa and TV Azteca, through a special dispensation from Emilio Azc\u00e1rraga Milmo, who tried to persuade her to return to Mexico with an exclusive deal, which she declined in order to pursue a career in Hollywood.\nHollywood breakthrough (1995\u20132001).\nIn 1995, Robert Rodriguez and his co-producer and then-wife, Elizabeth Avellan, cast Hayek opposite Antonio Banderas in the starring role of self-confident and feisty Carolina in \"Desperado\", her breakout film. Describing the film's process as \"grueling\", Hayek had to audition several times for Rodriguez before landing the part, and a love scene in the script proved particularly difficult for her to film because she did not want to be nude on camera. She once remarked: \"It took eight hours [to film] instead of an hour\". Budgeted at $7 million, \"Desperado\" was a commercial success, grossing $25.4\u00a0million in the United States. A brief role as a vampire queen followed in Rodriguez's cult horror film \"From Dusk till Dawn\" (1996), in which she performed an erotic table-top snake dance. She also appeared in the 1996 drama \"Follow Me Home\" and the cop comedy \"Fled\".\nHayek next starred in the romantic comedy \"Fools Rush In\" (1997) as a photographer in an on-and-off relationship with a New York City architect, played by Matthew Perry. Critic Roger Ebert gave the film 3 out of 4 stars and described it as \"a sweet, entertaining retread of an ancient formula\", elevated by good performances (particularly Hayek's) and an insightful \"level of observation and human comedy\". \"Fools Rush In\" was a moderate commercial success and earned Hayek an ALMA Award nomination for Outstanding Actress in a Feature Film. In another romantic comedy, \"Breaking Up\" (also 1997), she and Russell Crowe portrayed a couple whose relationship leads to an out-of-the-blue marriage. Ken Eisner of \"Variety\" wrote: \"Russell Crowe and Salma Hayek make attractive leads, but they have neither the marquee power nor the requisite chemistry to keep \"Breaking Up\" from getting left at the altar of general distribution.\" Indeed, the film was distributed for selected markets in the United States only.\nIn 1998, Hayek played an aspiring young singer in the 1970s New York City nightlife scene in Mark Christopher's drama \"54\", a doughnut shop waitress in Dan Ireland's dramedy \"The Velocity of Gary\" and a nurse in Rodriguez's supernatural horror film \"The Faculty\". In 1999, Hayek was unorthodoxly cast in Kevin Smith's religious satire \"Dogma\" as Serendipity, \"the [Muse] who throughout history inspired all the geniuses of art and music, like Mozart and Michelangelo, and never got any of the credit\". She also portrayed the alleged daughter of a kidnapped scientist alongside Will Smith in the period Western \"Wild Wild West\". \"Dogma\" was well received by critics and audiences, but \"Wild Wild West\" proved a commercial failure despite being one of the most expensive films ever made at the time of its release.\nHayek founded her production company, Ventanarosa, in 1999, through which she produces film and television projects. Her first feature as a producer was \"El Coronel No Tiene Quien Le Escriba\" (1999), Mexico's official selection for Best Foreign Film at the Oscars. In 2000, Hayek had an uncredited role in \"Traffic\", and played an aspiring actress in Mike Figgis' experimental film \"Timecode\", a waitress in the Spanish drama \"Living It Up\", and a cop and Playboy model in the heist comedy \"Chain of Fools\". She also produced and starred in the television film \"In the Time of the Butterflies\" (2001), based on the book by Julia \u00c1lvarez book about the Mirabal sisters. Hayek played one of the sisters, Minerva, and Edward James Olmos played the Dominican dictator Rafael Le\u00f3nidas Trujillo, whom the sisters opposed.\nWorldwide recognition (2002\u20132009).\nIn Julie Taymor's biographical film \"Frida\" (2002), Hayek served as a producer and starred as surrealist painter Frida Kahlo. She became interested in the role several years prior to commencing production for the film, having \"been fascinated by Kahlo's work from the time she was 13 or 14\", although not immediately a fan: \"At that age I did not like her work [...] I found it ugly and grotesque. But something intrigued me, and the more I learned, the more I started to appreciate her work. There was a lot of passion and depth. Some people see only pain, but I also see irony and humor. I think what draws me to her is what [husband] Diego saw in her. She was a fighter. Many things could have diminished her spirit, like the accident or Diego's infidelities. But she wasn't crushed by anything\". She was so determined to play the role that she sought out Dolores Olmedo Patino, longtime-lover of Diego Rivera, and, after his death, administrator to the rights of Frida and Rivera's art, which Rivera had \"willed [...] to the Mexican people\", bequeathing the trust to Olmedo. Hayek personally secured access to Kahlo's paintings from Kahlo and began to assemble a supporting cast, approaching Alfred Molina for the role of Rivera in 1998. Upon its release, \"Frida\" was a critical darling and an arthouse success. In his review for the film, David Denby of \"The New Yorker\" concluded: \"Smart, willful, and perverse, this Frida is nobody's servant, and the tiny Hayek plays her with head held high\". Her portrayal of Kahlo made her the first Mexican actress to be nominated for the Academy Award for Best Actress and earned her Golden Globe Award, Screen Actors Guild Award and British Academy Film Award nominations for Best Actress.\nIn 2003, Hayek produced and directed \"The Maldonado Miracle\", a Showtime film based on the book of the same name, for which she won the Daytime Emmy Award for Outstanding Directing in a Children Special, reunited with Robert Rodriguez for ' and \"Once Upon a Time in Mexico\", and made an appearance in the documentary '. \"Once Upon a Time in Mexico\", which made $98.2 million worldwide, was the final film of the \"Mariachi Trilogy\" and featured Hayek reprising her role from \"Desperado\".\nIn Brett Ratner's action comedy \"After the Sunset\" (2004), Hayek starred as the girlfriend of a master thief, with Pierce Brosnan. A box office flop, the film received largely negative reviews from critics. James Berardinelli found the film to be \"a mess, but [it's] a fun, breezy mess\", criticizing the overall heist and weak characterization but gave praise to the quick pacing chemistry between Brosnan and Hayek. In 2005, she served as a member of the 58th Cannes Film Festival jury, co-hosted the annual Nobel Peace Prize Concert with Julianne Moore in Oslo, Norway, and directed a music video for Prince, titled \"Te Amo Corazon\" (\"I love you, sweetheart\") that featured M\u00eda Maestro.\nHayek appeared alongside her good friend Pen\u00e9lope Cruz in the 2006 Western comedy \"Bandidas\", portraying two women who become a bank robbing duo in an effort to combat a ruthless enforcer terrorizing their town. Randy Cordova of the \"Arizona Republic\" said the film \"sports\" Hayek and her co-star Pen\u00e9lope Cruz as the \"lusty dream team\" and that they were the \"marketing fantasy\" for the film. \"Bandidas\" was followed by \"Ask the Dust\", a period romance set in Los Angeles based on a John Fante novel and co-starring Colin Farrell. Peter Bradshaw of \"The Guardian\" found \"something a little forced in both lead performances\", and with a limited theatrical release, the film was not a financial success. Her last film of 2006 was \"Lonely Hearts\", a neo-noir crime drama chronicling the notorious \"lonely hearts killers\" of the 1940s, Raymond Fernandez and Martha Beck, in which Hayek played Beck, with Jared Leto taking on the role of Fernandez. The film received mixed reviews from critics, but the cast garnered praise. Peter Travers of \"Rolling Stone\" stated: \"When Hayek and Leto are onscreen, you do not look away.\"\nHayek served as an executive producer for the American television series \"Ugly Betty\" (2006\u20132010), after adapting the story for American television with Ben Silverman, who acquired the rights and scripts from the Colombian telenovela \"Yo Soy Betty La Fea\" in 2001. Originally intended as a half-hour sitcom for NBC in 2004, the project would later be picked up by ABC for the 2006\u20132007 season with Silvio Horta also producing. She guest-starred on the series as Sofia Reyes, a magazine editor. \"Ugly Betty\" was a success with critics and audiences, won a Golden Globe Award for Best Comedy Series in 2007, and earned Hayek nominations for both Outstanding Guest Actress in a Comedy Series and Outstanding Comedy Series at the 59th Primetime Emmy Awards. After finalizing negotiations with MGM to become the CEO of her own Latin-themed film production company, Ventanarosa, in 2007, Hayek signed a two-year deal with ABC for Ventanarosa to develop projects for the network.\nIn 2007, Hayek made a cameo appearance, as a nurse singing a cover of The Beatles song \"Happiness Is A Warm Gun\", in Julie Taymor's jukebox musical romantic drama \"Across the Universe\". The role of Madame Truska, a woman who can grow an indestructible beard, in \"\" (2009), was Hayek's first acting project following the birth of her daughter. She characterized the film, which was an adaptation of the book series \"The Saga of Darren Shan\" by author Darren Shan, as \"a little bit of hard work. But it's not like I have to be emotionally devastated for months\". The film was a critical and commercial failure. Screen Rant felt that Hayek is \"fun as the bearded lady Madame Truska but [...] is unable to single-handedly elevate the material\".\nContinued commercial success (2010\u20132017).\nIn 2010, Hayek played a fashion designer and the wife of a Hollywood talent agent (Adam Sandler) in the comedy \"Grown Ups\" which, despite a negative critical reception, made $271.4 million globally. She is the voice of Kitty Softpaws, a street-savvy Tuxedo cat, alongside Antonio Banderas in \"Puss in Boots\" (2011). A spin-off of the \"Shrek\" franchise, \"Puss in Boots\" received positive reviews from critics, grossed $554.9 million at the box office, and was nominated for Best Animated Feature at the 84th Academy Awards. In 2011, she also obtained Hispanic roles in two international productions \u2014a dancer in the French drama \"Americano\" and the wife of a former advertising executive in the Spanish \"As Luck Would Have It\"\u2014 which earned her nominations for the San Sebasti\u00e1n International Film Festival Award for Best Actress and the Goya Award for Best Actress, respectively.\nIn 2012, Hayek directed Jada Pinkett Smith in the music video \"Nada Se Compara\", lent her voice for Peter Lord's animated film \"The Pirates! In an Adventure with Scientists!\", and played a cartel leader in Oliver Stone's action film \"Savages\" and a school nurse in Frank Coraci's comedy \"Here Comes the Boom\". She reprised her role in \"Grown Ups 2\" (2013) which, like the first film, was a commercial success despite a negative critical response.\nHayek served as a producer and provided her voice for the character of Kamila, a widowed mother, in \"The Prophet\" (2014), adapted from the 1923 book by Kahlil Gibran. Describing the film as a \"love letter to my heritage\", Hayek said it helped her explore her relationship with her late grandfather, who was a fan of the book, and remarked: \"Between all the connections of our ancestors and the memories of the ones that are no longer with us, I hope they are proud of this film because I did it also for them\". In 2014, she made a brief appearance in James Bobin's comedy sequel \"Muppets Most Wanted\", starred as a woman forced into sexual slavery in Joe Lynch's action drama \"Everly\", and reunited with Pierce Brosnam to play his love interest in Tom Vaughan's romantic comedy \"Some Kind of Beautiful\". \"Everly\" and \"Some Kind of Beautiful \" were both distributed for online markets and poorly received; while critics noted that the former \"benefits from Joe Lynch's stylish direction and Salma Hayek's starring work, but it's too thinly written and sleazily violent to fully recommend\", Rotten Tomatoes gave the latter a 6% rating based on 34 reviews.\nIn \"Tale of Tales\" (2015), a European fantasy film directed and written by Matteo Garrone, Hayek appeared as the 17th-century Queen of Longtrellis. A screen adaptation based on collections of tales by Italian poet and courtier Giambattista Basile, the film competed for the Palme d'Or at the 68th Cannes Film Festival. In 2016, Hayek voiced the role of Teresa del Taco in \"Sausage Party\", an adult animated film she described as \"the naughtiest thing I've ever done. I never thought I'd ever say some of those things out loud. But, I had a lot of fun [...] It's a different kind of crazy\". The highest grossing R-rated animated film of all time, \"Sausage Party\" grossed $140.4 million worldwide.\nHayek took on the role of a holistic medicine practitioner who attends a wealthy client's dinner party in Miguel Arteta's drama \"Beatriz at Dinner\" (2017), which Owen Gleiberman of \"Variety\" called a \"small-scale but elegantly deft squirmfest that features a luminous performance\" by the actress. That role earned Hayek an Independent Spirit Film Award nomination for Best Female Lead. The comedy \"How to Be a Latin Lover\" (2017) was a sleeper hit upon its release and featured Hayek as the estranged sister of a man who has made a career of seducing rich older women. Her last film outing of 2017 was Patrick Hughes's action comedy \"The Hitman's Bodyguard\", in which she starred as the wife of a convicted hitman, opposite Ryan Reynolds and Samuel L. Jackson. The film made an impressive $176.6 million globally.\nRecent roles (2018\u2013present).\nHayek was cast as Eva Torres, a high-frequency trading executive, alongside Jesse Eisenberg and Alexander Skarsg\u00e5rd, in Kim Nguyen's tech drama \"The Hummingbird Project\" (2018), and as Nancy Teagarten, one half of a couple experiencing a series of financial crises, with Alec Baldwin, in Fred Wolf's comedy \"Drunk Parents\" (2019). In 2020, Hayek appeared as a cosmetics mogul in Miguel Arteta's comedy \"Like a Boss\", with Rose Byrne and Tiffany Haddish, and the alternative wife of a man in Sally Potter's drama \"The Roads Not Taken\", with Javier Bardem and Elle Fanning.\nThe drama \"Bliss\" (2021), which starred Hayek as a homeless woman befriending a recently divorced man (Owen Wilson), was released on Amazon Prime Video. She next reunited with director Patrick Hughes and actors Ryan Reynolds and Samuel L. Jackson in \"Hitman's Wife's Bodyguard\", the sequel for the 2017 film \"The Hitman's Bodyguard\", which was released on June 16, 2021, to mediocre reviews. John Defore of \"The Hollywood Reporter\", however, praised Hayek's \"foul-mouthed\" portrayal, writing: \"The one smart thing the film does is promote Salma Hayek, as the eponymous spouse of Samuel L. Jackson's hitman, from the small but scene-stealing role she played in the first film. [...] At least we can appreciate Hayek's enthusiasm for the over-the-top role\". Unlike the first film, \"Hitman's Wife's Bodyguard\" had lackluster box office returns.\nHayek portrayed Ajak, the wise and spiritual leader of the titular group, in the Marvel Cinematic Universe picture \"Eternals\", directed by Chlo\u00e9 Zhao, who \"personally selected\" her for the role. Initially surprised by Marvel's interest on her casting, Hayek described her involvement in the film as \"empowering\" and recalled getting \"emotional\" upon seeing her character's superhero costume, stating: \"It was because it means so much to so many people that, to think that for a Mexican girl \u2014a Mexican woman in her 50s\u2014 was able to be a superhero. I felt a lot of pride to have my superhero outfit on. It meant something\". Hayek, who is of both Spanish and Lebanese descent, subsequently became the first Arab actress with a main role in the Marvel Cinematic Universe. The film, released in the United States on November 5, 2021, generated a divergent critical response and made $401 million worldwide. She has since signed a deal to star in multiple Marvel Cinematic Universe projects. Her last film of 2021 was Ridley Scott's biographical crime drama \"House of Gucci\", in which she played the friend and confidante of Patrizia Reggiani, Giuseppina \"Pina\" Auriemma, alongside Lady Gaga as Reggiani, Adam Driver, and her \"Lonely Hearts\" co-star Jared Leto. Hayek then reprised her role as Kitty Softpaws in \"\", which received critical acclaim, grossed $485.3 million, and like its predecessor was nominated for the Academy Award for Best Animated Feature.\nIn June 2022, Hayek was cast in Angelina Jolie's upcoming film, \"Without Blood\", based on the bestselling Italian novel by Alessandro Baricco. It was filmed in Rome, Apulia, and Basilicata. Hayek will star in the film alongside Demi\u00e1n Bichir.\nIn 2023, she appeared as herself in the episode \"Joan Is Awful\" of the Netflix anthology \"Black Mirror\".\nOther ventures.\nAdvocacy.\nHayek's charitable work includes increasing awareness on violence against women and discrimination against immigrants. On July 19, 2005, Hayek testified before the U.S. Senate Committee on the Judiciary supporting reauthorizing the Violence Against Women Act. In February 2006, she donated $25,000 to a Coatzacoalcos, Mexico, shelter for battered women and another $50,000 to Monterrey based anti-domestic violence groups. She is a board member of V-Day, the charity founded by playwright Eve Ensler. While Hayek previously stated that she is not a feminist, she later revised her stance, stating: \"I am a feminist because a lot of amazing women have made me who I am today. [...] But \u2013 it should not be just because I am a woman\".\nHayek also advocates breastfeeding. During a 2009 UNICEF fact-finding trip to Sierra Leone, she breastfed a hungry week-old baby whose mother could not produce milk. Hayek said she did it to reduce the stigma associated with breastfeeding and to encourage infant nutrition. In 2010, Hayek's humanitarian work earned her a nomination for the VH1 Do Something Awards. In 2013, alongside Beyonc\u00e9 and Frida Giannini, Hayek launched \"Chime for Change\", a Gucci campaign that aims to spread female empowerment. For International Women's Day 2014 Hayek was one of the artist signatories of Amnesty International's letter, to then British Prime Minister David Cameron, campaigning for women's rights in Afghanistan. Following her visit to Lebanon in 2015, Hayek criticized the discrimination against women there.\nOn December 13, 2017, Hayek published an op-ed in \"The New York Times\" stating that she had been harassed and abused by film producer Harvey Weinstein during the production of \"Frida\".\nIn 2019, the Pinault family pledged US$113 million to support the reconstruction efforts of Notre Dame Cathedral in Paris, following its destruction in a fire. In 2020, Hayek raised awareness through her Instagram for the disappearance of Vanessa Guillen.\nEndorsements.\nHayek was a spokeswoman for Revlon in 1998 and has been a spokeswoman for Avon cosmetics since February 2004. She modeled for Chopard in 2001, was featured in a series of Spanish language commercials for Lincoln cars in 2002, and in Campari ads, photographed by Mario Testino, in 2006. On April 3, 2009, she helped introduce La Do\u00f1a, a watch by Cartier inspired by fellow Mexican actress Mar\u00eda F\u00e9lix.\nHayek has worked with the Procter &amp; Gamble Company and UNICEF to promote the funding (through disposable diaper sales) of vaccines against maternal and neonatal tetanus. She is a global spokesperson for the Pampers/UNICEF partnership to help raise awareness of the program. The partnership involves Procter &amp; Gamble donating the cost of one tetanus vaccination (approximately 24 cents) for every pack of Pampers sold.\nIn 2008, Hayek co-founded Juice Generation's juice delivery program Cooler Cleanse. After writing the foreword to Juice Generation founder Eric Helms' 2014 book \"The Juice Generation: 100 Recipes for Fresh Juices and Superfood Smoothies\", she and Helms launched the beauty subscription delivery service Blend It Yourself in 2017, based on Hayek's personal beauty elixirs, which supplies subscribers with the prepared organic frozen smoothie and acai bowl ingredients.\nIn 2011, Hayek launched her own line of cosmetics, skincare, and haircare products called Nuance by Salma Hayek, to be sold at CVS stores in North America.\nPublic image.\nEarly in her career, Hayek came to be regarded as a sex symbol, and most of her early films, it has been noted, such as the action-oriented \"Desperado\", \"From Dusk Till Dawn\", and \"Fled\", \"predominantly featured her in racy sex symbol type of roles\" and ultimately made Hayek a familiar face with mainstream audiences. Various media publications have cited her as one of Hollywood's most beautiful actresses. \"People\" named her one of the 50 most beautiful people in the world in 1996, 2003 and 2008, \"Maxim\" ranked her 34th and 90th on their Hot 100 list in 2005 and 2007, respectively, and \"FHM\" included her on their 100 Sexiest Women in the World list in 2005 and 2006. A July 2007 poll by E-Poll Market Research found Hayek to be the \"sexiest celebrity\" among a group of 3,000 public figures, with 65 percent of respondents using the term \"sexy\" to describe her. The Armani dress Hayek wore to the 1997 Academy Awards was voted by E! Entertainment as one of the five most memorable in Oscar history.\nFrom April 7 to June 18, 2006, the Blue Star Contemporary Art Center in San Antonio, Texas hosted an exhibition called \"Solamente Salma\" (Spanish for \"Only Salma\"), consisting of 16 portrait paintings by muralist George Yepes and filmmaker Robert Rodriguez of Hayek as the Aztec goddess Itzpapalotl. In July 2007, \"The Hollywood Reporter\" ranked Hayek 4th in their Latino Power 50, a list of the most powerful Latin members of Hollywood. In 2008, she was awarded the Women in Film Lucy Award, in recognition of her creative works that have enhanced the perception of women through the medium of television, and \"Entertainment Weekly\" ranked her 17th in their list of the 25 Smartest People in TV.\nThroughout her career, Hayek has graced the covers of numerous international magazines, including North America's \"InStyle\", \"Elle\", \"Premiere\", \"Glamour\" and \"Variety\"; Britain's \"Maxim\", \"Marie Claire\" and \"Total Film\"; and France's \"Entrevue\" and \"Madame Figaro\". She was one of fifteen women selected to appear on the cover of the September 2019 issue of \"British Vogue\", by guest editor Meghan, Duchess of Sussex.\nPersonal life.\nHayek is a naturalized United States citizen. She has studied at Ramtha's School of Enlightenment and practices yoga. Hayek, who was raised Catholic, stated in a 2007 interview that she was no longer devout and did not believe in the Church, in part because she disagreed with practices such as its campaign against condoms in Africa, where she said AIDS and overpopulation were rampant, though she clarified that she still believed in Jesus Christ and God.\nOn March 9, 2007, Hayek confirmed her engagement to French billionaire and Kering CEO Fran\u00e7ois-Henri Pinault as well as her pregnancy. She gave birth to their daughter on September 21, 2007, at Cedars-Sinai Medical Center in Los Angeles, CA. They were married on Valentine's Day 2009 in Paris. On April 25, 2009, they renewed their vows in Venice, Italy.\nFilmography and accolades.\nHayek's films that have earned the most at the box office, as of 2022[ [update]], include:\nHayek's performance as Frida Kahlo in \"Frida\" (2002) garnered her nominations for Best Actress at the 75th Academy Awards, the 61st Golden Globe Awards, the 53rd British Academy Television Awards and the 9th Screen Actors Guild Awards. She won the Daytime Emmy Award for Outstanding Directing in a Children Special for \"The Maldonado Miracle\" (2004) and received two Primetime Emmy Award nominations, one for Outstanding Guest Actress in a Comedy Series and the other for Outstanding Comedy Series as an executive producer, for her work on \"Ugly Betty\" (2006\u201310). In 2011, Hayek was appointed Knight (Chevalier) of the National Order of the Legion of Honour, the highest French order of merit, and in 2021, she was honored with a star on the Hollywood Walk of Fame.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27718", "revid": "2105939", "url": "https://en.wikipedia.org/wiki?curid=27718", "title": "Super Bowl", "text": "National Football League championship game\nThe Super Bowl, originally known as the AFL\u2013NFL World Championship Game, is the annual league championship game of the National Football League (NFL) of the United States. It has served as the final game of every NFL season since 1966, replacing the NFL Championship Game. Since 2022, the game has been played on the second Sunday in February. Prior Super Bowls were played on Sundays in early to mid-January from 1967 to 1978, late January from 1979 to 2003, and the first Sunday of February from 2004 to 2021. Winning teams are awarded the Vince Lombardi Trophy, named after the eponymous coach who won the first two Super Bowls. Because the NFL restricts the use of its \"Super Bowl\" trademark, it is frequently referred to as the \"big game\" or other generic terms by non-sponsoring corporations. The day the game is held is commonly referred to as \"Super Bowl Sunday\" or \"Super Sunday\".\nThe game was created as part of a 1966 merger agreement between the NFL and the competing American Football League (AFL) to have their best teams compete for a championship. It was originally called the AFL\u2013NFL World Championship Game until the \"Super Bowl\" moniker was adopted in 1969's Super Bowl III. The first four Super Bowls from 1967 to 1970 were played before the merger, with the NFL and AFL each winning two. After the merger in 1970, the 10 AFL teams and three NFL teams formed the American Football Conference (AFC) and the remaining 13 NFL teams formed the National Football Conference (NFC). All games since 1971's Super Bowl V have been played between the two best teams from each conference, with the NFC leading the AFC 28\u201327.\nAmong the NFL's current 32 teams, 20 (11 NFC, 9 AFC) have won a Super Bowl and 16 (8 AFC, 8 NFC) hold multiple titles. The AFC's Pittsburgh Steelers and New England Patriots have the most Super Bowl titles at six each. The San Francisco 49ers have won 5 Super Bowls, including two back-to-back victories. The Patriots also have the most Super Bowl appearances at 11. The Patriots and the Denver Broncos of the AFC hold the record for the most defeats in the Super Bowl at five each. The Baltimore Ravens of the AFC and the Tampa Bay Buccaneers of the NFC are the only franchises to be undefeated in multiple Super Bowls, having each won two. Among the 12 teams who have not won a Super Bowl, the NFC's Detroit Lions and the AFC's Jacksonville Jaguars, Houston Texans, and Cleveland Browns are the only four to have not appeared in the game.\nThe Super Bowl is among the world's most-watched single sporting events and frequently commands the largest audience among all American broadcasts during the year. It is second only to the UEFA Champions League final as the most watched annual club sporting event worldwide, and the seven most-watched broadcasts in American television history are Super Bowls. Its halftime shows feature top artists, and headlining a Super Bowl is considered one of the highest honors in music. Commercial airtime during the Super Bowl broadcast is the most expensive of the year because of the high viewership, leading to companies regularly developing their most expensive advertisements for the broadcast and commercial viewership becoming an integral part of the event. The Super Bowl is also the second-largest event for American food consumption, behind Thanksgiving dinner, with fans commonly purchasing beer, hot dogs, nachos, and other concessions, spending an average of $58 on food and drinks during an NFL game.\nOrigin.\nSince the turn of the 20th century, college football teams from across the United States have scheduled \"bowl games\" against each other. The original \"bowl game\" was the Rose Bowl Game in Pasadena, California, which was first played in 1902 as the \"Tournament East\u2013West football game\" as part of the Pasadena Tournament of Roses. In 1923, the Tournament East-West football game moved to the new Rose Bowl Stadium; the stadium got its name from the fact that the game played there was part of the Tournament of Roses and that it was shaped like a bowl, much like the Yale Bowl in New Haven, Connecticut. The Tournament of Roses football game thus eventually came to be known as the Rose Bowl Game. Exploiting the Rose Bowl Game's popularity, post-season college football contests were created for Miami (the Orange Bowl), New Orleans (the Sugar Bowl), and El Paso (the Sun Bowl) in 1935, and for Dallas (the Cotton Bowl) in 1937. By the time the first Super Bowl was played, the term \"bowl\" for any major American football game was well established.\nFor four decades after its 1920 inception, the NFL successfully fended off several rival leagues. In 1960, it encountered its most serious competitor when the American Football League (AFL) was formed. The AFL vied with the NFL for players and fans. After the AFL's inaugural season, AFL commissioner Joe Foss sent an invitation to the NFL on January 14, 1961, to schedule a \"World Playoff\" game between the two leagues' champions, beginning with the upcoming 1961 season. The first World Playoff game, if actually played, would have matched up the AFL champion Houston Oilers against the NFL champion Green Bay Packers.\nIn the mid-1960s, Lamar Hunt, owner of the AFL's Kansas City Chiefs, first used the term \"Super Bowl\" to refer to the AFL\u2013NFL championship game in the merger meetings. Hunt later said the name was likely in his head because his children had been playing with a Super Ball toy; a vintage example of the ball is on display at the Pro Football Hall of Fame in Canton, Ohio. In a July 25, 1966, letter to NFL commissioner Pete Rozelle, Hunt wrote, \"I have kiddingly called it the 'Super Bowl,' which obviously can be improved upon.\"\nThe leagues' owners chose the name \"AFL\u2013NFL Championship Game\", but in July 1966 the \"Kansas City Star\" quoted Hunt in discussing \"the Super Bowl\u2014that's my term for the championship game between the two leagues\", and the media immediately began using the term. Green Bay safety Tom Brown used the name leading up to the first championship game: \"I would guess you can't get any bigger in professional football than to play in the first Super Bowl game\". In May 1967, The league stated that \"not many people like it. It's a bad play on words. Everything became super this and super that\". Rozelle was asking for suggestions, and early contenders included \"Merger Bowl\", \"Summit Bowl\", and \"The Game\". The Associated Press reported that \"Super Bowl\" \"grew and grew and grew\u2014until it reached the point that there was Super Week, Super Sunday, Super Teams, Super Players, ad infinitum\". \"Super Bowl\" became official beginning with the third annual game.\nRoman numerals are used to identify each Super Bowl, rather than the year in which it is held, since the fifth edition, in January 1971. The sole exception to this naming convention tradition occurred with Super Bowl 50, played on February 7, 2016, following the 2015 season. The following year, the nomenclature returned to Roman numerals for Super Bowl LI.\nAfter the NFL's Green Bay Packers won the first two Super Bowls, some team owners feared for the future of the merger. At the time, many doubted the competitiveness of AFL teams compared with their NFL counterparts, though that perception changed when the AFL's New York Jets defeated the heavily favored NFL contender Baltimore Colts in Super Bowl III in Miami. One year later, the AFL's Kansas City Chiefs defeated the NFL's Minnesota Vikings 23\u20137 in Super Bowl IV in New Orleans, which was the final AFL\u2013NFL World Championship Game played before the merger. Beginning with the 1970 season, the NFL realigned into two conferences; the former AFL teams plus three NFL teams (the Baltimore Colts, Pittsburgh Steelers, and Cleveland Browns) would constitute the American Football Conference (AFC), while the remaining NFL clubs would form the National Football Conference (NFC). The champions of the two conferences would play each other in the Super Bowl.\nThe winning team receives the Vince Lombardi Trophy, named after the former coach of the Green Bay Packers, who won the first two Super Bowl games as well as five NFL championships preceding the merger (1961, 1962, 1965, 1966, 1967). Following Lombardi's death in September 1970, the trophy was named after him. The first trophy awarded under the new name was presented to the Baltimore Colts following their win in Super Bowl V in Miami.\nGame history.\nThe Super Bowl was held in January from its inception in 1967 until 2001. In 2002, a week of regular season games was postponed and rescheduled following the September 11 attacks; as a result, Super Bowl XXXVI became the first edition of the game played in February. Super Bowl XXXVII was held in January, but all subsequent games were held on the first Sunday in February until the schedule expansion of the 2021 season moved the game to the second Sunday.\nThe current NFL schedule begins on the weekend immediately after Labor Day (the first Monday in September). That weekend is the first of an 18-week regular season, followed by three weeks of playoff games and one week for the Pro Bowl. The Super Bowl is contested the week after the Pro Bowl. This schedule has been in effect since an 18th week and 17th regular season game were added to the NFL schedule for the 2021 season, with Super Bowl LVI on February 13, 2022, the first to be played under this format.\nThe Pittsburgh Steelers and New England Patriots are tied with a record six Super Bowl wins. The Dallas Cowboys and San Francisco 49ers have five victories each, while the Packers, Chiefs and New York Giants have four. Fourteen other NFL franchises have won at least one Super Bowl.\nThe Patriots own the record for most Super Bowl appearances with eleven. The Cowboys, Steelers, Broncos and the 49ers are tied for second with eight appearances apiece, reaching that milestone in this respective order. Bill Belichick owns the record for the most Super Bowl wins (eight) and appearances (twelve: nine times as head coach, once as assistant head coach, and twice as defensive coordinator) by an individual. Tom Brady has the most Super Bowl starts (ten) and wins as a player (seven), while Charles Haley has the second-most wins among players with five.\nEight teams have appeared in Super Bowl games without a win. The Minnesota Vikings were the first team to appear four times without a win, while the Buffalo Bills played in a record four consecutive Super Bowls, losing all four matches. The Patriots and Broncos are tied for the most Super Bowl losses at five.\nThe Cleveland Browns, Detroit Lions, Houston Texans, and Jacksonville Jaguars are the four teams to have never appeared in a Super Bowl, although the Browns and Lions both won NFL championships before the Super Bowl era. The Jaguars, who began play in 1995, and the Texans, who began play in 2002, are among the youngest franchises in the league.\n1960s: Early history and Packers dominance.\nThe Packers won the first two AFL\u2013NFL World Championship Games, later renamed Super Bowls, defeating the Kansas City Chiefs and Oakland Raiders following the 1966 and 1967 seasons, respectively. The Packers were led by quarterback Bart Starr, who was named the Most Valuable Player (MVP) for both games. These two championships, coupled with the Packers' NFL championships in 1961, 1962, and 1965, amount to the most successful stretch in NFL History; five championships in seven years, and the second threepeat in NFL history (1965, 1966, and 1967). The Packers are the only team to threepeat, as they also accomplished the feat in the pre-playoff era (1929, 1930 and 1931). The first playoff game in the NFL was in 1932.\nIn Super Bowl III, the AFL's New York Jets defeated the 19.5-point favorite Baltimore Colts of the NFL, 16\u20137. The Jets were led by quarterback Joe Namath, who had said that he guaranteed a Jets win before the game, and former Colts head coach Weeb Ewbank, and their victory demonstrated that the AFL was competitive with the NFL. This was reinforced the following year when the Chiefs defeated the NFL's Vikings 23\u20137 in Super Bowl IV.\n1970s: Dominant franchises.\nAfter the AFL\u2013NFL merger was completed in 1970, three franchises\u2014the Cowboys, Miami Dolphins, and Steelers\u2014would go on to dominate the 1970s, winning a combined eight Super Bowls between them in the decade, with the Steelers winning four of the eight.\nThe Baltimore Colts, now a member of the AFC, would start the decade by defeating the Cowboys in Super Bowl V, a game which is the only Super Bowl to date in which a player from the losing team won the Super Bowl MVP (Cowboys' linebacker Chuck Howley). Beginning with this Super Bowl, all Super Bowls have served as the NFL's championship game.\nThe Cowboys, coming back from a loss the previous season, won Super Bowl VI over the Dolphins. However, this would be the Dolphins' final loss for over a year, as the next year, the Dolphins would go 14\u20130 in the regular season and eventually win all their playoff games, capped off with a 14\u20137 victory in Super Bowl VII, becoming the first and only team in the Super Bowl era to finish an entire perfect regular and postseason undefeated. The Dolphins would repeat as league champions by winning Super Bowl VIII a year later with a 24\u20137 win over the Minnesota Vikings.\nIn the mid to late 1970s, the Steelers became the first NFL dynasty of the post-merger era by winning four Super Bowls (IX, X, XIII, and XIV) in six years. They were led by head coach Chuck Noll, the play of offensive stars Terry Bradshaw, Franco Harris, Lynn Swann, John Stallworth, and Mike Webster, and their dominant \"Steel Curtain\" defense, led by \"Mean\" Joe Greene, L. C. Greenwood, Ernie Holmes, Mel Blount, Jack Ham, and Jack Lambert. Many of the team's key players were selected in the 1974 draft, in which Pittsburgh selected four future Hall of Famers, the most for any team in any sport in a single draft. A fifth player, Donnie Shell, was signed by Pittsburgh after going unselected in the 1974 NFL draft; he too was later enshrined in the Hall of Fame. The Steelers were the first team to win three and then four Super Bowls and appeared in six AFC Championship Games during the decade, making the playoffs in eight straight seasons. Pittsburgh still remains the only team to win back-to-back Super Bowls twice and four Super Bowls in a six-year period.\nThe Steelers' 1970s dynasty was interrupted only by the Raiders' first Super Bowl win in Super Bowl XI and the Cowboys' second Super Bowl win in Super Bowl XII. Conversely, the Vikings, with their Purple People Eaters defense, were the only other team to appear in multiple Super Bowls (IV, VIII, IX and XI) during the decade but failed to win each one.\n1980s and 1990s: The NFC's winning streak.\nIn the 1980s and 1990s, the tables turned for the AFC, as the NFC dominated the Super Bowls of the new decade and most of those in the 1990s. The NFC won 16 of the 20 Super Bowls during these two decades, including 13 straight from Super Bowl XIX to Super Bowl XXXI.\nThe most successful team of the 1980s was the 49ers, which featured the West Coast offense of Hall of Fame head coach Bill Walsh. This offense was led by three-time Super Bowl MVP and Hall of Fame quarterback Joe Montana, Super Bowl MVP and Hall of Fame wide receiver Jerry Rice, running back Roger Craig, and Hall of Fame defensive safety/cornerback Ronnie Lott. Under their leadership, the 49ers won four Super Bowls in the decade (XVI, XIX, XXIII, and XXIV) and made nine playoff appearances between 1981 and 1990, including eight division championships, becoming the second dynasty of the post-merger NFL. The 1984 San Francisco 49ers were the first team to achieve an 18\u20131 record, doing so under Walsh. The 1989 San Francisco 49ers, under first-year head coach George Seifert, posted the most lop-sided victory in Super Bowl history, defeating the Denver Broncos by a score of 55\u201310 in Super Bowl XXIV.\nThe 1980s also produced the 1985 Chicago Bears, who posted an 18\u20131 record under head coach Mike Ditka; quarterback Jim McMahon; and Hall of Fame running back Walter Payton. Their team won Super Bowl XX in dominant fashion. The Washington Redskins and New York Giants were also top teams of this period; Washington won Super Bowls XVII, XXII, and XXVI. The Giants claimed Super Bowls XXI and XXV. Both teams won multiple Super Bowls with different starting quarterbacks; Washington won with Joe Theismann (XVII), Doug Williams (XXII) and Mark Rypien (XXVI), and the Giants with Phil Simms (XXI) and Jeff Hostetler (XXV). As in the 1970s, the Raiders were the only AFC team to interrupt the Super Bowl dominance of NFC teams; they won Super Bowls XV and XVIII (the latter as the Los Angeles Raiders).\nConversely, the Cincinnati Bengals (XVI and XXIII), Dolphins, (XVII and XIX), and Broncos (XXI, XXII and XXIV) made multiple Super Bowls in the 1980s without winning one.\nFollowing several seasons with poor records in the 1980s, the Cowboys rose back to prominence in the 1990s. During this decade, the Cowboys made post-season appearances every year except for the seasons of 1990 and 1997. From 1992 to 1996, the Cowboys won their division championship each year. In this same period, the Buffalo Bills reached the Super Bowl for a record four consecutive years, but lost all four (XXV-XXVIII). After Super Bowl championships by division rivals New York (1990) and Washington (1991), the Cowboys won three of the next four Super Bowls (XXVII, XXVIII, and XXX) led by quarterback Troy Aikman, running back Emmitt Smith, and wide receiver Michael Irvin. All three of these players went to the Hall of Fame. The Cowboys' streak was interrupted by the 49ers, who were the first team to win their league-leading fifth title overall with Super Bowl XXIX with a dominant performance featuring the Super Bowl MVP and Hall of Fame quarterback Steve Young (who threw a Super Bowl record 6 touchdown passes), Hall of Fame wide receiver Jerry Rice, and Hall of Fame cornerback Deion Sanders; however, the Cowboys' victory in Super Bowl XXX the next year also gave them five titles overall and they did so with Sanders after he won the Super Bowl the previous year with the 49ers. The NFC's winning streak was continued by the Packers led by Hall of Fame quarterback Brett Favre, won Super Bowl XXXI, their first championship since Super Bowl II in 1967.\nThe Patriots made their maiden Super Bowl appearances in XX (1985) and XXXI (1996) but lost both times. However, the turn of the century would soon bring hope and glory to the franchise.\n2000s: AFC resurgence and the rise of the Patriots.\nSuper Bowl XXXII saw quarterback John Elway and running back Terrell Davis lead the Denver Broncos to an upset victory over the defending champion Packers, snapping the NFC's thirteen-year winning streak. The following year, the Broncos defeated the Atlanta Falcons in Super Bowl XXXIII, Elway's fifth Super Bowl appearance, his second NFL championship, and his final NFL game. The back-to-back victories heralded a change in momentum in which AFC teams would win nine out of 12 Super Bowls. In the years between 1995 and 2018, five teams\u2014the Steelers, Patriots, Broncos, Baltimore Ravens, and Indianapolis Colts\u2014accounted for 22 of the 24 AFC Super Bowl appearances (including the last 16), with those same teams often meeting each other earlier in the playoffs. In contrast, the NFC saw a different representative in the Super Bowl every season from 2001 through 2010.\nThe New England Patriots became the dominant team throughout the early 2000s, winning the championship three out of four years early in the decade. They would become only the second team in the history of the NFL to do so (after the 1990s Dallas Cowboys). In Super Bowl XXXVI, first-year starting quarterback Tom Brady led his team to a 20\u201317 upset victory over the St. Louis Rams, who two seasons earlier won Super Bowl XXXIV. Brady would go on to win the MVP award for this game. The Patriots also won Super Bowls XXXVIII and XXXIX defeating the Carolina Panthers and the Philadelphia Eagles respectively. This four-year stretch of Patriot dominance was interrupted by the Tampa Bay Buccaneers' 48\u201321 Super Bowl XXXVII victory over the Oakland Raiders.\nThe Steelers and Colts continued the era of AFC dominance by winning Super Bowls XL and XLI in the 2005 and 2006 seasons, respectively defeating the Seattle Seahawks and Chicago Bears.\nIn the 2007 season, the Patriots became the fourth team in NFL history to have a perfect unbeaten and untied regular-season record, the second in the Super Bowl era after the 1972 Miami Dolphins, and the first to finish 16\u20130. They easily marched through the AFC playoffs and were heavy favorites in Super Bowl XLII. However, they lost that game to Eli Manning and the New York Giants 17\u201314, leaving the Patriots' 2007 record at 18\u20131.\nThe following season, the Steelers logged their record sixth Super Bowl title (XLIII) in a 27\u201323, final-minute victory against the Arizona Cardinals.\nThe 2009 season saw the New Orleans Saints defeat the Indianapolis Colts in Super Bowl XLIV by a score of 31\u201317 to take home their first championship. With this victory, the Saints joined the New York Jets as the only teams to have won in their sole Super Bowl appearance, a distinction the Ravens also enjoyed in winning Super Bowl XXXV after the 2000 season and the Buccaneers in 2002.\n2010s: Patriots reign; parity in the NFC.\nIn the AFC, this era was dominated by the Patriots, with the only four other teams to represent the conference being the Steelers, Ravens, Broncos, and Chiefs. The Patriots had tied a record with the 1970s Dallas Cowboys for most Super Bowl appearances in a decade with five appearances (2011, 2014, 2016, 2017, 2018). The Patriots also had four Super Bowl appearances in five years. They also had eight consecutive AFC championship appearances spanning 2011\u20132018.\nThe Super Bowls of the 2000s and 2010s saw strong performances from several of the participating quarterbacks, especially on the AFC side with repeated appearances by the same teams and players. In particular, Tom Brady, Ben Roethlisberger, or Peyton Manning appeared as the AFC team's quarterback in all but two of the Super Bowls from 2001 through 2018. Conversely, the only NFC teams to make the Super Bowl multiple times with the same quarterback in this era were the Seahawks, led by quarterback Russell Wilson, and the Giants, led by quarterback Eli Manning.\nOne of these teams was featured in the culmination of the 2010 season, Super Bowl XLV, which brought the Packers their fourth Super Bowl victory and record thirteenth NFL championship overall with the defeat of the Steelers in February 2011. This became Aaron Rodgers' only Super Bowl victory.\nThe following year, in Super Bowl XLVI, the Patriots made their first appearance of the decade, a position where they would become a mainstay. The Patriots, however, lost to the Eli Manning-led Giants, 21\u201317, who had beaten the Patriots four years before. This was the Giants' fourth Super Bowl victory.\nIn Super Bowl XLVII, the NFC's 49ers were defeated by the Ravens 34\u201331. The game had been dubbed as the 'Harbaugh Bowl' in the weeks leading up to the game, due to the fact that the coaches of the two teams, John Harbaugh and Jim Harbaugh, are brothers. During the third quarter, the Ravens had a commanding 28\u20136 lead. However, there was a blackout in New Orleans, where the game was being played. The game was delayed for 34 minutes, and after play resumed, San Francisco stormed back with 17 straight points, but still lost.\nSuper Bowl XLVIII, played at New Jersey's MetLife Stadium in February 2014, was the first Super Bowl held outdoors in a cold-weather environment. The Seahawks won their first NFL title with a 43\u20138 defeat of the Broncos, in a highly touted matchup that pitted Seattle's top-ranked defense against a Peyton Manning-led Denver offense that had broken the NFL's single-season scoring record.\nIn Super Bowl XLIX, the Patriots beat the defending Super Bowl champions, the Seahawks, by a score of 28\u201324. Down by 10, the Patriots mounted a late fourth quarter comeback to win the game with Tom Brady scoring two touchdowns in the fourth quarter. In a key play in the final seconds of the game, then-rookie free agent Malcolm Butler would intercept a pass by Russell Wilson at the one-yard line, allowing the Patriots to run out the clock and end the game. Tom Brady was awarded his third Super Bowl MVP, tying Joe Montana for the most Super Bowl MVP awards.\nIn Super Bowl 50, the first Super Bowl to be branded with Arabic numerals, the Broncos, led by the league's top-ranked defense, defeated the Panthers, who had the league's top-ranked offense, in what became the final game of quarterback Peyton Manning's career. Von Miller dominated, totaling 2.5 sacks and forcing two Cam Newton fumbles; both fumbles leading to Broncos touchdowns.\nIn Super Bowl LI, the first Super Bowl to end in overtime, the Atlanta Falcons led 28\u20133 late in the third quarter, but the Patriots came back to tie the game 28\u201328 with back-to-back touchdowns and two-point conversions, and the Patriots went on to win 34\u201328 in overtime. This 25-point deficit was the largest comeback win for any team in a Super Bowl, breaking the previous of a 10-point deficit to come back and win. The Patriots never held the lead until the game-winning touchdown in overtime. It was Tom Brady's 5th Super Bowl win and he was awarded his record fourth Super Bowl MVP, throwing a then-record 466 yards for 43 completions.\nIn Super Bowl LII, the Philadelphia Eagles defeated the defending champion Patriots 41\u201333, ending a 57-year championship drought for the franchise. Nick Foles won the Super Bowl MVP. The Patriots totaled 613 yards in defeat, with Tom Brady breaking his previous Super Bowl record of 466 passing yards with an all-time playoff record of 505 passing yards in the high-scoring game; while the Eagles would gain 538 yards in the victory. The combined total for both teams of 1,151 yards of offense broke an NFL record (for any game) that had stood for nearly seven decades. The Patriots' 33 points were the highest losing score in Super Bowl history, a record held until 2023, when the Eagles lost Super Bowl LVII to the Kansas City Chiefs by a score of 38\u201335. It was the Eagles' third Super Bowl appearance and their first win in franchise history. With the Eagles' victory, the NFC East became the first division to have each team win at least one Super Bowl.\nWhile Super Bowl LII produced the second highest-scoring Super Bowl, the following year's Super Bowl LIII became the lowest-scoring Super Bowl. The Patriots defeated the Los Angeles Rams, 13\u20133. In so doing, they became the team with the lowest point total by a winning team in Super Bowl history. Tom Brady would receive a record sixth Super Bowl championship, the most of any player in NFL history, surpassing his tie with Charles Haley for five wins. Brady would also become the oldest player to ever win a Super Bowl at age 41, while Bill Belichick would be the oldest coach to ever win a Super Bowl at age 66. Wide receiver Julian Edelman was named Super Bowl MVP.\n2020s: Beginning of the Chiefs' dominance.\nIn Super Bowl LIV, the Chiefs defeated the 49ers in a comeback, 31\u201320, for their first Super Bowl title in 50 years. This victory marked the first time since 1991 that the NFC did not have more Super Bowl victories than the AFC. The Patriots were absent; after making it to the Super Bowl in each of the last three years and winning two of them, they had lost in the Wild Card round of the playoffs to the Tennessee Titans 20\u201313. That game represented Tom Brady's final game as a New England Patriot.\nIn Super Bowl LV, which took place in Tampa, Florida, the Tampa Bay Buccaneers defeated the defending champion Chiefs, 31\u20139. No player on the Buccaneers who scored points (Rob Gronkowski, Antonio Brown, Leonard Fournette, and Ryan Succop) was on the Buccaneers' roster the previous season. This marked a record seventh Super Bowl victory for Tom Brady, also more than any individual NFL franchise, and who would also break his own record for the oldest quarterback to win a championship at 43 years old. Tampa Bay head coach Bruce Arians would also break Bill Belichick's record for the oldest head coach to win a championship at 68. Super Bowl LV also marked the first time in the history of the modern league that a host city's professional football franchise got to play in a Super Bowl that was hosted in their home stadium.\nA year later in Inglewood, California, the Los Angeles Rams defeated the Cincinnati Bengals 23\u201320 to win Super Bowl LVI, becoming the second team to win the Super Bowl in its home stadium.\nOn February 12, 2023, at State Farm Stadium in Glendale, Arizona, the Chiefs overcame a 10-point deficit at halftime to defeat the Philadelphia Eagles 38\u201335, winning Super Bowl LVII on a last-minute field goal.\nOn February 11, 2024, the Chiefs won Super Bowl LVIII at Allegiant Stadium on an overtime touchdown. The first Super Bowl in Las Vegas, this was a rematch of Super Bowl LIV between the 49ers and the Chiefs, and was the Chiefs' fourth Super Bowl appearance in five years. The second Super Bowl to go into overtime, the Chiefs came back from another 10-point deficit to win their third Super Bowl in five years and secure back-to-back championships for the first time since the 2004 New England Patriots.\nOn February 9, 2025, at the Caesars Superdome in New Orleans, Patrick Mahomes went to his fifth Super Bowl since he became the starting quarterback. This made the Chiefs the first team in NFL history to win back-to-back Super Bowls and then appear in the Super Bowl again the following year, and also the first team in NFL history to play in five Super Bowls over a six-year period. The Chiefs played the Philadelphia Eagles in Super Bowl LIX. This was the second time the Chiefs rematched another team in the Super Bowl. The Eagles successfully avenged their Super Bowl LVII defeat, winning 40\u201322 after leading 34\u20130 at the end of the third quarter and preventing the Chiefs from becoming the first team to win three straight Super Bowl championships. Jalen Hurts was named Super Bowl MVP.\nTelevision coverage and ratings.\nThe Super Bowl is one of the most-watched annual sporting events in the world, with viewership overwhelmingly domestic. The only other annual event that gathers more viewers is the UEFA Champions League final. For many years, the Super Bowl has possessed a large US and global television viewership, and it is often the most-watched United States originating television program of the year. The game tends to have a high Nielsen television rating, which is usually around a 40 rating and 60 shares. This means that, on average, more than 100 million people from the United States alone are tuned into the Super Bowl at any given moment.\nIn press releases preceding the game, the NFL has claimed that the Super Bowl has a potential worldwide audience of around one billion people in over 200 countries. However, this figure refers to the number of people \"able\" to watch the game, not the number of people who will actually be watching. Regardless, the statements have been frequently misinterpreted in the media as referring to the latter figure, leading to a misperception about the game's actual global audience. The New York-based media research firm Initiative measured the global audience for the Super Bowl XXXIX at 93 million people, with 98 percent of that figure being viewers in North America, which meant roughly two million people outside North America watched the Super Bowl that year.\nSuper Bowl LVIII holds the record for average number of US viewers, with 123.7 million, making the game the most-viewed television broadcast of any kind in American history. The halftime show set a record with 129.2 million viewers tuning in.\nThe highest-rated game according to Nielsen was Super Bowl XVI in 1982, which was watched in 49.1% of households (73 shares), or 40,020,000 households at the time. Super Bowl XVI still ranks fourth on Nielsen's list of top-rated programs of all time, with three other Super Bowls (XVII, XX, and XLIX) in the top ten.\nFamous Super Bowl commercials include the 1984 introduction of Apple's Macintosh computer, the Budweiser \"Bud Bowl\" campaign, and the dot-com ads aired during Super Bowl XXXIV. As the television ratings of the Super Bowl have steadily increased over the years, commercial prices have also increased, with advertisers paying as much as $7 million for a thirty-second spot during Super Bowl LVI in 2022. A segment of the audience tunes into the Super Bowl solely to view commercials. In 2010, Nielsen reported that 51 percent of Super Bowl viewers tune in for the commercials.\nSince 1991, the Super Bowl has begun between 6:19 and 6:40 PM EST so that most of the game is played during the primetime hours on the East Coast.\nUS television rights.\nThroughout most of its history, the Super Bowl has been rotated annually between the same American television networks that broadcast the NFL's regular season and postseason games.\nSuper Bowl I, played in 1967, is the only Super Bowl to have been broadcast in the United States by two different broadcasters simultaneously. At the time, NBC held the rights to nationally televise AFL games while CBS had the rights to broadcast NFL games. Both networks were allowed to cover the game, and each network used its own announcers, but NBC was only allowed to use the CBS feed instead of producing its own.\nBeginning with Super Bowl II, NBC televised the game in even years and CBS in odd years. This annual rotation between the two networks continued through the 1970 AFL\u2013NFL merger when NBC was given the rights to televise AFC games and CBS winning the rights to broadcast NFC games. Although ABC began broadcasting \"Monday Night Football\" in 1970, it was not added to the Super Bowl rotation until Super Bowl XIX, played in 1985. ABC, CBS and NBC then continued to rotate the Super Bowl until 1994, when Fox replaced CBS as the NFC broadcaster. CBS then took NBC's place in the rotation after CBS replaced NBC as the AFC broadcaster in 1998. As a result of new contracts signed in 2006, with NBC taking over \"Sunday Night Football\" from ESPN, and \"Monday Night Football\" moving from ABC to ESPN, NBC took ABC's place in the Super Bowl rotation. The rotation between CBS, Fox, and NBC will continue until the new contracts that took effect for the first time with Super Bowl LVIII, allowing ABC to return and starting a four-network rotation.\nThe four-year rotation beginning with Super Bowl LVIII also allows each broadcaster to offer simulcasts or alternative broadcasts on its sister networks and platforms. CBS's sister network Nickelodeon aired an alternate children-oriented telecast of Super Bowl LVIII. And ABC's rights include ESPN simulcasts and alternative broadcasts on other ESPN networks.\nThe NFL has broken the traditional broadcasting rotation if it can be used to bolster other major sporting events a network airs afterwards. For example, CBS was given Super Bowl XXVI (1992) after it won the rights to air the 1992 Winter Olympics, with NBC subsequently airing Super Bowl XXVII (1993) and Super Bowl XXVIII (1994) in consecutive years. Likewise, NBC aired Super Bowl LVI (2022) instead of CBS during the 2022 Winter Olympics, which were also aired by NBC. CBS received Super Bowl LV (2021) in return. Under the four-network rotation that will take effect beginning in 2024, the league will award NBC the Super Bowl during Winter Olympic years.\nThe first six Super Bowls were blacked out in the television markets of the host cities, due to league restrictions then in place. Super Bowl VII (1973) was telecast in Los Angeles on an experimental basis after all tickets were sold ten days before the game.\nGame analyst John Madden is the only person to broadcast a Super Bowl for each of the four networks that have televised the game (five with CBS, three with Fox, two with ABC, and one with NBC).\n&lt;br&gt;\n Parameter #1 (name of content note) and parameter #2 (text of content note) must both be entered.\n^\u00a0**:\u00a0The first Super Bowl was simultaneously broadcast by CBS and NBC, with each network using the same video feed (from CBS), but providing its own commentary.\nLead-out programming.\nThe Super Bowl provides an extremely strong lead-in to programming following it on the same channel, the effects of which can last for several hours. For instance, in discussing the ratings of a local TV station, Buffalo television critic Alan Pergament noted that following Super Bowl XLVII, which aired on CBS: \"A paid program that ran on CBS4 (WIVB-TV) at 2:30 in the morning had a 1.3 rating. That's higher than some CW prime time shows get on WNLO-TV, Channel 4's sister station.\"\nBecause of this strong coattail effect, the network that airs the Super Bowl typically takes advantage of the large audience to air an episode of a hit series or to premiere the pilot of a promising new one in the lead-out slot, which immediately follows the Super Bowl and post-game coverage.\nCeremonies and entertainment.\nEarly Super Bowls featured a halftime show consisting of marching bands from local colleges or high schools; but as the popularity of the game increased, a trend emerged where popular singers and musicians performed during its pre-game ceremonies and the halftime show, or simply sang the national anthem of the United States, \"America the Beautiful\", or \"Lift Every Voice and Sing\".\nThe U.S. national anthem has been performed at all but one Super Bowl: Super Bowl XI in 1977 when Vikki Carr sang \"America the Beautiful\" in place of the anthem. Beginning with Super Bowl XLIII in 2009, \"America the Beautiful\" is sung before the national anthem every year and is followed by the presentation of the colors and a military flyover preceding the anthem. Beginning with Super Bowl LV in 2021, \"Lift Every Voice and Sing\" is sung prior to \"America the Beautiful\" in honor of Black History Month.\nFor many years, Whitney Houston's performance of the national anthem at Super Bowl XXV in 1991, during the Gulf War, had long been regarded as one of the best renditions of the anthem in history. Before Super Bowl XLVIII, soprano Ren\u00e9e Fleming became the first opera singer to perform the anthem.\nRecently, the winner of the Walter Payton NFL Man of the Year Award has been acknowledged before \"America the Beautiful\" and \"The Star-Spangled Banner\".\nSince Super Bowl XII in 1978, a former football player, a celebrity, or another special guest participates in the coin toss ceremony to recognize their community involvement or significance.\nThe pre-game ceremonies usually go in the following order:\nUnlike regular season or playoff games, thirty minutes are allocated for the Super Bowl halftime. After a special live episode of the Fox sketch comedy series \"In Living Color\" caused a drop in viewership for the Super Bowl XXVI halftime show, the NFL sought to increase the Super Bowl's audience by hiring A-list talent to perform. They approached Michael Jackson, whose performance the following year drew higher figures than the game itself. U2 performed at Super Bowl XXXVI in 2002; during their third song, \"Where the Streets Have No Name\", the band played under a large projection screen which scrolled through names of the victims of the September 11 attacks.\nThe halftime show of Super Bowl XXXVIII attracted controversy, following an incident in which Justin Timberlake removed a piece of Janet Jackson's top, briefly exposing one of her breasts before the broadcast quickly cut away from the shot. The incident led to fines being issued by the FCC (and a larger crackdown over \"indecent\" content broadcast on television), and MTV (then a sister to the game's broadcaster that year, CBS, under Viacom) being banned by the NFL from producing the Super Bowl halftime show in the future. In an effort to prevent a repeat of the incident, the NFL held a moratorium on Super Bowl halftime shows featuring pop performers, and instead invited a single, headlining veteran act, such as Paul McCartney, the Rolling Stones, the Who, Prince, and Bruce Springsteen. This practice ended at Super Bowl XLV, which returned to using current pop acts such as the Black Eyed Peas, Katy Perry, and Lady Gaga.\nMinnesota Vikings announcer Alan Roach is the official public address announcer of the Super Bowl since Super Bowl XL in 2006, with the exceptions of Super Bowl XLVIII, XLIX and 50 when the Denver Broncos played in those games. Roach was also Denver's regular P.A. announcer during those years, and thus the league felt it was a potential competitive advantage. In those years, NFL on Westwood One host and NFL Films voice Scott Graham held the duties.\nExcluding Super Bowl XXXIX, the \"I'm going to Disney World!\" advertising campaign took place in every Super Bowl since Super Bowl XXI in 1987, when quarterback Phil Simms from the Giants became the first player to say the tagline.\nVenues.\nAs of Super Bowl LIX, 30 of 59 Super Bowls have been played in three metropolitan areas: the Greater Miami area (eleven times), New Orleans (eleven times), and the Greater Los Angeles area (eight times). No market or region without an active NFL franchise has ever hosted a Super Bowl, and the presence of an NFL team in a market or region is now a \"de jure\" requirement for bidding on the game. For instance, while Los Angeles has been an eight-time host city, with its most recent being Super Bowl LVI in 2022, it did not host one from the until in 2016 and 2017 respectively. The Caesars Superdome in New Orleans has hosted eight Super Bowls, the most of any venue. The Orange Bowl was the only AFL stadium to host a Super Bowl and the only stadium to host consecutive Super Bowls, hosting Super Bowls II and III.\nSeven Super Bowls have been held in a stadium other than the one the NFL team in that city was using at the time, a situation that has not arisen after Super Bowl XXVII's host stadium was selected on March 19, 1991. This was as the winning market was previously not required to host the Super Bowl in the same stadium that its NFL team used, if the stadium in which the Super Bowl was held was perceived to be a better stadium for a large high-profile event than the existing NFL home stadium in the same city; for example, five of Los Angeles's Bowls were played at the Rose Bowl, which has never been used by any NFL franchise outside of the Super Bowl. Besides the Rose Bowl, the only other Super Bowl venues that were not the home stadium to NFL teams at the time were Rice Stadium (the Houston Oilers had played in Rice Stadium previously but moved to the Astrodome several years before Super Bowl VIII) and Stanford Stadium. Starting with the selection of the Super Bowl XXVIII venue on May 23, 1990, the league has given preference in awarding the Super Bowl to brand new or recently renovated NFL stadiums, alongside a trend of teams demanding public money or relocating to play in new stadiums.\nTo date only two teams have qualified for a Super Bowl at their home stadiums: the 2020 Tampa Bay Buccaneers, who won Super Bowl LV hosted at Raymond James Stadium (selected on May 23, 2017), and the 2021 Los Angeles Rams the following season, who won Super Bowl LVI at SoFi Stadium. Before that, the closest any team had come to accomplishing this feat were the 2017 Minnesota Vikings, who reached the NFC Championship Game but lost to the Eagles. In that instance, U.S. Bank Stadium became the first Super Bowl host stadium (selected on May 20, 2014) to also host a Divisional Playoff Game in the same season (which the Vikings won); all previous times that the Super Bowl host stadium hosted another playoff game in the same postseason were all Wild Card games. Two teams have played the Super Bowl in their home market but at a different venue than their home stadium: the Los Angeles Rams, who lost Super Bowl XIV in the Rose Bowl instead of Los Angeles Memorial Coliseum; and the 49ers, who won Super Bowl XIX in Stanford Stadium instead of Candlestick Park, during a time when the league often picked a stadium that was not home to an NFL team to host the Super Bowl (see above).\nTraditionally, the NFL does not award Super Bowls to stadiums that are located in climates with an expected average daily temperature less than on game day unless the field can be completely covered by a fixed or retractable roof. Six Super Bowls have been played in northern cities: two in the Detroit area\u2014Super Bowl XVI at Pontiac Silverdome in Pontiac, Michigan, and Super Bowl XL at Ford Field in Detroit; two in Minneapolis\u2014Super Bowl XXVI at the Hubert H. Humphrey Metrodome and Super Bowl LII at the U.S. Bank Stadium; one in Indianapolis at Lucas Oil Stadium for Super Bowl XLVI; and one in New Jersey\u2014Super Bowl XLVIII at MetLife Stadium. Only MetLife Stadium did not have a roof (be it fixed or retractable) but it was still picked as the host stadium for Super Bowl XLVIII in an apparent waiver of the warm-climate rule, with a contingency plan to reschedule the game in the event of heavy snowfall. MetLife Stadium's selection over Sun Life Stadium generated controversy as the league requested a roof to be added to Sun Life Stadium (a venue afflicted with a heavy rainstorm during Super Bowl XLI) in order to be considered for future Super Bowls, which was done during a remodeling from 2015 into 2016. It then hosted Super Bowl LIV.\nThere have been a few instances where the league has rescinded the Super Bowl from cities. Super Bowl XXVII in 1993 was originally awarded to Sun Devil Stadium in Tempe, Arizona, but after Arizona voters elected not to recognize Martin Luther King, Jr. Day as a paid state employees' holiday in 1990, the NFL moved the game to the Rose Bowl in Pasadena, California. When voters in Arizona opted to create such a legal holiday in 1992, Super Bowl XXX in 1996 was awarded to Tempe. Super Bowl XXXIII in 1999 was awarded first to Candlestick Park in San Francisco, but when plans to renovate the stadium fell through, the game was moved to Pro Player Stadium in greater Miami. Super Bowl XXXVII in 2003 was awarded to a new stadium not yet built in San Francisco, but when that stadium failed to be built, the game was moved to Qualcomm Stadium in San Diego. Super Bowl XLIV, slated for February 2010, was withdrawn from New York City's proposed West Side Stadium, because the city, state, and proposed tenants (New York Jets) could not agree on funding. Super Bowl XLIV was then eventually awarded to Sun Life Stadium in Miami Gardens, Florida. Super Bowl XLIX in 2015 was originally given to Arrowhead Stadium in Kansas City, Missouri, but after two sales taxes failed to pass at the ballot box (a renovation proposal had passed successfully, but a second ballot question to add a rolling roof structure to be shared with Kaufmann Stadium critical for the game to be hosted was rejected), and opposition by local business leaders and politicians increased, Kansas City eventually withdrew its request to host the game. Super Bowl XLIX was then eventually awarded to University of Phoenix Stadium in Glendale, Arizona. Super Bowl LV in 2021 was first awarded to the yet-to-be completed SoFi Stadium, but construction delays forced the game to be moved to Raymond James Stadium and SoFi Stadium was then given Super Bowl LVI in 2022. Super Bowl LVIII in 2024 was first given to the Superdome, but the NFL's 2021 regular season expansion pushed the game from February 4 to February 11 in a direct conflict with New Orleans' Mardi Gras celebrations; Super Bowl LVIII was then moved to Allegiant Stadium in Nevada and New Orleans was given Super Bowl LIX in 2025.\nSelection process.\nThe location of the Super Bowl is chosen at a meeting of all NFL team owners, usually three to five years before the event. The game has never been played in a metropolitan area that lacked an NFL franchise at the time the game was played, although in 2007 NFL commissioner Roger Goodell suggested that a Super Bowl might be played in London, perhaps at Wembley Stadium.\nThrough Super Bowl LVI, teams were allowed to bid for the rights to host Super Bowls, where cities submitted proposals to host a Super Bowl and were evaluated in terms of stadium renovation and their ability to host, but this competition was rescinded in 2018. The league has made all decisions regarding hosting sites from Super Bowl LVII onward; the league chose a potential venue unilaterally, the chosen team put together a hosting proposal, and the league voted upon it to determine if it is acceptable.\nIn 2014, a document listing the specific requirements of Super Bowl hosts was leaked, giving a clear list of what was required for a Super Bowl host. Some of the host requirements include:\nMuch of the cost of a Super Bowl is to be assumed by the host community, although some costs are enumerated within the requirements to be assumed by the NFL. New Orleans, the site of Super Bowl XLVII in 2013, invested more than $1 billion in infrastructure improvements in the years leading up to the game.\nThe NFL allocates backup stadiums for the Super Bowl every year, in the event of a last-minute relocation of the game.\nHome team designation.\nThe designated \"home team\" alternates between the NFC team in odd-numbered games and the AFC team in even-numbered games. This alternation was initiated with the first Super Bowl, when the Packers were the designated home team. Regardless of being the home or away team of record, each team has its team logo and wordmark painted in one of the end zones. Designated away teams have won 32 of 59 Super Bowls to date (approximately 54%).\nSince Super Bowl XIII in 1979, the home team is given the choice of wearing its colored or white jerseys. Originally, the designated home team had to wear its colored jerseys, which resulted in the Cowboys donning their less exposed[\"\"] dark blue jerseys for Super Bowl V. While most of the home teams in the Super Bowl have chosen to wear their colored jerseys, there have been seven exceptions: the Cowboys during Super Bowls XIII and XXVII, the Washington Redskins during Super Bowl XVII, the Steelers during Super Bowl XL, the Broncos during Super Bowl 50, the Patriots in Super Bowl LII, and the Buccaneers in Super Bowl LV. The Cowboys, since 1964, have worn white jerseys at home. The Washington Redskins wore white at home under coach Joe Gibbs starting in 1981 through 1992, continued by Richie Petitbon and Norv Turner through 2000, then again when Gibbs returned from 2004 through 2007. Meanwhile, the Steelers, who have always worn their black jerseys at home since the AFL\u2013NFL merger in 1970, opted for the white jerseys after winning three consecutive playoff games on the road, wearing white. The Steelers' decision was compared with the Patriots in Super Bowl XX; the Patriots had worn white jerseys at home during the 1985 season, but after winning road playoff games against the Jets and Dolphins wearing red jerseys, New England opted to switch to scarlet for the Super Bowl as the designated home team. For the Broncos in Super Bowl 50, Denver general manager John Elway simply stated, \"We've had Super Bowl success in our white uniforms\"; they previously had been 0\u20134 in Super Bowls when wearing their orange jerseys. The Broncos' decision is also perceived to be made out of superstition, losing all Super Bowl games with the orange jerseys in terrible fashion. It is unclear why the Patriots chose to wear their white jerseys for Super Bowl LII. During the pairing of Bill Belichick and Tom Brady, New England has mostly worn their blue jerseys for home games, but have worn white for a home game in the 2008, 2010, and 2011 seasons. The Patriots were 3\u20130 in their white uniforms in Super Bowls before Super Bowl LII with Belichick and Brady, and they may have been going on recent trends of teams who wear white for the Super Bowl game. For Super Bowl LV, when the Buccaneers became the first team to reach the Super Bowl that their own stadium hosted, the Buccaneers were designated the home team as per AFC-NFC rotation and elected to wear their white jerseys, having previously won both their divisional and championship post-season games on the road in white jerseys (the Buccaneers also often wear white at home during the regular season). White-shirted teams have won 37 of 59 Super Bowls to date (approximately 63%). The only teams to win in their dark-colored uniform in more recent years are the Packers against the Steelers in Super Bowl XLV, the Eagles against the Patriots in Super Bowl LII, the Chiefs against the 49ers in Super Bowls LIV and LVIII, and the Eagles against the Chiefs in LIX. Since Super Bowl XXXIX, teams in white jerseys have won 16 of the last 21 Super Bowls.\nThe 49ers, as part of the league's 75th Anniversary celebration, used their 1955 throwback uniform in Super Bowl XXIX, which for that year was their regular home jersey. The Los Angeles Rams in Super Bowl LIII wore their royal blue and yellow uniforms, which was a throwback uniform but then turned into their primary colors over the navy blue and metallic gold uniform, which they have previously worn for six home games including a home playoff game. No team has yet worn a third jersey or Color Rush uniform for the Super Bowl. The 49ers reportedly requested to wear an all-white third jersey ensemble for Super Bowl LIV, which the \"San Francisco Chronicle\" noted they could do with special permission from the league; the league never granted such permission, and the 49ers instead opted for their standard uniform of white jerseys with gold pants.\nHost cities/regions.\nSixteen different regions have hosted Super Bowls.\nHost stadiums.\nA total of 27 different stadiums have either hosted, or are scheduled to host, a Super Bowl, with 14 of the stadiums having hosted, or are scheduled to host, more than one Super Bowl. Seven of the Super Bowl hosting stadiums have been demolished.\nThe years listed in the table below are the years the game was actually played (\"will be played\"[\u02c7]) rather than the NFL season it concluded.\n^\u00a0^:\u00a0Stadium has since been demolished.\n^\u00a0\u2021:\u00a0Prior to the incorporation of Miami Gardens in 2003, the stadium was in unincorporated Miami-Dade County.\n^\u00a0\u2020\u2020:\u00a0The original Stanford Stadium, which hosted Super Bowl XIX, was demolished and a new stadium constructed on the site in 2006.\n^\u00a0\u02c7:\u00a0Future Super Bowls, also denoted by \"italics\".\nFuture venues.\nThe Super Bowl has not yet been played in any region that lacked an NFL or AFL franchise at the time the game was played.\nSan Diego is the only metropolitan area as of 2021 that has hosted past Super Bowls, but does not currently have an NFL franchise: San Diego Stadium hosted three Super Bowls before their NFL franchise relocated to Los Angeles. Also, London, England, has occasionally been mentioned as a host city for a Super Bowl in the near future. Wembley Stadium has hosted several NFL games as part of the NFL International Series and is specifically designed for large, individual events, and NFL Commissioner Roger Goodell has openly discussed the possibility on different occasions.\nTime zone complications are a significant obstacle to a Super Bowl in London; a typical 6:30\u00a0p.m. EST start would result in the game beginning at 11:30\u00a0p.m. local time in London: this is an unusually late hour to be holding spectator sports, while the NFL has never in its history started a game later than 9:15\u00a0p.m. local time.\nAlthough bids have been submitted for all Super Bowls through Super Bowl LIX, the soonest that any stadium outside the NFL's footprint could serve as host would be Super Bowl LXIII in 2029, but Las Vegas is currently negotiating with the NFL to host that edition.\nEight stadiums that hosted at least one Super Bowl no longer exist:\nSuper Bowl trademark.\nThe NFL very actively seeks to prevent what it calls unauthorized commercial use of its trademarked terms \"NFL\", \"Super Bowl\", and \"Super Bowl Sunday\". As a result, many events and promotions tied to the game, but not sanctioned by the NFL, are asked to refer to it as \"The Big Game\", or other generic descriptions. A radio spot for Planters nuts parodied this, by saying \"it would be \"super\"... to have a \"bowl\"... of Planters nuts while watching the big game!\" and comedian Stephen Colbert began referring to the game in 2014 as the \"Superb Owl\". In 2015, the NFL filed opposition with the USPTO Trademark Trial and Appeal Board to a trademark application submitted by an Arizona-based nonprofit for \"Superb Owl\". Another entity has a service mark for \"Superb Owl\".\nThe NFL claims that the use of the phrase \"Super Bowl\" implies an NFL affiliation, and on this basis the league asserts broad rights to restrict how the game may be shown publicly; for example, the league says Super Bowl showings are prohibited in churches or at other events that \"promote a message\", while non-sporting event venues are also prohibited to show the Super Bowl on any television screen larger than 55\u00a0inches. Some critics say the NFL is exaggerating its ownership rights by stating that \"any use is prohibited\", as this contradicts the broad doctrine of fair use in the United States. Legislation was proposed by Utah Senator Orrin Hatch in 2008 \"to provide an exemption from exclusive rights in copyright for certain nonprofit organizations to display live football games\", and \"for other purposes\".\nIn 2004, the NFL started issuing cease-and-desist letters to casinos in Las Vegas that were hosting Super Bowl parties. \"Super Bowl\" is a registered trademark, owned by the NFL, and any other business using that name for profit-making ventures is in violation of federal law, according to the letters. In reaction to the letters, many Las Vegas resorts, rather than discontinue the popular and lucrative parties, started referring to them as \"Big Game Parties\".\nIn 2006, the NFL made an attempt to trademark \"The Big Game\" as well; however, it withdrew the application in 2007 due to growing commercial and public relations opposition to the move, mostly from Stanford University and the University of California, Berkeley and their fans, as the Stanford Cardinal football and California Golden Bears football teams compete in the \"Big Game\", which has been played since 1892 (28 years before the formation of the NFL and 75 years before Super Bowl I). Additionally, the Mega Millions lottery game was known as \"The Big Game\" (then \"The Big Game Mega Millions\") from 1996 to 2002.\nTraditions.\nOver the years, the Super Bowl has developed a number of traditions and mainstays. Some date back to the earliest Super Bowls, while others are more recent inventions.\nRoman numerals.\nUnique among the major North American professional sports leagues, the NFL uses Roman numerals to designate its championship Super Bowl game. An exception to this rule occurred in Super Bowl 50 for marketing purposes.\nCommercials.\nCommercials have become one of the most culturally iconic aspects of the Super Bowl, with many viewers watching the game only to watch the commercials. Due to the NFL charging large fees for commercial rights, Super Bowl commercials are noted for their extremely high budgets compared to typical TV commercials and their use of celebrity endorsements.\nPresidential interview.\nSince George W. Bush, every President of the United States has sat for at least one pre-game Super Bowl interview. President Bush was interviewed before the game in 2004, but it did not become a regular tradition until the Presidency of Barack Obama, who was interviewed each year of his presidency. Donald Trump was interviewed in 2017, 2019, and 2020 and Joe Biden was interviewed in 2021 and 2022. In 2025, Trump was again interviewed during the first year of his second term. Interview topics were mostly apolitical and focused on football before 2014, but this changed when Bill O'Reilly conducted a more confrontational interview with President Obama before Super Bowl XLVIII. Since then, interviews have been more focused on politics and public policy.\nNotes and references.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27725", "revid": "23755636", "url": "https://en.wikipedia.org/wiki?curid=27725", "title": "Surface area", "text": "Measure of a two-dimensional surface\nThe surface area (symbol A) of a solid object is a measure of the total area that the surface of the object occupies. The mathematical definition of surface area in the presence of curved surfaces is considerably more involved than the definition of arc length of one-dimensional curves, or of the surface area for polyhedra (i.e., objects with flat polygonal faces), for which the surface area is the sum of the areas of its faces. Smooth surfaces, such as a sphere, are assigned surface area using their representation as parametric surfaces. This definition of surface area is based on methods of infinitesimal calculus and involves partial derivatives and double integration.\nA general definition of surface area was sought by Henri Lebesgue and Hermann Minkowski at the turn of the twentieth century. Their work led to the development of geometric measure theory, which studies various notions of surface area for irregular objects of any dimension. An important example is the Minkowski content of a surface.\nDefinition.\nWhile the areas of many simple surfaces have been known since antiquity, a rigorous mathematical \"definition\" of area requires a great deal of care.\nThis should provide a function\n formula_1\nwhich assigns a positive real number to a certain class of surfaces that satisfies several natural requirements. The most fundamental property of the surface area is its additivity: \"the area of the whole is the sum of the areas of the parts\". More rigorously, if a surface \"S\" is a union of finitely many pieces \"S\"1, \u2026, \"S\"\"r\" which do not overlap except at their boundaries, then \n formula_2\nSurface areas of flat polygonal shapes must agree with their geometrically defined area. Since surface area is a geometric notion, areas of congruent surfaces must be the same and the area must depend only on the shape of the surface, but not on its position and orientation in space. This means that surface area is invariant under the group of Euclidean motions. These properties uniquely characterize surface area for a wide class of geometric surfaces called \"piecewise smooth\". Such surfaces consist of finitely many pieces that can be represented in the parametric form\n formula_3\nwith a continuously differentiable function formula_4 The area of an individual piece is defined by the formula\n formula_5\nThus the area of \"S\"\"D\" is obtained by integrating the length of the normal vector formula_6 to the surface over the appropriate region \"D\" in the parametric \"uv\" plane. The area of the whole surface is then obtained by adding together the areas of the pieces, using additivity of surface area. The main formula can be specialized to different classes of surfaces, giving, in particular, formulas for areas of graphs \"z\" = \"f\"(\"x\",\"y\") and surfaces of revolution.\nOne of the subtleties of surface area, as compared to arc length of curves, is that surface area cannot be defined simply as the limit of areas of polyhedral shapes approximating a given smooth surface. It was demonstrated by Hermann Schwarz that already for the cylinder, different choices of approximating flat surfaces can lead to different limiting values of the area; this example is known as the Schwarz lantern.\nVarious approaches to a general definition of surface area were developed in the late nineteenth and the early twentieth century by Henri Lebesgue and Hermann Minkowski. While for piecewise smooth surfaces there is a unique natural notion of surface area, if a surface is very irregular, or rough, then it may not be possible to assign an area to it at all. A typical example is given by a surface with spikes spread throughout in a dense fashion. Many surfaces of this type occur in the study of fractals. Extensions of the notion of area which partially fulfill its function and may be defined even for very badly irregular surfaces are studied in geometric measure theory. A specific example of such an extension is the Minkowski content of the surface.\nCommon formulas.\nRatio of surface areas of a sphere and cylinder of the same radius and height.\nThe below given formulas can be used to show that the surface area of a sphere and cylinder of the same radius and height are in the ratio 2\u00a0:\u00a03, as follows.\nLet the radius be \"r\" and the height be \"h\" (which is 2\"r\" for the sphere).\nformula_7\nThe discovery of this ratio is credited to Archimedes.\nIn chemistry.\nSurface area is important in chemical kinetics. Increasing the surface area of a substance generally increases the rate of a chemical reaction. For example, iron in a fine powder will combust, while in solid blocks it is stable enough to use in structures. For different applications a minimal or maximal surface area may be desired.\nIn biology.\nThe surface area of an organism is important in several considerations, such as regulation of body temperature and digestion. Animals use their teeth to grind food down into smaller particles, increasing the surface area available for digestion. The epithelial tissue lining the digestive tract contains microvilli, greatly increasing the area available for absorption. Elephants have large ears, allowing them to regulate their own body temperature. In other instances, animals will need to minimize surface area; for example, people will fold their arms over their chest when cold to minimize heat loss.\nThe surface area to volume ratio (SA:V) of a cell imposes upper limits on size, as the volume increases much faster than does the surface area, thus limiting the rate at which substances diffuse from the interior across the cell membrane to interstitial spaces or to other cells. Indeed, representing a cell as an idealized sphere of radius r, the volume and surface area are, respectively, \"V\" = (4/3)\"\u03c0r\"3 and \"SA\" = 4\"\u03c0r\"2. The resulting surface area to volume ratio is therefore 3/\"r\". Thus, if a cell has a radius of 1 \u03bcm, the SA:V ratio is 3; whereas if the radius of the cell is instead 10 \u03bcm, then the SA:V ratio becomes 0.3. With a cell radius of 100, SA:V ratio is 0.03. Thus, the surface area falls off steeply with increasing volume.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27727", "revid": "169132", "url": "https://en.wikipedia.org/wiki?curid=27727", "title": "Solid state", "text": "Solid state, or solid matter, is one of the four fundamental states of matter.\nSolid state may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "27728", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=27728", "title": "Statistical Mechanics", "text": ""}
{"id": "27730", "revid": "45916690", "url": "https://en.wikipedia.org/wiki?curid=27730", "title": "Serbo-Croatian", "text": "South Slavic language\n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nSerbo-Croatian, also known as Bosnian-Croatian-Montenegrin-Serbian (BCMS), is a South Slavic language and the primary language of Serbia, Croatia, Bosnia and Herzegovina, and Montenegro. It is a pluricentric language with four mutually intelligible standard varieties, namely Serbian, Croatian, Bosnian, and Montenegrin.\nSouth Slavic languages historically formed a dialect continuum. The region's turbulent history, particularly due to the expansion of the Ottoman Empire, led to a complex dialectal and religious mosaic. Due to population migrations, Shtokavian became the most widespread supradialect in the western Balkans, encroaching westward into the area previously dominated by Chakavian and Kajkavian. Bosniaks, Croats, and Serbs differ in religion and were historically often part of different cultural spheres, although large portions of these populations lived side by side under foreign rule. During that period, the language was referred to by various names, such as \"Slavic\" in general, or \"Serbian\", \"Croatian\" or \"Bosnian\" in particular. In a classicizing manner, it was also referred to as \"Illyrian\".\nThe standardization of Serbo-Croatian was initiated in the mid-19th-century Vienna Literary Agreement by Croatian and Serbian writers and philologists, decades before a Yugoslav state was established. From the outset, literary Serbian and Croatian exhibited slight differences, although both were based on the same Shtokavian dialect\u2014Eastern Herzegovinian. In the 20th century, Serbo-Croatian served as the lingua franca of the country of Yugoslavia, being the sole official language in the Kingdom of Yugoslavia (when it was called \"Serbo-Croato-Slovenian\"), and afterwards the official language of four out of six republics of the Socialist Federal Republic of Yugoslavia. The breakup of Yugoslavia influenced language attitudes, leading to the ethnic and political division of linguistic identity. Since then, Bosnian has likewise been established as an official standard in Bosnia and Herzegovina, and efforts to codify a separate Montenegrin standard continue.\nLike other South Slavic languages, Serbo-Croatian has a relatively simple phonology, with the common five-vowel system and twenty-five consonants. Its grammar evolved from Common Slavic, with complex inflection, preserving seven grammatical cases in nouns, pronouns, and adjectives. Verbs exhibit imperfective or perfective aspect, with a moderately complex tense system. Serbo-Croatian is a pro-drop language with flexible word order, subject\u2013verb\u2013object being the default. It can be written in either the Latin (Gaj's Latin alphabet) or Cyrillic script (Serbian Cyrillic alphabet), and the orthography is highly phonemic in all standards. Despite the many linguistic similarities among the standard varieties, each possesses distinctive traits, although these differences remain minimal.\nName.\nThroughout the history of the South Slavs, the vernacular, literary, and written languages (e.g., Chakavian, Kajkavian, Shtokavian) of various regions and ethnic groups developed and diverged independently. Before the 19th century, these languages were collectively called \"Illyrian\", \"Slavic\", \"Slavonian\", \"Bosnian\", \"Dalmatian\", \"Serbian\", or \"Croatian\". Since the 19th century, the term \"Illyrian\" or \"Illyric\" was frequently used, sometimes leading to confusion with the ancient Illyrian language. Although the word \"Illyrian\" was used occasionally before, its widespread usage began after Ljudevit Gaj and several other prominent linguists met at Ljudevit Vukotinovi\u0107's house to discuss the issue in 1832. The term \"Serbo-Croatian\" was first used by Jacob Grimm in 1824, later popularized by the Viennese philologist Jernej Kopitar, and adopted by Croatian grammarians in Zagreb in 1854 and 1859. At that time, Serb and Croat lands were still part of the Ottoman and Austrian Empires.\nSerbo-Croatian is typically referred to by the names of its standardized varieties\u2014Serbian, Croatian, Bosnian, and Montenegrin. It is rarely referred to by the names of its sub-dialects, such as Bunjevac or \u0160okac. In the language itself, it is formally known as (\"Serbo-Croatian\") and (\"Croato-Serbian\"). Historically, linguists and philologists, including \u0110uro Dani\u010di\u0107 and Tomislav Mareti\u0107, have referred to the language as \"Serbian or Croatian\" and \"Croatian or Serbian\". Serbo-Croatian is often colloquially called \"na\u0161 jezik\" (\"our language\") or \"na\u0161ki\" (sic. \"ourish\" or \"ourian\") by native speakers. This term is frequently used by those who wish to avoid linguistic discussions. Native speakers traditionally describe their language as \"jedan ali ne jedinstven\" (\"one but not uniform\").\nIn 1988, Croatian linguist Dalibor Brozovi\u0107 advocated the term \"Serbo-Croatian\", stating that, by analogy with Indo-European, it not only denotes the two components of the same language but also delineates the geographical region in which it is spoken, encompassing all language varieties within these boundaries, including Bosnian and Montenegrin. Croatian linguist Mate Kapovi\u0107 suggested \"Standard Shtokavian\" as the ethnically neutral and linguistically most precise term. Nowadays, the use of the term \"Serbo-Croatian\" is controversial due to the widespread perception that national identity and language should correspond. However, it is still used in academic and linguistic contexts due to the lack of a succinct alternative. Following the breakup of Yugoslavia, alternative designations have emerged, such as \"Bosnian/Croatian/Serbian\" (BCS), which is frequently used in political contexts, including by the International Criminal Tribunal for the former Yugoslavia.\nHistory.\nStandardization.\nIn the mid-19th century, Serbian (led by self-taught writer and folklorist Vuk Stefanovi\u0107 Karad\u017ei\u0107) and most Croatian writers and linguists (represented by the Illyrian movement and led by Ljudevit Gaj and \u0110uro Dani\u010di\u0107), proposed the use of the most widespread dialect, Shtokavian, as the base for their common standard language. Karad\u017ei\u0107 standardised the Serbian Cyrillic alphabet, and Gaj and Dani\u010di\u0107 standardized the Croatian Latin alphabet, on the basis of vernacular speech phonemes and the principle of phonological spelling. In 1850 Serbian and Croatian writers and linguists signed the Vienna Literary Agreement, declaring their intention to create a unified standard. Thus a complex bi-variant language appeared, which the Serbs officially called \"Serbo-Croatian\" or \"Serbian or Croatian\" and the Croats \"Croato-Serbian\", or \"Croatian or Serbian\". Yet, in practice, the variants of the conceived common literary language served as different literary variants, chiefly differing in lexical inventory and stylistic devices. The common phrase describing this situation was that Serbo-Croatian or \"Croatian or Serbian\" was a single language. In 1861, after a long debate, the Croatian Sabor put up several proposed names to a vote of the members of the parliament; \"Yugoslavian\" was opted for by the majority and legislated as the official language of the Triune Kingdom. The Austrian Empire, suppressing Pan-Slavism at the time, did not confirm this decision and legally rejected the legislation, but in 1867 finally settled on \"Croatian or Serbian\" instead. During the Austro-Hungarian rule in Bosnia and Herzegovina, the language of all three nations in this territory was declared \"Bosnian\" until the death of administrator von K\u00e1llay in 1907, at which point the name was changed to \"Serbo-Croatian\".\nWith unification of the first the Kingdom of the Serbs, Croats, and Slovenes \u2013 the approach of Karad\u017ei\u0107 and the Illyrians became dominant. The official language was called \"Serbo-Croato-Slovenian\" (\"srpsko-hrvatsko-slovena\u010dki\") in the 1921 constitution. In 1929, the constitution was suspended, and the country was renamed the Kingdom of Yugoslavia, while the official language of Serbo-Croato-Slovene was reinstated in the 1931 constitution.\nIn June 1941, the Nazi puppet Independent State of Croatia began to rid the language of \"Eastern\" (Serbian) words, and shut down Serbian schools. The totalitarian dictatorship introduced a language law that promulgated Croatian linguistic purism as a policy that tried to implement a complete elimination of Serbisms and internationalisms.\nOn January 15, 1944, the Anti-Fascist Council of the People's Liberation of Yugoslavia (AVNOJ) declared Croatian, Serbian, Slovene, and Macedonian to be equal in the entire territory of Yugoslavia. In 1945 the decision to recognize Croatian and Serbian as separate languages was reversed in favor of a single Serbo-Croatian or Croato-Serbian language. In the Communist-dominated second Yugoslavia, ethnic issues eased to an extent, but the matter of language remained blurred and unresolved.\nIn 1954, major Serbian and Croatian writers, linguists and literary critics, backed by Matica srpska and Matica hrvatska signed the Novi Sad Agreement, which in its first conclusion stated: \"Serbs, Croats and Montenegrins share a single language with two equal variants that have developed around Zagreb (western) and Belgrade (eastern)\". The agreement insisted on the equal status of Cyrillic and Latin scripts, and of Ekavian and Ijekavian pronunciations. It also specified that \"Serbo-Croatian\" should be the name of the language in official contexts, while in unofficial use the traditional \"Serbian\" and \"Croatian\" were to be retained. Matica hrvatska and Matica srpska were to work together on a dictionary, and a committee of Serbian and Croatian linguists was asked to prepare a . During the sixties both books were published simultaneously in Ijekavian Latin in Zagreb and Ekavian Cyrillic in Novi Sad. Yet Croatian linguists claim that it was an act of unitarianism. The evidence supporting this claim is patchy: Croatian linguist Stjepan Babi\u0107 complained that the television transmission from Belgrade always used the Latin alphabet\u2014 which was true, but was not proof of unequal rights, but of frequency of use and prestige. Babi\u0107 further complained that the Novi Sad Dictionary (1967) listed side by side words from both the Croatian and Serbian variants wherever they differed, which one can view as proof of careful respect for both variants, and not of unitarism. Moreover, Croatian linguists criticized those parts of the Dictionary for being unitaristic that were written by Croatian linguists. And finally, Croatian linguists ignored the fact that the material for the came from the Croatian Philological Society. Regardless of these facts, Croatian intellectuals brought the Declaration on the Status and Name of the Croatian Literary Language in 1967. On occasion of the publication's 45th anniversary, the Croatian weekly journal \"Forum\" published the Declaration again in 2012, accompanied by a critical analysis.\nWest European scientists judge the Yugoslav language policy as an exemplary one: although three-quarters of the population spoke one language, no single language was official on a federal level. Official languages were declared only at the level of constituent republics and provinces, and very generously: Vojvodina had five (among them Slovak and Romanian, spoken by 0.5 per cent of the population), and Kosovo four (Albanian, Turkish, Romany and Serbo-Croatian). Newspapers, radio and television studios used sixteen languages, fourteen were used as languages of tuition in schools, and nine at universities. Only the Yugoslav People's Army used Serbo-Croatian as the sole language of command, with all other languages represented in the army's other activities\u2014however, this is not different from other armies of multilingual states, or in other specific institutions, such as international air traffic control where English is used worldwide. All variants of Serbo-Croatian were used in state administration and republican and federal institutions. Both Serbian and Croatian variants were represented in respectively different grammar books, dictionaries, school textbooks and in books known as (which detail spelling rules). Serbo-Croatian was a kind of soft standardisation. However, legal equality could not dampen the prestige Serbo-Croatian had: since it was the language of three quarters of the population, it functioned as an unofficial lingua franca. And within Serbo-Croatian, the Serbian variant, with twice as many speakers as the Croatian, enjoyed greater prestige, reinforced by the fact that Slovene and Macedonian speakers preferred it to the Croatian variant because their languages are also Ekavian. This is a common situation in other pluricentric languages, e.g. the variants of German differ according to their prestige, the variants of Portuguese too. Moreover, all languages differ in terms of prestige: \"the fact is that languages (in terms of prestige, learnability etc.) are not equal, and the law cannot make them equal\".\nLegal status.\nThe 1946, 1953, and 1974 constitutions of the Socialist Federal Republic of Yugoslavia did not name specific official languages at the federal level. The 1992 constitution of the Federal Republic of Yugoslavia, in 2003 renamed Serbia and Montenegro, stated in Article 15: \"In the Federal Republic of Yugoslavia, the Serbian language in its ekavian and ijekavian dialects and the Cyrillic script shall be official, while the Latin script shall be in official use as provided for by the Constitution and law.\"\nThe term \"Serbo-Croatian\" (or synonyms) is not officially used in any of the successor countries of former Yugoslavia. The current Serbian constitution of 2006 refers to the official language as \"Serbian\", while the current Montenegrin constitution of 2007 proclaims \"Montenegrin\" as the official language but also grants other Serbo-Croatian varieties the right to official use. Croatian is the official language of Croatia, while Serbian is also official in municipalities with significant Serb population. In Bosnia and Herzegovina, all three standard varieties are recorded as official.\nIn Serbia, the Serbian standard has an official status countrywide, while both Serbian and Croatian are official in the province of Vojvodina. A large Bosniak minority is present in the southwest region of Sand\u017eak, but the \"official recognition\" of Bosnian is moot. Bosnian is an optional course in first and second grade of the elementary school, while it is also in official use in the municipality of Novi Pazar. However, its nomenclature is controversial, as there is incentive that it is referred to as \"Bosniak\" (\"bo\u0161nja\u010dki\") rather than \"Bosnian\" (\"bosanski\") (see also: Bosnian language#Controversy and recognition).\nModern developments.\nIn 2017, numerous prominent writers, scientists, journalists, activists, and other public figures from Croatia, Bosnia and Herzegovina, Montenegro, and Serbia signed the Declaration on the Common Language, which states that all standard varieties are equal and belong to a common polycentric language, just like German, English, and Spanish.\nDemographics.\nAbout million people declare their native language as either 'Bosnian', 'Croatian', 'Serbian', 'Montenegrin', or 'Serbo-Croatian'.\nSerbian is spoken by million people around the world, mostly in Serbia ( million), Bosnia and Herzegovina ( million), and Montenegro (). Besides these, Serbian minorities are found in Kosovo, North Macedonia and in Romania. In Serbia, there are about 760,000 second-language speakers of Serbian, including Hungarians in Vojvodina and the 400,000 estimated Roma. In Kosovo, Serbian is spoken by the members of the Serbian minority which approximates between 70,000 and 100,000. Familiarity of Kosovar Albanians with Serbian varies depending on age and education, and exact numbers are not available.\nCroatian is spoken by million people in the world, including million in Croatia and in Bosnia and Herzegovina. A small Croatian minority that lives in Italy, known as Molise Croats, have somewhat preserved traces of Croatian. In Croatia, 170,000, mostly Italians and Hungarians, use it as a second language.\nBosnian is spoken by million people worldwide, chiefly Bosniaks, including million in Bosnia and Herzegovina, in Serbia and in Montenegro.\nMontenegrin is spoken by people globally. The notion of Montenegrin as a separate standard from Serbian is relatively recent. In the 2011 census, around 229,251 Montenegrins, of the country's 620,000, declared Montenegrin as their native language.\nSerbo-Croatian is also a second language of many Slovenians and Macedonians, especially those born during the time of Yugoslavia. According to the 2002 census, Serbo-Croatian and its variants have the largest number of speakers of the minority languages in Slovenia.\nGrammar.\nSerbo-Croatian is a highly inflected language. Traditional grammars list seven cases for nouns and adjectives: nominative, genitive, dative, accusative, vocative, locative, and instrumental, reflecting the original seven cases of Proto-Slavic, and indeed older forms of Serbo-Croatian itself. However, in modern Shtokavian the locative has almost merged into dative (the only difference is based on accent in some cases), and the other cases can be shown declining; namely:\nLike most Slavic languages, there are mostly three genders for nouns: masculine, feminine, and neuter, a distinction which is still present even in the plural (unlike Russian and, in part, the \u010cakavian dialect). They also have two numbers: singular and plural. However, some consider there to be three numbers (paucal or \"dual,\" too), since (still preserved in closely related Slovene) after two (\"dva\", \"dvije\"/\"dve\"), three (\"tri\") and four (\"\u010detiri\"), and all numbers ending in them (e.g. twenty-two, ninety-three, one hundred four, but not twelve through fourteen) the genitive singular is used, and after all other numbers five (\"pet\") and up, the genitive plural is used. (The number one [\"jedan\"] is treated as an adjective.) Adjectives are placed in front of the noun they modify and must agree in both case and number with it.\nThere are seven tenses for verbs: past, present, future, exact future, aorist, imperfect, and pluperfect; and three moods: indicative, imperative, and conditional. However, the latter three tenses are typically used only in Shtokavian writing, and the time sequence of the exact future is more commonly formed through an alternative construction.\nIn addition, like most Slavic languages, the Shtokavian verb also has one of two aspects: perfective or imperfective. Most verbs come in pairs, with the perfective verb being created out of the imperfective by adding a prefix or making a stem change. The imperfective aspect typically indicates that the action is unfinished, in progress, or repetitive; while the perfective aspect typically denotes that the action was completed, instantaneous, or of limited duration. Some \u0160tokavian tenses (namely, aorist and imperfect) favor a particular aspect (but they are rarer or absent in \u010cakavian and Kajkavian). Actually, aspects \"compensate\" for the relative lack of tenses, because verbal aspect determines whether the act is completed or in progress in the referred time.\nPhonology.\nVowels.\nThe Serbo-Croatian vowel system is simple, with only five vowels in Shtokavian. All vowels are monophthongs. The oral vowels are as follows:\nThe vowels can be short or long, but the phonetic quality does not change depending on the length. In a word, vowels can be long in the stressed syllable and the syllables following it, never in the ones preceding it.\nConsonants.\nThe consonant system is more complicated, and its characteristic features are series of affricate and palatal consonants. As in English, voice is phonemic, but aspiration is not.\nIn consonant clusters all consonants are either voiced or voiceless. All the consonants are voiced if the last consonant is normally voiced or voiceless if the last consonant is normally voiceless. This rule does not apply to approximants\u00a0\u2013 a consonant cluster may contain voiced approximants and voiceless consonants; as well as to foreign words (\"Washington\" would be transcribed as \"Va\u0161inGton\"), personal names and when consonants are not inside of one syllable.\n can be syllabic, playing the role of the syllable nucleus in certain words (occasionally, it can even have a long accent). For example, the tongue-twister \"navrh brda vrba mrda\" involves four words with syllabic . A similar feature exists in Czech, Slovak, and Macedonian. Very rarely other sonorants can be syllabic, like (in \"bicikl\"), (surname \"\u0160tarklj\"), (unit \"njutn\"), as well as and in slang.\nPitch accent.\nApart from Slovene, Serbo-Croatian is the only Slavic language with a pitch accent (simple tone) system. This feature is present in some other Indo-European languages, such as Norwegian, Ancient Greek, and Punjabi. Neo-Shtokavian Serbo-Croatian, which is used as the basis for standard Bosnian, Croatian, Montenegrin, and Serbian, has four \"accents\", which involve either a rising or falling tone on either long or short vowels, with optional post-tonic lengths:\nThe tone stressed vowels can be approximated in English with \"set\" vs. \"setting?\" said in isolation for a short tonic \"e,\" or \"leave\" vs. \"leaving?\" for a long tonic \"i,\" due to the prosody of final stressed syllables in English.\nGeneral accent rules in the standard language:\nThere are no other rules for accent placement, thus the accent of every word must be learned individually; furthermore, in inflection, accent shifts are common, both in type and position (the so-called \"mobile paradigms\"). The second rule is not strictly obeyed, especially in borrowed words.\nComparative and historical linguistics offers some clues for memorising the accent position: If one compares many standard Serbo-Croatian words to e.g. cognate Russian words, the accent in the Serbo-Croatian word will be one syllable before the one in the Russian word, with the rising tone. Historically, the rising tone appeared when the place of the accent shifted to the preceding syllable (the so-called \"Neo-Shtokavian retraction\"), but the quality of this new accent was different \u2013 its melody still \"gravitated\" towards the original syllable. Most Shtokavian (Neo-Shtokavian) dialects underwent this shift, but Chakavian, Kajkavian and the Old-Shtokavian dialects did not.\nAccent diacritics are not used in the ordinary orthography, but only in the linguistic or language-learning literature (e.g. dictionaries, orthography and grammar books). However, there are very few minimal pairs where an error in accent can lead to misunderstanding.\nOrthography.\nSerbo-Croatian orthography is almost entirely phonetic. Thus, most words should be spelled as they are pronounced. In practice, the writing system does not take into account allophones which occur as a result of interaction between words:\nAlso, there are some exceptions, mostly applied to foreign words and compounds, that favor morphological/etymological over phonetic spelling:\nOne systemic exception is that the consonant clusters ds and d\u0161 are not respelled as ts and t\u0161 (although \"d\" tends to be unvoiced in normal speech in such clusters):\nOnly a few words are intentionally \"misspelled\", mostly in order to resolve ambiguity:\nWriting systems.\nThrough history, this language has been written in a number of writing systems:\nThe oldest texts since the 11th century are in Glagolitic, and the oldest preserved text written completely in the Latin alphabet is , from 1345. The Arabic alphabet had been used by Bosniaks; Greek writing is out of use there, and Arabic and Glagolitic persisted so far partly in religious liturgies.\nThe Serbian Cyrillic alphabet () was revised by Vuk Stefanovi\u0107 Karad\u017ei\u0107 in the 19th century.\nThe Croatian Latin alphabet () followed suit shortly afterwards, when Ljudevit Gaj defined it as standard Latin with five extra letters that had diacritics, apparently borrowing much from Czech, but also from Polish, and inventing the unique digraphs \u27e8lj\u27e9, \u27e8nj\u27e9 and \u27e8d\u017e\u27e9. These digraphs are represented as \u27e8\u013c\u27e9, \u27e8\u0144\u27e9 and \u27e8\u01f5\u27e9 respectively in the , published by the former Yugoslav Academy of Sciences and Arts in Zagreb. The latter digraphs, however, are unused in the literary standard of the language. All in all, this makes Serbo-Croatian the only Slavic language to officially use both the Latin and Cyrillic scripts, albeit the Latin version is more commonly used.\nIn both cases, spelling is phonetic and spellings in the two alphabets map to each other one-to-one:\nThe digraphs \"Lj\", \"Nj\" and \"D\u017e\" represent distinct phonemes and are considered to be single letters. In crosswords, they are put into a single square, and in sorting, lj follows l and nj follows n, except in a few words where the individual letters are pronounced separately. For instance, \"to outlive\" is composed of the prefix \"out, over\" and the verb \"to live\". The Cyrillic alphabet avoids such ambiguity by providing a single letter for each phoneme: .\n\"\u0110\" used to be commonly written as \"Dj\" on typewriters, but that practice led to too many ambiguities. It is also used on car license plates. Today \"Dj\" is often used again in place of \"\u0110\" on the Internet as a replacement due to the lack of installed Serbo-Croat keyboard layouts.\nSerbian, Bosnian and Montenegrin standards officially use both alphabets, while Croatian uses the Latin only.\nLatin script has been rising in popularity in Serbia with the advent of the digital age and Internet in Serbia, whether due to restraints (Cyrillic letters use up twice the space and therefore cost on SMS), accessibility (intention to be readable internationally, as the Latin alphabet is taught in all four countries speaking the language) or ease of use. This has been perceived by Serbian government officials as a suppression and threat for existence of the national script that is Cyrillic, with the Ministry of Culture and Information of Serbia pushing for more tight language laws on top of those stipulated by the existing Constitution.\nMontenegrin alphabet, adopted in 2009, provides replacements of and with an addition of acute accent on and , forming \u27e8\u015b\u27e9 and \u27e8\u017a\u27e9 in both Latin and Cyrillic, but they remain largely unused, even by the Parliament of Montenegro which introduced them.\nAn experimental alphabet called 'Slavica' fusing Latin and Cyrillic was devised by linguistic amateur Rajko Igi\u0107 in 1986 and published in his 1987 book in a quixotic attempt to mend the linguistic differences and ambiguities between the two alphabets, carefully avoiding graphemes that look alike and following the principle of 'one sound, one letter' already accomplished by the Cyrillic alphabet.\nUnicode has separate characters for the digraphs lj (\u01c7, \u01c8, \u01c9), nj (\u01ca, \u01cb, \u01cc) and d\u017e (\u01c4, \u01c5, \u01c6).\nDialectology.\nSouth Slavic historically formed a dialect continuum, i.e. each dialect has some similarities with the neighboring one, and differences grow with distance. However, migrations from the 16th to 18th centuries resulting from the spread of Ottoman Empire on the Balkans have caused large-scale population displacement that broke the dialect continuum into many geographical pockets. Migrations in the 20th century, primarily caused by urbanization and wars, also contributed to the reduction of dialectal differences.\nThe primary dialects are named after the most common question word for \"what\": Shtokavian uses the pronoun \"\u0161to\" or \"\u0161ta\", Chakavian uses \"\u010da\" or \"ca\", Kajkavian (\"kajkavski\"), \"kaj\" or \"kej\". In native terminology they are referred to as \"nar(j)e\u010dje\", which would be equivalent of \"group of dialects\", whereas their many subdialects are referred to as \"dijalekti \"\"dialects\" or \"govori \"\"speeches\".\nThe pluricentric Serbo-Croatian standard language and all four contemporary standard variants are based on the Eastern Herzegovinian subdialect of Neo-Shtokavian. Other dialects are not taught in schools or used by the state media. The Torlakian dialect is often added to the list, though sources usually note that it is a transitional dialect between Shtokavian and the Bulgaro-Macedonian dialects.\nThe Serbo-Croatian dialects differ not only in the question word they are named after, but also heavily in phonology, accentuation and intonation, case endings and tense system (morphology) and basic vocabulary. In the past, Chakavian and Kajkavian dialects were spoken on a much larger territory, but have been replaced by \u0160tokavian during the period of migrations caused by Ottoman Turkish conquest of the Balkans in the 15th and the 16th centuries. These migrations caused the koin\u00e9isation of the Shtokavian dialects, that used to form the West Shtokavian (more closer and transitional towards the neighbouring Chakavian and Kajkavian dialects) and East Shtokavian (transitional towards the Torlakian and the whole Bulgaro-Macedonian area) dialect bundles, and their subsequent spread at the expense of Chakavian and Kajkavian. As a result, \u0160tokavian now covers an area larger than all the other dialects combined, and continues to make its progress in the enclaves where non-literary dialects are still being spoken.\nThe differences among the dialects can be illustrated on the example of Schleicher's fable. Diacritic signs are used to show the difference in accents and prosody, which are often quite significant, but which are not reflected in the usual orthography.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nClassification by \"jat\" reflex.\nA series of isoglosses crosscuts the main dialects. The modern reflexes of the long Common Slavic vowel \"jat\", usually transcribed *\u011b, vary by location as /i/, /e/, and /ije/ or /je/. Local varieties of the dialects are labeled Ikavian, Ekavian, and Ijekavian, respectively, depending on the reflex. The long and short \"jat\" is reflected as long or short */i/ and /e/ in Ikavian and Ekavian, but Ijekavian dialects introduce a \"ije\"/\"je\" alternation to retain a distinction.\nStandard Croatian and Bosnian are based on Ijekavian, whereas Serbian uses both Ekavian and Ijekavian forms (Ijekavian for Bosnian Serbs, Ekavian for most of Serbia). Influence of standard language through state media and education has caused non-standard varieties to lose ground to the literary forms.\nThe jat-reflex rules are not without exception. For example, when short \"jat\" is preceded by \"r\", in most Ijekavian dialects developed into /re/ or, occasionally, /ri/. The prefix \"pr\u011b-\" (\"trans-, over-\") when long became \"pre-\" in eastern Ijekavian dialects but to \"prije-\" in western dialects; in Ikavian pronunciation, it also evolved into \"pre-\" or \"prije-\" due to potential ambiguity with \"pri-\" (\"approach, come close to\"). For verbs that had \"-\u011bti\" in their infinitive, the past participle ending \"-\u011bl\" evolved into \"-io\" in Ijekavian Neo-\u0160tokavian.\nThe following are some examples:\nSociolinguistic debate.\nThe nature and classification of Serbo-Croatian has been the subject of long-standing sociolinguistic debate. The question is whether Serbo-Croatian should be called a single language or a cluster of closely related languages.\nViews of linguists in the former Yugoslavia.\nViews of Croatian linguists.\nA prevailing view among Croatian linguists is that there has never been a Serbo-Croatian language, but two different standard languages that overlapped sometime in the course of history. However, Croatian linguist Snje\u017eana Kordi\u0107 has been leading an academic discussion on this issue in the Croatian journal \"Knji\u017eevna republika\" from 2001 to 2010. In the discussion, she shows that linguistic criteria such as mutual intelligibility, the huge overlap in the linguistic system, and the same dialect basis of the standard language are evidence that Croatian, Serbian, Bosnian and Montenegrin are four national variants of the pluricentric Serbo-Croatian language. In 2010, Croatian writer Igor Mandi\u0107 described the debate as \"the longest, the most serious and most acrid (...) in 21st-century Croatian culture\". Inspired by that discussion, a monograph on language and nationalism has been published.\nSome Croatian linguists, like Kordi\u0107, continue to argue that Serbo-Croatian is a single language. They argue that the Serbo-Croatian standard varieties\u2014Bosnian, Croatian, Montenegrin, and Serbian\u2014are completely mutually intelligible. In addition, Gaj's Latin and Serbian Cyrillic alphabets perfectly match each other due to the work of Ljudevit Gaj and Vuk Karad\u017ei\u0107. Linguists supporting this perspective often cite the Swadesh list of 100 basic vocabulary items, which are identical across all four Serbo-Croatian varieties. According to Swadesh's criteria, an 81% overlap is sufficient to classify varieties as a single language. Furthermore, the standard varieties are typologically and structurally nearly identical in terms of grammar, including morphology and syntax. Serbo-Croatian was standardized in the mid-19th century, and subsequent efforts to dissolve its linguistic unity are seen by some scholars as politically motivated. According to phonology, morphology, and syntax, these standard varieties are considered part of the single language as they are all based on the \u0160tokavian dialect.\nOn the other hand, a number of Croatian linguists argue against the view that Serbo-Croatian constitutes a single language. They acknowledge that similar arguments are made for other official standards derived from nearly identical material bases, such as Malaysian Malay and Indonesian (together called Malay), or Hindi and Urdu (together called Hindustani). However, they argue that these arguments have flaws, as phonology, morphology, and syntax are not the only defining features of a language. Other fields\u2014semantics, pragmatics, stylistics, and lexicology\u2014also exhibit differences. However, that is the case with other pluricentric languages. Some comparisons are drawn to the closely related North Germanic languages, although these languages are not fully mutually intelligible as the Serbo-Croatian standard varieties are.\nAdditionally, it is argued that the standardization of the Croatian language was a gradual process spanning several centuries. Croatian drew on Chakavian and Kajkavian influences, on the Dubrovnik subdialect\u2014a specific western idiom of the Eastern Herzegovinian dialect rooted in Western Shtokavian\u2014and on Western Shtokavian more generally. By contrast, Serbian draws primarily from Eastern Shtokavian, which includes the Eastern Herzegovinian dialect. Since the Croatian used in early Ragusan literature (e.g., in the works of Dr\u017ei\u0107 and Gunduli\u0107 in the 16th and 17th centuries) is virtually the same as the contemporary standard Croatian, aside from archaisms, the 19th-century formal standardization is considered by Croatian linguists as the final step in a process that had already lasted for over three centuries.\nViews of Serbian linguists.\nIn 2021, the Board for Standardization of the Serbian Language issued an opinion that Serbo-Croatian is one language, and that it should be referred to as \"Serbian language\", while \"Croatian\", \"Bosnian\" and \"Montenegrin\" are to be considered merely local names for Serbian language. This opinion was widely criticized by Croatian government and representatives of the Croatian minority in Serbia. Serbian linguist Ranko Bugarski called this opinion \"absurd\" and \"legacy of the 19th century linguistics\". He said that Serbo-Croatian should be considered one language in a scientific sense under the \"Serbo-Croatian\" label, but four different languages in an administrative sense. Legally, Croatian, Bosnian and Montenegrin are all officially recognized minority languages in Serbia. The Serbian Government also officially recognized Bunjevac language as a standard minority language in 2018 and was approved by the Serbian Ministry of Education for learning in schools.\nViews within nationalist linguistics.\nIn nationalist linguistics exist conflicting views on shared or related linguistical heritage. Those nationalists among the Croats conflictingly claim either that they speak an entirely separate language from Serbs and Bosniaks or that these two peoples have, due to the longer literary and lexicographic tradition of popular language among Croats, somehow \"borrowed\" their standard languages from them (e.g. Serbian literature until early-19th century was primarily written in Serbian recension of Church Slavonic and Slavonic-Serbian). There's a common debate about positive or negative influence of the Croatian Vukovians, and perception that Vuk Karad\u017ei\u0107 invented the Greater Serbian linguistic ideology which is culturally appropriating Croatian language/dialects and literary tradition (although a great part of the criticism should be directed to the early Slavists instead). Bosniak nationalists claim that both Croats and Serbs have \"appropriated\" the Bosnian language, since Ljudevit Gaj and Vuk Karad\u017ei\u0107 preferred the Neo-\u0160tokavian Ijekavian dialect, widely spoken in Bosnia and Herzegovina, as the basis for language standardization. Whereas the nationalists among the Serbs claim either that any divergence in the standard language is artificial, and that the whole Shtokavian dialect is Serbian (and hence the Croatian, Bosnian and Montenegrin standard languages are variations of the Serbian language), and only the Chakavian and Kajkavian dialects are Croatian, in more extreme formulations accusing the Croats to have \"taken\" or \"stolen\" their language from the Serbs.\nViews of international linguists.\nLinguist Enisa Kafadar argues that there is only one Serbo-Croatian language with several varieties. This has made it possible to include all four varieties in new grammars of the language. Daniel Bun\u010di\u0107 concludes that it is a pluricentric language, with four standard variants spoken in Serbia, Croatia, Montenegro, and Bosnia-Herzegovina. The mutual intelligibility between their speakers \"exceeds that between the standard variants of English, French, German, or Spanish\". \"There is no doubt of the near 100% mutual intelligibility of (standard) Croatian and (standard) Serbian, as is obvious from the ability of all groups to enjoy each others' films, TV and sports broadcasts, newspapers, rock lyrics etc.\" Other linguists have argued that the differences between the variants of Serbo-Croatian are less significant than those between the variants of English, German, Dutch, and Hindustani.\nAmong pluricentric languages, Serbo-Croatian was the only one with a pluricentric standardisation within one state. The dissolution of Yugoslavia has made Serbo-Croatian even more of a typical pluricentric language, since the variants of other pluricentric languages are also spoken in different states.\nAs in other pluricentric languages, all Serbo-Croatian standard varieties are based on the same dialect (the Eastern Herzegovinian subdialect of the Shtokavian dialect) and consequently, according to the sociolinguistic definitions, constitute a single pluricentric language (and not, for example, several Ausbau languages). According to linguist John Bailyn, \"An examination of all the major 'levels' of language shows that BCS is clearly a single language with a single grammatical system.\"\nThe prevailing view among Croatian linguists\u2014that there is no single Serbo-Croatian language but rather several different standard languages\u2014has been criticized by German linguist Bernhard Gr\u00f6schel in his monograph \"Serbo-Croatian Between Linguistics and Politics\".\nThe use of \"Serbo-Croatian\" as a linguistic label has been the subject of long-standing controversy. Linguist Wayles Browne calls it a \"term of convenience\" and notes the difference of opinion as to whether it comprises a single language or a cluster of languages. Ronelle Alexander refers to the national standards as three separate languages, but also notes that the reasons for this are complex and generally non-linguistic. She calls BCS (her term for Serbo-Croatian) a single language for communicative linguistic purposes, but three separate languages for symbolic non-linguistic purposes.\nViews of international organizations.\nWhile it operated, the International Criminal Tribunal for the former Yugoslavia translated court proceedings and documents into what it referred to as \"Bosnian/Croatian/Serbian\", usually abbreviated as BCS. Translators were employed from all regions of the former Yugoslavia and all national and regional variations were accepted, regardless of the nationality of the person on trial (sometimes against a defendant's objections), on the grounds of mutual intelligibility.\nSince 18 February 2000, the ISO 639 classification has recognized Serbo-Croatian as a macrolanguage, deprecating its original ISO 639-1 code . In ISO 639-3, Serbo-Croatian is assigned the code , which has no equivalent in ISO 639-2.\nAlthough the ISO 639\u20111 code has been deprecated, it remains recognized as an IETF language tag under BCP\u202f47.\nThe International Organization for Standardization (ISO) has also defined a Universal Decimal Classification (UDC) number for the Serbo-Croatian language group (811.163.4), with subdivisions for Serbian (811.163.41) and Croatian (811.163.42).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27735", "revid": "93143", "url": "https://en.wikipedia.org/wiki?curid=27735", "title": "List of science-fiction awards", "text": ""}
{"id": "27737", "revid": "140154", "url": "https://en.wikipedia.org/wiki?curid=27737", "title": "Saint Kitts", "text": "Island in the West Indies; part of the Federation of St. Kitts and Nevis\nSaint Kitts, officially Saint Christopher, is an island in the West Indies. The west side of the island borders the Caribbean Sea, and the eastern coast faces the Atlantic Ocean. Saint Kitts and the neighbouring island of Nevis constitute one country: the Federation of Saint Kitts and Nevis. Saint Kitts and Nevis are separated by a shallow channel known as \"The Narrows\".\nSaint Kitts became home to the first Caribbean British and French colonies in the mid-1620s. Along with the island of Nevis, Saint Kitts was a member of the British West Indies until gaining independence on 19 September 1983.\nThe island is one of the Leeward Islands in the Lesser Antilles. It is situated about southeast of Miami, Florida, US. The land area of Saint Kitts is about , being approximately long and on average about across.\nSaint Kitts has a population of about 40,000, the majority of whom are of African descent. The primary language is English, with a literacy rate of approximately 98%. Residents call themselves \"Kittitians\". The island is named after the Christian Saint Christopher; \"Kit\" was formerly a common diminutive of \"Christopher\".\nBrimstone Hill Fortress National Park, a UNESCO World Heritage Site, is the largest fortress ever built in the Eastern Caribbean. The island of Saint Kitts is home to the Warner Park Cricket Stadium, which was used to host 2007 Cricket World Cup matches. This made Saint Kitts and Nevis the smallest nation to ever host a World Cup event. Saint Kitts is also home to several institutions of higher education, including Ross University School of Veterinary Medicine, Windsor University School of Medicine, and the University of Medicine and Health Sciences.\nGeography.\nThe capital of the two-island nation, and also its largest port, is the town of Basseterre on Saint Kitts. There is a modern facility for handling large cruise ships there. A ring road goes around the perimeter of the island with smaller roads branching off it; the interior of the island is too steep for habitation.\nSaint Kitts is away from Sint Eustatius to the north and from Nevis to the south. St. Kitts has three distinct groups of volcanic peaks: the North West or Mount Misery Range; the Middle or Verchilds Range and the South East or Olivees Range. The highest peak is Mount Liamuiga, formerly Mount Misery, a dormant volcano high.\nGeology.\nThe youngest volcanic centre is Mt. Liamuiga, in diameter and rising to an elevation of . Its last eruption was 1,620 years ago, corresponding with the Steel Dust series of pyroclastic deposits on the western flank. The Mansion Series of pyroclastic deposits and andesite with basalt layers occur on the northern flank, along with mudflows. This volcano has a crater wide and deep, plus two distinct parasitic domes consisting primarily of andesite, Brimstone Hill and Sandy Point Hill which is coalesced with Farm Flat. Brimstone Hill is noted for having limestone on its flanks, which was dragged upward with the formation of the dome 44,400 years ago. Mt. Liamuiga partially overlays the Middle Range to the southeast. This Middle Range is another stratovolcano 976 m in height with a small summit crater containing a lake. Next in line is the South East Range, 1 Myr in age, consisting of four peaks. Ottley's dome and Monkey Hill dome are on the flanks, while the older volcanoes represented by Canada Hills, and Conaree Hills lie past the airport and Basseterre on the southeast flank. The Salt Dome Peninsula contains the oldest volcanic deposits, 2.3\u20132.77 Myr in age, consisting of at least nine Pelean domes rising up to in height, which includes Williams Hill and St. Anthony's Peak.\nHistory.\nDuring the last ice age, the sea level was up to lower and St. Kitts and Nevis were one island along with Saba and Sint Eustatius (also known as Statia).\nSt. Kitts was originally settled by pre-agricultural, pre-ceramic \"Archaic people\", who migrated south down the archipelago from Florida. In a few hundred years they disappeared, to be replaced by the ceramic-using and agriculturalist Saladoid people around 100 BC, who migrated to St. Kitts north up the archipelago from the banks of the Orinoco River in Venezuela. Around 800 AD, they were replaced by the Igneri people, members of the Arawak group.\nAround 1300 AD, the Kalinago, or Carib people arrived on the islands. These agriculturalists quickly dispersed the Igneri, and forced them northwards to the Greater Antilles. They named Saint Kitts \"Liamuiga\" meaning \"fertile island\", and would likely have expanded further north if not for the arrival of Europeans.\nA Spanish expedition under Christopher Columbus arrived and claimed the island for Spain in 1493.\nThe first English colony was established in 1623, followed by a French colony in 1625. The English and French briefly united to pre-empt a Kalinago ambush. They massacred the local Kalinago, and then partitioned the island, with the English colonists in the middle and the French on either end. In 1629, a Spanish force sent to clear the islands of foreign settlement seized St. Kitts. The English settlement was rebuilt following the 1630 peace between England and Spain.\nThe island alternated repeatedly between English (then British) and French control during the 17th and 18th centuries, as one power took the whole island, only to have it switch hands due to treaties or military action. Actions included the Siege of Brimstone Hill and the Battle of Saint Kitts. Parts of the island were heavily fortified, as exemplified by the UNESCO World Heritage Site at Brimstone Hill and the now-crumbling Fort Charles.\nSince 1783, Saint Kitts has been affiliated with the Kingdom of Great Britain, which became the United Kingdom.\nSlavery.\nThe island originally produced tobacco, but farmers switched to sugarcane in 1640 because of stiff competition from the colony of Virginia. The labour-intensive cultivation of sugar cane was the reason for the large-scale importation of African slaves. The importation began almost immediately upon the arrival of Europeans to the region even though sugarcane wasn't cultivated for another two hundred years on the island, leading some to discredit the earliest claims of imported African labour.\nThe purchasing of enslaved Africans was outlawed in the British Empire by an Act of Parliament in 1807. Slavery was abolished by an Act of Parliament which became law on 1 August 1834. This emancipation was followed by four years of forced enslavement (1834-1838) against which the nominally freed Africans on St. Kitts revolted and martial law was declared with British warships sent from Antigua to force the rebels back to the plantations. The four years of forced enslavement was referred to as the apprenticeship system and was put in place to protect the \"planters\" (plantation owners) from losing their free labour force.\n1 August is now celebrated as a public holiday and is called Emancipation Day. In 1883, Saint Kitts, Nevis, and Anguilla were all linked under one presidency, located on Saint Kitts, to the dismay of the Nevisians and Anguillans. Anguilla left this arrangement in 1971, after an armed raid on Saint Kitts on the 10th of June 1967.\nSugar production continued to dominate the local economy until 2005, when, after 365 years of having a monoculture, the government closed the sugar industry. This decision was made because of huge losses and European Union plans to greatly cut sugar prices.\nGovernment.\nFor purposes of governing, the island is divided into nine parishes:\nEconomy.\nSaint Kitts &amp; Nevis uses the Eastern Caribbean dollar, which maintains a fixed exchange rate of 2.7-to-one with the United States dollar. The US dollar is almost as widely accepted on the island as the Eastern Caribbean dollar.\nFor hundreds of years, Saint Kitts operated as a sugar monoculture, but due to decreasing profitability, the government closed the industry in 2005. Tourism is a major and growing source of income to the island, although the number and density of resorts is less than on many other Caribbean islands. Transportation, non-sugar agriculture, manufacturing and construction are the other growing sectors of the economy.\nSaint Kitts is dependent on tourism to drive its economy. Tourism has been increasing since 1978. In 2009, there were 587,479 arrivals to Saint Kitts compared to 379,473 in 2007, a growth of just under 40% in a two-year period. As tourism grows, the demand for vacation property increases in conjunction.\nSaint Kitts &amp; Nevis also acquires foreign direct investment from their unique citizenship-by-investment programme, outlined in their Citizenship Act of 1984. Interested parties can acquire citizenship if they pass the government's strict background checks and make an investment into an approved real estate development. Purchasers who pass government due diligence and make a minimum investment of US$400,000, into qualifying government-approved real estate, are entitled to apply for citizenship of the Federation of Saint Kitts and Nevis. Many projects are approved under the citizenship-by-investment programme.\nThe country hosts an annual St. Kitts Music Festival.\nTransportation.\nRobert L. Bradshaw International Airport serves Saint Kitts. \nThe Basseterre Ferry Terminal facilitates travel between Saint Kitts and sister island Nevis.\nThe narrow-gauge (30 inches) St. Kitts Scenic Railway circles the island and offers passenger service from its headquarters near the airport, although the service is geared more for tourists than as day-to-day transportation for residents. Built between 1912 and 1926 to transport sugar cane from farms to the sugar factory in Basseterre, since 2003 the railway has offered a 3.5-hour, 30-mile circle tour of the island on specially designed double-decker open-air coaches, with 12 miles of the trip being by bus.\nNotable natives and residents.\nSaint Kitts is or was the residence of:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27739", "revid": "20284886", "url": "https://en.wikipedia.org/wiki?curid=27739", "title": "Shogi", "text": "Japanese strategy board game\n, also known as Japanese chess, is a strategy board game for two players. It is one of the most popular board games in Japan and is in the same family of games as Western chess, chaturanga, xiangqi, Indian chess, Makruk, and janggi. \"Sh\u014dgi\" means general's (\"sh\u014d\" ) board game (\"gi\" ).\nShogi was the earliest historical chess-related game to allow captured pieces to be returned to the board by the capturing player. This \"drop rule\" is speculated to have been invented in the 15th century and possibly connected to the practice of 15th-century mercenaries switching loyalties when captured instead of being killed.\nThe earliest predecessor of the game, chaturanga, originated in India in the 6th century, and the game was likely transmitted to Japan via China or Korea sometime after the Nara period. Shogi in its present form was played as early as the 16th century, while a direct ancestor without the drop rule was recorded from 1210 in a historical document \"Nich\u016breki\", which is an edited copy of \"Sh\u014dch\u016breki\" and \"Kaich\u016breki\" from the late Heian period (c. 1120).\nEquipment.\nTwo players face each other across a board composed of rectangles in a grid of 9 \"ranks\" (rows, ) by 9 \"files\" (columns, ) yielding an 81-square board. In Japanese they are called and , but in English they are conventionally referred to as Black and White, with Black being the first player.\nThe board is nearly always rectangular, and the rectangles are undifferentiated by marking or color. Pairs of dots mark the players' promotion zones.\nEach player has a set of 20 flat wedge-shaped pentagonal pieces of slightly different sizes. Except for the kings, opposing pieces are undifferentiated by marking or color. Pieces face \"forward\" by having the pointed side of each piece oriented toward the opponent's side \u2013 this shows who controls the piece during play. The pieces from largest (most important) to smallest (least important) are:\nSeveral of these names were chosen to correspond to their rough equivalents in international chess, and not as literal translations of the Japanese names.\nEach piece has its name written on its surface in the form of two \"kanji\" (Chinese characters used as syllabograms or as logograms to record texts in Old Japanese), usually in black ink. On the reverse side of each piece, other than the king and gold general, are one or two other characters, in amateur sets often in a different color (usually red); this side is turned face up during play to indicate that the piece has been promoted.\nIn some cases, the backsides of the King pieces (the narrow side which faces back toward the player during normal play) will display kanji containing additional information about the piece manufacturers.\nFollowing is a table of the pieces with their Japanese representations and English equivalents. The abbreviations are used for game notation and often when referring to the pieces in speech in Japanese.\nEnglish speakers sometimes refer to promoted bishops as \"horses\" and promoted rooks as \"dragons\", after their Japanese names, and generally use the Japanese term \"tokin\" for promoted pawns. Silver generals and gold generals are commonly referred to simply as \"silvers\" and \"golds\", respectively.\nThe characters inscribed on the reverse sides of the pieces to indicate promotion may be in red ink, and are usually cursive. The characters on the backs of the pieces that promote to gold generals are cursive variants of 'gold', becoming more cursive (more abbreviated) as the value of the original piece decreases. These cursive forms have these equivalents in print: for promoted silver, for promoted knight, for promoted lance, and for promoted pawn (tokin). Another typographic convention has abbreviated versions of the original values, with a reduced number of strokes: for a promoted knight , for a promoted lance , and the as above for a promoted silver, but (a hiragana symbol for the syllable \"to\") for \"tokin\".\nThe suggestion that the Japanese characters have deterred Western players from learning shogi has led to \"Westernized\" or \"international\" pieces which use iconic symbols instead of characters. Most players soon learn to recognize the characters, however, partially because the traditional pieces are already iconic by size, with more powerful pieces being larger. As a result, Westernized pieces have never become popular. Bilingual pieces with both Japanese characters and English captions have been developed as have pieces with animal cartoons.\nSetup and gameplay.\nEach player sets up friendly pieces facing forward (toward the opponent).\nThat is, the first rank is\nOr\nA \"furigoma\" \u632f\u308a\u99d2 'piece toss' is used to decide who moves first. One of the players tosses five pawns. If the number of tokins (promoted pawns, \u3068) facing up is higher than unpromoted pawns (\u6b69), then the player who tossed the pawns plays \"gote\" \u5f8c\u624b 'white' (that is, getting the second move).\nAfter the piece toss \"furigoma,\" the game proceeds. If multiple games are played, then players alternate turns for who goes first in subsequent games. (The terms \"Black\" and \"White\" are used to differentiate sides although there is no difference in the color of the pieces.) For each turn, a player may either move a piece that is currently on the board (and potentially promote it, capture an opposing piece, or both) or else drop a piece that has been previously captured onto a square of the board. These options are explained below.\nRules.\nObjective.\nThe usual goal of a game is for one player to checkmate the other player's king, winning the game.\nMovement.\nMost shogi pieces can move only to an adjacent square. A few may move across the board, and one jumps over intervening pieces.\nThe lance, bishop, and rook are \"ranging\" pieces: They can move any number of squares along a straight line limited only by intervening pieces and the edge of the board. If an opposing piece intervenes, it may be captured by removing it from the board and replacing it with the moving piece. If a friendly piece intervenes, the moving piece must stop short of that square; if the friendly piece is adjacent, the moving piece may not move in that direction at all.\nA king (\u7389/\u738b) moves one square in any direction, orthogonal or diagonal.\nA rook (\u98db) moves any number of squares in an orthogonal direction.\nA bishop (\u89d2) moves any number of squares in a diagonal direction. Because they cannot move orthogonally, the players' unpromoted bishops can reach only half the squares of the board, unless one is captured and then dropped.\nA gold general (\u91d1) moves one square orthogonally, or one square diagonally forward, giving it six possible destinations. It cannot move diagonally backwards.\nA silver general (\u9280) moves one square diagonally, or one square straight forward, giving it five possible destinations. Because an unpromoted silver can retreat more easily than a promoted one, it is common to leave a silver unpromoted at the far side of the board. (See Promotion).\nA knight (\u6842) jumps at an angle intermediate to orthogonal and diagonal, amounting to one square straight forward plus one square diagonally forward, in a single move. Thus the knight has two possible forward destinations. Unlike international chess knights, shogi knights cannot move to the sides or in a backwards direction. The knight is the only piece that ignores intervening pieces on the way to its destination. It is not blocked from moving if the square in front of it is occupied, but neither can it capture a piece on that square. It is often useful to leave a knight unpromoted at the far side of the board. A knight \"must\" promote, however, if it reaches either of the two furthest ranks. (See Promotion.)\nA lance (\u9999) moves just like the rook except it cannot move backwards or to the sides. It is often useful to leave a lance unpromoted at the far side of the board. A lance \"must\" promote, however, if it reaches the furthest rank. (See Promotion.)\nA pawn (\u6b69) moves one square straight forward. It cannot retreat. Unlike international chess pawns, shogi pawns capture the same way as they move. A pawn \"must\" promote if it arrives at the furthest rank. (See Promotion.) In practice, however, a pawn is usually promoted whenever possible. There are two restrictions on where a pawn may be dropped. (See Drops.)\nAll pieces but the knight move either horizontally, vertically, or diagonally. These directions cannot be combined in a single move; one direction must be chosen.\nEvery piece blocks the movement of all other non-jumping pieces through the square it occupies.\nIf a piece occupies a legal destination for an opposing piece, it may be \"captured\" by removing it from the board and replacing it with the opposing piece. The capturing piece may not continue beyond that square on that turn. Shogi pieces capture the same as they move.\nNormally, when moving a piece, a player snaps it to the board with the ends of the fingers of the same hand. This makes a sudden sound effect, bringing the piece to the attention of the opponent. This is also true for capturing and dropping pieces. On a traditional \"shogi-ban\", the pitch of the snap is deeper, delivering a subtler effect.\nPromotion.\nA player's \"promotion zone\" consists of the furthest one-third of the board \u2013 the three ranks occupied by the opponent's pieces at setup. The zone is typically delineated on shogi boards by two inscribed dots. When a piece is moved, if part of the piece's path lies within the promotion zone (that is, if the piece moves into, out of, or wholly within the zone; but \"not\" if it is dropped into the zone \u2013 see Drops), then the player has the option to \"promote\" the piece at the end of the turn. Promotion is indicated by turning the piece over after it moves, revealing the character of the promoted piece.\nPromoting a piece is usually not compulsory; however, if a pawn or lance is moved to the furthest rank, or a knight is moved to either of the two furthest ranks, that piece \"must\" promote (otherwise, it would have no legal move on subsequent turns). A silver general is never required to promote, and it is often advantageous to keep a silver general unpromoted (it is easier, for example, to extract an unpromoted silver from behind enemy lines: a promoted silver, with only one line of retreat, can be easily blocked.) Rooks, bishops and pawns are almost always promoted, as these pieces do not lose any of their powers upon promotion.\nPromoting a piece changes the way it moves. The various pieces promote as follows:\nWhen captured, a piece loses its promoted status. Otherwise promotion is permanent.\nA promoted rook (literally dragon king (); shortended forms: and ) moves as a rook and as a king. It is commonly referred to as dragon.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nA promoted bishop (literally dragon horse (); shortened form ) moves as a bishop and as a king. It is commonly referred to as horse.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nA promoted silver (\u6210\u9280 \"narigin\"; alternate forms: \u5168, cursive \u91d1), a promoted knight (\u6210\u6842 \"narikei\"; alternate forms: \u572d, \u4eca, cursive \u91d1), a promoted lance (\u6210\u9999 \"nariky\u014d\"; alternate forms: \u674f, \u4edd, cursive \u91d1) and a promoted pawn (\u3068\u91d1 \"tokin\"; alternate forms: \u3068, \u4e2a) all move the same way as a gold general. The promoted pawn is often called by its Japanese name tokin, even by non-Japanese players.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nDrops.\nCaptured pieces are retained in hand and can be brought back into play under the capturing player's control. The Japanese term for \"piece(s) in hand\" is either \u6301\u3061\u99d2 \"mochigoma\" or \u624b\u99d2 \"tegoma.\" On any turn, instead of moving a piece on the board, a player may select a piece in hand and place it \u2013 unpromoted side up and facing the opposing side \u2013 on any empty square. The piece is then one of that player's active pieces on the board and can be moved accordingly. This is called \"dropping\" the piece, or simply, a \"drop\". A drop counts as a complete move.\nA drop cannot capture a piece, nor does dropping within the promotion zone result in immediate promotion. Capture and/or promotion may occur normally, however, on subsequent moves of the piece.\nRestrictions. There are three restrictions on dropping pieces; the last two of these apply only to pawns.\nA corollary of the second restriction is that a player with an unpromoted pawn on every file is unable to drop a pawn anywhere. For this reason, it is common to sacrifice a pawn in order to gain flexibility for drops.\nCaptured pieces are typically kept on a wooden stand (\u99d2\u53f0 \"komadai)\" which is traditionally placed so that its bottom-left corner aligns with the bottom-right corner of the board from the perspective of each player. It is not permissible to hide pieces from full view.\nIt is common for players to swap bishops, which oppose each other across the board, early in the game. This leaves each player with a bishop in hand to be dropped later. The ability for drops in shogi gives the game tactical richness and complexity. The fact that no piece ever goes entirely out of play accounts for the rarity of draws.\nCheck.\nWhen a player's move threatens to capture the opposing king on the next turn, the move is said to \"give check\" to the king and the king is said to be \"in check.\" If a player's king is in check, that player's responding move must remove the check. Ways to remove a check include moving the king away from the threat, capturing the threatening piece, or placing another interposing piece between the king and the threatening piece.\nTo announce check in Japanese, one can say \"\u014dte\" (), however, this is an influence of international chess and is not required, even as a courtesy. It may be common to announce \"\u014dte\" in beginner matches or for local rules to dictate that you have to announce it. Announcing a check vocally is unheard of in competitive tournaments.\nEnd of the game.\nThe usual way for shogi games to end is for one side to checkmate the other side's king, after which the losing player will be given the opportunity to admit defeat. Unlike western chess or xiangqi, checkmate is almost always the result in shogi since pieces never retire from play, which gives the players a sufficient number of pieces to deliver checkmate. That said, there are three other possible ways for a game to end: \"repetition\" ( \"sennichite\"), \"impasse\" ( \"jish\u014dgi\"), and an \"illegal move\" ( \"hansokute\"). The first two \u2013 repetition and impasse \u2013 are particularly uncommon. Illegal moves are also uncommon in professional games although this may not be true with amateur players (especially beginners).\nUnlike western chess, there is no tradition of offering a mutual draw by agreement.\nCheckmate.\nIf the king is in check and there is no possible move which could protect the king, the move is said to \"checkmate\" (\"tsumi\" \u8a70\u307f) the king. Checkmate effectively means that the opponent wins the game as the player would have no remaining legal moves. (See also: tsumeshogi, hisshi.)\nResignation.\nThe losing player will usually resign when the situation is thought to be hopeless and may declare the resignation at any time during their turn. Although a player may resign just after they are checkmated, playing up to the checkmate point rarely occurs in practice as players normally resign as soon as a loss is deemed inevitable. Similarly, if a player were to lose in an Entering King situation (see section below) by having less than 24 points (or by any of the other Impasse rules used by amateurs), then the player will usually resign before that point.\nIn traditional tournament play, a formal resignation is required \u2013 that is, a checkmate is not a sufficient condition for winning. The resignation is indicated by bowing and/or saying 'I lost' (\u8ca0\u3051\u307e\u3057\u305f \"makemashita\") and/or placing the right hand over the piece stands. Placing the hand over the piece stand is a vestige of an older practice of gently dropping one's pieces in hand over the board in order to indicate resignation. In western practice, a handshake may be used.\nIllegal move.\nIn professional and serious (tournament) amateur games, a player who makes an illegal move loses immediately. The loss stands even if play continued and the move was discovered later in game. However, if neither the opponent nor a third party points out the illegal move and the opponent later resigned, the resignation stands as the result.\nIllegal moves include:\nIn friendly amateur games, this rule is sometimes relaxed, and the player may be able to take back the illegal move and replay a new legal move.\nIn particular, the Two Pawn violation is the most common illegal move played by professional players. The Two Pawn violation played by Takahiro Toyokawa (against K\u014dsuke Tamura) in the 2004 NHK Cup is infamous since it was broadcast on television. On the 109th move, Toyokawa (playing as Black) dropped a pawn to the 29\u00a0square while he already had a pawn in play on the board on the 23\u00a0square and, thus, lost the game.\nRepetition (draw).\nIf the same game position occurs four times with the same player to move and the same pieces in hand for each player, then the game ends in a repetition draw (\u5343\u65e5\u624b \"sennichite,\" lit. \"moves for a thousand days\"), as long as the positions are not due to perpetual check. Perpetual check (\u9023\u7d9a\u738b\u624b\u306e\u5343\u65e5\u624b) is an illegal move (see above), which ends the game in a loss in tournament play.\nIn professional shogi, a repetition draw outcome is not a final result as draws essentially do not count. Each game can only end in either a win or loss. In the case of a repetition draw, professional shogi players will have to immediately play a subsequent game (or as many games as necessary) with sides reversed in order to obtain a true win outcome. (That is, the player who was White becomes Black, and vice versa.) Also, depending on the tournament, professional players play the subsequent game in the remainder of the allowed game time.\nThus, aiming for a repetition draw may be a possible professional strategy for the White player in order to play the second replay game as Black, which has a slight statistical advantage and/or greater initiative. For instance, Bishop Exchange Fourth File Rook is a passive strategy for White with the goal of a repetition draw (as it requires two tempo losses \u2013 swinging the rook and trading the bishops) while it is a very aggressive strategy if played by Black.\nRepetition draws are rare in professional shogi occurring in about 1\u20132% of games and even rarer in amateur games. In professional shogi, repetition draws usually occur in the opening as certain positions are reached that are theoretically disadvantaged for both sides (reciprocal zugzwang). In amateur shogi, repetition draws tend to occur in the middle or endgame as a result of player errors.\nImpasse.\nThe game reaches an Impasse or Deadlock (\u6301\u5c06\u68cb \"jish\u014dgi\") if both kings have advanced into their respective promotion zones \u2013 a situation known as \u76f8\u5165\u7389 (\"ai-ny\u016b gyoku\" \"double entering kings\") \u2013 and neither player can hope to mate the other or to gain any further material. An Impasse can result in either a win or a draw. If an Impasse happens, the winner is decided as follows: each player agrees to an Impasse, then each rook or bishop, promoted or not, scores 5 points for the owning player, and all other pieces except kings score 1 point each. A player scoring fewer than 24 points loses. (Note that in the start position, both players have 27 points each.) If neither player has fewer than 24, the game is no contest \u2013 a draw. In professional shogi, an Impasse result is always a draw since a player that cannot obtain the 24 points will simply resign. \"Jish\u014dgi\" is considered an outcome in its own right rather than no contest, but there is no practical difference. As an Impasse needs to be agreed on for the rule to be invoked, a player may refuse to do so and attempt to win the game in future moves. If that happens, there is no official rule about the verdict of the game.\nHowever, in amateur shogi, there are different practices most of which force a win resolution to the Impasse in order to avoid a draw result.\nThe first draw by Impasse occurred in 1731 in a bishop handicap game between the seventh Lifetime Meijin, S\u014dkan It\u014d II, and his brother, S\u014dkei \u014chashi.\nEntering King.\nAs a practical matter, when an opponent's king has entered a player's own territory especially with supporting defending pieces, the opponent's king is often very difficult to mate given the forward attacking nature of most shogi pieces. This state is referred to as entering king (\u5165\u7389 \"ny\u016b gyoku\"). If both players' kings are in entering king states, the game becomes more likely to result in an impasse.\nIn the adjacent diagram example, although White's king is in a strong Bear-in-the-hole castle, Black's king has entered White's territory making it very difficult to mate. Therefore, this position favors Black.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nAn example of Entering King occurred in the fourth game of the 60th \u014ci title match between Masayuki Toyoshima and Kazuki Kimura held on August 20\u201321, 2019. After being unsuccessful in attacking Kimura and also in defending his own king within his camp, Toyoshima (playing as White) moved his king away from Kimura's attacking pieces by fleeing up the second file, ultimately entering his king into Kimura's camp by move 150. Although Toyoshima had achieved Entering King, he still had only 23 points\u2014one point shy of the required 24 points for an Impasse draw\u2014while Kimura (Black) had 31 points. Toyoshima then spent the next 134 moves trying to bring his point total, which fluctuated between 17 and 23, up to the necessary 24. By the 231st move, the game had reached a Double Entering Kings state, and by move 285 Kimura had successfully kept Toyoshima's point total at bay. Here, Toyoshima with 20 points (and Kimura at 34 points) resigned. Incidentally, this game broke the record of longest game in a title match.\nAmateur resolutions.\nFor amateur games, there are various guidances with little standardization. Fairbairn reports a practice in the 1980s (considered a rule by the now defunct Shogi Association for The West) where the dispute is resolved by either player moving all friendly pieces into the promotion zone and then the game ends with points tallied.\nAnother resolution is the 27-Point (27\u70b9\u6cd5) rule used for some amateur tournaments. One version of this is simply the player who has 27 or more points is the winner of the Impasse. Another version is a 27-Point Declaration rule. For instance, the Declaration rule on the online shogi site, 81Dojo, is that the player who wants to declare an Impasse win must (i) declare an intention to win via Impasse, (ii) have the king in the enemy camp (the promotion zone for that player), (iii) 10 other pieces must be in the promotion zone, (iv) not be in check, (v) have time remaining, and (vi) must have 28 points if Black or 27 points if White. If all of these conditions are met, then the Impasse declarer will win the game regardless of whether the opponent objects.\nYet another resolution to Impasse is the so-called Try Rule (\u30c8\u30e9\u30a4\u30eb\u30fc\u30eb \"torair\u016bru\"). In this case, after both kings have entered their corresponding promotion zones, then the player who first moves the king to the opponent's king's start square (51 for Black, 59 for White) first will be the winner. As an example, the popular (Shogi Wars) app by HEROZ Inc. used the Try Rule up until 2014. (Now the app uses a variant of the 27-Point Declaration Rule \u2013 although it differs from the variant used on the 81Dojo site.) The idea of the \"Try Rule\" was taken from rugby football (see Try (rugby)).\nDraws in tournaments.\nIn professional tournaments, the rules typically require drawn games to be replayed with sides reversed, possibly with reduced time limits. They are rare compared to chess and xiangqi, occurring at a rate of 1\u20132% even in amateur games.\nThe 1982 \"Meijin\" title match between Makoto Nakahara and Hifumi Katoh was unusual in this regard with an impasse draw in the first (Double Fortress) game on April 13\u201314 (only the fifth draw in the then 40-year history of the tournament). This game (with Katoh as Black) lasted for 223 moves with 114 minutes spent pondering a single move. One of the reasons for the length of this game was that White (Nakahara) was very close to falling below the minimum of 24 points required for a draw. Thus, the end of the endgame was strategically about trying to keep White's points above the 24-point threshold. In this match, \"sennichite\" occurred in the sixth and eighth games. Thus, this best-of-seven match lasted eight games and took over three months to finish; Black did not lose a single game and the eventual victor was Katoh at 4\u20133.\nTime control.\nProfessional games are timed as in international chess, but professional shogi players are almost never expected to keep time in their games. Instead a timekeeper is assigned, typically an apprentice professional. Time limits are much longer than in international chess (9 hours a side plus extra time in the prestigious \"Meijin\" title match), and in addition \"by\u014dyomi\" (literally \"second counting\") is employed. This means that when the ordinary time has run out, the player will from that point on have a certain amount of time to complete every move (a \"by\u014dyomi\" period), typically upwards of one minute. The final ten seconds are counted down, and if the time expires the player to move loses the game immediately. Amateurs often play with electronic clocks that beep out the final ten seconds of a \"by\u014dyomi\" period, with a prolonged beep for the last five.\nPlayer rank and handicaps.\nAmateur players are ranked from 15 \"ky\u016b\" to 1 ky\u016b and then from 1 \"dan\" to 8 dan. Amateur 8 dan was previously only honorarily given to famous people. While it is now possible to win amateur 8 dan by actual strength (winning amateur Ryu-oh 3 times), this has yet to be achieved.\nProfessional players operate with their own scale, from 6 ky\u016b to 3 dan for pro-aspiring players and professional 4 dan to 9 dan for formal professional players. Amateur and professional ranks are offset (with amateur 4 dan being equivalent to professional 6 ky\u016b).\nHandicaps.\nShogi has a handicap system (like go) in which games between players of disparate strengths are adjusted so that the stronger player is put in a more disadvantageous position in order to compensate for the difference in playing levels. In a handicap game, one or more of White's pieces are removed from the setup, and instead White plays first.\nThe imbalance created by this method of handicapping is not as strong as it is in western chess because material advantage is not as powerful in shogi.\nNotation.\nThere are two common systems used to notate piece movements in shogi game records. One is used in Japanese language texts while a second was created for western players by George Hodges and Glyndon Townhill in the English language. This system was updated by Hosking to be closer to the Japanese standard (two numerals). Other systems are used to notate shogi board positions. Unlike chess, the origin (11 square) is at the top right of a printed position rather than the bottom left.\nIn western piece movement notation, the format is the piece initial followed by the type of movement and finally the file and rank where the piece moved to. The piece initials are K (King), R (Rook), B (Bishop), G (Gold), S (Silver), N (Knight), L (Lance), and P (Pawn). Simple movement is indicated with -, captures with x, and piece drops with *. The files are indicated with numerals 1\u20139. The older Hodges standard used letters a\u2013i for ranks, and the newer Hosking standard also uses numerals 1\u20139 for the ranks. Thus, Rx24 indicates 'rook captures on 24'. Promoted pieces are notated with + prefixed to the piece initial (e.g. +Rx24). Piece promotion is also indicated with + (e.g. S-21+) while unpromotion is indicated with = (e.g. S-21=). Piece ambiguity is resolved by notating which square a piece is moving from (e.g. N65-53+ means 'knight from 65 moves to 53 and promotes,' which distinguishes it from N45-53+).\nThe Japanese notation system uses Japanese characters for pieces and promotion indication and uses Japanese numerals instead of letters for ranks. Movement type aside from drops is not indicated, and the conventions for resolving ambiguity are quite different from the western system. As examples, the western Rx24 would be ' in Japanese notation, +Rx24 would be ', S-21+ would be ', S-21= would be ', and N65-53+ would be ' showing that the leftmost knight jumped (implicitly from the 65 square), which distinguishes it from ' in which the rightmost knight jumped. However, it is becoming common to use Arabic numerals for both files and ranks, for example ' or '.\nAlthough not strictly part of the notational calculus for games, game results are indicated in Japanese newspapers, websites, etc. with wins indicated by a white circle and losses indicated by a black circle.\nStrategy and tactics.\nBear-in-the-hole Static Rook by white against High Mino Castle 4th File Ranging Rook by black\nShogi is similar to chess but has a much larger game tree complexity because of the use of drops, greater number of pieces, and larger board size. In comparison, shogi games average about 140 (half-)moves per game (or 70 chess move-pairs) whereas chess games average about 80 moves per game (or 40 chess move-pairs) and minishogi averages about 40 moves per game (or 20 chess move-pairs).\nLike chess, however, the game can be divided into the opening, middle game and endgame, each requiring a different strategy. The opening consists of arranging one's defenses usually in a castle and positioning for attack; the mid game consists of attempting to break through the opposing defenses while maintaining one's own; and the endgame starts when one side's defenses have been compromised.\nIn the adjacent diagram, Black has chosen a Ranging Rook position (specifically Fourth File Rook) where the rook has been moved leftward away from its starting position. Additionally, Black is using a Silver Crown castle, which is a type of fortification structure constructed with one silver and two gold pieces and the king moved inside of the fortification \u2013 the \"silver crown\" name comes from the silver being positioned directly above the king's head on the 27 square as if it were a crown. In the diagram, White has chosen a Static Rook position, in which the rook remains on its starting square. This Static Rook position is specifically a type of Counter-Ranging Rook position known as Bear-in-the-hole Static Rook that uses a Bear-in-the-hole castle. The Bear-in-the-hole fortification has the king moved all the way into very edge corner of the board on the 11 square as if it were a badger in a hole with a silver moved to the 22 square in order to close up the hole and additional reinforcing golds on 31 and 32 squares. This board position required 33 moves (or 12 move pairs as counted in western chess) to construct.\nEtiquette.\nShogi players are expected to follow etiquette in addition to rules explicitly described. Commonly accepted etiquette include the following:\nShogi piece sets may contain two types of king pieces, (king) and (jewel). In this case, the higher classed player, in either social or genuine shogi player rank, may take the king piece. For example, in titleholder system games, the current titleholder takes the king piece as the higher.\nThe higher-ranked (or older) player also sits facing the door of the room and is the person who takes the pieces out of the piece box.\nShogi does not have a touch-move rule as in western chess tournament play or chu shogi. However, in professional games, a piece is considered to be moved when the piece has been let go of. In both amateur and professional play, any piece may be touched in order to adjust its centralization within its square (to look tidy).\nTaking back moves (\u5f85\u3063\u305f \"matta\") in professional games is prohibited. However, in friendly amateur games in Japan, it is often permitted.\nProfessional players are required to follow several ritualistic etiquette prescriptions such as kneeling exactly 15 centimeters from the shogi board, sitting in the formal seiza position, etc.\nGame setup.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nTraditionally, the order of placing the pieces on the board is determined. There are two commonly used orders, the \"\u014chashi\" order \u5927\u6a4b\u6d41 and the \"It\u014d\" order \u4f0a\u85e4\u6d41. Placement sets pieces with multiples (generals, knights, lances) from left to right in all cases, and follows the order:\nIn ito, the player now places:\nIn ohashi, the player now places:\nFurigoma.\nAmong amateur tournaments, the higher-ranked player or defending champion performs the piece toss. In professional games, the furigoma is done on the behalf of the higher-ranked player/champion by the timekeeper who kneels by the side of the higher-ranked player and tosses the pawn pieces onto a silk cloth. In friendly amateur games, a player will ask the opponent to toss the pawns out of politeness. Otherwise, the person who tosses the pawns can be determined by Rock\u2013paper\u2013scissors.\nHistory.\nFrom \"The Chess Variant Pages\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt; The world's first chess variant, chaturanga arose in India in approximately the seventh century AD. From there it migrated both westward and northward, mutating along the way. The western branch became shatranj in Arabia and Orthodox Chess in Europe. The northern branch became xiangqi in China and janggi in Korea. Sometime in the tenth to twelfth centuries, 'chess' crossed the channel to Japan where it spawned a number of interesting variants. One of these was called 'Small Shogi'. Eventually, Small Shogi (though it went through many forms) won out over the larger variants and is now referred to simply as 'Shogi'. It is certain that Shogi in its present form was played in Japan as early as the 16th century.\nIt is not clear when chess was brought to Japan. The earliest generally accepted mention of shogi is (1058\u20131064) by Fujiwara Akihira. The oldest archaeological evidence is a group of 16 shogi pieces excavated from the grounds of K\u014dfuku-ji in Nara Prefecture. As it was physically associated with a wooden tablet written on in the sixth year of Tengi (1058), the pieces are thought to date from that period. These simple pieces were cut from a writing plaque in the same five-sided shape as modern pieces, with the names of the pieces written on them.\nThe dictionary of common folk culture, (c. 1210\u20131221), a collection based on the two works and , describes two forms of shogi, large \"(dai)\" shogi and small \"(sh\u014d)\" shogi. These are now called Heian shogi (or Heian small shogi) and Heian dai shogi. Heian small shogi is the version on which modern shogi is based, but the \"Nich\u016breki\" states that one wins if one's opponent is reduced to a single king, indicating that drops had not yet been introduced. According to Yasuji Shimizu, chief researcher at the Archaeological Institute of Kashihara, Nara Prefecture, the names of the Heian shogi pieces keep those of chaturanga (general, elephant, horse, chariot and soldier), and add to them five treasures of Buddhism (jade, gold, silver, cassia bark, and incense).\nAround the 13th century the game of dai shogi developed, created by increasing the number of pieces in Heian shogi, as was sho shogi, which added the rook, bishop, and drunken elephant from dai shogi to Heian shogi. The drunken elephant steps one square in any direction except directly backward, and promotes to the prince, which acts as a second king and must also be captured along with the original king for the other player to win. Around the 15th century, the rules of dai shogi were simplified, creating the game of chu shogi. Chu shogi, like its parent dai shogi, contains many distinct pieces, such as the queen (identical with Western chess) and the lion (which moves like a king, but twice per turn, potentially being able to capture twice, among other idiosyncrasies). The popularity of dai shogi soon waned in favour of chu shogi, until it stopped being played commonly. Chu shogi rivalled sho shogi in popularity until the introduction of drops in the latter, upon which standard shogi became ascendant, although chu shogi was still commonly played until about World War II, especially in Kyoto.\nIt is thought that the rules of standard shogi were fixed in the 16th century, when the drunken elephant was removed from the set of pieces present in sho shogi. There is no clear record of when drops were introduced, however.\nIn the Edo period, shogi variants were greatly expanded: tenjiku shogi, dai dai shogi, maka dai dai shogi, tai shogi, and taikyoku shogi were all invented. It is thought that these were played to only a very limited extent, however. Both standard shogi and Go were promoted by the Tokugawa shogunate. In 1612, the shogunate passed a law giving endowments to top shogi players (). During the reign of the eighth sh\u014dgun, Tokugawa Yoshimune, castle shogi tournaments were held once a year on the 17th day of Kannazuki, corresponding to November 17, which is Shogi Day on the modern calendar.\nThe title of \"meijin\" became hereditary in the \u014chashi and It\u014d families until the fall of the shogunate, when it came to be passed by recommendation. Today the title is used for the winner of the Meijin-sen competition, the first modern title match. From around 1899, newspapers began to publish records of shogi matches, and high-ranking players formed alliances with the aim of having their games published. In 1909, the was formed, and in 1924, the was formed. This was an early incarnation of the modern , or JSA, and 1924 is considered by the JSA to be the date it was founded.\nIn 1935, \"meijin\" Kinjir\u014d Sekine stepped down, and the rank of meijin came to be awarded to the winner of a . became the first Meijin under this system in 1937. This was the start of the (see titleholder system). After the war other tournaments were promoted to title matches, culminating with the in 1988 for the modern line-up of seven. About 200 professional shogi players compete. Each year, the title holder defends the title against a challenger chosen from knockout or round matches.\nAfter the Second World War, SCAP (occupational government mainly led by US) tried to eliminate all \"feudal\" factors from Japanese society and shogi was included in the possible list of items to be banned along with Bushido (philosophy of samurai) and other things. SCAP's reason for banning shogi was that the game uniquely utilized captured pieces. SCAP insisted that this could lead to the idea of prisoner abuse. K\u014dz\u014d Masuda, then one of the top professional shogi players, when summoned to the SCAP headquarters for an investigation, criticized such understanding of shogi, instead insisting that it was chess that potentially contained the idea of prisoner abuse, because opposing pieces are removed permanently, while shogi gives prisoners the chance to get back into the game. Masuda also argued that chess contradicts the ideal of gender equality in western society because the king shields himself behind the queen and runs away. Masuda later claimed his arguments eventually led to the exemption of shogi from the list of items to be banned.\nTournament play.\nThere are two organizations for shogi professional players in Japan: the JSA, and the , or LPSA. The JSA is the primary organization for men and women's professional shogi while the LPSA is a group of women professionals who broke away from the JSA in 2007 to establish their own independent organization. Both organize tournaments for their members and have reached an agreement to cooperate with each other to promote shogi through events and other activities. Top professional players are fairly well-paid from tournament earnings. In 2016, the highest tournament earners were Yoshiharu Habu and Akira Watanabe who earned \u00a591,500,000 and \u00a573,900,000. (The tenth highest earner, Kouichi Fukaura, won \u00a518,490,000.)\nThe JSA recognizes two categories of shogi professionals: , and . Sometimes \"kishi\" are addressed as , a term from Go used to distinguish \"kishi\" from other classes of players. JSA professional ranks and female professional ranks are not equivalent and each has their own promotion criteria and ranking system. In 2006, the JSA officially granted women \"professional status\". This is not equivalent, however, to the more traditional way of \"gaining professional status\", i.e., being promoted from the : leagues of strong amateur players aspiring to become a professional. Rather, it is a separate system especially designed for female professionals. Qualified amateurs, regardless of gender, may apply for the \"Shoreikai System\" and all those who successfully \"graduate\" are granted \"kishi\" status; however, no woman has yet to accomplish this feat (the highest women have reached is \"Shoreikai 3 \"dan\" league\" by Kana Satomi and Tomoka Nishiyama), so \"kishi\" is de facto only used to refer to male shogi professionals.\nThe JSA is the only body which can organize tournaments for professionals, e.g., the eight major tournaments in the titleholder system and other professional tournaments. In 1996, Yoshiharu Habu became the only \"kishi\" to hold seven major titles at the same time. For female professionals, both the JSA and LPSA organize tournaments, either jointly or separately. Tournaments for amateurs may be organized by the JSA and LPSA as well as local clubs, newspapers, private corporations, educational institutions or municipal governments for cities or prefectures under the guidance of the JSA or LPSA.\nSince the 1990s, shogi has grown in popularity outside Japan, particularly in the People's Republic of China, and especially in Shanghai. The January 2006 edition of stated that there were 120,000 shogi players in Shanghai. The spread of the game to countries where Chinese characters are not in common use, however, has been slower.\nIn Europe.\nEuropean shogi tournaments vary in format, including both individual and team competitions. Major events are typically held annually, attracting players of all skill levels. The tournaments often feature different time controls, ranging from classical formats to faster-paced variants like blitz shogi. Notable tournaments include the European Shogi Championship and various national championships.\nAs of November 2017[ [update]], there were over 1,200 active players in Europe.\nComputer shogi.\nShogi has the highest game complexity of all popular chess variants. Computers have steadily improved in playing shogi since the 1970s. In 2007, champion Yoshiharu Habu estimated the strength of the 2006 world computer shogi champion Bonanza at the level of two-dan shoreikai.\nThe JSA prohibits its professionals from playing computers in public without prior permission, with the reason of promoting shogi and monetizing the computer\u2013human events.\nOn October 12, 2010, after some 35 years of development, a computer finally beat a professional player, when the top ranked female champion Ichiyo Shimizu was beaten by the Akara2010 system in a game lasting just over 6 hours.\nOn July 24, 2011, computer shogi programs Bonanza and Akara crushed the amateur team of Kosaku and Shinoda in two games. The allotted time for the amateurs was one hour and then three minutes per move. The allotted time for the computer was 25 minutes and then 10 seconds per move.\nOn April 20, 2013, GPS Shogi defeated 8-dan professional shogi player Hiroyuki Miura in a 102-move game which lasted over 8 hours.\nOn December 13, 2015, the highest rated player on Shogi Club 24 was computer program Ponanza, rated 3455.\nOn April 10, 2016, Ponanza defeated Takayuki Yamasaki, 8-dan in 85 moves. Takayuki used 7 hours 9 minutes.\nIn October 2017, DeepMind claimed that its program AlphaZero, after a full nine hours of training, defeated Elmo in a 100-game match, winning 90, losing 8, and drawing two.\nFrom a computational complexity point of view, generalized shogi is EXPTIME-complete.\nVideo games.\nHundreds of video games were released exclusively in Japan for several consoles.\nClubhouse Games: 51 Worldwide Classics was released internationally by Nintendo in 2020 for the Nintendo Switch console, offering both Shogi and mini Shogi variants using either traditional or bilingual pieces.\nCulture.\nAccording to professional player Yoshiharu Habu, in Japan shogi is viewed as not merely a game as entertainment or a mind sport but is instead an art that is a part of traditional Japanese culture along with haiku, tanka, noh, ikebana, and the Japanese tea ceremony. Its elevated status was established by the \"iemoto\" system supported by the historical shogunate.\nThe backwards \"uma\" (shogi horse symbol) is often featured on merchandise (such as on large decorative shogi piece sculptures, keychains, and other keepsakes) available for sale in Tend\u014d. It also serves as a symbol of good luck. (Cf. Rabbit's foot.) There are multiple theories on its origin. One is that \"uma\" (\u3046\u307e ) spelled in the Japanese syllabary backwards is \u307e\u3046 \"mau\" (\u821e\u3046), which means \"(to) dance\" and dancing horses are a good luck omen.\nAiring in 2025 on Netflix, a TV series titled Miss King featured shogi as a focal point of the drama series.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nRules\nOnline play\nOnline tools"}
{"id": "27742", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=27742", "title": "SI derived units freeform table", "text": ""}
{"id": "27743", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=27743", "title": "Solar energy", "text": "Radiant light and heat from the Sun, harnessed with technology\nSolar energy is the radiant energy from the Sun's light and heat, which can be harnessed using a range of technologies such as solar electricity, solar thermal energy (including solar water heating) and solar architecture. It is an essential source of renewable energy, and its technologies are broadly characterized as either passive solar or active solar depending on how they capture and distribute solar energy or convert it into solar power. Active solar techniques include the use of photovoltaic systems, concentrated solar power, and solar water heating to harness the energy. Passive solar techniques include designing a building for better daylighting, selecting materials with favorable thermal mass or light-dispersing properties, and organizing spaces that naturally circulate air.\nIn 2011, the International Energy Agency said that \"the development of affordable, inexhaustible and clean solar energy technologies will have huge longer-term benefits. It will increase countries' energy security through reliance on an indigenous, inexhaustible, and mostly import-independent resource, enhance sustainability, reduce pollution, lower the costs of mitigating global warming ... these advantages are global\".\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nPotential.\nThe Earth receives 174\u00a0petawatts (PW) of incoming solar radiation (insolation) at the upper atmosphere. Approximately 30% is reflected back to space while the rest, 122 PW, is absorbed by clouds, oceans and land masses. The spectrum of solar light at the Earth's surface is mostly spread across the visible and near-infrared ranges with a small part in the near-ultraviolet. Most of the world's population live in areas with insolation levels of 150\u2013300 watts/m2, or 3.5\u20137.0 kWh/m2 per day.\nSolar radiation is absorbed by the Earth's land surface, oceans \u2013 which cover about 71% of the globe \u2013 and atmosphere. Warm air containing evaporated water from the oceans rises, causing atmospheric circulation or convection. When the air reaches a high altitude, where the temperature is low, water vapor condenses into clouds, which rain onto the Earth's surface, completing the water cycle. The latent heat of water condensation amplifies convection, producing atmospheric phenomena such as wind, cyclones and anticyclones. Sunlight absorbed by the oceans and land masses keeps the surface at an average temperature of 14\u00a0\u00b0C. By photosynthesis, green plants convert solar energy into chemically stored energy, which produces food, wood and the biomass from which fossil fuels are derived.\nThe total solar energy absorbed by Earth's atmosphere, oceans and land masses is approximately 122 PW\u00b7year = 3,850,000\u00a0exajoules (EJ) per year. In 2002 (2019), this was more energy in one hour (one hour and 25 minutes) than the world used in one year. Photosynthesis captures approximately 3,000\u00a0EJ per year in biomass.\nThe potential solar energy that could be used by humans differs from the amount of solar energy present near the surface of the planet because factors such as geography, time variation, cloud cover, and the land available to humans limit the amount of solar energy that we can acquire. In 2021, Carbon Tracker Initiative estimated the land area needed to generate all our energy from solar alone was 450,000 km2 \u2014 or about the same as the area of Sweden, or the area of Morocco, or the area of California (0.3% of the Earth's total land area).\nSolar technologies are categorized as either passive or active depending on the way they capture, convert and distribute sunlight and enable solar energy to be harnessed at different levels around the world, mostly depending on the distance from the Equator. Although solar energy refers primarily to the use of solar radiation for practical ends, all types of renewable energy, other than geothermal power and tidal power, are derived either directly or indirectly from the Sun.\nActive solar techniques use photovoltaics, concentrated solar power, solar thermal collectors, pumps, and fans to convert sunlight into useful output. Passive solar techniques include selecting materials with favorable thermal properties, designing spaces that naturally circulate air, and referencing the position of a building to the Sun. Active solar technologies increase the supply of energy and are considered supply side technologies, while passive solar technologies reduce the need for alternative resources and are generally considered demand-side technologies.\nIn 2000, the United Nations Development Programme, UN Department of Economic and Social Affairs, and World Energy Council published an estimate of the potential solar energy that could be used by humans each year. This took into account factors such as insolation, cloud cover, and the land that is usable by humans. It was stated that solar energy has a global potential of per year \"(see table below)\".\nThermal energy.\nSolar thermal technologies can be used for water heating, space heating, space cooling and process heat generation.\nEarly commercial adaptation.\nIn 1878, at the Universal Exposition in Paris, Augustin Mouchot successfully demonstrated a solar steam engine but could not continue development because of cheap coal and other factors.\nIn 1897, Frank Shuman, a US inventor, engineer and solar energy pioneer built a small demonstration solar engine that worked by reflecting solar energy onto square boxes filled with ether, which has a lower boiling point than water and were fitted internally with black pipes which in turn powered a steam engine. In 1908 Shuman formed the Sun Power Company with the intent of building larger solar power plants. He, along with his technical advisor A.S.E. Ackermann and British physicist Sir Charles Vernon Boys, developed an improved system using mirrors to reflect solar energy upon collector boxes, increasing heating capacity to the extent that water could now be used instead of ether. Shuman then constructed a full-scale steam engine powered by low-pressure water, enabling him to patent the entire solar engine system by 1912.\nShuman built the world's first solar thermal power station in Maadi, Egypt, between 1912 and 1913. His plant used parabolic troughs to power a engine that pumped more than of water per minute from the Nile River to adjacent cotton fields. Although the outbreak of World War I and the discovery of cheap oil in the 1930s discouraged the advancement of solar energy, Shuman's vision, and basic design were resurrected in the 1970s with a new wave of interest in solar thermal energy. In 1916 Shuman was quoted in the media advocating solar energy's utilization, saying:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We have proved the commercial profit of sun power in the tropics and have more particularly proved that after our stores of oil and coal are exhausted the human race can receive unlimited power from the rays of the Sun.\u2014\u200a\nWater heating.\nSolar hot water systems use sunlight to heat water. In middle geographical latitudes (between 40\u00a0degrees north and 40\u00a0degrees south), 60 to 70% of the domestic hot water use, with water temperatures up to , can be provided by solar heating systems. The most common types of solar water heaters are evacuated tube collectors (44%) and glazed flat plate collectors (34%) generally used for domestic hot water; and unglazed plastic collectors (21%) used mainly to heat swimming pools.\nAs of 2015, the total installed capacity of solar hot water systems was approximately 436 thermal gigawatt (GWth), and China is the world leader in their deployment with 309\u00a0GWth installed, taken up 71% of the market. Israel and Cyprus are the per capita leaders in the use of solar hot water systems with over 90% of homes using them. In the United States, Canada, and Australia, heating swimming pools is the dominant application of solar hot water with an installed capacity of 18\u00a0GWth as of 2005.\nHeating, cooling and ventilation.\nIn the United States, heating, ventilation and air conditioning (HVAC) systems account for 30% (4.65\u00a0EJ/yr) of the energy used in commercial buildings and nearly 50% (10.1\u00a0EJ/yr) of the energy used in residential buildings. Solar heating, cooling and ventilation technologies can be used to offset a portion of this energy. Use of solar for heating can roughly be divided into passive solar concepts and active solar concepts, depending on whether active elements such as sun tracking and solar concentrator optics are used.\nThermal mass is any material that can be used to store heat\u2014heat from the Sun in the case of solar energy. Common thermal mass materials include stone, cement, and water. Historically they have been used in arid climates or warm temperate regions to keep buildings cool by absorbing solar energy during the day and radiating stored heat to the cooler atmosphere at night. However, they can be used in cold temperate areas to maintain warmth as well. The size and placement of thermal mass depend on several factors such as climate, daylighting, and shading conditions. When duly incorporated, thermal mass maintains space temperatures in a comfortable range and reduces the need for auxiliary heating and cooling equipment.\nA solar chimney (or thermal chimney, in this context) is a passive solar ventilation system composed of a vertical shaft connecting the interior and exterior of a building. As the chimney warms, the air inside is heated, causing an updraft that pulls air through the building. Performance can be improved by using glazing and thermal mass materials in a way that mimics greenhouses.\nDeciduous trees and plants have been promoted as a means of controlling solar heating and cooling. When planted on the southern side of a building in the northern hemisphere or the northern side in the southern hemisphere, their leaves provide shade during the summer, while the bare limbs allow light to pass during the winter. Since bare, leafless trees shade 1/3 to 1/2 of incident solar radiation, there is a balance between the benefits of summer shading and the corresponding loss of winter heating. In climates with significant heating loads, deciduous trees should not be planted on the Equator-facing side of a building because they will interfere with winter solar availability. They can, however, be used on the east and west sides to provide a degree of summer shading without appreciably affecting winter solar gain.\nCooking.\nSolar cookers use sunlight for cooking, drying, and pasteurization. They can be grouped into three broad categories: box cookers, panel cookers, and reflector cookers. The simplest solar cooker is the box cooker first built by Horace de Saussure in 1767. A basic box cooker consists of an insulated container with a transparent lid. It can be used effectively with partially overcast skies and will typically reach temperatures of . Panel cookers use a reflective panel to direct sunlight onto an insulated container and reach temperatures comparable to box cookers. Reflector cookers use various concentrating geometries (dish, trough, Fresnel mirrors) to focus light on a cooking container. These cookers reach temperatures of and above but require direct light to function properly and must be repositioned to track the Sun.\nProcess heat.\nSolar concentrating technologies such as parabolic dish, trough and Scheffler reflectors can provide process heat for commercial and industrial applications. The first commercial system was the Solar Total Energy Project (STEP) in Shenandoah, Georgia, US where a field of 114 parabolic dishes provided 50% of the process heating, air conditioning and electrical requirements for a clothing factory. This grid-connected cogeneration system provided 400\u00a0kW of electricity plus thermal energy in the form of 401\u00a0kW steam and 468\u00a0kW chilled water and had a one-hour peak load thermal storage. Evaporation ponds are shallow pools that concentrate dissolved solids through evaporation. The use of evaporation ponds to obtain salt from seawater is one of the oldest applications of solar energy. Modern uses include concentrating brine solutions used in leach mining and removing dissolved solids from waste streams.\nClothes lines, clotheshorses, and clothes racks dry clothes through evaporation by wind and sunlight without consuming electricity or gas. In some states of the United States legislation protects the \"right to dry\" clothes. Unglazed transpired collectors (UTC) are perforated sun-facing walls used for preheating ventilation air. UTCs can raise the incoming air temperature up to and deliver outlet temperatures of . The short payback period of transpired collectors (3 to 12\u00a0years) makes them a more cost-effective alternative than glazed collection systems. As of 2003, over 80 systems with a combined collector area of had been installed worldwide, including an collector in Costa Rica used for drying coffee beans and a collector in Coimbatore, India, used for drying marigolds.\nWater treatment.\nSolar distillation can be used to make saline or brackish water potable. The first recorded instance of this was by 16th-century Arab alchemists. A large-scale solar distillation project was first constructed in 1872 in the Chilean mining town of Las Salinas. The plant, which had solar collection area of , could produce up to per day and operate for 40\u00a0years. Individual still designs include single-slope, double-slope (or greenhouse type), vertical, conical, inverted absorber, multi-wick, and multiple effect. These stills can operate in passive, active, or hybrid modes. Double-slope stills are the most economical for decentralized domestic purposes, while active multiple effect units are more suitable for large-scale applications.\nSolar water disinfection (SODIS) involves exposing water-filled plastic polyethylene terephthalate (PET) bottles to sunlight for several hours. Exposure times vary depending on weather and climate from a minimum of six hours to two days during fully overcast conditions. It is recommended by the World Health Organization as a viable method for household water treatment and safe storage. Over two million people in developing countries use this method for their daily drinking water.\nSolar energy may be used in a water stabilization pond to treat waste water without chemicals or electricity. A further environmental advantage is that algae grow in such ponds and consume carbon dioxide in photosynthesis, although algae may produce toxic chemicals that make the water unusable.\nMolten salt technology.\nMolten salt can be employed as a thermal energy storage method to retain thermal energy collected by a solar tower or solar trough of a concentrated solar power plant so that it can be used to generate electricity in bad weather or at night. It was demonstrated in the Solar Two project from 1995 to 1999. The system is predicted to have an annual efficiency of 99%, a reference to the energy retained by storing heat before turning it into electricity, versus converting heat directly into electricity. The molten salt mixtures vary. The most extended mixture contains sodium nitrate, potassium nitrate and calcium nitrate. It is non-flammable and non-toxic, and has already been used in the chemical and metals industries as a heat-transport fluid. Hence, experience with such systems exists in non-solar applications.\nThe salt melts at . It is kept liquid at in an insulated \"cold\" storage tank. The liquid salt is pumped through panels in a solar collector where the focused irradiance heats it to . It is then sent to a hot storage tank. This is so well insulated that the thermal energy can be usefully stored for up to a week.\nWhen electricity is needed, the hot salt is pumped to a conventional steam-generator to produce superheated steam for a turbine/generator as used in any conventional coal, oil, or nuclear power plant. A 100-megawatt turbine would need a tank about tall and in diameter to drive it for four hours by this design.\nSeveral parabolic trough power plants in Spain and solar power tower developer SolarReserve use this thermal energy storage concept. The Solana Generating Station in the U.S. has six hours of storage by molten salt. In Chile, The Cerro Dominador power plant has a 110\u00a0MW solar-thermal tower, the heat is transferred to molten salts.\nThe molten salts then transfer their heat in a heat exchanger to water, generating superheated steam, which feeds a turbine that transforms the kinetic energy of the steam into electric energy using the Rankine cycle. In this way, the Cerro Dominador plant is capable of generating around 110 MW of power.\nThe plant has an advanced storage system enabling it to generate electricity for up to 17.5 hours without direct solar radiation, which allows it to provide a stable electricity supply without interruptions if required. The Project secured up to 950 GW\u00b7h per year sale. Another project is the Mar\u00eda Elena plant is a 400\u00a0MW thermo-solar complex in the northern Chilean region of Antofagasta employing molten salt technology.\nConcentrated solar power.\nConcentrating Solar Power (CSP) systems use lenses or mirrors and tracking systems to focus a large area of sunlight into a small beam. The concentrated heat is then used as a heat source for a conventional power plant. A wide range of concentrating technologies exists; the most developed are the parabolic trough, the solar tower collectors, the concentrating linear Fresnel reflector, and the Stirling dish. Various techniques are used to track the Sun and focus light. In all of these systems, a working fluid is heated by the concentrated sunlight, and is then used for power generation or energy storage. Designs need to account for the risk of a dust storm, hail, or another extreme weather event that can damage the fine glass surfaces of solar power plants. Metal grills would allow a high percentage of sunlight to enter the mirrors and solar panels while also preventing most damage.\nArchitecture and urban planning.\nSunlight has influenced building design since the beginning of architectural history. Advanced solar architecture and urban planning methods were first employed by the Greeks and Chinese, who oriented their buildings toward the south to provide light and warmth.\nThe common features of passive solar architecture are orientation relative to the Sun, compact proportion (a low surface area to volume ratio), selective shading (overhangs) and thermal mass. When these features are tailored to the local climate and environment, they can produce well-lit spaces that stay in a comfortable temperature range. Socrates' Megaron House is a classic example of passive solar design. The most recent approaches to solar design use computer modeling tying together solar lighting, heating and ventilation systems in an integrated solar design package. Active solar equipment such as pumps, fans, and switchable windows can complement passive design and improve system performance.\nUrban heat islands (UHI) are metropolitan areas with higher temperatures than that of the surrounding environment. The higher temperatures result from increased absorption of solar energy by urban materials such as asphalt and concrete, which have lower albedos and higher heat capacities than those in the natural environment. A straightforward method of counteracting the UHI effect is to paint buildings and roads white and to plant trees in the area. Using these methods, a hypothetical \"cool communities\" program in Los Angeles has projected that urban temperatures could be reduced by approximately 3\u00a0\u00b0C at an estimated cost of US$1\u00a0 billion, giving estimated total annual benefits of US$530\u00a0 million from reduced air-conditioning costs and healthcare savings.\nAgriculture and horticulture.\nAgriculture and horticulture seek to optimize the capture of solar energy to optimize the productivity of plants. Techniques such as timed planting cycles, tailored row orientation, staggered heights between rows and the mixing of plant varieties can improve crop yields. While sunlight is generally considered a plentiful resource, the exceptions highlight the importance of solar energy to agriculture. During the short growing seasons of the Little Ice Age, French and English farmers employed fruit walls to maximize the collection of solar energy. These walls acted as thermal masses and accelerated ripening by keeping plants warm. Early fruit walls were built perpendicular to the ground and facing south, but over time, sloping walls were developed to make better use of sunlight. In 1699, Nicolas Fatio de Duillier even suggested using a tracking mechanism which could pivot to follow the Sun. Applications of solar energy in agriculture aside from growing crops include pumping water, drying crops, brooding chicks and drying chicken manure. More recently the technology has been embraced by vintners, who use the energy generated by solar panels to power grape presses.\nGreenhouses convert solar light to heat, enabling year-round production and the growth (in enclosed environments) of specialty crops and other plants not naturally suited to the local climate. Primitive greenhouses were first used during Roman times to produce cucumbers year-round for the Roman emperor Tiberius. The first modern greenhouses were built in Europe in the 16th century to keep exotic plants brought back from explorations abroad. Greenhouses remain an important part of horticulture today. Plastic transparent materials have also been used to similar effect in polytunnels and row covers.\nTransport.\nDevelopment of a solar-powered car has been an engineering goal since the 1980s. The World Solar Challenge is a biannual solar-powered car race, where teams from universities and enterprises compete over across central Australia from Darwin to Adelaide. In 1987, when it was founded, the winner's average speed was and by 2007 the winner's average speed had improved to .\nThe North American Solar Challenge and the planned South African Solar Challenge are comparable competitions that reflect an international interest in the engineering and development of solar powered vehicles.\nSome vehicles use solar panels for auxiliary power, such as for air conditioning, to keep the interior cool, thus reducing fuel consumption.\nIn 1975, the first practical solar boat was constructed in England. By 1995, passenger boats incorporating PV panels began appearing and are now used extensively. In 1996, Kenichi Horie made the first solar-powered crossing of the Pacific Ocean, and the \"Sun21\" catamaran made the first solar-powered crossing of the Atlantic Ocean in the winter of 2006\u20132007. There were plans to circumnavigate the globe in 2010.\nIn 1974, the unmanned AstroFlight Sunrise airplane made the first solar flight. On 29 April 1979, the \"Solar Riser\" made the first flight in a solar-powered, fully controlled, man-carrying flying machine, reaching an altitude of . In 1980, the \"Gossamer Penguin\" made the first piloted flights powered solely by photovoltaics. This was quickly followed by the \"Solar Challenger\" which crossed the English Channel in July 1981. In 1990 Eric Scott Raymond in 21 hops flew from California to North Carolina using solar power. Developments then turned back to unmanned aerial vehicles (UAV) with the \"Pathfinder\" (1997) and subsequent designs, culminating in the \"Helios\" which set the altitude record for a non-rocket-propelled aircraft at in 2001. The \"Zephyr\", developed by BAE Systems, is the latest in a line of record-breaking solar aircraft, making a 54-hour flight in 2007, and month-long flights were envisioned by 2010. From March 2015 to July 2016, Solar Impulse, an electric aircraft, successfully circumnavigated the globe. It is a single-seat plane powered by solar cells and capable of taking off under its own power. The design allows the aircraft to remain airborne for several days.\nA solar balloon is a black balloon that is filled with ordinary air. As sunlight shines on the balloon, the air inside is heated and expands, causing an upward buoyancy force, much like an artificially heated hot air balloon. Some solar balloons are large enough for human flight, but usage is generally limited to the toy market as the surface-area to payload-weight ratio is relatively high.\nSquad Solar vehicle.\nThe Squad Solar is a Neighborhood Electric Vehicle that has a solar roof and can be plugged into a normal 120 volt outlet to be charged.\nFuel production.\nSolar chemical processes use solar energy to drive chemical reactions. These processes offset energy that would otherwise come from a fossil fuel source and can also convert solar energy into storable and transportable fuels. Solar induced chemical reactions can be divided into thermochemical or photochemical. A variety of fuels can be produced by artificial photosynthesis. The multielectron catalytic chemistry involved in making carbon-based fuels (such as methanol) from reduction of carbon dioxide is challenging; a feasible alternative is hydrogen production from protons, though use of water as the source of electrons (as plants do) requires mastering the multielectron oxidation of two water molecules to molecular oxygen. Some have envisaged working solar fuel plants in coastal metropolitan areas by 2050\u00a0\u2013 the splitting of seawater providing hydrogen to be run through adjacent fuel-cell electric power plants and the pure water by-product going directly into the municipal water system. In addition, chemical energy storage is another solution to solar energy storage.\nHydrogen production technologies have been a significant area of solar chemical research since the 1970s. Aside from electrolysis driven by photovoltaic or photochemical cells, several thermochemical processes have also been explored. One such route uses concentrators to split water into oxygen and hydrogen at high temperatures (). Another approach uses the heat from solar concentrators to drive the steam reformation of natural gas thereby increasing the overall hydrogen yield compared to conventional reforming methods. Thermochemical cycles characterized by the decomposition and regeneration of reactants present another avenue for hydrogen production. The Solzinc process under development at the Weizmann Institute of Science uses a 1\u00a0MW solar furnace to decompose zinc oxide (ZnO) at temperatures above . This initial reaction produces pure zinc, which can subsequently be reacted with water to produce hydrogen.\nEnergy storage methods.\nThermal mass systems can store solar energy in the form of heat at domestically useful temperatures for daily or interseasonal durations. Thermal storage systems generally use readily available materials with high specific heat capacities such as water, earth and stone. Well-designed systems can lower peak demand, shift time-of-use to off-peak hours and reduce overall heating and cooling requirements.\nPhase change materials such as paraffin wax and Glauber's salt are another thermal storage medium. These materials are inexpensive, readily available, and can deliver domestically useful temperatures (approximately ). The \"Dover House\" (in Dover, Massachusetts) was the first to use a Glauber's salt heating system, in 1948. Solar energy can also be stored at high temperatures using molten salts. Salts are an effective storage medium because they are low-cost, have a high specific heat capacity, and can deliver heat at temperatures compatible with conventional power systems. The Solar Two project used this method of energy storage, allowing it to store in its 68 m3 storage tank with an annual storage efficiency of about 99%.\nOff-grid PV systems have traditionally used rechargeable batteries to store excess electricity. With grid-tied systems, excess electricity can be sent to the transmission grid, while standard grid electricity can be used to meet shortfalls. Net metering programs give household systems credit for any electricity they deliver to the grid. This is handled by 'rolling back' the meter whenever the home produces more electricity than it consumes. If the net electricity use is below zero, the utility then rolls over the kilowatt-hour credit to the next month. Other approaches involve the use of two meters, to measure electricity consumed vs. electricity produced. This is less common due to the increased installation cost of the second meter. Most standard meters accurately measure in both directions, making a second meter unnecessary.\nPumped-storage hydroelectricity stores energy in the form of water pumped when energy is available from a lower elevation reservoir to a higher elevation one. The energy is recovered when demand is high by releasing the water, with the pump becoming a hydroelectric power generator.\nDevelopment, deployment and economics.\nBeginning with the surge in coal use, which accompanied the Industrial Revolution, energy consumption steadily transitioned from wood and biomass to fossil fuels. The early development of solar technologies starting in the 1860s was driven by an expectation that coal would soon become scarce. However, development of solar technologies stagnated in the early 20th\u00a0 century in the face of the increasing availability, economy, and utility of coal and petroleum.\nThe 1973 oil embargo and 1979 energy crisis caused a reorganization of energy policies around the world. It brought renewed attention to developing solar technologies. Deployment strategies focused on incentive programs such as the Federal Photovoltaic Utilization Program in the US and the Sunshine Program in Japan. Other efforts included the formation of research facilities in the US (SERI, now NREL), Japan (NEDO), and Germany (Fraunhofer Institute for Solar Energy Systems ISE).\nCommercial solar water heaters began appearing in the United States in the 1890s. These systems saw increasing use until the 1920s but were gradually replaced by cheaper and more reliable heating fuels. As with photovoltaics, solar water heating attracted renewed attention as a result of the oil crises in the 1970s, but interest subsided in the 1980s due to falling petroleum prices. Development in the solar water heating sector progressed steadily throughout the 1990s, and annual growth rates have averaged 20% since 1999. Although generally underestimated, solar water heating and cooling is by far the most widely deployed solar technology with an estimated capacity of 154\u00a0 GW as of 2007.\nThe International Energy Agency has said that solar energy can make considerable contributions to solving some of the most urgent problems the world now faces:\nThe development of affordable, inexhaustible, and clean solar energy technologies will have huge longer-term benefits. It will increase countries' energy security through reliance on an indigenous, inexhaustible, and mostly import-independent resource, enhance sustainability, reduce pollution, lower the costs of mitigating climate change, and keep fossil fuel prices lower than otherwise. These advantages are global. Hence the additional costs of the incentives for early deployment should be considered learning investments; they must be wisely spent and need to be widely shared.\nIn 2011, a report by the International Energy Agency found that solar energy technologies such as photovoltaics, solar hot water, and concentrated solar power could provide a third of the world's energy by 2060 if politicians commit to limiting climate change and transitioning to renewable energy. The energy from the Sun could play a key role in de-carbonizing the global economy alongside improvements in energy efficiency and imposing costs on greenhouse gas emitters. \"The strength of solar is the incredible variety and flexibility of applications, from small scale to big scale\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We have proved ... that after our stores of oil and coal are exhausted the human race can receive unlimited power from the rays of the Sun.\u2014\u200aIn 2021 Lazard estimated the levelized cost of new build unsubsidized utility scale solar electricity at less than 37 dollars per MWh and existing coal-fired power above that amount. The 2021 report also said that new solar was also cheaper than new gas-fired power, but not generally existing gas power.\nEmerging technologies.\nExperimental solar power.\nConcentrated photovoltaics (CPV) systems employ sunlight concentrated onto photovoltaic surfaces for the purpose of electricity generation. Thermoelectric, or \"thermovoltaic\" devices convert a temperature difference between dissimilar materials into an electric current.\nSolar-assisted heat pump.\nA heat pump is a device that provides heat energy from a source of heat to a destination called a \"heat sink\". Heat pumps are designed to move thermal energy opposite to the direction of spontaneous heat flow by absorbing heat from a cold space and releasing it to a warmer one. A solar-assisted heat pump represents the integration of a heat pump and thermal solar panels in a single integrated system. Typically these two technologies are used separately (or only placing them in parallel) to produce hot water. In this system the solar thermal panel performs the function of the low temperature heat source and the heat produced is used to feed the heat pump's evaporator. The goal of this system is to get high COP and then produce energy in a more efficient and less expensive way.\nIt is possible to use any type of solar thermal panel (sheet and tubes, roll-bond, heat pipe, thermal plates) or hybrid (mono/polycrystalline, thin film) in combination with the heat pump. The use of a hybrid panel is preferable because it allows covering a part of the electricity demand of the heat pump and reduces the power consumption and consequently the variable costs of the system.\nSolar aircraft.\nAn electric aircraft is an aircraft that runs on electric motors rather than internal combustion engines, with electricity coming from fuel cells, solar cells, ultracapacitors, power beaming, or batteries.\nCurrently, flying manned electric aircraft are mostly experimental demonstrators, though many small unmanned aerial vehicles are powered by batteries. Electrically powered model aircraft have been flown since the 1970s, with one report in 1957. The first man-carrying electrically powered flights were made in 1973. Between 2015 and 2016, a manned, solar-powered plane, \"Solar Impulse 2\", completed a circumnavigation of the Earth.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27744", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=27744", "title": "Solar box cooker", "text": ""}
{"id": "27745", "revid": "29539620", "url": "https://en.wikipedia.org/wiki?curid=27745", "title": "Standard temperature and pressure", "text": "Reference values for temperature and pressure\nStandard temperature and pressure (STP) or standard conditions for temperature and pressure are various standard sets of conditions for experimental measurements used to allow comparisons to be made between different sets of data. The most used standards are those of the International Union of Pure and Applied Chemistry (IUPAC) and the National Institute of Standards and Technology (NIST), although these are not universally accepted. Other organizations have established a variety of other definitions.\nIn industry and commerce, the standard conditions for temperature and pressure are often necessary for expressing the volumes of gases and liquids and related quantities such as the rate of volumetric flow (the volumes of gases vary significantly with temperature and pressure): standard cubic meters per second (Sm3/s), and normal cubic meters per second (Nm3/s).\nMany technical publications (books, journals, advertisements for equipment and machinery) simply state \"standard conditions\" without specifying them; often substituting the term with older \"normal conditions\", or \"NC\". In special cases this can lead to confusion and errors. Good practice always incorporates the reference conditions of temperature and pressure. If not stated, some room environment conditions are supposed, close to 1 atm pressure, \u00a0K (\u00a0\u00b0C), and 0% humidity.\nDefinitions.\nIn chemistry, IUPAC changed its definition of standard temperature and pressure in 1982:\nNIST uses a temperature of 20\u00a0\u00b0C (293.15\u00a0K, 68\u00a0\u00b0F) and an absolute pressure of 1\u00a0atm (14.696\u00a0psi, 101.325\u00a0kPa). This standard is also called normal temperature and pressure (abbreviated as NTP). However, a common temperature and pressure in use by NIST for thermodynamic experiments is 298.15\u00a0K (25\u00a0\u00b0C, 77\u00a0\u00b0F) and 1 bar (14.5038 psi, 100 kPa). NIST also uses 15\u00a0\u00b0C (288.15\u00a0K, 59\u00a0\u00b0F) for the temperature compensation of refined petroleum products, despite noting that these two values are not exactly consistent with each other.\nThe ISO 13443 standard reference conditions for natural gas and similar fluids are and 101.325 kPa;\nby contrast, the American Petroleum Institute adopts .\nPast uses.\nBefore 1918, many professionals and scientists using the metric system of units defined the standard reference conditions of temperature and pressure for expressing gas volumes as being and . During those same years, the most commonly used standard reference conditions for people using the imperial or U.S. customary systems was and 14.696\u00a0psi (1\u00a0atm) because it was almost universally used by the oil and gas industries worldwide. The above definitions are no longer the most commonly used in either system of units.\nCurrent use.\nMany different definitions of standard reference conditions are currently being used by organizations all over the world. The table below lists a few of them, but there are more. Some of these organizations used other standards in the past. For example, IUPAC has, since 1982, defined standard reference conditions as being 0\u00a0\u00b0C and 100\u00a0kPa (1\u00a0bar), in contrast to its old standard of 0\u00a0\u00b0C and 101.325\u00a0kPa (1\u00a0atm). The new value is the mean atmospheric pressure at an altitude of about 112 metres, which is closer to the worldwide median altitude of human habitation (194 m).\nNatural gas companies in Europe, Australia, and South America have adopted 15\u00a0\u00b0C (59\u00a0\u00b0F) and 101.325\u00a0kPa (14.696\u00a0psi) as their standard gas volume reference conditions, used as the base values for defining the standard cubic meter. Also, the International Organization for Standardization (ISO), the United States Environmental Protection Agency (EPA) and National Institute of Standards and Technology (NIST) each have more than one definition of standard reference conditions in their various standards and regulations.\nAbbreviations:\nInternational Standard Atmosphere.\nIn aeronautics and fluid dynamics the \"International Standard Atmosphere\" (ISA) is a specification of pressure, temperature, density, and speed of sound at each altitude. At standard mean sea level it specifies a temperature of , pressure of (1 atm), and a density of . It also specifies a temperature lapse rate of \u22126.5\u00a0\u00b0C (\u221211.7\u00a0\u00b0F) per km (approximately \u22122\u00a0\u00b0C (\u22123.6\u00a0\u00b0F) per 1,000\u00a0ft).\nThe International Standard Atmosphere is representative of atmospheric conditions at mid latitudes. In the US this information is specified the U.S. Standard Atmosphere which is identical to the \"International Standard Atmosphere\" at all altitudes up to 65,000 feet above sea level.\nStandard laboratory conditions.\nBecause many definitions of standard temperature and pressure differ in temperature significantly from standard laboratory temperatures (e.g. 0\u00a0\u00b0C vs. ~28\u00a0\u00b0C), reference is often made to \"standard laboratory conditions\" (a term deliberately chosen to be different from the term \"standard conditions for temperature and pressure\", despite its semantic near identity when interpreted literally). However, what is a \"standard\" laboratory temperature and pressure is inevitably geography-bound, given that different parts of the world differ in climate, altitude and the degree of use of heat/cooling in the workplace. For example, schools in New South Wales, Australia use 25\u00a0\u00b0C at 100\u00a0kPa for standard laboratory conditions.\nASTM International has published Standard ASTM E41- Terminology Relating to Conditioning and hundreds of special conditions for particular materials and test methods. Other standards organizations also have specialized standard test conditions.\nMolar volume of a gas.\nIt is as important to indicate the applicable reference conditions of temperature and pressure when stating the molar volume of a gas as it is when expressing a gas volume or volumetric flow rate. Stating the molar volume of a gas without indicating the reference conditions of temperature and pressure has very little meaning and can cause confusion.\nThe molar volume of gases around STP and at atmospheric pressure can be calculated with an accuracy that is usually sufficient by using the ideal gas law. The molar volume of any ideal gas may be calculated at various standard reference conditions as shown below:\nTechnical literature can be confusing because many authors fail to explain whether they are using the ideal gas constant \"R\", or the specific gas constant \"R\"s. The relationship between the two constants is \"R\"s = \"R\" / \"m\", where \"m\" is the molecular mass of the gas.\nThe US Standard Atmosphere (USSA) uses 8.31432\u00a0m3\u00b7Pa/(mol\u00b7K) as the value of \"R\". However, the USSA in 1976 does recognize that this value is not consistent with the values of the Avogadro constant and the Boltzmann constant.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27748", "revid": "22651524", "url": "https://en.wikipedia.org/wiki?curid=27748", "title": "Synthesiser", "text": ""}
{"id": "27750", "revid": "6702527", "url": "https://en.wikipedia.org/wiki?curid=27750", "title": "Script kiddie", "text": "Unskilled malicious hacker\nA script kiddie, skript kiddie, skiddie, kiddie, or skid is a pejorative for an unskilled individual who uses malicious scripts or programs developed by others.\nCharacteristics.\nThe term script kiddie was first used in 1988. In Brazil, the term \"lammer\" arose in the late 1980s and is more commonly used instead.\nIn a Carnegie Mellon report prepared for the US Department of Defense in 2000, script kiddies are defined as The more immature but unfortunately often just as dangerous exploiter of security lapses on the Internet. The typical script kiddy uses existing and frequently well known and easy-to-find techniques and programs or scripts to search for and exploit weaknesses in other computers on the Internet\u2014often randomly and with little regard or perhaps even understanding of the potentially harmful consequences.\nScript kiddies typically have at least one or more effective and easily downloadable programs capable of breaching computers and networks.\nScript kiddies vandalize websites both for the thrill of it and to increase their reputation among their peers. Some more malicious script kiddies have used virus toolkits to create and propagate the Anna Kournikova and Love Bug viruses. Script kiddies lack, or are only developing, programming skills sufficient to understand the effects and side effects of their actions. As a result, they leave significant traces which lead to their detection, or directly attack companies which have detection and countermeasures already in place. For example, they may report crashes they cause while developing malware on their system, unintentionally sending their source code to Microsoft.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27751", "revid": "43933890", "url": "https://en.wikipedia.org/wiki?curid=27751", "title": "SVG", "text": "Two-dimensional vector image file format\nScalable Vector Graphics (SVG) is an XML-based vector graphics format for defining two-dimensional graphics, having support for interactivity and animation. The SVG specification is an open standard developed by the World Wide Web Consortium since 1999.\nSVG images are defined in a vector graphics format and stored in XML text files. SVG images can thus be scaled in size without loss of quality, and SVG files can be searched, indexed, scripted, and compressed. The XML text files can be created and edited with text editors or vector graphics editors, and are rendered by most web browsers. SVG can include JavaScript, potentially leading to cross-site scripting.\nHistory.\nSVG has been in development within the World Wide Web Consortium (W3C) since 1999 after six competing proposals for vector graphics languages had been submitted to the consortium during 1998 (see below).\nThe early SVG Working Group decided not to develop any of the commercial submissions, but to create a new markup language that was informed by but not really based on any of them.\nSVG was developed by the W3C SVG Working Group starting in 1998, after six competing vector graphics submissions were received that year:\nThe working group was chaired at the time by Chris Lilley of the W3C.\nEarly adoption was limited due to lack of support in older versions of Internet Explorer. However, as of 2011, all major desktop browsers began to support SVG. Native browser support offers various advantages, such as not requiring plugins, allowing SVG to be mixed with other content, and improving rendering and scripting reliability. Mobile support for SVG exists in various forms, with different devices and browsers supporting SVG Tiny 1.1 or 1.2. SVG can be produced using vector graphics editors and rendered into raster formats. In web-based applications, Inline SVG allows embedding SVG content within HTML documents.\nThe SVG specification was updated to version 1.1 in 2011. Scalable Vector Graphics 2 became a W3C Candidate Recommendation on 15 September 2016. SVG 2 incorporates several new features in addition to those of SVG 1.1 and SVG Tiny 1.2.\nVersion 2.\nSVG 2 removes or deprecates some features of SVG 1.1 and incorporates new features from HTML5 and Web Open Font Format (WOFF):\nSVG 2 reached the Candidate Recommendation stage on 15 September 2016, and revised versions were published on 7 August 2018 and 4 October 2018. The latest draft was released on 14 September 2025.\nFeatures.\nSVG supports interactivity, animation, and rich graphical capabilities, making it suitable for both web and print applications. SVG images can be compressed with the gzip algorithm, resulting in SVGZ files that are typically 20\u201350% smaller than the original. SVG also supports metadata, enabling better indexing, searching, and retrieval of SVG content.\nSVG allows three types of graphic objects: vector graphic shapes (such as paths consisting of straight lines and curves), bitmap images, and text. Graphical objects can be grouped, styled, transformed and composited into previously rendered objects. The feature set includes nested transformations, clipping paths, alpha masks, filter effects and template objects. SVG drawings can be interactive and can include animation, defined in the SVG XML elements or via scripting that accesses the SVG Document Object Model (DOM).\nSVG uses CSS for styling and JavaScript for scripting. Text, including internationalization and localization, appearing in plain text within the SVG DOM, enhances the accessibility of SVG graphics.\nPrinting.\nThough the SVG Specification primarily focuses on vector graphics markup language, its design includes the basic capabilities of a page description language like Adobe's PDF. It contains provisions for rich graphics, and is compatible with CSS for styling purposes. SVG has the information needed to place each glyph and image in a chosen location on a printed page.\nScripting and animation.\nSVG drawings can be dynamic and interactive. Time-based modifications to the elements can be described in SMIL, or can be programmed in a scripting language (e.g. JavaScript). The W3C explicitly recommends SMIL as the standard for animation in SVG.\nA rich set of event handlers such as \"onmouseover\" and \"onclick\" can be assigned to any SVG graphical object to apply actions and events.\nMobile profiles.\nBecause of industry demand, two mobile profiles were introduced with SVG 1.1: \"SVG Tiny\" (SVGT) and \"SVG Basic\" (SVGB).\nThese are subsets of the full SVG standard, mainly intended for user agents with limited capabilities. In particular, SVG Tiny was defined for highly restricted mobile devices such as cellphones; it does not support styling or scripting. SVG Basic was defined for higher-level mobile devices, such as smartphones.\nIn 2003, the 3GPP, an international telecommunications standards group, adopted SVG Tiny as the mandatory vector graphics media format for next-generation phones. SVGT is the required vector graphics format and support of SVGB is optional for Multimedia Messaging Service (MMS) and Packet-switched Streaming Service. It was later added as required format for vector graphics in 3GPP IP Multimedia Subsystem (IMS).\nNeither mobile profile includes support for the full Document Object Model (DOM), while only SVG Basic has optional support for scripting, but because they are fully compatible subsets of the full standard, most SVG graphics can still be rendered by devices which only support the mobile profiles.\nSVGT 1.2 adds a microDOM (\u03bcDOM), styling and scripting. SVGT 1.2 also includes some features not found in SVG 1.1, including non-scaling strokes, which are supported by some SVG 1.1 implementations, such as Opera, Firefox, and WebKit. As shared code bases between desktop and mobile browsers increased, the use of SVG 1.1 over SVGT 1.2 also increased.\nCompression.\nSVG images, being XML, contain many repeated fragments of text, so they are well suited for lossless data compression algorithms. When an SVG image has been compressed with the gzip algorithm, it is referred to as an \"SVGZ\" image and uses the corresponding codice_6 filename extension. Conforming SVG 1.1 viewers will display compressed images. An SVGZ file is typically 20 to 50 percent of the original size. W3C provides SVGZ files to test for conformance.\nDesign.\nThe SVG 1.1 specification defines 14 functional areas or feature sets:\nSimple or compound shape outlines are drawn with curved or straight lines that can be filled in, outlined, or used as a clipping path. Paths have a compact coding.\nFor example, &lt;dfn&gt;codice_7&lt;/dfn&gt; (for \"move to\") precedes initial numeric x and y coordinates, and &lt;dfn&gt;codice_8&lt;/dfn&gt; (for \"line to\") precedes a point to which a line should be drawn. Further command letters (codice_9, codice_10, codice_11, codice_12, and codice_13) precede data that is used to draw various B\u00e9zier and elliptical curves. codice_14 is used to close a path.\nIn all cases, absolute coordinates follow capital letter commands and relative coordinates are used after the equivalent lower-case letters.\nStraight-line paths and paths made up of a series of connected straight-line segments (polylines), as well as closed polygons, circles, and ellipses can be drawn. Rectangles and round-cornered rectangles are also standard elements.\nUnicode character text included in an SVG file is expressed as XML character data. Many visual effects are possible, and the SVG specification automatically handles bidirectional text (for composing a combination of English and Arabic text, for example), vertical text (as Chinese or Japanese may be written) and characters along a curved path (such as the text around the edge of the Great Seal of the United States).\nSVG shapes can be filled and outlined (painted with a color, a gradient, or a pattern). Fills may be opaque, or have any degree of transparency.\n\"Markers\" are line-end features, such as arrowheads, or symbols that can appear at the vertices of a polygon.\nColors can be applied to all visible SVG elements, either directly or via codice_15, codice_16, and other properties. Colors are specified in the same way as in CSS2, i.e. using names like codice_17 or codice_18, in hexadecimal such as codice_19 or codice_20, in decimal like codice_21, or as percentages of the form codice_22.\nSVG shapes can be filled or outlined with solid colors as above, or with color gradients or with repeating patterns. Color gradients can be linear or radial (circular), and can involve any number of colors as well as repeats. Opacity gradients can also be specified. Patterns are based on predefined raster or vector graphic objects, which can be repeated in codice_23 and codice_24 directions. Gradients and patterns can be animated and scripted.\nSince 2008, there has been discussion among professional users of SVG that either gradient meshes or preferably diffusion curves could usefully be added to the SVG specification. It is said that a \"simple representation [using diffusion curves] is capable of representing even very subtle shading effects\" and that \"Diffusion curve images are comparable both in quality and coding efficiency with gradient meshes, but are simpler to create (according to several artists who have used both tools), and can be captured from bitmaps fully automatically.\" The current draft of SVG 2 includes gradient meshes.\nGraphic elements, including text, paths, basic shapes and combinations of these, can be used as outlines to define both \"inside\" and \"outside\" regions that can be painted (with colors, gradients and patterns) independently. Fully opaque \"clipping paths\" and semi-transparent \"masks\" are \"composited\" together to calculate the color and opacity of every pixel of the final image, using alpha blending.\nA filter effect consists of a series of graphics operations that are applied to a given source vector graphic to produce a modified bitmapped result.\nSVG images can interact with users in many ways. In addition to hyperlinks as mentioned below, any part of an SVG image can be made receptive to user interface events such as changes in focus, mouse clicks, scrolling or zooming the image and other pointer, keyboard and document events. Event handlers may start, stop or alter animations as well as trigger scripts in response to such events.\nSVG images can contain hyperlinks to other documents, using XLink. Through the use of the codice_25 element or a fragment identifier, URLs can link to SVG files that change the visible area of the document. This allows for creating specific view states that are used to zoom in/out of a specific area or to limit the view to a specific element. This is helpful when creating sprites. XLink support in combination with the codice_26 element also allow linking to and re-using internal and external elements. This allows coders to do more with less markup and makes for cleaner code.\nAll aspects of an SVG document can be accessed and manipulated using scripts in a similar way to HTML. The default scripting language is JavaScript and there are defined Document Object Model (DOM) objects for every SVG element and attribute. Scripts are enclosed in codice_27 elements. They can run in response to pointer events, keyboard events and document events as required.\n SVG content can be animated using the built-in animation elements such as codice_28, codice_29 and codice_30. Content can be animated by manipulating the DOM using ECMAScript and the scripting language's built-in timers. SVG animation has been designed to be compatible with current and future versions of Synchronized Multimedia Integration Language (SMIL). Animations can be continuous, they can loop and repeat, and they can respond to user events, as mentioned above.\nAs with HTML and CSS, text in SVG may reference external font files, such as system fonts. If the required font files do not exist on the machine where the SVG file is rendered, the text may not appear as intended. To overcome this limitation, text can be displayed in an \"SVG font\", where the required glyphs are defined in SVG as a font that is then referenced from the codice_31 element.\nIn accord with the W3C's Semantic Web initiative, SVG allows authors to provide metadata about SVG content. The main facility is the codice_32 element, where the document can be described using Dublin Core metadata properties (e.g. title, creator/author, subject, description, etc.). Other metadata schemas may also be used. In addition, SVG defines codice_33 and codice_34 elements where authors may also provide plain-text descriptive material within an SVG image to help indexing, searching and retrieval by a number of means.\nAn SVG document can define components including shapes, gradients etc., and use them repeatedly. SVG images can also contain raster graphics, such as PNG and JPEG images, and further SVG images.\nThis code will produce the colored shapes shown in the image, excluding the grid and labels:\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;\n&lt;!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"&gt;\n&lt;svg width=\"391\" height=\"391\" viewBox=\"-70.5 -70.5 391 391\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"&gt;\n&lt;rect fill=\"#fff\" stroke=\"#000\" x=\"-70\" y=\"-70\" width=\"390\" height=\"390\"/&gt;\n&lt;g opacity=\"0.8\"&gt;\n &lt;rect x=\"25\" y=\"25\" width=\"200\" height=\"200\" fill=\"lime\" stroke-width=\"4\" stroke=\"pink\" /&gt;\n &lt;circle cx=\"125\" cy=\"125\" r=\"75\" fill=\"orange\" /&gt;\n &lt;polyline points=\"50,150 50,200 200,200 200,100\" stroke=\"red\" stroke-width=\"4\" fill=\"none\" /&gt;\n &lt;line x1=\"50\" y1=\"50\" x2=\"200\" y2=\"200\" stroke=\"blue\" stroke-width=\"4\" /&gt;\n&lt;/g&gt;\n&lt;/svg&gt;\nImplementation.\nThe use of SVG on the web was limited by the lack of support in older versions of Internet Explorer (IE). Many websites that serve SVG images also provide the images in a raster format, either automatically by HTTP content negotiation or by allowing the user directly to choose the file.\nWeb browsers.\nKonqueror was the first browser to support SVG in release version 3.2 in February 2004. As of 2011, all major desktop browsers, and many minor ones, have some level of SVG support. Other browsers' implementations are not yet complete; see comparison of layout engines for further details.\nSome earlier versions of Firefox (e.g. versions between 1.5 and 3.6), as well as a few other, now outdated, web browsers capable of displaying SVG graphics, needed them embedded in codice_35 or codice_36 elements to display them integrated as parts of an HTML webpage instead of using the standard way of integrating images with codice_37. However, SVG images may be included in XHTML pages using XML namespaces.\nTim Berners-Lee, the inventor of the World Wide Web, was critical of early versions of Internet Explorer for its failure to support SVG.\nThere are several advantages to native and full support: plugins are not needed, SVG can be freely mixed with other content in a single document, and rendering and scripting become considerably more reliable.\nMobile devices.\nSupport for SVG may be limited to SVGT on older or more limited smart phones or may be primarily limited by their respective operating system. Adobe Flash Lite has optionally supported SVG Tiny since version 1.1. At the SVG Open 2005 conference, Sun demonstrated a mobile implementation of SVG Tiny 1.1 for the Connected Limited Device Configuration (CLDC) platform.\nMobiles that use Opera Mobile, as well as the iPhone's built in browser, also include SVG support. However, even though it used the WebKit engine, the Android built-in browser did not support SVG prior to v3.0 (Honeycomb). Prior to v3.0, Firefox Mobile 4.0b2 (beta) for Android was the first browser running under Android to support SVG by default.\nThe level of SVG Tiny support available varies from mobile to mobile, depending on the SVG engine installed. Many newer mobile products support additional features beyond SVG Tiny 1.1, like gradient and opacity; this is sometimes referred to as \"SVGT 1.1+\", though there is no such standard.\nRIM's BlackBerry has built-in support for SVG Tiny 1.1 since version 5.0. Support continues for WebKit-based BlackBerry Torch browser in OS 6 and 7.\nNokia's S60 platform has built-in support for SVG. For example, icons are generally rendered using the platform's SVG engine. Nokia has also led the JSR 226: Scalable 2D Vector Graphics API expert group that defines Java ME API for SVG presentation and manipulation. This API has been implemented in S60 Platform 3rd Edition Feature Pack 1 and onward. Some Series 40 phones also support SVG (such as Nokia 6280).\nMost Sony Ericsson phones beginning with K700 (by release date) support SVG Tiny 1.1. Phones beginning with K750 also support such features as opacity and gradients. Phones with Sony Ericsson Java Platform-8 have support for JSR 226.\nWindows Phone has supported SVG since version 7.5.\nSVG is also supported on various mobile devices from Motorola, Samsung, LG, and Siemens mobile/BenQ-Siemens. eSVG, an SVG rendering library mainly written for embedded devices, is available on some mobile platforms.\nAuthoring.\nSVG images can be hand coded or produced by the use of a vector graphics editor, such as Inkscape, Adobe Illustrator, Adobe Animate, or CorelDRAW, and rendered to common raster image formats such as PNG using the same software. Additionally, editors like Inkscape and Boxy SVG provide tools to trace raster images to B\u00e9zier curves typically using image tracing back-ends like potrace, autotrace, and imagetracerjs.\nSoftware can be programmed to render SVG images by using a library such as librsvg used by GNOME since 2000, Batik and ThorVG (Thor Vector Graphics) since 2020 for lightweight systems. SVG images can also be rendered to any desired popular image format by using ImageMagick, a free command-line utility (which also uses librsvg under the hood).\nFor web-based applications, the mode of usage termed Inline SVG allows SVG content to be embedded within an HTML document using an codice_38 tag. Its graphical capabilities can then be employed to create sophisticated user interfaces as the SVG and HTML share context, event handling, and CSS.\nOther uses for SVG include embedding for use in word processing (e.g. with LibreOffice) and desktop publishing (e.g. Scribus), plotting graphs (e.g. gnuplot), and importing paths (e.g. for use in GIMP or Blender). The application services Microsoft 365 and Microsoft Office 2019 offer support for exporting, importing and editing SVG images. The Uniform Type Identifier for SVG used by Apple is codice_39 and conforms to codice_40 and codice_41.\nSecurity.\nAs a document format, similar to HTML documents, SVG can host scripts or CSS. This is an issue when an attacker can upload a SVG file to a website, such as a profile picture, and the file is treated as a normal picture but contains malicious content. For instance, if an SVG file is deployed as a CSS background image, or a logo on some website, or in some image gallery, then when the image is loaded in a browser it activates a script or other content. This could lock up the browser (the Billion laughs attack), but could also lead to HTML injection and cross-site scripting attacks. The W3C therefore stipulate certain requirements when SVG is simply used for images: SVG Security.\nThe W3C says that Inline SVG (an SVG file loaded natively on a website) is considered less of a security risk because the content is part of a greater document, and so scripting and CSS would not be unexpected.\nRelated work.\nThe MPEG-4 Part 20 standard \u2013 \"Lightweight Application Scene Representation (LASeR) and Simple Aggregation Format (SAF)\" is based on SVG Tiny. It was developed by MPEG (ISO/IEC JTC 1/SC29/WG11) and published as ISO/IEC 14496-20:2006. SVG capabilities are enhanced in MPEG-4 Part 20 with key features for mobile services, such as dynamic updates, binary encoding, state-of-art font representation. SVG was also accommodated in MPEG-4 Part 11, in the Extensible MPEG-4 Textual (XMT) format \u2013 a textual representation of the MPEG-4 multimedia content using XML.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27752", "revid": "18426370", "url": "https://en.wikipedia.org/wiki?curid=27752", "title": "Spectroscopy", "text": "Study involving matter and electromagnetic radiation\nSpectroscopy is the field of study that measures and interprets electromagnetic spectra as it interacts with matter. In narrower contexts, spectroscopy is the precise study of color as generalized from radiated visible light to all bands of the electromagnetic spectrum.\nSpectroscopy, primarily in the electromagnetic spectrum, is a fundamental exploratory tool in the fields of astronomy, chemistry, materials science, and physics, allowing the composition, physical and electronic structure of matter to be investigated at the atomic, molecular and macro scale, and over astronomical distances.\nHistorically, spectroscopy originated as the study of the wavelength dependence of the absorption by gas phase matter of visible light dispersed by a prism. Current applications of spectroscopy include biomedical spectroscopy in the areas of tissue analysis and medical imaging. Matter waves and acoustic waves can also be considered forms of radiative energy, and recently gravitational waves have been associated with a spectral signature in the context of the Laser Interferometer Gravitational-Wave Observatory (LIGO).\nIntroduction.\nSpectroscopy is a branch of science concerned with the spectra of electromagnetic radiation as a function of its wavelength or frequency, as measured by spectrographic equipment and other techniques, in order to obtain information concerning the structure and properties of matter. Spectral measurement devices are referred to as spectrometers, spectrophotometers, spectrographs or spectral analyzers. Most spectroscopic analysis in the laboratory starts with a sample to be analyzed. A light source is sent through a monochromator to spatially separate the colors before passing a selected frequency band through the sample, then the output is captured by a photodiode. For astronomical purposes, the telescope must be equipped with the light dispersion device. There are various versions of this basic setup that may be employed.\nSpectroscopy began with Isaac Newton splitting light with a prism; a key moment in the development of modern optics. Therefore, it was originally the study of visible light that we call color. Following the contributions of James Clerk Maxwell, this study later came to include the entire electromagnetic spectrum. Although color is involved in spectroscopy, it is not equivalent to the absorption and reflection of certain electromagnetic waves that give objects or elements a sense of color to our eyes. Rather, spectroscopy involves the splitting of light by a prism, diffraction grating, or similar instrument, to display a particular discrete line pattern called a \"spectrum\", which is unique for each different type of element or molecule. Most elements are first put into a gaseous state to allow the spectra to be examined, although today other methods can be used for different phases of matter. Each element that is diffracted by a prism-like instrument displays either an absorption spectrum or an emission spectrum depending upon whether the element is being cooled or heated.\nUntil recently all spectroscopy involved the study of line spectra and most spectroscopy still does. Vibrational spectroscopy is the branch of spectroscopy that studies the spectra. However, the latest developments in spectroscopy can sometimes dispense with the dispersion technique. In biochemical spectroscopy, information can be gathered about biological tissue by absorption and light scattering techniques. Light scattering spectroscopy is a type of reflectance spectroscopy that determines tissue structures by examining elastic scattering. In such a case, it is the tissue that acts as a diffraction or dispersion mechanism.\nSpectroscopic studies were central to the development of quantum mechanics. The first useful quantum atomic models, including Bohr model, the Schr\u00f6dinger equation, and Matrix mechanics, reproduced the spectral lines of hydrogen. These equated discrete quantum jumps of the bound electron in a hydrogen atom to the discrete hydrogen spectrum. Max Planck's explanation of blackbody radiation involved spectroscopy because he was comparing the wavelength of light using a photometer to the temperature of a Black Body. Spectroscopy is used in physical and analytical chemistry because atoms and molecules have unique spectra. As a result, these spectra can be used to detect, identify and quantify information about the atoms and molecules.\nSpectroscopy is used in astronomy and remote sensing on Earth. Most research telescopes have spectrographs. The measured spectra are used to determine the chemical composition and physical properties of astronomical objects, such as their temperature, elemental abundances, velocity, rotation, magnetic field, and more. An important use for spectroscopy is in biochemistry. Molecular samples may be analyzed for species identification and energy content.\nTheory.\nThe underlying premise of spectroscopy is that light is made of different wavelengths and that each wavelength corresponds to a different frequency. The importance of spectroscopy is centered around the fact that every element in the periodic table has a unique light spectrum described by the frequencies of light it emits or absorbs consistently appearing in the same part of the electromagnetic spectrum when that light is diffracted. This opened up an entire field of study with anything that contains atoms. Spectroscopy is the key to understanding the atomic properties of all matter. As such spectroscopy opened up many new sub-fields of science yet undiscovered. The idea that each atomic element has its unique spectral signature enabled spectroscopy to be used in a broad number of fields each with a specific goal achieved by different spectroscopic procedures. The National Institute of Standards and Technology maintains a public Atomic Spectra Database that is continually updated with precise measurements.\nWith an absorption spectrophotometer, the level of absorption of a light source is determined by the Beer-Lambert Law:\nformula_1\nwhere formula_2 is the light intensity before passing through the sample, formula_3 is the output intensity, formula_4 is the extinction coefficient, formula_5 is the path length through the sample, and formula_6 is the concentration of the sample. The extinction coefficient depends on the wavelength selected and the molecule being sampled.\nResonances by the frequency were first characterized in mechanical systems such as pendulums, which have a frequency of motion noted famously by Galileo. In quantum mechanical systems, the analogous resonance is a coupling of two quantum mechanical stationary states of a system, such as two atomic orbitals, via an oscillatory source of energy such as a photon. The coupling of the two states is strongest when the source energy matches the energy difference between the two states. That is, a photon at the right energy is more likely to cause an electron to jump between two orbitals, a process called electron excitation. The energy E of a photon is related to its frequency \u03bd by \"E\" \n \"h\u03bd\" where h is the Planck constant, and so a spectrum of the system response vs. photon frequency will peak at the resonant frequency or energy.\nAny part of the electromagnetic spectrum may be used to analyze a sample from the infrared to the ultraviolet telling scientists different properties about the very same sample, a discovery that led to a broadening of the field of spectroscopy. For instance in chemical analysis, the most common types of spectroscopy include atomic spectroscopy, infrared spectroscopy, ultraviolet and visible spectroscopy, Raman spectroscopy and nuclear magnetic resonance. In nuclear magnetic resonance (NMR), the theory behind it is that frequency is analogous to resonance and its corresponding resonant frequency.\nClassification of methods.\nSpectroscopy is a sufficiently broad field that many sub-disciplines exist, each with numerous implementations of specific spectroscopic techniques. The various implementations and techniques can be classified in several ways.\nType of radiative energy.\nThe types of spectroscopy are distinguished by the type of radiative energy involved in the interaction. In many applications, the spectrum is determined by measuring changes in the intensity or frequency of this energy. The types of radiative energy studied include:\nNature of the interaction.\nThe types of spectroscopy also can be distinguished by the nature of the interaction between the energy and the material. These interactions include:\nType of material.\nSpectroscopic studies are designed so that the radiant energy interacts with specific types of matter.\nAtoms.\nAtomic spectroscopy was the first application of spectroscopy. Atomic absorption spectroscopy and atomic emission spectroscopy involve visible and ultraviolet light. These absorptions and emissions, often referred to as atomic spectral lines, are due to electronic transitions of outer shell electrons as they rise and fall from one electron orbit to another. Atoms also have distinct x-ray spectra that are attributable to the excitation of inner shell electrons to excited states.\nAtoms of different elements have distinct spectra and therefore atomic spectroscopy allows for the identification and quantitation of a sample's elemental composition. After inventing the spectroscope, Robert Bunsen and Gustav Kirchhoff discovered new elements by observing their emission spectra. Atomic absorption lines are observed in the solar spectrum and referred to as Fraunhofer lines after their discoverer. A comprehensive explanation of the hydrogen spectrum was an early success of quantum mechanics and explained the Lamb shift observed in the hydrogen spectrum, which further led to the development of quantum electrodynamics.\nModern implementations of atomic spectroscopy for studying visible and ultraviolet transitions include flame emission spectroscopy, inductively coupled plasma atomic emission spectroscopy, glow discharge spectroscopy, microwave induced plasma spectroscopy, and spark or arc emission spectroscopy. Techniques for studying x-ray spectra include X-ray spectroscopy and X-ray fluorescence.\nMolecules.\nThe combination of atoms into molecules leads to the creation of unique types of energetic states and therefore unique spectra of the transitions between these states. Molecular spectra can be obtained due to electron spin states (electron paramagnetic resonance), molecular rotations, molecular vibration, and electronic states. Rotations are collective motions of the atomic nuclei and typically lead to spectra in the microwave and millimetre-wave spectral regions. Rotational spectroscopy and microwave spectroscopy are synonymous. Vibrations are relative motions of the atomic nuclei and are studied by both infrared and Raman spectroscopy. Electronic excitations are studied using visible and ultraviolet spectroscopy as well as fluorescence spectroscopy.\nStudies in molecular spectroscopy led to the development of the first maser and contributed to the subsequent development of the laser.\nCrystals and extended materials.\nThe combination of atoms or molecules into crystals or other extended forms leads to the creation of additional energetic states. These states are numerous and therefore have a high density of states. This high density often makes the spectra weaker and less distinct, i.e., broader. For instance, blackbody radiation is due to the thermal motions of atoms and molecules within a material. Acoustic and mechanical responses are due to collective motions as well.\nPure crystals, though, can have distinct spectral transitions, and the crystal arrangement also has an effect on the observed molecular spectra. The regular lattice structure of crystals also scatters x-rays, electrons or neutrons allowing for crystallographic studies.\nNuclei.\nNuclei also have distinct energy states that are widely separated and lead to gamma ray spectra. Distinct nuclear spin states can have their energy separated by a magnetic field, and this allows for nuclear magnetic resonance spectroscopy.\nOther types.\nOther types of spectroscopy are distinguished by specific applications or implementations:\nApplications.\nThere are several applications of spectroscopy in the fields of medicine, physics, chemistry, and astronomy. Taking advantage of the properties of absorbance and, with astronomy, emission, spectroscopy can be used to identify certain states of nature. The uses of spectroscopy in so many different fields and for so many different applications has caused specialty scientific subfields. Such examples include:\nHistory.\nThe history of spectroscopy began with Isaac Newton's optics experiments (1666\u20131672). According to Andrew Fraknoi and David Morrison, \"In 1672, in the first paper that he submitted to the Royal Society, Isaac Newton described an experiment in which he permitted sunlight to pass through a small hole and then through a prism. Newton found that sunlight, which looks white to us, is actually made up of a mixture of all the colors of the rainbow.\" Newton applied the word \"spectrum\" to describe the rainbow of colors that combine to form white light and that are revealed when the white light is passed through a prism.\nFraknoi and Morrison state that \"In 1802, William Hyde Wollaston built an improved spectrometer that included a lens to focus the Sun's spectrum on a screen. Upon use, Wollaston realized that the colors were not spread uniformly, but instead had missing patches of colors, which appeared as dark bands in the spectrum.\" During the early 1800s, Joseph von Fraunhofer made experimental advances with dispersive spectrometers that enabled spectroscopy to become a more precise and quantitative scientific technique. Since then, spectroscopy has played and continues to play a significant role in chemistry, physics, and astronomy. Per Fraknoi and Morrison, \"Later, in 1815, German physicist Joseph Fraunhofer also examined the solar spectrum, and found about 600 such dark lines (missing colors), are now known as Fraunhofer lines, or Absorption lines.\"\nSpectra of atoms and molecules often consist of a series of spectral lines, each one representing a resonance between two different quantum states. The explanation of these series, and the spectral patterns associated with them, were one of the experimental enigmas that drove the development and acceptance of quantum mechanics. The hydrogen spectral series in particular was first successfully explained by the Rutherford\u2013Bohr quantum model of the hydrogen atom. In some cases spectral lines are well separated and distinguishable, but spectral lines can also overlap and appear to be a single transition if the density of energy states is high enough. Named series of lines include the principal, sharp, diffuse and fundamental series.\nHobbyist.\nSpectroscopy has emerged as a growing practice within the maker movement, enabling hobbyists and educators to construct functional spectrometers using readily available materials. Utilizing components like CD/DVD diffraction gratings, smartphones, and 3D-printed parts, these instruments offer a hands-on approach to understanding light and matter interactions. Smartphone applications along with open-source tools facilitate integration, greatly simplify the capturing and analysis of spectral data. While limitations in resolution, calibration accuracy, and stray light management exist compared to professional equipment, DIY spectroscopy provides valuable educational experiences and contributes to citizen science initiatives, fostering accessibility to spectroscopic techniques.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27753", "revid": "933709", "url": "https://en.wikipedia.org/wiki?curid=27753", "title": "List of science fiction themes", "text": "The following is a list of articles about recurring themes in science fiction.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27754", "revid": "1317307591", "url": "https://en.wikipedia.org/wiki?curid=27754", "title": "Samaritanism", "text": "Abrahamic monotheistic ethnic religion \nSamaritanism (; ) is an Abrahamic monotheistic ethnic religion. It comprises the collective spiritual, cultural, and legal traditions of the Samaritan people, who originate from the Hebrews and Israelites and began to emerge as a relatively distinct group after the Kingdom of Israel was conquered by the Neo-Assyrian Empire during the Iron Age. Central to the faith is the Samaritan Pentateuch, which Samaritans believe is the original and unchanged version of the Torah.\nAlthough it developed alongside and is closely related to Judaism, Samaritanism asserts itself as the truly preserved form of the monotheistic faith that the Israelites adopted under Moses. Samaritan belief also holds that the Israelites' original holy site was Mount Gerizim, near Nablus, and that Jerusalem only attained importance under Israelite dissenters who had followed Eli to the city of Shiloh; the Israelites who remained at Mount Gerizim would become the Samaritans in the Kingdom of Israel, whereas the Israelites who left would become the Jews in the Kingdom of Judah. Mount Gerizim is likewise revered by Samaritans as the location where the Binding of Isaac took place, in contrast to the Jewish belief that it occurred at Jerusalem's Temple Mount.\nToday there are only about 900 followers, which makes Samaritanism one of the smallest religions globally.\nHistory.\nTraditional accounts.\nSamaritanism holds that the summit of Mount Gerizim is the true location of God's Holy Place. Samaritans trace their history as a separate entity to a period soon after the Israelites' entry into the Promised Land. Samaritan historiography traces the schism to High Priest Eli leaving Mount Gerizim, where stood the first Israelite altar in Canaan, and building a competing altar in nearby Shiloh. The dissenting group of Israelites who had followed Eli to Shiloh would be the ones who in later years would head south to settle Jerusalem (the Jews), whereas the Israelites who stayed on Mount Gerizim, in Samaria, would become known as the Samaritans.\nAbu l-Fath, who wrote a major work of Samaritan history in the 14th century, comments on Samaritan origins as follows:\nA terrible civil war broke out between Eli son of Yafni, of the line of Ithamar, and the sons of Pincus (Phinehas), because Eli son of Yafni resolved to usurp the High Priesthood from the descendants of Pincus. He used to offer sacrifices on an altar of stones. He was 50 years old, endowed with wealth and in charge of the treasury of the Children of Israel. ...\nHe offered a sacrifice on the altar, but without salt, as if he were inattentive. When the Great High Priest Ozzi learned of this, and found the sacrifice was not accepted, he thoroughly disowned him; and it is (even) said that he rebuked him.\nThereupon he and the group that sympathized with him, rose in revolt and at once he and his followers and his beasts set off for Shiloh. Thus Israel split in factions. He sent to their leaders saying to them, \"Anyone who would like to see wonderful things, let him come to me.\" Then he assembled a large group around him in Shiloh, and built a Temple for himself there; he constructed a place like the Temple [on Mount Gerizim]. He built an altar, omitting no detail\u2014it all corresponded to the original, piece by piece.\nAt this time the Children of Israel split into three factions. A loyal faction on Mount Gerizim; a heretical faction that followed false gods; and the faction that followed Eli son of Yafni in Shiloh.\nFurther, the \"Samaritan New Chronicle\" or \"Adler\", named after its editor Elkan Nathan Adler (1861\u20131946), which is believed to have been composed in the 18th century using earlier chronicles as sources, states:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;And the Children of Israel in his days divided into three groups. One did according to the abominations of the Gentiles and served other gods; another followed Eli the son of Yafni, although many of them turned away from him after he had revealed his intentions; and a third remained with the High Priest Uzzi ben Bukki, the chosen place.\nScholarly perspective.\nModern genetic studies (2004) suggest that Samaritans' lineages trace back to a common ancestor with Jews in the paternally-inherited Jewish high priesthood (Cohanim) temporally proximate to the period of the Assyrian conquest of the kingdom of Israel, and are probably descendants of the historical Israelite population. The religion of the proto-Samaritans at this time was probably no different than that of their southern counterparts in Judea. This likely remained the case for several centuries after the destruction of the Kingdom of Israel, as Judean cultic reforms instituted by the kings Hezekiah and Josiah experience little opposition extending to the Samaritan people in the north, according to the biblical text.\nThough Samaritans certainly were culturally unique, they were closely intertwined with the Jews to the south. As such, Samaritanism likely did not emerge as a distinct tradition until the Hasmonean and Roman era, by which point Yahwism had coalesced into Second Temple Judaism. The temple on Mount Gerizim, the central place of worship in Samaritanism, was built in the 5th century BCE, as one of many Yahwistic temples in Samaria. However, the temple precinct experienced a centuries-long period of large-scale construction beginning around the 4th century BCE, which indicates that its status as the pre-eminent place of worship among Samaritans had only just been established. Likewise, theological debates between Jews and Samaritans are attested as early as the 2nd century BCE, indicating that the Samaritan Pentateuch had already taken shape, in some form.\nThe Hasmonean king John Hyrcanus destroyed the Mount Gerizim temple and brought Samaria under his control around 120 BCE, which led to a longlasting sense of mutual hostility between the Jews and Samaritans. From this point, the Samaritans likely sought to consciously distance themselves from their Judean brethren, and both peoples came to see the Samaritan faith as a religion distinct from Judaism.\nThe relationship between Jews and Samaritans only further deteriorated with time. By the time of Jesus, Samaritans and Jews deeply disparaged one another, as evinced by Jesus' Parable of the Good Samaritan.\nBeliefs.\nThe principal beliefs of Samaritanism are as follows:\nFestivals and observances.\nThe Samaritans have conserved the institution of a high priesthood and the practice of slaughtering and eating lambs on Passover eve. They celebrate Pesach, Shavuot, and Sukkot, but use a different mode from that employed in Judaism in order to determine the dates annually. Yom Teru'ah (the Biblical name for \"Rosh Hashanah\"), at the beginning of Tishrei, is not considered a New Year as it is in Rabbinic Judaism.\nThe sabbath is observed weekly by the Samaritan community every week from Friday to Saturday beginning and ending at sundown. For 24 hours, the families gather together to celebrate the rest day: all electricity with the exception of minimal lighting (kept on the entire day) in the house is disconnected, no work is done, and neither cooking nor driving is allowed. The time is devoted to worship which consists of seven prayer services (divided into two for sabbath eve, two in the morning, two in afternoon and one at eve of conclusion), reading the weekly Torah portion (according to the Samaritan yearly Torah cycle), spending quality time with family, taking meals, rest and sleep, and visiting other members of the community.\nPassover is particularly important in the Samaritan community, climaxing with the sacrifice of up to 40 sheep. The Counting of the Omer remains largely unchanged; however, the week before Shavuot is a unique festival celebrating the continued commitment Samaritanism has maintained since the time of Moses. Shavuot is characterized by nearly day-long services of continuous prayer, especially over the stones on Gerizim traditionally attributed to Joshua. \nDuring Sukkot, the sukkah is built inside houses, as opposed to outdoor settings that are traditional among Jews. Samaritan historian Benyamim Tsedaka traces the indoor-sukkah tradition to persecution of Samaritans during the Byzantine Empire. The roof of the Samaritan sukkah is decorated with citrus fruits and the branches of palm, myrtle, and willow trees, according to the Samaritan interpretation of the four species designated in the Torah for the holiday.\nReligious texts.\nSamaritan law differs from Halakha (Rabbinic Jewish law) and other Jewish movements. The Samaritans have several groups of religious texts, which correspond to Jewish Halakha. A few examples of such texts are:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27760", "revid": "43067996", "url": "https://en.wikipedia.org/wiki?curid=27760", "title": "Statute of Anne", "text": "1710 British copyright legislation\nThe Statute of Anne, also known as the Copyright Act 1709 or the Copyright Act 1710 (cited either as 8 Ann. c. 21 or as 8 Ann. c. 19), was an act of the Parliament of Great Britain passed in 1710, which was the first statute to provide for copyright regulated by the government and courts, rather than by private parties.\nPrior to the statute's enactment in 1710, copying restrictions were authorised by the Licensing of the Press Act 1662 (14 Cha. 2. c. 33). These restrictions were enforced by the Stationers' Company, a guild of printers given the exclusive power to print\u2014and the responsibility to censor\u2014literary works. The censorship administered under the 1662 act led to public protest; as the act had to be renewed at two-year intervals, authors and others sought to prevent its reauthorisation. Following the expiry of the 1662 act in 1694, Parliament refused to renew the act, ending the Stationers' monopoly and press restrictions.\nOver the next 10 years the Stationers repeatedly advocated bills to re-authorise the old licensing system, but Parliament declined to enact them. Faced with this failure, the Stationers decided to emphasise the benefits of licensing to authors rather than publishers, and the Stationers succeeded in getting Parliament to consider a new bill. On 12 December 1709, the Stationers submitted yet another petition asking for legislation on the issue, and the House of Commons gave three MPs \u2013 Spencer Compton, Craven Peyton and Edward Wortley \u2013 permission to form a drafting committee. On 11 January 1710, Wortley introduced this bill, titling it \"A Bill for the Encouragement of Learning and for Securing the Property of Copies of Books to the rightful Owners thereof\". This bill, which after substantial amendments was granted royal assent on 5 April 1710, became known as the Statute of Anne owing to its passage during the reign of Queen Anne. The new law prescribed a copyright term of 14 years, with a provision for renewal for a similar term, during which only the author and the printers to whom they chose to license their works could publish the author's creations. Following this, the work's copyright would expire, with the material falling into the public domain. Despite a period of instability known as the Battle of the Booksellers when the initial copyright terms under the statute began to expire, the statute remained in force until the Copyright Act 1842 (5 &amp; 6 Vict. c. 45) replaced it.\nThe statute is considered a \"watershed event in Anglo-American copyright history\u00a0... transforming what had been the publishers' private law copyright into a public law grant\". Under the statute, copyright was for the first time vested in authors rather than publishers; it also included provisions for the public interest, such as a legal deposit scheme. The statute was an influence on copyright law in several other nations, including the United States, and even in the 21st century is \"frequently invoked by modern judges and academics as embodying the utilitarian underpinnings of copyright law\".\nBackground.\nWith the introduction of the printing press to England by William Caxton in 1476, printed works became both more common and more economically important. As early as 1483, Richard III recognised the value of literary works by specifically exempting them from the government's protectionist legislation. Over the next fifty years, the government moved further towards economic regulation, abolishing the provision with the Printers and Binders Act 1533 (25 Hen. 8. c. 15), which also banned the import of foreign works and empowered the Lord Chancellor to set maximum pricing for English books. This was followed by increasing degrees of censorship. A further proclamation of 1538, aiming to stop the spread of Lutheran doctrine, saw Henry VIII note that \"sondry contentious and sinyster opiniones, have by wrong teachynge and naughtye bokes increaced and growen within this his realme of England\", and declare that all authors and printers must allow the Privy Council or their agents to read and censor books before publication.\nStationers' Company.\nThis censorship peaked on 4 May 1557, when Mary I issued a royal warrant formally incorporating the Stationers' Company. The old method of censorship had been limited by the Second Statute of Repeal, and with Mary's increasing unpopularity the existing system was unable to cope with the number of critical works being printed. Instead, the royal warrant devolved this power to the company. This was done by decreeing that only the company's publishers could print and distribute books. Their Wardens were given the power to enter any printing premises, destroy illegal works and imprison anyone found manufacturing them. In this way the government \"harnessed the self interest of the publishers to the yoke of royal incentive\", guaranteeing that the company would follow the rules due to the economic monopoly it gave their members. With the abolition of the Star Chamber and Court of High Commission by the Long Parliament, the legal basis for this warrant was removed, but the Long Parliament chose to replace it with the Licensing Act 1662 (14 Cha. 2. c. 33). This provided that the company would retain their original powers, and imposed additional restrictions on printing; King's Messengers were permitted to enter any home or business in search of illegal presses. The legislation required renewal every two years, and was regularly reapproved.\nThis was not \"copyright\" as is normally understood; although there was a monopoly on the right to copy, this was available to publishers, not authors, and did not exist by default; it only applied to books which had been accepted and published by the company. A member of the company would register the book, and would then have a perpetual copyright over its printing, copying and publication, which could be leased, transferred to others or given to heirs upon the member's death. The only exception to this was that, if a person tried to make a copy of a copyrighted material and warned the owner of the copyright (i.e. the printer), and the owner did not reprint it within six months, then this person could continue with the printing (provided that the author of the material did not object), giving a \"ratable\" part of the profits to the owner of the copyright. This did not mean, though, a loss of copyright ownership, but a provision to allow other presses the right to reprint books that were unavailable. Authors themselves were not particularly respected until the 18th century, and were not permitted to be members of the company, playing no role in the development or use of its licences despite the company's sovereign authority to decide what was published. There is evidence that some authors were recognised by the Company itself to have the right to copy and the right to alter their works; these authors were uniformly the writers of uneconomical books who were underwriting their publication.\nThe company's monopoly, censorship and failure to protect authors made the system highly unpopular; John Milton wrote \"Areopagitica\" as a result of his experiences with the company, accusing Parliament of being deceived by \"the fraud of some old patentees and monopolisers in the trade of bookselling\". He was not the first writer to criticise the system, with John Locke writing a formal memorandum to the MP Edward Clarke in 1693 while the Licensing Act was being renewed, complaining that the existing system restricted the free exchange of ideas and education while providing an unfair monopoly for Company members. Academic Mark Rose attributes the efforts of Milton to promote the \"bourgeois public sphere\", along with the Glorious Revolution's alterations to the political system and the rise of public coffee houses, as the source of growing public unhappiness with the system. At the same time, this was a period in which clearly defined political parties were taking shape, and with the promise of regular elections, an environment where the public were of increasing importance to the political process. The result was a \"developing public sphere [which] provided the context that enabled the collapse of traditional press controls\".\nLapse of the Licensing of the Press Act 1662.\nThe Licensing of the Press Act 1662 (14 Cha. 2. c. 33), which was continued by the Licensing of the Press Act 1664 (16 Cha. 2. c. 8), the Licensing of the Press (No. 2) Act 1664 (16 &amp; 17 Cha. 2. c. 7), the Licensing of the Press Act 1665 (17 Cha. 2. c. 4), the Administration of Intestates' Estate Act 1685 (1 Ja. 2. c. 17) and the Estreats (Personal Representatives) Act 1692 (4 Will. &amp; Mar. c. 24), lapsed in 25 April 1694.\nIn November 1694, a committee was appointed by the Commons to see what laws were \"lately expired and expiring [and] fit to be revived and continued\". The Committee reported in January 1695, and suggested the renewal of the 1662 act; this was included in the \"Continuation Bill\", but rejected by the House of Commons on 11 February. When it reached the House of Lords, the Lords re-included the 1662 act, and returned the bill to the Commons. In response, a second committee was appointed \u2013 this one to produce a report indicating why the Commons disagreed with the inclusion of the Licensing Act, and chaired by Edward Clarke. This committee soon reported to the Commons, and Clarke was ordered to carry a message to the Lords requesting a conference over the 1662 act. On 18 April 1695, Clarke met with representatives of the Lords, and they agreed to allow the Continuation Bill to pass without the renewal of the act. With this, \"the Lords' decision heralded an end to a relationship that had developed throughout the sixteenth and seventeenth centuries between the State and the Company of Stationers\", ending both nascent publishers' copyright and the existing system of censorship.\nJohn Locke's close relationship with Clarke, along with the respect he commanded, is seen by academics as what led to this decision. Locke had spent the early 1690s campaigning against the statute, considering it \"ridiculous\" that the works of dead authors were held perpetually in copyright. In letters to Clarke he wrote of the absurdity of the existing system, complaining primarily about the unfairness of it to authors, and \"[t]he parallels between Locke's commentary and those reasons presented by the Commons to the Lords for refusing to renew the 1662 act are striking\". He was assisted by a number of independent printers and booksellers, who opposed the monopolistic aspects of the act, and introduced a petition in February 1693 that the act prevented them from conducting their business. The \"developing public sphere\", along with the harm the existing system had caused to both major political parties, is also seen as a factor.\nThe failure to renew the Licensing Act led to confusion and both positive and negative outcomes; while the government no longer played a part in censoring publications, and the monopoly of the Company over printing was broken, there was uncertainty as to whether or not copyright was a binding legal concept without the legislation. Economic chaos also resulted; with the company now unable to enforce any monopoly, provincial towns began establishing printing presses, producing cheaper books than the London booksellers. The absence of the censorship provisions also opened Britain up as a market for internationally printed books, which were similarly cheaper than those British printers could produce.\nAttempts at replacement.\nThe rejection of the existing system was not done with universal approval, and there were ultimately twelve unsuccessful attempts to replace it. The first was introduced to the House of Commons on 11 February 1695. A committee, again led by Clarke, was to write a \"Bill for the Better Regulating of Printing and the Printing Presses\". This bill was essentially a copy of the Licensing Act, but with a narrower jurisdiction; only books covering religion, history, the affairs of the state or the law would require official authorisation. Four days after its introduction, the Stationers' held an emergency meeting to agree to petition the Commons \u2013 this was because the bill did not contain any reference to books as property, eliminating their monopoly on copying. Clarke also had issues with the provisions, and the debate went on until the end of the Parliamentary session, with the bill failing to pass.\nWith the end of the Parliamentary session came the first general election under the Triennial Act 1694 (6 &amp; 7 Will. &amp; Mar. c. 2), which required the Monarch to dissolve Parliament every 3 years, causing a general election. This led to the \"golden age\" of the English electorate, and allowed for the forming of two major political parties \u2013 the Whigs and Tories. At the same time, with the failure to renew the 1662 act, a political press developed. While the act had been in force only one official newspaper existed; the \"London Gazette\", published by the government. After its demise, a string of newspapers sprang into being, including the \"Flying Post\", the \"Evening Post\" and the \"Daily Courant\". Newspapers had a strong bias towards particular parties, with the \"Courant\" and the \"Flying Post\" supporting the Whigs and the \"Evening Post\" in favour of the Tories, leading to politicians from both parties realising the importance of an efficient propaganda machine in influencing the electorate. This added a new dimension to the Commons' decision to reject two new renewals of the Licensing Act in the new Parliamentary session.\nAuthors, as well as Stationers, then joined the demand for a new system of licensing. Jonathan Swift was a strong advocate for licensing, and Daniel Defoe wrote on 8 November 1705 that with the absence of licensing, \"One Man Studies Seven Year, to bring a finish'd Peice into the World, and a Pyrate Printer, Reprints his Copy immediately, and Sells it for a quarter of the Price\u00a0... these things call for an Act of Parliament\". Seeing this, the Company took the opportunity to experiment with a change to their approach and argument. Instead of lobbying because of the effect the absence of legislation was having on their trade, they lobbied on behalf of the authors, but seeking the same things. The first indication of this change in approach comes from the 1706 pamphlet by John How, a stationer, titled \"Reasons humbly Offer'd for a Bill for the Encouragement of Learning and the Improvement of Printing\". This argued for a return to licensing, not with reference to the printers, but because without something to protect authors and guarantee them an income, \"Learned men will be wholly discouraged from Propagating the most useful Parts of Knowledge and Literature\". Using these new tactics and the support of authors, the Company petitioned Parliament again in both 1707 and 1709 to introduce a bill providing for copyright.\nAct.\nPassage.\nAlthough both bills failed, they led to media pressure that was exacerbated by both Defoe and How. Defoe's \"A Review\", published on 3 December 1709 and demanding \"a Law in the present Parliament\u00a0... for the Encouragement of Learning, Arts, and Industry, by securing the Property of Books to the Authors or Editors of them\", was followed by How's \"Some Thoughts on the Present State of Printing and Bookselling\", which hoped that Parliament \"might think fit to secure Property in Books by a Law\". This was followed by another review by Defoe on 6 December, in which he even went so far as to provide a draft text for the bill. On 12 December, the Stationers submitted yet another petition asking for legislation on the issue, and the House of Commons gave three MPs \u2013 Spencer Compton, Craven Peyton and Edward Wortley \u2013 permission to form a drafting committee. On 11 January 1710, Wortley introduced this bill, titling it \"A Bill for the Encouragement of Learning and for Securing the Property of Copies of Books to the rightful Owners thereof\".\nThe bill imposed fines on anyone who imported or traded in unlicensed or foreign books, required every book for which copyright protection was sought to be entered into the Stationers' Register, provided a legal deposit system centred around the King's Library, the University of Oxford and the University of Cambridge, but said nothing about limiting the term of copyright. It also specified that books were property; an emphasis on the idea that authors deserved copyright simply due to their efforts. The Stationers were enthusiastic, urging Parliament to pass the bill, and it received its second reading on 9 February. A Committee of the Whole met to amend it on 21 February, with further alterations made when it was passed back to the House of Commons on 25 February. Alterations during this period included minor changes, such as extending the legal deposit system to cover Sion College and the Faculty of Advocates, but also major ones, including the introduction of a limit on the length of time for which copyright would be granted.\nLinguistic amendments were also included; the line in the preamble emphasising that authors possessed books as they would any other piece of property was dropped, and the bill moved from something designed \"for Securing the Property of Copies of Books to the rightful Owners thereof\" to a bill \"for the Encouragement of Learning, by Vesting the Copies of Printed Books in the Authors or Purchasers of such Copies\". Another amendment allowed anyone to own and trade in copies of books, undermining the Stationers. Other changes were made when the bill went to the House of Lords, and it was finally returned to the Commons on 5 April. The aims of the resulting statute are debated; Ronan Deazley suggests that the intent was to balance the rights of the author, publisher and public in such a way as to ensure the maximum dissemination of works, while other academics argue that the bill was intended to protect the company's monopoly or, conversely, to weaken it. Oren Bracha, writing in the \"Berkeley Technology Law Journal\", says that when considering which of these options are correct, \"the most probable answer [is] all of them\". Whatever the motivations, the bill was passed on 5 April 1710, and is commonly known simply as the Statute of Anne due its passage during the reign of Queen Anne.\nText.\nConsisting of 11 sections, the Statute of Anne is formally titled \"An Act for the Encouragement of Learning, by Vesting the Copies of Printed Books in the Authors or Purchasers of Copies, during the Times therein mentioned\". The preamble for the statute indicates the purpose of the legislation \u2013 to bring order to the book trade \u2013 saying: &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Whereas Printers, Booksellers, and other Persons, have of late frequently taken the Liberty of Printing, Reprinting, and Publishing, or causing to be Printed, Reprinted, and Published Books, and other Writings, without the Consent of the Authors or Proprietors of such Books and Writings, to their very great Detriment, and too often to the Ruin of them and their Families: For Preventing therefore such Practices for the future, and for the Encouragement of Learned Men to Compose and Write useful Books; May it please Your Majesty, that it may be Enacted\u00a0...\nThe statute then continued by stating the nature of copyright. The right granted was the right to copy; to have sole control over the printing and reprinting of books, with no provision to benefit the owner of this right after the sale. This right, previously held by the Stationers' Company's members, would automatically be given to the author as soon as it was published, although they had the ability to license these rights to another person. The copyright could be gained through two stages; first, the registration of the book's publication with the company, to prevent unintentional infringement, and second, the deposit of copies of the book at the Stationers' Company, the royal library and various universities. One restriction on copyright was a \"cumbersome system\" designed to prohibit unreasonably high prices for books, which limited how much authors could charge for copies. There was also a prohibition on importing foreign works, with exceptions made for Latin and Greek classics.\nOnce registration had been completed and the deposits were made, the author was granted an exclusive right to control the copying of the book. Penalties for infringing this right were severe, with all infringing copies to be destroyed and large fines to be paid to both the copyright holder and the government; there was only a three-month statute of limitations on bringing a case, however. This exclusive right's length was dependent on when the book had been published. If it was published after 10 April 1710, the length of copyright was 14 years; if published before that date, 21 years. An author who survived until the copyright expired would be granted an additional 14-year term, and when that ran out, the works would enter the public domain. Copyright under the statute applied to Scotland and England, as well as Ireland when that country joined the union in 1800.\nAftermath.\nImpact.\nThe statute was initially welcomed, ushering in \"stability to an insecure book trade\" while providing for a \"pragmatic bargain\" between the rights of the author, publisher and public intended to boost public learning and the availability of knowledge. The clause requiring book deposits, however, was not seen as a success. If the books were not deposited, the penalties would be severe, with a fine of \u00a35. The number of deposits required, however, meant that it was a substantial burden; a print run might only be of 250 copies, and if they were particularly expensive to print, it could be cheaper to ignore the law. Some booksellers argued that the deposit provision only applied to registered books, and so deliberately avoided registration just to be able to minimise their liability. This was further undermined by the ruling in \"Beckford v Hood\", where the Court of King's Bench confirmed that, even without registration, copyright could be enforced against infringers.\nAnother failure, identified by Bracha, is not found in what the statute covered, but in what it did not. The statute did not provide any means for identifying authors, did not identify what constituted authored works, and covered only \"books\", even while discussing \"property\" as a whole. Moreover, the right provided was merely that of \"making and selling\u00a0... exact reprints. To a large extent, the new regime was the old stationer's privilege, except it was universalised, capped in time, and formally conferred upon authors rather than publishers\". The effect of the statute on authors was also minimal. Previously, publishers would have bought the original manuscript from writers for a lump sum; with the passage of the statute, they simply did the same thing, but with the manuscript's copyright as well. The remaining economic power of the company also allowed them to pressure booksellers and distributors into continuing their past arrangements, meaning that even theoretically \"public domain\" works were, in practise, still treated as copyrighted.\nBattle of the Booksellers.\nWhen the copyrights granted to works published before the statute began to expire in 1731, the Stationers' Company and their publishers again began to fight to preserve the status quo. Their first port of call was Parliament, where they lobbied for new legislation to extend the length of copyright, and when this failed, they turned to the courts. Their principal argument was that copyright had not been created by the Statute of Anne; it existed beforehand, in the common law, and was perpetual. As such, even though the statute provided for a limited term, all works remained in copyright under the common law regardless of when statutory copyright expired. Starting in 1743, this began a thirty-year campaign known as the \"Battle of the Booksellers\". They first tried going to the Court of Chancery and applying for injunctions prohibiting other publishers from printing their works, and this was initially successful. A series of legal setbacks over the next few years, however, left the law ambiguous.\nThe first major action taken to clarify the situation was \"Millar v Taylor\". Andrew Millar, a British publisher, purchased the rights to James Thomson's \"The Seasons\" in 1729, and when the copyright term expired, a competing publisher named Robert Taylor began issuing his own reprints of the work. Millar sued, and went to the Court of King's Bench to obtain an injunction and advocate perpetual copyright at common law. The jury found that the facts submitted by Millar were accurate, and asked the judges to clarify whether common law copyright existed. The first arguments were delivered on 30 June 1767, with John Dunning representing Millar and Edward Thurlow representing Taylor. A second set of arguments were submitted for Millar by William Blackstone on 7 June, and judgment was given on 20 April 1769. The final decision, written by Lord Mansfield and endorsed by Aston and Willes JJ, confirmed that there existed copyright at common law that turned \"upon Principles before and independent\" of the Statute of Anne, something justified because it was right \"that an Author should reap the pecuniary Profits of his own Ingenuity and Labour\". In other words, regardless of the statute, there existed a perpetual copyright under the common law. Yates J dissented, on the grounds that the focus on the author obscured the effect this decision would have on \"the rest of mankind\", which he felt would be to create a virtual monopoly, something that would harm the public and should certainly not be considered \"an encouragement of the propagation of learning\".\nAlthough this decision was a boon to the Stationers, it was short-lived. Following \"Millar\", the right to print \"The Seasons\" was sold to a coalition of publishers including Thomas Becket. Two Scottish printers, Alexander and John Donaldson, began publishing an unlicensed edition, and Becket successfully obtained an injunction to stop them. This decision was appealed in \"Donaldson v Beckett\", and eventually went to the House of Lords. After consulting with the judges of the King's Bench, Common Pleas and Exchequer of Pleas, the Lords concluded that copyright was not perpetual, and that the term permitted by the Statute of Anne was the maximum length of legal protection for publishers and authors alike.\nExpansion and repeal.\nUntil its repeal, most extensions to copyright law were based around provisions found in the Statute of Anne. The one successful bill from the lobbying in the 1730s, which came into force on 29 September 1739, extended the provision prohibiting the import of foreign books to also prohibit the import of books that, while originally published in Britain, were being reprinted in foreign nations and then shipped to England and Wales. This was intended to stop the influx of cheap books from Ireland, and also repealed the price restrictions in the Statute of Anne. Another alteration was over the legal deposit provisions of the statute, which many booksellers found unfair. Despite an initial period of compliance, the principle of donating copies of books to certain libraries lapsed, partly due to the unwieldiness of the statute's provisions and partly because of a lack of cooperation by the publishers. In 1775 Lord North, who was Chancellor of the University of Oxford, succeeded in passing a bill that reiterated the legal deposit provisions and granted the universities perpetual copyright on their works.\nAnother range of extensions came in relation to what could be copyrighted. The statute only referred to books, and being an act of Parliament, it was necessary to pass further legislation to include various other types of intellectual property. The Engraving Copyright Act 1734 (8 Geo. 2. c. 13) extended copyright to cover engravings, statutes in 1789 and 1792 involved cloth, sculptures were copyrighted in 1814 and the performance of plays and music were covered by copyright in 1833 and 1842 respectively. The length of copyright was also altered; the &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Copyright Act 1814 (54 Geo. 3. c. 156) set a copyright term of either 28 years, or the natural life of the author if this was longer. Despite these expansions, some still felt copyright was not a strong enough regime. In 1837, Thomas Noon Talfourd introduced a bill into Parliament to expand the scope of copyright. A friend of many men of letters, Talfourd aimed to provide adequate rewards for authors and artists. He campaigned for copyright to exist for the life of the author, with an additional 60 years after that. He also proposed that existing statutes be codified under the bill, so that the case law that had arisen around the Statute of Anne was clarified.\nTalfourd's proposals led to opposition, and he reintroduced modified versions of them year on year. Printers, publishers and booksellers were concerned about the cost implications for original works, and for reprinting works that had fallen out of copyright. Many within Parliament argued that the bill failed to take into account the public interest, including Lord Macaulay, who succeeded in defeating one of Talfourd's bills in 1841. The Copyright Act 1842 (5 &amp; 6 Vict. c. 45) passed, but \"fell far short of Talfourd's dream of a uniform, consistent, codified law of copyright\". It extended copyright to life plus seven years, and, as part of the codification clauses, repealed the Statute of Anne.\nSignificance.\nThe Statute of Anne is traditionally seen as \"a historic moment in the development of copyright\", and the first statute in the world to provide for copyright. Craig Joyce and Lyman Ray Patterson, writing in the \"Emory Law Journal\", call this a \"too simple understanding [that] ignores the statute's source\", arguing that it is at best a derivative of the Licensing Act. Even considering this, however, the Statute of Anne was \"the watershed event in Anglo-American copyright history\u00a0... transforming what had been the publishers' private law copyright into a public law grant\". Patterson, writing separately, does note the differences between the Licensing Act and the Statute of Anne; the question of censorship was, by 1710, out of the question, and in that regard the statute is distinct, not providing for censorship.\nIt also marked the first time that copyright had been vested primarily in the author, rather than the publisher, and also the first time that the injurious treatment of authors by publishers was recognised; regardless of what authors signed away, the second 14-year term of copyright would automatically return to them. Even in the 21st century, the Statute of Anne is \"frequently invoked by modern judges and academics as embodying the utilitarian underpinnings of copyright law\". In \"IceTV Pty Ltd v Nine Network Australia Pty Ltd\", for example, the High Court of Australia noted that the title of the statute \"echoed explicitly the emphasis on the practical or utilitarian importance that certain seventeenth-century philosophers attached to knowledge and its encouragement in the scheme of human progress\". Despite \"widely recognised flaws\", the act became a model copyright statute, both within the United Kingdom and internationally. Christophe Geiger notes that it is \"a difficult, almost impossible task\" to analyse the relationship between the Statute of Anne and early French copyright law, both because it is difficult to make a direct connection, and because the ongoing debate over both has led to radically different interpretations of each nation's law.\nSimilarly, Belgium took no direct influence from the statute or English copyright theory, but Joris Deene of the University of Ghent identifies an indirect influence \"at two levels\"; the criteria for what constitutes copyrightable material, which comes from the work of English theorists such as Locke and Edward Young, and the underlying justification of copyright law. In Belgium, this justification is both that copyright serves the public interest, and that copyright is a \"private right\" that serves the interests of individual authors. Both theories were taken into account in \"Donaldson v Beckett\", as well as in the drafting of the Statute of Anne, and Deene infers that they subsequently affected the Belgian debates over their first copyright statute. In the United States, the Copyright Clause of the United States Constitution and the first Federal copyright statute, the Copyright Act of 1790, both draw on the Statute of Anne. The 1790 act contains provisions for a 14-year term of copyright and sections that provide for authors who published their works before 1790, both of which mirror the protection offered by the statute 80 years previously.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27761", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=27761", "title": "School choice", "text": "Term for pre-college public education options\nSchool choice is a term for education options that allow students and families to select alternatives to traditional public schools. \nSchool choice options include scholarship tax credit programs, open enrollment laws (which allow students to attend public schools other than their neighborhood school), charter schools, magnet schools, virtual schools, homeschooling, education savings accounts (ESAs), and individual education tax credits or deductions.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nForms.\nScholarship tax credits.\nScholarship tax credit programs grant individuals and businesses a full or partial credit toward their taxes for donations made to scholarship granting organizations (SGOs; also called school tuition organizations). SGOs use the donations to create scholarships that allow students to attend private schools or out-of-district public schools. These programs currently exist in fourteen states: Alabama, Arizona, Florida, Georgia, Illinois, Iowa, Kansas, Louisiana, Minnesota, New Hampshire, Oklahoma, Pennsylvania, Rhode Island, and Virginia.\nVouchers.\nVouchers help pay for private school tuition, whether secular or religious, and depending on jurisdiction for charter schools, home schooling, or public schools.\nCharter schools.\nCharter schools are independent public schools that are exempt from many of the regulations governing public schools. These exemptions grant charter schools some autonomy and flexibility with decision-making, such as teacher contracts, hiring, and curriculum. In return, charter schools are subject to stricter accountability on spending and academic performance. Most states and the national capital of Washington, D.C. have charter school laws, though they vary in how charter schools are approved.\nMagnet schools.\nMagnet schools are public schools that specialize in science, technology, art or other specific areas. Magnet schools are not open to all children; some require a competitive examination. Magnet schools are an example of open enrollment programs, which refer to that allow families to choose public schools other than the ones they are assigned.\nHomeschooling.\nHome education or homeschooling is education provided at home, provided primarily by a parent or under direct parental control. Informal home education predates public schools, and formal instruction in the home has at times been popular. As public education grew during the 1900s, homeschooling dropped. Since 2000, the number of children educated at home has increased, particularly in the US. Laws relevant to home education differ: in some states, the parent needs to notify the state that the child is to be educated at home, while in others, at least one parent must be a certified teacher and annual progress reports are reviewed by the state.\nInter-district enrollment.\nIntra-district open enrollment programs allow school choice within a district, while inter-district open enrollment allows families to choose schools outside the district.\nTo participate in California's District of Choice program, district governing boards declare themselves a District of Choice and set a quota for how many students to accept. School districts cannot discriminate among students, but can limit the number through a lottery system.\nEducation savings accounts.\nESAs allow parents to receive public funds in a government-authorized savings account. These funds are often distributed in the form of a debit card that can be used to pay for various services, such as private school tuition and fees, online programs, private tutoring, community college costs, higher education services, and other approved learning materials and services. ESAs can pay for a combination of public school courses and private services.\nTax credit/deduction.\nSome states allow parents to claim a tax credit or deduction to help fund certain educational expenses. These can include private school tuition, textbooks, school supplies and equipment, tutoring, and transportation.\nSome other jurisdictions reduce the income tax for parents, so educational expenses can be more economical, which include private school tuition, supplies, computers, books, tutors, and transportation.\nOnline learning.\nOnline learning allows students to work with teachers and their courses over the internet.\nComposites.\nCourse choice programs, public school courses, and special education therapies can be integrated into a student's curriculum, potentially with hybrid funding.\nBy country.\nBelgium.\nThe Flemish community of Belgium has a high-performing education system as measured by PISA scores. Most private schools are subject to government targets and inspections. Schools are not allowed to select students via admissions tests, performance, religious background, or gender. The Flemish education system allows choice between teaching styles and competition, while suffering from relatively high socio-economic segregation.\nChile.\nIn Chile, researchers reported that when controlling for student background (parental income and education), the difference in performance between public and private sectors is not significant. Variation within each sector is greater than that between the two systems.\nSweden.\nSweden's system of school choice is one of the world's freest, providing public funds for student choice of publicly or privately run school, including religious and for-profit schools. Fifteen years after the 1993 reform, private school enrollment had increased from 1% to 10% of the student population.\nUnited States.\nSchool choice is the subject of fierce debate in various state legislatures across the United States. The most common type of school choice in the United States, measured both by the number of programs and by the number of participating students, are scholarship tax credit programs. These allow individuals or corporations to receive tax credits toward their state taxes in exchange for donations made to non-profit organizations that grant private school scholarships. A similar subsidy may be provided by a state through a school voucher program.\nDebate.\nArguments in favor.\nIn the United States, support for school choice has been paired with parental rights. For example, Virginia Governor Glenn Youngkin asserted that he won his 2021 race by emphasizing that parents have the right to make decisions about their children\u2019s education and supported school choice.\nArguments against.\nEven with vouchers and other financial assistance to parents, opponents of school choice believe that K\u201312 education should not be a cost item in the for-profit sector. As public school advocate Diane Ravitch wrote, \"Free public education\u2014open to all and democratically controlled\u2014is one of the pillars of our democracy.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27762", "revid": "4637213", "url": "https://en.wikipedia.org/wiki?curid=27762", "title": "Star Frontiers", "text": "Science fiction tabletop role-playing game\nStar Frontiers is a science fiction role-playing game produced by TSR from 1982 to 1985. The game offers a space opera action-adventure setting.\nDescription.\n\"Star Frontiers\" is a space opera role-playing game that is set near the center of a spiral galaxy (the setting does not specify whether the galaxy is our own Milky Way). A previously undiscovered quirk of the laws of physics allows starships to jump to \"The Void\", a hyperspatial realm that greatly shortens the travel times between inhabited worlds, once they reach 1% of the speed of light. Four races \u2014 Dralasite, Humans, Vrusk, and Yazirian \u2014 have independently discovered this way of travelling vast distances, and in \"The Frontier Sector\", they form the United Planetary Federation (UPF). A large number of the star systems shown on the map of the Frontier sector in the basic rulebook are unexplored and undetailed, allowing the gamemaster to put whatever they wish there.\nPlayers can take on any number of possible roles in the setting but usually act as hired agents of the Pan Galactic corporation in exploring the Frontier and fighting the aggressive incursions of the alien and mysterious worm-like race known as the Sathar. Most published modules for the game follow these themes.\nThe game is a percentile-based system and uses only 10-sided dice. Characters have eight attributes rated from 1-100, which are paired together: Strength/Stamina, Dexterity/Reaction Speed, Intuition/Logic, and Personality/Leadership.\nCharacters also each have a Primary Skill Area (PSA), either Military, Technological, or Biosocial. Character generation uses a point-buy system to buy skills; skills falling within a character's PSA can be bought at a discount. Unlike TSR's better-known fantasy role-playing game \"Dungeons &amp; Dragons\", there is no character level advancement in \"Star Frontiers\", although skills can be improved through experience.\nBecause of the lack of magical healing found in fantasy RPGs, characters are quite durable in combat. Medical technology is also advanced, so characters can recover quickly from wounds with appropriate medical attention. Additionally, a dead character can be \"frozen\" and revived later.\nThe original boxed set includes two ten-sided dice, a large set of cardboard counters, and a folding map with a futuristic city on one side and various wilderness areas on the other. The box also includes the first \"Star Frontiers\" adventure, SF-0: \"Crash on Volturnus\". The characters would remain marooned on Volturnus through the next few modules: SF-1: \"Volturnus, Planet of Mystery\" (1982) and SF-2: \"Starspawn of Volturnus\" (1982)\nIn his 2023 book \"Monsters, Aliens, and Holes in the Ground\", RPG historian Stu Horvath noted that during this time on Volturnus, \"Strangely, \"Star Frontiers\", a science fiction game about space exploration, went two years without rules for spaceships.\"\nPublication history.\nAlthough TSR was a pioneer in developing science fiction role-playing games like the generation ship game \"Metamorphosis Alpha\" (1976) and the post-apocalyptic \"Gamma World\" (1978), they didn't immediately publish a space opera to rival Game Designer's Workshop's very popular \"Traveller\" (1977). Then in the early 1980s, David Cook and Lawrence Schick developed the rules for a TSR game they called \"Alien Worlds\". Those rules turned out to be too complex, and Cook and Schick severely edited the game to produce a more streamlined system \u2014 a 1984 article in \"Dragon\" noted that much of the material excised from \"Alien Worlds\" \"was felt to be too complex; playability was emphasized in the final version over complete realism.\" The revised game was titled \"Star Frontiers\" and was published by TSR in 1982.\nIn 1983, Mike Gray, Allen Hammack, Harold Johnson, David C. Sutherland III, and Steve Winter revised and expanded the game; this was released as \"Star Frontiers: Alpha Dawn\". About the same time, TSR released \"Knight Hawks\" (1983), designed by Douglas Niles, which provided rules for using starships, and for starship combat.\nTSR released several more adventures to take advantage of the expanded rules in \"Alpha Dawn\", including SF-3: \"Sundown on Starmist\" (1983), SF-4: \"Mission to Alcazzar\" (1984), SF-5: \"Bugs in the System\" (1985) and SF-6: \"Dark Side of the Moon\" (1985).\nAdventures using the \"Knight Hawks\" spaceship rules included SFKH-1: \"Dramune Run\" (1984) and a trilogy set \"Beyond the Frontier\" in which the players learn more about the Sathar and foil their latest plot (SFKH-2: \"Mutiny on the Eleanor Moraes\" (1984), SFKH-3: \"Face of the Enemy\" (1985), and SFKH-4: \"The War Machine\" (1985)).\nIn addition to adventures, several game aids were released, including the \"Star Frontiers Referee's Screen and Mini-Module\" in 1983, and the \"Star Frontiers Character Record Sheets\" in 1984, a 32-page book of character sheets with cover art by Larry Elmore.\nTwo modules published in 1984 also re-created the plot and setting of the movies ' and '.\nIn 1985, TSR signalled a new expansion to the game by publishing \"Zebulon's Guide to Frontier Space\" (1985) which introduced several additional races and radical changes to the game's mechanics. Although several more volumes were planned, they were never published, as TSR abruptly ended support for the \"Star Frontiers\" game. Various reasons for this sudden termination have been proposed \u2014 RPG historian Stu Horvath presented the possibility that TSR was angling to gain the game license for \"Star Wars\" and \"ditched \"Star Frontiers\" on the hubristic assumption they could outbid the competition.\" Whether or not this was the reason, TSR ultimately lost a bidding war for the \"Star Wars\" rights to West End Games.\n\"d20 Modern\".\nAfter TSR's takeover by Wizards of the Coast (WotC), the \"Star Frontiers\" campaign setting was resurrected and updated for WotC's \"d20 Modern\" role-playing game system in the science fiction supplement \"d20 Future\" (2004); the new revision was titled \"Star Law\".\nReception.\nIn Issue 37 of \"White Dwarf\", Andy Slack stated that \"Unfortunately, I can't say the system struck me as especially realistic; but if you like action adventure, thinking with your fists, and \"Star Wars\" (and who doesn't from time to time) you can have a lot of fun with this game.\" Slack concluded by giving it an overall rating of 7 out of 10.\nIn the February 1983 issue of \"The Space Gamer\", William A. Barton commented, \"\"Star Frontiers\" probably isn't going to lose TSR any money. But I wish there were a lot more to commend it than that.\"\nIn the inaugural issue of TSR's UK role-playing game magazine \"Imagine\", Jim Bambra liked the game, saying, \"In summary, the \"Starfrontiers\" game is an excellent introduction to Sci Fi gaming, a game I heartily recommend to beginners and experienced gamers. A lot of expertise has gone into the designing of this product and the result is a very enjoyable and easy to learn game.\"\nIan R. Beste reviewed \"Star Frontiers\" for \"Different Worlds\" magazine and stated that \"It would be easy to say that \"Star Frontiers\" is just \"D&amp;D\" with lasers. It isn't exactly, but it's unlikely to make anyone drop their existing campaign to set up one for \"Star Frontiers\". This game just don't have a solid science fiction feel to it.\"\nIn the November 1983 issue of \"Asimov's Science Fiction\", Dana Lombardy commented, \"Warning: these games can be addictive! Successfully completing an adventure (which sometimes means simply surviving!), or having your character obliterated in one of them, will probably make you want to play even more challenging adventures. TSR has a lot to offer the novice and experienced SF gamer in \"Star Frontiers\".\"\nAlso writing for \"Imagine\", Stephen Nutt reviewed \"Star Frontiers Character Record Sheets\", and stated that \"it makes up handsomely for the originals in the boxed set, which are rather pedestrian in comparison.\"\nThe French games magazine \"Jeux &amp; Strat\u00e9gie\" dismissed this game as fantasy masquerading as science fiction, commenting, \"The fact remains that it is simply a transfer of \"D&amp;D\" into a sci-fi world. We find the same type of scenarios, the monsters being replaced by extraterrestrial life forms, and the elves by Yazirians.\"\nIn Issue 30 of the French games magazine \"Casus Belli\", Jean Bolczesak liked the game but found its science fiction content a bit simplistic, commenting, \"\"Star Frontiers\" is playable, interesting and ESPECIALLY entertaining. But \"Star Frontiers\" is a game that presents a rather caricatured vision of science fiction. Since Dick and Herbert, SF is no longer necessarily a literary genre reserved for the simple-minded and the mentally ill. You can be passionate about space opera without being completely stupid.\" Bolczesak also pointed out the lack of content about spaceships and planet creation. Despite this, Bolczesak concluded, \"\"Star Frontiers\" is not a bad game, however, far from it. To be honest, it is even excellent for all 'dungeoners' who dream of exploring the galaxy. Especially if they like action and sci-fi, but not 'hard science'.\"\nIn his 1990 book \"The Complete Guide to Role-Playing Games\", game critic Rick Swan called \"Star Frontiers\" \"a streamlined, easy-to-learn game stressing general concepts while minimizing complicated mechanics.\" Swan concluded by giving the game a solid rating of 3 out of 4 and a qualified recommendation, saying, \"It's an excellent game for beginners, but experienced players may be disappointed that it lacks the scope of more elaborate science-fiction games such as \"MegaTraveller\".\"\nScott Taylor revisited \"Star Frontiers\" several times for \"Black Gate\":\nSubsequent legal dispute over trademark.\nIn 2021, a new iteration of TSR Games was launched by a group including Ernie Gygax, son of the deceased Tactical Studies Rules (TSR) co-founder Gary Gygax, and Justin LaNasa. They announced plans to release tabletop games and operate the Dungeon Hobby Shop Museum, which is located in the first office building of the original TSR. In July 2022, \"TechRaptor\" reported on a leaked \"Star Frontiers: New Genesis\" (a reboot of \"Star Frontiers\") playtest created by LaNasa's TSR; the content contains \"blatantly racist\" descriptions of character races and the race design \"plays into Nazi eugenics\". The content also contains \"homophobic, transphobic, and anti-semitic content, as well as additional material of a discriminatory nature\". \"IGN Southeast Asia\" highlighted that in this playtest game a black \"race is classified as a 'Subrace' and having 'average' intellect with a maximum intelligence rating of 9, whereas the 'norse' race has a minimum intelligence rating of 13\".\nIn September 2022, Wizards of the Coast sued TSR Games and the Dungeon Hobby Shop Museum to enjoin these companies from publishing games under the \"Star Frontiers\" and \"TSR\" trademarks. In its motion for a preliminary injunction, Wizards of the Coast wrote that TSR's \"Star Frontiers: New Genesis\" game is \"despicable\" and \"blatantly racist and transphobic\", and that the publication of such content would inflict reputational harm on Wizards of the Coast. Charlie Hall, for \"Polygon\", commented that \"Wizards' filing also seeks to undermine LaNasa's most powerful argument \u2014 that Wizards abandoned TSR and other related trademarks, thus opening the door to his usurping of the brand and its games. [...] Here's where things get complicated. Wizards admits that it failed to file paperwork for the registration of TSR, Star Frontiers, and other related marks in a timely fashion as required under federal law. But through continued sales of related products and use of the related IP, the company claims ownership via 'common law trademark rights.' It will be up to a jury to determine if that is, in fact, the case.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27763", "revid": "33164707", "url": "https://en.wikipedia.org/wiki?curid=27763", "title": "Structuralism", "text": "Intellectual current and methodological approach in the social science\nStructuralism is an intellectual current and methodological approach, primarily in the social sciences, that interprets elements of human culture by way of their relationship to a broader system. It works to uncover the structural patterns that underlie all things that humans do, think, perceive, and feel. \nAlternatively, as summarized by philosopher Simon Blackburn, structuralism is:\"The belief that phenomena of human life are not intelligible except through their interrelations. These relations constitute a structure, and behind local variations in the surface phenomena there are constant laws of abstract structure.\"\nHistory and background.\nThe term \"structuralism\" is ambiguous, referring to different schools of thought in different contexts. As such, the movement in humanities and social sciences called structuralism relates to sociology. Emile Durkheim based his sociological concept on 'structure' and 'function', and from his work emerged the sociological approach of structural functionalism.\nApart from Durkheim's use of the term \"structure\", the semiological concept of Ferdinand de Saussure became fundamental for structuralism. Saussure conceived language and society as a system of relations. His linguistic approach was also a refutation of evolutionary linguistics.\nStructuralism in Europe developed in the early 20th century, mainly in France and the Russian Empire, in the structural linguistics of Ferdinand de Saussure and the subsequent Prague, Moscow, and Copenhagen schools of linguistics. As an intellectual movement, structuralism became the heir to existentialism. After World War II, an array of scholars in the humanities borrowed Saussure's concepts for use in their respective fields. French anthropologist Claude L\u00e9vi-Strauss was arguably the first such scholar, sparking a widespread interest in structuralism.\nThroughout the 1940s and 1950s, existentialism, such as that propounded by Jean-Paul Sartre, was the dominant European intellectual movement. Structuralism rose to prominence in France in the wake of existentialism, particularly in the 1960s. The initial popularity of structuralism in France led to its spread across the globe. By the early 1960s, structuralism as a movement was coming into its own and some believed that it offered a single unified approach to human life that would embrace all disciplines.\nBy the late 1960s, many of structuralism's basic tenets came under attack from a new wave of predominantly French intellectuals/philosophers such as historian Michel Foucault, Jacques Derrida, Marxist philosopher Louis Althusser, and literary critic Roland Barthes. Though elements of their work necessarily relate to structuralism and are informed by it, these theorists eventually came to be referred to as post-structuralists. Many proponents of structuralism, such as Lacan, continue to influence continental philosophy and many of the fundamental assumptions of some of structuralism's post-structuralist critics are a continuation of structuralist thinking.\nRussian functional linguist Roman Jakobson was a pivotal figure in the adaptation of structural analysis to disciplines beyond linguistics, including philosophy, anthropology, and literary theory. Jakobson was a decisive influence on anthropologist Claude L\u00e9vi-Strauss, by whose work the term \"structuralism\" first appeared in reference to social sciences. L\u00e9vi-Strauss' work in turn gave rise to the structuralist movement in France, also called French structuralism, influencing the thinking of other writers, most of whom disavowed themselves as being a part of this movement. This included such writers as Louis Althusser and psychoanalyst Jacques Lacan, as well as the structural Marxism of Nicos Poulantzas. Roland Barthes and Jacques Derrida focused on how structuralism could be applied to literature.\nFerdinand de Saussure.\nThe origins of structuralism are connected with the work of Ferdinand de Saussure on linguistics along with the linguistics of the Prague and Moscow schools. In brief, Saussure's structural linguistics propounded three related concepts.\nL\u00e9vi-Strauss.\nStructuralism rejected the concept of human freedom and choice, focusing instead on the way that human experience and behaviour is determined by various structures. The most important initial work on this score was L\u00e9vi-Strauss's 1949 volume \"The Elementary Structures of Kinship\". L\u00e9vi-Strauss had known Roman Jakobson during their time together at the New School in New York during WWII and was influenced by both Jakobson's structuralism, as well as the American anthropological tradition. \nIn \"Elementary Structures\", he examined kinship systems from a structural point of view and demonstrated how apparently different social organizations were different permutations of a few basic kinship structures. In the late 1958, he published \"Structural Anthropology\", a collection of essays outlining his program for structuralism.\nLacan and Piaget.\nBlending Freud and Saussure, French (post)structuralist Jacques Lacan applied structuralism to psychoanalysis. Similarly, Jean Piaget applied structuralism to the study of psychology, though in a different way. Piaget, who would better define himself as constructivist, considered structuralism as \"a method and not a doctrine,\" because, for him, \"there exists no structure without a construction, abstract or genetic.\"\n'Third order'.\nProponents of structuralism argue that a specific domain of culture may be understood by means of a structure that is modelled on language and is distinct both from the organizations of reality and those of ideas, or the imagination\u2014the \"third order.\" In Lacan's psychoanalytic theory, for example, the structural order of \"the Symbolic\" is distinguished both from \"the Real\" and \"the Imaginary;\" similarly, in Althusser's Marxist theory, the structural order of the capitalist mode of production is distinct both from the actual, real agents involved in its relations and from the ideological forms in which those relations are understood.\nAlthusser.\nAlthough French theorist Louis Althusser is often associated with structural social analysis, which helped give rise to \"structural Marxism,\" such association was contested by Althusser himself in the Italian foreword to the second edition of \"Reading Capital\". In this foreword Althusser states the following: \nDespite the precautions we took to distinguish ourselves from the 'structuralist' ideology\u2026, despite the decisive intervention of categories foreign to 'structuralism'\u2026, the terminology we employed was too close in many respects to the 'structuralist' terminology not to give rise to an ambiguity. With a very few exceptions\u2026our interpretation of Marx has generally been recognized and judged, in homage to the current fashion, as 'structuralist'.\u2026 We believe that despite the terminological ambiguity, the profound tendency of our texts was not attached to the 'structuralist' ideology.\nAssiter.\nIn a later development, feminist theorist Alison Assiter enumerated four ideas common to the various forms of structuralism:\nIn linguistics.\nIn Ferdinand de Saussure's \"Course in General Linguistics\", the analysis focuses not on the use of language (\"parole\", 'speech'), but rather on the underlying system of language (\"langue\"). This approach examines how the elements of language relate to each other in the present, synchronically rather than diachronically. Saussure argued that linguistic signs were composed of two parts:\nThis differed from previous approaches that focused on the relationship between words and the things in the world that they designate.\nAlthough not fully developed by Saussure, other key notions in structural linguistics can be found in structural \"idealism.\" A structural idealism is a class of linguistic units (lexemes, morphemes, or even constructions) that are possible in a certain position in a given \"syntagm\", or linguistic environment (such as a given sentence). The different functional role of each of these members of the paradigm is called 'value' (French: \"\").\nPrague School.\nIn France, Antoine Meillet and \u00c9mile Benveniste continued Saussure's project, and members of the Prague school of linguistics such as Roman Jakobson and Nikolai Trubetzkoy conducted influential research. The clearest and most important example of Prague school structuralism lies in phonemics. Rather than simply compiling a list of which sounds occur in a language, the Prague school examined how they were related. They determined that the inventory of sounds in a language could be analysed as a series of contrasts. \nThus, in English, the sounds /p/ and /b/ represent distinct phonemes because there are cases (\"minimal pairs\") where the contrast between the two is the only difference between two distinct words (e.g. 'pat' and 'bat'). Analyzing sounds in terms of contrastive features also opens up comparative scope\u2014for instance, it makes clear the difficulty Japanese speakers have differentiating /r/ and /l/ in English and other languages is because these sounds are not contrastive in Japanese. Phonology would become the paradigmatic basis for structuralism in a number of different fields.\nBased on the Prague school concept, Andr\u00e9 Martinet in France, J. R. Firth in the UK and Louis Hjelmslev in Denmark developed their own versions of structural and functional linguistics.\nIn anthropology.\nAccording to structural theory in anthropology and social anthropology, \"meaning\" is produced and reproduced within a culture through various practices, phenomena, and activities that serve as systems of signification. \nA structuralist approach may study activities as diverse as food-preparation and serving rituals, religious rites, games, literary and non-literary texts, and other forms of entertainment to discover the deep structures by which meaning is produced and reproduced within the culture. For example, L\u00e9vi-Strauss analysed in the 1950s cultural phenomena including mythology, kinship (the alliance theory and the incest taboo), and food preparation. In addition to these studies, he produced more linguistically-focused writings in which he applied Saussure's distinction between \"langue\" and \"parole\" in his search for the fundamental structures of the human mind, arguing that the structures that form the \"deep grammar\" of society originate in the mind and operate in people unconsciously. L\u00e9vi-Strauss took inspiration from mathematics.\nAnother concept used in structural anthropology came from the Prague school of linguistics, where Roman Jakobson and others analysed sounds based on the presence or absence of certain features (e.g., voiceless vs. voiced). L\u00e9vi-Strauss included this in his conceptualization of the universal structures of the mind, which he held to operate based on pairs of binary oppositions such as hot-cold, male-female, culture-nature, cooked-raw, or marriageable vs. tabooed women.\nA third influence came from Marcel Mauss (1872\u20131950), who had written on gift-exchange systems. Based on Mauss, for instance, L\u00e9vi-Strauss argued an \"alliance\" theory\u2014that kinship systems are based on the exchange of women between groups\u2014as opposed to the \"'descent'-based\" theory described by Edward Evans-Pritchard and Meyer Fortes. While replacing Mauss at his \"Ecole Pratique des Hautes Etudes\" chair, the writings of L\u00e9vi-Strauss became widely popular in the 1960s and 1970s and gave rise to the term \"structuralism\" itself.\nIn Britain, authors such as Rodney Needham and Edmund Leach were highly influenced by structuralism. Authors such as Maurice Godelier and Emmanuel Terray combined Marxism with structural anthropology in France. In the United States, authors such as Marshall Sahlins and James Boon built on structuralism to provide their own analysis of human society. Structural anthropology fell out of favour in the early 1980s for a number of reasons. D'Andrade suggests that this was because it made unverifiable assumptions about the universal structures of the human mind. Authors such as Eric Wolf argued that political economy and colonialism should be at the forefront of anthropology. More generally, criticisms of structuralism by Pierre Bourdieu led to a concern with how cultural and social structures were changed by human agency and practice, a trend which Sherry Ortner has referred to as 'practice theory'.\nOne example is Douglas E. Foley's \"Learning Capitalist Culture\" (2010), in which he applied a mixture of structural and Marxist theories to his ethnographic fieldwork among high school students in Texas. Foley analyzed how they reach a shared goal through the lens of social solidarity when he observed \"Mexicanos\" and \"Anglo-Americans\" come together on the same football team to defeat the school's rivals. However, he also continually applies a marxist lens and states that he, \"wanted to wow peers with a new cultural marxist theory of schooling.\"\nSome anthropological theorists, however, while finding considerable fault with L\u00e9vi-Strauss's version of structuralism, did not turn away from a fundamental structural basis for human culture. The Biogenetic Structuralism group for instance argued that some kind of structural foundation for culture must exist because all humans inherit the same system of brain structures. They proposed a kind of neuroanthropology which would lay the foundations for a more complete scientific account of cultural similarity and variation by requiring an integration of cultural anthropology and neuroscience\u2014a program that theorists such as Victor Turner also embraced.\nIn literary criticism and theory.\nIn literary theory, structuralist criticism relates literary texts to a larger structure, which may be a particular genre, a range of intertextual connections (such as patterns of metaphor),\na model of a universal narrative structure, or a system of recurrent patterns or motifs.\nThe field of structuralist semiotics argues that there must be a structure in every text, which explains why it is easier for experienced readers than for non-experienced readers to interpret a text. Everything that is written seems to be governed by rules, or \"grammar of literature\", that one learns in educational institutions and that are to be unmasked.\nA potential problem for a structuralist interpretation is that it can be highly reductive; as scholar Catherine Belsey puts it: \"the structuralist danger of collapsing all difference.\" An example of such a reading might be if a student concludes the authors of \"West Side Story\" did not write anything \"really\" new, because their work has the same structure as Shakespeare's \"Romeo and Juliet\". In both texts a girl and a boy fall in love (a \"formula\" with a symbolic operator between them would be \"Boy + Girl\") despite the fact that they belong to two groups that hate each other (\"Boy's Group - Girl's Group\" or \"Opposing forces\") and conflict is resolved by their deaths. Structuralist readings focus on how the structures of the single text resolve inherent narrative tensions. If a structuralist reading focuses on multiple texts, there must be some way in which those texts unify themselves into a coherent system. The versatility of structuralism is such that a literary critic could make the same claim about a story of two \"friendly\" families (\"Boy's Family + Girl's Family\") that arrange a marriage between their children despite the fact that the children hate each other (\"Boy - Girl\") and then the children commit suicide to escape the arranged marriage; the justification is that the second story's structure is an 'inversion' of the first story's structure: the relationship between the values of love and the two pairs of parties involved have been reversed.\nStructuralist literary criticism argues that the \"literary banter of a text\" can lie only in new structure, rather than in the specifics of character development and voice in which that structure is expressed. Literary structuralism often follows the lead of Vladimir Propp, Algirdas Julien Greimas, and Claude L\u00e9vi-Strauss in seeking out basic deep elements in stories, myths, and more recently, anecdotes, which are combined in various ways to produce the many versions of the ur-story or ur-myth.\nThere is considerable similarity between structural literary theory and Northrop Frye's archetypal criticism, which is also indebted to the anthropological study of myths. Some critics have also tried to apply the theory to individual works, but the effort to find unique structures in individual literary works runs counter to the structuralist program and has an affinity with New Criticism.\nIn economics.\nYifu Lin criticizes early structural economic systems and theories, discussing the failures of it. He writes:\"The structuralism believes that the failure to develop advanced capital-intensive industries spontaneously in a developing country is due to market failures caused by various structural rigidities...\" \"According to neoliberalism, the main reason for the failure of developing countries to catch up with developed countries was too much state intervention in the market, causing misallocation of resources, rent seeking and so forth.\"Rather these failures are more so centered around the unlikelihood of such quick development of these advanced industries within developing countries.\nNew Structural Economics (NSE).\nNew structural economics is an economic development strategy developed by World Bank Chief Economist Justin Yifu Lin. The strategy combines ideas from both neoclassical economics and structural economics.\nNSE studies two parts: the base and the superstructure. A base is a combination of forces and relations of production, consisting of, but not limited to, industry and technology, while the superstructure consists of hard infrastructure and institutions. This results in an explanation of how the base impacts the superstructure which then determines transaction costs.\nInterpretations and general criticisms.\nStructuralism is less popular today than other approaches, such as post-structuralism and deconstruction. Structuralism has often been criticized for being ahistorical and for favouring deterministic structural forces over the ability of people to act. As the political turbulence of the 1960s and 1970s (particularly the student uprisings of May 1968) began affecting academia, issues of power and political struggle moved to the center of public attention.\nIn the 1980s, deconstruction\u2014and its emphasis on the fundamental ambiguity of language rather than its logical structure\u2014became popular. By the end of the century, structuralism was seen as a historically important school of thought, but the movements that it spawned, rather than structuralism itself, commanded attention.\nSeveral social theorists and academics have strongly criticized structuralism or even dismissed it. French hermeneutic philosopher Paul Ric\u0153ur (1969) criticized L\u00e9vi-Strauss for overstepping the limits of validity of the structuralist approach, ending up in what Ric\u0153ur described as \"a Kantianism without a transcendental subject.\" \nAnthropologist Adam Kuper (1973) argued that:'Structuralism' came to have something of the momentum of a millennial movement and some of its adherents felt that they formed a secret society of the seeing in a world of the blind. Conversion was not just a matter of accepting a new paradigm. It was, almost, a question of salvation. Philip Noel Pettit (1975) called for an abandoning of \"the positivist dream which L\u00e9vi-Strauss dreamed for semiology,\" arguing that semiology is not to be placed among the natural sciences. Cornelius Castoriadis (1975) criticized structuralism as failing to explain symbolic mediation in the social world; he viewed structuralism as a variation on the \"logicist\" theme, arguing that, contrary to what structuralists advocate, language\u2014and symbolic systems in general\u2014cannot be reduced to logical organizations on the basis of the binary logic of oppositions. \nCritical theorist J\u00fcrgen Habermas (1985) accused structuralists like Foucault of being positivists; Foucault, while not an ordinary positivist per se, paradoxically uses the tools of science to criticize science, according to Habermas (see \"Performative contradiction\" and \"Foucault\u2013Habermas debate\"). Sociologist Anthony Giddens (1993) is another notable critic; while Giddens draws on a range of structuralist themes in his theorizing, he dismisses the structuralist view that the reproduction of social systems is merely \"a mechanical outcome.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27764", "revid": "20468248", "url": "https://en.wikipedia.org/wiki?curid=27764", "title": "Systems engineering", "text": "Interdisciplinary field of engineering\nSystems engineering is an interdisciplinary field of engineering and engineering management that focuses on how to design, integrate, and manage complex systems over their life cycles. At its core, systems engineering utilizes systems thinking principles to organize this body of knowledge. The individual outcome of such efforts, an engineered system, can be defined as a combination of components that work in synergy to collectively perform a useful function.\nIssues such as requirements engineering, reliability, logistics, coordination of different teams, testing and evaluation, maintainability, and many other disciplines, aka \"ilities\", necessary for successful system design, development, implementation, and ultimate decommission become more difficult when dealing with large or complex projects. Systems engineering deals with work processes, optimization methods, and risk management tools in such projects. It overlaps technical and human-centered disciplines such as industrial engineering, production systems engineering, process systems engineering, mechanical engineering, manufacturing engineering, production engineering, control engineering, software engineering, electrical engineering, cybernetics, aerospace engineering, organizational studies, civil engineering and project management. Systems engineering ensures that all likely aspects of a project or system are considered and integrated into a whole.\nThe systems engineering process is a discovery process that is quite unlike a manufacturing process. A manufacturing process is focused on repetitive activities that achieve high-quality outputs with minimum cost and time. The systems engineering process must begin by discovering the real problems that need to be resolved and identifying the most probable or highest-impact failures that can occur. Systems engineering involves finding solutions to these problems.\nHistory.\nThe term \"systems engineering\" can be traced back to Bell Telephone Laboratories in the 1940s. The need to identify and manipulate the properties of a system as a whole, which in complex engineering projects may greatly differ from the sum of the parts' properties, motivated various industries, especially those developing systems for the U.S. military, to apply the discipline.\nWhen it was no longer possible to rely on design evolution to improve upon a system and the existing tools were not sufficient to meet growing demands, new methods began to be developed that addressed the complexity directly. The continuing evolution of systems engineering comprises the development and identification of new methods and modeling techniques. These methods aid in a better comprehension of the design and developmental control of engineering systems as they grow more complex. Popular tools that are often used in the systems engineering context were developed during these times, including Universal Systems Language (USL), Unified Modeling Language (UML), Quality function deployment (QFD), and Integration Definition (IDEF).\nIn 1990, a professional society for systems engineering, the \"National Council on Systems Engineering\" (NCOSE), was founded by representatives from a number of U.S. corporations and organizations. NCOSE was created to address the need for improvements in systems engineering practices and education. As a result of growing involvement from systems engineers outside of the U.S., the name of the organization was changed to the International Council on Systems Engineering (INCOSE) in 1995. Schools in several countries offer graduate programs in systems engineering, and continuing education options are also available for practicing engineers.\nConcept.\nSystems engineering signifies only an approach and, more recently, a discipline in engineering. The aim of education in systems engineering is to formalize various approaches simply and in doing so, identify new methods and research opportunities similar to that which occurs in other fields of engineering. As an approach, systems engineering is holistic and interdisciplinary in flavor.\nOrigins and traditional scope.\nThe traditional scope of engineering embraces the conception, design, development, production, and operation of physical systems. Systems engineering, as originally conceived, falls within this scope. \"Systems engineering\", in this sense of the term, refers to the building of engineering concepts.\nEvolution to a broader scope.\nThe use of the term \"systems engineer\" has evolved over time to embrace a wider, more holistic concept of \"systems\" and of engineering processes. This evolution of the definition has been a subject of ongoing controversy, and the term continues to apply to both the narrower and a broader scope.\nTraditional systems engineering was seen as a branch of engineering in the classical sense, that is, as applied only to physical systems, such as spacecraft and aircraft. More recently, systems engineering has evolved to take on a broader meaning especially when humans were seen as an essential component of a system. Peter Checkland, for example, captures the broader meaning of systems engineering by stating that 'engineering' \"can be read in its general sense; you can engineer a meeting or a political agreement.\"\nConsistent with the broader scope of systems engineering, the Systems Engineering Body of Knowledge (SEBoK) has defined three types of systems engineering:\nHolistic view.\nSystems engineering focuses on analyzing and eliciting customer needs and required functionality early in the development cycle, documenting requirements, then proceeding with design synthesis and system validation while considering the complete problem, the system lifecycle. This includes fully understanding all of the stakeholders involved. Oliver et al. claim that the systems engineering process can be decomposed into:\nWithin Oliver's model, the goal of the Management Process is to organize the technical effort in the lifecycle, while the Technical Process includes \"assessing available information\", \"defining effectiveness measures\", to \"create a behavior model\", \"create a structure model\", \"perform trade-off analysis\", and \"create sequential build &amp; test plan\".\nDepending on their application, although there are several models that are used in the industry, all of them aim to identify the relation between the various stages mentioned above and incorporate feedback. Examples of such models include the Waterfall model and the VEE model (also called the V model).\nInterdisciplinary field.\nSystem development often requires contribution from diverse technical disciplines. By providing a systems (holistic) view of the development effort, systems engineering helps mold all the technical contributors into a unified team effort, forming a structured development process that proceeds from concept to production to operation and, in some cases, to termination and disposal. In an acquisition, the holistic integrative discipline combines contributions and balances tradeoffs among cost, schedule, and performance while maintaining an acceptable level of risk covering the entire life cycle of the item.\nThis perspective is often replicated in educational programs, in that systems engineering courses are taught by faculty from other engineering departments, which helps create an interdisciplinary environment.\nManaging complexity.\nThe need for systems engineering arose with the increase in complexity of systems and projects, in turn exponentially increasing the possibility of component friction, and therefore the unreliability of the design. When speaking in this context, complexity incorporates not only engineering systems but also the logical human organization of data. At the same time, a system can become more complex due to an increase in size as well as with an increase in the amount of data, variables, or the number of fields that are involved in the design. The International Space Station is an example of such a system.\nThe development of smarter control algorithms, microprocessor design, and analysis of environmental systems also come within the purview of systems engineering. Systems engineering encourages the use of tools and methods to better comprehend and manage complexity in systems. Some examples of these tools can be seen here:\nTaking an interdisciplinary approach to engineering systems is inherently complex since the behavior of and interaction among system components is not always immediately well defined or understood. Defining and characterizing such systems and subsystems and the interactions among them is one of the goals of systems engineering. In doing so, the gap that exists between informal requirements from users, operators, marketing organizations, and technical specifications is successfully bridged.\nScope.\nThe principles of systems engineering\u00a0\u2013 holism, emergent behavior, boundary, et al.\u00a0\u2013 can be applied to any system, complex or otherwise, provided systems thinking is employed at all levels. Besides defense and aerospace, many information and technology-based companies, software development firms, and industries in the field of electronics &amp; communications require systems engineers as part of their team.\nAn analysis by the INCOSE Systems Engineering Center of Excellence (SECOE) indicates that optimal effort spent on systems engineering is about 15\u201320% of the total project effort. At the same time, studies have shown that systems engineering essentially leads to a reduction in costs among other benefits. However, no quantitative survey at a larger scale encompassing a wide variety of industries has been conducted until recently. Such studies are underway to determine the effectiveness and quantify the benefits of systems engineering.\nSystems engineering encourages the use of modeling and simulation to validate assumptions or theories on systems and the interactions within them.\nUse of methods that allow early detection of possible failures, in safety engineering, are integrated into the design process. At the same time, decisions made at the beginning of a project whose consequences are not clearly understood can have enormous implications later in the life of a system, and it is the task of the modern systems engineer to explore these issues and make critical decisions. No method guarantees today's decisions will still be valid when a system goes into service years or decades after first conceived. However, there are techniques that support the process of systems engineering. Examples include soft systems methodology, Jay Wright Forrester's System dynamics method, and the Unified Modeling Language (UML)\u2014all currently being explored, evaluated, and developed to support the engineering decision process.\nEducation.\nEducation in systems engineering is often seen as an extension to the regular engineering courses, reflecting the industry attitude that engineering students need a foundational background in one of the traditional engineering disciplines (e.g. aerospace engineering, civil engineering, electrical engineering, mechanical engineering, manufacturing engineering, industrial engineering, chemical engineering)\u2014plus practical, real-world experience to be effective as systems engineers. Undergraduate university programs explicitly in systems engineering are growing in number but remain uncommon, the degrees including such material are most often presented as a BS in Industrial Engineering. Typically programs (either by themselves or in combination with interdisciplinary study) are offered beginning at the graduate level in both academic and professional tracks, resulting in the grant of either a MS/MEng or Ph.D./EngD degree.\nINCOSE, in collaboration with the Systems Engineering Research Center at Stevens Institute of Technology maintains a regularly updated directory of worldwide academic programs at suitably accredited institutions. As of 2017, it lists over 140 universities in North America offering more than 400 undergraduate and graduate programs in systems engineering. Widespread institutional acknowledgment of the field as a distinct subdiscipline is quite recent; the 2009 edition of the same publication reported the number of such schools and programs at only 80 and 165, respectively.\nEducation in systems engineering can be taken as \"systems-centric\" or \"domain-centric\":\nBoth of these patterns strive to educate the systems engineer who is able to oversee interdisciplinary projects with the depth required of a core engineer.\nSystems engineering topics.\nSystems engineering tools are strategies, procedures, and techniques that aid in performing systems engineering on a project or product. The purpose of these tools varies from database management, graphical browsing, simulation, and reasoning, to document production, neutral import/export, and more.\nSystem.\nThere are many definitions of what a system is in the field of systems engineering. Below are a few authoritative definitions:\nSystems engineering processes.\nSystems engineering processes encompass all creative, manual, and technical activities necessary to define the product and which need to be carried out to convert a system definition to a sufficiently detailed system design specification for product manufacture and deployment. Design and development of a system can be divided into four stages, each with different definitions: \nDepending on their application, tools are used for various stages of the systems engineering process:\nUsing models.\nModels play important and diverse roles in systems engineering. A model can be defined in several\nways, including:\nTogether, these definitions are broad enough to encompass physical engineering models used in the verification of a system design, as well as schematic models like a functional flow block diagram and mathematical (i.e. quantitative) models used in the trade study process. This section focuses on the last.\nThe main reason for using mathematical models and diagrams in trade studies is to provide estimates of system effectiveness, performance or technical attributes, and cost from a set of known or estimable quantities. Typically, a collection of separate models is needed to provide all of these outcome variables. The heart of any mathematical model is a set of meaningful quantitative relationships among its inputs and outputs. These relationships can be as simple as adding up constituent quantities to obtain a total, or as complex as a set of differential equations describing the trajectory of a spacecraft in a gravitational field. Ideally, the relationships express causality, not just correlation. Furthermore, key to successful systems engineering activities are also the methods with which these models are efficiently and effectively managed and used to simulate the systems. However, diverse domains often present recurring problems of modeling and simulation for systems engineering, and new advancements are aiming to cross-fertilize methods among distinct scientific and engineering communities, under the title of 'Modeling &amp; Simulation-based Systems Engineering'.\nModeling formalisms and graphical representations.\nInitially, when the primary purpose of a systems engineer is to comprehend a complex problem, graphic representations of a system are used to communicate a system's functional and data requirements. Common graphical representations include:\nA graphical representation relates the various subsystems or parts of a system through functions, data, or interfaces. Any or each of the above methods is used in an industry based on its requirements. For instance, the N2 chart may be used where interfaces between systems are important. Part of the design phase is to create structural and behavioral models of the system.\nOnce the requirements are understood, it is now the responsibility of a systems engineer to refine them and to determine, along with other engineers, the best technology for a job. At this point starting with a trade study, systems engineering encourages the use of weighted choices to determine the best option. A decision matrix, or Pugh method, is one way (QFD is another) to make this choice while considering all criteria that are important. The trade study in turn informs the design, which again affects graphic representations of the system (without changing the requirements). In an SE process, this stage represents the iterative step that is carried out until a feasible solution is found. A decision matrix is often populated using techniques such as statistical analysis, reliability analysis, system dynamics (feedback control), and optimization methods.\nOther tools.\nSystems Modeling Language.\nSystems Modeling Language (SysML), a modeling language used for systems engineering applications, supports the specification, analysis, design, verification and validation of a broad range of complex systems.\nLifecycle Modeling Language.\nLifecycle Modeling Language (LML), is an open-standard modeling language designed for systems engineering that supports the full lifecycle: conceptual, utilization, support, and retirement stages.\nRelated fields and sub-fields.\nMany related fields may be considered tightly coupled to systems engineering. The following areas have contributed to the development of systems engineering as a distinct entity:\nCognitive systems engineering.\nCognitive systems engineering (CSE) is a specific approach to the description and analysis of human-machine systems or sociotechnical systems. The three main themes of CSE are how humans cope with complexity, how work is accomplished by the use of artifacts, and how human-machine systems and socio-technical systems can be described as joint cognitive systems. CSE has since its beginning become a recognized scientific discipline, sometimes also referred to as cognitive engineering. The concept of a Joint Cognitive System (JCS) has in particular become widely used as a way of understanding how complex socio-technical systems can be described with varying degrees of resolution. The more than 20 years of experience with CSE has been described extensively.\nConfiguration management.\nLike systems engineering, configuration management as practiced in the defense and aerospace industry is a broad systems-level practice. The field parallels the taskings of systems engineering; where systems engineering deals with requirements development, allocation to development items and verification, configuration management deals with requirements capture, traceability to the development item, and audit of development item to ensure that it has achieved the desired functionality and outcomes that systems engineering and/or Test and Verification Engineering have obtained and proven through objective testing.\nControl engineering.\nControl engineering and its design and implementation of control systems, used extensively in nearly every industry, is a large sub-field of systems engineering. The cruise control on an automobile and the guidance system for a ballistic missile are two examples. Control systems theory is an active field of applied mathematics involving the investigation of solution spaces and the development of new methods for the analysis of the control process.\nIndustrial engineering.\nIndustrial engineering is a branch of engineering that concerns the development, improvement, implementation, and evaluation of integrated systems of people, money, knowledge, information, equipment, energy, material, and process. Industrial engineering draws upon the principles and methods of engineering analysis and synthesis, as well as mathematical, physical, and social sciences together with the principles and methods of engineering analysis and design to specify, predict, and evaluate results obtained from such systems.\nProduction Systems Engineering.\nProduction Systems Engineering (PSE) is an emerging branch of Engineering intended to uncover fundamental principles of production systems and utilize them for analysis, continuous improvement, and design.\nInterface design.\nInterface design and its specification are concerned with assuring that the pieces of a system connect and inter-operate with other parts of the system and with external systems as necessary. Interface design also includes assuring that system interfaces are able to accept new features, including mechanical, electrical, and logical interfaces, including reserved wires, plug-space, command codes, and bits in communication protocols. This is known as extensibility. Human-Computer Interaction (HCI) or Human-Machine Interface (HMI) is another aspect of interface design and is a critical aspect of modern systems engineering. Systems engineering principles are applied in the design of communication protocols for local area networks and wide area networks.\nMechatronic engineering.\nMechatronic engineering, like systems engineering, is a multidisciplinary field of engineering that uses dynamic systems modeling to express tangible constructs. In that regard, it is almost indistinguishable from Systems Engineering, but what sets it apart is the focus on smaller details rather than larger generalizations and relationships. As such, both fields are distinguished by the scope of their projects rather than the methodology of their practice.\nOperations research.\nOperations research supports systems engineering. Operations research, briefly, is concerned with the optimization of a process under multiple constraints.\nPerformance engineering.\nPerformance engineering is the discipline of ensuring a system meets customer expectations for performance throughout its life. Performance is usually defined as the speed with which a certain operation is executed or the capability of executing a number of such operations in a unit of time. Performance may be degraded when operations queued to execute are throttled by limited system capacity. For example, the performance of a packet-switched network is characterized by the end-to-end packet transit delay or the number of packets switched in an hour. The design of high-performance systems uses analytical or simulation modeling, whereas the delivery of high-performance implementation involves thorough performance testing. Performance engineering relies heavily on statistics, queueing theory, and probability theory for its tools and processes.\nProgram management and project management.\nProgram management (or project management) has many similarities with systems engineering, but has broader-based origins than the engineering ones of systems engineering. Project management is also closely related to both program management and systems engineering. Both include scheduling as engineering support tool in assessing interdisciplinary concerns under management process. In particular, the direct relationship of resources, performance features, and risk to the duration of a task or the dependency links among tasks and impacts across the system lifecycle are systems engineering concerns.\nProposal engineering.\nProposal engineering is the application of scientific and mathematical principles to design, construct, and operate a cost-effective proposal development system. Basically, proposal engineering uses the \"systems engineering process\" to create a cost-effective proposal and increase the odds of a successful proposal.\nReliability engineering.\nReliability engineering is the discipline of ensuring a system meets customer expectations for reliability throughout its life (i.e. it does not fail more frequently than expected). Next to the prediction of failure, it is just as much about the prevention of failure. Reliability engineering applies to all aspects of the system. It is closely associated with maintainability, availability (dependability or RAMS preferred by some), and integrated logistics support. Reliability engineering is always a critical component of safety engineering, as in failure mode and effects analysis (FMEA) and hazard fault tree analysis, and of security engineering.\nRisk management.\nRisk management, the practice of assessing and dealing with risk is one of the interdisciplinary parts of Systems Engineering. In development, acquisition, or operational activities, the inclusion of risk in tradeoffs with cost, schedule, and performance features, involves the iterative complex configuration management of traceability and evaluation to the scheduling and requirements management across domains and for the system lifecycle that requires the interdisciplinary technical approach of systems engineering. Systems Engineering has Risk Management define, tailor, implement, and monitor a structured process for risk management which is integrated into the overall effort.\nSafety engineering.\nThe techniques of safety engineering may be applied by non-specialist engineers in designing complex systems to minimize the probability of safety-critical failures. The \"System Safety Engineering\" function helps to identify \"safety hazards\" in emerging designs and may assist with techniques to \"mitigate\" the effects of (potentially) hazardous conditions that cannot be designed out of systems.\nSecurity engineering.\nSecurity engineering can be viewed as an interdisciplinary field that integrates the community of practice for control systems design, reliability, safety, and systems engineering. It may involve such sub-specialties as authentication of system users, system targets, and others: people, objects, and processes.\nSoftware engineering.\nFrom its beginnings, software engineering has helped shape modern systems engineering practice. The techniques used in the handling of the complexities of large software-intensive systems have had a major effect on the shaping and reshaping of the tools, methods, and processes of Systems Engineering.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27765", "revid": "42964511", "url": "https://en.wikipedia.org/wiki?curid=27765", "title": "September 4", "text": "&lt;templatestyles src=\"This date in recent years/styles.css\"/&gt;\nDay of the yearSeptember 4 is the day of the year in the Gregorian calendar\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27766", "revid": "50637565", "url": "https://en.wikipedia.org/wiki?curid=27766", "title": "Sam &amp; Max", "text": "American media franchise\nSam &amp; Max is an American media franchise about Sam and Max, a pair of anthropomorphic vigilante private investigators. The characters, who occupy a universe that parodies American popular culture, were created by Dave Purcell before being developed by his brother Steve Purcell in their youths, and later debuted in a 1987 comic book series. The characters have since been the subject of a graphic adventure video game developed by LucasArts, a produced for Fox in cooperation with Nelvana Limited, and a series of episodic adventure games developed by Telltale Games. In addition, a variety of machinima and a webcomic have been produced for the series.\nThe characters are based in a dilapidated office block in New York City. Sam is a six-foot-tall dog who wears a suit and a fedora, while Max is a short and aggressive \"hyperkinetic rabbity thing\". Both enjoy solving problems and cases as maniacally as possible, often with complete disregard for the law. Driving a seemingly indestructible black-and-white 1960 DeSoto Adventurer, the pair travel to many contemporary and historical locations to fight crime, including the Moon, Ancient Egypt, the White House and the Philippines, as well as several fictitious locations.\nThe series has been very successful despite its relatively limited amount of media, and has gathered a significant fan base. However, the franchise did not gain more widespread recognition until after the 1993 release of LucasArts' \"Sam &amp; Max Hit the Road\", which cultivated interest in Purcell's original comics. \"Sam &amp; Max Hit the Road\" is regarded as an exceptional adventure game and an iconic classic of computer gaming in the 1990s. Subsequent video games and the television series have also fared well with both critics and fans; critics consider the episodic video games to be the first successful application of the episodic distribution model.\nOverview.\nCreation.\nThe idea of \"Sam &amp; Max\" originated with Steve Purcell's younger brother, Dave, who invented the concept of a comic about a detective team consisting of a dog and a rabbit in his youth. Dave often left the comics around the house, so Steve, in a case of sibling rivalry, often finished the incomplete stories in parodies of their original form, deliberately making the characters mix up each other's names, over-explain things, shoot at each other and mock the way in which they had been drawn, as \"kind of a parody of the way a kid talks when he's writing comics\". Over time, this developed from Steve merely mocking his brother's work to him creating his own full stories with the characters. Ultimately, in the late 1970s, Dave Purcell gave Steve the rights to the characters, signing them over in a contract on Steve's birthday and allowing him to develop the characters in his own way. In 1980, Purcell began to produce \"Sam &amp; Max\" comic strips for the weekly newsletter of the California College of Arts and Crafts. While the visual appearance of the characters had not yet been fully developed, the stories were similar in style to those that followed when Purcell was offered by \"Fish Police\" author Steven Moncuse the chance to publish his work properly in 1987.\nMany aspects of the \"Sam &amp; Max\" comics were influenced by Purcell's own experiences. Rats and cockroaches are common throughout the franchise, the former inspired by Purcell's pet rat. In another example, Sam and Max are occasionally shown playing a game called \"fizzball\", in which the object of the exercise is to hit a can of beer in mid-air with a solid axe handle. Purcell had previously invented the game with his friends, including fellow comic book writers Art Adams and Mike Mignola.\nCharacters.\nSam.\nSam is a laid-back but enthusiastic, brown-coated anthropomorphic Irish Wolfhound, described as a \"canine shamus\". He wears either a gray or blue suit with a matching fedora, to make people more cooperative when conversing with a six-foot talking dog. A warped sense of justice makes Sam the more passionate of the pair for their police work, only held back from taking his job seriously by Max. Nevertheless, he enjoys the mannerisms and dress that come with their line of work. Sam possesses near encyclopedic amounts of knowledge, particularly on obscure topics, and is prone to long-winded sentences filled with elaborate terminology. Although he is always keen to display this information\u2014regardless of its accuracy\u2014Sam can be capable of total ignorance towards more practical matters; for instance, despite his regard for his DeSoto Adventurer, he is severely negligent with the car's maintenance. Sam still retains various doglike qualities: he is excitable and enthusiastic, but also susceptible to emotions of embarrassment and guilt. Nevertheless, Sam is \"not above sticking his head out the car window and letting his tongue flap in the breeze\". Sam is very friendly and polite in spite of his over-the-top recklessness as an officer, and is shown to be quite cordial with his allies. That said, While he does deeply care about his friends, he has no problems with using manipulative tactics on them in order to further his goals when it comes to his job. He rarely loses his temper, and is able to react to panic-inducing situations with extreme calm. At the off chance he does get angry, Sam tends to react in a violent, uncharacteristically savage manner, in which case Max usually calms him down and prevents him from acting upon his anger. Sam usually is armed with an oversized .44 revolver. \nSam is voiced by Bill Farmer in \"Sam &amp; Max Hit the Road\", Harvey Atkin in the animated series and David Nowlin from Telltale's games onward.\nMax.\nMax is an anthropomorphic \"hyperkinetic, three-foot rabbity thing\" with white fur, but prefers being called a lagomorph. Max retains few characteristics consistent with a rabbit, with permanently rigid ears set in an excited posture and a huge jaw normally stuck in a crazed grin. Unhinged, uninhibited and near psychotic, Max enjoys violence and tends to prefer the aggressive way of solving problems, seeing the world as little more than a vessel for his \"pinball-like stream of consciousness\". This creates a seeming disregard for self-preservation; Max will revel in dangerous situations with little impression that he understands the risks he faces. As a result, Max is usually enthusiastic to engage in any activity, including being used by Sam as a cable cutter or an impromptu bludgeon. Despite this, Max possesses a sharp mind and an observational nature, and enjoys interpreting new experiences in as unpredictable a manner as possible. However, Max has a distaste for long stories and occasionally loses focus during lengthy scenes of plot exposition; by his own admission, Max possesses a particularly short attention span. On top of this short attention span, it has been shown numerous times that Max has an extremely poor memory to go along with it. Despite his seemingly heartless personality, he does have moments where he demonstrates care and compassion for others, and he believes strongly in upholding the law in his own twisted way. he's also very protective of Sam, but Max can still act violently towards his friend, stating that when he dies, he will take Sam with him. Moreover, Max is extremely possessive of Sam and their status as partners and best friends. Max traditionally carries a Luger pistol, but as he wears no clothes, other characters often make comments as to where Max keeps it on his person. Purcell considers Max to be representative of pure id, the uncoordinated instinctual trends of the human psyche. \nMax's voice is provided by Nick Jameson in \"Sam &amp; Max Hit the Road\" and by Robert Tinkler in the animated series. Andrew Chaikin originally voiced Max in the first episode of Telltale's games before being replaced by William Kasten, while Dave Boat voices the character from \"Poker Night 2\" onward.\nMedia.\nComic books.\nSam and Max debuted in the 1987 comic book series \"Sam &amp; Max: Freelance Police\", published by Fishwrap Productions, also the publisher of \"Fish Police\". The first comic, \"Monkeys Violating the Heavenly Temple\", was Steve Purcell's first full story. The comic came about after Purcell agreed to create a full \"Sam &amp; Max\" story for publication alongside Steve Moncuse's \"Fish Police\" series. \"Monkeys Violating the Heavenly Temple\" established many of the key features in the series; the main story of the comic saw the Freelance Police journey to the Philippines to stop a volcano god cult. \"Night of the Gilded Heron-Shark\" and \"Night of the Cringing Wildebeest\" accompanied the main story, focusing on a stand-off with a group of gangsters in Sam and Max's office and an investigation into a carnival refreshment booth respectively.\nOver the subsequent years, several other comics were published, often by different publishers, including and Epic Comics. \"Fair Wind to Java\" was originally published in 1988 as a Munden's Bar story in the pages of First Comics' \"Grimjack\", featuring the Freelance Police fighting pyramid-building aliens in Ancient Egypt, and was followed in 1989 by \"On the Road\", a three chapter story showing what Sam and Max do on vacation. In 1990, Christmas-themed story \"The Damned Don't Dance\" was released. 1992 saw the release of two further comics: \"Bad Day On The Moon\" took the Freelance Police to deal with a roach infestation bothering giant rats on the Moon, and was later adapted as a story for the animated TV series, whilst \"Beast From The Cereal Aisle\" focused on the duo conducting an exorcism at the local supermarket. Two more comics were produced in 1997, \"The Kids Take Over\" and \"Belly Of The Beast\". The former has Sam and Max wake up from cryogenic sleep to discover that the entire world is now ruled by children while the latter sees the Freelance Police confronting a vampire abducting children at Halloween.\nPurcell joined LucasArts in 1988 as an artist and game designer, where he was approached about contributing to LucasArts' new quarterly newsletter, \"The Adventurer\", a publication designed to inform customers about upcoming LucasArts games and company news. From its debut issue in 1990 to 1996, Purcell created twelve comic strips for the newsletter. The strips portrayed a variety of stories, from similar plots as in the comic books to parodies of LucasArts games such as \"Monkey Island\" and \"Full Throttle\" and the Lucasfilm franchises \"Star Wars\" and \"Indiana Jones\".\nIn 1995, all of the comics and \"The Adventurer\" strips published to that date were released in a compilation, \"Sam &amp; Max: Surfin' the Highway\". Published by Marlowe &amp; Company, the 154 page book was updated and republished in 1996. This original version of \"Surfin' the Highway\" went out of print in 1997, becoming a high-priced collector's item sold through services such as eBay. In 2007, a 197-page twenty-year anniversary edition, containing all printed comics and strips as well as a variety of other artwork, was co-designed by Steve Purcell and Jake Rodkin and published by Telltale Games. This second publication received an Eisner Award nomination for \"Best Graphic Album \u2013 Reprint\" in 2009.\nIn December 2005, Purcell started a \"Sam &amp; Max\" webcomic, hosted on the website of Telltale Games. Entitled \"The Big Sleep\", the webcomic began with Sam and Max bursting out of their graves at Kilpeck Church in England, symbolizing the Freelance Police's return after nearly a decade. In the twelve page story, Max has to save Sam after earwigs start a colony in Sam's brain. The webcomic concluded in April 2007, and was later awarded the Eisner Award for \"Best Digital Comic\" of 2007.\nVideo games.\nFollowing LucasArts' employment of Purcell in 1988, the characters of Sam and Max appeared in internal testing material for new SCUMM engine programmers; Purcell created animated versions of the characters and an office backdrop for the programmers to practice on. In 1992, LucasArts offered Purcell the chance to create a video game out of the characters, out of a wish to use new characters after the success of its two other main adventure titles, \"Monkey Island\" and \"Maniac Mansion\", and after a positive reaction from fans to the \"Sam &amp; Max\" comic strips featured in LucasArts' \"The Adventurer\" newsletter. Consequently, development on a graphic adventure game, \"Sam &amp; Max Hit the Road\", began shortly after. Based on the SCUMM engine and designed by Sean Clark, Michael Stemmle, Steve Purcell and his future wife Collette Michaud, the game was partially based on the 1989 comic \"On The Road\", and featured the Freelance Police travelling across America in search of an escaped bigfoot. Sam was voiced in the game by comedian Bill Farmer, while actor Nick Jameson voiced Max. \"Sam &amp; Max Hit the Road\" was originally released for DOS in November 1993. Soon after \"Sam &amp; Max Hit the Road\", another \"Sam &amp; Max\" game using SCUMM entered planning under Purcell and Dave Grossman, but was abandoned. In a later interview Grossman described this sequel's highlight as \"a giant spaceship shaped like Max's head\".\nIn September 2001, development began on a new project, \"Sam &amp; Max Plunge Through Space\". The game was to be an Xbox exclusive title, developed by Infinite Machine, a small company consisting of a number of former LucasArts employees. The story of the game was developed by Purcell and fellow designer Chuck Jordan and involved the Freelance Police travelling the galaxy to find a stolen Statue of Liberty. Infinite Machine went bankrupt within a year, partially due to the failure of their first game, \"New Legends\", and the project was abandoned.\nAt the 2002 Electronic Entertainment Expo convention, nearly a decade after the release of \"Sam &amp; Max Hit the Road\", LucasArts announced the production of a PC sequel, entitled \"\". \"Freelance Police\", like \"Hit the Road\", was to be a point-and-click graphic adventure game, using a new 3D game engine. Development of \"Freelance Police\" was led by Michael Stemmle. Steve Purcell contributed to the project by writing the story and producing concept art. Farmer and Jameson were also set to reprise their voice acting roles. In March 2004, however, quite far into the game's development, \"Sam &amp; Max: Freelance Police\" was abruptly cancelled by LucasArts, citing \"current market place realities and underlying economic considerations\" in a short press release. The fan reaction to the cancellation was strong; a petition of 32,000 signatures stating the disappointment of fans was later presented to LucasArts.\nAfter LucasArts' license with Steve Purcell expired in 2005, the \"Sam &amp; Max\" franchise moved to Telltale Games, a company of former LucasArts employees who had worked on a number of LucasArts adventure games, including on the development of \"Freelance Police\". Under Telltale Games, a new episodic series of \"Sam &amp; Max\" video games was made. Like both \"Sam &amp; Max Hit the Road\" and \"Freelance Police\", \"Sam &amp; Max Save the World\" was in a point-and-click graphic adventure game format. The game used a new 3D game engine, different from the one used in \"Freelance Police\". The first season ran for six episodes, each with a self-contained storyline but with an overall story arc involving hypnotism running through the series. The first episode was released on GameTap in October 2006, with episodes following regularly until April 2007. Sam is voiced by David Nowlin, while Max is voiced by William Kasten in all episodes except the first one, where Andrew Chaikin voices the character. In addition, Telltale Games produced fifteen machinima shorts to accompany the main episodes. These shorts were released in groups of three in between the release of each episode, showing the activities of the Freelance Police in between each story.\nA second season of episodic video games was developed by Telltale Games. \"Sam &amp; Max Beyond Time and Space\" followed the same overall format as \"Save the World\", with each episode having an overarching storyline involving time travel and laundering of the souls of the dead. As with \"Save the World\", episodes were originally published on GameTap before being made available for general release. The season consisted of five episodes and ran from November 2007 to April 2008. Nowlin and Kasten both returned to reprise their voice roles. In addition to the main games, a twenty-minute machinima video was produced, taking the form of a \"Sam &amp; Max\" Christmas special.\nA third game entitled \"\" was scheduled for release in 2009; the title was later pushed back to 2010, with concept art emerging after Telltale's completion of \"Tales of Monkey Island\". The season again ran for five episodes, released monthly from April to August 2010. \"The Devil's Playhouse\" followed a structure similar to \"Tales of Monkey Island\", with each episode forming a part of an ongoing narrative, involving psychic powers and forces that used them for world domination. A two-minute Flash cartoon also accompanied the game, dealing with the origin story of General Skun-ka'pe, one of the game's antagonists. Max also appears in Telltale's 2010 casual game \"Poker Night at the Inventory\" alongside Tycho Brahe from \"Penny Arcade\", the Heavy from \"Team Fortress 2\" and Strong Bad from \"Homestar Runner\". Sam and Max (now voiced by Dave Boat) also appear in the game's sequel alongside Claptrap from \"Borderlands\", Brock Samson from \"The Venture Bros.\", Ash Williams from \"Evil Dead\" and GLaDOS from \"Portal\".\nA \"Sam &amp; Max\" virtual reality game, \"Sam &amp; Max: This Time It's Virtual\", was developed by HappyGiant. Purcell served as a consultant for game design, Stemmle returned as designer and writer, Jared Emerson-Johnson returned as composer, and Nowlin and Boat returned to voice Sam and Max, respectively. The game was released in July 2021 for Oculus Quest, with releases for SteamVR and Viveport Infinity to follow in late 2021, and for PlayStation VR in 2022. Remasters of all three Telltale seasons were released between 2020 and 2024. The remasters were developed by Skunkape Games, a studio made up of former members of the original development team and named in reference to the General Skun-ka'pe character from \"The Devil's Playhouse\".\nTelevision series.\n\"Sam &amp; Max\" was adapted into a cartoon series for Fox in 1997. Produced by Canadian studio Nelvana, the series ran for 24 episodes. Each episode was approximately ten minutes, and were often aired in pairs, with the exception of the first and last episodes, which were 20 minutes long. Broadcast on Fox Kids in the United States, YTV in Canada, and Channel 4 in the United Kingdom, the first episode was aired on October 4, 1997; the series concluded on April 25, 1998. As opposed to the more adult humor in the rest of the series, \"The Adventures of Sam &amp; Max: Freelance Police\" was aimed more at children, even though some humor in it was often directed at adults. As such, the violence inherent in the franchise is toned down, including removing Sam and Max's guns, and the characters do not use the moderate profanity that they use in their other appearances. As in most \"Sam &amp; Max\" stories, the series revolves around the Freelance Police accepting missions from their mysterious superior, the commissioner, and embarking on cases to a large variety of implausible locations. Sam is voiced by Harvey Atkin, while Max is voiced by Robert Tinkler. The series performed well and was considered a success, and in 1998 received the Gemini Award for \"Best Animated Program or Series\". Despite the series' success, a second season was never commissioned. In 2007, Shout! Factory acquired the rights for DVD release of the series. In October, as part of their marketing for \"Sam &amp; Max Save the World\", GameTap hosted the series on their website. The DVD release of the series was later published in March 2008.\nMusic.\nThe \"Sam &amp; Max\" franchise features a variety of soundtracks that accompany its video game products. This music is mostly grounded in film noir jazz, incorporating various other styles at certain points, such as Dixieland, waltz and mariachi, usually to support the cartoon nature of the series. The first \"Sam &amp; Max\" game, \"Sam &amp; Max Hit the Road\", was one of the first games to feature a fully scored music soundtrack, written by LucasArts' composers Clint Bajakian, Michael Land and Peter McConnell. The music was incorporated into the game using Land and McConnell's iMUSE engine, which allowed for audio to be synchronized with the visuals. Although the full soundtrack was never released, audio renders of four of the game's MIDI tracks were included on the CD version of the game.\nFor \"Sam &amp; Max Save the World\", \"Beyond Time and Space\", and \"The Devil's Playhouse\", Telltale Games contracted composer Jared Emerson-Johnson, a musician whose previous work included composition and sound editing for LucasArts, to write the scores. The soundtracks for the first two games were released in two disc sets after the release of the games themselves; the \"Season One Soundtrack\" was published in July 2007, whilst the \"Season Two Soundtrack\" was released in September 2008. Emerson-Johnson's scores use live performances as opposed to synthesized music often used elsewhere in the video game industry. Critics reacted positively to Emerson-Johnson's scores, IGN described Emerson-Johnson's work as a \"breath of fresh air\", while 1UP.com praised his work as \"top-caliber\" and Music4Games stated that the \"whimsical nature of [the classical jazz approach] is well suited to the \"Sam &amp; Max\" universe, which approaches American popular culture with a level of irreverence\". Purcell later commented that Emerson-Johnson had seamlessly blended a \"huge palette of genres and styles\", whilst in September 2008, Brendan Q. Ferguson, one of the lead designers on \"Save the World\" and \"Beyond Time and Space\", said that he believed that it was Emerson-Johnson's scores that created the vital atmosphere in the games, noting that prior to the implementation of the soundtracks, playing the games was an \"unrelenting horror\". Emerson-Johnson later returned to compose music for the \"Remastered\" releases, as well as \"This Time It's Virtual\".\nCultural impact and reception.\nThe \"Sam &amp; Max\" franchise has been highly successful critically, and is considered an iconic and influential aspect of the video game industry in the 1990s and the adventure game genre. In 2007, Steve Purcell wrote that he was somewhat surprised at the success of his creation, noting that the series had gained a large fan gathering despite the small size of the franchise. As the series contains only a small number of comics, video games and a short TV series, Purcell commented that there was \"certainly not enough material to build that relentless traction of an endlessly renewed sitcom or a syndicated comic that has existed since the Korean Conflict\". The comics were well received by critics, many praising the humor and style of the stories and characters. However, later commentators have noted that the comic book series did not gain much popularity or recognition until after the release of \"Sam &amp; Max Hit the Road\" in 1993; the later episodic video games are seen to have revived interest in the comics again, resulting in the creation of the webcomic \"The Big Sleep\" and publication of an anniversary edition of \"Surfin' The Highway\".\nUpon its release in 1993, \"Sam &amp; Max Hit the Road\" was met with near universal acclaim. Critics praised the title for its humor, voice acting, graphics, music and gameplay. It has since come to be regarded as a classic graphic adventure game, one of the most critically successful projects by LucasArts to date. \"Sam &amp; Max Hit the Road\" is regularly featured in lists of top games, and was nominated for the 1994 Annie Award for \"Best Animated CD-ROM\", although the award instead went to LucasArts' \"\". The abrupt cancellation of the sequel to \"Sam &amp; Max Hit the Road\" in 2004 garnered substantial criticism of LucasArts. In addition to a petition of 32,000 signatures objecting to the termination of development on \"Sam &amp; Max: Freelance Police\", both Steve Purcell and the media were critical of LucasArts' decision. Purcell stated that he failed to understand quite why the game was cancelled, as he believed the development of the game was proceeding without hindrance, while the media put forward the view that LucasArts was moving to consolidate its position with low business risk \"Star Wars\" video games instead of pursuing the adventure games that had brought them success in earlier years. The cancellation of \"Freelance Police\" is often cited as the culmination in a perceived decline in the overall adventure game genre, and LucasArts later dismissed many of the designers involved with developing their adventure games, effectively ending their adventure game era.\nAlthough \"Sam &amp; Max Save the World\" did not receive the critical acclaim that \"Sam &amp; Max Hit the Road\" acquired, it still received a favorable response from critics across its release in 2006 and 2007. Critics praised the game's humor, graphics and gameplay, although concerns were voiced over the low difficulty of the puzzles and the effectiveness of the story. \"Save the World\" is considered by journalists in the video game industry to be the first successful application of episodic gaming, as Telltale Games had managed to release a steady stream content with only small time gaps. Previous attempts by Valve with the \"Half-Life\" series, Ritual Entertainment with \"SiN Episodes\" and Telltale Games themselves with \"\" were for a variety of reasons not considered successful implementations of the distribution model. \"Beyond Time and Space\" was considered similar to \"Save the World\" and reviewers equally praised and faulted the game on this, although overall \"Beyond Time and Space\" received a good reception from critics.\nThe success of the franchise has spawned a selection of merchandise, including posters and prints, items of clothing and sketchbooks of Purcell's work during various stages of the series' development. Collectable statues of the characters have also been created. However, perhaps due to references in Purcell's sketchbooks and demand from both fans and journalists alike, a plush toy of Max has been created and sold, albeit limited edition, as a collaboration between internet shop Hashtag Collectibles and Steve Purcell. A limited edition plush toy of Sam has also been created and sold in late 2023 on Uncute's website, and Max being brought back along with him for a limited time once again, alongside Max themed slippers in 2024. Boss Fight Studios produced a new line of action figures based on the Freelance Police for 2019, and the prototypes were first revealed at New York Toy Fair.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27767", "revid": "38020738", "url": "https://en.wikipedia.org/wiki?curid=27767", "title": "Standard-definition television", "text": "Digital TV with similar definition to analog broadcasts\nStandard-definition television (SDTV; also standard definition or SD) is a television system that uses a resolution that is not considered to be either high or enhanced definition. \"Standard\" refers to offering a similar resolution to the analog broadcast systems used when it was introduced.\nHistory and characteristics.\nSDTV originated from the need for a standard to digitize analog TV (defined in BT.601) and is now used for digital TV broadcasts and home appliances such as game consoles and DVD disc players.\nDigital SDTV broadcast eliminates the ghosting and noisy images associated with analog systems. However, if the reception has interference or is poor, where the error correction cannot compensate one will encounter various other artifacts such as image freezing, stuttering, or dropouts from missing intra-frames or blockiness from missing macroblocks. The audio encoding is the last to suffer a loss due to the lower bandwidth requirements.\nStandards that support digital SDTV broadcast include DVB, ATSC, and ISDB. The last two were originally developed for HDTV, but are also used for their ability to deliver multiple SD video and audio streams via multiplexing.\nPAL and NTSC.\nThe two SDTV signal types are 576i (with 576 interlaced lines of resolution, derived from the European-developed PAL and SECAM systems), and 480i (with 480 interlaced lines of resolution, based on the American NTSC system). SDTV refresh rates are 25, 29.97 and 30 frames per second, again based on the analog systems mentioned.\nIn North America, digital SDTV is broadcast in the same 4:3 fullscreen aspect ratio as NTSC signals, with content often being center cut.\nIn other parts of the world that used the PAL or SECAM color systems, digital standard-definition television is now usually shown with a , with the transition occurring between the mid-1990s and late-2000s depending on the region. Older programs with a 4:3 aspect ratio are broadcast with a flag that switches the display to 4:3. Some broadcasters prefer to reduce the horizontal resolution by anamorphically scaling the video into a pillarbox.\nPixel aspect ratio.\nThe pixel aspect ratio is the same for 720- and 704-pixel resolutions because the visible image (be it 4:3 or 16:9) is contained in the center 704 horizontal pixels of the digital frame. In the case of a digital video line having 720 horizontal pixels (including horizontal blanking), only the center 704 pixels contain the actual 4:3 or 16:9 image, and the 8-pixel-wide stripes on either side are called nominal analog blanking or horizontal blanking and should be discarded when displaying the image. Nominal analog blanking should not be confused with overscan, as overscan areas are part of the actual 4:3 or 16:9 image.\nFor SMPTE 259M-C compliance, an SDTV broadcast image is scaled to 720 pixels wide for every 480 NTSC (or 576 PAL) lines of the image with the amount of non-proportional line scaling dependent on either the display or pixel aspect ratio. Only 704 center pixels contain the actual image and 16 pixels are reserved for horizontal blanking, though a number of broadcasters fill the whole 720 frames. The display ratio for broadcast widescreen is commonly 16:9 (pixel aspect ratio of 40:33 for anamorphic); the display ratio for a traditional or letterboxed broadcast is 4:3 (pixel aspect ratio of 10:11).\nAn SDTV image outside the constraints of the SMPTE standards requires no non-proportional scaling with 640 pixels (defined by the adopted IBM VGA standard) for every line of the image. The display and pixel aspect ratio is generally not required with the line height defining the aspect. For widescreen 16:9, 360 lines define a widescreen image and for traditional 4:3, 480 lines define an image.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27768", "revid": "13051", "url": "https://en.wikipedia.org/wiki?curid=27768", "title": "Standard Definition TV", "text": ""}
{"id": "27769", "revid": "46051904", "url": "https://en.wikipedia.org/wiki?curid=27769", "title": "SDTV", "text": ""}
{"id": "27770", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=27770", "title": "Sir Fred Hoyle", "text": ""}
{"id": "27772", "revid": "10689882", "url": "https://en.wikipedia.org/wiki?curid=27772", "title": "Sandstone", "text": "Type of sedimentary rock\nSandstone is a clastic sedimentary rock composed mainly of sand-sized (0.0625 to 2\u00a0mm) silicate grains, cemented together by another mineral. Sandstones comprise about 20\u201325% of all sedimentary rocks.\nMost sandstone is composed of quartz or feldspar because they are the most resistant minerals to the weathering processes at the Earth's surface. Like uncemented sand, sandstone may be imparted any color by impurities within the minerals, but the most common colors are tan, brown, yellow, red, grey, pink, white, and black. Because sandstone beds can form highly visible cliffs and other topographic features, certain colors of sandstone have become strongly identified with certain regions, such as the red rock deserts of Arches National Park and other areas of the American Southwest.\nRock formations composed of sandstone usually allow the percolation of water and other fluids and are porous enough to store large quantities, making them valuable aquifers and petroleum reservoirs.\nQuartz-bearing sandstone can be changed into quartzite through metamorphism, usually related to tectonic compression within orogenic belts.\nOrigins.\nSandstones are \"clastic\" in origin (as opposed to either \"organic\", like chalk and coal, or \"chemical\", like gypsum and jasper). The silicate sand grains from which they form are the product of physical and chemical weathering of bedrock. Weathering and erosion are most rapid in areas of high relief, such as volcanic arcs, areas of continental rifting, and orogenic belts.\nEroded sand is transported by rivers or by the wind from its source areas to depositional environments where tectonics has created accommodation space for sediments to accumulate. Forearc basins tend to accumulate sand rich in lithic grains and plagioclase. Intracontinental basins and grabens along continental margins are also common environments for deposition of sand.\nAs sediments continue to accumulate in the depositional environment, older sand is buried by younger sediments, and it undergoes diagenesis. This mostly consists of compaction and lithification of the sand. Early stages of diagenesis, described as \"eogenesis\", take place at shallow depths (a few tens of meters) and are characterized by bioturbation and mineralogical changes in the sands, with only slight compaction. The red hematite that gives red bed sandstones their color is likely formed during eogenesis. Deeper burial is accompanied by \"mesogenesis\", during which most of the compaction and lithification takes place.\nCompaction takes place as the sand comes under increasing pressure from overlying sediments. Sediment grains move into more compact arrangements, ductile grains (such as mica grains) are deformed, and pore space is reduced. In addition to this physical compaction, chemical compaction may take place via pressure solution. Points of contact between grains are under the greatest strain, and the strained mineral is more soluble than the rest of the grain. As a result, the contact points are dissolved away, allowing the grains to come into closer contact.\nLithification follows closely on compaction, as increased temperatures at depth hasten deposition of cement that binds the grains together. Pressure solution contributes to cementing, as the mineral dissolved from strained contact points is redeposited in the unstrained pore spaces.\nMechanical compaction takes place primarily at depths less than . Chemical compaction continues to depths of , and most cementation takes place at depths of .\nUnroofing of buried sandstone is accompanied by \"telogenesis\", the third and final stage of diagenesis. As erosion reduces the depth of burial, renewed exposure to meteoric water produces additional changes to the sandstone, such as dissolution of some of the cement to produce secondary porosity.\nComponents.\nFramework grains.\nFramework grains are sand-sized ( diameter) detrital fragments that make up the bulk of a sandstone. Most framework grains are composed of quartz or feldspar, which are the common minerals most resistant to weathering processes at the Earth's surface, as seen in the Goldich dissolution series. Framework grains can be classified into several different categories based on their mineral composition:\n*Alkali feldspar range in chemical composition from KAlSi3O8 to NaAlSi3O8.\n*Plagioclase feldspar range in composition from NaAlSi3O8 to CaAl2Si2O8.\nMatrix.\nMatrix is very fine material, which is present within interstitial pore space between the framework grains. The nature of the matrix within the interstitial pore space results in a twofold classification:\nCement.\nCement is what binds the siliciclastic framework grains together. Cement is a secondary mineral that forms after deposition and during burial of the sandstone. These cementing materials may be either silicate minerals or non-silicate minerals, such as calcite.\nSandstone that becomes depleted of its cement binder through weathering gradually becomes friable and unstable. This process can be somewhat reversed by the application of tetraethyl orthosilicate () which will deposit amorphous silicon dioxide between the sand grains. The reaction is as follows.\nPore space.\nPore space includes the open spaces within a rock or a soil. The pore space in a rock has a direct relationship to the porosity and permeability of the rock. The porosity and permeability are directly influenced by the way the sand grains are packed together.\nTypes of sandstone.\nSandstones are typically classified by point-counting a thin section using a method like the Gazzi-Dickinson Method. This yields the relative percentages of quartz, feldspar, and lithic grains and the amount of clay matrix. The composition of a sandstone can provide important information on the genesis of the sediments when used with a triangular quartz, feldspar, lithic chart (QFL diagrams). However, geologists have not been able to agree on a set of boundaries separating regions of the QFL triangle.\nVisual aids are diagrams that allow geologists to interpret different characteristics of a sandstone. For example, a QFL chart can be marked with a provenance model that shows the likely tectonic origin of sandstones with various compositions of framework grains. Likewise, the stage of textural maturity chart illustrates the different stages that a sandstone goes through as the degree of kinetic processing of the sediments increases.\nDott's classification scheme.\nDott's (1964) sandstone classification scheme is one of many such schemes used by geologists for classifying sandstones. Dott's scheme is a modification of Gilbert's classification of silicate sandstones, and it incorporates R.L. Folk's dual textural and compositional maturity concepts into one classification system. The philosophy behind combining Gilbert's and R. L. Folk's schemes is that it is better able to \"portray the continuous nature of textural variation from mudstone to arenite and from stable to unstable grain composition\". Dott's classification scheme is based on the mineralogy of framework grains, and on the type of matrix present in between the framework grains.\nIn this specific classification scheme, Dott has set the boundary between arenite and wackes at 15% matrix. In addition, Dott also breaks up the different types of framework grains that can be present in a sandstone into three major categories: quartz, feldspar, and lithic grains.\nQuartzite.\nWhen sandstone is subjected to the great heat and pressure associated with regional metamorphism, the individual quartz grains recrystallize, along with the former cementing material, to form the metamorphic rock called quartzite. Most or all of the original texture and sedimentary structures of the sandstone are erased by the metamorphism. The grains are so tightly interlocked that when the rock is broken, it fractures through the grains to form an irregular or conchoidal fracture.\nGeologists had recognized by 1941 that some rocks show the macroscopic characteristics of quartzite, even though they have not undergone metamorphism at high pressure and temperature. These rocks have been subject only to the much lower temperatures and pressures associated with diagenesis of sedimentary rock, but diagenesis has cemented the rock so thoroughly that microscopic examination is necessary to distinguish it from metamorphic quartzite. The term \"orthoquartzite\" is used to distinguish such sedimentary rock from \"metaquartzite\" produced by metamorphism. By extension, the term \"orthoquartzite\" has occasionally been more generally applied to any quartz-cemented quartz arenite. Orthoquartzite (in the narrow sense) is often 99% SiO2 with only very minor amounts of iron oxide and trace resistant minerals such as zircon, rutile and magnetite. Although few fossils are normally present, the original texture and sedimentary structures are preserved.\nThe typical distinction between a true orthoquartzite and an ordinary quartz sandstone is that an orthoquartzite is so highly cemented that it will fracture across grains, not around them. This is a distinction that can be recognized in the field. In turn, the distinction between an orthoquartzite and a metaquartzite is the onset of recrystallization of existing grains. The dividing line may be placed at the point where strained quartz grains begin to be replaced by new, unstrained, small quartz grains, producing a \"mortar texture\" that can be identified in thin sections under a polarizing microscope. With increasing grade of metamorphism, further recrystallization produces \"foam texture\", characterized by polygonal grains meeting at triple junctions, and then \"porphyroblastic texture\", characterized by coarse, irregular grains, including some larger grains (porphyroblasts.)\nUses.\nSandstone has been used since prehistoric times for construction, decorative art works and tools. It has been widely employed around the world in constructing temples, churches, homes and other buildings, and in civil engineering.\nAlthough its resistance to weathering varies, sandstone is easy to work. That makes it a common building and paving material, including in asphalt concrete. However, some types that have been used in the past, such as the Collyhurst sandstone used in North West England, have had poor long-term weather resistance, necessitating repair and replacement in older buildings. Because of the hardness of individual grains, uniformity of grain size and friability of their structure, some types of sandstone are excellent materials from which to make grindstones, for sharpening blades and other implements. Non-friable sandstone can be used to make grindstones for grinding grain, e.g., gritstone.\nA type of pure quartz sandstone, orthoquartzite, with more of 90\u201395 percent of quartz, has been proposed for nomination to the Global Heritage Stone Resource. In some regions of Argentina, the orthoquartzite-stoned fa\u00e7ade is one of the main features of the Mar del Plata style bungalows.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27773", "revid": "609725", "url": "https://en.wikipedia.org/wiki?curid=27773", "title": "Sophia of Hanover", "text": "Electress of Hanover from 1692 to 1698\nSophia (, ; 14 October\u00a0[O.S. 3 October]\u00a01630 \u2013 8 June\u00a0[O.S. 28 May]\u00a01714) was Electress of Hanover from 1692 to 1698 as the consort of Prince-Elector Ernest Augustus. She was later the heiress presumptive to the thrones of England and Scotland (later Great Britain) and Ireland under the Act of Settlement 1701, as she was the granddaughter of King James VI and I. Sophia died less than two months before she would have become Queen of Great Britain and Ireland. Consequently, her son George succeeded her first cousin once removed, Queen Anne, to the British throne. The succession to the throne has since been composed entirely of, and legally defined as, Sophia's legitimate and Protestant descendants.\nSophia was born in The Hague to Frederick V, formerly Elector Palatine and King of Bohemia, and Elizabeth (Stuart), daughter of King James VI and I. She grew up in the Dutch Republic, where her family had sought refuge after the sequestration of their Electorate during the Thirty Years' War. Sophia's brother Charles Louis was restored as elector in the Palatinate as part of the Peace of Westphalia. During this time, the English Stuarts also went into exile and Sophia was courted by her cousin, Charles II of England. \nSophia instead married Prince Ernest Augustus, her third cousin, in 1658. Despite his temper and frequent absences, Sophia loved him and bore him seven children who survived to adulthood. Born a landless cadet, Ernest Augustus succeeded in having the House of Hanover raised to electoral dignity in 1692. As a result, Princess Sophia became Electress of Hanover, the title by which she is best remembered. A patron of the arts, Sophia commissioned Herrenhausen Palace and its gardens and sponsored philosophers, such as Gottfried Leibniz and John Toland.\nEarly life.\nThe twelfth child and fifth daughter of Frederick V of the Palatinate and Elizabeth Stuart, also known as the \"Winter King and Queen of Bohemia\" for their short rule in that country, Sophia was born in The Wassenaer Hof, The Hague, Dutch Republic, where her parents had fled into exile after the Battle of White Mountain. Through her mother, she was the granddaughter of James VI and I, king of Scotland and England in a personal union. At birth, Sophia was granted an annuity of 40 thalers by the Estates of Friesland. Three noble ladies, also named Sophia, were to act as her godmothers.\nSophia's birth was accompanied by the death by drowning of her eldest brother, Frederick Henry. When Sophia was nine years old, her brother Gustavus died, something that affected her even 40 years later. \nWhen she was 21, Sophia started her friendship with Ren\u00e9 Descartes, who was so impressed with her that he dedicated Principles of Philosophy to her, writing in the dedication that he had \"never met anyone who could so thoroughly understand all that is contained in my writings\".\nAn attack of smallpox in 1650 may have reduced her beauty. However, in 1653, there was discussion of a match between her and Ferdinand IV, King of the Romans, but he soon died.\nSophia was courted by her first cousin, Charles II of England, but she rebuffed his advances as she thought he was using her in order to get money from her mother's supporter, Lord William Craven.\nMarriage.\nBefore her marriage, Sophia, as the daughter of Frederick V, Elector Palatine of the Rhine, was referred to as Sophie, Princess Palatine of the Rhine, or as Sophia of the Palatinate. The Electors of the Palatinate were the Calvinist senior branch of House of Wittelsbach, whose Catholic branch ruled the Electorate of Bavaria.\nOn 30 September 1658, she married Ernest Augustus, Duke of Brunswick-L\u00fcneburg, at Heidelberg, who in 1692 became the first Elector of Hanover. Ernest Augustus was a second cousin of Sophia's mother Elizabeth Stuart, Queen of Bohemia, as they were both great-grandchildren of Christian III of Denmark.\nSophia became a friend and admirer of Gottfried Leibniz while he was librarian at the Court of Hanover. Their friendship lasted from 1676 until her death in 1714. This friendship resulted in a substantial correspondence, first published in the 19th century (Klopp 1973), that reveals Sophia to have been a woman of exceptional intellectual ability and curiosity. She was well-read in the works of Ren\u00e9 Descartes and Baruch Spinoza. Together with Ernest Augustus she greatly improved the Herrenhausen Palace, and she was the guiding spirit in the creation of the Herrenhausen Gardens surrounding the palace, where she died.\nIn 1680, during another long visit to Italy by her husband, Sophia wrote her memories of her first fifty-years of life.\nLetters.\nSophia was an amazing writer renowned across Europe for her intellect. She is placed among Madame de Sevigne and Cardinal de Retz as chroniclers of history in royal and princely courts. \nShe first sat down to write her memoirs when she was fifty, around when some of her family had died, most notably, her brother and sister, Karl-Ludwig and Elisabeth of the Palatinate, as therapy.\nIssue.\nSophia had seven children who reached adulthood:\nThree of her sons were killed in battle.\nSophia was absent for almost a year, 1664\u201365, during a long holiday with Ernest Augustus in Italy. She corresponded regularly with her sons' governess and took a great interest in her sons' upbringing, even more so on her return. After Sophia's tour, she bore Ernest Augustus another four sons and a daughter. In her letters, Sophia describes her eldest son as a responsible, conscientious child who set an example to his younger brothers and sisters.\nSophia was, at first, against the marriage of her son George and Sophia Dorothea of Celle, looking down on Sophia Dorothea's mother \u00c9l\u00e9onore Desmier d'Olbreuse (who was not of royal birth and to whom Sophia referred as \"mouse dirt mixed among the pepper\") and concerned by Sophia Dorothea's legitimated status, but was eventually won over by the financial advantages inherent in the marriage.\nHeiress presumptive.\nIn September 1700, Sophia met her cousin King William III of England, Scotland and Ireland at Het Loo Palace in Apeldoorn, Netherlands. This happened two months after the death of his nephew Prince William, Duke of Gloucester, son of Princess Anne of Denmark (the future Queen Anne). By this time, given the ailing William III's reluctance to remarry, the inclusion of Sophia in the line of succession was becoming more likely because she was a Protestant, as was her son. Her candidature was aided by the fact that she had grown up in the Netherlands close to William III and was able to converse fluently with him in Dutch, his native tongue.\nA year after their meeting, the Parliament of England passed the Act of Settlement 1701, which declared that in the event of no legitimate issue from Anne or William III, the crowns of England and Ireland were to settle upon \"the most excellent princess Sophia, electress and duchess-dowager of Hanover\" and \"the heirs of her body, being Protestant\". Scotland being a separate state in international law at the time, this did not mean she would also succeed Anne as queen of Scotland, which led to a succession crisis and eventually to the Treaty of Union between Scotland and England in 1706/07.\nThe key excerpt from the Act, naming Sophia as heir presumptive, reads:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Therefore for a further Provision of the Succession of the Crown in the Protestant Line We Your Majesties most dutifull and Loyall Subjects the Lords Spirituall and Lords Temporall and Commons in this present Parliament assembled do beseech Your Majesty that it may be enacted and declared and be it enacted and declared by the Kings most Excellent Majesty by and with the Advice and Consent of the Lords Spirituall and Temporall and Commons in this present Parliament assembled and by the Authority of the same That the most Excellent Princess Sophia Electress and Dutchess Dowager of Hannover Daughter of the most Excellent Princess Elizabeth late Queen of Bohemia Daughter of our late Sovereign Lord King James the First of happy Memory be and is hereby declared to be the next in Succession in the Protestant Line to the Imperiall Crown and Dignity of the forsaid Realms of England France and Ireland with the Dominions and Territories thereunto belonging after His Majesty and the Princess Anne of Denmark and in Default of Issue of the said Princess Anne and of His Majesty respectively.\nSophia was made next in line to cut off a claim by the Catholic James Francis Edward Stuart, who would have become James III and VIII, and to deny the throne to the many other Roman Catholics and spouses of Roman Catholics who held a claim. The act restricts the British throne to the \"Protestant heirs\" of Sophia of Hanover who had never been Roman Catholic, or married a Roman Catholic. In 1711, the General Assembly of the Church of Scotland recommended that its congregations pray regularly \"for the Princess Sophia, Electoress and Duchess Dowager of Hanover, and the Protestant line in that family, upon whom the succession to the crown of these dominions is by law established\".\nSome British politicians attempted several times to bring Sophia to England in order to enable her to assume government immediately in the event of Anne's death. It was argued that such a course was necessary to ensure Sophia's succession, for Anne's Roman Catholic half-brother was significantly closer to London than was Sophia. The Electress was eager to move to London, but the proposal was denied, as such action would mortally offend Anne, who was strongly opposed to a rival court in her kingdom. Anne might have been aware that Sophia, who was active and lively despite her old age, could cut a better figure than herself. Sophia was completely uncertain of what would happen after Anne's death, saying: \"What Parliament does one day, it undoes the next.\"\nWhen the law was passed in mid-1701, Sophia at age 70, five of her children from ages 35 to 41, and three legitimate grandchildren from ages 14 to 18, were alive. Although Sophia was 35 years older than Anne, she was very fit and healthy, and invested time and energy in securing the succession either for herself or her son. There are more than 5,000 legitimate descendants of Sophia, although not all are in the line of succession. The Sophia Naturalization Act 1705 (4 &amp; 5 Ann. c. 16) granted the right of British (or more correctly English, as Great Britain only came into existence in 1707) nationality to Sophia's non-Roman Catholic descendants; those who had obtained the right to British citizenship via this Act at any time before its repeal by the British Nationality Act 1948 retain this lawful right today.\nDeath and legacy.\nAlthough considerably older than Queen Anne, Sophia enjoyed much better health. According to the Countess of B\u00fcckeburg in a letter to Sophia's niece, the Raugravine Luise, on 5 June 1714 Sophia felt ill after receiving an angry letter from Queen Anne. Three days later, on 8 June, she was walking in the gardens of Herrenhausen when she ran to shelter from a sudden downpour of rain and collapsed and died in the arms of her granddaughter-in-law Caroline of Ansbach, Electoral Princess of Hanover. Sophia was 83, a very advanced age for the era. Queen Anne died less than two months later on 1 August 1714 at the age of 49. Had Sophia survived Anne, she would have been the oldest person to ascend the British throne.\nUpon Sophia's death, her eldest son Elector George Louis of Hanover (1660\u20131727) became heir presumptive in her place and within two months succeeded Anne as George I of Great Britain. Sophia's daughter Sophia Charlotte of Hanover (1668\u20131705) married Frederick I of Prussia, from whom the later Prussian and German monarchs descend.\nSophia was buried in the chapel of Leine Palace in Hanover, as were her husband and their son George I. After the destruction of the palace and its chapel during World War II by Allied aerial raids, their remains were moved into the mausoleum of King Ernest Augustus I in the Berggarten of Herrenhausen Gardens in 1957.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27774", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=27774", "title": "Scanning tunneling microscope", "text": "Instrument able to image surfaces at the atomic level by exploiting quantum tunneling effects\nA scanning tunneling microscope (STM) is a type of scanning probe microscope used for imaging surfaces at the atomic level. Its development in 1981 earned its inventors, Gerd Binnig and Heinrich Rohrer, then at IBM Z\u00fcrich, the Nobel Prize in Physics in 1986. STM senses the surface by using an extremely sharp conducting tip that can distinguish features smaller than 0.1\u00a0nm with a 0.01\u00a0nm (10\u00a0pm) depth resolution. This means that individual atoms can routinely be imaged and manipulated. Most scanning tunneling microscopes are built for use in ultra-high vacuum at temperatures approaching absolute zero, but variants exist for studies in air, water and other environments, and for temperatures over 1000\u00a0\u00b0C.\nSTM is based on the concept of quantum tunneling. When the tip is brought very near to the surface to be examined, a bias voltage applied between the two allows electrons to tunnel through the vacuum separating them. The resulting \"tunneling current\" is a function of the tip position, applied voltage, and the local density of states (LDOS) of the sample. Information is acquired by monitoring the current as the tip scans across the surface, and is usually displayed in image form.\nA refinement of the technique known as scanning tunneling spectroscopy consists of keeping the tip in a constant position above the surface, varying the bias voltage and recording the resultant change in current. Using this technique, the local density of the electronic states can be reconstructed. This is sometimes performed in high magnetic fields and in presence of impurities to infer the properties and interactions of electrons in the studied material, for example from Quasiparticle interference imaging.\nScanning tunneling microscopy can be a challenging technique, as it requires extremely clean and stable surfaces, sharp tips, excellent vibration isolation, and sophisticated electronics. Nonetheless, many hobbyists build their own microscopes.\nProcedure.\nThe tip is brought close to the sample by a coarse positioning mechanism that is usually monitored visually. At close range, fine control of the tip position with respect to the sample surface is achieved by piezoelectric scanner tubes whose length can be altered by a control voltage. A bias voltage is applied between the sample and the tip, and the scanner is gradually elongated until the tip starts receiving the tunneling current. The tip\u2013sample separation \"w\" is then kept somewhere in the 4\u20137\u00a0\u00c5 (0.4\u20130.7\u00a0nm) range, slightly above the height where the tip would experience repulsive interaction (\"w\" &lt; 3 \u00c5), but still in the region where attractive interaction exists (3 &lt; \"w\" &lt; 10 \u00c5). The tunneling current, being in the sub-nanoampere range, is amplified as close to the scanner as possible. Once tunneling is established, the sample bias and tip position with respect to the sample are varied according to the requirements of the experiment.\nAs the tip is moved across the surface in a discrete \"x\"\u2013\"y\" matrix, the changes in surface height and population of the electronic states cause changes in the tunneling current. Digital images of the surface are formed in one of the two ways: in the \"constant-height mode\" changes of the tunneling current are mapped directly, while in the \"constant-current mode\" the voltage that controls the height (\"z\") of the tip is recorded while the tunneling current is kept at a predetermined level.\nIn constant-current mode, feedback electronics adjust the height by a voltage to the piezoelectric height-control mechanism. If at some point the tunneling current is below the set level, the tip is moved towards the sample, and conversely. This mode is relatively slow, as the electronics need to check the tunneling current and adjust the height in a feedback loop at each measured point of the surface. When the surface is atomically flat, the voltage applied to the \"z\"-scanner mainly reflects variations in local charge density. But when an atomic step is encountered, or when the surface is buckled due to reconstruction, the height of the scanner also have to change because of the overall topography. The image formed of the \"z\"-scanner voltages that were needed to keep the tunneling current constant as the tip scanned the surface thus contain both topographical and electron density data. In some cases it may not be clear whether height changes came as a result of one or the other.\nIn constant-height mode, the \"z\"-scanner voltage is kept constant as the scanner swings back and forth across the surface, and the tunneling current, exponentially dependent on the distance, is mapped. This mode of operation is faster, but on rough surfaces, where there may be large adsorbed molecules present, or ridges and groves, the tip will be in danger of crashing.\nThe raster scan of the tip is anything from a 128\u00d7128 to a 1024\u00d71024 (or more) matrix, and for each point of the raster a single value is obtained. The images produced by STM are therefore grayscale, and color is only added in post-processing in order to visually emphasize important features.\nIn addition to scanning across the sample, information on the electronic structure at a given location in the sample can be obtained by sweeping the bias voltage (along with a small AC modulation to directly measure the derivative) and measuring current change at a specific location. This type of measurement is called scanning tunneling spectroscopy (STS) and typically results in a plot of the local density of states as a function of the electrons' energy within the sample. The advantage of STM over other measurements of the density of states lies in its ability to make extremely local measurements. This is how, for example, the density of states at an impurity site can be compared to the density of states around the impurity and elsewhere on the surface.\nInstrumentation.\nThe main components of a scanning tunneling microscope are the scanning tip, piezoelectrically controlled height (\"z\" axis) and lateral (\"x\" and \"y\" axes) scanner, and coarse sample-to-tip approach mechanism. The microscope is controlled by dedicated electronics and a computer. The system is supported on a vibration isolation system.\nThe tip is often made of tungsten or platinum\u2013iridium wire, though gold is also used. Tungsten tips are usually made by electrochemical etching, and platinum\u2013iridium tips by mechanical shearing. The resolution of an image is limited by the radius of curvature of the scanning tip. Sometimes, image artefacts occur if the tip has more than one apex at the end; most frequently \"double-tip imaging\" is observed, a situation in which two apices contribute equally to the tunneling. While several processes for obtaining sharp, usable tips are known, the ultimate test of quality of the tip is only possible when it is tunneling in the vacuum. Every so often the tips can be conditioned by applying high voltages when they are already in the tunneling range, or by making them pick up an atom or a molecule from the surface.\nIn most modern designs the scanner is a hollow tube of a radially polarized piezoelectric with metallized surfaces. The outer surface is divided into four long quadrants to serve as \"x\" and \"y\" motion electrodes with deflection voltages of two polarities applied on the opposing sides. The tube material is a lead zirconate titanate ceramic with a piezoelectric constant of about 5\u00a0nanometres per volt. The tip is mounted at the center of the tube. Because of some crosstalk between the electrodes and inherent nonlinearities, the motion is calibrated, and voltages needed for independent \"x\", \"y\" and \"z\" motion applied according to calibration tables.\nDue to the extreme sensitivity of the tunneling current to the separation of the electrodes, proper vibration isolation or a rigid STM body is imperative for obtaining usable results. In the first STM by Binnig and Rohrer, magnetic levitation was used to keep the STM free from vibrations; now mechanical spring or gas spring systems are often employed. Additionally, mechanisms for vibration damping using eddy currents are sometimes implemented. Microscopes designed for long scans in scanning tunneling spectroscopy need extreme stability and are built in anechoic chambers\u2014dedicated concrete rooms with acoustic and electromagnetic isolation that are themselves floated on vibration isolation devices inside the laboratory.\nMaintaining the tip position with respect to the sample, scanning the sample and acquiring the data is computer-controlled. Dedicated software for scanning probe microscopies is used for image processing as well as performing quantitative measurements.\nSome scanning tunneling microscopes are capable of recording images at high frame rates. Videos made of such images can show surface diffusion or track adsorption and reactions on the surface. In video-rate microscopes, frame rates of 80\u00a0Hz have been achieved with fully working feedback that adjusts the height of the tip.\nPrinciple of operation.\nQuantum tunneling of electrons is a functioning concept of STM that arises from quantum mechanics. Classically, a particle hitting an impenetrable barrier will not pass through. If the barrier is described by a potential acting along \"z\" direction, in which an electron of mass \"m\"e acquires the potential energy \"U\"(\"z\"), the electron's trajectory will be deterministic and such that the sum \"E\" of its kinetic and potential energies is at all times conserved:\n formula_1\nThe electron will have a defined, non-zero momentum \"p\" only in regions where the initial energy \"E\" is greater than \"U\"(\"z\"). In quantum physics, however, the electron can pass through classically forbidden regions. This is referred to as tunneling.\nRectangular barrier model.\nThe simplest model of tunneling between the sample and the tip of a scanning tunneling microscope is that of a rectangular potential barrier. An electron of energy \"E\" is incident upon an energy barrier of height \"U\", in the region of space of width \"w\". An electron's behavior in the presence of a potential \"U\"(\"z\"), assuming one-dimensional case, is described by wave functions formula_2 that satisfy the Schr\u00f6dinger equation\n formula_3\nwhere \"\u0127\" is the reduced Planck constant, \"z\" is the position, and \"m\"e is the electron mass. In the zero-potential regions on two sides of the barrier, the wave function takes on the forms\n formula_4 for \"z\" &lt; 0,\n formula_5 for \"z\" &gt; \"w\",\nwhere formula_6. Inside the barrier, where \"E\" &lt; \"U\", the wave function is a superposition of two terms, each decaying from one side of the barrier:\n formula_7 for 0 &lt; \"z\" &lt; \"w\",\nwhere formula_8.\nThe coefficients \"r\" and \"t\" provide measure of how much of the incident electron's wave is reflected or transmitted through the barrier. Namely, of the whole impinging particle current formula_9 only formula_10 is transmitted, as can be seen from the probability current expression\n formula_11\nwhich evaluates to formula_12. The transmission coefficient is obtained from the continuity condition on the three parts of the wave function and their derivatives at \"z\" = 0 and \"z\" = \"w\" (detailed derivation is in the article Rectangular potential barrier). This gives formula_13 where formula_14. The expression can be further simplified, as follows:\nIn STM experiments, typical barrier height is of the order of the material's surface work function \"W\", which for most metals has a value between 4 and 6\u00a0eV. The work function is the minimum energy needed to bring an electron from an occupied level, the highest of which is the Fermi level (for metals at \"T\" = 0\u00a0K), to vacuum level. The electrons can tunnel between two metals only from occupied states on one side into the unoccupied states of the other side of the barrier. Without bias, Fermi energies are flush, and there is no tunneling. Bias shifts electron energies in one of the electrodes higher, and those electrons that have no match at the same energy on the other side will tunnel. In experiments, bias voltages of a fraction of 1\u00a0V are used, so formula_15 is of the order of 10 to 12\u00a0nm\u22121, while \"w\" is a few tenths of a nanometre. The barrier is strongly attenuating. The expression for the transmission probability reduces to formula_16 The tunneling current from a single level is therefore\n formula_17\nwhere both wave vectors depend on the level's energy \"E\", formula_18 and formula_19\nTunneling current is exponentially dependent on the separation of the sample and the tip, typically reducing by an order of magnitude when the separation is increased by 1\u00a0\u00c5 (0.1\u00a0nm). Because of this, even when tunneling occurs from a non-ideally sharp tip, the dominant contribution to the current is from its most protruding atom or orbital.\nTunneling between two conductors.\nAs a result of the restriction that the tunneling from an occupied energy level on one side of the barrier requires an empty level of the same energy on the other side of the barrier, tunneling occurs mainly with electrons near the Fermi level. The tunneling current can be related to the density of available or filled states in the sample. The current due to an applied voltage \"V\" (assume tunneling occurs from the sample to the tip) depends on two factors: 1) the number of electrons between the Fermi level \"E\"F and \"E\"F\u00a0\u2212\u00a0\"eV\" in the sample, and 2) the number among them that have corresponding free states to tunnel into on the other side of the barrier at the tip. The higher the density of available states in the tunneling region the greater the tunneling current. By convention, a positive \"V\" means that electrons in the tip tunnel into empty states in the sample; for a negative bias, electrons tunnel out of occupied states in the sample into the tip.\nFor small biases and temperatures near absolute zero, the number of electrons in a given volume (the electron concentration) that are available for tunneling is the product of the density of the electronic states \"\u03c1\"(\"E\"F) and the energy interval between the two Fermi levels, \"eV\". Half of these electrons will be travelling away from the barrier. The other half will represent the electric current impinging on the barrier, which is given by the product of the electron concentration, charge, and velocity \"v\" (\"I\"i\u00a0=\u00a0\"nev\"),\n formula_20\nThe tunneling electric current will be a small fraction of the impinging current. The proportion is determined by the transmission probability \"T\", so\\\n formula_21\nIn the simplest model of a rectangular potential barrier the transmission probability coefficient \"T\" equals |\"t\"|2.\nBardeen's formalism.\nA model that is based on more realistic wave functions for the two electrodes was devised by John Bardeen in a study of the metal\u2013insulator\u2013metal junction. His model takes two separate orthonormal sets of wave functions for the two electrodes and examines their time evolution as the systems are put close together. Bardeen's novel method, ingenious in itself, solves a time-dependent perturbative problem in which the perturbation emerges from the interaction of the two subsystems rather than an external potential of the standard Rayleigh\u2013Schr\u00f6dinger perturbation theory.\nEach of the wave functions for the electrons of the sample (S) and the tip (T) decay into the vacuum after hitting the surface potential barrier, roughly of the size of the surface work function. The wave functions are the solutions of two separate Schr\u00f6dinger equations for electrons in potentials \"U\"S and \"U\"T. When the time dependence of the states of known energies formula_22 and formula_23 is factored out, the wave functions have the following general form\n formula_24\n formula_25\nIf the two systems are put closer together, but are still separated by a thin vacuum region, the potential acting on an electron in the combined system is \"U\"T + \"U\"S. Here, each of the potentials is spatially limited to its own side of the barrier. Only because the tail of a wave function of one electrode is in the range of the potential of the other, there is a finite probability for any state to evolve over time into the states of the other electrode. The future of the sample's state \"\u03bc\" can be written as a linear combination with time-dependent coefficients of formula_26 and all formula_27:\n formula_28\nwith the initial condition formula_29. When the new wave function is inserted into the Schr\u00f6dinger equation for the potential \"U\"T + \"U\"S, the obtained equation is projected onto each separate formula_30 (that is, the equation is multiplied by a formula_31 and integrated over the whole volume) to single out the coefficients formula_32 All formula_33 are taken to be \"nearly orthogonal\" to all formula_34 (their overlap is a small fraction of the total wave functions), and only first-order quantities retained. Consequently, the time evolution of the coefficients is given by\n formula_35\nBecause the potential \"U\"T is zero at the distance of a few atomic diameters away from the surface of the electrode, the integration over \"z\" can be done from a point \"z\"0 somewhere inside the barrier and into the volume of the tip (\"z\"\u00a0&gt;\u00a0\"z\"0).\nIf the tunneling matrix element is defined as\n formula_36\nthe probability of the sample's state \"\u03bc\" evolving in time \"t\" into the state of the tip \"\u03bd\" is\n formula_37\nIn a system with many electrons impinging on the barrier, this probability will give the proportion of those that successfully tunnel. If at a time \"t\" this fraction was formula_38 at a later time \"t\"\u00a0+\u00a0d\"t\" the total fraction of formula_39 would have tunneled. The \"current\" of tunneling electrons at each instance is therefore proportional to formula_40 divided by formula_41 which is the time derivative of formula_42\n formula_43\nThe time scale of the measurement in STM is many orders of magnitude larger than the typical femtosecond time scale of electron processes in materials, and formula_44 is large. The fraction part of the formula is a fast-oscillating function of formula_45 that rapidly decays away from the central peak, where formula_46. In other words, the most probable tunneling process, by far, is the elastic one, in which the electron's energy is conserved. The fraction, as written above, is a representation of the delta function, so\n formula_47\nSolid-state systems are commonly described in terms of continuous rather than discrete energy levels. The term formula_48 can be thought of as the density of states of the tip at energy formula_49 giving\n formula_50\nThe number of energy levels in the sample between the energies formula_51 and formula_52 is formula_53 When occupied, these levels are spin-degenerate (except in a few special classes of materials) and contain charge formula_54 of either spin. With the sample biased to voltage formula_55 tunneling can occur only between states whose occupancies, given for each electrode by the Fermi\u2013Dirac distribution formula_56, are not the same, that is, when either one or the other is occupied, but not both. That will be for all energies formula_51 for which formula_58 is not zero. For example, an electron will tunnel from energy level formula_59 in the sample into energy level formula_60 in the tip (formula_61), an electron at formula_60 in the sample will find unoccupied states in the tip at formula_63 (formula_64), and so will be for all energies in between. The tunneling current is therefore the sum of little contributions over all these energies of the product of three factors: formula_65 representing available electrons, formula_58 for those that are allowed to tunnel, and the probability factor formula_67 for those that will actually tunnel:\n formula_68\nTypical experiments are run at a liquid-helium temperature (around 4\u00a0K), at which the Fermi-level cut-off of the electron population is less than a millielectronvolt wide. The allowed energies are only those between the two step-like Fermi levels, and the integral becomes\n formula_69\nWhen the bias is small, it is reasonable to assume that the electron wave functions and, consequently, the tunneling matrix element do not change significantly in the narrow range of energies. Then the tunneling current is simply the convolution of the densities of states of the sample surface and the tip:\n formula_70\nHow the tunneling current depends on distance between the two electrodes is contained in the tunneling matrix element\n formula_71\nThis formula can be transformed so that no explicit dependence on the potential remains. First, the formula_72 part is taken out from the Schr\u00f6dinger equation for the tip, and the elastic tunneling condition is used so that\n formula_73\nNow formula_74 is present in the Schr\u00f6dinger equation for the sample and equals the kinetic plus the potential operator acting on formula_75 However, the potential part containing \"U\"S is on the tip side of the barrier nearly zero. What remains,\n formula_76\ncan be integrated over \"z\" because the integrand in the parentheses equals formula_77\nBardeen's tunneling matrix element is an integral of the wave functions and their gradients over a surface separating the two planar electrodes:\n formula_78\nThe exponential dependence of the tunneling current on the separation of the electrodes comes from the very wave functions that \"leak\" through the potential step at the surface and exhibit exponential decay into the classically forbidden region outside of the material.\nThe tunneling matrix elements show appreciable energy dependence, which is such that tunneling from the upper end of the \"eV\" interval is nearly an order of magnitude more likely than tunneling from the states at its bottom. When the sample is biased positively, its unoccupied levels are probed as if the density of states of the tip is concentrated at its Fermi level. Conversely, when the sample is biased negatively, its occupied electronic states are probed, but the spectrum of the electronic states of the tip dominates. In this case it is important that the density of states of the tip is as flat as possible.\nThe results identical to Bardeen's can be obtained by considering adiabatic approach of the two electrodes and using the standard time-dependent perturbation theory. This leads to Fermi's golden rule for the transition probability formula_79 in the form given above.\nBardeen's model is for tunneling between two planar electrodes and does not explain scanning tunneling microscope's lateral resolution. Tersoff and Hamann used Bardeen's theory and modeled the tip as a structureless geometric point. This helped them disentangle the properties of the tip\u2014which are hard to model\u2014from the properties of the sample surface. The main result was that the tunneling current is proportional to the local density of states of the sample at the Fermi level taken at the position of the center of curvature of a spherically symmetric tip (\"s\"-wave tip model). With such a simplification, their model proved valuable for interpreting images of surface features bigger than a nanometre, even though it predicted atomic-scale corrugations of less than a picometre. These are well below the microscope's detection limit and below the values actually observed in experiments.\nIn sub-nanometre-resolution experiments, the convolution of the tip and sample surface states will always be important, to the extent of the apparent inversion of the atomic corrugations that may be observed within the same scan. Such effects can only be explained by modeling of the surface and tip electronic states and the ways the two electrodes interact from first principles.\nEarly invention.\nAn earlier invention similar to Binnig and Rohrer's, the \"Topografiner\" of R. Young, J. Ward, and F. Scire from the NIST, relied on field emission. However, Young is credited by the Nobel Committee as the person who realized that it should be possible to achieve better resolution by using the tunnel effect.\nOther related techniques.\nMany other microscopy techniques have been developed based upon STM. These include photon scanning microscopy (PSTM), which uses an optical tip to tunnel photons; scanning tunneling potentiometry (STP), which measures electric potential across a surface; spin-polarized scanning tunneling microscopy (SPSTM), which uses a ferromagnetic tip to tunnel spin-polarized electrons into a magnetic sample; multi-tip scanning tunneling microscopy, which enables electrical measurements to be performed at the nanoscale; and atomic force microscopy (AFM), in which the force caused by interaction between the tip and sample is measured.\nSTM can be used to manipulate atoms and change the topography of the sample. This is attractive for several reasons. Firstly the STM has an atomically precise positioning system, which enables very accurate atomic-scale manipulation. Furthermore, after the surface is modified by the tip, the same instrument can be used to image the resulting structures. IBM researchers famously developed a way to manipulate xenon atoms adsorbed on a nickel surface. This technique has been used to create electron \"corrals\" with a small number of adsorbed atoms and observe Friedel oscillations in the electron density on the surface of the substrate. Aside from modifying the actual sample surface, one can also use the STM to tunnel electrons into a layer of electron-beam photoresist on the sample, in order to do lithography. This has the advantage of offering more control of the exposure than traditional electron-beam lithography. Another practical application of STM is atomic deposition of metals (gold, silver, tungsten, etc.) with any desired (pre-programmed) pattern, which can be used as contacts to nanodevices or as nanodevices themselves.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27775", "revid": "33454411", "url": "https://en.wikipedia.org/wiki?curid=27775", "title": "STM", "text": "STM may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "27777", "revid": "269022", "url": "https://en.wikipedia.org/wiki?curid=27777", "title": "Semi-automatic handgun", "text": ""}
{"id": "27778", "revid": "50441216", "url": "https://en.wikipedia.org/wiki?curid=27778", "title": "Svenska Akademiens ordbok", "text": "Svenska Akademiens ordbok (), abbreviated SAOB, is a historical dictionary of the Swedish language published by the Swedish Academy. It is the Swedish counterpart of the \"Oxford English Dictionary\" (OED) or the \"Deutsches W\u00f6rterbuch\" (DWB). \nWork on the dictionary started in 1787. The first edition was published in 39 volumes between 1898 and 2023, in Swedish alphabetical order, and contains over 500,000 entries. Updating of the earlier volumes, A to R, is expected to continue until 2030. The last volume was printed in about 500 copys. The 39 volumes total 33,111 pages. The searchable web version has been available since 1997. Citations date back to 1521.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27780", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=27780", "title": "Sun/Sunspot", "text": ""}
{"id": "27781", "revid": "4441371", "url": "https://en.wikipedia.org/wiki?curid=27781", "title": "Shirehorses", "text": "UK parody rock band, 1997\u20132001\nThe Shirehorses were a spoof band comprising two BBC Radio DJs from Manchester, Mark Radcliffe and Marc Riley, known collectively as Mark and Lard.\nAs part of their BBC Radio 1 shows, the pair produced pastiches of chart songs, such as \"You're Gormless\", a parody of Babybird's \"You're Gorgeous\", \"Lardy Boy\", a parody of Placebo's \"Nancy Boy\", and \"Why Is It Always Dairylea\", spoofing Travis's \"Why Does It Always Rain on Me?\", using the band names 'Baby Bloke', 'Gazebo' and 'Dave Lee Travisty' respectively. When they rewrote The Seahorses' \"Love Is the Law\" as \"(Now) I Know (Where I'm Going) Our Kid\", they chose the stage-name Shirehorses, which they then retained for future recordings and performances. Other parodies include \"I Want a Roll with It\" (spoofing \"Roll with It\" by Oasis), \"Feel Like Shite\" (\"Alright\" by Supergrass), and \"Country Spouse\" (\"Country House\" by Blur). \nThe band toured extensively, playing many small, university gigs to exploit their popularity with students. However, they also performed at larger venues, supporting Blur on a 1997 UK tour, taking in several stadia, and appearing at Glastonbury Festival in 1997.\nMarc Riley was formerly a member of British Manchester band the Fall and later the Creepers before embarking on a radio presentation career alongside Mark Radcliffe. Formerly a double act on BBC Radio 1, in March 2004 they went their separate ways, Radcliffe initially to BBC Radio 2, Riley to BBC Radio 6 Music and later joined at the station by Mark Radcliffe as part of the afternoon Radcliffe and Maconie show.\nDiscography.\nThe Shirehorses have released two albums to date:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27783", "revid": "49679309", "url": "https://en.wikipedia.org/wiki?curid=27783", "title": "Stem cell", "text": "Unspecialized biological cell that can become specialized\nIn multicellular organisms, stem cells are undifferentiated or partially differentiated cells that can change into various types of cells and proliferate indefinitely to produce more of the same stem cell. They are the earliest type of cell in a cell lineage. They are found in both embryonic and adult organisms, but they have slightly different properties in each. They are usually distinguished from progenitor cells, which cannot divide indefinitely, and precursor or blast cells, which are usually committed to differentiating into one cell type.\nIn mammals, roughly 50 to 150 cells make up the inner cell mass during the blastocyst stage of embryonic development, around days 5\u201314. These have stem-cell capability. \"In vivo\", they eventually differentiate into all of the body's cell types (making them pluripotent). This process starts with the differentiation into the three germ layers \u2013 the ectoderm, mesoderm and endoderm \u2013 at the gastrulation stage. However, when they are isolated and cultured \"in vitro\", they can be kept in the stem-cell stage and are known as embryonic stem cells (ESCs).\nAdult stem cells are found in a few select locations in the body, known as niches, such as those in the bone marrow or gonads. They exist to replenish rapidly lost cell types and are multipotent or unipotent, meaning they only differentiate into a few cell types or one type of cell. In mammals, they include, among others, hematopoietic stem cells, which replenish blood and immune cells, basal cells, which maintain the skin epithelium, and mesenchymal stem cells, which maintain bone, cartilage, muscle and fat cells. Adult stem cells are a small minority of cells; they are vastly outnumbered by the progenitor cells and terminally differentiated cells that they differentiate into.\nResearch into stem cells grew out of findings by Canadian biologists Ernest McCulloch, James Till and Andrew J. Becker at the University of Toronto and the Ontario Cancer Institute in the 1960s. As of 2016[ [update]], the only established medical therapy using stem cells is hematopoietic stem cell transplantation, first performed in 1958 by French oncologist Georges Math\u00e9. Since 1998 however, it has been possible to culture and differentiate human embryonic stem cells (in stem-cell lines). The process of isolating these cells has been controversial, because it typically results in the destruction of the embryo. Sources for isolating ESCs have been restricted in some European countries and Canada, but others such as the UK and China have promoted the research. Somatic cell nuclear transfer is a cloning method that can be used to create a cloned embryo for the use of its embryonic stem cells in stem cell therapy. In 2006, a Japanese team led by Shinya Yamanaka discovered a method to convert mature body cells back into stem cells. These were termed induced pluripotent stem cells (iPSCs).\nHistory.\nThe term \"stem cell\" was coined by Theodor Boveri and Valentin Haecker in late 19th century. Pioneering works in theory of blood stem cell were conducted in the beginning of 20th century by Artur Pappenheim, Alexander A. Maximow, Franz Ernst Christian Neumann.\nThe key properties of a stem cell were first defined by Ernest McCulloch and James Till at the University of Toronto and the Ontario Cancer Institute in the early 1960s. They discovered the blood-forming stem cell, the hematopoietic stem cell (HSC), through their pioneering work in mice. McCulloch and Till began a series of experiments in which bone marrow cells were injected into irradiated mice. They observed lumps in the spleens of the mice that were linearly proportional to the number of bone marrow cells injected. They hypothesized that each lump (colony) was a clone arising from a single marrow cell (stem cell). In subsequent work, McCulloch and Till, joined by graduate student Andrew John Becker and senior scientist Louis Siminovitch, confirmed that each lump did in fact arise from a single cell. Their results were published in \"Nature\" in 1963. In that same year, Siminovitch was a lead investigator for studies that found colony-forming cells were capable of self-renewal, which is a key defining property of stem cells that Till and McCulloch had theorized.\nThe first therapy using stem cells was a bone marrow transplant performed by French oncologist Georges Math\u00e9 in 1956 on five workers at the Vin\u010da Nuclear Institute in Yugoslavia who had been affected by a criticality accident. The workers all survived.\nIn 1981, embryonic stem (ES) cells were first isolated and successfully cultured using mouse blastocysts by British biologists Martin Evans and Matthew Kaufman. This allowed the formation of murine genetic models, a system in which the genes of mice are deleted or altered in order to study their function in pathology. In 1991, a process that allowed the human stem cell to be isolated was patented by Ann Tsukamoto. By 1998, human embryonic stem cells were first isolated by American biologist James Thomson, which made it possible to have new transplantation methods or various cell types for testing new treatments. In 2006, Shinya Yamanaka's team in Kyoto, Japan converted fibroblasts into pluripotent stem cells by modifying the expression of only four genes. The feat represents the origin of induced pluripotent stem cells, known as iPS cells.\nIn 2011, a female maned wolf, run over by a truck, underwent stem cell treatment at the Zoo Bras\u00edlia, this being the first recorded case of the use of stem cells to heal injuries in a wild animal.\nProperties.\nThe classical definition of a stem cell requires that it possesses two properties:\nSelf-renewal.\nTwo mechanisms ensure that a stem cell population is maintained (does not shrink in size):\n1. Asymmetric cell division: a stem cell divides into one mother cell, which is identical to the original stem cell, and another daughter cell, which is differentiated.\nWhen a stem cell self-renews, it divides and disrupts the undifferentiated state. This self-renewal demands control of cell cycle as well as upkeep of multipotency or pluripotency, which all depends on the stem cell.\nH.\nStem cells use telomerase, a protein that restores telomeres, to protect their DNA and extend their cell division limit (the Hayflick limit).\nPotency meaning.\nPotency specifies the differentiation potential (the potential to differentiate into different cell types) of the stem cell.\nIdentification.\nIn practice, stem cells are identified by whether they can regenerate tissue. For example, the defining test for bone marrow or hematopoietic stem cells (HSCs) is the ability to transplant the cells and save an individual without HSCs. This demonstrates that the cells can produce new blood cells over a long term. It should also be possible to isolate stem cells from the transplanted individual, which can themselves be transplanted into another individual without HSCs, demonstrating that the stem cell was able to self-renew.\nProperties of stem cells can be illustrated \"in vitro\", using methods such as clonogenic assays, in which single cells are assessed for their ability to differentiate and self-renew. Stem cells can also be isolated by their possession of a distinctive set of cell surface markers. However, \"in vitro\" culture conditions can alter the behavior of cells, making it unclear whether the cells shall behave in a similar manner \"in vivo\". There is considerable debate as to whether some proposed adult cell populations are truly stem cells.\nEmbryonic.\nEmbryonic stem cells (ESCs) are the cells of the inner cell mass of a blastocyst, formed prior to implantation in the uterus. In human embryonic development the blastocyst stage is reached 4\u20135 days after fertilization, at which time it consists of 50\u2013150 cells. ESCs are pluripotent and give rise during development to all derivatives of the three germ layers: ectoderm, endoderm and mesoderm. In other words, they can develop into each of the more than 200 cell types of the adult body when given sufficient and necessary stimulation for a specific cell type. They do not contribute to the extraembryonic membranes or to the placenta.\nDuring embryonic development the cells of the inner cell mass continuously divide and become more specialized. For example, a portion of the ectoderm in the dorsal part of the embryo specializes as 'neurectoderm', which will become the future central nervous system (CNS). Later in development, neurulation causes the neurectoderm to form the neural tube. At the neural tube stage, the anterior portion undergoes encephalization to generate or 'pattern' the basic form of the brain. At this stage of development, the principal cell type of the CNS is considered a neural stem cell.\nThe neural stem cells self-renew and at some point transition into radial glial progenitor cells (RGPs). Early-formed RGPs self-renew by symmetrical division to form a reservoir group of progenitor cells. These cells transition to a neurogenic state and start to divide asymmetrically to produce a large diversity of many different neuron types, each with unique gene expression, morphological, and functional characteristics. The process of generating neurons from radial glial cells is called neurogenesis. The radial glial cell, has a distinctive bipolar morphology with highly elongated processes spanning the thickness of the neural tube wall. It shares some glial characteristics, most notably the expression of glial fibrillary acidic protein (GFAP). The radial glial cell is the primary neural stem cell of the developing vertebrate CNS, and its cell body resides in the ventricular zone, adjacent to the developing ventricular system. Neural stem cells are committed to the neuronal lineages (neurons, astrocytes, and oligodendrocytes), and thus their potency is restricted.\nNearly all research to date has made use of mouse embryonic stem cells (mES) or human embryonic stem cells (hES) derived from the early inner cell mass. Both have the essential stem cell characteristics, yet they require very different environments in order to maintain an undifferentiated state. Mouse ES cells are grown on a layer of gelatin as an extracellular matrix (for support) and require the presence of leukemia inhibitory factor (LIF) in serum media. A drug cocktail containing inhibitors to GSK3B and the MAPK/ERK pathway, called 2i, has also been shown to maintain pluripotency in stem cell culture. Human ESCs are grown on a feeder layer of mouse embryonic fibroblasts and require the presence of basic fibroblast growth factor (bFGF or FGF-2). Without optimal culture conditions or genetic manipulation, embryonic stem cells will rapidly differentiate.\nA human embryonic stem cell is also defined by the expression of several transcription factors and cell surface proteins. The transcription factors Oct-4, Nanog, and Sox2 form the core regulatory network that ensures the suppression of genes that lead to differentiation and the maintenance of pluripotency. The cell surface antigens most commonly used to identify hES cells are the glycolipids stage specific embryonic antigen 3 and 4, and the keratan sulfate antigens Tra-1-60 and Tra-1-81. The molecular definition of a stem cell includes many more proteins and continues to be a topic of research.\nBy using human embryonic stem cells to produce specialized cells like nerve cells or heart cells in the lab, scientists can gain access to adult human cells without taking tissue from patients. They can then study these specialized adult cells in detail to try to discern complications of diseases, or to study cell reactions to proposed new drugs.\nBecause of their combined abilities of unlimited expansion and pluripotency, embryonic stem cells remain a theoretically potential source for regenerative medicine and tissue replacement after injury or disease., however, there are currently no approved treatments using ES cells. The first human trial was approved by the US Food and Drug Administration in January 2009. However, the human trial was not initiated until October 13, 2010, in Atlanta for spinal cord injury research. On November 14, 2011, the company conducting the trial (Geron Corporation) announced that it will discontinue further development of its stem cell programs. Differentiating ES cells into usable cells while avoiding transplant rejection are just a few of the hurdles that embryonic stem cell researchers still face. Embryonic stem cells, being pluripotent, require specific signals for correct differentiation \u2013 if injected directly into another body, ES cells will differentiate into many different types of cells, causing a teratoma. Many nations currently have moratoria or limitations on either human ES cell research or the production of new human ES cell lines due to their ethical controversies. \nThe use of embryonic stem cells has generated significant ethical and political controversy. Central to the debate is the moral status of the human embryo, as deriving ES typically involves the destruction of early-stage embryos. Critics argue that this practice violates the sanctity of human life, and therefore is unacceptable.\nMesenchymal stem cells.\nMesenchymal stem cells (MSC) or mesenchymal stromal cells, also known as medicinal signaling cells are known to be multipotent, which can be found in adult tissues, for example, in the muscle, liver, bone marrow and adipose tissue. Mesenchymal stem cells usually function as structural support in various organs as mentioned above, and control the movement of substances. MSC can differentiate into numerous cell categories as an illustration of adipocytes, osteocytes, and chondrocytes, derived by the mesodermal layer. Where the mesoderm layer provides an increase to the body's skeletal elements, such as relating to the cartilage or bone. The term \"meso\" means middle, infusion originated from the Greek, signifying that mesenchymal cells are able to range and travel in early embryonic growth among the ectodermal and endodermal layers. This mechanism helps with space-filling thus, key for repairing wounds in adult organisms that have to do with mesenchymal cells in the dermis (skin), bone, or muscle.\nMesenchymal stem cells are known to be essential for regenerative medicine. They are broadly studied in clinical trials. Since they are easily isolated and obtain high yield, high plasticity, which makes able to facilitate inflammation and encourage cell growth, cell differentiation, and restoring tissue derived from immunomodulation and immunosuppression. MSC comes from the bone marrow, which requires an aggressive procedure when it comes to isolating the quantity and quality of the isolated cell, and it varies by how old the donor. When comparing the rates of MSC in the bone marrow aspirates and bone marrow stroma, the aspirates tend to have lower rates of MSC than the stroma. MSC are known to be heterogeneous, and they express a high level of pluripotent markers when compared to other types of stem cells, such as embryonic stem cells. MSCs injection leads to wound healing primarily through stimulation of angiogenesis.\nCell cycle control.\nEmbryonic stem cells (ESCs) have the ability to divide indefinitely while keeping their pluripotency, which is made possible through specialized mechanisms of cell cycle control. Compared to proliferating somatic cells, ESCs have unique cell cycle characteristics\u2014such as rapid cell division caused by shortened G1 phase, absent G0 phase, and modifications in cell cycle checkpoints\u2014which leaves the cells mostly in S phase at any given time. ESCs' rapid division is demonstrated by their short doubling time, which ranges from 8 to 10 hours, whereas somatic cells have doubling time of approximately 20 hours or longer. As cells differentiate, these properties change: G1 and G2 phases lengthen, leading to longer cell division cycles. This suggests that a specific cell cycle structure may contribute to the establishment of pluripotency.\nParticularly because G1 phase is the phase in which cells have increased sensitivity to differentiation, shortened G1 is one of the key characteristics of ESCs and plays an important role in maintaining undifferentiated phenotype. Although the exact molecular mechanism remains only partially understood, several studies have shown insight on how ESCs progress through G1\u2014and \u00a0potentially other phases\u2014so rapidly.\nThe cell cycle is regulated by complex network of cyclins, cyclin-dependent kinases (Cdk), cyclin-dependent kinase inhibitors (Cdkn), pocket proteins of the retinoblastoma (Rb) family, and other accessory factors. Foundational insight into the distinctive regulation of ESC cell cycle was gained by studies on mouse ESCs (mESCs). mESCs showed a cell cycle with highly abbreviated G1 phase, which enabled cells to rapidly alternate between M phase and S phase. In a somatic cell cycle, oscillatory activity of Cyclin-Cdk complexes is observed in sequential action, which controls crucial regulators of the cell cycle to induce unidirectional transitions between phases: Cyclin D and Cdk4/6 are active in the G1 phase, while Cyclin E and Cdk2 are active during the late G1 phase and S phase; and Cyclin A and Cdk2 are active in the S phase and G2, while Cyclin B and Cdk1 are active in G2 and M phase. However, in mESCs, this typically ordered and oscillatory activity of Cyclin-Cdk complexes is absent. Rather, the Cyclin E/Cdk2 complex is constitutively active throughout the cycle, keeping retinoblastoma protein (pRb) hyperphosphorylated and thus inactive. This allows for direct transition from M phase to the late G1 phase, leading to absence of D-type cyclins and therefore a shortened G1 phase. Cdk2 activity is crucial for both cell cycle regulation and cell-fate decisions in mESCs; downregulation of Cdk2 activity prolongs G1 phase progression, establishes a somatic cell-like cell cycle, and induces expression of differentiation markers.\nIn human ESCs (hESCs), the duration of G1 is dramatically shortened. This has been attributed to high mRNA levels of G1-related Cyclin D2 and Cdk4 genes and low levels of cell cycle regulatory proteins that inhibit cell cycle progression at G1, such as p21CipP1, p27Kip1, and p57Kip2. Furthermore, regulators of Cdk4 and Cdk6 activity, such as members of the Ink family of inhibitors (p15, p16, p18, and p19), are expressed at low levels or not at all. Thus, similar to mESCs, hESCs show high Cdk activity, with Cdk2 exhibiting the highest kinase activity. Also similar to mESCs, hESCs demonstrate the importance of Cdk2 in G1 phase regulation by showing that G1 to S transition is delayed when Cdk2 activity is inhibited and G1 is arrest when Cdk2 is knocked down. However unlike mESCs, hESCs have a functional G1 phase. hESCs show that the activities of Cyclin E/Cdk2 and Cyclin A/Cdk2 complexes are cell cycle-dependent and the Rb checkpoint in G1 is functional.\nESCs are also characterized by G1 checkpoint non-functionality, even though the G1 checkpoint is crucial for maintaining genomic stability. In response to DNA damage, ESCs do not stop in G1 to repair DNA damages but instead, depend on S and G2/M checkpoints or undergo apoptosis. The absence of G1 checkpoint in ESCs allows for the removal of cells with damaged DNA, hence avoiding potential mutations from inaccurate DNA repair. Consistent with this idea, ESCs are hypersensitive to DNA damage to minimize mutations passed onto the next generation.\nFetal.\nThe primitive stem cells located in the organs of fetuses are referred to as fetal stem cells.\nThere are two types of fetal stem cells:\nAdult.\nAdult stem cells, also called somatic (from Greek \u03c3\u03c9\u03bc\u03b1\u03c4\u03b9\u03ba\u00f3\u03c2, \"of the body\") stem cells, are stem cells which maintain and repair the tissue in which they are found.\nThere are four known accessible sources of autologous adult stem cells in humans:\nStem cells can also be taken from umbilical cord blood just after birth. Of all stem cell types, autologous harvesting involves the least risk. By definition, autologous cells are obtained from one's own body, just as one may bank their own blood for elective surgical procedures.\nPluripotent adult stem cells are rare and generally small in number, but they can be found in umbilical cord blood and other tissues. Bone marrow is a rich source of adult stem cells, which have been used in treating several conditions including liver cirrhosis, chronic limb ischemia and endstage heart failure. The quantity of bone marrow stem cells declines with age and is greater in males than females during reproductive years. Much adult stem cell research to date has aimed to characterize their potency and self-renewal capabilities. DNA damage accumulates with age in both stem cells and the cells that comprise the stem cell environment. This accumulation is considered to be responsible, at least in part, for increasing stem cell dysfunction with aging (see DNA damage theory of aging).\nMost adult stem cells are lineage-restricted (multipotent) and are generally referred to by their tissue origin (mesenchymal stem cell, adipose-derived stem cell, endothelial stem cell, dental pulp stem cell, etc.). Muse cells (multi-lineage differentiating stress enduring cells) are a recently discovered pluripotent stem cell type found in multiple adult tissues, including adipose, dermal fibroblasts, and bone marrow. While rare, muse cells are identifiable by their expression of SSEA-3, a marker for undifferentiated stem cells, and general mesenchymal stem cells markers such as CD90, CD105. When subjected to single cell suspension culture, the cells will generate clusters that are similar to embryoid bodies in morphology as well as gene expression, including canonical pluripotency markers Oct4, Sox2, and Nanog.\nAdult stem cell treatments have been successfully used for many years to treat leukemia and related bone/blood cancers through bone marrow transplants. Adult stem cells are also used in veterinary medicine to treat tendon and ligament injuries in horses.\nThe use of adult stem cells in research and therapy is not as controversial as the use of embryonic stem cells, because the production of adult stem cells does not require the destruction of an embryo. Additionally, in instances where adult stem cells are obtained from the intended recipient (an autograft), the risk of rejection is essentially non-existent. Consequently, more US government funding is being provided for adult stem cell research.\nWith the increasing demand of human adult stem cells for both research and clinical purposes (typically 1\u20135 million cells per kg of body weight are required per treatment) it becomes of utmost importance to bridge the gap between the need to expand the cells in vitro and the capability of harnessing the factors underlying replicative senescence. Adult stem cells are known to have a limited lifespan in vitro and to enter replicative senescence almost undetectably upon starting in vitro culturing.\nHematopoietic stem cells.\nHematopoietic stem cells (HSCs) are vulnerable to DNA damage and mutations that increase with age. This vulnerability may explain the increased risk of slow growing blood cancers (myeloid malignancies) in the elderly. Several factors appear to influence HSC aging including responses to the production of reactive oxygen species that may cause DNA damage and genetic mutations as well as altered epigenetic profiling.\nAmniotic.\nAlso called perinatal stem cells, these multipotent stem cells are found in amniotic fluid and umbilical cord blood. These stem cells are very active, expand extensively without feeders and are not tumorigenic. Amniotic stem cells are multipotent and can differentiate in cells of adipogenic, osteogenic, myogenic, endothelial, hepatic and also neuronal lines.\nAmniotic stem cells are a topic of active research.\nUse of stem cells from amniotic fluid overcomes the ethical objections to using human embryos as a source of cells. Roman Catholic teaching forbids the use of embryonic stem cells in experimentation; accordingly, the Vatican newspaper \"Osservatore Romano\" called amniotic stem cells \"the future of medicine\".\nIt is possible to collect amniotic stem cells for donors or for autologous use: the first US amniotic stem cells bank was opened in 2009 in Medford, MA, by Biocell Center Corporation and collaborates with various hospitals and universities all over the world.\nInduced pluripotent.\nAdult stem cells have limitations with their potency; unlike embryonic stem cells (ESCs), they are not able to differentiate into cells from all three germ layers. As such, they are deemed multipotent.\nHowever, reprogramming allows for the creation of pluripotent cells, induced pluripotent stem cells (iPSCs), from adult cells. These are not adult stem cells, but somatic cells (e.g. epithelial cells) reprogrammed to give rise to cells with pluripotent capabilities. Using genetic reprogramming with protein transcription factors, pluripotent stem cells with ESC-like capabilities have been derived. The first demonstration of induced pluripotent stem cells was conducted by Shinya Yamanaka and his colleagues at Kyoto University. They used the transcription factors Oct3/4, Sox2, c-Myc, and Klf4 to reprogram mouse fibroblast cells into pluripotent cells. Subsequent work used these factors to induce pluripotency in human fibroblast cells. Junying Yu, James Thomson, and their colleagues at the University of Wisconsin\u2013Madison used a different set of factors, Oct4, Sox2, Nanog and Lin28, and carried out their experiments using cells from human foreskin. However, they were able to replicate Yamanaka's finding that inducing pluripotency in human cells was possible.\nInduced pluripotent stem cells differ from embryonic stem cells. They share many similar properties, such as pluripotency and differentiation potential, the expression of pluripotency genes, epigenetic patterns, embryoid body and teratoma formation, and viable chimera formation, but there are many differences within these properties. The chromatin of iPSCs appears to be more \"closed\" or methylated than that of ESCs. Similarly, the gene expression pattern between ESCs and iPSCs, or even iPSCs sourced from different origins. There are thus questions about the \"completeness\" of reprogramming and the somatic memory of induced pluripotent stem cells. Despite this, inducing somatic cells to be pluripotent appears to be viable.\nAs a result of the success of these experiments, Ian Wilmut, who helped create the first cloned animal Dolly the Sheep, has announced that he will abandon somatic cell nuclear transfer as an avenue of research.\nThe ability to induce pluripotency benefits developments in tissue engineering. By providing a suitable scaffold and microenvironment, iPSC can be differentiated into cells of therapeutic application, and for \"in vitro\" models to study toxins and pathogenesis.\nInduced pluripotent stem cells provide several therapeutic advantages. Like ESCs, they are pluripotent. They thus have great differentiation potential; theoretically, they could produce any cell within the human body (if reprogramming to pluripotency was \"complete\"). Moreover, unlike ESCs, they potentially could allow doctors to create a pluripotent stem cell line for each individual patient. Frozen blood samples can be used as a valuable source of induced pluripotent stem cells. Patient specific stem cells allow for the screening for side effects before drug treatment, as well as the reduced risk of transplantation rejection. Despite their current limited use therapeutically, iPSCs hold great potential for future use in medical treatment and research.\nCell cycle control.\nThe key factors controlling the cell cycle also regulate pluripotency. Thus, manipulation of relevant genes can maintain pluripotency and reprogram somatic cells to an induced pluripotent state. However, reprogramming of somatic cells is often low in efficiency and considered stochastic.\nWith the idea that a more rapid cell cycle is a key component of pluripotency, reprogramming efficiency can be improved. Methods for improving pluripotency through manipulation of cell cycle regulators include: overexpression of Cyclin D/Cdk4, phosphorylation of Sox2 at S39 and S253, overexpression of Cyclin A and Cyclin E, knockdown of Rb, and knockdown of members of the Cip/Kip family or the Ink family. Furthermore, reprogramming efficiency is correlated with the number of cell divisions happened during the stochastic phase, which is suggested by the growing inefficiency of reprogramming of older or slow diving cells.\nLineage.\nLineage is an important procedure to analyze developing embryos. Since cell lineages shows the relationship between cells at each division. This helps in analyzing stem cell lineages along the way which helps recognize stem cell effectiveness, lifespan, and other factors. With the technique of cell lineage mutant genes can be analyzed in stem cell clones that can help in genetic pathways. These pathways can regulate how the stem cell perform.\nTo ensure self-renewal, stem cells undergo two types of cell division (see \"Stem cell division and differentiation\" diagram). Symmetric division gives rise to two identical daughter cells both endowed with stem cell properties. Asymmetric division, on the other hand, produces only one stem cell and a progenitor cell with limited self-renewal potential. Progenitors can go through several rounds of cell division before terminally differentiating into a mature cell. It is possible that the molecular distinction between symmetric and asymmetric divisions lies in differential segregation of cell membrane proteins (such as receptors) between the daughter cells.\nAn alternative theory is that stem cells remain undifferentiated due to environmental cues in their particular niche. Stem cells differentiate when they leave that niche or no longer receive those signals. Studies in \"Drosophila\" germarium have identified the signals decapentaplegic and adherens junctions that prevent germarium stem cells from differentiating.\nIn the United States, Executive Order 13505 established that federal money can be used for research in which approved human embryonic stem-cell (hESC) lines are used, but it cannot be used to derive new lines. The National Institutes of Health (NIH) Guidelines on Human Stem Cell Research, effective July 7, 2009, implemented the Executive Order 13505 by establishing criteria which hESC lines must meet to be approved for funding. The NIH Human Embryonic Stem Cell Registry can be accessed online and has updated information on cell lines eligible for NIH funding. There are 486 approved lines as of January 2022.\nTherapies.\nStem cell therapy is the use of stem cells to treat or prevent a disease or condition. Bone marrow transplant is a form of stem cell therapy that has been used for many years because it has proven to be effective in clinical trials. Stem cell implantation may help in strengthening the left-ventricle of the heart, as well as retaining the heart tissue to patients who have suffered from heart attacks in the past.\nFor over 50 years, hematopoietic stem cell transplantation (HSCT) has been used to treat people with conditions such as leukaemia and lymphoma; this is the only widely practiced form of stem-cell therapy. As of 2016[ [update]], the only established therapy using stem cells is hematopoietic stem cell transplantation. This usually takes the form of a bone-marrow transplantation, but the cells can also be derived from umbilical cord blood. Research is underway to develop various sources for stem cells as well as to apply stem-cell treatments for neurodegenerative diseases&gt; and conditions such as diabetes and heart disease.\nAdvantages.\nStem cell treatments may lower symptoms of the disease or condition that is being treated. The lowering of symptoms may allow patients to reduce the drug intake of the disease or condition. Stem cell treatment may also provide knowledge for society to further stem cell understanding and future treatments. The physicians' creed would be to do no injury, and stem cells make that simpler than ever before. Surgical processes by their character are harmful. Tissue has to be dropped as a way to reach a successful outcome. One may prevent the dangers of surgical interventions using stem cells. Additionally, there's a possibility of disease, and whether the procedure fails, further surgery may be required. Risks associated with anesthesia can also be eliminated with stem cells. On top of that, stem cells have been harvested from the patient's body and redeployed in which they're wanted. Since they come from the patient's own body, this is referred to as an autologous treatment. Autologous remedies are thought to be the safest because there's likely zero probability of donor substance rejection.\nDisadvantages.\nStem cell treatments may require immunosuppression because of a requirement for radiation before the transplant to remove the person's previous cells, or because the patient's immune system may target the stem cells. One approach to avoid the second possibility is to use stem cells from the same patient who is being treated.\nPluripotency in certain stem cells could also make it difficult to obtain a specific cell type. It is also difficult to obtain the exact cell type needed, because not all cells in a population differentiate uniformly. Undifferentiated cells can create tissues other than desired types.\nSome stem cells form tumors after transplantation; pluripotency is linked to tumor formation especially in embryonic stem cells, fetal proper stem cells, induced pluripotent stem cells. Fetal proper stem cells form tumors despite multipotency.\nEthical concerns are also raised about the practice of using or researching embryonic stem cells. Harvesting cells from the blastocyst results in the death of the blastocyst. The concern is whether or not the blastocyst should be considered as a human life. The debate on this issue is mainly a philosophical one, not a scientific one.\nStem cell tourism.\nStem cell tourism is the part of the medical tourism industry in which patients travel to obtain stem cell procedures.\nThe United States has had an explosion of \"stem cell clinics\". Stem cell procedures are highly profitable for clinics. The advertising sounds authoritative but the efficacy and safety of the procedures is unproven. Patients sometimes experience complications, such as spinal tumors and death. The high expense can also lead to financial problems. According to researchers, there is a need to educate the public, patients, and doctors about this issue.\nAccording to the International Society for Stem Cell Research, the largest academic organization that advocates for stem cell research, stem cell therapies are under development and cannot yet be said to be proven. Doctors should inform patients that clinical trials continue to investigate whether these therapies are safe and effective but that unethical clinics present them as proven.\nResearch.\nSome of the fundamental patents covering human embryonic stem cells are owned by the Wisconsin Alumni Research Foundation (WARF) \u2013 they are patents 5,843,780, 6,200,806, and 7,029,913 invented by James A. Thomson. WARF does not enforce these patents against academic scientists, but does enforce them against companies.\nIn 2006, a request for the US Patent and Trademark Office (USPTO) to re-examine the three patents was filed by the Public Patent Foundation on behalf of its client, the non-profit patent-watchdog group Consumer Watchdog (formerly the Foundation for Taxpayer and Consumer Rights). In the re-examination process, which involves several rounds of discussion between the USPTO and the parties, the USPTO initially agreed with Consumer Watchdog and rejected all the claims in all three patents, however in response, WARF amended the claims of all three patents to make them more narrow, and in 2008 the USPTO found the amended claims in all three patents to be patentable. The decision on one of the patents (7,029,913) was appealable, while the decisions on the other two were not. Consumer Watchdog appealed the granting of the '913 patent to the USPTO's Board of Patent Appeals and Interferences (BPAI) which granted the appeal, and in 2010 the BPAI decided that the amended claims of the '913 patent were not patentable. However, WARF was able to re-open prosecution of the case and did so, amending the claims of the '913 patent again to make them more narrow, and in January 2013 the amended claims were allowed.\nIn July 2013, Consumer Watchdog announced that it would appeal the decision to allow the claims of the '913 patent to the US Court of Appeals for the Federal Circuit (CAFC), the federal appeals court that hears patent cases. At a hearing in December 2013, the CAFC raised the question of whether Consumer Watchdog had legal standing to appeal; the case could not proceed until that issue was resolved.\nConditions.\nDiseases and conditions where stem cell treatment is being investigated include:\nProduction.\nResearch is underway to develop various sources for stem cells.\nOrganoids.\nResearch is attempting to generating organoids using stem cells, which would allow for further understanding of human development, organogenesis, and modeling of human diseases. Engineered 'synthetic organizer' (SO) cells can instruct stem cells to grow into specific tissues and organs. The program used native and synthetic cell adhesion protein molecules (CAMs) that help make cells sticky. The organizer cells self-assembled around mouse ESCs. These cells were engineered to produce morphogens (signaling molecules) that direct cellular development based on their concentration. Delivered morphogens disperse, leaving higher concentrations closer to the source and lower concentrations further away. These gradients signal cells' ultimate roles, such as nerve, skin cell, or connective tissue. The engineered organizer cells were also fitted with a chemical switch that enabled the researchers to turn the delivery of cellular instructions on and off, as well as a 'suicide switch' for eliminating the cells when needed. SOs carry spatial and biochemical information, allowing considerable discretion in organoid formation.\nRisks.\nHepatotoxicity and drug-induced liver injury account for a substantial number of failures of new drugs in development and market withdrawal, highlighting the need for screening assays such as stem cell-derived hepatocyte-like cells, that are capable of detecting toxicity early in the drug development process.\nDormancy.\nIn August 2021, researchers in the Princess Margaret Cancer Centre at the University Health Network published their discovery of a dormancy mechanism in key stem cells which could help develop cancer treatments in the future.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27784", "revid": "50550083", "url": "https://en.wikipedia.org/wiki?curid=27784", "title": "Sappho", "text": "Ancient Greek lyric poet (c. 630\u2013c. 570 BC)\nSappho ( \"Sapph\u1e53\" ; Aeolic Greek \"Ps\u00e1pph\u014d\"; c.\u2009630) was an Ancient Greek poet from Eresos or Mytilene on the island of Lesbos. Sappho is known for her lyric poetry, written to be sung while accompanied by music. In ancient times, Sappho was widely regarded as one of the greatest lyric poets and was given names such as the \"Tenth Muse\" and \"The Poetess\". Most of Sappho's poetry is now lost, and what is not has mostly survived in fragmentary form; only the Ode to Aphrodite is certainly complete. As well as lyric poetry, ancient commentators claimed that Sappho wrote elegiac and iambic poetry. Three epigrams formerly attributed to Sappho have survived, but these are actually Hellenistic imitations of Sappho's style.\nLittle is known of Sappho's life. She was from a wealthy family from Lesbos, though her parents' names are uncertain. Ancient sources say that she had three brothers: Charaxos, Larichos and Eurygios. Two of them, Charaxos and Larichos, are mentioned in the Brothers Poem discovered in 2014. She also appears to have had a daughter, traditionally identified with Cle\u00efs, who is mentioned in two of Sappho's fragments, 98 and 132. Sappho was exiled to Sicily around 600BC, and may have continued to work until around 570BC. According to legend, she killed herself by leaping from the Leucadian cliffs due to her unrequited love for the ferryman Phaon.\nSappho was a prolific poet, probably composing around 10,000 lines. She was best-known in antiquity for her love poetry; other themes in the surviving fragments of her work include family and religion. She probably wrote poetry for both individual and choral performance. Most of her best-known and best-preserved fragments explore personal emotions and were probably composed for solo performance. Her works are known for their clarity of language, vivid images, and immediacy. The context in which she composed her poems has long been the subject of scholarly debate; the most influential suggestions have been that she had some sort of educational or religious role, or wrote for the symposium.\nSappho's poetry was well-known and greatly admired through much of antiquity, and she was among the canon of Nine Lyric Poets most highly esteemed by scholars of Hellenistic Alexandria. Sappho's poetry is still considered extraordinary and her works continue to influence other writers. Beyond her poetry, she is well known as a symbol of love and desire between women, with the English words \"sapphic\" and \"lesbian\" deriving from her name and that of her home island, respectively.\nAncient sources.\nModern knowledge of Sappho comes both from what can be inferred from her own poetry and from mentions of her in other ancient texts. Her poetry \u2013 which, with the exception of a single complete poem, survives only in fragments \u2013 is the only contemporary source for her life. The earliest surviving biography of Sappho dates to the late second or early third centuryAD, approximately eight centuries after her own lifetime; the next is the \"Suda\", a tenth-century Byzantine encyclopedia. Other sources that mention details of her life were written much closer to her own era, beginning in the fifth centuryBC; one of the earliest is Herodotus' account of the relationship between the Egyptian courtesan Rhodopis and Sappho's brother Charaxos. The information about her life recorded in ancient sources was derived from statements in her own poetry that ancient authors assumed were autobiographical, along with local traditions. Some of the ancient traditions about her, such as those about her sexuality and appearance, may derive from ancient Athenian comedy.\nUntil the 19th century, ancient biographical accounts of archaic poets' lives were largely accepted as factual. In the 19th century, classicists began to be more sceptical of these traditions, and instead tried to derive biographical information from the poets' own works. In the latter half of the 20th century, scholars became increasingly sceptical of Greek lyric poetry as a source of autobiographical information, questioning whether the first person narrator in the poems was meant to express the experiences and feelings of the poets. Some scholars, such as Mary Lefkowitz, argue that almost nothing can be known about the lives of early Greek poets such as Sappho; most scholars believe that ancient testimonies about poets' lives contain some truth but must be treated with caution.\nLife.\nLittle is known about Sappho's life for certain. She was from the island of Lesbos and lived at the end of the seventh and beginning of the sixth centuriesBC. This is the date given by most ancient sources, who considered her a contemporary of the poet Alcaeus and the tyrant Pittacus, both also from Lesbos. She therefore may have been born in the third quarter of the seventh century \u2013 Franco Ferrari infers a date of around 650 or 640BC; David Campbell suggests around or before 630BC. Gregory Hutchinson suggests she was active until around 570BC.\nTradition names Sappho's mother as Cle\u00efs. This may derive from a now-lost poem or record, though ancient scholars may simply have guessed this name, assuming that Sappho's daughter was named Cle\u00efs after her mother. Ancient sources record ten different names for Sappho's father; this proliferation of possible names suggests that he was not explicitly named in any of her poetry. The earliest and most commonly attested name for him is Scamandronymus. In Ovid's \"Heroides\", Sappho's father died when she was six. He is not mentioned in any of her surviving works, but Campbell suggests that this detail may have been based on a now-lost poem. Her own name is found in numerous variant spellings; the form that appears in her own extant poetry is ().\nSappho was said to have three brothers: Eurygios, Larichos, and Charaxos. According to Athenaeus, she praised Larichos for being a cupbearer in the town hall of Mytilene, an office held by boys of the best families. This indication that Sappho was born into an aristocratic family is consistent with the sometimes-rarefied environments that her verses record. One ancient tradition tells of a relationship between Charaxos and the Egyptian courtesan Rhodopis. In the fifth century BC Herodotus, the oldest source of the story, reports that Charaxos ransomed Rhodopis for a large sum and that Sappho wrote a poem rebuking him for this. The names of two of the brothers, Charaxos and Larichos, are mentioned in the Brothers Poem, discovered in 2014; the final brother, Eurygios, is mentioned in three ancient sources but nowhere in the extant works of Sappho.\nSappho may have had a daughter named Cle\u00efs, who is referred to in two fragments. Not all scholars accept that Cle\u00efs was Sappho's daughter. Fragment 132 describes Cle\u00efs as \"\", which, as well as meaning \"child\", can also refer to the \"youthful beloved in a male homosexual liaison\". It has been suggested that Cle\u00efs was one of her younger lovers, rather than her daughter, though Judith Hallett argues that the description of Cleis as \"\" (\"beloved\") in fragment 132 suggests that Sappho was referring to Cle\u00efs as her daughter, as in other Greek literature the word is used for familial but not sexual relationships.\nAccording to the \"Suda\", Sappho was married to Kerkylas of Andros. This name appears to have been invented by a comic poet: the name appears to be a diminutive of the word , a possible meaning of which is \"penis\", and which is not otherwise attested as a name, while \"Andros\", as well as being the name of a Greek island, is a form of the Greek word , which means \"man\". Thus the name, for which an English equivalent could be \"Prick (of the isle) of Man\", is likely to have originated from a comic play.\nOne tradition said that Sappho was exiled from Lesbos around 600BC. The only ancient source for this story is the Parian Chronicle, which records her going into exile in Sicily some time between 604 and 595. This may have been as a result of her family's involvement with the conflicts between political elites on Lesbos in this period. It is unknown which side Sappho's family took in these conflicts, but most scholars believe that they were in the same faction as her contemporary Alcaeus, who was exiled when Myrsilus took power.\nA tradition going back at least to Menander (Fr. 258 K) suggested that Sappho killed herself by jumping off the Leucadian cliffs due to her unrequited love of Phaon, a ferryman. This story is related to two myths about the goddess Aphrodite. In one, Aphrodite rewarded the elderly ferryman Phaon with youth and good looks as a reward for taking her in his ferry without asking for payment; in the other, Aphrodite was cured of her grief at the death of her lover Adonis by throwing herself off the Leucadian cliffs on the advice of Apollo. The story of Sappho's leap is regarded as ahistorical by modern scholars, perhaps invented by the comic poets or originating from a misreading of a first-person reference in a non-biographical poem. It was used to reassure ancient audiences of Sappho's heterosexuality, and became particularly important in the nineteenth century to writers who saw homosexuality as immoral and wished to construct Sappho as heterosexual.\nWorks.\nSappho probably wrote around 10,000 lines of poetry; today, only about 650 survive. She is best known for her lyric poetry, written to be accompanied by music. The \"Suda\" also attributes to her epigrams, elegiacs, and iambics; three of these epigrams are extant, but are in fact later Hellenistic poems inspired by Sappho. The iambic and elegiac poems attributed to her in the \"Suda\" may also be later imitations. Ancient authors claim that she primarily wrote love poetry, and the indirect transmission of her work supports this notion. However, the papyrus tradition suggests that this may not have been the case: a series of papyri published in 2014 contains fragments of ten consecutive poems from an ancient edition of Sappho, of which only two are certainly love poems, while at least three and possibly four are primarily concerned with family.\nAncient editions.\nIt is uncertain when Sappho's poetry was first written down. Some scholars believe that she wrote her own poetry down for future readers; others that if she wrote her works down it was as an aid to reperformance rather than as a work of literature in its own right. In the fifth centuryBC, Athenian book publishers probably began to produce copies of Lesbian lyric poetry, some including explanatory material and glosses as well as the poems themselves. Some time in the second or third centuryBC, Alexandrian scholars produced a critical edition of her poetry. There may have been more than one Alexandrian edition \u2013 John J. Winkler argues for two, one edited by Aristophanes of Byzantium and another by his pupil Aristarchus of Samothrace. This is not certain \u2013 ancient sources tell us that Aristarchus' edition of Alcaeus replaced the edition by Aristophanes, but are silent on whether Sappho's work also went through multiple editions.\nThe Alexandrian edition of Sappho's poetry may have been based on an Athenian text of her poems, or one from her native Lesbos, and was divided into at least eight books, though the exact number is uncertain. Many modern scholars have followed Denys Page, who conjectured a ninth book in the standard edition; Dimitrios Yatromanolakis doubts this, noting that though ancient sources refer to an eighth book of her poetry, none mention a ninth. The Alexandrian edition of Sappho probably grouped her poems by their metre: ancient sources tell us that each of the first three books contained poems in a single specific metre. Book one of the Alexandrian edition, made up of poems in Sapphic stanzas, seems to have been ordered alphabetically.\nEven after the publication of the standard Alexandrian edition, Sappho's poetry continued to circulate in other poetry collections. For instance, the Cologne Papyrus on which the Tithonus poem is preserved was part of a Hellenistic anthology of poetry, which contained poetry arranged by theme, rather than by metre and incipit, as it was in the Alexandrian edition.\nSurviving poetry.\nThe earliest surviving manuscripts of Sappho, including the potsherd on which fragment 2 is preserved, date to the third centuryBC, and thus might predate the Alexandrian edition. The latest surviving copies of her poems transmitted directly from ancient times are written on parchment codex pages from the sixth and seventh centuriesAD, and were surely reproduced from ancient papyri now lost. Manuscript copies of her works may have survived a few centuries longer, but around the ninth century her poetry appears to have disappeared, and by the 12th century, John Tzetzes could write that \"the passage of time has destroyed Sappho and her works\".\nAccording to legend, Sappho's poetry was lost because the church disapproved of her morals. These legends appear to have originated in the Renaissance \u2013 around 1550, Jerome Cardan wrote that Gregory Nazianzen had her work publicly destroyed, and at the end of the 16th century Joseph Justus Scaliger claimed that her works were burned in Rome and Constantinople in 1073 on the orders of Pope Gregory VII.\nIn reality, Sappho's work was probably lost as the demand for it was insufficiently great for it to be copied onto parchment when codices superseded papyrus scrolls as the predominant form of book. A contributing factor to the loss of her poems may have been her Aeolic dialect, considered provincial in a period where the Attic dialect was seen as the true classical Greek, and had become the standard for literary compositions. Consequently, many readers found her dialect difficult to understand: in the second centuryAD, the Roman author Apuleius specifically remarks on its \"strangeness\", and several commentaries on the subject demonstrate the difficulties that readers had with it. This was part of a more general decline in interest in the archaic poets; indeed, the surviving papyri suggest that Sappho's poetry survived longer than that of her contemporaries such as Alcaeus.\nOnly approximately 650 lines of Sappho's poetry still survive, of which just one poem \u2013 the Ode to Aphrodite \u2013 is complete, and more than half of the original lines survive in around ten more fragments. Many of the surviving fragments of Sappho contain only a single word \u2013 for example, fragment 169A is simply a word meaning \"wedding gifts\" (, ), and survives as part of a dictionary of rare words. The two major sources of surviving fragments of Sappho are quotations in other ancient works, from a whole poem to as little as a single word, and fragments of papyrus, many of which were rediscovered at Oxyrhynchus in Egypt. Other fragments survive on other materials, including parchment and potsherds. The oldest surviving fragment of Sappho currently known is the Cologne papyrus that contains the Tithonus poem, dating to the third centuryBC.\nUntil the last quarter of the 19th century, Sappho's poetry was known only through quotations in the works of other ancient authors. In 1879, the first new discovery of a fragment of Sappho was made at Fayum. By the end of the 19th century, Bernard Pyne Grenfell and Arthur Surridge Hunt had begun to excavate an ancient rubbish dump at Oxyrhynchus, leading to the discoveries of many previously unknown fragments of Sappho. Fragments of Sappho continue to be rediscovered. Major discoveries were made in 2004 (the \"Tithonus poem\" and a new, previously unknown fragment) and 2014 (fragments of nine poems: five already known but with new readings, four, including the \"Brothers Poem\", not previously known). Additionally, in 2005 a commentary on her poems on a papyrus from the second or third century AD was published.\nStyle.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n &lt;poem&gt;\nHe seems like a god to me the man who is near you,\nListening to your sweet voice and exquisite laughter\nThat makes my heart so wildly beat in my breast.\nIf I but see you for a moment, then all my words\nLeave me, my tongue is broken and a sudden fire\nCreeps through my blood. No longer can I see.\nMy ears are full of noise. In all my body I\nShudder and sweat. I am pale as the sun-scorched\nGrass. In my fury I seem like a dead woman,\nBut I would dare...&lt;/poem&gt;\u2014 Sappho 31, trans. Edward Storer\nSappho worked within a well-developed tradition of poetry from Lesbos, which had evolved its own poetic diction, metres, and conventions. Prior to Sappho and her contemporary Alcaeus, Lesbos was associated with poetry and music through the mythical Orpheus and Arion, and through the seventh-centuryBC poet Terpander. The Aeolic metrical tradition in which she composed her poetry was distinct from that of the rest of Greece as its lines always contained a fixed number of syllables \u2013 in contrast to other traditions that allowed for the substitution of two short syllables for one long or vice versa.\nSappho was one of the first Greek poets to adopt the \"lyric 'I'\" \u2013 to write poetry adopting the viewpoint of a specific person, in contrast to the earlier poets Homer and Hesiod, who present themselves more as \"conduits of divine inspiration\". Her poetry explores individual identity and personal emotions \u2013 desire, jealousy, and love; it also adopts and reinterprets the existing imagery of epic poetry in exploring these themes. Much of her poetry focuses on the lives and experiences of women. Along with the love poetry for which she is best known, her surviving works include poetry focused on the family, epic-influenced narrative, wedding songs, cult hymns, and invective.\nWith the exception of a few songs, where the performance context can be deduced from the surviving fragments with some degree of confidence, scholars disagree on how and where Sappho's works were performed. They seem to have been composed for a variety of occasions both public and private, and probably encompassed both solo and choral works. Most of her best-preserved fragments, such as the Ode to Aphrodite, are usually thought to be written for solo performance \u2013 though some scholars, such as Andr\u00e9 Lardinois, believe that most or all of her poems were originally composed for choral performances. These works, which Leslie Kurke describes as \"private and informal compositions\" in contrast to the public ritual nature of cultic hymns and wedding songs, tend to avoid giving details of a specific chronological, geographical, or occasional setting, which Kurke suggests facilitated their reperformance by performers outside Sappho's original context.\nSappho's poetry is known for its clear language and simple thoughts, sharply-drawn images, and use of direct quotation that brings a sense of immediacy. Unexpected word-play is a characteristic feature of her style. An example is from fragment 96: \"now she stands out among Lydian women as after sunset the rose-fingered moon exceeds all stars\", a variation of the Homeric epithet \"rosy-fingered Dawn\". Her poetry often uses hyperbole, according to ancient critics \"because of its charm\": for example, in fragment 111 she writes that \"The groom approaches like Ares [...] Much bigger than a big man\".\nKurke groups Sappho with those archaic Greek poets from what has been called the \"\u00e9lite\" ideological tradition, which valued luxury () and high birth. These elite poets tended to identify themselves with the worlds of Greek myths, gods, and heroes, as well as the wealthy East, especially Lydia. Thus in fragment 2 she has Aphrodite \"pour into golden cups nectar lavishly mingled with joys\", while in the Tithonus poem she explicitly states that \"I love the finer things []\". According to Page duBois, the language, as well as the content, of Sappho's poetry evokes an aristocratic sphere. She contrasts Sappho's \"flowery,[...] adorned\" style with the \"austere, decorous, restrained\" style embodied in the works of later classical authors such as Sophocles, Demosthenes, and Pindar.\nMusic.\nSappho's poetry was written to be sung, but its musical content is largely uncertain. \nAs it is unlikely that any system of musical notation existed in Ancient Greece before the fifth century, the original music that accompanied her songs probably did not survive until the classical period, and no ancient musical scores to accompany her poetry survive. Sappho reportedly wrote in the mixolydian mode, which was considered sorrowful; it was commonly used in Greek tragedy, and Aristoxenus believed that the tragedians learned it from Sappho. Aristoxenus attributed to Sappho the invention of this mode, but this is unlikely. While there are no attestations that she used other modes, she presumably varied them depending on the poem's character. When originally sung, each syllable of her text likely corresponded to one note as the use of lengthy melismata developed in the later classical period.\nSappho wrote both songs for solo and choral performance. With Alcaeus, she pioneered a new style of sung monody (single-line melody) that departed from the multi-part choral style that largely defined earlier Greek music. This style afforded her more opportunities to individualize the content of her poems; the historian Plutarch noted that she \"speaks words mingled truly with fire, and through her songs, she draws up the heat of her heart\". Some scholars theorize that the Tithonus poem was among her works meant for a solo singer. Only fragments of Sappho's choral works are extant; of these, her epithalamia (wedding songs) survive better than her cultic hymns. The later compositions were probably meant for antiphonal performance between either a male and female choir or a soloist and choir.\nIn Sappho's time, sung poetry was usually accompanied by musical instruments, which usually doubled the voice in unison or played homophonically an octave higher or lower. Her poems mention numerous instruments, including the pektis, a harp of Lydian origin, and lyre. Sappho is most closely associated with the barbitos, a lyre-like string instrument that was deep in pitch. Euphorion of Chalcis reports that she referred to it in her poetry, and a fifth-century red-figure vase by either the Dokimasia Painter or Brygos Painter includes Sappho and Alcaeus with barbitoi. Sappho mentions the aulos, a wind instrument with two pipes, in fragment 44 as accompanying the song of the Trojan women at Hector and Andromache's wedding, but not as accompanying her own poetry. Later Greek commentators wrongly believed that she had invented the plectrum.\nSocial context.\nOne of the major focuses of scholars studying Sappho has been to attempt to determine the cultural context in which Sappho's poems were composed and performed. Various cultural contexts and social roles played by Sappho have been suggested: primarily teacher, priestess, chorus leader, and symposiast. However, the performance contexts of many of Sappho's fragments are not easy to determine, and for many more than one possible context is conceivable.\nOne longstanding suggestion of a social role for Sappho is that of \"Sappho as schoolmistress\". This view, popular in the nineteenth and early twentieth centuries, was advocated by the German classicist Ulrich von Wilamowitz-Moellendorff, to \"explain away Sappho's passion for her 'girls'\" and defend her from accusations of homosexuality. More recently the idea has been criticised by historians as anachronistic and has been rejected by several prominent classicists as unjustified by the evidence. In 1959, Denys Page, for example, stated that Sappho's extant fragments portray \"the loves and jealousies, the pleasures and pains, of Sappho and her companions\"; and he adds, \"We have found, and shall find, no trace of any formal or official or professional relationship between them... no trace of Sappho the principal of an academy.\" Campbell in 1967 judged that Sappho may have \"presided over a literary coterie\", but that \"evidence for a formal appointment as priestess or teacher is hard to find\". None of Sappho's own poetry mentions her teaching, and the earliest source to support the idea of Sappho as a teacher comes from Ovid, six centuries after Sappho's lifetime.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n &lt;poem&gt;So you hate me now, Atthis, and\nTurn towards Andromeda.&lt;/poem&gt;\u2014 Sappho 131, trans. Edward Storer\nIn the second half of the twentieth century, scholars began to interpret Sappho as involved in the ritual education of girls, for instance as a trainer of choruses of girls. Though not all of her poems can be interpreted in this light, Lardinois argues that this is the most plausible social context to site Sappho in. Another interpretation which became popular in the twentieth century was of Sappho as a priestess of Aphrodite. However, though Sappho wrote hymns, including some dedicated to Aphrodite, there is no evidence that she held a priesthood. More recent scholars have proposed that Sappho was part of a circle of women who took part in symposia, for which she composed and performed poetry, or that she wrote her poetry to be performed at men's symposia. Though her songs were certainly later performed at symposia, there is no external evidence for archaic Greek women's symposia, and even if some of her works were composed for a sympotic context, it is doubtful that the cultic hymns or poems about family would have been.\nDespite scholars' best attempts to find one, Yatromanolakis argues that there is no single performance context to which all of Sappho's poems can be attributed. Camillo Neri argues that it is unnecessary to assign all of her poetry to one context, and suggests that she could have composed poetry both in a pedogogic role and as part of a circle of friends.\nSexuality.\nThe word \"lesbian\" is an allusion to Sappho, originating from the name of the island of Lesbos, where she was born. However, though in modern culture Sappho is seen as a lesbian, she has not always been considered so. In classical Athenian comedy (from the Old Comedy of the fifth century to Menander in the late fourth and early third centuriesBC), Sappho was caricatured as a promiscuous heterosexual woman, and the earliest surviving sources to explicitly discuss Sappho's homoeroticism come from the Hellenistic period. The earliest of these is a fragmentary biography written on papyrus in the late third or early second centuryBC, which states that Sappho was \"accused by some of being irregular in her ways and a woman-lover\". Denys Page comments that the phrase \"by some\" implies that even the full corpus of Sappho's poetry did not provide conclusive evidence of whether she described herself as having sex with women. These ancient authors do not appear to have believed that Sappho did, in fact, have sexual relationships with other women, and as late as the 10th century the \"Suda\" records that Sappho was \"slanderously accused\" of having sexual relationships with her \"female pupils\".\nSappho wrote powerful love poems to women, which is why she is so strongly associated with same-sex love between women. The concept of a fixed sexual identity like \"lesbian\" did not exist in ancient Greece as it does today. However, Sappho's work and the context of her life have led many modern scholars and queer communities to view her as a gay or bisexual woman, and a foundational figure in LGBTQ+ history.\nAmong modern scholars, Sappho's sexuality is still debated: Andr\u00e9 Lardinois has described it as the \"Great Sappho Question\". Early translators of Sappho sometimes heterosexualised her poetry. Ambrose Philips' 1711 translation of the Ode to Aphrodite portrayed the object of Sappho's desire as male, a reading that was followed by virtually every other translator of the poem until the 20th century, while in 1781 Alessandro Verri interpreted fragment 31 as being about Sappho's love for Phaon. Friedrich Gottlieb Welcker argued that Sappho's feelings for other women were \"entirely idealistic and non-sensual\", while Karl Otfried M\u00fcller wrote that fragment 31 described \"nothing but a friendly affection\": Glenn Most comments that \"one wonders what language Sappho would have used to describe her feelings if they had been ones of sexual excitement\", if this theory were correct. By 1970, the psychoanalyst George Devereux argued that the same poem contained \"proof positive of [Sappho's] lesbianism\".\nToday, it is generally accepted that Sappho's poetry portrays homoerotic feelings: as Sandra Boehringer puts it, her works \"clearly celebrate eros between women\". Toward the end of the 20th century, though, some scholars began to reject the question of whether Sappho was a lesbian \u2013 Glenn Most wrote that Sappho herself \"would have had no idea what people mean when they call her nowadays a homosexual\", Andr\u00e9 Lardinois stated that it is \"nonsensical\" to ask whether Sappho was a lesbian, and Page duBois calls the question a \"particularly obfuscating debate\". Some scholars argue that although Sappho would not have understood modern conceptions of sexuality, lesbianism has always existed and she was fundamentally a lesbian. Others, influenced by Michel Foucault's work on the history of sexuality, believe that it is incoherent to project the concept of lesbianism onto an ancient figure like Sappho. Melissa Mueller argues that Sappho's poetry can be read as queer even if the question of her lesbianism is undecidable.\nLegacy.\nAncient reputation.\nIn antiquity, Sappho's poetry was highly admired, and several ancient sources refer to her as the \"tenth Muse\". The earliest surviving text to do so is a third-centuryBC epigram by Dioscorides, but poems are preserved in the \"Greek Anthology\" by Antipater of Sidon and attributed to Plato on the same theme. She was sometimes referred to as \"The Poetess\", just as Homer was \"The Poet\". The scholars of Alexandria included her in the canon of nine lyric poets. According to Aelian, the Athenian lawmaker and poet Solon asked to be taught a song by Sappho \"so that I may learn it and then die\". This story may well be apocryphal, especially as Ammianus Marcellinus tells a similar story about Socrates and a song of Stesichorus, but it is indicative of how highly Sappho's poetry was considered in the ancient world.\nSappho's poetry also influenced other ancient authors. Plato cites Sappho in his \"Phaedrus\", and Socrates' second speech on love in that dialogue appears to echo Sappho's descriptions of the physical effects of desire in fragment 31. Many Hellenistic poets alluded to or adapted Sappho's works. The Locrian poet Nossis was described by Marilyn B. Skinner as an imitator of Sappho, and Kathryn Gutzwiller argues that Nossis explicitly positioned herself as an inheritor of Sappho's position as a female poet. Several of Theocritus' poems allude to Sappho, including \"Idyll\" 28, which imitates both her language and meter. Poems such as Erinna's \"Distaff\" and Callimachus' \"Lock of Berenice\" are Sapphic in theme, being concerned with separation \u2013 Erinna from her childhood friend; the lock of Berenice's hair from Berenice herself.\nIn the first centuryBC, the Roman poet Catullus established the themes and metres of Sappho's poetry as a part of Latin literature, adopting the Sapphic stanza, believed in antiquity to have been invented by Sappho, giving his lover in his poetry the name \"Lesbia\" in reference to Sappho, and adapting and translating Sappho's 31st fragment in his poem 51. Fragment 31 is widely referenced in Latin literature: as well as by Catullus, it is alluded to by authors including Lucretius in the \"De rerum natura\", Plautus in \"Miles Gloriosus\", and Virgil in book 12 of the \"Aeneid\". Latin poets also referenced other fragments: the section on Eppia in Juvenal's sixth satire references fragment 16, a poem in Sapphic stanzas from Statius' \"Silvae\" may reference the Ode to Aphrodite, and Horace's \"Ode\" 3.27 alludes to fragment 94.\nOther ancient poets wrote about Sappho's life. She was a popular character in ancient Athenian comedy, and at least six separate comedies called \"Sappho\" are known. The earliest known ancient comedy to take Sappho as its main subject was the early-fifth or late-fourth centuryBC \"Sappho\" by Ameipsias, though nothing is known of it apart from its name. As these comedies survive only in fragments, it is uncertain exactly how they portrayed Sappho, but she was likely characterised as a promiscuous woman. In Diphilos' play, she was the lover of the poets Anacreon and Hipponax. Sappho was also a favourite subject in the visual arts. She was the most commonly depicted poet on sixth and fifth-century Attic red-figure vase paintings \u2013 though unlike male poets such as Anacreon and Alcaeus, in the four surviving vases in which she is identified by an inscription she is never shown singing. She was also shown on coins from Mytilene and Eresos from the first to third centuriesAD, and reportedly depicted in a sculpture by Silanion at Syracuse, statues in Pergamon and Constantinople, and a painting by the Hellenistic artist Leon.\nFrom the fourth centuryBC, ancient works portray Sappho as a tragic heroine, driven to suicide by her unrequited love for Phaon. A fragment of a play by Menander says that Sappho threw herself off of the cliff at Leucas out of her love for him. Ovid's \"Heroides\" 15 is written as a letter from Sappho to Phaon, and when it was first rediscovered in the 15th century was thought to be a translation of an authentic letter by Sappho. Sappho's suicide was also depicted in classical art, for instance on the first-centuryBC Porta Maggiore Basilica in Rome.\nWhile Sappho's poetry was admired in the ancient world, her character was not always so well considered. In the Roman period, critics found her lustful and perhaps even homosexual. Horace called her \"\" (\"masculine Sappho\") in his \"Epistles\", which the later Porphyrio commented was \"either because she is famous for her poetry, in which men more often excel, or because she is maligned for having been a tribad\". By the third centuryAD, the difference between Sappho's literary reputation as a poet and her moral reputation as a woman had become so significant that the suggestion that there were in fact two Sapphos began to develop. In his \"Historical Miscellanies\", Aelian wrote that there was \"another Sappho, a courtesan, not a poetess\".\nModern reception.\nBy the medieval period, Sappho's works had been lost, though she was still quoted in later authors. Her work became more accessible in the 16th century through printed editions of those authors who had quoted her. In 1508 Aldus Manutius printed an edition of Dionysius of Halicarnassus, which contained Sappho 1, the Ode to Aphrodite, and the first printed edition of Longinus' \"On the Sublime\", complete with his quotation of Sappho 31, appeared in 1554. In 1566, the French printer Robert Estienne produced an edition of the Greek lyric poets that contained around 40 fragments attributed to Sappho.\nIn 1652, the first English translation of a poem by Sappho was published, in John Hall's translation of \"On the Sublime\". In 1681 Anne Le F\u00e8vre's French edition of Sappho made her work even more widely known. Theodor Bergk's 1854 edition became the standard edition of Sappho in the second half of the 19th century; in the first part of the 20th century, the papyrus discoveries of new poems by Sappho led to editions and translations by Edwin Marion Cox and John Maxwell Edmonds, and culminated in the 1955 publication of Edgar Lobel's and Denys Page's \"Poetarum Lesbiorum Fragmenta\".\nLike the ancients, modern critics have tended to consider Sappho's poetry \"extraordinary\". As early as the ninth century, Sappho was referred to as a talented female poet, and in works such as Boccaccio's \"De Claris Mulieribus\" and Christine de Pisan's \"Book of the City of Ladies\" she gained a reputation as a learned lady. Even after Sappho's works had been lost, the Sapphic stanza continued to be used in medieval lyric poetry, and with the rediscovery of her work in the Renaissance, she began to increasingly influence European poetry. In the 16th century, members of La Pl\u00e9iade, a circle of French poets, were influenced by her to experiment with Sapphic stanzas and with writing love-poetry with a first-person female voice.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n&lt;poem&gt; Thy soul\nGrown delicate with satieties,\nAtthis.\n O Atthis,\nI long for thy lips.\nI long for thy narrow breasts,\nThou restless, ungathered.&lt;/poem&gt; \u2014 Ezra Pound, \"\u1f30\u03bc\u03ad\u03c1\u03c1\u03c9\": adaptation of Sappho 96\nFrom the Romantic era, Sappho's work \u2013 especially her Ode to Aphrodite \u2013 has been a key influence of conceptions of what lyric poetry should be. Poets such as Alfred Lord Tennyson in the 19th century, and A. E. Housman in the 20th century, have been influenced by her poetry. Tennyson based poems including \"Eleanore\" and \"Fatima\" on Sappho's fragment 31, while three of Housman's works are adaptations of the Midnight Poem, long thought to be by Sappho though the authorship is now disputed. At the beginning of the 20th century, the Imagists \u2013 especially Ezra Pound, H. D., and Richard Aldington \u2013 were influenced by Sappho's fragments; a number of Pound's poems in his early collection \"Lustra\" were adaptations of Sapphic poems, while H. D.'s poetry frequently echoed Sappho stylistically and thematically, and in some cases, such as \"Fragment 40\", more specifically invoke Sappho's writing.\nWestern classical composers have also been inspired by Sappho. The story of Sappho and Phaon began to appear in opera in the late 18th century, for example in Simon Mayr's \"Saffo\"; in the 19th century Charles Gounod's \"Sapho\" and Giovanni Pacini's \"Saffo\" portrayed a Sappho involved in political revolts. In the 20th century, Peggy Glanville-Hicks' opera \"Sappho\" was based on the play by Lawrence Durrell. Instrumental works inspired by Sappho include \"Chant sapphique\" by Camille Saint-Sa\u00ebns, and the percussion piece \"Psappha\" by Iannis Xenakis. Composers have also set Sappho's own poetry to music: for example Xenakis' \"A\u00efs\", which uses text from fragment 95, and \"Charaxos, Eos and Tithonos\" (2014) by Theodore Antoniou, based on the 2014 discoveries.\nIt was not long after the rediscovery of Sappho that her sexuality once again became the focus of critical attention. In the early 17th century, John Donne wrote \"Sapho to Philaenis\", returning to the idea of Sappho as a hypersexual lover of women. The modern debate on Sappho's sexuality began in the 19th century, with Welcker publishing, in 1816, an article defending Sappho from charges of prostitution and lesbianism, arguing that she was chaste \u2013 a position that was later taken up by Wilamowitz at the end of the 19th and Henry Thornton Wharton at the beginning of the 20th centuries. In the 19th century Sappho was co-opted by Charles Baudelaire in France and later Algernon Charles Swinburne in England for the Decadent Movement. The critic Douglas Bush characterised Swinburne's sadomasochistic Sappho as \"one of the daughters of de Sade\", the French author known for his violent pornographic books. By the late 19th century, lesbian writers such as Michael Field and Amy Levy became interested in Sappho for her sexuality, and by the turn of the 20th century she was considered a \"patron saint of lesbians\".\nFrom the beginning of the 19th century, women poets such as Felicia Hemans (\"The Last Song of Sappho\") and Letitia Elizabeth Landon (\"Sketch the First. Sappho\", and in \"Ideal Likenesses\") took Sappho as one of their progenitors. Sappho also began to be regarded as a role model for campaigners for women's rights, beginning with works such as Caroline Norton's \"The Picture of Sappho\". Later in that century, she became a model for the so-called New Woman \u2013 independent and educated women who desired social and sexual autonomy \u2013 and by the 1960s, the feminist Sappho was \u2013 along with the hypersexual, often but not exclusively lesbian Sappho \u2013 one of the two most important cultural perceptions of her.\nThe discoveries of new poems by Sappho in 2004 and 2014 excited both scholarly and media attention. The announcement of the Tithonus poem was the subject of international news coverage, and was described by Marilyn Skinner as \"the \"trouvaille\" of a lifetime\". The publication of the Brothers Poem a decade later saw further news coverage and discussion on social media, while M. L. West described the 2014 discoveries as \"the greatest for 92 years\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27786", "revid": "48978265", "url": "https://en.wikipedia.org/wiki?curid=27786", "title": "Simon bar Kokhba", "text": "Leader of the Bar Kokhba revolt (132\u2013136 CE)\nSimon bar Kokhba ( ) or Simon bar Koseba ( ), commonly referred to simply as Bar Kokhba, was a Jewish military leader in Judea. He lent his name to the Bar Kokhba revolt, which he initiated against the Roman Empire in 132 CE. Though they were ultimately unsuccessful, Bar Kokhba and his rebels did manage to establish and maintain a Jewish state for about three years after beginning the rebellion. Bar Kokhba served as the state's leader, crowning himself as \"nasi\" (lit.\u2009'prince'). Some of the rabbinic scholars in his time believed him to be the long-expected Messiah. In 135, Bar Kokhba was killed by Roman troops in the fortified town of Betar. The Judean rebels who remained after his death were all killed or enslaved within the next year, and their defeat was followed by a harsh crackdown on the Judean populace by the Roman emperor Hadrian.\nName.\nDocumented name.\nDocuments discovered in the 20th century in the Cave of Letters give his original name, with variations: Simeon bar Kosevah (&lt;templatestyles src=\"Script/styles_hebrew.css\" /&gt;\u05e9\u05de\u05e2\u05d5\u05df \u05d1\u05e8 \u05db\u05d5\u05e1\u05d1\u05d4\u200e), Bar Koseva\u02be\u200e (&lt;templatestyles src=\"Script/styles_hebrew.css\" /&gt;\u05d1\u05e8 \u05db\u05d5\u05e1\u05d1\u05d0\u200e) or Ben Koseva\u02be\u200e (&lt;templatestyles src=\"Script/styles_hebrew.css\" /&gt;\u05d1\u05df \u05db\u05d5\u05e1\u05d1\u05d0\u200e). It is probable that his original name was Bar Koseba. The name may indicate that his father or his place of origin was named Koseva(h), with Khirbet Kuwayzibah being a likely nominee for identification; Others, namely Emil Sch\u00fcrer, think the surname may have been an indication of his place of birth, in the village known as Chozeba (maybe Chezib) but might as well be a general family name.\nNicknames.\nDuring the revolt, the Jewish sage Rabbi Akiva regarded Simon as the Jewish messiah. The Jerusalem Talmud (Taannit 4:5) records his statement that the Star Prophecy verse from Numbers 24:17, \"There shall come a star out of Jacob,\" referred to him. This was based on identification of the Hebrew word for star, \"kokhav\", and his name, \"bar Kozeva.\" The name Bar Kokhba, which references this statement of Akiva, does not appear in the Talmud, but only in ecclesiastical sources, until the 16th century. The Jerusalem Talmud (\"Taanit\" 4:5) and the Babylonian Talmud (\"Sanhedrin\" 93b and 97b) mention him by the name of Bar Kozeva.\nRevolt leader.\nBackground.\nDespite the devastation wrought by the Romans during the First Jewish\u2013Roman War (66\u201373 CE), which left the population and countryside in ruins, a series of laws passed by Roman Emperors provided the incentive for the second rebellion. Based on the delineation of years in Eusebius' \"Chronicon\" (whose Latin translation is known as the Chronicle of Jerome) the Jewish revolt began under the Roman governor Tineius (Tynius) Rufus in the 16th year of Hadrian's reign, or what was equivalent to the 4th year of the 227th Olympiad. Hadrian sent an army to crush the resistance, but it faced a strong opponent, since Bar Kokhba, as the recognised leader of Israel, punished any Jew who refused to join his ranks. Two and a half years later, after the war had ended, the Roman emperor Hadrian barred Jews from entering Aelia Capitolina, the pagan city he had built on the ruins of Jewish Jerusalem. The name Aelia was derived from one of the emperor's names, Aelius. According to Philostorgius, this was done so that its former Jewish inhabitants \"might not find in the name of the city a pretext for claiming it as their country.\"\nOverview.\nFor many Jews of the time, this turn of events was heralded as the long-hoped-for Messianic Age. The Romans fared very poorly during the initial revolt facing a unified Jewish force, in contrast to the First Jewish\u2013Roman War, where Flavius Josephus records three separate Jewish armies fighting each other for control of the Temple Mount during the three weeks after the Romans had breached Jerusalem's walls and were fighting their way to the center. Being outnumbered and taking heavy casualties, the Romans adopted a scorched earth policy which reduced and demoralised the Judean populace, slowly grinding away at the will of the Judeans to sustain the war.\nDuring the final phase of the war, Bar Kokhba took up refuge in the fortress of Betar. The Romans eventually captured it after laying siege to the city.\nThe Jerusalem Talmud makes several claims considered as non-historical by modern scholarship. One such claim is that the duration of the siege was of three and half years, although the war itself lasted, according to the same author, two and half years. Another part of the Talmudic narrative is that the Romans killed all the defenders except for one Jewish youth, Simeon ben Gamliel II, whose life was spared. According to Cassius Dio, 580,000 Jews were killed in overall war operations across the country, and some 50 fortified towns and 985 villages razed to the ground, while the number of those who perished by famine, disease and fire was beyond finding out.\nOutcome and aftermath.\nSo costly was the Roman victory, that the Emperor Hadrian, when reporting to the Roman Senate, did not see fit to begin with the customary greeting \"If you and your children are healthy, it is well; I and the legions are healthy.\"\nIn the aftermath of the war, Hadrian consolidated the older political units of Judaea, Galilee and Samaria into the new province of Syria Palaestina, which is commonly interpreted as an attempt to complete the disassociation with Judaea.\nArchaeological findings.\nIn the late 20th and 21st century, new information about the revolt came to light from the discovery of several collections of letters, some possibly by Bar Kokhba himself, in the Cave of Letters overlooking the Dead Sea. These letters can now be seen at the Israel Museum.\nIn March 2024, a coin bearing the inscription \"Eleazar the Priest\" was found along with \"Year 1 of the Redemption of Israel\" on the bottom.\nIdeology and language.\nAccording to Israeli archaeologist Yigael Yadin, Bar Kokhba tried to revive Hebrew and make Hebrew the official language of the Jews as part of his messianic ideology. In \"A Roadmap to the Heavens: An Anthropological Study of Hegemony among Priests, Sages, and Laymen (Judaism and Jewish Life)\" by Sigalit Ben-Zion (page 155), Yadin remarked: \"it seems that this change came as a result of the order that was given by Bar Kokhba, who wanted to revive the Hebrew language and make it the official language of the state.\"\nCharacter.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"From Shim\u02bbon ben Cosibah to Yeshu\u02bba ben Galgulah and to the men of the Gader, Peace. I call heaven to my witness that I am fed-up with the Galileans that be with you, every man! [And] that I am resolved to put fetters on your feet, just as I did to Ben \u02bbAflul.\"(Original Hebrew) &lt;templatestyles src=\"Script/styles_hebrew.css\" /&gt;\u05de\u05e9\u05de\u05e2\u05d5\u05df \u05d1\u05df \u05db\u05d5\u05e1\u05d1\u05d4 \u05dc\u05d9\u05e9\u05e2 \u05d1\u05df \u05d2[\u05dc]\u05d2\u05dc\u05d4 \u05d5\u05dc\u05d0\u05e0\u05e9\u05d9 \u05d4\u05db\u05e8\u05da \u05e9\u05dc\u05d5[\u05dd]. \u05de\u05e2\u05d9\u05d3 \u05d0\u05e0\u05d9 \u05e2\u05dc\u05d9 \u05ea \u05e9\u05de\u05d9\u05dd \u05d9\u05e4\u05e1[\u05d3] \u05de\u05df \u05d4\u05d2\u05dc\u05dc\u05d0\u05d9\u05dd \u05e9\u05d4\u05e6\u05dc\u05db\u05dd \u05db\u05dc \u05d0\u05d3\u05dd \u05e9\u05d0\u05e0\u05d9 \u05e0\u05ea\u05df \u05ea\u05db\u05d1\u05dc\u05d9\u05dd \u05d1\u05e8\u05d2\u05dc\u05db\u05dd \u05db\u05de\u05d4 \u05e9\u05e2\u05e1\u05ea[\u05d9] \u05dc\u05d1\u05df \u05e2\u05e4\u05dc\u05d5\u05dc [\u05e9]\u05de\u05e2\u05d5\u05df \u05d1[\u05df]\u200e\nTalmud.\nSimon bar Kokhba is portrayed in rabbinic literature as being somewhat irrational and irascible in conduct. The Talmud says that he presided over an army of Jewish insurgents numbering some 200,000, but had compelled its young recruits to prove their valor by each man chopping off one of his own fingers. The Sages of Israel complained to him why he marred the people of Israel with such blemishes. Whenever he would go forth into battle, he was reported as saying: \"O Master of the universe, there is no need for you to assist us [against our enemies], but do not embarrass us either!\" It is also said of him that he killed his maternal uncle, Rabbi Elazar Hamuda\u02bbi, after suspecting him of collaborating with the enemy, thereby forfeiting Divine protection, which led to the destruction of Betar in which Bar Kokhba himself also perished.\nHadrian is thought to have personally supervised the closing military operations in the siege against Betar. When the Roman army eventually took the city, soldiers carried Bar Kokhba's severed head to Hadrian, and when Hadrian asked who it was that killed him, a Samaritan replied that he had killed him. When Hadrian requested that they bring the severed head (Greek: \"protome\") of the slain victim close to him that he might see it, Hadrian observed that a serpent was wrapped around the head. Hadrian then replied: \"Had it not been for God who killed him, who would have been able to kill him!?\"\nEusebius.\nAccording to Eusebius' \"Chronicon\", he severely punished the Christians with death by different means of torture for their refusal to fight against the Romans.\nIn popular culture.\nSince the end of the nineteenth century, Bar-Kochba has been the subject of numerous works of art (dramas, operas, novels, etc.), including:\nAnother operetta on the subject of Bar Kokhba was written by the Russian-Jewish emigre composer Yaacov Bilansky Levanon in Palestine in the 1920s.\nJohn Zorn's Masada Chamber Ensemble recorded an album called \"Bar Kokhba\", showing a photograph of the Letter of Bar Kokhba to Yeshua, son of Galgola on the cover.\nThe Bar Kokhba game.\nAccording to a legend, during his reign, Bar Kokhba was once presented a mutilated man, who had his tongue ripped out and hands cut off. Unable to talk or write, the victim was incapable of telling who his attackers were. Thus, Bar Kokhba decided to ask simple questions to which the dying man was able to nod or shake his head with his last movements; the murderers were consequently apprehended.\nIn Hungary, this legend spawned the \"Bar Kokhba game\", in which one of two players comes up with a word or object, while the other must figure it out by asking questions only to be answered with \"yes\" or \"no\". The questioner usually asks first if it is a living being, if not, if it is an object, if not, it is surely an abstraction. The verb \"kibarkochb\u00e1zni\" (\"to Bar Kochba out\") became a common language verb meaning \"retrieving information in an extremely tedious way\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27790", "revid": "50860679", "url": "https://en.wikipedia.org/wiki?curid=27790", "title": "Schizophrenia", "text": "Mental disorder with psychotic symptoms\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nSchizophrenia is a mental disorder characterized variously by hallucinations (typically, hearing voices), delusions, disorganized thinking or behavior, and flat or inappropriate affect. Symptoms develop gradually and typically begin during young adulthood and rarely resolve. There is no objective diagnostic test; diagnosis is based on observed behavior, a psychiatric history that includes the person's reported experiences, and reports of others familiar with the person. For a formal diagnosis, the described symptoms need to have been present for at least six months (according to the DSM-5) or one month (according to the ICD-11). Many people with schizophrenia have other mental disorders, especially mood, anxiety, and substance use disorders, as well as obsessive\u2013compulsive disorder (OCD).\nAbout 0.3% to 0.7% of people are diagnosed with schizophrenia during their lifetime. In 2017, there were an estimated 1.1\u00a0million new cases and in 2022 a total of 24 million cases globally. Males are more often affected and on average have an earlier onset than females. The causes of schizophrenia may include genetic and environmental factors. Genetic factors include a variety of common and rare genetic variants. Possible environmental factors include being raised in a city, childhood adversity, cannabis use during adolescence, infections, the age of a person's mother or father, and poor nutrition during pregnancy.\nAbout half of those diagnosed with schizophrenia will experience a marked improvement over the long term with no further relapses, and a small proportion of these will recover completely. The other half will have a lifelong impairment. In severe cases, people may be admitted to hospitals. Social problems such as long-term unemployment, poverty, homelessness, exploitation, and victimization are commonly correlated with schizophrenia. Compared to the general population, people with schizophrenia have a higher suicide rate (about 5% overall) and more physical health problems, leading to an average decrease in life expectancy by 20 to 28 years. In 2015, an estimated 17,000 deaths were linked to schizophrenia.\nThe mainstay of treatment is antipsychotic medication, including olanzapine and risperidone, along with counseling, job training, and social rehabilitation. Up to a third of people do not respond to initial antipsychotics, in which case clozapine is offered. A network meta-analysis of 15 antipsychotic drugs found that all were more effective than placebo for schizophrenia, with clozapine showing the highest efficacy; side effect profiles differ substantially across drugs. In situations where doctors judge that there is a risk of harm to self or others, they may impose short involuntary hospitalization. Long-term hospitalization is used on a small number of people with severe schizophrenia. In some countries where supportive services are limited or unavailable, long-term hospital stays are more common.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nSigns and symptoms.\nSchizophrenia is a mental disorder characterized by significant alterations in perception, thoughts, mood, and behavior. Symptoms are described in terms of positive, negative, and cognitive symptoms. The positive symptoms of schizophrenia are the same for any psychosis and are sometimes referred to as psychotic symptoms. These may be present in any of the different psychoses and are often transient, making early diagnosis of schizophrenia problematic. Psychosis noted for the first time in a person who is later diagnosed with schizophrenia is referred to as a first-episode psychosis (FEP).\nPositive symptoms.\nPositive symptoms are those symptoms that are not normally experienced, but are present in people during a psychotic episode in schizophrenia, including delusions, hallucinations, and disorganized thoughts, speech and behavior or inappropriate affect, typically regarded as manifestations of psychosis. Hallucinations occur at some point in the lifetimes of 80% of those with schizophrenia and most commonly involve the sense of hearing (most often hearing voices), but can sometimes involve any of the other senses such as taste, sight, smell, and touch. The frequency of hallucinations involving multiple senses is double the rate of those involving only one sense. They are also typically related to the content of the delusional theme. Delusions are bizarre or persecutory in nature. Distortions of self-experience such as feeling that others can hear one's thoughts (thought broadcasting delusion) or that thoughts are being inserted into one's mind, sometimes termed passivity phenomena, are also common. The type and content of auditory and visual hallucinations appears to be influenced, at least in part, by cultural and religious factors. Patients in the United Kingdom and United States are more likely to report hearing criticisms and commands; patients in Africa, Asia, and the Middle East report more religious messaging in their hallucinations. This is true even among transplants to these countries, suggesting these differences are cultural, and not genetic. Positive symptoms generally respond well to medication and become reduced over the course of the illness, perhaps linked to the age-related decline in dopamine activity.\nNegative symptoms.\nNegative symptoms are deficits of normal emotional responses, or of other thought processes. The five recognized domains of negative symptoms are: blunted affect \u2013 showing flat expressions (monotone) or little emotion; alogia \u2013 a poverty of speech; anhedonia \u2013 an inability to feel pleasure; asociality \u2013 the lack of desire to form relationships, and avolition \u2013 a lack of motivation and apathy. Avolition and anhedonia are seen as motivational deficits resulting from impaired reward processing. Reward is the main driver of motivation and this is mostly mediated by dopamine. It has been suggested that negative symptoms are multidimensional and they have been categorised into two subdomains of apathy or lack of motivation, and diminished expression. Apathy includes avolition, anhedonia, and social withdrawal; diminished expression includes blunt affect and alogia. Sometimes diminished expression is treated as both verbal and non-verbal.\nApathy accounts for around 50% of the most often found negative symptoms and affects functional outcome and subsequent quality of life. Apathy is related to disrupted cognitive processing affecting memory and planning, including goal-directed behaviour. The two subdomains have suggested a need for separate treatment approaches. A lack of distress is another noted negative symptom. A distinction is often made between those negative symptoms that are inherent to schizophrenia, termed primary; and those that result from positive symptoms, from the side effects of antipsychotics, substance use disorder, and social deprivation, termed secondary negative symptoms. Negative symptoms are less responsive to medication and the most difficult to treat. However, if properly assessed, secondary negative symptoms are amenable to treatment. There is some evidence that the negative symptoms of schizophrenia are amenable to psychostimulant medication, although such drugs have varying degrees of risk for causing positive psychotic symptoms.\nScales for specifically assessing the presence of negative symptoms, and for measuring their severity, and their changes have been introduced since the earlier scales such as the PANNS that deals with all types of symptoms. These scales are the \"Clinical Assessment Interview for Negative Symptoms\" (CAINS), and the \"Brief Negative Symptom Scale\" (BNSS) also known as second-generation scales. In 2020, ten years after its introduction, a cross-cultural study of the use of BNSS found valid and reliable psychometric evidence for its five-domain structure cross-culturally. The BNSS can assess both the presence and severity of negative symptoms of the five recognized domains and an additional item of reduced normal distress. It has been used to measure changes in negative symptoms in trials of psychosocial and pharmacological interventions.\nCognitive symptoms.\nAn estimated 70% of those with schizophrenia have cognitive deficits, and these are most pronounced in early-onset and late-onset illness. These are often evident long before the onset of illness in the prodromal stage, and may be present in childhood or early adolescence. They are a core feature but not considered to be core symptoms, as are positive and negative symptoms. However, their presence and degree of dysfunction is taken as a better indicator of functionality than the presentation of core symptoms. Cognitive deficits become worse at first episode psychosis but then return to baseline, and remain fairly stable over the course of the illness.\nCognitive deficits may be of neurocognition (nonsocial) or of social cognition. Neurocognition is the ability to receive and remember information, and includes verbal fluency, memory, reasoning, problem solving, speed of processing, and auditory and visual perception. Verbal memory and attention are seen to be the most affected. Verbal memory impairment is associated with a decreased level of semantic processing (relating meaning to words). Another memory impairment is that of episodic memory. An impairment in visual perception that is consistently found in schizophrenia is that of visual backward masking. Visual processing impairments include an inability to perceive complex visual illusions. Social cognition is concerned with the mental operations needed to interpret, and understand the self and others in the social world. This is also an associated impairment, and facial emotion perception (FEP) is often found to be difficult. Cognitive impairments do not usually respond to antipsychotics, and there are a number of interventions that are used to try to improve them; cognitive remediation therapy is of particular help.\nNeurological soft signs of clumsiness and loss of fine motor movement are often found in schizophrenia, which may resolve with effective treatment of FEP.\nOnset.\nOnset typically occurs between the late teens and early 30s, with the peak incidence occurring in males in the early to mid-twenties, and in females in the late twenties. Onset before the age of 17 is known as early-onset, and before the age of 13, as can sometimes occur, is known as childhood schizophrenia or very early-onset. Onset can occur between the ages of 40 and 60, known as late-onset schizophrenia. Onset over the age of 60, which may be difficult to differentiate as schizophrenia, is known as very-late-onset schizophrenia-like psychosis. Late onset has shown that a higher rate of females are affected; they have less severe symptoms and need lower doses of antipsychotics. The tendency for earlier onset in males is later seen to be balanced by a post-menopausal increase in the development in females. Estrogen produced pre-menopause has a dampening effect on dopamine receptors but its protection can be overridden by a genetic overload. There has been a dramatic increase in the numbers of older adults with schizophrenia.\nOnset may happen suddenly or may occur after the slow and gradual development of a number of signs and symptoms, a period known as the prodromal stage. Up to 75% of those with schizophrenia go through a prodromal stage. The negative and cognitive symptoms in the prodrome stage can precede FEP (first episode psychosis) by many months and up to five years. The period from FEP and treatment is known as the duration of untreated psychosis (DUP) which is seen to be a factor in functional outcome. The prodromal stage is the high-risk stage for the development of psychosis. Since the progression to first episode psychosis is not inevitable, an alternative term is often preferred of at risk mental state. Cognitive dysfunction at an early age impacts a young person's usual cognitive development. Recognition and early intervention at the prodromal stage would minimize the associated disruption to educational and social development and has been the focus of many studies.\nRisk factors.\nSchizophrenia is described as a neurodevelopmental disorder with no precise boundary, or single cause, and is thought to develop from gene\u2013environment interactions with involved vulnerability factors. The interactions of these risk factors are complex, as numerous and diverse insults from conception to adulthood can be involved. A genetic predisposition on its own, without interacting environmental factors, will not give rise to the development of schizophrenia. The genetic component means that prenatal brain development is disturbed, and environmental influence affects the postnatal development of the brain. Evidence suggests that genetically susceptible children are more likely to be vulnerable to the effects of environmental risk factors.\nGenetic.\nEstimates of the heritability of schizophrenia are between 70% and 80%, which implies that 70% to 80% of the individual differences in risk of schizophrenia are associated with genetics. These estimates vary because of the difficulty in separating genetic and environmental influences, and their accuracy has been queried. The greatest risk factor for developing schizophrenia is having a first-degree relative with the disease (risk is 6.5%); more than 40% of identical twins of those with schizophrenia are also affected. If one parent is affected the risk is about 13% and if both are affected the risk is nearly 50%. However, the \"DSM-5\" indicates that most people with schizophrenia have no family history of psychosis. Results of candidate gene studies of schizophrenia have generally failed to find consistent associations, and the genetic loci identified by genome-wide association studies explain only a small fraction of the variation in the disease.\nMany genes are known to be involved in schizophrenia, each with small effects and unknown transmission and expression. The summation of these effect sizes into a polygenic risk score can explain at least 7% of the variability in liability for schizophrenia. Around 5% of cases of schizophrenia are understood to be at least partially attributable to rare copy number variations (CNVs); these structural variations are associated with known genomic disorders involving deletions at 22q11.2 (DiGeorge syndrome) and 17q12 (17q12 microdeletion syndrome), duplications at 16p11.2 (most frequently found) and deletions at 15q11.2 (Burnside\u2013Butler syndrome). Some of these CNVs increase the risk of developing schizophrenia by as much as 20-fold, and are frequently comorbid with autism and intellectual disabilities.\nThe genes CRHR1 and CRHBP are associated with the severity of suicidal behavior. These genes code for stress response proteins needed in the control of the HPA axis, and their interaction can affect this axis. Response to stress can cause lasting changes in the function of the HPA axis possibly disrupting the negative feedback mechanism, homeostasis, and the regulation of emotion leading to altered behaviors.\nThe question of how schizophrenia could be primarily genetically influenced, given that people with schizophrenia have lower fertility rates, is a paradox. It is expected that genetic variants that increase the risk of schizophrenia would be selected against, due to their negative effects on reproductive fitness. A number of potential explanations have been proposed, including that alleles associated with schizophrenia risk confers a fitness advantage in unaffected individuals. While some evidence has not supported this idea, others propose that a large number of alleles each contributing a small amount can persist.\nA meta-analysis found that oxidative DNA damage was significantly increased in schizophrenia.\nEnvironmental.\nEnvironmental factors, each associated with a slight risk of developing schizophrenia in later life include oxygen deprivation, infection, prenatal maternal stress, and malnutrition in the mother during prenatal development. A risk is associated with maternal obesity, in increasing oxidative stress, and dysregulating the dopamine and serotonin pathways. Both maternal stress and infection have been demonstrated to alter fetal neurodevelopment through an increase of pro-inflammatory cytokines. There is a slighter risk associated with being born in the winter or spring possibly due to vitamin D deficiency or a prenatal viral infection. Other infections during pregnancy or around the time of birth that have been linked to an increased risk include infections by \"Toxoplasma gondii\" and \"Chlamydia\". The increased risk is about five to eight percent. Viral infections of the brain during childhood are also linked to a risk of schizophrenia during adulthood. Cat exposure is also associated with an increased risk of broadly defined schizophrenia-related disorders, with an odds ratio of 2.4. Exposure to specific medications such as tramadol and desmopressin has been found be associated with an increased risk of incident schizophrenia, while other medications including anti-protozoans were associated with a decrease in schizophrenia risk. \nAdverse childhood experiences (ACEs), severe forms of which are classed as childhood trauma, range from being bullied or abused, to the death of a parent. Many adverse childhood experiences can cause toxic stress and increase the risk of psychosis. Chronic trauma, including ACEs, can promote lasting inflammatory dysregulation throughout the nervous system. It is suggested that early stress may contribute to the development of schizophrenia through these alterations in the immune system. Schizophrenia was the last diagnosis to benefit from the link made between ACEs and adult mental health outcomes.\nLiving in an urban environment during childhood or as an adult has consistently been found to increase the risk of schizophrenia by a factor of two, even after taking into account drug use, ethnic group, and size of social group. A possible link between the urban environment and pollution has been suggested to be the cause of the elevated risk of schizophrenia. Other risk factors include social isolation, immigration related to social adversity and racial discrimination, family dysfunction, unemployment, and poor housing conditions. Having a father older than 40 years, or parents younger than 20 years are also associated with schizophrenia.\nSubstance use.\nAbout half of those with schizophrenia use recreational drugs including alcohol, tobacco, and cannabis excessively. Use of stimulants such as amphetamine and cocaine can lead to a temporary stimulant psychosis, which presents very similarly to schizophrenia. Rarely, alcohol use can also result in a similar alcohol-related psychosis. Drugs may also be used as coping mechanisms by people who have schizophrenia, to deal with depression, anxiety, boredom, and loneliness. The use of cannabis and tobacco are not associated with the development of cognitive deficits, and sometimes a reverse relationship is found where their use improves these symptoms. However, substance use disorders are associated with an increased risk of suicide, and a poor response to treatment.\nCannabis use may be a contributory factor in the development of schizophrenia, potentially increasing the risk of the disease in those who are already at risk. The increased risk may require the presence of certain genes within an individual. Its use is associated with doubling the rate.\nCauses.\nThe causes of schizophrenia are still unknown. Several models have been put forward to explain the link between altered brain function and schizophrenia. The prevailing model of schizophrenia is that of a neurodevelopmental disorder, and the underlying changes that occur before symptoms become evident are seen as arising from the interaction between genes and the environment. Extensive studies support this model. Maternal infections, malnutrition and complications during pregnancy and childbirth are known risk factors for the development of schizophrenia, which usually emerges between the ages of 18 and 25, a period that overlaps with certain stages of neurodevelopment. Gene-environment interactions lead to deficits in the neural circuitry that affect sensory and cognitive functions.\nThe common dopamine and glutamate models proposed are not mutually exclusive; each is seen to have a role in the neurobiology of schizophrenia. The most common model put forward was the dopamine hypothesis of schizophrenia, which attributes psychosis to the mind's faulty interpretation of the misfiring of dopaminergic neurons. This has been directly related to the symptoms of delusions and hallucinations. Abnormal dopamine signaling has been implicated in schizophrenia based on the usefulness of medications that affect the dopamine receptor and the observation that dopamine levels are increased during acute psychosis. A decrease in D1 receptors in the dorsolateral prefrontal cortex may also be responsible for deficits in working memory.\nThe glutamate hypothesis of schizophrenia links alterations between glutamatergic neurotransmission and the neural oscillations that affect connections between the thalamus and the cortex. Studies have shown that a reduced expression of a glutamate receptor \u2013 NMDA receptor, and glutamate blocking drugs such as phencyclidine and ketamine can mimic the symptoms and cognitive problems associated with schizophrenia. Post-mortem studies consistently find that a subset of these neurons fail to express GAD67 (GAD1), in addition to abnormalities in brain morphometry. The subsets of interneurons that are abnormal in schizophrenia are responsible for the synchronizing of neural ensembles needed during working memory tasks. These give the neural oscillations produced as gamma waves that have a frequency of between 30 and 80 hertz. Both working memory tasks and gamma waves are impaired in schizophrenia, which may reflect abnormal interneuron functionality. An important process that may be disrupted in neurodevelopment is astrogenesis \u2013 the formation of astrocytes. Astrocytes are crucial in contributing to the formation and maintenance of neural circuits and it is believed that disruption in this role can result in a number of neurodevelopmental disorders including schizophrenia. Evidence suggests that reduced numbers of astrocytes in deeper cortical layers are assocociated with a diminished expression of EAAT2, a glutamate transporter in astrocytes; supporting the glutamate hypothesis.\nDeficits in executive functions, such as planning, inhibition, and working memory, are pervasive in schizophrenia. Although these functions are separable, their dysfunction in schizophrenia may reflect an underlying deficit in the ability to represent goal related information in working memory, and to use this to direct cognition and behavior. These impairments have been linked to a number of neuroimaging and neuropathological abnormalities. For example, functional neuroimaging studies report evidence of reduced neural processing efficiency, whereby the dorsolateral prefrontal cortex is activated to a greater degree to achieve a certain level of performance relative to controls on working memory tasks. These abnormalities may be linked to the consistent post-mortem finding of reduced neuropil, evidenced by increased pyramidal cell density and reduced dendritic spine density. These cellular and functional abnormalities may also be reflected in structural neuroimaging studies that find reduced grey matter volume in association with deficits in working memory tasks.\nPositive symptoms have been linked to cortical thinning in the superior temporal gyrus. The severity of negative symptoms has been linked to reduced thickness in the left medial orbitofrontal cortex. Anhedonia, traditionally defined as a reduced capacity to experience pleasure, is frequently reported in schizophrenia. However, a large body of evidence suggests that hedonic responses are intact in schizophrenia, and that what is reported to be anhedonia is a reflection of dysfunction in other processes related to reward. Overall, a failure of reward prediction is thought to lead to impairment in the generation of cognition and behavior required to obtain rewards, despite normal hedonic responses.\nAnother theory links abnormal brain lateralization to the development of being left-handed which is significantly more common in those with schizophrenia. This abnormal development of hemispheric asymmetry is noted in schizophrenia. Studies have concluded that the link is a true and verifiable effect that may reflect a genetic link between lateralization and schizophrenia.\nBayesian models of brain functioning have been used to link abnormalities in cellular functioning to symptoms. Both hallucinations and delusions have been suggested to reflect improper encoding of prior expectations, thereby causing expectation to excessively influence sensory perception and the formation of beliefs. In approved models of circuits that mediate predictive coding, reduced NMDA receptor activation, could in theory result in the positive symptoms of delusions and hallucinations.\nFrom an evolutionary perspective, schizophrenia is regarded as an \u201cevolutionary puzzle\u201d because it shows high heritability (~60-80 %) and significant impairment in reproduction, yet persists at ~1 % prevalence. One hypothesis suggests that mild schizotypal traits may have historically conferred advantages (such as enhanced creativity or verbal ability,) while more severe forms represent the breakdown of these systems. Experimental models also propose that selection for language and social-cognitive complexity may have increased vulnerability to psychosis when environmental or developmental stressors intervene.\nDiagnosis.\nCriteria.\nSchizophrenia is diagnosed based on criteria in either the \"Diagnostic and Statistical Manual of Mental Disorders\" (DSM) published by the American Psychiatric Association or the International Statistical Classification of Diseases and Related Health Problems (ICD) published by the World Health Organization (WHO). These criteria use the self-reported experiences of the person and reported abnormalities in behavior, followed by a psychiatric assessment. The mental status examination is an important part of the assessment. An established tool for assessing the severity of positive and negative symptoms is the Positive and Negative Syndrome Scale (PANSS). This has been seen to have shortcomings relating to negative symptoms, and other scales \u2013 the \"Clinical Assessment Interview for Negative Symptoms\" (CAINS), and the \"Brief Negative Symptoms Scale\" (BNSS) have been introduced. The DSM-5, published in 2013, gives a \"Scale to Assess the Severity of Symptom Dimensions\" outlining eight dimensions of symptoms.\nDSM-5 states that to be diagnosed with schizophrenia, two diagnostic criteria have to be met over the period of one month, with a significant impact on social or occupational functioning for at least six months. One of the symptoms needs to be either delusions, hallucinations, or disorganized speech. A second symptom could be one of the negative symptoms, or severely disorganized or catatonic behaviour. A different diagnosis of schizophreniform disorder can be made before the six months needed for the diagnosis of schizophrenia.\nIn Australia, the guideline for diagnosis is for six months or more with symptoms severe enough to affect ordinary functioning. In the UK diagnosis is based on having the symptoms for most of the time for one month, with symptoms that significantly affect the ability to work, study, or carry on ordinary daily living, and with other similar conditions ruled out.\nThe ICD criteria are typically used in European countries; the DSM criteria are used predominantly in the United States and Canada, and are prevailing in research studies. In practice, agreement between the two systems is high. The current proposal for the ICD-11 criteria for schizophrenia recommends adding self-disorder as a symptom.\nA major unresolved difference between the two diagnostic systems is that of the requirement in DSM of an impaired functional outcome. WHO for ICD argues that not all people with schizophrenia have functional deficits and so these are not specific for the diagnosis.\nNeuroimaging techniques.\nFunctional magnetic resonance imaging (fMRI) has become a tool in understanding brain activity and connectivity differences in individuals with schizophrenia. Through resting-state fMRI, researchers have observed altered connectivity patterns within several key brain networks, such as the default mode network (DMN), salience network (SN), and central executive network (CEN). Alterations may underlie cognitive and emotional symptoms in schizophrenia, such as disorganized thinking, impaired attention, and emotional dysregulation.\nComorbidities.\nMany people with schizophrenia may have one or more other mental disorders, such as anxiety disorders, obsessive\u2013compulsive disorder, or substance use disorder. These are separate disorders that require treatment. When comorbid with schizophrenia, substance use disorder and antisocial personality disorder both increase the risk for violence. Comorbid substance use disorder also increases the risk of suicide.\nSleep disorders often co-occur with schizophrenia, and may be an early sign of relapse. Sleep disorders are linked with positive symptoms such as disorganized thinking and can adversely affect cortical plasticity and cognition. The consolidation of memories is disrupted in sleep disorders. They are associated with severity of illness, a poor prognosis, and poor quality of life. Sleep onset and maintenance insomnia is a common symptom, regardless of whether treatment has been received or not. Genetic variations have been found associated with these conditions involving the circadian rhythm, dopamine and histamine metabolism, and signal transduction.\nSchizophrenia is also associated with a number of somatic comorbidities including diabetes mellitus type 2, autoimmune diseases, and cardiovascular diseases. The association of these with schizophrenia may be partially due to medications (e.g. dyslipidemia from antipsychotics), environmental factors (e.g. complications from an increased rate of cigarette smoking), or associated with the disorder itself (e.g. diabetes mellitus type 2 and some cardiovascular diseases are thought to be genetically linked). These somatic comorbidities contribute to reduced life expectancy among persons with the disorder.\nDifferential diagnosis.\nTo make a diagnosis of schizophrenia other possible causes of psychosis need to be excluded.858 Psychotic symptoms lasting less than a month may be diagnosed as brief psychotic disorder, or as schizophreniform disorder. Psychosis is noted in \"Other specified schizophrenia spectrum and other psychotic disorders\" as a DSM-5 category. Schizoaffective disorder is diagnosed if symptoms of mood disorder are substantially present alongside psychotic symptoms. Psychosis that results from a general medical condition or substance is termed secondary psychosis.\nPsychotic symptoms may be present in several other conditions, including bipolar disorder, borderline personality disorder, substance intoxication, substance-induced psychosis, and a number of drug withdrawal syndromes. Non-bizarre delusions are also present in delusional disorder, and social withdrawal in social anxiety disorder, avoidant personality disorder and schizotypal personality disorder. Schizotypal personality disorder has symptoms that are similar but less severe than those of schizophrenia. Schizophrenia occurs along with obsessive\u2013compulsive disorder (OCD) considerably more often than could be explained by chance, although it can be difficult to distinguish obsessions that occur in OCD from the delusions of schizophrenia. There can be considerable overlap with the symptoms of post-traumatic stress disorder.\nA more general medical and neurological examination may be needed to rule out medical illnesses which may rarely produce psychotic schizophrenia-like symptoms, such as metabolic disturbance, systemic infection, syphilis, HIV-associated neurocognitive disorder, epilepsy, limbic encephalitis, and brain lesions. Stroke, multiple sclerosis, hyperthyroidism, hypothyroidism, and dementias such as Alzheimer's disease, Huntington's disease, frontotemporal dementia, and the Lewy body dementias may also be associated with schizophrenia-like psychotic symptoms. It may be necessary to rule out a delirium, which can be distinguished by visual hallucinations, acute onset and fluctuating level of consciousness, and indicates an underlying medical illness. Investigations are not generally repeated for relapse unless there is a specific \"medical\" indication or possible adverse effects from antipsychotic medication. In children hallucinations must be separated from typical childhood fantasies. It is difficult to distinguish childhood schizophrenia from autism.\nPrevention.\nPrevention of schizophrenia is difficult as there are no reliable markers for the later development of the disorder.\nEarly intervention programs diagnose and treat patients in the prodromal phase of the illness. There is some evidence that these programs reduce symptoms. Patients tend to prefer early treatment programs to ordinary treatment and are less likely to disengage from them. As of 2020, it is unclear whether the benefits of early treatment persist once the treatment is terminated.\nCognitive behavioral therapy may reduce the risk of psychosis in those at high risk after a year and is recommended in this group, by the National Institute for Health and Care Excellence (NICE). Another preventive measure is to avoid drugs that have been associated with development of the disorder, including cannabis, cocaine, and amphetamines.\nAntipsychotics are prescribed following a first-episode psychosis, and following remission, a preventive maintenance use is continued to avoid relapse. However, it is recognized that some people do recover following a single episode and that long-term use of antipsychotics will not be needed but there is no way of identifying this group.\nManagement.\nThe primary treatment of schizophrenia is the use of antipsychotic medications, often in combination with psychosocial interventions and social supports. Community support services including drop-in centers, visits by members of a community mental health team, supported employment, and support groups are common. The time between the onset of psychotic symptoms to being given treatment \u2013 the duration of untreated psychosis (DUP) \u2013 is associated with a poorer outcome in both the short term and the long term.\nVoluntary or involuntary admission to hospital may be imposed by doctors and courts who deem a person to be having a severe episode. In the UK, large mental hospitals termed asylums began to be closed down in the 1950s with the advent of antipsychotics, and with an awareness of the negative impact of long-term hospital stays on recovery. This process was known as deinstitutionalization, and community and supportive services were developed to support this change. Many other countries followed suit with the US starting in the 60s. There still remain a smaller group of people who do not improve enough to be discharged. In some countries that lack the necessary supportive and social services, long-term hospital stays are more usual.\nMedication.\nA Bayesian network meta-analysis of 212 randomized controlled trials including 43,049 participants found that all 15 antipsychotic drugs reviewed were more effective than placebo in the acute treatment of schizophrenia, with clozapine showing the greatest efficacy and amisulpride the lowest all-cause discontinuation. While differences in efficacy were modest, side-effect profiles varied widely, indicating that antipsychotic selection should be guided by individual patient needs rather than the traditional classification into first- and second-generation drugs.\nThe first-line treatment for schizophrenia is an antipsychotic. The first-generation antipsychotics, now called typical antipsychotics, like haloperidol, are dopamine antagonists that block D2 receptors, and affect the neurotransmission of dopamine. Those brought out later, the second-generation antipsychotics known as atypical antipsychotics, including olanzapine and risperidone, can also have an effect on another neurotransmitter, serotonin. Antipsychotics can reduce the symptoms of anxiety within hours of their use, but, for other symptoms, they may take several days or weeks to reach their full effect. They have little effect on negative and cognitive symptoms, which may be helped by additional psychotherapies and medications. There is no single antipsychotic suitable for first-line treatment for everyone, as responses and tolerances vary between people. Stopping medication may be considered after a single psychotic episode where there has been a full recovery with no symptoms for twelve months. Repeated relapses worsen the long-term outlook and the risk of relapse following a second episode is high, and long-term treatment is usually recommended.\nAbout half of those with schizophrenia will respond favourably to antipsychotics, and have a good return of functioning. However, positive symptoms persist in up to a third of people. Following two trials of different antipsychotics over six weeks, that also prove ineffective, they will be classed as having treatment-resistant schizophrenia (TRS), and clozapine will be offered. Clozapine is of benefit to around half of this group although it has the potentially serious side effect of agranulocytosis (lowered white blood cell count) in less than 4% of people.\nAbout 30 to 50 percent of people with schizophrenia do not accept that they have an illness or comply with their recommended treatment. For those who are unwilling or unable to take medication regularly, long-acting injections of antipsychotics may be used, which reduce the risk of relapse to a greater degree than oral medications. When used in combination with psychosocial interventions, they may improve long-term adherence to treatment.\nA 2025 meta-analysis showed xanomeline and trospium's effect in the improvement of symptoms of schizophrenia. The fixed-dose combination medication xanomeline/trospium chloride (Cobenfy) was approved for medical use in the United States in September 2024. It is the first cholinergic agonist approved by the US Food and Drug Administration (FDA) to treat schizophrenia.\nNegative and cognitive symptoms are an unmet clinical need in antipsychotic-based treatment approaches. Psychostimulant drugs have been found effective in the treatment of negative symptoms, but are rarely prescribed due to concerns about the excacerbation of positive symptoms. It is possible that low-dose psychedelic therapies could be of benefit in schizophrenia through their prosocial and procognitive effects, although there is a serious risk that high dose psychedelic therapies could lead to worsening of positive symptoms.\nAdverse effects.\nExtrapyramidal symptoms, including akathisia, are associated with all commercially available antipsychotic to varying degrees.566 There is little evidence that second generation antipsychotics have reduced levels of extrapyramidical symptoms compared to typical antipsychotics.566 Tardive dyskinesia can occur due to long-term use of antipsychotics, developing after months or years of use. The antipsychotic clozapine is also associated with thromboembolism (including pulmonary embolism), myocarditis, and cardiomyopathy.\nPsychosocial interventions.\nA number of psychosocial interventions that include several types of psychotherapy may be useful in the treatment of schizophrenia such as: family therapy, group therapy, cognitive remediation therapy (CRT), cognitive behavioral therapy (CBT), and metacognitive training. Skills training, help with substance use, and weight management \u2013 often needed as a side effect of an antipsychotic \u2013 are also offered. In the US, interventions for first episode psychosis have been brought together in an overall approach known as coordinated speciality care (CSC) and also includes support for education. In the UK \"care across all phases\" is a similar approach that covers many of the treatment guidelines recommended. The aim is to reduce the number of relapses and stays in the hospital.\nOther support services for education, employment, and housing are usually offered. For people with severe schizophrenia, who are discharged from a stay in the hospital, these services are often brought together in an integrated approach to offer support in the community away from the hospital setting. In addition to medicine management, housing, and finances, assistance is given for more routine matters such as help with shopping and using public transport. This approach is known as assertive community treatment (ACT) and has been shown to achieve positive results in symptoms, social functioning and quality of life. Another more intense approach is known as \"intensive care management\" (ICM). ICM is a stage further than ACT and emphasises support of high intensity in smaller caseloads, (less than twenty). This approach is to provide long-term care in the community. Studies show that ICM improves many of the relevant outcomes including social functioning.\nSome studies have shown little evidence for the effectiveness of CBT in either reducing symptoms or preventing relapse. However, other studies have found that CBT does improve overall psychotic symptoms (when in use with medication) and it has been recommended in Canada, but has been seen to have no effect on social function, relapse, or quality of life. In the UK it is recommended as an add-on therapy in the treatment of schizophrenia. Arts therapies are seen to improve negative symptoms in some people, and are recommended by NICE in the UK. This approach is criticised as having not been well-researched, and arts therapies are not recommended in Australian guidelines for example. Peer support, in which people with personal experience of schizophrenia, provide help to each other, is of unclear benefit.\nOther.\nExercise including aerobic exercise has been shown to improve positive and negative symptoms, cognition, working memory, and improve quality of life. Exercise has also been shown to increase the volume of the hippocampus in those with schizophrenia. A decrease in hippocampal volume is one of the factors linked to the development of the disease. However, there still remains the problem of increasing motivation for, and maintaining participation in physical activity. Supervised sessions are recommended. In the UK healthy eating advice is offered alongside exercise programs.\nAn inadequate diet is often found in schizophrenia, and associated vitamin deficiencies including those of folate, and vitamin D are linked to the risk factors for the development of schizophrenia and for early death including heart disease. Those with schizophrenia possibly have the worst diet of all the mental disorders. Lower levels of folate and vitamin D have been noted as significantly lower in first episode psychosis. The use of supplemental folate is recommended. A zinc deficiency has also been noted. Vitamin B12 is also often deficient and this is linked to worse symptoms. Supplementation with B vitamins has been shown to significantly improve symptoms, and to put in reverse some of the cognitive deficits. It is also suggested that the noted dysfunction in gut microbiota might benefit from the use of probiotics.\nPrognosis.\nSchizophrenia has great human and economic costs. It decreases life expectancy by between 10 and 28 years. This is primarily because of its association with heart disease, diabetes, obesity, poor diet, a sedentary lifestyle, and smoking, with an increased rate of suicide playing a lesser role. Side effects of antipsychotics may also increase the risk.\nAlmost 40% of those with schizophrenia die from complications of cardiovascular disease which is seen to be increasingly associated. An underlying factor of sudden cardiac death may be Brugada syndrome (BrS) \u2013 BrS mutations that overlap with those linked with schizophrenia are the calcium channel mutations. BrS may also be drug-induced from certain antipsychotics and antidepressants. Primary polydipsia, or excessive fluid intake, is relatively common in people with chronic schizophrenia. This may lead to hyponatremia which can be life-threatening. Antipsychotics can lead to a dry mouth, but there are several other factors that may contribute to the disorder; it may reduce life expectancy by 13 percent. Barriers to improving the mortality rate in schizophrenia are poverty, overlooking the symptoms of other illnesses, stress, stigma, and medication side effects.\nSchizophrenia is a major cause of disability. In 2016, it was classed as the 12th most disabling condition. Approximately 75% of people with schizophrenia have ongoing disability with relapses. Some people do recover completely and others function well in society. Most people with schizophrenia live independently with community support. About 85% are unemployed. In people with a first episode of psychosis in schizophrenia a good long-term outcome occurs in 31%, an intermediate outcome in 42% and a poor outcome in 31%. Males are affected more often than females, and have a worse outcome. Studies showing that outcomes for schizophrenia appear better in the developing than the developed world have been questioned. Social problems, such as long-term unemployment, poverty, homelessness, exploitation, stigmatization and victimization are common consequences, and lead to social exclusion.\nThere is a higher than average suicide rate associated with schizophrenia estimated at 5% to 6%, most often occurring in the period following onset or first hospital admission. Several times more (20 to 40%) attempt suicide at least once. There are a variety of risk factors, including male sex, depression, a high IQ, heavy smoking, and substance use. Repeated relapse is linked to an increased risk of suicidal behavior. The use of clozapine can reduce the risk of suicide, and of aggression.\nA strong association between schizophrenia and tobacco smoking has been shown in worldwide studies. Smoking is especially high in those diagnosed with schizophrenia, with estimates ranging from 80 to 90% being regular smokers, as compared to 20% of the general population. Those who smoke tend to smoke heavily, and additionally smoke cigarettes with high nicotine content. Some propose that this is in an effort to improve symptoms. Among people with schizophrenia use of cannabis is also common.\nSchizophrenia leads to an increased risk of dementia.\nViolence.\nMost people with schizophrenia are not aggressive, and are more likely to be victims of violence rather than perpetrators. People with schizophrenia are commonly exploited and victimized by violent crime as part of a broader dynamic of social exclusion. People diagnosed with schizophrenia are also subject to forced drug injections, seclusion, and restraint at high rates.\nThe risk of violence by people with schizophrenia is small. There are minor subgroups where the risk is high. This risk is usually associated with a comorbid disorder such as a substance use disorder \u2013 in particular alcohol, or with antisocial personality disorder. Substance use disorder is strongly linked, and other risk factors are linked to deficits in cognition and social cognition including facial perception and insight that are in part included in theory of mind impairments. Poor cognitive functioning, decision-making, and facial perception may contribute to making a wrong judgement of a situation that could result in an inappropriate response such as violence. These associated risk factors are also present in antisocial personality disorder which when present as a comorbid disorder greatly increases the risk of violence.\nEpidemiology.\nIn 2017, the Global Burden of Disease Study estimated there were 1.1\u00a0million new cases; in 2022 the World Health Organization (WHO) reported a total of 24 million cases globally. Schizophrenia affects around 0.3\u20130.7% of people at some point in their life. In areas of conflict this figure can rise to between 4.0 and 6.5%. It occurs 1.4\u00a0times more frequently in males than females and typically appears earlier in men.\nWorldwide, schizophrenia is the most common psychotic disorder. The frequency of schizophrenia varies across the world, within countries, and at the local and neighborhood level; this variation in prevalence between studies over time, across geographical locations, and by gender is as high as fivefold.\nSchizophrenia causes approximately one percent of worldwide disability adjusted life years and resulted in 17,000 deaths in 2015.\nIn 2000, WHO found the percentage of people affected and the number of new cases that develop each year is roughly similar around the world, with age-standardized prevalence per 100,000 ranging from 343 in Africa to 544 in Japan and Oceania for men, and from 378 in Africa to 527 in Southeastern Europe for women.\nHistory.\nConceptual development.\nAccounts of a schizophrenia-like syndrome are rare in records before the 19th century; the earliest case reports were in 1797 and 1809. The term \"dementia praecox\" (\"premature dementia\") was used by German psychiatrist Heinrich Sch\u00fcle in 1886 and then in 1891 by Arnold Pick in a case report of hebephrenia. In 1893 Emil Kraepelin used the term in making a distinction, known as the Kraepelinian dichotomy, between the two psychoses: dementia praecox and manic depression (now called bipolar disorder). When it became evident that the disorder was not a degenerative dementia, it was renamed \"schizophrenia\" by Eugen Bleuler in 1908.\nThe word \"schizophrenia\" (\"splitting of the mind\") is Modern Latin, derived from the Greek \"schizein\" () and \"phr\u0113n\" (). Its use was intended to describe the separation of function between personality, thinking, memory, and perception.\nIn the early 20th century, the psychiatrist Kurt Schneider categorized the psychotic symptoms of schizophrenia into two groups: hallucinations and delusions. The hallucinations were listed as specific to auditory and the delusions included thought disorders. These were seen as important symptoms, termed \"first-rank\". The most common first-rank symptom was found to belong to thought disorders. In 2013 the first-rank symptoms were excluded from the DSM-5 criteria; while they may not be useful in diagnosing schizophrenia, they can assist in differential diagnosis.\nSubtypes of schizophrenia\u2014classified as paranoid, disorganized, catatonic, undifferentiated, and residual\u2014were difficult to distinguish and are no longer recognized as separate conditions by DSM-5 (2013) or ICD-11.\nBreadth of diagnosis.\nBefore the 1960s, nonviolent petty criminals and women were sometimes diagnosed with schizophrenia, categorizing the latter as ill for not performing their duties as wives and mothers. In the mid- to late 1960s, black men were categorized as \"hostile and aggressive\" and diagnosed as schizophrenic at much higher rates, their civil rights and Black Power activism labeled as delusions.\nIn the early 1970s in the United States, the diagnostic model for schizophrenia was broad and clinically based using DSM II. Schizophrenia was diagnosed far more in the United States than in Europe, where the ICD-9 criteria were followed. The US model was criticised for failing to demarcate clearly those people with a mental illness. In 1980 DSM III was published and showed a shift in focus from the clinically based biopsychosocial model to a reason-based medical model. DSM IV brought an increased focus on an evidence-based medical model.\nHistorical treatment.\nIn the 1930s a number of shock procedures which induced seizures (convulsions) or comas were used to treat schizophrenia. Insulin shock involved injecting large doses of insulin to induce comas, which in turn produced hypoglycemia and convulsions. The use of electricity to induce seizures was in use as electroconvulsive therapy (ECT) by 1938.\nCarried out from the 1930s until the 1970s in the United States and until the 1980s in France, psychosurgery, including such modalities as the lobotomy, is recognized as a human rights abuse. In the mid-1950s, chlorpromazine, the first typical antipsychotic, was introduced, followed in the 1970s by clozapine, the first atypical antipsychotic.\nPolitical abuse.\nFrom the 1960s until 1989, psychiatrists in the USSR and Eastern Bloc diagnosed thousands of people with sluggish schizophrenia, without signs of psychosis, based on \"the assumption that symptoms would later appear\". Now discredited, the diagnosis provided a convenient way to confine political dissidents.\nSociety and culture.\nIn the United States, the annual cost of schizophrenia \u2013 including direct costs (outpatient, inpatient, drugs, and long-term care) and non-healthcare costs (law enforcement, reduced workplace productivity, and unemployment) \u2013 was estimated at $62.7\u00a0billion for the year 2002. In the UK the cost in 2016 was put at \u00a311.8\u00a0billion per year with a third of that figure directly attributable to the cost of hospital, social care and treatment.\nStigma.\nIn 2002, the term for schizophrenia in Japan was changed from to to reduce stigma and confusion with \"multiple personalities\". The new name, also interpreted as \"integration disorder\", was inspired by the biopsychosocial model. A similar change was made in South Korea in 2012 to attunement disorder.\nStigma may prevent further research and treatment as in history treated some in the past invariably worse to recovery.\nCultural depictions.\nMedia coverage, especially movies, reinforce the public perception of an association between schizophrenia and violence. A majority of movies have historically depicted characters with schizophrenia as criminal, dangerous, violent, unpredictable and homicidal, and depicted delusions and hallucinations as the main symptoms of schizophrenic characters, ignoring other common symptoms, furthering stereotypes of schizophrenia including the idea of a split personality.\nThe book \"A Beautiful Mind\" chronicled the life of John Forbes Nash who had been diagnosed with schizophrenia and won the Nobel Memorial Prize in Economic Sciences. The book was made into a film with the same name; an earlier documentary film was \"A Brilliant Madness\".\nIn the UK, guidelines for reporting conditions and award campaigns have shown a reduction in negative reporting since 2013.\nIn 1964 a case study of three males diagnosed with schizophrenia who each had the delusional belief that they were Jesus Christ was published as \"The Three Christs of Ypsilanti\"; a film with the title \"Three Christs\" was released in 2020.\nResearch.\nA 2015 Cochrane review found unclear evidence of benefit from brain stimulation techniques to treat the positive symptoms of schizophrenia, in particular auditory verbal hallucinations (AVHs). Most studies focus on transcranial direct-current stimulation (tDCM), and repetitive transcranial magnetic stimulation (rTMS). Techniques based on focused ultrasound for deep brain stimulation could provide insight for the treatment of AVHs.\nThe study of potential biomarkers that would help in diagnosis and treatment of schizophrenia is an active area of research as of 2020. Possible biomarkers include markers of inflammation, neuroimaging, brain-derived neurotrophic factor (BDNF), and speech analysis. Some markers such as C-reactive protein are useful in detecting levels of inflammation implicated in some psychiatric disorders but they are not disorder-specific. Other inflammatory cytokines are found to be elevated in first episode psychosis and acute relapse that are normalized after treatment with antipsychotics, and these may be considered as state markers. Deficits in sleep spindles in schizophrenia may serve as a marker of an impaired thalamocortical circuit, and a mechanism for memory impairment. MicroRNAs are highly influential in early neuronal development, and their disruption is implicated in several CNS disorders; circulating microRNAs (cimiRNAs) are found in body fluids such as blood and cerebrospinal fluid, and changes in their levels are seen to relate to changes in microRNA levels in specific regions of brain tissue. These studies suggest that cimiRNAs have the potential to be early and accurate biomarkers in a number of disorders including schizophrenia.\nOngoing fMRI research aims to identify biomarkers within these brain networks, potentially aiding in earlier diagnosis and better tracking of treatment responses in schizophrenia.\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27791", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=27791", "title": "Sophie Germain", "text": "French mathematician, physicist, and philosopher\nMarie-Sophie Germain (; 1 April 1776 \u2013 27 June 1831) was a French mathematician, physicist, and philosopher. Despite initial opposition from her parents and difficulties presented by society, she gained education from books in her father's library, including ones by Euler, and from correspondence with famous mathematicians such as Lagrange, Legendre, and Gauss (under the pseudonym of Monsieur Le Blanc). One of the pioneers of elasticity theory, she won the grand prize from the Paris Academy of Sciences for her essay on the subject. Her work on Fermat's Last Theorem provided a foundation for mathematicians exploring the subject for hundreds of years after. Because of prejudice against her sex, she was unable to make a career out of mathematics, but she worked independently throughout her life. Before her death, Gauss had recommended that she be awarded an honorary degree, but that never occurred. On 27 June 1831, she died from breast cancer. At the centenary of her life, a street and a girls' school were named after her. The Academy of Sciences established the Sophie Germain Prize in her honour.\nEarly life.\nFamily.\nMarie-Sophie Germain was born in a house on Rue Saint-Denis on 1 April 1776, in Paris, France, and baptized the same day. According to most sources, her father, Ambroise-Fran\u00e7ois, was a wealthy silk merchant, though some believe he was a goldsmith. In 1789, he was elected as a representative of the bourgeoisie to the \u00c9tats-G\u00e9n\u00e9raux, which he saw change into the National Assembly. It is therefore assumed that Sophie witnessed many discussions between her father and his friends on politics and philosophy. Gray proposes that after his political career, Ambroise-Fran\u00e7ois became the director of a bank; in any case, the family remained well-off enough to support Germain throughout her adult life.\nMarie-Sophie had one younger sister, Ang\u00e9lique-Ambroise, and one older sister, Marie-Madeline. Her mother was also named Marie-Madeline, and this plethora of \"Maries\" may have been the reason she went by Sophie. Germain's nephew Armand-Jacques Lherbette, Marie-Madeline's son, published some of Germain's work after she died (see Work in Philosophy).\nIntroduction to mathematics.\nWhen Germain was 13, the Bastille fell, and the revolutionary atmosphere of the city forced her to stay inside. For entertainment, she turned to her father's library. Here she found J. E. Montucla's \"L'Histoire des Math\u00e9matiques\", and his story of the death of Archimedes intrigued her.\nGermain thought that if the geometry method, which at that time referred to all of pure mathematics, could hold such fascination for Archimedes, it was a subject worthy of study. So she pored over every book on mathematics in her father's library, even teaching herself Latin and Greek, so she could read works like those of Sir Isaac Newton and Leonhard Euler. She also enjoyed by \u00c9tienne B\u00e9zout and by . Later, Cousin visited Germain at home, encouraging her in her studies.\nGermain's parents did not at all approve of her sudden fascination with mathematics, which was then thought inappropriate for a woman. When night came, they would deny her warm clothes and a fire for her bedroom to try to keep her from studying, but after they left, she would take out candles, wrap herself in quilts and do mathematics. After some time, her mother even secretly supported her.\n\u00c9cole Polytechnique.\nIn 1794, when Germain was 18, the \u00c9cole Polytechnique opened. As a woman, Germain was barred from attending, but the new system of education made the \"lecture notes available to all who asked\". The new method also required the students to \"submit written observations\". Germain obtained the lecture notes and began sending her work to Joseph Louis Lagrange, a faculty member. She used the name of a former student Monsieur Antoine-Auguste Le Blanc, \"fearing\", as she later explained to Gauss, \"the ridicule attached to a female scientist\". When Lagrange saw the intelligence of M. Le Blanc, he requested a meeting, and thus Sophie was forced to disclose her true identity. Fortunately, Lagrange did not mind that Germain was a woman, and he became her mentor.\nEarly work in number theory.\nCorrespondence with Legendre.\nGermain first became interested in number theory in 1798 when Adrien-Marie Legendre published . After studying the work, she opened correspondence with him on number theory, and later, elasticity. Legendre included some of Germain's work in the to his second edition of the , where he calls it (\"very ingenious\"). See also Her work on Fermat's Last Theorem below.\nCorrespondence with Gauss.\nGermain's interest in number theory was renewed when she read Carl Friedrich Gauss's monumental work . After three years of working through the exercises and trying her own proofs for some of the theorems, she wrote, again under the pseudonym of M.\u00a0Le\u00a0Blanc, to the author himself, who was one year younger than she. Gauss's replies were mailed to the home of Antoine-Isaac, Baron Silvestre De Sacy, who must have understood Germain's reasons for assuming a masculine pseudonym and agreed to help her conceal her identity.\nThe first letter, dated 21 November 1804, discussed Gauss's and presented some of Germain's work on Fermat's Last Theorem. In the letter, Germain claimed to have proved the theorem for \"n\"\u00a0=\u00a0\"p\"\u00a0\u2212\u00a01, where \"p\" is a prime number of the form \"p\"\u00a0=\u00a08\"k\"\u00a0+\u00a07. However, her proof contained a weak assumption, and Gauss's reply did not comment on Germain's proof.\nAround 1807 (sources differ), during the Napoleonic wars, the French were occupying the German town of Braunschweig, where Gauss lived. Germain, concerned that he might suffer the fate of Archimedes, wrote to General Pernety (Joseph Marie de Pernety), a family friend, requesting that he ensure Gauss's safety. General Pernety sent the chief of a battalion to meet with Gauss personally to see that he was safe. As it turned out, Gauss was fine, but he was confused by the mention of Sophie's name.\nThree months after the incident, Germain disclosed her true identity to Gauss. He replied:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;How can I describe my astonishment and admiration on seeing my esteemed correspondent M.\u00a0Le\u00a0Blanc metamorphosed into this celebrated person ... when a woman, because of her sex, our customs and prejudices, encounters infinitely more obstacles than men in familiarising herself with [number theory's] knotty problems, yet overcomes these fetters and penetrates that which is most hidden, she doubtless has the noblest courage, extraordinary talent, and superior genius.Gauss's letters to Olbers show that his praise for Germain was sincere. In the same 1807 letter, Germain claimed that if formula_1 is of the form formula_2, then formula_3 is also of that form. Gauss replied with a counterexample: formula_4 can be written as formula_5, but formula_6 cannot.\nAlthough Gauss thought well of Germain, his replies to her letters were often delayed, and he generally did not review her work. Eventually his interests turned away from number theory, and in 1809 the letters ceased. Despite the friendship of Germain and Gauss, they never met.\nWork in elasticity.\nGermain's first attempt for the Academy Prize.\nWhen Germain's correspondence with Gauss ceased, she took interest in a contest sponsored by the Paris Academy of Sciences concerning Ernst Chladni's experiments with vibrating metal plates. The object of the competition, as stated by the academy, was \"to give the mathematical theory of the vibration of an elastic surface and to compare the theory to experimental evidence\". Lagrange's comment that a solution to the problem would require the invention of a new branch of analysis deterred all but two contestants, Denis Poisson and Germain. Then Poisson was elected to the academy, thus becoming a judge instead of a contestant, and leaving Germain as the only entrant to the competition.\nIn 1809 Germain began work. Legendre assisted by giving her equations, references, and current research. She submitted her paper early in the fall of 1811 and did not win the prize. The judging commission felt that \"the true equations of the movement were not established\", even though \"the experiments presented ingenious results\". Lagrange was able to use Germain's work to derive an equation that was \"correct under special assumptions\".\nSubsequent attempts for the Prize.\nThe contest was extended by two years, and Germain decided to try again for the prize. At first Legendre continued to offer support, but then he refused all help. Germain's anonymous 1813 submission was still littered with mathematical errors, especially involving double integrals, and it received only an honorable mention because \"the fundamental base of the theory [of elastic surfaces] was not established\". The contest was extended once more, and Germain began work on her third attempt. This time she consulted with Poisson. In 1814 he published his own work on elasticity and did not acknowledge Germain's help (although he had worked with her on the subject and, as a judge on the academy commission, had had access to her work).\nGermain submitted her third paper, \"\", under her own name, and on 8 January 1816 she became the first woman to win a prize from the Paris Academy of Sciences. She did not appear at the ceremony to receive her award. Although Germain had at last been awarded the , the academy was still not fully satisfied. Germain had derived the correct differential equation (a special case of the Kirchhoff\u2013Love equation), but her method did not predict experimental results with great accuracy, as she had relied on an incorrect equation from Euler, which led to incorrect boundary conditions. Here is Germain's final equation for the vibration of a plane lamina:\n formula_7\nwhere \"N\"2 is a constant.\nAfter winning the academy contest, she was still not able to attend its sessions because of the academy's tradition of excluding women other than the wives of members. Seven years later this situation was transformed, when she made friends with Joseph Fourier, a secretary of the academy, who obtained tickets to the sessions for her.\nLater work in elasticity.\nGermain published her prize-winning essay at her own expense in 1821, mostly because she wanted to present her work in opposition to that of Poisson. In the essay she pointed out some of the errors in his method.\nIn 1826 she submitted a revised version of her 1821 essay to the academy. According to Andrea Del Centina, the revision included attempts to clarify her work by \"introducing certain simplifying hypotheses\". This put the academy in an awkward position, as they felt the paper to be \"inadequate and trivial\", but they did not want to \"treat her as a professional colleague, as they would any man, by simply rejecting the work\". So Augustin-Louis Cauchy, who had been appointed to review her work, recommended her to publish it, and she followed his advice.\nOne further work of Germain's on elasticity was published posthumously in 1831, her \"\". She used the mean curvature in her research (see Honors in number theory).\nLater work in number theory.\nRenewed interest.\nGermain's best work was in number theory, and her most significant contribution to number theory dealt with Fermat's Last Theorem. In 1815, after the elasticity contest, the academy offered a prize for a proof of Fermat's Last Theorem. It reawakened Germain's interest in number theory, and she wrote to Gauss again after ten years of no correspondence.\nIn the letter, Germain said that number theory was her preferred field and that it was in her mind all the time she was studying elasticity. She outlined a strategy for a general proof of Fermat's Last Theorem, including a proof for a special case. Germain's letter to Gauss contained her substantial progress toward a proof. She asked Gauss whether her approach to the theorem was worth pursuing. Gauss never answered.\nHer work on Fermat's Last Theorem.\nFermat's Last Theorem can be divided into two cases. Case 1 involves all powers \"p\" that do not divide any of \"x\", \"y\", or \"z\". Case 2 includes all \"p\" that divide at least one of \"x\", \"y\", or \"z\". Germain proposed the following, commonly called \"Sophie Germain's theorem\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nLet \"p\" be an odd prime. If there exists an auxiliary prime \"P\"\u00a0=\u00a02\"Np\"\u00a0+\u00a01 (\"N\" is any positive integer not divisible by 3) such that:\nThen the first case of Fermat's Last Theorem holds true for \"p\".\nGermain used this result to prove the first case of Fermat's Last Theorem for all odd primes \"p\"\u00a0&lt;\u00a0100, but according to Andrea Del Centina, \"she had actually shown that it holds for every exponent \"p\"\u00a0&lt;\u00a0197\". L. E. Dickson later used Germain's theorem to prove the first case of Fermat's Last Theorem for all odd primes less than 1700.\nIn an unpublished manuscript titled , Germain showed that any counterexamples to Fermat's theorem for \"p\"\u00a0&gt;\u00a05 must be numbers \"whose size frightens the imagination\", around 40 digits long. Germain did not publish this work. Her theorem is known only because of the footnote in Legendre's treatise on number theory, where he used it to prove Fermat's Last Theorem for \"p\"\u00a0=\u00a05 (see Correspondence with Legendre). Germain also proved or nearly proved several results that were attributed to Lagrange or were rediscovered years later. Del Centina states that \"after almost two hundred years her ideas were still central\", but ultimately her method did not work.\nWork in philosophy.\nIn addition to mathematics, Germain studied philosophy and psychology. She wanted to classify facts and generalize them into laws that could form a system of psychology and sociology, which were then just coming into existence. Her philosophy was highly praised by Auguste Comte.\nTwo of her philosophical works, and , were published, both posthumously. This was due in part to the efforts of Lherbette, her nephew, who collected her philosophical writings and published them. is a collection of personal notes on scientific subjects (the writings of Tycho, Newton, and Laplace), aphorisms, and philosophical reflections. In , the work admired by Comte, Germain argues that there are no substantive differences between the sciences and the humanities.\nFinal years.\nIn 1829 Germain learned that she had breast cancer. Despite the pain, she continued to work. In 1831 \"Crelle's Journal\" published her paper on the curvature of elastic surfaces and \"a note about finding \"y\" and \"z\" in formula_8\". Mary Gray records: \"She also published in an examination of principles which led to the discovery of the laws of equilibrium and movement of elastic solids.\" On 27 June 1831, she died in the house at 13 rue de Savoie.\nDespite Germain's intellectual achievements, her death certificate lists her as a \" (property holder), not a \". But her work was not unappreciated by everyone. When the matter of honorary degrees came up at the University of G\u00f6ttingen in 1837\u2014six years after Germain's death\u2014Gauss lamented: \"she [Germain] proved to the world that even a woman can accomplish something worthwhile in the most rigorous and abstract of the sciences and for that reason would well have deserved an honorary degree\".\nAssessments.\nContemporary assessments.\nVesna Petrovich found that the educated world's response to the publication in 1821 of Germain's prize-winning essay \"ranged from polite to indifferent\". Yet, some critics had high praise for it. Of her essay in 1821, Cauchy said: \"[it] was a work for which the name of its author and the importance of the subject both deserved the attention of mathematicians\". Claude-Louis Navier sent Germain a note calling it \"a work so remarkable that quite few men could read it, and only one woman could write it.\"\nGermain's contemporaries also had good things to say relating to her work in mathematics. Gauss certainly thought highly of her and recognized that European culture presented special difficulties to a woman in mathematics (see Correspondence with Gauss).\nModern assessments.\nThe modern view generally acknowledges that although Germain had great talent as a mathematician, her haphazard education had left her without the strong base she needed to truly excel. As explained by Gray, \"Germain's work in elasticity suffered generally from an absence of rigor, which might be attributed to her lack of formal training in the rudiments of analysis.\" Petrovich adds: \"This proved to be a major handicap when she could no longer be regarded as a young prodigy to be admired but was judged by her peer mathematicians.\"\nNotwithstanding the problems with Germain's theory of vibrations, Gray states that \"Germain's work was fundamental in the development of a general theory of elasticity.\" When the Eiffel Tower was built and engraved with the names of 72 great French scientists, engineers, and mathematicians, Germain's name was not among them; H. J. Mozans conjectured that despite the salience of her work to the tower's construction, she was excluded from this list because she was a woman.\nConcerning her early work in number theory, J. H. Sampson states: \"She was clever with formal algebraic manipulations; but there is little evidence that she really understood the , and her work of that period that has come down to us seems to touch only on rather superficial matters.\" Gray adds on to say \"The inclination of sympathetic mathematicians to praise her work rather than to provide substantive criticism from which she might learn was crippling to her mathematical development.\" Yet Marilyn Bailey Ogilvie recognizes that \"Sophie Germain's creativity manifested itself in pure and applied mathematics ... [she] provided imaginative and provocative solutions to several important problems\", and, as Petrovich proposes, it may have been her very lack of training that gave her unique insights and approaches. Louis Bucciarelli and Nancy Dworsky, Germain's biographers, summarize as follows: \"All the evidence argues that Sophie Germain had a mathematical brilliance that never reached fruition due to a lack of rigorous training available only to men.\"\nHonors.\nMemorials.\nGermain's resting place in the P\u00e8re Lachaise Cemetery in Paris is marked by a gravestone. At the centennial celebration of her life, a street and a girls' school were named after her, and a plaque was placed at the house where she died. The City Council of Paris commissioned a bust by Zacharie Astruc, based upon a death mask in the collection of the National Museum of Natural History, which was erected in the main courtyard of the school on 2 August 1890. There are no known likenesses of Germain made from life, nor contemporary verbal descriptions of her appearance.\nIn January 2020, Satellogic, a high-resolution Earth observation imaging and analytics company, launched a \u00d1uSat type micro-satellite named in honor of Sophie Germain.\nHonors in number theory.\nE. Dubouis defined a \"sophien\" of a prime n to be a prime \u03b8 where \"\u03b8\"\u00a0=\u00a0\"kn\"\u00a0+\u00a01, for such n that yield \u03b8 such that \"x\"\"n\"\u00a0=\u00a0\"y\"\"n\"\u00a0+\u00a01 (mod \"\u03b8\") has no solutions when x and y are prime to n.\nA Sophie Germain prime is a prime p such that 2\"p\"\u00a0+\u00a01 is also prime.\nThe \"Germain curvature\" (also called mean curvature) is formula_9, where \"k\"1 and \"k\"2 are the maximum and minimum values of the normal curvature.\nSophie Germain's identity states that for any {\"x\", \"y\"},\n formula_10\nSophie Germain Prize.\nThe Sophie Germain Prize (), awarded annually by the Foundation Sophie Germain, is conferred by the Academy of Sciences in Paris. Its purpose is to honour a French mathematician for research in the foundations of mathematics. This award, in the amount of \u20ac8,000, was established in 2003, under the auspices of the Institut de France.\nGermain in popular culture.\nGermain was referenced and quoted in David Auburn's 2001 play \"Proof.\" The protagonist is a young struggling female mathematician, Catherine, who found great inspiration in the work of Germain. Germain was also mentioned in John Madden's film adaptation of the same name in a conversation between Catherine (Gwyneth Paltrow) and Hal (Jake Gyllenhaal).\nIn the fictional work \"The Last Theorem\" by Arthur C. Clarke and Frederik Pohl, Sophie Germain was credited with inspiring the central character, Ranjit Subramanian, to solve Fermat's Last Theorem.\nA musical about Sophie Germain's life, entitled \"The Limit\", premiered at VAULT Festival in London, 2019.\nSophie Germain is referenced in Season 1 Episode 3 of the 2025 British miniseries \"Prime Target\". A library book entitled \"Sophie Germain: The Unsolved Riddle\" (there appears to be no such book) serves as a \"mailbox\" for a brilliant, deceased prime number theorist named Safiya Zamil to have passed a handwritten note to a future mathematician on a similar prime number quest.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27793", "revid": "1866741", "url": "https://en.wikipedia.org/wiki?curid=27793", "title": "Shoa", "text": "Shoa may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "27794", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=27794", "title": "Small arms", "text": ""}
{"id": "27796", "revid": "50865785", "url": "https://en.wikipedia.org/wiki?curid=27796", "title": "Succubus", "text": "Mythological demoness who seduces men\nA succubus (pl.\u2009succubi) is a female demon who is described in various European folklore as appearing in the dreams of male humans in order to seduce them. Repeated interactions between a succubus and a man will lead to sexual activity, a bond forming between them, and ultimately sexual intercourse, as she requires semen to survive. The establishment and perpetuation of such a relationship enables the production of a hybrid child known as a cambion, but at the expense of the man, whose mental and physical health will deteriorate rapidly, eventually resulting in his death if the succubus continues courting him for a protracted period.\nIn modern representations, a succubus is often depicted as a beautiful woman seductress or charming, rather than as demonic or frightening, to attract people instead of repulsing them. The male counterpart of the succubus is the incubus. Historically, folkloric belief in succubi was motivated by distressing nighttime phenomena, chiefly wet dreams and sleep paralysis.\nIn medieval Europe, union of a incubus or succubus and a human was supposed by some to result in the birth of beings half-demon and half-human children. Legendary magician Merlin was said to have been fathered by an incubus. Walter Stephens writes in his book \"Demon Lovers\" that some traditions hold that repeated sexual activity with an incubus or succubus may result in the deterioration of health, an impaired mental state, or even death.\nEtymology.\nThe term derives from Late Latin ' \"paramour\" from ' \"to lie beneath\" (\"-\" \"under\" and \"\" \"to lie\"), used to describe this being's implied sexual position relative to the sleeper's position. The English word \"succubus\" dates from the late 14th century. The succubus is also known as the earth wanderer.\nIn folklore.\nAs depicted in the Jewish mystical treatise \"Zohar\" and the medieval Jewish satirical text \"Alphabet of Ben Sira\", Lilith was Adam's first wife, who later became a succubus. She left Adam and refused to return to the Garden of Eden after she mated with the archangel Samael. In Zoharistic Kabbalah, there were four succubi who mated with the archangel Samael. The four original queens of the demons were Lilith, Eisheth Zenunim, Agrat bat Mahlat, and Naamah. A succubus may take the form of a beautiful woman, but closer inspection may reveal deformities of her body, such as bird-like claws or serpentine tails. Folklore also describes men being forced to perform the act of cunnilingus. In later folklore, a succubus took the form of a siren.\nThroughout history, priests and rabbis, including Hanina ben Dosa and Abaye, tried to curb the power of succubi over humans. However, not all succubi were malevolent. According to Walter Map in the satire \"\" (\"Trifles of Courtiers\"), Pope Sylvester II (999\u20131003) was allegedly involved with a succubus named Meridiana, who helped him achieve his high rank in the Catholic Church. Before his death, he confessed of his sins and died repentant.\nAbility to reproduce.\nAccording to the Kabbalah and the school of Rashba, three of the original demon queens\u2014Agrat bat Mahlat, Naamah and Eisheth Zenunim\u2014give birth to children, with the exception of Lilith. According to other legends, Lilith has children, who are referred to as Lilin.\nAccording to the ', or \"Witches' Hammer\", written by Heinrich Kramer (Institor) in 1486, succubi collect semen from men they seduce. Incubi, or male demons, then use the semen to impregnate human females, thus explaining how demons could apparently sire children, despite the traditional belief that they were incapable of reproduction. Children so begotten\u2014cambions\u2014were supposed to be those that were born deformed, or more susceptible to supernatural influences.\nKing James in his dissertation titled \"D\u00e6monologie \"refutes the possibility for angelic entities to reproduce and instead offered a suggestion that a devil would carry out two methods of impregnating women - the first, to steal the sperm out of a dead man and deliver it into a woman. If a demon could extract the semen quickly, the substance could not be instantly transported to a female host, causing it to go cold. This explains his view that succubi and incubi were the same demonic entity, only to be described differently based on the tormented sexes being conversed with. The second method was the idea that a dead body could be possessed by a devil, causing it to rise and have sexual relations with others. However, no mention has been found of a female corpse being possessed to elicit sex from men.\nParallels in non-Western traditions.\nArabian mythology.\nIn Arabian mythology, the ' () is a spirit similar to the succubus, with origins possibly in ancient Egyptian religion or in the animistic beliefs of pre-Islamic Arabia. A ' \"sleeps with the person and has relations during sleep as is known by the dreams\". They are said to be invisible, but a person with \"second sight\" can see them, often in the form of a cat, dog, or other household pet. \"In Omdurman it is a spirit which possesses. ...Only certain people are possessed and such people cannot marry or the qarina will harm them.\"\nIn Upper Egyptian folk belief, the \"qar\u00eenah\" can be appeased by sacrificing an all-black animal to her. The animal is slaughtered without prayers, and it is cooked without salt. No one speaks during the meal and it is buried in the house of those it has afflicted.\nBuddhist canon.\nA Buddhist scripture regarding prayer to Avalokite\u015bvara, the \"Dharani Sutra of Amoghap\u0101\u015ba\", promises to those who pray that \"you will not be attacked by demons who either suck your energy or make love to you in your dreams.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27797", "revid": "50859364", "url": "https://en.wikipedia.org/wiki?curid=27797", "title": "Suzanne Vega", "text": "American singer-songwriter (born 1959)\nSuzanne Nadine Vega (\"n\u00e9e\" Peck; born July 11, 1959) is an American singer-songwriter of folk-inspired music. Vega's music career spans 40 years. In the mid-1980s and 1990s, she released four singles that entered the Top 40 on the UK singles chart, \"Marlene on the Wall\", \"Left of Center\", \"Luka\" and \"No Cheap Thrill\".\n\"Tom's Diner\", which was originally released as an a cappella recording on Vega's second studio album, \"Solitude Standing\" (1987), was remixed in 1990 as a dance track by English electronic music producers DNA with her vocals, and it became a Top 10 hit in five countries. The original a cappella recording of the song was used as a test during the creation of the MP3 format. The role of her song in the development of the MP3 compression prompted Vega to be given the title of \"The Mother of the MP3\".\nVega has released ten studio albums; her most recent release is the studio album \"Flying with Angels\", released on May 2, 2025 by Cooking Vinyl.\nEarly life.\nSuzanne Nadine Vega was born on July 11, 1959, in Santa Monica, California. Her parents divorced soon after her birth. Her mother, Pat Vega (n\u00e9e Schumacher), is a computer systems analyst of German-Swedish heritage. Her father, Richard Peck, is of English, Irish and Scottish origin. Her stepfather, Edgardo Vega Yunqu\u00e9, also known as Ed Vega, was a novelist and professor from Puerto Rico. When Vega was two and a half, her family moved to New York City. She grew up in Spanish Harlem and the Upper West Side. She was not aware that Peck was her biological father until she was nine years old. Vega and Peck met for the first time in her late 20s, and they remain in contact.\nShe attended the High School of Performing Arts (since renamed Fiorello H. LaGuardia High School) where she studied modern dance and graduated in 1977.\nCareer.\n1980s.\nWhile majoring in English literature at Barnard College, she performed in small venues in Greenwich Village, where she was a regular contributor to Jack Hardy's Monday night songwriters' group at the Cornelia Street Cafe and had some of her first songs published on \"Fast Folk\" anthology albums. In 1984, she received a major label recording contract, making her one of the first \"Fast Folk\" artists to break out on a major label.\nVega's eponymous debut studio album was released on May 1, 1985 by A&amp;M Records and was well received by critics in the U.S.; it reached platinum status in the United Kingdom. Produced by Lenny Kaye and Steve Addabbo, the songs feature Vega's acoustic guitar in straightforward arrangements which deviated from the prevailing trends of the time. A music video was released for the album's song \"Marlene on the Wall\", which went into MTV and VH1's rotations. During this period Vega also wrote lyrics, and sang vocals for two songs (\"Lightning\" and \"Freezing\") on the 1986 studio album \"Songs from Liquid Days\" by composer and pianist Philip Glass.\nVega's song \"Left of Center\" co-written with Steve Addabbo, was released as part of the soundtrack to the John Hughes film \"Pretty in Pink\" (1986). It features British musician Joe Jackson on piano and was released as a single in May 1986, reaching No. 32 on the UK singles chart.\nIn 1986, she was interviewed by Lou Reed on \"120 Minutes\" to promote a Greenpeace benefit concert, which led to them becoming friends, and after Reed's death in 2013, Vega has covered \"Walk on the Wild Side\" at all of her live concerts since, as a tribute.\nHer next studio album, \"Solitude Standing\" (1987), garnered critical and commercial success, selling over one million copies in the U.S. It includes the international hit single \"Luka\", which is written about, and from the point of view of, an abused child. Many years later Vega revealed that the song dealt with the abuse that she herself had suffered from her stepfather. While continuing a focus on Vega's acoustic guitar, the music of her second album is more strongly pop-oriented and features fuller arrangements. Following the success of the album, in 1989 Vega became the first female artist to headline the Glastonbury Festival. Vega performed her set whilst wearing a bulletproof vest, her band having received death threats from an obsessed fan ahead of the festival.\nThe a cappella \"Tom's Diner\" from \"Solitude Standing\" became a hit in 1990, having been remixed by two English electronic music producers under the name DNA. The track was originally a bootleg, until Vega allowed DNA to release it through her record company, and it became her biggest hit.\n1990s.\nVega's third studio album, \"Days of Open Hand\" (1990), combines Vega's established folk rock style with more varied instrumentation such as the ney and dumbec and experimental arrangements. High-profile contributors to the album include Philip Glass, Shawn Colvin, and John Linnell of They Might Be Giants. The album saw greater use of synthesizers and samplers than Vega's previous studio albums; these included the digital Fairlight CMI and analog Voyetra-8.\nIn 1992, she released her fourth studio album \"99.9F\u00b0\", which mixed folk and pop music with electronic elements. This record was awarded Gold status by the RIAA in recognition of selling over 500,000 copies in the U.S. The single \"Blood Makes Noise\" from this album peaked at number-one on \"Billboard\"'s Modern Rock Tracks. Vega later married the album's producer, Mitchell Froom.\nHer fifth studio album, \"Nine Objects of Desire\", was released in 1996. The music varies between a frugal, simple style and the industrial production of \"99.9F\u00b0\". This album contains \"Caramel\", featured in the romantic comedy film \"The Truth About Cats &amp; Dogs\" (1996), and later the trailer for the romantic drama film \"Closer\" (2004). A song not included on that album, \"Woman on the Tier\", was featured on the soundtrack of the crime drama film \"Dead Man Walking\" (1996).\nIn 1997 she took a singing part on the concept album \"Heaven &amp; Hell\", a musical interpretation of the seven deadly sins by her colleague Joe Jackson, with whom she had already collaborated in 1986 on \"Left of Center\".\nIn 1999, Avon Books published Vega's book \"The Passionate Eye: The Collected Writings of Suzanne Vega\", a volume of poems, lyrics, essays and journalistic pieces.\n2000s.\nIn September 2001, Vega released her sixth studio album \"Songs in Red and Gray\", which was her final release for A&amp;M Records. Three songs deal with Vega's divorce from her first husband, Mitchell Froom.\nAt the memorial concert for her brother Tim Vega in December 2002, Vega began her role as the subject of the direct-cinema documentary, \"Some Journey\", directed by Christopher Seufert. The documentary has not yet been released.\nUnderground hip-hop duo Felt named a track \"Suzanne Vega\" on their debut studio album \", released in 2002.\nIn 2003, the 21-song greatest hits compilation album \" was released. (The UK version of \"Retrospective\" included an eight-song bonus CD as well as a DVD containing 12 songs). In the same year she was invited by Grammy Award-winning jazz guitarist Bill Frisell to play at the \"Century of Song\" concerts at the famed Ruhrtriennale in Ruhr, Germany.\nIn 2003, she hosted the American Public Media radio series \"American Mavericks\", about 20th century American composers, which received the Peabody Award for Excellence in Broadcasting.\nOn August 3, 2006, Vega became the first major recording artist to perform live in the Internet-based virtual world \"Second Life\". The event was hosted by John Hockenberry of public radio's \"The Infinite Mind\".\nOn September 17, 2006, she performed in Central Park, as part of a benefit concert for the Save Darfur Coalition. During the concert she highlighted her support for Amnesty International, of which she has been a member since 1988.\nIn early October 2006, Vega participated in the Academia Film Olomouc (AFO) in Olomouc, the Czech Republic, the oldest festival of documentary films in Europe, in which she appeared as a main guest. She was invited there as the subject of the documentary film by director Christopher Seufert, that had a test screening at the festival. At the end of the festival she performed her classic songs and added one brand new piece called \"New York Is a Woman\".\nVega is also interviewed in the book \"Everything Is Just a Bet\" which was published in Czech in October 2006. The book contains 12 interview transcriptions from the talk show called \"Stage Talks\" that regularly runs in the \u0160vandovo divadlo (\u0160vandovo Theatre) in Prague. Vega introduced the book to the audience of the \u0160vandovo divadlo (\u0160vandovo Theatre), and together with some other Czech celebrities gave a signing session.\nShe signed a new recording contract with Blue Note Records in the spring of 2006, and released \"Beauty &amp; Crime\" on July 17, 2007. The album, produced by Jimmy Hogarth, won a Grammy Award for Best Engineered Album, Non-Classical. Her contract was not renewed and she was released in June 2008.\nIn 2007, Vega followed the lead of numerous other mainstream artists and released her track \"Pornographer's Dream\" as podsafe. The song spent two weeks at number-one during 2007 and finished as the No. 11 hit of the year on the PMC Top10's annual countdown. \nVega was a member of the Annual Independent Music Awards judging panel in multiple years, from the 6th through to the 14th iterations.\nIn 2008, a fire that broke out on the backlot of Universal Studios Hollywood in Los Angeles County, California resulted in the loss or damage of some Vega recordings.\n2010s.\nA partial cover version of her song \"Tom's Diner\" was used to introduce the British crime thriller film \"4.3.2.1.\" (2010), with its lyrics largely rewritten to echo the plot. This musical hybrid was released as \"Keep Moving\". Vega participated in the Danger Mouse and Sparklehorse studio album \"Dark Night of the Soul\" (2010). She wrote both melody and lyrics for her song, which is titled \"Man Who Played God\", inspired by a biography of Spanish artist Pablo Picasso. Vega sang lead vocals on the song \"Now I Am an Arsonist\" with singer-songwriter Jonathan Coulton on his eighth studio album, \"Artificial Heart\" (2011).\nVega has re-recorded her back-catalogue, both for artistic and commercial (and control) reasons, in the \"Close-Up\" series. Vol. 1 (\"Love Songs\") and Vol. 2 (\"People &amp; Places\") appeared in 2010 while Vol. 3 (\"States of Being\") was released in July 2011 followed by Vol. 4 (\"Songs of Family\") in September 2012. Volumes 2, 3 and 4 of the \"Close-Up\" albums included previously unrecorded material; Volumes 2 and 3 each included one new collaboratively written song, while Volume 4 included three songs that Vega had written years earlier, but had not previously gotten around to recording. In all, Vega's \"Close-Up\" series features 60 re-recorded songs and five new compositions, representing about three-quarters of her lifetime songwriting output.\nWhile performing live, Vega and long-term collaborator Gerry Leonard began to introduce a number of new songs into the setlist, including the live favorite \"I Never Wear White\". Over the course of a year, the songs were completed and recorded in a live-studio setting with the help of a number of guests. Produced by Leonard, \"Tales from the Realm of the Queen of Pentacles\" was released in February 2014. It was her first album of new material in seven years and became Vega's first studio album to reach the UK Top 40 since 1992, peaking at No. 37.\nVega's ninth studio album, \"\", was released on October 14, 2016.\n2020s.\nIn February and March 2023, Vega toured the UK. On May 2, 2025, Vega released her tenth studio album \"Flying with Angels\". This was followed by a European tour.\nSongwriting.\nAt the age of nine she began to write poetry. She was encouraged to do so by her stepfather. It took her three years to write her first song, \"Brother Mine\", which was finished at the age of 14. It was first published on \"Close-Up Vol. 4, Songs of Family\" (2012), along with her other early song, \"The Silver Lady\".\nVega has not learned to read musical notation; she sees the melody as a shape and chords as colors. She focuses on lyrics and melodic ideas; for advanced features \u2013 like intros or bridges \u2013 she relies on other artists with whom she works. Most of her albums, except the first one, were made in such cooperation.\nVega finishes 80% of the songs she starts writing. She got the melody of \"Tom's Diner\" while walking down Broadway in New York City. She was thinking of French New Wave films.\nThe most important artistic influences on her work come from Lou Reed, Bob Dylan and Leonard Cohen. Some other important artists for her are Paul Simon and Laura Nyro.\nGuitars.\nSuzanne Vega currently plays Furch Guitars, a brand made in the Czech Republic, and her song \"Tom's Diner\" was the focus of a win-a-guitar competition run by Furch in 2021. In the mid-1980s she played Guild guitars, and in the 1990s she played Yamaha and Taylor guitars at different times.\nBooks.\nIn 1998, she wrote the book \"The Passionate Eye: The Collected Writing of Suzanne Vega.\" In 2014, Vega wrote the foreword for the book about singer, songwriter, and poet Leonard Cohen, \"Leonard Cohen on Leonard Cohen\".\nTheater.\nVega and Duncan Sheik wrote a play \"Carson McCullers Talks About Love\", about the life of the writer Carson McCullers. In the play directed by Kay Matschullat, which premiered in 2011, Vega alternates between monologue and songs. Vega and Sheik were nominated for Outstanding Music in a Play for the 57th annual Drama Desk awards.\nThe studio album \"\", based on this play, was released in 2016. Vega considers it to be a third version, because it's rewritten, and she made the first version in college.\nIn early 2020, Vega played the role of \"Band Leader\" in an off-Broadway musical based on the comedy-drama film \"Bob &amp; Carol &amp; Ted &amp; Alice\" (1969), directed by Scott Elliott and produced at The New Group in New York City. She replaced Sheik, who wrote the show's music and co-wrote the lyrics with Amanda Green. In his review for \"The New York Times\", critic Ben Brantley called the \"brandy-voiced\" Vega \"a delightful, smoothly sardonic presence.\"\nAmanuensis Productions.\nVega established her own record label after the 2008 financial crisis. From that point, she stopped working for Blue Note Records and started thinking about re-recording her back catalog with new arrangements and gaining control over her works (which she eventually did with the 2014 \"Close-Up Series\").\nThe name \"Amanuensis Productions\" was meant as a private joke about \"servant\" (amanuensis) owning the \"masters\" (recording masters), also a pun at A&amp;M still legally owning her previous master tapes.\nRunning the label proved to be harder than she expected. In 2015, it barely \"broke even\", but new licenses were coming for \"Tom's Diner\".\nPersonal life.\nOn March 17, 1995, Vega married Mitchell Froom, a musician and a record producer (who played on and produced \"99.9F\u00b0\" and \"Nine Objects of Desire\"). They have a daughter, Ruby Froom (born July 8, 1994). The alternative rock band Soul Coughing's debut studio album \"Ruby Vroom\" (1994) was named for her, with Vega's approval. Vega and Froom separated and divorced in 1998.\nOn February 11, 2006, Vega married Paul Mills, a lawyer and poet, \"22 years after he first proposed to her\". In 1977, at the age of 27, Mills, then a young poet who went by \"Poez\", dated Vega for a time, but when she was ambivalent about his marriage proposal, he moved to California to become a lawyer. In 2005, their paths crossed again, and he moved back to New York to refocus on his poetry, and the following year the young couple finally tied the knot.\nBeginning in 2010, Ruby Froom has occasionally performed with her mother on tour.\nVega practices Nichiren Buddhism and is a member of the American branch of the worldwide Buddhist association Soka Gakkai International.\nAwards and nominations.\n! Year !! Awards !! Work !! Category !! Result\nDiscography.\nStudio albums\nLive albums\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27799", "revid": "26536202", "url": "https://en.wikipedia.org/wiki?curid=27799", "title": "Semigroup", "text": "Algebraic structure consisting of a set with an associative binary operation\nIn mathematics, a semigroup is an algebraic structure consisting of a set together with an associative internal binary operation on it.\nThe binary operation of a semigroup is most often denoted multiplicatively (just notation, not necessarily the elementary arithmetic multiplication): formula_1, or simply formula_2, denotes the result of applying the semigroup operation to the ordered pair formula_3. Associativity is formally expressed as that formula_4 for all formula_5, formula_6 and formula_7 in the semigroup.\nSemigroups may be considered a special case of magmas, where the operation is associative, or as a generalization of groups, without requiring the existence of an identity element or inverses. As in the case of groups or magmas, the semigroup operation need not be commutative, so formula_1 is not necessarily equal to formula_9; a well-known example of an operation that is associative but non-commutative is matrix multiplication. If the semigroup operation is commutative, then the semigroup is called a \"commutative semigroup\" or (less often than in the analogous case of groups) it may be called an \"abelian semigroup\".\nA monoid is an algebraic structure intermediate between semigroups and groups, and is a semigroup having an identity element, thus obeying all but one of the axioms of a group: existence of inverses is not required of a monoid. A natural example is strings with concatenation as the binary operation, and the empty string as the identity element. Restricting to non-empty strings gives an example of a semigroup that is not a monoid. Positive integers with addition form a commutative semigroup that is not a monoid, whereas the non-negative integers do form a monoid. A semigroup without an identity element can be easily turned into a monoid by just adding an identity element. Consequently, monoids are studied in the theory of semigroups rather than in group theory. Semigroups should not be confused with quasigroups, which are generalization of groups in a different direction; the operation in a quasigroup need not be associative but quasigroups preserve from groups the notion of division. Division in semigroups (or in monoids) is not possible in general.\nThe formal study of semigroups began in the early 20th century. Early results include a Cayley theorem for semigroups realizing any semigroup as a transformation semigroup, in which arbitrary functions replace the role of bijections in group theory. A deep result in the classification of finite semigroups is Krohn\u2013Rhodes theory, analogous to the Jordan\u2013H\u00f6lder decomposition for finite groups. Some other techniques for studying semigroups, like Green's relations, do not resemble anything in group theory.\nThe theory of finite semigroups has been of particular importance in theoretical computer science since the 1950s because of the natural link between finite semigroups and finite automata via the syntactic monoid. In probability theory, semigroups are associated with Markov processes. In other areas of applied mathematics, semigroups are fundamental models for linear time-invariant systems. In partial differential equations, a semigroup is associated to any equation whose spatial evolution is independent of time.\nThere are numerous special classes of semigroups, semigroups with additional properties, which appear in particular applications. Some of these classes are even closer to groups by exhibiting some additional but not all properties of a group. Of these we mention: regular semigroups, orthodox semigroups, semigroups with involution, inverse semigroups and cancellative semigroups. There are also interesting classes of semigroups that do not contain any groups except the trivial group; examples of the latter kind are bands and their commutative subclass \u2013 semilattices, which are also s.\nDefinition.\nA semigroup is a set formula_10 together with a binary operation formula_11 (that is, a function formula_12) that satisfies the associative property:\n for all formula_13, the equation formula_14 holds.\nMore succinctly, a semigroup is an associative magma.\nBasic concepts.\nIdentity and zero.\nA left identity of a semigroup formula_10 (or more generally, magma) is an element formula_23 such that for all formula_5 in formula_10, formula_26. Similarly, a right identity is an element formula_27 such that for all formula_5 in formula_10, formula_30. Left and right identities are both called one-sided identities. A semigroup may have one or more left identities but no right identity, and vice versa.\nA two-sided identity (or just identity) is an element that is both a left and right identity. Semigroups with a two-sided identity are called monoids. A semigroup may have at most one two-sided identity. If a semigroup has a two-sided identity, then the two-sided identity is the only one-sided identity in the semigroup. If a semigroup has both a left identity and a right identity, then it has a two-sided identity (which is therefore the unique one-sided identity).\nA semigroup formula_10 without identity may be embedded in a monoid formed by adjoining an element formula_32 to formula_10 and defining formula_34 for all formula_35. The notation formula_36 denotes a monoid obtained from formula_10 by adjoining an identity if necessary (formula_38 for a monoid).\nSimilarly, every magma has at most one absorbing element, which in semigroup theory is called a zero. Analogous to the above construction, for every semigroup formula_10, one can define formula_40, a semigroup with 0 that embeds formula_10.\nSubsemigroups and ideals.\nThe semigroup operation induces an operation on the collection of its subsets: given subsets formula_42 and formula_43 of a semigroup formula_10, their product formula_45, written commonly as formula_46, is the set formula_47. (This notion is defined identically as it is for groups.) In terms of this operation, a subset formula_42 is called\nIf formula_42 is both a left ideal and a right ideal then it is called an ideal (or a two-sided ideal).\nIf formula_10 is a semigroup, then the intersection of any collection of subsemigroups of formula_10 is also a subsemigroup of formula_10.\nSo the subsemigroups of formula_10 form a complete lattice.\nAn example of a semigroup with no minimal ideal is the set of positive integers under addition. The minimal ideal of a commutative semigroup, when it exists, is a group.\nGreen's relations, a set of five equivalence relations that characterise the elements in terms of the principal ideals they generate, are important tools for analysing the ideals of a semigroup and related notions of structure.\nThe subset with the property that every element commutes with any other element of the semigroup is called the center of the semigroup. The center of a semigroup is actually a subsemigroup.\nHomomorphisms and congruences.\nA semigroup homomorphism is a function that preserves semigroup structure. A function formula_60 between two semigroups is a homomorphism if the equation\n formula_61.\nholds for all elements formula_62, formula_63 in formula_10, i.e. the result is the same when performing the semigroup operation after or before applying the map formula_27.\nA semigroup homomorphism between monoids preserves identity if it is a monoid homomorphism. But there are semigroup homomorphisms that are not monoid homomorphisms, e.g. the canonical embedding of a semigroup formula_10 without identity into formula_36. Conditions characterizing monoid homomorphisms are discussed further. Let formula_68 be a semigroup homomorphism. The image of formula_27 is also a semigroup. If formula_70 is a monoid with an identity element formula_71, then formula_72 is the identity element in the image of formula_27. If formula_74 is also a monoid with an identity element formula_75 and formula_75 belongs to the image of formula_27, then formula_78, i.e. formula_27 is a monoid homomorphism. Particularly, if formula_27 is surjective, then it is a monoid homomorphism.\nTwo semigroups formula_10 and formula_82 are said to be isomorphic if there exists a bijective semigroup homomorphism formula_60. Isomorphic semigroups have the same structure.\nA semigroup congruence formula_84 is an equivalence relation that is compatible with the semigroup operation. That is, a subset formula_85 that is an equivalence relation and formula_86 and formula_87 implies formula_88 for every formula_89 in formula_10. Like any equivalence relation, a semigroup congruence formula_84 induces congruence classes\n formula_92\nand the semigroup operation induces a binary operation formula_93 on the congruence classes:\n formula_94.\nBecause formula_84 is a congruence, the set of all congruence classes of formula_84 forms a semigroup with formula_93, called the quotient semigroup or factor semigroup, and denoted formula_98. The mapping formula_99 is a semigroup homomorphism, called the quotient map, canonical surjection or projection; if formula_10 is a monoid then quotient semigroup is a monoid with identity formula_101. Conversely, the kernel of any semigroup homomorphism is a semigroup congruence. These results are nothing more than a particularization of the first isomorphism theorem in universal algebra. Congruence classes and factor monoids are the objects of study in string rewriting systems.\nA nuclear congruence on formula_10 is one that is the kernel of an endomorphism of formula_10.\nA semigroup formula_10 satisfies the maximal condition on congruences if any family of congruences on formula_10, ordered by inclusion, has a maximal element. By Zorn's lemma, this is equivalent to saying that the ascending chain condition holds: there is no infinite strictly ascending chain of congruences on formula_10.\nEvery ideal formula_107 of a semigroup induces a factor semigroup, the Rees factor semigroup, via the congruence formula_108 defined by formula_109 if either formula_110, or both formula_5 and formula_6 are in formula_107.\nQuotients and divisions.\nThe following notions introduce the idea that a semigroup is contained in another one.\nA semigroup \"T\" is a quotient of a semigroup \"S\" if there is a surjective semigroup morphism from \"S\" to \"T\". For example, (Z/2Z, +) is a quotient of (Z/4Z, +), using the morphism consisting of taking the remainder modulo 2 of an integer.\nA semigroup \"T\" divides a semigroup \"S\", denoted \"T\" \u227c \"S\" if \"T\" is a quotient of a subsemigroup \"S\". In particular, subsemigroups of \"S\" divides \"T\", while it is not necessarily the case that there are a quotient of \"S\".\nBoth of those relations are transitive.\nStructure of semigroups.\nFor any subset \"A\" of \"S\" there is a smallest subsemigroup \"T\" of \"S\" that contains \"A\", and we say that \"A\" generates \"T\". A single element \"x\" of \"S\" generates the subsemigroup {\"x\"\"n\"|\"n\" \u2208 Z+}. If this is finite, then \"x\" is said to be of finite order, otherwise it is of infinite order.\nA semigroup is said to be periodic if all of its elements are of finite order.\nA semigroup generated by a single element is said to be monogenic (or cyclic). If a monogenic semigroup is infinite then it is isomorphic to the semigroup of positive integers with the operation of addition.\nIf it is finite and nonempty, then it must contain at least one idempotent.\nIt follows that every nonempty periodic semigroup has at least one idempotent.\nA subsemigroup that is also a group is called a subgroup. There is a close relationship between the subgroups of a semigroup and its idempotents. Each subgroup contains exactly one idempotent, namely the identity element of the subgroup. For each idempotent \"e\" of the semigroup there is a unique maximal subgroup containing \"e\". Each maximal subgroup arises in this way, so there is a one-to-one correspondence between idempotents and maximal subgroups. Here the term \"maximal subgroup\" differs from its standard use in group theory.\nMore can often be said when the order is finite. For example, every nonempty finite semigroup is periodic, and has a minimal ideal and at least one idempotent. The number of finite semigroups of a given size (greater than 1) is (obviously) larger than the number of groups of the same size. For example, of the sixteen possible \"multiplication tables\" for a set of two elements {\"a\", \"b\"}, eight form semigroups whereas only four of these are monoids and only two form groups. For more on the structure of finite semigroups, see \"Krohn\u2013Rhodes theory\".\nStructure theorem for commutative semigroups.\nThere is a structure theorem for commutative semigroups in terms of semilattices. A semilattice (or more precisely a meet-semilattice) (\"L\", \u2264) is a partially ordered set where every pair of elements \"a\", \"b\" \u2208 \"L\" has a greatest lower bound, denoted \"a\" \u2227 \"b\". The operation \u2227 makes \"L\" into a semigroup that satisfies the additional idempotence law \"a\" \u2227 \"a\" = \"a\".\nGiven a homomorphism \"f\" : \"S\" \u2192 \"L\" from an arbitrary semigroup to a semilattice, each inverse image \"S\"\"a\" = \"f\"\u22121{\"a\"} is a (possibly empty) semigroup. Moreover, \"S\" becomes graded by \"L\", in the sense that \"S\"\"a\"\"S\"\"b\" \u2286 \"S\"\"a\"\u2227\"b\".\nIf \"f\" is onto, the semilattice \"L\" is isomorphic to the quotient of \"S\" by the equivalence relation ~ such that \"x\" ~ \"y\" if and only if \"f\"(\"x\") = \"f\"(\"y\"). This equivalence relation is a semigroup congruence, as defined above.\nWhenever we take the quotient of a commutative semigroup by a congruence, we get another commutative semigroup. The structure theorem says that for any commutative semigroup \"S\", there is a finest congruence ~ such that the quotient of \"S\" by this equivalence relation is a semilattice. Denoting this semilattice by \"L\", we get a homomorphism \"f\" from \"S\" onto \"L\". As mentioned, \"S\" becomes graded by this semilattice.\nFurthermore, the components \"S\"\"a\" are all Archimedean semigroups. An Archimedean semigroup is one where given any pair of elements \"x\", \"y \", there exists an element \"z\" and \"n\" &gt; 0 such that \"x\"\"n\" = \"yz\".\nThe Archimedean property follows immediately from the ordering in the semilattice \"L\", since with this ordering we have \"f\"(\"x\") \u2264 \"f\"(\"y\") if and only if \"x\"\"n\" = \"yz\" for some \"z\" and \"n\" &gt; 0.\nGroup of fractions.\nThe group of fractions or group completion of a semigroup \"S\" is the group \"G\" = \"G\"(\"S\") generated by the elements of \"S\" as generators and all equations \"xy\" = \"z\" that hold true in \"S\" as relations. There is an obvious semigroup homomorphism \"j\" : \"S\" \u2192 \"G\"(\"S\") that sends each element of \"S\" to the corresponding generator. This has a universal property for morphisms from \"S\" to a group: given any group \"H\" and any semigroup homomorphism \"k\" : \"S\" \u2192 \"H\", there exists a unique group homomorphism \"f\" : \"G\" \u2192 \"H\" with \"k\" = \"fj\". We may think of \"G\" as the \"most general\" group that contains a homomorphic image of \"S\".\nAn important question is to characterize those semigroups for which this map is an embedding. This need not always be the case: for example, take \"S\" to be the semigroup of subsets of some set \"X\" with set-theoretic intersection as the binary operation (this is an example of a semilattice). Since \"A\".\"A\" = \"A\" holds for all elements of \"S\", this must be true for all generators of \"G\"(\"S\") as well, which is therefore the trivial group. It is clearly necessary for embeddability that \"S\" have the cancellation property. When \"S\" is commutative this condition is also sufficient, and the group of fractions can be constructed as the Grothendieck group of the semigroup, or via a minor variant of the standard construction of the field of fractions of an integral domain. The problem for non-commutative semigroups can be traced to the first substantial paper on semigroups. Anatoly Maltsev gave necessary and sufficient conditions for embeddability in 1937.\nSemigroup methods in partial differential equations.\nSemigroup theory can be used to study some problems in the field of partial differential equations. Roughly speaking, the semigroup approach is to regard a time-dependent partial differential equation as an ordinary differential equation on a function space. For example, consider the following initial/boundary value problem for the heat equation on the spatial interval (0, 1) \u2282 R and times \"t\" \u2265 0:\n formula_114\nLet \"X\" = \"L\"2((0, 1) R) be the \"L\"\"p\" space of square-integrable real-valued functions with domain the interval (0, 1) and let \"A\" be the second-derivative operator with domain\n formula_115\nwhere formula_116 is a Sobolev space. Then the above initial/boundary value problem can be interpreted as an initial value problem for an ordinary differential equation on the space \"X\":\n formula_117\nOn an heuristic level, the solution to this problem \"ought\" to be\nformula_118\nHowever, for a rigorous treatment, a meaning must be given to the exponential of \"tA\". As a function of \"t\", exp(\"tA\") is a semigroup of operators from \"X\" to itself, taking the initial state \"u\"0 at time \"t\" = 0 to the state \"u\"(\"t\") = exp(\"tA\")\"u\"0 at time \"t\". The operator \"A\" is said to be the infinitesimal generator of the semigroup.\nHistory.\nThe study of semigroups trailed behind that of other algebraic structures with more complex axioms such as groups or rings. A number of sources attribute the first use of the term (in French) to J.-A. de S\u00e9guier in \"\u00c9lements de la Th\u00e9orie des Groupes Abstraits\" (Elements of the Theory of Abstract Groups) in 1904. The term is used in English in 1908 in Harold Hinton's \"Theory of Groups of Finite Order\".\nAnton Sushkevich obtained the first non-trivial results about semigroups. His 1928 paper \"\u00dcber die endlichen Gruppen ohne das Gesetz der eindeutigen Umkehrbarkeit\" (\"On finite groups without the rule of unique invertibility\") determined the structure of finite simple semigroups and showed that the minimal ideal (or Green's relations J-class) of a finite semigroup is simple. From that point on, the foundations of semigroup theory were further laid by David Rees, James Alexander Green, Evgenii Sergeevich Lyapin, Alfred H. Clifford and Gordon Preston. The latter two published a two-volume monograph on semigroup theory in 1961 and 1967 respectively. In 1970, a new periodical called \"Semigroup Forum\" (currently published by Springer Verlag) became one of the few mathematical journals devoted entirely to semigroup theory.\nThe representation theory of semigroups was developed in 1963 by Boris Schein using binary relations on a set \"A\" and composition of relations for the semigroup product. At an algebraic conference in 1972 Schein surveyed the literature on B\"A\", the semigroup of relations on \"A\". In 1997 Schein and Ralph McKenzie proved that every semigroup is isomorphic to a transitive semigroup of binary relations.\nIn recent years researchers in the field have become more specialized with dedicated monographs appearing on important classes of semigroups, like inverse semigroups, as well as monographs focusing on applications in algebraic automata theory, particularly for finite automata, and also in functional analysis.\nGeneralizations.\nIf the associativity axiom of a semigroup is dropped, the result is a magma, which is nothing more than a set \"M\" equipped with a binary operation that is closed \"M\" \u00d7 \"M\" \u2192 \"M\".\nGeneralizing in a different direction, an n\"-ary semigroup (also n\"-semigroup, polyadic semigroup or multiary semigroup) is a generalization of a semigroup to a set \"G\" with a \"n\"-ary operation instead of a binary operation. The associative law is generalized as follows: ternary associativity is (\"abc\")\"de\" = \"a\"(\"bcd\")\"e\" = \"ab\"(\"cde\"), i.e. the string \"abcde\" with any three adjacent elements bracketed. \"n\"-ary associativity is a string of length \"n\" + (\"n\" \u2212 1) with any \"n\" adjacent elements bracketed. A 2-ary semigroup is just a semigroup. Further axioms lead to an \"n\"-ary group.\nA third generalization is the semigroupoid, in which the requirement that the binary relation be total is lifted. As categories generalize monoids in the same way, a semigroupoid behaves much like a category but lacks identities.\nInfinitary generalizations of commutative semigroups have sometimes been considered by various authors.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27800", "revid": "1254927316", "url": "https://en.wikipedia.org/wiki?curid=27800", "title": "Second Gulf War", "text": ""}
{"id": "27801", "revid": "7852030", "url": "https://en.wikipedia.org/wiki?curid=27801", "title": "Super Mario Kart", "text": "1992 video game\n is a 1992 kart racing game developed and published by Nintendo for the Super Nintendo Entertainment System (SNES). The first game in the \"Mario Kart\" series, it was released in Japan on August 27, 1992, North America on September 1, 1992, the United Kingdom in October 1992, and Europe on January 21, 1993. Selling 8.76 million copies worldwide, the game went on to become the fourth best-selling SNES game of all time. \"Super Mario Kart\" was re-released on the Wii's Virtual Console in 2009, on the Wii U's Virtual Console in 2013, and on the New Nintendo 3DS's Virtual Console in 2016. Nintendo re-released \"Super Mario Kart\" in 2017 as part of the company's Super NES Classic Edition.\nIn \"Super Mario Kart\", the player takes control of one of eight \"Mario\" series characters, each with differing capabilities. In single-player mode, players can race against computer-controlled characters in 4 multi-race cups consisting of 20 tracks (5 in each cup) over three difficulty levels (50cc, 100cc and 150cc). During the races, offensive and speed boosting power-ups can be used to gain an advantage. Alternatively, players can race against the clock in a Time Trial mode. In multiplayer mode, two players can simultaneously take part in the cups or can race against each other one-on-one in Match Race mode. In a third multiplayer mode \u2013 Battle Mode \u2013 the aim is to defeat the other players by attacking them with power-ups, destroying balloons which surround each kart.\n\"Super Mario Kart\" received positive reviews and was praised for its presentation, innovation and use of Mode 7 graphics. It has been ranked among the greatest video games of all time by several magazines and organizations. It is often credited with creating the kart racing subgenre of video games, leading other developers to try to duplicate its success. The game is seen as having been key to expanding the \"Mario\" series into non-platforming games; this diversity has led to it becoming the best-selling game franchise of all time. Several sequels to \"Super Mario Kart\" have been released for consoles, handhelds and in arcades, each enjoying critical and commercial success. While some elements have developed throughout the series, the core experience from \"Super Mario Kart\" has remained intact.\nGameplay.\n\"Super Mario Kart\" is a kart racing game featuring several single and multiplayer modes. During the game, players take control of one of eight \"Mario\" franchise characters, each with differing capabilities, and drive karts around tracks with a \"Mario\" franchise theme. In order for them to begin driving, Lakitu appears with a traffic light hanging on his fishing pole at the starting line, which starts the countdown. When the light turns green, the race or battle begins. During a race, the player's viewpoint is from behind their kart. The goal of the game is to either finish a race ahead of other racers, who are controlled by the computer and other players, or complete a circuit in the fastest time. There is a battle mode in which the aim is to attack the karts of the other human players.\nSome tracks feature chevron-shaped boost panels to increase speed for a brief moment. In addition, there are also short ramps that racers can use to launch themselves in the air. A combination of the two makes the player jump higher at a high speed.\nPanels marked with question marks are arrayed on the race tracks; they give special abilities (power-ups) to a player's kart if the vehicle passes over them. Certain power-ups, such as the ability to throw shells and bananas, allow racers to hit other racers with objects, causing them to spin and lose control. A kart that obtains the star power-up is temporarily invincible. Computer players have specific special powers associated with each character that they are able to use throughout the race. Lines of coins are found on the tracks in competitive race modes. By running over these coins, a kart collects them to increase its top speed. Having coins helps players when their kart is hit by another: instead of spinning and losing control, they lose a coin. Coins are lost when karts are struck by power-ups or fall off the tracks.\nThe game features advanced maneuvers such as power sliding and hopping. Power sliding allows a kart to maintain its speed while turning, although executing the maneuver for too long causes the kart to spin. Hopping helps a kart execute tighter turns: the kart makes a short hop and turns in the air, speeding off in the new direction when it lands. Reviewers praised \"Super Mario Kart\"'s gameplay, describing the battle mode as \"addictive\" and the single player gameplay as \"incredible\". \"IGN\" stated that the gameplay mechanics defined the genre.\nModes.\n\"Super Mario Kart\" has two single-player modes: Mario Kart GP (which stands for Grand Prix) and Time Trial. In Mario Kart GP, one player is required to race against seven computer-controlled characters in a series of five races which are called cups. Initially, there are three cups available \u2013 the Mushroom Cup, Flower Cup, and Star Cup \u2013 at two difficulty levels, 50cc and 100cc. By winning all three of the cups at the 100cc level, a fourth cup \u2013 the Special Cup \u2013 is unlocked. Winning all four cups at 100cc unlocks a new difficulty level, 150cc. Each cup consists of five five-lap races, each taking place on a distinct track. In order to continue through a cup, a position of fourth or higher must be achieved in each race. If a player finishes in the fifth to eighth position, they are \"ranked out\" and the race must be replayed \u2013 at the cost of one of a limited number of lives \u2013 until a placing of fourth or above is achieved. If the player has no lives when they rank out, the game is over. Points are accrued by finishing in the top four positions in a race; first to fourth place receive nine, six, three and one points. If a player finishes in the same position three times in a row, then an extra life is awarded. The finishing order for that race will then become the starting grid for the next race; for example, if a player finishes in first place, then that player will start the next race in the same position. The racer with the highest number of points after all five races have been completed wins the cup. In time trial mode, players race against the clock through the same tracks that are present in Mario Kart GP mode, attempting to set the fastest time possible.\n\"Super Mario Kart\" has three multiplayer modes; Mario Kart GP, Match Race, and Battle Mode. The multiplayer modes support two players and the second player uses the bottom half of the screen which is used as a map in the single-player modes. Mario Kart GP is the same as in single-player, the only difference being that there are two human-controlled and six computer-controlled drivers. Match Race involves the two players going head to head on a track of their choice without any opponents. In Battle Mode, the two players again go head to head, but this time in one of four dedicated Battle Mode courses. Each player starts with three balloons around their kart which can be popped by power-ups fired by the other player. The first player to have all three of their balloons popped loses.\nCharacters.\n\"Super Mario Kart\" features eight playable characters from the \"Mario\" series \u2013 Mario, Luigi, Princess Peach, Yoshi, Bowser, Donkey Kong Jr., Koopa Troopa and Toad. Each character's kart has different capabilities with differing levels of top speed, acceleration and handling. During races, computer-controlled characters have special items, or superpowers, which they are able to use. These powers are specific to each character; for example, Yoshi drops eggs which cause players who hit them to lose coins and spin, while Donkey Kong Jr. throws bananas.\nThe characters are rendered as sprites portrayed from sixteen different angles. In 2005, Nintendojo called the sprites \"not-so-pretty\" when they are rendered at a distance, and \"IGN\" has commented on the dated look of the game. \"Super Mario Kart\" was the first game to feature playable characters from the \"Mario\" series other than Mario or Luigi in a non-platforming game and the selection and different attributes of the characters is regarded as one of the game's strengths, \"IGN\" describing a well-balanced \"all-star cast\". All of the characters present in \"Super Mario Kart\" have gone on to appear in later games in the series, except for Donkey Kong Jr. and Koopa Troopa, who have only appeared intermittently after being replaced by Donkey Kong and Wario respectively in \"Mario Kart 64\".\nTracks.\nThe tracks in \"Super Mario Kart\" are based on locations in \"Super Mario World\" such as Donut Plains. Each of the four cups contains five different tracks for a total of twenty unique tracks, additionally there are four unique Battle Mode courses. The course outlines are marked out by impassable barriers and feature a variety of bends ranging from sharp hairpins to wide curves which players can power slide around. Numerous obstacles themed from the \"Mario\" series appear, such as Thwomps in the Bowser's Castle tracks, the Cheep-Cheeps from \"Super Mario World\" in Koopa Beach and pipe barriers which are found in the Mario Circuit tracks. Other features include off-road sections which slow down the karts such as the mud bogs in the Choco Island tracks. Each cup track is littered with coins and power-up tiles, as well as turbo tiles which give the karts a boost of speed and jumps which launch the karts into the air.\nThe tracks have received positive commentary, with GameSpy describing them as wonderfully designed and \"IGN\" calling them perfect. When naming its top five \"Mario Kart\" tracks of all time in 2008, \"1UP.com\" named Battle Mode Course 4 at number three and Rainbow Road \u2013 along with its subsequent versions in the series \u2013 at number one. The track themes in \"Super Mario Kart\" influenced later games in the series; recurring themes that first appeared in \"Super Mario Kart\" include haunted tracks, Bowser's Castle and Rainbow Road. Some of the tracks from \"Super Mario Kart\" have reappeared in later games, including the Game Boy Advance title \"\", which features all twenty tracks as an unlockable extra feature.\nDevelopment.\n\"Super Mario Kart\" was produced by \"Mario\" creator Shigeru Miyamoto and directed by Tadashi Sugiyama and Hideki Konno. The development team set out to produce a racing game capable of displaying two players on the same game screen simultaneously, in contrast to the single-player gameplay \"F-Zero\". This led to simpler tracks than those of \"F-Zero\". \"Computer and Video Games\" suggest that this initial emphasis on creating a two player experience is the reason for the game's horizontal split-screen during single-player. Battle Mode was developed from the desire to create a one-on-one mode where victory was not determined simply by competing for rank. Masato Kimura, who worked on \"F-Zero\", served as the lead programmer for \"Super Mario Kart\".\nThe game did not start out as a \"Mario\" series game and the first prototype featured a generic kart racer character; the team decided that characters three heads tall would best suit the design of the karts. They did not decide to incorporate \"Mario\" characters until a few months into development. The choice was made after the development team observed how one kart looked to another driving past it, decided to see what it would look like with Mario in the kart. Thinking that having Mario in the kart looked better than previous designs, the idea of a Mario themed racing game was born.\nNotable in the development of \"Super Mario Kart\" was its use of Mode 7 graphics. First seen in \"F-Zero\", Mode 7 is a form of texture mapping available on the SNES which allows a plane to be rotated and scaled freely, achieving a pseudo-three-dimensional appearance. \"1UP.com\" have credited the use of Mode 7 with giving the game graphics which at the time of release were considered to be \"breathtaking\". Retrospective reflection on the Mode 7 visuals was mixed, with \"IGN\" stating that the once revolutionary technology now looks \"crude and flickery\". \"Super Mario Kart\" featured a DSP (Digital Signal Processor) chip; DSPs were used in SNES games as they provided a better handling of floating point calculations to assist with three-dimensional maths. The DSP-1 chip that was used in \"Super Mario Kart\" went on to be the most popular DSP chip to be used in SNES games. The music for the game was created by composer Soyo Oka, who previously composed games for Nintendo such as \"Pilotwings\" and \"Ice Hockey\".\nReception.\n\"Super Mario Kart\" received critical acclaim and proved to be a commercial success; it received a Player's Choice release after selling one million copies and went on to sell 8.76 million copies worldwide, becoming the fourth best-selling game ever for the SNES. In Japan, it was the top-selling game in September 1992 and became a multi-million seller in 1992, eventually selling a total of 3.82 million in Japan. In Europe, it was the top-selling game during the first quarter of 1993, above the Sega Mega Drive titles \"Sonic the Hedgehog 2\" and \"Streets of Rage 2\" during the same period. In the United Kingdom, \"Super Mario Kart\" was the top-selling Super NES game in February 1993, and it went on to be the seventh best-selling game of 1993 with more than 250,000 sales in the country.\nAggregate scoring sites GameRankings and MobyGames both give an average of more than 90\u00a0percent. Critics praised the game's Mode 7 graphics. Another aspect of the game to have been praised is its gameplay, which \"Thunderbolt\" has described as the \"deepest [and] most addictive... to be found on the SNES console\". Retrospective reviews of the game have been positive with perfect scores given by review sites including \"Thunderbolt\" and \"HonestGamers\". The use of the style and characters from the \"Mario\" franchise was also praised as well as the individual characteristics of each racer. \"Mean Machines\" described the game as having \"struck gold\" in a way that no other \u2013 not even its sequels \u2013 has matched and \"GameSpot\" named the game as one of the greatest games of all time for its innovation, gameplay and visual style. \"Entertainment Weekly\" wrote that although the game might appear to be a \"cynical attempt by Nintendo to cash in on its \"Super Mario\" franchise\" the review concluded that \"plunking the familiar characters down in souped-up go-carts actually makes for a delightful racing game.\" \"GamePro\" said the game \"does an excellent job of capturing the thrill of Go-cart racing, and wraps it up in the familiar, fun, \"Mario\"-land atmosphere.\" The reviewer also praised the use of Mode 7 and challenging CPU-controlled opponents.\n\"Super Mario Kart\" has been listed among the best games ever made several times. In 1995, \"Total!\" rated the game 16th on its \"Top 100 SNES Games.\" In 1996, \"Next Generation\" listed it as number 37 on their \"Top 100 Games of All Time\", commenting that the controls are elegantly designed to offer \"supreme fun\". In 1996, \"GamesMaster\" ranked the game 16th on their \"Top 100 Games of All Time\". In 1999, \"Next Generation\" listed \"Super Mario Kart\" as number 7 on their \"Top 50 Games of All Time\", commenting that, \"Imitated a thousand times, but never, ever, equalled, \"Mario Kart\" changed the rules for the driving game and gave the world one of the most engrossing and addictive two-player experiences ever\". \"Electronic Gaming Monthly\" ranked it as the 15th best console video game of all time, attributing its higher ranking than \"Mario Kart 64\" (which came in 49th) to its superior track design and powerups. \"IGN\" ranked it as the 15th best game ever in 2005, describing it as \"the original karting masterpiece\" and as the 23rd best game ever in 2007, discussing its originality at time of release. \"The Age\" placed it at number 19 on their list of the 50 best games in 2005 and in 2007 \"Edge\" ranked \"Super Mario Kart\" at number 14 on a list of their 100 best games, noting its continued influence on video game design. The game is included in \"Yahoo Games UK\"'s list of the hundred greatest games of all time which praises the appealing characters and power ups and \"1UP.com\"'s \"Essential 50\", a list of the fifty most important games ever made. The game placed 13th in \"Official Nintendo Magazine\"'s 100 greatest Nintendo games of all time. \"Guinness World Records\" ranked it at number 1 on a list of the top 50 console games of all time based on initial impact and lasting legacy. \"Game Informer\" ranked the game at 35 on their top 100 games of all time in 2001 praising how the game's Mode 7 revolutionized racing games. In 2018, \"Complex\" listed \"Super Mario Kart\" seventh on its \"The Best Super Nintendo Games of All Time\". In 2019, The Strong National Museum of Play inducted \"Super Mario Kart\" to its World Video Game Hall of Fame.\nLegacy.\n\"Super Mario Kart\" has been credited with inventing the \"kart racing\" subgenre of video gaming; after its release, several other developers attempted to duplicate its success. In 1994, less than two years after the release of \"Super Mario Kart\", Sega released \"Sonic Drift\"; a kart racing game featuring characters from the \"Sonic the Hedgehog\" series. Also in 1994, Ubisoft released \"Street Racer\", a kart racing game for the SNES and Mega Drive/Genesis which included a four player mode not present in \"Super Mario Kart\". Apogee Software released \"Wacky Wheels\" for PC and Atari Corporation released \"Atari Karts\" for the Atari Jaguar in 1995. Future games that followed in the mould of \"Super Mario Kart\" include \"South Park Rally\", \"Konami Krazy Racers\", \"Diddy Kong Racing\", \"Sonic &amp; Sega All-Stars Racing\" and several racing games in the \"Crash Bandicoot\" series. Response to the karting games released since \"Super Mario Kart\" has been mixed, with \"GameSpot\" describing them as tending to be bad while \"1UP.com\" notes that countless developers have tried to improve upon the \"Mario Kart\" formula without success.\n\"Super Mario Kart\" is credited as being the first non-platforming game to feature multiple playable characters from the \"Mario\" franchise. As well as several sequels Nintendo has released numerous other sporting and non-sporting Mario spin-offs since \"Super Mario Kart\"; a trend in part accredited to the commercial and critical success of the game. The \"Mario\" characters have appeared in many sports games including those relating to basketball, baseball, golf, tennis, and association football (soccer). Non-sporting franchises using the \"Mario\" characters have been created, including the \"Super Smash Bros.\" series of fighting games and the \"Mario Party\" series of board game-based party games. \"Mario\" series characters have made cameos in games from other series such as \"SSX on Tour\" and \"NBA Street V3\", both published by EA Sports. The genre-spanning nature of the \"Mario\" series that was sparked off by the success of \"Super Mario Kart\" has been described as key to the success and longevity of the franchise; keeping people interested despite the infrequency of traditional \"Mario\" platforming games. Following this model the \"Mario\" series has gone on to become the best selling video game franchise of all time with 193 million units sold as of January 2007, almost 40 million units ahead of second-ranked franchise \"Pok\u00e9mon\", also by Nintendo.\n\"Super Mario Kart\" was re-released on the Japanese Virtual Console on June 9, 2009, and later in North America on November 23, 2009. Previously, when naming it as one of the most wanted games for the platform in November 2008, \"Eurogamer\" stated that problems emulating the Mode 7 graphics were responsible for its absence.\nThe game was released for the Wii U Virtual Console in Japan during June 2013, and in Europe on March 27, 2014. In addition, North American users were able to get the game starting from August 6, 2014 to celebrate the 22nd anniversary of the game, which included the new game update of \"Mario Kart 8\" on August 27, 2014.\nIn 2016, the game was re-released for the New Nintendo 3DS.\nNintendo re-released \"Super Mario Kart\" in 2017 as part of the company's Super NES Classic Edition.\n\"Super Mario 3D World\" has a stage with a look based on the Mario Circuit racetracks from \"Super Mario Kart\". A remixed version of the music can be heard. \"Super Mario Odyssey\" has a remix, when racing an RC car around a track in New Donk City in the Metro Kingdom.\nSeveral future \"Mario Kart\" games contain re-imaginings of courses from \"Super Mario Kart\". \"\" contains all of them, though they need to be unlocked. \"Mario Kart DS\" contains remakes of the Mario Circuit 1, Donut Plains 1, Koopa Beach 2, and Choco Island 2 courses. \"Mario Kart Wii\" has remakes of the Ghost Valley 2 and Mario Circuit 3 courses. \"Mario Kart 7\" has remakes of the Mario Circuit 2 and Rainbow Road courses. \"Mario Kart 8\" has remakes of the Donut Plains 3 and Rainbow Road courses, though the latter is only available as downloadable content in the original release. The enhanced Nintendo Switch port of \"Mario Kart 8\", \"Mario Kart 8 Deluxe\", later added remakes of the Mario Circuit 3 and Bowser Castle 3 courses as downloadable content.\nSequels.\nSeveral sequels to \"Super Mario Kart\" have been released for successive generations of Nintendo consoles, each receiving commercial success and critical acclaim. While some elements have developed throughout the series, the core experience from \"Super Mario Kart\" has remained intact. The first sequel, \"Mario Kart 64\", was released in 1996 for the Nintendo 64 and was the first \"Mario Kart\" game to feature fully 3D graphics. Although reviewers including \"IGN\" and \"GameSpot\" felt that the single-player gameplay was lacking compared to its predecessor, the simultaneous four-person multiplayer modes \u2013 a first for the Nintendo 64 \u2013 were praised. The second sequel, ', was released for the Game Boy Advance in 2001. It was described by \"GameSpot\" as more of a remake of \"Super Mario Kart\" than a sequel to \"Mario Kart 64\" and featured a return to the graphical style of the original. As well as featuring new tracks, players are able to unlock the original SNES tracks if certain achievements are completed. ' was released for the GameCube in 2003. Unlike any other \"Mario Kart\" game before or since, it features two riders in each kart, allowing for a new form of cooperative multiplayer where one player controls the kart's movement and the other fires weapons. \"Mario Kart DS\", released for the Nintendo DS in 2005, was the first \"Mario Kart\" game to include online play via the Nintendo Wi-Fi Connection. It went on to become the best selling handheld racing game of all time, selling 7.83 million units. The game marks the debut of tracks appearing in previous games. \"Mario Kart Wii\" was released for the Wii in 2008 and incorporates motion controls and 12-player racing. Like \"Mario Kart DS\", it includes online play; it allows racers to play as user-created Miis (after unlocking the Mii character) as well as \"Mario\" series characters and comes packaged with the Wii Wheel peripheral, which can act as the game's primary control mechanism when coupled with a Wii Remote. \"Mario Kart Wii\" went on to be the worldwide best-selling game of 2008. \"Mario Kart 7\" for the Nintendo 3DS was released in 2011, which features racing on land, sea, and air. \"Mario Kart 7\" added the ability to customize the kart and to race in first-person mode. Three \"Mario Kart\" arcade games have been released, \"Mario Kart Arcade GP\" in 2005, \"Mario Kart Arcade GP 2\" in 2007, and \"Mario Kart Arcade GP DX\" in 2013. All of them were developed jointly by Nintendo and Namco and feature Namco characters including Pac-Man and Blinky. The most recent entry in the series is \"Mario Kart 8\" for the Wii U, which was released at the end of May 2014, which brings back gliders and propellers from \"Mario Kart 7\" as well as 12-player racing in \"Mario Kart Wii\". \"Mario Kart 8\" includes a new feature called Mario Kart TV, where players can watch highlights of previous races and uploading them to YouTube. Another new feature is anti-gravity racing, where players can race on walls and ceilings. An enhanced port, \"Mario Kart 8 Deluxe\", was released on the Nintendo Switch on April 28, 2017. The game keeps most elements from the Wii U version, while adding more characters, kart parts, battle modes, and battle stages. The port received universal critical acclaim, and has sold over 61 million copies as of March 2024, becoming the best selling game for the console. Furthermore, the number of copies sold exceeded that of \"Super Mario Bros.\", released on the Nintendo Entertainment System, making it the first \"Mario\" title to outsell a previous instalment.\nAs the series has progressed, many aspects included in \"Super Mario Kart\" have been developed and altered. The power-up boxes which are flat against the track in \"Super Mario Kart\" due to the technical limitations of the SNES became floating boxes in later games. The roster of racers has expanded in recent games to include a greater selection of Nintendo characters including some which had not been created at the time of \"Super Mario Kart\"'s release \u2013 such as Petey Piranha from \"Super Mario Sunshine\" who appeared in \"Mario Kart: Double Dash!!\". Multiplayer has remained a key feature of the series and has expanded from the two-player modes available in \"Super Mario Kart\": first to allow up to four simultaneous players in split-screen in \"Mario Kart 64\"; then leveraging the GameCube's LAN Adapter for up to sixteen players in \"Mario Kart Double Dash!!\"; and eventually supporting up to twelve simultaneous online players in \"Mario Kart Wii\". Many of the track themes have been retained throughout the series, including Rainbow Road \u2013 the final track of the Special Cup \u2013 which has appeared in every \"Mario Kart\" console game. Other features present in \"Super Mario Kart\" have disappeared from the series. These include the \"superpowers\" of the computer characters, the feather power-up which allows players to jump high into the air and having a restricted number of lives. The only other \"Mario Kart\" games to feature the coin collecting of the original are \"Mario Kart: Super Circuit\", \"Mario Kart 7\", and \"Mario Kart 8\". The aspects of style and gameplay from \"Super Mario Kart\" that have been retained throughout the series have led Nintendo to face criticism for a lack of originality but the franchise is still considered to be a beloved household name by many, known for its familiar core gameplay.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27802", "revid": "892079", "url": "https://en.wikipedia.org/wiki?curid=27802", "title": "Seymour Papert", "text": "American computer scientist (1928\u20132016)\nSeymour Aubrey Papert (; 29 February 1928\u00a0\u2013 31 July 2016) was a South African-born American mathematician, computer scientist, and educator, who spent most of his career teaching and researching at the Massachusetts Institute of Technology. He was one of the pioneers of artificial intelligence, and of the constructionist movement in education. He was co-inventor, with Wally Feurzeig and Cynthia Solomon, of the Logo programming language.\nEarly years and education.\nBorn to a Jewish family, Papert attended the University of the Witwatersrand, receiving a Bachelor of Arts degree in philosophy in 1949 followed by a PhD in mathematics in 1952. He then went on to receive a second doctorate, also in mathematics, at the University of Cambridge (1959), supervised by Frank Smithies.\nCareer.\nPapert worked as a researcher in a variety of places, including St. John's College, Cambridge, the Henri Poincar\u00e9 Institute at the University of Paris, the University of Geneva, and the National Physical Laboratory in London before becoming a research associate at MIT in 1963. He held this position until 1967, when he became professor of applied math and was made co-director of the MIT Artificial Intelligence Laboratory by its founding director Professor Marvin Minsky, until 1981; he also served as Cecil and Ida Green professor of education at MIT from 1974 to 1981.\nResearch.\nPapert worked on learning theories, and was known for focusing on the impact of new technologies on learning in general, and in schools as learning organizations in particular.\nConstructionism.\nAt MIT, Papert went on to create the Epistemology and Learning Research Group at the MIT Architecture Machine Group which later became the MIT Media Lab. Here, he was the developer of a theory on learning called constructionism, built upon the work of Jean Piaget in constructivist learning theories. Papert had worked with Piaget at the University of Geneva from 1958 to 1963 and was one of Piaget's prot\u00e9g\u00e9s; Piaget himself once said that \"no one understands my ideas as well as Papert\". Papert has rethought how schools should work, based on these theories of learning.\nLogo.\nPapert used Piaget's work in his development of the Logo programming language while at MIT. He created Logo as a tool to improve the way children think and solve problems. A small mobile robot called the \"Logo Turtle\" was developed, and children were shown how to use it to solve simple problems in an environment of play. A main purpose of the Logo Foundation research group is to strengthen the ability to learn knowledge. Papert insisted a simple language or program that children can learn\u2014like Logo\u2014can also have advanced functionality for expert users.\nOther work.\nAs part of his work with technology, Papert has been a proponent of the Knowledge Machine. He was one of the principals for the One Laptop Per Child initiative to manufacture and distribute The Children's Machine in developing nations.\nPapert also collaborated with the construction toy manufacturer Lego on their Logo-programmable Lego Mindstorms robotics kits, which were named after his groundbreaking 1980 book.\nA curated archive of Papert's articles, speeches, and interviews may be found on a website dedicated to Papert at: The Daily Papert.\nPersonal life.\nPapert became a political and anti-apartheid activist early in his life in South Africa. He subsequently chose self exile. He was a leading figure in the revolutionary socialist circle around \"Socialist Review\" while living in London in the 1950s. Papert was also a prominent activist against South African apartheid policies during his university education.\nPapert was married to Dona Strauss, and later to Androula Christofides Henriques.\nPapert's third wife was MIT professor Sherry Turkle, and together they wrote the influential paper \"Epistemological Pluralism and the Revaluation of the Concrete\".\nIn his final 24 years, Papert was married to Suzanne Massie, who was a Russian scholar and author of \"Pavlovsk: The Life of a Russian Palace\" and \"Land of the Firebird\".\nAccident in Hanoi.\nPapert (then aged 78), received a serious brain injury when struck by a motor scooter on 5 December 2006 while crossing the street with colleague Uri Wilensky when they were both attending the 17th International Commission on Mathematical Instruction (ICMI) Study conference in Hanoi, Vietnam. He underwent emergency surgery to remove a blood clot at the French Hospital of Hanoi before being transferred in a complex operation by Swiss Air Ambulance https:// ) Bombardier Challenger Jet to Boston, Massachusetts, where he spent approximately four weeks in intensive care. He was moved to a hospital closer to his home in January 2007, but then developed sepsis which damaged a heart valve, which was later replaced.\nBy 2008 he had returned home, could think and communicate clearly and walk \"almost unaided\", but still had \"some complicated speech problems\" and was in receipt of extensive rehabilitation support. His rehabilitation team used some of the very principles of experiential, hands-on learning that he had pioneered.\nPapert died at his home in Blue Hill, Maine, on 31 July 2016.\nAwards, honours, and legacy.\nPapert's work has been used by other researchers in the fields of education and computer science. He influenced the work of Uri Wilensky in the design of NetLogo and collaborated with him on the study of knowledge restructurations, as well as the work of Andrea diSessa and the development of \"dynaturtles\". In 1981, Papert along with several others in the Logo group at MIT, started Logo Computer Systems Inc. (LCSI), of which he was board chair for over 20 years. Working with LCSI, Papert designed a number of award-winning programs, including LogoWriter and Lego/Logo (marketed as Lego Mindstorms). He also influenced the research of Idit Harel Caperton, coauthoring articles and the book \"Constructionism\", and chairing the advisory board of the company MaMaMedia. He also influenced Alan Kay and the Dynabook concept, and worked with Kay on various projects.\nPapert won a Guggenheim fellowship in 1980, a Marconi International fellowship in 1981, the Software Publishers Association Lifetime Achievement Award in 1994, and the Smithsonian Award from \"Computerworld\" in 1997. Papert has been called by Marvin Minsky \"the greatest of all living education theorists\".\nMIT President L. Rafael Reif summarized Papert's lifetime of accomplishments: \"With a mind of extraordinary range and creativity, Seymour Papert helped revolutionize at least three fields, from the study of how children make sense of the world, to the development of artificial intelligence, to the rich intersection of technology and learning. The stamp he left on MIT is profound. Today, as MIT continues to expand its reach and deepen its work in digital learning, I am particularly grateful for Seymour's groundbreaking vision, and we hope to build on his ideas to open doors to learners of all ages, around the world.\"\nIn 2016 Papert's alma mater, University of Witwatersrand, awarded him the degree of \"Doctor of Science in Engineering, honoris causa\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27804", "revid": "30681431", "url": "https://en.wikipedia.org/wiki?curid=27804", "title": "Search engine (computing)", "text": "System to help searching for information\nIn computing, a search engine is an information retrieval software system designed to help find information stored on one or more computer systems. Search engines discover, crawl, transform, and store information for retrieval and presentation in response to user queries. The search results are usually presented in a list and are commonly called \"hits\". The most widely used type of search engine is a web search engine, which searches for information on the World Wide Web.\nA search engine normally consists of four components, as follows: a search interface, a crawler (also known as a spider or bot), an indexer, and a database. The crawler traverses a document collection, deconstructs document text, and assigns surrogates for storage in the search engine index. Online search engines store images, link data and metadata for the document.\nHow search engines work.\nSearch engines provide an interface to a group of items that enables users to specify criteria about an item of interest and have the engine find the matching items. The criteria are referred to as a search query. In the case of text search engines, the search query is typically expressed as a set of words that identify the desired concept that one or more documents may contain. There are several styles of search query syntax that vary in strictness. It can also switch names within the search engines from previous sites. Whereas some text search engines require users to enter two or three words separated by white space, other search engines may enable users to specify entire documents, pictures, sounds, and various forms of natural language. Some search engines apply improvements to search queries to increase the likelihood of providing a quality set of items through a process known as query expansion. Query understanding methods can be used as standardized query language.\nThe list of items that meet the criteria specified by the query is typically sorted, or ranked. Ranking items by relevance (from highest to lowest) reduces the time required to find the desired information. Probabilistic search engines rank items based on measures of similarity (between each item and the query, typically on a scale of 1 to 0, 1 being most similar) and sometimes popularity or authority (see Bibliometrics) or use relevance feedback. Boolean search engines typically only return items which match exactly without regard to order, although the term \"Boolean search engine\" may simply refer to the use of Boolean-style syntax (the use of operators AND, OR, NOT, and XOR) in a probabilistic context.\nTo provide a set of matching items that are sorted according to some criteria quickly, a search engine will typically collect metadata about the group of items under consideration beforehand through a process referred to as indexing. The index typically requires a smaller amount of computer storage, which is why some search engines only store the indexed information and not the full content of each item, and instead provide a method of navigating to the items in the search engine result page. Alternatively, the search engine may store a copy of each item in a cache so that users can see the state of the item at the time it was indexed or for archive purposes or to make repetitive processes work more efficiently and quickly.\nOther types of search engines do not store an index. Crawler, or spider type search engines (a.k.a. real-time search engines) may collect and assess items at the time of the search query, dynamically considering additional items based on the contents of a starting item (known as a seed, or seed URL in the case of an Internet crawler). Meta search engines store neither an index nor a cache and instead simply reuse the index or results of one or more other search engine to provide an aggregated, final set of results.\nDatabase size, which had been a significant marketing feature through the early 2000s, was similarly displaced by emphasis on relevancy ranking, the methods by which search engines attempt to sort the best results first. Relevancy ranking first became a major issue c.\u20091996, when it became apparent that it was impractical to review full lists of results. Consequently, algorithms for relevancy ranking have continuously improved. Google's PageRank method for ordering the results has received the most press, but all major search engines continually refine their ranking methodologies with a view toward improving the ordering of results. As of 2006, search engine rankings are more important than ever, so much so that an industry has developed (\"search engine optimizers\", or \"SEO\") to help web-developers improve their search ranking, and an entire body of case law has developed around matters that affect search engine rankings, such as use of trademarks in metatags. The sale of search rankings by some search engines has also created controversy among librarians and consumer advocates.\nSearch engine experience for users continues to be enhanced. Google's addition of the Google Knowledge Graph has had wider ramifications for the Internet, possibly even limiting certain websites traffic, for example Wikipedia. By pulling information and presenting it on Google's page, some argue that it can negatively affect other sites. However, there have been no major concerns.\nSearch engine categories.\nWeb search engines.\nSearch engines that are expressly designed for searching web pages, documents, and images were developed to facilitate searching through a large, nebulous blob of unstructured resources. They are engineered to follow a multi-stage process: crawling the infinite stockpile of pages and documents to skim the figurative foam from their contents, indexing the foam/buzzwords in a sort of semi-structured form (database or something), and at last, resolving user entries/queries to return mostly relevant results and links to those skimmed documents or pages from the inventory.\nCrawl.\nIn the case of a wholly textual search, the first step in classifying web pages is to find an \u2018index item\u2019 that might relate expressly to the \u2018search term.\u2019 In the past, search engines began with a small list of URLs as a so-called seed list, fetched the content, and parsed the links on those pages for relevant information, which subsequently provided new links. The process was highly cyclical and continued until enough pages were found for the searcher's use.\nThese days, a continuous crawl method is employed as opposed to an incidental discovery based on a seed list. The crawl method is an extension of aforementioned discovery method.\nMost search engines use sophisticated scheduling algorithms to \u201cdecide\u201d when to revisit a particular page, to appeal to its relevance. These algorithms range from constant visit-interval with higher priority for more frequently changing pages to adaptive visit-interval based on several criteria such as frequency of change, popularity, and overall quality of site. The speed of the web server running the page as well as resource constraints like amount of hardware or bandwidth also figure in.\nLink map.\nPages that are discovered by web crawls are often distributed and fed into another computer that creates a map of resources uncovered. The bunchy clustermass looks a little like a graph, on which the different pages are represented as small nodes that are connected by links between the pages. \nThe excess of data is stored in multiple data structures that permit quick access to said data by certain algorithms that compute the popularity score of pages on the web based on how many links point to a certain web page, which is how people can access any number of resources concerned with diagnosing psychosis. Another example would be the accessibility/rank of web pages containing information on Mohamed Morsi versus the very best attractions to visit in Cairo after simply entering \u2018Egypt\u2019 as a search term. One such algorithm, PageRank, proposed by Google founders Larry Page and Sergey Brin, is well known and has attracted a lot of attention because it highlights repeat mundanity of web searches courtesy of students that don't know how to properly research subjects on Google. \nThe idea of doing link analysis to compute a popularity rank is older than PageRank. However, In October 2014, Google\u2019s John Mueller confirmed that Google is not going to be updating it (Page Rank) going forward. Other variants of the same idea are currently in use \u2013 grade schoolers do the same sort of computations in picking kickball teams. These ideas can be categorized into three main categories: rank of individual pages and nature of web site content. Search engines often differentiate between internal links and external links, because web content creators are not strangers to shameless self-promotion. Link map data structures typically store the anchor text embedded in the links as well, because anchor text can often provide a \u201cvery good quality\u201d summary of a web page's content.\nDatabase Search Engines.\nSearching for text-based content in databases presents a few special challenges from which a number of specialized search engines flourish. Databases can be slow when solving complex queries (with multiple logical or string matching arguments). Databases allow pseudo-logical queries which full-text searches do not use. There is no crawling necessary for a database since the data is already structured. However, it is often necessary to index the data in a more economized form to allow a more expeditious search.\nMixed Search Engines.\nSometimes, data searched contains both database content and web pages or documents. Search engine technology has developed to respond to both sets of requirements. Most mixed search engines are large Web search engines, like Google. They search both through structured and unstructured data sources. Take for example, the word \u2018ball.\u2019 In its simplest terms, it returns more than 40 variations on Wikipedia alone. Did you mean a ball, as in the social gathering/dance? A soccer ball? The ball of the foot? Pages and documents are crawled and indexed in a separate index. Databases are indexed also from various sources. Search results are then generated for users by querying these multiple indices in parallel and compounding the results according to \u201crules.\u201d\nHistory of search technology.\nThe Memex.\nThe concept of hypertext and a memory extension originates from an article that was published in \"The Atlantic Monthly\" in July 1945 written by Vannevar Bush, titled \"As We May Think\". Within this article Vannevar urged scientists to work together to help build a body of knowledge for all mankind. He then proposed the idea of a virtually limitless, fast, reliable, extensible, associative memory storage and retrieval system. He named this device a memex.\nBush regarded the notion of \u201cassociative indexing\u201d as his key conceptual contribution. As he explained, this was \u201ca provision whereby any item may be caused at will to select immediately and automatically another. This is the essential feature of the memex. The process of tying two items together is the important thing.\nAll of the documents used in the memex would be in the form of microfilm copy acquired as such or, in the case of personal records, transformed to microfilm by the machine itself. Memex would also employ new retrieval techniques based on a new kind of associative indexing the basic idea of which is a provision whereby any item may be caused at will to select immediately and automatically another to create personal \"trails\" through linked documents. The new procedures, that Bush anticipated facilitating information storage and retrieval would lead to the development of wholly new forms of the encyclopedia.\nThe most important mechanism, conceived by Bush, is the associative trail. It would be a way to create a new linear sequence of microfilm frames across any arbitrary sequence of microfilm frames by creating a chained sequence of links in the way just described, along with personal comments and side trails.\nIn 1965, Bush took part in the project INTREX of MIT, for developing technology for mechanization the processing of information for library use. In his 1967 essay titled \"Memex Revisited\", he pointed out that the development of the digital computer, the transistor, the video, and other similar devices had heightened the feasibility of such mechanization, but costs would delay its achievements.\nSMART.\nGerard Salton, who died on August 28 of 1995, was the father of modern search technology. His teams at Harvard and Cornell developed the SMART informational retrieval system. Salton's Magic Automatic Retriever of Text included important concepts like the vector space model, Inverse Document Frequency (IDF), Term Frequency (TF), term discrimination values, and relevancy feedback mechanisms.\nHe authored a 56-page book called \"A Theory of Indexing\" which explained many of his tests, upon which search is still largely based.\nString Search Engines.\nIn 1987, an article was published detailing the development of a character string search engine (SSE) for rapid text retrieval on a double-metal 1.6-\u03bcm n-well CMOS solid-state circuit with 217,600 transistors lain out on a 8.62x12.76-mm die area. The SSE accommodated a novel string-search architecture which combines a 512-stage finite-state automaton (FSA) logic with a content addressable memory (CAM) to achieve an approximate string comparison of 80 million strings per second. The CAM cell consisted of four conventional static RAM (SRAM) cells and a read/write circuit. Concurrent comparison of 64 stored strings with variable length was achieved in 50 ns for an input text stream of 10 million characters/s, permitting performance despite the presence of single character errors in the form of character codes. Furthermore, the chip allowed nonanchor string search and variable-length `don't care' (VLDC) string search.\nSee also.\nOthers.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27805", "revid": "50970080", "url": "https://en.wikipedia.org/wiki?curid=27805", "title": "Spaced repetition", "text": "Learning technique performed with flashcards\nSpaced repetition is an evidence-based learning technique that is usually performed with flashcards. Newly introduced and more difficult flashcards are shown more frequently, while older and less difficult flashcards are shown less frequently in order to exploit the psychological spacing effect. The use of spaced repetition has been proven to increase the rate of learning.\nAlthough the principle is useful in many contexts, spaced repetition is commonly applied in contexts in which a learner must acquire many items and retain them indefinitely in memory. It is, therefore, well suited for the problem of vocabulary acquisition in the course of second-language learning. A number of spaced repetition software programs have been developed to aid the learning process. It is also possible to perform spaced repetition with physical flashcards using the Leitner system. The testing effect and spaced repetition can be combined to improve long-term memory. Therefore, memorization can be easier to do.\nHistory.\nThe method of spaced repetition was first conceived of in the 1880s by German scientist Hermann Ebbinghaus. Ebbinghaus created the 'forgetting curve'\u2014a graph portraying the loss of learned information over time\u2014and postulated that it can be curbed by reviewing such information at several intervals over a period of time.\nIt was also tested by Thomas Landauer and Robert A. Bjork in 1978; they gathered a group of psychology students, showing the students pictures of a certain individual followed by that individual's name. This is also known as a face-name association. With the repetition of seeing the person's name and face they were able to associate the name and face of that individual shown with the expansion of time due to the spaced repetition.\nSchacter, Rich, and Stampp in 1985 expanded the research to include people who have amnesia and other memory disorders. The findings showed that using spaced repetition can not only help students with name face association but patients dealing with memory impairments.\nIn 1989, C.\u00a0J. Camp decided that using this technique with Alzheimer's patients may increase their duration of remembering particular things. These results show that the expansion of the time interval shows the strongest benefits for memory.\nSpaced repetition is a method where the subject is asked to remember a certain fact with the time intervals increasing each time the fact is presented or said. If the subject is able to recall the information correctly the time is doubled to further help them keep the information fresh in their mind to recall in the future. With this method, the patient is able to place the information in their long-term memory. If they are unable to remember the information they go back to the previous step and continue to practice to help make the technique lasting (Vance &amp; Farr, 2007).\nThe expansion is done to ensure a high success level of recalling the information on the first time and increasing the time interval to make the information long-lasting to help keep the information always accessible in their mind.\nThroughout the development of spaced repetition, they have found that patients using this technique with dementia are able to recall the information weeks\u2014even months\u2014later. The technique has been successful in helping dementia patients remember particular objects' names, daily tasks, name face association, information about themselves, and many other facts and behaviors (Small, 2012). Sufficient test evidence shows that spaced repetition is valuable in learning new information and recalling information from the past.\nSmall combines the works and findings of quite a few scientists to come up with five reasons why spaced repetition works: it helps show the relationship of routine memories, it shows the benefits of learning things with an expansion of time, it helps the patient with Alzheimer's dementia keep their brain active, it has a high success level with little to no errors, and the technique is meaningful for the patient to do and remember more things) Joltin et al. (2003), had a caregiver train a woman with Alzheimer's by giving her the name of her grandchild over the phone while asking her to associate with the picture of the grandchild posted on the refrigerator. After training, the woman was able to recall the name of her grandchild five days later.\nResearch and application.\nThe notion that spaced repetition could be used for improving learning was first proposed in the book \"Psychology of Study\" by C. A. Mace in 1932: \"Perhaps the most important discoveries are those which relate to the appropriate distribution of the periods of study... Acts of revision should be spaced in gradually increasing intervals, roughly intervals of one day, two days, four days, eight days, and so on.\"\nIn 1939, H. F. Spitzer tested the effects of a type of spaced repetition on sixth-grade students in Iowa who were learning science facts. Spitzer tested over 3600 students in Iowa and showed that spaced repetition was effective. This early work went unnoticed, and the field was relatively quiet until the late 1960s when cognitive psychologists, including Melton and Landauer and Bjork, explored manipulation of repetition timing as a means to improve recall. Around the same time, Pimsleur language courses pioneered the practical application of spaced repetition theory to language learning, and in 1973 Sebastian Leitner devised his \"Leitner system\", an all-purpose spaced repetition learning system based on flashcards.\nWith the increase in access to personal computers in the 1980s, spaced repetition began to be implemented with computer-assisted language learning software-based solutions (see ), enabling automated scheduling and statistic gathering, scaling to thousands of cards scheduled individually. To enable the user to reach a target level of achievement (e.g. 90% of all material correctly recalled at any given time point), the software adjusts the repetition spacing interval. Material that is hard appears more often and material that is easy less often, with difficulty defined according to the ease with which the user is able to produce a correct response.\nThe data behind this initial research indicated that an increasing space between rehearsals (expanding) would yield a greater percentage of accuracy at test points. Spaced repetition with expanding intervals is believed to be so effective because with each expanded interval of repetition it becomes more difficult to retrieve the information because of the time elapsed between test periods; this creates a deeper level of processing of the learned information in long-term memory at each point. Another reason that the expanding repetition model is believed to work so effectively is that the first test happens early on in the rehearsal process. The purpose of this is to increase repetition success. By having a first test that followed initial learning with a successful repetition, people are more likely to remember this successful repetition on the following tests. Although expanding retrieval is commonly associated with spaced repetition, a uniform retrieval schedule is also a form of spaced repetition procedure.\nA study conducted by Bui et al. (2013) examined how the advantages of spaced repetition can be influenced by the difference in working memory and the complexity of tasks that occurs between the repetitions. The researchers found participants with a higher working memory benefited from spaced repetition and showed better performance on challenging tasks.\nSpaced repetition is typically studied through the use of memorizing facts. Traditionally speaking, it has not been applied to fields that required some manipulation or thought beyond simple factual/semantic information. A more recent study has shown that spaced repetition can benefit tasks such as solving math problems. In a study conducted by Pashler, Rohrer, Cepeda, and Carpenter, participants had to learn a simple math principle in either a spaced or massed retrieval schedule. The participants given the spaced repetition learning tasks showed higher scores on a final test distributed after their final practice session.\nThis is unique in the sense that it shows spaced repetition can be used to not only remember simple facts or contextual data but it can also be used in fields, such as math, where manipulation and the use of particular principles or formulas (e.g. y = mx + b) is necessary. These researchers also found that it is beneficial for feedback to be applied when administering the tests. When a participant gave a wrong response, they were likely to get it correct on the following tests if the researcher gave them the correct answer after a delayed period.\nBuilding on this, more recent studies have applied spaced repetition to procedural skill acquisition in complex domains. For example, a pilot study in neurosurgery training found that incorporating spaced repetition into a six-week simulation module improved residents\u2019 proficiency in performing complex surgical procedures. Participants who engaged in structured, repeated practice showed significant improvements in objective performance metrics compared to those who trained using traditional methods alone. This suggests that spaced repetition can effectively facilitate the acquisition of procedural knowledge in surgical contexts, including its demonstrated applications in other areas of medical training.\nSpaced repetition is a useful tool for learning that is relevant to many domains such as fact learning, mathematics, and procedural skills, and many different tasks (expanding or uniform retrieval). Many studies over the years have contributed to the use and implementation of spaced repetition, and it still remains a subject of interest for many researchers.\nOver the years, techniques and tests have been formed to better patients with memory difficulties. Spaced repetition is one of these solutions to help better the patients' minds. Spaced repetition is used in many different areas of memory from remembering facts to remembering how to ride a bike to remembering past events from childhood. Recovery practice is used to see if an individual is able to recall something immediately after they have seen or studied it. Increasing recovery practice is frequently used as a technique in improving long-term memory, essentially for young children trying to learn and older individuals with memory diseases.\nAlgorithms.\nThere are several families of spaced repetition algorithms:\nEvidence and criticism.\nSpaced repetition is widely accepted as a performant learning strategy in a number of domains, with many researchers suggesting implementing this method in formal education. There is evidence that the popular method of \"expanding intervals\" (when the interval between the repetitions increases with each repetition) performs as well as or better than uniformly spaced repetitions. Some papers find expanding intervals to be beneficial for recall. Other meta-analyses tend to conclude that both methods yield similar results, therefore concluding that \"strong recommendations to teachers and students in favor of spaced retrieval practice are warranted\". \nSeveral mechanisms were suggested for expanding intervals providing an additional benefit; the most notable one is that one of the core tenets of spaced repetition is that spacing increases the effort for retrieval, and that expanding intervals allow to gradually increase that difficulty. However, little evidence has been found to back this claim. It has been argued that the benefit observed for expanding intervals in some studies is due to other factors, such as the timing of the first retrieval, the number of repetitions or the overall spacing between the tests. It has also been proposed that the best schedule is learner-dependent, making general recommendations irrelevant.\nImplementations.\nSoftware.\nMost spaced repetition software (SRS) is modeled after the manual style of learning with physical flashcards: items to memorize are entered into the program as question-answer pairs. When a pair is due to be reviewed, the question is displayed on a screen, and the user must attempt to answer. After answering, the user manually reveals the answer and then tells the program (subjectively) how difficult answering was. The program schedules pairs based on spaced repetition algorithms. Without a computer program, the user has to schedule physical flashcards; this is time-intensive and limits users to simple algorithms like the Leitner system.\nTo optimize review schedules, developments in spaced repetition algorithms focus on predictive modeling. These algorithms use randomly determined equations to determine the most effective timing for review sessions.\nFurther refinements with regard to software:\nPaper flash cards.\nThe Leitner system is a widely used method of efficiently using flashcards that was proposed by the German science journalist Sebastian Leitner in the 1970s. It is a simple implementation of the principle of spaced repetition, where cards are reviewed at increasing intervals.\nIn this method, flashcards are sorted into groups according to how well the learner knows each one in Leitner's learning box. The learners try to recall the solution written on a flashcard. If they succeed, they send the card to the next group. If they fail, they send it back to the first group. Each succeeding group has a longer period of time before the learner is required to revisit the cards. In Leitner's original method, published in his book \"\" (\"How To Learn To Learn\"), the schedule of repetition was governed by the size of the partitions in the learning box. These were 1, 2, 5, 8 and 14\u00a0cm. Only when a partition became full was the learner to review some of the cards it contained, moving them forward or back, depending on whether they remembered them.\nAudio instruction.\nGraduated-interval recall is a type of spaced repetition published by Paul Pimsleur in 1967. It is used in the Pimsleur language learning system and is particularly suited to programmed audio instruction due to the very short times (measured in seconds or minutes) between the first few repetitions, as compared to other forms of spaced repetition which may not require such precise timings. The intervals published in Pimsleur's paper were: 5 seconds, 25 seconds, 2 minutes, 10 minutes, 1 hour, 5 hours, 1 day, 5 days, 25 days, 4 months, and 2 years.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27806", "revid": "221", "url": "https://en.wikipedia.org/wiki?curid=27806", "title": "SuperMemo", "text": "Spaced repetition memorization/learning software\n \nSuperMemo (from \"Super Memory\") is a learning method and software package developed by SuperMemo World and SuperMemo R&amp;D with Piotr Wo\u017aniak in Poland from 1985 to the present. It is based on research into long-term memory, and is a practical application of the spaced repetition learning method that has been proposed for efficient instruction by a number of psychologists as early as in the 1930s.\nThe method is available as a computer program for Windows, Windows CE, Windows Mobile (Pocket PC), Palm OS (PalmPilot), etc. Course software by the same company (\"SuperMemo World\") can also be used in a web browser or even without a computer.\nThe desktop version of SuperMemo started as a flashcard software (SuperMemo 1.0 (1987)). It has supported incremental reading since SuperMemo 10 (2000).\nSoftware implementation.\nThe SuperMemo program stores a database of questions and answers constructed by the user. When reviewing information saved in the database, the program uses the SuperMemo algorithm to decide what questions to show the user. The user then answers the question and rates their relative ease of recall - with grades of 0 to 5 (0 is the hardest, 5 is the easiest) - and their rating is used to calculate how soon they should be shown the question again. While the exact algorithm varies with the version of SuperMemo, in general, items that are harder to remember show up more frequently.\nBesides simple text questions and answers, the latest version of SuperMemo supports images, video, and HTML questions and answers.\nSince 2000, SuperMemo has had a unique set of features that distinguish it from other spaced repetition programs, called incremental reading (IR or \"increading\"). Whereas earlier versions were built around users entering information they wanted to use, using IR, users can import text that they want to learn from. The user reads the text inside of SuperMemo, and tools are provided to bookmark one's location in the text and automatically schedule it to be revisited later, extract valuable information, and turn extracts into questions for the user to learn. By automating the entire process of reading and extracting knowledge to be remembered all in the same program, time is saved from having to manually prepare information, and insights into the nature of learning can be used to make the entire process more natural for the user. Furthermore, since the process of extracting knowledge can often lead to the extraction of more information than can actually be feasibly remembered, a priority system is implemented that allows the user to ensure that the most important information is remembered when they can't review all information in the system.\nAlgorithms.\nThe specific algorithms SuperMemo uses have been published, and re-implemented in other programs.\nDifferent algorithms have been used; SM-0 refers to the original (non-computer-based) algorithm, while SM-2 refers to the original computer-based algorithm released in 1987 (used in SuperMemo versions 1.0 through 3.0, referred to as SM-2 because SuperMemo version 2 was the most popular of these). Subsequent versions of the software have claimed to further optimize the algorithm.\nPiotr Wo\u017aniak, the developer of SuperMemo algorithms, released the description for SM-5 in a paper titled \"Optimization of repetition spacing in the practice of learning.\" Little detail is specified in the algorithms released later than that.\nIn 1995, SM-8, which capitalized on data collected by users of SuperMemo 6 and SuperMemo 7 and added a number of improvements that strengthened the theoretical validity of the function of optimum intervals and made it possible to accelerate its adaptation, was introduced in SuperMemo 8.\nIn 2002, SM-11, the first SuperMemo algorithm that was resistant to interference from the delay or advancement of repetitions was introduced in SuperMemo 11 (aka SuperMemo 2002). In 2005, SM-11 was tweaked to introduce boundaries on A and B parameters computed from the Grade vs. Forgetting Index data.\nIn 2011, SM-15, which notably eliminated two weaknesses of SM-11 that would show up in heavily overloaded collections with very large item delays, was introduced in Supermemo 15.\nIn 2016, SM-17, the first version of the algorithm to incorporate the two component model of memory, was introduced in SuperMemo 17.\nThe latest version of the SuperMemo algorithm is SM-18, released in 2019.\nDescription of SM-2 algorithm.\nThe first computer-based SuperMemo algorithm (SM-2) tracks three properties for each card being studied:\nEvery time the user starts a review session, SuperMemo provides the user with the cards whose last review occurred at least I days ago. For each review, the user tries to recall the information and (after being shown the correct answer) specifies a grade q (from 0 to 5) indicating a self-evaluation the quality of their response, with each grade having the following meaning:\nThe following algorithm is then applied to update the three variables associated with the card:\n algorithm SM-2 is\n input: user grade \"q\"\n repetition number \"n\"\n easiness factor \"EF\"\n interval \"I\"\n output: updated values of \"n\", \"EF\", and \"I\"\n if \"q\" \u2265 3 \"(correct response)\" then\n if \"n\" = 0 then\n \"I\" \u2190 1\n else if \"n\" = 1 then\n \"I\" \u2190 6\n else\n \"I\" \u2190 round(\"I\" \u00d7 \"EF\")\n end if\n increment \"n\"\n else \"(incorrect response)\"\n \"n\" \u2190 0\n \"I\" \u2190 1\n end if\n \"EF\" \u2190 \"EF\" + (0.1 \u2212 (5 \u2212 \"q\") \u00d7 (0.08 + (5 \u2212 \"q\") \u00d7 0.02))\n if \"EF\" &lt; 1.3 then\n \"EF\" \u2190 1.3\n end if\n return (\"n\", \"EF\", \"I\")\nAfter all scheduled reviews are complete, SuperMemo asks the user to re-review any cards they marked with a grade less than 4 repeatedly until they give a grade \u2265 4.\nNon-SuperMemo implementations.\nSome of the algorithms have been re-implemented in other, often free programs such as Anki, Mnemosyne, and Emacs Org-mode's Org-drill. See full list of flashcard software.\nThe SM-2 algorithm has proven most popular in other applications, and is used (in modified form) in Anki and Mnemosyne, among others. Org-drill implements SM-5 by default, and optionally other algorithms such as SM-2 and a simplified SM-8.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27808", "revid": "30021739", "url": "https://en.wikipedia.org/wiki?curid=27808", "title": "Samuel Pepys", "text": "English writer and politician (1633\u20131703)\nSamuel Pepys ( ; 23 February 1633 \u2013 26 May 1703) was an English writer and Tory politician. He served as an official in the Navy Board and Member of Parliament, but is most remembered today for the diary he kept for almost a decade. Though he had no maritime experience, Pepys rose to be the Chief Secretary to the Admiralty under both Charles II and James II through patronage, diligence, and his talent for administration. His influence and reforms at the English Admiralty were important in the early professionalisation of the Royal Navy.\nThe detailed private diary that Pepys kept from 1660 until 1669 was first published in the 19th\u00a0century and is one of the most important primary sources of the Stuart Restoration. It provides a combination of personal revelation and eyewitness accounts of great events, such as the Great Plague of London, the Second Anglo-Dutch War and the Great Fire of London.\nEarly life.\nPepys was born in Salisbury Court, Fleet Street, London, on 23 February 1633, the son of John Pepys (1601\u20131680), a tailor, and Margaret Pepys (\"n\u00e9e\" Kite; died 1667), daughter of a Whitechapel butcher. His great-uncle Talbot Pepys was Recorder and briefly Member of Parliament (MP) for Cambridge in 1625. His father's first cousin Sir Richard Pepys was elected MP for Sudbury in 1640, appointed Baron of the Exchequer on 30 May 1654, and appointed Lord Chief Justice of Ireland on 25 September 1655.\nPepys was the fifth of 11 children, but child mortality was high and he was soon the eldest survivor. He was baptised at St Bride's Church on 3 March 1633. Pepys did not spend all of his infancy in London; for a while, he was sent to live with nurse Goody Lawrence at Kingsland, just north of the city. In about 1644, Pepys attended Huntingdon Grammar School before being educated at St Paul's School, London, c.\u20091646\u20131650. He attended the execution of Charles I in 1649.\nIn 1650, he went to the University of Cambridge, having received two exhibitions from St Paul's School (perhaps owing to the influence of George Downing, who was chairman of the judges and for whom he later worked at the Exchequer) and a grant from the Mercers' Company. In October, he was admitted as a sizar to Magdalene College; he moved there in March 1651 and took his Bachelor of Arts degree in 1654.\nLater in 1654 or early in 1655, he entered the household of one of his father's cousins, Sir Edward Montagu, who was later created the 1st Earl of Sandwich.\nWhen he was 22, Pepys married 14-year-old Elisabeth de St Michel, a descendant of French Huguenot immigrants, first in a religious ceremony on 10 October 1655 and later in a civil ceremony on 1 December 1655 at St Margaret's, Westminster.\nIllness.\nFrom a young age, Pepys suffered from bladder stones in his urinary tract\u2014a condition from which his mother and brother John also later suffered. He was almost never without pain, as well as other symptoms, including \"blood in the urine\" (haematuria). By the time of his marriage, the condition was very severe.\nIn 1657, Pepys decided to undergo surgery; not an easy option, as the operation was known to be especially painful and hazardous. Nevertheless, Pepys consulted surgeon Thomas Hollier and, on 26 March 1658, the operation took place in a bedroom in the house of Pepys' cousin Jane Turner. Pepys' stone was successfully removed and he resolved to hold a celebration on every anniversary of the operation, which he did for several years. However, there were long-term effects from the operation. The incision on his bladder broke open again late in his life. The procedure may have left him sterile, though there is no direct evidence for this, as he was childless before the operation. In mid-1658 Pepys moved to Axe Yard, near the modern Downing Street. He worked as a teller in the Exchequer under George Downing.\nDiary.\nOn 1 January 1660 (\"1 January 1659/1660\" in contemporary terms), Pepys began to keep a diary. He recorded his daily life for almost 10 years. This record of a decade of Pepys' life in one and a quarter million words and populated by over 3,000 individuals is often regarded as Britain's most celebrated diary. Pepys has been called the greatest diarist of all time due to his frankness in writing concerning his own weaknesses and the accuracy with which he records events of daily British life and major events in the 17th century. Pepys wrote about the contemporary court and theatre (including his amorous affairs with the actresses), his household, and major political and social occurrences. Historians have used his diary to gain greater insight and understanding of life in London in the 17th century. Pepys wrote consistently on subjects such as personal finances, the time he got up in the morning, the weather, and what he ate. He wrote at length about his new watch which he was very proud of (and which had an alarm, a new accessory at the time), a country visitor who did not enjoy his time in London because he felt that it was too crowded, and his cat waking him up at one in the morning. Pepys' diary is one of a very few sources which provides such length in details of everyday life of an upper-middle-class man during the 17th century. The descriptions of the lives of his servants like Jane Birch provide a valuable detailed insight into their lives.\nAside from day-to-day activities, Pepys also commented on the significant and turbulent events of his nation. England was in disarray when he began writing his diary. Oliver Cromwell had died just fifteen months earlier, creating a period of civil unrest and a large power vacuum to be filled. Pepys had been a strong supporter of Cromwell, but he converted to the Royalist cause upon the Protector's death. He was on the ship that returned Charles II to England to take up his throne and gave first-hand accounts of other significant events from the early years of the Restoration, such as the coronation of Charles II, the Great Plague, the Great Fire of London, and the Anglo\u2013Dutch Wars.\nPepys did not plan on his contemporaries ever seeing his diary, which is evident from the fact that he wrote in shorthand and sometimes in a \"code\" of various Spanish, French, and Italian words (especially when describing his illicit affairs). However, Pepys often juxtaposed profanities in his native English amidst his \"code\" of foreign words, a practice which would reveal the details to any casual reader. He did intend for future generations to see the diary, as evidenced by its inclusion in his library and its catalogue before his death along with the shorthand guide he used and the elaborate planning by which he ensured his library survived intact after his death.\nThe women he pursued, his friends, and his dealings are all laid out. His diary reveals his jealousies, insecurities, trivial concerns, and his fractious relationship with his wife. It has been an important account of London in the 1660s. The juxtaposition of his commentary on politics and national events, alongside the very personal, can be seen from the beginning. His opening paragraphs, written in January 1660, begin:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Blessed be God, at the end of the last year I was in very good health, without any sense of my old pain but upon taking of cold. I lived in Axe yard, having my wife and servant Jane, and no more in family than us three. My wife, after the absence of her terms for seven weeks, gave me hopes of her being with child, but on the last day of the year she hath them again.\nThe condition of the State was thus. \"Viz.\" the Rump, after being disturbed by my Lord Lambert, was lately returned to sit again. The officers of the army all forced to yield. Lawson lie[s] still in the River and Monke is with his army in Scotland. Only my Lord Lambert is not yet come in to the Parliament; nor is it expected that he will, without being forced to it.\nThe entries from the first few months were filled with news of General George Monck's march on London. In April and May of that year, he encountered problems with his wife, and he accompanied Montagu's fleet to the Netherlands to bring Charles II back from exile. Montagu was made Earl of Sandwich on 18 June, and Pepys secured the position of Clerk of the Acts to the Navy Board on 13 July. As secretary to the board, Pepys was entitled to a \u00a3350 annual salary plus the various gratuities and benefits that came with the job\u2014including bribes. He rejected an offer of \u00a31,000 for the position from a rival and soon afterward moved to official accommodation in Seething Lane in the City of London.\nPepys stopped writing his diary in 1669. His eyesight began to trouble him and he feared that writing in dim light was damaging his eyes. He did imply in his last entries that he might have others write his diary for him, but doing so would result in a loss of privacy and it seems that he never went through with those plans. In the end, Pepys lived another 34 years without going blind, but he never took to writing his diary again.\nHowever, Pepys dictated a journal for two months in 1669\u201370 as a record of his dealings with the Commissioners of Accounts at that period. He also kept a diary for a few months in 1683 when he was sent to Tangier as the most senior civil servant in the Navy, during the English evacuation. The diary mostly covers work-related matters.\nPublic life.\nOn the Navy Board, Pepys proved to be a more able and efficient worker than colleagues in higher positions. This often annoyed Pepys and provoked much harsh criticism in his diary. Among his colleagues were Admiral Sir William Penn, Sir George Carteret, Sir John Mennes and Sir William Batten.\nPepys learned arithmetic from a private tutor and used models of ships to make up for his lack of first-hand nautical experience, and ultimately came to play a significant role in the board's activities. In September 1660, he was made a Justice of the Peace; on 15 February 1662, Pepys was admitted as a Younger Brother of Trinity House; and on 30 April, he received the freedom of Portsmouth. Through Sandwich, he was involved in the administration of the short-lived English colony at Tangier. He joined the Tangier committee in August 1662 when the colony was first founded and became its treasurer in 1665. In 1663, he independently negotiated a \u00a33,000 contract for Norwegian masts, demonstrating the freedom of action that his superior abilities allowed. He was appointed to a commission of the royal fishery on 8 April 1664.\nPepys' job required him to meet many people to dispense money and make contracts. He often laments how he \"lost his labour\" having gone to some appointment at a coffee house or tavern, only to discover that the person whom he was seeking was not there. These occasions were a constant source of frustration to Pepys.\nPepys increased his wealth substantially through corruption. In seven and a half years, his net worth rose by \u00a37,500 on an annual salary of \u00a3350. In one instance, Pepys helped the career of a shipwright who provided sexual favours from his wife in return. Although he lived in a time when corruption was common, Pepys was not a minor practitioner in this.\nMajor events.\nPepys' diary provides a first-hand account of the Restoration, and includes detailed accounts of several major events of the 1660s, along with the lesser known diary of John Evelyn. In particular, it is an invaluable source for the study of the Second Anglo-Dutch War of 1665\u20137, the Great Plague of 1665, and the Great Fire of London in 1666. In relation to the Plague and Fire, C. S. Knighton has written: \"From its reporting of these two disasters to the metropolis in which he thrived, Pepys's diary has become a national monument.\" Robert Latham, editor of the definitive edition of the diary, remarks concerning the Plague and Fire: \"His descriptions of both\u2014agonisingly vivid\u2014achieve their effect by being something more than superlative reporting; they are written with compassion. As always with Pepys it is people, not literary effects, that matter.\"\nSecond Anglo-Dutch War.\nIn early 1665, the start of the Second Anglo-Dutch War placed great pressure on Pepys. His colleagues were either engaged elsewhere or incompetent, and Pepys had to conduct a great deal of business himself. He excelled under the pressure, which was extreme due to the complexity and underfunding of the Royal Navy. At the outset, he proposed a centralised approach to supplying the fleet. His idea was accepted, and he was made surveyor-general of victualling in October 1665. The position brought a further \u00a3300 a year.\nPepys wrote about the Second Anglo-Dutch War: \"In all things, in wisdom, courage, force and success, the Dutch have the best of us and do end the war with victory on their side\". And King Charles II said: \"Don't fight the Dutch, imitate them\".\nIn 1667, with the war lost, Pepys helped to discharge the navy. The Dutch had defeated England on open water and now began to threaten English soil itself. In June 1667, they conducted their Raid on the Medway, broke the defensive chain at Gillingham, and towed away the , one of the Royal Navy's most important ships. As he had done during the Fire and the Plague, Pepys again removed his wife and his gold from London.\nThe Dutch raid was a major concern in itself, but Pepys was personally placed under a different kind of pressure: the Navy Board and his role as Clerk of the Acts came under scrutiny from the public and from Parliament. The war ended in August and, on 17 October, the House of Commons created a committee of \"miscarriages\". On 20 October, a list was demanded from Pepys of ships and commanders at the time of the division of the fleet in 1666. However, these demands were actually quite desirable for him, as tactical and strategic mistakes were not the responsibility of the Navy Board.\nThe Board did face some allegations regarding the Medway raid, but they could exploit the criticism already attracted by Commissioner of Chatham Peter Pett to deflect criticism from themselves. The committee accepted this tactic when they reported in February 1668. The Board was, however, criticised for its use of tickets to pay seamen. These tickets could only be exchanged for cash at the Navy's treasury in London. Pepys made a long speech at the bar of the Commons on 5 March 1668 defending this practice. It was, in the words of C. S. Knighton, a \"virtuoso performance\".\nThe commission was followed by an investigation led by a more powerful authority, the commissioners of accounts. They met at Brooke House, Holborn and spent two years scrutinising how the war had been financed. In 1669, Pepys had to prepare detailed answers to the committee's eight \"Observations\" on the Navy Board's conduct. In 1670, he was forced to defend his own role. A seaman's ticket with Pepys' name on it was produced as incontrovertible evidence of his corrupt dealings but, thanks to the intervention of the king, Pepys emerged from the sustained investigation relatively unscathed.\nGreat Plague.\nOutbreaks of plague were not unusual events in London; major epidemics had occurred in 1592, 1603, 1625 and 1636. Furthermore, Pepys was not among the groups of people who were most at risk. He did not live in cramped housing, he did not routinely mix with the poor, and he was not required to keep his family in London in the event of a crisis. It was not until June 1665 that the unusual seriousness of the plague became apparent, so Pepys' activities in the first five months of 1665 were not significantly affected by it. Claire Tomalin wrote that 1665 was, to Pepys, one of the happiest years of his life. He worked very hard that year, and the outcome was that he quadrupled his fortune. In his annual summary on 31 December, he wrote, \"I have never lived so merrily (besides that I never got so much) as I have done this plague time\".\nNonetheless, Pepys was certainly concerned about the plague. On 16 August he wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;But, Lord! how sad a sight it is to see the streets empty of people, and very few upon the 'Change. Jealous of every door that one sees shut up, lest it should be the plague; and about us two shops in three, if not more, generally shut up.\u2014\u200a\nHe also chewed tobacco as a protection against infection, and worried that wig-makers might be using hair from the corpses as a raw material. Furthermore, it was Pepys who suggested that the Navy Office should evacuate to Greenwich, although he did offer to remain in town himself. He later took great pride in his stoicism. Meanwhile, Elisabeth Pepys was sent to Woolwich. She did not return to Seething Lane until January 1666 and was shocked by the sight of St Olave's churchyard, where 300 people had been buried.\nGreat Fire of London.\nIn the early hours of 2 September 1666, Pepys was awakened by Jane the maid, his servant, who had spotted a fire in the Billingsgate area. He decided that the fire was not particularly serious and returned to bed. Shortly after waking, his servant returned and reported that 300 houses had been destroyed and that London Bridge was threatened. Pepys went to the Tower of London to get a better view. Without returning home, he took a boat and observed the fire for over an hour. In his diary, Pepys recorded his observations as follows:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I down to the water-side, and there got a boat and through bridge, and there saw a lamentable fire. Poor Michell's house, as far as the Old Swan, already burned that way, and the fire running further, that in a very little time it got as far as the Steeleyard, while I was there. Everybody endeavouring to remove their goods, and flinging into the river or bringing them into lighters that layoff; poor people staying in their houses as long as till the very fire touched them, and then running into boats, or clambering from one pair of stairs by the water-side to another. And among other things, the poor pigeons, I perceive, were loth to leave their houses, but hovered about the windows and balconys till they were, some of them burned, their wings, and fell down. Having staid, and in an hour's time seen the fire: rage every way, and nobody, to my sight, endeavouring to quench it, but to remove their goods, and leave all to the fire, and having seen it get as far as the Steele-yard, and the wind mighty high and driving it into the City; and every thing, after so long a drought, proving combustible, even the very stones of churches, and among other things the poor steeple by which pretty Mrs.\u2014\u2014\u2014\u2014 lives, and whereof my old school-fellow Elborough is parson, taken fire in the very top, and there burned till it fell down...\u2014\u200a\nThe wind was driving the fire westward, so he ordered the boat to go to Whitehall and became the first person to inform the king of the fire. According to his entry of 2 September 1666, Pepys recommended to the king that homes be pulled down in the path of the fire in order to stem its progress. Accepting this advice, the king told him to go to Lord Mayor Thomas Bloodworth and tell him to start pulling down houses. Pepys took a coach back as far as St Paul's Cathedral before setting off on foot through the burning city. He found the Lord Mayor, who said, \"Lord! what can I do? I am spent: people will not obey me. I have been pulling down houses; but the fire overtakes us faster than we can do it.\" At noon, he returned home and \"had an extraordinary good dinner, and as merry, as at this time we could be\", before returning to watch the fire in the city once more. Later, he returned to Whitehall, then met his wife in St James's Park. In the evening, they watched the fire from the safety of Bankside. Pepys writes that \"it made me weep to see it\". Returning home, Pepys met his clerk Tom Hayter who had lost everything. Hearing news that the fire was advancing, he started to pack up his possessions by moonlight.\nA cart arrived at 4 a.m. on 3 September and Pepys spent much of the day arranging the removal of his possessions. Many of his valuables, including his diary, were sent to a friend from the Navy Office at Bethnal Green. At night, he \"fed upon the remains of yesterday's dinner, having no fire nor dishes, nor any opportunity of dressing any thing.\" The next day, Pepys continued to arrange the removal of his possessions. By then, he believed that Seething Lane was in grave danger, so he suggested calling men from Deptford to help pull down houses and defend the king's property. He described the chaos in the city and his curious attempt at saving his own goods:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Sir W. Pen and I to Tower-streete, and there met the fire burning three or four doors beyond Mr. Howell's, whose goods, poor man, his trayes, and dishes, shovells, &amp;c., were flung all along Tower-street in the kennels, and people working therewith from one end to the other; the fire coming on in that narrow streete, on both sides, with infinite fury. Sir W. Batten not knowing how to remove his wine, did dig a pit in the garden, and laid it in there; and I took the opportunity of laying all the papers of my office that I could not otherwise dispose of. And in the evening Sir W. Pen and I did dig another, and put our wine in it; and I my Parmazan cheese, as well as my wine and some other things.\u2014\u200a\nPepys had taken to sleeping on his office floor; on Wednesday, 5 September, he was awakened by his wife at 2 a.m. She told him that the fire had almost reached All Hallows-by-the-Tower and that it was at the foot of Seething Lane. He decided to send her and his gold\u2014about \u00a32,350\u2014to Woolwich. In the following days, Pepys witnessed looting, disorder, and disruption. On 7 September, he went to Paul's Wharf and saw the ruins of St Paul's Cathedral, of his old school, of his father's house, and of the house in which he had had his bladder stone removed. Despite all this destruction, Pepys' house, office, and diary were saved.\nPersonal life.\nThe diary gives a detailed account of Pepys' personal life. He was fond of wine, plays, and the company of other people. He also spent time evaluating his fortune and his place in the world. He was always curious and often acted on that curiosity, as he acted upon almost all his impulses. Periodically, he would resolve to devote more time to hard work instead of leisure. For example, in his entry for New Year's Eve, 1661, he writes: \"I have newly taken a solemn oath about abstaining from plays and wine\u2026\" The following months reveal his lapses to the reader; by 17 February, it is recorded, \"Here I drank wine upon necessity, being ill for the want of it.\"\nPepys was one of the most important civil servants of his age, and was also a widely cultivated man, taking an interest in books, music, the theatre, and science. Aside from English, he was fluent in French and read many texts in Latin. His favourite author was Virgil. He was passionately interested in music; he composed, sang, and played for pleasure, and even arranged music lessons for his servants. He played the lute, viol, violin, flageolet, recorder and spinet to varying degrees of proficiency. He was also a keen singer, performing at home, in coffee houses, and even in Westminster Abbey. He and his wife took flageolet lessons from master Thomas Greeting. He also taught his wife to sing and paid for dancing lessons for her (although these stopped when he became jealous of the dancing master).\nPepys was an investor in the Company of Royal Adventurers Trading to Africa, which held the Royal monopoly on trading along the west coast of Africa in gold, silver, ivory and slaves.\nSexual relations.\nPropriety did not prevent him from engaging in a number of extramarital liaisons with various women that were chronicled in his diary, often in some detail when relating the intimate details. The most dramatic of these encounters was with Deborah Willet, a young woman engaged as a companion for Elisabeth Pepys. On 25 October 1668, Pepys was surprised by his wife as he embraced Deb Willet; he writes that his wife \"coming up suddenly, did find me imbracing the girl con \"[with]\" my hand sub \"[under]\" su \"[her]\" coats; and endeed I was with my main \"[hand]\" in her cunny. I was at a wonderful loss upon it and the girl also...\" Following this event, he was characteristically filled with remorse, but (equally characteristically) continued to pursue Willet after she had been dismissed from the Pepys household. Pepys also had a habit of fondling the breasts of his maid Mary Mercer while she dressed him in the morning.\nPepys may also have dallied with a leading actress of the Restoration period, Mary Knep. \"Mrs Knep was the wife of a Smithfield horsedealer, and the mistress of Pepys\"\u2014or at least \"she granted him a share of her favours\". Scholars disagree on the full extent of the Pepys/Knep relationship, but much of later generations' knowledge of Knep comes from the diary. Pepys first met Knep on 6 December 1665. He described her as \"pretty enough, but the most excellent, mad-humoured thing, and sings the noblest that I ever heard in my life.\" He called her husband \"an ill, melancholy, jealous-looking fellow\" and suspected him of abusing his wife. Knep provided Pepys with backstage access and was a conduit for theatrical and social gossip. When they wrote notes to each other, Pepys signed himself \"Dapper Dickey\", while Knep was \"Barbry Allen\" (a popular song that was an item in her musical repertory).\nPepys' reference to purchasing the pornographic book \"L'Escole des Filles\" appears to be the first English reference to pornography. He writes in his diary that it was a \"mighty lewd book\", and burned it after reading it.\nMuch of Pepys' behaviour towards women, which he cataloged himself in his diary, would today be considered sexual harassment, sexual assault, and rape. Despite his kindness and emotional loyalty towards some women in his life, Pepys ultimately believed men were entitled to the bodies of girls and women. Kate Loveman of Cambridge University describes this belief: \"[In his diary] Pepys's sexual language of being 'kind', 'touching', and 'tumbling' emphasized his indulgence and playfulness, while masking coercion and violence; meanwhile, [his victim] Lane's claims of assault he regarded as exemplifying a woman's 'falseness', not because he thought there had been no violence, but because she had no moral right to protest.\"\nText of the diary.\nThe diary was written in one of the many standard forms of shorthand used in Pepys' time, in this case called tachygraphy, and devised by Thomas Shelton. It is clear from its content that it was written as a purely personal record of his life and not for publication, yet there are indications that Pepys took steps to preserve the bound manuscripts of his diary. He wrote it out in fair copy from rough notes, and he also had the loose pages bound into six volumes, catalogued them in his library with all his other books, and is likely to have suspected that eventually someone would find them interesting.\nSimplified Pepys family tree.\nThis tree summarizes, in a more compact form and with a few additional details, trees published elsewhere in a box-like form. It is meant to help the reader of the \"Diary\" and also integrates some biographical information found in the same sources.\n&lt;templatestyles src=\"Template:Hidden begin/styles.css\"/&gt;Simplified Pepys family tree\n&lt;templatestyles src=\"Tree list/styles.css\" /&gt;\nAfter the diary.\nPepys' health suffered from the long hours that he worked throughout the period of the diary. Specifically, he believed that his eyesight had been affected by his work. He reluctantly concluded in his last entry, dated 31 May 1669, that he should completely stop writing for the sake of his eyes, and only dictate to his clerks from then on, which meant that he could no longer keep his diary.\nPepys and his wife took a holiday to France and the Low Countries in June\u2013October 1669; on their return, Elisabeth fell ill and died on 10 November 1669. Pepys erected a monument to her in the church of St Olave's, Hart Street, London. Pepys never remarried, but he did have a long-term housekeeper named Mary Skinner who was assumed by many of his contemporaries to be his mistress and sometimes referred to as Mrs. Pepys. In his will, he left her an annuity of \u00a3200 and many of his possessions.\nMember of Parliament and Secretary of the Admiralty.\nIn 1672, he became an Elder Brother of Trinity House and served in this capacity until 1689; he was Master of Trinity House in 1676\u20131677 and again in 1685\u20131686. In 1673, he was promoted to Secretary of the Admiralty Commission and elected MP for Castle Rising in Norfolk.\nIn 1673, he was involved with the establishment of the Royal Mathematical School at Christ's Hospital, which was to train 40 boys annually in navigation, for the benefit of the Royal Navy and the English Merchant Navy. In 1675, he was appointed a Governor of Christ's Hospital and for many years he took a close interest in its affairs. Among his papers are two detailed memoranda on the administration of the school. In 1699, after the successful conclusion of a seven-year campaign to get the master of the Mathematical School replaced by a man who knew more about the sea, he was rewarded for his service as a Governor by being made a Freeman of the City of London. He also served as Master (without ever having been a Freeman or Liveryman) of the Clothworkers' Company (1677\u20138).\nAt the beginning of 1679, Pepys was elected MP for Harwich in Charles II's third parliament which formed part of the Cavalier Parliament. He was elected along with Sir Anthony Deane, a Harwich alderman and leading naval architect, to whom Pepys had been a patron since 1662. By May of that year, they were under attack from their political enemies. Pepys resigned as Secretary of the Admiralty. They were imprisoned in the Tower of London on suspicion of treasonable correspondence with France, specifically leaking naval intelligence. The charges are believed to have been fabricated under the direction of Anthony Ashley-Cooper, 1st Earl of Shaftesbury. Pepys was accused, among other things, of being a secret member of the Catholic Church in England. Pepys and Deane were released in July, but proceedings against them were not dropped until June 1680.\nThough he had resigned from the Tangier committee in 1679, in 1683 he was sent to Tangier to assist Lord Dartmouth with the evacuation and abandonment of the English colony. After six months' service, he travelled back through Spain accompanied by the naval engineer Edmund Dummer, returning to England after a particularly rough passage on 30 March 1684. In June 1684, once more in favour, he was appointed King's Secretary for the affairs of the Admiralty, a post that he retained after the death of Charles II (February 1685) and the accession of James II. The phantom Pepys Island, alleged to be near South Georgia, was named after him in 1684, having been first \"discovered\" during his tenure at the Admiralty.\nFrom 1685 to 1688, he was active not only as Secretary of the Admiralty, but also as MP for Harwich. He had been elected MP for Sandwich, but this election was contested and he immediately withdrew to Harwich. When James fled the country at the end of 1688, Pepys's career also came to an end. In January 1689, he was defeated in the parliamentary election at Harwich; in February, one week after the accession of William III and Mary II, he resigned his secretaryship.\nRoyal Society.\nHe was elected a Fellow of the Royal Society in 1665 and served as its President from 1 December 1684 to 30 November 1686. Isaac Newton's \"Principia Mathematica\" was published during this period, and the imprimatur on the book's title page is signed by Pepys in his role as president. There is a probability problem called the \"Newton\u2013Pepys problem\" that arose out of correspondence between Newton and Pepys about whether one is more likely to roll at least one six with six dice or at least two sixes with twelve dice. It has only recently been noted that the gambling advice that Newton gave Pepys was correct, while the logical argument with which Newton accompanied it was unsound.\nRetirement and death.\nHe was imprisoned on suspicion of Jacobitism from May to July 1689 and again in June 1690, but no charges were ever successfully brought against him. After his release, he retired from public life at age 57. He moved out of London ten years later (1701) to a house in Clapham owned by his friend William Hewer, who had begun his career working for Pepys in the admiralty. Clapham was in the country at the time; it is now part of inner London.\nPepys lived there until his death on 26 May 1703. He had no children and bequeathed his estate to his unmarried nephew John Jackson. Pepys had disinherited his nephew Samuel Jackson for marrying contrary to his wishes. When John Jackson died in 1724, Pepys' estate reverted to Anne, daughter of Archdeacon Samuel Edgeley, niece of Will Hewer and sister of Hewer Edgeley, nephew and godson of Pepys' old Admiralty employee and friend Will Hewer. Hewer was also childless and left his immense estate to his nephew Hewer Edgeley (consisting mostly of the Clapham property, as well as lands in Clapham, London, Westminster, and Norfolk) on condition that the nephew (and godson) would adopt the surname Hewer. So Will Hewer's heir became Hewer Edgeley-Hewer, and he adopted the old Will Hewer home in Clapham as his residence. That is how the Edgeley family acquired the estates of both Samuel Pepys and Will Hewer, with sister Anne inheriting Pepys' estate, and brother Hewer inheriting that of Will Hewer. On the death of Hewer Edgeley-Hewer in 1728, the old Hewer estate went to Edgeley-Hewer's widow Elizabeth, who left the estate to Levett Blackborne, the son of Abraham Blackborne, merchant of Clapham, and other family members, who later sold it off in lots. Lincoln's Inn barrister Levett Blackborne also later acted as attorney in legal scuffles for the heirs who had inherited the Pepys estate.\nPepys' former prot\u00e9g\u00e9 and friend Hewer acted as the executor of Pepys's estate.\nPepys was buried along with his wife in St Olave's Church, Hart Street in London.\nPepys Library.\nPepys was a lifelong bibliophile and carefully nurtured his large collection of books, manuscripts, and prints. At his death, there were more than 3,000 volumes, including the diary, all carefully catalogued and indexed; they form one of the most important surviving 17th-century private libraries. The most important items in the Library are the six original bound manuscripts of Pepys' diary, but there are other remarkable holdings, including:\nThe library includes an extensive collection of documents relating to the administration of the navy in Pepys' time. These have been used as a dominant source for understanding how the navy was governed and the level of influence exerted by those involved. Comparison of notes made by Pepys' brother John of a meeting on 22 July 1676 with the official minutes taken by Samuel calls into question the completeness and accuracy of the latter. For instance, the official minutes make no mention that the Duke of York even attended, when John's notes make clear that the Duke was an active participant. The suggestion is made that Samuel Pepys' naval journal presents a \"flawed and incomplete picture\" of how the navy was run in the 1670s, despite it being a key source, widely cited by historians.\nPepys made detailed provisions in his will for the preservation of his book collection. His nephew and heir John Jackson died in 1723, when it was transferred intact to Magdalene College, Cambridge, where it can be seen in the Pepys Library. The bequest included all the original bookcases and his elaborate instructions that placement of the books \"be strictly reviewed and, where found requiring it, more nicely adjusted\".\nThe Ephemera Society emblem uses Pepys' portrait and characterizes him as \"the first general ephemerist.\" Two large albums of ephemera saved by Pepys are in his library.\nPublication history of the diary.\nMotivated by the publication of John Evelyn's Diary in 1818, Lord Granville deciphered a few pages. John Smith (later the Rector of St Mary the Virgin in Baldock) was then engaged to transcribe the diaries into plain English. He laboured at this task for three years, from 1819 to 1822, unaware until nearly finished that a key to the shorthand system was stored in Pepys' library a few shelves above the diary volumes. Others had apparently succeeded in reading the diary earlier, perhaps knowing about the key, because a work of 1812 quotes from a passage of it. Smith's transcription, which is also kept in the Pepys Library, was the basis for the first published edition of the diary, edited by Lord Braybrooke, released in two volumes in 1825 along with selected correspondence. The second edition was brought out in 1828. An enlarged third edition was published in 1848. The fourth edition was published in 1854.\nA second transcription, done with the benefit of the key but often less accurately, was completed in 1875 by Mynors Bright and published in 1875\u20131879. This added about a third to the previously published text, but still left only about 80% of the diary in print. Henry B. Wheatley, drawing on both his predecessors, produced a new edition in 1893\u20131899, revised in 1926 with extensive notes and an index.\nAll of these editions omitted passages (chiefly about Pepys' sexual adventures) that the editors thought were too obscene ever to be printed. Wheatley, in the preface to his edition, noted, \"a few passages which cannot possibly be printed. It may be thought by some that these omissions are due to an unnecessary squeamishness, but it is not really so, and readers are therefore asked to have faith in the judgement of the editor.\" Wheatley claims to have indicated all such omissions with an ellipsis, but comparison with the modern text indicates that he did not always do this, and that he silently bowdlerised a number of words.\nThe complete, unexpurgated, and definitive edition, edited and transcribed by Robert Latham and William Matthews, was published by Bell &amp; Hyman, London, and the University of California Press, Berkeley, in nine volumes, along with separate Companion and Index volumes, over the years 1970\u20131983. Various single-volume abridgements of this text are also available.\nThe Introduction in Volume I provides a scholarly but readable account of \"The Diarist\", \"The Diary\" (\"The Manuscript\", \"The Shorthand\", and \"The Text\"), \"History of Previous Editions\", \"The Diary as Literature\", and \"The Diary as History\". The Companion provides a long series of detailed essays about Pepys and his world.\nThe first unabridged recording of the diary as an audiobook was published in 2015 by \"Naxos AudioBooks\".\nOn 1 January 2003 Phil Gyford started a weblog, pepysdiary.com, that serialised the diary one day each evening together with annotations from the public and experts alike. In December 2003 the blog won the best specialist blog award in \"The Guardian\"'s Best of British Blogs. In 2021, Gyford noted the existence of the Samuel Pepys Twitter account; set up in 2008, the account similarly serialises Pepys' diary each day.\nAdaptations.\nIn 1958, the BBC produced a serial called \"The Diary of Samuel Pepys\", in which Peter Sallis played the title role. In 2003, a television film, \"The Private Life of Samuel Pepys\" aired on BBC2, in which Steve Coogan played Pepys. The 2004 film \"Stage Beauty\" concerns London theatre in the 17th century and is based on Jeffrey Hatcher's play \"Compleat Female Stage Beauty\", which in turn was inspired by a reference in Pepys' diary to the actor Edward Kynaston, who played female roles in the days when women were forbidden to appear on stage. Pepys is a character in the film and is portrayed as an ardent devotee of the theatre. Hugh Bonneville plays Pepys. Daniel Mays portrays Pepys in \"The Great Fire\", a 2014 BBC television miniseries. Pepys has also been portrayed in various other film and television productions, played by diverse actors including Mervyn Johns, Michael Palin, Michael Graham Cox and Philip Jackson.\nBBC Radio 4 has broadcast serialised radio dramatisations of the diary. In the 1990s it was performed as a \"Classic Serial\" starring Bill Nighy, and in the 2010s it was serialised as part of the \"Woman's Hour\" radio magazine programme. One audiobook edition of Pepys' diary selections is narrated by Kenneth Branagh. A fictionalised Pepys narrates the second chapter of Harry Turtledove's science fiction novel \"A Different Flesh\" (serialised 1985\u20131988, book form 1988). This chapter is entitled \"And So to Bed\" and written in the form of entries from the Pepys diary. The entries detail Pepys' encounter with American \"Homo erectus\" specimens (imported to London as beasts of burden) and his formation of the \"transformational theory of life\", thus causing evolutionary theory to gain a foothold in scientific thought in the 17th century rather than the 19th. Deborah Swift's 2017 novel \"Pleasing Mr Pepys\" is described as a \"re-imagining of the events in Samuel Pepys's Diary\". The 2022 book \"The Lost Diary of Samuel Pepys\" by Jack Jewers imagined a secret continuation of Pepys' diaries, in which he became an unwilling agent for the crown. The novel, which was named a \"Sunday Times\" historical fiction book of the year, is to be followed by a sequel, \"The King's Man\", in 2025.\nBiographical studies.\nSeveral detailed studies of Pepys' life are available. Arthur Bryant published his three-volume study in 1933\u20131938, long before the definitive edition of the diary, but, thanks to Bryant's lively style, it is still of interest. In 1974, Richard Ollard produced a new biography that drew on Latham's and Matthew's work on the text, benefiting from the author's deep knowledge of Restoration politics. Other biographies include: \"Samuel Pepys: A Life\", by Stephen Coote (London: Hodder &amp; Stoughton, 2000) and, \"Samuel Pepys and His World\", by Geoffrey Trease (London: Thames and Hudson, 1972).\nThe most recent general study, \"\", is by Claire Tomalin. Tomalin's book won the 2002 Whitbread Book of the Year award, the judges calling it a \"rich, thoughtful and deeply satisfying\" account that unearths \"a wealth of material about the uncharted life of Samuel Pepys\".\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\nEditions of letters and other publications.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nThe Diary (Definitive and Unexpurgated Edition).\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nCited secondary sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "27809", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=27809", "title": "Chemical synapse", "text": "Biological junctions through which neurons' signals can be sent\nChemical synapses are biological junctions through which neurons' signals can be sent to each other and to non-neuronal cells such as those in muscles or glands. Chemical synapses allow neurons to form circuits within the central nervous system. They are crucial to the biological computations that underlie perception and thought. They allow the nervous system to connect to and control other systems of the body.\nAt a chemical synapse, one neuron releases neurotransmitter molecules into a small space (the synaptic cleft) that is adjacent to the postsynaptic cell (e.g., another neuron). The neurotransmitter molecules are contained within small sacs called synaptic vesicles, and are released into the synaptic cleft by exocytosis. These molecules then bind to neurotransmitter receptors on the postsynaptic cell. Finally, to terminate its action, the neurotransmitter is cleared from the cleft through one of several mechanisms, including enzymatic degradation or re-uptake, by specific transporters, either into the presynaptic cell or to neuroglia.\nThe adult human brain is estimated to contain from 1014 to 5 \u00d7 1014 (100\u2013500 trillion) synapses. Every cubic millimeter of cerebral cortex contains roughly a billion (short scale, i.e. 109) of them. The number of synapses in the human cerebral cortex has separately been estimated at 0.15 quadrillion (150 trillion)\nThe word \"synapse\" was introduced by Sir Charles Scott Sherrington in 1897. Chemical synapses are not the only type of biological synapse: electrical and immunological synapses also exist. Without a qualifier, however, \"synapse\" commonly refers to chemical synapses.\nStructure.\nSynapses are functional connections between neurons, or between neurons and other types of cells. A typical neuron gives rise to several thousand synapses, although there are some types that make far fewer. Most synapses connect axons to dendrites, but there are also other types of connections, including axon-to-cell-body, axon-to-axon, and dendrite-to-dendrite. Synapses are generally too small to be recognizable using a light microscope except as points where the membranes of two cells appear to touch, but their cellular elements can be visualized clearly using an electron microscope.\nChemical synapses pass information directionally from a presynaptic cell to a postsynaptic cell and are therefore asymmetric in structure and function. The presynaptic axon terminal, or synaptic bouton, is a specialized area within the axon of the presynaptic cell that contains neurotransmitters enclosed in small membrane-bound spheres called synaptic vesicles (as well as a number of other supporting structures and organelles, such as mitochondria and endoplasmic reticulum). Some synaptic vesicles are docked at the presynaptic plasma membrane at regions called active zones.\nImmediately opposite is a region of the postsynaptic cell containing neurotransmitter receptors; for synapses between two neurons the postsynaptic region may be found on the dendrites or cell body. Immediately behind the postsynaptic membrane is an elaborate complex of interlinked proteins called the postsynaptic density (PSD).\nProteins in the PSD are involved in anchoring and trafficking neurotransmitter receptors and modulating the activity of these receptors. The receptors and PSDs are often found in specialized protrusions from the main dendritic shaft called dendritic spines.\nSynapses may be described as symmetric or asymmetric. When examined under an electron microscope, asymmetric synapses are characterized by rounded vesicles in the presynaptic cell, and a prominent postsynaptic density. Asymmetric synapses are typically excitatory. Symmetric synapses in contrast have flattened or elongated vesicles, and do not contain a prominent postsynaptic density. Symmetric synapses are typically inhibitory.\nThe synaptic cleft\u2014also called synaptic gap\u2014is a gap between the pre- and postsynaptic cells that is about 20\u00a0nm (0.02 \u03bc) wide. The small volume of the cleft allows neurotransmitter concentration to be raised and lowered rapidly.\nAn autapse is a chemical (or electrical) synapse formed when the axon of one neuron synapses with its own dendrites.\nSignaling in chemical synapses.\nOverview.\nSome authors consider signal transmission at a chemical synapse as a special case of paracrine signaling., while others treat it a separate signaling mechanism.\nHere is a summary of the sequence of events that take place in synaptic transmission from a presynaptic neuron to a postsynaptic cell. Each step is explained in more detail below. Note that with the exception of the final step, the entire process may run only a few hundred microseconds, in the fastest synapses.\nNeurotransmitter release.\nThe release of a neurotransmitter is triggered by the arrival of a nerve impulse (or action potential) and occurs through an unusually rapid process of cellular secretion (exocytosis). Within the presynaptic nerve terminal, vesicles containing neurotransmitter are localized near the synaptic membrane. The arriving action potential produces an influx of calcium ions through voltage-dependent, calcium-selective ion channels at the down stroke of the action potential (tail current). Calcium ions then bind to synaptotagmin proteins found within the membranes of the synaptic vesicles, allowing the vesicles to fuse with the presynaptic membrane. The fusion of a vesicle is a stochastic process, leading to frequent failure of synaptic transmission at the very small synapses that are typical for the central nervous system. Large chemical synapses (e.g. the neuromuscular junction), on the other hand, have a synaptic release probability, in effect, of 1. Vesicle fusion is driven by the action of a set of proteins in the presynaptic terminal known as SNAREs. As a whole, the protein complex or structure that mediates the docking and fusion of presynaptic vesicles is called the active zone. The membrane added by the fusion process is later retrieved by endocytosis and recycled for the formation of fresh neurotransmitter-filled vesicles.\nAn exception to the general trend of neurotransmitter release by vesicular fusion is found in the type II receptor cells of mammalian taste buds. Here the neurotransmitter ATP is released directly from the cytoplasm into the synaptic cleft via voltage gated channels.\nReceptor binding.\nReceptors on the opposite side of the synaptic gap bind neurotransmitter molecules. Receptors can respond in either of two general ways. First, the receptors may directly open ligand-gated ion channels in the postsynaptic cell membrane, causing ions to enter or exit the cell and changing the local transmembrane potential. The resulting change in voltage is called a postsynaptic potential. In general, the result is \"excitatory\" in the case of depolarizing currents, and \"inhibitory\" in the case of hyperpolarizing currents. Whether a synapse is excitatory or inhibitory depends on what type(s) of ion channel conduct the postsynaptic current(s), which in turn is a function of the type of receptors and neurotransmitter employed at the synapse. The second way a receptor can affect membrane potential is by modulating the production of chemical messengers inside the postsynaptic neuron. These second messengers can then amplify the inhibitory or excitatory response to neurotransmitters.\nTermination.\nAfter a neurotransmitter molecule binds to a receptor molecule, it must be removed to allow for the postsynaptic membrane to continue to relay subsequent EPSPs and/or IPSPs. This removal can happen through one or more processes:\nSynaptic strength.\nThe strength of a synapse has been defined by Bernard Katz as the product of (presynaptic) release probability \"pr\", quantal size \"q\" (the postsynaptic response to the release of a single neurotransmitter vesicle, a 'quantum'), and \"n\", the number of release sites. \"Unitary connection\" usually refers to an unknown number of individual synapses connecting a presynaptic neuron to a postsynaptic neuron. \nThe amplitude of postsynaptic potentials (PSPs) can be as low as 0.4 mV to as high as 20 mV. The amplitude of a PSP can be modulated by neuromodulators or can change as a result of previous activity. Changes in the synaptic strength can be short-term, lasting seconds to minutes, or long-term (long-term potentiation, or LTP), lasting hours. Learning and memory are believed to result from long-term changes in synaptic strength, via a mechanism known as synaptic plasticity.\nReceptor desensitization.\nDesensitization of the postsynaptic receptors is a decrease in response to the same neurotransmitter stimulus. It means that the strength of a synapse may in effect diminish as a train of action potentials arrive in rapid succession \u2013 a phenomenon that gives rise to the so-called frequency dependence of synapses. The nervous system exploits this property for computational purposes, and can tune its synapses through such means as phosphorylation of the proteins involved.\nSynaptic plasticity.\nSynaptic transmission can be changed by previous activity. These changes are called synaptic plasticity and may result in either a decrease in the efficacy of the synapse, called depression, or an increase in efficacy, called potentiation. These changes can either be long-term or short-term. Forms of short-term plasticity include synaptic fatigue or depression and synaptic augmentation. Forms of long-term plasticity include long-term depression and long-term potentiation. Synaptic plasticity can be either homosynaptic (occurring at a single synapse) or heterosynaptic (occurring at multiple synapses).\nHomosynaptic plasticity.\nHomosynaptic plasticity (or also homotropic modulation) is a change in the synaptic strength that results from the history of activity at a particular synapse. This can result from changes in presynaptic calcium as well as feedback onto presynaptic receptors, i.e. a form of autocrine signaling. Homosynaptic plasticity can affect the number and replenishment rate of vesicles or it can affect the relationship between calcium and vesicle release. Homosynaptic plasticity can also be postsynaptic in nature. It can result in either an increase or decrease in synaptic strength.\nOne example is neurons of the sympathetic nervous system (SNS), which release noradrenaline, which, besides affecting postsynaptic receptors, also affects presynaptic \u03b12-adrenergic receptors, inhibiting further release of noradrenaline. This effect is utilized with clonidine to perform inhibitory effects on the SNS.\nHeterosynaptic plasticity.\nHeterosynaptic plasticity (or also heterotropic modulation) is a change in synaptic strength that results from the activity of other neurons. Again, the plasticity can alter the number of vesicles or their replenishment rate or the relationship between calcium and vesicle release. Additionally, it could directly affect calcium influx. Heterosynaptic plasticity can also be postsynaptic in nature, affecting receptor sensitivity.\nOne example is again neurons of the sympathetic nervous system, which release noradrenaline, which, in addition, generates an inhibitory effect on presynaptic terminals of neurons of the parasympathetic nervous system.\nIntegration of synaptic inputs.\nIn general, if an excitatory synapse is strong enough, an action potential in the presynaptic neuron will trigger an action potential in the postsynaptic cell. In many cases the excitatory postsynaptic potential (EPSP) will not reach the threshold for eliciting an action potential. When action potentials from multiple presynaptic neurons fire simultaneously, or if a single presynaptic neuron fires at a high enough frequency, the EPSPs can overlap and summate. If enough EPSPs overlap, the summated EPSP can reach the threshold for initiating an action potential. This process is known as summation, and can serve as a high pass filter for neurons.\nOn the other hand, a presynaptic neuron releasing an inhibitory neurotransmitter, such as GABA, can cause an inhibitory postsynaptic potential (IPSP) in the postsynaptic neuron, bringing the membrane potential farther away from the threshold, decreasing its excitability and making it more difficult for the neuron to initiate an action potential. If an IPSP overlaps with an EPSP, the IPSP can in many cases prevent the neuron from firing an action potential. In this way, the output of a neuron may depend on the input of many different neurons, each of which may have a different degree of influence, depending on the strength and type of synapse with that neuron. John Carew Eccles performed some of the important early experiments on synaptic integration, for which he received the Nobel Prize for Physiology or Medicine in 1963.\nVolume transmission.\nWhen a neurotransmitter is released at a synapse, it reaches its highest concentration inside the narrow space of the synaptic cleft, but some of it is certain to diffuse away before being reabsorbed or broken down. If it diffuses away, it has the potential to activate receptors that are located either at other synapses or on the membrane away from any synapse. The extrasynaptic activity of a neurotransmitter is known as \"volume transmission\". It is well established that such effects occur to some degree, but their functional importance has long been a matter of controversy.\nRecent work indicates that volume transmission may be the predominant mode of interaction for some special types of neurons. In the mammalian cerebral cortex, a class of neurons called neurogliaform cells can inhibit other nearby cortical neurons by releasing the neurotransmitter GABA into the extracellular space. GABA released from neurogliaform cells into the extracellular space also acts on surrounding astrocytes, assigning a role for volume transmission in the control of ionic and neurotransmitter homeostasis. Approximately 78% of neurogliaform cell boutons do not form classical synapses. This may be the first definitive example of neurons communicating chemically where classical synapses are not present.\nRelationship to electrical synapses.\nAn electrical synapse is an electrically conductive link between two abutting neurons that is formed at a narrow gap between the pre- and postsynaptic cells, known as a gap junction. At gap junctions, cells approach within about 3.5\u00a0nm of each other, rather than the 20 to 40\u00a0nm distance that separates cells at chemical synapses. As opposed to chemical synapses, the postsynaptic potential in electrical synapses is not caused by the opening of ion channels by chemical transmitters, but rather by direct electrical coupling between both neurons. Electrical synapses are faster than chemical synapses. Electrical synapses are found throughout the nervous system, including in the retina, the reticular nucleus of the thalamus, the neocortex, and in the hippocampus. While chemical synapses are found between both excitatory and inhibitory neurons, electrical synapses are most commonly found between smaller local inhibitory neurons. Electrical synapses can exist between two axons, two dendrites, or between an axon and a dendrite. In some fish and amphibians, electrical synapses can be found within the same terminal of a chemical synapse, as in Mauthner cells.\nEffects of drugs.\nOne of the most important features of chemical synapses is that they are the site of action for the majority of psychoactive drugs. Synapses are affected by drugs, such as curare, strychnine, cocaine, morphine, alcohol, LSD, risperidone, and countless others. These drugs have different effects on synaptic function, and often are restricted to synapses that use a specific neurotransmitter. For example, curare is a poison that stops acetylcholine from depolarizing the postsynaptic membrane, causing paralysis. Strychnine blocks the inhibitory effects of the neurotransmitter glycine, which causes the body to pick up and react to weaker and previously ignored stimuli, resulting in uncontrollable muscle spasms. Morphine acts on synapses that use endorphin neurotransmitters, and alcohol increases the inhibitory effects of the neurotransmitter GABA. LSD interferes with synapses that use the neurotransmitter serotonin. Risperidone is a blocker of various receptors including several dopamine and serotonin receptors, and it can bind with high affinity to some types of serotonin receptors. Cocaine blocks reuptake of dopamine and therefore increases its effects.\nHistory and etymology.\nDuring the 1950s, Bernard Katz and Paul Fatt observed spontaneous miniature synaptic currents at the frog neuromuscular junction. Based on these observations, they developed the 'quantal hypothesis' that is the basis for our current understanding of neurotransmitter release as exocytosis and for which Katz received the Nobel Prize in Physiology or Medicine in 1970. In the late 1960s, Ricardo Miledi and Katz advanced the hypothesis that depolarization-induced influx of calcium ions triggers exocytosis.\nSir Charles Scott Sherringtonin coined the word 'synapse' and the history of the word was given by Sherrington in a letter he wrote to John Fulton:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;'I felt the need of some name to call the junction between nerve-cell and nerve-cell... I suggested using \"syndesm\"... He [ Sir Michael Foster ] consulted his Trinity friend Verrall, the Euripidean scholar, about it, and Verrall suggested \"synapse\" (from the Greek \"clasp\").'\u2013Charles Scott Sherrington\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27811", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=27811", "title": "Sleep and learning", "text": "Multiple hypotheses explain the possible connections between sleep and learning in humans. Research indicates that sleep does more than allow the brain to rest; it may also aid the consolidation of long-term memories.\nREM sleep and slow-wave sleep play different roles in memory consolidation. REM is associated with the consolidation of nondeclarative (implicit) memories. An example of a nondeclarative memory would be a task we can do without consciously thinking about, such as riding a bike. Slow-wave, or non-REM (NREM) sleep, consolidates declarative (explicit) memories. These are facts that need to be consciously remembered, such as dates for a history class.\nIncreased learning.\nPopular sayings can reflect the notion that remolded memories produce new creative associations in the morning, and that performance often improves after a time-interval that includes sleep. Current studies demonstrate that a healthy sleep produces a significant learning-dependent performance boost. The idea is that sleep helps the brain to edit its memory, looking for important patterns and extracting overarching rules which could be described as 'the gist', and integrating this with existing memory. The 'synaptic scaling' hypothesis suggests that sleep plays an important role in regulating learning that has taken place while awake, enabling more efficient and effective storage in the brain, making better use of space and energy.\nHealthy sleep must include the appropriate sequence and proportion of NREM and REM phases, which play different roles in the memory consolidation-optimization process. During a normal night of sleep, a person will alternate between periods of NREM and REM sleep. Each cycle is approximately 90 minutes long, containing a 20-30 minute bout of REM sleep. NREM sleep consists of sleep stages 1\u20134, and is where movement can be observed. A person can still move their body when they are in NREM sleep. If someone sleeping turns, tosses, or rolls over, this indicates that they are in NREM sleep. REM sleep is characterized by the lack of muscle activity. Physiological studies have shown that aside from the occasional twitch, a person actually becomes paralyzed during REM sleep. In motor skill learning, an interval of sleep may be critical for the expression of performance gains; without sleep these gains will be delayed.\nProcedural memories are a form of nondeclarative memory, so they would most benefit from the fast-wave REM sleep. In a study, procedural memories have been shown to benefit from sleep. Subjects were tested using a tapping task, where they used their fingers to tap a specific sequence of numbers on a keyboard, and their performances were measured by accuracy and speed. This finger-tapping task was used to simulate learning a motor skill. The first group was tested, retested 12 hours later while awake, and finally tested another 12 hours later with sleep in between. The other group was tested, retested 12 hours later with sleep in between, and then retested 12 hours later while awake. The results showed that in both groups, there was only a slight improvement after a 12-hour wake session, but a significant increase in performance after each group slept. This study gives evidence that REM sleep is a significant factor in consolidating motor skill procedural memories, therefore sleep deprivation can impair performance on a motor learning task. This memory decrement results specifically from the loss of stage 2, REM sleep.\nDeclarative memory has also been shown to benefit from sleep, but not in the same way as procedural memory. Declarative memories benefit from the slow-waves nREM sleep. A study was conducted where the subjects learned word pairs, and the results showed that sleep not only prevents the decay of memory, but also actively fixates declarative memories. Two of the groups learned word pairs, then either slept or stayed awake, and were tested again. The other two groups did the same thing, except they also learned interference pairs right before being retested to try to disrupt the previously learned word pairs. The results showed that sleep was of \"some\" help in retaining the word pair associations, while against the interference pair, sleep helped \"significantly\".\nAfter sleep, there is increased insight. This is because sleep helps people to reanalyze their memories. The same patterns of brain activity that occur during learning have been found to occur again during sleep, only faster. One way that sleep strengthens memories is by weeding out the less successful connections between neurons in the brain. This weeding out is essential to prevent overactivity. The brain compensates for strengthening some synapses (connections) between neurons, by weakening others. The weakening process occurs mostly during sleep. This weakening during sleep allows for strengthening of other connections while we are awake. Learning is the process of strengthening connections, therefore this process could be a major explanation for the benefits that sleep has on memory.\nResearch has shown that taking an afternoon nap increases learning capacity. A study tested two groups of subjects on a nondeclarative memory task. One group engaged in REM sleep, and one group did not (meaning that they engaged in NREM sleep). The investigators found that the subjects who engaged only in NREM sleep did not show much improvement. The subjects who engaged in REM sleep performed significantly better, indicating that REM sleep facilitated the consolidation of nondeclarative memories. A more recent study demonstrated that a procedural task was learned and retained better if it was encountered immediately before going to sleep, while a declarative task was learned better in the afternoon.\nElectrophysiological evidence in rats.\nA 2009 study based on electrophysiological recordings of large ensembles of isolated cells in the prefrontal cortex of rats revealed that cell assemblies that formed upon learning were more preferentially active during subsequent sleep episodes. More specifically, those replay events were more prominent during slow wave sleep and were concomitant with hippocampal reactivation events. This study has shown that neuronal patterns in large brain networks are tagged during learning so that they are replayed, and supposedly consolidated, during subsequent sleep. There have been other studies that have shown similar reactivation of learning pattern during motor skill and neuroprosthetic learning. Notably, new evidence is showing that reactivation and rescaling may be co-occurring during sleep.\nSleep in relation to school.\nSleep has been directly linked to the grades of students. One in four U.S. high school students admit to falling asleep in class at least once a week. Consequently, results have shown that those who sleep less do poorly. In the United States, sleep deprivation is common with students because almost all schools begin early in the morning and many of these students either choose to stay awake late into the night or cannot do otherwise due to delayed sleep phase syndrome. As a result, students that should be getting between 8.5 and 9.25 hours of sleep are getting only 7 hours. Perhaps because of this sleep deprivation, their grades are lower and their concentration is impaired.\nResearch shows that different remote learning modalities significantly affect nursing students' perceptions of their sleep quality. During the COVID-19 pandemic, a study found that students engaged in asynchronous learning reported better sleep quality compared to those in hybrid or in-person learning environments. Over half of the nursing students surveyed reported getting less than the recommended 7 hours of sleep per night; however, students who reported more sleep hours also reported better sleep quality.\nGiven the significant impact of sleep deprivation on academic performance and the differing sleep patterns observed in students, educational institutions have begun to reconsider start times. For instance, a school in New Zealand changed its start time to 10:30\u00a0a.m. in 2006, to allow students to keep to a schedule that allowed more sleep. In 2009, Monkseaton High School, in North Tyneside, had 800 pupils aged 13\u201319 starting lessons at 10\u00a0a.m. instead of the normal 9\u00a0a.m. and reported that general absence dropped by 8% and persistent absenteeism by 27%. In 2024, some 20 schools in Denmark have pushed back their start times, and there have been positive results.\nCollege students represent one of the most sleep-deprived segments of the population. Only 11% of American college students sleep well, and 40% of students feel well rested only two days per week. About 73% have experienced at least some occasional sleep issues. This poor sleep is thought to have a severe impact on their ability to learn and remember information because the brain is being deprived of time that it needs to consolidate information which is essential to the learning process.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27812", "revid": "7716227", "url": "https://en.wikipedia.org/wiki?curid=27812", "title": "Specie", "text": ""}
{"id": "27813", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=27813", "title": "Systematics", "text": "Branch of biology\nSystematics is the study of the diversification of living forms, both past and present, and the relationships among living things through time. Relationships are visualized as evolutionary trees (synonyms: phylogenetic trees, phylogenies). Phylogenies have two components: branching order (showing group relationships, graphically represented in cladograms) and branch length (showing amount of evolution). Phylogenetic trees of species and higher taxa are used to study the evolution of traits (e.g., anatomical or molecular characteristics) and the distribution of organisms (biogeography). Systematics, in other words, is used to understand the evolutionary history of life on Earth.\nThe word systematics is derived from the Latin word of Ancient Greek origin \"systema,\" which means systematic arrangement of organisms. Carl Linnaeus used 'Systema Naturae' as the title of his book.\nBranches and applications.\nIn the study of biological systematics, researchers use the different branches to further understand the relationships between differing organisms. These branches are used to determine the applications and uses for modern day systematics.\nBiological systematics classifies species by using three specific branches. \"Numerical systematics\", or \"biometry\", uses biological statistics to identify and classify animals. \"Biochemical systematics\" classifies and identifies animals based on the analysis of the material that makes up the living part of a cell\u2014such as the nucleus, organelles, and cytoplasm. \"Experimental systematics\" identifies and classifies animals based on the evolutionary units that comprise a species, as well as their importance in evolution itself. Factors such as mutations, genetic divergence, and hybridization all are considered evolutionary units.\nWith the specific branches, researchers are able to determine the applications and uses for modern-day systematics. These applications include: \nDefinition and relation with taxonomy.\nJohn Lindley provided an early definition of systematics in 1830, although he wrote of \"systematic botany\" rather than using the term \"systematics\".\nIn 1970 Michener \"et al.\" defined \"systematic biology\" and \"taxonomy\" (terms that are often confused and used interchangeably) in relationship to one another as follows:\nSystematic biology (hereafter called simply systematics) is the field that (a) provides scientific names for organisms, (b) describes them, (c) preserves collections of them, (d) provides classifications for the organisms, keys for their identification, and data on their distributions, (e) investigates their evolutionary histories, and (f) considers their environmental adaptations. This is a field with a long history that in recent years has experienced a notable renaissance, principally with respect to theoretical content. Part of the theoretical material has to do with evolutionary areas (topics e and f above), the rest relates especially to the problem of classification. Taxonomy is that part of Systematics concerned with topics (a) to (d) above.\nThe term \"taxonomy\" was coined by Augustin Pyramus de Candolle while the term \"systematic\" was coined by Carl Linnaeus the father of taxonomy.\nTaxonomy, systematic biology, systematics, biosystematics, scientific classification, biological classification, phylogenetics: At various times in history, all these words have had overlapping, related meanings. However, in modern usage, they can all be considered synonyms of each other.\nFor example, Webster's 9th New Collegiate Dictionary of 1987 treats \"classification\", \"taxonomy\", and \"systematics\" as synonyms. According to this work, the terms originated in 1790, c.\u20091828, and in 1888 respectively. Some claim systematics alone deals specifically with relationships through time, and that it can be synonymous with phylogenetics, broadly dealing with the inferred hierarchy of organisms. This means it would be a subset of taxonomy as it is sometimes regarded, but the inverse is claimed by others.\nEuropeans tend to use the terms \"systematics\" and \"biosystematics\" for the study of biodiversity as a whole, whereas North Americans tend to use \"taxonomy\" more frequently. However, taxonomy, and in particular alpha taxonomy, is more specifically the identification, description, and naming (i.e. nomenclature) of organisms, while \"classification\" focuses on placing organisms within hierarchical groups that show their relationships to other organisms. All of these biological disciplines can deal with both extinct and extant organisms.\nSystematics uses taxonomy as a primary tool in understanding, as nothing about an organism's relationships with other living things can be understood without it first being properly studied and described in sufficient detail to identify and classify it correctly. Scientific classifications are aids in recording and reporting information to other scientists and to laymen. The systematist, a scientist who specializes in systematics, must, therefore, be able to use existing classification systems, or at least know them well enough to skilfully justify not using them.\nPhenetics was an attempt to determine the relationships of organisms through a measure of overall similarity, making no distinction between plesiomorphies (shared ancestral traits) and apomorphies (derived traits). From the late-20th century onwards, it was superseded by cladistics, which rejects plesiomorphies in attempting to resolve the phylogeny of Earth's various organisms through time. Today's[ [update]] systematists generally make extensive use of molecular biology and of computer programs to study organisms.\nTaxonomic characters.\nTaxonomic characters are the taxonomic attributes that can be used to provide the evidence from which relationships (the phylogeny) between taxa are inferred. Kinds of taxonomic characters include:\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27814", "revid": "4351416", "url": "https://en.wikipedia.org/wiki?curid=27814", "title": "Sine (disambiguation)", "text": "Sine is a trigonometric function.\nSine may also refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "27833", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=27833", "title": "Strength of memory", "text": ""}
{"id": "27834", "revid": "1461430", "url": "https://en.wikipedia.org/wiki?curid=27834", "title": "Sleep", "text": "Naturally recurring resting state of mind and body\nSleep is a state of reduced mental and physical activity in which consciousness is altered and certain sensory activity is inhibited. During sleep, there is a marked decrease in muscle activity and interactions with the surrounding environment. While sleep differs from wakefulness in terms of the ability to react to stimuli, it still involves active brain patterns, making it more reactive than a coma or disorders of consciousness.\nSleep occurs in repeating periods, during which the body alternates between two distinct modes: rapid eye movement sleep (REM) and non-REM sleep. Although REM stands for \"rapid eye movement\", this mode of sleep has many other aspects, including virtual paralysis of the body. Dreams are a succession of images, ideas, emotions, and sensations that usually occur involuntarily in the mind during certain stages of sleep.\nDuring sleep, most of the body's systems are in an anabolic state, helping to restore the immune, nervous, skeletal, and muscular systems; these are vital processes that maintain mood, memory, and cognitive function, and play a large role in the function of the endocrine and immune systems. The internal circadian clock promotes sleep daily at night, when it is dark. The diverse purposes and mechanisms of sleep are the subject of substantial ongoing research. Sleep is a highly conserved behavior across animal evolution, likely going back hundreds of millions of years, and originating as a means for the brain to cleanse itself of waste products. In a major breakthrough, researchers have found that cleansing, including the removal of amyloid, may be a core purpose of sleep.\nHumans may suffer from various sleep disorders, including dyssomnias, such as insomnia, hypersomnia, narcolepsy, and sleep apnea; parasomnias, such as sleepwalking and rapid eye movement sleep behavior disorder; bruxism; and circadian rhythm sleep disorders. The use of artificial light has substantially altered humanity's sleep patterns. Common sources of artificial light include outdoor lighting and the screens of digital devices such as smartphones and televisions, which emit large amounts of blue light, a form of light typically associated with daytime. This disrupts the release of the hormone melatonin needed to regulate the sleep cycle.\nPhysiology.\nThe most pronounced physiological changes in sleep occur in the brain. The brain uses significantly less energy during sleep than it does when awake, especially during non-REM sleep. In areas with reduced activity, the brain restores its supply of adenosine triphosphate (ATP), the molecule used for short-term storage and transport of energy. In quiet waking, the brain is responsible for 20% of the body's energy use, thus this reduction has a noticeable effect on overall energy consumption.\nSleep increases the sensory threshold. In other words, sleeping persons perceive fewer stimuli, but can generally still respond to loud noises and other salient sensory events.\nDuring slow-wave sleep, humans secrete bursts of growth hormone. All sleep, even during the day, is associated with the secretion of prolactin.\nKey physiological methods for monitoring and measuring changes during sleep include electroencephalography (EEG) of brain waves, electrooculography (EOG) of eye movements, and electromyography (EMG) of skeletal muscle activity. Simultaneous collection of these measurements is called polysomnography, and can be performed in a specialized sleep laboratory. Sleep researchers also use simplified electrocardiography (EKG) for cardiac activity and actigraphy for motor movements.\nBrain waves in sleep.\nThe electrical activity seen on an EEG represents brain waves. The amplitude of EEG waves at a particular frequency corresponds to various points in the sleep-wake cycle, such as being asleep, being awake, or falling asleep. Alpha, beta, theta, gamma, and delta waves are all seen in the different stages of sleep. Each waveform maintains a different frequency and amplitude. Alpha waves are seen when a person is in a resting state, but is still fully conscious. Their eyes may be closed and all of their body is resting and relatively still, where the body is starting to slow down. Beta waves take over alpha waves when a person is at attention, as they might be completing a task or concentrating on something. Beta waves consist of the highest of frequencies and the lowest of amplitude, and occur when a person is fully alert. Gamma waves are seen when a person is highly focused on a task or using all their concentration. Theta waves occur during the period of a person being awake, and they continue to transition into Stage 1 of sleep and in stage 2. Delta waves are seen in stages 3 and 4 of sleep when a person is in their deepest of sleep.\nNon-REM and REM sleep.\nSleep is divided into two broad types: non-rapid eye movement (non-REM or NREM) sleep and rapid eye movement (REM) sleep. Non-REM and REM sleep are so different that physiologists identify them as distinct behavioral states. Non-REM sleep occurs first and after a transitional period is called slow-wave sleep or deep sleep. During this phase, body temperature and heart rate fall, and the brain uses less energy. REM sleep, also known as paradoxical sleep, represents a smaller portion of total sleep time. It is the main occasion for dreams (or nightmares), and is associated with desynchronized and fast brain waves, eye movements, loss of muscle tone, and suspension of homeostasis.\nThe sleep cycle of alternate NREM and REM sleep takes an average of 90 minutes, occurring 4\u20136 times in a good night's sleep. The American Academy of Sleep Medicine (AASM) divides NREM into three stages: N1, N2, and N3, the last of which is also called delta sleep or slow-wave sleep. The whole period normally proceeds in the order: N1 \u2192 N2 \u2192 N3 \u2192 N2 \u2192 REM. REM sleep occurs as a person returns to stage 2 or 1 from a deep sleep. There is a greater amount of deep sleep (stage N3) earlier in the night, while the proportion of REM sleep increases in the two cycles just before natural awakening.\nAwakening.\nAwakening can mean the end of sleep, or simply a moment to survey the environment and readjust body position before falling back asleep. Sleepers typically awaken soon after the end of a REM phase or sometimes in the middle of REM. Internal circadian indicators, along with a successful reduction of homeostatic sleep need, typically bring about awakening and the end of the sleep cycle. Awakening involves heightened electrical activation in the brain, beginning with the thalamus and spreading throughout the cortex.\nOn a typical night of sleep, there is not much time that is spent in the waking state. In various sleep studies that have been conducted using the electroencephalography, it has been found that females are awake for 0\u20131% during their nightly sleep while males are awake for 0\u20132% during that time. In adults, wakefulness increases, especially in later cycles. One study found 3% awake time in the first ninety-minute sleep cycle, 8% in the second, 10% in the third, 12% in the fourth, and 13\u201314% in the fifth. Most of this awake time occurred shortly after REM sleep.\nToday, many humans wake up with an alarm clock; however, people can also reliably wake themselves up at a specific time with no need for an alarm. Many sleep quite differently on workdays versus days off, a pattern which can lead to chronic circadian desynchronization. Many people regularly look at television and other screens before going to bed, a factor which may exacerbate disruption of the circadian cycle. Scientific studies on sleep have shown that sleep stage at awakening is an important factor in amplifying sleep inertia.\nDeterminants of alertness after waking up include quantity/quality of the sleep, physical activity the day prior, a carbohydrate-rich breakfast, and a low blood glucose response to it.\nTiming.\nSleep timing is controlled by the circadian clock (Process C), sleep-wake homeostasis (Process S), and to some extent by the individual will.\nCircadian clock.\nSleep timing depends greatly on hormonal signals from the circadian clock, or Process C, a complex neurochemical system which uses signals from an organism's environment to recreate an internal day\u2013night rhythm. Process C counteracts the homeostatic drive for sleep during the day (in diurnal animals) and augments it at night. The suprachiasmatic nucleus (SCN), a brain area directly above the optic chiasm, is presently considered the most important nexus for this process; however, secondary clock systems have been found throughout the body.\nAn organism whose circadian clock exhibits a regular rhythm corresponding to outside signals is said to be \"entrained\"; an entrained rhythm persists even if the outside signals suddenly disappear. If an entrained human is isolated in a bunker with constant light or darkness, he or she will continue to experience rhythmic increases and decreases of body temperature and melatonin, on a period that slightly exceeds 24 hours. Scientists refer to such conditions as free-running of the circadian rhythm. Under natural conditions, light signals regularly adjust this period downward, so that it corresponds better with the exact 24 hours of an Earth day.\nThe circadian clock exerts constant influence on the body, affecting sinusoidal oscillation of body temperature between roughly 36.2\u00a0\u00b0C and 37.2\u00a0\u00b0C. The suprachiasmatic nucleus itself shows conspicuous oscillation activity, which intensifies during subjective day (i.e., the part of the rhythm corresponding with daytime, whether accurately or not) and drops to almost nothing during subjective night. The circadian pacemaker in the suprachiasmatic nucleus has a direct neural connection to the pineal gland, which releases the hormone melatonin at night. Cortisol levels typically rise throughout the night, peak in the awakening hours, and diminish during the day. Circadian prolactin secretion begins in the late afternoon, especially in women, and is subsequently augmented by sleep-induced secretion, to peak in the middle of the night. Circadian rhythm exerts some influence on the nighttime secretion of growth hormone.\nThe circadian rhythm influences the ideal timing of a restorative sleep episode. Sleepiness increases during the night. REM sleep occurs more during body temperature minimum within the circadian cycle, whereas slow-wave sleep can occur more independently of circadian time.\nThe internal circadian clock is profoundly influenced by changes in light, since these are its main clues about what time it is. Exposure to even small amounts of light during the night can suppress melatonin secretion, and increase body temperature and wakefulness. Short pulses of light, at the right moment in the circadian cycle, can significantly 'reset' the internal clock. Blue light, in particular, exerts the strongest effect, leading to concerns that use of a screen before bed may interfere with sleep.\nModern humans often find themselves desynchronized from their internal circadian clock, due to the requirements of work (especially night shifts), long-distance travel, and the influence of universal indoor lighting. Even if they have sleep debt, or feel sleepy, people can have difficulty staying asleep at the peak of their circadian cycle. Conversely, they can have difficulty waking up in the trough of the cycle. A healthy young adult entrained to the sun will (during most of the year) fall asleep a few hours after sunset, experience body temperature minimum at 6 a.m., and wake up a few hours after sunrise.\nProcess S.\nGenerally speaking, the longer an organism is awake, the more it feels a need to sleep (\"sleep debt\"). This driver of sleep is referred to as Process S. The balance between sleeping and waking is regulated by a process called homeostasis. Induced or perceived lack of sleep is called sleep deprivation.\nProcess S is driven by the depletion of glycogen and accumulation of adenosine in the forebrain that disinhibits the ventrolateral preoptic nucleus, allowing for inhibition of the ascending reticular activating system.\nSleep deprivation tends to cause slower brain waves in the frontal cortex, shortened attention span, higher anxiety, impaired memory, and a grouchy mood. Conversely, a well-rested organism tends to have improved memory and mood. Neurophysiological and functional imaging studies have demonstrated that frontal regions of the brain are particularly responsive to homeostatic sleep pressure.\nThere is disagreement on how much sleep debt is possible to accumulate, and whether sleep debt is accumulated against an individual's average sleep or some other benchmark. It is also unclear whether the prevalence of sleep debt among adults has changed appreciably in the industrialized world in recent decades. Sleep debt does show some evidence of being cumulative. Subjectively, however, humans seem to reach maximum sleepiness 30 hours after waking. It is likely that in Western societies, children are sleeping less than they previously have.\nOne neurochemical indicator of sleep debt is adenosine, a neurotransmitter that inhibits many of the bodily processes associated with wakefulness. Adenosine levels increase in the cortex and basal forebrain during prolonged wakefulness, and decrease during the sleep-recovery period, potentially acting as a homeostatic regulator of sleep. Coffee, tea, and other sources of caffeine temporarily block the effect of adenosine, prolong sleep latency, and reduce total sleep time and quality.\nSocial timing.\nHumans are also influenced by aspects of \"social time\", such as the hours when other people are awake, the hours when work is required, the time on clocks, etc. Time zones, standard times used to unify the timing for people in the same area, correspond only approximately to the natural rising and setting of the sun. An extreme example of the approximate nature of time zones is China, a country which used to span five time zones and now officially uses only one (UTC+8).\nDistribution.\nIn polyphasic sleep, an organism sleeps several times in a 24-hour cycle, whereas in monophasic sleep this occurs all at once. Under experimental conditions, humans tend to alternate more frequently between sleep and wakefulness (i.e., exhibit more polyphasic sleep) if they have nothing better to do. Given a 14-hour period of darkness in experimental conditions, humans tended towards bimodal sleep, with two sleep periods concentrated at the beginning and at the end of the dark time. Bimodal sleep in humans was more common before the Industrial Revolution.\nDifferent characteristic sleep patterns, such as the familiarly so-called \"early bird\" and \"night owl\", are called \"chronotypes\". Genetics and sex have some influence on chronotype, but so do habits. Chronotype is also liable to change over the course of a person's lifetime. Seven-year-olds are better disposed to wake up early in the morning than are fifteen-year-olds. Chronotypes far outside the normal range are called circadian rhythm sleep disorders.\nNaps.\nNaps are short periods of sleep that one might take during the daytime, often in order to get the necessary amount of rest. Napping is often associated with childhood, but around one-third of American adults partake in it daily. The optimal nap duration is around 10\u201320 minutes, as researchers have proven that it takes at least 30 minutes to enter slow-wave sleep, the deepest period of sleep. Napping too long and entering the slow wave cycles can make it difficult to awake from the nap and leave one feeling unrested. This period of drowsiness is called sleep inertia.\nThe siesta habit has recently been associated with a 37% lower coronary mortality, possibly due to reduced cardiovascular stress mediated by daytime sleep. Short naps at mid-day and mild evening exercise were found to be effective for improved sleep, cognitive tasks, and mental health in elderly people.\nGenetics.\nMonozygotic (identical) but not dizygotic (fraternal) twins tend to have similar sleep habits. Neurotransmitters, molecules whose production can be traced to specific genes, are one genetic influence on sleep that can be analyzed. The circadian clock has its own set of genes. Genes which may influence sleep include ABCC9, DEC2, Dopamine receptor D2 and variants near PAX 8 and VRK2. While the latter have been found in a GWAS study that primarily detects correlations (but not necessarily causation), other genes have been shown to have a more direct effect. For instance, mice lacking dihydropyrimidine dehydrogenase (Dpyd) had 78.4 min less sleep during the lights-off period than wild-type mice. Dpyd encodes the rate-limiting enzyme in the metabolic pathway that catabolizes uracil and thymidine to \u03b2-alanine, an inhibitory neurotransmitter. This also supports the role of \u03b2-alanine as a neurotransmitter that promotes sleep in mice.\nGenes for short sleep duration.\n The genes DEC2, ADRB1, NPSR1 and GRM1 are implicated in enabling short sleep.\nQuality.\nThe quality of sleep may be evaluated from an objective and a subjective point of view. Objective sleep quality refers to how difficult it is for a person to fall asleep and remain in a sleeping state, and how many times they wake up during a single night. Poor sleep quality disrupts the cycle of transition between the different stages of sleep. Subjective sleep quality in turn refers to a sense of being rested and regenerated after awaking from sleep. A study by A. Harvey et al. (2002) found that insomniacs were more demanding in their evaluations of sleep quality than individuals who had no sleep problems.\nHomeostatic sleep propensity (the need for sleep as a function of time elapsed since the last adequate sleep episode) must be balanced against the circadian element for satisfactory sleep. Along with corresponding messages from the circadian clock, this tells the body it needs to sleep. The timing is correct when the following two circadian markers occur after the middle of the sleep episode and before awakening: maximum concentration of the hormone melatonin, and minimum core body temperature.\nIdeal duration.\nHuman sleep-needs vary by age and amongst individuals; sleep is considered to be adequate when there is no daytime sleepiness or dysfunction. Moreover, self-reported sleep duration is only moderately correlated with actual sleep time as measured by actigraphy, and those affected with sleep state misperception may typically report having slept only four hours despite having slept a full eight hours.\nResearchers have found that sleeping 6\u20137 hours each night correlates with longevity and cardiac health in humans, though many underlying factors may be involved in the causality behind this relationship.\nSleep difficulties are furthermore associated with psychiatric disorders such as depression, alcoholism, and bipolar disorder. Up to 90 percent of adults with depression are found to have sleep difficulties. Dysregulation detected by EEG includes disturbances in sleep continuity, decreased delta sleep and altered REM patterns with regard to latency, distribution across the night and density of eye movements.\nSleep duration can also vary according to season. Up to 90% of people report longer sleep duration in winter, which may lead to more pronounced seasonal affective disorder.\nChildren.\nBy the time infants reach the age of two, their brain size has reached 90 percent of an adult-sized brain; a majority of this brain growth has occurred during the period of life with the highest rate of sleep. The hours that children spend asleep influence their ability to perform on cognitive tasks. Children who sleep through the night and have few night waking episodes have higher cognitive attainments and easier temperaments than other children.\nSleep also influences language development. To test this, researchers taught infants a faux language and observed their recollection of the rules for that language. Infants who slept within four hours of learning the language could remember the language rules better, while infants who stayed awake longer did not recall those rules as well. There is also a relationship between infants' vocabulary and sleeping: infants who sleep longer at night at 12 months have better vocabularies at 26 months.\nChildren can greatly benefit from a structured bedtime routine. This can look differently among families, but will generally consist of a set of rituals such as reading a bedtime story, a bath, brushing teeth, and can also include a show of affection from the parent to the child such as a hug or kiss before bed. A bedtime routine will also include a consistent time that the child is expected to be in bed ready for sleep. Having a reliable bedtime routine can help improve a child's quality of sleep as well as prepare them to make and keep healthy sleep hygiene habits in the future.\nRecommended duration.\nChildren need many hours of sleep per day in order to develop and function properly: up to 18 hours for newborn babies, with a declining rate as a child ages. Early in 2015, after a two-year study, the National Sleep Foundation in the US announced newly revised recommendations as shown in the table below.\nFunctions.\n&lt;templatestyles src=\"Unsolved/styles.css\" /&gt;\nUnsolved problem in biology\nWhat is the biological function of sleep?\nMore unsolved problems in biology\nRestoration.\nThe sleeping brain has been shown to remove metabolic end products at a faster rate than during an awake state, by increasing the flow of cerebrospinal fluid during sleep. The mechanism for this removal appears to be the glymphatic system, a system that does for the brain what the lymphatic system does for the body. Further research has shown that the glymphatic system is driven by pulses of hormones that in turn create surges in blood flow that cause the cerebrospinal fluid to flow, carrying away metabolites.\nSleep may facilitate the synthesis of molecules that help repair and protect the brain from metabolic end products generated during waking. Anabolic hormones, such as growth hormones, are secreted preferentially during sleep. The brain concentration of glycogen increases during sleep, and is depleted through metabolism during wakefulness.\nThe human organism physically restores itself during sleep, occurring mostly during slow-wave sleep during which body temperature, heart rate, and brain oxygen consumption decrease. In both the brain and body, the reduced rate of metabolism enables countervailing restorative processes. While the body benefits from sleep, the brain actually requires sleep for restoration, whereas these processes can take place during quiescent waking in the rest of the body. The essential function of sleep may be its restorative effect on the brain: \"Sleep is of the brain, by the brain and for the brain.\" Furthermore, this includes almost any brain, no matter how small: sleep is observed to be a necessary behavior across most of the animal kingdom, including some of the least cognitively advanced animals, implying that sleep is essential to the most fundamental brain processes, i.e. neuronal firing. This shows that sleep is vital even when there is no need for other functions of sleep, such as memory consolidation or dreaming.\nMemory processing.\nIt has been widely accepted that sleep must support the formation of long-term memory, and generally increasing previous learning and experiences recalls. However, its benefit seems to depend on the phase of sleep and the type of memory. For example, declarative and procedural memory-recall tasks applied over early and late nocturnal sleep, as well as wakefulness controlled conditions, have been shown that declarative memory improves more during early sleep (dominated by SWS) while procedural memory during late sleep (dominated by REM sleep) does so.\nWith regard to declarative memory, the functional role of SWS has been associated with hippocampal replays of previously encoded neural patterns that seem to facilitate long-term memory consolidation. This assumption is based on the active system consolidation hypothesis, which states that repeated reactivations of newly encoded information in the hippocampus during slow oscillations in NREM sleep mediate the stabilization and gradual integration of declarative memory with pre-existing knowledge networks on the cortical level. It assumes the hippocampus might hold information only temporarily and in a fast-learning rate, whereas the neocortex is related to long-term storage and a slow-learning rate. This dialogue between the hippocampus and neocortex occurs in parallel with hippocampal sharp-wave ripples and thalamo-cortical spindles, synchrony that drives the formation of the spindle-ripple event which seems to be a prerequisite for the formation of long-term memories.\nReactivation of memory also occurs during wakefulness and its function is associated with serving to update the reactivated memory with newly encoded information, whereas reactivations during SWS are presented as crucial for memory stabilization. Based on targeted memory reactivation (TMR) experiments that use associated memory cues to triggering memory traces during sleep, several studies have been reassuring the importance of nocturnal reactivations for the formation of persistent memories in neocortical networks, as well as highlighting the possibility of increasing people's memory performance at declarative recalls.\nFurthermore, nocturnal reactivation seems to share the same neural oscillatory patterns as reactivation during wakefulness, processes which might be coordinated by theta activity. During wakefulness, theta oscillations have been often related to successful performance in memory tasks, and cued memory reactivations during sleep have been showing that theta activity is significantly stronger in subsequent recognition of cued stimuli as compared to uncued ones, possibly indicating a strengthening of memory traces and lexical integration by cuing during sleep. However, the beneficial effect of TMR for memory consolidation seems to occur only if the cued memories can be related to prior knowledge.\nDreaming.\nDuring sleep, especially REM sleep, humans tend to experience dreams. These are elusive and mostly unpredictable first-person experiences which seem logical and realistic to the dreamer while they are in progress, despite their frequently bizarre, irrational, and/or surreal qualities that become apparent when assessed after waking. Dreams often seamlessly incorporate concepts, situations, people, and objects within a person's mind that would not normally go together. They can include apparent sensations of all types, especially vision and movement.\nDreams tend to rapidly fade from memory after waking. Some people choose to keep a dream journal, which they believe helps them build dream recall and facilitate the ability to experience lucid dreams.\nA lucid dream is a type of dream in which the dreamer becomes aware that they are dreaming while dreaming. In a preliminary study, dreamers were able to consciously communicate with experimenters via eye movements or facial muscle signals, and were able to comprehend complex questions and use working memory.&lt;ref name=\"10.1016/j.cub.2021.01.026\"&gt; Available under https:// .&lt;/ref&gt;\nPeople have proposed many hypotheses about the functions of dreaming. Sigmund Freud postulated that dreams are the symbolic expression of frustrated desires that have been relegated to the unconscious mind, and he used dream interpretation in the form of psychoanalysis in attempting to uncover these desires.\nCounterintuitively, penile erections during sleep are not more frequent during sexual dreams than during other dreams. The parasympathetic nervous system experiences increased activity during REM sleep which may cause erection of the penis or clitoris. In males, 80% to 95% of REM sleep is normally accompanied by partial to full penile erection, while only about 12% of men's dreams contain sexual content.\nDisorders.\nInsomnia.\nInsomnia is a general term for difficulty falling asleep and/or staying asleep. Insomnia is the most common sleep problem, with many adults reporting occasional insomnia, and 10\u201315% reporting a chronic condition. Insomnia can have many different causes, including psychological stress, a poor sleep environment, an inconsistent sleep schedule, or excessive mental or physical stimulation in the hours before bedtime. Insomnia is often treated through behavioral changes like keeping a regular sleep schedule, avoiding stimulating or stressful activities before bedtime, and cutting down on stimulants such as caffeine. The sleep environment may be improved by installing heavy drapes to shut out all sunlight, and keeping computers, televisions, and work materials out of the sleeping area.\nA 2010 review of published scientific research suggested that exercise generally improves sleep for most people, and helps sleep disorders such as insomnia. The optimum time to exercise \"may\" be 4 to 8 hours before bedtime, though exercise at any time of day is beneficial, with the exception of heavy exercise taken shortly before bedtime, which may disturb sleep. However, there is insufficient evidence to draw detailed conclusions about the relationship between exercise and sleep. Nonbenzodiazepine sleeping medications such as Ambien, Imovane, and Lunesta (also known as \"Z-drugs\"), while initially believed to be entirely better and safer than earlier generations of \u2009in\u00adclud\u00ading benzodiazepine \u2009are now known to be similar in more ways than thought. White noise appears to be a promising treatment for insomnia.\nSleep health.\nSleep duration and quality.\nSleep duration measures the length of sleep, whereas sleep quality includes factors such as speed in falling asleep and whether sleep is unbroken. Adequate quality sleep is linked with better mood and the abilities to express and quickly process emotion.\nLow quality sleep has been linked with health conditions like cardiovascular disease, obesity, and mental illness. While poor sleep is common among those with cardiovascular disease, some research indicates that poor sleep can be a contributing cause. Short sleep duration of less than seven hours is correlated with coronary heart disease and increased risk of death from coronary heart disease. Sleep duration greater than nine hours is also correlated with coronary heart disease, as well as stroke and cardiovascular events.\nIn both children and adults, short sleep duration is associated with an increased risk of obesity, with various studies reporting an increased risk of 45\u201355%. Other aspects of sleep health have been associated with obesity, including daytime napping, sleep timing, the variability of sleep timing, and low sleep efficiency. However, sleep duration is the most-studied for its impact on obesity.\nSleep problems have been frequently viewed as a symptom of mental illness rather than a causative factor. However, a growing body of evidence suggests that they are both a cause and a symptom of mental illness. Insomnia is a significant predictor of major depressive disorder; a meta-analysis of 170,000 people showed that insomnia at the beginning of a study period indicated a more than the twofold increased risk for major depressive disorder. Some studies have also indicated correlation between insomnia and anxiety, post-traumatic stress disorder, and suicide. Sleep disorders can increase the risk of psychosis and worsen the severity of psychotic episodes.\nSleep research also displays differences in race and class. Short sleep and poor sleep are observed more frequently in ethnic minorities than in whites in the US. African-Americans report experiencing short durations of sleep five times more often than whites, possibly as a result of social and environmental factors. A study done in the USA suggested that higher rates of sleep apnea (and poorer responses to treatment) are suffered by children in disadvantaged neighborhoods (which, in context, includes a disproportionate effect on children of African-American descent).\nSleep hygiene.\nSleep health can be improved through implementing good sleep hygiene habits. Having good sleep hygiene can help to improve your physical and mental health by providing your body with the necessary rejuvenation only restful sleep can provide. Some ways to improve sleep health include going to sleep at consistent times every night, avoiding any electronic devices such as televisions in the bedroom, getting adequate exercise throughout your day, and avoiding caffeine in the hours before going to sleep. Another way to greatly improve sleep hygiene is by creating a peaceful and relaxing sleep environment. Sleeping in a dark and clean room with things like a white noise maker can help facilitate restful sleep. However, noise, with the exception of white noise, may not be good for sleep.\nSleep and musculoskeletal health.\nMany studies have linked sleep posture and the characteristics of pillows and mattresses on the one hand with back and neck pain on the other.\nSleeping in the prone position has been found to place stress on the spine and may cause back pain, whereas sleeping on the back or on the side can provide relief.\nSimilarly, sleeping on the back or side is also recommended to prevent neck pain.\nTo prevent neck pain, side sleepers are advised to adjust the height of their pillow so that the spine remains straight, without tilting to the right or left.\nIn one study, precise pillow-height adjustment using the SSS-8 questionnaire significantly reduced pain in half of the patients suffering from neck pain.\nIn addition, people with neck pain are often advised to use a supplementary pillow or rolled towel to support the neck.\nWhen sleeping on the side, experts recommend placing a pillow between the knees to keep the legs aligned and prevent rotation of the spine.\nCompared to sleeping on the back, side sleeping has been reported to help reduce heartburn, sleep apnea, and back pain, whereas sleeping on the back may help alleviate hip pain, teeth grinding, and neck pain. Furthermore, when comparing right- versus left-side sleeping, right-side sleep has been found to improve overall sleep quality, while left-side sleep may help reduce heartburn.\nMattresses and pillows also influence sleep quality and overall health. A medium-firm to firm mattress has been found to be most effective in preventing back pain and improving sleep quality.\nLatex pillows have been shown to be effective in reducing neck pain.\nPhysicians also recommend performing muscle-stretching exercises upon waking and engaging in stretching and relaxation routines before sleep to help alleviate muscle pain.\nDrugs and diet.\nDrugs which induce sleep, known as hypnotics, include benzodiazepines (although these interfere with REM); nonbenzodiazepine hypnotics such as eszopiclone (Lunesta), zaleplon (Sonata), and zolpidem (Ambien); antihistamines such as diphenhydramine (Benadryl) and doxylamine; alcohol (ethanol), (which exerts an excitatory rebound effect later in the night and intereferes with REM) barbiturates (which have the same problem), melatonin (a component of the circadian clock) and cannabis (which may also interfere with REM). Some opioids (including morphine, codeine, heroin, and oxycodone) also induce sleep, and can disrupt sleep architecture and sleep stage distribution. The endogenously produced drug gamma-hydroxybutyrate (GHB) is capable of producing high quality sleep that is indistinguishable from natural sleep architecture in humans.\nStimulants, which inhibit sleep, include caffeine, an adenosine antagonist; amphetamine, methamphetamine, MDMA, empathogen-entactogens, and related drugs; cocaine, which can alter the circadian rhythm, and methylphenidate, which acts similarly; and eugeroic drugs like modafinil and armodafinil with poorly understood mechanisms. Consuming high amounts of the stimulant caffeine can result in interrupted sleep patterns and sometimes sleep deprivation. This vicious cycle can result in drowsiness which can then result in a higher consumption of caffeine in order to stay awake the next day. This cycle can lead to decreased cognitive function and an overall feeling of fatigue.\nSome drugs may alter sleep architecture without inhibiting or inducing sleep. Drugs that amplify or inhibit endocrine and immune system secretions associated with certain sleep stages have been shown to alter sleep architecture. The growth hormone releasing hormone receptor agonist MK-677 has been shown to increase REM in older adults as well as stage IV sleep in younger adults by approximately 50%.\nDiet.\nDietary and nutritional choices may affect sleep duration and quality. One 2016 review indicated that a high-carbohydrate diet promoted a shorter onset to sleep and a longer duration of sleep than a high-fat diet. A 2012 investigation indicated that mixed micronutrients and macronutrients are needed to promote quality sleep. A varied diet containing fresh fruits and vegetables, low saturated fat, and whole grains may be optimal for individuals seeking to improve sleep quality. Epidemiological studies indicate fewer insomnia symptoms and better sleep quality with a Mediterranean diet. Two studies have indicated a benefit of tart cherry juice for insomnia, or for increasing sleep efficiency as well as total sleep time. High-quality clinical trials on long-term dietary practices are needed to better define the influence of diet on sleep quality.\nIn culture.\nAnthropology.\nResearch suggests that sleep patterns vary significantly across cultures. The most striking differences are observed between societies that have plentiful sources of artificial light and ones that do not. The primary difference appears to be that pre-light cultures have more broken-up sleep patterns. For example, people without artificial light might go to sleep far sooner after the sun sets, but then wake up several times throughout the night, punctuating their sleep with periods of wakefulness, perhaps lasting several hours. During pre-industrial Europe, biphasic (bimodal) sleeping was considered the norm. Sleep onset was determined not by a set bedtime, but by whether there were things to do.\nThe boundaries between sleeping and waking are blurred in these societies. Some observers believe that nighttime sleep in these societies is most often split into two main periods, the first characterized primarily by deep sleep and the second by REM sleep.\nSome societies display a fragmented sleep pattern in which people sleep at all times of the day and night for shorter periods. In many nomadic or hunter-gatherer societies, people sleep on and off throughout the day or night depending on what is happening. Plentiful artificial light has been available in the industrialized West since at least the mid-19th century, and sleep patterns have changed significantly everywhere that lighting has been introduced. In general, people sleep in a more concentrated burst through the night, going to sleep much later, although this is not always the case.\nHistorian A. Roger Ekirch thinks that the traditional pattern of \"segmented sleep,\" as it is called, began to disappear among the urban upper class in Europe in the late 17th century and the change spread over the next 200 years; by the 1920s \"the idea of a first and second sleep had receded entirely from our social consciousness.\" Ekirch attributes the change to increases in \"street lighting, domestic lighting and a surge in coffee houses,\" which slowly made nighttime a legitimate time for activity, decreasing the time available for rest. Today in most societies people sleep during the night, but in very hot climates they may sleep during the day. During Ramadan, many Muslims sleep during the day rather than at night.\nIn some societies, people sleep with at least one other person (sometimes many) or with animals. In other cultures, people rarely sleep with anyone except for an intimate partner. In almost all societies, sleeping partners are strongly regulated by social standards. For example, a person might only sleep with the immediate family, the extended family, a spouse or romantic partner, children, children of a certain age, children of a specific gender, peers of a certain gender, friends, peers of equal social rank, or with no one at all. Sleep may be an actively social time, depending on the sleep groupings, with no constraints on noise or activity.\nPeople sleep in a variety of locations. Some sleep directly on the ground; others on a skin or blanket; others sleep on platforms or beds. Some sleep with blankets, some with pillows, some with simple headrests, some with no head support. These choices are shaped by a variety of factors, such as climate, protection from predators, housing type, technology, personal preference, and the incidence of pests.\nIn mythology and literature.\nSleep has been seen in culture as similar to death since antiquity; in Greek mythology, Hypnos (the god of sleep) and Thanatos (the god of death) were both said to be the children of Nyx (the goddess of night). John Donne, Samuel Taylor Coleridge, Percy Bysshe Shelley, John Keats and other poets have all written poems about the relationship between sleep and death. Shelley describes them as \"both so passing, strange and wonderful!\" Keats similarly poses the question: \"Can death be sleep, when life is but a dream\". Many people consider dying in one's sleep is the most peaceful way to die. Phrases such as \"big sleep\" and \"rest in peace\" are often used in reference to death, possibly in an effort to lessen its finality. Sleep and dreaming have sometimes been seen as providing the potential for visionary experiences. In medieval Irish tradition, in order to become a fil\u00ed, the poet was required to undergo a ritual called the \"imbas forosnai\", in which they would enter a mantic, trancelike sleep.\nMany cultural stories have been told about people falling asleep for extended periods of time. The earliest of these stories is the ancient Greek legend of Epimenides of Knossos. According to the biographer Diogenes La\u00ebrtius, Epimenides was a shepherd on the Greek island of Crete. One day, one of his sheep went missing and he went out to look for it, but became tired and fell asleep in a cave under Mount Ida. When he awoke, he continued searching for the sheep, but could not find it, so he returned to his old farm, only to discover that it was now under new ownership. He went to his hometown, but discovered that nobody there knew him. Finally, he met his younger brother, who was now an old man, and learned that he had been asleep in the cave for fifty-seven years.\nA far more famous instance of a \"long sleep\" today is the Christian legend of the Seven Sleepers of Ephesus, in which seven Christians flee into a cave during pagan times in order to escape persecution, but fall asleep and wake up 360 years later to discover, to their astonishment, that the Roman Empire is now predominantly Christian. The American author Washington Irving's short story \"Rip Van Winkle\", first published in 1819 in his collection of short stories \"The Sketch Book of Geoffrey Crayon, Gent.\", is about a man in colonial America named Rip Van Winkle who falls asleep on one of the Catskill Mountains and wakes up twenty years later after the American Revolution. The story is now considered one of the greatest classics of American literature.\nIn studies on consciousness and philosophy.\nAs an altered state of consciousness, dreamless deep sleep has been used as a way to investigate animal/human consciousness and qualia. Insights about differences of the living sleeping brain to its wakeful state and the transition period may have implications for potential explanations of human subjective experience, the so-called hard problem of consciousness, often delegated to the realm of philosophy, including neurophilosophy (or in some cases to religion and similar approaches).\nIn art.\nOf the thematic representations of sleep in art, physician and sleep researcher Meir Kryger wrote, \"[Artists] have intense fascination with mythology, dreams, religious themes, the parallel between sleep and death, reward, abandonment of conscious control, healing, a depiction of innocence and serenity, and the erotic.\"\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "27835", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=27835", "title": "Sociology of Religion", "text": ""}
