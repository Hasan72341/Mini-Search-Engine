{"id": "47696", "revid": "16055414", "url": "https://en.wikipedia.org/wiki?curid=47696", "title": "SUV", "text": "Type of automobile\nA sport utility vehicle (SUV) is a car classification that combines elements of road-going passenger cars with features from off-road vehicles, such as raised ground clearance and four-wheel drive.\nThere is no commonly agreed-upon definition of an SUV, and usage of the term varies between countries. Thus, it is \"a loose term that traditionally covers a broad range of vehicles with four-wheel drive.\" Some definitions claim that an SUV must be built on a light truck chassis; however, broader definitions consider any vehicle with off-road design features to be an SUV. A crossover SUV is often defined as an SUV built with a unibody construction (as with passenger cars); however, the designations are increasingly blurred because of the capabilities of the vehicles, the labelling by marketers, and the electrification of new models.\nThe predecessors to SUVs date back to military and low-volume models from the late 1930s, and the four-wheel-drive station wagons and carryalls that began to be introduced in 1949. Some SUVs produced today use unibody construction; however, in the past, more SUVs used body-on-frame construction. During the late 1990s and early 2000s, the popularity of SUVs significantly increased, often at the expense of the popularity of large sedans and station wagons. SUVs accounted for 45.9% of the world's passenger car market in 2021.\nSUVs have been criticized for a variety of environmental and safety-related reasons. They generally have poorer fuel efficiency and require more resources to manufacture than smaller vehicles, contributing more to climate change and environmental degradation. Between 2010 and 2018, SUVs were the second-largest contributor to the global increase in carbon emissions worldwide. Their higher center of gravity increases their risk of rollovers. Their higher front-end profile makes them at least twice as likely to kill pedestrians they hit. Additionally, the psychological sense of security they provide influences drivers to drive less cautiously, and may in-turn, cause others with smaller vehicles to opt for SUVs in the future under the sense of security, all the while increasing the rate of fatalities of pedestrians.\nDefinitions.\nThere is no universally accepted definition of the sport utility vehicle. Dictionaries, automotive experts, and journalists use varying wordings and defining characteristics, in addition to regional variations of usage by both the media and the general public. The auto industry also has not settled on one definition of the SUV.\nAmerican English.\nAutomotive websites' descriptions of SUVs range from specifically \"combining car-like appointments and wagon practicality with steadfast off-road capability\" with \"chair-height seats and picture-window visibility\" to the more general \"nearly anything with available all-wheel drive and raised ground clearance\". It is also suggested that the term \"SUV\" has replaced \"jeep\" as a general term for off-road vehicles.\nAmerican dictionary definitions for SUVs include:\nBritish English.\nIn British English, the terms \"4x4\" (pronounced \"four-by-four\"), \"jeep\", four wheel drive, or \"off-road vehicle\" are generally used instead of \"sport utility vehicle\". The sardonic term \"Chelsea tractor\" is also commonly used, due to the perceived popularity of the vehicles with urban residents of Chelsea, London, and their likeness to vehicles used by farmers.\nThe \"Collins English Dictionary\" defines a sport utility vehicle as a \"powerful vehicle with four-wheel drive that can be driven over rough ground. The abbreviation SUV is often used.\"\nOther countries.\nIn Europe, the term SUV is generally used for road-oriented vehicles, described as \"J-segment\" by the European Commission. \"Four-by-four\" or the brand name of the vehicle is typically used for off-road-oriented vehicles. Similarly, in New Zealand, vehicles designed for off-road use are typically referred to as \"four-wheel drives\" instead of SUVs.\nGovernment regulations.\nIn the United States, many government regulations simply have categories for \"off-highway vehicles\" which are loosely defined and often result in SUVs (along with pick-up trucks and minivans) being classified as light trucks. For example, corporate average fuel economy (CAFE) regulations previously included \"permit greater cargo-carrying capacity than passenger carrying volume\" in the definition for trucks, resulting in cars with removable rear seats, like the PT Cruiser, being classified as light trucks.\nThis classification as trucks allowed SUVs to be regulated less strictly than passenger cars under the Energy Policy and Conservation Act for fuel economy, and the Clean Air Act for emissions. However, from 2004 onwards, the United States Environmental Protection Agency (EPA) began to hold sport utility vehicles to the same tailpipe emissions standards as cars for criteria pollutants, though not greenhouse gas emissions standards as they were not set until 2010. In 2011, the CAFE regulations were changed to classify small, two-wheel-drive SUVs as passenger cars.\nHowever, the licensing and traffic enforcement regulations in the United States vary from state to state, and an SUV may be classified as a car in some states but as a truck in others. For industry production statistics, SUVs are counted in the light truck product segment.\nIn India, all SUVs are classified in the \"Utility Vehicle\" category per the Society of Indian Automobile Manufacturers (SIAM) definitions and carry a 27% excise tax. Those that are long, have a engine or larger, along with of ground clearance, are subject to a 30% excise duty.\nIn Australia, SUV sales were helped by having lower import duties than passenger cars. Up until January 2010, SUVs were subject to a 5% import tariff, compared with 10% for passenger cars.\nHigher parking fee.\nIn February 2024, voters in Paris mandated a triple parking charge rate for SUVs, citing environmental impact and street capacity; this followed similar decisions in Lyon and T\u00fcbingen with similar ordinances being considered by London, Brussels and Amsterdam.\nCharacteristics.\nChassis.\nMany years after most passenger cars had transitioned to unibody construction, most SUVs continued to use a separate body-on-frame method, due to being based on the chassis from a light truck, commercial vehicle, pickup truck, or off-road vehicle.\nThe first mass-produced unibody four-wheel-drive passenger car was the Russian 1955 GAZ-M20 Pobeda M-72, which could be considered the first crossover car. The 1977 Lada Niva was the first off-road vehicle to use both a unibody construction and a coil-sprung independent front suspension. The relatively compact Niva is considered a predecessor to the crossover SUV and combines a hatchback-like passenger car body with full-time four-wheel drive, low-range gearing, and lockable center differential.\nNonetheless, unibody SUVs remained rare until the 1984 Jeep Cherokee (XJ) was introduced and became a sales success. The introduction of the 1993 Jeep Grand Cherokee resulted in many of Jeep's SUV models using unibody construction, with many other brands following suit since the mid-1990s. Today, most SUVs in production use a unibody construction and relatively few models continue to use body-on-frame construction.\nBody style.\nSUVs are typically of a two-box design similar to a station wagon. The engine compartment is in the front, followed by a combined passenger/cargo area (unlike a sedan, which has a separate trunk/boot compartment).\nUp until approximately 2010, many SUV models were available in two-door body styles. Since then, manufacturers began to discontinue the two-door models as the four-door models became more popular.\nA few two-door SUVs remain available, such as the body-on-frame Suzuki Jimny, Mahindra Thar, Toyota Land Cruiser Prado, Ford Bronco, and Jeep Wrangler as well as the Range Rover Evoque crossover SUV.\nSafety.\nSUVs typically have high ground clearance and a tall body. This results in a high center of mass, which made SUVs more prone to roll-over accidents. In 2003, SUVs were quoted as 2.5 times more likely to roll over in a crash than regular cars.\nBetween 1991 and 2001, the United States saw a 150% increase in sport-utility vehicle rollover deaths. In 2001, though roll-overs constituted just 3% of vehicle crashes overall, they caused over 30% of occupant fatalities in crashes; and in crashes where the vehicle did roll over, SUV occupants in the early 2000s were nearly three times as likely to be killed as other car passengers. Vehicles with a high center of gravity do sometimes fail the moose test of maneuverability conducted by Swedish consumer magazine Teknikens V\u00e4rld, for example, the 1997 Mercedes-Benz A-Class and 2011 Jeep Grand Cherokee.\nThe increasing popularity of SUVs in the 1990s and early 2000s was partly due to buyers perceiving that SUVs provide greater safety for occupants, due to their larger size and raised ride height. Regarding the safety of other road users, SUVs are exempted from U.S. regulation stating that a passenger car bumper must protect the area between above the ground. This often increases the damage to the other car in a collision with an SUV, because the impact occurs at a higher location on the other car. In 2000\u20132001, 60% of fatal side-impact collisions were where the other vehicle was an SUV, an increase from 30% in 1980\u20131981.\nThe introduction of electronic stability control (ESC) and rollover mitigation, as well as increased analysis of the risks of a rollover, led the IIHS to report in 2015 that \"the rollover death rate of 5 per million registered vehicle years for 2011 models is less than a quarter of what it was for 2004 models. With ESC dramatically reducing rollover risk, the inherent advantages offered by SUVs' greater size, weight, and height emerge more clearly. Today's SUVs have the lowest driver death rate of any vehicle type.\"\nThe high danger for cyclists and pedestrians of being seriously injured or even killed by SUV drivers has caused some public protests against SUVs in urban areas. In 2020, a study by the U.S.-based IIHS found that, of a sample of 79 crashes from three urban areas in Michigan, SUVs caused more serious injuries compared to cars when impacts occurred at greater than . The IIHS noted the sample size of the study was small and that more research is needed. The popularity of SUVs contributed to an increase in pedestrian fatalities in the U.S. during the 2010s, alongside other factors such as distracted and drunk driving.\nA 2021 study by the University of Illinois Springfield showed that SUVs are 8 times more likely to kill children in a collision than passenger cars, and multiple times more lethal to adult pedestrians and cyclists.\nEnvironmental impact.\nSUVs generally have poorer fuel efficiency than smaller cars, and thus contribute more to environmental degradation and global warming.\nSUVs emit about 700 megatonnes of carbon dioxide per year, a gas which is linked to global warming. According to the International Energy Agency, from 2010 SUVs have been the second-largest contributor to the increase in global CO2 emissions, second only to the power sector.\nSUVs were responsible for all of the 3.3 million barrels a day growth in oil demand from passenger cars between 2010 and 2018, whereas efficiency improvements in smaller cars saved over 2 million barrels a day, with electric cars reducing oil demand by under 100,000 barrels a day.\nWhereas SUVs can be electrified, or converted to run on a variety of alternative fuels, including hydrogen, their (manufacturing) emissions will always be larger than smaller electric cars. On average, SUVs consume about a quarter more energy than medium-size cars. Furthermore, the vast majority of these vehicles are not converted to use alternative fuels.\nBetween 2010 and 2018 SUVs were the second largest contributor to the global increase in carbon emissions worldwide.\nTypes of SUV.\nCrossover SUV.\nThe \"crossover SUV\" segment (also known as \"CUVs\" or simply \"crossovers\") has become increasingly popular since around 2010. Crossovers are often based on a platform shared with a passenger car, as a result, they typically have better comfort and fuel economy, but less off-road capability (many crossovers are sold without all-wheel drive) than pickup truck-based SUVs.\nThe difference between crossovers and other SUVs is sometimes defined as a crossover being built using a unibody platform (the type used by most passenger cars), while an SUV is built using a body-on-frame platform (the type used by off-road vehicles and light trucks). However, these definitions are often blurred in practice, since unibody vehicles are also often referred to as SUVs. Also, crossover is a relatively recent term and early unibody SUVs (such as the 1984 Jeep Cherokee) are rarely called crossovers. Due to these inconsistencies, the term SUV is often used as a catch-all for both crossovers and SUVs.\nOutside of the United States, the term crossover tends to be used for C-segment (compact) or smaller vehicles, with large unibody vehicles\u2014such as the Mercedes-Benz GLS-Class, BMW X7, and Range Rover\u2014usually referred to as SUVs rather than crossovers. In the United Kingdom, a crossover is sometimes defined as a hatchback model with raised ride height and SUV-like styling features.\nExamples: \u00a0\nMini SUV.\nThe smallest size class of SUVs is the \"mini SUV\". In Japan, SUVs under \u2014such as the Mitsubishi Pajero Mini\u2014are included in the kei car category and therefore attract lower taxes.\nMany recent vehicles labeled as mini SUVs are technically subcompact crossovers and are built on the platform of a subcompact (also called supermini or B-segment) passenger car.\nExamples: \u00a0\nCompact SUV.\nThe \"compact SUV\" is the next bigger-size class after mini SUVs.\nMany recent vehicles labeled as compact SUVs are technically compact crossovers and are built on the platform of a compact (C-segment) passenger car.\nExamples: \u00a0\nMid-size SUV.\nThe next larger size is called the \"mid-size SUV\". Some mid-size SUVs are based on platforms shared with passenger cars and therefore, are crossovers. Other mid-size SUVs are based on compact or mid-size pickups.\nExamples: \u00a0\nFull-size SUV.\nFull-size SUVs are the largest size of commonly produced SUVs. Some, such as the Ford Expedition, and Chevrolet Tahoe, are marketed for their off-road capabilities, and others, such as the Lincoln Navigator and Cadillac Escalade, are marketed as luxury vehicles. While a few full-size SUVs are built on dedicated platforms; most share their platforms with full-size pickup trucks.\nExamples: \u00a0\nExtended-length SUV.\nSome North American SUVs are available as a long-bodied version of a full-size SUV, which is called an \"extended-length SUV\" like the Ford Expedition EL and the Chevrolet Suburban. The additional length is used to provide extra space for rear passengers or cargo. As per the full-size SUVs they are based on, most extended-length SUVs are built on dedicated platforms, full-sized pickups (1\u20442 ton), or heavy-duty pickups (3\u20444 ton or more).\nExtended-length SUVs are mostly sold in North America but may also be exported to other markets in small numbers.\nExamples: \u00a0\nCoupe SUV.\nSome SUVs or crossovers with sloping rear rooflines are marketed as \"coupe crossover SUVs\" or \"coupe SUVs\", even though they have four side doors for passenger access to the seats and rear hatches for cargo area access.\nHistory.\n1930s to 1948.\nJust before and during World War II, prototypes and low-volume production examples of military cars with sedan or station wagon-type bodies and rugged, off-road capable four-wheel drive chassis began to appear around the world. These early models included the 1936 Kurogane Type 95 from Japan, the 1938 GAZ-61 from Russia as well as the 1941 Volkswagen Kommandeurswagen and 1936 Opel Gel\u00e4ndesportwagen from Germany. An early predecessor to the design of modern SUVs was the 1940 Humber Heavy Utility, a four-wheel-drive off-road vehicle built on the chassis of the Humber Super Snipe passenger car.\nThe most prohibitive initial factors to the potential civilian popularity of an SUV-like car were their cost and the availability of certain critical parts. Before the war, adding four-wheel drive to a car almost doubled its cost. Compared to a common, rear-wheel drive vehicle, any 4WD (four-wheel drive) needed many essential extra components, including a transfer case, a second differential, and constant-velocity joints for the driven front axle\u2014which were expensive due to the precision involved in this required manufacturing gears and other specialized parts. Before World WarII, these were produced in the United States by only a few specialized firms with limited production capacity. Due to the increase in demand for parts for the war effort, in early 1942 Ford, Dodge, and Chevrolet joined in fabricating these parts in mass quantities, boosting their production more than 100-fold.\nAn early usage of the term was the 1947 Crosley CC Four Sport Utility model, which used a convertible wagon body style and is therefore unrelated to the design of later SUVs.\n1949 to 1970s.\nSeveral models of carryall wagons began to be offered with four-wheel drive, beginning in 1949 when the Willys Jeep Station Wagon introduced the option of four-wheel drive. Four-wheel-drive versions of the Chevrolet Suburban were introduced for 1955, followed by the International Harvester Travelall in 1956 (credited as being the first full-size SUV) and the Power Wagon Town Wagon in 1957.\nDeveloped as a competitor to the Jeep CJ, the compact International Scout was introduced in 1961, offering either two- or four-wheel drive and a variety of engine options. The Harvester Scout provided many other options designed to appeal to a wide range of customers for numerous uses as well. The 1963 Jeep Wagoneer (SJ) introduced a sophisticated station wagon body design that was more carlike than any other four-wheel-drive vehicle on the market. The 1967 Toyota Land Cruiser FJ55 station wagon was the first comfort-oriented version of the Land Cruiser off-road vehicle. The two-door Chevrolet K5 Blazer (and related GMC K5 Jimmy) were introduced for 1969, and the two-door International Scout II was introduced in 1971. The first European luxury off-road vehicle was the 1970 Range Rover Classic, which was marketed as a luxury car for both on-road and off-road usage.\nIn 1972 Subaru Leone 4WD wagon was introduced in Japan, which was not designed as an off-road vehicle, but a version of the front-wheel-drive passenger car. Some argue that this was the first SUV. It was also classified as a commercial vehicle in the home market, just like later SUVs.\nThe first relevant usage of the term SUV was in advertising brochures for the full-sized 1974 Jeep Cherokee (SJ), which used the wording \"sport(s) utility vehicle\" as a description for the vehicle. The 1966 Ford Bronco included a \"sport utility\" model; however, in this case it was used for the two-door pickup truck version.\nThe VAZ-2121 (now designated Lada Niva Legend) was the first mass-market 4WD unibody car in some markets in 1977. The AMC Eagle introduced in the North American market in 1979, and is often called the first mass-market \"crossover\", although that term had not been coined at the time. In contrast to truck or utility-vehicle based designs and the Niva that was purpose-built for rural areas, American Motors Corporation (AMC) utilized a long-serving existing car platform and designed a new automatic full-time AWD system. It was first with \"SUV styling on a raised passenger-car platform combined with AWD.\" \"Four Wheeler\" magazine described the AMC Eagle as \"the beginning of a new generation of cars\".\n1980s to 1990s.\nThe compact-sized 1984 Jeep Cherokee (XJ) is often credited as the first SUV in the modern understanding of the term. The use of unibody construction was unique at the time for a four-wheel drive and also reduced the weight of the new Cherokee. It also appealed to urban families due to having a more compact size (compared to the full-size Wagoneer and previous generation Cherokee SJ models) as well as a plush interior resembling a station wagon. As the new Cherokee became a major sales success, the term \"sport utility vehicle\" began to be used in the national press for the first time. \"The advent and immediate success of AMC/Jeep's compact four-door Cherokee turned the truck industry upside down.\"\nThe U.S. corporate average fuel economy (CAFE) standard was introduced in 1975 to reduce fuel usage, but included relaxed regulations for \"light trucks\" to avoid businesses paying extra taxes for work vehicles. This created a loophole that manufacturers increasingly exploited since the 1980s oil glut (which started an era of cheap gasoline), whereby SUVs were designed to be classified as light trucks despite their primary use as passenger vehicles to receive tax concessions and less stringent fuel economy requirements. This enabled manufacturers to sell more profitable, larger, more polluting vehicles, instead of the smaller, less polluting, less profitable cars, that the CAFE regulations intended.\nFor example, the United States Environmental Protection Agency agreed to classify the new Jeep Cherokee as a light truck following lobbying from its manufacturer; the Cherokee was then marketed by the company as a passenger vehicle. This increased the SUV boom as other manufacturers introduced their own SUVs in response to the compact Cherokee taking sales from their regular cars.\nIn 1994 the U.S. Environmental Protection Agency began classifying vehicles by \"market class\". For SUVs in 1994 they included three Jeep models, the Cherokee, Grand Cherokee and Wrangler. Two Ford models were the Bronco and the Explorer. Six General Motors models including the GMC Jimmy, the Yukon, and the Suburban 1500; the Chevrolet Suburban 1500, and the Blazer (1500 and S10); the Geo Tracker (Convertible or Van); and finally the Oldsmobile Bravada. Eleven Japanese models classified as SUVs were the Toyota 4Runner and Land Cruiser; the Honda Passport; the Nissan Pathfinder; the Mazda Navajo; the Mitsubishi Montero; the Isuzu Amigo, Rodeo, and Trooper; and the Suzuki Samurai and Sidekick. From Europe the three Land Rover models, the Range Rover, the Defender and the Discovery were classified as SUVs.\nBy late 1996 \"Consumers Digest\" magazine was calling the trend an \"SUV craze\", and by 1999 the U.S. sales of SUVs and light trucks for the first time exceeded sales of regular passenger cars.2\n2000s.\nBy 2003, there were 76 million SUVs and light trucks on U.S. roads, representing approximately 35% of the vehicles on the road.\nCar manufacturers were keen to promote SUV sales over other types of cars due to higher profits in the segment. An SUV could be sold with a profit margin of US$ or more (US$ per SUV in the case of the Ford Excursion), while compact cars were often sold at a loss of a few hundred dollars per car. As a result, several manufacturing plants were converted from car production to SUV production (such as the General Motors plant in Arlington, Texas in 1996), and many long-running U.S. sedan models were discontinued.\nFrom the mid-2000s until 2010, U.S. sales of SUVs and other light trucks experienced a dip due to increasing fuel prices and then a declining economy. From 2008 until 2010, General Motors closed four assembly plants that were producing SUVs and trucks. Sales of SUVs and light trucks sales began to recover in 2010, as fuel prices decreased and the North American economy improved.\n2010s to 2020s.\nIn 2019, the International Energy Agency (IEA) reported that the global number of SUVs and crossovers on the road multiplied by six since 2010\u2014from 35 million to 200 million vehicles, and their market share has grown to 40 percent of worldwide new light-vehicle sales at the end of the decade.\nBy 2013, small and compact SUVs had increased to become the third-largest market segment. Since the early 2000s, new versions have been introduced to appeal to a wider audience, such as crossovers and other small SUVs. Larger SUVs also remained popular, with sales of General Motors' large SUV models increasing significantly in 2013.\nIn 2015, global sales of SUVs overtook the \"lower medium car\" segment, to become the largest market segment, accounting for 22.9% of \"light vehicle\" sales in 2015. The following year, worldwide SUV sales experienced further growth of 22%. The world's fastest-growing SUV markets in 2014\u20132015 were: China (+\u200a47.9%), Italy (+\u200a48.6%), Spain (+\u200a42%), Portugal (+\u200a54.8 %), and Thailand (+\u200a56.4%). The SUV segment further grew to 26% of the global passenger car market in 2016, then to 36.8% of the market in Q1\u2013Q3 of 2017.\nIn the U.S. at the end of 2016, sales of SUVs and light-duty trucks had surpassed traditional car sales for the year by over 3 million units. Manufacturers continued to phase out the production of sedan models, replacing them with new models of SUVs.\nLuxury brands have increasingly introduced SUV or crossover models in the 2010s. For example: Rolls-Royce Cullinan, Bentley Bentayga, Aston Martin DBX, Maserati Levante, Lamborghini Urus, and Ferrari Purosangue.\nIn 2019 SUVs made up 47.4% of U.S. sales compared to only 22.1% for sedans.\nMotorsport.\nSUVs have competed in various off-road racing competitions, such as the Dakar Rally, Baja 1000, FIA Cross-Country Rally World Cup, King of the Hammers, and Australasian Safari. SUVs have also competed in the Trophee Andros ice-racing series.\nNicknames.\nSeveral derogatory or pejorative terms for SUVs are based on the combination of an affluent suburb name and \"tractor\", particularly for expensive vehicles from luxury brands. Examples include \"Toorak Tractor\" (Melbourne, Australia), \"Chelsea Tractor\" (London, England) and \"Remuera Tractor\" (Auckland, New Zealand). These terms relate to the theory that four-wheel drive capabilities are not required by affluent SUV owners, and that the SUV is purchased as a status symbol rather than for practical reasons.\nIn Norway, the term ('Stock Exchange Tractor') serves a similar purpose. In the Netherlands, SUVs are sometimes called \"P.C. Hooft-tractors\" after the exclusive P.C. Hooftstraat Amsterdam shopping street.\nCommercial SUVs.\nA commercial SUV is an SUV or crossover, that is used for commercial purposes. The category is very similar to panel trucks since the Chevrolet Suburban (an SUV) had panel truck versions, which were used for commercial purposes.\nThe first SUV-like vehicle that had commercial versions was the Chevrolet Suburban panel truck. Panel trucks by American manufacturers were built until the late 1970s.\nWhile panel trucks manufactured by European manufacturers were rare, commercial versions of off-road vehicles were very common, Land Rover manufactured commercial versions of the Land Rover and the Defender. Commercial SUVs are factory-built and most of them are not independent conversions, which means they can be bought from dealerships and showrooms.\nExamples of SUVs used as commercial vehicles in Europe include: Citroen C5 Aircross Commercial SUV, the Land Rover Discovery, the Dacia Duster Flika, and the Mitsubishi Pajero.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "47697", "revid": "1255878", "url": "https://en.wikipedia.org/wiki?curid=47697", "title": "Timecode", "text": "Sequence of numeric codes generated at regular intervals by a timing synchronization system\nA timecode (alternatively, time code) is a sequence of numeric codes generated at regular intervals by a timing synchronization system. Timecode is used in video production, show control and other applications which require temporal coordination or logging of recording or actions.\nVideo and film.\nIn video production and filmmaking, SMPTE timecode is used extensively for synchronization, and for logging and identifying material in recorded media. During filmmaking or video production shoot, the camera assistant will typically log the start and end timecodes of shots, and the data generated will be sent on to the editorial department for use in referencing those shots. This shot-logging process was traditionally done by hand using pen and paper, but is now typically done using shot-logging software running on a laptop computer that is connected to the timecode generator or the camera itself.\nThe SMPTE family of timecodes are almost universally used in film, video and audio production, and can be encoded in many different formats, including:\nKeykode, while not a timecode, is used to identify specific film frames in film post-production that uses physical film stock. Keykode data is normally used in conjunction with SMPTE timecode.\nRewritable consumer timecode is a proprietary consumer video timecode system that is not frame-accurate, and is therefore not used in professional post-production.\nOther formats.\nTimecodes for purposes other than video and audio production include:\nTimecode generators.\nDepending on the environment, timecode generators can take various forms."}
{"id": "47698", "revid": "8524693", "url": "https://en.wikipedia.org/wiki?curid=47698", "title": "Victoria Adams", "text": "Victoria Adams may refer to:\nSee also.\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about people with the same name. "}
{"id": "47700", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=47700", "title": "Coral", "text": "Marine invertebrates of the subphylum Anthozoa\nCorals are colonial marine invertebrates within the subphylum Anthozoa of the phylum Cnidaria. They typically form compact colonies of many identical individual polyps. Coral species include the important reef builders that inhabit tropical oceans and secrete calcium carbonate to form a hard skeleton.\nA coral \"group\" is a colony of very many genetically identical polyps. Each polyp is a sac-like animal typically only a few millimeters in diameter and a few centimeters in height. A set of tentacles surround a central mouth opening. Each polyp excretes an exoskeleton near the base. Over many generations, the colony thus creates a skeleton characteristic of the species which can measure up to several meters in size. Individual colonies grow by asexual reproduction of polyps. Corals also breed sexually by spawning: polyps of the same species release gametes simultaneously overnight, often around a full moon. Fertilized eggs form planulae, a mobile early form of the coral polyp which, when mature, settles to form a new colony.\nAlthough some corals are able to catch plankton and small fish using stinging cells on their tentacles, most corals obtain the majority of their energy and nutrients from photosynthetic unicellular dinoflagellates of the genus \"Symbiodinium\" that live within their tissues. These are commonly known as zooxanthellae and give the coral color. Such corals require sunlight and grow in clear, shallow water, typically at depths less than , but corals in the genus \"Leptoseris\" have been found as deep as . Corals are major contributors to the physical structure of the coral reefs that develop in tropical and subtropical waters, such as the Great Barrier Reef off the coast of Australia. These corals are increasingly at risk of bleaching events where polyps expel the zooxanthellae in response to stress such as high water temperature or toxins.\nOther corals do not rely on zooxanthellae and can live globally in much deeper water, such as the cold-water genus \"Lophelia\" which can survive as deep as . Some have been found as far north as the Darwin Mounds, northwest of Cape Wrath, Scotland, and others off the coast of Washington state and the Aleutian Islands.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nTaxonomy.\nThe classification of corals has been discussed for millennia, owing to having similarities to both plants and animals. Aristotle's pupil Theophrastus described the red coral, \"korallion\", in his book on stones, implying it was a mineral, but he described it as a deep-sea plant in his \"Enquiries on Plants\", where he also mentions large stony plants that reveal bright flowers when under water in the Gulf of Heroes. Pliny the Elder stated boldly that several sea creatures including sea nettles and sponges \"are neither animals nor plants, but are possessed of a third nature (\"tertia natura\")\". Petrus Gyllius copied Pliny, introducing the term \"zoophyta\" for this third group in his 1535 book \"On the French and Latin Names of the Fishes of the Marseilles Region\"; it is popularly but wrongly supposed that Aristotle created the term. Gyllius further noted, following Aristotle, how hard it was to define what was a plant and what was an animal. The Babylonian Talmud refers to coral among a list of types of trees, and the 11th-century French commentator Rashi describes it as \"a type of tree (\u05de\u05d9\u05df \u05e2\u05e5) that grows underwater that goes by the (French) name 'coral'.\"\nThe Persian polymath Al-Biruni (d.1048) classified sponges and corals as animals, arguing that they respond to touch. Nevertheless, people believed corals to be plants until the eighteenth century when William Herschel used a microscope to establish that coral had the characteristic thin cell membranes of an animal.\nPresently, corals are classified as species of animals within the sub-classes Hexacorallia and Octocorallia of the class Anthozoa in the phylum Cnidaria. Hexacorallia includes the stony corals and these groups have polyps that generally have a 6-fold symmetry. Octocorallia includes blue coral and soft corals. Species of Octocorallia have polyps with an eightfold symmetry, with each polyp having eight tentacles and eight mesenteries. The group of corals is paraphyletic because the sea anemones are also in the sub-class Hexacorallia.\nSystematics.\nThe delineation of coral species is challenging as hypotheses based on morphological traits contradict hypotheses formed via molecular tree-based processes. As of 2020, there are 2175 identified separate coral species, 237 of which are currently endangered, making distinguishing corals to be the utmost of importance in efforts to curb extinction. Adaptation and delineation continues to occur in species of coral in order to combat the dangers posed by the climate crisis. Corals are colonial modular organisms formed by asexually produced and genetically identical modules called polyps. Polyps are connected by living tissue to produce the full organism.\u00a0The living tissue allows for inter module communication (interaction between each polyp), which appears in colony morphologies produced by corals, and is one of the main identifying characteristics for\u00a0a species of coral.\nThere are two main classifications for corals: hard coral (scleractinian and stony coral) which form reefs by a calcium carbonate base, with polyps that bear six stiff tentacles, and soft coral (Alcyonacea and ahermatypic coral) which are pliable and formed by a colony of polyps with eight feather-like tentacles.\u00a0These two classifications arose from https:// in their branch tips and bases that arose through developmental signaling pathways such as Hox, Hedgehog, Wnt, and BMP.\nScientists typically select \"Acropora\" as research models since they are the most diverse genus of hard coral, having over 120 species.\u00a0Most species within this genus have polyps which are dimorphic: axial polyps grow rapidly and have lighter coloration, while radial polyps are small and are darker in coloration. In the \"Acropora\" genus, gamete synthesis and photosynthesis occur at the basal polyps, growth occurs mainly at the radial polyps. Growth at the site of the radial polyps encompasses two processes: asexual reproduction via https://, and skeleton deposition of the calcium carbonate via extracellular matrix (ECM) proteins acting as differentially expressed (DE) signaling genes between both branch tips and bases. These processes lead to colony differentiation, which is the most accurate distinguisher between coral species. In the Acropora genus, colony differentiation through up-regulation and down-regulation of DEs.\nSystematic studies of soft coral species have faced challenges due to a lack of taxonomic knowledge.\u00a0Researchers have not found enough variability within the genus to confidently delineate similar species, due to a low rate in mutation of mitochondrial DNA.\nEnvironmental factors, such as the rise of temperatures and acid levels in our oceans account for some speciation of corals in the form of species lost.\u00a0Various coral species have heat shock proteins (HSP) that are also in the category of DE across species.\u00a0These HSPs help corals combat the increased temperatures they are facing which lead to protein denaturing, growth loss, and eventually coral death.\u00a0Approximately 33% of coral species are on the International Union for Conservation of Nature's endangered species list and at risk of species loss.\u00a0Ocean acidification (falling pH levels in the oceans) is threatening the continued species growth and differentiation of corals.\u00a0Mutation rates of \"Vibrio shilonii\", the reef pathogen responsible for coral bleaching, heavily outweigh the\u00a0typical reproduction rates of coral colonies when pH levels fall. Thus, corals are unable to mutate their HSPs and other climate change preventative genes to combat the increase in temperature and decrease in pH at a competitive rate to these pathogens responsible for coral bleaching, resulting in species loss.\nAnatomy.\nFor most of their life corals are sessile animals of colonies of genetically identical polyps. Each polyp varies from millimeters to centimeters in diameter, and colonies can be formed from many millions of individual polyps. Stony coral (also known as hard coral) polyps produce a skeleton composed of calcium carbonate to strengthen and protect the organism. This is deposited by the polyps and by the coenosarc, the living tissue that connects them. The polyps sit in cup-shaped depressions in the skeleton known as corallites. Colonies of stony coral are markedly variable in appearance; a single species may adopt an encrusting, plate-like, bushy, columnar or massive solid structure, the various forms often being linked to different types of habitat, with variations in light level and water movement being significant.\nThe body of the polyp may be roughly compared in a structure to a sac, the wall of which is composed of two layers of cells. The outer layer is known technically as the ectoderm, the inner layer as the endoderm. Between ectoderm and endoderm is a supporting layer of gelatinous substance termed mesoglea, secreted by the cell layers of the body wall. The mesoglea can contain skeletal elements derived from cells migrated from the ectoderm.\nThe sac-like body built up in this way is attached to a hard surface, which in hard corals are cup-shaped depressions in the skeleton known as corallites. At the center of the upper end of the sac lies the only opening called the mouth, surrounded by a circle of tentacles which resemble glove fingers. The tentacles are organs which serve both for tactile sense and for the capture of food. Polyps extend their tentacles, particularly at night, often containing coiled stinging cells (cnidocytes) which pierce, poison and firmly hold living prey paralyzing or killing them. Polyp prey includes plankton such as copepods and fish larvae. Longitudinal muscular fibers formed from the cells of the ectoderm allow tentacles to contract to convey the food to the mouth. Similarly, circularly disposed muscular fibers formed from the endoderm permit tentacles to be protracted or thrust out once they are contracted. In both stony and soft corals, the polyps can be retracted by contracting muscle fibers, with stony corals relying on their hard skeleton and cnidocytes for defense. Soft corals generally secrete terpenoid toxins to ward off predators.\nIn most corals, the tentacles are retracted by day and spread out at night to catch plankton and other small organisms. Shallow-water species of both stony and soft corals can be zooxanthellate, the corals supplementing their plankton diet with the products of photosynthesis produced by these symbionts. The polyps interconnect by a complex and well-developed system of gastrovascular canals, allowing significant sharing of nutrients and symbionts.\nThe external form of the polyp varies greatly. The column may be long and slender, or may be so short in the axial direction that the body becomes disk-like. The tentacles may number many hundreds or may be very few, in rare cases only one or two. They may be simple and unbranched, or feathery in pattern. The mouth may be level with the surface of the peristome, or may be projecting and trumpet-shaped.\nSoft corals.\nSoft corals have no solid exoskeleton as such. However, their tissues are often reinforced by small supportive elements known as sclerites made of calcium carbonate. The polyps of soft corals have eight-fold symmetry, which is reflected in the \"Octo\" in Octocorallia.\nSoft corals vary considerably in form, and most are colonial. A few soft corals are stolonate, but the polyps of most are connected by sheets of tissue called coenosarc, and in some species these sheets are thick and the polyps deeply embedded in them. Some soft corals encrust other sea objects or form lobes. Others are tree-like or whip-like and have a central axial skeleton embedded at their base in the matrix of the supporting branch. These branches are composed of a fibrous protein called gorgonin or of a calcified material.\nStony corals.\nThe polyps of stony corals have six-fold symmetry. In stony corals, the tentacles are cylindrical and taper to a point, but in soft corals they are pinnate with side branches known as pinnules. In some tropical species, these are reduced to mere stubs and in some, they are fused to give a paddle-like appearance.\nCoral skeletons are biocomposites (mineral + organics) of calcium carbonate, in the form of calcite or aragonite. In scleractinian corals, \"centers of calcification\" and fibers are clearly distinct structures differing with respect to both morphology and chemical compositions of the crystalline units. The organic matrices extracted from diverse species are acidic, and comprise proteins, sulphated sugars and lipids; they are species specific. The soluble organic matrices of the skeletons allow to differentiate zooxanthellae and non-zooxanthellae specimens.\nSpecifically, calcification in corals takes place within specialized vesicles inside cells or at the interface between the calicoblastic ectoderm and the growing skeleton. This process is precisely regulated to control the formation and orientation of calcium carbonate crystals. The Skeletal Organic Matrix (SOM), primarily composed of proteins secreted by the calicoblastic ectoderm, plays a central role in this regulation. Among these proteins, CARPs (coral acid-rich proteins) and SAPs (skeletal aspartic acid-rich proteins) facilitate the transport of calcium ions () toward the calcifying space. Importantly, carbonate precipitation in the calicoblastic space is not solely governed by the aragonite saturation state (formula_1); rather, it depends on the orchestrated activity of SOM components. The distinct spatial distribution of these proteins\u2014observed both on coral skeletons and in coral cell cultures\u2014underscores their specific and diverse roles in directing crystal nucleation, growth, and overall skeletal architecture.\nThe enzyme \u03b1-carbonic anhydrase (CA) plays a vital role in regulating inorganic carbon balance within coral cells. It catalyzes two reversible reactions: the hydration of carbon dioxide () into bicarbonate () and a proton (), and the dehydration of bicarbonate back into and a proton. Through these interconversions, \u03b1-carbonic anhydrase facilitates the efficient transport and supply of dissolved inorganic carbon for both photosynthesis and calcification, maintaining the delicate equilibrium between and bicarbonate required for coral metabolic and skeletal processes.\nOcean acidification poses a major threat to coral calcification by reducing the availability of carbonate ions (), which are essential for forming calcium carbonate () skeletons. Under increasingly acidified conditions, corals must expend more energy to pump protons () out of the calcifying space in order to maintain favorable conditions for mineral deposition. This heightened energetic demand compromises coral growth and skeletal density, resulting in weaker and more brittle structures. Consequently, coral reefs become more susceptible to physical damage from waves and storms, as well as less resilient to other environmental stressors.\nEcology.\nFeeding.\nPolyps feed on a variety of small organisms, from microscopic zooplankton to small fish. The polyp's tentacles immobilize or kill prey using stinging cells called cnidocytes, commonly called nematocysts. These cells carry venom which they rapidly release in response to contact with another organism. A dormant nematocyst discharges in response to nearby prey touching the trigger. A stiff flap called an operculum opens and its stinging apparatus fires the barb into the prey. The venom is injected through the hollow filament to immobilise the prey; the tentacles then manoeuvre the prey into the stomach. Once the prey is digested the stomach reopens allowing the elimination of waste products and the beginning of the next hunting cycle.\nIntracellular symbionts.\nMany corals, as well as other cnidarian groups such as sea anemones form a symbiotic relationship with a class of dinoflagellate algae, zooxanthellae of the genus \"Symbiodinium\", which can form as much as 30% of the tissue of a polyp. Typically, each polyp harbors one species of alga, and coral species show a preference for \"Symbiodinium\". Young corals are not born with zooxanthellae, but acquire the algae from the surrounding environment, including the water column and local sediment. The main benefit of the zooxanthellae is their ability to photosynthesize which supplies corals with the products of photosynthesis, including glucose, glycerol, also amino acids, which the corals can use for energy. Zooxanthellae also benefit corals by aiding in calcification, for the coral skeleton, and waste removal. In addition to the soft tissue, microbiomes are also found in the coral's mucus and (in stony corals) the skeleton, with the latter showing the greatest microbial richness.\nThe zooxanthellae benefit from a safe place to live and consume the polyp's carbon dioxide, phosphate and nitrogenous waste. Stressed corals will eject their zooxanthellae, a process that is becoming increasingly common due to strain placed on coral by rising ocean temperatures. Mass ejections are known as coral bleaching because the algae contribute to coral coloration; some colors, however, are due to host coral pigments, such as green fluorescent proteins (GFPs). Ejection increases the polyp's chance of surviving short-term stress and if the stress subsides they can regain their algae. Sometimes, instead of regaining the same algal species, they will switch out their heat intolerant microalgal symbiont for a more heat tolerant species as a response to rising ocean temperatures. Unfortunately, heat-stress tolerant algae may not always be available or accepted by the coral host. If the stressful conditions persist, the polyp eventually dies. Zooxanthellae are located within the coral cytoplasm and due to the algae's photosynthetic activity the internal pH of the coral can be raised; this behavior indicates that the zooxanthellae are responsible to some extent for the metabolism of their host corals. Stony Coral Tissue Loss Disease has been associated with the breakdown of host-zooxanthellae physiology. Moreover, Vibrio bacterium are known to have virulence traits used for host coral tissue damage and photoinhibition of algal symbionts. Therefore, both coral and their symbiotic microorganisms could have evolved to harbour traits resistant to disease and transmission.\nReproduction.\nCorals can be both gonochoristic (unisexual) and hermaphroditic, each of which can reproduce sexually and asexually. Reproduction also allows coral to settle in new areas. Reproduction is coordinated by chemical communication.\nSexual.\nCorals predominantly reproduce sexually. About 25% of hermatypic corals (reef-building stony corals) form single-sex (gonochoristic) colonies, while the rest are hermaphroditic. It is estimated more than 67% of coral are simultaneous hermaphrodites.\nBroadcasters.\nAbout 75% of all hermatypic corals \"broadcast spawn\" by releasing gametes\u2014eggs and sperm\u2014into the water where they meet and fertilize to spread offspring. Corals often synchronize their time of spawning. This reproductive synchrony is essential so that male and female gametes can meet. Spawning frequently takes place in the evening or at night, and can occur as infrequently as once a year, and within a window of 10\u201330 minutes.\nSynchronous spawning is very typical on the coral reef, and often, all corals spawn on the same night even when multiple species are present. Synchronous spawning may form hybrids and is perhaps involved in coral speciation.\nEnvironmental cues that influence the release of gametes into the water vary from species to species. The cues involve temperature change, lunar cycle, day length, and possibly chemical signalling. \nOther factors that affect the rhythmicity of organisms in marine habitats include salinity, mechanical forces, and pressure or magnetic field changes.\nMass coral spawning often occurs at night on days following a full moon. A full moon is equivalent to four to six hours of continuous dim light exposure, which can cause light-dependent reactions in protein. Corals contain light-sensitive cryptochromes, proteins whose light-absorbing flavin structures are sensitive to different types of light. This allows corals such as \"Dipsastraea speciosa\" to detect and respond to changes in sunlight and moonlight.\nMoonlight itself may actually suppress coral spawning. The most immediate cue to cause spawning appears to be the dark portion of the night between sunset and moonrise. \nOver the lunar cycle, moonrise shifts progressively later, occurring after sunset on the day of the full moon. The resulting dark period between day-light and night-light removes the suppressive effect of moonlight and enables coral to spawn.\nThe spawning event can be visually dramatic, clouding the usually clear water with gametes. Once released, gametes fertilize at the water's surface and form a microscopic larva called a planula, typically pink and elliptical in shape. A typical coral colony needs to release several thousand larvae per year to overcome the odds against formation of a new colony.\nStudies suggest that light pollution desynchronizes spawning in some coral species.\nIn areas such as the Red Sea, as many as 10 out of 50 species may be showing spawning asynchrony, compared to 30 years ago. The establishment of new corals in the area has decreased and in some cases ceased. The area was previously considered a refuge for corals because mass bleaching events due to climate change had not been observed there. Coral restoration techniques for coral reef management are being developed to increase fertilization rates, larval development, and settlement of new corals.\nBrooders.\nBrooding species are most often ahermatypic (not reef-building) in areas of high current or wave action. Brooders release only sperm, which is negatively buoyant, sinking onto the waiting egg carriers that harbor unfertilized eggs for weeks. Synchronous spawning events sometimes occur even with these species. After fertilization, the corals release planula that are ready to settle.\nPlanulae.\nThe time from spawning to larval settlement is usually two to three days but can occur immediately or up to two months. Broadcast-spawned planula larvae develop at the water's surface before descending to seek a hard surface on the benthos to which they can attach and begin a new colony. The larvae often need a biological cue to induce settlement such as specific crustose coralline algae species or microbial biofilms. High failure rates afflict many stages of this process, and even though thousands of eggs are released by each colony, few new colonies form. During settlement, larvae are inhibited by physical barriers such as sediment, as well as chemical (allelopathic) barriers. The larvae metamorphose into a single polyp and eventually develops into a juvenile and then adult by asexual budding and growth.\nAsexual.\nWithin a coral head, the genetically identical polyps reproduce asexually, either by budding (gemmation) or by dividing, whether longitudinally or transversely.\nBudding involves splitting a smaller polyp from an adult. As the new polyp grows, it forms . The distance between the new and adult polyps grows, and with it, the coenosarc (the common body of the colony). Budding can be intratentacular, from its oral discs, producing same-sized polyps within the ring of tentacles, or extratentacular, from its base, producing a smaller polyp.\nDivision forms two polyps that each become as large as the original. Longitudinal division begins when a polyp broadens and then divides its coelenteron (body), effectively splitting along its length. The mouth divides and new tentacles form. The two polyps thus created then generate their missing body parts and exoskeleton. Transversal division occurs when polyps and the exoskeleton divide transversally into two parts. This means one has the basal disc (bottom) and the other has the oral disc (top); the new polyps must separately generate the missing pieces.\nAsexual reproduction offers the benefits of high reproductive rate, delaying senescence, and replacement of dead modules, as well as geographical distribution.\nColony division.\nWhole colonies can reproduce asexually, forming two colonies with the same genotype. The possible mechanisms include fission, bailout and fragmentation. Fission occurs in some corals, especially among the family Fungiidae, where the colony splits into two or more colonies during early developmental stages. Bailout occurs when a single polyp abandons the colony and settles on a different substrate to create a new colony. Fragmentation involves individuals broken from the colony during storms or other disruptions. The separated individuals can start new colonies.\nCoral microbiomes.\nCorals are one of the more common examples of an animal host whose symbiosis with microalgae can turn to dysbiosis, and is visibly detected as bleaching. Coral microbiomes have been examined in a variety of studies, which demonstrate how oceanic environmental variations, most notably temperature, light, and inorganic nutrients, affect the abundance and performance of the microalgal symbionts, as well as calcification and physiology of the host.\nStudies have also suggested that resident bacteria, archaea, and fungi additionally contribute to nutrient and organic matter cycling within the coral, with viruses also possibly playing a role in structuring the composition of these members, thus providing one of the first glimpses at a multi-domain marine animal symbiosis. The gammaproteobacterium \"Endozoicomonas\" is emerging as a central member of the coral's microbiome, with flexibility in its lifestyle. Given the recent mass bleaching occurring on reefs, corals will likely continue to be a useful and popular system for symbiosis and dysbiosis research.\n\"Astrangia poculata\", the northern star coral, is a temperate stony coral, widely documented along the eastern coast of the United States. The coral can live with and without zooxanthellae (algal symbionts), making it an ideal model organism to study microbial community interactions associated with symbiotic state. However, the ability to develop primers and probes to more specifically target key microbial groups has been hindered by the lack of full-length 16S rRNA sequences, since sequences produced by the Illumina platform are of insufficient length (approximately 250 base pairs) for the design of primers and probes. In 2019, Goldsmith et al. demonstrated Sanger sequencing was capable of reproducing the biologically relevant diversity detected by deeper next-generation sequencing, while also producing longer sequences useful to the research community for probe and primer design (see diagram on right).\nHolobionts.\nReef-building corals are well-studied holobionts that include the coral itself together with its symbiont zooxanthellae (photosynthetic dinoflagellates), as well as its associated bacteria and viruses. Co-evolutionary patterns exist for coral microbial communities and coral phylogeny.\nIt is known that the coral's microbiome and symbiont influence host health, however, the historic influence of each member on others is not well understood. Scleractinian corals have been diversifying for longer than many other symbiotic systems, and their microbiomes are known to be partially species-specific. It has been suggested that \"Endozoicomonas\", a commonly highly abundant bacterium in corals, has exhibited codiversification with its host. This hints at an intricate set of relationships between the members of the coral holobiont that have been developing as evolution of these members occurs.\nA study published in 2018 revealed evidence of phylosymbiosis between corals and their tissue and skeleton microbiomes. The coral skeleton, which represents the most diverse of the three coral microbiomes, showed the strongest evidence of phylosymbiosis. Coral microbiome composition and richness were found to reflect coral phylogeny. For example, interactions between bacterial and eukaryotic coral phylogeny influence the abundance of \"Endozoicomonas\", a highly abundant bacterium in the coral holobiont. However, host-microbial cophylogeny appears to influence only a subset of coral-associated bacteria.\nReefs.\nMany corals in the order Scleractinia are hermatypic, meaning that they are involved in building reefs. Most such corals obtain some of their energy from zooxanthellae in the genus \"Symbiodinium\". These are symbiotic photosynthetic dinoflagellates which require sunlight; reef-forming corals are therefore found mainly in shallow water. They secrete calcium carbonate to form hard skeletons that become the framework of the reef. However, not all reef-building corals in shallow water contain zooxanthellae, and some deep water species, living at depths to which light cannot penetrate, form reefs but do not harbour the symbionts.\nThere are various types of shallow-water coral reef, including fringing reefs, barrier reefs and atolls; most occur in tropical and subtropical seas. They are very slow-growing, adding perhaps one centimetre (0.4\u00a0in) in height each year. The Great Barrier Reef is thought to have been laid down about two million years ago. Over time, corals fragment and die, sand and rubble accumulates between the corals, and the shells of clams and other molluscs decay to form a gradually evolving calcium carbonate structure. Coral reefs are extremely diverse marine ecosystems hosting over 4,000 species of fish, massive numbers of cnidarians, molluscs, crustaceans, and many other animals.\nEvolution.\nAt certain times in the geological past, reef-building organisms similar to corals were very abundant. Like modern corals, these ancient organisms built reefs, some of which ended as great structures in sedimentary rocks. Fossils of fellow reef-dwellers algae, sponges, and the remains of many echinoids, brachiopods, bivalves, gastropods, and trilobites appear along with coral fossils. This makes some corals useful index fossils. Coral fossils are not restricted to reef remnants, and many solitary fossils are found elsewhere, such as \"Cyclocyathus\", which occurs in England's Gault clay formation.\nEarly corals.\nReef-building organisms similar to modern corals first appeared in the Cambrian about https://\u00a0million years ago. Fossils are extremely rare until the Ordovician period, 100 million years later, when Heliolitida, rugose, and tabulate corals became widespread. Paleozoic corals often contained numerous endobiotic symbionts.\nTabulate corals occur in limestones and calcareous shales of the Ordovician period, with a gap in the fossil record due to extinction events at the end of the Ordovician. Corals reappeared some millions of years later during the Silurian period, and tabulate corals often form low cushions or branching masses of calcite alongside rugose corals. Tabulate coral numbers began to decline during the middle of the Silurian period.\nRugose or horn corals became dominant by the middle of the Silurian period, and during the Devonian, corals flourished with more than 200 genera. The rugose corals existed in solitary and colonial forms, and were also composed of calcite. Both rugose and tabulate corals became extinct in the Permian\u2013Triassic extinction event https://\u00a0million years ago (along with 85% of marine species), and there is a gap of tens of millions of years until new forms of coral evolved in the Triassic.\nModern corals.\nThe currently ubiquitous stony corals, Scleractinia, appeared in the Middle Triassic to fill the niche vacated by the extinct rugose and tabulate orders and is not closely related to the earlier forms. Unlike the corals prevalent before the Permian extinction, which formed skeletons of a form of calcium carbonate known as calcite, modern stony corals form skeletons composed of the aragonite. Their fossils are found in small numbers in rocks from the Triassic period, and become common in the Jurassic and later periods. Although they are geologically younger than the tabulate and rugose corals, the aragonite of their skeletons is less readily preserved, and their fossil record is accordingly less complete.\nStatus.\nThreats.\nCoral reefs are under stress around the world. In particular, coral mining, agricultural and urban runoff, pollution (organic and inorganic), overfishing, blast fishing, disease, and the digging of canals and access into islands and bays are localized threats to coral ecosystems. Broader threats are sea temperature rise, sea level rise and pH changes from ocean acidification, all associated with greenhouse gas emissions. In 1998, 16% of the world's reefs died as a result of increased water temperature.\nApproximately 10% of the world's coral reefs are dead. About 60% of the world's reefs are at risk due to human-related activities. The threat to reef health is particularly strong in Southeast Asia, where 80% of reefs are endangered. Over 50% of the world's coral reefs may be destroyed by 2030; as a result, most nations protect them through environmental laws.\nIn the Caribbean and tropical Pacific, direct contact between ~40\u201370% of common seaweeds and coral causes bleaching and death to the coral via transfer of lipid-soluble metabolites. Seaweed and algae proliferate given adequate nutrients and limited grazing by herbivores such as parrotfish.\nWater temperature changes of more than or salinity changes can kill some species of coral. Under such environmental stresses, corals expel their Symbiodinium; without them, coral tissues reveal the white of their skeletons, an event known as coral bleaching.\nSubmarine springs found along the coast of Mexico's Yucat\u00e1n Peninsula produce water with a naturally low pH (relatively high acidity) providing conditions similar to those expected to become widespread as the oceans absorb carbon dioxide. Surveys discovered multiple species of live coral that appeared to tolerate the acidity. The colonies were small and patchily distributed and had not formed structurally complex reefs such as those that compose the nearby Mesoamerican Barrier Reef System.\nCoral health.\nTo assess the threat level of coral, scientists developed a coral imbalance ratio, Log (Average abundance of disease-associated taxa / Average abundance of healthy associated taxa). The lower the ratio the healthier the microbial community is. This ratio was developed after the microbial mucus of coral was collected and studied.\nClimate change impacts.\nIncreasing sea surface temperatures in tropical regions (~) the last century have caused major coral bleaching, death, and therefore shrinking coral populations. Although coral are able to adapt and acclimate, it is uncertain if this evolutionary process will happen quickly enough to prevent major reduction of their numbers. Climate change causes more frequent and more severe storms that can destroy coral reefs.\nAnnual growth bands in some corals, such as the deep sea bamboo corals (\"Isididae\"), may be among the first signs of the effects of ocean acidification on marine life. The growth rings allow geologists to construct year-by-year chronologies, a form of incremental dating, which underlie high-resolution records of past climatic and environmental changes using geochemical techniques.\nCertain species form communities called microatolls, which are colonies whose top is dead and mostly above the water line, but whose perimeter is mostly submerged and alive. Average tide level limits their height. By analyzing the various growth morphologies, microatolls offer a low-resolution record of sea level change. Fossilized microatolls can also be dated using radiocarbon dating. Such methods can help to reconstruct Holocene sea levels.\nThough coral have large sexually-reproducing populations, their evolution can be slowed by abundant asexual reproduction. Gene flow is variable among coral species. According to the biogeography of coral species, gene flow cannot be counted on as a dependable source of adaptation as they are very stationary organisms. Also, coral longevity might factor into their adaptivity.\nHowever, adaptation to climate change has been demonstrated in many cases, which is usually due to a shift in coral and zooxanthellae genotypes. These shifts in allele frequency have progressed toward more tolerant types of zooxanthellae. Scientists found that a certain scleractinian zooxanthella is becoming more common where sea temperature is high. Symbionts able to tolerate warmer water seem to photosynthesise more slowly, implying an evolutionary trade-off.\nIn the Gulf of Mexico, where sea temperatures are rising, cold-sensitive staghorn and elkhorn coral have shifted in location.\nNot only have the symbionts and specific species been shown to shift, but there seems to be a certain growth rate favorable to selection. Slower-growing but more heat-tolerant corals have become more common. The changes in temperature and acclimation are complex. Some reefs in current shadows represent a refugium location that will help them adjust to the disparity in the environment even if eventually the temperatures may rise more quickly there than in other locations. This separation of populations by climatic barriers causes a realized niche to shrink greatly in comparison to the old fundamental niche.\nGeochemistry.\nCorals are shallow, colonial organisms that integrate oxygen and trace elements into their skeletal aragonite (polymorph of calcite) crystalline structures as they grow. Geochemical anomalies within the crystalline structures of corals represent functions of temperature, salinity and oxygen isotopic composition. Such geochemical analysis can help with climate modeling. The ratio of oxygen-18 to oxygen-16 (\u03b418O), for example, is a proxy for temperature.\nStrontium/calcium ratio anomaly.\nTime can be attributed to coral geochemistry anomalies by correlating strontium/calcium minimums with sea surface temperature (SST) maximums to data collected from http://.\nOxygen isotope anomaly.\nThe comparison of coral strontium/calcium minimums with sea surface temperature maximums, data recorded from http://, time can be correlated to coral strontium/calcium and \u03b418O variations. To confirm the accuracy of the annual relationship between Sr/Ca and \u03b418O variations, a perceptible association to annual coral growth rings confirms the age conversion. Geochronology is established by the blending of Sr/Ca data, growth rings, and stable isotope data. El Nino-Southern Oscillation (ENSO) is directly related to climate fluctuations that influence coral \u03b418O ratio from local salinity variations associated with the position of the South Pacific convergence zone (SPCZ) and can be used for ENSO modeling.\nSea surface temperature and sea surface salinity.\nThe global moisture budget is primarily being influenced by tropical sea surface temperatures from the position of the Intertropical Convergence Zone (ITCZ). The Southern Hemisphere has a unique meteorological feature positioned in the southwestern Pacific Basin called the South Pacific Convergence Zone (SPCZ), which contains a perennial position within the Southern Hemisphere. During ENSO warm periods, the SPCZ reverses orientation extending from the equator down south through Solomon Islands, Vanuatu, Fiji and towards the French Polynesian Islands; and due east towards South America affecting geochemistry of corals in tropical regions.\nGeochemical analysis of skeletal coral can be linked to sea surface salinity (SSS) and sea surface temperature (SST), from http:// data, of tropical oceans to seawater \u03b418O ratio anomalies from corals. ENSO phenomenon can be related to variations in sea surface salinity (SSS) and sea surface temperature (SST) that can help model tropical climate activities.\nLimited climate research on current species.\nClimate research on live coral species is limited to a few studied species. Studying \"Porites\" coral provides a stable foundation for geochemical interpretations that is much simpler to physically extract data in comparison to \"Platygyra\" species where the complexity of \"Platygyra\" species skeletal structure creates difficulty when physically sampled, which happens to be one of the only multidecadal living coral records used for coral paleoclimate modeling.\nProtection.\nMarine Protected Areas, Biosphere reserves, marine parks, national monuments world heritage status, fishery management and habitat protection can protect reefs from anthropogenic damage.\nMany governments now prohibit removal of coral from reefs, and inform coastal residents about reef protection and ecology. While local action such as habitat restoration and herbivore protection can reduce local damage, the longer-term threats of acidification, temperature change and sea-level rise remain a challenge.\nProtecting networks of diverse and healthy reefs, not only climate refugia, helps ensure the greatest chance of genetic diversity, which is critical for coral to adapt to new climates. A variety of conservation methods applied across marine and terrestrial threatened ecosystems makes coral adaption more likely and effective.\nTo eliminate destruction of corals in their indigenous regions, projects have been started to grow corals in non-tropical countries.\nRelation to humans.\nLocal economies near major coral reefs benefit from an abundance of fish and other marine creatures as a food source. Reefs also provide recreational scuba diving and snorkeling tourism. These activities can damage coral but international projects such as Green Fins that encourage dive and snorkel centres to follow a Code of Conduct have been proven to mitigate these risks.\nJewelry.\nCorals' many colors give it appeal for necklaces and other jewelry. Intensely red coral is prized as a gemstone. Sometimes called fire coral, it is not the same as fire coral. Red coral is very rare because of overharvesting. In general, it is inadvisable to give coral as gifts since they are in decline from stressors like climate change, pollution, and unsustainable fishing.\nAlways considered a precious mineral, \"the Chinese have long associated red coral with auspiciousness and longevity because of its color and its resemblance to deer antlers (so by association, virtue, long life, and high rank\". It reached its height of popularity during the Manchu or Qing Dynasty (1644\u20131911) when it was almost exclusively reserved for the emperor's use either in the form of coral beads (often combined with pearls) for court jewelry or as decorative Penjing (decorative miniature mineral trees). Coral was known as \"shanhu\" in Chinese. The \"early-modern 'coral network' [began in] the Mediterranean Sea [and found its way] to Qing China via the English East India Company\". There were strict rules regarding its use in a code established by the Qianlong Emperor in 1759.\nBy the middle of the 19th century, \"coral fisheries\" existed in the Mediterranean, the Red Sea, Persian Gulf and elsewhere. An instrument used to retrieve the coral consisted of two beams of heavy wood attached to each other at right angles. Heavy stones were added to make the apparatus sink and netting was attached beneath the device. It is then lowered by a strong rope over an outcrop of coral and the boat trawls over the coral causing it to break off and be caught in the netting. The device is then drawn to the surface by the boat crew.\nMedicine.\nIn medicine, chemical compounds from corals can potentially be used to treat cancer, neurological diseases, inflammation including arthritis, pain, bone loss, high blood pressure and for other therapeutic uses. Coral skeletons, e.g. \"Isididae\" are being researched for their potential near-future use for bone grafting in humans.\nCoral Calx, known as Praval Bhasma in Sanskrit, is widely used in traditional system of Indian medicine as a supplement in the treatment of a variety of bone metabolic disorders associated with calcium deficiency. In classical times ingestion of pulverized coral, which consists mainly of the weak base calcium carbonate, was recommended for calming stomach ulcers by Galen and Dioscorides.\nConstruction.\nCoral reefs in places such as the East African coast are used as a source of building material. Ancient (fossil) coral limestone, notably including the Coral Rag Formation of the hills around Oxford (England), was once used as a building stone, and can be seen in some of the oldest buildings in that city including the Saxon tower of St Michael at the Northgate, St. George's Tower of Oxford Castle, and the medieval walls of the city.\nShoreline protection.\nHealthy coral reefs absorb 97 percent of a wave's energy, which buffers shorelines from currents, waves, and storms, helping to prevent loss of life and property damage. Coastlines protected by coral reefs are also more stable in terms of erosion than those without.\nLocal economies.\nCoastal communities near coral reefs rely heavily on them. Worldwide, more than 500 million people depend on coral reefs for food, income, coastal protection, and more. The total economic value of coral reef services in the United States \u2013 including fisheries, tourism, and coastal protection \u2013 is more than $3.4 billion a year.\nAquaria.\nThe saltwater fishkeeping hobby has expanded, over recent years, to include reef tanks, fish tanks that include large amounts of live rock on which coral is allowed to grow and spread. These tanks are either kept in a natural-like state, with algae (sometimes in the form of an algae scrubber) and a deep sand bed providing filtration, or as \"show tanks\", with the rock kept largely bare of the algae and microfauna that would normally populate it, in order to appear neat and clean.\nThe most popular kind of coral kept is soft coral, especially zoanthids and mushroom corals, which are especially easy to grow and propagate in a wide variety of conditions, because they originate in enclosed parts of reefs where water conditions vary and lighting may be less reliable and direct. More serious fishkeepers may keep small polyp stony coral, which is from open, brightly lit reef conditions and therefore much more demanding, while large polyp stony coral is a sort of compromise between the two.\nAquaculture.\nCoral aquaculture, also known as \"coral farming\" or \"coral gardening\", is the cultivation of corals for commercial purposes or coral reef restoration. Aquaculture is showing promise as a potentially effective tool for restoring coral reefs, which have been declining around the world. The process bypasses the early growth stages of corals when they are most at risk of dying. Coral fragments known as \"seeds\" are grown in nurseries then replanted on the reef. Coral is farmed by coral farmers who live locally to the reefs and farm for reef conservation or for income. It is also farmed by scientists for research, by businesses for the supply of the live and ornamental coral trade and by private aquarium hobbyists.\nGallery.\n\"Further images: and \"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47701", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=47701", "title": "Short stories", "text": ""}
{"id": "47702", "revid": "50565646", "url": "https://en.wikipedia.org/wiki?curid=47702", "title": "Torture", "text": "Deliberate infliction of suffering on a person\nTorture is the deliberate infliction of severe pain or suffering on a person for reasons including punishment, extracting a confession, interrogation for information, or intimidating third parties.\nSome definitions restrict torture to acts carried out by the state, while others include non-state actors. Most victims of torture are poor and marginalized people suspected of crimes, although torture against political prisoners, or during armed conflict, has received disproportionate attention. Judicial corporal punishment and capital punishment are sometimes seen as forms of torture, but this label is internationally controversial. A variety of methods of torture are used, often in combination; the most common form of physical torture is beatings. Beginning in the twentieth century, many torturers have preferred non-scarring or psychological methods to maintain deniability. \nTorturers more commonly act out of fear, or due to limited resources, rather than sadism. Although most torturers are thought to learn about torture techniques informally and rarely receive explicit orders, they are enabled by organizations that facilitate and encourage their behavior. Once a torture program begins, it usually escalates beyond what is intended initially and often leads to involved agencies losing effectiveness. Torture aims to break the victim's will, destroy their agency and personality, and is cited as one of the most damaging experiences that a person can undergo. Many victims suffer both physical damage\u2014chronic pain is particularly common\u2014and mental sequelae. Although torture survivors have some of the highest rates of post-traumatic stress disorder, many are psychologically resilient. \nTorture has been carried out since ancient times. However, in the eighteenth and nineteenth centuries, many Western countries abolished the official use of torture in the judicial system, although it continued to be used throughout the world. Public opinion research shows general opposition to torture. It is prohibited under international law for all states under all circumstances and is explicitly forbidden by several treaties. Opposition to torture stimulated the formation of the human rights movement after World War II, and it continues to be an important human rights issue. Although prevention efforts have been of mixed effectiveness, institutional reforms and the elimination of incommunicado detention have had positive effects. Despite its decline, torture is still practiced in or by most countries.\nDefinitions.\nTorture is conventionally understood as the deliberate infliction of severe pain or suffering on a helpless person under the control of a perpetrator. The generally accepted components of the definition of torture are as follows: \nDepending on the definition used, torture may be distinguished from cruel, inhuman, or degrading treatment (CIDT) by the severity or the purpose. The definition of torture excludes and can be seen to legitimize other forms of pain, suffering, and degradation, particularly institutionalized, collective, and structural violence, while legal scholar Erg\u00fcn Cakal argues that violent practices come to be recognized as torture after they no longer serve the purpose of the state.\nHistory.\nPre-abolition.\nTorture was legally and morally acceptable in most ancient, medieval, and early modern societies. Societies used torture as part of the judicial process, and painful punishments were distinguished from torture. Historically, torture was seen as a reliable way to elicit the truth, a suitable punishment, and deterrence against future offenses. When torture was legally regulated, there were restrictions on the allowable methods. In most societies, citizens could be judicially tortured only under exceptional circumstances and for a serious crime such as treason, often only when some evidence already existed. In contrast, non-citizens such as foreigners and slaves were commonly tortured.\nThere is archaeological evidence of torture in Early Neolithic Europe, about 7,000 years ago. Torture is commonly mentioned in historical sources on Assyria and Achaemenid Persia. Torture was rare in early medieval Europe but became more common between 1200 and 1400. Torture was still a labor-intensive process reserved for the most severe crimes; most torture victims were men accused of murder, treason, or theft. The Ottoman Empire and Qajar Iran used torture in cases where circumstantial evidence tied someone to a crime, although Islamic law has traditionally considered evidence obtained under torture to be inadmissible.\nAbolition and continued use.\nTorture remained legal in Europe during the seventeenth century, but its practice declined. Torture was already of marginal importance to European criminal justice systems by its formal abolition in the 18th and early 19th centuries. Theories for why torture was abolished include Enlightenment ideas about the value of the human person, the lowering of the standard of proof in criminal cases, popular views that no longer saw pain as morally redemptive, and the expansion of imprisonment as an alternative to executions or painful punishments. It is not known if torture also declined in non-Western states or European colonies during the nineteenth century. In China, judicial torture, which had been practiced for more than two millennia, was banned in 1905 along with flogging and \"lingchi\" (dismemberment) as a means of execution, although torture in China continued throughout the twentieth and twenty-first centuries.\nTorture was widely used by colonial powers to subdue resistance and reached a peak during the anti-colonial wars in the twentieth century. An estimated 300,000 people were tortured during the Algerian War of Independence (1954\u20131962), and the United Kingdom and Portugal also used torture in attempts to retain their respective empires. Independent states in Africa, the Middle East, and Asia often used torture in the twentieth century, but it is unknown whether their use of torture increased or decreased compared to nineteenth-century levels. During the first half of the twentieth century, torture became more prevalent in Europe with the advent of secret police, World War I and World War II, and communist and fascist states. Torture was used by both communist and anti-communist governments during the Cold War in Latin America, with an estimated 100,000 to 150,000 victims of torture by United States\u2013backed regimes. The only countries in which torture was rare during the twentieth century were the liberal democracies of the West, where torture was used against ethnic minorities or criminal suspects from marginalized classes, and during overseas wars against foreign populations.\nPrevalence.\nMost countries practice torture, although few acknowledge it. Despite one of the most unambiguous and absolute prohibitions known to international law, torture continues to be more or less openly practiced in some states; others have changed which techniques are used and denied, covered up, or outsourced torture programs. Measuring the rate at which torture occurs is difficult because it is typically committed in secrecy, and abuses are likelier to come to light in open societies where there is a commitment to protecting human rights. Many torture survivors, especially those from poor or marginalized populations, are unwilling to report. Monitoring has focused on police stations and prisons, although torture can also occur in other facilities such as immigration detention and youth detention centers. Torture that occurs outside of custody\u2014including extrajudicial punishment, intimidation, and crowd control\u2014has traditionally not been counted, even though some studies have suggested it is more common than torture in places of detention. There is even less information on the prevalence of torture before the twentieth century. Although it is often assumed that men suffer torture at a higher rate than women, there is a lack of evidence. Some quantitative research has estimated that torture rates are either stagnant or increasing over time, but this may be a measurement effect.\nAlthough liberal democracies are less likely to abuse their citizens, they may practice torture against marginalized citizens and non-citizens to whom they are not democratically accountable. Voters may support violence against out-groups seen as threatening; majoritarian institutions are ineffective at preventing torture against minorities or foreigners. Torture is more likely when a society feels threatened because of wars or crises, but studies have not found a consistent relationship between the use of torture and terrorist attacks.\nTorture is directed against certain segments of the population, who are denied the protection against torture given to others. Torture of political prisoners and torture during armed conflicts receive more attention compared to torture of the poor or criminal suspects. Most victims of torture are suspected of crimes; a disproportionate number of victims are from poor or marginalized communities. Groups especially vulnerable to torture include unemployed young men, the urban poor, LGBT people, refugees and migrants, ethnic and racial minorities, indigenous people, and people with disabilities. Relative poverty and the resulting inequality in particular leave poor people vulnerable to torture. Criminalization of the poor, through laws targeting homelessness, sex work, or working in the informal economy, can lead to violent and arbitrary policing. Routine violence against poor and marginalized people is often not seen as torture, and its perpetrators justify the violence as a legitimate policing tactic; victims lack the resources or standing to seek redress.\nPerpetrators.\nSince most research has focused on torture victims, less is known about the perpetrators of torture. Many torturers see their actions as serving a higher political or ideological goal that justifies torture as a legitimate means of protecting the state. Fear is often the motivation for torture, and it is typically not a rational response as it is usually ineffective or even counterproductive at achieving the desired aim. Torture victims are often viewed by the perpetrators as severe threats and enemies of the state. Studies of perpetrators do not support the common assumption that they are psychologically pathological. Most perpetrators do not volunteer to be torturers; many have an innate reluctance to employ violence, and rely on coping mechanisms, such as alcohol or drugs. Psychiatrist Pau P\u00e9rez-Sales finds that torturers act from a variety of motives such as ideological commitment, personal gain, group belonging, avoiding punishment, or avoiding guilt from previous acts of torture. \nIn contrast to the assumption that torture is ordered at the highest levels of government, the approval or acquiescence of superiors is a necessary but not sufficient condition for torture to occur, given that a specific order to torture rarely can be identified. In many cases, a combination of dispositional and situational effects lead a person to become a torturer. In most cases of systematic torture, the torturers were desensitized to violence by being exposed to physical or psychological abuse during training which can be a deliberate tactic to create torturers. Even when not explicitly ordered by the government to torture, perpetrators may feel peer pressure due to competitive masculinity. Elite and specialized police units are especially prone to torturing, perhaps because of their tight-knit nature and insulation from oversight. Although some torturers are formally trained, most are thought to learn about torture techniques informally.\nTorture can be a side effect of a broken criminal justice system in which underfunding, lack of judicial independence, or corruption undermines effective investigations and fair trials. In this context, people who cannot afford bribes are likely to become victims of torture. Understaffed or poorly trained police are more likely to resort to torture when interrogating suspects. In some countries, such as Kyrgyzstan, suspects are more likely to be tortured at the end of the month because of performance quotas.\nThe contribution of bureaucracy to torture is under-researched and poorly understood. Torturers rely on both active supporters and those who ignore it. Military, intelligence, psychology, medical, and legal professionals can all be complicit in torture. Incentives can favor the use of torture on an institutional or individual level, and some perpetrators are motivated by the prospect of career advancement. Bureaucracy can diffuse responsibility for torture and help perpetrators excuse their actions. Maintaining secrecy is often essential to maintaining a torture program, which can be accomplished in ways ranging from direct censorship, denial, or mislabeling torture as something else, to offshoring abuses to outside a state's territory. Along with official denials, torture is enabled by moral disengagement from the victims and impunity for the perpetrators. Public demand for decisive action against crime or even support for torture against criminals can facilitate its use.\nOnce a torture program is begun, it is difficult or impossible to prevent it from escalating to more severe techniques and expanding to larger groups of victims, beyond what is originally intended or desired by decision-makers. Sociologist Christopher J. Einolf argues that \"torture can create a vicious cycle in which a fear of internal enemies leads to torture, torture creates false confessions, and false confessions reinforce torturers' fears, leading to a spiral of paranoia and ever-increasing torture\"\u2014similar to a witch hunt. Escalation of torture is especially difficult to contain in counterinsurgency operations. Torture and specific techniques spread between different countries, especially by soldiers returning home from overseas wars, although this process is poorly understood.\nPurpose.\nPunishment.\nTorture for punishment dates back to antiquity and is still employed in the twenty-first century.\nA common practice in countries with dysfunctional justice systems or overcrowded prisons is for police to apprehend suspects, torture them, and release them without a charge. Such torture could be performed in a police station, the victim's home, or a public place. In South Africa, the police have been observed handing suspects over to vigilantes to be tortured. This type of extrajudicial violence is often carried out in public as a form of social control to deter others. It discriminatorily targets minorities and marginalized groups and may be supported by the public, especially if people do not trust the official justice system.\nJudicial corporal punishment was initially excepted from the UN definition of torture, which \"does not include pain or suffering arising only from, inherent in or incidental to lawful sanctions\", although it is explicitly prohibited under the Geneva Conventions. From the 1990s, courts increasingly recognized it as a form of torture, although this norm has met opposition from practitioners of Islamic law and other traditional justice practices. Capital punishment is an extreme form of corporal punishment and its use has become increasingly circumscribed. Certain methods of execution have been banned as tortuous, and the psychological harm of capital punishment has also been recognized as torture. Others do not consider corporal punishment with a fixed penalty to be torture, as it does not seek to break the victim's will.\nDeterrence.\nTorture may also be used indiscriminately to terrorize people other than the direct victim or to deter opposition to the government. In the United States, torture was used to deter slaves from escaping or rebelling. Some defenders of judicial torture prior to its abolition argued that it deterred crime; reformers contended that because torture was carried out in secret, it could not be an effective deterrent. Authoritarian regimes often resort to indiscriminate repression because they cannot accurately identify potential opponents. Many insurgencies lack the necessary infrastructure for a torture program and instead intimidate by killing. Research has found that state torture can extend the lifespan of terrorist organizations, increase incentives for insurgents to use violence, and radicalize the opposition. \nIn the twentieth century, well-known examples include the Khmer Rouge and anti-communist regimes in Latin America, who tortured and murdered their victims as part of forced disappearance. Ba'athist Syria's massive torture program existed to eliminate dissent and for perpetrators to show loyalty to the regime, although all evidence indicates it did not reduce political opposition. Several torture researchers have argued that torture is used by Israel to dominate and terrorize Palestinians, particularly during the Gaza genocide Another form of torture for deterrence is violence against migrants, as has been reported during pushbacks on the European Union's external borders.\nConfession.\nTorture has been used throughout history to extract confessions from detainees. In 1764, Italian reformer Cesare Beccaria denounced torture as \"a sure way to acquit robust scoundrels and to condemn weak but innocent people\". Similar doubts about torture's effectiveness had been voiced for centuries previously, including by Aristotle. Despite the abolition of judicial torture, it sees continued use to elicit confessions, especially in judicial systems placing a high value on confessions in criminal matters. The use of torture to force suspects to confess is facilitated by laws allowing extensive pre-trial detention. Research has found that coercive interrogation is slightly more effective than cognitive interviewing for extracting a confession from a suspect, but presents a higher risk of false confession. Many torture victims will say whatever the torturer wants to hear to end the torture. Others who are guilty refuse to confess, especially if they believe it would only bring more torture or punishment. Medieval justice systems attempted to counteract the risk of false confession under torture by requiring confessors to provide falsifiable details about the crime, and only allowing torture if there was already some evidence against the accused. In some countries, political opponents are tortured to force them to confess publicly as a form of state propaganda.\nInterrogation.\nThe use of torture to obtain information during interrogation accounts for a small percentage of worldwide torture cases; its use for obtaining confessions or intimidation is more common. Although interrogational torture has been used in conventional wars, it is even more common in asymmetric war or civil wars. The ticking time bomb scenario is extremely rare, if not impossible, but is cited to justify torture for interrogation. Fictional portrayals of torture as an effective interrogational method have fueled misconceptions that justify the use of torture. Experiments comparing torture with other interrogation methods cannot be performed for ethical and practical reasons. Most scholars of torture are skeptical about its efficacy in obtaining accurate information, while others hold that it is impossible to know its effectiveness, and in some cases actionable intelligence has been obtained. Interrogational torture can often shade into confessional torture or simply into entertainment, and some torturers do not distinguish between interrogation and confession. Although skeptical of some criticisms of torture, Ron E. Hassner argues that to be effective torture must be planned and drawn out. \"Our society would have to acquiesce to a massive bureaucratized torture campaign, at times of peace or war, that targeted thousands, from all walks of life, regardless of culpability, in order to extract modest intelligence that was, at best, corroborative.\"\nMethods.\nA wide variety of techniques have been used for torture. Nevertheless, there are limited ways of inflicting pain while minimizing the risk of death. Survivors report that the exact method used is not significant. Most forms of torture include both physical and psychological elements and multiple methods are typically used on one person. Different methods of torture are popular in different countries. Low-tech methods are more commonly used than high-tech ones, and attempts to develop scientifically validated torture technology have failed. The prohibition of torture motivated a shift to methods that do not leave marks to aid in deniability and to deprive victims of legal redress. As they faced more pressure and scrutiny, democracies led the innovation in clean torture practices in the early twentieth century; such techniques diffused worldwide by the 1960s. Patterns of torture differ based on a torturer's time limits\u2014for example, resulting from legal limits on pre-trial detention. While some methods are considered inherently tortuous, others may contribute to a finding of torture depending on the circumstances and cumulative impact.\nBeatings or blunt trauma are the most common form of physical torture reported by about two-thirds of survivors. They may be either unsystematic or focused on a specific part of the body, as in falanga (the soles of the feet), repeated strikes against both ears, or shaking the detainee so that their head moves back and forth. Often, people are suspended in painful positions such as strappado or upside-down hanging in combination with beatings. People may also be subjected to stabbings or puncture wounds, have their nails removed, or body parts amputated. Burns are also common, especially cigarette burns, but other instruments are also employed, including hot metal, hot fluids, the sun, or acid. Forced ingestion of water, food, or other substances, or injections are also used as torture. Electric shocks are often used to torture, especially to avoid other methods that are more likely to leave scars. Asphyxiation, of which waterboarding is a form, inflicts torture on the victim by cutting off their air supply.\nPsychological torture includes methods that involve no physical element as well as forcing a person to do something and physical attacks that ultimately target the mind. Death threats, mock execution, or being forced to witness the torture of another person are often reported to be subjectively worse than being physically tortured and are associated with severe sequelae. Other torture techniques include sleep deprivation, overcrowding or solitary confinement, withholding of food or water, sensory deprivation (such as hooding), exposure to extremes of light or noise (e.g., musical torture), humiliation (which can be based on sexuality or the victim's religious or national identity), and the use of animals such as dogs to frighten or injure a prisoner. Positional torture works by forcing the person to adopt a stance, putting their weight on a few muscles, causing pain without leaving marks, for example standing or squatting for extended periods. Rape and sexual assault are universal torture methods and frequently instill a permanent sense of shame in the victim and in some cultures, humiliate their family and society. Cultural and individual differences affect how the victim perceives different torture methods.\nEffects.\nTorture is one of the most devastating experiences that a person can undergo. Torture aims to break the victim's will and destroy the victim's agency and personality. Torture survivor Jean Am\u00e9ry argued that it was \"the most horrible event a human being can retain within himself\" and that \"whoever was tortured, stays tortured\". Many torture victims, including Am\u00e9ry, later die by suicide. Survivors often experience social and financial problems. Circumstances such as housing insecurity, family separation, and the uncertainty of applying for asylum in a safe country strongly impact survivors' well-being. \nDeath is not an uncommon outcome of torture. Understanding of the link between specific torture methods and health consequences is lacking. These consequences can include peripheral neuropathy, damage to teeth, rhabdomyolysis from extensive muscle damage, traumatic brain injury, sexually transmitted infection, and pregnancy from rape. Chronic pain and pain-related disability are commonly reported, but there is scant research into this effect or possible treatments. Common psychological problems affecting survivors include traumatic stress, anxiety, depression, and sleep disturbance. An average of 40 percent have long-term post-traumatic stress disorder (PTSD), a higher rate than for any other traumatic experience. Not all survivors or rehabilitation experts support using medical categories to define their experience, and many survivors remain psychologically resilient.\nCriminal prosecutions for torture are rare and most victims who submit formal complaints are not believed. Despite the efforts for evidence-based evaluation of the scars from torture such as the Istanbul Protocol, most physical examinations are inconclusive. The effects of torture are one of several factors that usually result in inconsistent testimony from survivors, hampering their effort to be believed and secure either refugee status in a foreign country or criminal prosecution of the perpetrators.\nAlthough there is less research on the effects of torture on perpetrators, they can experience moral injury or trauma symptoms similar to the victims, especially when they feel guilty about their actions. Torture has corrupting effects on the institutions and societies that perpetrate it. Torturers forget important investigative skills because torture can be an easier way than time-consuming police work to achieve high conviction rates, encouraging the continued and increased use of torture. Public disapproval of torture can harm the international reputation of countries that use it, strengthen and radicalize violent opposition to those states, and encourage adversaries to themselves use torture.\nPublic opinion.\nStudies have found that most people around the world oppose the use of torture in general. Some hold definite views on torture; for others, torture's acceptability depends on the victim. Support for torture in specific cases is correlated with the belief that torture is effective and used in ticking time bomb cases. Women are more likely to oppose torture than men. Nonreligious people are less likely to support the use of torture than religious people, although for the latter group, increased religiosity increases opposition to torture. The personality traits of right-wing authoritarianism, social dominance orientation, and retributivism are correlated with higher support for torture; embrace of democratic values such as liberty and equality reduces support for torture. Public opinion is most favorable to torture, on average, in countries with low per capita income and high levels of state repression. Public opinion and civil society mobilizations are an important constraint on the use of torture by states. \nProhibition.\nThe prohibition of torture is generally accepted as intended to protect human dignity and the physical and mental integrity of the victim. Torture is criticized based on all major ethical frameworks, including deontology, consequentialism, and virtue ethics. Some contemporary philosophers argue that torture is never morally acceptable; others propose exceptions to the general rule in real-life equivalents of the ticking time-bomb scenario. The accusation of torture is often perceived as a more serious stigma than inhuman or degrading treatment that causes similar amounts of human suffering.\nThe abolition and prohibition of torture was justified by rhetoric classifying it as barbaric and uncivilized. By the late nineteenth century, countries began to be condemned internationally for the use of torture. The ban on torture became part of the civilizing mission justifying colonial rule on the pretext of ending torture, despite the use of torture by colonial rulers themselves. The condemnation was strengthened during the twentieth century in reaction to the use of torture by Nazi Germany and the Soviet Union. Shocked by Nazi atrocities during World War II, after which torture featured prominently in the Nuremberg trials, the United Nations drew up the 1948 Universal Declaration of Human Rights, which prohibited torture. Torture stimulated the creation of the human rights movement. Beginning with the 1969 Greek case, the definition of torture\u2014left undefined in most treaties\u2014has been fleshed out in case law. In the early 1970s, Amnesty International launched a global campaign against torture, exposing its widespread use and leading to the United Nations Convention against Torture (CAT) in 1984.\nThe prohibition of torture is a peremptory norm (\"jus cogens\") in international law, meaning that it is forbidden for all states under all circumstances. The CAT and its Optional Protocol focus on the prevention of torture, which was already prohibited in international human rights law (IHRL) under other treaties such as the International Covenant on Civil and Political Rights. The CAT specifies that torture must be a criminal offense under a country's laws, evidence obtained under torture may not be admitted in court, and deporting a person to another country where they are likely to face torture is forbidden. Even when it is illegal under national law, judges in many countries continue to admit evidence obtained under torture or ill treatment. It is disputed whether ratification of the CAT decreases, does not affect, or even increases the rate of torture in a country. Torture is prohibited in international criminal law as a war crime and crime against humanity; unlike in IHRL, it may be perpetrated by non-state actors. In 1987, Israel became the only country in the world to purportedly legalize torture. More prominently, the prohibition was challenged by the United States government using the same argument of state security deployed by Israel and various colonial powers, as it embarked on an overseas torture program as part of its war on terror. \nPrevention.\nThere is some evidence that institutionalized torture prevention reduces the rate of torture, although prevention efforts are complicated both by lack of understanding about why torture occurs and by lack of application of what is known. Torture proliferates in situations of incommunicado detention. Because the risk of torture is highest directly after an arrest, procedural safeguards such as immediate access to a lawyer and notifying relatives of an arrest are the most effective ways of prevention. Visits by independent monitoring bodies to detention sites can also help reduce torture. Legal changes that are not implemented in practice have little effect on the incidence of torture. Legal changes can be particularly ineffective in places where the law has limited legitimacy or is routinely ignored. Naming and shaming campaigns against torture have shown mixed results; they can be ineffective and even make things worse.\nSociologically torture operates as a subculture, frustrating prevention efforts because torturers can find a way around rules. Safeguards against torture in detention can be evaded by beating suspects during round-ups or on the way to the police station. General training of police to improve their ability to investigate crime has been more effective at reducing torture than specific training focused on human rights. Institutional police reforms have been effective when abuse is systematic. Political scientist Darius Rejali criticizes torture prevention research for not figuring out \"what to do when people are bad; institutions broken, understaffed, and corrupt; and habitual serial violence is routine\". Malcolm Evans, a longtime participant in United Nations anti-torture efforts, believes that \"fundamental shifts and changes in societal attitudes\" towards the people at risk of becoming torture victims may be required to put an end to torture.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "47707", "revid": "51021567", "url": "https://en.wikipedia.org/wiki?curid=47707", "title": "Feyenoord", "text": "Association football club in the Netherlands\nFootball club\nFeyenoord Rotterdam () is a Dutch professional football club based in Rotterdam, which plays in the Eredivisie, the top tier in Dutch football. Founded as Wilhelmina in 1908, the club changed to various names before settling on being called after its neighbourhood in 1912 as SC Feijenoord, updated in 1974 to SC Feyenoord, and then to \"Feyenoord\" in 1978, when it split from the amateur club under its wing, SC Feyenoord. Since 1937, Feyenoord's home ground has been the Stadion Feijenoord, nicknamed De Kuip (\"The Tub\"), the second largest stadium in Netherlands.\nFeyenoord is one of the most successful clubs in Dutch football, winning 16 Dutch football championships, 14 KNVB Cups, and 5 Johan Cruyff Shields. Internationally, the club has won one European Cup, two UEFA Cups, and one Intercontinental Cup. The club has played continuously in the top ten of the Dutch football system since gaining promotion to \"Eerste Klasse (\"the Eredivisie's forerunner competition) in 1921, more times than any other club in the country, including the likes of Ajax and PSV Eindhoven.\nFeyenoord is known as a people's club with large national support. Its most successful period was the 1960s and 1970s, when Coen Moulijn, Willem van Hanegem and Ove Kindvall led the club to six league titles, two European trophies, and an Intercontinental Cup, thereby becoming the first Dutch club in history to win both the European Cup and the Intercontinental Cup. In the 21st century, Feyenoord ended an 18-year league title drought in 2017 and won the 2002 UEFA Cup against Borussia Dortmund in its home stadium, which makes them the only team from the Netherlands to win a European trophy this century.\nFeyenoord has a longstanding rivalry with their arch rival Ajax, a clash between two teams from the two biggest cities in the Netherlands, called \"De Klassieker\" (\"The Classic\"). The club's anthem is \"Hand in Hand\". The home shirt colours are red and white split down the middle with both the shorts and socks being black.\nAs of 2017, Feyenoord is a multi-sports club, including Sportclub Feyenoord (amateur football team), Feyenoord Basketball, Feyenoord Futsal and Feyenoord Handball.\nHistory.\nFoundation.\nThe football club Wilhelmina was founded in the pub \"De Vereeniging\" on 19 July 1908 and played in blue-sleeved red shirts and white shorts. Between 1908, 1910, 1911, and 1912, the club underwent a series of changes of name and team colours, becoming Hillesluise Football Club in 1909, and then RVV Celeritas. Upon earning promotion to the National football association in 1912, the club renamed to SC Feijenoord (after the city district in which the team was founded), and changed uniform once again, adopting the red and white shirts, black shorts and black socks that they still wear today. In 1917, Feijenoord were promoted to the highest level of Dutch football and moved to the ground \"Kromme Zandweg\".\nFirst successes.\nAfter 16 years the formation of the club and a mere three years after they were promoted for the second time to the highest level of Dutch football, Feijenoord earned their first honours by capturing the national league championship in 1924. The team enjoyed a string of successes in the latter half of the decade, taking divisional titles in 1926, 1927, 1928 and 1929, and winning their second national championship in 1928.\nFeijenoord won their first Dutch Cup in 1930 by scoring the only goal in a derby final against Excelsior. They continued to dominate their division with three consecutive titles, but were winless in subsequent championship finals. Five years after their first cup win, Feijenoord took the prize for a second time in 1935, by beating HVV Helmond.\nFeijenoord started to attract more fans to their stadium at Kromme Zandweg, and in 1933, they decided to build a new facility. The club moved to the Feijenoord Stadion (nicknamed \"De Kuip\" or \"the Tub\") in 1937, playing the first match there on 27 March against Beerschot. During this period Feijenoord won three consecutive division titles from 1936 to 1938, with their third and fourth national championships coming in 1936 and 1938.\nDuring World War II, Feijenoord played their matches at Sparta Rotterdam's Kasteel, as the Nazis had occupied De Kuip. When Het Kasteel was unavailable due to clashes with Sparta fixtures, Feijenoord played at their former ground, the Kromme Zandweg.\nFeijenoord again won a division title with a national championship in 1940, their fifth Dutch title. During the German occupation of the Netherlands, play continued in Dutch football leagues, though the 1945 championship was cancelled as the war came to its conclusion. During this period, Feijenoord's only trophy was a divisional championship in 1943. After the war, Feijenoord did not perform as well as they had in previous decades, not seriously challenging in their division and so missing the national playoff rounds.\nOn 30 June 1954, the chairmen of the three biggest Rotterdam teams organised a meeting in Utrecht, which was attended by several chairmen of other clubs and a delegation of the KNVB to discuss the start of professional football in the Netherlands. The professional era commenced with the first Eredivisie season in 1954/1955. Feijenoord were one of the clubs participating in the inaugural Eredivisie and have never been relegated. One of the most memorable matches in these first years of professional football was the clash between Feijenoord and the Volewijckers at 2 April 1956, which Feijenoord won 11\u20134, with nine goals by Henk Schouten. Feijenoord would grow an intense rivalry with Ajax. Matches between the two clubs quickly were dubbed as \"de Klassieker\" (\"The Classic\"). The first memorable \"Klassieker\" from a Feijenoord point of view took place at 11 November 1956, when Daan den Bleijker scored four times to give Feijenoord a 7\u20133 win over their archrivals.\nGolden era.\nFeijenoord claimed their first professional Eredivisie Championship and their sixth Dutch Championship in 1961. On the road to the title Ajax was beaten 9\u20135 in De Kuip, four of Feijenoord's goals were scored by Henk Schouten. The following season, they played their first European Cup match facing IFK G\u00f6teborg. The Swedes were beaten 0\u20133 in Gothenburg and 8\u20132 in Rotterdam. Feijenoord were eliminated by Tottenham Hotspur in the following round. In 1962, Feijenoord successfully defended their Dutch Championship title and reached the final of the Intertoto Cup 1961\u201362. where Feijenoord faced arch-rival Ajax in the final and subsequently lost 4\u20132.\nOn 12 December 1962, Feijenoord played a decisive match versus Vasas SC in the second round of the 1962\u201363 European Cup. The first two legs, in Rotterdam and Budapest, both ended in a 1\u20130 home victory, forcing a replay on a neutral ground to take place. The match was played in Antwerp, where 30,000 Feijenoord fans travelled by bus to see their team play. Also this time, the final score was 1\u20130; Rinus Bennaars scored the only goal and was immediately nicknamed \"The Hero of Deurne\", reflecting the neighbourhood in Antwerp where the match was played. The events in Antwerp resulted in an enduring friendly relationship between the fans of Feijenoord and Royal Antwerp.\nIn 1963, hundreds of thousands of people stood ashore by the Nieuwe Maas and the Nieuwe Waterweg to wave two ships, de \"Groote Beer\" and the \"Waterman\" goodbye. The ships transported thousands of Feijenoord fans to Lisbon where the club faced Benfica on 8 May 1963 in the European Cup semi-finals. The first leg, held in Rotterdam a month earlier, finished 0\u20130. Despite Feijenoord eventually losing the match 3\u20131, this turned out to be the start of the most successful period in the club's history. Feijenoord won the double for the first time in their history in 1965, and managed to win another double a few years later in 1969. The 1965 title secured Feijenoord a spot in the 1965\u201366 European Cup, where they faced multiple cup champion Real Madrid on 8 September 1965. During the match, Hans Kraay had to leave the pitch injured after 31\u00a0minutes, without being substituted. He returned at the start of the second half and scored the goal which resulted in a 2\u20131 win. During the match, fans' favourite Coen Moulijn was attacked by a Spanish defender. Moulijn then proceeded to chase the defender down the pitch, leading other players, and even fans who entered the pitch, to do the same. The referee could do nothing but to suspend the match at 2\u20131 in Feijenoord's favour. Two weeks later, Real Madrid comfortably beat Feijenoord 5\u20130 and eventually won the European Cup that season.\nAs the 1969 Dutch champions, Feijenoord participated in the 1969\u201370 European Cup. After winning against Knattspyrnuf\u00e9lag Reykjav\u00edkur 16\u20132 on aggregate in the first round, the club faced Milan. Feijenoord lost the first leg 1\u20130 in Italy but overcame the loss in their own stadium with a 2\u20130 win, securing a place in the quarter-finals, where they faced ASK Vorw\u00e4rts Berlin.\nThe tie followed the same pattern as the previous round: Feijenoord losing the first match 1\u20130 away, then winning 2\u20130 at home. In the semi-finals, Feijenoord beat Legia Warszawa 2\u20130 on aggregate, earning Feijenoord their first European final. Feijenoord faced Celtic in the final, held in the San Siro stadium in Milan. Goals by Tommy Gemmell and Rinus Isra\u00ebl resulted in a 1\u20131 draw after 90\u00a0minutes. Three minutes before the end of extra time, Ove Kindvall scored Feijenoord's winning goal, leading Feijenoord to be the first Dutch team to claim a major European trophy.\nAs reigning European champions, Feijenoord faced Estudiantes La Plata in the Intercontinental Cup. The first match in Buenos Aires' La Bombonera finished in a 2\u20132 draw. Back in Rotterdam, Feijenoord managed a 1\u20130 victory (winning goal by Joop van Daele) to win the world club crown, the first Dutch team to do so. Estudiantes player Oscar Malbernat got frustrated and grabbed Van Daele's glasses and trampled on them. \"You are not allowed to play with glasses... at least not in South America\" was his excuse. As the cup holders, Feijenoord participated in the 1970\u201371 European Cup despite relinquishing the Dutch title, which was won by Ajax. Feijenoord were eliminated in the first round, following a surprise defeat by the Romanian team UTA Arad. In 1971, Feijenoord won their 10th Dutch Championship.\nIn 1974, the club changed their name from \"Feijenoord\" to Feyenoord, as people from outside the Netherlands did not know how to pronounce Dutch \"ij\". Under their new name, they played in the 1973\u201374 UEFA Cup, reaching the final, following a 4\u20133 aggregate win over VfB Stuttgart in the semi-finals. The opponent in the final was Tottenham Hotspur. Spurs took a 2\u20131 lead in the first leg at White Hart Lane, but Theo de Jong equalised after 85\u00a0minutes and the match ended in a 2\u20132 draw. Feyenoord then won their match in Rotterdam 2\u20130, thanks to goals by Wim Rijsbergen and Peter Ressel, and also became the first Dutch team to win the UEFA Cup. As a result, Spurs fans started to riot, introducing Dutch football to the spectre of hooliganism in the process. The remainder of the decade saw Feyenoord win only one more honour: the Dutch Championship in 1974.\nFalling out of contention.\nIn 1978, the club divided their professional and amateur sides to form two separate teams, Feyenoord Rotterdam for professionals and SC Feyenoord for amateurs.\nFeyenoord won their fifth Dutch Cup in 1980 by beating Ajax 3\u20131 in the final.\nIn 1984, Feyenoord had another bright season, winning the double for the third time in their history. Key players in the squad from this period included Johan Cruyff, Ruud Gullit and Peter Houtman (who later became the Feyenoord stadium announcer). Cruyff reacted to Ajax's decision not to offer him a new contract at the start of the season and signed for archrivals Feyenoord instead. Cruyff's move to Rotterdam was criticised and increased Ajax's motivation to beat Feyenoord. In the Olympic Stadium of Amsterdam Feyenoord suffered one of their most heavy defeats ever: 8\u20132. However, Feyenoord later defeated Ajax in Rotterdam 4\u20131 and Ajax were subsequently beaten a second time in the Dutch Cup. Feyenoord proceeded to win a league and cup double by beating Fortuna Sittard in the cup final.\nAfter the successful season, Feyenoord experienced a lean period and were unable to finish the season in a higher position than third. In the 1989\u201390 season, the club struggled to remain in the Eredivisie, but eventually managed to avoid relegation. The club had financial problems, and as a result, the staff was not able to recover and their main sponsor, HCS went bankrupt.\nBack to winning silverware.\nWhen Wim Jansen was appointed as the interim manager to replace G\u00fcnder Bengtsson and Pim Verbeek after a 6\u20130 defeat against PSV, the outlook began to improve for the club. PSV, the strongest Dutch club of the period, were knocked out of the KNVB Cup by a Henk Fr\u00e4ser goal in Eindhoven. Feyenoord progressed to the 1991 final, where they beat BVV Den Bosch 1\u20130 to win the competition. As the cup holders, they faced champions PSV again, this time in the 1991 Dutch Supercup, the first Supercup held since 1949. PSV were beaten 1\u20130 by a Marian Damaschin goal to add another honour to the club's achievements. They went on to win another Dutch Cup in 1992, beating Roda JC 3\u20130 in the final. The same year, Feyenoord reached the semi-finals in the 1991\u201392 European Cup Winners' Cup, beating Tottenham Hotspur in the quarter-finals, before being eliminated by Monaco on away goals, after two draws.\nIn 1993, Feyenoord secured another Dutch Championship by beating Groningen 5\u20130 in the last league match of the season. The match was played at the Oosterpark Stadion in Groningen, so 40.000 Feyenoord fans watched the game on giant screens in De Kuip. The title was followed by another two Dutch Cups in 1994 (beating NEC 2\u20131) and 1995 (beating Volendam 2\u20131). During the 1994\u201395 UEFA Cup Winners' Cup, Feyenoord reached the quarter-finals after beating Werder Bremen in the second round. They eventually lost to Real Zaragoza. In the quarter-finals in the 1995 KNVB Cup, Feyenoord visited Ajax, which would win the 1994\u201395 UEFA Champions League later that season. Ajax was leading 1\u20130 when Ruud Heus equalised with a penalty just before full-time. In extra time, Feyenoord became the only team to defeat Ajax the same season they won the Eredivisie and the Champions League unbeaten. The goal scored by Mike Obiku was the decider as the new golden goal rule became in use. During the 1995\u201396 UEFA Cup Winners' Cup, Everton and Borussia M\u00f6nchengladbach were beaten. A total of 14,000 Feyenoord fans travelled to Germany to support the team against M\u00f6nchengladbach. Feyenoord were eliminated in the semi-finals by a Carsten Jancker-inspired Rapid Wien.\nFeyenoord made their UEFA Champions League debut in 1997\u201398, finishing third in their group behind Manchester United and Juventus. However, Juventus was beaten 2\u20130 in Rotterdam, with both Feyenoord goals scored by Julio Cruz. In 1998, the FIOD-ECD (Fiscal Information and Investigation Service/Economic Investigation Service) visited Feyenoord because of suspected fraud, mainly based on the signings of Aurelio Vidmar, Christian Gyan and Patrick Allotey. This became an ongoing scandal in following years, with club chairman Jorien van den Herik the main suspect. On 25 April 1999, Feyenoord secured their 14th Dutch Championship. 250,000 fans celebrated with the team in the center of Rotterdam. However, later in the evening, heavy rioting started. Prior to the start of the 1999\u20132000 season, Ajax were beaten in their own stadium when Feyenoord won their second Dutch Super Cup title after a free-kick goal by Patrick Paauwe secured a 3\u20132 win.\nAnother European prize.\nDuring the 1999\u20132000 season, Feyenoord participated in the Champions League for the second time. This time, the club managed to finish second in their group, behind Rosenborg BK and ahead of Borussia Dortmund. Feyenoord reached the second group stage and secured wins against Marseille (home) and Lazio (away). Chelsea won both clashes and, as a result, Feyenoord had to win their last group match away to Marseille to reach the knockout stages. The final result was 0\u20130, and Feyenoord were eliminated.\nFeyenoord again participated in the Champions League in 2001\u201302, finishing third in a group containing Bayern Munich, Sparta Prague and Spartak Moscow. This meant Feyenoord continued their European season in the 2001\u201302 UEFA Cup instead of the second Champions League group stage. The disappointment of failing to reach the second group stage eventually resulted in optimism and celebration. By defeating SC Freiburg and Rangers, Feyenoord faced fellow Dutch club PSV in the quarter-finals. Both matches ended in 1\u20131 draws, and the clash went into extra time and a penalty shoot-out. Pierre van Hooijdonk, who had a superb season by scoring many free-kicks goals, secured Feyenoord's win by scoring a 90th-minute equalizer before finishing PSV off by scoring the last goal in the penalty shoot-out. A 1\u20130 win in Milan against Internazionale and a 2\u20132 return match in Rotterdam then earned Feyenoord a spot in the final, against Borussia Dortmund. Coincidentally, the final was held at De Kuip, and as a result, most spectators inside the stadium were Feyenoord fans. Feyenoord took a 2\u20130 lead after another free-kick goal and a penalty by Van Hooijdonk. Early in the second half, M\u00e1rcio Amoroso scored a goal to make it 2\u20131. Jon Dahl Tomasson then made it 3\u20131. Dortmund only managed to score one more goal and the cup was won by Bert van Marwijk's Feyenoord. It is still the last time a Dutch team won a major European trophy.\nA huge party erupted in and outside De Kuip not only because of the title, but also because the final was held several days after Rotterdam's political figure Pim Fortuyn was murdered. Many fans were still full of emotion, before and after the match. As a result of Fortuyn's murder, the cup was not officially celebrated in the city centre.\nInconsistent domestic results.\nThe 2002 UEFA Cup win was the start of a long dry spell for Feyenoord. In the 2002\u201303 season, the club finish third in the Eredivisie, as well as reach the final of the KNVB Cup, which was lost 1\u20134 to Utrecht. However, in the following years, Feyenoord disappointed in both the Eredivisie and KNVB Cup.\nIn between, in 2002 Feyenoord and chairman Jorien van den Herik were both found not guilty. Following the prosecutor's appeal, and despite three years of investigations, the trial verdict was upheld. Nonetheless, the prosecution stated it would not yet abandon its case.\nThe 2005\u201306 season ended in disappointment for Feyenoord. The team pursued the Dutch championship for most of the season, but eventually lost out to champions PSV. The newly created Dutch play-offs then proved to be gloomy for Feyenoord. Ajax, which finished several points behind in the regular league, were Feyenoord's opponent in the play-offs. Ajax outclassed them and Feyenoord lost out on a Champions League place.\nIn the 2006\u201307 season, Feyenoord's supporters saw their two star players leave to Chelsea (Salomon Kalou) and Liverpool (Dirk Kuyt). At the same time, it became clear Feyenoord were in an appalling financial state despite earlier comments made by chairman Jorien van den Herik, who claimed that the club was financially healthy. Supporters' unrest grew into anger when Feyenoord bought Angelos Charisteas, a back-up striker of arch-rivals Ajax, with a poor track record, as a replacement for Dirk Kuyt. After continuous protests, Van den Herik resigned and the club began managerial reforms. Feyenoord were banned from European competition following hooliganism prior to and during a match against Nancy, despite an appeal by the club. The season ended in bitter disappointment with a seventh-place finish, causing Feyenoord to miss European football for the first time in 16\u00a0years. A brilliant performance from young Dutch left back Royston Drenthe at the 2007 UEFA European Under-21 Championship had investors flocking to the new investment schemes Feyenoord had established. The club appointed former manager Bert van Marwijk and was able to make a number of high-profile signings, including Giovanni van Bronckhorst and Roy Makaay. Despite the efforts, Feyenoord underperformed once again in the Eredivisie, finishing in a disappointing sixth place. The disappointment was relieved by claiming their first trophy in six years: 100\u00a0years after the foundation of the club, Feyenoord managed to win the KNVB Cup after defeating Roda JC 2\u20130. As Van Marwijk accepted a job as manager of the national team, Feyenoord appointed Gertjan Verbeek as their manager for the 2008\u201309 season.\nFinancial problems.\nIn the 2008\u201309 season, Feyenoord celebrated their 100th birthday and organised many events throughout the year. The old \"golden logo\" returned as Feyenoord's official logo, which had earlier been presented at the 2007 New Year's brunch. During the summer, a historical tournament was held between Feyenoord and the three opponents they met in the European Cup finals \u2013 Borussia Dortmund, Tottenham Hotspur and Celtic \u2013 named the Feyenoord Jubilee Tournament.\nMidway through the season, manager Verbeek was sacked due to disappointing league results. His assistant, Leon Vlemmings, took over as manager. The results in this period improved slightly, resulting in securing a spot in the playoffs for the final Dutch Europa League slot.\nFor the 2009\u201310 season, Feyenoord appointed former assistant manager and Feyenoord footballer Mario Been to take over from Vlemmings. Been, after achieving minor European successes with NEC, was considered the ideal candidate for the job. Former manager Leo Beenhakker, at the time manager of the Poland national team, took over as technical director. Partly because of this position, Beenhakker was able to attract more investors to the club, leading to some unexpected signings, including Sekou Ciss\u00e9, Dani Fern\u00e1ndez and Stefan Babovi\u0107.\nOn 24 October 2010, Feyenoord lost heavily to PSV 10\u20130. In mid-January 2011, Beenhakker resigned after multiple clashes with the Feyenoord directors. His replacement was former Feyenoord player Martin van Geel, who at the time was working as technical director for fellow Eredivisie club Roda JC.\nIn July 2011, a majority of players in the squad voted to oust Been as club manager; 13 of 18 players voted they had lost all confidence in Been's ability to successfully manage the club. Been's subsequent sacking became global news, if only because reports of Been's firing quickly became a trending topic on Twitter, leaving people around the world to wonder who exactly Been was.\nAfter Louis van Gaal turned down an offer to manage Feyenoord, the club approached former Barcelona defender Ronald Koeman, who had played for Feyenoord during the late 1990s. With his eventual hiring as manager, Koeman became the first to ever serve as both player and head coach at all teams of the so-called \"traditional big three\" of Dutch football: Ajax, PSV and Feyenoord. Moreover, he played and managed these teams in the same order.\nRonald Koeman era: revival with youth players.\nAt the beginning of the 2011\u201312 season, Feyenoord lost valuable players Leroy Fer, Georginio Wijnaldum and Andr\u00e9 Bahia to Twente, PSV and Samsunspor respectively. In return, the club restocked with players such as Jordy Clasie, Miquel Nelom, Guyon Fernandez and Kaj Ramsteijn, who came mostly from their own youth academy. Two other players were loaned, John Guidetti from Manchester City and Otman Bakkal from PSV. Feyenoord started the season well and played the first match of the Eredivisie against the other Rotterdam club in the league, Excelsior. Feyenoord ended the season by placing second in the Eredivisie, resulting in the third qualifying round for Champions League football.\nOn 16 December 2011, it was revealed that Feyenoord had been placed in the more favorable second category (Categorie 2), meaning Feyenoord were no longer in debt, according to the KNVB. They achieved the reclassification following the transfer of several significant players and a large capital injection made by the organisation VVF (Friends of Feyenoord, Vrienden Van Feyenoord). However, to remain in the second category, Feyenoord needed to obtain the same number of points earned, rounding up to at least 65\u00a0points. On 13 April 2012, Feyenoord was officially out of what has been described as the \"financial dangerzone\" and was officially placed in the second category. According to club chairman Eric Gudde, the placing in the more favourable category came earlier than anticipated; he also congratulated the fans and promised to maintain the same policy until Feyenoord was completely healthy again, saying the club will never fall back into the first category.\nDespite no longer having to request permission from the KNVB to invest in new players, Feyenoord kept continuing the policy for the 2012\u201313 season, only contracting players who were either out of contract or available for a low transfer fee. John Goossens, Ruud Vormer and Daryl Janmaat were out of contract and signed a deal with Feyenoord over their respective prior clubs. Mitchell te Vrede played for the affiliated football club Excelsior, as well as for the highest-ranked academy team Jong Feyenoord/Excelsior and was promoted to the main senior team. Harmeet Singh and Lex Immers were the only two players whom Feyenoord paid a transfer fee for. Singh, a Norwegian midfielder and one of two non-Eredivisie players joining Feyenoord, was purchased from V\u00e5lerenga, while Immers joined from ADO Den Haag. The other non-Eredivisie player joining Feyenoord was Omar Elabdellaoui, who was brought in on loan from Manchester City.\nOn 2 July 2012, Karim El Ahmadi completed his transfer from Feyenoord to English Premier League club Aston Villa for an undisclosed fee believed to be in the region of \u20ac2.6\u00a0million. On 15 July, Aston Villa supports uploaded a picture on Twitter which showed Ron Vlaar, Feyenoord captain since 2010\u201311, visiting Villa Park \u2013 Aston Villa's home ground \u2013 in Birmingham. Shortly after, Martin van Geel confirmed Vlaar sought to leave Feyenoord. After the incident, Villa did not contact Vlaar, prompting Ronald Koeman to issue Villa a deadline of 23 July to negotiate Vlaar's transfer. On 23 July, Vlaar told the public that he would not leave Feyenoord, and said that he felt he was kept \"dangling\" by Villa. However, four days later, Vlaar told the public he would eventually be joining Villa, as he had agreed personal terms and would sign for Villa subject to him passing a medical. On 1 August, Vlaar officially joined Aston Villa, signing a three-year contract. Feyenoord supporters received the news generally mixed, with some congratulating and wishing the best of luck and others feeling betrayed by Vlaar for misleading them. Stefan de Vrij became the new Feyenoord captain, with Jordy Clasie, who because of his good play and tenacity soon became one of the most popular players among the supporters, becoming vice-captain.\nOn 7 August, Feyenoord was eliminated by Dynamo Kyiv in the third qualifying round of the Champions League following losses in both legs. Feyenoord was therefore demoted to the play-off round of the UEFA Europa League. Koeman said that Feyenoord was the better side over the two legs but had missed a scoring striker, referring to John Guidetti, who had rejoined Manchester City following the end of his loan. On 10 August 2012, Dutch international and M\u00e1laga defender Joris Mathijsen joined Feyenoord on a three-year contract. M\u00e1laga had made clear to Mathijsen that he needed to find a new club to generate income for the financially suffering M\u00e1laga after Sheikh Al Thani left. Stefan de Vrij remained captain, despite Mathijsen being more experienced at both international and club level.\nAfter drawing the first leg of the Europa League qualifier at home 2\u20132 against Sparta Prague, Feyenoord was eliminated following a 2\u20130 loss in the second leg, meaning Feyenoord would not be playing European football in 2012\u201313. Following these events, Feyenoord loaned Parma and former AZ striker Graziano Pell\u00e8 and exchanged Jerson Cabral for Twente striker Wesley Verhoek in a straight player swap. Feyenoord ended the season in third, behind champions Ajax and second-placed PSV. Pell\u00e8 surprised many after scoring 27 goals in 29 matches, prompting Feyenoord to sign him permanently from Parma on a contract lasting until summer 2017.\nIn the 2013\u201314 season, Feyenoord recorded the worst start in its history, losing its first three matches to PEC Zwolle, Twente and Ajax respectively. Feyenoord would recover, but its performances were unstable throughout the season. However, because the Eredivisie's other top teams also played inconsistently, Feyenoord remained in the title race, although it eventually finished second, four points behind Ajax. In the UEFA Europa League, Feyenoord was eliminated in the third qualifying round by Kuban Krasnodar, making it Feyenoord's fifth consecutive season without European football.\nOn 1 February 2014, Ronald Koeman announced he would be resigning at the end of the season. On 3 March 2014, Fred Rutten was named the new manager for the 2014\u201315 season.\nDuring the summer of the 2014\u201315 season, Feyenoord lost four of its best players: Daryl Janmaat to Newcastle United, Stefan de Vrij to Lazio, Bruno Martins Indi to Porto and Graziano Pell\u00e8 to Southampton, with Southampton having just appointed Koeman as its new manager. To replace them, as well as other departed players, Feyenoord signed Warner Hahn from Dordrecht, Luke Wilkshire from Dynamo Moscow, Khalid Boulahrouz from Br\u00f8ndby, Bilal Ba\u015fa\u00e7\u0131ko\u011flu from Heerenveen, Colin Kazim-Richards from Bursaspor, Jens Toornstra from Utrecht, Kenneth Vermeer from Ajax and Karim El Ahmadi from Aston Villa, returning to the club after two years in England.\nWith new players as well as a new head coach, Feyenoord began the 2014\u201315 Eredivisie season with just five points after four matches. However, the club was successful in reaching the Europa League group stage for the first time in six years. After losing to Besiktas 5\u20132 aggregate in the third qualifying round of the Champions League, they defeated Zorya Luhansk in the final qualifying round of the Europa League play-off, 5\u20134 aggregate.\nFeyenoord won with 2\u20131 against Standard Li\u00e8ge in their first home match in Group G of the Europa League. It was the first victory for Feyenoord in the Europa League group stage in eight years. Feyenoord also beat Rijeka (2\u20130) and defending champions Sevilla (2\u20130), results sufficient for Feyenoord's progress to the knockout round for the first time in ten years. In the knockout round, Feyenoord lost to Roma 3\u20132 on aggregate. After this loss, Feyenoord did not recover. Despite nearly securing a spot in next season's Europa League qualification rounds, they failed to win any of their last five matches, ending the year in the fourth spot, behind AZ. In the play-offs to earn a spot for Europa League, they were eliminated by Heerenveen. After manager Fred Rutten opted not to extend his contract, on 23 March 2015 Feyenoord announced former Dutch international and Feyenoord player Giovanni van Bronckhorst would become its new manager. That summer the club contracted several new key players, Eric Botteghin from FC Groningen, Jan-Arie van der Heijden from Vitesse, and Eljero Elia from SV Werder Bremen. It also welcomed back Dirk Kuyt from Fenerbah\u00e7e on a one-year contract.\nFeyenoord started the season well and was in title contention until the winter break. However, Feyenoord hit a low point by losing seven matches a row. In the Eredivisie the team came third, a distance behind Ajax and the champions PSV. However, Feyenoord also booked a success. After eight years without any prizes, Feyenoord won its 12th KNVB Cup on 24 April 2016. That next summer Feyenoord managed to do some good business in the transfer market. The contracts of starting players like Dirk Kuyt and Eljero Elia were extended. Furthermore, it acquired Nicolai J\u00f8rgensen from F.C. Copenhagen for \u20ac3,500,000 and Brad Jones was contracted on a free transfer from NEC as a replacement for injured first-choice goalkeeper Kenneth Vermeer.\nEnd of 18 year title drought.\nThe 2016\u201317 season started positively, as the first nine league matches were won, and Feyenoord beat Manchester United F.C. 1\u20130 in the Europa League. This match, and all of Feyenoord's European home games were played in only a half-full stadium. These measures were taken to avoid new penalties from the UEFA. In that same week reigning Dutch champions PSV were beaten, 0\u20131. The first loss of points was against Ajax on 23 October 2016. The final score was 1\u20131 after goals of Kasper Dolberg and Dirk Kuyt. A week later another draw followed against SC Heerenveen. On 6 November, a weakened team lost for the first time that season; relegation candidate Go Ahead Eagles won 1\u20130. In the European campaign Feyenoord struggled, and after losses to Manchester United (4\u20130) and Fenerbah\u00e7e (0\u20131) the European adventure ended. In the Eredivisie the team booked big victories, such as a 6\u20131 defeat against Sparta and 0\u20134 against AZ. With a 5-point lead to second place Ajax, Feyenoord ended the year at the top of the league table.\nIn the second half of the season, Feyenoord started strongly, winning the first seven league games of 2017. However, in Arnhem, Vitesse proved to be too strong in the KNVB Cup (2\u20130). Feyenoord beat PSV at home (2\u20131), due to an own goal from PSV-goalkeeper Jeroen Zoet, which was indicated by Goal-line technology. On 5 March, Sparta was the first team to beat Feyenoord in the new year, by a goal in the first minute of the game, scored by Mathias Pogba. Feyenoord recovered quickly and another big win followed when they beat AZ, 5\u20132, and a week later SC Heerenveen were defeated 2\u20131. When Feyenoord lost to Ajax, and drew against PEC Zwolle, their lead was reduced to one point. After two more victories from Feyenoord and a loss for Ajax against PSV, the gap was four points with two games to go. One week before the end of the competition, Feyenoord could become champions away at Excelsior, just 4 kilometers from their home stadium, De Kuip, and also in Rotterdam. However, the team had a complete off-day and lost, 3\u20130. One week later, in the final game of the season, the team still became champions by beating Heracles by 3\u20131. All three goals were made by the team captain, Dirk Kuyt, who would later announce his retirement. The championship was Feyenoord's 15th and the first in 18 years. Feyenoord was the second team in the history of the Dutch league to stay at the top of the table the entire season. Because of the championship, Feyenoord was to compete for the Johan Cruyff Shield against cup winner Vitesse in the Kuip on 5 August 2017. After a 1\u20131 tie Feyenoord beat Vitesse by penalties.\nAs the Dutch champions, Feyenoord qualified directly for the 2017\u201318 UEFA Champions League group stage. The team was drawn with Manchester City, Shakhtar Donetsk and Napoli, and eventually lost its first 5 matches. However, their last home match \u2013 against Napoli \u2013 ended in victory, winning 2\u20131. That same season, Feyenoord was not able to win the Dutch championship again, but won the Dutch Cup after beating AZ 3\u20130 in the final. The 2018\u201319 season started with disappointment. Feyenoord qualified for the third qualifying round of the UEFA Europa League by virtue of winning the Dutch Cup. However, Feyenoord was immediately eliminated by AS Tren\u010d\u00edn. During the 2018-19 Eredivisie season, Feyenoord was not able to maintain the pace of Ajax and PSV and finished in third place. However, Feyenoord beat both title contenders at home. It was the first loss of PSV after opening with a 13-game winning streak. Also, Feyenoord won against Ajax in historic fashion with 6\u20132. Ajax got revenge by beating Feyenoord in De Kuip in the semi-final of the Dutch Cup. After the season, head coach Giovanni van Bronckhorst left the club, while star player Robin van Persie retired. Jaap Stam was appointed as the new head coach.\nNew struggles.\nThe 2019\u201320 season started with mixed results. Feyenoord reached the group stage of the Europa League by comfortably beating Dinamo Tbilisi and Hapoel Be'er Sheva. However, in the eredivisie Feyenoord won only 3 of the first 10 matches and found themselves in 10th place before heading into the Amsterdam for an away game against title holders and league leaders Ajax. After the first half, Ajax lead the game 4\u20130, which was also the final result. Jaap Stam resigned after the game, after which Dick Advocaat replaced him as head coach of Feyenoord. With Advocaat as the new head coach, Feyenoord improved, staying undefeated and climbed the table from the 12th to 3rd place and was only six points behind league leaders Ajax and AZ. Furthermore, Feyenoord qualified for the final of the Dutch Cup. However, the Eredivisie was suspended and eventually abandoned due to the outbreak of the COVID-19 pandemic. The ranking when the league was suspended became the final ranking, meaning Feyenoord ended the season in third place, qualifying for the group stage of the 2020\u201321 Europa League. The cup final was not played.\nFeyenoord had a decent start of the 2020\u201321 Eredivisie season, losing only once after 16 matches. However, Feyenoord was eliminated during the group stage of the Europa League. In the league, Feyenoord found themselves on second place, three points behind league leaders Ajax before playing them in a direct confrontation for the top spot. Ajax won the match 1\u20130. Feyenoord had a disappointing second half of the season, winning only 6 matches. In the meanwhile, Feyenoord lost 4\u20133 against SC Heerenveen in the quarter finals of the KNVB cup, despite a 1\u20133 lead in the second half. Feyenoord finished in fifth place, and had to participate in the play-off tournament to secure a spot in the UEFA Europa Conference League. Feyenoord succeeded, by first beating Sparta and then FC Utrecht, both with 2\u20130 victories. During the season, it was announced that AZ coach Arne Slot would succeed Dick Advocaat as the head coach of Feyenoord.\nArne Slot era: back in title contention and European final.\nFor the 2021\u201322 season, Feyenoord participated in the inaugural edition of the UEFA Europa Conference League. Feyenoord narrowly defeated FC Drita 3\u20132 in the second qualifying round. But Feyenoord improved, beating FC Luzern 3-0 twice in the third qualifying round and IF Elfsborg 6\u20133 on aggregate. Feyenoord topped a group with Maccabi Haifa, Union Berlin and Slavia Prague and qualified for the round of 16. Feyenoord defeated Partizan Belgrado 5\u20132 away and 3\u20131 at home. In the quarter finals, Feyenoord again played Slavia Prague. After a 3\u20133 draw at home, Feyenoord managed to win 1\u20133 in Prague. In the semi finals, Feyenoord faced Olympique Marseille. The first game in the Kuip was won 3\u20132. In Marseille, Feyenoord held on to a 0\u20130 draw. The team managed to reach the final but lost 1\u20130 to Italian club Roma. In the Eredivisie, Feyenoord improved on the total of the previous season, finishing in third place with 71 points. In the Dutch Cup, Feyenoord was eliminated in the second round after extra time by FC Twente.\nAfter the success in the Conference League, Feyenoord lost many players, including nine players who played in the Conference League Final. With a new squad, Feyenoord managed to stay in title contention in the 2022\u201323 Eredivisie Season. Only one match was lost in the first half of the season, 4\u20133 against PSV. During the world cup break, Feyenoord topped the table, 3 points clear of runners up PSV and Ajax. After the world cup break, the form improved. While a few games against other title contenders were drawn, Feyenoord was able to keep hold of the first spot. Feyenoord started a 13-game winning streak, among others booking crucial, late victories against AZ at home and away against Ajax. The win against Ajax was the first win of Feyenoord in an away match against Ajax since 2005. Feyenoord secured the title two games before the end of the season by winning 3\u20130 against Go Ahead Eagles. It was the 16th championship win in the history of the club and the first since 2017. Feyenoord was lauded by many experts as the deserved champion, due to their energetic and attacking playing style.\nIn the Europa League, Feyenoord was drawn in a group with FC Midtjylland, Sturm Graz, and S.S. Lazio. All teams ended with 8 points, but Feyenoord finished the group stage in first place by virtue of a superior goal difference. In the round of 16, Feyenoord defeated Shaktar Donetsk 8\u20132 on aggregate and was drawn to play against AS Roma again in the quarter finals. The first match at home ended with a 1\u20130 victory. The return match went to extra time and resulted in a 4\u20131 victory for AS Roma. In the Dutch Cup, Feyenoord was defeated in the semi-finals at home by Ajax, 1\u20132. Due to the successes and playing style of Feyenoord, there was some serious interest from clubs in Arne Slot, including from Tottenham Hotspur. However, after a few weeks of rumours Arne Slot extended his contract, citing he was not finished yet at Feyenoord.\nFeyenoord started the 2023\u201324 Eredivisie season slowly. The Johan Cruijff Schaal was lost against PSV 0\u20131, while the first two league games were drawn. Feyenoord then booked seven consecutive victories, including a 0\u20134 away win against Ajax in Amsterdam. This streak was ended by a loss in Enschede against FC Twente. Feyenoord also lost again at home against PSV 1\u20132. Despite these setbacks, Feyenoord had more points after 16 matches compared to the previous season. However, as PSV started the season perfectly, winning all their 16 matches, Feyenoord found themselves in second place, 10 points behind their rivals at the winter break. In the 2023\u201324 UEFA Champions League, Feyenoord was drawn in group with Atletico Madrid, Celtic and again S.S. Lazio. Feyenoord won the home games against Celtic and S.S. Lazio. Despite showing good form and impressing foreign media with their play, Feyenoord failed to pick up a single point in the away matches and at home against Atletico. Feyenoord ended the group stage on third place and qualified for the preliminary round of the 2023\u201324 UEFA Europa League. Feyenoord was drawn against Roma again. Both matches ended in a 1\u20131 draw, after which Feyenoord was defeated in a penalty shootout. It was the third year in a row that Feyenoord's European season was ended by AS Roma.\nAfter the winter break, Feyenoord won at 1\u20130 home against PSV in the third round of the KNVB-cup. It was the first defeat of PSV against a Dutch opponent in almost a year. Feyenoord played AZ at home in the quarter finals and won 2\u20130. In the semi-finals, Feyenoord played at home again, this time against Keuken Kampioen Divisie team FC Groningen. Feyenoord won the match 2-1 and advanced to the finals against NEC Nijmegen. In the league, Feyenoord stayed in second place, among others drawing against PSV, 2-2. It was the only time PSV didn't win a home game in the Eredivisie. On April 7, Feyenoord defeated Ajax at home 6\u20130. It was the biggest defeat of Ajax in a competitive game since the inception of the Eredivisie and the first time Ajax failed to score in both league games against Feyenoord. In the KNVB Cup Final against NEC Nijmegen, Feyenoord won 1\u20130. It was the 14th cup victory of Feyenoord and the first since 2018. Feyenoord clinched second place and qualification for the group stage of the 2024\u201325 UEFA Champions League four games before the end of the season by winning 1\u20133 at Go Ahead Eagles. After this game, Liverpool and Feyenoord reached an agreement that Arne Slot would transfer to Liverpool, succeeding Jurgen Klopp as head coach. Feyenoord outscored PSV in the second half of the season with 5 points, however it was not enough the erase the deficit. Feyenoord remained unbeaten in all competitive matches after the winter break and ended the season with 84 points, one point shy of their highest total in 1973. Coincidentally, in both seasons Feyenoord finished in second place.\nBrian Priske, coach of Sparta Prague and born in Denmark, was appointed as the successor of Arne Slot. He became the first foreign head coach at Feyenoord since 1991, when Gunder Bengtsson from Sweden was head coach. Priske started his tenure by winning the Johan Cruijff Schaal against champions PSV. After a spectacular game that ended in a 4\u20134 draw, Feyenoord won after a penalty shoot-out. With a new coach and new players, Feyenoord only won two of the first six league games, drawing the others. Then, Feyenoord won six out of the next seven games, only losing against Ajax. In the Champions-League, Feyenoord mixed disappointing home loses against Bayer Leverkussen and Red Bull Salzburg with positive results in away matches. Feyenoord won 2\u20133 against Girona and 1\u20133 against Benfica, and drew 3\u20133 after being 3\u20130 down against Manchester City. In the Eredivisie, by the winter break, Feyenoord was in 4th place, 10 points behind league leaders PSV. Feyenoord continued to show poor form after the winter break, losing at home against FC Utrecht and drawing away against Willem II. Before the home game against Bayern Munich in the Champions League, persistent rumors appeared that Priske would be dismissed after the game, even with a win. However, after Feyenoord won the game 3\u20130, Feyenoord maintained Priske.\nFollowing another series of disappointing results, Priske was eventually dismissed. The lack of chemistry between (part of) the coaching staff and the players, the disappointing results in the league, the lack of development in play and the poor physical condition of the players \u2013 which resulted in many injuries \u2013 were all reasons for this decision. Youth Academy coach Pascal Bosschaart would temporarily take over as head coach. With Pascal Bosschaart, Feyenoord was able to eliminate AC Milan in the preliminary rounds of the Champions League, by winning 1\u20130 at home and drawing 1\u20131 in Milan. This set-up a leg in the round of 16 with Internazionale. Feyenoord announced that Robin van Persie, former player and current head coach of SC Heerenveen would take over as the permanent head coach. With Van Persie as the new head coach, Feyenoord was eliminated in the Champions League bij Internazionale. In the Eredivisie, Feyenoord recovered and clinched third place and the qualifying rounds of the 2025\u201326 UEFA Champions League one match before the end of the season by beating RKC at home.\nLocation.\nFeyenoord are located in the Feijenoord district of southern Rotterdam and is named after the district in which the club was founded. More frequent appearances in international tournaments led the club to change its name in 1974, because foreign fans unfamiliar with the Dutch language did not know how to pronounce ij. Beside Feyenoord, there are two other professional football clubs in Rotterdam: Sparta and Excelsior. Feyenoord and Sparta (promoted after the 2018\u201319 season) and Excelsior (promoted after the 2024\u201325 season) are all playing in the 2025\u201326 Eredivisie season.\nStadium.\nDe Kuip.\nThe club's Feijenoord Stadion, located in the IJsselmonde district of Rotterdam, is nicknamed \"De Kuip\", Dutch for \"The Tub\". It was built in 1937 and is a major European stadium. It has 51,117 seats and has hosted a record of ten finals of UEFA club competitions, including the 2002 UEFA Cup Final fittingly won by Feyenoord. Former Feyenoord player Mike Obiku once said, \"Every time you enter the pitch, you're stepping into a lion's den.\" Feyenoord, however, does not own the stadium; it is an organisation on its own.\nIn 1935, Feijenoord player Puck van Heel hit the first pole on their way into their new stadium. The stadium was opened on 27 March 1937 and Beerschot was beaten by 5\u20132, Leen Vente scored the first goal in De Kuip. Already in the very beginning the stadium was sold out on several occasions and other events held at de Kuip also gained high attendance. During World War II, the stadium was one of the few locations which was not bombed, however the Nazis occupied the stadium. After the war, De Kuip became a popular location once again. In 1949, the attendance record was broken during the match to decide the Dutch championship between SVV Schiedam and Heerenveen; 64,368 fans attended the match.\nBesides football, there were also boxing and motorcycle speedway races in De Kuip, which were also gaining popularity. In 1953, people had to hide inside the stadium during the North Sea flood of 1953. On 27 November 1957, Feyenoord played versus Bolton Wanderers during an evening match. It was the first time the floodlights were used. The players entered the pitch in the dark and the fans were asked to light their matchsticks when the floodlights were activated. Since that evening, that match at De Kuip has always been special among Feyenoord fans.\nIn 1963, De Kuip hosted their first European final (Cup winners' Cup) between Tottenham Hotspur and Atl\u00e9tico Madrid. Nine more European finals would follow in the years after with Feyenoord's win over Borussia Dortmund in the 2002 UEFA Cup final being the tenth and latest. The attendance record of 1949 was broken in 1968 when 65,427 fans attended the Feyenoord\u2013Twente match.\nNew stadium.\nIn December 2006, Feyenoord director Chris Woerts announced that Feyenoord were developing plans to build a new stadium which would have a capacity of roughly 90,000 seats. The stadium would most likely be placed on the Nieuwe Maas, the river that runs through Rotterdam, and should be completed by 2016.\nIn May 2008, Woerts announced further details: the club is aiming for a stadium with a capacity of around 100,000 seats. If possible, a capacity of over 130,000 should be realized according to Woerts, which would earn the title of biggest stadium in Europe. The club emphasized its efforts to make it a true football stadium with seats close to the pitch. The stadium will get a retractable roof so that other events can be held as well. According to plans in those days, the stadium should be ready in 2016. Due to financial difficulties for all parties involved and the fact that the Netherlands were not chosen to host the 2018 FIFA World Cup, the plans for a new stadium have been put on hold. A new stadium will most likely be built in the future, though it will likely not have a spectator capacity greater than 70,000.\nIn September 2012, Feyenoord confirmed that they would try to build a new stadium by 2018. The stadium was designed by VolkerWessels, it would have cost around \u20ac300\u00a0million (~\u00a3242\u00a0million). Another option was a plan made by a consortium of BAM, Eneco Energie and Siemens. But the plan was rejected by the Feyenoord and Stadion Feijenoord direction. The new stadium should be a 63,000 all-seater. Due to the illustrious history of De Kuip, many fans were against the demolition of De Kuip and instead preferred a renovation of the current stadium. One of those initiatives was \"Red de Kuip\", which is Dutch for Save de Kuip. They made plans of building a third tier on top of the current stadium, increasing the capacity to 68,000. This plan would cost only \u20ac117\u00a0million (~\u00a394\u00a0million).\nIn 2016, Feyenoord announced their plans for a new stadium called Feyenoord City. The planned capacity was set to be around 65,000 seats, which would've made it the Netherlands' largest stadium. Despite the council approving the plans for the new stadium, it once again proved unpopular with many Feyenoord supporters. In May 2022, the director of Stadion Feyenoord, Jan van Merwijk announced that Feyenoord City would not be feasible due to financial difficulties, and that a major renovation of Stadion Feyenoord would also be out of question for the time being.\nStadium songs.\nOfficial Feyenoord hymn.\nFeyenoord's official hymn since 1961 is called \"Hand in Hand\". Its melody was written in the 19th century by German Wilhelm Speidel. In 1961, Jaap Valkhoff wrote the lyrics which became popular among Feyenoord supporters who adopted the song as their unofficial hymn. Valkhoff wrote lyrics on the same melody for several other teams as well. Among them were Feyenoord's archrivals Ajax. Nowadays, the song is heard wherever Feyenoord play their matches, but also fans of MVV and Club Brugge have their own version that they sing.\nOther songs.\nWhen a goal is scored by Feyenoord in their home matches the song \"I Will Survive\", covered by the Hermes House Band (but made famous by Gloria Gaynor in the 1970s) is played.\nFeyenoord supporters are known to be creative and have a lot of various songs and chants in their equipment during matches. Among the most important Feyenoord songs are \"Wie heeft er weer een goal gescoord, Feijenoord, Feijenoord\" by Tom Manders, \"Mijn Feyenoord\" by Lee Towers, \"Feyenoord, wat gaan we doen vandaag?\" by Cock van der Palm, and \"De laatste trein naar Rotterdam\" by Tom Manders. During the 2001/02 season, when Feyenoord won the UEFA Cup, a parody of the song \"Put your hands up\" by Black and White Brothers was launched, called \"Put your hands up for Pi-Air\", a tribute to Pierre (\"Pi-Air\") van Hooijdonk, one of the club's key players at the time. In the 1970s, Coen Moulijn also had a song dedicated to him, \"Coentje Coentje Coentje\".\nSupporters.\nThe supporters of Feyenoord are said to be one of the most loyal supporter groups in the world supporting the team during both good or bad times. They are nicknamed \"Het Legioen\", Dutch for \"The Legion\" and can be found everywhere in the Netherlands and far across the Dutch borders. Squad number 12 is never given to a player, but is reserved for Het Legioen instead.\nPopularity.\nFeyenoord is a popular club in the Netherlands with a large number of supporters. The team's first training session of a season alone attracts thousands of fans; 20,000 attended 2007\u201308's inaugural session.\nIn 1963, about 3,000 fans boarded on two ships, among thousands of others by train or car and they travelled to Lisbon where Feyenoord faced Benfica in the European Cup. When Feyenoord play abroad in European competitions, about 8,000 travel together to support their team. Almost 15,000 fans were cheering for their team in 1996 when Feyenoord played in Germany against Borussia M\u00f6nchengladbach. About 40,000 fans visit a regular match at home while top classes against Ajax, PSV and European cup opponents are sold out most of the time. About 250,000 fans showed up when Feyenoord's Dutch championship was celebrated in 1999 at the Coolsingel in the centre of the city. After Feyenoord beat Internazionale in the 2002 UEFA Cup semi-final, Inter midfielder Clarence Seedorf said, \"I really enjoyed the atmosphere in the Kuip. As an ex-Ajax player I was really given the bird, but that's all part of the emotions in football. It also illustrates the intense way in which the Feyenoord supporters experience their club's matches.\"\nA number of the club's followers acknowledge a very close link with English side Sunderland A.F.C.. Over 100 Feyenoord supporters attended a function in Sunderland on the evening before their fixture with Newcastle in April 2015 and a similar number of Sunderland fans made the journey to watch the Dutch side in their ultimately delayed fixture against Vitesse.\nBeyond the Netherlands, Feyenoord opened a fanshop in the centre of Tokyo, when Japanese player Shinji Ono was a key player at the club, and also in South Korea when Song Chong-Gug played for Feyenoord.\nSupporters organisations.\nFeyenoord have one official fan supporters club, the Feyenoord Supportersvereniging. Independent of the club, FSV has a membership of about 23,000, as of 2006. The FSV act as a liaison between club and fans, produce match programmes, arrange travel to away games and organise supporters' evenings, as well as being involved in the other supporters organisations. Children between 0 and 12\u00a0years old can join the \"Kameraadjes\" group ().\nIn 1998, the Feyenoord Supporters Vereniging were wondering about whether or not it would be possible to create more atmosphere inside the stadium mainly during important matches. As a result, a few huge flags were produced and brought into the stadium prior to matches played by Feyenoord. The flags were a success, but people started asking for more activities and a meeting between fans and officials were arranged. In 2000 Harry Veth was given permission to establish a group of five Feyenoord fans called TIFO team Feyenoord Rotterdam. Besides creating more flags and small pieces of paper released from the second platform the team also started to organise bigger activities. The first big activity was held on 10 December 2000 when Feyenoord faced Ajax and 40 fog machines were activated when the players entered the pitch. In the following years many different and various activities were held to improve the atmosphere inside the stadium. Feyenoord's TIFO team became famous abroad as well and the Italian TIFO foundation awarded Feyenoord the Best of TIFO Award 2000/01.\nJeugdproject.\nFeyenoord's Jeugdproject (Youth Project) concentrate on children between 6 and 12\u00a0years of age, playing football at schools and amateur teams. To show the kids the importance of sports and sportsmanship, Feyenoord invite the children to De Kuip to see what sport can do to people: happiness, disappointment, excitement, emotions, fear and cosines, it brings people together. In Feyenoord's Youth Project visiting a match is the central point, but there is also an educative and cultural character included. Feyenoord provide schools and amateur clubs with small teaching books and expect these to be filled in by the visiting youth when they enter the stadium on a match day. The groups that support Feyenoord in the most original way and those who can predict the score correctly are awarded with prizes.\nOpening day.\nA few weeks after the start of the pre-season, yet prior to the start of the competitive season, the club opens its doors for free for all Feyenoord fans and to present the squad for the upcoming season. De Kuip already opens in the morning when there are many activities around the stadium mainly for children and promotional activities for companies which have a partnership with Feyenoord. Fans can also take a stadium tour and walk on the pitch. The activities inside the stadium itself normally start around noon, when there are several performances by various artists. Every year, the new Feyenoord ambassador of the year is announced at opening day. A minute of silence is held for all former Feyenoord players who have died and for known fans who have died in the previous year.\nFormer Feyenoord players return to De Kuip every year to play versus a team of Dutch celebrities. The stadium activities end after the squad for the upcoming season is presented to the fans. This is a special event, mainly for the new signings of the team. They arrive into the ground via helicopter, with a full stadium of fans in attendance. Once they are there, the other players and club officials enter the pitch one by one. All players are available for autograph sessions afterwards. Feyenoord's open day attracts approximately 60,000 to 70,000 fans towards Rotterdam, coming from all over the Netherlands, while there are only 51,117 seats available within the stadium. The opening day is known as a unique event in the Netherlands.\nNotable supporters.\nNotable supporters of Feyenoord include Craig Bellamy, Wouter Bos, Gerard Cox, Robert Eenhoorn, DJ Paul Elstak, Arjan Erkel, Dennis van der Geest, Ernesto Hoost, Jan Marijnissen, and Raemon Sluiter.\nRaemon Sluiter, Lee Towers, Dennis van der Geest, Robert Eenhoorn and Renate Verbaan have all officially been Feyenoord ambassadors. Gerard Meijer is the current ambassador, also being appointed \"ambassador for life\" on 19 July 2008.\nRivalries.\nDe Klassieker.\nAjax from Amsterdam are Feyenoord's archrivals. The two clubs share a long history together and matches between the two clubs are called \"De Klassieker\" (lit.\u2009'The Classic'). The rivalry is not only between the two teams, but also a confrontation between the two largest cities of the country, Amsterdam and Rotterdam, two cities with extreme differences in attitude and culture. The meeting between the two teams is still considered to be the biggest match of the season. In the past, there have been many clashes between the supporters of both clubs, of which the Beverwijk clash in 1997 is the most infamous, with Ajax fan Carlo Picornie being killed and several others injured.\nIn 2004, Feyenoord player Jorge Acu\u00f1a was taken to hospital with head, neck and rib injuries after Feyenoord players were attacked by Ajax hooligans during a match between the reserve teams of both clubs. Another Feyenoord player, Robin van Persie, had to be rescued by Ajax coach John van 't Schip and player Dani\u00ebl de Ridder. In 2005, riots before and after the match occurred in Rotterdam and were considered to belong to the worst in the history of Dutch football.\nRotterdam derby.\nRotterdam is the city with the most professional teams in the Netherlands. Besides Feyenoord there are Sparta Rotterdam and Excelsior. There is a rivalry between the teams, mostly between Feyenoord and Sparta as Excelsior used to be Feyenoord's feeder club, but it is not comparable to other local derbies. The rivalry between Sparta and Feyenoord is mostly seen on the Sparta side. The rivalry started in the 1910s and 20s, when Sparta was regarded as a club for the elite, while Feyenoord was regarded the club for the people, mostly workers. Some Sparta fans have refused to enter Feyenoord's De Kuip stadium, even when Sparta had reached the KNVB Cup final, which was played in De Kuip. In the 1950s there was much more of a rivalry. One of the key factors for these feelings was footballer Tinus Bosselaar, who moved from Sparta to Feyenoord in 1954 before Sparta re-signed him, despite Feyenoord trying to prevent the deal in court.\nFeyenoord also have a rivalry abroad against Tottenham Hotspur following several violent clashes between the club's supporters and Tottenham's \"link\" to Ajax.\n \"As of 11 March 2025\"\nUEFA club coefficient ranking.\nUEFA club coefficient: 71,000 (26th) \nFeyenoord coaches.\nFeyenoord have had coaches from all over Europe. In the early years, the club mainly had English managers, as football was already professional there. Feyenoord's first Dutch coach was Engel Geneugelijk (ad interim), while Richard Dombi is seen as the first successful coach. He led the team in three different periods. During the club's weakest period, Feyenoord was coached by two coaches at once, the Dutchman Pim Verbeek and the Swede Gunder Bengtsson. Bengtsson was the last foreign coach to lead Feyenoord. Feyenoord's international trophies were won by Ernst Happel, Wiel Coerver and Bert van Marwijk.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nFeyenoord chairmen.\nAlthough Feyenoord's coaches have come from all over Europe, the club's chairmen have been mostly Dutch, with Amandus Lundqvist from Sweden as the only exception. With 28\u00a0years, Cor Kieboom was the longest-reigning chairman in club history.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nMedia.\nSince 2000 Feyenoord has had its own television programme, shown weekly on SBS6. The show features interviews with players and other team members as well as documentaries about the team. As of the 2006\u201307 season Feyenoord launched its own Feyenoord TV project on their website with daily news and reports that tells everything about the club. In 1993, Feyenoord introduced their own newspaper, the \"Feyenoord Krant\", the only Dutch club to do so. The newspaper is published fortnightly, with a print run of 25,000. Extra editions are published to coincide with European matches. Inside the newspaper news, background information, interviews, reports and columns by Feyenoord related figures can be found.\nFeyenoord were one of the latest Dutch teams to open their own official website on 21 May 2001.\nThe site is available in Dutch and English, plus other languages depending upon the nationalities of the club's high-profile players. As of 2007, Japanese and Korean editions are available due to the popularity of Shinji Ono and Song Chong-Gug in their home countries. Since 2004, Feyenoord have shared a website \"2 teams 1 goal\" with UNICEF as part of Feyenoord's children's welfare project in Ghana. To mark Feyenoord's centenary another site was launched in January 2007 to publicise events related to the occasion. Feyenoord also opened official Live.com and YouTube pages in 2006.\nFeyenoord also offer the option to follow the club with news and statistics on cell phones or email. For each and every home match a daily program magazine is created and children who are members of the Kameraadjes also receive a magazine. At the beginning of the season Feyenoord produce a new presentation magazine, while at the end of the season a Feyenoord yearbook is created.\nIn January 2024, Feyenoord launched its own streaming service named \"Feyenoord One\". The streaming service provides exclusive documentaries, video series, replays of historical matches and livestreams of select youth academy matches.\n \"As of 1 September 2025\"\nCurrent squad.\n&lt;templatestyles src=\"Template:Football squad player/styles.css\" /&gt;\nOut on loan.\n&lt;templatestyles src=\"Template:Football squad player/styles.css\" /&gt;\n \"As of 18 August 2025\"\nReserve squad.\n&lt;templatestyles src=\"Template:Football squad player/styles.css\" /&gt;\nPartnerships.\nSC Feyenoord.\nSC Feyenoord are Feyenoord's amateur and youth side, who have played at Varkenoord, directly behind De Kuip since 1949. Sportclub Feyenoord's annual youth trials attract a large number of hopefuls, with thousands of boys attempting to impress the coaches.\nThe Feyenoord squad typically contains a number of players who joined the club after playing for Sportclub Feyenoord, and several players from Sportclub Feyenoord have progressed to have successful careers at international level, including Puck van Heel, Wim Jansen and Giovanni van Bronckhorst. A number of high-profile managers also started their coaching careers at Varkenoord, including Clemens Westerhof and Leo Beenhakker.\nPartnerships with other clubs.\nAs of 2007, Feyenoord have three formal partnerships, a satellite club arrangement with nearby Excelsior, a partnership with Hungary's \u00dajpest FC and the Feyenoord Academy in Ghana. The strongest of these partnerships is that with Excelsior, who since 1996 have loaned young Feyenoord players on the verge of the first team. The purpose of this is to allow them to experience regular first-team football, aiding their development while simultaneously strengthening Excelsior's squad. The highest profile players to have played at Excelsior as part of this arrangement are Thomas Buffel and Salomon Kalou, who were both subsequently involved in transfer deals worth several million euros. The partnership between Feyenoord and Excelsior was scaled back in 2006, though the clubs still work together.\nFeyenoord's co-operation with \u00dajpest started when Hungarian ex-footballer and former Feyenoord player J\u00f3zsef Kiprich joined the Hungarian team as an under-19 coach and started as a scout for Feyenoord.\nThe Feyenoord Ghana academy in arose form a visit by Feyenoord chairman Jorien van den Herik to Abidjan to sign the then unknown Bonaventure Kalou, when Van den Herik contacted with the education institute at Kalou's club. The academy was built in Fetteh, just outside Accra, after go-ahead for and was given by the Chief of Fetteh in 1998. At the academy, young talented African footballers can work on their football skills. In addition to helping their football potential, the students are provided with formal education which is funded by Feyenoord. The Feyenoord Academy currently play their matches in the OneTouch Premier League.\nThe club have also entered into several other partnerships which are now discontinued, most extensively in Brazil with Am\u00e9rica and J.J.'s football school in Rio de Janeiro. Other clubs who have previously entered partnerships with Feyenoord include Parramatta Power, Nagoya Grampus Eight, B.93, Helsingborgs IF, Supersport United, Westerlo, KV Mechelen, Brei\u00f0ablik UBK, Lyn, UKS SMS \u0141\u00f3d\u017a, Omiya Ardija and Jiangsu Shuntian.\nThe club also set ties with Indian Super League franchise Delhi Dynamos FC.\nOn 15 January 2019, Feyenoord announced a partnership with Eerste Divisie club FC Dordrecht which would see players which are not yet ready for the first team loaned out to FC Dordrecht.\nWomen's team.\nOn 31 March 2021, Feyenoord announced that the club would be joining the women's Eredivisie from the start of the 2021\u201322 season.\nSponsorships.\nAs of the 1981\u201382 Eredivisie season, the KNVB allowed the teams participating in the league to use sponsor names on their shirts in exchange for money. At the time, Feyenoord's shirts were produced by Adidas and the first main sponsor was the Dutch Yellow Pages, Gouden Gids. In the second half of the 1982\u201383 season Adidas were replaced by Puma as the shirt supplier. As a result, the Gouden Gids name was enlarged and was more visible on the shirts. Gouden Gids sponsored the team until 1984, when Opel became the new sponsor. The deal between Feyenoord and Opel lasted until 1989, but in 1987 Hummel International replaced Puma as the shirt manufacturer.\nIn 1989, Hummel produced the shirts sponsored by HCS. In 1990, Adidas began producing Feyenoord's kits, however HCS declared bankruptcy shortly thereafter and could no longer sponsor the club. Stad Rotterdam Verzekeringen then began sponsoring Feyenoord in what would turn out to be a long-term partnership: it remained Feyenoord's main sponsor until 2004, when it was taken-over by Fortis. In January 2007, the parties' sponsorship contract was extended until 2009, with the option of Fortis continuing its obligations for an additional three seasons. In 2000, Kappa began producing the club's kits (replacing Adidas) until after the 2008\u201309, when it was replaced by Puma.\nWhen Fortis faced near bankruptcy, its assets were divided among several companies. The same insurance branch which previously sponsored Feyenoord became ASR. To help with their brand recognition, it decided to continue Fortis' sponsor obligations, but in 2011, it announced it would stop its sponsorship deal in the 2012\u201313 season. However, due to an economic recession, Feyenoord had trouble finding a new shirt sponsor. Feyenoord and ASR therefore reached a compromise: ASR would remain sponsor for one more season, giving Feyenoord the time it needed to find another sponsor. After negotiations with several corporations, Opel became the club's new sponsor, signing a contract until 2018.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47708", "revid": "76", "url": "https://en.wikipedia.org/wiki?curid=47708", "title": "Year 2000 bug", "text": ""}
{"id": "47709", "revid": "11952314", "url": "https://en.wikipedia.org/wiki?curid=47709", "title": "Feyenoord rotterdam", "text": ""}
{"id": "47710", "revid": "7852030", "url": "https://en.wikipedia.org/wiki?curid=47710", "title": "Cotton gin", "text": "Machine that separates cotton from seeds\nA cotton gin\u2014meaning \"cotton engine\"\u2014is a machine that quickly and easily separates cotton fibers from their seeds, enabling much greater productivity than manual cotton separation. The separated seeds may be used to grow more cotton or to produce cottonseed oil. Handheld roller gins had been used in the Indian subcontinent since at earliest 500 and later in other regions. The Indian worm-gear roller gin was invented sometime around the 16th century and has, according to Lakwete, remained virtually unchanged up to the present time. A modern mechanical cotton gin was created by American inventor Eli Whitney in 1793 and patented in 1794. \nWhitney's gin used a combination of a wire screen and small wire hooks to pull the cotton through, while brushes continuously removed the loose cotton lint to prevent jams. It revolutionized the cotton industry in the United States by making cotton farming more profitable and efficient, and consequently led to the growth of slavery in the Southern United States due to dependence on slaves for harvesting. The invention has thus been identified as an inadvertent contributing factor to the outbreak of the American Civil War. Modern automated cotton gins use multiple powered cleaning cylinders and saws, and offer far higher productivity than their hand-powered precursors.\nPurpose.\nCotton fibers are produced in the seed pods (\"bolls\") of the cotton plant where the fibers (\"lint\") in the bolls are tightly interwoven with seeds. To make the fibers usable, the seeds and fibers must first be separated, a task which had been previously performed manually, with production of cotton requiring hours of labor for the separation. Many simple seed-removing devices had been invented, but until the innovation of the cotton gin, most required significant operator attention and worked only on a small scale.\nMechanism.\nWhitney's gin is made with two rotating cylinders. The first cylinder has lines of teeth around the circumference, and angled against this cylinder is a metal plate with small holes, \"ginning ribs\", through which the teeth can fit with minimal gaps. The teeth grip the cotton fibers as the mechanism rotates, dragging them through these small holes. The seeds are too big to fit through the holes, and are thus removed from the rotating cotton by the metal plate, before they fall into a collecting pot. On the other side of the first cylinder, there is a second cylinder, also rotating, with brushes attached. This second cylinder wipes the cotton from the first, and deposits it into the collecting bucket.\nThe seed is reused for planting or is sent to an oil mill to be further processed into cottonseed oil and cottonseed meal. The lint cleaners again use saws and grid bars, this time to separate immature seeds and any remaining foreign matter from the fibers. The bale press then compresses the cotton into bales for storage and shipping. Modern gins can process up to 15 tonnes (33,000 lb) of cotton per hour.\nHistory.\nA single-roller cotton gin came into use in India by the 5th century. An improvement invented in India was the two-roller gin, known as the \"churka\", \"charki\", or \"wooden-worm-worked roller\".\nEarly cotton gins.\nThe earliest versions of the cotton gin consisted of a single roller made of iron or wood and a flat piece of stone or wood. The earliest evidence of the cotton gin is found in the fifth century, in the form of Buddhist paintings depicting a single-roller gin in the Ajanta Caves in western India. These early gins were difficult to use and required a great deal of skill. A narrow single roller was necessary to expel the seeds from the cotton without crushing the seeds. The design was similar to that of a mealing stone, which was used to grind grain. The early history of the cotton gin is ambiguous, because archeologists likely mistook the cotton gin's parts for other tools.\nMedieval and Early Modern India.\nBetween the 12th and 14th centuries, dual-roller gins appeared in India and China. The Indian version of the dual-roller gin was prevalent throughout the Mediterranean cotton trade by the 16th century. This mechanical device was, in some areas, driven by waterpower.\nThe worm gear roller gin, which was invented in the Indian subcontinent during the early Delhi Sultanate era of the 13th to 14th centuries, came into use in the Mughal Empire sometime around the 16th century, and is still used in the Indian subcontinent through to the present day. Another innovation, the incorporation of the crank handle in the cotton gin, first appeared sometime during the late Delhi Sultanate or the early Mughal Empire. The incorporation of the worm gear and crank handle into the roller cotton gin led to greatly expanded Indian cotton textile production during the Mughal era.\nIt was reported that, with an Indian cotton gin, which is half machine and half tool, one man and one woman could clean 28 pounds of cotton per day. With a modified Forbes version, one man and a boy could produce 250 pounds per day. If oxen were used to power 16 of these machines, and a few people's labor was used to feed them, they could produce as much work as 750 people did formerly.\nUnited States.\nThe Indian roller cotton gin, known as the \"churka\" or \"charkha\", was introduced to the United States in the mid-18th century, when it was adopted in the southern United States. The device was adopted for cleaning long-staple cotton but was not suitable for the short-staple cotton that was more common in certain states such as Georgia. Several modifications were made to the Indian roller gin by Mr. Krebs in 1772 and Joseph Eve in 1788, but their uses remained limited to the long-staple variety, up until Eli Whitney's development of a short-staple cotton gin in 1793.\nEli Whitney's patent.\nEli Whitney (1765\u20131825) applied for a patent of his cotton gin on October 28, 1793; the patent was granted on March 14, 1794, but was not validated until 1807. Whitney's patent was assigned patent number 72X. There is slight controversy over whether the idea of the modern cotton gin and its constituent elements are correctly attributed to Eli Whitney. The popular image of Whitney inventing the cotton gin is attributed to an article on the subject written in the early 1870s and later reprinted in 1910 in \"The Library of Southern Literature\". In this article, the author claimed Catharine Littlefield Greene suggested to Whitney the use of a brush-like component instrumental in separating out the seeds and cotton. Greene's alleged role in the invention of the gin has not been verified independently.\nWhitney's cotton gin model was capable of cleaning of lint per day. The model consisted of a wooden cylinder covered by rows of slender wires which caught the fibers of the cotton bolls. Each row of wires then passed through the bars of a comb-like grid, pulling the cotton fibers through the grid as they did. The comb-like teeth of the grids were closely spaced, preventing the seeds, fragments of the hard dried calyx of the original cotton flower, or sticks and other debris attached to the fibers from passing through. A series of brushes on a second rotating cylinder then brushed the now-cleaned fibers loose from the wires, preventing the mechanism from jamming.\nMany contemporary inventors attempted to develop a design that would process short staple cotton, and Hodgen Holmes, Robert Watkins, William Longstreet, and John Murray had all been issued patents for improvements to the cotton gin by 1796. However, the evidence indicates Whitney did invent the saw gin, for which he is famous. Although he spent many years in court attempting to enforce his patent against planters who made unauthorized copies, a change in patent law ultimately made his claim legally enforceable \u2013 too late for him to make much money from the device in the single year remaining before the patent expired.\nMcCarthy's gin.\nWhile Whitney's gin facilitated the cleaning of seeds from short-staple cotton, it damaged the fibers of extra-long staple cotton (\"Gossypium barbadense\"). In 1840 Fones McCarthy received a patent for a \"Smooth Cylinder Cotton-gin\", a roller gin. McCarthy's gin was marketed for use with both short-staple and extra-long staple cotton but was particularly useful for processing long-staple cotton. After McCarthy's patent expired in 1861, McCarthy type gins were manufactured in Britain and sold around the world. McCarthy's gin was adopted for cleaning the Sea Island variety of extra-long staple cotton grown in Florida, Georgia and South Carolina. It cleaned cotton several times faster than the older gins, and, when powered by one horse, produced 150 to 200 pounds of lint a day. The McCarthy gin used a reciprocating knife to detach seed from the lint. Vibration caused by the reciprocating motion limited the speed at which the gin could operate. In the middle of the 20th Century gins using a rotating blade replaced ones using a reciprocating blade. These descendants of the McCarthy gin are the only gins now used for extra-long staple cotton in the United States.\nMunger system gin.\nFor a decade and a half after the end of the Civil War in 1865, a number of innovative features became widely used for ginning in the United States. They included steam power instead of animal power, an automatic feeder to assure that the gin stand ran smoothly, a condenser to make the clean cotton coming out of the gin easier to handle, and indoor presses so that cotton no longer had to be carried across the gin yard to be baled. Then, in 1879, while he was running his father's gin in Rutersville, Texas, Robert S. Munger invented additional system ginning techniques. Robert and his wife, Mary Collett, later moved to Mexia, Texas, built a system gin, and obtained related patents.\nThe Munger System Ginning Outfit (or system gin) integrated all the ginning operation machinery, thus assuring the cotton would flow through the machines smoothly. Such system gins use air to move cotton from machine to machine. Munger's motivation for his inventions included improving employee working conditions in the gin. However, the selling point for most gin owners was the accompanying cost savings while producing cotton both more speedily and of higher quality.\nBy the 1960s, many other advances had been made in ginning machinery, but the manner in which cotton flowed through the gin machinery continued to be the Munger system.\nEconomic Historian William H. Phillips referred to the development of system ginning as \"The Munger Revolution\" in cotton ginning. He wrote,\n\"The Munger innovations were the culmination of what geographer Charles S. Aiken has termed the second ginning revolution, in which the privately owned plantation gins were replaced by large-scale public ginneries. This revolution, in turn, led to a major restructuring of the cotton gin industry, as the small, scattered gin factories and shops of the nineteenth century gave way to a dwindling number of large twentieth-century corporations designing and constructing entire ginning operations.\"\nOne of the few (and perhaps only) examples of a Munger gin left in existence is on display at Frogmore Plantation in Louisiana.\nEffects in the United States.\nPrior to the introduction of the mechanical cotton gin, cotton had required considerable labor to clean and separate the fibers from the seeds. With Eli Whitney's gin, cotton became a tremendously profitable business, creating many fortunes in the Antebellum South. Cities such as New Orleans, Louisiana; Mobile, Alabama; Charleston, South Carolina; and Galveston, Texas became major shipping ports, deriving substantial economic benefit from cotton raised throughout the South. Additionally, the greatly expanded supply of cotton created strong demand for textile machinery and improved machine designs that replaced wooden parts with metal. This led to the invention of many machine tools in the early 19th century.\nThe invention of the cotton gin caused massive growth in the production of cotton in the United States, concentrated mostly in the South. Cotton production expanded from 750,000 bales in 1830 to 2.85 million bales in 1850. As a result, the region became even more dependent on plantations that used black slave labor, with plantation agriculture becoming the largest sector of its economy. While it took a single laborer about ten hours to separate a single pound of fiber from the seeds, a team of two or three slaves using a cotton gin could produce around fifty pounds of cotton in just one day. The number of slaves rose in concert with the increase in cotton production, increasing from around 700,000 in 1790 to around 3.2 million in 1850. The invention of the cotton gin led to increased demands for slave labor in the American South, reversing the economic decline that had occurred in the region during the late 18th century. The cotton gin thus \"transformed cotton as a crop and the American South into the globe's first agricultural powerhouse\".\nThe invention of the cotton gin led to an increase in the use of slaves on Southern plantations. Because of that inadvertent effect on American slavery, which ensured that the South's economy developed in the direction of plantation-based agriculture (while encouraging the growth of the textile industry elsewhere, such as in the North), the invention of the cotton gin is frequently cited as one of the indirect causes of the American Civil War.\nModern cotton gins.\nIn modern cotton production, cotton arrives at industrial cotton gins either in trailers, in compressed rectangular \"modules\" weighing up to 10 metric tons each or in polyethylene wrapped round modules similar to a bale of hay produced during the picking process by the most recent generation of cotton pickers. Trailer cotton (i.e. cotton not compressed into modules) arriving at the gin is sucked in via a pipe, approximately in diameter, that is swung over the cotton. This pipe is usually manually operated but is increasingly automated in modern cotton plants. The need for trailers to haul the product to the gin has been drastically reduced since the introduction of modules. If the cotton is shipped in modules, the module feeder breaks the modules apart using spiked rollers and extracts the largest pieces of foreign material from the cotton. The module feeder's loose cotton is then sucked into the same starting point as the trailer cotton.\nThe cotton then enters a dryer, which removes excess moisture. The cylinder cleaner uses six or seven rotating, spiked cylinders to break up large clumps of cotton. Finer foreign material, such as soil and leaves, passes through rods or screens for removal. The stick machine uses centrifugal force to remove larger foreign matter, such as sticks and burrs, while the cotton is held by rapidly rotating saw cylinders.\nThe gin stand uses the teeth of rotating saws to pull the cotton through a series of \"ginning ribs\", which pull the fibers from the seeds which are too large to pass through the ribs. The cleaned seed is then removed from the gin via an auger conveyor system. The seed is reused for planting or is sent to an oil mill to be further processed into cottonseed oil and cottonseed meal. The lint cleaners again use saws and grid bars, this time to separate immature seeds and any remaining foreign matter from the fibers. The bale press then compresses the cotton into bales for storage and shipping. Modern gins can process up to of cotton per hour.\nModern cotton gins create a substantial amount of cotton gin residue (CGR) consisting of sticks, leaves, dirt, immature bolls, and cottonseed. Research is currently under way to investigate the use of this waste in producing ethanol. Due to fluctuations in the chemical composition in processing, there is difficulty in creating a consistent ethanol process, but there is potential to further maximize the utilization of waste in cotton production.\nReferences.\nNotes\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography"}
{"id": "47711", "revid": "41081054", "url": "https://en.wikipedia.org/wiki?curid=47711", "title": "FreeCell", "text": "Solitaire card game\nFreeCell is a solitaire card game played using the standard 52-card deck. It is fundamentally different from most solitaire games in that very few deals are unsolvable, and all cards are dealt face-up from the beginning of the game. It was originally created as a computer game by Paul Alfille. Microsoft has included an implementation of FreeCell in every release of the Windows operating system since 1995, which has greatly contributed to the game's popularity.\nRules.\nOne standard 52-card deck is used. There are four open cells and four open foundations. Cards are dealt face-up into eight cascades, four of which comprise seven cards each and four of which comprise six cards each. \nThe top card of each cascade begins a sequence. Tableaus must be built down by alternating colors. Foundations are built up by suit. The foundations begin with Ace and are built up to King.\nAny cell card or top card of any cascade may be moved to build on a tableau, or moved to an empty cell, an empty cascade, or its foundation.\nThe game is won after all cards are moved to their foundation piles. \nSupermoves.\nIn FreeCell, unlike many solitaire card games, only one card may be moved at a time. Complete or partial tableaus may be moved to build on existing tableaus, or moved to empty cascades, only by a sequence of moves which recursively place and remove cards through intermediate locations. \nFor example, with one empty cell, the top card of one tableau can be moved to a free cell. The second card from the top of that tableau can now be moved onto another tableau. Then the original top card can be moved from the cell on top of it.\nSuch a sequence of moves is called a \"supermove\". Computer implementations often show this motion, but players using physical decks typically just move the tableau at once. \nThe maximum number formula_1 of cards in a tableau that can be moved to another tableau equals the number of empty cells plus one, with that number doubling for each empty cascade: formula_2, where formula_3 is the number of empty cascades and formula_4 is the number of empty cells. The maximum number that can be moved to an empty cascade is formula_5.\nNumbered hands.\nAlthough software implementations vary, most versions label the hands with a number derived from the seed value used by the random number generator to shuffle the cards.\nMicrosoft FreeCell is so definitive for FreeCell players that many other software implementations include compatibility with its random number generator in order to replicate its numbered hands.\nHistory and variants.\nOne of the oldest ancestors of FreeCell is Eight Off. In the June 1968 edition of \"Scientific American\", Martin Gardner described in his \"Mathematical Games\" column a game by C. L. Baker which is similar to FreeCell, except that cards on the tableau are built by suit rather than by alternate colors. Gardner wrote, \"The game was taught to Baker by his father, who in turn learned it from an Englishman during the 1920s.\" This variant is now called Baker's Game. FreeCell's origins may date back even further to 1945 and to a Scandinavian game called Napoleon in St. Helena (not the solitaire game Napoleon at St Helena, also known as Forty Thieves).\nPaul Alfille changed Baker's Game by making cards build according to alternate colors, thus creating FreeCell. He implemented the first computerised version as a medical student at the University of Illinois, in the TUTOR programming language for the PLATO educational computer system in 1978. Alfille was able to display easily recognizable graphical images of playing cards on the 512 \u00d7 512 monochrome display on the PLATO systems.\nThis original FreeCell environment allowed games with 4\u201310 columns and 1\u201310 cells in addition to the standard 8 \u00d7 4 game. For each variant, the program stored a ranked list of the players with the longest winning streaks. There was also a tournament system that allowed people to compete to win difficult hand-picked deals. Paul Alfille described this early FreeCell environment in more detail in an interview from 2000.\nIn 2012, researchers used evolutionary computation methods to create winning FreeCell players.\nA variant where card sequence movement is not limited by available cells is known as Relaxed FreeCell.\nOther solitaire games related to or inspired by FreeCell include Seahaven Towers, Penguin, Stalactites, ForeCell, Antares (a cross with Scorpion).\nUnsolvable hands.\nIn 2018, Theodore Pringle and Shlomi Fish found that, of 8.6 billion FreeCell Pro deals, 102075 deals were impossible to solve, or approximately one impossible deal out of 84,000 random deals. It is estimated that around 99.999% of possible deals are solvable. Deal number 11982 from the Windows version of FreeCell is an example of an unsolvable FreeCell deal, the only deal among the original \"Microsoft 32,000\" which is unsolvable.\nSolver complexity.\nThe FreeCell game has a constant number of cards. This implies that in constant time, a person or computer could list all of the possible moves from a given start configuration and discover a winning set of moves or, assuming the game cannot be solved, the lack thereof. To perform an interesting complexity analysis, one must construct a generalized version of the FreeCell game with 4 \u00d7 \"n\" cards. This generalized version of the game is NP-complete; it is unlikely that any algorithm more efficient than a brute-force search exists which can find solutions for arbitrary generalized FreeCell configurations.\nThere are 52! (i.e., 52 factorial), or approximately 8\u00d71067, distinct deals. However, some games are effectively identical to others because suits assigned to cards are arbitrary or columns can be swapped. After taking these factors into account, there are approximately 1.75\u00d71064 distinct games.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47712", "revid": "3525933", "url": "https://en.wikipedia.org/wiki?curid=47712", "title": "Norfolk (disambiguation)", "text": "Norfolk is a county in England.\nNorfolk may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "47713", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=47713", "title": "Direct current", "text": "Unidirectional flow of electric charge\nDirect current (DC) is one-directional flow of electric charge. An electrochemical cell is a prime example of DC power. Direct current may flow through a conductor such as a wire, but can also flow through semiconductors, insulators, or even through a vacuum as in electron or ion beams. The electric current flows in a constant direction, distinguishing it from alternating current (AC). A term formerly used for this type of current was galvanic current.\nThe abbreviations \"AC\" and \"DC\" are often used to mean simply \"alternating\" and \"direct\", as when they modify \"current\" or \"voltage\".\nDirect current may be converted from an alternating current supply by use of a rectifier, which contains electronic elements (usually) or electromechanical elements (historically) that allow current to flow only in one direction. Direct current may be converted into alternating current via an inverter.\nDirect current has many uses, from the charging of batteries to large power supplies for electronic systems, motors, and more. Very large quantities of electrical energy provided via direct-current are used in smelting of aluminum and other electrochemical processes. It is also used for some railways, especially in urban areas. High-voltage direct current is used to transmit large amounts of power from remote generation sites or to interconnect alternating current power grids.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nHistory.\nDirect current was produced in 1800 by Italian physicist Alessandro Volta's battery, his Voltaic pile. The nature of how current flowed was not yet understood. French physicist Andr\u00e9-Marie Amp\u00e8re conjectured that current travelled in one direction from positive to negative. When French instrument maker Hippolyte Pixii built the first dynamo electric generator in 1832, he found that as the magnet used passed the loops of wire each half turn, it caused the flow of electricity to reverse, generating an alternating current. At Amp\u00e8re's suggestion, Pixii later added a commutator, a type of \"switch\" where contacts on the shaft work with \"brush\" contacts to produce direct current.\nThe late 1870s and early 1880s saw electricity starting to be generated at power stations. These were initially set up to power arc lighting (a popular type of street lighting) running on very high voltage (usually higher than 3,000 volts) direct current or alternating current. This was followed by the widespread use of low voltage direct current for indoor electric lighting in business and homes after inventor Thomas Edison launched his incandescent bulb based electric \"utility\" in 1882. Because of the significant advantages of alternating current over direct current in using transformers to raise and lower voltages to allow much longer transmission distances, direct current was replaced over the next few decades by alternating current in power delivery. In the mid-1950s, high-voltage direct current transmission was developed, and is now an option instead of long-distance high voltage alternating current systems. For long distance undersea cables (e.g. between countries, such as NorNed), this DC option is the only technically feasible option. For applications requiring direct current, such as third rail power systems, alternating current is distributed to a substation, which utilizes a rectifier to convert the power to direct current.\nVarious definitions.\nThe term \"DC\" is used to refer to power systems that use only one electrical polarity of voltage or current, and to refer to the constant, zero-frequency, or slowly varying local mean value of a voltage or current. For example, the voltage across a DC voltage source is constant as is the current through a direct current source. The DC solution of an electric circuit is the solution where all voltages and currents are constant. Any stationary voltage or current waveform can be decomposed into a sum of a DC component and a zero-mean time-varying AC component; the DC component is defined to be the expected value, or the average value of the voltage or current over all time.\nAlthough DC stands for \"direct current\", DC often refers to \"constant polarity\". Under this definition, DC voltages can vary in time, as seen in the raw output of a rectifier or the fluctuating voice signal on a telephone line.\nSome forms of DC (such as that produced by a voltage regulator) have almost no variations in voltage, but may still have variations in output power and current.\nCircuits.\nA direct current circuit is an electrical circuit that consists of any combination of constant voltage sources, constant current sources, and resistors. In this case, the circuit voltages and currents are independent of time. A particular circuit voltage or current does not depend on the past value of any circuit voltage or current. This implies that the system of equations that represent a DC circuit do not involve integrals or derivatives with respect to time.\nIf a capacitor or inductor is added to a DC circuit, the resulting circuit is not, strictly speaking, a DC circuit. However, most such circuits have a DC solution. This solution gives the circuit voltages and currents when the circuit is in DC steady state. Such a circuit is represented by a system of differential equations. The solution to these equations usually contain a time varying or transient part as well as constant or steady state part. It is this steady state part that is the DC solution. There are some circuits that do not have a DC solution. Two simple examples are a constant current source connected to a capacitor and a constant voltage source connected to an inductor.\nIn electronics, it is common to refer to a circuit that is powered by a DC voltage source such as a battery or the output of a DC power supply as a DC circuit even though what is meant is that the circuit is DC powered.\nIn a DC circuit, a power source (e.g. a battery, capacitor, etc.) has a positive and negative terminal, and likewise, the load also has a positive and negative terminal. To complete the circuit, positive charges need to flow from the power source to the load. The charges will then return to the negative terminal of the load, which will then flow back to the negative terminal of the battery, completing the circuit. If either the positive or negative terminal is disconnected, the circuit will not be complete and the charges will not flow.\nIn some DC circuit applications, polarity does not matter, which means you can connect positive and negative backwards and the circuit will still be complete and the load will still function normally. However, in most DC applications, polarity does matter, and connecting the circuit backwards will result in the load not working properly.\nApplications.\nDomestic and commercial buildings.\nDC is commonly found in many extra-low voltage applications and some low-voltage applications, especially where these are powered by batteries or solar power systems (since both can produce only DC).\nMost electronic circuits or devices require a DC power supply.\nDomestic DC installations usually have different types of sockets, connectors, switches, and fixtures from those suitable for alternating current. This is mostly due to the lower voltages used, resulting in higher currents to produce the same amount of power.\nIt is usually important with a DC appliance to observe polarity, unless the device has a diode bridge to correct for this.\nAutomotive.\nMost automotive applications use DC. An automotive battery provides power for engine starting, lighting, the ignition system, the climate controls, and the infotainment system among others. The alternator is an AC device which uses a rectifier to produce DC for battery charging. Most highway passenger vehicles use nominally 12\u00a0V systems. Many heavy trucks, farm equipment, or earth moving equipment with Diesel engines use 24 volt systems. In some older vehicles, 6\u00a0V was used, such as in the original classic Volkswagen Beetle. At one point a 42\u00a0V electrical system was considered for automobiles, but this found little use. To save weight and wire, often the metal frame of the vehicle is connected to one pole of the battery and used as the return conductor in a circuit. Often the negative pole is the chassis \"ground\" connection, but positive ground may be used in some wheeled or marine vehicles.\nIn a battery electric vehicle, there are usually two separate DC systems. The \"low voltage\" DC system typically operates at 12V, and serves the same purpose as in an internal combustion engine vehicle. The \"high voltage\" system operates at 300-400V (depending on the vehicle), and provides the power for the traction motors. Increasing the voltage for the traction motors reduces the current flowing through them, increasing efficiency.\nTelecommunication.\nTelephone exchange communication equipment uses standard \u221248\u00a0V DC power supply. The negative polarity is achieved by grounding the positive terminal of power supply system and the battery bank. This is done to prevent electrolysis depositions. Telephone installations have a battery system to ensure power is maintained for subscriber lines during power interruptions.\nOther devices may be powered from the telecommunications DC system using a DC-DC converter to provide any convenient voltage.\nMany telephones connect to a twisted pair of wires, and use a bias tee to internally separate the AC component of the voltage between the two wires (the audio signal) from the DC component of the voltage between the two wires (used to power the phone).\nHigh-voltage power transmission.\nHigh-voltage direct current (HVDC) electric power transmission systems use DC for the bulk transmission of electrical power, in contrast with the more common alternating current systems. For long-distance transmission, HVDC systems may be less expensive and suffer lower electrical losses.\nOther.\nApplications using fuel cells (mixing hydrogen and oxygen together with a catalyst to produce electricity and water as byproducts) also produce only DC.\nLight aircraft electrical systems are typically 12\u00a0V or 24\u00a0V DC similar to automobiles.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47714", "revid": "46051904", "url": "https://en.wikipedia.org/wiki?curid=47714", "title": "Domain", "text": "A domain is a geographic area controlled by a single person or organization. Domain may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "47715", "revid": "46628330", "url": "https://en.wikipedia.org/wiki?curid=47715", "title": "Station", "text": "Station may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "47716", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=47716", "title": "High-voltage direct current", "text": "Electric power transmission system\nA high-voltage direct current (HVDC) electric power transmission system uses direct current (DC) for electric power transmission, in contrast with the more common alternating current (AC) transmission systems. Most HVDC links use voltages between 100\u00a0kV and 800\u00a0kV.\nHVDC lines are commonly used for long-distance power transmission, since they require fewer conductors and incur less power loss than equivalent AC lines. HVDC also allows power transmission between AC transmission systems that are not synchronized. Since the power flow through an HVDC link can be controlled independently of the phase angle between source and load, it can stabilize a network against disturbances due to rapid changes in power. HVDC also allows the transfer of power between grid systems running at different frequencies, such as 50 and 60\u00a0Hz. This improves the stability and economy of each grid, by allowing the exchange of power between previously incompatible networks.\nThe modern form of HVDC transmission uses technology developed extensively in the 1930s in Sweden (ASEA) and in Germany. Early commercial installations included one in the Soviet Union in 1951 between Moscow and Kashira, and a 100\u00a0kV, 20\u00a0MW system between Gotland and mainland Sweden in 1954. The longest HVDC link in the world is the Zhundong\u2013South Anhui link in China a \u00b11,100\u00a0kV, ultra HVDC line with a length of more than .\nHigh voltage transmission.\nHigh voltage is used for electric power transmission to reduce the energy lost in the resistance of the wires. For a given quantity of power transmitted, doubling the voltage will deliver the same power at only half the current:\nformula_1\nSince the energy lost as heat in the wires is directly proportional to the square of the current formula_2 using half the current at double the voltage reduces the line losses by a factor of 4. While energy lost in transmission can also be reduced by decreasing the resistance by increasing the conductor size, larger conductors are heavier and more expensive.\nHigh voltage cannot readily be used for lighting or motors, so transmission-level voltages must be reduced for end-use equipment. Transformers are used to change the voltage levels in alternating current (AC) transmission circuits, but cannot pass DC current. Transformers made AC voltage changes practical, and AC generators were more efficient than those using DC. These advantages led to early low-voltage DC transmission systems being supplanted by AC systems around the turn of the 20th century.\nPractical conversion of current between AC and DC became possible with the development of power electronics devices such as mercury-arc valves and, starting in the 1970s, power semiconductor devices including thyristors, integrated gate-commutated thyristors (IGCTs), MOS-controlled thyristors (MCTs) and insulated-gate bipolar transistors (IGBT).\nHistory.\nElectromechanical systems.\nThe first long-distance transmission of electric power was demonstrated using direct current in 1882 in the 57 km Miesbach-Munich Power Transmission, but only 1.5\u00a0kW was transmitted. An early method of HVDC transmission was developed by the Swiss engineer Ren\u00e9 Thury and his method, the Thury system, was put into practice by 1889 in Italy by the Acquedotto De Ferrari-Galliera company. This system used series-connected motor-generator sets to increase the voltage. Each set was insulated from electrical ground and driven by insulated shafts from a prime mover. The transmission line was operated in a constant-current mode, with up to 5,000 volts across each machine, some machines having double commutators to reduce the voltage on each commutator. This system transmitted 630\u00a0kW at 14\u00a0kV DC over a distance of . The Moutiers\u2013Lyon system transmitted 8,600\u00a0kW of hydroelectric power a distance of , including of underground cable. This system used eight series-connected generators with dual commutators for a total voltage of 150\u00a0kV between the positive and negative poles, and operated from c.1906 until 1936. Fifteen Thury systems were in operation by 1913. Other Thury systems operating at up to 100\u00a0kV DC worked into the 1930s, but the rotating machinery required high maintenance and had high energy loss.\nVarious other electromechanical devices were tested during the first half of the 20th century with little commercial success. One technique attempted for conversion of direct current from a high transmission voltage to lower utilization voltage was to charge series-connected batteries, then reconnect the batteries in parallel to serve distribution loads. While at least two commercial installations were tried around the turn of the 20th century, the technique was not generally useful owing to the limited capacity of batteries, difficulties in switching between series and parallel configurations, and the inherent energy inefficiency of a battery charge/discharge cycle.\nMercury arc valves.\nFirst proposed in 1914, the grid controlled mercury-arc valve became available during the period 1920 to 1940 for the rectifier and inverter functions associated with DC transmission. Starting in 1932, General Electric tested mercury-vapor valves and a 12\u00a0kV DC transmission line, which also served to convert 40\u00a0Hz generation to serve 60\u00a0Hz loads, at Mechanicville, New York. In 1941, a 60\u00a0MW, \u00b1200\u00a0kV, buried cable link, known as the Elbe-Project, was designed for the city of Berlin using mercury arc valves but, owing to the collapse of the German government in 1945, the project was never completed. The nominal justification for the project was that, during wartime, a buried cable would be less conspicuous as a bombing target. The equipment was moved to the Soviet Union and was put into service there as the Moscow\u2013Kashira HVDC system. The Moscow\u2013Kashira system and the 1954 connection by Uno Lamm's group at ASEA between the mainland of Sweden and the island of Gotland marked the beginning of the modern era of HVDC transmission.\nMercury arc valves were common in systems designed up to 1972, the last mercury arc HVDC system (the Nelson River Bipole 1 system in Manitoba, Canada) having been put into service in stages between 1972 and 1977. Since then, all mercury arc systems have been either shut down or converted to use solid-state devices. The last HVDC system to use mercury arc valves was the Inter-Island HVDC link between the North and South Islands of New Zealand, which used them on one of its two poles. The mercury arc valves were decommissioned on 1 August 2012, ahead of the commissioning of replacement thyristor converters.\nThyristor valves.\nThe development of thyristor valves for HVDC began in the late 1960s. The first complete HVDC scheme based on thyristor was the Eel River scheme in Canada, which was built by General Electric and went into service in 1972.\nSince 1977, new HVDC systems have used solid-state devices, in most cases thyristors. Like mercury arc valves, thyristors require connection to an external AC circuit in HVDC applications to turn them on and off. HVDC using thyristors is also known as \"line-commutated converter\" (LCC) HVDC.\nOn March 15, 1979, a 1920\u00a0MW thyristor based direct current connection between Cabora Bassa and Johannesburg () was energized. The conversion equipment was built in 1974 by Allgemeine Elektricit\u00e4ts-Gesellschaft AG (AEG), and Brown, Boveri &amp; Cie (BBC) and Siemens were partners in the project. Service interruptions of several years were a result of a civil war in Mozambique. The transmission voltage of \u00b1533\u00a0kV was the highest in the world at the time.\nCapacitor-commutated converters.\nLine-commutated converters have some limitations in their use for HVDC systems. This results from requiring a period of \"reverse\" voltage to affect the turn off. An attempt to address these limitations is the capacitor-commutated converter (CCC). The CCC has series capacitors inserted into the AC line connections. CCC has remained only a niche application because of the advent of voltage-source converters (VSCs) which more directly address turn-off issues.\nVoltage-source converters.\nWidely used in motor drives since the 1980s, voltage-source converters (VSCs) started to appear in HVDC in 1997 with the experimental Hellsj\u00f6n\u2013Gr\u00e4ngesberg project in Sweden. By the end of 2011, this technology had captured a significant proportion of the HVDC market.\nThe development of higher rated insulated-gate bipolar transistors (IGBTs), gate turn-off thyristors (GTOs), and integrated gate-commutated thyristors (IGCTs), has made HVDC systems more economical and reliable. This is because modern IGBTs incorporate a short-circuit failure mode, wherein should an IGBT fail, it is mechanically shorted. Therefore, modern VSC HVDC converter stations are designed with sufficient redundancy to guarantee operation over their entire service lives. The manufacturer Hitachi Energy (formerly Hitachi ABB Power Grids) calls this concept \"HVDC Light\", while Siemens calls a similar concept \"HVDC PLUS\" (\"Power Link Universal System\") and Alstom call their product based upon this technology \"HVDC MaxSine\". They have extended the use of HVDC down to blocks as small as a few tens of megawatts and overhead lines as short as a few dozen kilometers. There are several different variants of VSC technology: most installations built until 2012 use pulse-width modulation in a circuit that is effectively an ultra-high-voltage motor drive. More recent installations, including HVDC PLUS and HVDC MaxSine, are based on variants of a converter called a \"modular multilevel converter\" (MMC).\nMultilevel converters have the advantage that they allow harmonic filtering equipment to be reduced or eliminated altogether. By way of comparison, AC harmonic filters of typical line-commutated converter stations cover nearly half of the converter station area.\nWith time, voltage-source converter systems will probably replace all installed simple thyristor-based systems, including the highest DC power transmission applications.\nComparison with AC.\nAdvantages.\nA long-distance, point-to-point HVDC transmission scheme generally has lower overall investment cost and lower losses than an equivalent AC transmission scheme. Although HVDC conversion equipment at the terminal stations is costly, the total DC transmission-line costs over long distances are lower than for an AC line of the same distance. HVDC requires less conductor per unit distance than an AC line, as there is no need to support three phases and there is no skin effect. AC systems use a higher peak voltage for the same power, increasing insulator costs.\nDepending on voltage level and construction details, HVDC transmission losses are quoted at 3.5% per , about 50% less than AC (6.7%) lines at the same voltage. This is because direct current transfers only active power and thus causes lower losses than alternating current, which transfers both active and reactive power. In other words, transmitting electric AC power over long distances inevitably results in a phase shift between voltage and current. Because of this phase shift the effective Power=Current*Voltage, where * designates a vector product, decreases. Since DC power has no phase, the phase shift cannot occur in the DC case.\nHVDC transmission may also be selected for other technical benefits. HVDC can transfer power between separate AC networks. HVDC power flow between separate AC systems can be automatically controlled to support either network during transient conditions, but without the risk that a major power-system collapse in one network will lead to a collapse in the second. The controllability feature is also useful where control of energy trading is needed.\nSpecific applications where HVDC transmission technology provides benefits include:\nCable systems.\nLong undersea or underground high-voltage cables have a high electrical capacitance compared with overhead transmission lines since the live conductors within the cable are surrounded by a relatively thin layer of insulation (the dielectric), and a metal sheath. The geometry is that of a long coaxial capacitor. The total capacitance increases with the length of the cable. This capacitance is in a parallel circuit with the load. Where alternating current is used for cable transmission, additional current must flow in the cable to charge this cable capacitance. Another way to look at this is to realize, that such capacitance causes a phase shift between voltage and current, and thus decrease of the transmitted power, which is a vector product of voltage and current. Additional energy losses also occur as a result of dielectric losses in the cable insulation. For a sufficiently long AC cable, the entire current-carrying ability of the conductor would be needed to supply the charging current alone. This cable capacitance issue limits the length and power-carrying ability of AC power cables.\nHowever, if direct current is used, the cable capacitance is charged only when the cable is first energized or if the voltage level changes; there is no additional current required. DC powered cables are limited only by their temperature rise and Ohm's law. Although some leakage current flows \"through\" the dielectric insulator, this effect is also present in AC systems and is small compared to the cable's rated current.\nOverhead line systems.\nThe capacitive effect of long underground or undersea cables in AC transmission applications also applies to AC overhead lines, although to a much lesser extent. Nevertheless, for a long AC overhead transmission line, the current flowing just to charge the line capacitance can be significant, and this reduces the capability of the line to carry useful current to the load at the remote end. Another factor that reduces the useful current-carrying ability of AC lines is the skin effect, which causes a nonuniform distribution of current over the cross-sectional area of the conductor. Transmission line conductors operating with direct current suffer from neither constraint. Therefore, for the same conductor losses (or heating effect), a given conductor can carry more power to the load when operating with HVDC than AC.\nFinally, depending upon the environmental conditions and the performance of overhead line insulation operating with HVDC, it may be possible for a given transmission line to operate with a constant HVDC voltage that is approximately the same as the peak AC voltage for which it is designed and insulated. The power delivered in an AC system is defined by the root mean square (RMS) of an AC voltage, but RMS is only about 71% of the peak voltage. Therefore, if the HVDC line can operate continuously with an HVDC voltage that is the same as the peak voltage of the AC equivalent line, then for a given current (where HVDC current is the same as the RMS current in the AC line), the power transmission capability when operating with HVDC is approximately 40% higher than the capability when operating with AC.\nAsynchronous connections.\nBecause HVDC allows power transmission between unsynchronized AC distribution systems, it can help increase system stability, by preventing cascading failures from propagating from one part of a wider power transmission grid to another. Changes in load that would cause portions of an AC network to become unsynchronized and to separate, would not similarly affect a DC link, and the power flow through the DC link would tend to stabilize the AC network. The magnitude and direction of power flow through a DC link can be directly controlled and changed as needed to support the AC networks at either end of the DC link.\nDisadvantages.\nThe disadvantages of HVDC are in conversion, switching, control, availability, and maintenance.\nHVDC is less reliable and has lower availability than alternating current (AC) systems, mainly due to the extra conversion equipment. Single-pole systems have availability of about 98.5%, with about a third of the downtime unscheduled due to faults. Fault-tolerant bipole systems provide high availability for 50% of the link capacity, but availability of the full capacity is about 97% to 98%.\nThe required converter stations are expensive and have limited overload capacity. At smaller transmission distances, the losses in the converter stations may be bigger than in an AC transmission line for the same distance. The cost of the converters may not be offset by reductions in line construction cost and power line loss.\nOperating an HVDC scheme requires many spare parts to be kept, often exclusively for one system, as HVDC systems are less standardized than AC systems and technology changes more quickly.\nIn contrast to AC systems, realizing multi-terminal systems is complex (especially with line commutated converters), as is expanding existing schemes to multi-terminal systems. Controlling power flow in a multi-terminal DC system requires good communication between all the terminals; power flow must be actively regulated by the converter control system instead of relying on the inherent impedance and phase angle properties of an AC transmission line. Multi-terminal systems are therefore rare. As of 2012[ [update]] only two are in service: the Quebec \u2013 New England Transmission between Radisson, Nicolet and Sandy Pond and the Sardinia\u2013mainland Italy link which was modified in 1989 to also provide power to the island of Corsica.\nHigh-voltage DC circuit breaker.\nHVDC circuit breakers are difficult to build because of arcing: under AC, the voltage inverts and in doing so crosses zero volts dozens of times a second. An AC arc will self-extinguish at one of these zero-crossing points because there cannot be an arc where there is no potential difference. DC will never cross zero volts and never self-extinguish, so arc distance and duration is far greater with DC than the same voltage AC. This means some mechanism must be included in the circuit breaker to force current to zero and extinguish the arc, otherwise arcing and contact wear would be too great to allow reliable switching.\nIn November 2012, ABB announced the first ultrafast HVDC circuit breaker. Mechanical circuit breakers are too slow for use in HVDC grids, although they have been used for years in other applications. Conversely, semiconductor breakers are fast enough but have a high resistance when conducting, wasting energy and generating heat in normal operation. The ABB breaker combines semiconductor and mechanical breakers to produce a \"hybrid breaker\" with both a fast break time and a low resistance in normal operation.\nCosts.\nWhile HVDC construction costs vary widely depending on the specifics of the project, some practitioners have provided some information:\nAn April 2010 announcement for a 2,000\u00a0MW, line between Spain and France is estimated at \u20ac700\u00a0million. This includes the cost of a tunnel through the Pyrenees.\nConversion process.\nConverter.\nAt the heart of an HVDC converter station, the equipment that performs the conversion between AC and DC is referred to as the \"converter\". Almost all HVDC converters are inherently capable of converting from AC to DC (\"rectification\") and from DC to AC (\"inversion\"), although in many HVDC systems, the system as a whole is optimized for power flow in only one direction. Irrespective of how the converter itself is designed, the station that is operating (at a given time) with power flow from AC to DC is referred to as the \"rectifier\" and the station that is operating with power flow from DC to AC is referred to as the \"inverter\".\nEarly HVDC systems used electromechanical conversion (the Thury system) but all HVDC systems built since the 1940s have used electronic converters. Electronic converters for HVDC are divided into two main categories:\nLine-commutated converters.\nMost of the HVDC systems in operation today are based on line-commutated converters (LCCs).\nThe basic LCC configuration uses a three-phase bridge rectifier known as a \"six-pulse bridge\", containing six electronic switches, each connecting one of the three phases to one of the two DC rails. A complete switching element is usually referred to as a \"valve\", irrespective of its construction. However, with a phase change only every 60\u00b0, considerable harmonic distortion is produced at both the DC and AC terminals when this arrangement is used.\nAn enhancement of this arrangement uses 12 valves in a \"twelve-pulse bridge\". The AC is split into two separate three-phase supplies before transformation. One of the sets of supplies is then configured to have a star (wye) secondary, and the other a delta secondary, establishing a 30\u00b0 phase difference between the two sets of three phases. With twelve valves connecting each of the two sets of three phases to the two DC rails, there is a phase change every 30\u00b0, and harmonics are considerably reduced. For this reason, the twelve-pulse system has become standard on most line-commutated converter HVDC systems built since the 1970s.\nWith line commutated converters, the converter has only one degree of freedom\u00a0\u2013 the \"firing angle\", which represents the time delay between the voltage across a valve becoming positive (at which point the valve would start to conduct if it were made from diodes) and the thyristors being turned on. The DC output voltage of the converter steadily becomes less positive as the firing angle is increased: firing angles of up to 90\u00b0 correspond to rectification and result in positive DC voltages, while firing angles above 90\u00b0 correspond to inversion and result in negative DC voltages. The practical upper limit for the firing angle is about 150\u2013160\u00b0 because above this, the valve would have insufficient turnoff time.\nEarly LCC systems used mercury-arc valves, which were rugged but required high maintenance. Because of this, many mercury-arc HVDC systems were built with bypass switchgear across each six-pulse bridge so that the HVDC scheme could be operated in six-pulse mode for short maintenance periods. The last mercury arc system, at the HVDC Inter-Island link, was decommissioned on 1 August 2012.\nThe thyristor valve was first used in HVDC systems in 1972. The thyristor is a solid-state semiconductor device similar to the diode, but with an extra control terminal that is used to switch the device on at a particular instant during the AC cycle. Because the voltages in HVDC systems, up to 800\u00a0kV in some cases, far exceed the breakdown voltages of the thyristors used, HVDC thyristor valves are built using large numbers of thyristors in series. Additional passive components such as grading capacitors and resistors need to be connected in parallel with each thyristor in order to ensure that the voltage across the valve is evenly shared between the thyristors. The thyristor plus its grading circuits and other auxiliary equipment is known as a \"thyristor level\".\nEach thyristor valve will typically contain tens or hundreds of thyristor levels, each operating at a different (high) potential with respect to earth. The command information to turn on the thyristors therefore cannot simply be sent using a wire connection\u00a0\u2013 it needs to be isolated. The isolation method can be magnetic but is usually optical. Two optical methods are used: indirect and direct optical triggering. In the indirect optical triggering method, low-voltage control electronics send light pulses along optical fibers to the \"high-side\" control electronics, which derives its power from the voltage across each thyristor. The alternative direct optical triggering method dispenses with most of the high-side electronics, instead using light pulses from the control electronics to switch light-triggered thyristors (LTTs).\nIn a line-commutated converter, the DC current (usually) cannot change direction; it flows through a large inductance and can be considered almost constant. On the AC side, the converter behaves approximately as a current source, injecting both grid-frequency and harmonic currents into the AC network. For this reason, a line commutated converter for HVDC is also considered as a \"current-source inverter\".\nVoltage-sourced converters.\nBecause thyristors can only be turned on (not off) by control action, the control system has only one degree of freedom \u2013 when to turn on the thyristor. This is an important limitation in some circumstances.\nWith some other types of semiconductor devices such as the insulated-gate bipolar transistor (IGBT), both turn-on and turn-off can be controlled, giving a second degree of freedom. As a result, they can be used to make \"self-commutated converters\". In such converters, the electric polarity of DC voltage is usually fixed and the DC voltage, being smoothed by a large capacitance, can be considered constant. For this reason, an HVDC converter using IGBTs is usually referred to as a \"voltage-sourced converter\". The additional controllability gives many advantages, notably the ability to switch the IGBTs on and off many times per cycle in order to improve the harmonic performance. Being self-commutated, the converter no longer relies on synchronous machines in the AC system for its operation. A voltage-sourced converter can therefore feed power to an AC network consisting only of passive loads, something which is impossible with LCC HVDC.\nHVDC systems based on voltage-sourced converters normally use the six-pulse connection because the converter produces much less harmonic distortion than a comparable LCC and the twelve-pulse connection is unnecessary.\nMost of the VSC HVDC systems built until 2012 were based on the \"two-level converter\", which can be thought of as a six-pulse bridge in which the thyristors have been replaced by IGBTs with inverse-parallel diodes and the DC smoothing reactors have been replaced by DC smoothing capacitors. Such converters derive their name from the discrete, two voltage levels at the AC output of each phase that correspond to the electrical potentials of the positive and negative DC terminals. Pulse-width modulation (PWM) is usually used to improve the harmonic distortion of the converter.\nSome HVDC systems have been built with \"three-level converters\", but today most new VSC HVDC systems are being built with some form of \"multilevel converter\", most commonly the \"modular multilevel converter\" (MMC), in which each valve consists of a number of independent converter submodules, each containing its own storage capacitor. The IGBTs in each submodule either bypass the capacitor or connect it into the circuit, allowing the valve to synthesize a stepped voltage with very low levels of harmonic distortion.\nConverter transformers.\nAt the AC side of each converter, transformers\u2014often a bank of three single-phase transformers\u2014isolate the station from the AC supply to provide a local earth and to achieve the correct DC voltage.\nConverter transformers for LCC HVDC schemes are quite specialized because of the high levels of harmonic currents that flow through them, and because the secondary winding insulation experiences a permanent DC voltage, which affects the design of the insulating structure inside the tank. In LCC systems, the transformers also need to provide the 30\u00b0 phase shift required for harmonic cancellation.\nConverter transformers for VSC HVDC systems are usually simpler and more conventional in design than those for LCC HVDC systems.\nReactive power.\nA major drawback of HVDC systems using line-commutated converters is that the converters inherently consume reactive power. The AC current flowing into the converter from the AC system lags behind the AC voltage so that, irrespective of the direction of active power flow, the converter always absorbs reactive power, behaving in the same way as a shunt reactor. The reactive power absorbed is at least 0.5 Mvar/MW under ideal conditions and can be higher than this when the converter is operating at higher than usual firing or extinction angle, or reduced DC voltage.\nAlthough at HVDC converter stations connected directly to power stations some of the reactive power may be provided by the generators themselves, in most cases the reactive power consumed by the converter must be provided by banks of shunt capacitors connected at the AC terminals of the converter. The shunt capacitors are usually connected directly to the grid voltage but in some cases may be connected to a lower voltage via a tertiary winding on the converter transformer. Since the reactive power consumed depends on the active power being transmitted, the shunt capacitors usually need to be subdivided into a number of switchable banks (typically four per converter) in order to prevent a surplus of reactive power being generated at low transmitted power. The shunt capacitors are almost always provided with tuning reactors and, where necessary, damping resistors so that they can perform a dual role as harmonic filters.\nVSCs, on the other hand, can either produce or consume reactive power on demand, with the result that usually no separate shunt capacitors are needed (other than those required purely for filtering).\nHarmonics and filtering.\nAll electronic power converters generate some degree of harmonic distortion on the AC and DC systems to which they are connected, and HVDC converters are no exception.\nWith the recently developed MMCs, levels of harmonic distortion may be practically negligible, but with line-commutated converters and simpler types of VSCs, considerable harmonic distortion may be produced on both the AC and DC sides of the converter. As a result, harmonic filters are nearly always required at the AC terminals of such converters, and in HVDC transmission schemes using overhead lines, may also be required on the DC side.\nFilters for line-commutated converters.\nThe basic building block of a line-commutated HVDC converter is the \"six-pulse bridge\". This arrangement produces very high levels of harmonic distortion. It is very costly to provide harmonic filters capable of suppressing such harmonics, so a variant known as the \"twelve-pulse bridge\", consisting of two six-pulse bridges in series with a 30\u00b0 phase shift between them, is nearly always used. The task of suppressing harmonics from this arrangement is still challenging, but manageable.\nLine-commutated converters for HVDC are usually include combinations of harmonic filters designed to deal with the 11th and 13th harmonics on the AC side, and 12th harmonic on the DC side. Sometimes, high-pass filters are included to deal with 23rd, 25th, 35th, 37th... on the AC side and 24th, 36th... on the DC side. Sometimes, the AC filters provide damping at lower-order, \"noncharacteristic\" harmonics such as 3rd or 5th harmonics.\nThe task of designing AC harmonic filters for HVDC converter stations is complex and computationally intensive, since in addition to ensuring that the converter does not produce an unacceptable level of voltage distortion on the AC system, it must be ensured that the harmonic filters do not resonate with some component elsewhere in the AC system. Detailed knowledge of the \"harmonic impedance\" of the AC system, at a wide range of frequencies, is needed in order to design the AC filters.\nDC filters are required only for HVDC transmission systems involving overhead lines. Voltage distortion is not a problem in its own right, since consumers do not connect directly to the DC terminals of the system, so the main design criterion for the DC filters is to ensure that the harmonic currents flowing in the DC lines do not induce interference in nearby open-wire telephone lines. With the rise in digital mobile telecommunications systems, which are much less susceptible to this type of interference, and fiber optic communication which is immune, DC filters are becoming less important for HVDC systems.\nFilters for voltage-sourced converters.\nSome types of voltage-sourced converters may produce such low levels of harmonic distortion that no filters are required. However, converter types such as the \"two-level\" converter, used with pulse-width modulation (PWM), still require some filtering, albeit less than on line-commutated converter systems.\nIn two-level converters, the harmonic spectrum is shifted to higher frequencies compared to line-commutated converters. The dominant harmonic frequencies are sidebands of the PWM frequency and multiples thereof. In HVDC applications, the PWM frequency is typically around 1 to 2\u00a0kHz. The higher frequencies allow the filter equipment to be smaller.\nConfigurations.\nMonopole.\nIn a monopole configuration, one of the terminals of the rectifier is connected to earth ground using an electrode. The other terminal, at high voltage relative to ground, is connected to a transmission line. With no metallic return conductor installed, return current flows in the earth (or water) between two stations. This arrangement is a type of single-wire earth return system.\nThe electrodes are usually located some tens of kilometers from the stations and are connected to the stations via a medium-voltage electrode line. The design of the electrodes themselves depends on whether they are located on land, on the shore or at sea. For the monopolar configuration with earth return, the earth current flow is unidirectional, which means that the design of one of the electrodes (the cathode) can be relatively simple, although the design of anode electrode is quite complex due to corrosion issues associated with electrochemistry.\nFor long-distance transmission, earth return can be considerably cheaper than alternatives using a dedicated neutral conductor, but it can lead to problems such as:\nThese effects can be eliminated with the installation of a metallic return conductor between the two ends of the monopolar transmission line. Since one terminal of the converters is connected to earth, the return conductor need not be insulated for the full transmission voltage, which makes it less costly than the high-voltage conductor. The decision of whether or not to use a metallic return conductor is based upon economic, technical and environmental factors.\nModern monopolar systems for pure overhead lines typically carry 2\u00a0GW. If underground or underwater cables are used, the typical value is 1\u00a0GW.\nMost monopolar systems are designed for future bipolar expansion. Transmission line towers may be designed to carry two conductors, even if only one is used initially for the monopole transmission system. The second conductor is either unused, used as electrode line or connected in parallel with the other (as in case of Baltic Cable).\nSymmetrical monopole.\nAn alternative is to use two high-voltage conductors, operating at about half of the DC voltage, with only a single converter at each end. In this arrangement, known as the \"symmetrical monopole\", the converters are earthed only via a high impedance and there is no earth current. The symmetrical monopole arrangement is uncommon with line-commutated converters (the NorNed interconnector being a rare example) but is very common with voltage-sourced converters when cables are used.\nBipolar.\nIn bipolar transmission, a pair of conductors is used, each at a high potential with respect to ground, in opposite polarity. Since these conductors must be insulated for the full voltage, transmission line cost is higher than a monopole with a return conductor. However, there are a number of advantages to bipolar transmission which can make it an attractive option:\nA bipolar system may also be installed with a metallic earth return conductor.\nBipolar systems may carry as much as 4\u00a0GW at voltages of \u00b1660\u00a0kV with a single converter per pole, as on the Ningdong\u2013Shandong project in China. With a power rating of 2,000\u00a0MW per twelve-pulse converter, the converters for that project were (as of 2010) the most powerful HVDC converters ever built. Even higher powers can be achieved by connecting two or more twelve-pulse converters in series in each pole, as is used in the \u00b1800\u00a0kV Xiangjiaba\u2013Shanghai project in China, which uses two twelve-pulse converter bridges in each pole, each rated at 400\u00a0kV DC and 1,600\u00a0MW.\nSubmarine cable installations initially commissioned as a monopole may be upgraded with additional cables and operated as a bipole.\nA bipolar scheme can be implemented so that the polarity of one or both poles can be changed. This allows the operation as two parallel monopoles. If one conductor fails, transmission can still continue at reduced capacity. Losses may increase if ground electrodes and lines are not designed for the extra current in this mode. To reduce losses in this case, intermediate switching stations may be installed, at which line segments can be switched off or parallelized. This was done at Inga\u2013Shaba HVDC.\nBack to back.\nA back-to-back station (B2B) is a plant in which both converters are in the same area, usually in the same building. The length of the direct current line is kept as short as possible. HVDC back-to-back stations are used for:\nThe DC voltage in the intermediate circuit can be selected freely at HVDC back-to-back stations because of the short conductor length. The DC voltage is usually selected to be as low as possible, in order to build a small valve hall and to reduce the number of thyristors connected in series in each valve. For this reason, at HVDC back-to-back stations, valves with the highest available current rating (in some cases, up to 4,500\u00a0A) are used.\nMulti-terminal systems.\nThe most common configuration of an HVDC link consists of two converter stations connected by an overhead power line or undersea cable.\nMulti-terminal HVDC links, connecting more than two points, are rare. The configuration of multiple terminals can be series, parallel, or hybrid (a mixture of series and parallel). Parallel configuration tends to be used for large-capacity stations, and series for lower capacity stations. An example is the 2,000\u00a0MW Quebec - New England Transmission system opened in 1992. When it opened in 1992, it was the largest multi-terminal HVDC system in the world.\nMulti-terminal systems are difficult to realize using line commutated converters because reversals of power are effected by reversing the polarity of DC voltage, which affects all converters connected to the system. With Voltage Sourced Converters, power reversal is achieved instead by reversing the direction of current, making parallel-connected multi-terminals systems much easier to control. For this reason, multi-terminal systems are expected to become much more common in the near future.\nChina is expanding its grid to keep up with increased power demand, while addressing environmental targets. China Southern Power Grid started a three terminals VSC HVDC pilot project in 2011. The project has designed ratings of \u00b1160\u00a0kV/200\u00a0MW-100\u00a0MW-50\u00a0MW and will be used to bring wind power generated on Nanao island into the mainland Guangdong power grid through of combination of HVDC land cables, sea cables and overhead lines. This project was put into operation on December 19, 2013.\nIn India, the multi-terminal North-East Agra project It is rated 6,000\u00a0MW, and it transmits power on a \u00b1800\u00a0kV bipolar line from two converter stations, at Biswanath Chariali and Alipurduar, in the east to a converter at Agra, a distance of .\nOther arrangements.\nCross-Skagerrak consisted since 1993 of three poles, from which two were switched in parallel and the third used an opposite polarity with a higher transmission voltage. This configuration ended in 2014 when poles 1 and 2 again were rebuilt to work in bipole and pole 3 (LCC) works in bipole with a new pole 4 (VSC). This is the first HVDC transmission where LCC and VSC poles cooperate in a bipole.\nA similar arrangement was the HVDC Inter-Island in New Zealand after a capacity upgrade in 1992, in which the two original converters (using mercury-arc valves) were parallel-switched feeding the same pole and a new third (thyristor) converter installed with opposite polarity and higher operation voltage. This configuration ended in 2012 when the two old converters were replaced with a single, new, thyristor converter.\nA scheme patented in 2004 is intended for conversion of existing AC transmission lines to HVDC. Two of the three circuit conductors are operated as a bipole. The third conductor is used as a parallel monopole, equipped with reversing valves (or parallel valves connected in reverse polarity). This allows heavier currents to be carried by the bipole conductors, and full use of the installed third conductor for energy transmission. High currents can be circulated through the line conductors even when load demand is low, for removal of ice. As of 2012,[ [update]] no tripole conversions are in operation, although a transmission line in India has been converted to bipole HVDC (HVDC Sileru-Barsoor).\nCorona discharge.\nCorona discharge is the creation of ions in a fluid (such as air) by the presence of a strong electric field. Electrons are torn from neutral air, and either the positive ions or the electrons are attracted to the conductor, while the charged particles drift. This effect can cause considerable power loss, create audible and radio-frequency interference, generate toxic compounds such as oxides of nitrogen and ozone, and bring forth arcing.\nBoth AC and DC transmission lines can generate coronas, in the former case in the form of oscillating particles, in the latter a constant wind. Due to the space charge formed around the conductors, an HVDC system may have about half the loss per unit length of a high voltage AC system carrying the same amount of power. With monopolar transmission the choice of polarity of the energized conductor leads to a degree of control over the corona discharge. In particular, the polarity of the ions emitted can be controlled, which may have an environmental impact on ozone creation. Negative coronas generate considerably more ozone than positive coronas, and generate it further \"downwind\" of the power line, creating the potential for health effects. The use of a \"positive\" voltage will reduce the ozone impacts of monopole HVDC power lines.\nApplications.\nOverview.\nThe controllability of a current-flow through HVDC rectifiers and inverters, their application in connecting unsynchronized networks, and their applications in efficient submarine cables mean that HVDC interconnectors are often used at national or regional boundaries for the exchange of power (in North America, HVDC connections divide much of Canada and the United States into several electrical regions that cross national borders, although the purpose of these connections is still to connect unsynchronized AC grids to each other). Offshore windfarms also require undersea cables, and their turbines are unsynchronized. In very long-distance connections between two locations, such as power transmission from a large hydroelectric power plant at a remote site to an urban area, HVDC transmission systems may appropriately be used; several schemes of these kind have been built. For interconnectors to Siberia, Canada, India, and the Scandinavian North, the decreased line-costs of HVDC also make it applicable, see List of HVDC projects. Other applications are noted throughout this article.\nAC network interconnectors.\nAC transmission lines can interconnect only synchronized AC networks with the same frequency with limits on the allowable phase difference between the two ends of the line. Many areas that wish to share power have unsynchronized networks. The power grids of the UK, Northern Europe and continental Europe are not united into a single synchronized network. Japan has 50\u00a0Hz and 60\u00a0Hz networks. Continental North America, while operating at 60\u00a0Hz throughout, is divided into regions which are unsynchronized: East, West, Texas, Quebec, and Alaska. Brazil and Paraguay, which share the enormous Itaipu Dam hydroelectric plant, operate on 60\u00a0Hz and 50\u00a0Hz respectively. However, HVDC systems make it possible to interconnect unsynchronized AC networks, and also add the possibility of controlling AC voltage and reactive power flow.\nA generator connected to a long AC transmission line may become unstable and fall out of synchronization with a distant AC power system. An HVDC transmission link may make it economically feasible to use remote generation sites. Wind farms located off-shore may use HVDC systems to collect power from multiple unsynchronized generators for transmission to the shore by an underwater cable.\nIn general, however, an HVDC power line will interconnect two AC regions of the power-distribution grid. Machinery to convert between AC and DC power adds a considerable cost in power transmission. The conversion from AC to DC is known as rectification, and from DC to AC as inversion. Above a certain break-even distance (about for submarine cables, and perhaps for overhead cables), the lower cost of the HVDC electrical conductors outweighs the cost of the electronics.\nThe conversion electronics also present an opportunity to effectively manage the power grid by means of controlling the magnitude and direction of power flow. An additional advantage of the existence of HVDC links, therefore, is potential increased stability in the transmission grid.\nRenewable electricity superhighways.\nA number of studies have highlighted the potential benefits of very wide area super grids based on HVDC since they can mitigate the effects of intermittency by averaging and smoothing the outputs of large numbers of geographically dispersed wind farms or solar farms. Czisch's study concludes that a grid covering the fringes of Europe could bring 100% renewable power (70% wind, 30% biomass) at close to today's prices. There has been debate over the technical feasibility of this proposal and the political risks involved in energy transmission across a large number of international borders.\nThe construction of such green power superhighways is advocated in a white paper that was released by the American Wind Energy Association and the Solar Energy Industries Association in 2009. Clean Line Energy Partners is developing four HVDC lines in the US for long-distance electric power transmission.\nIn January 2009, the European Commission proposed \u20ac300\u00a0million to subsidize the development of HVDC links between Ireland, Britain, the Netherlands, Germany, Denmark, and Sweden, as part of a wider \u20ac1.2\u00a0billion package supporting links to offshore wind farms and cross-border interconnectors throughout Europe. Meanwhile, the recently founded Union of the Mediterranean has embraced a Mediterranean Solar Plan to import large amounts of concentrated solar power into Europe from North Africa and the Middle East. Japan-Taiwan-Philippines HVDC interconnector was proposed in 2020. The purpose of this interconnector is to facilitate cross-border renewable power trading with Indonesia and Australia, in preparation for the future Asian Pacific Super Grid.\nAdvancements in UHVDC.\nUHVDC (ultrahigh-voltage direct-current) is shaping up to be the latest technological front in high voltage DC transmission technology. UHVDC is defined as DC voltage transmission of above 800\u00a0kV (HVDC is generally just 100 to 800\u00a0kV).\nOne of the problems with current UHVDC supergrids is that \u2013 although less than AC transmission or DC transmission at lower voltages \u2013 they still suffer from power loss as the length is extended. A typical loss for 800 kV lines is 2.6% over . Increasing the transmission voltage on such lines reduces the power loss, but until recently, the interconnectors required to bridge the segments were prohibitively expensive. However, with advances in manufacturing, it is becoming more and more feasible to build UHVDC lines.\nIn 2010, ABB built the world's first 800\u00a0kV UHVDC in China. The Zhundong\u2013Wannan UHVDC line with 1100 kV, length and 12 GW capacity was completed in 2018. As of 2020, at least thirteen UHVDC transmission lines in China have been completed.\nWhile the majority of recent UHVDC technology deployment is in China, it has also been deployed in South America as well as other parts of Asia. In India, a , 800 kV, 6 GW line between Raigarh and Pugalur is expected to be completed in 2019. In Brazil, the Xingu-Estreito line over with 800 kV and 4 GW was completed in 2017, and the Xingu-Rio line over with 800 kV and 4 GW was completed in 2019, both to transmit the energy from Belo Monte Dam. As of 2020, no UHVDC line (\u2265 800 kV) exists in Europe or North America.\nA 1,100\u00a0kV link in China was completed in 2019 over a distance of with a power capacity of 12\u00a0GW. With this dimension, intercontinental connections become possible which could help to deal with the fluctuations of wind power and photovoltaics.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47717", "revid": "2400126", "url": "https://en.wikipedia.org/wiki?curid=47717", "title": "Srinivasa Ramanujan", "text": "Indian mathematician (1887\u20131920)\nSrinivasa Ramanujan Iyengar\n (22 December 1887\u00a0\u2013 26 April 1920) was an Indian mathematician who worked during the early 20th century. Despite having almost no formal training in pure mathematics, he made substantial contributions to mathematical analysis, number theory, infinite series, and continued fractions, including solutions to mathematical problems then considered unsolvable.\nRamanujan initially developed his own mathematical research in isolation. According to Hans Eysenck, \"he tried to interest the leading professional mathematicians in his work, but failed for the most part. What he had to show them was too novel, too unfamiliar, and additionally presented in unusual ways; they could not be bothered.\" Seeking mathematicians who could better understand his work, in 1913 he began a mail correspondence with the English mathematician G. H. Hardy at the University of Cambridge, England. Recognising Ramanujan's work as extraordinary, Hardy arranged for him to travel to Cambridge. In his notes, Hardy commented that Ramanujan had produced groundbreaking new theorems, including some that \"defeated me completely; I had never seen anything in the least like them before\", and some recently proven but highly advanced results.\nThroughout his life, Ramanujan independently compiled nearly 3,900 results (mostly identities and equations). Many were completely novel; his original and highly unconventional results, such as the Ramanujan prime, the Ramanujan theta function, partition formulae and mock theta functions, have opened entire new areas of work and inspired further research. Of his thousands of results, most have been proven correct. \"The Ramanujan Journal\", a scientific journal, was established to publish work in all areas of mathematics influenced by Ramanujan, and his notebooks\u2014containing summaries of his published and unpublished results\u2014have been analysed and studied for decades since his death as a source of new mathematical ideas. As late as 2012, researchers continued to discover that mere comments in his writings about \"simple properties\" and \"similar outputs\" for certain findings were themselves profound and subtle number theory results that remained unsuspected until nearly a century after his death. He became one of the youngest Fellows of the Royal Society and only the second Indian member, and the first Indian to be elected a Fellow of Trinity College, Cambridge.\nIn 1919, ill health\u2014now believed to have been hepatic amoebiasis (a complication from episodes of dysentery many years previously)\u2014compelled Ramanujan's return to India, where he died in 1920 at the age of 32. His last letters to Hardy, written in January 1920, show that he was still continuing to produce new mathematical ideas and theorems. His \"lost notebook\", containing discoveries from the last year of his life, caused great excitement among mathematicians when it was rediscovered in 1976.\nEarly life.\nRamanujan (literally, \"younger brother of Rama\", a Hindu deity) was born in British-ruled India on 22 December 1887 into a Tamil Brahmin Iyengar family in Erode, in present-day Tamil Nadu. His father, Kuppuswamy Srinivasa Iyengar, originally from Thanjavur district, worked as a clerk in a sari shop. His mother, Komalatammal, was a housewife and sang at a local temple. They lived in a small traditional home on Sarangapani Sannidhi Street in the town of Kumbakonam. The family home is now a museum. When Ramanujan was a year and a half old, his mother gave birth to a son, Sadagopan, who died less than three months later. In December 1889, Ramanujan contracted smallpox, but recovered. He moved with his mother to her parents' house in Kanchipuram, near Madras (now Chennai). His mother gave birth to two more children, in 1891 and 1894, both of whom died before their first birthdays.\nOn 1 October 1892, Ramanujan was enrolled at the local school. After his maternal grandfather lost his job as a court official in Kanchipuram, Ramanujan and his mother moved back to Kumbakonam, and he was enrolled in Kangayan Primary School. When his paternal grandfather died, he was sent back to his maternal grandparents, then living in Madras. He did not like school in Madras, and tried to avoid attending. His family enlisted a local constable to make sure he attended school. Within six months, Ramanujan was back in Kumbakonam.\nSince Ramanujan's father was at work most of the day, his mother took care of the boy, and they had a close relationship. From her, he learned about tradition and puranas, to sing religious songs, to attend pujas at the temple, and to maintain particular eating habits\u2014all part of Brahmin culture. At Kangayan Primary School, Ramanujan performed well. Just before turning 10, in November 1897, he passed his primary examinations in English, Tamil, geography, and arithmetic with the best scores in the district. That year, Ramanujan entered Town Higher Secondary School, where he encountered formal mathematics for the first time.\nA child prodigy by age 11, he had exhausted the mathematical knowledge of two college students who were lodgers at his home. He was later lent a book written by S. L. Loney on advanced trigonometry. He mastered this by the age of 13 while discovering sophisticated theorems on his own. By 14, he received merit certificates and academic awards that continued throughout his school career, and he assisted the school in the logistics of assigning its 1,200 students (each with differing needs) to its approximately 35 teachers. He completed mathematical exams in half the allotted time, and showed a familiarity with geometry and infinite series. Ramanujan was shown how to solve cubic equations in 1902. He would later develop his own method to solve the quartic. In 1903, he tried to solve the quintic, not knowing that it was impossible to solve with radicals.\nIn 1903, when he was 16, Ramanujan obtained from a friend a library copy of \"A Synopsis of Elementary Results in Pure and Applied Mathematics\", G. S. Carr's collection of 5,000 theorems. Ramanujan reportedly studied the contents of the book in detail. The next year, Ramanujan independently developed and investigated the Bernoulli numbers and calculated the Euler\u2013Mascheroni constant up to 15 decimal places. His peers at the time said they \"rarely understood him\" and \"stood in respectful awe\" of him.\nWhen he graduated from Town Higher Secondary School in 1904, Ramanujan was awarded the K. Ranganatha Rao prize for mathematics by the school's headmaster, Krishnaswami Iyer. Iyer introduced Ramanujan as an outstanding student who deserved scores higher than the maximum. He received a scholarship to study at Government Arts College, Kumbakonam, but was so intent on mathematics that he could not focus on any other subjects and failed most of them, losing his scholarship in the process. In August 1905, Ramanujan ran away from home, heading towards Visakhapatnam, and stayed in Rajahmundry for about a month. He later enrolled at Pachaiyappa's College in Madras. There, he passed in mathematics, choosing only to attempt questions that appealed to him and leaving the rest unanswered, but performed poorly in other subjects, such as English, physiology, and Sanskrit. Ramanujan failed his Fellow of Arts exam in December 1906 and again a year later. Without an FA degree, he left college and continued to pursue independent research in mathematics, living in extreme poverty and often on the brink of starvation.\nIn 1910, after a meeting between the 23-year-old Ramanujan and the founder of the Indian Mathematical Society, V. Ramaswamy Aiyer, Ramanujan began to get recognition in Madras's mathematical circles, leading to his inclusion as a researcher at the University of Madras.\nAdulthood in India.\nOn 14 July 1909, Ramanujan married Janaki (Janakiammal; 21 March 1899 \u2013 13 April 1994), a girl his mother had selected for him a year earlier and who was ten years old when they married. It was not unusual then for marriages to be arranged with girls at a young age. Janaki was from Rajendram, a village close to Marudur (Karur district) Railway Station. Ramanujan's father did not participate in the marriage ceremony. As was common at that time, Janaki continued to stay at her maternal home for three years after marriage, until she reached puberty. In 1912, she and Ramanujan's mother joined Ramanujan in Madras.\nAfter the marriage, Ramanujan developed a hydrocele testis. The condition could be treated with a routine surgical operation that would release the blocked fluid in the scrotal sac, but his family could not afford the operation. In January 1910, a doctor volunteered to do the surgery at no cost.\nAfter his successful surgery, Ramanujan searched for a job. He stayed at a friend's house while he went from door to door around Madras looking for a clerical position. To make money, he tutored students at Presidency College who were preparing for their Fellow of Arts exam.\nIn late 1910, Ramanujan was sick again. He feared for his health, and told his friend R. Radakrishna Iyer to \"hand [his notebooks] over to Professor Singaravelu Mudaliar [the mathematics professor at Pachaiyappa's College] or to the British professor Edward B. Ross, of the Madras Christian College.\" After Ramanujan recovered and retrieved his notebooks from Iyer, he took a train from Kumbakonam to Villupuram, a city under French control. In 1912, Ramanujan moved with his wife and mother to a house in Saiva Muthaiah Mudali street, George Town, Madras, where they lived for a few months. In May 1913, upon securing a research position at Madras University, Ramanujan moved with his family to Triplicane.\nPursuit of career in mathematics.\nIn 1910, Ramanujan met deputy collector V. Ramaswamy Aiyer, who founded the Indian Mathematical Society. Wishing for a job at the revenue department where Aiyer worked, Ramanujan showed him his mathematics notebooks. As Aiyer later recalled:\nI was struck by the extraordinary mathematical results contained in [the notebooks]. I had no mind to smother his genius by an appointment in the lowest rungs of the revenue department.\nAiyer sent Ramanujan, with letters of introduction, to his mathematician friends in Madras. Some of them looked at his work and gave him letters of introduction to R. Ramachandra Rao, the district collector for Nellore and the secretary of the Indian Mathematical Society. Rao was impressed by Ramanujan's research but doubted that it was his own work. Ramanujan mentioned a correspondence he had with Professor Saldhana, a notable Bombay mathematician, in which Saldhana expressed a lack of understanding of his work but concluded that he was not a fraud. Ramanujan's friend C. V. Rajagopalachari tried to quell Rao's doubts about Ramanujan's academic integrity. Rao agreed to give him another chance, and listened as Ramanujan discussed elliptic integrals, hypergeometric series, and his theory of divergent series, which Rao said ultimately convinced him of Ramanujan's brilliance. When Rao asked him what he wanted, Ramanujan replied that he needed work and financial support. Rao consented and sent him to Madras. He continued his research with Rao's financial aid. With Aiyer's help, Ramanujan had his work published in the \"Journal of the Indian Mathematical Society. \nOne of the first problems he posed in the journal was to find the value of:\n formula_1\nHe waited for a solution to be offered in three issues, over six months, but failed to receive any. At the end, Ramanujan supplied an incomplete solution to the problem himself. On page 105 of his first notebook, he formulated an equation that could be used to solve the infinitely nested radicals problem.\n formula_2\nUsing this equation, the answer to the question posed in the \"Journal\" was simply 3, obtained by setting \"x\" = 2, \"n\" = 1, and \"a\" = 0. Ramanujan wrote his first formal paper for the \"Journal\" on the properties of Bernoulli numbers. One property he discovered was that the denominators of the fractions of Bernoulli numbers (sequence in the OEIS) are always divisible by six. He also devised a method of calculating Bn based on previous Bernoulli numbers. One of these methods follows:\nIt will be observed that if \"n\" is even but not equal to zero,\nIn his 17-page paper \"Some Properties of Bernoulli's Numbers\" (1911), Ramanujan gave three proofs, two corollaries and three conjectures. His writing initially had many flaws. As \"Journal\" editor M. T. Narayana Iyengar noted:\nMr. Ramanujan's methods were so terse and novel and his presentation so lacking in clearness and precision, that the ordinary [mathematical reader], unaccustomed to such intellectual gymnastics, could hardly follow him.\nRamanujan later wrote another paper and also continued to provide problems in the \"Journal\". In early 1912, he got a temporary job in the Madras Accountant General's office, with a monthly salary of 20 rupees. He lasted only a few weeks. Toward the end of that assignment, he applied for a position under the Chief Accountant of the Madras Port Trust.\nIn a letter dated 9 February 1912, Ramanujan wrote:\nSir,\n\u00a0I understand there is a clerkship vacant in your office, and I beg to apply for the same. I have passed the Matriculation Examination and studied up to the F.A. but was prevented from pursuing my studies further owing to several untoward circumstances. I have, however, been devoting all my time to Mathematics and developing the subject. I can say I am quite confident I can do justice to my work if I am appointed to the post. I therefore beg to request that you will be good enough to confer the appointment on me.\nAttached to his application was a recommendation from E. W. Middlemast, a mathematics professor at the Presidency College, who wrote that Ramanujan was \"a young man of quite exceptional capacity in Mathematics\". Three weeks after he applied, on 1 March, Ramanujan learned that he had been accepted as a Class III, Grade IV accounting clerk, making 30 rupees per month. At his office, Ramanujan easily and quickly completed the work he was given and spent his spare time doing mathematical research. Ramanujan's boss, Sir Francis Spring, and S. Narayana Iyer, a colleague who was also treasurer of the Indian Mathematical Society, encouraged Ramanujan in his mathematical pursuits.\nContacting British mathematicians.\nIn the spring of 1913, Narayana Iyer, Ramachandra Rao and E. W. Middlemast tried to present Ramanujan's work to British mathematicians. M. J. M. Hill of University College London commented that Ramanujan's papers were riddled with holes. He said that although Ramanujan had \"a taste for mathematics, and some ability\", he lacked the necessary educational background and foundation to be accepted by mathematicians. Although Hill did not offer to take Ramanujan on as a student, he gave thorough and serious professional advice on his work. With the help of friends, Ramanujan drafted letters to leading mathematicians at Cambridge University.\nThe first two professors, H. F. Baker and E. W. Hobson, returned Ramanujan's papers without comment. On 16 January 1913, Ramanujan wrote to G. H. Hardy, whom he knew from studying \"Orders of Infinity\" (1910). Coming from an unknown mathematician, the nine pages of mathematics made Hardy initially view Ramanujan's manuscripts as a possible fraud. Hardy recognised some of Ramanujan's formulae but others \"seemed scarcely possible to believe\". One of the theorems Hardy found amazing was on the bottom of page three (valid for 0 &lt; \"a\" &lt; \"b\" +):\n formula_3\nHardy was also impressed by some of Ramanujan's other work relating to infinite series:\n formula_4\n formula_5\nThe first result had already been determined by G. Bauer in 1859. The second was new to Hardy, and was derived from a class of functions called hypergeometric series, which had first been researched by Euler and Gauss. Hardy found these results \"much more intriguing\" than Gauss's work on integrals. After seeing Ramanujan's theorems on continued fractions on the last page of the manuscripts, Hardy said the theorems \"defeated me completely; I had never seen anything in the least like them before\", and that they \"must be true, because, if they were not true, no one would have the imagination to invent them\". Hardy asked a colleague, J. E. Littlewood, to take a look at the papers. Littlewood was amazed by Ramanujan's genius. After discussing the papers with Littlewood, Hardy concluded that the letters were \"certainly the most remarkable I have received\" and that Ramanujan was \"a mathematician of the highest quality, a man of altogether exceptional originality and power\". One colleague, E. H. Neville, later remarked that \"No one who was in the mathematical circles in Cambridge at that time can forget the sensation caused by this letter... not one [theorem] could have been set in the most advanced mathematical examination in the world\".\nOn 8 February 1913, Hardy wrote Ramanujan a letter expressing interest in his work, adding that it was \"essential that I should see proofs of some of your assertions\". Before his letter arrived in Madras during the third week of February, Hardy contacted the Indian Office to plan for Ramanujan's trip to Cambridge. Secretary Arthur Davies of the Advisory Committee for Indian Students met with Ramanujan to discuss the overseas trip. In accordance with his Brahmin upbringing, Ramanujan refused to leave his country to \"go to a foreign land\", and his parents were also opposed for the same reason. Meanwhile, he sent Hardy a letter packed with theorems, writing, \"I have found a friend in you who views my labour sympathetically.\"\nTo supplement Hardy's endorsement, Gilbert Walker, a former mathematical lecturer at Trinity College, Cambridge, looked at Ramanujan's work and expressed amazement, urging the young man to spend time at Cambridge. As a result of Walker's endorsement, B. Hanumantha Rao, a mathematics professor at an engineering college, invited Ramanujan's colleague Narayana Iyer to a meeting of the Board of Studies in Mathematics to discuss \"what we can do for S. Ramanujan\". The board agreed to grant Ramanujan a monthly research scholarship of 75 rupees for the next two years at the University of Madras.\nWhile he was engaged as a research student, Ramanujan continued to submit papers to the \"Journal of the Indian Mathematical Society.\" In one instance, Iyer submitted some of Ramanujan's theorems on summation of series to the journal, adding, \"The following theorem is due to S. Ramanujan, the mathematics student of Madras University.\" Later in November, British Professor Edward B. Ross of Madras Christian College, whom Ramanujan had met a few years before, stormed into his class one day with his eyes glowing, asking his students, \"Does Ramanujan know Polish?\" The reason was that in one paper, Ramanujan had anticipated the work of a Polish mathematician whose paper had just arrived in the day's mail. In his quarterly papers, Ramanujan drew up theorems to make definite integrals more easily solvable. Working off Giuliano Frullani's 1821 integral theorem, Ramanujan formulated generalisations that could be made to evaluate formerly unyielding integrals.\nHardy's correspondence with Ramanujan soured after Ramanujan refused to come to England. Hardy enlisted a colleague lecturing in Madras, E. H. Neville, to mentor and bring Ramanujan to England. Neville asked Ramanujan why he would not go to Cambridge. Ramanujan apparently had now accepted the proposal; Neville said, \"Ramanujan needed no converting\" and \"his parents' opposition had been withdrawn\". Apparently, Ramanujan's mother had a vivid dream in which Ramanujan was surrounded by Europeans, and the family goddess, the deity of Namagiri, commanded her \"to stand no longer between her son and the fulfilment of his life's purpose\". On 17 March 1914, Ramanujan travelled to England by ship, leaving his wife to stay with his parents in India.\nLife in England.\nRamanujan departed from Madras aboard the S.S. \"Nevasa\" on 17 March 1914. When he disembarked in London on 14 April, Neville was waiting for him with a car. Four days later, Neville took him to his house on Chesterton Road in Cambridge. Ramanujan immediately began his work with Littlewood and Hardy. After six weeks, Ramanujan moved out of Neville's house and took up residence on Whewell's Court, a five-minute walk from Hardy's room. \nHardy and Littlewood began to look at Ramanujan's notebooks. Hardy had already received 120 theorems from Ramanujan in the first two letters, but there were many more results and theorems in the notebooks. Hardy saw that some were wrong, others had already been discovered, and the rest were new breakthroughs. Ramanujan left a deep impression on Hardy and Littlewood. Littlewood commented, \"I can believe that he's at least a Jacobi\", while Hardy said he \"can compare him only with Euler or Jacobi.\"\nRamanujan spent nearly five years in Cambridge collaborating with Hardy and Littlewood, and published part of his findings there. Hardy and Ramanujan had highly contrasting personalities. Their collaboration was a clash of different cultures, beliefs, and working styles. In the previous few decades, the foundations of mathematics had come into question and the need for mathematically rigorous proofs was recognised. Hardy was an atheist and an apostle of proof and mathematical rigour, whereas Ramanujan was a deeply religious man who relied very strongly on his intuition and insights. Hardy tried his best to fill the gaps in Ramanujan's education and to mentor him in the need for formal proofs to support his results, without hindering his inspiration\u2014a conflict that neither found easy.\nRamanujan was awarded a \"Bachelor of Arts by Research\" degree (the predecessor of the PhD degree) in March 1916 for his work on highly composite numbers, sections of the first part of which had been published the preceding year in the \"Proceedings of the London Mathematical Society.\" The paper was more than 50 pages long and proved various properties of such numbers. Hardy disliked this topic area but remarked that though it engaged with what he called the 'backwater of mathematics', in it Ramanujan displayed 'extraordinary mastery over the algebra of inequalities'.\nOn 6 December 1917, Ramanujan was elected to the London Mathematical Society. On 2 May 1918, he was elected a Fellow of the Royal Society, the second Indian admitted, after Ardaseer Cursetjee in 1841. At age 31, Ramanujan was one of the youngest Fellows in the Royal Society's history. He was elected \"for his investigation in elliptic functions and the Theory of Numbers.\" On 13 October 1918, he was the first Indian to be elected a Fellow of Trinity College, Cambridge.\nIllness and death.\nRamanujan had numerous health problems throughout his life. His health worsened in England; possibly he was also less resilient due to the difficulty of keeping to the strict dietary requirements of his religion there and because of wartime rationing in 1914\u201318. He was diagnosed with tuberculosis and a severe vitamin deficiency, and confined to a sanatorium. He attempted suicide in late 1917 or early 1918 by jumping on the tracks of a London underground station. Scotland Yard arrested him for attempting suicide (which was a crime), but released him after Hardy intervened. In 1919, Ramanujan returned to Kumbakonam, Madras Presidency, where he died in 1920 aged 32. After his death, his brother Tirunarayanan compiled Ramanujan's remaining handwritten notes, consisting of formulae on singular moduli, hypergeometric series and continued fractions. In his last days, though in severe pain, \"he continued doing his mathematics filling sheet after sheet with numbers\", Janaki Ammal recounts.\nRamanujan's widow, Smt. Janaki Ammal, moved to Bombay. In 1931, she returned to Madras and settled in Triplicane, where she supported herself on a pension from Madras University and income from tailoring. In 1950, she adopted a son, W. Narayanan, who eventually became an officer of the State Bank of India and raised a family. In her later years, she was granted a lifetime pension from Ramanujan's former employer, the Madras Port Trust, and pensions from, among others, the Indian National Science Academy and the state governments of Tamil Nadu, Andhra Pradesh and West Bengal. She continued to cherish Ramanujan's memory, and was active in efforts to increase his public recognition; prominent mathematicians, including George Andrews, Bruce C. Berndt and B\u00e9la Bollob\u00e1s made it a point to visit her while in India. She died at her Triplicane residence in 1994.\nA 1994 analysis of Ramanujan's medical records and symptoms by D. A. B. Young concluded that his medical symptoms\u2014including his past relapses, fevers, and hepatic conditions\u2014were much closer to those of hepatic amoebiasis, an illness then widespread in Madras, than of tuberculosis. He had two episodes of dysentery before he left India. When not properly treated, amoebic dysentery can lie dormant for years and lead to hepatic amoebiasis, whose diagnosis was not then well established. At the time, if properly diagnosed, amoebiasis was a treatable and often curable disease; British soldiers who contracted it during the First World War were being successfully cured of amoebiasis around the time Ramanujan left England.\nPersonality and spiritual life.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nWhile asleep, I had an unusual experience. There was a red screen formed by flowing blood, as it were. I was observing it. Suddenly a hand began to write on the screen. I became all attention. That hand wrote a number of elliptic integrals. They stuck to my mind. As soon as I woke up, I committed them to writing.\n\u2014Srinivasa Ramanujan\nRamanujan has been described as a person of a somewhat shy and quiet disposition, a dignified man with pleasant manners. He lived a simple life at Cambridge. Ramanujan's first Indian biographers describe him as a rigorously orthodox Hindu. He credited his acumen to his family goddess, Namagiri Thayar (Goddess Mahalakshmi) of Namakkal. He looked to her for inspiration in his work and said he dreamed of blood drops that symbolised her consort, Narasimha. Later he had visions of scrolls of complex mathematical content unfolding before his eyes. He often said, \"An equation for me has no meaning unless it expresses a thought of God.\"\nHardy cites Ramanujan as remarking that all religions seemed equally true to him. Hardy further argued that Ramanujan's religious belief had been romanticised by Westerners and overstated\u2014in reference to his belief, not practice\u2014by Indian biographers. At the same time, he remarked on Ramanujan's strict vegetarianism.\nSimilarly, in an interview with \"Frontline\", Berndt said, \"Many people falsely promulgate mystical powers to Ramanujan's mathematical thinking. It is not true. He has meticulously recorded every result in his three notebooks,\" further speculating that Ramanujan worked out intermediate results on slate that he could not afford the paper to record more permanently.\nBerndt reported that Janaki said in 1984 that Ramanujan spent so much of his time on mathematics that he did not go to the temple, that she and her mother often fed him because he had no time to eat, and that most of the religious stories attributed to him originated with others. However, his orthopraxy was not in doubt.\nMathematical achievements.\nIn mathematics, there is a distinction between insight and formulating or working through a proof. Ramanujan proposed an abundance of formulae that could be investigated later in depth. G.\u00a0H. Hardy said that Ramanujan's discoveries are unusually rich and that there is often more to them than initially meets the eye. As a byproduct of his work, new directions of research were opened up. Examples of the most intriguing of these formulae include infinite series for \u03c0, one of which is given below:\nformula_6\nThis result is based on the negative fundamental discriminant d = \u22124 \u00d7 58 = \u2212232 with class number \"h\"(\"d\") = 2. Further, 26390 = 5 \u00d7 7 \u00d7 13 \u00d7 58 and 16 \u00d7 9801 = 3962, which is related to the fact that\nformula_7\nThis might be compared to Heegner numbers, which have class number 1 and yield similar formulae.\nRamanujan's series for \u03c0 converges extraordinarily rapidly and forms the basis of some of the fastest algorithms used to calculate \u03c0. Truncating the sum to the first term also gives the approximation for \u03c0, which is correct to six decimal places; truncating it to the first two terms gives a value correct to 14 decimal places &lt;templatestyles src=\"Crossreference/styles.css\" /&gt;.\nOne of Ramanujan's remarkable capabilities was the rapid solution of problems, illustrated by the following anecdote about an incident in which P. C. Mahalanobis posed a problem:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nHis intuition also led him to derive some previously unknown identities, such as\n formula_8\nfor all \"\u03b8\" such that formula_9 and formula_10, where \u0393(\"z\") is the gamma function, and related to a special value of the Dedekind eta function. Expanding into series of powers and equating coefficients of \"\u03b8\"0, \"\u03b8\"4, and \"\u03b8\"8 gives some deep identities for the hyperbolic secant.\nIn 1918, Hardy and Ramanujan studied the partition function \"P\"(\"n\") extensively. They gave a non-convergent asymptotic series that permits exact computation of the number of partitions of an integer. In 1937, Hans Rademacher refined their formula to find an exact convergent series solution to this problem. Ramanujan and Hardy's work in this area gave rise to a powerful new method for finding asymptotic formulae called the circle method.\nIn the last year of his life, Ramanujan discovered mock theta functions. For many years, these functions were a mystery, but they are now known to be the holomorphic parts of harmonic weak Maass forms.\nThe Ramanujan conjecture.\nAlthough there are numerous statements that could have borne the name \"Ramanujan conjecture,\" one was highly influential in later work. In particular, the connection of this conjecture with conjectures of Andr\u00e9 Weil in algebraic geometry opened up new areas of research. That Ramanujan conjecture is an assertion on the size of the tau-function, which has a generating function as the discriminant modular form \u0394(\"q\"), a typical cusp form in the theory of modular forms. It was finally proven in 1973, as a consequence of Pierre Deligne's proof of the Weil conjectures. The reduction step involved is complicated. Deligne won a Fields Medal in 1978 for that work.\nIn his paper \"On certain arithmetical functions\", Ramanujan defined the so-called delta-function, whose coefficients are called \"\u03c4\"(\"n\") (the Ramanujan tau function). He proved many congruences for these numbers, such as \"\u03c4\"(\"p\") \u2261 1 + \"p\"11 mod 691 for primes p. This congruence (and others like it that Ramanujan proved) inspired Jean-Pierre Serre (1954 Fields Medalist) to conjecture that there is a theory of Galois representations that \"explains\" these congruences and more generally all modular forms. \u0394(\"z\") is the first example of a modular form to be studied in this way. Deligne (in his Fields Medal-winning work) proved Serre's conjecture. The proof of Fermat's Last Theorem proceeds by first reinterpreting elliptic curves and modular forms in terms of these Galois representations. Without this theory, there would be no proof of Fermat's Last Theorem.\nRamanujan's notebooks.\nWhile still in Madras, Ramanujan recorded the bulk of his results in four notebooks of looseleaf paper. They were mostly written up without any derivations. This is probably the origin of the misapprehension that Ramanujan was unable to prove his results and simply thought up the final result directly. Mathematician Bruce C. Berndt, in his review of these notebooks and Ramanujan's work, says that Ramanujan most certainly was able to prove most of his results, but chose not to record the proofs in his notes.\nThis may have been for any number of reasons. Since paper was very expensive, Ramanujan did most of his work and perhaps his proofs on slate, after which he transferred the final results to paper. At the time, slates were commonly used by mathematics students in the Madras Presidency. He was also quite likely to have been influenced by the style of G. S. Carr's book, which stated results without proofs. It is also possible that Ramanujan considered his work to be for his personal interest alone and therefore recorded only the results.\nThe first notebook has 351 pages with 16 somewhat organised chapters and some unorganised material. The second has 256 pages in 21 chapters and 100 unorganised pages, and the third 33 unorganised pages. The results in his notebooks inspired numerous papers by later mathematicians trying to prove what he had found. Hardy himself wrote papers exploring material from Ramanujan's work, as did G. N. Watson, B. M. Wilson, and Bruce Berndt.\nIn 1976, George Andrews rediscovered a fourth notebook with 87 unorganised pages, the so-called \"lost notebook\".\nHardy\u2013Ramanujan number 1729.\nThe number 1729 is known as the Hardy\u2013Ramanujan number after a famous visit by Hardy to see Ramanujan at a hospital. In Hardy's words:\nI remember once going to see him when he was ill at Putney. I had ridden in taxi cab number 1729 and remarked that the number seemed to me rather a dull one, and that I hoped it was not an unfavorable omen. \"No\", he replied, \"it is a very interesting number; it is the smallest number expressible as the sum of two cubes in two different ways.\"\nImmediately before this anecdote, Hardy quoted Littlewood as saying, \"Every positive integer was one of [Ramanujan's] personal friends.\"\nThe two different ways are:\nformula_11\nGeneralisations of this idea have created the notion of \"taxicab numbers\".\nMathematicians' views of Ramanujan.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"Of course, we're always hoping. That's one reason I always read letters that come in from obscure places and are written in an illegible scrawl. I always hope it might be from another Ramanujan.\"\n\u2014Freeman Dyson on how another such genius might appear anywhere\nIn his obituary of Ramanujan, written for \"Nature\" in 1920, Hardy observed that Ramanujan's work primarily involved fields less known even among other pure mathematicians, concluding:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nHardy further said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;He combined a power of generalisation, a feeling for form, and a capacity for rapid modification of his hypotheses, that were often really startling, and made him, in his own peculiar field, without a rival in his day. The limitations of his knowledge were as startling as its profundity. Here was a man who could work out modular equations and theorems... to orders unheard of, whose mastery of continued fractions was... beyond that of any mathematician in the world, who had found for himself the functional equation of the zeta function and the dominant terms of many of the most famous problems in the analytic theory of numbers; and yet he had never heard of a doubly periodic function or of Cauchy's theorem, and had indeed but the vaguest idea of what a function of a complex variable was...\"\nAs an example, Hardy commented on 15 theorems in the first letter. Of those, the first 13 are correct and insightful, the 14th is incorrect but insightful, and the 15th is correct but misleading.\n(14): The coefficient of formula_12 in formula_13 is the integer nearest toformula_14This \"was one of the most fruitful he ever made, since it ended by leading us to all our joint work on partitions\".\nWhen asked about the methods Ramanujan used to arrive at his solutions, Hardy said they were \"arrived at by a process of mingled argument, intuition, and induction, of which he was entirely unable to give any coherent account.\" He also said that he had \"never met his equal, and can compare him only with Euler or Jacobi\". Hardy thought Ramanujan worked in a 19th-century style, where arriving at correct formulas was more important than systematic formal theories. Hardy thought his achievements were greatest in algebra, especially hypergeometric series and continued fractions.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nHe discovered fewer new things in analysis, possibly because he lacked the formal education and did not find books to learn it from, but rediscovered many results, including the prime number theorem. In analysis, he worked on the elliptic functions and the analytic theory of numbers. In analytic number theory, he was as imaginative as usual, but much of what he imagined was wrong. Hardy blamed this on the inherent difficulty of analytic number theory, where imagination had led many great mathematicians astray. In analytic number theory, rigorous proof is more important than imagination, the opposite of Ramanujan's style. His \"one great failure\" is that he knew \"nothing at all about the theory of analytic functions\".\nLittlewood reportedly said that helping Ramanujan catch up with European mathematics beyond what was available in India was very difficult because each new point mentioned to Ramanujan caused him to produce original ideas that prevented Littlewood from continuing the lesson.\nK. Srinivasa Rao has said, \"As for his place in the world of Mathematics, we quote Bruce C. Berndt: 'Paul Erd\u0151s has passed on to us Hardy's personal ratings of mathematicians. Suppose that we rate mathematicians on the basis of pure talent on a scale from 0 to 100. Hardy gave himself a score of 25, J. E. Littlewood 30, David Hilbert 80 and Ramanujan 100.'\" During a May 2011 lecture at IIT Madras, Berndt said that over the last 40 years, as nearly all of Ramanujan's conjectures had been proven, there had been greater appreciation of Ramanujan's work and brilliance, and that Ramanujan's work was now pervading many areas of modern mathematics and physics.\nPosthumous recognition.\nThe year after his death, \"Nature\" listed Ramanujan among other distinguished scientists and mathematicians on a \"Calendar of Scientific Pioneers\" who had achieved eminence. Ramanujan's home state of Tamil Nadu celebrates 22 December (Ramanujan's birthday) as 'State IT Day'. Stamps picturing Ramanujan were issued by the government of India in 1962, 2011, 2012 and 2016.\nSince Ramanujan's centennial year, his birthday, 22 December, has been annually celebrated as Ramanujan Day by the Government Arts College, Kumbakonam, where he studied, and at the IIT Madras in Chennai. The International Centre for Theoretical Physics (ICTP) has created a prize in Ramanujan's name for young mathematicians from developing countries in cooperation with the International Mathematical Union, which nominates members of the prize committee. SASTRA University, a private university based in Tamil Nadu, has instituted the SASTRA Ramanujan Prize of US$10,000 to be given annually to a mathematician not exceeding age 32 for outstanding contributions in an area of mathematics influenced by Ramanujan.\nBased on the recommendations of a committee appointed by the University Grants Commission (UGC), Government of India, the Srinivasa Ramanujan Centre, established by SASTRA, has been declared an off-campus centre under the ambit of SASTRA University. House of Ramanujan Mathematics, a museum of Ramanujan's life and work, is also on this campus. SASTRA purchased and renovated the house where Ramanujan lived at Kumabakonam.\nIn 2011, on the 125th anniversary of his birth, the Indian government declared that 22 December will be celebrated every year as \"National Mathematics Day\". Then Indian Prime Minister Manmohan Singh also declared that 2012 would be celebrated as National Mathematics Year and 22 December as National Mathematics Day of India.\nRamanujan IT City is an information technology (IT) special economic zone (SEZ) in Chennai that was built in 2011. Situated next to the Tidel Park, it includes with two zones, with a total area of , including of office space.\nCommemorative postal stamps.\nCommemorative stamps released by India Post (by year):\nSelected papers.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSelected publications on Ramanujan and his work.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nSelected publications on works of Ramanujan.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nThis book was originally published in 1927 after Ramanujan's death. It contains the 37 papers published in professional journals by Ramanujan during his lifetime. The third reprint contains additional commentary by Bruce C. Berndt.\nThese books contain photocopies of the original notebooks as written by Ramanujan.\nThis book contains photocopies of the pages of the \"Lost Notebook\".\nThis was produced from scanned and microfilmed images of the original manuscripts by expert archivists of Roja Muthiah Research Library, Chennai.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47718", "revid": "17216044", "url": "https://en.wikipedia.org/wiki?curid=47718", "title": "Flagstaff", "text": "Flagstaff commonly refers to:\nFlagstaff may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "47719", "revid": "42677165", "url": "https://en.wikipedia.org/wiki?curid=47719", "title": "Coulomb", "text": "SI derived unit of electric charge \n&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nThe coulomb (symbol: C) is the unit of electric charge in the International System of Units (SI). It is defined to be equal to the electric charge delivered by a 1 ampere current in 1 second, with the elementary charge \"e\" as a defining constant in the SI.\nDefinition.\nThe SI defines the coulomb as \"the quantity of electricity carried in 1 second by a current of 1 ampere\" by fixing the value of the elementary charge, \"e\"\u00a0=\u00a0. Inverting the relationship, the coulomb can be expressed in terms of the elementary charge:\nformula_1\nIt is approximately and is thus not an integer multiple of the elementary charge. \nThe coulomb was previously defined in terms of the ampere based on the force between two wires, as 1 A \u00d7 1 s. \nThe 2019 redefinition of the ampere and other SI base units fixed the numerical value of the elementary charge when expressed in coulombs and therefore fixed the value of the coulomb when expressed as a multiple of the fundamental charge.\nSI prefixes.\nLike other SI units, the coulomb can be modified by adding a prefix that multiplies it by a power of 10.\nName and history.\nThe coulomb is named after Charles-Augustin de Coulomb. As with every SI unit named after a person, its symbol starts with an upper case letter (C), but when written in full, it follows the rules for capitalisation of a common noun; i.e., \"coulomb\" becomes capitalised at the beginning of a sentence and in titles but is otherwise in lower case.\nBy 1878, the British Association for the Advancement of Science had defined the volt, ohm, and farad, but not the coulomb. In 1881, the International Electrical Congress, now the International Electrotechnical Commission (IEC), approved the volt as the unit for electromotive force, the ampere as the unit for electric current, and the coulomb as the unit of electric charge.\nAt that time, the volt was defined as the potential difference [i.e., what is nowadays called the \"voltage (difference)\"] across a conductor when a current of one ampere dissipates one watt of power.\nThe coulomb (later \"absolute coulomb\" or \"abcoulomb\" for disambiguation) was part of the EMU system of units. The \"international coulomb\" based on laboratory specifications for its measurement was introduced by the IEC in 1908. The entire set of \"reproducible units\" was abandoned in 1948 and the \"international coulomb\" became the modern coulomb.\nNotes and references.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47720", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=47720", "title": "School of Advanced Military Studies", "text": "United States military postgraduate school\nMilitary unit\nThe School of Advanced Military Studies (SAMS) is one of four United States Army schools that make up the United States Army Command and General Staff College (CGSC) at Fort Leavenworth, Kansas. The \"enormously rigorous\" graduate school consists of three programs: the larger Advanced Military Studies Program (AMSP); the Advanced Strategic Leadership Studies Program (ASLSP), a Joint Military Professional Education II (JPME II) certified senior service college program for senior field-grade officers, and the Advanced Strategic Planning and Policy Program (\"ASP3\"), which supports officers in obtaining doctorates from civilian schools.\nThe school educates future leaders of the United States Armed Forces, its allies, and the Interagency at the graduate level to be agile and adaptive leaders who think critically at the strategic and operational levels to solve complex ambiguous problems. The student body is small but diverse and comprises members of each of the US armed forces, various US government agencies, and allied military forces. Graduates of AMSP are colloquially known as \"Jedi Knights\".\nThe school issues a master's degree in Military Art and Science, and provides its graduates with the skills to deal with the disparate challenges encountered in contemporary military and government operations. The modern course produces \"leaders with the flexibility of mind to solve complex operational and strategic problems in peace, conflict, and war\". Various senior military leaders have recognized the contributions of SAMS graduates in supporting global contingency operations.\nThe first class began at the school in mid-1983 and 13 students graduated the following year. Due to increasing requirements for SAMS graduates in the US military, the army expanded the school in the 1990s, and in 2010 over 120 students graduated. Since the school's inception, SAMS planners have supported every major US military campaign, providing the army \"with many of its top campaign planners for the late twentieth and early twenty-first centuries\".\nHistory.\nThe SAMS course was designed to fill a gap in US military education between the CGSC's focus on tactics and the War College's focus on grand strategy and national security policy. In 1981, Colonel Huba Wass de Czege convinced Lieutenant General William R. Richardson, who was serving as Commander of the Combined Arms Center and Commandant of the Command and General Staff College at Fort Leavenworth from 1979 to 1981, that a second year of military education was needed for select officers. After receiving final approval, Wass de Czege helped plan and develop the school, which would open in mid-1983. Although there was some disagreement about the purpose of the course, army leaders and the course designers settled on a plan to provide officers with a \"broad, deep military education in the science and art of war.\"\nIn June 1983, the first class of 13 US Army students began in the basement of Bell Hall at Fort Leavenworth. Initially, there were some internal problems with facilities and scheduling, and in the school's early years there was uncertainty whether its graduates would be accepted and how they would perform in the force. When the first class graduated in 1984, SAMS had already become \"the symbol for intellectual renaissance in the officer corps\". When the first director, Wass de Czege, was succeeded by Colonel Richard Sennreich in 1985, the school was already beginning to produce results and the US Army and the college regarded SAMS as a \"useful experiment\". By 1987, enrollment of high-quality officers had risen and sister services were becoming interested in sending students to SAMS. The program's growing popularity and reputation also began attracting students from allied countries.\nSAMS graduates first were in active service in December 1989 during Operation Just Cause in Panama. A core planning cell of seven SAMS graduates \"crafted a well rehearsed and well executed plan that simultaneously struck some roughly 50 objectives in a single coordinated blow\". According to Colonel Kevin Benson, the tenth director of the school, \"The Army and SAMS faced a test of battle and the new group of highly-educated planners appeared to have passed the test with flying colors.\" After its mission in Panama, the army's leaders began to draw on SAMS to assist in additional ways. In the early 1990s, US Army leaders called upon the school to help develop army doctrine. Lieutenant Colonel Thomas E. Mitchell, Colonel James McDonough (the fifth SAMS director), and other members of the SAMS team helped revise the US Army Doctrinal Manual 100-5 \"Operations\" in 1990\u20131993.\nLieutenant General Guy C. Swan said that SAMS graduates were indispensable in Europe after the fall of the Berlin Wall and the dissolution of the Warsaw Pact. They were expected to \"re-engineer the decades of planning that had gone into the GDP [General Defense Plan] almost overnight\". Swan said that this was \"the first true test of SAMS on a large scale\". SAMS graduates served in Operation Desert Shield/Desert Storm, and were \"remembered most famously in the early days for producing the 'Jedi Knights' employed by Gen. Norman Schwarzkopf in developing the famous 'left hook'\". SAMS graduates also served in roles beyond the initial planning, with 82 graduates participating in diverse theater tasks by February 1991. As a result, US Army leadership regarded SAMS as being a source of \"superb planners\".\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThe number one reason for the success of Desert Storm was General (H. Norman) Schwarzkopf. ... The number two reason was the air war, and the number three reason was the SAMS graduates who put together General Schwarzkopf's plan.\n \u2014 Williamson Murray, Professor of Military History at Ohio State University, 1991.\nAfter Desert Storm, the army struggled with military operations other than war, such as peacekeeping and peace enforcement operations. The school and its graduates examined the situations in Bosnia, Haiti, and Somalia. Graduates also participated in Defense Support of Civil authorities missions. The course continued to change in the 1990s. Under Colonel Gregory Fontenot, the school moved from Fort Leavenworth's Flint Hall to Eisenhower Hall in October 1994. In later years, the school's leadership expanded the number of seminars and the civilian faculty. The military continues to draw heavily on SAMS in the twenty-first century. SAMS planners have played a significant role in the Global War on Terror. Beginning in 2002, the United States Central Command requested planners from SAMS and its sister schools, the United States Air Force's School of Advanced Air and Space Studies (SAASS), which was designed to be similar to SAMS, and the United States Marine Corps's School of Advanced Warfighting (SAW). SAMS students from the 2002 and 2003 classes participated as planners in the preparations for the invasion of Iraq and the plan for the post-combat occupation.\nThe school continued to change and develop, and an additional faculty expansion occurred in 2005\u20132006. Also, the Fellows' curriculum shifted further away from that of the AMSP program. To keep pace with increasing demand for SAMS planners, the commander of the army's Training and Doctrine Command directed an expansion that was approved by the Chief of Staff of the Army, and the school's 11th director, Colonel Steve Banach, began a winter-start course in 2007. During this period, SAMS provided planners to help forward-deployed headquarters plan operations and contingencies. The school moved to new premises in the newly renovated Muir Hall at Fort Leavenworth on 30 August 2011.\nContributions.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nI realized that the SAMS guy in the Division HQ was the go-to person for everyone.\n \u2014 Lieutenant General Mark Hertling, 1988 SAMS graduate.\nSAMS graduates have supported every major US military campaign between 1984 and 2009. SAMS graduates are known for their \"critical thinking skill sets\", and are consistently called for by combatant commanders around the world. In 2010, Brigadier General Sean MacFarland said, \"In a crisis, the president always asks, 'where are the aircraft carriers?' In the Army, leaders ask, 'Where are the SAMS graduates?' Just as the aircraft carrier was a game changer in naval warfare, SAMS graduates and practitioners of operational art have been game changers in land warfare.\"\nThe school has won praise by senior US military leaders. According to Major General David Hogg, \"SAMS has a reputation for producing skilled planners that can take complex ideas and develop cohesive plans.\" In 2010, army Vice Chief of Staff Peter W. Chiarelli said that SAMS was \"at the forefront of the effort to remake strategic military planning for the 21st century\".\nFacilities and student body.\nAs of 2014[ [update]], the SAMS teaching facilities are mainly housed in Muir Hall (image right), which was once a stable, and Flint Hall. The AMSP courses are taught mostly in Muir Hall\u2014the current SAMS headquarters\u2014while Flint Hall houses additional AMSP seminars. Both buildings were renovated in 2011 and their classrooms accommodate seminars of about 16\u201318 students and an instructor. The renovations for Muir Hall cost $12.2\u00a0million, including $3\u00a0million in information systems that allow students to collaborate digitally, replicating a common practice seen in militaries today.\nThe application process includes an examination, an interview, and a supervisor assessment. Applicants must also complete the US Army's Command and General Staff School or an equivalent intermediate-level education course offered by another uniformed service. The student body of SAMS comprises mostly US Army field grade officers from combat, combat support, and combat service support branches. However, in 1987 the US Air Force graduated three officers and officers from the US Navy and US Marine Corps graduated in following years. US government agencies began sending students to SAMS in 2007. The Department of State, Federal Bureau of Investigation, and the United States Agency for International Development (USAID) have sent students to the school. Also warrant officers first attended SAMS in 2010.\nAllied foreign militaries also provide students. In 1999, the school graduated its first international officers\u2014Norwegian and Canadian. Argentina, Australia, Colombia, France, Germany, Hungary, India, Jordan, Republic of Macedonia, the Netherlands, Pakistan, Romania, South Korea, Brazil, Spain, and the United Kingdom have also sent students through the course.\nCurricula.\nThe Command and General Staff College awards a Master of Military Art and Science (M.M.A.S.) professional degree to graduates of the School of Advanced Military Studies. The degree is accredited by the Higher Learning Commission for collegiate institutions in the midwestern United States.\nAdvanced Military Studies Program.\nMost students participate in the Advanced Military Studies Program (AMSP). In 2009, the school held eight AMSP seminars. AMSP is intended to educate students in military arts and science, and focuses on operational art and covers a variety of subjects, including military problem solving; military theory and history, military doctrine, operational planning; battle dynamics, operational theory and practice, contemporary military operations, and the application of national elements of power. Besides classroom studies and operational exercises, students must complete a research monograph and an oral examination. After graduating, officers serve on a division, corps, or Army Service Component Command staff, or in a functional area assignment.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nAMSP graduates are eagerly sought out by senior commanders for addition to their staffs as high-level planners and in other capacities demanding a more sophisticated appreciation of the operational level of war, joint operations, and the evolving contemporary operating environment.\n \u2014 United States Army Command and General Staff College.\nAdvanced Strategic Leadership Studies Program.\nASLSP is the school's senior service college resident program, educating sixteen officers for strategic-level responsibilities; developing them to be senior leaders. Students are senior lieutenant colonels, colonels, and their Naval, Coast Guard, and US interagency civilian equivalents. Classes include students from the UK, Canadian, and German armies. Most military students are former battalion commanders. The faculty consists of four civilian professors, one of whom also serves as the program's Director, plus one military faculty member. Graduates are awarded a Masters of Arts degree in Strategic Studies, Military Education Level (MEL) I, and Joint Professional Military Education (JPME) II. US military officers are also awarded the SAMS Additional Skill Identifier (ASI) 6S.\nThe program began in 1984 as the Advanced Operational Studies Fellowship (AOSF) by diverting lieutenant colonel War College selectees to Fort Leavenworth for an equivalent education program. The AOSF program had students completing the AMSP coursework, and then serve as the principal instructors of AMSP during their second year. In 1995, the name of the program was changed to the Advanced Operational Art Studies Fellowship (AOASF), and in the early 21st century its curriculum was more closely aligned to the strategic level of war. In 2013, the program was again modified in part to bring it more in alignment with TRADOC policies, and to prepare it for Joint Professional Education II accreditation. It was at that time renamed the Advanced Strategic Leadership Studies Program (ASLSP).\nThe course focuses on the strategic and political aspects of war and educationally prepares students for assignments as strategic leaders. The academic year runs from late June through late May. The ASLSP curriculum provides a comprehensive, multifaceted focus at the theater-strategic level across the spectrum of Joint and land force operations during peace, crisis, and war. The program includes classroom studies of strategy, regional studies, joint operations, strategic leadership, and twentieth-century conflict. Students also research and write a publishable-quality monograph of 10,000- 12,000 words on a suitable subject. ASLSP includes an extensive field studies program, with approximately eight weeks of TDY, to reinforce and expand classroom studies and meet with senior leaders across JIIM organizations. Field Studies include interactions with several agencies in the National Capital Region, Europe, Asia-Pacific, and CONUS-based combatant commands, and visits to various military and civilian governmental agencies. Normally, six US Army officers and the USMC, Canadian, and German officers remain for a second year to serve as seminar leaders in the AMSP course, while one US Army officer joins the faculty of the ASLSP as the military faculty member. Graduates typically serve in a follow-on command assignment or work for a three- or four-star general officer as a member of his or her staff.\nNotes.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\na. According to Kevin Benson, the 10th director of the school, \"The first 'official' reference to the School of Advanced Military Studies (SAMS) graduates as Jedi Knights was on 12 May 1992 during a meeting of the Committee on Armed Services Military Education Panel in Washington D.C.\" Congressman Ike Skelton stated, \"we all know that the real stamp of approval came when General Schwarzkopf requested SAMS graduates, sometimes referred to as 'Jedi Knights,\" be sent to his headquarters in Riyadh to assist in developing the campaign plan.\"\nb. The other two officers assigned to assist Wass de Czege in preparing the curricula for the school were Lieutenant Colonels Hal Winton and Douglas Johnson. Another key member of the SAMS staff was Mrs. Candace Hamm whose service to the school since 1988 earned her the title of \"\"godmother\" of SAMS\".\nc. SAASS's first director, Colonel William Fortner, stated in 1991 that the new school (originally called the School of Advanced Airpower Studies) \"will be similar to the Army's School of Advanced Military Studies at Fort Leavenworth\", with additional focuses on air power topics.\nd. Initially, the requirement was to complete a master's thesis. School director Don Holder (1987\u20131989) changed this requirement to two monographs, the first with a tactical focus, and the second on an operational level topic. This continued until the school's eighth director, Robin P. Swan (1998\u20132001) changed the monograph requirement back to one \"in the face of multiple and competing requirements\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "47721", "revid": "1030826", "url": "https://en.wikipedia.org/wiki?curid=47721", "title": "Carrier frequency", "text": ""}
{"id": "47722", "revid": "31696229", "url": "https://en.wikipedia.org/wiki?curid=47722", "title": "Mitropa Cup", "text": "Football tournament\nThe Mitropa Cup, officially called Coupe de l'Europe Centrale, Mitteleurop\u00e4ischer Pokal or Central European Cup, was one of the first international major European football cups for club sides. It was conducted among the successor states of the former Austria-Hungary. After World War II in 1951 a replacement tournament named \"Zentropa Cup\" was held, but just for one season, the Mitropa Cup name was revived, and again in 1958 the name of the tournament changed to \"Danube Cup\" but only for one season. The tournament was discontinued after 1992.\nThe most successful club is Vasas with six titles.\nHistory.\nThis\n\"International\" competition for football clubs was founded in 1897 in Vienna. The Challenge Cup was invented by John Gramlick Sr., a co-founder of the Vienna Cricket and Football-Club. In this cup competition all clubs of the Austro-Hungarian Empire that normally would not meet could take part, though actually almost only clubs from the Empire's three major cities Vienna, Budapest and Prague participated. The Challenge Cup was carried out until the year 1911 and is today seen as the predecessor to the Mitropa Cup and consequently the European Cup and Champions League. The last winner of the cup was Wiener Sport-Club, one of the oldest and most traditional football clubs of Austria where the cup still remains.\nThe idea of a European cup competition was shaped after World War I which brought the defeat and collapse of the Austro-Hungarian Empire. The centre of this idea were the Central European countries that, at this time, were still leading in continental football. In the early 1920s they introduced professional leagues, the first continental countries to do so. Austria started in 1924, followed by Czechoslovakia in 1925 and Hungary in 1926. In order to strengthen the dominance of these countries in European football and to financially support the professional clubs, the introduction of the Mitropa Cup was decided at a meeting in Venice on 17 July, following the initiative of the head of the Austrian Football Association (\u00d6FB), Hugo Meisl. Moreover, the creation of a European Cup for national teams \u2013 that unlike the Challenge Cup and the Mitropa Cup would not be annual \u2013 was also part of the agreement. The first matches were played on 14 August 1927. The competition was between the top professional teams of Central Europe.\nInitially two teams each from Austria, Hungary, Czechoslovakia and Yugoslavia entered, competing in a knock-out competition. The countries involved could either send their respective league winners and runners-up, or league winners and cup winners to take part. The first winners were the Czech side, AC Sparta Prague. In 1929 Italian teams replaced the Yugoslavian ones. The competition was expanded to four teams from each of the competing countries in 1934. Other countries were invited to participate \u2013 Switzerland in 1936, and Romania, Switzerland and Yugoslavia in 1937. Austria was withdrawn from the competition following the Anschluss in 1938. In 1939, prior to the start of World War II, the cup involved only eight teams (two each from Hungary, Czechoslovakia and Italy and one each from Romania and Yugoslavia). The level of the competing nations is clearly shown by Italy's two World Cup titles (1934 &amp; 1938), Czechoslovakia's (1934) and Hungary's (1938) World Cup final, and Austria's (1934) and Yugoslavia's (1930) semi-finals. Out of the eleven different teams competing in the first three World Cups, five were part of the Mitropa Cup.\nA tournament was started in 1940, but abandoned before the final match due to World War II. Again, only eight teams competed, three each from Hungary and Yugoslavia and two from Romania. Hungarian Ferencv\u00e1ros and Romanian Rapid (which had won on lots after three draws) qualified for the final, but did not meet because the northern part of Transylvania (lost shortly after World War I) was ceded to Hungary from Romania.\nChampions.\nFinals.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nPerformances.\nNote: The 1960 edition is not included in the list because it was won by a nation rather than club.\nMitropa Super Cup.\nAdditionally, a \"Mitropa Super Cup\" was contested in 1989 between the winners of 1988 and 1989. Ostrava won the first leg 3\u20130 on 12 April 1989.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47723", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=47723", "title": "Palestinian homeland", "text": ""}
{"id": "47724", "revid": "2842084", "url": "https://en.wikipedia.org/wiki?curid=47724", "title": "Dicaearchus", "text": "4th-century BC Greek philosopher and geographer\nDicaearchus of Messana (; \"Dikaiarkhos\"; c.\u2009370/350\u00a0\u2013 c.\u2009post 323 BC), also written Dikaiarchos (), was a Greek philosopher, geographer and author. Dicaearchus was a student of Aristotle in the Lyceum. Very little of his work remains extant. He wrote on geography and the history of Greece, of which his most important work was his \"Life of Greece\". Although modern scholars often consider him a pioneer in the field of cartography, this is based on a misinterpretation of a reference in Cicero to Dicaearchus's \"tabulae\", which does not refer to any maps made by Dicaearchus but is a pun on account books and refers to Dicaearchus's \"Descent into the Sanctuary of Trophonius.\" He also wrote books on ancient Greek poets, philosophy and politics.\nLife.\nHe was the son of one Pheidias, and born at Messana in Sicily, Magna Graecia, though he passed part of his life in Greece, and especially in Athens and the Peloponnesus. He also travelled to make his measurements of mountains. He was a disciple of Aristotle and a friend of Aristoxenus (a letter written to him is attested in Cicero). Eighteenth- and early nineteenth-century scholarship often considered him a friend of Theophrastus as well, but this is based on the reference to a man named Theophrastus in the spurious \"Description of Greece\", which is transmitted under Dicaearchus's name but actually consists of excerpts from a geographic poem written by Dionysius, son of Calliphon, and from a prose periegesis of Greece, written by Heraclides Criticus. It is uncertain when Dicaearchus died. The only certain terminus post quem is the death of Alexander the Great (323 BC). According to Pliny, Dicaearchus measured mountains \"with the support of the kings\" (). Most scholars identify these kings as Cassander and Ptolemy I Soter. If this identification is correct, this would put Dicaearchus's activity between 306 and 287 BC. However, the kings might also refer to Philip III Arrhidaeus and Alexander IV, who were the nominatim kings after the death of Alexander the Great. If that identification is correct, this moves his activity to 323\u2013317 BC.\nWritings.\nDicaearchus was highly esteemed by the ancients as a philosopher and as a man of most extensive and learned information upon a great variety of things. His work is known only from the many fragmentary quotations of later writers. His works were geographical, political, historical and philosophical; but it is difficult to draw up an accurate list of them, since some that are quoted as distinct works may have been only sections of greater ones, and many titles are only attested once. The fragments extant, moreover, do not always enable us to form a clear notion of the works to which they once belonged. The geographical works of Dicaearchus were, according to Strabo, criticised in many respects by Polybius, though Strabo himself was more forgiving of Dicaearchus's ignorance of western and northern Europe, since \u2013 unlike Polybius \u2013 Dicaearchus had never visited these places.\nDicaearchus wrote on cultural history, music and literature:\nAmong his geographical works may be mentioned:\nOf a political nature was:\nAmong his other philosophical works may be mentioned:\nDicaearchus also wrote speeches:\nThere is lastly one spurious work and one doubtful work:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47725", "revid": "43252809", "url": "https://en.wikipedia.org/wiki?curid=47725", "title": "Organisation of Islamic Cooperation", "text": "International organisation\nThe Organisation of Islamic Cooperation (OIC; ; ), formerly the Organisation of the Islamic Conference, is an intergovernmental organisation founded in 1969. It consists of 57 member states, 48 of which are Muslim-majority. The organisation claims to be \"the collective voice of the Muslim world\" and works to \"safeguard and protect the interests of the Muslim world in the spirit of promoting international peace and harmony\".\nOIC has permanent delegations to the United Nations and the European Union. Its official languages are Arabic, English, and French. It operates affiliated, specialised, and subsidiary organs within the framework of OIC Charter.\nMember states had a collective population of over 1.8 billion as of 2015, accounting for just under a quarter of the world's population. The collective area is 31.66 m km2.\nHistory.\nOn 21 August 1969, after the Al-Aqsa mosque fire in Jerusalem, Amin al-Husseini, the former Mufti of Jerusalem, called for a summit of all Muslim heads of state. The fire destroyed part of the old wooden roof and an 800-year-old pulpit. The arsonist was an Australian Christian fundamentalist Denis Michael Rohan. On 25 September 1969, representatives of 24 Muslim majority countries met in Rabat, Morocco. A resolution was passed stating that Muslim governments would henceforth strive for close cooperation and mutual assistance in economic, scientific, cultural and religious endeavors.\nIn March 1970, the First Islamic Conference of Foreign Ministers was held in Jeddah, Saudi Arabia. In 1972, the Organisation of the Islamic Conference was founded.\nWhile the al-Aqsa fire is regarded as one of the catalysts, many Muslims aspired to a pan-Islamic institution that would serve the common political, economic, and social interests of the \"ummah\" (Muslim community) beginning in the 19th century. In particular, the collapse of the Ottoman Empire and the Caliphate after World War I left a vacuum.\nAccording to its charter, the OIC aims to preserve Islamic social and economic values; promote solidarity amongst member states; increase cooperation in social, economic, cultural, scientific, and political areas; uphold international peace and security; and advance education, particularly in science and technology.\nThe OIC emblem contains three main elements that reflect its vision and mission as incorporated in its Charter: the Kaaba, the Globe, and the Crescent.\nOn 5 August 1990, 45 foreign ministers of the OIC adopted the Cairo Declaration on Human Rights in Islam to provide guidance in matters of human rights in as much as they are compatible with Sharia (Quranic Law).\nThe Parliamentary Union of the OIC Member States (PUOICM) was established in Iran in 1999, and its head office is situated in Tehran. Only OIC members are entitled to membership in the union.\nIn March 2008, the OIC revised its charter to promote human rights, fundamental freedoms, and good governance in member states. The revisions removed any mention of the Cairo Declaration. Within the revised charter, the OIC supported the Charter of the United Nations and international law, without mentioning the Universal Declaration of Human Rights.\nOn 28 June 2011, during the 38th Council of Foreign Ministers meeting (CFM) in Astana, Kazakhstan, the organisation changed its name from Organisation of the Islamic Conference (; ) to its current name. The OIC also changed its logo at this time.\nAccording to the UNHCR, OIC countries hosted 18 million refugees by the end of 2010. OIC members continued to absorb refugees from other conflicts, including 2011 uprising in Syria. In May 2012, the OIC addressed these concerns at the \"Refugees in the Muslim World\" conference in Ashgabat, Turkmenistan.\nOn 27 June 2007, then-United States President George W. Bush announced that the United States would delegate an envoy to the OIC. Bush said of the envoy, \"Our special envoy will listen to and learn from representatives from Muslim states, and will share with them America's views and values.\" As of June 2015[ [update]], Arsalan Suleman is acting special envoy. He was appointed on 13 February 2015. In an investigation of the accuracy of a series of chain emails, Snopes.com reported that during the October 2003\u00a0\u2013 April 2004 session of the General Assembly, 17 individual members of the OIC voted against the United States 88% of the time.\nMembers.\nThe Organisation of Islamic Cooperation has 57 members, 56 of which are also member states of the United Nations. The exception is Palestine. Some member countries-Ivory Coast, Guyana, Gabon, Mozambique, Nigeria, Suriname, Togo and Uganda are not Muslim-majority. Bosnia and Herzegovina, the Central African Republic, Thailand, Russia, and Northern Cyprus (under the name \"Turkish Cypriot State\") are observer states, and other organisations and groups participate as observers.\nSyria\u2019s OIC membership was suspended on 14\u201315 August 2012, because of the government\u2019s use of heavy weapons against civilians and its refusal to engage in peaceful dialogue. On March 7, 2025, Syria officially restored a full membership after the fall of the Assad regime.\nPositions.\n\"Fitna\".\nThe OIC, on 28 March 2008, joined the criticism of the film \"Fitna\" by Dutch lawmaker Geert Wilders, which features disturbing images of violent acts juxtaposed with alleged verses from the \"Quran\".\nHouthis.\nIn March 2015, the OIC announced its support for the Saudi Arabian-led intervention in Yemen against the Shia Houthis.\nIsraeli\u2013Palestinian conflict.\nThe OIC supports a two-state solution to the Israeli\u2013Palestinian conflict.\nThe OIC calls for a boycott of Israeli products in an effort to pressure Israel into ending the occupation of the Palestinian territories.\nAt a 2013 meeting in Conakry, Guinea, Secretary-General Ekmeleddin Ihsanoglu said that foreign ministers would discuss the possibility of cutting ties with any state that recognised Jerusalem as the capital of Israel or that moves its embassy to its environs.\nAt a December 2017 extraordinary meeting held in response US President Donald Trump's decision to recognise Jerusalem, the \"Istanbul Declaration on Freedom for Al Quds\". was adopted.\nIn September 2019, the OIC condemned Israeli Prime Minister Benjamin Netanyahu's plans to annex the eastern portion of the occupied West Bank known as the Jordan Valley. In January 2024, the OIC expressed support for South Africa's ICJ genocide case against Israel.\nIndia.\nIslam is the second-largest religion in India after Hinduism. Over 200 million Muslims constitute approximately 15% of the country's population. India has the largest Muslim population other than Muslim-majority or Islamic states. However, India's relationship with Pakistan (an Islamic state), has featured hostilities and armed conflict since the 1947 Partition of India. The poor relationship between them impacted India\u2013OIC relations due to Pakistan's status as a founding member. India pushed for the OIC to accept it as a member state, arguing that Indian Muslims comprise 11% of the world's Muslim population; Pakistan has staunchly opposed this.\nPakistan cites its conflict with India over the Kashmir region as its rationale. It frequently accuses India of perpetrating human rights abuses against Kashmiris in the Indian-administered territory of Jammu and Kashmir. The region has experienced an ongoing militant uprising since the 1980s. The OIC has been urged to press India on the Kashmir dispute, and has faced pushback from Indian officials for occasional references to Jammu and Kashmir. Historically, the Muslim world has largely lent its support to Pakistan on the issue.\nThe first OIC summit held in 1969 in Rabat did not address the dispute, while granting India membership was discussed. The head of the Indian delegation addressed the summit. The erstwhile President of Pakistan, Yahya Khan, reportedly expressed mixed views. The Indian delegation, led by then Indian President Fakhruddin Ali Ahmad, was scheduled to attend the summit but ultimately was not allowed in due to Pakistan's controversial boycott threat. Differences between the two states led Pakistan to keep India out for the final session of the 1969 conference and all OIC subsequent summits.\n2019 Pulwama attack and India\u2013Pakistan standoff.\nOn 14 February 2019, a suicide-bombing attack by a Muslim militant in Jammu and Kashmir killed over 40 Indian soldiers, for which responsibility was claimed by Jaish-e-Mohammed, a Pakistan-based terrorist group. In March 2019, India conducted airstrikes in Pakistani territory, which subsequently led to the 2019 India\u2013Pakistan military standoff.\nAfter these events, Indian Foreign Minister Sushma Swaraj was invited to participate in an OIC summit. However, Pakistan protested this development and demanded that India be blocked from the event, accusing the latter of an unprovoked violation of Pakistani airspace while Indian officials claimed that the strike was carried out on terrorist-training camps. Following requests by Pakistan shortly after the 14 February attack, the OIC held an emergency meeting on 26 February. The organisation subsequently condemned India's military response to the attack and advised both sides to exercise restraint.\nFor the first time in five decades, the United Arab Emirates invited India as a \"guest of honour\" to attend the inaugural plenary 46th meeting of OIC foreign ministers in Abu Dhabi on 1 and 2 March 2019, overriding protests by Pakistan. In response Pakistan boycotted the meeting. Indian Foreign Minister Swaraj headed the Indian delegation at the summit.\nOn 18 April 2020, OIC issued a statement, urging the Modi administration of India to take urgent steps to \"stop the growing tide of Islamophobia\", citing attacks by Hindu nationalists against Indian Muslims and the allegation against Muslims of spreading COVID-19 in the country.\nCartoons of Muhammad.\nCartoons of Muhammad, published in a Danish newspaper in September 2005, offended a number of Muslims. The Third Extraordinary Session of the Islamic Summit Conference in December 2005 condemned publication of the cartoons, resulting in broader coverage of the issue by news media in Muslim countries. Subsequently, violent demonstrations throughout the Islamic world resulted in multiple deaths.\nHuman rights.\nOIC created the Cairo Declaration on Human Rights in Islam. Proponents claim it is not an alternative to the UDHR, but rather complementary to it. Article 24 states that \"all the rights and freedoms stipulated in this Declaration are subject to the Islamic Shari'ah\" and Article 25 follows with \"the Islamic Shari'ah is the only source of reference for the explanation or clarification of any of the articles of this Declaration.\" Attempts to have it adopted by the United Nations Human Rights Council met criticism, because of its contradiction of the UDHR, including from liberal Muslim groups. Critics of the CDHR state bluntly that it is \"manipulation and hypocrisy,\" \"designed to dilute, if not altogether eliminate, civil and political rights protected by international law\" and attempts to \"circumvent these principles [of freedom and equality].\"\nHuman Rights Watch says that OIC \"fought doggedly\" and successfully within the United Nations Human Rights Council to shield states from criticism, except criticism of Israel. For example, when independent experts reported violations of human rights in the 2006 Lebanon War, \"state after state from the OIC took the floor to denounce the experts for daring to look beyond Israeli violations to discuss Hezbollah's as well. OIC demands that the council \"should work cooperatively with abusive governments rather than condemn them.\" HRW responded that this works with those who are willing to cooperate; others exploit the passivity.\nOIC has been criticised for failing to discuss the treatment of ethnic minorities within member countries, such as the oppression of the Kurds in Syria and Turkey, the Ahwaz in Iran, the Hazaras in Afghanistan, the 'Al-Akhdam' in Yemen, or the Berbers in Algeria.\nAlong with OIC's 2008 charter revisions, the member states created the Independent Permanent Human Rights Commission (IPHRC). The IPHRC is an advisory body, independent from OIC, composed of eighteen individuals from diverse educational and professional backgrounds. IPHRC has the power to monitor human rights within the member states and facilitates the integration of human rights into all OIC mandates. IPHRC also aids in the promotion of political, civil, and economic rights in all member states.\nIn September 2017, the Independent Human Rights Commission (IPHRC) of the OIC strongly condemned the human rights violations against the Rohingya Muslims in Myanmar.\nIn December 2018, the OIC tentatively raised the issue of China's Xinjiang internment camps and human rights abuses against the Uyghurs. The OIC reversed its position after a visit to Xinjiang, and in March 2019, the OIC issued a report on human rights for Muslim minorities that praised China for \"providing care to its Muslim citizens\" and looked forward to greater cooperation with the PRC. In December 2020 a coalition of American Muslim groups criticised OIC for failing to speak up to prevent the abuse of the Uyghurs and accused member states of being influenced by Chinese power. The groups included the Council on American-Islamic Relations.\nLGBT rights.\nIn March 2012, the United Nations Human Rights Council held its first discussion of discrimination based on sexual orientation and gender identity, following the 2011 passage of a resolution supporting LGBT rights proposed by the Republic of South Africa. Pakistan's representative addressed the session on behalf of the OIC, denouncing the discussion and questioning the concept of sexual orientation, which he said promoted \"licentious behaviour\u00a0... against the fundamental teachings of various religions, including Islam\". He stated that the council should not discuss the topic again. Most Arab countries and some African countries walked out of the session.\nNonetheless, OIC members Albania, Gabon, Guinea-Bissau, Suriname and Sierra Leone signed a 2011 UN declaration supporting LGBT rights in the General Assembly. Bahrain, Iraq, Jordan and Turkey legalised homosexuality.\nIn May 2016, 57 countries including Egypt, Iran, Pakistan, Saudi Arabia and the United Arab Emirates from the Organisation of Islamic Cooperation requested the removal of LGBT associations from 2016 High Level Meeting on Ending AIDS, sparking protests by the United States, Canada, the European Union and LGBT communities.\nScience and technology.\nAstana Declaration.\nThe Astana Declaration is a policy guidance adopted by OIC members at the Astana Summit. The Astana Declaration commits members to increase investment in science and technology, education, eradicate extreme poverty, and implement UN Sustainable Development Goals.\nNon-state terrorism.\nIn 1999, OIC adopted the OIC Convention on Combatting International Terrorism. Human Rights Watch reported that the definition of terrorism in article 1 describes \"any act or threat of violence carried out with the aim of, among other things, imperiling people\u2019s honour, occupying or seizing public or private property, or threatening the stability, territorial integrity, political unity or sovereignty of a state.\" HRW described this as vague, ill-defined, and including much that is outside the generally accepted concept of terrorism. In HRW's view, it labels, or could easily be used to label, as terrorist actions, acts of peaceful expression, association, and assembly.\nLegal scholar Ben Saul argued that the definition is subjective and ambiguous and concluded that it left a \"serious danger of the abusive use of terrorist prosecutions against political opponents\" and others.\nHRW is concerned by OIC's apparent unwillingness to recognise as terrorism acts that serve causes endorsed by their member states. Article 2 reads: \"Peoples' struggle including armed struggle against foreign occupation, aggression, colonialism, and hegemony, aimed at liberation and self-determination.\" HRW suggested that OIC embrace \"longstanding and universally recognised international human rights standards\", a request that has not led to any results.\nDuring a meeting in Malaysia in April 2002, delegates discussed terrorism but failed to reach a definition of it. They rejected, however, any description of the Palestinian fight with Israel as terrorism. Their declaration was explicit: \"We reject any attempt to link terrorism to the struggle of the Palestinian people in the exercise of their inalienable right to establish their independent state with Al-Quds Al-Shrif (Jerusalem) as its capital.\" In fact, at the outset of the meeting, the OIC countries signed a statement praising the Palestinians and their \"blessed .\" The word terrorism was restricted to describe Israel, whom they condemned for \"state terrorism\" in their war with the Palestinian people.\nAt the 34th Islamic Conference of Foreign Ministers (ICFM), an OIC section, in May 2007, the foreign ministers termed Islamophobia \"the worst form of terrorism\".\nDispute with Thailand.\nThailand responded to OIC criticism of human rights abuses in the Muslim majority provinces of Pattani, Yala, and Narathiwat in the south of the country. In a statement issued on 18 October 2005, secretary-general Ihsanoglu vocalised concern over the continuing conflict in the south that \"claimed the lives of innocent people and forced the migration of local people out of their places\". He stressed that the Thai government's security approach to the crisis would aggravate the situation and lead to continued violence.\nOn 18\u201319 April 2009, exiled Patani leader Abu Yasir Fikri was invited to the OIC to speak about the conflict and present a proposal to end the violence between the Thai government and the ethnically Malay Muslims living in the neglected south. The group has been struggling against Thai assimilation policy and for self governance since the area was annexed by Thailand in 1902. Fikri presented a six-point solution at the conference that included obtaining the same basic rights as other groups when it came to rights of language, religion, and culture. He suggested that Thailand give up its discriminatory policies against the Patani people and allow Patani to at least be allowed the same self-governing rights as other regions in Thailand, citing that this does not go against the Thai constitution since it had been done in other parts of Thailand. He criticised the Thai government's escalation of violence by arming and creating Buddhist militia groups and questioned their intentions. He added that Thai policies of not investigating corruption, murder, and human rights violations perpetrated by Bangkok-led administration and military personnel was an obstacle for achieving peace and healing the deep wounds of \"third-class\" citizens.\nThai foreign minister Kantathi Suphamongkhon said in response: \"We have made it clear to the OIC several times that the violence in the deep South is not caused by religious conflict and the government grants protection to all of our citizens no matter what religion they embrace.\" The Foreign Ministry issued a statement dismissing the OIC's criticism and accusing it of disseminating misperceptions and misinformation about the situation in the southern provinces. \"If the OIC secretariat really wants to promote the cause of peace and harmony in the three southern provinces of Thailand, the responsibility falls on the OIC secretariat to strongly condemn the militants, who are perpetrating these acts of violence against both Thai Muslims and Thai Buddhists.\" HRW and Amnesty International offsered the same concerns as OIC, rebuffing Thailand's attempts to dismiss the issue.\nNotable meetings.\nVarious OIC meetings have attracted global attention.\nNinth meeting of PUOICM.\nThe ninth meeting of Parliamentary Union of the OIC member states (PUOICM) was held on 15 and 16 February 2007 in Kuala Lumpur, Malaysia. The speaker of Malaysia's House of Representatives, Ramli bin Ngah Talib, spoke at the inaugural ceremony. One main agenda item was stopping Israel from continuing its excavation at the Western Wall of the Temple Mount / Masjid Al-Aqsa, Islam's third holiest site. OIC also discussed how it might send peacekeeping troops to Muslim states, as well as the possibility of a name change and charter changes. Return of the sovereignty right to the Iraqi people along with withdrawal of foreign troops from Iraq was another one of the main agenda items.\nPakistani Foreign Minister Khurshid Mahmud Kasuri stated on 14 February that the secretary general of OIC and foreign ministers of seven \"like-minded Muslim countries\" would meet in Islamabad on 25 February following meetings of President Musharraf with the heads of Muslim countries to discuss \"a new initiative\" for the resolution of the Israeli\u2013Palestinian conflict.\nIPHRC trip to Washington, DC.\nIn December 2012, IPHRC met in Washington, D.C. for the first time. The IPHRC held meetings at the National Press Club, Capitol Hill, and Freedom House discussing the issues of human rights in the OIC member states. During their roundtable discussion with Freedom House, the IPHRC emphasised the adoption of the Universal Declaration of Human Rights and the rejection of the Cairo Declaration by the OIC.\nObserver status dispute.\nThe September 2014's high-level Summit of the OIC, in New York, ended without adopting any resolutions or conclusions, for the first time in several years, due to a dispute regarding the status of one of its Observer states. Egypt, Iran and the United Arab Emirates demanded that the OIC remove the term 'Turkish Cypriot State' in reference to the unrecognised Turkish Republic of Northern Cyprus (TRNC), which had observer status within the organisation. Egypt's president Abdel Fattah el-Sisi insisted that any reference to the \"Turkish Republic of Northern Cyprus or Turkish Cypriot State\" was unacceptable and was ultimately the reason for the OIC not adopting any resolutions or conclusions in the 2014 summit.\nEmergency meetings on Hamas-Israeli war.\nOn November 11, 2023 the group and the Arab League met in Riyadh for a special summit on the Gaza humanitarian situation created by the Gaza war.\nOn 5 August 2024 Iran called for an emergency meeting of the OIC on 7 August because it wanted to drum up support for its war against Israel in the wake of the Tehran assassination of Hamas leader Ismail Haniyeh. Jeddah, Saudi Arabia hosted the meeting, and Iran's foreign minister Ali Bagheri said Ayatollah Khomeini has no other choice but to use his right to self-defense. Other participants raised concerns about a wider regional conflict and Bagheri's motion failed to carry.\nStructure and organisation.\nThe OIC is headquartered in Jeddah, Saudi Arabia with regional offices in New York, Geneva, Brussels, Iraq, Kabul, and Indonesia.\nThe OIC system consists of:\nIslamic Summit.\nThe largest meeting, attended by the heads of state and government of the member states, convenes every three years. The Islamic Summit takes policy decisions and provide guidance on all issues pertaining to the realisation of the objectives as provided in the Charter and consider other issues of concern to the Member States and the Ummah.\nIslamic Conference of Foreign Ministers.\nIslamic Conference of Foreign Ministers meets once a year to examine a progress report on the implementation of its decisions taken within the framework of the policy defined by the Islamic Summit.\nUniversities.\nThe OIC sponsors four universities: the Islamic University of Technology, a subsidiary organ; and three affiliated institutions; the Islamic University in Uganda; the Islamic University of Niger; and the International Islamic University Malaysia.\nSecretary General.\nThe Secretary General is elected by the Council of Foreign Ministers for a term of five years, with a maximum of two terms. The Secretary-General is elected from among nationals of the Member States in accordance with the principles of equitable geographical distribution, rotation and equal opportunity for all Member States with due consideration to competence, integrity and experience.\nPermanent Secretariat.\nThe Permanent Secretariat is the executive organ of the Organisation, entrusted with the implementation of the decisions of the two preceding bodies, and is located in Jeddah, Saudi Arabia.\nCriticism.\nOIC has been criticised by many Muslims for its lack of engagement and solutions for Muslim countries in crisis. It is said to have made progress in social and academic terms but not politically.\nIn 2020, Pakistan's Minister of Foreign Affairs SM Qureshi criticised OIC for its stand with regard to Kashmir issue.\nThe Organisation of Islamic Cooperation has been criticised for advocating for limitations to the freedom of speech and freedom of religion by interpreting apostasy and heresy as anti-Islamic speech and Islamophobia.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47727", "revid": "51062969", "url": "https://en.wikipedia.org/wiki?curid=47727", "title": "Baltimore County, Maryland", "text": "County in Maryland, United States\nBaltimore County is the third-most populous county in the U.S. state of Maryland. The county is part of the Central Maryland region of the state. Baltimore County partly surrounds but does not include the independent city of Baltimore. It is part of the Northeast megalopolis, which stretches from Northern Virginia in the south to Boston in the north and includes major American population centers, including New York City and Philadelphia. Major economic sectors in the county include education, government, and health care. As of the 2020 census, the population was 854,535. The county is home to several universities, including Goucher College, Stevenson University, Towson University, and University of Maryland, Baltimore County.&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\n17th century.\nThe name \"Baltimore\" derives from Cecil Calvert, 2nd Baron Baltimore (1605\u20131675), proprietor of the colonial-era Province of Maryland, and the town of Baltimore in County Cork, Ireland. The earliest known documentary record of the county is dated January 12, 1659, when a writ was issued on behalf of the General Assembly of Maryland to its sheriff.\nThe county was founded in 1659, and is now one of 23 counties in the state. The initial Baltimore County was larger geographically than it is currently, including most of northeastern Maryland, which was then the northwestern frontier of the Province and included the present-day jurisdictions of Baltimore City, Cecil and Harford Counties, and parts of Carroll, Anne Arundel, Frederick, Howard, and Kent Counties.\nIn 1674, a proclamation of the Proprietor established the then-extensive boundary lines for old Baltimore County. Over the next century, various segments of the old county were sliced off as population and settlements increased in fringe regions. A portion of northeastern Baltimore County, as well as a portion of northwestern Kent County, was split off to create Cecil County. In 1748, a portion of western Baltimore County, as well as a portion of Prince George's County to the south, were split off to create Frederick County. In 1773, Harford County to the east was split off, and in 1837 another part of western Baltimore County was combined with a part of eastern Frederick County to create Carroll County. After the adjustment of Baltimore County's southern boundary with Anne Arundel County, stated to be the upper Middle and Western Branches of the Patapsco River in 1727, a portion of the county's northwestern area was designated in 1838 as the \"Western District\" or \"Howard District\" of Arundel and in 1851 was officially separated to form Howard County.\nPrior to 1674, Baltimore County court sessions were held in private residences, according to sketchy documentary evidence. In 1674, the General Assembly passed \"An Act for erecting a Court-house and Prison in each County within this Province\". The site of the courthouse, jail and county seat for Baltimore County was evidently \"Old Baltimore\" near the Bush River on land that in 1773 became part of Harford County.\nThe exact location of Old Baltimore is Chilbury Point on the north side of the Bush River owned by the Garrison of the present-day Aberdeen Proving Ground (APG), a U.S. Army weapons testing facility. It is a popular spot of local boaters. APG's Cultural Resource Management Program attempted to find Old Baltimore, contracting with R. Christopher Goodwin &amp; Associates (Goodwin). Goodwin first performed historical and archival work and coordinated with existing landscape features to locate the site of Old Baltimore. APG's Explosive Ordnance Disposal of Army personnel defused any unexploded ordnance. In 1997\u20131998. Goodwin dug 420 test pits, uncovering artifacts including a King Charles II farthing coin, and French and English gun flints. An unearthed brick foundation proved to be the remains of the tavern owned by colonist James Phillips. Another prominent landholder in Old Baltimore was William Osbourne, who operated the ferry across the Bush River.\nIn 1683, the Maryland General Assembly passed \"An Act for Advancement of Trade\" to \"establish towns, ports, and places of trade, within the province.\" One of the towns established by the act was \"on Bush River, on Town Land, near the Court-House\". The courthouse on the Bush River referenced in the 1683 Act was in all likelihood the one created by the 1674 Act. \"Old Baltimore\" was in existence as early as 1674, but no documents describe what may have preceded it.\nBy 1695, the \"Old Baltimore\" courthouse had evidently been abandoned. County justices put the site up for sale. Apparently a new courthouse at \"Simm's Choice\" on the Baltimore County side of Little Gunpowder Falls had been under construction since 1692.\n18th century.\nIn 1700, builder Michael Judd sold it to the county justices. This change of location, away from the Bush River area, reflects the growing economic and political importance of the Gunpowder region. During the next decade, the county seat moved to Joppa.\nBy 1724, the legislative assembly authorized Thomas Tolley, Capt. John Taylor, Daniel Scott, Lancelot Todd, and John Stokes purchased 20 acres from \"Taylor's Choice,\" a tract named after John Taylor. The assembly's ordinance directed that the land be divided into 40 lots with streets and alleys to accompany the courthouse and jail erected previously. By 1750, about 50 houses (including a few large two-story brick structures), a church (St. John's Anglican Parish), a courthouse, three stone warehouses, inns, taverns, stores, a public wharf and a \"gallows-tree\" with an \"Amen Corner\" with pillories and whipping posts (now located northeast of the City of Baltimore near present-day suburban \"Joppatowne\" off Harford Road) existed.\nA new port and wharfing site, Elkridge Landing, on the upper Patapsco River's Western Branch, became prosperous in the 18th century. It was established on the \"falls\" of the river, below the rapids and rocks, where the river was deep enough for loaded sailing merchantmen. The landing was a designated \"port of entry\" and was the terminus of several \"rolling roads\" on which horse or oxen-drawn hogsheads (huge barrels) packed with tobacco were wheeled down to the Landing/port to be loaded on ships sailing for London and Europe. Gradually the site silted-up from soil erosion and poor farming cultivation on the upper Patapsco, and the maritime economy of the Landing faded. In the 19th century, it became an important stop on the Baltimore and Ohio Railroad and the main north-south East Coast highway for wagons and carriages. Still, later it was on Washington Boulevard (designated U.S. Route 1) by 1926.\nWith a bit of financial pressure, and after paying for the cost of a new courthouse (300 pounds sterling), dominant business, commercial and political residents of the Town of Baltimore were able to have the Maryland General Assembly relocate the county seat to their growing port town. In 1768, following receipt of petitions for and against the relocation, the General Assembly passed an Act that moved the county seat from Joppa to Baltimore. The first courthouse was constructed in 1768 at a new Courthouse Square at present-day North Calvert Street, between East Lexington and East Fayette Streets.\n19th century.\nThe city of Baltimore, Jonestown, and Fells Point were incorporated as the City of Baltimore in 1796\u20131797. The city remained a part of surrounding Baltimore County and continued to serve as its county seat from 1768 to 1851.\nThe site of the courthouse is now \"Battle Monument Square\", constructed 1815\u20131822 to commemorate the city and county defense in the War of 1812, including the bombardment of Fort McHenry by the British Royal Navy fleet in the Patapsco River, the two-day stand-off in fortifications dug east of the city on Loudenschlager's Hill (now \"Hampstead Hill\" in today's Patterson Park) and the earlier Battle of North Point in \"Godly Woods\" on the \"Patapsco Neck\" peninsula in the southeastern portion of the county, during September 12\u201314, 1814. These events have been commemorated ever since by Defenders Day, an annual city, county, and state official holiday on September 12.\nA second city-county courthouse constructed in 1805\u20131809 was moved to the western side of the Square at North Calvert and East Lexington. A third courthouse including the lower magistrates, commissioners, district and circuit courts, orphans (inheritances/wills) court, small claims court and the old Supreme Bench of Baltimore City was constructed on the entire western block of North Calvert, East Lexington, East Fayette and Saint Paul Streets from 1896 to 1900.\nIn 1816, the City of Baltimore annexed from Baltimore County several parcels of land known as the \"Precincts\" on its west, north, east and southwest sides. The County separated from the city (which it surrounds on the east, north, and west) on July 4, 1851, as a result of the adoption of the 1851 second state constitution. Baltimore became one of the few \"independent cities\" in the United States, putting it on the same level with the state's other 23 counties and granting limited \"home rule\" powers outside the authority of the Maryland General Assembly.\nTowsontown was voted in a referendum by the voting citizens as the new \"county seat\" on February 13, 1854. The City of Baltimore continued annexing land from the county, extending its western and northern boundaries in 1888. The factory and business owners in the eastern industrial communities of Canton and Highlandtown resisted and opposed annexation, but were annexed 30 years later. The last major annexation took place in 1918\u20131919, which again took territory from the county on all three sides (west, north, and east) and to the south for the first time from Anne Arundel County, along the south shores of the Patapsco River.\n20th century.\nA new Baltimore County Courthouse was authorized to be built facing Washington Avenue, between Chesapeake and Pennsylvania Avenues to replace the previous courthouse and governmental offices then centered for near 85 years in the city, which had been the official \"county seat\" since just before the American Revolution. Later surrounded by manicured flower gardens, shrubs and curved walkways, the historical landmark is built of local limestone and marble. It was completed and dedicated in 1855. Wings and annexes were added in 1910, 1923 and 1958. By the 1970s, the county's legal system and governmental offices had grown so much that a separate modernistic \"County Courts Building\" was erected to the west behind the old Courthouse with its annexes, separated by a paved plaza which is used for employee/visitors relaxations and official ceremonies.\nA constitutional amendment to the 1867 Maryland Constitution was approved by referendum in 1948, prohibiting any future annexations without approval from residents in affected territories.\nExtensive city-county hostilities came during the Civil Rights Movement, and by the 1980s the county's older inner suburbs faced increasing urban social ills. An atmosphere of cooperation emerged with the drawing of cross-border state assembly districts, organizing of regional government agencies, and increasing state assumption of powers.\nThe county has a number of properties and sites of local, state and national historical interest on the National Register of Historic Places which is maintained by the National Park Service of the U.S. Department of the Interior by the \"Historic Sites Act\" of August 1935.\nIn 1985, the Clarence M. Mitchell Jr. City Circuit Courthouse was named in honor of Baltimorean and Civil Rights Movement leader Clarence M. Mitchell Jr..\nPolitics and government.\nBaltimore County has had a charter government since 1956. The government consists of a County Executive and a seven-member County Council. The County Executive and Council members are elected in years of gubernatorial elections. The County Executive may serve a maximum of two consecutive terms.\nWithout incorporated cities or towns, the county government provides all local services to its residents, many of which are normally associated with city-type governmental agencies.\nIn 1956, the County adopted an \"executive-council\" system of government with \"at large\" representatives, replacing its traditional system of an elected Board of County Commissioners. Since then it has had eleven county executives and one \"acting\" executive, of which ten were Democrats and two were Republicans. The former Vice President of the United States, Spiro T. Agnew, served as the third executive from 1962 to 1966 and subsequently was elected Governor of Maryland, serving from 1967 to 1969. He was later accused of corruption and bribery while serving as County executive and continuing to accept bribes as the state's governor and as U.S. vice president. He pleaded \"no contest\" to unprecedented Federal criminal charges. He was forced to resign the Vice Presidency in 1973.\nPolitically, Baltimore County leans Democratic, but not as overwhelmingly as Baltimore City. In general, the northern portions of the county lean Republican, while the southern portion is more Democratic.\nState's attorney.\nThe Baltimore County State's Attorney is responsible for prosecuting the felony, misdemeanor, and juvenile cases that occur in the county. As of 2017, the State's Attorney was Scott Shellenberger (Democrat). He followed Sandra A. O'Connor, a Republican who served eight terms before retiring in 2006.\nLaw enforcement.\nThe Baltimore County Police Department is responsible for police services.\nEstablished in the mid-17th century, the Sheriff of Baltimore County was at first filled by county justices from 1662 to 1676. After 1676, the Court submitted three names from which the colonial governor chose a sheriff. Although terms of office initially varied, by 1692, a uniform two-year term was imposed. In 1699 a three-year term with separate commissions was adopted. The sheriff acted as the chief local representative of the proprietary government. His duties included the collection of all public taxes and after 1692, the collection of the yearly poll tax of forty pounds of tobacco for the support of the Anglican (Church of England) clergy and parishes. A sheriff received a percentage of collected monies, generally about five percent. He also received a yearly salary for duties such as reporting to the governor on affairs within the county, taking/estimating the census periodically, conveying official laws and proprietary requests to the county courts and selecting juries for court sessions. Along with enforcing all provincial laws, he posted new laws in public places. While his primary duty was to serve the Proprietor, the sheriff was aware of problems faced by poor planters and tradesmen. With taxes, yearly quit-rents and other costly expenditures, many of the poorer settlers were unable to pay their obligations when due. The sheriff often extended credit to these planters and paid their immediate obligations out of his own pocket. This lessened the impact of taxes for the poor, who repaid the sheriff after their harvests were brought in.\nThe modern Baltimore County Sheriff's Department is responsible for security of the two major County Circuit Courts buildings and various courtrooms elsewhere as well as process and warrant service. Sheriff's Deputies are sworn police officers and share the same powers of the more recently organized County Police Department. As of 2019, the Baltimore County Sheriff is a Democrat, R. J. Fisher.\nThe Maryland State Police is headquartered at 1201 Reisterstown Road in the Pikesville CDP.\nThe Federal Bureau of Investigation (FBI) Baltimore field office is located in Milford Mill.\nFire Department.\nThe Baltimore County Fire Department (B.Co.F.D.) provides fire protection, emergency medical services and emergency rescue services to the county and surrounding areas, including Baltimore City, through mutual-aid pacts with those jurisdictions. The department consists of both paid and volunteer companies that provide services to overlapping territories. Twenty-five career (paid) stations and 28 volunteer stations operate there. More than 1,000 paid personnel and more than 2,000 volunteers serve in the department. The department conducts annual fire inspections on commercial properties, fire investigation and fire prevention education activities as well as water and tactical rescue.\nSworn in as fire chief on July 1, 2019, Joanne R. Rund is the first female chief to be permanently appointed to the position.\nCounty executives.\nThe Baltimore County Executive oversees the executive branch of the County government, which is charged with implementing County law and overseeing the government operations.\nList of County Executives\nNotes: Anderson resigned after being convicted of several crimes and sentenced to prison. Kamenetz died on May 10, 2018. County Administrative Officer Frederick J. Homan was acting county executive until the county council named Mohler to serve the remainder of Kamenetz's term.\nCounty council.\nThe County Council adopts ordinances and resolutions and holds the county's legislative powers.\nAs of April 2023[ [update]], the council has 4 Democrats and 3 Republicans.\nPolitics.\nBaltimore County is somewhat of a bellwether for Maryland politics. While it leans slightly Republican compared to the state as a whole, Republicans running for statewide office must carry it solidly to win a statewide election.\nAfter going Republican in all but one presidential election from 1944 to 1988, it has voted for the Democratic candidate for president in each election since 1992. Along with neighboring Howard County, it has voted for the state-wide presidential winner in 10 straight elections, the longest such streak in the state. However, in gubernatorial elections, it has often gone Republican (1994, 1998, 2006) even as a Democratic candidate was elected governor. In the 2014 gubernatorial election Republican Larry Hogan won Baltimore County by over 20 points (59.03% to 38.89%).\nFederal government.\nBaltimore County is represented by Republican Andy Harris of Maryland's 1st congressional district, Democrat Johnny Olszewski of the 2nd district, and Democrat Kweisi Mfume of the 7th district.\nGeography.\nAccording to the U.S. census bureau, the county covers , of which is land and (12%) of which is water. It is the third-largest county in Maryland by land area. The larger portion of the terrain consists of hills often rising to a height of above tide water.\nThe highest elevation is approximately above sea level at Maryland's state border with Pennsylvania near Steltz. The lowest elevation is sea level along the shoreline of Chesapeake Bay.\nMuch of the county is suburban, straddling the border between the Piedmont plateau to the northwest and in the southern and southeastern regions of the county bordering the Patapsco River and the Chesapeake Bay, the Atlantic coastal plain. Northern Baltimore County is primarily rural, with a landscape of rolling hills and deciduous forests characteristic of the Southeastern mixed forests and shares the geography with its neighbors to the east and west, Carroll County and Harford County, and going north across the historic Mason\u2013Dixon line into Adams County and York County in south central Pennsylvania.\nClimate.\nThe county has a humid subtropical climate (\"Cfa\") except in the northern tier where a hot-summer humid continental climate (\"Dfa\") exists. Average monthly temperatures in Towson range from 33.3\u00a0\u00b0F in January to 76.9\u00a0\u00b0F in July. The county has three hardiness zones: 6b in some higher northern areas, 7a in most of the county by area, and 7b in areas close enough to the Chesapeake Bay or the City of Baltimore.\nTransportation.\nMajor roads and highways.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nTransit.\nThe Maryland Transit Administration (MTA) operates three rail systems\u2014one light rail, one rapid transit, and one commuter rail\u2014in the Baltimore area; all three systems have stations in Baltimore County. The heavy-rail Metro SubwayLink runs northwest of the city to Owings Mills; the Light RailLink system runs north of Baltimore City to Hunt Valley and south of the city through Baltimore Highlands with some routes terminating at Baltimore/Washington International Thurgood Marshall Airport, Maryland. Commuter MARC Train service is available in the county at Halethorpe, St. Denis, and Martin State Airport stations.\nThe MTA's local and regional bus services also serve Baltimore County.\nRail.\nBoth CSX Transportation and Amtrak mainlines run through the county. Former rail lines running through the County beginning in the 19th Century were the Maryland and Pennsylvania Railroad (MPR) and the Northern Central Railway (previously the Baltimore and Susquehanna Railroad, later becoming part of the old Pennsylvania Railroad). MPR and parts of the Northern Central were abandoned. The present-day streetcar/trolley line coming north from Anne Arundel County and the International Airport through Baltimore City uses the Northern Central right-of-way south of Cockeysville and Timonium; starting slightly north of that, the right-of-way was converted into the popular hiking, biking and jogging pathway from Cockeysville to the Mason\u2013Dixon line with Pennsylvania known now as the Torrey C. Brown Rail Trail, named for a former state secretary of natural resources.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2010 census.\nAs of the 2010 United States census, 805,029\u00a0people, 316,715\u00a0households, and 205,113\u00a0families resided there. The population density was . The 335,622 housing units supported an average density of . The racial makeup of the county was 64.6% white, 26.1% black or African American, 5.0% Asian, 0.3% American Indian, 1.6% from other races, and 2.4% from two or more races. Those of Hispanic or Latino origin made up 4.2% of the population. In terms of ancestry, 20.7% were German, 14.6% were Irish, 8.7% were English, 7.4% were Italian, 5.8% were Polish and 5.0% were American.\nOf the 316,715\u00a0households, 31.4% had children under the age of 18 living with them, 45.5% were married couples living together, 14.5% had a female householder with no husband present, 35.2% were non-families, and 28.3% of all households were made up of individuals. The average household size was 2.48 and the average family size was 3.04. The median age was 39.1 years.\nThe household median income was $63,959 and the median income for a family was $78,385. Males had a median income of $53,104 versus $43,316 for females. The per capita income for the county was $33,719. About 5.3% of families and 8.1% of the population were below the poverty line, including 10.1% of those under age 18 and 7.6% of those age 65 or over.\nEconomy.\nAmong the county's major employers are MedStar Franklin Square Medical Center on the east side in Rossville, the Social Security Administration, the national headquarters of which are in Woodlawn, and The Black &amp; Decker Corporation, in Towson. As of 2009, the county's workforce totaled 410,100, with 25% employed in the fields of education, health and human services, 10% in retailing, and less than 1% in agriculture.\nTop employers.\nAccording to the county's 2011 Comprehensive Annual Financial Report, the top employers in the county are concentrated in the government, medical and educational fields. The only commercial entity is Erickson Living:\nAgriculture.\nThe University of Maryland Extension system provides &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Extension for the county. The state Farm Bureau oversees the &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;County Farm Bureau here.\n&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Switchgrass (\"Panicum virgatum\") is a potential energy crop and soil improver however it does not compete well with some warm-season annual grass weeds and broadleaf weeds here. Sadeghpour \"et al.\", 2014 finds that various winter cereals including oat and rye are helpful covers for weed control, rye moreso than oat. However they still found that herbicide (specifically atrazine or quinclorac) is needed as supplemental weed control. Osipitan \"et al.\", 2018 believe this result generalizes to early season cover cropping for weed control in general.\nEducation.\nColleges and universities.\nThe University System of Maryland maintains two universities in Baltimore County:\nThe two private colleges in Baltimore County are:\nOther schools with a campus in Baltimore County:\nPublic schools.\nAll public schools in Baltimore County are operated by Baltimore County Public Schools, the sole school district in the county, with the exception of the Imagine Me Charter School, which opened August 2008.\nPrivate schools.\nBaltimore County has a number of private schools at the K-12 grade levels. Among them are:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCommunities.\nCensus-designated places.\nAll areas in Baltimore County are unincorporated and have no legal jurisdiction over their area.\nThe following census-designated places recognized by the U.S. Census Bureau:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nUnincorporated communities.\nAlthough not formally Census-Designated Places, these other communities are known locally and, in many cases, have their own post offices and are shown on roadmaps:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47729", "revid": "53396", "url": "https://en.wikipedia.org/wiki?curid=47729", "title": "Allegany County, Maryland", "text": "County in Maryland, United States\nAllegany County is a county located in the northwestern part of the U.S. state of Maryland. As of the 2020 census, the population was 68,106. Its county seat is Cumberland. The name \"Allegany\" may come from a local Lenape word, \"welhik hane\" or \"oolikhanna,\" which means 'best flowing river of the hills' or 'beautiful stream'. A number of counties and a river in the Appalachian region of the U.S. are named \"Allegany\", \"Allegheny\", or \"Alleghany\". Allegany County is part of the Western Maryland region of the state, and is part of the Cumberland metropolitan area.\nHistory.\nThe western part of Maryland (including the present Allegany County) was originally part of Prince George's County when Maryland was formed in 1696. This county included six current counties, and by repeated splitting, new ones were generated: Frederick from Prince George's in 1748; and Montgomery and Washington from Frederick in 1776.\nAllegany County was formed in 1789 by the splitting of Washington County. At the time it was the westernmost county in Maryland, but a split in 1872 created Garrett County, the current westernmost county.\nPrior to 1789, the Virginia Commonwealth claimed the area of present-day Garrett and Allegany Counties, of Maryland. A 1771\u20131780 map of Virginias counties, shows Hampshire County, but the Virginia State boundary has Hampshire outside that boundary line. When conducting genealogical research, it is possible to find tax records for Hampshire County, Virginia included in Maryland records, and Maryland records in Hampshire County... Hampshire County was formed in 1758 by the Virginia Commonwealth and at its founding, included the present day counties of Garrett and Allegany Counties in Maryland, and Hardy, Grant, Mineral, and part of Morgan Counties in what is now West Virginia.\nIn 1899, Theodore Roosevelt, then Governor of New York, passed through Allegany County on a four \u00bd-hour \u201cwhistle stop\u201d tour.\nGeography.\nAccording to the U.S. Census Bureau, the county has a total area of , of which is land and (1.3%) is water.\nAllegany County lies primarily in the Ridge-and-Valley Country of the Appalachian Mountains. It is bordered to the north by the Mason\u2013Dixon line with Pennsylvania, to the south by the Potomac River and West Virginia, to the east by Sideling Hill Creek and Washington County, Maryland, and to the west by a land border with Garrett County, Maryland. The western part of the county contains a portion of the steep Allegheny Front, which marks the transition to the higher-elevation Appalachian Plateau and Allegheny Mountain region. The town of Frostburg is located west of the Front at an elevation of nearly 2,100 feet above sea level, while the county seat of Cumberland, only eight miles away, has an elevation of only 627 feet.\nMountains.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nAdjacent counties.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2010 census.\nAs of the 2010 United States census, there were 75,087\u00a0people, 29,177\u00a0households, and 17,959\u00a0families residing in the county. The population density was . There were 33,311 housing units at an average density of . The racial makeup of the county was 89.2% white, 8.0% black or African American, 0.8% Asian, 0.1% American Indian, 0.2% from other races, and 1.6% from two or more races. Those of Hispanic or Latino origin made up 1.4% of the population. In terms of ancestry, 31.8% were German, 14.6% were Irish, 11.9% were English, 11.8% were American, and 5.6% were Italian.\nOf the 29,177\u00a0households, 26.0% had children under the age of 18 living with them, 46.0% were married couples living together, 11.0% had a female householder with no husband present, 38.4% were non-families, and 31.6% of all households were made up of individuals. The average household size was 2.30 and the average family size was 2.86. The median age was 40.9 years.\nThe median income for a household in the county was $37,747 and the median income for a family was $52,680. Males had a median income of $42,322 versus $29,594 for females. The per capita income for the county was $20,764. About 9.6% of families and 14.5% of the population were below the poverty line, including 18.3% of those under age 18 and 8.8% of those age 65 or over.\n2000 census.\nAs of the census of 2000, there were 74,930 people, 29,322 households, and 18,883 families residing in the county. The population density was . There were 32,984 housing units at an average density of . The racial makeup of the county was 93.02% White, 5.35% Black or African American, 0.15% Native American, 0.52% Asian, 0.03% Pacific Islander, 0.19% from other races, and 0.75% from two or more races. 0.76% of the population were Hispanic or Latino of any race. 29.0% were of German, 16.7% US or American, 12.8% Irish, 10.7% English and 5.3% Italian ancestry according to the 2000 census.\nThere were 29,322 households, out of which 26.50% had children under the age of 18 living with them, 50.60% were married couples living together, 10.30% had a female householder with no husband present, and 35.60% were non-families. 30.10% of all households were made up of individuals, and 15.20% had someone living alone who was 65 years of age or older. The average household size was 2.35 and the average family size was 2.90.\nIn the county, the population was spread out, with 20.60% under the age of 18, 11.20% from 18 to 24, 26.80% from 25 to 44, 23.50% from 45 to 64, and 17.90% who were 65 years of age or older. The median age was 39 years. For every 100 females there were 99.20 males. For every 100 females age 18 and over, there were 96.90 males.\nThe median income for a household in the county was $30,821, and the median income for a family was $39,886. Males had a median income of $31,316 versus $21,334 for females. The per capita income for the county was $16,780. About 9.70% of families and 14.80% of the population were below the poverty line, including 17.70% of those under age 18 and 9.50% of those age 65 or over.\nAs of 2010[ [update]], Allegany County had a racial and ethnic population composition of 88.16% Non-Hispanic whites, 8.03% Blacks, 0.14% Native Americans, 0.76% Asians, 0.04% Pacific Islanders, 0.08% Non-Hispanics who reported some other race, 1.47% Non-Hispanics who reported two or more races and 1.44% Hispanics.\nEconomy.\nAccording to the county's comprehensive annual financial reports, the top employers by number of employees in the county are the following. (\"NR\" indicates the employer was not ranked among the top ten employers that year.)\nCommunities.\nCensus-designated places.\nOccupying a middle ground between incorporated and unincorporated areas are Special Tax Districts, quasi-municipal unincorporated areas created by legislation passed by the Maryland General Assembly. They lack home rule authority and must petition the General Assembly for changes affecting the authority of the district. There are eight Special Tax Districts in the county:\nOther census-designated places in the county include:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nUnincorporated communities.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nGovernment and infrastructure.\nCurrent government.\nThe Allegany County Government is governed by a 3-member board of County Commissioners.\nLibraries.\nThe library system was created in 1960, when libraries in Cumberland, Frostburg, LaVale, Pennsylvania Avenue School, and Westernport were merged to form a unified library system. The first of the libraries which would make up the library system was the Washington Street library, founded in 1924. The most recent addition to the library system was the Georges Creek library, which opened in March 2001. The Allegany County Library System currently has six branches: Frostburg Library, Georges Creek Library, LaVale Library, South Cumberland Library, Washington Street Library, and Westernport Library.\nInfrastructure.\nThe North Branch Correctional Institution, (opened 2003), and the earlier adjacent Western Correctional Institution are operated by the Division of Corrections of the Maryland Department of Public Safety and Correctional Services, (with its headquarters in Baltimore) is located in an unincorporated area of Allegany County, just southwest of Cumberland. The prison housed male death row inmates, who were moved from the Maryland Correctional Adjustment Center, from June 2010 until death row was closed in 2014.\nPolitics.\nAllegany County was granted a home rule form of government in 1974. It is a strongly Republican county, the last Democrat to win a majority being Jimmy Carter in 1976. The only other Democrats to carry the county since 1880 have been Lyndon B. Johnson, Franklin D. Roosevelt (twice), and by very narrow margins Harry S. Truman in 1948 and Woodrow Wilson in 1912.\nTransportation.\nAllegany County has been, since colonial times, an important node on the nation's transportation network as a key transition point in the movement of goods and people to and from the ports of the Mid-Atlantic and the agricultural and industrial production centers of the Ohio Valley and Midwest. The Cumberland Narrows, a naturally occurring watergap separating Wills and Haystack Mountains, serves as one of the few passages through what is otherwise one of the steepest rushes of the Ridge and Valley province. Because of this, Cumberland has been the site of both planned and completed transportation projects focused on connecting east and west.\nOn his fateful march from Alexandria to Fort Duquesne in modern-day Pittsburgh during the French and Indian War, British General Edward Braddock and his men, including then-Lieutenant Colonel and Braddock's aide-de-camp George Washington, carved a road, closely following the Native American Nemacolin's Path, from the British encampment at Fort Cumberland, through the Allegheny Mountains all the way to Fort Duquesne. This road, known in early America as Braddock's Road, became the guidelines for the earliest sections of the Cumberland Road, or what later became known as the National Road. Specifically, the section on Braddock's Road from Cumberland to Uniontown, Pennsylvania was followed nearly exactly in the early construction of the National Road. A monument to the start of the National Road now stands on Greene Street in Cumberland, very near the spot Braddock and his men began their expedition.\nIn modern times, Allegany County is an important regional crossroads. It is crossed from east to west by Interstate 68 and US Route 40, and from north to south by US Route 220, which from Cumberland to the Mason\u2013Dixon line is part of the Appalachian Development Highway System's Corridor O.\nMajor highways.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nEducation.\nPublic K\u201312 education in the county is handled by Allegany County Public Schools (ACPS). ACPS is governed by an elected, five-member Board of Education, plus an appointed superintendent. ACPS manages three high schools (grades 9\u201312), three middle schools (grades 6\u20138), 13 elementary schools (grades K\u20135), and one K\u20138 school, plus the Center for Career and Technical Education in Cresaptown, and the Eckhart Alternative School in Eckhart Mines.\nAllegany County is also home to three Christian parochial schools: Bishop Walsh School (Catholic) in Cumberland, Lighthouse Christian Academy (non-denominational) in Cumberland, and Calvary Christian Academy (non-denominational) in Cresaptown.\nAllegany County is home to Frostburg State University, one of the eleven member universities of the University System of Maryland, and the only public, four-year university in Maryland west of the Washington\u2013Baltimore combined statistical area. The university, founded in 1898 as the Frostburg State Normal School, FSU, as the university is known to students and alumni, now offers more than 40 undergraduate majors and has a yearly enrollment consistently over 5,000 students.\nA junior college experience is available in Allegany County with the Allegany College of Maryland, located in Cumberland. Allegany College provides more than 50 associate degree programs and more than 20 certificate programs, and has more than 3,500 enrollees and more than 16,000 registrants in its Continuing Education programs. ACM also operates a satellite campus in Everett, Pennsylvania, about 30 miles north of Cumberland in Bedford County.\nNatural resources.\nThe primary mineral resources extracted for use in Allegany County are coal, iron, sandstone, and limestone. Coal-bearing formations are concentrated in the Georges Creek Basin in the western part of the county.\nSee also.\nSandy Creek may not be mentioned here. Here is a reference that it existed (the letter symbols at the end of the reference are defined in a table at the end of Keegan's book)\nA Third Rutan Family Index p 177 By James J. Keegan\nMaryland Listings:\nPeter Rutan - (1776-1848_ p/John Rutan-Catherine Jones of Morris Co. NJ; m (1) Elizabeth McIlrath (1771\u20131845) (2) Mary Webb (1788\u20131855) in 1846; he was living in Sandy Creek, Allegany Co. in 1880 and moved to Markleysburg, Fayette Co. PA in 1812; they later (lived) in Caroll Co. OH; GSNJ; LDS; MEACH\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47730", "revid": "20957809", "url": "https://en.wikipedia.org/wiki?curid=47730", "title": "Washington County, Maryland", "text": "County in Maryland, United States\nWashington County is a county located in the U.S. state of Maryland. The population was 154,705 as of the 2020 census. Its county seat and largest city is Hagerstown. The county is part of the Western Maryland region of the state.\nWashington County was the first county in the United States to be named for the Revolutionary War general (and later President) George Washington. Washington County is one of three Maryland counties recognized by the Appalachian Regional Commission as being part of Appalachia. The county borders southern Pennsylvania to the north, Northern Virginia to the south, and the Martinsburg Panhandle of West Virginia to the south and west. Washington County is included in the Hagerstown metropolitan area, which is also included in the Washington metropolitan area.\nHistory.\nFor thousands of years, Native Americans inhabited the lands that would later form Washington County. Archaeological evidence suggests that an Iroquoian people known as the Susquehannock occupied this region around 1600. In the early 17th century, England began to settle lands on the Chesapeake Bay to the east of present-day Washington County. Contact between the Susquehannock and these English settlers was limited until English merchant William Claiborne from Virginia began trading with the Susquehannock in the 1630s.\nIn 1634, England established the Province of Maryland as an English colony with their founding of St. Mary's City to the southeast of present-day Washington County. English-Susquehannock relations then began to deteriorate, as Maryland formed an alliance with the Piscataway people, who were the frequent target of Susquehannock raids. The founding of the province also disrupted their trade alliance with Claiborne as he refused to acknowledge Maryland's authority. In 1641, the Governor of Maryland declared the Susquehannock \"enemies of the province\", and Susquehannock raids on Maryland and the Piscataway continued intermittently until 1652. \nAcquisition by Maryland.\nIn the winter of 1652, the Susquehannock were attacked by the Mohawk, and although the attack was repulsed, it led to the Susquehannock negotiating the Articles of Peace and Friendship with Maryland. The Susquehannock relinquished their claim to territory on either side of the Chesapeake Bay and reestablished their earlier trading relationship with the English. In 1696, the province incorporated its western portions (including its claims to present-day Washington County) into Prince George's County. In 1707, Maryland became a British colony as the result of the union of the Kingdoms of England and Scotland.\nIn the 1730s, European settlers arrived in present-day Washington County, and in 1748, Frederick County, which then included Washington County, separated from Prince George's County. During the French and Indian War, Marylanders constructed Fort Frederick in 1756. Later, Maryland was one of the colonies that revolted to form the Thirteen Colonies during the American Revolutionary War in 1775. On September 6, 1776, Maryland formed Washington County from a part of Frederick County. It was the first county in the United States named after George Washington. The State of Maryland ratified the United States Constitution and officially joined the United States in 1788. In 1789, part of Washington County was divided to form Allegany County, which itself was later divided in 1872 to form Garrett County. \nWashington County has over 30 historical sites and is home to 3 National Parks, 7 State Parks, 14 County Parks, and numerous City and Town Parks. A number of properties in the county are listed on the National Register of Historic Places. The county's history includes riots during the Whiskey Rebellion, several Civil War battles including the Battle of Antietam, the site where the abolitionist John Brown planned his raid on Harpers Ferry, and the location of railroads that facilitated westward expansion of the United States.\nGeography.\nAccording to the U.S. Census Bureau, the county has a total area of , of which is land and (2.0%) is water.\nWashington County is located in the Appalachian Mountains, stretching from the Ridge-and-Valley Country in the west to South Mountain in the east, which is an extension of the Blue Ridge. Much of the county lies in the broad Hagerstown Valley between these two zones; the valley is part of the Great Appalachian Valley that continues southward into Virginia and West Virginia as the Shenandoah Valley and northward into Pennsylvania as the Cumberland Valley.\nThe county is bordered to the north by the Mason\u2013Dixon line with Pennsylvania, to the south by the Potomac River and the states of Virginia and West Virginia, to the west by Sideling Hill Creek and Allegany County, Maryland, and to the east by Frederick County and South Mountain.\nMajor highways.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2000 census.\nAs of the census of 2010, there were 147,430 people, 49,726 households, and 34,112 families residing in the county. The population density was . There were 52,972 housing units at an average density of . The racial makeup of the county was 89.71% White or Caucasian, 7.77% Black or African American, 0.18% Native American, 0.80% Asian, 0.04% Pacific Islander, 0.46% from other races, and 1.04% from two or more races. 1.19% of the population were Hispanic or Latino of any race, 32.1% identified as being of German ancestry, 21.4% American, 8.8% Irish, and 8.4% English ancestry.\nThere were 49,726 households, out of which 31.30% had children under the age of 18 living with them, 54.00% were married couples living together, 10.70% had a female householder with no husband present, and 31.40% were non-families. 26.00% of all households were made up of individuals, and 11.10% had someone living alone who was 65 years of age or older. The average household size was 2.46 and the average family size was 2.96.\nIn the county, the population was spread out, with 23.40% under the age of 18, 8.10% from 18 to 24, 31.30% from 25 to 44, 23.00% from 45 to 64, and 14.20% who were 65 years of age or older. The median age was 37 years. For every 100 females, there were 104.50 males. For every 100 females age 18 and over, there were 104.00 males.\n2010 census.\nAs of the 2010 United States census, there were 147,430\u00a0people, 55,687\u00a0households, and 37,506\u00a0families residing in the county. The population density was . There were 60,814 housing units at an average density of . The racial makeup of the county was 85.1% white, 9.6% black or African American, 1.4% Asian, 0.2% American Indian, 1.1% from other races, and 2.6% from two or more races. Those of Hispanic or Latino origin made up 3.5% of the population. In terms of ancestry, 31.7% were German, 14.1% were Irish, 9.8% were English, 8.5% were American, and 5.1% were Italian.\nOf the 55,687\u00a0households, 32.4% had children under the age of 18 living with them, 50.6% were married couples living together, 12.0% had a female householder with no husband present, 32.6% were non-families, and 26.6% of all households were made up of individuals. The average household size was 2.50 and the average family size was 3.01. The median age was 39.7 years.\nThe median income for a household in the county was $52,994 and the median income for a family was $65,811. Males had a median income of $47,622 versus $34,225 for females. The per capita income for the county was $26,588. About 7.7% of families and 10.4% of the population were below the poverty line, including 14.1% of those under age 18 and 8.8% of those age 65 or over.\nCommunities.\nTowns.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCensus-designated places.\nThe Census Bureau recognizes the following census-designated places in the county:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nUnincorporated communities.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nPolitics and government.\nFederal representation.\nThe county is located within Maryland's 6th congressional district. The representative of the district currently is April McClain Delaney (D).\nLike most of Appalachia, German-influenced and Unionist Western Maryland, Washington County is solidly Republican. The last Democrat to carry Washington County at a Presidential level was Lyndon Johnson during his 1964 landslide win over Barry Goldwater, although between 1888 and 1940 the county was a consistent bellwether for all Presidential elections.\nState representation.\nWashington County is represented by two senators in the Maryland State Senate. Member Mike McKay (R), serves the 1st district in Maryland and Paul D. Corderman (R), serves in the 2nd district. The county also is represented in Maryland General Assembly\u2019s other primary division, the Maryland House of Delegates. Delegates who stand for Washington County include: Terry Baker (R) for District 1C, William Valentine (R) and William J. Wivell (R) for District 2A and Matthew Schindler (D) for District 2B.\nCounty government.\nWashington County\u2019s \u201cleader\u201d is known as the County Administrator. Currently, Michelle Gordon serves as the County Administrator. However, Washington County's County Commissioners exercise executive powers as they exist in the government of the county.\nThe County Commissioners in Washington County comprise the traditional form of county government in Maryland. Current members include: John Barr (President) (R), Jeffrey A. Cline (Vice President) (R), Randall Wagner (R), Derek Harvey (R), and Randy Leatherman (R). \nEconomy.\nIn 2000, the median income for a household in the county was $40,617, and the median income for a family was $48,962. Males had a median income of $34,917 versus $24,524 for females. The per capita income for the county was $20,062. About 7.00% of families and 9.50% of the population were below the poverty line, including 12.30% of those under age 18 and 9.50% of those age 65 or over.\nAccording to the Maryland Department of Business and Economic Development, the following were the major employers in the county (excluding post offices, state government, and local governments, but including public institutions of higher education):\nWashington County is top in the state for commercial production of fruits, tree nuts, and berries.\nEducation.\nWashington County Public Schools administers public schools in the county. See https:// for a detailed listing of elementary, middle, high, and other schools.\nHigh schools.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47731", "revid": "38001712", "url": "https://en.wikipedia.org/wiki?curid=47731", "title": "Howard County, Maryland", "text": "County in Maryland, United States\nHoward County is located in the U.S. state of Maryland. As of the 2020 census, the population is 334,529. Since there are no incorporated municipalities, there is no incorporated county seat either. Therefore, its county seat is the unincorporated community of Ellicott City. Howard County is part of the Baltimore metropolitan area.\nThe county is home to Columbia, a planned community between Baltimore and Washington, D.C. with a population of approximately 100,000, founded in 1967.\nHoward County is frequently cited for its affluence, quality of life, and excellent schools. Its estimated 2020 median household income of $124,042 (~$ in 2024) makes it one of the wealthiest counties in the US. Many of the most affluent communities in the area, such as Clarksville, Dayton, Glenelg, Glenwood, and West Friendship, are located along the Route 32 corridor in Howard County. The main population center of Columbia/Ellicott City is regularly ranked in \"Money\" magazine's Top 10 \"Best Places to Live\". According to data from the U.S. Census Bureau, Howard County ranks fourth in the nation for educational attainment, with an estimated 63.6% of residents 25 and over holding a bachelor's degree or higher. In 2022, the Howard County Public School System was ranked the best school district in Maryland.\nIn 2010, the center of population of Maryland was located in the Howard County town of Jessup.\nEtymology.\nThe name of the county honors Colonel John Eager Howard, an officer in the \"Maryland Line\" of the Continental Army in the American Revolutionary War, commander notably at the Battle of Cowpens in South Carolina in 1781, among others. He was the fifth governor of Maryland, serving from 1788 to 1791.\nHistory.\nPrior to the European colonization of what is now Howard County in the 1600s, the area served as farming and hunting grounds for Indigenous peoples including the Piscataway and Susquehannock peoples. The Maryland Historical Trust has documented Indigenous sites along the Patapsco, Patuxent, Middle and Little Patuxent River valleys. In 1652, the Susquehannock tribes signed a peace treaty with Maryland, giving up their provenance over the territory that is now Howard County. In 1800, the mean center of U.S. population as calculated by the US Census Bureau was found in what is now Howard County.\nIn 1838, Dr. William Watkins of Richland Manor proposed the \"Howard District\" of Anne Arundel County. After several adjournments, the area of western Anne Arundel County was designated the Howard District in 1839. The district had the same status as a county except that it was not separately represented in the Maryland General Assembly. In 1841, the county built its first courthouse in Ellicott City. At the January 1851 constitutional convention, Thomas Beale Dorsey submitted a petition led by James Sykes. A committee was formed with Dorsey, Bowie, Smith, Harbine and Ricaud. After several postponements, the district was erected officially as Howard County on July 4, 1851, after the approval of the new constitution at the election held June 4, 1851.\nThe plantations of modern Howard County used slave labor as early as 1690. At the time of the Underground Railroad, some Howard County residents assisted slaves who were escaping to freedom. This was particularly risky, as many prominent plantation families were Confederate sympathizers during the Civil War, contributing militiamen to the South to protect local interests. Maryland was exempt from the Emancipation Proclamation, later abolishing slavery in the update of the Maryland Constitution in November 1864.\nOn May 1, 1883, Howard County joined Anne Arundel County and Harford County in liquor prohibition.\nBy 1899, Howard County contained of dirt and of stone roads, including three paid turnpikes maintained by 118 men. Most traffic consisted of loads delivered to rail crossings. In 1909, County Commissioners Hess, Werner and O'Neil were charged with malfeasance regarding contract bids.\nIn 1918, a deadly flu pandemic swept the county starting with an early outbreak in Camp Meade in adjacent Anne Arundel County. The 1930s saw a shift from one-room schoolhouses to centralized schools with bus service. By 1939 wheat harvesting fell to just . In 1940, local newspaper owner Paul Griffith Stromberg led a five-county commission to study a superhighway between Baltimore and Washington through Howard County. The Federal Aid Highway Act of 1956 eventually led to the construction of Interstate 70 across northern Howard County and Interstate 95 across the eastern part of the county. The sparsely populated county hosted population centers in Ellicott City, Elkridge, Savage, North Laurel and Lisbon with W.R. Grace and Johns Hopkins Applied Physics Lab as the largest new employers. Residents elected officials that campaigned to keep the county rural while planners prepared public works to support a quarter million residents by the year 2000. Race relations and desegregation became major issues of the time.\nFrom 1963 to 1966 the Rouse Company bought of land and rezoned it for the Columbia Development. In 1972, the Marriott company proposed to build a regional theme park on Rouse-owned land but was denied zoning.\nThe county has a number of properties on the National Register of Historic Places.\nGeography.\nAccording to the U.S. Census Bureau, the county has a total area of , of which is land and (1.0%) is water. It is the second-smallest county in Maryland by land area and smallest by total area.\nHoward County is located in the Piedmont Plateau region of Maryland, with rolling hills making up most of the landscape. It is bounded on the north and northeast by the Patapsco River, on the southwest by the Patuxent River, and on the southeast by a land border with Anne Arundel County. Both the Patapsco and Patuxent run largely through publicly accessible parkland along the county borders. The Patuxent border includes the Triadelphia and Rocky Gorge reservoirs.\nClimate.\nHoward County lies in the humid subtropical climate zone. As one travels west in the county away from the Baltimore area, the winter temperatures get lower and winter snow is more common. Annual rainfall is about throughout the county. Over a 60-year period from 1950 to 2010, there were 394 National Climatic Data Center reportable events causing 617 injuries, and 99 fatalities. There were 9 reported tornadoes, reaching a maximum of F2, with no recorded fatalities.\nDemographics.\nFor much of the 1800s and 1900s, Howard County was a predominantly white and mainly rural county with a small population. In 1950, the population was only 23,000. Since the 1950s, the county's population has increased tenfold and has diversified into a majority minority county. Almost half of Howard County's population identified as non-Hispanic and/or non-white by 2017. Much of the racial diversification of Howard County came after 1967, when The Rouse Company designed Columbia to be a planned community that included people from diverse socioeconomic and racial backgrounds. African-Americans have lived in Howard County for centuries, with the African-American population increasing greatly after the 1960s. Immigration from Asia, particularly Korea, India, and China, as well as Latin America, has also contributed to Howard County's diversity. While historically primarily Christian, Howard County now has sizable Jewish, Muslim, and Hindu populations. As of 2019, 18,700 Jewish people lived in the county, making up 5.8% of the total population. More than 6,000 non-Jewish people in the county have Jewish people in their households. As of 2010, only 1% of Jews in the county were Orthodox, while one-third each were Conservative and Reform and one-quarter were secular or non-denominational. In the same year, one-quarter of the Jewish community were poor or financially insecure, 17% made less than $50,000 per year, and half made annual incomes of $100,000 or more.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2020 census.\nAs of the 2020 United States census, there were 328,200\u00a0people by June 1, 2020 The population density was \n2010 census.\nAs of the 2010 United States census, there were 287,085\u00a0people, 104,749\u00a0households, and 76,333\u00a0families residing in the county. The population density was . There were 109,282 housing units at an average density of . The racial makeup of the county was 62.2% white, 17.5% Black or African American, 14.4% Asian, 0.3% American Indian, 2.0% from other races, and 3.6% from two or more races. Those of Hispanic or Latino origin made up 5.8% of the population. In terms of ancestry, 17.7% were German, 13.9% were Irish, 10.6% were English, 7.0% were Italian, and 4.6% were American.\nOf the 104,749\u00a0households, 39.3% had children under the age of 18 living with them, 58.9% were married couples living together, 10.5% had a female householder with no husband present, 27.1% were non-families, and 21.9% of all households were made up of individuals. The average household size was 2.72, and the average family size was 3.20. The median age was 38.4 years.\nThe median income for a household in the county was $103,273, and the median income for a family was $119,810. Males had a median income of $82,307 versus $59,128 for females. The per capita income for the county was $45,294. About 2.8% of families and 4.2% of the population were below the poverty line, including 4.6% of those under age 18 and 5.5% of those age 65 or over.\n2000 census.\nAs of the census of 2000, there were 247,842 people, 90,043 households, and 65,821 families residing in the county. The population density was . There were 92,818 housing units at an average density of . The racial makeup of the county was 74.33% White, 14.42% Black, 0.24% Native American, 7.68% Asian, 0.04% Pacific Islander, 1.11% from other races, and 2.19% from two or more races. 3.02% of the population were Hispanic or Latino of any race. 15.1% were of German, 11.0% Irish, 9.3% English, 6.6% Italian and 5.7% American ancestry.\nThere were 90,043 households, out of which 40.00% had children under the age of 18 living with them, 60.50% were married couples living together, 9.50% had a female householder with no husband present, and 26.90% were non-families. 20.80% of all households were made up of individuals, and 4.60% had someone living alone who was 65 years of age or older. The average household size was 2.71, and the average family size was 3.18.\nIn the county, the population was spread out, with 28.10% under the age of 18, 6.30% from 18 to 24, 34.40% from 25 to 44, 23.80% from 45 to 64, and 7.50% who were 65 years of age or older. The median age was 36 years. For every 100 females, there were 96.60 males. For every 100 females age 18 and over, there were 92.90 males.\nThe median income for a household in the county was $101,003, and the median income for a family was $117,186 in 2009. The per capita income was $44,120. About 2.70% of families and 4.00% of the population were below the poverty line.\nEducation.\nThe Howard County Public School System, the school district for the entire county, manages 71 schools and serves approximately 49,000 students. The graduation rate from this school district was 90.4% in 2009, and the county's schools are ranked among the best in the state. Student test scores consistently top the list for all Maryland school districts. Reservoir High School is currently the largest school in the county with over 1,900 students.\nLibrary.\nIn 2013 Howard County Library System was selected as the Library of the Year by \"Library Journal\" and cited by editor-at-large, John N. Berry, as \"a 21st-century library model, with a position, doctrine, purpose, and curriculum worthy of study and consideration by every library in America, if not the world.\" In 2015 the Howard County Library System was designated the top Star Library in its class.\nPolitics and government.\nHoward County has voted for the Democratic presidential candidate in every election from 1992 on. In the 2020 presidential election, Democratic Party candidate Joe Biden received the highest percentage of Howard County's votes of any presidential candidate in the history of the county. The less populated western and northern parts of Howard County lean Republican. The more heavily populated southern and eastern parts are heavily Democratic.\nHoward County has a record of acting as a bellwether in state-wide elections since the late 20th century: Since at least the 1950s, Howard County has voted for the successful senatorial candidate in both Maryland's Class I and Class III seats, and since 1998 the county has voted for the successful gubernatorial candidate, voting for Republican Bob Ehrlich in the 2002 gubernatorial election, Democrat Martin O'Malley in 2006 and 2010, Republican Larry Hogan in 2014 and 2018, and Democrat Wes Moore in 2022. Since 1984, the county has also voted for the state-wide presidential winner, a streak of 10 straight presidential elections.\nAt the state level of government, Howard County is represented by nine Democrats in the Maryland House of Delegates and three Democrats in the Maryland Senate. One Democratic state senator from the county represents a district that spills into Montgomery County to the west, as do two Democratic state delegates. Another Democratic state senator represents a district that splits into Anne Arundel County to the south-east, along with two Democratic state delegates.\nFrom 1914 to 1968, Howard County was governed by a system of three elected commissioners with four-year terms. Prior to 1962, the only polling location in the county was located in Ellicott City. In May 1962, voters were offered a second location to vote, also in Ellicott City at the National Armory on Montgomery Road. Senator James Clark Jr. proposed a five-person County Council and a County Executive in 1965. In 1968, the county implemented a charter form of government. In 1984 a councilmanic referendum was approved, switching council from at-large representation to district representation. The County Council serves as the county's legislative branch; members also provide constituent service and sit as members of the Zoning Board and Liquor Board. The current Howard County Executive is Democrat Calvin Ball III, who was elected in November 2018 and took office on December 3, 2018. The county is entirely within Maryland's 3rd congressional district, represented by Democrat Sarah Elfreth.\nCounty Council.\nThe County Council adopts ordinances and resolutions, and has all of the county's legislative powers. There are five council districts throughout the county. The current County Council as of December 2022 includes 4 Democrats and 1 Republican.\nEconomy.\nStatistics for July 2014 indicate that Howard County's unemployment rate is at 5.2 percent (7,527 persons).\nHoward County Public School System employs 8,136 of which 4,670 are teachers. The County Government employs 3,323 outside of the school system with 672 police, 482 public works, and 472 fire and rescue employees. The top ten private sector employers in Howard County are as follows:\nAwards.\nAwards and recognitions achieved by Howard County or locations within it include the following:\nTransportation.\nAirports.\nHoward County does not have any commercial or public-use airport facilities. A 1967 Airport Study Commission recommended a facility for 150\u2013250 aircraft to provide economic development, but was not initiated. With the closure of Haysfield Airport in 2012, there is one privately owned airstrip, Glenair Airport in Glenelg. Commercial air service is provided by Baltimore/Washington International Airport, Ronald Reagan Washington National Airport, and Washington Dulles International Airport.\nMajor highways.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCommunities.\nCensus-designated places.\nThe Census Bureau recognizes the following Census-designated places in the county:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nUnincorporated communities.\nUnincorporated places not listed as Census-designated places but known in the area include:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47732", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=47732", "title": "Fourier-transform spectroscopy", "text": "Spectroscopy based on time- or space-domain data\nFourier-transform spectroscopy (FTS) is a measurement technique whereby spectra are collected based on measurements of the coherence of a radiative source, using time-domain or space-domain measurements of the radiation, electromagnetic or not. It can be applied to a variety of types of \"spectroscopy\" including optical spectroscopy, infrared spectroscopy (FTIR, FT-NIRS), nuclear magnetic resonance (NMR) and magnetic resonance spectroscopic imaging (MRSI), mass spectrometry and electron spin resonance spectroscopy. \nThere are several methods for measuring the temporal coherence of the light (see: field-autocorrelation), including the continuous-wave and the pulsed Fourier-transform spectrometer or Fourier-transform spectrograph.\nThe term \"Fourier-transform spectroscopy\" reflects the fact that in all these techniques, a Fourier transform is required to turn the raw data into the actual spectrum, and in many of the cases in optics involving interferometers, is based on the Wiener\u2013Khinchin theorem.\nConceptual introduction.\nMeasuring an emission spectrum.\nOne of the most basic tasks in spectroscopy is to characterize the spectrum of a light source: how much light is emitted at each different wavelength. The most straightforward way to measure a spectrum is to pass the light through a monochromator, an instrument that blocks all of the light \"except\" the light at a certain wavelength (the un-blocked wavelength is set by a knob on the monochromator). Then the intensity of this remaining (single-wavelength) light is measured. The measured intensity directly indicates how much light is emitted at that wavelength. By varying the monochromator's wavelength setting, the full spectrum can be measured. This simple scheme in fact describes how \"some\" spectrometers work.\nFourier-transform spectroscopy is a less intuitive way to get the same information. Rather than allowing only one wavelength at a time to pass through to the detector, this technique lets through a beam containing many different wavelengths of light at once, and measures the \"total\" beam intensity. Next, the beam is modified to contain a \"different\" combination of wavelengths, giving a second data point. This process is repeated many times. Afterwards, a computer takes all this data and works backwards to infer how much light there is at each wavelength.\nTo be more specific, between the light source and the detector, there is a certain configuration of mirrors that allows some wavelengths to pass through but blocks others (due to wave interference). The beam is modified for each new data point by moving one of the mirrors; this changes the set of wavelengths that can pass through.\nAs mentioned, computer processing is required to turn the raw data (light intensity for each mirror position) into the desired result (light intensity for each wavelength). The processing required turns out to be a common algorithm called the Fourier transform (hence the name, \"Fourier-transform spectroscopy\"). The raw data is sometimes called an \"interferogram\". Because of the existing computer equipment requirements, and the ability of light to analyze very small amounts of substance, it is often beneficial to automate many aspects of the sample preparation. The sample can be better preserved and the results are much easier to replicate. Both of these benefits are important, for instance, in testing situations that may later involve legal action, such as those involving drug specimens.\nMeasuring an absorption spectrum.\nThe method of Fourier-transform spectroscopy can also be used for absorption spectroscopy. The primary example is \"FTIR Spectroscopy\", a common technique in chemistry.\nIn general, the goal of absorption spectroscopy is to measure how well a sample absorbs or transmits light at each different wavelength. Although absorption spectroscopy and emission spectroscopy are different in principle, they are closely related in practice; any technique for emission spectroscopy can also be used for absorption spectroscopy. First, the emission spectrum of a broadband lamp is measured (this is called the \"background spectrum\"). Second, the emission spectrum of the same lamp \"shining through the sample\" is measured (this is called the \"sample spectrum\"). The sample will absorb some of the light, causing the spectra to be different. The ratio of the \"sample spectrum\" to the \"background spectrum\" is directly related to the sample's absorption spectrum.\nAccordingly, the technique of \"Fourier-transform spectroscopy\" can be used both for measuring emission spectra (for example, the emission spectrum of a star), \"and\" absorption spectra (for example, the absorption spectrum of a liquid).\nContinuous-wave \"Michelson\" or \"Fourier-transform\" spectrograph.\nThe Michelson spectrograph is similar to the instrument used in the Michelson\u2013Morley experiment. Light from the source is split into two beams by a half-silvered mirror, one is reflected off a fixed mirror and one off a movable mirror, which introduces a time delay\u2014the Fourier-transform spectrometer is just a Michelson interferometer with a movable mirror. The beams interfere, allowing the temporal coherence of the light to be measured at each different time delay setting, effectively converting the time domain into a spatial coordinate. By making measurements of the signal at many discrete positions of the movable mirror, the spectrum can be reconstructed using a Fourier transform of the temporal coherence of the light. Michelson spectrographs are capable of very high spectral resolution observations of very bright sources.\nThe Michelson or Fourier-transform spectrograph was popular for infra-red applications at a time when infra-red astronomy only had single-pixel detectors. Imaging Michelson spectrometers are a possibility, but in general have been supplanted by imaging Fabry\u2013P\u00e9rot instruments, which are easier to construct.\nExtracting the spectrum.\nThe intensity as a function of the path length difference (also denoted as retardation) in the interferometer formula_1 and wavenumber formula_2 is \nformula_3\nwhere formula_4 is the spectrum to be determined. Note that it is not necessary for formula_4 to be modulated by the sample before the interferometer. In fact, most FTIR spectrometers place the sample after the interferometer in the optical path. The total intensity at the detector is\n formula_6\nThis is just a Fourier cosine transform. The inverse gives us our desired result in terms of the measured quantity formula_7:\nformula_8\nPulsed Fourier-transform spectrometer.\nA pulsed Fourier-transform spectrometer does not employ transmittance techniques. In the most general description of pulsed FT spectrometry, a sample is exposed to an energizing event which causes a periodic response. The frequency of the periodic response, as governed by the field conditions in the spectrometer, is indicative of the measured properties of the analyte.\nExamples of pulsed Fourier-transform spectrometry.\nIn magnetic spectroscopy (EPR, NMR), a microwave pulse (EPR) or a radio frequency pulse (NMR) in a strong ambient magnetic field is used as the energizing event. This turns the magnetic particles at an angle to the ambient field, resulting in gyration. The gyrating spins then induce a periodic current in a detector coil. Each spin exhibits a characteristic frequency of gyration (relative to the field strength) which reveals information about the analyte.\nIn Fourier-transform mass spectrometry, the energizing event is the injection of the charged sample into the strong electromagnetic field of a cyclotron. These particles travel in circles, inducing a current in a fixed coil on one point in their circle. Each traveling particle exhibits a characteristic cyclotron frequency-field ratio revealing the masses in the sample.\nFree induction decay.\nPulsed FT spectrometry gives the advantage of requiring a single, time-dependent measurement which can easily deconvolute a set of similar but distinct signals. The resulting composite signal, is called a \"free induction decay,\" because typically the signal will decay due to inhomogeneities in sample frequency, or simply unrecoverable loss of signal due to entropic loss of the property being measured.\nNanoscale spectroscopy with pulsed sources.\nPulsed sources allow for the utilization of Fourier-transform spectroscopy principles in scanning near-field optical microscopy techniques. Particularly in nano-FTIR, where the scattering from a sharp probe-tip is used to perform spectroscopy of samples with nanoscale spatial resolution, a high-power illumination from pulsed infrared lasers makes up for a relatively small scattering efficiency (often &lt; 1%) of the probe.\nStationary forms of Fourier-transform spectrometers.\nIn addition to the scanning forms of Fourier-transform spectrometers, there are a number of stationary or self-scanned forms. While the analysis of the interferometric output is similar to that of the typical scanning interferometer, significant differences apply, as shown in the published analyses. Some stationary forms retain the Fellgett multiplex advantage, and their use in the spectral region where detector noise limits apply is similar to the scanning forms of the FTS. In the photon-noise limited region, the application of stationary interferometers is dictated by specific consideration for the spectral region and the application.\nFellgett advantage.\nOne of the most important advantages of Fourier-transform spectroscopy was shown by P. B. Fellgett, an early advocate of the method. The Fellgett advantage, also known as the multiplex principle, states that when obtaining a spectrum when measurement noise is dominated by detector noise (which is independent of the power of radiation incident on the detector), a multiplex spectrometer such as a Fourier-transform spectrometer will produce a relative improvement in signal-to-noise ratio, compared to an equivalent scanning monochromator, of the order of the square root of \"m\", where \"m\" is the number of sample points comprising the spectrum. However, if the detector is shot-noise dominated, the noise will be proportional to the square root of the power, thus for a broad boxcar spectrum (continuous broadband source), the noise is proportional to the square root of \"m\", thus precisely offset the Fellgett's advantage. For line emission sources the situation is even worse and there is a distinct `multiplex disadvantage' as the shot noise from a strong emission component will overwhelm the fainter components of the spectrum. Shot noise is the main reason Fourier-transform spectrometry was never popular for ultraviolet (UV) and visible spectra.\nMeasurement of real-time periodic dynamics.\nFourier-transform spectroscopy can also be used for measuring real-time periodic spectral intensity dynamics. Consider an electric field component formula_9 being a periodic function of modulation frequency formula_10, its information content measured by a Fourier-transform spectrometer is given by:\n formula_11\nwhere formula_12 is the Doppler frequency, and the field dynamics has been expanded into a Fourier series. The field dynamics in formula_13 can be measured at the frequency domain at isolated RF frequencies of formula_14. By encoding the broadband coherent light source with common and fixed formula_10, periodic spectral intensity dynamics can be simultaneously readout for light components at different formula_12. \nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47733", "revid": "11308236", "url": "https://en.wikipedia.org/wiki?curid=47733", "title": "Ramanujan (disambiguation)", "text": "Srinivasa Ramanujan (1887\u20131920) was an Indian mathematician.\nRamanujan may refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "47734", "revid": "44507996", "url": "https://en.wikipedia.org/wiki?curid=47734", "title": "Chhattisgarh", "text": "State in central India\nChhattisgarh (; ) is a landlocked state in Central India. It is the ninth largest state by area, and with a population of roughly 30 million, the seventeenth most populous. It borders seven states \u2013 Uttar Pradesh to the north, Madhya Pradesh to the northwest, Maharashtra to the southwest, Jharkhand to the northeast, Odisha to the east, Andhra Pradesh and Telangana to the south. Formerly a part of Madhya Pradesh, it was granted statehood on 1 November 2000 with Raipur as the designated state capital.\nThe Sitabenga caves in Chhattisgarh, one of the earliest examples of theatre architecture in India, are dated to the Mauryan period of 3rd century BCE.\nThe region was split between rivaling dynasties from the sixth to twelfth centuries, and parts of it were briefly under the Chola dynasty in the 11th century. Eventually, most of Chhattisgarh was consolidated under the Kingdom of Haihaiyavansi, whose rule lasted for 700 years until they were brought under Maratha suzerainty in 1740. The Bhonsles of Nagpur incorporated Chhattisgarh into the Kingdom of Nagpur in 1758 and ruled until 1845, when the region was annexed by the East India Company, and was later administered under the Raj until 1947 as the Chhattisgarh Division of the Central Provinces. Some areas constituting present-day Chhattisgarh were princely states that were later merged into Madhya Pradesh. The States Reorganisation Act, 1956 placed Chhattisgarh in Madhya Pradesh, and it remained a part of that state for 44 years.\nChhattisgarh is one of the fastest-developing states in India. Its Gross State Domestic Product (GSDP) is () (2023\u201324 est.), with a per capita GSDP of \u20b9 (2023\u201324 est.). A resource-rich state, it has the third largest coal reserves in the country and provides electricity, coal, and steel to the rest of the nation. It also has the third largest forest cover in the country after Madhya Pradesh and Arunachal Pradesh with over 41.21% of the state covered by forests.\nEtymology.\nThere are several theories as to the origin of the name \"Chhattisgarh\", which in ancient times was known as Dakshina Kosala (South Kosala), the native place of Rama's mother Kausalya. \"Chhattisgarh\" was popularised later during the time of the Maratha Empire and was first used in an official document in 1795. The Bastar region was previously referred to as and .\nThe most popular theory claims that Chhattisgarh takes its name from the 36 ancient forts (from \"chhattis\" meaning thirty-six and \"garh\" meaning fort) in the area. The old state had 36 demesnes (feudal territories): Ratanpur, Vijaypur, Kharound, Maro, Kautgarh, Nawagarh, Sondhi, Aukhar, Padarbhatta, Semriya, Champa, Lafa, Chhuri, Kenda, Matin, Aparora, Pendra, Kurkuti-kandri, Raipur, Patan, Simaga, Singarpur, Lavan, Omera, Durg, Saradha, Sirasa, Menhadi, Khallari, Sirpur, Figeswar, Rajim, Singhangarh, Suvarmar, Tenganagarh and Akaltara. However, most historians disagree with this theory as 36 forts have not been found and identified.\nAccording to the opinion of Hiralal, it is said that at one time there were 36 strongholds in this area, that is why its name was Chhattisgarh. But even after the increase in the number of strongholds, there was no change in the name, Chhattisgarh is the State of India which has been given the status of 'Mahtari' (Mother). There are two regions in India which are named for special reasons \u2013 one was 'Magadha' which became \"Bihar\" due to the abundance of Buddhism viharas and the other was 'Dakshina Kosala' which became \"Chhattisgarh\" due to the inclusion of thirty-six strongholds.\nAnother view, more popular with experts and historians, is that Chhattisgarh is the corrupted form of \"Chedisgarh\" meaning \"Raj\" or \"Empire of the Chedis\". In ancient times, Chhattisgarh region had been part of the Chedi dynasty of Kalinga, in modern Odisha. In the medieval period up to 1803, a major portion of present eastern Chhattisgarh was part of the Sambalpur Kingdom of Odisha.\nHistory.\nAncient and medieval history.\nDuring post Vedic period the Chhattisgarh region south-east to Da\u015b\u0101r\u1e47as was referred as Pulinda. Pulinda tribe were dominating tribe in this region.\nSurguja District of Chhattisgarh is notable for finding of Mauryan and Nanda period coins. Few gold and silver coins of the Nanda - Mauryan ages, picked up at Akaltara and Thathari of the adjacent district of Bilaspur. Another major discovery was Sirpur of Chhattisgarh. According to the Chinese traveler Hiuen Tsang, Ashoka erected Buddhist stupas in Shripura (modern-day Sirpur), the ancient capital of Dakshina Kosala.\nSitabenga caves are one of the earliest examples of theatre architecture in India located on Ramgarh hill of Chhattisgarh dated to Mauryan period of 3rd century BCE.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\n&lt;poem&gt;\nLine1 \"Poets venerable by nature kindle the heart, who\" (... lost ...)\nLine2 \"At the swing-festival of the vernal full-moon, when frolics and music abound, people thus tie (...lost...) thick with jasmine flowers.\"\n&lt;/poem&gt;\nJogimara caves contain ancient Brahmi inscription and the oldest painting known in India. The inscription can be translated as either a love proclamation by a girl or a dancer-painter creating a cave theatre together. In ancient times, this region was known as Dakshina Kosala. This area is also mentioned in Ramayana and Mahabharata.One of the earliest statues of Vishnu has been excavated from Shunga period site at Malhar.\nThe plains region of Chhattisgarh was formerly under the Mauryas, although they likely did not exercise much direct control in the region. After the collapse of the Mauryas, Kharavela of the Mahameghavahana dynasty, which was based in neighbouring Kalinga, took over most of Dakshina Kosala. Later in the third century, the Sathavahanas took over Dakshina Kosala, but this was contested and it returned to Megha rule. Mahendra of Dakshina Kosala, who is believed to be identified with a Megha monarch, was the ruler when Samudragupta carried out his Dakshinapatha conquests and conquered Dakshina Kosala, as recorded in Gupta inscriptions in the early 4th century CE. Afterwards the Guptas held control over Chhattisgarh through vassal rulers, and shared control with the contemporaneous Vakatakas. In the late 5th century CE, the Vakataka ruler Harisena recorded his conquest of the Dakshina Kosala region.\nAfter the death of Vakataka ruler Harisena, the Rajarsitulyakula dynasty centred at Arang, former Gupta feudatories, took power and briefly ruled all of Dakshina Kosala. They were contemporaneous with the Nala dynasty, which was centered on the Bastar and Koraput regions. Both these dynasties were succeeded by the Sharabhpurias in the early 6th century, who were likely also former Gupta vassals who had their capital at present-day Sirpur. The Panduvanshis of Mekala, centered in the northern Chhattisgarh plain, and the Panduvamshis of Dakshina Kosala both ruled parts of Chhattisgarh, but the chronology of these kingdoms is not certain. These kingdoms variously controlled the region from the 6th to 8th centuries CE. There is some evidence that the Somavanshis, who later gained power in Kalinga, originated from the Panduvanshis of Dakshina Kosala and were driven out by the Kalachuris of Tripuri in the late 8th century. The Kalachuris of Tripuri held on to the region for the next 200 years, splitting off their territories in Kosala in the late 10th century to be given to a vassal branch which also called itself Kalachuris.\nThe Kalachuris of Ratnapura, who were these vassals, became independent at the start of the 11th century to rule and fight off challenges to their authority by neighbouring kingdoms, most notably the Eastern Gangas. The last known successor is from the late 13th century, after which the records become less available. By the early 14th century, it appears as if the dynasty split into two branches: one ruling from Ratnapur and another moving to Raipur. This is attested to by inscriptions of the king Vahara in the late 15th century, identified with a figure Bahar Sahai in local tradition at the end of the 18th century. Vahara fought against the Afghans and shifted the capital to Kosgain from Ratnapur. These rulers are now identified as the Haihaiyavanshis and acknowledged the nominal overlordship of the Mughals when they arrived. In the late 14th century, Bastar was ruled by a dynasty which claimed descent from the brother of Prataparudra, the last Kakatiya king, Annamaraja.\nMost of Chhattisgarh was consolidated under the Haihaiyavanshi Kingdom, who ruled central Chhattisgarh and held smaller kingdoms like Kanker under their authority. The Haihaiyavanshis continued to rule the region for 700 years until they were invaded by the Marathas in 1740 and came under their authority. Chhattisgarh was directly annexed to the Maratha Nagpur Kingdom in 1758 on the death of Mohan Singh, the last independent ruler of Chhattisgarh.\nModern history.\nChhattisgarh was under Maratha Rule (Bhonsles of Nagpur) from 1741 to 1845. It came under British rule from 1845 to 1947 as the Chhattisgarh Division of the Central Provinces. Raipur gained prominence over the capital Ratanpur with the advent of the British in 1845. In 1905, the Sambalpur district was transferred to Odisha and the estates of Surguja were transferred from Bengal to Chhattisgarh.\nThe area constituting the new state merged into Madhya Pradesh on 1 November 1956, under the States Reorganisation Act, 1956, and remained a part of that state for 44 years. Prior to that, the region was part of the Central Provinces and Berar (CP and Berar) under British rule. Some areas constituting the Chhattisgarh state were princely states under British rule, but were later on merged into Madhya Pradesh.\nSeparation of Chhattisgarh.\nThe demand for Chhattisgarh to be a separate state first rose in the 1920s, with similar demands appearing at regular intervals; however, a well-organised movement was never initiated. Several all-party platforms were created and usually resolved around petitions, public meetings, seminars, rallies and strikes. The demand was raised by the Raipur Congress unit in 1924 and was also discussed in the Indian Congress at Tripuri. A discussion about forming a Regional Congress organisation for Chhattisgarh took place. In 1954, when the State Reorganisation Commission was set up, the demand was put forward but was rejected. In 1955, the demand was raised in the Nagpur assembly of Madhya Bharat.\nIn the 1990s, the demand became more prominent, resulting in the formation of a statewide political forum known as the Chhattisgarh Rajya Nirman Manch. The forum was led by Chandulal Chadrakar and several successful region-wide strikes and rallies were organised under it, all of which were supported by major political parties, such as the Indian National Congress and the Bharatiya Janata Party.\nThe new National Democratic Alliance government sent the Separate Chhattisgarh Bill for approval by the Madhya Pradesh Assembly, where it was unanimously approved and then submitted to the Lok Sabha. The bill was passed in the Lok Sabha and the Rajya Sabha, which allowed the creation of the state of Chhattisgarh. K. R. Narayanan gave his consent to the Madhya Pradesh Reorganisation Act on 25 August 2000 and the government of India set 1 November 2000 as the day Chhattisgarh would be separated from Madhya Pradesh. As such, Chhattisgarh was formed from Madhya Pradesh.\nGeography.\nThe northern and southern parts of the state are hilly, while the central part is a fertile plain. The highest point in the state is the Gaurlata near Samri, Balrampur-Ramanujganj district. Deciduous forests of the Eastern Highlands Forests cover roughly 44% of the state.\nIn the north lies the edge of the great Indo-Gangetic plain. The Rihand River, a tributary of the Ganges, drains this area. The eastern end of the Satpura Range and the western edge of the Chota Nagpur Plateau form an east\u2013west belt of hills that divide the Mahanadi River basin from the Indo-Gangetic plain. The outline of Chhattisgarh is like a sea horse.\nThe central part of the state lies in the fertile upper basin of the Mahanadi and its tributaries, of which Shivnath River is a major one running around 300\u00a0km long. This area has extensive rice cultivation. The upper Mahanadi basin is separated from the upper Narmada basin to the west by the Maikal Hills (part of the Satpuras) and from the plains of Odisha to the east by ranges of hills. The southern part of the state lies on the Deccan plateau, in the watershed of the Godavari River and its tributary, the Indravati River. The Mahanadi is the chief river of the state. The other main rivers are Hasdeo (a tributary of Mahanadi), Rihand, Indravati, Jonk, Arpa and Shivnath.\nForest.\nThe state has the third largest forest by area in India. The state animal is the \"van bhainsa\", or wild Asian buffalo. The state bird is the \"pahari myna\", or hill myna. The state tree is the Sal (Sarai) found in Bastar division.\nChhattisgarh has the 3rd largest forest cover in the country. The state is surrounded by the forests in Madhya Pradesh (1st), Odisha (4th), Maharashtra (5th), Jharkhand and Telangana making it India's largest covered forests across state boundaries. There are multiple National Parks, Tiger Reserves across the state. Achanakmar-Amarkantak Biosphere Reserve is UNESCO recognised Biosphere with total area of \nClimate.\nChhattisgarh has a tropical climate. It is hot and humid in the summer because of its proximity to the Tropic of Cancer and its dependence on the monsoons for rains. Summer temperatures in Chhattisgarh can reach up to . The monsoon season is from late June to October and is a welcome respite from the heat. Chhattisgarh receives an average of of rain. Winter is from November to January. Winters are pleasant with low temperatures and less humidity. Ambikapur, Mainpat, Pendra Road, Samri and Jashpur are some of the coldest places in the state.\nTransport.\nRoads.\nChhattisgarh has four-lane or two-lane roads that provide connectivity to major cities. A total of 20 national highways pass through the state, together measuring . Many national highways exist only on paper and are not fully converted into four-lane, let alone six-lane or eight-lane, highways. These include:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nThe state highways and major district roads constitute another network of .\nRail network.\nAlmost the entire railway network spread over the state comes under the geographical jurisdiction of the South East Central Railway Zone of Indian Railways centred around Bilaspur, which is the zonal headquarters of this zone. Almost 85% of tracks are electrified, the non-electrified route is the Maroda\u2013Bhanupratappur line from the Durg\u2013Bhanupratappur branch line, which is 120\u00a0km long. The main railway junctions are Bilaspur Junction, Durg Junction, and Raipur, which is also a starting point of many long-distance trains. These three junctions are well-connected to the major cities of India and also these station comes under the top 50 booking stations in India.\nThe state has the highest freight loading in the country, and one-sixth of the Indian Railway's revenue comes from Chhattisgarh. The length of the rail network in the state is 1,108\u00a0km, while a third track has been commissioned between Durg and Raigarh. Construction of some new railway lines include Dalli\u2013Rajhara\u2013Jagdalpur rail line, Pendra Road\u2013Gevra Road rail line, Raigarh\u2013Mand Colliery to Bhupdeopur rail line and Barwadih\u2013Chirmiri rail line. Freight/goods trains provide services mostly to coal and iron ore industries in east\u2013west corridor (Mumbai\u2013Howrah route). There is a lack of passenger services to the north and south of Chhattisgarh.\nMajor railway stations of Chhattisgarh.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nAir.\nThe air infrastructure in Chhattisgarh is gradually improving. Swami Vivekananda Airport in Raipur is the primary airport (domestic) and is well connected to all major cities of India. Besides this, the smaller Bilaspur Airport, Jagdalpur Airport and Ambikapur Airport are regionally connected with scheduled commercial services. A massive reduction in sales tax on aviation turbine fuel (ATF) from 25 to 4% in Chhattisgarh in 2003 contributed to a sharp rise in passenger flow. The passenger flow increased by 58% between 2011 and November 2012.\nGovernance.\nThe State Legislative Assembly is composed of 90 members of the Legislative Assembly. There are 11 members of the Lok Sabha from Chhattisgarh. The Rajya Sabha has five members from the state\nAdministration.\nDistricts.\nChhattisgarh comprises 33 districts. The following are the list of the districts of Chhattisgarh State with major cities:\nEconomy.\nChhattisgarh's nominal gross state domestic product (GSDP) is estimated at () in 2023\u201324, the 17th largest state economy in India. The economy of Chhattisgarh recorded a growth rate of 11.2% in 2023\u201324. Chhattisgarh's success factors in achieving high growth rate are growth in agriculture and industrial production.\nAgriculture.\nAgriculture is counted as the chief economic occupation of the state. According to a government estimate, the net sown area of the state is 4.828\u00a0million hectares and the gross sown area is 5.788\u00a0million hectares. Horticulture and animal husbandry also engage a major share of the total population of the state. About 80% of the population of the state is rural and the main livelihood of the villagers is agriculture and agriculture-based small industry.\nThe majority of the farmers are still practicing the traditional methods of cultivation, resulting in low growth rates and productivity. The farmers have to be made aware of modern technologies suitable to their holdings. Providing adequate knowledge to the farmers is essential for a better implementation of the agricultural development plans and to improve productivity.\nConsidering this and a very limited irrigated area, the productivity of not only rice but also other crops is low, hence the farmers are unable to obtain economic benefits from agriculture and it has remained as subsistence agriculture till now.\nAgricultural products.\nThe main crops are rice, maize, \"kodo-kutki\" and other small millets and pulses (\"tuar\" and \"kulthi\"); oilseeds, such as groundnuts (peanuts), soybeans and sunflowers are also grown. In the mid-1990s, most of Chhattisgarh was still a monocrop belt. Only one-fourth to one-fifth of the sown area was double-cropped. When a very substantial portion of the population is dependent on agriculture, a situation where nearly 80% of a state's area is covered only by one crop, immediate attention to turn them into double crop areas is needed. Also, very few cash crops are grown in Chhattisgarh, so there is a need to diversify the agricultural produce towards oilseeds and other cash crops. Chhattisgarh is also called the \"rice bowl of central India\".\nIrrigation.\nIn Chhattisgarh, rice, the main crop, is grown on about 77% of the net sown area. Only about 20% of the area is under irrigation; the rest depends on rain. Of the three agroclimatic zones, about 73% of the Chhattisgarh plains, 97% of the Bastar plateau, and 95% of the northern hills are rainfed. The irrigated area available for double cropping is only 87,000\u00a0ha in the Chhattisgarh plains and 2300\u00a0ha in Bastar plateau and northern hills. Due to this, the productivity of rice and other crops is low, hence the farmers are unable to obtain economic benefits from agriculture and it has remained as subsistence agriculture till now, though agriculture is the main occupation of more than 80% of the population.\nIn the Chhattisgarh region, about 22% of the net cropped area was under irrigation as compared to 36.5% in Madhya Pradesh in 1998\u201399, whereas the average national irrigation was about 40%. The irrigation is characterised by a high order of variability ranging from 1.6% in Bastar to 75.0% in Dhamtari. Based on an average growth trend in the irrigated area, about 0.43% of additional area is brought under irrigation every year as compared to 1.89% in Madhya Pradesh and 1.0% in the country as a whole. Thus, irrigation has been growing at a very low rate in Chhattisgarh and the pace of irrigation is so slow, that it would take about 122 years to reach the 75% level of net irrigated area in Chhattisgarh at the present rate of growth.\nChhattisgarh has a limited irrigation system, with dams and canals on some rivers. Average rainfall in the state is around 1400\u00a0mm and the entire state falls under the rice agroclimatic zone. The Large variation in the yearly rainfall directly affects the production of rice. Irrigation is the prime need of the state for its overall development and therefore the state government has given top priority to the development of irrigation.\nA total of four major, 33 medium, and 2199 minor irrigation projects have been completed and five major, nine medium, and 312 minor projects are under construction, as of 31 March 2006.\nIndustrial sector.\nPower sector.\nChhattisgarh is one of the few states of India where the power sector is effectively developed. Based on the current production of surplus electric power, the position of the State is comfortable and profitable. The Chhattisgarh State Electricity Board (CSEB) is in a strong position to meet the electricity requirement of the state and is in good financial health. According to Central Electricity Authority (CEA), Chhattisgarh provides electricity to several other states because of surplus production.\nIn Chhattisgarh, National Thermal Power Corporation Limited (NTPC) has Sipat Thermal Power Station with a capacity of 2,980 MW at Sipat, Bilaspur; LARA Super Thermal Power Station with a nameplate capacity of 1600MW and Korba Super Thermal Power Station with a capacity of 2,600 MW at Korba, while CSEB's units have a thermal capacity of 1,780 MW and hydel capacity of 130 MW. Apart from NTPC and CSEB, there are several private generation units of large and small capacity. The state government has pursued a liberal policy with regard to captive generation which has resulted in a number of private companies coming up.\nThe state has a potential of 61,000 MW of additional thermal power in terms of availability of coal for more than 100 years and more than 2,500 MW hydel capacity. To use this vast potential, substantial additions to the existing generation capacity are already underway.\nSteel sector.\nThe steel industry is one of the biggest heavy industries of Chhattisgarh. Bhilai Steel Plant, Bhilai operated by SAIL, with a capacity of 5.4\u00a0million tonnes per year, is regarded as a significant growth indicator of the state. More than 100 steel rolling mills, 90 sponge iron plants, and ferro-alloy units are in Chhattisgarh. Along with Bhilai, today Jagdalpur, Raipur, Bilaspur, Korba and Raigarh have become the steel hub of Chhattisgarh. Today, Raipur and Jagdalpur has become the centre of the steel sector, the biggest market for steel in India.\nAluminium sector.\nThe aluminium industry of Chhattisgarh was established by the erstwhile Bharat Aluminium Company (now Vedanta Resources) in Korba, Chhattisgarh, which has a capacity of around 5,700,000 tonnes each year.\nNatural resources.\nGevra, Dipka, Kusmunda open cast coal mines in Korba are the largest in India and the biggest man-made structure visible in satellite images of India. Major coal companies are SECL, Adani, Jindal which operate multiple coal mines across northeast Chhattisgarh.\nCentral India Coalfields.\nThe Central India Coalfields are spread over the districts of Surguja, Koriya (both in Chhattisgarh), Shahdol and Umaria (both in Madhya Pradesh). The group covers an area of about with estimated reserves of 15,613.98 million tonnes. The deposits are at a depth of 0\u20131200 meters. Therefore, extraction is mainly amenable to underground mining except for a few blocks in the eastern part of these coalfields which have opencast potential.\nJhilimili Coalfield located in Surguja district is spread over an area of . Estimated total reserves are 215.31 million tonnes, out of which about half have been indicated to be Grade I. According to the Geological Survey of India, total reserves of non-coking coal (as of 1 January 2004) in Jhilimili Coalfield (up to a depth of 300m) was 267.10 million tonnes.\nThe Sonhat is a large coal field representing one of the largest coal reserves in India having estimated reserves of 2.67 billion tonnes of coal.\nBisrampur coal field represents one of the largest coal reserves in India having estimated reserves of 1.61 billion tonnes of coal.\nChirimiri Coalfield is located in the valley of the Hasdeo River, a tributary of the Mahanadi. Opened in 1930 with production starting in 1932, and has been owned by several companies and owners such as Chirimiri Colliery Company Pvt. Ltd., Dababhoy's New Chirimiri Ponri Hill Company (Private) Limited, United Collieries Limited, K.N. Dhady and Indra Singh &amp; Sons (Private) Limited. These were nationalized in 1973.\nThis coalfield is spread over of hilly country and includes both the sections \u2013 Kurasia and Chirimiri. Total reserves in the Chirimiri coalfield have been estimated to be around 312.11 million tonnes. According to Geological Survey of India reserves of non-coking coal up to a depth of 300 m in Chirimiri Coalfield was 362.16 million tonnes.\nSouth Chhattisgarh coalfields.\nThe South Chhattisgarh Coalfields are made up of the Mand Raigarh, Korba, and Hasdo Arand coalfields. Of at least twelve seams in the Mand Valley, the Mand and Taraimar seams are important.\nMand Raigarh Coalfield includes the areas earlier known as North Raigarh, South Raigarh, and Mand River Coalfields and is located in Raigarh district and lies in the valley of the Mand River, a tributary of the Mahanadi. This coalfield is spread over an area of . The field has a potential for mining power-grade coal, much of which can be extracted through open-cast mining. Gare block has been identified for captive mining by private companies.\nAccording to the Geological Survey of India total reserves (including proved, indicated, and inferred reserves) of non-coking coal in the Mand Raigarh Coalfield is 18,532.93 million tonnes. Out of this 13,868.20 million tonnes is up to a depth of 300 metres, 4569.51 million tonnes is at a depth of 300\u2013600 metres and 95.22 million tonnes is at a depth of 600\u20131200 m.\nMineral deposits.\nChhattisgarh is rich in minerals. It produces 50% of the country's total cement production. Due to its proximity to the western States of Maharashtra and Gujarat, it has the highest producing coal mines in India. It has the highest output of coal in the country with the second-highest reserves. It is third in iron ore production and first in tin production. Limestone, dolomite and bauxite are abundant. It is the only tin ore-producing state in India. Other commercially extracted minerals include corundum, garnet, quartz, marble, alexandrite and diamonds.\nRowghat iron ore deposits are located in the Antagarh Tahsil of Kanker district and contain the largest iron ore deposits after the Bailadila Iron Ore Mine. Rowghat Mines' reserves have been assessed at 731.93 Mn tonnes. Bailadila has reserves assessed at 1.343 Bn tonnes. Iron ore deposits in Rowghat were discovered in 1899 and in 1949 Geological Survey of India investigated the area.\nRowghat deposit is NNW of Narayanpur, and about from Jagdalpur. Fe content varies in the various blocks - A Block (62.58% Fe), B Block (50.29% Fe), C Block (57.00% Fe), D Block (60.00% Fe), E Block (52.93% Fe), and F Block (59.62% Fe).\nInformation and technologies.\nIn recent years, Chhattisgarh has also received exposure in information technology (IT) projects and consultancy. Its government is also promoting IT and has set up a body to take care of IT solutions. The body, known as CHiPS, is providing large IT projects such as Choice, Swan, and so forth.\nMajor companies.\nMajor companies with a presence in the state include:\nExports.\nChhattisgarh's total exports were US$353.3\u00a0million in 2009\u201310. Nearly 75% of exports come from Bhilai and the remaining are from Urla, Bhanpuri, and Sirgitti. The major export products include steel, handicrafts, handlooms, blended yarn, food and agri-products, iron, aluminum, cement, minerals, and engineering products. CSIDC (Chhattisgarh State Industrial Development Corporation Limited) is the nodal agency of the government of Chhattisgarh for export promotion in the state.\nMedia.\nMainline print media present in Chhattisgarh are Hari Bhoomi, Dainik Bhaskar, Patrika, Navabharat, and Nai Duniya.\nHuman Development Indicators.\nHDI.\nAs of 2018, Chhattisgarh state had a Human Development Index value of 0.613 (medium), ranking 31st in Indian states &amp; union territories. The national average is 0.647 according to Global Data Lab.\nStandard of living.\nThe standard of living in Chhattisgarh is extremely imbalanced. The cities such as Durg, Raipur, Bhilai and Bilaspur have a medium to high standard of living, while the rural and forested areas lack even the basic resources and amenities. For example, Bhilai has a literacy rate of 86%, while Bastar has a literacy rate of 54%.\nRaipur, the capital of Chhattisgarh, is one of the fastest-developing cities in India. Atal Nagar (Formerly \"Naya Raipur\") is the new planned city that is touted to become the financial hub of the Central Indian region. New world-class educational institutions and hospitals have already been established in the city.\nAccording to the NITI Aayog's Fiscal Health Index 2025, Chhattisgarh ranks second with a score of 55.2.\nEducation Index.\nChhattisgarh has an Education Index of 0.526 according to the 2011 NHDR, which is higher than that of the states of Bihar, Jharkhand, Uttar Pradesh, and Rajasthan. The Average Literacy rate in Chhattisgarh for Urban regions was 84.05 percent in which males were 90.58% literate while female literacy stood at 73.39%. Total literates in the urban region of Chhattisgarh were 4,370,966.\nAmong the marginalized groups, STs are at the bottom of the rankings, further emphasizing the lack of social development in the state. Bastar and Dantewada in south Chhattisgarh are the most illiterate districts and the dropout ratio is the highest among all the districts. The reason for this is the extreme poverty in rural areas.\nRamakrishna Mission Asharama Narainpur serves the tribals in the abhjhmad jungle region of Chhattisgarh for their upliftment and education.\nAs per census 2011, the State has a population of 25.5\u00a0million and six medical colleges (five Government and one private) with an intake capacity of 700 students and a doctor-patient ratio of 1:17,000.\nUnder The NITI Aayog released Health Index report titled, \"Healthy States, Progressive India\", Chhattisgarh has an index of 52.02 Out of 100, which is better than states such as Madhya Pradesh, Haryana, Rajasthan, Odisha, Bihar, Assam and Uttar Pradesh.\nDespite different health-related schemes and programs, the health indicators such as the percentage of women with BMI&lt;18.5, Under Five Mortality Rate and underweight children, are poor. This may be due to the difficulty in accessing the remote areas in the state. The prevalence of female malnutrition in Chhattisgarh is higher than the national average\u2014half of the ST females are malnourished. The performance of SCs is a little better than the corresponding national and state average. The Under Five Mortality Rate among STs is significantly higher than the national average.\nNet state domestic product.\nChhattisgarh is one of the emerging states with relatively high growth rates of net state domestic product (NSDP) (8.2% vs. 7.1% All India over 2002\u20132008) and per capita NSDP (6.2% vs. 5.4% All India over 2002\u20132008). The growth rates of the said parameters are above the national averages and thus it appears that Chhattisgarh is catching up with other states in this respect. However, the state still has very low levels of per capita income as compared to the other states.\nUrbanisation.\nOut of the total population of Chhattisgarh, 23.24% live in urban regions. The total population living in urban areas is 5,937,237, of which 3,035,469 are males and the remaining 2,901,768 are females.\nRaipur, Durg, Bhilai Nagar, Bilaspur, Korba, Jagdalpur, Rajnandgaon, Ambikapur and Raigarh are some of the urban towns and cities in the region.\nSex ratio.\nThere are more than 13 million males and 12.9\u00a0million females in Chhattisgarh, which constitutes 2.11% of the country's population. The sex ratio in the state is one of the most balanced in India with 991 females per 1,000 males, as is the child sex ratio with 964 females per 1,000 males (Census 2011)\nFertility rate.\nChhattisgarh has a fairly high fertility rate (2.4) as of 2017 compared to All India (2.2) and the replacement rate (2.1). It has a rural fertility rate of 2.6 and an urban fertility rate of 1.9\nSC and ST population.\nWith the exception of the hilly states of the north-east, Chhattisgarh has one of highest shares of Scheduled Tribe (ST) populations within a state, accounting for about 10 percent of the STs in India. Scheduled Tribes make up 30.62% of the population. The tribals are an important part of the state population and mainly inhabit the dense forests of Bastar and other districts of south Chhattisgarh. The percentage increase in the population of the scheduled list of tribals during the 2001\u20132011 decade had been at the rate of 18.23%. The Scheduled Caste (SC) population of Chhattisgarh is 2,418,722 as per the 2001 census constituting 11.6 percent of the total population (20,833,803). The proportion of Scheduled Castes has increased from 11.6 percent in 2001 to 12.8% in 2011.\nPoverty.\nThe incidence of poverty in Chhattisgarh is very high. The estimated poverty ratio in 2004\u201305 based on uniform reference period consumption was around 50 percent, which is approximately double the all-India level. The incidence of poverty in the rural and urban areas is almost the same.\nMore than half of the rural STs and urban SCs are poor. In general, the proportion of poor SC and ST households in the state is higher than the state average and their community's respective national averages (except for rural SC households). Given that more than 50 percent of the state's population is ST and SC, the high incidence of income poverty among them is a matter of serious concern in the state.\nThis indicates that the good economic performance in recent years has not percolated to this socially deprived group, which is reflected in their poor performance in human development indicators.\nAccess to drinking water.\nIn terms of access to improved drinking water sources, at the aggregate level, Chhattisgarh fared better than the national average and the SCs of the state performed better than the corresponding national average. Scheduled Tribes are marginally below the state average, but still better than the STs at the all-India level.\nThe proportion of households with access to improved sources of drinking water in 2008\u201309 was 91%. This proportion was over 90% even in states like Bihar, Chhattisgarh, Madhya Pradesh and Uttar Pradesh. This was largely because these states had over 70% of their households accessing tube wells/hand pumps as sources of drinking water.\nSanitation.\nSanitation facilities in the state were abysmally low with only about 41 percent having toilet facilities before the Swachh Bharat Mission was launched by the Government of India. The Urban areas of Chhattisgarh attained the title of open defecation free on 2 October 2017 and the rural areas have achieved a 90.31% sanitation coverage. What sets Chhattisgarh apart from other states of India is an approach to bring in behavioral change in order to get open defecation-free status. In Chhattisgarh, people don't get toilet incentives before the construction of toilets, so they have to construct the toilet with their own money, and only after using the toilet for 3 months are they entitled to the incentive amount.\nIn 2020, it again won the title of the cleanest state with more than 100 Urban Local Bodies, as announced by Minister for Housing and Urban Affairs Hardeep Singh Puri following the 'Swachh Survekshan 2020'. In the Swachh Survekshan Awards-2023, Chhattisgarh secured the third rank in the 'Best Performing States' category.\nTeledensity.\nAcross states, it has been found that teledensity (telephone density) was below 10 percent in 2010 for Chhattisgarh and Jharkhand, reflecting a lack of access to telephones in these relatively poorer states. But due to development of new technology the teledensity in 2017 is 68.08 percent which shows improvement of telecom infrastructure. On the other hand, for states like Delhi and Himachal Pradesh and metropolitan cities like Kolkata, Mumbai, and Chennai, teledensity was over 100 percent in 2010 implying that individuals have more than one telephone connection.\nRoad density.\nThe total density of National Highways (NHs) in Chhattisgarh is at 23.4\u00a0km per 1,000\u00a0km2 out of the total length of 3,168\u00a0km in the State, the Central Government has informed.\nChhattisgarh Government had completed construction of 5,266 cement concrete (CC) roads having a total length of 1,530\u00a0km in various villages of the State as on 31 May 2016 under 'Mukhyamantri Gram Sadak Yojana'.\nWitchcraft.\nTo bring about social reforms and with a view to discourage undesirable social practices, Chhattisgarh government has enacted the Chhattisgarh Tonhi Atyachar (Niwaran) Act, 2005 against witchery. Much has to be done on the issue of law enforcement by judicial authorities to protect women in this regard, bringing such persecution to an end.\nSome sections of tribal population of Chhattisgarh state believe in witchcraft. Women are believed to have access to supernatural forces and are accused of being witches (\"tonhi\") often to settle personal scores.\nAs of 2010, they are still hounded out of villages on the basis of flimsy accusations by male village sorcerers paid to do so by villagers with personal agendas, such as property and goods acquisition. According to National Geographic Channel's investigations, those accused are fortunate if they are only verbally bullied and shunned or exiled from their village.\nDemographics.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nChhattisgarh has an urban population of 23.4% (around 5.1\u00a0million people in 2011) residing in urban areas. According to a report by the government of India, at least 30% are Scheduled Tribes, 12% are Scheduled Castes and over 45.5% belong to the official list of Other Backward Classes. The plains are numerically dominated by castes such as Teli, Satnami and Yadav while forest areas are mainly occupied by tribes such as Gond, Halba, Kamar/Bujia and Oraon. There is also a major general population like Rajputs, Brahmin, Kurmi, Bania, etc. A community of Bengalis has existed in major cities since the times of the British Raj. They are associated with education, industry, and services.\nReligion.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nAccording to the 2011 census, 93.25% of Chhattisgarh's population practised Hinduism, while 2.02% followed Islam, 1.92% followed Christianity and a smaller number followed Buddhism, Sikhism, Jainism or other religions.\nHindus are the majority in the state and are the dominant religion in all districts of the state. One sect particular to Chhattisgarh are the Satnamis aka Satnampanthis, who follow Guru Ghasidas, a saint who promoted bhakti towards God and against the caste system. Chhattisgarh has many famous pilgrimage sites, such as the Bambleshwari Temple in Dongargarh and Danteshwari temple in the Dantewada, one of the Shakti Peethas. Buddhism was once a major religion in Chhattisgarh.\nIslam is the second-largest religion, concentrated in urban centres. Most Christians are tribals from the Surguija region.\nLanguage.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nThe official languages of the state are Modern Standard Hindi and Chhattisgarhi, both of which are Central Indo-Aryan languages (also known as \"Hindi languages\", forming a part of the Hindi Belt). Chhattisgarhi is spoken and understood by the majority of people in Chhattisgarh and is the dominant language in the Chhattisgarh plain. Chhattisgarhi is called Khaltahi by tribals and Laria in Odia. Chhattisgarhi is itself divided into many dialects, one of the most distinct being Surgujia from the Surguja region, which is sometimes considered its own language. Near the Uttar Pradesh border this dialect merges into Bhojpuri, while it merges with Bagheli near the Madhya Pradesh border. Surgujia also merges into Sadri in the northeast along the border with Jharkhand. Standard Hindi is spoken by many migrants from outside the state, and is a major language in the cities and industrial centres, while many whose language is actually Chhattisgarhi record their speech as \"Hindi\" in the census. Odia is widely spoken in eastern Chhattisgarh, especially near the Odisha border. Telugu and Marathi speaking minorities can be found along the Telangana and Maharashtra borders respectively. In the eastern Bastar region, Halbi and Bhatri are major languages.\nIn addition, Chhattisgarh has several indigenous languages. Kurukh and Korwa are both spoken in the Surguja region. Gondi is a major language in southern Chhattisgarh: Bastar and the adjoining districts. Gondi has many dialects, such as Muria in north Bastar, which transitions to Madia further south and Dorli, transitional between Gondi and Koya, along the borders of Andhra Pradesh and Telangana. In the east of Bastar. Most Gonds in the north and east of Bastar, as well as the rest of the state, speak regional languages and have largely forgotten their original tongue.\nGender ratio.\nChhattisgarh has a high female-male sex ratio (991) ranking at the fifth position among other states of India. Although this ratio is small compared to other states, it is unique in India because Chhattisgarh is the 10th-largest state in India.\nThe gender ratio (number of females per 1,000 males) has been steadily declining over 20th century in Chhattisgarh. But it is conspicuous that Chhattisgarh always had a better female-to-male ratio compared with national average.\nRural women, although poor, are independent, better organised, and socially outspoken. According to another local custom, women can choose to terminate a marriage relationship through a custom called \"chudi pahanana\", if she desires. Most of the old temples and shrines follow Shaktism and are goddess-centric (e.g., Shabari, Mahamaya, Danteshwari) and the existence of these temples gives insight into the historical and current social fabric of this state. However, a mention of these progressive local customs in no way suggests that the ideology of female subservience does not exist in Chhattisgarh. On the contrary, male authority and dominance are seen quite clearly in social and cultural life.\nCulture.\nDance.\nPanthi, the folk dance of the Satnami community, has religious overtones. Panthi is performed on Maghi Purnima, the anniversary of the birth of Guru Ghasidas. The dancers dance around a jaitkhamb set up for the occasion, to songs eulogising their spiritual head. The songs reflect a view of \"nirvana\", conveying the spirit of their guru's renunciation and the teachings of saint poets like Kabir, Ramdas and Dadu. Dancers with bent torsos and swinging arms dance, carried away by their devotion. As the rhythm quickens, they perform acrobatics and form human pyramids.\nPandavani.\nPandavani is a folk ballad form performed predominantly in Chhattisgarh. It depicts the story of the Pandavas, the leading characters in the epic Mahabharata. The artists in the Pandavani narration consist of a lead artist and some supporting singers and musicians. There are two styles of narration in Pandavani, Vedamati, and Kapalik. In the Vedamati style, the lead artist narrates in a simple manner by sitting on the floor throughout the performance. The Kaplik style is livelier, where the narrator actually enacts the scenes and characters. Padma Shri, Padma Bhushan, and Padma Vibhushan Teejan Bai is most popular artist of Pandavani\nRaut Nacha.\nRaut Nacha, the folk dance of cowherds, is a traditional dance of Yaduvanshis (clan of Yadu) as symbol of worship to Krishna from the 4th day of Diwali (Goverdhan Puja) till the time of Dev Uthani Ekadashi (day of awakening of the gods after a brief rest) which is the 11th day after Diwali according to the Hindu calendar. The dance closely resembles Krishna's dance with the gopis (milkmaids).\nIn Bilaspur, the Raut Nach Mahotsav folk dance festival has been organised annually since 1978. Tens of hundreds of Rautt dancers from remote areas participate.\nSuwa Nacha.\nSoowa or Suwa tribal dance in Chhattisgarh is also known as Parrot Dance. It is a symbolic form of dancing related to worship. Dancers keep a parrot in a bamboo pot and form a circle around it. Then performers sing and dance, moving around it with clapping. This is one of the main dance forms of tribal women of Chhattisgarh.\nKarma.\nTribal groups like Gonds, the Baigas and the Oraons in Chhattisgarh have the Karma dance as part of their culture. Both men and women arrange themselves in two rows and follow the rhythmic steps, directed by the singer group. The Karma tribal dance marks the end of the rainy season and the advent of spring season.\nCinema.\nChhollywood is Chhattisgarh's film industries. Every year many Chhattisgarhi films are produced by local producers.\nLata Mangeshkar sang a song for Chhattisgarhi film Bhakla of Dhriti pati sarkar.\nMohammed Rafi sang a song for Chhattisgarhi film. He had also sung songs for various Chhattisgarhi films like Ghardwaar, Kahi Debe Sandesh, Punni Ke Chanda, etc.\nCuisine.\nChhattisgarh is known as the rice bowl of India and has a rich tradition of food culture.\nThe typical Chhattisgarhi thali consists of roti, bhat, dal or kadhi, curry, chutney and bhaji. Few Chhattisgarhi dishes are Aamat, Bafauri, Bhajia, Chousela, Dubkikadhi, Farra, Khurmi, Moong Bara, Thethari, and Muthia.\nFestivals of Chhattisgarh.\nMajor festivals of Chhattisgarh include Bastar Dussehra/ Durga Puja, Bastar Lokotsav, Madai Festival, Rajim Kumbh Mela, and Pakhanjore Mela (Nara Narayan Mela).\nTourism.\nChhattisgarh, situated in the heart of India, is endowed with a rich cultural heritage and attractive natural diversity. The state is full of ancient monuments, rare wildlife, exquisitely carved temples, Buddhist sites, palaces, waterfalls, caves, rock paintings, and hill plateaus.\nMaitri Bagh in Bhilai is the largest and oldest zoo of Madhya Pradesh and Chhattisgarh.\nMainpat is mini Shimla of Chhattisgarh.\nThere are many waterfalls, hot springs, caves, temples, dams and national parks, tiger reserves and wildlife sanctuaries in Chhattisgarh.\nIndia's first man-made jungle safari is also situated in Raipur.\nSports.\nAbujhmad Peace Marathon is the largest sports event of Narainpur.\nThe Chhattisgarhiya Olympics are an annual Chhattisgarhi celebration of traditional Indian games such as kabaddi and kho-kho. The inaugural 2022 edition drew in around 2.6 million participants (almost 10% of the state's population).\nEducation.\nAccording to the census of 2011, Chhattisgarh's literacy, the most basic indicator of education, was at 71.04 percent. Female literacy was at 60.59 percent.\nAbsolute literates and literacy rate.\nData from Census of India, 2011.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47735", "revid": "20585603", "url": "https://en.wikipedia.org/wiki?curid=47735", "title": "470s BC", "text": "Decade\nDecade\nThis article concerns the period 479 BC \u2013 470 BC.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47736", "revid": "39446055", "url": "https://en.wikipedia.org/wiki?curid=47736", "title": "460s BC", "text": "Decade\nDecade\nThis article concerns the period 469 BC \u2013 460 BC.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47737", "revid": "43944218", "url": "https://en.wikipedia.org/wiki?curid=47737", "title": "Las Vegas", "text": "Most populous city in Nevada, United States\nLas Vegas, colloquially referred to as Vegas, is the most populous city in the U.S. state of Nevada and the seat of Clark County. It is the 24th-most populous city in the United States, with 641,903 residents at the 2020 census. The Las Vegas metropolitan area has an estimated 2.4 million residents and is the 29th-largest metropolitan area in the country. Las Vegas is an internationally renowned major resort city, known primarily for its gambling, shopping, fine dining, entertainment, and nightlife. Most of these venues are located in downtown Las Vegas or on the Las Vegas Strip, which is outside city limits in the unincorporated towns of Paradise and Winchester. The Las Vegas Valley serves as the leading financial, commercial, and cultural center in Nevada.\nLas Vegas was settled in 1905 and officially incorporated in 1911. At the close of the 20th century, it was the most populated North American city founded within that century. Population growth has accelerated since the 1960s and into the 21st century, and between 1990 and 2000 the population increased by 85.2%.\nThe city bills itself as the Entertainment Capital of the World, and is famous for its luxurious and large casino-hotels. As of 2023, Las Vegas attracts over 40.8 million visitors annually, making it one of the most visited cities in the United States and consistently ranking among the world's top tourist destinations. It is the third most popular U.S. destination for business conventions and a global leader in the hospitality industry. The city's tolerance for numerous forms of adult entertainment has earned it the nickname \"Sin City,\" and has made it a popular setting for films, literature, television programs, commercials and music videos.\nToponymy.\nIn 1829, Mexican trader and explorer Antonio Armijo led a group consisting of 60 men and 100 mules along the Old Spanish Trail from modern day New Mexico to California. Along the way, the group stopped in what would become Las Vegas and noted its natural water sources, now referred to as the Las Vegas Springs, which supported extensive vegetation such as grasses and mesquite trees. The springs were a significant natural feature in the valley, with streams that supported a meadow ecosystem. This region served as the winter residence for the Southern Paiute people, who utilized the area's resources before moving to higher elevations during the summer months. The Spanish \"las vegas\" or \"the meadows\" (more precisely, lower land near a river) in English, was applied to describe the fertile lowlands near the springs. Over time, the name began to refer to the populated settlement.\nHistory.\nNomadic Paleo-Indians traveled to the Las Vegas area 10,000 years ago, leaving behind petroglyphs. Ancient Puebloan and Paiute tribes followed at least 2,000 years ago.\nA young Mexican scout named Rafael Rivera is credited as the first non-Native American to encounter the valley, in 1829. Trader Antonio Armijo led a 60-man party along the Spanish Trail to Los Angeles, California, in 1829. In 1844, John C. Fr\u00e9mont arrived, and his writings helped lure pioneers to the area. Downtown Las Vegas's Fremont Street is named after him.\nEleven years later, members of the Church of Jesus Christ of Latter-day Saints chose Las Vegas as the site to build a fort halfway between Salt Lake City and Los Angeles, where they would travel to gather supplies. The fort was abandoned several years afterward. The remainder of this Old Mormon Fort can still be seen at the intersection of Las Vegas Boulevard and Washington Avenue.\nLas Vegas was founded as a city in 1905, when of land adjacent to the Union Pacific Railroad tracks were auctioned in what would become the downtown area. In 1911, Las Vegas was incorporated as a city.\nThe year 1931 was pivotal for Las Vegas. At that time, Nevada legalized casino gambling and reduced residency requirements for divorce to six weeks. This year also witnessed the beginning of construction of the tunnels of nearby Hoover Dam. The influx of construction workers and their families helped Las Vegas avoid economic calamity during the Great Depression. The construction work was completed in 1935.\nIn late 1941, Las Vegas Army Airfield was established. Renamed Nellis Air Force Base in 1950, it is now home to the United States Air Force Thunderbirds aerobatic team.\nFollowing World War II, lavishly decorated hotels, gambling casinos, and big-name entertainment became synonymous with Las Vegas.\nIn 1951, nuclear weapons testing began at the Nevada Test Site, northwest of Las Vegas. During this time, the city was nicknamed the \"Atomic City\". Residents and visitors were able to witness the mushroom clouds (and were exposed to the fallout) until 1963 when the Partial Nuclear Test Ban Treaty required that nuclear tests be moved underground.\nIn 1955, the Moulin Rouge Hotel opened and became the first racially integrated casino-hotel in Las Vegas.\nIn 1995, the Fremont Street Experience opened in Las Vegas's downtown area. This canopied five-block area features 12.5\u00a0million LED lights and 550,000 watts of sound from dusk until midnight during shows held at the top of each hour.\nDue to the realization of many revitalization efforts, 2012 was dubbed \"The Year of Downtown\". Projects worth hundreds of millions of dollars made their debut at this time, including the Smith Center for the Performing Arts, the Discovery Children's Museum, the Mob Museum, the Neon Museum, a new City Hall complex, and renovations for a new Zappos.com corporate headquarters in the old City Hall building.\nGeography.\nLas Vegas is situated in a basin on the floor of the Mojave Desert, and is surrounded by mountain ranges. Much of the landscape is rocky and arid, with desert vegetation and wildlife. It can be subjected to torrential flash floods, although much has been done to mitigate the effects of flash floods through improved drainage systems.\nThe city's elevation is approximately above sea level, though the surrounding peaks reach elevations of over and act as barriers to the strong flow of moisture from the surrounding area. According to the United States Census Bureau, the city has an area of , of which is land and (0.03%) is water.\nAfter Alaska and California, Nevada is the third most seismically active state in the U.S. It has been estimated by the United States Geological Survey (USGS) that over the next 50 years, there is a 10\u201320% chance of an M6.0 or greater earthquake occurring within of Las Vegas.\nWithin the city are many lawns, trees, and other greenery. Due to water resource issues, there has been a movement to encourage xeriscapes. Another part of conservation efforts is scheduled watering days for residential landscaping. A U.S. Environmental Protection Agency grant in 2008 funded a program that analyzed and forecast growth and environmental effects through 2019.\nClimate.\nLas Vegas has a subtropical hot desert climate (K\u00f6ppen climate classification: \"BWh\", Trewartha climate classification \"BWhk\"), typical of the Mojave Desert in which it lies. This climate is typified by long, extremely hot summers; warm transitional seasons; and short winters with mild days and cool nights. There is abundant sunshine throughout the year, with an average of 310 sunny days and bright sunshine during 86% of all daylight hours. Rainfall is scarce, with an average of dispersed between roughly 26 total rainy days per year. Las Vegas is among the sunniest, driest, and least humid locations in North America, with exceptionally low dew points and humidity that sometimes remains below 10%.\nThe summer months of June through September are extremely hot, though moderated by the low humidity levels. July is the hottest month, with an average daytime high of . On average, 137 days per year reach or exceed , of which 78 days reach and 10 days reach . During the peak intensity of summer, overnight lows frequently remain above , and occasionally above .\nWhile most summer days are consistently hot, dry, and cloudless, the North American Monsoon sporadically interrupts this pattern and brings more cloud cover, thunderstorms, lightning, increased humidity, and brief spells of heavy rain. Potential monsoons affect Las Vegas between July and August. Summer in Las Vegas is marked by significant diurnal temperature variation. While less extreme than other parts of the state, nighttime lows in Las Vegas are often or more lower than daytime highs. The average hottest night of the year is . The all-time record is at .\nLas Vegas winters are relatively short, with typically mild daytime temperatures and chilly nights. Sunshine is abundant in all seasons. December is both the year's coolest and cloudiest month, with an average daytime high of and sunshine occurring during 78% of its daylight hours. Winter evenings are defined by clear skies and swift drops in temperature after sunset, with overnight minima averaging around in December and January. Owing to its elevation that ranges from , Las Vegas experiences markedly cooler winters than other areas of the Mojave Desert and the adjacent Sonoran Desert that are closer to sea level. The city records freezing temperatures an average of 10 nights per winter. It is exceptionally rare for temperatures to reach or fall below .\nMost of the annual precipitation falls during the winter. February, the wettest month, averages only four days of measurable rain. The mountains immediately surrounding the Las Vegas Valley accumulate snow every winter, but significant accumulation within the city is rare, although moderate accumulations occur every few years. The most recent accumulations occurred on February 18, 2019, when parts of the city received about of snow and on February 20 when the city received almost . Other recent significant snow accumulations occurred on December 25, 2015, and December 17, 2008. Unofficially, Las Vegas's largest snowfall on record was the that fell in 1909. In recent times, ice days have not occurred, although was measured in 1963. On average the coldest day is .\nThe highest temperature officially observed for Las Vegas is , as measured at Harry Reid International Airport on July 7, 2024. The lowest temperature was , recorded on two days: January 25, 1937, and January 13, 1963. The official record hot daily minimum is on July 19, 2005, and July 1, 2013. The official record cold daily maximum is on January 8 and 21, 1937. July 2024 was the hottest month ever recorded in Las Vegas, with its highest recorded mean daily average temperature over the month of , its highest recorded mean daily maximum temperature of , and its highest recorded mean nightly minimum temperature of .\nDue to concerns about climate change in the wake of a 2002 drought, daily water consumption has been reduced from per resident in 2003 to around in 2015.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2020 census.\nAccording to the 2020 United States census, the city of Las Vegas had 644,883 people living in 244,429 households. The racial composition of the City of Las Vegas was 49.2% white, 11.9% black, 1.1% American Indian or Alaska Native, 6.9% Asian, Hispanic or Latino residents of any race were 34.1% and 16.2% from two or more races. 40.8% were non-Hispanic white.\nApproximately 5.8% of residents are under the age of five, 22.8% under the age of eighteen and 15.6% over 65 years old. Females are 50.0% of the total population.\nFrom 2019 to 2023, Las Vegas had approximately 244,429 households, with an average of 2.63 persons per household. About 55.7% of housing units were owner-occupied, and the median value of owner-occupied housing was $395,300. Median gross rent during this period was $1,456 per month (in 2023 dollars).\nThe median household income in Las Vegas from 2019 to 2023 was $70,723, while the per capita income was $38,421 (in 2023 dollars). Approximately 14.2% of the population lived below the poverty line during the same period.\nResidents over 25 years old with a high school diploma were 85.8% of the population with 27.3% having attained a bachelor's degree or higher.\nAbout 33.0% of residents aged 5 and older speak a language other than English at home. 20.9% of residents are foreign-born.\nThe mean travel time to work for residents aged 16 and older was approximately 25.8 minutes between 2019 and 2023. The vast majority of households in Las Vegas are digitally connected, with 95.6% having a computer and 89.1% subscribing to broadband internet services.\nEthnicity.\nThe largest ancestries in Las Vegas Valley/Clark County were Mexican (23.2%), German (7.4%), Filipino (6.8%), English (6.8%), Irish (6.2%), and Italian (4.5%). As of 2023[ [update]], Native Hawaiians numbered around 22,000 in the metropolitan area, the largest Hawaiian population outside of Hawaii. As a result, Las Vegas has been nicknamed the \"ninth island of Hawaii.\"\nReligion.\nAccording to the Pew Research Center, the majority of residents throughout Las Vegas Valley/Clark County are Christian (61%) with Catholics as the largest denomination (22%), followed by evangelical (19%), mainline protestants (9%), and members of historically Black protestant churches (6%). 6% of residents are members of the Church of Jesus Christ of Latter Day Saints (Mormons).\nAgnostic (10%) and Atheist (3%) are the largest groups of residents who are unaffiliated with a religion, which overall represent 34% of the population. Other religious groups, such as Judaism (1%), Islam (2%), and Buddhism (1%) together compose about 5% of the population.\nMarriage and divorce.\nAccording to a 2004 study, Las Vegas has one of the highest divorce rates This is partly due to residents of states with more restrictive divorce laws traveling to Nevada, and in particular to Las Vegas, to get divorced. As of 2022[ [update]], the Centers for Disease Control and Prevention identified Nevada as a whole as having the highest divorce rate in the United States, with 4.4. divorces per 1,000 marriages. This is down from 11.4 divorces per 1,000 marriages in 1990 and is part of a national trend of fewer divorces.\nNevada marriage requirements are equally lax resulting in one of the highest marriage rates of U.S. cities, with many licenses issued to people from outside the area.\n2010 census.\nAccording to the 2010 Census, the city of Las Vegas had a population of 583,756. The city's racial composition had shifted slightly, with 47.91% of the population identifying as White alone (non-Hispanic), 10.63% as Black or African American alone (non-Hispanic), 0.41% as Native American or Alaska Native alone (non-Hispanic), 5.93% as Asian alone (non-Hispanic), 0.53% as Pacific Islander alone (non-Hispanic), 0.19% as Other Race alone (non-Hispanic), and 2.91% as Mixed race or Multiracial (non-Hispanic). Hispanic or Latino individuals of any race represented 31.50% of the population.\n2000 census.\nAccording to the 2000 census, Las Vegas had a population of 474,434 people. The racial makeup of the city was 58.52% White alone (non-Hispanic), 10.19% Black or African American alone (non-Hispanic), 0.51% Native American or Alaska Native alone (non-Hispanic), 4.72% Asian alone (non-Hispanic), 0.41% Pacific Islander alone (non-Hispanic), 0.14% Other Race alone (non-Hispanic), and 2.52% Mixed race or Multiracial (non-Hispanic). Hispanic or Latino individuals of any race made up 23.81% of the population.\nEconomy.\nThe primary drivers of the Las Vegas economy are tourism, gaming, and conventions, which in turn feed the retail and restaurant industries.\nTourism.\nThe major attractions in Las Vegas are the casinos and the hotels, although in recent years other new attractions have begun to emerge.\nMost casinos in the downtown area are on Fremont Street, with The STRAT Hotel, Casino &amp; Skypod as one of the few exceptions. Fremont East, adjacent to the Fremont Street Experience, was granted variances to allow bars to be closer together, similar to the Gaslamp Quarter of San Diego, the goal being to attract a different demographic than the Strip attracts.\nDowntown casinos.\nThe Golden Gate Hotel and Casino, downtown along the Fremont Street Experience, is the oldest continuously operating hotel and casino in Las Vegas; it opened in 1906 as the Hotel Nevada.\nIn 1931, the Northern Club (now the La Bayou) opened. The most notable of the early casinos may have been Binion's Horseshoe (now Binion's Gambling Hall and Hotel) while it was run by Benny Binion.\nBoyd Gaming has a major presence downtown operating the California Hotel &amp; Casino, the Fremont Hotel &amp; Casino, and the Main Street Casino. The Four Queens also operates downtown along the Fremont Street Experience.\nDowntown casinos that have undergone major renovations and revitalization in recent years include the Golden Nugget Las Vegas, The D Las Vegas (formerly Fitzgerald's), the Downtown Grand Las Vegas (formerly Lady Luck), the El Cortez Hotel &amp; Casino, and the Plaza Hotel &amp; Casino.\nIn 2020, Circa Resort &amp; Casino opened, becoming the first all-new hotel-casino to be built on Fremont Street since 1980.\nLas Vegas Strip.\nThe center of the gambling and entertainment industry is the Las Vegas Strip, outside the city limits in the surrounding unincorporated communities of Paradise and Winchester in Clark County. Some of the largest casinos and buildings are there.\nWelcome signs.\nIn 1929, the city installed a welcome arch over Fremont Street, at the corner of Main Street. It remained in place until 1931.\nIn 1959, the Welcome to Fabulous Las Vegas sign was installed at the south end of the Las Vegas Strip. A replica welcome sign, standing nearly tall, was installed within city limits in 2002, at Las Vegas Boulevard and Fourth Street. The replica was destroyed in 2016, when a pickup truck crashed into it.\nIn 2018, the city approved plans for a new gateway landmark in the form of neon arches. It was built within city limits, in front of the Strat resort and north of Sahara Avenue. The project, built by YESCO, cost $6.5\u00a0million and stands high. Officially known as the Gateway Arches, the project was completed in 2020. The steel arches are blue during the day, and light up in a variety of colors at night.\nAlso located just north of the Strat are a pair of giant neon showgirls, initially added in 2018 as part of a $400,000 welcome display. The original showgirls were tall, but were replaced by new ones in 2022, rising . The originals were refurbished following weather damage and installed at the Las Vegas Arts District.\nDevelopment.\nWhen The Mirage opened in 1989, it started a trend of major resort development on the Las Vegas Strip outside of the city. This resulted in a drop in tourism in the downtown area, but many recent projects have increased the number of visitors to downtown.\nAn effort has been made by city officials to diversify the economy by attracting health-related, high-tech and other commercial interests. No state tax for individuals or corporations, as well as a lack of other forms of business-related taxes, have aided the success of these efforts.\nThe Fremont Street Experience was built in an effort to draw tourists back to the area and has been popular since its startup in 1995.\nThe city conducted a land-swap deal in 2000 with Lehman Brothers, acquiring of property near downtown Las Vegas in exchange for of the Las Vegas Technology Center. In 2004, Las Vegas Mayor Oscar Goodman announced that the area would become home to Symphony Park (originally called \"Union Park\"), a mixed-use development. The development is home to the Cleveland Clinic Lou Ruvo Center for Brain Health, The Smith Center for the Performing Arts, the Discovery Children's Museum, the Las Vegas Chamber of Commerce, and four residential projects totaling 600 residential units as of 2024.\nIn 2005, the World Market Center opened, consisting of three large buildings taking up . Trade shows for the furniture and furnishing industries are held there semiannually.\nAlso nearby is the Las Vegas North Premium Outlets. With a second expansion, completed in May 2015, the mall currently offers 175 stores.\nCity offices moved to a new Las Vegas City Hall in February 2013 on downtown's Main Street. The former city hall building is now occupied by the corporate headquarters for the online retailer Zappos.com, which opened downtown in 2013. Zappos CEO Tony Hsieh took an interest in the urban area and contributed $350 million toward a revitalization effort called the Downtown Project. Projects funded include Las Vegas's first independent bookstore, The Writer's Block.\nOther industries.\nA number of new industries have moved to Las Vegas in recent decades. Zappos.com (now an Amazon subsidiary) was founded in San Francisco but by 2013 had moved its headquarters to downtown Las Vegas. Allegiant Air, a low-cost air carrier, launched in 1997 with its first hub at Harry Reid International Airport and headquarters in nearby Summerlin.\nPlanet 13 Holdings, a cannabis company, opened the world's largest cannabis dispensary in Las Vegas at .\nEffects of growth on water supply.\nA growing population means the Las Vegas Valley used more water in 2014 than in 2011. Although water conservation efforts implemented in the wake of a 2002 drought have had some success, local water consumption remains 30\u00a0percent greater than in Los Angeles, and over three times that of San Francisco metropolitan area residents. The Southern Nevada Water Authority is building a $1.4\u00a0billion tunnel and pumping station to bring water from Lake Mead, has purchased water rights throughout Nevada, and has planned a controversial $3.2\u00a0billion pipeline across half the state. By law, the Las Vegas Water Service District \"may deny any request for a water commitment or request for a water connection if the District has an inadequate supply of water.\" But limiting growth on the basis of an inadequate water supply has been unpopular with the casino and building industries.\nCulture.\n \nThe city is home to several museums, including the Neon Museum (the location for many of the historical signs from Las Vegas's mid-20th century heyday), The Mob Museum, the Las Vegas Natural History Museum, the Discovery Children's Museum, the Nevada State Museum and the Old Las Vegas Mormon Fort State Historic Park.\nThe city's extensive Downtown Arts District hosts numerous galleries and events, including the annual Las Vegas Film Festival. \"First Friday\" is a monthly celebration that includes arts, music, special presentations and food in a section of the city's downtown region called 18b, The Las Vegas Arts District. The festival extends into the Fremont East Entertainment District. The Thursday evening before First Friday is known in the arts district as \"Preview Thursday,\" which highlights new gallery exhibitions throughout the district.\nThe Las Vegas Academy of International Studies, Performing and Visual Arts is a Grammy award-winning magnet school located in downtown Las Vegas. The Smith Center for the Performing Arts is downtown in Symphony Park and hosts various Broadway shows and other artistic performances.\nLas Vegas has earned the moniker \"Gambling Capital of the World,\" as it has the world's most land-based casinos. The city is also host to more AAA Five Diamond hotels than any other city in the world.\nSports.\nThe Las Vegas Valley is the home of three major professional teams: the National Hockey League (NHL)'s Vegas Golden Knights, an expansion team that began play in the 2017\u201318 NHL season at T-Mobile Arena in nearby Paradise, the National Football League (NFL)'s Las Vegas Raiders, who relocated from Oakland, California, in 2020 and play at Allegiant Stadium in Paradise, and the Women's National Basketball Association (WNBA)'s Las Vegas Aces, who play at the Mandalay Bay Events Center. The Athletics of Major League Baseball (MLB) will move to Las Vegas by 2028.\nTwo minor league sports teams play in the Las Vegas area. The Las Vegas Aviators of the Pacific Coast League, the Triple-A farm club of the Athletics, play at Las Vegas Ballpark in nearby Summerlin. The Las Vegas Lights FC of the United Soccer League play in Cashman Field in Downtown Las Vegas.\nThe Las Vegas metropolitan area has been the site of many prominent combat sports events, such as boxing and MMA, with Las Vegas being considered by many as the \"fight capital of the world\". The mixed martial arts promotion, Ultimate Fighting Championship (UFC), is headquartered in Las Vegas and also frequently holds fights in the city at T-Mobile Arena and at the UFC Apex training facility near the headquarters.\nNorth of Las Vegas is the Las Vegas Motor Speedway, a 1.5 mile tri-oval constructed in 1972 that hosts two NASCAR Cup Series races each year, one in the spring and a playoff race in the fall.\nParks and recreation.\nThe city's parks and recreation department operates 78 regional, community, neighborhood, and pocket parks; four municipal swimming pools, 11 recreational centers, four active adult centers, eight cultural centers, six galleries, eleven dog parks, and four golf courses: Angel Park Golf Club, Desert Pines Golf Club, Durango Hills Golf Club, and the Las Vegas Municipal Golf Course.\nIt is also responsible for 123 playgrounds, 23 softball fields, 10 football fields, 44 soccer fields, 10 dog parks, six community centers, four senior centers, 109 skate parks, and six swimming pools.\nGovernment.\nThe city of Las Vegas has a council\u2013manager government. The mayor sits as a council member-at-large and presides over all city council meetings. If the mayor cannot preside over a city council meeting, then the Mayor pro tempore is the presiding officer of the meeting until the Mayor returns to his/her seat. The city manager is responsible for the administration and the day-to-day operations of all municipal services and city departments. The city manager maintains intergovernmental relationships with federal, state, county and other local governments.\nOut of the 2,265,461 people in Clark County as of the 2020 Census, approximately 1,030,000 people live in unincorporated Clark County, and around 650,000 live in incorporated cities such as North Las Vegas, Henderson and Boulder City. Las Vegas and Clark County share a police department, the Las Vegas Metropolitan Police Department, which was formed after a 1973 merger of the Las Vegas Police Department and the Clark County Sheriff's Department. North Las Vegas, Henderson, Boulder City, Mesquite, UNLV and CCSD have their own police departments.\nThe federally-recognized Las Vegas Tribe of Paiute Indians (Southern Paiute: Nuvagantucimi) occupies a reservation just north downtown between Interstate-15 and Main Street.\nDowntown is the location of Lloyd D. George Federal District Courthouse and the Regional Justice Center, draws numerous companies providing bail, marriage, divorce, tax, incorporation and other legal services.\nPolitics.\nLas Vegas City Presidential Election Results\nEducation.\nPrimary and secondary schools.\nPrimary and secondary public education is provided by the Clark County School District.\nPublic higher education.\nPublic higher education is provided by the Nevada System of Higher Education (NSHE). Public institutions serving Las Vegas include the University of Nevada, Las Vegas (UNLV), the College of Southern Nevada (CSN), Nevada State University (NSU), and the Desert Research Institute (DRI).\nUNLV is a public, land-grant, R1 research university and is home to the Kirk Kerkorian School of Medicine and the William S. Boyd School of Law, the only law school in Nevada. The university's campus is urban and located about two miles east of the Las Vegas strip. The Desert Research Institute's southern campus sits next to UNLV, while its northern campus is in Reno.\nCSN, with campuses throughout Clark County, is a community college with one of the largest enrollments in the United States. In unincorporated Clark County, CSN's Charleston campus is home to the headquarters of Nevada Public Radio (KNPR), an NPR member station.\nPrivate higher education.\nTouro University Nevada located in Henderson is a non-profit, private institution primarily focusing on medical education. Other institutions include a number of for-profit private schools (e.g., Le Cordon Bleu College of Culinary Arts and Carrington College, among others).\nMedia.\nBroadcast.\nLas Vegas is served by 10 full power television stations and 46 radio stations. The area is also served by two NOAA Weather Radio transmitters (162.55\u00a0MHz located in Boulder City and 162.40\u00a0MHz located on Potosi Mountain).\nTransportation.\nRTC Transit is a public transportation system providing bus service throughout Las Vegas, Henderson, North Las Vegas and other areas of the valley. Inter-city bus service to and from Las Vegas is provided by Greyhound, BoltBus, Orange Belt Stages, Tufesa, and several smaller carriers.\nAmtrak trains have not served Las Vegas since the service via the \"Desert Wind\" at Las Vegas station ceased in 1997, but Amtrak California operates Amtrak Thruway dedicated service between the city and its passenger rail stations in Bakersfield, California, as well as Los Angeles Union Station via Barstow.\nHigh-speed rail project Brightline West began construction in 2024 to connect Brightline's Las Vegas station and the Rancho Cucamonga station in Greater Los Angeles.\nThe Las Vegas Monorail on the Strip was privately built, and upon bankruptcy taken over by the Las Vegas Convention and Visitors Authority.\nSilver Rider Transit operates three routes within Las Vegas, offering connections to Laughlin, Mesquite, and Sandy Valley.\nThe Union Pacific Railroad is the only Class I railroad providing rail freight service to the city. Until 1997, the Amtrak \"Desert Wind\" train service ran through Las Vegas using the Union Pacific Railroad tracks.\nIn March 2010, the RTC launched bus rapid transit link in Las Vegas called the \"Strip &amp; Downtown Express\" with limited stops and frequent service that connects downtown Las Vegas, the Strip and the Las Vegas Convention Center. Shortly after the launch, the RTC dropped the \"ACE\" name.\nIn 2016, 77.1 percent of working Las Vegas residents (those living in the city, but not necessarily working in the city) commuted by driving alone. About 11 percent commuted via carpool, 3.9 percent used public transportation, and 1.4 percent walked. About 2.3 percent of Las Vegas commuters used all other forms of transportation, including taxi, bicycle, and motorcycle. About 4.3% of working Las Vegas residents worked at home. In 2015, 10.2 percent of city of Las Vegas households were without a car, which increased slightly to 10.5 percent in 2016. The national average was 8.7 percent in 2016. Las Vegas averaged 1.63 cars per household in 2016, compared to a national average of 1.8 per household.\nWith some exceptions, including Las Vegas Boulevard, Boulder Highway (SR 582) and Rancho Drive (SR 599), the majority of surface streets in Las Vegas are laid out in a grid along Public Land Survey System section lines. Many are maintained by the Nevada Department of Transportation as state highways. The street numbering system is divided by the following streets:\nInterstates 15, 11, and US 95 lead out of the city in four directions. Two major freeways \u2013 Interstate 15 and Interstate 11/U.S. Route 95 \u2013 cross in downtown Las Vegas. I-15 connects Las Vegas to Los Angeles, and heads northeast to and beyond Salt Lake City. I-11 goes northwest to the Las Vegas Paiute Indian Reservation and southeast to Henderson and to the Mike O'Callaghan\u2013Pat Tillman Memorial Bridge, where from this point I-11 will eventually continue along US 93 towards Phoenix, Arizona. US 95 (and eventually I-11) connects the city to northwestern Nevada, including Carson City and Reno. US 93 splits from I-15 northeast of Las Vegas and goes north through the eastern part of the state, serving Ely and Wells. US 95 heads south from US 93 near Henderson through far eastern California. A partial beltway has been built, consisting of Interstate 215 on the south and Clark County 215 on the west and north. Other radial routes include Blue Diamond Road (SR 160) to Pahrump and Lake Mead Boulevard (SR 147) to Lake Mead.\nEast\u2013west roads, north to south\nHarry Reid International Airport handles international and domestic flights into the Las Vegas Valley. The airport also serves private aircraft and freight/cargo flights. Most general aviation traffic uses the smaller North Las Vegas Airport and Henderson Executive Airport.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47742", "revid": "17859592", "url": "https://en.wikipedia.org/wiki?curid=47742", "title": "Brooklyn Bridge", "text": "Bridge in New York City\nThe Brooklyn Bridge is a cable-stayed suspension bridge in New York City, spanning the East River between the boroughs of Manhattan and Brooklyn. Opened on May 24, 1883, the Brooklyn Bridge was the first fixed crossing of the East River. It was also the longest suspension bridge in the world when opened, with a main span of and a deck above mean high water. The span was originally called the New York and Brooklyn Bridge or the East River Bridge but was officially renamed the Brooklyn Bridge in 1915.\nProposals for a bridge connecting Manhattan and Brooklyn were first made in the early 19th century; these plans evolved into what is now the Brooklyn Bridge, designed by John A. Roebling. The project's chief engineer, his son Washington Roebling, contributed further design work, assisted by the latter's wife, Emily Warren Roebling. Construction started in 1870 and was overseen by the New York Bridge Company, which in turn was controlled by the Tammany Hall political machine. Numerous controversies and the novelty of the design prolonged the project over thirteen years. After opening, the Brooklyn Bridge underwent several reconfigurations, having carried horse-drawn vehicles and elevated railway lines until 1950. To alleviate increasing traffic flows, additional bridges and tunnels were built across the East River. Due to gradual deterioration, the Brooklyn Bridge was renovated several times, including in the 1950s, 1980s, and 2010s.\nThe Brooklyn Bridge is the southernmost of five vehicular bridges connecting Manhattan Island and Long Island, with the Manhattan Bridge, the Williamsburg Bridge, the Queensboro Bridge, and the Robert F. Kennedy Bridge (formerly known as the Triborough Bridge) to the north. Only passenger vehicles and pedestrian and bicycle traffic are permitted. A major tourist attraction since it opened, the Brooklyn Bridge has become an icon of New York City. Over the years, the bridge has been used for stunts and performances, as well as several crimes, attacks and vandalism. The Brooklyn Bridge is designated a National Historic Landmark, a New York City landmark, and a National Historic Civil Engineering Landmark.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nDescription.\nThe Brooklyn Bridge, an early example of a steel-wire suspension bridge, uses a hybrid design combining elements of cable-stayed and suspension bridges, with both vertical and diagonal suspender cables. Its stone towers are neo-Gothic, with characteristic pointed arches. The New York City Department of Transportation (NYCDOT), which maintains the bridge, says that its original paint scheme was \"Brooklyn Bridge Tan\" and \"Silver\", but other accounts state that it was originally entirely \"Rawlins Red\".\nDeck.\nTo provide sufficient clearance for shipping in the East River, the Brooklyn Bridge incorporates long approach viaducts on either end to raise it from low ground on both shores. Including approaches, the Brooklyn Bridge is a total of long when measured between the curbs at Park Row in Manhattan and Sands Street in Brooklyn. A separate measurement of is sometimes given; this is the distance from the curb at Centre Street in Manhattan.\nSuspension span.\nThe main span between the two suspension towers is long and wide. The bridge \"elongates and contracts between the extremes of temperature from 14 to 16 inches\". Navigational clearance is above mean high water (MHW). A 1909 \"Engineering Magazine\" article said that, at the center of the span, the height above MHW could fluctuate by more than due to temperature and traffic loads, while more rigid spans had a lower maximum deflection.\nThe side spans, between each suspension tower and each side's suspension anchorages, are long. At the time of construction, engineers had not yet discovered the aerodynamics of bridge construction, and bridge designs were not tested in wind tunnels. John Roebling designed the Brooklyn Bridge's truss system to be six to eight times as strong as he thought it needed to be. As such, the open truss structure supporting the deck is, by its nature, subject to fewer aerodynamic problems. However, due to a supplier's fraudulent substitution of inferior-quality wire in the initial construction, the bridge was reappraised at the time as being only four times as strong as necessary.\nThe main span and side spans are supported by a structure containing trusses that run parallel to the roadway, each of which is deep. Originally there were six trusses, but two were removed during a late-1940s renovation. The trusses allow the Brooklyn Bridge to hold a total load of , a design consideration from when it originally carried heavier elevated trains. These trusses are held up by suspender ropes, which hang downward from each of the four main cables. Crossbeams run between the trusses at the top, and diagonal and vertical stiffening beams run on the outside and inside of each roadway.\nAn elevated pedestrian-only promenade runs in between the two roadways and above them. It typically runs below the level of the crossbeams, except at the areas surrounding each tower. Here, the promenade rises to just above the level of the crossbeams, connecting to a balcony that slightly overhangs the two roadways. The path is generally wide. The iron railings were produced by Janes &amp; Kirtland, a Bronx iron foundry that also made the United States Capitol dome and the Bow Bridge in Central Park.\nApproaches.\nEach of the side spans is reached by an approach ramp. The approach ramp from the Brooklyn side is shorter than the approach ramp from the Manhattan side. The approaches are supported by Renaissance-style arches made of masonry; the arch openings themselves were filled with brick walls, with small windows within. The approach ramp contains nine arch or iron-girder bridges across side streets in Manhattan and Brooklyn.\nUnderneath the Manhattan approach, a series of brick slopes or \"banks\" was developed into a skate park, the Brooklyn Banks, in the late 1980s. The park uses the approach's support pillars as obstacles. In the mid-2010s, the Brooklyn Banks were closed to the public because the area was being used as a storage site during the bridge's renovation. The skateboarding community has attempted to save the banks on multiple occasions; after the city destroyed the smaller banks in the 2000s, the city government agreed to keep the larger banks for skateboarding. When the NYCDOT removed the bricks from the banks in 2020, skateboarders started an online petition. In the 2020s, local resident Rosa Chang advocated for the space under the Manhattan approach to be converted into a recreational area known as Gotham Park. Some of the space under the Manhattan approach reopened in May 2023 as a park called the Arches; this was followed in November 2024 by another section of parkland.\nCables.\nThe Brooklyn Bridge contains four main cables, which descend from the tops of the suspension towers and support the deck. Two are located to the outside of the bridge's roadways, while two are in the median of the roadways. Each main cable measures in diameter and contains 5,282 parallel, galvanized steel wires wrapped closely together in a cylindrical shape. These wires are bundled in 19 individual strands, with 278 wires to a strand. This was the first use of bundling in a suspension bridge and took several months for workers to tie together. Since the 2000s, the main cables have also supported a series of 24-watt LED lighting fixtures, referred to as \"necklace lights\" due to their shape.\nIn addition, either 1,088, 1,096, or 1,520 galvanized steel wire suspender cables hang downward from the main cables. Another 400 cable stays extend diagonally from the towers. The vertical suspender cables and diagonal cable stays hold up the truss structure around the bridge deck. The bridge's suspenders originally used wire rope, which was replaced in the 1980s with galvanized steel made by Bethlehem Steel. The vertical suspender cables measure long, and the diagonal stays measure long.\nAnchorages.\nEach side of the bridge contains an anchorage for the main cables. The anchorages are trapezoidal limestone structures located slightly inland of the shore, measuring at the base and at the top. Each anchorage weighs . The Manhattan anchorage rests on a foundation of bedrock while the Brooklyn anchorage rests on clay.\nThe anchorages both have four anchor plates, one for each of the main cables, which are located near ground level and parallel to the ground. The anchor plates measure , with a thickness of and weigh each. Each anchor plate is connected to the respective main cable by two sets of nine eyebars, each of which is about long and up to thick. The chains of eyebars curve downward from the cables toward the anchor plates, and the eyebars vary in size depending on their position.\nThe anchorages also contain numerous passageways and compartments. Starting in 1876, in order to fund the bridge's maintenance, the New York City government made the large vaults under the bridge's Manhattan anchorage available for rent, and they were in constant use during the early 20th century. The vaults were used to store wine, as they were kept at a consistent temperature due to a lack of air circulation. The Manhattan vault was called the \"Blue Grotto\" because of a shrine to the Virgin Mary next to an opening at the entrance. The vaults were closed for public use in the late 1910s and 1920s during World War I and Prohibition but were reopened thereafter. When \"New York\" magazine visited one of the cellars in 1978, it discovered a \"fading inscription\" on a wall reading: \"Who loveth not wine, women and song, he remaineth a fool his whole life long.\" Leaks found within the vault's spaces necessitated repairs during the late 1980s and early 1990s. By the late 1990s, the chambers were being used to store maintenance equipment.\nTowers.\nThe bridge's two suspension towers are tall with a footprint of at the high water line. They are built of limestone, granite, and Rosendale cement. The limestone was quarried at the Clark Quarry in Essex County, New York. The granite blocks were quarried and shaped on Vinalhaven Island, Maine, under a contract with the Bodwell Granite Company, and delivered from Maine to New York by schooner. The Manhattan tower contains of masonry, while the Brooklyn tower has of masonry. There are 56 LED lamps mounted onto the towers.\nEach tower contains a pair of Gothic Revival pointed arches, through which the roadways run. The arch openings are tall and wide. The tops of the towers are located above the floor of each arch opening, while the floors of the openings are above mean water level, giving the towers a total height of above mean high water.\nCaissons.\nThe towers rest on underwater caissons made of southern yellow pine and filled with cement. Inside both caissons were spaces for construction workers. The Manhattan side's caisson is slightly larger, measuring and located below high water, while the Brooklyn side's caisson measures and is located below high water. The caissons were designed to hold at least the weight of the towers which would exert a pressure of when fully built, but the caissons were over-engineered for safety. During an accident on the Brooklyn side, when air pressure was lost and the partially-built towers dropped full-force down, the caisson sustained an estimated pressure of with only minor damage. Most of the timber used in the bridge's construction, including in the caissons, came from mills at Gascoigne Bluff on St. Simons Island, Georgia.\nThe Brooklyn side's caisson, which was built first, originally had a height of and a ceiling composed of five layers of timber, each layer tall. Ten more layers of timber were later added atop the ceiling, and the entire caisson was wrapped in tin and wood for further protection against flooding. The thickness of the caisson's sides was at both the bottom and the top. The caisson had six chambers: two each for dredging, supply shafts, and airlocks.\nThe caisson on the Manhattan side was slightly different because it had to be installed at a greater depth. To protect against the increased air pressure at that depth, the Manhattan caisson had 22 layers of timber on its roof, seven more than its Brooklyn counterpart had. The Manhattan caisson also had fifty pipes for sand removal, a fireproof iron-boilerplate interior, and different airlocks and communication systems.\nHistory.\nPlanning.\nProposals for a bridge between the then-separate cities of Brooklyn and New York had been suggested as early as 1800. At the time, the only travel between the two cities was by a number of ferry lines. Engineers presented various designs, such as chain or link bridges, though these were never built because of the difficulties of constructing a high enough fixed-span bridge across the extremely busy East River. There were also proposals for tunnels under the East River, but these were considered prohibitively expensive. German immigrant engineer John Augustus Roebling proposed building a suspension bridge over the East River in 1857. He had previously designed and constructed shorter suspension bridges, such as Roebling's Delaware Aqueduct in Lackawaxen, Pennsylvania, and the Niagara Suspension Bridge. In 1867, Roebling erected what became the John A. Roebling Suspension Bridge over the Ohio River between Cincinnati, Ohio, and Covington, Kentucky.\nIn February 1867, the New York State Senate passed a bill that allowed the construction of a suspension bridge from Brooklyn to Manhattan. Two months later, the New York and Brooklyn Bridge Company was incorporated with a board of directors (later converted to a board of trustees). There were twenty trustees in total: eight each appointed by the mayors of New York and Brooklyn, as well as the mayors of each city and the auditor and comptroller of Brooklyn. The company was tasked with constructing what was then known as the New York and Brooklyn Bridge. Alternatively, the span was just referred to as the \"Brooklyn Bridge\", a name originating in a January 25, 1867, letter to the editor sent to the \"Brooklyn Daily Eagle.\" The act of incorporation, which became law on April 16, 1867, authorized the cities of New York (now Manhattan) and Brooklyn to subscribe to $5\u00a0million in capital stock, which would fund the bridge's construction.\nRoebling was subsequently named the chief engineer of the work and, by September 1867, had presented a master plan. According to the plan, the bridge would be longer and taller than any suspension bridge previously built. It would incorporate roadways and elevated rail tracks, whose tolls and fares would provide the means to pay for the bridge's construction. It would also include a raised promenade that served as a leisurely pathway. The proposal received much acclaim in both cities, and residents predicted that the New York and Brooklyn Bridge's opening would have as much of an impact as the Suez Canal, the first transatlantic telegraph cable or the first transcontinental railroad. By early 1869, however, some individuals started to criticize the project, saying either that the bridge was too expensive, or that the construction process was too difficult.\nTo allay concerns about the design of the New York and Brooklyn Bridge, Roebling set up a \"Bridge Party\" in March 1869, where he invited engineers and members of U.S. Congress to see his other spans. Following the bridge party in April, Roebling and several engineers conducted final surveys. During the process, it was determined that the main span would have to be raised from above MHW, requiring several changes to the overall design. In June 1869, while conducting these surveys, Roebling sustained a crush injury to his foot when a ferry pinned it against a piling. After amputation of his crushed toes, he developed a tetanus infection that left him incapacitated and resulted in his death the following month. Washington Roebling, John Roebling's 32-year-old son, was then hired to fill his father's role. Tammany Hall leader William M. Tweed also became involved in the bridge's construction because, as a major landowner in New York City, he had an interest in the project's completion. The New York and Brooklyn Bridge Company\u2014later known simply as the New York Bridge Company\u2014was actually overseen by Tammany Hall, and it approved Roebling's plans and designated him as chief engineer of the project.\nConstruction.\nCaissons.\nConstruction of the Brooklyn Bridge began on January 2, 1870. The first work entailed the construction of two caissons, upon which the suspension towers would be built. The Brooklyn side's caisson was built at the Webb &amp; Bell shipyard in Greenpoint, Brooklyn, and was launched into the river on March 19, 1870. Compressed air was pumped into the caisson, and workers entered the space to dig the sediment until it sank to the bedrock. As one sixteen-year-old from Ireland, Frank Harris, described the fearful experience:The six of us were working naked to the waist in the small iron chamber with the temperature of about 80 degrees Fahrenheit: In five minutes the sweat was pouring from us, and all the while we were standing in icy water that was only kept from rising by the terrific pressure. No wonder the headaches were blinding. Once the caisson had reached the desired depth, it was to be filled in with vertical brick piers and concrete. However, due to the unexpectedly high concentration of large boulders atop the riverbed, the Brooklyn caisson took several months to sink to the desired depth. Furthermore, in December 1870, its timber roof caught fire, delaying construction further. The \"Great Blowout\", as the fire was called, delayed construction for several months, since the holes in the caisson had to be repaired. On March 6, 1871, the repairs were finished, and the caisson had reached its final depth of ; it was filled with concrete five days later. Overall, about 264 individuals were estimated to have worked in the caisson every day, but because of high worker turnover, the final total was thought to be about 2,500 men in total. In spite of this, only a few workers were paralyzed. At its final depth, the caisson's air pressure was .\nThe Manhattan side's caisson was the next structure to be built. To ensure that it would not catch fire like its counterpart had, the Manhattan caisson was lined with fireproof plate iron. It was launched from Webb &amp; Bell's shipyard on May 11, 1871, and maneuvered into place that September. Due to the extreme underwater air pressure inside the much deeper Manhattan caisson, many workers became sick with \"the bends\"\u2014decompression sickness\u2014during this work, despite the incorporation of airlocks (which were believed to help with decompression sickness at the time). This condition was unknown at the time and was first called \"caisson disease\" by the project physician, Andrew Smith. Between January 25 and May 31, 1872, Smith treated 110 cases of decompression sickness, while three workers died from the disease. When iron probes underneath the Manhattan caisson found the bedrock to be even deeper than expected, Washington Roebling halted construction due to the increased risk of decompression sickness. After the Manhattan caisson reached a depth of with an air pressure of , Washington deemed the sandy subsoil overlying the bedrock beneath to be sufficiently firm, and subsequently infilled the caisson with concrete in July 1872.\nWashington Roebling himself suffered a paralyzing injury as a result of caisson disease shortly after ground was broken for the Brooklyn tower foundation. His debilitating condition left him unable to supervise the construction in person, so he designed the caissons and other equipment from his apartment, directing \"the completion of the bridge through a telescope from his bedroom.\" His wife, Emily Warren Roebling, not only provided written communications between her husband and the engineers on site, but also understood mathematics, calculations of catenary curves, strengths of materials, bridge specifications, and the intricacies of cable construction. She spent the next 11 years helping supervise the bridge's construction, taking over much of the chief engineer's duties, including day-to-day supervision and project management.\nTowers.\nAfter the caissons were completed, piers were constructed on top of each of them upon which masonry towers would be built. The towers' construction was a complex process that took four years. Since the masonry blocks were heavy, the builders transported them to the base of the towers using a pulley system with a continuous steel wire rope, operated by steam engines at ground level. The blocks were then carried up on a timber track alongside each tower and maneuvered into the proper position using a derrick atop the towers. The blocks sometimes vibrated the ropes because of their weight, but only once did a block fall.\nConstruction on the suspension towers started in mid-1872, and by the time work was halted for the winter in late 1872, parts of each tower had already been built. By mid-1873, there was substantial progress on the towers' construction. The Brooklyn side's tower had reached a height of above mean high water (MHW), while the tower on the Manhattan side had reached above MHW. The arches of the Brooklyn tower were completed by August 1874. The tower was substantially finished by December 1874 with the erection of saddle plates for the main cables at the top of the tower. However, the ornamentation on the Brooklyn tower could not be completed until the Manhattan tower was finished. The last stone on the Brooklyn tower was raised in June 1875 and the Manhattan tower was completed in July 1876. The saddle plates atop both towers were also raised in July 1876. The work was dangerous: by 1876, three workers had died having fallen from the towers, while nine other workers were killed in other accidents.\nWhen the towers were completed, they were taller than any building in the city, with the exception of the spire of Trinity Church, which reached . This remained the case until 1890. \nIn 1875, while the towers were being constructed, the project had depleted its original $5\u00a0million budget. Two bridge commissioners, one each from Brooklyn and Manhattan, petitioned New York state lawmakers to allot another $8\u00a0million for construction. Ultimately, the legislators passed a law authorizing the allotment with the condition that the cities would buy the stock of Brooklyn Bridge's private stockholders.\nWork proceeded concurrently on the anchorages on each side. The Brooklyn anchorage broke ground in January 1873 and was subsequently substantially completed in August 1875. The Manhattan anchorage was built in less time, having started in May 1875, it was mostly completed in July 1876. The anchorages could not be fully completed until the main cables were spun, at which point another would be added to the height of each anchorage.\nCables.\nThe first temporary wire was stretched between the towers on August 15, 1876, using chrome steel provided by the Chrome Steel Company of Brooklyn. The wire was then stretched back across the river, and the two ends were spliced to form a traveler, a lengthy loop of wire connecting the towers, which was driven by a steam hoisting engine at ground level. The wire was one of two that were used to create a temporary footbridge for workers while cable spinning was ongoing. The next step was to send an engineer across the completed traveler wire in a boatswain's chair slung from the wire, to show the workforce it was safe enough. The bridge's master mechanic, E. F. Farrington, was selected for this task, and an estimated crowd of 10,000 people on both shores watched him cross. A second traveler wire was then stretched across the span, a task that was completed by August 30. The temporary footbridge, located some above the elevation of the future deck, was completed in February 1877.\nBy December 1876, a steel contract for the permanent cables still had not been awarded. There was disagreement over whether the bridge's cables should use the as-yet-untested Bessemer steel or the well-proven crucible steel. Until a permanent contract was awarded, the builders ordered of wire in the interim, 10 tons each from three companies, including Washington Roebling's own steel mill in Trenton, New Jersey. In the end, it was decided to use number 8 Birmingham gauge (approximately 4\u00a0mm or 0.165 inches in diameter) crucible steel, and a request for bids was distributed, to which eight companies responded. In January 1877, a contract for crucible steel was awarded to J. Lloyd Haigh, who was associated with bridge trustee Abram Hewitt, whom Roebling distrusted.\nThe spinning of the wires required the manufacture of large coils of it which were galvanized but not oiled when they left the factory. The coils were delivered to a yard near the Brooklyn anchorage. There they were dipped in linseed oil, hoisted to the top of the anchorage, dried out and spliced into a single wire, and finally coated with red zinc for further galvanizing. There were thirty-two drums at the anchorage yard, eight for each of the four main cables. Each drum had a capacity of of wire. The first experimental wire for the main cables was stretched between the towers on May 29, 1877, and spinning began two weeks later. All four main cables were being strung by that July. During that time, the temporary footbridge was unofficially opened to members of the public, who could receive a visitor's pass; by August 1877 several thousand visitors from around the world had used the footbridge. The visitor passes ceased that September after a visitor had an epileptic seizure and nearly fell off.\nAs the wires were being spun, work also commenced on the demolition of buildings on either side of the river for the Brooklyn Bridge's approaches; this work was mostly complete by September 1877. The following month, initial contracts were awarded for the suspender wires, which would hang down from the main cables and support the deck. By May 1878, the main cables were more than two-thirds complete. However, the following month, one of the wires slipped, killing two people and injuring three others. In 1877, Hewitt wrote a letter urging against the use of Bessemer steel in the bridge's construction. Bids had been submitted for both crucible steel and Bessemer steel; John A. Roebling's Sons submitted the lowest bid for Bessemer steel, but at Hewitt's direction, the contract was awarded to Haigh.\nA subsequent wire sampling by Roebling's assistant engineers discovered that Haigh had substituted inferior quality wire in the cables. Of eighty rings of wire that were tested, only five met standards, and it was estimated that Haigh had earned $300,000 from the deception. At this point, it was too late to replace the cables that had already been constructed. Roebling determined that the poorer wire would leave the bridge only four times as strong as necessary, rather than six to eight times as strong. The inferior-quality wire was allowed to remain and 150 extra wires were added to each cable. To avoid public controversy, Haigh was not fired, but instead was required to personally pay for the extra higher-quality wire needed. The contract for the remaining wire was awarded to the John A. Roebling's Sons, and by October\u00a05, 1878, the last of the main cables' wires went over the river.\nNearing completion.\nAfter the suspender wires had been placed, workers began erecting steel crossbeams to support the roadway as part of the bridge's overall superstructure. Construction on the bridge's superstructure started in March 1879, but, as with the cables, the trustees initially disagreed on whether the steel superstructure should be made of Bessemer or crucible steel. That July, the trustees decided to award a contract for of Bessemer steel to the Edgemoor (or Edge Moor) Iron Works, based in Philadelphia, to be delivered by 1880. The trustees later passed another resolution for another of Bessemer steel. However, by February 1880 the steel deliveries had not started. That October, the bridge trustees questioned Edgemoor's president about the delay in steel deliveries. Despite Edgemoor's assurances that the contract would be fulfilled, the deliveries still had not been completed by November 1881. Brooklyn mayor Seth Low, who became part of the board of trustees in 1882, became the chairman of a committee tasked to investigate Edgemoor's failure to fulfill the contract. When questioned, Edgemoor's president stated that the delays were the fault of another contractor, the Cambria Iron Company, who was manufacturing the eyebars for the bridge trusses; at that point, the contract was supposed to be complete by October 1882.\nFurther complicating the situation, Washington Roebling had failed to appear at the trustees' meeting in June 1882, since he had gone to Newport, Rhode Island. After the news media discovered this, most of the newspapers called for Roebling to be fired as chief engineer, except for the \"Daily State Gazette\" of Trenton, New Jersey, and the \"Brooklyn Daily Eagle\". Some of the longstanding trustees, including Henry C. Murphy, James S. T. Stranahan, and William C. Kingsley, were willing to vouch for Roebling, since construction progress on the Brooklyn Bridge was still ongoing. However, Roebling's behavior was considered suspect among the younger trustees who had joined the board more recently.\nConstruction on the bridge itself was noted in formal reports that Murphy presented each month to the mayors of New York and Brooklyn. For example, Murphy's report in August 1882 noted that the month's progress included 114 intermediate cords erected within a week, as well as 72 diagonal stays, 60 posts, and numerous floor beams, bridging trusses, and stay bars. By early 1883, the Brooklyn Bridge was considered mostly completed and was projected to open that June. Contracts for bridge lighting were awarded by February 1883, and a toll scheme was approved that March.\nOpposition.\nThere was substantial opposition to the bridge's construction from shipbuilders and merchants located to the north, who argued that the bridge would not provide sufficient clearance underneath for ships. In May 1876, these groups, led by Abraham Miller, filed a lawsuit in the United States District Court for the Southern District of New York against the cities of New York and Brooklyn.\nIn 1879, an Assembly Sub-Committee on Commerce and Navigation began an investigation into the Brooklyn Bridge. A seaman who had been hired to determine the height of the span, testified to the committee about the difficulties that ship masters would experience in bringing their ships under the bridge when it was completed. Another witness, Edward Wellman Serrell, a civil engineer, said that the calculations of the bridge's assumed strength were incorrect. The Supreme Court decided in 1883 that the Brooklyn Bridge was a lawful structure.\nOpening.\nThe New York and Brooklyn Bridge was opened for use on May\u00a024, 1883. Thousands of people attended the opening ceremony, and many ships were present in the East River for the occasion. Officially, Emily Warren Roebling was the first to cross the bridge. The bridge opening was also attended by U.S. president Chester A. Arthur and New York mayor Franklin Edson, who crossed the bridge and shook hands with Brooklyn mayor Seth Low at the Brooklyn end. Abram Hewitt gave the principal address.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It is not the work of any one man or of any one age. It is the result of the study, of the experience, and of the knowledge of many men in many ages. It is not merely a creation; it is a growth. It stands before us today as the sum and epitome of human knowledge; as the very heir of the ages; as the latest glory of centuries of patient observation, profound study and accumulated skill, gained, step by step, in the never-ending struggle of man to subdue the forces of nature to his control and use.\u2014\u200a\nThough Washington Roebling was unable to attend the ceremony (and rarely visited the site again), he held a celebratory banquet at his house on the day of the bridge opening. Further festivity included the performance by a band, gunfire from ships, and a fireworks display. On that first day, a total of 1,800 vehicles and 150,300 people crossed the span. Less than a week after the Brooklyn Bridge opened, ferry crews reported a sharp drop in patronage, while the bridge's toll operators were processing over a hundred people a minute. However, cross-river ferries continued to operate until 1942.\nThe bridge had cost US$ in 1883 dollars (about US$ in 2024) to build, of which Brooklyn paid two-thirds. The bonds to fund the construction would not be paid off until 1956. An estimated 27 men died during its construction. Since the New York and Brooklyn Bridge was the only bridge across the East River at that time, it was also called the East River Bridge. Until the construction of the nearby Williamsburg Bridge in 1903, the New York and Brooklyn Bridge was the longest suspension bridge in the world, 20% longer than any built previously.\nAt the time of opening, the Brooklyn Bridge was not complete; the proposed public transit across the bridge was still being tested, while the Brooklyn approach was being completed. On May\u00a030, 1883, six days after the opening, a woman falling down a stairway at the Brooklyn approach caused a stampede which resulted in at least twelve people being crushed and killed. In subsequent lawsuits, the Brooklyn Bridge Company was acquitted of negligence. However, the company did install emergency phone boxes and additional railings, and the trustees approved a fireproofing plan for the bridge. Public transit service began with the opening of the New York and Brooklyn Bridge Railway, a cable car service, on September 25, 1883. On May\u00a017, 1884, one of the circus master P. T. Barnum's most famous attractions, Jumbo the elephant, led a parade of 21 elephants over the Brooklyn Bridge. This helped to lessen doubts about the bridge's stability while also promoting Barnum's circus.\n1880s to 1900s.\nPatronage across the Brooklyn Bridge increased in the years after it opened; a million people paid to cross in the first six months. The bridge carried 8.5\u00a0million people in 1884, its first full year of operation; this number doubled to 17\u00a0million in 1885 and again to 34\u00a0million in 1889. Many of these people were cable car passengers. Additionally, about 4.5\u00a0million pedestrians a year were crossing the bridge for free by 1892.\nThe first proposal to make changes to the bridge was sent in only two and a half years after it opened, when Linda Gilbert suggested glass steam-powered elevators and an observatory be added to the bridge and a fee charged for use, which would in part fund the bridge's upkeep and in part fund her prison reform charity. This proposal was considered but not acted upon. Numerous other proposals were made during the first fifty years of the bridge's life. Trolley tracks were added in the center lanes of both roadways in 1898, allowing trolleys to use the bridge as well. That year, the formerly separate City of Brooklyn was unified with New York City, and the Brooklyn Bridge fell under city control.\nConcerns about the Brooklyn Bridge's safety were raised during the turn of the century. In 1898, traffic backups due to a dead horse caused one of the truss cords to buckle. There were more significant worries after twelve suspender cables snapped in 1901, though a thorough investigation found no other defects. After the 1901 incident, five inspectors were hired to examine the bridge each day, a service that cost $250,000 a year. The Brooklyn Rapid Transit Company, which operated routes across the Brooklyn Bridge, issued a notice in 1905 saying that the bridge had reached its transit capacity.\nBy 1890, due to the popularity of the Brooklyn Bridge, there were proposals to construct other bridges across the East River between Manhattan and Long Island. Although a second deck for the Brooklyn Bridge was proposed, it was thought to be infeasible because doing so would overload the bridge's structural capacity. The first new bridge across the East River, the Williamsburg Bridge, opened upstream in 1903 and connected Williamsburg, Brooklyn, with the Lower East Side of Manhattan. This was followed by the Queensboro Bridge between Queens and Manhattan in March 1909, and the Manhattan Bridge between Brooklyn and Manhattan in December 1909. Several subway, railroad, and road tunnels were also constructed, which helped to accelerate the development of Manhattan, Brooklyn, and Queens.\n1910s to 1940s.\nTolls on the bridge were abolished in 1911. In addition, the city government passed a bill to officially name the structure the \"Brooklyn Bridge\" in January 1915.\nOstensibly in an attempt to reduce traffic on nearby city streets, Grover Whalen, the commissioner of Plant and Structures, banned motor vehicles from the Brooklyn Bridge on July 6, 1922. The real reason for the ban was an incident the same year where two cables slipped due to high traffic loads. Both Whalen and Roebling called for the renovation of the Brooklyn Bridge and the construction of a parallel bridge, though the parallel bridge was never built. Whalen's successor William Wirt Mills announced in 1924 that a new wood-block pavement would be installed, permitting motor vehicles to use the bridge again; motor traffic was again allowed on the bridge starting on May 12, 1925.\nAs part of an experiment, starting in November 1946, the Manhattan-bound roadway carried Brooklyn-bound traffic during the evening rush hours. The experiment ended after two months due to complaints about congestion.\nMid- to late 20th century.\nUpgrades.\nThe first major upgrade to the Brooklyn Bridge commenced in 1948, when a contract to entirely reconstruct the approach ramps was awarded to David B. Steinman. The renovation was expected to double the capacity of the bridge's roadways to nearly 6,000 cars per hour, at a projected cost of $7\u00a0million. The renovation included the demolition of both the elevated and the trolley tracks on the roadways, the removal of trusses separating the inner elevated tracks from the existing vehicle lanes and the widening of each roadway from two to three lanes, as well as the construction of a new steel-and-concrete floor. In addition, new ramps were added to Adams Street, Cadman Plaza, and the Brooklyn Queens Expressway (BQE) on the Brooklyn side, and to Park Row on the Manhattan side. The bridge was briefly closed to all traffic for the first time ever in January 1950, and the trolley tracks closed that March to allow the widening work to occur. During the construction project, one roadway at a time was closed, allowing reduced traffic flows to cross the bridge in one direction only.\nThe widened south roadway was completed in May 1951, followed by the north roadway in October 1953. The restoration was finished in May 1954 with the completion of the reconstructed elevated promenade. While the rebuilding of the span was ongoing, a fallout shelter was constructed beneath the Manhattan approach in anticipation of the Cold War. The abandoned space in one of the masonry arches was stocked with emergency survival supplies for a potential nuclear attack by the Soviet Union; these supplies remained in place half a century later. In addition, defensive barriers were added to the bridge as a safeguard against sabotage.Simultaneous with the rebuilding of the Brooklyn Bridge, a double-decked viaduct for the BQE was being built through an existing steel overpass of the bridge's Brooklyn approach ramp. The segment of the BQE from Brooklyn Bridge south to Atlantic Avenue opened in June 1954, but the direct ramp from the northbound BQE to the Manhattan-bound Brooklyn Bridge did not open until 1959. The city also widened the Adams Street approach in Brooklyn, between the bridge and Fulton Street, from between 1954 and 1955. Subsequently, Boerum Place from Fulton Street south to Atlantic Avenue was also widened. This required the demolition of the old Kings County courthouse. The towers were cleaned in 1958 and the Brooklyn anchorage was repaired the next year.\nOn the Manhattan side, the city approved a controversial rebuilding of the Manhattan entrance plaza in 1953. The project, which would add a grade-separated junction over Park Row, was hotly contested because it would require the demolition of 21 structures, including the old New York World Building. The reconstruction also necessitated the relocation of 410 families on Park Row. In December 1956, the city started a two-year renovation of the plaza. This required the closure of one roadway at a time, as was done during the rebuilding of the bridge itself. Work on redeveloping the area around the Manhattan approach started in the mid-1960s. At the same time, plans were announced for direct ramps to the elevated FDR Drive to alleviate congestion at the approach. The ramp from FDR Drive to the Brooklyn Bridge was opened in 1968, followed by the ramp from the bridge to FDR Drive the next year. A single ramp from the Manhattan-bound Brooklyn Bridge to northbound Park Row was constructed in 1970. A repainting of the bridge was announced two years later in advance of its 90th anniversary.\nDeterioration and late-20th century repair.\nThe Brooklyn Bridge gradually deteriorated due to age and neglect. While it had 200 full-time dedicated maintenance workers before World War II, that number dropped to five by the late 20th century, and the city as a whole only had 160 bridge maintenance workers. In 1974, heavy vehicles such as vans and buses were banned from the bridge to prevent further erosion of the concrete roadway. A report in \"The New York Times\" four years later noted that the cables were visibly fraying and the pedestrian promenade had holes in it. The city began planning to replace all the Brooklyn Bridge's cables at a cost of $115\u00a0million, as part of a larger project to renovate the Brooklyn, Manhattan, Williamsburg, and Queensboro bridges. By 1980, the Brooklyn Bridge was in such dire condition that it faced imminent closure. In some places, half of the strands in the cables were broken.\nIn June 1981, two of the diagonal stay cables snapped, killing a pedestrian. Subsequently, the anchorages were found to have developed rust, and an emergency cable repair was necessitated less than a month later after another cable developed slack. Following the incident, the city accelerated the timetable of its proposed cable replacement, and it commenced a $153\u00a0million rehabilitation of the Brooklyn Bridge in advance of the 100th anniversary. As part of the project, the bridge's original suspender cables installed by J. Lloyd Haigh were replaced by Bethlehem Steel in 1986, marking the cables' first replacement since construction. In addition, the staircase at Washington Street in Brooklyn was renovated, the stairs from Tillary and Adams Streets were replaced with a ramp, and the short flights of steps from the promenade to each tower's balcony were removed. In a smaller project, the bridge was floodlit at night starting in 1982 to highlight its architectural features.\nAdditional problems persisted, and in 1993, high levels of lead were discovered near the bridge's towers. Further emergency repairs were undertaken in mid-1999 after small concrete shards began falling from the bridge into the East River. The concrete deck had been installed during the 1950s renovations and had a lifespan of about 60 years. The Park Row exit from the bridge's westbound lanes was closed as a safety measure after the September\u00a011, 2001, attacks on the nearby World Trade Center. That section of Park Row had been closed off since it ran right underneath 1\u00a0Police Plaza, the headquarters of the New York City Police Department (NYPD). In early 2003, to save money on electricity, the NYCDOT turned off the bridge's \"necklace lights\" at night. They were turned back on later that year after several private entities made donations to fund the lights.\n21st century.\nAfter the 2007 collapse of the I-35W bridge in Minneapolis, public attention focused on the condition of bridges across the U.S. \"The New York Times\" reported that the Brooklyn Bridge approach ramps had received a \"poor\" rating during an inspection in 2007. However, a NYCDOT spokesman said that the poor rating did not indicate a dangerous state but rather implied it required renovation. In 2010, the NYCDOT began renovating the approaches and deck, as well as repainting the suspension span. Work included widening two approach ramps from one to two lanes by re-striping a new prefabricated ramp; raising clearance over the eastbound BQE at York Street; seismic retrofitting; replacement of rusted railings and safety barriers; and road deck resurfacing. The work necessitated detours for four years. At the time, the project was scheduled to be completed in 2014; but completion was later delayed to 2015, then again to 2017. The project's cost also increased from $508\u00a0million in 2010 to $811\u00a0million in 2016.\nIn August 2016, the NYCDOT announced that it would conduct a seven-month, $370,000 study to verify if the bridge could support a heavier upper deck that consisted of an expanded bicycle and pedestrian path. By then, about 10,000 pedestrians and 3,500 cyclists used the pathway on an average weekday. Work on the pedestrian entrance on the Brooklyn side was underway by 2017. The NYCDOT also indicated in 2016 that it planned to reinforce the Brooklyn Bridge's foundations to prevent it from sinking, as well as repair the masonry arches on the approach ramps, which had been damaged by Hurricane Sandy four years earlier. In July 2018, the New York City Landmarks Preservation Commission approved a further renovation of the Brooklyn Bridge's suspension towers and approach ramps. That December, the federal government gave the city $25\u00a0million in funding, which would pay for a $337\u00a0million rehabilitation of the bridge approaches and the suspension towers. Work started in late 2019 and was scheduled to be completed in four years. This restoration included removing bricks from the arches and putting fresh concrete behind them, using mortar from the same upstate quarries as the original mortar. The granite arches were also cleaned, revealing the original gray color of the stone, which had long been hidden by grime. Additionally, 56 LED lamps were installed on the bridge at a cost of $2.4 million.\nIn early 2020, City Council speaker Corey Johnson and the nonprofit Van Alen Institute hosted an international contest to solicit plans for the redesign of the bridge's walkway. Ultimately, in January 2021, the city decided to install a two-way protected bike path on the Manhattan-bound roadway, replacing the leftmost vehicular lane. The bike lane would allow the existing promenade to be used exclusively by pedestrians. Work on the bike lane started in June 2021, and the new path was completed on September 14, 2021. Despite the addition of the bike path, the bridge's walkway was still frequently overcrowded, prompting the city to propose that street vendors be banned from the bridge and others citywide. All vendors were banned from the bridge in January 2024, and the same month, the bridge's new LED lights were illuminated for the first time. The National Transportation Safety Board recommended in early 2025 that the bridge undergo a structural vulnerability assessment, following the Francis Scott Key Bridge collapse in Maryland the previous year.\nUsage.\nVehicular traffic.\nHorse-drawn carriages have been allowed to use the Brooklyn Bridge's roadways since its opening. Originally, each of the two roadways carried two lanes of a different direction of traffic. The lanes were relatively narrow at only wide. In July 1922, motor vehicles were banned from the bridge; the ban lasted until May 1925.\nAfter 1950, the main roadway carried six lanes of automobile traffic, three in each direction. It was then reduced to five lanes with the addition of a two-way bike lane on the Manhattan-bound side in 2021. Because of the roadway's posted height restriction of and weight restriction of , commercial vehicles and buses are prohibited from using the Brooklyn Bridge. The weight restrictions prohibit heavy passenger vehicles such as pickup trucks and SUVs from using the bridge, though this is not often enforced in practice.\nOn the Brooklyn side, vehicles can enter the bridge from Tillary/Adams Streets to the south, Sands/Pearl Streets to the west, and exit 28B of the eastbound Brooklyn-Queens Expressway. In Manhattan, cars can enter from both the northbound and southbound FDR Drive, as well as Park Row to the west, Chambers/Centre Streets to the north, and Pearl Street to the south. However, the exit from the bridge to northbound Park Row was closed after the September 11 attacks because of increased security concerns: that section of Park Row ran under One Police Plaza, the NYPD headquarters.\nExit list.\nVehicular access to the bridge is provided by a complex series of ramps on both sides of the bridge. There are two entrances to the bridge's pedestrian promenade on either side. The current configuration, including the closed ramp from the bridge to the northbound Park Row, was constructed from the mid-1950s until the early 1970s.\nRail traffic.\nFormerly, rail traffic operated on the Brooklyn Bridge as well. Cable cars and elevated railroads used the bridge until 1944, while trolleys ran until 1950.\nCable cars and elevated railroads.\nThe New York and Brooklyn Bridge Railway, a cable car service, began operating on September\u00a025, 1883; it ran on the inner lanes of the bridge, between terminals at the Manhattan and Brooklyn ends. Since Washington Roebling believed that steam locomotives would put excessive loads upon the structure of the Brooklyn Bridge, the cable car line was designed as a steam/cable-hauled hybrid. They were powered from a generating station under the Brooklyn approach. The cable cars could not only regulate their speed on the &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3+3\u20444% upward and downward approaches, but also maintain a constant interval between each other. There were 24 cable cars in total.\nInitially, the service ran with single-car trains, but patronage soon grew so much that by October 1883, two-car trains were in use. The line carried three million people in the first six months, nine million in 1884, and nearly 20\u00a0million in 1885 following the opening of the Brooklyn Union Elevated Railroad. Accordingly, the track layout was rearranged and more trains were ordered. At the same time, there were highly controversial plans to extend the elevated railroads onto the Brooklyn Bridge, under the pretext of extending the bridge itself. After disputes, the trustees agreed to build two elevated routes to the bridge on the Brooklyn side. Patronage continued to increase, and in 1888, the tracks were lengthened and even more cars were constructed to allow for four-car cable car trains. Electric wires for the trolleys were added by 1895, allowing for the potential future decommissioning of the steam/cable system. The terminals were rebuilt once more in July 1895, and, following the implementation of new electric cars in late 1896, the steam engines were dismantled and sold.\nFollowing the unification of the cities of New York and Brooklyn in 1898, the New York and Brooklyn Bridge Railway ceased to be a separate entity that June and the Brooklyn Rapid Transit Company (BRT) assumed control of the line. The BRT started running through-services of elevated trains, which ran from Park Row Terminal in Manhattan to points in Brooklyn via the Sands Street station on the Brooklyn side. Before reaching Sands Street (at Tillary Street for Fulton Street Line trains, and at Bridge Street for Fifth Avenue Line and Myrtle Avenue Line trains), elevated trains bound for Manhattan were uncoupled from their steam locomotives. The elevated trains were then coupled to the cable cars, which would pull the passenger carriages across the bridge.\nThe BRT did not run any elevated train through services from 1899 to 1901. Due to increased patronage after the opening of the Interborough Rapid Transit Company (IRT)'s first subway line, the Park Row station was rebuilt in 1906. In the early 20th century, there were plans for Brooklyn Bridge elevated trains to run underground to the BRT's proposed Chambers Street station in Manhattan, though the connection was never opened. The overpass across William Street was closed in 1913 to make way for the proposed connection. In 1929, the overpass was reopened after it became clear that the connection would not be built.\nAfter the IRT's Joralemon Street Tunnel and the Williamsburg Bridge tracks opened in 1908, the Brooklyn Bridge no longer held a monopoly on rail service between Manhattan and Brooklyn, and cable service ceased. New subway lines from the IRT and from the BRT's successor Brooklyn\u2013Manhattan Transit Corporation (BMT), built in the 1910s and 1920s, posed significant competition to the Brooklyn Bridge rail services. With the opening of the Independent Subway System in 1932 and the subsequent unification of all three companies into a single entity in 1940, the elevated services started to decline, and the Park Row and Sands Street stations were greatly reduced in size. The Fifth Avenue and Fulton Street services across the Brooklyn Bridge were discontinued in 1940 and 1941 respectively, and the elevated tracks were abandoned permanently with the withdrawal of Myrtle Avenue services in 1944.\nTrolleys.\nA plan for trolley service across the Brooklyn Bridge was presented in 1895. Two years later, the Brooklyn Bridge trustees agreed to a plan where trolleys could run across the bridge under ten-year contracts. Trolley service, which began in 1898, ran on what are now the two middle lanes of each roadway (shared with other traffic). Brooklyn Bridge Local trolley service between the two ends of the bridge was introduced in January 1908. The cable cars were discontinued immediately afterward, and the shuttle was also eliminated. After cable service was withdrawn, the trolley tracks on the Brooklyn side were rebuilt to alleviate congestion. Trolley service on the middle lanes continued until the elevated lines stopped using the bridge in 1944, when they moved to the protected center tracks. On March\u00a05, 1950, the streetcars also stopped running, and the bridge was redesigned exclusively for automobile traffic.\nWalkway.\nThe Brooklyn Bridge has an elevated promenade open to pedestrians in the center of the bridge, located above the automobile lanes. The promenade is usually located below the height of the girders, except at the approach ramps leading to each tower's balcony. The path is generally wide, though this is constrained by obstacles such as protruding cables, benches, and stairways, which create \"pinch points\" at certain locations. The path narrows to at the locations where the main cables descend to the level of the promenade. Further exacerbating the situation, these \"pinch points\" are some of the most popular places to take pictures. As a result, in 2016, the NYCDOT announced that it planned to double the promenade's width.\nA center line was painted to separate cyclists from pedestrians in 1971, creating one of the city's first dedicated bike lanes. Initially, the northern side of the promenade was used by pedestrians and the southern side by cyclists. In 2000, these were swapped, with cyclists taking the northern side and pedestrians taking the southern side. On September 14, 2021, the NYCDOT closed off the left-side car lane on the Manhattan-bound side with protective barriers and fencing to create a new bike path, and cyclists were banned from the upper pedestrian lane.\nPedestrian access to the bridge from the Brooklyn side is from either the median of Adams Street at its intersection with Tillary Street or a staircase near Prospect Street between Cadman Plaza East and West. In Manhattan, the pedestrian walkway is accessible from crosswalks at the intersection of the bridge and Centre Street, or through a staircase leading to Park Row.\nEmergency use.\nWhile the bridge has always permitted the passage of pedestrians, the promenade facilitates movement when other means of crossing the East River have become unavailable. During transit strikes by the Transport Workers Union in 1980 and 2005, people commuting to work used the bridge; they were joined by Mayors Ed Koch and Michael Bloomberg, who crossed as a gesture to the affected public. Pedestrians also walked across the bridge as an alternative to suspended subway services following the 1965, 1977, and 2003 blackouts, and after the September 11 attacks.\nDuring the 2003 blackouts, many crossing the bridge reported a swaying motion. The higher-than-usual pedestrian load caused this swaying, which was amplified by the tendency of pedestrians to synchronize their footfalls with a sway. Several engineers expressed concern about how this would affect the bridge, although others noted that the bridge did withstand the event and that the redundancies in its design\u2014the inclusion of the three support systems (suspension system, diagonal stay system, and stiffening truss)\u2014make it \"probably the best secured bridge against such movements going out of control\". In designing the bridge, John Roebling had stated that the bridge would sag but not fall, even if one of these structural systems were to fail altogether.\nTolls.\nThe Brooklyn Bridge was initially a toll bridge. Though carriages and cable-car customers had paid tolls ever since the bridge's opening, pedestrians were spared from the tolls originally. By the first decade of the 20th century, pedestrians were also paying tolls. Tolls on all four bridges across the East River\u2014the Brooklyn Bridge, as well as the Manhattan, Williamsburg, and Queensboro bridges to the north\u2014were abolished in July 1911 as part of a populist policy initiative headed by New York City mayor William Jay Gaynor.\nIn 1970, the federal government enacted the Clean Air Act, a series of federal air pollution regulations. As part of a plan by mayor John Lindsay and the federal Environmental Protection Agency, the city government considered implementing tolls on the four free East River bridges, including the Brooklyn Bridge, in the early 1970s. The plan would have raised money for New York City's transit system and allowed the city to meet the Clean Air Act. Abraham Beame, who became mayor in 1974, refused to implement the tolls, and the United States Congress subsequently moved to forbid tolls on the free East River bridges. The United States Department of Transportation determined that several of these bridges were built partially with federal funds and, under federal law, could not be tolled.\nA plan for congestion pricing in New York City was approved in mid-2023, allowing the Metropolitan Transportation Authority to toll drivers who enter Manhattan south of 60th Street. Congestion pricing was implemented in January 2025. Most traffic between the Brooklyn Bridge and FDR Drive is exempt from the toll, but all other Manhattan-bound drivers pay a toll, which varies based on the time of day. Although no toll is charged upon exiting the congestion zone, Brooklyn-bound drivers must pay a toll to access streets leading to the bridge, unless they use the FDR Drive.\nNotable events.\nStunts.\nThere have been several notable jumpers from the Brooklyn Bridge. The first person was Robert Emmet Odlum, brother of women's rights activist Charlotte Odlum Smith, on May\u00a019, 1885. He struck the water at an angle and died shortly afterwards from internal injuries. Steve Brodie supposedly dropped from underneath the bridge in July 1886 and was briefly arrested for it, though there is some doubt about whether he actually jumped. Larry Donovan made a slightly higher jump from the railing a month afterward. The first known person to jump from the bridge with the intention of suicide was Francis McCarey in 1892. A lesser known early jumper was James Duffy of County Cavan, Ireland, who on April\u00a015, 1895, asked several men to watch him jump from the bridge. Duffy jumped and was not seen again. Additionally, the cartoonist Otto Eppers jumped and survived in 1910, and was then tried and acquitted for attempted suicide. The Brooklyn Bridge has since developed a reputation as a suicide bridge due to the number of jumpers who do so intending to kill themselves, though exact statistics are difficult to find.\nOther notable feats have taken place on or near the bridge. In 1919, Giorgio Pessi piloted what was then one of the world's largest airplanes, the Caproni Ca.5, under the bridge. In 1993, bridge jumper Thierry Devaux illegally performed eight acrobatic bungee jumps above the East River close to the Brooklyn tower.\nCrimes and terrorism.\nOn March\u00a01, 1994, Lebanese-born Rashid Baz opened fire on a van carrying members of the Chabad-Lubavitch Orthodox Jewish Movement, striking 16-year-old student Ari Halberstam and three others traveling on the bridge. Halberstam died five days later from his wounds, and Baz was later convicted of murder. He was apparently acting out of revenge for the Hebron massacre of Palestinian Muslims a few days prior to the incident. After initially classifying the killing as one committed out of road rage, the Justice Department reclassified the case in 2000 as a terrorist attack. The entrance ramp to the bridge on the Manhattan side was dedicated as the Ari Halberstam Memorial Ramp in 1995.\nSeveral potential attacks or disasters have also been averted. In 1979, police disarmed a stick of dynamite placed under the Brooklyn approach, and an artist in Manhattan was arrested that year after another bombing attempt. In 2003, truck driver Iyman Faris was sentenced to about 20 years in prison for providing material support to Al-Qaeda, after an earlier plot to destroy the bridge by cutting through its support wires with blowtorches was thwarted.\nArrests.\nAt 9:00\u00a0a.m. on May\u00a019, 1977, artist Jack Bashkow climbed one of the towers for \"Bridging\", a \"media sculpture\" by the performance group Art Corporation of America Inc. Seven artists climbed the largest bridges connected to Manhattan \"to replace violence and fear in mass media for one day\". When each of the artists had reached the tops of the bridges, they ignited bright-yellow flares at the same moment, resulting in rush hour traffic disruption, media attention, and the arrest of the climbers, though the charges were later dropped. Called \"the first social-sculpture to use mass-media as art\" by conceptual artist Joseph Beuys, the event was on the cover of the \"New York Post\", received international attention, and received ABC Eyewitness News' \"1977 Best News of the Year\" award. John Halpern documented the incident in the film \"Bridging, 1977\". Halpern attempted another \"bridging\" \"social sculpture\" in 1979, when he planted a radio receiver, gunpowder and fireworks in a bucket atop one of the towers. The piece was later discovered by police, leading to his arrest for possessing a bomb.\nOn October 1, 2011, more than 700 protesters with the Occupy Wall Street movement were arrested while attempting to march across the bridge on the roadway. Protesters disputed the police account of the events and claimed that the arrests were the result of being trapped on the bridge by the NYPD. The majority of the arrests were subsequently dismissed.\nOn July\u00a022, 2014, the two American flags on the flagpoles atop each tower were found to have been replaced by bleached-white American flags. Initially, cannabis activism was suspected as a motive, but on August\u00a012, 2014, two Berlin artists claimed responsibility for hoisting the two white flags, having switched out the original flags with their replicas. The artists said that the flags were meant to celebrate \"the beauty of public space\" and the anniversary of the death of German-born John Roebling, and they denied that it was an \"anti-American statement\".\nAnniversary celebrations.\nThe 50th-anniversary celebrations on May\u00a024, 1933, included a ceremony featuring an airplane show, ships, and fireworks, as well as a banquet. During the centennial celebrations on May\u00a024, 1983, a flotilla of ships visited the harbor, officials held parades, and Grucci Fireworks held a fireworks display that evening. For the centennial, the Brooklyn Museum exhibited a selection of the original drawings made for the bridge's construction, including those by Washington Roebling. Media coverage of the centennial was declared \"the public relations triumph of 1983\" by \"Inc.\"\nThe 125th anniversary of the bridge's opening was celebrated by a five-day event on May\u00a022\u201326, 2008, which included a live performance by the Brooklyn Philharmonic, a special lighting of the bridge's towers, and a fireworks display. Other events included a film series, historical walking tours, information tents, a series of lectures and readings, a bicycle tour of Brooklyn, a miniature golf course featuring Brooklyn icons, and other musical and dance performances. Just before the anniversary celebrations, artist Paul St George installed the Telectroscope, a video link on the Brooklyn side of the bridge that connected to a matching device on London's Tower Bridge. A renovated pedestrian connection to Dumbo, Brooklyn, was also reopened before the anniversary celebrations.\nCollisions.\nOver the years, numerous vessels have struck the bridge. In 1921, the steel mast of the schooner \"Edward J. Lawrence\" was bent while being towed under the bridge deck. and in 1935, three of the four steel masts on the freighter \"Tirpitz\" hit the bridge deck. Additionally, the radar of the freighter \"Hai Soo\" was destroyed in 1986 when it struck a net below the Brooklyn Bridge's deck.\nThe masts of the Mexican Navy training ship ARM \"Cuauht\u00e9moc\" smashed into the bridge deck on May 17, 2025, with approximately 200 people on the ship. The ship masts were at least higher than the Brooklyn Bridge's navigational clearance of . Two persons were killed and 19 injured, but the structure of the bridge was undamaged.\nImpact.\nAt the time of construction, contemporaries marveled at what technology was capable of, and the bridge became a symbol of the era's optimism. John Perry Barlow wrote in the late 20th century of the \"literal and genuinely religious leap of faith\" embodied in the bridge's construction, saying that the \"Brooklyn Bridge required of its builders faith in their ability to control technology\".\nHistorical designations and plaques.\nThe Brooklyn Bridge has been listed as a National Historic Landmark since January\u00a029, 1964, and was subsequently added to the National Register of Historic Places on October\u00a015, 1966. The bridge has also been a New York City designated landmark since August\u00a024, 1967, and was designated a National Historic Civil Engineering Landmark in 1972. In addition, it was placed on UNESCO's list of tentative World Heritage Sites in 2017.\nA bronze plaque is attached to the Manhattan anchorage, which was constructed on the site of the Samuel Osgood House at 1\u00a0Cherry Street in Manhattan. Named after Samuel Osgood, a Massachusetts politician and lawyer, it was built in 1770 and served as the first U.S. presidential mansion. The Osgood House was demolished in 1856.\nAnother plaque on the Manhattan side of the pedestrian promenade, installed by the city in 1975, indicates the bridge's status as a city landmark.\nCulture.\nThe Brooklyn Bridge has had an impact on idiomatic American English. For example, references to \"selling the Brooklyn Bridge\" are frequent in American culture, sometimes presented as a historical reality but more often as an expression meaning an idea that strains credulity. George C. Parker and William McCloundy were two early 20th-century con men who may have perpetrated this scam successfully, particularly on new immigrants, although the author of \"The Brooklyn Bridge: A Cultural History\" wrote, \"No evidence exists that the bridge has ever been sold to a 'gullible outlander'\".\nAs a tourist attraction, the Brooklyn Bridge is a popular site for clusters of love locks, wherein a couple inscribes a date and their initials onto a lock, attach it to the bridge, and throw the key into the water as a sign of their love. The practice is illegal in New York City and the NYPD can give violators a $100 fine. NYCDOT workers periodically remove the love locks from the bridge at a cost of $100,000 per year.\nTo highlight the Brooklyn Bridge's cultural status, the city proposed building a Brooklyn Bridge museum near the bridge's Brooklyn end in the 1970s. Though the museum was ultimately not constructed, as many as 10,000 drawings and documents relating to it were found in a carpenter shop in Williamsburg in 1976. These documents were given to the New York City Municipal Archives, where they are normally located, though a selection of them were displayed at the Whitney Museum of American Art when they were discovered.\nMedia.\nThe bridge is often featured in wide shots of the New York City skyline in television and film and has been depicted in numerous works of art. Fictional works have used the Brooklyn Bridge as a setting; for instance, the dedication of a portion of the bridge, and the bridge itself, were key components in the 2001 film \"Kate &amp; Leopold\". Furthermore, the Brooklyn Bridge has also served as an icon of America, with mentions in numerous songs, books, and poems. Among the most notable of these works is that of American Modernist poet Hart Crane, who used the Brooklyn Bridge as a central metaphor and organizing structure for his second book of poetry, \"The Bridge\" (1930).\nThe Brooklyn Bridge has also been lauded for its architecture. One of the first positive reviews was \"The Bridge As A Monument\", a \"Harper's Weekly\" piece written by architecture critic Montgomery Schuyler and published a week after the bridge's opening. In the piece, Schuyler wrote: \"It so happens that the work which is likely to be our most durable monument, and to convey some knowledge of us to the most remote posterity, is a work of bare utility; not a shrine, not a fortress, not a palace, but a bridge.\" Architecture critic Lewis Mumford cited the piece as the impetus for serious architectural criticism in the U.S. He wrote that in the 1920s the bridge was a source of \"joy and inspiration\" in his childhood, and that it was a profound influence in his adolescence. Later critics would regard the Brooklyn Bridge as a work of art, as opposed to an engineering feat or a means of transport. Not all critics appreciated the bridge, however. Henry James, writing in the early 20th century, cited the bridge as an ominous symbol of the city's transformation into a \"steel-souled machine room\".\nThe construction of the Brooklyn Bridge is detailed in numerous media sources, including David McCullough's 1972 book \"The Great Bridge\" and Ken Burns's 1981 documentary \"Brooklyn Bridge\". It is also described in \"Seven Wonders of the Industrial World\", a BBC docudrama series with an accompanying book, as well as \"Chief Engineer: Washington Roebling, The Man Who Built the Brooklyn Bridge\", a biography published in 2017.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\nWikisource items:\n\u200b\n&lt;/td&gt;\n&lt;/tr&gt;&lt;/table&gt;"}
{"id": "47744", "revid": "48035214", "url": "https://en.wikipedia.org/wiki?curid=47744", "title": "Land for peace", "text": "Legal interpretation in the Arab-Israeli conflict\nLand for peace is a legalistic interpretation of UN Security Council Resolution 242 which has been used as the basis of subsequent Arab\u2013Israeli peace making. The name \"Land for Peace\" is derived from the wording of the resolution's first operative paragraph which affirms that peace should include the application of two principles: Withdrawal of Israeli forces (Giving Up Land), and Termination of all claims or states of belligerency (Making Peace). Since the resolution stipulates that both principles should apply, they can be viewed jointly as giving up land for peace, referred to more concisely as \"land for peace\".\nThis interpretation is widely contested because it implies that Israeli withdrawal is linked to its neighbours' willingness to formally make peace. Competing interpretations of the resolution regard Israel as being obligated to withdraw unilaterally from all territories captured in 1967. Operative paragraph 1 of Resolution 242 reads as follows:\n1. Affirms that the fulfillment of Charter principles requires the establishment of a just and lasting peace in the Middle East which should include the application of both the following principles:\n (i) Withdrawal of Israel armed forces from territories occupied in the recent conflict;\n (ii) Termination of all claims or states of belligerency and respect for and acknowledgement of the sovereignty, territorial integrity and political independence of every State in the area and their right to live in peace within secure and recognized boundaries free from threats or acts of force;\nIn 1976, when Lord Caradon was asked about the concessions the Arab states would have to make to Israel as part of an overall settlement, he said \"Well, that's perfectly obvious if you read again the principles of 242, which have been accepted by Egypt, Jordan, Syria and Saudi Arabia, and in effect by Israel. The provision is that if there is an adequate withdrawal, all states in the area must be free to live within secure and recognized boundaries, free from force and threat of force. So it is an acceptance that Israel has a right to exist, just as they would have a right to their homeland, and have a right to exist. This is the essential bargain that we are proposing. It's not a new thing, it's been going since 1967.\nPeace treaties.\nOn 19 June 1967, shortly after the Six-Day War, the Israeli government voted to return the Sinai to Egypt and the Golan Heights to Syria in exchange for a permanent peace settlement and a demilitarization of the returned territories. This decision was not made public at the time, nor was it conveyed to any Arab state. Israeli Foreign Minister Abba Eban has said that it had been conveyed, but there seems to be no solid evidence to corroborate his claim; no formal peace proposal was made either directly or indirectly by Israel. The Americans, who were briefed of the Cabinet's decision by Eban, were not asked to convey it to Cairo and Damascus as official peace proposals, nor were they given indications that Israel expected a reply. Eban rejected the prospect of a mediated peace, insisting on the need for direct negotiations with the Arab governments.\nThe Arab position, as it emerged in September 1967 at the Khartoum Arab Summit, was to reject any peaceful settlement with the State of Israel. The eight participating states\u2014Egypt, Syria, Jordan, Lebanon, Iraq, Algeria, Kuwait, and Sudan\u2014passed a resolution that would later become known as the \"three no's\": there would be no peace, no recognition and no negotiation with Israel. Prior to that, King Hussein of Jordan had stated that he could not rule out a possibility of a \"real, permanent peace\" between Israel and the Arab states.\nThe first application of the land for peace formula was Israel's peace treaty with Egypt in 1979, under which Israel withdrew from the Sinai as part of a comprehensive peace agreement facilitated by economic assistance to both sides from the United States.\nIn 1994 a similar comprehensive agreement invoking resolution 242 formed the basis of the Israel Jordan peace treaty whereby both sides redeployed to their respective sides of the agreed international boundary.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47748", "revid": "40192293", "url": "https://en.wikipedia.org/wiki?curid=47748", "title": "Bjork", "text": ""}
{"id": "47749", "revid": "22651524", "url": "https://en.wikipedia.org/wiki?curid=47749", "title": "West bank", "text": ""}
{"id": "47750", "revid": "48984234", "url": "https://en.wikipedia.org/wiki?curid=47750", "title": "Gaza strip", "text": ""}
{"id": "47751", "revid": "29566584", "url": "https://en.wikipedia.org/wiki?curid=47751", "title": "Gloucestershire", "text": "County of England\nGloucestershire ( , ; abbreviated Glos.) is a ceremonial county in South West England. It is bordered by Herefordshire to the north-west, Worcestershire to the north, Warwickshire to the north-east, Oxfordshire to the east, Wiltshire to the south, Bristol and Somerset to the south-west, and the Welsh county of Monmouthshire to the west. The largest settlement is the city of Gloucester.\nThe county is predominantly rural, with an area of , and a population of 975,712 in 2024. Gloucester is located in the north-centre of the county, and the spa town of Cheltenham is immediately to the east. Other towns include Tewkesbury in the north, Cirencester in the east, Stroud in the centre, and Yate in the south. The far south of the county, including Filton and Kingswood, is densely populated and forms part of the Bristol built-up area. For local government purposes Gloucestershire comprises a non-metropolitan county, with six districts, and the unitary authority area of South Gloucestershire. South Gloucestershire Council is a member of the West of England Combined Authority.\nGloucestershire is bisected by the river River Severn, which enters the county near Tewkesbury and forms a wide valley down its centre before broadening into a large tidal estuary. The east of the county contains the majority of the Cotswolds, and the uplands in the west are part of the Forest of Dean and the Wye Valley. All three areas have been designated national landscapes.\nGloucestershire was likely established in the tenth century and expanded to approximately its current borders in the eleventh. The county was relatively settled during the late Middle Ages, and contained several wealthy monasteries such as Tewkesbury, Gloucester, Hailes, and Cirencester; the Forest of Dean was also a major iron-producing region in this period. The city of Bristol became an independent county in 1373, by which point it was the third-largest city in England. Gloucestershire was not heavily industrialised during the Industrial Revolution, but the Port of Gloucester was expanded with new docks and the small Forest of Dean coalfield was exploited.\nHistory.\nGloucestershire is a historic county mentioned in the \"Anglo-Saxon Chronicle\" in the 10th century, though the areas of Winchcombe and the Forest of Dean were not added until the late 11th century.\nGloucestershire originally included Bristol, then a small town. Members of local rural communities moved to the port city (which was to become Bristol), and Bristol's population grew rapidly during the Industrial Revolution. Bristol became a county in its own right, separate from Gloucestershire and Somerset, in 1373. It later became part of the administrative County of Avon from 1974 to 1996. Some northern parts of the county, including Long Marston and Welford-on-Avon, were transferred to Warwickshire in 1931.\nUpon the abolition of Avon in 1996, the region north of Bristol became a unitary authority area of South Gloucestershire and is now part of the ceremonial county of Gloucestershire. In March 2008, the ceremonial county of Gloucestershire adopted a flag through a contest judged by the High Sheriff of Gloucestershire, Jonathan Carr.\nIn July 2007, Gloucestershire was subject to some of the worst flooding in recorded British history, with tens of thousands of residents affected. The RAF conducted the largest peacetime domestic operation in its history to rescue over 120 residents from flood-affected areas. The damage was estimated at over \u00a32\u00a0billion.\nGeography and environment.\nGloucestershire has three main landscape areas: a large part of the Cotswolds, the Royal Forest of Dean, and the Severn Vale. The Cotswolds take up a large portion of the east and south of the county, the Forest of Dean taking up the west, with the Severn and its valley running between these features. The Daffodil Way in the Leadon Valley, on the border of Gloucestershire and Herefordshire surrounding the village of Dymock, is known for its many spring flowers, orchards, and woodland, which attracts many walkers. In the west, the Wye Valley borders Wales.\nDemography.\nEthnicity.\nFor the overwhelming majority of Gloucestershire\u2019s history, the population of the ceremonial county was ethnically homogeneous, with the population being of White British ethnicity. In the 2021 census, the ceremonial county of Gloucestershire had a usual resident population of 935,500. The ceremonial county of Gloucestershire is divided between one non-metropolitan county: Gloucestershire County Council, which, in the 2021 census, had a usual resident population of 645,100, and one unitary authority: South Gloucestershire Council, which, in the 2021 census, had a usual resident population of 290,400. In the 2021 census, the ethnic composition of the ceremonial county of Gloucestershire comprised: 92.5% White; 3.2% Asian; 1.3% Black; 2.3% Mixed; and 0.8% Other.\n \nReligion.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nIn the 2021 census, the religious composition of the ceremonial county of Gloucestershire comprised: 47.6% Christianity; 42.8% No religion; 1.5% Islam; 0.7% Hinduism; 0.4% Buddhism; 0.2% Sikhism; 0.1% Judaism; 0.5% Other religion; and 6.1% Not stated.\nGovernance.\nThe 2025 Gloucestershire County Council election was held on 1 May 2025. The council had been under no overall control prior to the election, being run by a Conservative minority administration. Following the election, the council remained under no overall control, with the Liberal Democrats becoming the largest party and Reform UK becoming the second largest party. At the subsequent annual council meeting on 21 May 2025, Liberal Democrat councillor Lisa Spivey was appointed leader of a Liberal Democrat minority administration. The County Council shares responsibility with six district councils: Tewkesbury, Forest of Dean, City of Gloucester, Cheltenham, Stroud, and Cotswold.\nThe southernmost part of the county, South Gloucestershire, is governed by South Gloucestershire Council, which is a unitary authority council independent of the county council, but the unitary authority is still part of the ceremonial county. Previously, the area of South Gloucestershire was part of the county of Avon. Although Avon was abolished in 1996, some services in South Gloucestershire are still provided in conjunction with other former parts of Avon county, such as the Avon Fire and Rescue Service. Since 2017, South Gloucestershire has been part of the West of England Combined Authority, which led by the mayor of the West of England.\nThe 2023 South Gloucestershire Council election was held on 4 May 2023. The council had been under Conservative majority control prior to the election. Following the election, the council is under no overall control, with the Conservatives remaining the largest party and the Liberal Democrats remaining the second largest party. At the subsequent annual council meeting on 24 May 2023, the Liberal Democrat councillor Claire Young was appointed leader of a Liberal Democrat\u2013Labour coalition administration. In the 2024 United Kingdom general election, Claire Young was elected Member of Parliament for Thornbury and Yate, resulting in Liberal Democrat councillor Maggie Tyrrell being appointed the new leader of the coalition administration.\nThere are six parliamentary constituencies in Gloucestershire, all of which are Conservative-controlled as of the 2019 general election. Due to the 2023 Periodic Review of Westminster constituencies, Gloucestershire will be combined with Wiltshire for parliamentary boundary purposes, allowing cross-county electoral divisions.\nEconomy.\nThis is a chart of trend of regional gross value added of Gloucestershire at current basic prices https:// (pp.\u00a0240\u2013253) by \"Office for National Statistics\" with figures in millions of Pounds Sterling.\nThe following is a chart of Gloucestershire's gross value added total in millions of Pounds Sterling from 1997 to 2009 based upon the Office for National Statistics figures\nThe 2009 estimation of \u00a311,452\u00a0million GVA can be compared to the South West regional average of \u00a37,927\u00a0million.\nEducation.\nSecondary schools.\nGloucestershire has mainly comprehensive schools with seven selective grammar schools; two are in Stroud, Stroud High School for girls and Marling School for boys, one in Cheltenham, Pate's Grammar, and four in Gloucester, Sir Thomas Rich's for boys (aged 11\u201318) and girls (aged 16\u201318, in the sixth form), and Denmark Road High School and Ribston Hall for girls and The Crypt which is mixed. There are 42 state secondary schools, not including sixth form colleges, and 12 independent schools, including Cheltenham Ladies' College, Cheltenham College, and Dean Close School. All but about two schools in each district have a sixth form, but the Forest of Dean only has two schools with sixth forms. All schools in South Gloucestershire have sixth forms.\nHigher and further education.\nGloucestershire has two universities, the University of Gloucestershire and the Royal Agricultural University, and four higher and further education colleges, Gloucestershire College, Cirencester College, South Gloucestershire and Stroud College, and the Royal Forest of Dean College. Each has campuses at multiple locations throughout the county.\nThe University of the West of England also has three locations in Gloucestershire; an associate faculty (Hartpury College) specialising in animal behaviour and welfare, agricultural and sports-related courses in Hartpury, Gloucestershire; a regional centre at the Gloucester Docks, Alexandra Warehouse, specialising in Adult and Mental Health Nursing; and Frenchay Campus in South Gloucestershire.\nTowns and cities.\nGloucestershire has one city and 33 towns:\nTowns.\nThe towns in Gloucestershire are:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSuburban town of Stroud:\nTown in Monmouthshire with suburbs in Gloucestershire:\nGreen belt.\nThe county has two green belt areas, the first covers the southern area in the South Gloucestershire district, to protect outlying villages and towns between Thornbury and Chipping Sodbury from the urban sprawl of the Bristol conurbation. The second belt lies around Gloucester, Cheltenham, and Bishop's Cleeve, to afford those areas and villages in between a protection from urban sprawl and further convergence. Both belts intersect with the boundaries of the Cotswolds AONB.\nTransport.\nRailways.\nGloucestershire once had a much larger railway network than it does now with over 100 stations in the county, the vast majority of which were closed during the Beeching cuts. Nowadays, only 15 remain within the county, mostly concentrated on the CrossCountry NE-SW route and around the North Fringe of Bristol. Some stations have been reopened in recent years; Cam and Dursley railway station opened in 1994, with Ashchurch for Tewkesbury opening three years later in 1997. Local campaign groups are also seeking to reopen several disused stations, including Charfield railway station in South Gloucestershire.\nAntiquities.\nThere are a number of Roman remains scattered across the county, including the Eastgate Viewing Chamber in Gloucester and Chedworth Roman Villa.\nThere are a variety of religious buildings across the county, notably the cathedral of Gloucester, the abbey church of Tewkesbury (which is over 500 years old and has the tallest Norman tower in England), and the church of Cirencester. Of the abbey of Hailes near Winchcombe, founded by Richard, Earl of Cornwall, in 1246, little more than the foundations are left, but these have been excavated and fragments have been brought to light.\nMost of the old market towns have parish churches. At Deerhurst near Tewkesbury and Bishop's Cleeve near Cheltenham, there are churches of special interest on account of the pre-Norman work they retain. There is also a Perpendicular church in Lechlade, and that at Fairford was built (c.\u20091500), according to tradition, to contain a series of stained-glass windows which are said to have been brought from the Netherlands. These are, however, adjudged to be of English workmanship.\nOther notable buildings include Calcot Barn in Calcot, a relic of Kingswood Abbey. Thornbury Castle is a Tudor country house, the pretensions of which evoked the jealousy of Cardinal Wolsey against its builder, Edward Stafford, duke of Buckingham, who was beheaded in 1521. Near Cheltenham is the 15th-century mansion of Southam de la Bere, of timber and stone. Memorials of the de la Bere family appear in the church at Cleeve. The mansion contains a tiled floor from Hailes Abbey. At Great Badminton is the mansion and vast domain of the Beauforts (formerly of the Botelers and others), on the south-eastern boundary of the county. Berkeley Castle at over 800 years old and the ruins of Witcombe Roman Villa at Great Witcombe are also notable heritage features.\nThere are several royal residences in Gloucestershire, including Highgrove House, Gatcombe Park, and (formerly) Nether Lypiatt Manor.\nAn annual \"cheese-rolling\" event takes place at Cooper's Hill, near Brockworth, and the Cotswold Games occurred within the county.\nPlaces of interest.\nPlaces of interest in Gloucestershire include:\nAreas of countryside in Gloucestershire include:\nScenic Railway Line:\nMedia.\nGloucestershire's only daily newspaper is the Western Daily Press, while The Citizen, which covers Gloucester, Stroud and the Forest of Dean, and the \"Gloucestershire Echo\", which covers Cheltenham, Tewkesbury and the Cotswolds, were published daily but since October 2017 have been weekly publications. All three, along with free weeklies 'The Forester', 'Stroud Life', 'The Gloucester News', and 'The Cheltenham and Tewkesbury News', are published by Local World.\nThe \"Stroud News &amp; Journal\" is a weekly paid-for newspaper based in Stroud. It is published in a tabloid format by Newsquest. Newsquest also produces the weekly \"Wilts and Gloucestershire Standard\" newspaper, which covers the southern and eastern parts of the county as well as the weekly \"Gloucestershire Gazette\", which covers the south of the county and much of South Gloucestershire.\n\"Gloucester News Centre\" is an independent news website with news and information for Gloucestershire.\nRadio stations in Gloucestershire include BBC Radio Gloucestershire, BBC Radio Bristol (for South Gloucestershire), Heart West, Sunshine Radio and Greatest Hits Radio Gloucestershire. There are also several community radio stations including Gloucester FM, Radio Winchcombe, Forest of Dean Radio, North Cotswold Community Radio, and Severn FM.\nLocal TV for the county is provided by BBC West and ITV West Country from Bristol, although in the northern extremes of Gloucestershire, BBC Midlands and ITV Central (West) from Birmingham covers this area. Some eastern parts of the county (Cirencester and parts of the Cotswolds) receive BBC South and ITV Meridian from Oxford.\nIn popular culture.\nThere are two well-known accounts of childhood in rural Gloucestershire in the early 20th century, Laurie Lee's \"Cider With Rosie\" and Winifred Foley's \"A Child in the Forest\". Part of Mrs. Craik's novel \"John Halifax, Gentleman\" is set in Enderley, a thinly disguised Amberley, where she lived at the time of writing. Most of the book is set in Nortonbury, easily recognisable as Tewkesbury.\nThe county has also been the setting for a number of high-profile movies and TV series, including \"Die Another Day\", the Harry Potter films and the BBC TV series \"Butterflies\".\n\"A Girl's Best Friend\", the pilot for the proposed \"Doctor Who\" spin-off \"K-9 and Company\", was filmed in Gloucestershire. The setting is the fictional town of Moreton Harwood. The fictional town of Leadworth in \"Doctor Who\" is in Gloucestershire. It is the home of companions Amy Pond, Rory Williams and River Song in their childhoods and young adulthoods. Additionally, the 2020 episode \"Fugitive of the Judoon\" was set and filmed at Gloucester Cathedral.\nA fictional Brimpsfield was the village, home of Peter and Abby Grant, in the 1970s BBC TV series \"Survivors\", with a railway connection to London.\nWitcombe Festival is an annual music festival held in Brockworth. As well as music, the three-day festival has its roots deep in cider. The festival consists of four stages and has been headlined by Dizzee Rascal, Plan B, Sigma, Ella Eyre, Example, Wiley, Heather Small, Lethal Bizzle and Tinchy Stryder.\nThe Romano/Celtic temple ruins in Lydney Park contributed to J.R.R. Tolkien's description of The Shire in his Middle-earth Legendarium.\nAnimals.\nThe famous Gloucestershire Old Spots pig is named for Gloucestershire and is historically associated with the county. Sheep roam widely in the Forest of Dean. The Forest of Dean and the Wye Valley also have wild boar.\nGloucester cattle, a rare breed, can still be found in and around Gloucestershire. They can be recognised by the white stripe that runs down the centre of their backs to the tip of their tails. The cattle are famous for producing milk for both Single Gloucester and Double Gloucester cheeses.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\nRudder, Samuel. (1779) \"A New History of Gloucestershire\". Reprint: Nonsuch Publishing, 2006. (Free download of original here: \"\")"}
{"id": "47752", "revid": "44120587", "url": "https://en.wikipedia.org/wiki?curid=47752", "title": "Domesday Book", "text": "11th-century survey of landholding in England\nDomesday Book ( ; the Middle English spelling of \"Doomsday Book\") is a manuscript record of the Great Survey of much of England and parts of Wales completed in 1086 at the behest of William the Conqueror. The manuscript was originally known by the Latin name Liber de Wintonia, meaning \"Book of Winchester\", where it was originally kept in the royal treasury. The \"Anglo-Saxon Chronicle\" states that in 1085 the king sent his agents to survey every shire in England, to list his holdings and dues owed to him.\nWritten in Medieval Latin, it was highly abbreviated and included some vernacular native terms without Latin equivalents. The survey's main purpose was to record the annual value of every piece of landed property to its lord, and the resources in land, labour force, and livestock from which the value derived.\nThe name \"Domesday Book\" came into use in the 12th century. Richard FitzNeal wrote in the (c.\u20091179) that the book was so called because its decisions were unalterable, like those of the Last Judgment, and its sentence could not be quashed.\nThe manuscript is now held at the National Archives in Kew, London. Domesday was first printed in full in 1783, and in 2011 the Open Domesday website made the manuscript available on the Internet.\nThe book is an invaluable primary source for modern historians, especially economic historians. No survey approaching the scope and extent of Domesday Book was attempted again in Britain until the 1873 \"Return of Owners of Land\" (sometimes termed the \"Modern Domesday\") which presented the first complete, post-Domesday picture of the distribution of landed property in the United Kingdom.\nName.\nThe manuscripts do not carry a formal title. The work is referred to internally as a (enrolling), and in other early administrative contexts as the king's (short writings). From about 1100, references appear to the (book) or (charter) of Winchester, its usual place of custody; and from the mid-12th to early 13th centuries to the Winchester or king's (roll).\nTo the English, who held the book in awe, it became known as \"Domesday Book\", in allusion to the Last Judgment and in specific reference to the definitive character of the record. The word \"doom\" was the usual Old English term for a law or judgment; it did not carry the modern overtones of fatality or disaster. Richard FitzNeal, treasurer of England under King Henry II, explained the name's connotations in detail in the (c.1179):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The natives call this book \"Domesday\", that is, the day of judgement. This is a metaphor: for just as no judgement of that final severe and terrible trial can be evaded by any subterfuge, so when any controversy arises in the kingdom concerning the matters contained in the book, and recourse is made to the book, its word cannot be denied or set aside without penalty. For this reason we call this book the \"book of judgements\", not because it contains decisions made in controversial cases, but because from it, as from the Last Judgement, there is no further appeal.\nThe name \"Domesday\" was subsequently adopted by the book's custodians, being first found in an official document in 1221.\nEither through false etymology or deliberate word play, the name also came to be associated with the Latin phrase (\"House of God\"). Such a reference is found as early as the late 13th century, in the writings of Adam of Damerham; and in the 16th and 17th centuries, antiquaries such as John Stow and Sir Richard Baker believed this was the name's origin, alluding to the church in Winchester in which the book had been kept. As a result, the alternative spelling \"Domesdei\" became popular for a while.\nThe usual modern scholarly convention is to call the work \"Domesday Book\" (or simply \"Domesday\"), without a definite article, but the form \"the Domesday Book\" is also found in both academic and non-academic contexts.\nContent and organisation.\nDomesday Book encompasses two independent works (originally in two physical volumes): \"Little Domesday\" (covering Norfolk, Suffolk, and Essex), and \"Great Domesday\" (covering much of the remainder of England\u2014except for lands in the north that later became Westmorland, Cumberland, Northumberland, and the County Palatine of Durham\u2014and parts of Wales bordering and included within English counties). Space was left in Great Domesday for a record of the City of London and Winchester, but they were never written up. Other areas of modern London were then in Middlesex, Surrey, Kent, and Essex and have their place in Domesday Book's treatment of those counties. Most of Cumberland, Westmorland, and the entirety of the County Palatine of Durham and Northumberland were omitted. They did not pay the national land tax called the geld, and the framework for Domesday Book was geld assessment lists.\n\"Little Domesday\", so named because its format is physically smaller than its companion's, is more detailed than Great Domesday. In particular, it includes the numbers of livestock on the home farms (demesnes) of lords, but not peasant livestock. It represents an earlier stage in processing the results of the Domesday Survey before the drastic abbreviation and rearrangement undertaken by the scribe of Great Domesday Book.\nBoth volumes are organised into a series of chapters (literally \"headings\", from Latin \"caput\", \"a head\") listing the manors held by each named tenant-in-chief directly from the king. Tenants-in-chief included bishops, abbots and abbesses, barons from Normandy, Brittany, and Flanders, minor French serjeants, and English thegns. The richest magnates held several hundred manors typically spread across England, though some large estates were highly concentrated. For example, Baldwin the Sheriff had 176 manors in Devon and four nearby in Somerset and Dorset. Tenants-in-chief held variable proportions of their manors in demesne, and had subinfeudated to others, whether their own knights (often tenants from Normandy), other tenants-in-chief of their own rank, or members of local English families. Manors were generally listed within each chapter by the hundred or wapentake (in eastern England), the second tier of local government under the counties, in which they lay.\nEach county's list opened with the king's demesne, which had possibly been the subject of separate inquiry. Under the feudal system, the king was the only true \"owner\" of land in England by virtue of his allodial title. He was thus the ultimate overlord, and even the greatest magnate could do no more than \"hold\" land from him as a tenant (from the Latin verb \"tenere\", \"to hold\") under one of the various contracts of feudal land tenure. Holdings of bishops followed, then of abbeys and religious houses, then of lay tenants-in-chief, and lastly the king's serjeants (\"servientes\") and thegns.\nIn some counties, one or more principal boroughs formed the subject of a separate section. A few have separate lists of disputed titles to land called \"clamores\" (claims). The equivalent sections in Little Domesday are called \"Inuasiones\" (annexations).\nIn total, 268,984 people are tallied in the Domesday Book, each of whom was the head of a household. Some households, such as urban dwellers, were excluded from the count, but the exact parameters remain a subject of historical debate. Sir Michael Postan, for instance, contends that these may not represent all rural households, but only full peasant tenancies, thus excluding landless men and some subtenants (potentially a third of the country's population). H. C. Darby, when factoring in the excluded households and using various different criteria for those excluded (as well as varying sizes for the average household), concludes that the 268,984 households listed most likely indicate a total English population between 1.2 and 1.6 million.\nDomesday names a total of 13,418 places. Apart from the wholly rural portions, which constitute its bulk, Domesday contains entries of interest concerning most towns, which were probably made because of their bearing on the fiscal rights of the crown therein. These include fragments of custumals (older customary agreements), records of the military service due, markets, mints, and so forth. From the towns, from the counties as wholes, and from many of its ancient lordships, the crown was entitled to archaic dues in kind, such as honey.\nThe Domesday Book lists 5,624 mills in the country, which is considered a low estimate since the book is incomplete. For comparison, fewer than 100 mills were recorded in the country a century earlier. Georges Duby indicates this means a mill for every 46 peasant households and implies a great increase in the consumption of baked bread in place of boiled and unground porridge. The book also lists 28,000 slaves, a smaller number than was enumerated in 1066.\nIn the Domesday Book, scribes' orthography was heavily geared towards French, most lacking k and w, regulated forms for sounds and and ending many hard consonant words with \u27e8e\u27e9 as they were accustomed to do with most dialects of French at the time.\nSimilar works.\nIn a parallel development, around 1100, the Normans in southern Italy completed their \"Catalogus Baronum\" based on Domesday Book. The original manuscript was destroyed in the Second World War, but the text survives in printed editions.\nSurvey.\nThe \"Anglo-Saxon Chronicle\" states that planning for the survey was conducted in 1085, and the book's colophon states the survey was completed in 1086. It is not known when exactly Domesday Book was compiled, but the entire copy of Great Domesday appears to have been copied out by one person on parchment (prepared sheepskin), while six scribes seem to have been used for Little Domesday. Writing in 2000, David Roffe argued that the inquest (survey) and the construction of the book were two distinct exercises. He believes the latter was completed, if not started, by William II following his accession to the English throne; William II quashed a rebellion that followed and was based on, though not consequence of, the findings of the inquest.\nMost shires were visited by a group of royal officers (\"legati\") who held a public inquiry, probably in the great assembly known as the shire court. These were attended by representatives of every township as well as of the local lords. The unit of inquiry was the hundred (a subdivision of the county, which then was an administrative entity). The return for each hundred was sworn to by 12 local jurors, half of them English and half of them Norman.\nWhat is believed to be a full transcript of these original returns is preserved for several of the Cambridgeshire Hundreds\u00a0\u2013 the Cambridge Inquisition\u00a0\u2013 and is of great illustrative importance. The \"Inquisitio Eliensis\" is a record of the lands of Ely Abbey. The \"Exon Domesday\" (named because the volume was held at Exeter) covers Cornwall, Devon, Dorset, Somerset, and one manor of Wiltshire. Parts of Devon, Dorset, and Somerset are also missing. Otherwise, this contains the full details supplied by the original returns.\nThrough comparison of what details are recorded in which counties, six Great Domesday \"circuits\" can be determined (plus a seventh circuit for the Little Domesday shires).\nPurpose.\nThree sources discuss the goal of the survey:\nAfter this had the king a large meeting, and very deep consultation with his council, about this land; how it was occupied, and by what sort of men. Then sent he his men over all England into each shire; commissioning them to find out 'How many hundreds of hides were in the shire, what land the king himself had, and what stock upon the land; or, what dues he ought to have by the year from the shire.' Also he commissioned them to record in writing, 'How much land his archbishops had, and his diocesan bishops, and his abbots, and his earls;' and though I may be prolix and tedious, 'What, or how much, each man had, who was an occupier of land in England, either in land or in stock, and how much money it was worth.' So very narrowly, indeed, did he commission them to trace it out, that there was not one single hide, nor a yard of land, nay, moreover (it is shameful to tell, though he thought it no shame to do it), not even an ox, nor a cow, nor a swine was there left, that was not set down in his writ. And all the recorded particulars were afterwards brought to him.\nThe primary purpose of the survey was to ascertain and record the fiscal rights of the king. These were mainly:\nAfter a great political convulsion such as the Norman Conquest, and the following wholesale confiscation of landed estates, William needed to reassert that the rights of the Crown, which he claimed to have inherited, had not suffered in the process. His Norman followers tended to evade the liabilities of their English predecessors. Historians believe the survey was to aid William in establishing certainty and a definitive reference point as to property holdings across the nation, in case such evidence was needed in disputes over Crown ownership.\nThe Domesday survey, therefore, recorded the names of the new holders of lands and the assessments on which their tax was to be paid. But it did more than this; by the king's instructions, it endeavoured to make a national valuation list, estimating the annual value of all the land in the country, (1) at the time of Edward the Confessor's death, (2) when the new owners received it, (3) at the time of the survey, and further, it reckoned, by command, the potential value as well. It is evident that William desired to know the financial resources of his kingdom, and it is probable that he wished to compare them with the existing assessment, which was one of considerable antiquity, though there are traces that it had been occasionally modified. The great bulk of Domesday Book is devoted to the somewhat arid details of the assessment and valuation of rural estates, which were as yet the only important source of national wealth. After stating the assessment of the manor, the record sets forth the amount of arable land, and the number of plough teams (each reckoned at eight oxen) available for working it, with the additional number (if any) that might be employed; then the river-meadows, woodland, pasture, fisheries (i.e. fishing weirs), water-mills, salt-pans (if by the sea), and other subsidiary sources of revenue; the peasants are enumerated in their several classes; and finally the annual value of the whole, past and present, is roughly estimated.\nThe organisation of the returns on a feudal basis, enabled the Conqueror and his officers to see the extent of a baron's possessions; and it also showed to what extent he had under-tenants and the identities of the under-tenants. This was of great importance to William, not only for military reasons but also because of his resolve to command the personal loyalty of the under-tenants (though the \"men\" of their lords) by making them swear allegiance to him. As Domesday Book normally records only the Christian name of an under-tenant, it is not possible to search for the surnames of families claiming a Norman origin. Scholars, however, have worked to identify the under-tenants, most of whom have foreign Christian names.\nThe survey provided the King with information on potential sources of funds when he needed to raise money. It includes sources of income but not expenses, such as castles, unless they needed to be included to explain discrepancies between pre- and post-Conquest holdings of individuals. Typically, this happened in a town, where separately recorded properties had been demolished to make way for a castle.\nEarly British authors thought that the motivation behind the Survey was to put into William's power the lands, so that all private property in land came only from the grant of King William, by lawful forfeiture. The use of the word \"antecessor\" in the Domesday Book is used for the former holders of the lands under Edward the Confessor, and who had been dispossessed by their new owners.\nSubsequent history.\nCustodial history.\nDomesday Book was preserved from the late 11th to the beginning of the 13th centuries in the royal Treasury at Winchester (the Norman kings' capital). It was often called the \"Book\" or \"Roll\" of Winchester. When the Treasury moved to the Palace of Westminster, probably under King John, the book went with it.\nThe two volumes (Great Domesday and Little Domesday) remained in Westminster, save for temporary releases, until the 19th century. They were held originally in various offices of the Exchequer: the Chapel of the Pyx of Westminster Abbey; the Treasury of Receipts; and the Tally Court. But on several occasions they were taken around the country with the Chancellor of the Exchequer: to York and Lincoln in 1300, to York in 1303 and 1319, to Hertford in the 1580s or 1590s, and to Nonsuch Palace, Surrey, in 1666 for a time after the Great Fire of London.\nFrom the 1740s onwards, they were held, with other Exchequer records, in the chapter house of Westminster Abbey. In 1859, they were transferred to the new Public Record Office, London. They are now held at the National Archives at Kew. The chest in which they were stowed in the 17th and 18th centuries is also at Kew.\nIn modern times, the books have been removed from the London area only rarely. In 1861\u20131863, they were sent to Southampton for photozincographic reproduction. In 1918\u201319, prompted by the threat of German bombing during the First World War, they were evacuated (with other Public Record Office documents) to Bodmin Prison, Cornwall. Likewise, in 1939\u20131945, during the Second World War, they were evacuated to Shepton Mallet Prison in Somerset.\nBinding.\nThe volumes have been rebound on several occasions. Little Domesday was rebound in 1320, its older oak boards being re-used. At a later date (probably in the Tudor period) both volumes were given new covers. They were rebound twice in the 19th century, in 1819 and 1869 \u2013 on the second occasion, by the binder Robert Riviere and his assistant, James Kew. In the 20th century, they were rebound in 1952, when their physical makeup was examined in greater detail; and yet again in 1986, for the survey's ninth centenary. On this last occasion Great Domesday was divided into two physical volumes, and Little Domesday into three volumes.\nPublication.\nThe project to publish Domesday was begun by the government in 1773, and the book appeared in two volumes in 1783, set in \"record type\" to produce a partial-facsimile of the manuscript. In 1811, a volume of indexes was added. In 1816, a supplementary volume, separately indexed, was published containing\nPhotographic facsimiles of Domesday Book, for each county separately, were published in 1861\u20131863, also by the government. Today, Domesday Book is available in numerous editions, usually separated by county and available with other local history resources.\nIn 1986, the BBC released the \"BBC Domesday Project,\" the results of a project to create a survey to mark the 900th anniversary of the original Domesday Book. In August 2006, the contents of Domesday went online, with an English translation of the book's Latin. Visitors to the website are able to look up a place name and see the index entry made for the manor, town, city or village. They can also, for a fee, download the relevant page.\nContinuing legal use.\nIn the Middle Ages, the Book's evidence was frequently invoked in the law courts. In 1960, it was among citations for a real manor which helps to evidence legal use rights on and anchorage into the Crown's foreshore; in 2010, as to proving a manor, adding weight of years to sporting rights (deer and foxhunting); and a market in 2019.\nImportance.\nH. C. Darby, a Welsh historical geographer and academic, noted that anyone who uses Domesday Book:\ncan have nothing but admiration for what is the oldest 'public record' in England and probably the most remarkable statistical document in the history of Europe. The continent has no document to compare with this detailed description covering so great a stretch of territory. And the geographer, as he turns over the folios, with their details of population and of arable, woodland, meadow and other resources, cannot but be excited at the vast amount of information that passes before his eyes.\nThe author of the article on the book in the 11th edition of the \"Encyclop\u00e6dia Britannica\" wrote, \"To the topographer, as to the genealogist, its evidence is of primary importance, as it not only contains the earliest survey of each township or manor, but affords, in the majority of cases, a clue to its subsequent descent.\"\nDarby also notes the inconsistencies across the text itself, saying, \"when this great wealth of data is examined more closely, perplexities and difficulties arise.\" One problem is that the clerks who compiled this document \"were but human; they were frequently forgetful or confused.\" The use of Roman numerals also led to countless mistakes. Darby states, \"Anyone who attempts an arithmetical exercise in Roman numerals soon sees something of the difficulties that faced the clerks.\" But more important are the numerous obvious omissions, and ambiguities in presentation. Darby first cites F. W. Maitland's comment following his compilation of a table of statistics from material taken from the Domesday Book survey, \"it will be remembered that, as matters now stand, two men not unskilled in Domesday might add up the number of hides in a county and arrive at very different results because they would hold different opinions as to the meanings of certain formulas which are not uncommon.\" Darby says, \"it would be more correct to speak not of 'the Domesday geography of England', but of 'the geography of Domesday Book'. The two may not be quite the same thing, and how near the record was to reality we can never know.\"\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "47753", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=47753", "title": "Domesday book", "text": ""}
{"id": "47754", "revid": "2842084", "url": "https://en.wikipedia.org/wiki?curid=47754", "title": "Philippa of Hainault", "text": "Queen of England from 1328 to 1369\nPhilippa of Hainault (sometimes spelled Hainaut; Middle French: \"Philippe de Hainaut\"; 24 June 1310 (or 1315) \u2013 15 August 1369) was Queen of England as the wife and political adviser of King Edward III. She acted as regent in 1346, when her husband was away for the Hundred Years' War.\nDaughter of William I, Count of Hainaut, and French princess Joan of Valois, Philippa was engaged to\u00a0Edward, Prince of Wales, in 1326. Their marriage was celebrated in York Minster on 24 January 1328, some months after Edward's accession to the throne of England and Isabella of France's infamous invasion. After her husband reclaimed the throne, Philippa influenced King Edward to take interest in the nation's commercial expansion, was part of the successful Battle of Neville's Cross, and often went on expeditions to Scotland and France. She won much popularity with the English people for her compassion in 1347, when she successfully persuaded the King to spare the lives of the Burghers of Calais. This popularity helped maintain peace in England throughout their long reign.\nChildhood.\nPhilippa was born on 24 June c.1310/15, in Valenciennes, Low Countries. She was one of eight children and the second of five daughters born from William I, Count of Hainaut, and Joan of Valois, granddaughter of King Philip III of France. The Royal House of Valois was a cadet branch of the Capetian dynasty, also known as the House of France.\nKing Edward II decided that an alliance with Flanders would benefit England and sent Bishop Stapledon of Exeter on the Continent as an ambassador. On his journey, he crossed into the county of Hainaut to inspect the daughters of Count William of Hainaut, to determine which daughter would be the most suitable as an eventual bride for young Prince Edward. The bishop's report to the King describes one of the Count's daughters in detail. A later annotation says it describes Philippa as a child, but historian Ian Mortimer argues that it is actually an account of her older sister Margaret. The description runs:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The lady whom we saw has not uncomely hair, betwixt blue-black and brown... Her face narrows between the eyes and its lower part is more narrow than her forehead. Her eyes are blackish-brown and deep. Her nose is fairly smooth and even, save that it is somewhat broad at the tip and flattened, and yet it is no snub-nose... Her lips are full, especially the lower lip... Her lower teeth project a little beyond the upper; yet this is but little seen... All her body is well set and unmaimed; and nought is amiss so far as a man may see. Moreover, she is brown of skin all over, much like her father. And she will be of the age of nine years on St. John's day next to come, as her mother said. She is neither too tall nor too short for such an age; she is of fair carriage. The damsel is well taught in all that becometh her rank and highly esteemed and well beloved by her parents and of all her meinie, in so far as we could inquire and learn the truth. In all things, she is pleasant enough, as it seems to us.\nGrowing up in the Low Countries in the period when this region was growing into a major trading centre, Philippa was well versed in finances and diplomacy. Her older sister Margaret succeeded their brother William II, Count of Hainaut, upon his death in battle. The counties of Holland, Zeeland and the seigniory of Frisia were devolved to Margaret after agreement between the sisters.\nFour years later, in the summer of 1326, Isabella of France, the Queen of England, arrived at the court of Hainaut to seek aid from Count William in order to depose her husband, Edward II, from the throne. Prince Edward had accompanied his mother to Hainaut, where she arranged the betrothal to 13-year-old Philippa in exchange for assistance. As the couple were second cousins (as great-grandchildren of Philip III of France), a papal dispensation was required; it was sent from Pope John XXII at Avignon in September 1327. Philippa's retinue arrived in England in December, escorted by her uncle John of Hainaut. On 23 December, she reached London where a \"rousing reception was accorded her\".\nQueen of England.\nFirst years.\nIn October 1327, Philippa married Edward by proxy through the Bishop of Coventry in Valenciennes. The official marriage was at York Minster on 24 January 1328, eleven months after Edward's accession to the English throne; although the de facto rulers were Queen Mother Isabella and her lover, Roger Mortimer, 1st Earl of March, who jointly acted as his regents. Soon after their marriage, the couple retired to live at Woodstock Palace in Oxfordshire. Unlike many of her predecessors, Philippa did not alienate the English people by retaining her foreign retinue or bringing large numbers of foreigners to the English court. In August, her dower was fixed. She became a patron of the chronicler Jean Froissart and owned several illuminated manuscripts, one of which currently is housed in the national library in Paris. Froissart began to describe her as \"The most gentle Queen, most liberal, and most courteous that ever was Queen in her days.\"\nAs Isabella did not wish to relinquish her own status, Philippa's coronation was postponed for two years. She was crowned queen on 18 February 1330 at Westminster Abbey, when she was almost five months pregnant. She gave birth to her first son, Edward, the following June. In October 1330, King Edward commenced his personal rule by staging a coup and ordering the arrest of the regents. Shortly afterward, Mortimer was executed for treason and the Queen Mother was sent to Castle Rising in Norfolk, where she spent a number of years under house arrest but with her privileges and freedom of movement eventually restored.\nShe was invested as a Lady of the Order of the Garter (LG) in 1358.\nPolitical influence.\nPhilippa proved to be the model of a queen and worked tirelessly for the crown, maintaining balance between royal and familial duties admired in tumultuous times. She was widely loved and respected as a queen who managed to have a successful marriage with Edward.\nAs the financial demands of the recent Hundred Years' War were enormous, Philippa wisely advised the King to take interest in the nation's commercial expansion as a different method of covering the expenses. She established the textile industry in Norwich by encouraging Flemish weavers to settle there and promoted coal mining in Tynedale.\nWhile her husband was away for the Hundred Years' War, she was appointed to serve as regent in 1346.\nIn 1364 or 1365, Edward III demanded the return of Hainaut and other inheritances which had been given over to the dukes of Bavaria\u2013Straubing in the name of Philippa, but he was unsuccessful as the custom in those regions favoured male heirs.\nMilitary campaigns.\nPhilippa served as regent of England during the absence of her spouse in 1346. Facing a Scottish invasion, she gathered the English army, fought the Scots at the Battle of Neville's Cross near Durham, and rallied the English soldiers on horse before them prior to the battle. This event resulted in an English victory and the Scottish King David II being taken prisoner, and held captive for eleven years.\nPhilippa accompanied her husband on expeditions to Scotland and the rest of Europe in the early campaigns of the Hundred Years War, where she won acclaim for her gentle nature and compassion. She was also remembered for persuading her husband to spare the lives of the Burghers of Calais, whom he had planned to execute as an example to the townspeople following his successful siege of that port.\nDeath and burial.\nOn 15 August 1369, Queen Philippa died of an illness similar to oedema in Windsor Castle. She was given a state funeral six months later on 9 January 1370 and was interred at Westminster Abbey. Her alabaster effigy was executed by sculptor Jean de Li\u00e8ge. Her tomb was placed on the northeast side of the Chapel of Edward the Confessor and on the opposite side of her husband's grandparents, Edward I and Eleanor of Castile. Eight years later, Edward III died and was buried next to Philippa. By all accounts, their forty-year marriage had been happy.\nThe Queen's College, Oxford was founded by her chaplain Robert de Eglesfield in her honour.\nIssue.\nPhilippa and Edward had thirteen children, including five sons who lived into adulthood. Three of their children died of the Black Death in 1348. The rivalry of their numerous descendants would bring about the long-running and bloody dynastic wars known as the Wars of the Roses in the 15th century.\nIn popular culture.\nPhilippa is a character in \"The Accursed Kings\", a series of French historical novels by Maurice Druon. She was portrayed by Fran\u00e7oise Burgi in the 1972 French miniseries adaptation of the series, and by Marie de Villepin in the 2005 adaptation.\nIn 2003, she was voted as 5th on the list of 100 Great Black Britons. The decision to include her on the list was heavily criticised, with many historians commenting that there was no evidence to suggest that Philippa had any African ancestry.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47756", "revid": "32720263", "url": "https://en.wikipedia.org/wiki?curid=47756", "title": "List of small groups", "text": "The following list in mathematics contains the finite groups of small order up to group isomorphism.\nCounts.\nFor \"n\" = 1, 2, \u2026 the number of nonisomorphic groups of order \"n\" is\n 1, 1, 1, 2, 1, 2, 1, 5, 2, 2, 1, 5, 1, 2, 1, 14, 1, 5, 1, 5, ... (sequence in the OEIS)\nFor labeled groups, see (sequence in the OEIS).\nGlossary.\nEach group is named by Small Groups library as G\"o\"\"i\", where \"o\" is the order of the group, and \"i\" is the index used to label the group within that order.\nCommon group names:\nThe notations Z\"n\" and Dih\"n\" have the advantage that point groups in three dimensions C\"n\" and D\"n\" do not have the same notation. There are more isometry groups than these two, of the same abstract group type.\nThe notation \"G\" \u00d7 \"H\" denotes the direct product of the two groups; \"G\"\"n\" denotes the direct product of a group with itself \"n\" times. \"G\" \u22ca \"H\" denotes a semidirect product where \"H\" acts on \"G\"; this may also depend on the choice of action of \"H\" on \"G\".\nAbelian and simple groups are noted. (For groups of order \"n\" &lt; 60, the simple groups are precisely the cyclic groups Z\"n\", for prime \"n\".) The equality sign (\"=\") denotes isomorphism.\nThe identity element in the cycle graphs is represented by the black circle. The lowest order for which the cycle graph does not uniquely represent a group is order 16.\nIn the lists of subgroups, the trivial group and the group itself are not listed. Where there are several isomorphic subgroups, the number of such subgroups is indicated in parentheses.\nAngle brackets &lt;relations&gt; show the presentation of a group.\nList of small abelian groups.\nThe finite abelian groups are either cyclic groups, or direct products thereof; see Abelian group. The numbers of nonisomorphic abelian groups of orders \"n\" = 1, 2, ... are\n 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, 2, 1, 1, 1, 5, 1, 2, 1, 2, ... (sequence in the OEIS)\nFor labeled abelian groups, see (sequence in the OEIS).\nList of small non-abelian groups.\nThe numbers of non-abelian groups, by order, are counted by (sequence in the OEIS). However, many orders have no non-abelian groups. The orders for which a non-abelian group exists are\n 6, 8, 10, 12, 14, 16, 18, 20, 21, 22, 24, 26, 27, 28, 30, 32, 34, 36, 38, 39, 40, 42, 44, 46, 48, 50, ... (sequence in the OEIS)\nClassifying groups of small order.\nSmall groups of prime power order \"p\"\"n\" are given as follows:\nMost groups of small order have a Sylow \"p\" subgroup \"P\" with a normal \"p\"-complement \"N\" for some prime \"p\" dividing the order, so can be classified in terms of the possible primes \"p\", \"p\"-groups \"P\", groups \"N\", and actions of \"P\" on \"N\". In some sense this reduces the classification of these groups to the classification of \"p\"-groups. Some of the small groups that do not have a normal \"p\"-complement include:\nThe smallest order for which it is \"not\" known how many nonisomorphic groups there are is 2048 = 211.\nSmall Groups Library.\nThe GAP computer algebra system contains a package called the \"Small Groups library,\" which provides access to descriptions of small order groups. The groups are listed up to isomorphism. At present, the library contains the following groups:\nIt contains explicit descriptions of the available groups in computer readable format.\nThe smallest order for which the Small Groups library does not have information is 1024.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47761", "revid": "50951271", "url": "https://en.wikipedia.org/wiki?curid=47761", "title": "Hitchhiking", "text": "Asking people, usually strangers, for a ride in their road vehicle\nHitchhiking (also known as hitch-hiking, hitching, thumbing, and autostop) is a means of transportation that relies on soliciting rides from individuals, usually strangers. Recognized hand gestures, signage, and casual prearrangement, as in a solicitation at a rest stop, are used.\nMost hitchhikes are free. Occasionally on a longer ride the driver may request their guest chip in towards gas, or coffee and such at a break; more often than asking they will volunteer to pay for such things themselves, recognizing that a person hitchhiking probably is low on funds, and willing to do a good turn. Casual contribution by the hitcher towards expenses does not a void a ride as a hitchhike, but arranging payment in advance, regardless of who is providing the transport, is fee-for-service, however informal.\nSignaling methods.\nHitchhikers use a variety of signals, typically hand gestures, or displays, including signs, to indicate they need a ride.\nCommon hand gestures include:\nThe gesture is unique to hitchhiking, and distinct from the waving display and arm motion of hailing a cab, or seeking to flag a vehicle down in an emergency. \nLegality.\nHitchhiking is historically a common practice worldwide, and there are very few places in the world where laws exist to restrict it. However, a minority of countries have laws that restrict hitchhiking at certain locations. In the United States, for example, some local governments have laws outlawing hitchhiking, on the basis of drivers' and hitchhikers' safety. In Canada, several highways have restrictions on hitchhiking, particularly in British Columbia and the 400-series highways in Ontario. In all countries in Europe, it is legal to hitchhike and in some places even encouraged. However, worldwide, even where hitchhiking is permitted, laws forbid hitchhiking in places where pedestrians are banned, such as the Autobahn (Germany), Autostrade (Italy), motorways (United Kingdom and continental Europe, with the exception of, at least, Lithuania) or Interstate highways (United States), although hitchhikers often obtain rides at entrances and truck stops where it is legal, at least throughout Europe with the exception of Italy.\nCommunity.\nIn recent years, hitchhikers have started efforts to strengthen their community. Examples include the annual Hitchgathering, an event organized by hitchhikers, for hitchhikers, and websites such as Hitchwiki, which are platforms for hitchhikers to share tips and provide a way of looking up good hitchhiking spots around the world.\nHitchhiking has also seen a rise in popularity amongst travel influencers and YouTube video bloggers, who travel to obscure (by Western standards) locations like China, Central Asia, and South East Asia. \nDecline.\nSee below.\nIn 2011, \"Freakonomics Radio\" reviewed sparse data about hitchhiking, and identified a steady decline in hitchhiking in the US since the 1970s, which it attributed to a number of factors, including a greater lack of trust of strangers, lower air travel costs due to deregulation, the presence of more money in the economy to pay for travel, and more numerous and more reliable cars.\nIn an experiment conducted in 2025, Swedish journalist Lukas Deininger hitchhiked from Mo i Rana, Norway to Ume\u00e5, Sweden. The initial wait for a car passing over the Norway\u2013Sweden border took three and a half hours, and the combined journey of lasted for approximately 27 hours, including sleep.\nEven though the dangers of hitchhiking were graphically portrayed in much earlier \"scare\" movies like 1945's \"Detour\", in which a psychotic woman hitchhiker terrorizes another hitchhiker, and the serial murderer driven \"The Hitch-Hiker\" in 1953, the marked increase in fear of hitchhiking from the early 1970s on is the immediate consequence of the diffusion of movies such as \"The Texas Chain Saw Massacre\" (1974), \"The Hitcher\" (1986), and a few real incidents involving imperiled hitchhikers, including the kidnapping of Colleen Stan in California. \nSome British researchers discuss reasons for hitchhiking's decline in the UK, and possible means of reviving it in safer and more organized forms.\nPublic policy support.\nSince the mid-2010s, local authorities in rural areas in Germany have started to support hitchhiking, and this has spread to Austria and the German-speaking region of Belgium. The objectives are both social and environmental: as ride sharing improves mobility for local residents (particularly young and old people without their own cars) in places where public transport is inadequate, thus improving networking among local communities in an environmentally friendly way. This support typically takes the form of providing hitchhiking benches (in German ) where people hoping for a ride can wait for cars. These benches are usually brightly coloured and located at the exit from a village, sometimes at an existing bus stop lay-by where vehicles can pull in safely. Some are even provided with large fold-out or slide-out signs with place names allowing hitchers to clearly signal where they want to go. Some \"Mitfahrb\u00e4nke\" have been installed with the help of the EU's LEADER programme for rural local development\nIn Austria, \"Mitfahrb\u00e4nke\" are especially common in Lower Austria and Tyrol, and are promoted by the Federal Ministry of Agriculture, Regions and Tourism under its \"klimaaktiv\" climate protection initiative. In 2018 the Tyrolean \"Mobilit\u00e4terInnen\" (\"mobility workers\") network published a \"Manual for the Successful Introduction of Hitch-hiking Benches\".\nSafety.\nLimited data is available regarding the safety of hitchhiking. Compiling good safety data requires counting hitchhikers, counting rides, and counting problems, all difficult tasks.\nTwo studies on the topic include a 1974 California Highway Patrol study and a 1989 German federal police (Bundeskriminalamt Wiesbaden) study. The California study found that hitchhikers were not disproportionately likely to be victims of crime. The German study concluded that the actual risk is much lower than the publicly perceived risk; the authors did not advise against hitchhiking in general. They found that in some cases there were verbal disputes or inappropriate comments, but physical attacks were very rare.\nRecommended safety practices include:\nIn the UK, The Scout Association specifically lists hitchhiking as an activity not permitted at any scouting event.\nAround the world.\nCuba.\nIn Cuba, picking up hitchhikers is mandatory for government vehicles, if passenger space is available. Hitchhiking is encouraged, as Cuba has few cars, and hitchhikers use designated spots. Drivers pick up waiting riders on a first come, first served basis.\nIsrael.\nIn Israel, hitchhiking is commonplace at designated locations called (&lt;templatestyles src=\"Script/styles_hebrew.css\" /&gt;\u05d8\u05e8\u05de\u05e4\u05d9\u05d0\u05d3\u05d4\u200e in Hebrew, derived from the German ). Travelers soliciting rides, called , wait at , typically junctions of highways or main roads outside of a city.\nPoland.\nHitchhiking in Poland has a long history and is still popular. It was legalised and formalised in 1957 so hitchhikers could buy booklets including coupons from travel agencies. These coupons were given to drivers who took hitchhikers. By the end of each season drivers who collected the highest number of coupons could exchange them for prizes, and others took part in a lottery. This so-called \"Akcja Autostop\" was popular till the end of the 1970s, but the sale of the booklet was discontinued in 1995.\nUnited States.\nHitchhiking became a common method of traveling during the Great Depression and during the \ncounterculture of the 1960s.\nWarnings of the potential dangers of picking up hitchhikers were publicized to drivers, who were advised that some hitchhikers would rob drivers and, in some cases, sexually assault or murder them. Other warnings were publicized to the hitchhikers themselves, alerting them to the same types of crimes being carried out by drivers. Still, hitchhiking was part of the American psyche and many people continued to stick out their thumbs, even in states where the practice had been outlawed.\nToday, hitchhiking is legal in 44 of the 50 states, the exceptions being Nevada, New Jersey, New York, Pennsylvania, Utah, and Wyoming. This is provided that the hitchhiker is not standing in the roadway or otherwise hindering the normal flow of traffic. Even in states where hitchhiking is illegal, hitchhikers are rarely ticketed. For example, the Wyoming Highway Patrol approached 524 hitchhikers in 2010, but only eight of them were cited.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47762", "revid": "48523215", "url": "https://en.wikipedia.org/wiki?curid=47762", "title": "Oliver Hazard Perry", "text": "United States Navy officer (1785\u20131819)\nOliver Hazard Perry (August 23, 1785 \u2013 August 23, 1819) was a United States Navy officer from South Kingstown, Rhode Island. A prominent member of the Perry family naval dynasty, he was the son of Sarah Wallace Alexander and Captain Christopher Raymond Perry, and older brother of Commodore Matthew C. Perry.\nPerry served in the West Indies during the Quasi War of 1798\u20131800 against France, in the Mediterranean during the Barbary Wars of 1801\u20131815, and in the Caribbean fighting piracy and the slave trade, but is most noted for his role in the War of 1812 during the 1813 Battle of Lake Erie. During the war against Britain, Perry supervised the building of a fleet at Erie, Pennsylvania. He earned the title \"Hero of Lake Erie\" for leading American forces in a decisive naval victory at the Battle of Lake Erie, receiving a Congressional Gold Medal and the Thanks of Congress.\nHis leadership materially aided the successful outcomes of all nine Lake Erie military campaign victories, and the victory was a turning point in the battle for the west in the war. He is remembered for the words on his battle flag, \"DONT [\"sic\"] GIVE UP THE SHIP\", which was a tribute to the dying command of his colleague Captain James Lawrence of USS \"Chesapeake\". He is also known for his message to General William Henry Harrison which reads in part, \"We have met the enemy and they are ours.\"\nPerry became embroiled in a long-standing and bitter controversy with the commander of , Captain Jesse Elliott, over their conduct in the Battle of Lake Erie, and both were the subject of official charges. In 1815, he successfully commanded in the Mediterranean during the Second Barbary War. So seminal was his career that he was lionized in the press (being the subject of scores of books and articles). He has been frequently memorialized, and many places, ships and persons have been named in his honor.\nChildhood and early life.\nPerry was the oldest of five boys born to Christopher and Sarah Wallace Perry (n\u00e9e Alexander). As a boy, Perry lived in Tower Hill, Rhode Island, sailing ships in anticipation of his future career as an officer in the United States Navy. Perry came from a long line of naval men from both sides of his family. His mother taught Perry and his younger brothers to read and write and had them attend Trinity Episcopal Church regularly, where he was baptized by Reverend William Smith on April 1, 1794, at the age of nine. Reverend Theodore Dehon, rector of the church from 1797 to 1810, had a significant influence on the young Perry. He was educated in Newport, Rhode Island. His earliest ancestor to the Americas was Edward Perry, who came from Devon, England, and settled in Sandwich, Massachusetts, around 1650 with his wife, Mary Freeman.\nEarly naval career.\nThrough his father's influence, Perry was appointed a midshipman in the United States Navy, at the age of thirteen, on April 7, 1799. Perry sailed aboard , of which his father was commanding officer, on her maiden voyage in June 1799. The ship made its first stop in Cuba, charged with receiving American merchant ships and providing escort from Havana to the United States. Perry's service aboard \"General Greene\" continued during the Quasi-War with France. He first experienced combat on February 9, 1800, off the coast of the French colony of Haiti, which was in a state of rebellion.\nDuring the First Barbary War, he served aboard and later was first lieutenant (second in command) of . He then served under Captain John Rodgers on and USS \"Essex\". He was placed in charge of the construction of gunboats in Newport and Westerly, Rhode Island.\nBeginning in April 1809, he commanded the sloop , engaging in patrol duties to enforce the Embargo Act, as well as a successful raid to regain an American ship held in Spanish territory in Florida. On January 9, 1811, \"Revenge\" ran aground off Rhode Island and was lost. \"Seeing fairly quickly that he could not save the vessel, [Perry] turned his attention to saving the crew, and after helping them down the ropes over the vessel's stern, he was the last to leave the vessel.\" The subsequent court-martial exonerated Perry, placing blame on the ship's pilot. In January 2011, a team of divers claimed to have discovered the remains of \"Revenge\", nearly 200 years to the day after it sank. Cannons from \"Revenge\" were salvaged by the U.S. Navy in 2017.\nFollowing the court-martial, Perry was given a leave of absence from the Navy. On May 5, 1811, he married Elizabeth Champlin Mason of Newport, Rhode Island, whom he had met at a dance in 1807. They enjoyed an extended honeymoon touring New England. The couple would eventually have five children, with one dying in infancy.\nWar of 1812.\nAt the beginning of the War of 1812, the British Royal Navy controlled the Great Lakes, except for Lake Huron. The United States Navy controlled Lake Champlain. The American naval forces were very small, allowing the British to make many advances in the Great Lakes and northern New York . The roles played by commanders like Perry, at Lake Erie and Isaac Chauncey at Lake Ontario and Thomas Macdonough at Lake Champlain all proved vital to the naval effort.\nNaval historian E. B. Potter noted that \"all naval officers of the day made a special study of Nelson's battles.\" Oliver Perry was no exception.\nAt his request, he was given command of the American naval forces on Lake Erie during the war. Secretary of the Navy Paul Hamilton had charged prominent merchant seaman Daniel Dobbins with building the American fleet on Presque Isle Bay at Erie, Pennsylvania, and Perry was named chief naval officer.\nPerry knew battle was coming, and he \"consciously followed Nelson's example in describing his battle plans to his captains.\" Perry's instructions were:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Commanding officers are particularly enjoined to pay attention in preserving their stations in the Line, and in all cases to keep as near the \"Lawrence\" as possible. ... Engage your designated adversary, in close action, at half cable's length. \u2014\u200a\nHero of Lake Erie.\nOn September 10, 1813, Perry's squadron fought the Battle of Lake Erie against a smaller Royal Navy squadron. It was at the outset of this battle that Perry famously said, \"If a victory is to be gained, I will gain it.\" Initially, the exchange of gunfire favored the British. Perry's flagship, , was so severely disabled in the encounter that the British commander, Robert Heriot Barclay, thought that Perry would surrender it, and sent a small boat to request that the American vessel pull down its flag.\nFaithful to the words of his battle flag, \"DONT [\"sic\"] GIVE UP THE SHIP\", a paraphrase of the dying words of Captain James Lawrence, the ship's namesake and Perry's friend, Perry, with \"Lawrence\"'s chaplain and purser as the remaining able crew, personally fired the final salvo. He then had his men row him a half-mile (0.8\u00a0km) through heavy gunfire to transfer his command to . Once aboard, Perry dispatched \"Niagara\"'s commander, Captain Jesse Elliott, to bring the other schooners into closer action while he steered \"Niagara\" toward the damaged British ships. Like Nelson's at Trafalgar, \"Niagara\" broke the opposing line.\nPerry's force pounded Barclay's ships until they could offer no effective resistance and surrendered. Although he had won the battle aboard \"Niagara\", he received Barclay's surrender on the deck of the recaptured \"Lawrence\" to allow him to see the terrible price Perry's men had paid. Perry's battle report to General William Henry Harrison was famously brief: \"We have met the enemy and they are ours; two ships, two brigs, one schooner and one sloop.\" The six captured ships were successfully returned to Presque Isle.\nAlthough the engagement was small compared to Napoleonic naval battles such as the Battle of Trafalgar, the victory had disproportionate strategic importance, opening Canada up to further American invasions, while simultaneously protecting the entire Ohio Valley. The loss of Barclay's squadron directly led to the critical Battle of the Thames, a victory over British and Indian forces by Harrison's army, the deaths of Tecumseh and Roundhead, and the breakup of his confederacy. Along with the Battle of Plattsburgh, it was one of only two battle of the war in which an entire squadron was defeated.\nPerry was involved in nine battles that led to and followed the Battle of Lake Erie, and they all had a seminal impact. \"What is often overlooked when studying Perry is how his physical participation and brilliant strategic leadership influenced the outcomes of all nine Lake Erie military campaign victories:\n Capturing Fort George, Ontario in the Battle of Fort George; Destroying the British munitions at Olde Fort Erie (see Capture of Fort Erie); Rescuing five vessels from Black Rock; Building the Erie fleet; Getting the ships over the sandbar; Blocking British supplies for a month prior to battle; Planning the Thames invasion with General Harrison; Winning the Battle of Lake Erie; and Winning the Battle of Thames.\nBattle Flag.\n\"Don't give up the ship!\" became the battle cry of Oliver Hazard Perry. The phrase was uttered by Captain James Lawrence as he died after being wounded by enemy fire aboard the \"Chesapeake\" on June 1, 1813. Perry learned of Lawrence's demise at Presque Isle. He honored Lawrence with the name of a brig, called \"Lawrence\". A battle flag was needed, and the words of Perry's good friend were suited for the coming days.\nMargaret Forster Steuart was enlisted to make the battle flag. She was a resident of Erie Pennsylvania, wife of Army Captain Thomas Steuart and sister to Thomas Forster, both friends of Perry's. Forster was the commander of the Erie Light Infantry that had guarded the fleet. With the help of her two daughters, three nieces, and a cousin, she had the flag ready for Perry within just a few days. As of July 2009, Perry's flag, Steuart's work, and Lawrence's dying words can be seen today, with the flag on display in Bancroft Hall's Memorial Hall at the U.S. Naval Academy in Annapolis.\nPerry\u2013Elliott controversy.\nWhile Nelson had Collingwood, Perry had Jesse Elliott, and was considerably less well served. Elliott, while serving with Isaac Chauncey at Lake Ontario, was tasked to augment Perry's squadron with 11 officers and 91 men, \"and none were sent but the worst.\" Subsequently, detailed by Chauncey to command \"Niagara,\" Elliott stated \"that if he could have foreseen that he himself should be sent to Lake Erie, his selections would have been different.\" Elliott then appropriated the \"best of the worst\" for \"Niagara\"; and Perry \"in the interest of harmony\" accepted the situation, though with growing ill-will.\nIn his initial post-action report, Perry had praised Captain Elliott's role in the American victory at Lake Erie; and as news of the battle spread, Perry and Elliott were both celebrated as national heroes. Soon after, however, several junior officers publicly criticized Elliott's performance during the battle, charging that Elliott allowed \"Lawrence\" to suffer the brunt of the British fire while holding \"Niagara\" back from the fight. William Vigneron Taylor, Perry's sailing master, in a letter to Taylor's wife, put it thus:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The \"Lawrence\" alone rec'd the fire of the whole British squadron 2 1/2 hours within pistol shot\u2014we were not supported as we ought to have been. Captain Perry led the \"Lawrence\" into action &amp; sustained the most destructive fire with the most gallant spirit perhaps that was ever witnessed under similar circumstances.\u2014\u200a\nThe meeting between Elliott and Perry on the deck of \"Niagara\" was terse. Elliott inquired how the day was going. Perry replied, \"Badly.\" Elliott then volunteered to take Perry's small boat and rally the schooners, and Perry acquiesced. As Perry turned \"Niagara\" into the battle, Elliott was not aboard. Elliott's rejoinder to history's criticism of inaction was that there had been a lack of effective signaling. Charges were filed, but not officially acted upon. Attempting to restore his honor, Elliott and his supporters began a 30-year campaign that would outlive both men and ultimately leave his reputation in tatters.\nIn Perry's report to Secretary of the Navy William Jones, written three days after the battle, he mentioned Elliott in what, at first, seem to be complimentary terms, but, when read carefully, betray his disdain for Elliott. Perry wrote, \"In this action he evinced his characteristic bravery and judgement; and, since the close of the action, has given me the most able and essential assistance.\"\nCongressional Gold Medal.\nOn January 6, 1814, Perry was honored with a Congressional Gold Medal, the Thanks of Congress, and a promotion to the rank of Captain. This was one of 27 Gold Medals authorized by Congress arising from the War of 1812.\n(Valor finds or makes a way. Between the Fleets of America and Britain September 10, 1813.)\nElliott was also recognized with a Congressional Gold Medal and the Thanks of Congress for his actions in the battle. This recognition would prove to fan the flames of resentment on both sides of the Elliott\u2013Perry controversy.\nIn recognition of his victory at Lake Erie, in 1813 Perry was elected as an honorary member of the New York Society of the Cincinnati.\nLater commands and controversies.\nIn May 1814, Perry took command of a squadron of seven gunboats based in Newport. He held this command for only two months as in July he was placed in command of , a 44-gun frigate which was under construction in Baltimore. While overseeing the outfitting of \"Java\", Perry participated in the defenses of Baltimore and Washington, D.C., during the British invasion of the Chesapeake Bay. In a twist of irony, these land battles would be the last time the career naval officer saw combat. The Treaty of Ghent was ratified before \"Java\" could be put to sea.\nFor Perry, the post-war years were marred by controversies. In 1815, he commanded \"Java\" in the Mediterranean during the Second Barbary War. While moored in Naples, Perry slapped the commander of the ship's Marines, Captain John Heath, whom Perry charged with \"disrespectful, insolent, and contemptuous conduct to me his superior officer\". The ensuing court-martial found both men guilty, but levied only mild reprimands. After the crew returned home, Heath challenged Perry to a pistol duel, which was fought on October 19, 1817, on the same field in Weehawken, New Jersey where Aaron Burr shot and killed Alexander Hamilton. Heath fired first and missed. Perry declined to return fire, satisfying the Marine's honor.\nPerry's return from the Mediterranean also reignited the feud with Elliott. After an exchange of angry letters, Elliott challenged Perry to a duel, which Perry refused. (While it was normally considered cowardly to refuse a duel, Perry's stature as a hero was such that no one doubted his physical courage and few felt that Perry had wrongly offended Elliott's honor.) He instead, on August 8, 1818, filed formal court-martial charges against Elliott. Perry filed a total of six charges and twenty-one specifications including \"conduct unbecoming an officer,\" and failure to \"do his utmost to take or destroy the vessel of the enemy which it was his duty to encounter.\"\nWishing to avoid a scandal between two decorated naval heroes, Secretary of the Navy Smith Thompson and President James Monroe suppressed the matter by offering Perry a diplomatic mission to South America in exchange for dropping his charges. This put an official end to the controversy, though it would continue to be debated for another quarter century.\nMission to Venezuela and death.\nIn 1818 Perry purchased a large house on Washington Square in Newport which was built in 1750 for merchant Peter Buloid. The house remained in the Perry family until 1865 and now serves as an antique bookstore.\nIn 1819, Perry sailed for the Orinoco River, Venezuela, aboard of the frigate with the frigate and the schooner , arriving on July 15 to discourage piracy, while still maintaining friendly relations with Republic of Venezuela and the Republic of Buenos Aires. Shifting his flag to USS \"Nonsuch\", due to its shallower draft, Perry sailed upriver to Angostura to negotiate an anti-piracy agreement with President Sim\u00f3n Bol\u00edvar. A favorable treaty was signed on August 11 with Vice President Francisco Antonio Zea in the absence of Bolivar (who was engaged in the liberation of New Granada), but when the schooner started downriver, many of her crew, including Perry, had been stricken with yellow fever.\nDespite the crew's efforts to reach Trinidad for medical assistance, the commodore died on board USS \"Nonsuch\" on August 23, 1819, his 34th birthday, as the ship entered the Gulf of Paria and was nearing Port of Spain. He was buried in Port of Spain.\nHis remains were later taken back to the United States in 1826 and interred in Newport, Rhode Island. Originally interred in the Old Common Burial Ground, his body was eventually moved to Newport's Island Cemetery.\nPerry Street in Savannah, Georgia, is named in his honor.\nFamily.\nPerry married Elizabeth Champlin Mason in 1811. They had five children, four of whom lived to maturity. They were:\nPerry's son Christopher Grant Champlin Perry was a physician, and served as commander of the Artillery Company of Newport from April 1848 until his death in 1854. In May 1849 he was commissioned as a Brigadier General in the Rhode Island Militia and given command of the 1st Brigade encompassing Newport and Bristol Counties.\nPerry's son Oliver Hazard Perry, Jr. entered the Navy as a midshipman in 1829, rose to the rank of lieutenant and resigned in 1849. He served on the United States Exploring Expedition under Captain Charles Wilkes from 1839 to 1842. Although he is buried in the same cemetery as his parents, for unknown reasons, he is not buried in the same plot with his parents.\nPerry's son Christopher Raymond Perry graduated from the United States Military Academy at West Point in 1842. He served during the Mexican War and fought at the Battle of Palo Alto on May 8, 1846, and at the Battle of Resaca-de\u2011la\u2011Palma on May 9, 1846. He died on active duty as a 1st lieutenant in 1848.\nDates of rank.\nAlthough Perry is often referred to as \"Commodore Perry,\" it should be kept in mind that, prior to the American Civil War, commodore was not a rank in the U.S. Navy but, rather, the title of an officer in command of a squadron of two or more ships. Perry first held the title of commodore when he took command of the Lake Erie squadron in 1813.\nAssignments.\nNote \u2013 Time gaps between assignments were probably in a \"waiting orders\" status.\nGeographical namesakes.\nMany locations in the United States are named in his honor, including:\nMonuments.\nThe national monument commemorating Perry is the Perry's Victory and International Peace Memorial in the village Put-In-Bay, Ohio on South Bass Island, Ohio. Its tower, the world's most massive Doric column, was constructed by a multi-state commission between 1912 and 1915.\nOther monuments include:\nDocumentary.\nIn 2016, principal photography began on \"We Have Met the Enemy\", a feature-length documentary produced by Lou Reda (\"Vietnam in HD\", \"The Blue and the Gray\"), for a planned spring 2017 release.\nEponymous ships.\nCommodore Perry has been repeatedly honored with ships bearing his name.\nPopular song.\nIn 1820, Anthony Philip Heinrich wrote a song, \"Ode to the Memory of Commodore O. H. Perry\", with words by Henry C. Lewis.\nNotes.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47763", "revid": "4842600", "url": "https://en.wikipedia.org/wiki?curid=47763", "title": "Environmental economics", "text": "Sub-field of economics\nEnvironmental economics is a sub-field of economics concerned with environmental issues. It has become a widely studied subject due to growing environmental concerns in the twenty-first century. Environmental economics \"undertakes theoretical or empirical studies of the economic effects of national or local environmental policies around the world. Particular issues include the costs and benefits of alternative environmental policies to deal with air pollution, water quality, toxic substances, solid waste, and global warming.\"\nEnvironmental Versus Ecological Economics.\nEnvironmental economics is distinguished from ecological economics in that ecological economics emphasizes the economy as a subsystem of the ecosystem with its focus upon preserving natural capital. While environmental economics focuses on human preferences, by trying to balance protecting natural resources with people's needs for products and services. Due to these differences it can be seen that ecological economics takes a more holistic approach to traditional economic theories, while environmental economics fits within traditional economic theories.\nOne survey of German economists found that ecological and environmental economics are different schools of economic thought, with ecological economists emphasizing \"strong\" sustainability and rejecting the proposition that human-made (\"physical\") capital can substitute for natural capital. And environmental economics focusing on the efficient allocation of natural resources in order to fulfill human wants.\nHistory.\n18th and 19th Century.\nAlthough the term \"environmental economics\" became popular beginning in the 1960s, the entwinement of the two fields of environmentalism and economics started much earlier. Starting with economist Marquis de Condorcet in the 18th century, who had an interest in the link between economic activity and environmental issues. This was seen in his usage of externalities while analyzing environmental issues.\nDuring the classical period of economics, Adam Smith realized while the market is able to allocate private goods efficiently for most goods, it fails to do so in some environmental circumstances. It is within these scenarios where the market fails, that the government needs to take action. This is seen in his quote \"Erecting and maintaining certain public works and certain public institutions which it can never be for the interest of any individual, or small number of individuals to erect and maintain; because the profit would never repay the expense to any individual or small number of individuals, though it may frequently do much more than repay it to a great society.\" Thomas Robert Malthus also was another classical economist whose work led to the beginnings of environmental economists. Malthus' theory of population argued that agricultural productivity faces diminishing returns, which ultimately limits the exponential growth of human populations. This thought process later led economists to think about the relationship between resource scarcity and economic development. David Ricardo's writings connected the natural environment and the standard of living which further helped to develop environmental economics later on. He stressed that the value of land varies based on how fertile it is. The last classical economist to add to environmental economics was John Stuart Mill. In his Principles of Political Economy, he wrote that the management of the environment cannot be done by the market and individuals, and is instead a governmental obligation, \"[I]s there not the earth itself, its forests and waters, and all other natural riches, above and below the surface? These are the inheritance of the human race, and there must be regulations for the common enjoyment of it. What rights, and under what conditions, a person shall be allowed to exercise over any portion of this common inheritance cannot be left undecided. No function of government is less optional than the regulation of these things, or more completely involved in the idea of civilized society.\"\n20th Century.\nEnvironmental economics became increasingly more popular in the 19th century. This is when the Resources for the Future (RFF) was established in Washington, D.C. This independent research organization applied economics to environmental issues. During this time H. Scott Gordon released his paper \"Economic Theory of a Common Property Resource: The Fishery\" which claimed that open access fisheries can be exploited leading to economic rents to be dissipated. Another important paper adding to environmental economics at this time was \"Spaceship Earth\" by Kenneth E. Boulding. This paper describes the physical limits of earths resources and how technology cannot truly help humans push those limits. Finally, Ronald Coase created an economic solution to environmental issues, which solidified environmental economics as a sub field of economics. He believed that there were two solutions 1) to tax the creator of the polluter and to create regulation that put the burden of action on the polluter or 2) the sufferer must pay the polluter to not pollute.\nTopics and concepts.\nMarket failure.\nCentral to environmental economics is the concept of market failure. Market failure means that markets fail to allocate resources efficiently. As stated by Hanley, Shogren, and White (2007): \"A market failure occurs when the market does not allocate scarce resources to generate the greatest social welfare. A wedge exists between what a private person does given market prices and what society might want him or her to do to protect the environment. Such a wedge implies wastefulness or economic inefficiency; resources can be reallocated to make at least one person better off without making anyone else worse off.\" This results in an inefficient market that needs to be corrected through avenues such as government intervention. Common forms of market failure include externalities, non-excludability and non-rivalry.\nExternality.\nAn externality exists when a person makes a choice that affects other people in a way that is not accounted for in the market price. An externality can be positive or negative but is usually associated with negative externalities in environmental economics. For instance, water seepage in residential buildings occurring in upper floors affect the lower floors. Another example concerns how the sale of Amazon timber disregards the amount of carbon dioxide released in the cutting. Or a firm emitting pollution will typically not take into account the costs that its pollution imposes on others. As a result, pollution may occur in excess of the 'socially efficient' level, which is the level that would exist if the market was required to account for the pollution. A classic definition influenced by Kenneth Arrow and James Meade is provided by Heller and Starrett (1976), who define an externality as \"a situation in which the private economy lacks sufficient incentives to create a potential market in some good and the nonexistence of this market results in losses of Pareto efficiency\". In economic terminology, externalities are examples of market failures, in which the unfettered market does not lead to an efficient outcome.\nCommon goods and public goods.\nWhen it is too costly to exclude some people from access to an environmental resource, the resource is either called a common property resource (when there is rivalry for the resource, such that one person's use of the resource reduces others' opportunity to use the resource) or a public good (when use of the resource is non-rivalrous). In either case of non-exclusion, market allocation is likely to be inefficient.\nThese challenges have long been recognized. Hardin's (1968) concept of the tragedy of the commons popularized the challenges involved in non-exclusion and common property. \"Commons\" refers to the environmental asset itself, \"common property resource\" or \"common pool resource\" refers to a property right regime that allows for some collective body to devise schemes to exclude others, thereby allowing the capture of future benefit streams; and \"open-access\" implies no ownership in the sense that property everyone owns nobody owns.\nThe basic problem is that if people ignore the scarcity value of the commons, they can end up expending too much effort, over harvesting a resource (e.g., a fishery). Hardin theorizes that in the absence of restrictions, users of an open-access resource will use it more than if they had to pay for it and had exclusive rights, leading to environmental degradation. See, however, Ostrom's (1990) work on how people using real common property resources have worked to establish self-governing rules to reduce the risk of the tragedy of the commons.\nThe mitigation of climate change effects is an example of a public good, where the social benefits are not reflected completely in the market price. Because the personal marginal benefits are less than the social benefits the market under-provides climate change mitigation. This is a public good since the risks of climate change are both non-rival and non-excludable. Such efforts are non-rival since climate mitigation provided to one does not reduce the level of mitigation that anyone else enjoys. They are non-excludable actions as they will have global consequences from which no one can be excluded. A country's incentive to invest in carbon abatement is reduced because it can \"free ride\" off the efforts of other countries. Over a century ago, Swedish economist Knut Wicksell (1896) first discussed how public goods can be under-provided by the market because people might conceal their preferences for the good, but still enjoy the benefits without paying for them.\nValuation.\nAssessing the economic value of the environment is a major topic within the field. The values of natural resources often are not reflected in prices that markets set and, in fact, many of them are available at no monetary charge. This mismatch frequently causes distortions in pricing of natural assets: both overuse of them and underinvestment in them. Economic value or tangible benefits of ecosystem services and, more generally, of natural resources, include both use and indirect (see the nature section of ecological economics). Non-use values include existence, option, and bequest values. For example, some people may value the existence of a diverse set of species, regardless of the effect of the loss of a species on ecosystem services. The existence of these species may have an option value, as there may be the possibility of using it for some human purpose. For example, certain plants may be researched for drugs. Individuals may value the ability to leave a pristine environment for their children.\nUse and indirect use values can often be inferred from revealed behavior, such as the cost of taking recreational trips or using hedonic methods in which values are estimated based on observed prices. These use values can also be predicted through defensive behavior against pollution or environmental hazards, which can reveal how much people are willing to spend on healthcare and other preventative measures to avoid these hazards. Another health-based predictor of environmental use value is the value of a statistical life (VSL), which provides an estimate of how much people are willing to pay for small reductions in their risk of dying from environmental hazards. Non-use values are usually estimated using stated preference methods such as contingent valuation or choice modelling. Contingent valuation typically takes the form of surveys in which people are asked how much they would pay to observe and recreate in the environment (willingness to pay) or their willingness to accept (WTA) compensation for the destruction of the environmental good. Hedonic pricing examines the effect the environment has on economic decisions through housing prices, traveling expenses, and payments to visit parks.\nState subsidy.\nAlmost all governments and states magnify environmental harm by providing various types of subsidies that have the effect of paying companies and other economic actors more to exploit natural resources than to protect them. The damage to nature of such public subsidies has been conservatively estimated at $4-$6 trillion U.S. dollars per year.\nSolutions.\nSolutions advocated to correct such externalities include:\nIf companies are allowed to include some of these externalities in their final prices, this could undermine the Jevons paradox and provide enough revenue to help companies innovate.\nRelationship to other fields.\nEnvironmental economics is related to ecological economics but there are differences. Most environmental economists have been trained as economists. They apply the tools of economics to address environmental problems, many of which are related to so-called market failures\u2014circumstances wherein the \"invisible hand\" of economics is unreliable. Most ecological economists have been trained as ecologists, but have expanded the scope of their work to consider the impacts of humans and their economic activity on ecological systems and services, and vice versa. This field takes as its premise that economics is a strict subfield of ecology. Ecological economics is sometimes described as taking a more pluralistic approach to environmental problems and focuses more explicitly on long-term environmental sustainability and issues of scale.\nEnvironmental economics is viewed as more idealistic in a price system; ecological economics as more realistic in its attempts to integrate elements outside of the price system as primary arbiters of decisions. These two groups of specialisms sometimes have conflicting views which may be traced to the different philosophical underpinnings.\nAnother context in which externalities apply is when globalization permits one player in a market who is unconcerned with biodiversity to undercut prices of another who is \u2013 creating a race to the bottom in regulations and conservation. This, in turn, may cause loss of natural capital with consequent erosion, water purity problems, diseases, desertification, and other outcomes that are not efficient in an economic sense. This concern is related to the subfield of sustainable development and its political relation, the anti-globalization movement.\nEnvironmental economics was once distinct from resource economics. Natural resource economics as a subfield began when the main concern of researchers was the optimal commercial exploitation of natural resource stocks. But resource managers and policy-makers eventually began to pay attention to the broader importance of natural resources (e.g. values of fish and trees beyond just their commercial exploitation). It is now difficult to distinguish \"environmental\" and \"natural resource\" economics as separate fields as the two became associated with sustainability. Many of the more radical green economists split off to work on an alternate political economy.\nEnvironmental economics was a major influence on the theories of natural capitalism and environmental finance, which could be said to be two sub-branches of environmental economics concerned with resource conservation in production, and the value of biodiversity to humans, respectively. The theory of natural capitalism (Hawken, Lovins, Lovins) goes further than traditional environmental economics by envisioning a world where natural services are considered on par with physical capital.\nThe more radical green economists reject neoclassical economics in favour of a new political economy beyond capitalism or communism that gives a greater emphasis to the interaction of the human economy and the natural environment, acknowledging that \"economy is three-fifths of ecology\". This political group is a proponent of a transition to renewable energy.\nThese more radical approaches would imply changes to money supply and likely also a bioregional democracy so that political, economic, and ecological \"environmental limits\" were all aligned, and not subject to the arbitrage normally possible under capitalism.\nAn emerging sub-field of environmental economics studies its intersection with development economics. Dubbed \"envirodevonomics\" by Michael Greenstone and B. Kelsey Jack in their paper \"Envirodevonomics: A Research Agenda for a Young Field\", the sub-field is primarily interested in studying \"why environmental quality [is] so poor in developing countries.\" A strategy for better understanding this correlation between a country's GDP and its environmental quality involves analyzing how many of the central concepts of environmental economics, including market failures, externalities, and willingness to pay, may be complicated by the particular problems facing developing countries, such as political issues, lack of infrastructure, or inadequate financing tools, among many others.\nIn the field of law and economics, environmental law is studied from an economic perspective. The economic analysis of environmental law studies instruments such as zoning, expropriation, licensing, third party liability, safety regulation, mandatory insurance, and criminal sanctions. A book by Michael Faure (2003) surveys this literature.\nProfessional bodies.\nThe main academic and professional organizations for the discipline of Environmental Economics are the Association of Environmental and Resource Economists (AERE) and the http://. The main academic and professional organization for the discipline of Ecological Economics is the International Society for Ecological Economics (ISEE). The main organization for Green Economics is the https://.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "47764", "revid": "5106682", "url": "https://en.wikipedia.org/wiki?curid=47764", "title": "Resource economics", "text": ""}
{"id": "47765", "revid": "1", "url": "https://en.wikipedia.org/wiki?curid=47765", "title": "Bit-mapped graphics", "text": ""}
{"id": "47766", "revid": "6048993", "url": "https://en.wikipedia.org/wiki?curid=47766", "title": "CDR coding", "text": "In computer science CDR coding is a compressed data representation for Lisp linked lists. It was developed and patented by the MIT Artificial Intelligence Laboratory, and implemented in computer hardware in a number of Lisp machines derived from the MIT CADR.\nCDR coding is in fact a fairly general idea; whenever a data object \"A\" ends in a reference to another data structure \"B\", we can instead place the structure \"B\" itself there, overlapping and running off the end of \"A\". By doing this we free the space required by the reference, which can add up if done many times, and also improve locality of reference, enhancing performance on modern machines. The transformation is especially effective for the cons-based lists it was created for; we free about half of the space for each node we perform this transformation on.\nIt is not always possible to perform this substitution, because there might not be a large enough chunk of free space beyond the end of A. Thus, some objects will end in a real reference, and some with the referenced object, and the machine must be able to tell by reading the final cell which one it is. This can be accomplished with some inefficiency in software by the use of tagged pointers, which allow a pointer in a final position to be specifically tagged as such, but is best done in hardware.\nIn the presence of mutable objects, CDR coding becomes more complex. If a reference is updated to point to another object, but currently has an object stored in that field, the object must be relocated, along with any other pointers to it. Not only are such moves typically expensive or impossible, but over time they cause fragmentation of the store. This problem is typically avoided by using CDR coding only on immutable data structures."}
{"id": "47767", "revid": "11221188", "url": "https://en.wikipedia.org/wiki?curid=47767", "title": "Threaded code", "text": "Program whose source code consists entirely of calls to functions\nIn computer science, threaded code is a programming technique where the code has a form that essentially consists entirely of calls to subroutines. It is often used in compilers, which may generate code in that form or be implemented in that form themselves. The code may be processed by an interpreter or it may simply be a sequence of machine code call instructions.\nThreaded code has better density than code generated by alternative generation techniques and by alternative calling conventions. In cached architectures, it may execute slightly slower. However, a program that is small enough to fit in a computer processor's cache may run faster than a larger program that suffers many cache misses. Small programs may also be faster at thread switching, when other programs have filled the cache.\nThreaded code is best known for its use in many compilers of programming languages, such as Forth, many implementations of BASIC, some implementations of COBOL, early versions of B, and other languages for small minicomputers and for amateur radio satellites.\nHistory.\nThe common way to make computer programs is to use a compiler to translate source code (written in some symbolic language) to machine code. The resulting executable is typically fast but, because it is specific to a hardware platform, it isn't portable. A different approach is to generate instructions for a virtual machine and to use an interpreter on each hardware platform. The interpreter instantiates the virtual machine environment and executes the instructions. Thus the interpreter, compiled to machine code, provides an abstraction layer for \"interpreted languages\" that only need little compilation to conform to that layer (compilation may be confined to generating an Abstract Syntax Tree) or even need no compilation at all (if the layer is designed to consume raw source code.)\nEarly computers had relatively little memory. For example, most Data General Nova, IBM 1130, and many of the first microcomputers had only 4\u00a0kB of RAM installed. Consequently, a lot of time was spent trying to find ways to reduce a program's size, to fit in the available memory.\nOne solution is to use an interpreter which reads the symbolic language a bit at a time, and calls functions to perform the actions. As the source code is typically much denser than the resulting machine code, this can reduce overall memory use. This was the reason Microsoft BASIC is an interpreter: its own code had to share the 4\u00a0kB memory of machines like the Altair 8800 with the user's source code. A compiler translates from a source language to machine code, so the compiler, source, and output must all be in memory at the same time. In an interpreter, there is no output. \nThreaded code is a formatting style for compiled code that minimizes memory use. Instead of writing out every step of an operation at its every occurrence in the program, as was common in macro assemblers for instance, the compiler writes each common bit of code into a subroutine. Thus, each bit exists in only one place in memory (see \"Don't repeat yourself\"). The top-level application in these programs may consist of nothing but subroutine calls. Many of these subroutines, in turn, also consist of nothing but lower-level subroutine calls.\nMainframes and some early microprocessors such as the RCA 1802 required several instructions to call a subroutine. In the top-level application and in many subroutines, that sequence is constantly repeated, with only the subroutine address changing from one call to the next. This means that a program consisting of many function calls may have considerable amounts of repeated code as well.\nTo address this, threaded code systems used pseudo-code to represent function calls in a single operator. At run time, a tiny \"interpreter\" would scan over the top-level code, extract the subroutine's address in memory, and call it. In other systems, this same basic concept is implemented as a branch table, dispatch table, or virtual method table, all of which consist of a table of subroutine addresses.\nDuring the 1970s, hardware designers spent considerable effort to make subroutine calls faster and simpler. On the improved designs, only a single instruction is expended to call a subroutine, so the use of a pseudo-instruction saves no room. Additionally, the performance of these calls is almost free of additional overhead. Today, though almost all programming languages focus on isolating code into subroutines, they do so for code clarity and maintainability, not to save space.\nThreaded code systems save room by replacing that list of function calls, where only the subroutine address changes from one call to the next, with a list of execution tokens, which are essentially function calls with the call opcode(s) stripped off, leaving behind only a list of addresses.\nOver the years, programmers have created many variations on that \"interpreter\" or \"small selector\". The particular address in the list of addresses may be extracted using an index, general-purpose register or pointer. The addresses may be direct or indirect, contiguous or non-contiguous (linked by pointers), relative or absolute, resolved at compile time or dynamically built. No single variation is \"best\" for all situations.\nDevelopment.\nTo save space, programmers squeezed the lists of subroutine calls into simple lists of subroutine addresses, and used a small loop to call each subroutine in turn. For example, the following pseudocode uses this technique to add two numbers A and B. In the example, the list is labeled thread and a variable ip (Instruction Pointer) tracks our place within the list. Another variable sp (Stack Pointer) contains an address elsewhere in memory that is available to hold a value temporarily.\nstart:\n ip = &amp;thread // points to the address '&amp;pushA', not the textual label 'thread'\ntop:\n jump *ip++ // follow ip to address in thread, follow that address to subroutine, advance ip\nthread:\n &amp;pushA\n &amp;pushB\n &amp;add\npushA:\n *sp++ = A // follow sp to available memory, store A there, advance sp to next \n jump top\npushB:\n *sp++ = B\n jump top\nadd:\n addend1 = *--sp // Pop the top value off the stack\n addend2 = *--sp // Pop second value off the stack\n *sp++ = addend1 + addend2 // Add the two values together and store the result on the top of the stack\n jump top\nThe calling loop at codice_1 is so simple that it can be repeated inline at the end of each subroutine. Control now jumps once, from the end of a subroutine to the start of another, instead of jumping twice via codice_1. For example:\nstart:\n ip = &amp;thread // ip points to &amp;pushA (which points to the first instruction of pushA)\n jump *ip++ // send control to first instruction of pushA and advance ip to &amp;pushB\nthread:\n &amp;pushA\n &amp;pushB\n &amp;add\npushA:\n *sp++ = A // follow sp to available memory, store A there, advance sp to next \n jump *ip++ // send control where ip says to (i.e. to pushB) and advance ip\npushB:\n *sp++ = B\n jump *ip++\nadd:\n addend1 = *--sp // Pop the top value off the stack\n addend2 = *--sp // Pop second value off the stack\n *sp++ = addend1 + addend2 // Add the two values together and store the result on top of the stack\n jump *ip++\nThis is called direct threaded code (DTC). Although the technique is older, the first widely circulated use of the term \"threaded code\" is probably James R. Bell's 1973 article \"Threaded Code\".\nIn 1970, Charles H. Moore invented a more compact arrangement, indirect threaded code (ITC), for his Forth virtual machine. Moore arrived at this arrangement because Nova minicomputers had an indirection bit in every address, which made ITC easy and fast. Later, he said that he found it so convenient that he propagated it into all later Forth designs.\nToday, some Forth compilers generate direct-threaded code while others generate indirect-threaded code. The executables act the same either way.\nThreading models.\nPractically all executable threaded code uses one or another of these methods for invoking subroutines (each method is called a \"threading model\").\nDirect threading.\nAddresses in the thread are the addresses of machine language. This form is simple, but may have overheads because the thread consists only of machine addresses, so all further parameters must be loaded indirectly from memory. Some Forth systems produce direct-threaded code. On many machines direct-threading is faster than subroutine threading (see reference below).\nAn example of a stack machine might execute the sequence \"push A, push B, add\". That might be translated to the following thread and routines, where codice_3 is initialized to the address labeled codice_4 (i.e., the address where codice_5 is stored).\nstart:\n ip = &amp;thread // ip points to &amp;pushA (which points to the first instruction of pushA)\n jump *ip++ // send control to first instruction of pushA and advance ip to &amp;pushB\nthread:\n &amp;pushA\n &amp;pushB\n &amp;add\npushA:\n PUSH(A)\n jump *ip++ // send control where ip says to (i.e. to pushB) and advance ip\npushB:\n PUSH(B)\n jump *ip++\nadd:\n result = POP() + POP()\n PUSH(result)\n jump *ip++\nAlternatively, operands may be included in the thread. This can remove some indirection needed above, but makes the thread larger:\nstart:\n ip = &amp;thread\n jump *ip++\nthread:\n &amp;push\n &amp;A // address where A is stored, not literal A\n &amp;push\n &amp;B\n &amp;add\npush:\n variable_address = *ip++ // must move ip past operand address, since it is not a subroutine address\n PUSH(*variable_address) // Read value from variable and push on stack\n jump *ip++\nadd:\n result = POP() + POP()\n PUSH(result)\n jump *ip++\nIndirect threading.\nIndirect threading uses pointers to locations that in turn point to machine code. The indirect pointer may be followed by operands which are stored in the indirect \"block\" rather than storing them repeatedly in the thread. Thus, indirect code is often more compact than direct-threaded code. The indirection typically makes it slower, though usually still faster than bytecode interpreters. Where the handler operands include both values and types, the space savings over direct-threaded code may be significant. Older FORTH systems typically produce indirect-threaded code.\nFor example, if the goal is to execute \"push A, push B, add\", the following might be used. Here, codice_3 is initialized to address codice_7, each code fragment (codice_8, codice_9) is found by double-indirecting through codice_3 and an indirect block; and any operands to the fragment are found in the indirect block following the fragment's address. This requires keeping the \"current\" subroutine in codice_3, unlike all previous examples where it contained the \"next\" subroutine to be called.\nstart:\n ip = &amp;thread // points to '&amp;i_pushA'\n jump *(*ip) // follow pointers to 1st instruction of 'push', DO NOT advance ip yet\nthread:\n &amp;i_pushA\n &amp;i_pushB\n &amp;i_add\ni_pushA:\n &amp;push\n &amp;A\ni_pushB:\n &amp;push\n &amp;B\ni_add:\n &amp;add\npush:\n *sp++ = *(**ip + 1) // look 1 past start of indirect block for operand address\n jump *(*++ip) // advance ip in thread, jump through next indirect block to next subroutine\nadd:\n addend1 = *--sp\n addend2 = *--sp\n *sp++ = addend1 + addend2\n jump *(*++ip)\nSubroutine threading.\nSo-called \"subroutine-threaded code\" (also \"call-threaded code\") consists of a series of machine-language \"call\" instructions (or addresses of functions to \"call\", as opposed to direct threading's use of \"jump\"). Early compilers for ALGOL, Fortran, Cobol and some Forth systems often produced subroutine-threaded code. The code in many of these systems operated on a last-in-first-out (LIFO) stack of operands, for which compiler theory was well-developed. Most modern processors have special hardware support for subroutine \"call\" and \"return\" instructions, so the overhead of one extra machine instruction per dispatch is somewhat diminished.\nAnton Ertl, the Gforth compiler's co-creator, stated that \"in contrast to popular myths, subroutine threading is usually slower than direct threading\". However, Ertl's most recent tests show that subroutine threading is faster than direct threading in 15 out of 25 test cases. More specifically, he found that direct threading is the fastest threading model on Xeon, Opteron, and Athlon processors, indirect threading is fastest on Pentium M processors, and subroutine threading is fastest on Pentium 4, Pentium III, and PPC processors.\nAs an example of call threading for \"push A, push B, add\":\nthread:\n call pushA\n call pushB\n call add\n ret\npushA:\n *sp++ = A\n ret\npushB:\n *sp++ = B\n ret\nadd:\n addend1 = *--sp\n addend2 = *--sp\n *sp++ = addend1 + addend2\n ret\nToken threading.\nToken-threaded code implements the thread as a list of indices into a table of operations; the index width is naturally chosen to be as small as possible for density and efficiency. 1 byte / 8-bits is the natural choice for ease of programming, but smaller sizes like 4-bits, or larger like 12 or 16 bits, can be used depending on the number of operations supported. As long as the index width is chosen to be narrower than a machine pointer, it will naturally be more compact than the other threading types without much special effort by the programmer. It is usually half to three-fourths the size of other threadings, which are themselves a quarter to an eighth the size of non-threaded code. The table's pointers can either be indirect or direct. Some Forth compilers produce token-threaded code. Some programmers consider the \"p-code\" generated by some Pascal compilers, as well as the bytecodes used by .NET, Java, BASIC and some C compilers, to be token-threading.\nA common approach, historically, is bytecode, which typically uses 8-bit opcodes with a stack-based virtual machine. The archetypal bytecode interpreter is known as a \"decode and dispatch interpreter\" and follows the form:\nstart:\n vpc = &amp;thread\ndispatch:\n addr = decode(&amp;vpc) // Convert the next bytecode operation to a pointer to machine code that implements it\n // Any inter-instruction operations are performed here (e.g. updating global state, event processing, etc)\n jump addr\nCODE_PTR decode(BYTE_CODE **p) {\n // In a more complex encoding, there may be multiple tables to choose between or control/mode flags\n return table[*(*p)++];\nthread: /* Contains bytecode, not machine addresses. Hence it is more compact. */\n 1 /*pushA*/\n 2 /*pushB*/\n 0 /*add*/\ntable:\n &amp;add /* table[0] = address of machine code that implements bytecode 0 */\n &amp;pushA /* table[1] ... */\n &amp;pushB /* table[2] ... */\npushA:\n *sp++ = A\n jump dispatch\npushB:\n *sp++ = B\n jump dispatch\nadd:\n addend1 = *--sp\n addend2 = *--sp\n *sp++ = addend1 + addend2\n jump dispatch\nIf the virtual machine uses only byte-size instructions, codice_12 is simply a fetch from codice_4, but often there are commonly used 1-byte instructions plus some less-common multibyte instructions (see complex instruction set computer), in which case codice_12 is more complex. The decoding of single byte opcodes can be very simply and efficiently handled by a branch table using the opcode directly as an index.\nFor instructions where the individual operations are simple, such as \"push\" and \"add\", the overhead involved in deciding what to execute is larger than the cost of actually executing it, so such interpreters are often much slower than machine code. However, for more complex (\"compound\") instructions, the overhead percentage is proportionally less significant.\nThere are times when token-threaded code can sometimes run faster than the equivalent machine code when that machine code ends up being too large to fit in the physical CPU's L1 instruction cache. The higher code density of threaded code, especially token-threaded code, can allow it to fit entirely in the L1 cache when it otherwise would not have, thereby avoiding cache thrashing. However, threaded code consumes both instruction cache (for the implementation of each operation) as well as data cache (for the bytecode and tables) unlike machine code which only consumes instruction cache; this means threaded code will eat into the budget for the amount of data that can be held for processing by the CPU at any given time. In any case, if the problem being computed involves applying a large number of operations to a small amount of data then using threaded code may be an ideal optimization.\nHuffman threading.\nHuffman threaded code consists of lists of tokens stored as Huffman codes. A Huffman code is a variable-length string of bits that identifies a unique token. A Huffman-threaded interpreter locates subroutines using an index table or a tree of pointers that can be navigated by the Huffman code. Huffman-threaded code is one of the most compact representations known for a computer program. The index and codes are chosen by measuring the frequency of calls to each subroutine in the code. Frequent calls are given the shortest codes. Operations with approximately equal frequencies are given codes with nearly equal bit-lengths. Most Huffman-threaded systems have been implemented as direct-threaded Forth systems, and used to pack large amounts of slow-running code into small, cheap microcontrollers. Most published uses have been in smart cards, toys, calculators, and watches. The bit-oriented tokenized code used in PBASIC can be seen as a kind of Huffman-threaded code.\nLesser-used threading.\nAn example is string threading, in which operations are identified by strings, usually looked up by a hash table. This was used in Charles H. Moore's earliest Forth implementations and in the University of Illinois's experimental hardware-interpreted computer language. It is also used in Bashforth.\nRPL.\nHP's RPL, first introduced in the HP-18C calculator in 1986, is a type of proprietary hybrid (direct-threaded and indirect-threaded) \"threaded interpretive language\" (TIL) that, unlike other TILs, allows embedding of RPL \"objects\" into the \"runstream\", i.e. the stream of addresses through which the interpreter pointer advances. An RPL \"object\" can be thought of as a special data type whose in-memory structure contains an address to an \"object prolog\" at the start of the object, and then data or executable code follows. The object prolog determines how the object's body should be executed or processed. Using the \"RPL inner loop\", which was invented and patented by William C. Wickes in 1986 and published in 1988, execution follows like so:\nThis can be represented more precisely by:\nWhere above, O is the current object pointer, I is the interpreter pointer, \u0394 is the length of one address word and the \"[]\" operator stands for \"dereference\".\nWhen control is transferred to an object pointer or an embedded object, execution continues as follows:\nOn HP's Saturn microprocessors that use RPL, there is a third level of indirection made possible by an architectural / programming trick which allows faster execution.\nBranches.\nIn all interpreters, a branch simply changes the thread pointer (codice_3) to a different address in the thread. A conditional jump-if-zero branch that jumps only if the top-of-stack value is zero could be implemented as shown below. This example uses the embedded parameter version of direct threading so the codice_16 line is the destination of where to jump if the condition is true, so it must be skipped (codice_17) over if the branch is not taken.\nthread:\n &amp;brz\n &amp;thread[123]\nbrz:\n when_true_ip = *ip++ // Get destination address for branch\n if (*--sp == 0) // Pop/Consume top of stack and check if it's zero\n ip = when_true_ip\n jump *ip++\nCommon amenities.\nSeparating the data and return stacks in a machine eliminates a great deal of stack management code, substantially reducing the size of the threaded code. The dual-stack principle originated three times independently: for Burroughs large systems, Forth, and PostScript. It is used in some Java virtual machines.\nThree registers are often present in a threaded virtual machine. Another one exists for passing data between subroutines ('words'). These are:\nOften, threaded virtual machines, such as implementations of Forth, have a simple virtual machine at heart, consisting of three \"primitives\". Those are:\nIn an indirect-threaded virtual machine, the one given here, the operations are:\n next:\n *ip++ -&gt; w\n jump **w++\n nest:\n ip -&gt; *rp++\n w -&gt; ip\n next\n unnest:\n *--rp -&gt; ip\n next\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47768", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=47768", "title": "Texas Instruments", "text": "American semiconductor designer and manufacturer\nTexas Instruments Incorporated (TI) is an American multinational semiconductor company headquartered in Dallas, Texas. It is one of the top 10 semiconductor companies worldwide based on sales volume. The company's focus is on developing analog chips and embedded processors, which account for more than 80% of its revenue. TI also produces digital light processing (DLP) technology and education technology products including calculators, microcontrollers, and multi-core processors.\nTexas Instruments emerged in 1951 after a reorganization of Geophysical Service Incorporated, a company founded in 1930 that manufactured equipment for use in the seismic industry, as well as defense electronics. TI produced the world's first commercial silicon transistor in 1954, and the same year designed and manufactured the first transistor radio. Jack Kilby invented the integrated circuit in 1958 while working at TI's Central Research Labs. TI also invented the hand-held calculator in 1967, and introduced the first single-chip microcontroller in 1970, which combined all the elements of computing onto one piece of silicon.\nIn 1987, TI invented the digital light processing device (also known as the DLP chip), which serves as the foundation for the company's DLP technology and DLP Cinema. TI released the popular TI-81 calculator in 1990, which made it a leader in the graphing calculator industry. Its defense business was sold to Raytheon Company in 1997; this allowed TI to strengthen its focus on digital solutions. After the acquisition of National Semiconductor in 2011, the company had a combined portfolio of 45,000 analog products and customer design tools. In the stock market, Texas Instruments is often regarded as an indicator for the semiconductor and electronics industry as a whole, since the company sells to more than 100,000 customers. \nHistory.\nTexas Instruments was founded by Cecil H. Green, J. Erik Jonsson, Eugene McDermott, and Patrick E. Haggerty in 1951. McDermott was one of the original founders of Geophysical Service Inc. (GSI) in 1930. McDermott, Green, and Jonsson were GSI employees who purchased the company in 1941. In November 1945, Patrick Haggerty was hired as general manager of the Laboratory and Manufacturing (L&amp;M) division, which focused on electronic equipment. By 1951, the L&amp;M division, with its defense contracts, was growing faster than GSI's geophysical division. The company was reorganized and initially renamed General Instruments Inc. Because a firm named General Instrument already existed, the company was renamed Texas Instruments that same year. From 1956 to 1961, Fred Agnich of Dallas, later a Republican member of the Texas House of Representatives, was the Texas Instruments president. Geophysical Service, Inc. became a subsidiary of Texas Instruments. Early in 1988, most of GSI was sold to the Halliburton Company.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Patrick Haggerty\u2014\u200a\nGeophysical Service Incorporated.\nIn 1930, J. Clarence Karcher and Eugene McDermott founded Geophysical Service, an early provider of seismic exploration services to the petroleum industry. In 1939, the company reorganized as Coronado Corp, an oil company with Geophysical Service Inc (GSI), now as a subsidiary. On December 6, 1941, McDermott along with three other GSI employees, J. Erik Jonsson, Cecil H. Green, and H. B. Peacock purchased GSI. During World War II, GSI expanded its services to include electronics for the U.S. Army, Army Signal Corps, and U.S. Navy. In 1951, the company changed its name to Texas Instruments, spun off to build seismographs for oil explorations and with GSI becoming a wholly owned subsidiary of the new company.\nAn early success came for TI-GSI in 1965, when GSI was able (under a Top Secret government contract) to monitor the Soviet Union's underground nuclear weapons testing under the ocean in Vela Uniform, a subset of Project Vela, to verify compliance of the Partial Nuclear Test Ban Treaty.\nTexas Instruments also continued to manufacture equipment for use in the seismic industry, and GSI continued to provide seismic services. After selling (and repurchasing) GSI, TI finally sold the company to Halliburton in 1988, after which sale GSI ceased to exist as a separate entity.\nSemiconductors.\nIn early 1952, Texas Instruments purchased a patent license to produce germanium transistors from Western Electric, the manufacturing arm of AT&amp;T, for US$25,000, beginning production by the end of the year. Haggerty brought Gordon Teal to the company due to his expertise in growing semiconductor crystals while at Bell Telephone Laboratories. Teal's first assignment was to direct TI's research laboratory. At the end of 1952, Texas Instruments announced that it had expanded to 2,000 employees and $17\u00a0million in sales.\nAmong his new hires was Willis Adcock, who joined TI early in 1953. Adcock, who like Teal was a physical chemist, began leading a small research group focused on the task of fabricating grown-junction, silicon, single-crystal, small-signal transistors. Adcock later became the first TI Principal Fellow.\nFirst silicon transistor and integrated circuits.\nIn January 1954, Morris Tanenbaum at Bell Telephone Laboratories created the first workable silicon transistor. This work was reported in the spring of 1954, at the IRE off-the-record conference on solid-state devices, and was later published in the \"Journal of Applied Physics\". Working independently in April 1954, Gordon Teal at TI created the first commercial silicon transistor and tested it on April 14, 1954. On May 10, 1954, at the Institute of Radio Engineers National Conference on Airborne Electronics in Dayton, Ohio, Teal presented a paper: \"Some Recent Developments in Silicon and Germanium Materials and Devices\".\nIn 1954, Texas Instruments designed and manufactured the first transistor radio. The Regency TR-1 used germanium transistors, as silicon transistors were much more expensive at the time. This was an effort by Haggerty to increase market demand for transistors.\nJack Kilby, an employee at TI, invented the integrated circuit in 1958. Kilby recorded his initial ideas concerning the integrated circuit in July 1958, and successfully demonstrated the world's first working integrated circuit on September 12, 1958. Six months later, Robert Noyce of Fairchild Semiconductor (who went on to co-found Intel) independently developed the integrated circuit with integrated interconnect, and is also considered an inventor of the integrated circuit. In 1969, Kilby was awarded the National Medal of Science, and in 1982 he was inducted into the National Inventor's Hall of Fame. Kilby also won the 2000 Nobel Prize in Physics for his part of the invention of the integrated circuit. Noyce's chip, made at Fairchild, was made of silicon, while Kilby's chip was made of germanium. In 2008, TI named its new development laboratory \"Kilby Labs\" after Jack Kilby.\nStandard TTL.\nThe 7400 series of transistor-transistor logic chips, developed by Texas Instruments in the 1960s, popularized the use of integrated circuits in computer logic. The military-grade version of this was the 5400 series.\nMicroprocessor.\nTexas Instruments invented the hand-held calculator (a prototype called \"Cal Tech\") in 1967 and the single-chip microcomputer in 1971, was assigned the first patent on a single-chip microprocessor (invented by Gary Boone) on September 4, 1973. This was disputed by Gilbert Hyatt, formerly of the Micro Computer Company, in August 1990, when he was awarded a patent superseding TI's. This was overturned on June 19, 1996, in favor of TI (note: Intel is usually given credit with Texas Instruments for the almost-simultaneous invention of the microprocessor).\nFirst speech synthesis chip.\nIn 1978, Texas Instruments introduced the first single-chip linear predictive coding speech synthesizer. In 1976, TI began a feasibility study of memory-intensive applications for bubble memory then being developed. They soon focused on speech applications. This resulted in the development of the TMC0280 one-chip linear predictive coding speech synthesizer, which was the first time a single silicon chip had electronically replicated the human voice. This was used in several TI commercial products beginning with Speak &amp; Spell, which was introduced at the Summer Consumer Electronics Show in June 1978. In 2001, TI left the speech synthesis business, selling it to Sensory Inc. of Santa Clara, California.\nConsumer electronics and computers.\nIn May 1954, Texas Instruments designed and built a prototype of the world's first transistor radio, and, through a partnership with Industrial Development Engineering Associates of Indianapolis, Indiana, the 100% solid-state radio was sold to the public beginning in October of that year.\nIn the 1960s, company president Pat Haggerty had a team that included Jack Kilby to work on a handheld calculator project. Kilby and two other colleagues created the Cal-Tech, a three-pound battery-powered calculator that could do basic math and fit six-digit numbers on its display. This 4.25 x 6.15 x 1.75 inch calculator's processor would originate the vast majority of Texas Instruments\u2019 revenue.\nIn 1973, the handheld calculator SR-10 (named after slide rule) and in 1974, the handheld scientific calculator SR-50 were issued by TI. Both had red LED-segments numeric displays. The optical design of the SR-50 is somewhat similar to the HP-35 edited by Hewlett-Packard before in early 1972, but buttons for the operations \"+\", \"\u2013\", ... are in the right of the number block and the decimal point lies between two neighboring digits.\nTI continued to be active in the consumer electronics market through the 1970s and 1980s. Early on, this also included two digital clock models \u2013 one for desk and the other a bedside alarm. From this sprang what became the Time Products Division, which made LED watches. Though these LED watches enjoyed early commercial success due to excellent quality, it was short-lived due to poor battery life. LEDs were replaced with LCD watches for a short time, but these could not compete because of styling issues, excessive makes and models, and price points. The watches were manufactured in Dallas and then Lubbock, Texas. Several spin-offs of the Speak &amp; Spell, such as the Speak &amp; Read and Speak &amp; Math, were introduced soon thereafter.\nIn 1979, TI entered the home computer market with the TI-99/4, a competitor to computers such as the Apple II, TRS-80, and the later Atari 400/800 and VIC-20. By late 1982, TI was dominating the U.S. home computer market, shipping 5,000 computers a day from their factory in Lubbock. It discontinued the TI-99/4A (1981), the sequel to the 99/4, in late 1983 amid an intense price war waged primarily against Commodore. At the 1983 Winter CES, TI showed models 99/2 and the Compact Computer 40, the latter aimed at professional users. The TI Professional (1983) ultimately joined the ranks of the many unsuccessful MS-DOS and x86-based\u2014but non-compatible\u2014competitors to the IBM PC (the founders of Compaq, an early leader in PC compatibles, all came from TI). The company for years successfully made and sold PC-compatible laptops before withdrawing from the market and selling its product line to Acer in 1998.\nDefense electronics.\nTI entered the defense electronics market in 1942 with submarine detection equipment, based on the seismic exploration technology previously developed for the oil industry. The division responsible for these products was known at different times as the Laboratory &amp; Manufacturing Division, the Apparatus Division, the Equipment Group, and the Defense Systems &amp; Electronics Group (DSEG).\nDuring the early 1980s, TI instituted a quality program which included Juran training, as well as promoting statistical process control, Taguchi methods, and Design for Six Sigma. In the late 1980s, the company, along with Eastman Kodak and Allied Signal, began involvement with Motorola, institutionalizing Motorola's Six Sigma methodology. Motorola, which originally developed the Six Sigma methodology, began this work in 1982. In 1992, the DSEG division of Texas Instruments' quality-improvement efforts were rewarded by winning the Malcolm Baldrige National Quality Award for manufacturing.\nInfrared and radar systems.\nTI developed the AAA-4 infrared search and track device in the late 1950s and early 1960s for the F-4B Phantom for passive scanning of jet-engine emissions, but it possessed limited capabilities and was eliminated on F-4Ds and later models.\nIn 1956, TI began research on infrared technology that led to several line scanner contracts and with the addition of a second scan mirror the invention of the first forward looking infrared (FLIR) in 1963 with production beginning in 1966. In 1972, TI invented the common module FLIR concept, greatly reducing cost and allowing reuse of common components.\nTI went on to produce side-looking radar systems, the first terrain-following radar and surveillance radar systems for both the military and FAA. TI demonstrated the first solid-state radar called Molecular Electronics for Radar Applications. In 1976, TI developed a microwave landing system prototype. In 1984, TI developed the first inverse synthetic aperture radar. The first single-chip gallium arsenide radar module was developed. In 1991, the military microwave integrated circuit program was initiated\u2014a joint effort with Raytheon.\nMissiles and laser-guided bombs.\nIn 1961, TI won the guidance and control system contract for the defense suppression AGM-45 Shrike antiradiation missile. This led later to the prime on the high-speed antiradiation missile (AGM-88 HARM) development contract in 1974 and production in 1981.\nIn 1964, TI began development of the first laser guidance system for precision-guided munitions, leading to the Paveway series of laser-guided bombs (LGBs). The first LGB was the BOLT-117.\nIn 1969, TI won the Harpoon (missile) Seeker contract. In 1986, TI won the Army FGM-148 Javelin fire-and-forget man portable antitank guided missile in a joint venture with Martin Marietta. In 1991, TI was awarded the contract for the AGM-154 Joint Standoff Weapon.\nIn 1988, TI paid the U.S. government $5.2 million \"to settle allegations one of its divisions overcharged the government on contracts for guided missiles sold to the Navy\".\nMilitary computers.\nBecause of TI's research and development of military temperature-range silicon transistors and integrated circuits (ICs), TI won contracts for the first IC-based computer for the U.S. Air Force in 1961 (molecular electronic computer) and for ICs for the Minuteman Missile the following year. In 1968, TI developed the data systems for Mariner Program. In 1991 TI won the F-22 Radar and Computer development contract.\nDivestiture to Raytheon.\nAs the defense industry consolidated, TI sold its defense business to the Raytheon Company in 1997 for $2.95 billion. The Department of Justice required that Raytheon divest the TI Monolithic Microwave Integrated Circuit (MMIC) operations after closing the transaction. The TI MMIC business accounted for less than $40 million in 1996 revenues, or roughly 2% of the $1.8 billion in total TI defense revenues, and was sold to TriQuint Semiconductor, Inc. Raytheon retained its own existing MMIC capabilities and has the right to license TI's MMIC technology for use in future product applications from TriQuint.\nShortly after Raytheon acquired TI DSEG, Raytheon then acquired Hughes Aircraft from General Motors. Raytheon then owned TI's mercury cadmium telluride detector business and infrared (IR) systems group. In California, it also had Hughes infrared detector and an IR systems business. When again the US government forced Raytheon to divest itself of a duplicate capability, the company kept the TI IR systems business and the Hughes detector business. As a result of these acquisitions, these former arch rivals of TI systems and Hughes detectors work together.\nImmediately after acquisition, DSEG was known as Raytheon TI Systems (RTIS). It is now fully integrated into Raytheon and this designation no longer exists.\nArtificial intelligence.\nTI was active in the area of artificial intelligence in the 1980s. In addition to ongoing developments in speech and signal processing and recognition, it developed and sold the Explorer computer family of Lisp machines. For the Explorer, a special 32-bit Lisp microprocessor was developed, which was used in the Explorer II and the TI MicroExplorer (a Lisp Machine on a NuBus board for the Apple Macintosh). AI application software developed by TI for the Explorer included the gate assignment system for Northwest Airlines and United Airlines, https:// \"an artificial intelligence program that captures the combined experience and knowledge of a half-dozen United operations experts.\" In software for the PC, they introduced \"Personal Consultant\", a rule-based expert system development tool and runtime engine, followed by \"Personal Consultant Plus\" written in the Lisp-like language from MIT known as Scheme, and the natural language menu system NLMenu.\nSensors and controls.\nTI was a major original-equipment manufacturer of sensor, control, protection, and RFID products for the automotive, appliance, aircraft, and other industries. The Sensors &amp; Controls division was headquartered in Attleboro, Massachusetts.\nBy the mid-1980s, industrial computers known as PLC's (programmable logic controllers) were separated from Sensors &amp; Controls as the Industrial Systems Division, which was sold in the early 1990s to Siemens.\nIn 2006, Bain Capital LLC, a private equity firm, purchased the Sensors &amp; Controls division for $3.0 billion in cash. The RFID portion of the division remained part of TI, transferring to the Application Specific Products business unit of the Semiconductor division, with the newly formed independent company based in Attleboro taking the name Sensata Technologies.\nSoftware.\nIn 1997, TI sold its software division, along with its main products such as the CA Gen, to Sterling Software, which is now part of Computer Associates. However, TI still owns small pieces of software, such as the software for calculators such as the TI Interactive!. TI also creates a significant amount of target software for its digital signal processors, along with host-based tools for creating DSP applications.\nFinances.\nFor the fiscal year 2017, Texas Instruments reported earnings of $3.682 billion, with an annual revenue of $14.961 billion, an increase of 11.9% over the previous fiscal cycle. TI shares traded at over $82 per share, and its market capitalization was valued at over $88.0 billion in October 2018. As of 2018, TI ranked 192nd on the Fortune 500 list of the largest United States corporations by revenue.\nDivisions.\nAs of 2016, TI is made up of four divisions: analog products, embedded processors, digital light processing, and educational technology.\nAs of January 2021, the industrial market accounts for 41 percent of TI's annual revenue, and the automotive market accounts for 21 percent.\nOther businesses.\nTI's remaining businesses consisting of DLP products (primarily used in projectors to create high-definition images), calculators and certain custom semiconductors known as application-specific integrated circuits.\nDLP Products.\nTexas Instruments sells DLP technology for TVs, video projectors, and digital cinema. On February 2, 2000, Philippe Binant, technical manager of Digital Cinema Project at Gaumont in France, realized the first digital cinema projection in Europe with the DLP Cinema technology developed by TI DLP technology enables a diverse range of display and advanced light control applications spanning industrial, enterprise, automotive, and consumer market segments.\nThe ASICs business develops more complex integrated-circuit solutions for clients on a custom basis.\nEducational technology.\nTI has produced educational toys for children, including the Little Professor in 1976 and Dataman in 1977.\nTI produces a range of calculators, with the TI-30 being one of the most popular early calculators. TI has also developed a line of graphing calculators, the first being the TI-81, and most popular being the TI-83 Plus (with the TI-84 Plus being an updated equivalent).\nMany TI calculators are still sold without graphing capabilities. The TI-30 has been replaced by the TI-30X IIS. Also, some financial calculators are for sale on the TI website.\nIn 2007, TI released the TI-Nspire family of calculators and computer software that has similar capabilities to the calculators.\nLess than 3% of Texas Instruments\u2019 overall revenue comes from calculators, part of the $1.43 billion revenue in the \"Other\" section in the company's 2018 annual report. Nevertheless, the calculators are a lucrative product. For example, estimates have a $15 to $20 cost to produce TI-84 Plus which likely has a profit margin of at least 50%.\nThroughout the 1980s, Texas Instruments worked closely with National Council of Teachers of Mathematics (NCTM) to develop a calculator to become the educational standard. In 1986, Connecticut School Board became the first to require a graphing calculator on state-mandated exams. Chicago Public Schools gave a free calculator to every student, beginning in the fourth grade, in 1988. New York required the calculator in 1992 for its Regents exams after first allowing it the previous year. The College Board required calculators on the Advanced Placement tests in 1993 and allowed calculators on the SAT a year later. Texas Instruments provides free services to the College Board, which administers AP tests and the SAT, and also has a group called Teachers Teaching for Technology (T3), which educates teachers on how to use its calculators.\nTI calculator community.\nIn the 1990s, with the advent of TI's graphing calculator series, programming became popular among some students. The TI-8x series of calculators (beginning with the TI-81) came with a built-in BASIC interpreter, through which simple programs could be created. The TI-83 was the first in the series to receive native assembly. Around the same time that these programs were first being written, programmers began creating websites to host their work, along with tutorials and other calculator-relevant information. This led to the formation of TI calculator webrings and eventually a few large communities, including ticalc.org.\nThe TI community reached the height of its popularity in the early 2000s, with many new websites and programming groups being started. In fact, the aforementioned community sites were exploding with activity, with close to 100 programs being uploaded daily by users of the sites. Also, a competition existed between both sites to be the top site in the community, which helped increase interest and activity in the community.\nOne of the common unifying forces that has united the community over the years has been the rather contentious relationship with TI regarding control over its graphing calculators. TI graphing calculators generally fall into two distinct groups\u2014the older ones powered by the Zilog Z80 and the newer ones running on the Motorola 68000 series. Both lines of calculators are locked by TI with checks in the hardware and through the signing of software to disable use of custom operating systems. However, users discovered the keys and published them in 2009. TI responded by sending invalid DMCA takedown notices, causing the Texas Instruments signing key controversy.\nCompetitors.\nTI has the largest market share in the analog semiconductor industry, accounting for over $10 billion of the total $57 billion market in 2020.\nAcquisitions.\nNational Semiconductor acquisition.\nOn April 4, 2011, Texas Instruments announced that it had agreed to buy National Semiconductor for $6.5 billion in cash. TI paid $25 per share of National Semiconductor stock, which was an 80% premium over the share price of $14.07 as of April 4, 2011, close. The deal made TI the world's largest maker of analog technology components.\nThe companies formally merged on September 23, 2011.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47769", "revid": "5846", "url": "https://en.wikipedia.org/wiki?curid=47769", "title": "Transistor\u2013transistor logic", "text": "Class of digital circuits\nTransistor\u2013transistor logic (TTL) is a logic family built from bipolar junction transistors (BJTs). Its name signifies that transistors perform both the logic function (the first \"transistor\") and the amplifying function (the second \"transistor\"), as opposed to earlier resistor\u2013transistor logic (RTL) and diode\u2013transistor logic (DTL).\nTTL integrated circuits (ICs) were widely used in applications such as computers, industrial controls, test equipment and instrumentation, consumer electronics, and synthesizers.\nAfter their introduction in integrated circuit form in 1963 by Sylvania Electric Products, TTL integrated circuits were manufactured by several semiconductor companies. The 7400 series by Texas Instruments became particularly popular. TTL manufacturers offered a wide range of logic gates, flip-flops, counters, and other circuits. Variations of the original TTL circuit design offered higher speed or lower power dissipation to allow design optimization. TTL devices were originally made in ceramic and plastic dual in-line package(s) and in flat-pack form. Some TTL chips are now also made in surface-mount technology packages.\nTTL became the foundation of computers and other digital electronics. Even after Very-Large-Scale Integration (VLSI) CMOS integrated circuit microprocessors made multiple-chip processors obsolete, TTL devices still found extensive use as glue logic interfacing between more densely integrated components.\nHistory.\nTTL was invented in 1961 by James L. Buie of TRW, which declared it \"particularly suited to the newly developing integrated circuit design technology.\" The original name for TTL was \"transistor-coupled transistor logic\" (TCTL). The first commercial integrated-circuit TTL devices were manufactured by Sylvania in 1963, called the Sylvania Universal High-Level Logic family (SUHL). The Sylvania parts were used in the controls of the Phoenix missile. TTL became popular with electronic systems designers after Texas Instruments introduced the 5400 series of ICs, with military temperature range, in 1964 and the later 7400 series, specified over a narrower range and with inexpensive plastic packages, in 1966.\nThe Texas Instruments 7400 family became an industry standard. Compatible parts were made by Motorola, AMD, Fairchild, Intel, Intersil, Signetics, Mullard, Siemens, SGS-Thomson, Rifa, National Semiconductor, and many other companies, even in the Eastern Bloc (Soviet Union, GDR, Poland, Czechoslovakia, Hungary, Romania \u2014 for details see 7400 series). Not only did others make compatible TTL parts, but compatible parts were made using many other circuit technologies as well. At least one manufacturer, IBM, produced non-compatible TTL circuits for its own use; IBM used the technology in the IBM System/38, IBM 4300, and IBM 3081.\nThe term \"TTL\" is applied to many successive generations of bipolar logic, with gradual improvements in speed and power consumption over about two decades. The most recently introduced family 74Fxx is still sold today (as of 2019), and was widely used into the late 90s. 74AS/ALS Advanced Schottky was introduced in 1985. As of 2008, Texas Instruments continues to supply the more general-purpose chips in numerous obsolete technology families, albeit at increased prices. Typically, TTL chips integrate no more than a few hundred transistors each. Functions within a single package generally range from a few logic gates to a microprocessor bit-slice. TTL also became important because its low cost made digital techniques economically practical for tasks previously done by analog methods.\nThe Kenbak-1, ancestor of the first personal computers, used TTL for its CPU instead of a microprocessor chip, which was not available in 1971. The Datapoint 2200 from 1970 used TTL components for its CPU and was the basis for the 8008 and later the x86 instruction set. The 1973 Xerox Alto and 1981 Star workstations, which introduced the graphical user interface, used TTL circuits integrated at the level of arithmetic logic units (ALUs) and bitslices, respectively. Most computers used TTL-compatible \"glue logic\" between larger chips well into the 1990s. Until the advent of programmable logic, discrete bipolar logic was used to prototype and emulate microarchitectures under development.\nImplementation.\nFundamental TTL gate.\nTTL inputs are the emitters of bipolar transistors. In the case of NAND inputs, the inputs are the emitters of multiple-emitter transistors, functionally equivalent to multiple transistors where the bases and collectors are tied together. The transistor's collector is buffered by a common emitter amplifier.\nInputs both logical ones. When all the inputs are held at high voltage, the base\u2013emitter junctions of the multiple-emitter transistor are reverse-biased. Unlike DTL, a small collector current (approximately 10\u00a0\u03bcA) is drawn by each of the inputs. This is because the transistor is in reverse-active mode. An approximately constant current flows from the positive rail, through the resistor and into the base of the multiple emitter transistor. This current passes through the base\u2013emitter junction of the output transistor, allowing it to conduct and pulling the output voltage low (logical zero).\nAn input logical zero. Note that the base\u2013collector junction of the multiple-emitter transistor and the base\u2013emitter junction of the output transistor are in series between the bottom of the resistor and ground. If one input voltage becomes zero, the corresponding base\u2013emitter junction of the multiple-emitter transistor is in parallel with these two junctions. A phenomenon called current steering means that when two voltage-stable elements with different threshold voltages are connected in parallel, the current flows through the path with the smaller threshold voltage. That is, current flows out of this input and into the zero (low) voltage source. As a result, no current flows through the base of the output transistor, causing it to stop conducting and the output voltage becomes high (logical one). During the transition the input transistor is briefly in its active region; so it draws a large current away from the base of the output transistor and thus quickly discharges its base. This is a critical advantage of TTL over DTL that speeds up the transition over a diode input structure.\nThe main disadvantage of TTL with a simple output stage is the relatively high output resistance at output logical \"1\" that is completely determined by the output collector resistor. It limits the number of inputs that can be connected (the fanout). Some advantage of the simple output stage is the high voltage level (up to VCC) of the output logical \"1\" when the output is not loaded.\nOpen collector wired logic.\nA common variation omits the collector resistor of the output transistor, making an open-collector output. This allows the designer to fabricate wired logic by connecting the open-collector outputs of several logic gates together and providing a single external pull-up resistor. If any of the logic gates becomes logic low (transistor conducting), the combined output will be low. Examples of this type of gate are the 7401 and 7403 series. Open-collector outputs of some gates have a higher maximum voltage, such as 15 V for the 7426, useful when driving non-TTL loads.\nTTL with a \"totem-pole\" output stage.\nTo solve the problem with the high output resistance of the simple output stage the second schematic adds to this a \"totem-pole\" (\"push\u2013pull\") output. It consists of the two n-p-n transistors V3 and V4, the \"lifting\" diode V5 and the current-limiting resistor R3 (see the figure on the right). It is driven by applying the same \"current steering\" idea as above.\nWhen V2 is \"off\", V4 is \"off\" as well and V3 operates in active region as a voltage follower producing high output voltage (logical \"1\").\nWhen V2 is \"on\", it activates V4, driving low voltage (logical \"0\") to the output. Again there is a current-steering effect: the series combination of V2's C-E junction and V4's B-E junction is in parallel with the series of V3 B-E, V5's anode-cathode junction, and V4 C-E. The second series combination has the higher threshold voltage, so no current flows through it, i.e. V3 base current is deprived. Transistor V3 turns \"off\" and it does not impact on the output.\nIn the middle of the transition, the resistor R3 limits the current flowing directly through the series connected transistor V3, diode V5 and transistor V4 that are all conducting. It also limits the output current in the case of output logical \"1\" and short connection to the ground. The strength of the gate may be increased without proportionally affecting the power consumption by removing the pull-up and pull-down resistors from the output stage.\nThe main advantage of TTL with a \"totem-pole\" output stage is the low output resistance at output logical \"1\". It is determined by the upper output transistor V3 operating in active region as an emitter follower. The resistor R3 does not increase the output resistance since it is connected in the V3 collector and its influence is compensated by the negative feedback. \nA disadvantage of the \"totem-pole\" output stage is the decreased voltage level (no more than 3.5 V) of the output logical \"1\" (even if the output is unloaded). The reasons for this reduction are the voltage drops across the V3 base\u2013emitter and V5 anode\u2013cathode junctions.\nInterfacing considerations.\nLike DTL, TTL is a \"current-sinking logic\" since a current must be drawn from inputs to bring them to a logic 0 voltage level. The driving stage must absorb up to 1.6 mA from a standard TTL input while not allowing the voltage to rise to more than 0.4 volts. The output stage of the most common TTL gates is specified to function correctly when driving up to 10 standard input stages (a fanout of 10). TTL inputs are sometimes simply left floating to provide a logical \"1\", though this usage is not recommended.\nStandard TTL circuits operate with a 5-volt power supply. A TTL input signal is defined as \"low\" when between 0\u00a0V and 0.8\u00a0V with respect to the ground terminal, and \"high\" when between 2\u00a0V and VCC (5\u00a0V), and if a voltage signal ranging between 0.8\u00a0V and 2.0\u00a0V is sent into the input of a TTL gate, there is no certain response from the gate and therefore it is considered \"uncertain\" (precise logic levels vary slightly between sub-types and by temperature). TTL outputs are typically restricted to narrower limits of between 0.0\u00a0V and 0.4\u00a0V for a \"low\" and between 2.4\u00a0V and VCC for a \"high\", providing at least 0.4\u00a0V of noise immunity. Standardization of the TTL levels is so ubiquitous that complex circuit boards often contain TTL chips made by many different manufacturers selected for availability and cost, compatibility being assured. Two circuit board units off the same assembly line on different successive days or weeks might have a different mix of brands of chips in the same positions on the board; repair is possible with chips manufactured years later than original components. Within usefully broad limits, logic gates can be treated as ideal Boolean devices without concern for electrical limitations. The 0.4\u00a0V noise margins are adequate because of the low output impedance of the driver stage, that is, a large amount of noise power superimposed on the output is needed to drive an input into an undefined region.\nIn some cases (e.g., when the output of a TTL logic gate needs to be used for driving the input of a CMOS gate), the voltage level of the \"totem-pole\" output stage at output logical \"1\" can be increased closer to VCC by connecting an external resistor between the V4 collector and the positive rail. It pulls up the V5 cathode and cuts-off the diode. However, this technique actually converts the sophisticated \"totem-pole\" output into a simple output stage having significant output resistance when driving a high level (determined by the external resistor).\nPackaging.\nLike most integrated circuits of the period 1963\u20131990, commercial TTL devices are usually packaged in dual in-line packages (DIPs), usually with 14 to 24 pins, for through-hole or socket mounting. Epoxy plastic (PDIP) packages were often used for commercial temperature range components, while ceramic packages (CDIP) were used for military temperature range parts.\nBeam-lead chip dies without packages were made for assembly into larger arrays as hybrid integrated circuits. Parts for military and aerospace applications were packaged in flatpacks, a form of surface-mount package, with leads suitable for welding or soldering to printed circuit boards. Today, many TTL-compatible devices are available in surface-mount packages, which are available in a wider array of types than through-hole packages.\nTTL is particularly well suited to bipolar integrated circuits because additional inputs to a gate merely required additional emitters on a shared base region of the input transistor. If individually packaged transistors were used, the cost of all the transistors would discourage one from using such an input structure. But in an integrated circuit, the additional emitters for extra gate inputs add only a small area.\nAt least one computer manufacturer, IBM, built its own flip chip integrated circuits with TTL; these chips were mounted on ceramic multi-chip modules.\nComparison with other logic families.\nTTL devices consume substantially more power than equivalent CMOS devices at rest, but power consumption does not increase with clock speed as rapidly as for CMOS devices. Compared to contemporary ECL circuits, TTL uses less power and has easier design rules but is substantially slower. Designers can combine ECL and TTL devices in the same system to achieve best overall performance and economy, but level-shifting devices are required between the two logic families. TTL is less sensitive to damage from electrostatic discharge than early CMOS devices.\nDue to the output structure of TTL devices, the output impedance is asymmetrical between the high and low state, making them unsuitable for driving transmission lines. This drawback is usually overcome by buffering the outputs with special line-driver devices where signals need to be sent through cables. ECL, by virtue of its symmetric low-impedance output structure, does not have this drawback.\nThe TTL \"totem-pole\" output structure often has a momentary overlap when both the upper and lower transistors are conducting, resulting in a substantial pulse of current drawn from the power supply. These pulses can couple in unexpected ways between multiple integrated circuit packages, resulting in reduced noise margin and lower performance. TTL systems usually have a decoupling capacitor for every one or two IC packages, so that a current pulse from one TTL chip does not momentarily reduce the supply voltage to another.\nSince the mid 1980s, several manufacturers supply CMOS logic equivalents with TTL-compatible input and output levels, usually bearing part numbers similar to the equivalent TTL component and with the same pinouts. For example, the 74HCT00 series provides many drop-in replacements for bipolar 7400 series parts, but uses CMOS technology. (The \"T\" in \"HCT\" stands for \"TTL-compatible\". The related 74HC00 series also uses CMOS technology but is not TTL-compatible.)\nSub-types.\nSuccessive generations of technology produced compatible parts with improved power consumption or switching speed, or both. Although vendors uniformly marketed these various product lines as TTL with Schottky diodes, some of the underlying circuits, such as used in the LS family, could rather be considered DTL.\nVariations of and successors to the basic TTL family, which has a typical gate propagation delay of 10ns and a power dissipation of 10\u00a0mW per gate, for a power\u2013delay product (PDP) or switching energy of about 100 pJ, include:\nMost manufacturers offer commercial and extended temperature ranges: for example Texas Instruments 7400 series parts are rated from 0 to 70\u00a0\u00b0C, and 5400 series devices over the military-specification temperature range of \u221255 to +125\u00a0\u00b0C.\nSpecial quality levels and high-reliability parts are available for military and aerospace applications.\nRadiation-hardened devices (for example from the SNJ54 series) are offered for space applications.\nApplications.\nBefore the advent of VLSI devices, TTL integrated circuits were a standard method of construction for the processors of minicomputer and midrange mainframe computers, such as the DEC VAX and Data General Eclipse; however some computer families were based on proprietary components (e.g. Fairchild CTL) while supercomputers and high-end mainframes used emitter-coupled logic. They were also used for equipment such as machine tool numerical controls, printers and video display terminals, and as microprocessors became more functional for \"glue logic\" applications, such as address decoders and bus drivers, which tie together the function blocks realized in VLSI elements. The Gigatron TTL is a more recent (2018) example of a processor built entirely with TTL integrated circuits.\nAnalog applications.\nWhile originally designed to handle logic-level digital signals, a TTL inverter can be biased as an analog amplifier. Connecting a resistor between the output and the input biases the TTL element as a negative feedback amplifier. Such amplifiers may be useful to convert analog signals to the digital domain but would not ordinarily be used where analog amplification is the primary purpose. TTL inverters can also be used in crystal oscillators where their analog amplification ability is significant.\nA TTL gate may operate inadvertently as an analog amplifier if the input is connected to a slowly changing input signal that traverses the unspecified region from 0.8\u00a0V to 2\u00a0V. The output can be erratic when the input is in this range. A slowly changing input like this can also cause excess power dissipation in the output circuit. If such an analog input must be used, there are specialized TTL parts with Schmitt trigger inputs available that will reliably convert the analog input to a digital value, effectively operating as a one bit A to D converter.\nSerial signaling.\nTTL serial refers to single-ended serial communication using raw transistor voltage levels: \"low\" for 0 and \"high\" for 1. UART over TTL serial is a common debug interface for embedded devices. Handheld devices such as graphing calculators and NMEA 0183-compliant GPS receivers and fishfinders also commonly use UART with TTL. TTL serial is only a \"de facto\" standard: there are no strict electrical guidelines. Driver\u2013receiver modules interface between TTL and longer-range serial standards: one example is the MAX232, which converts from and to RS-232.\nDifferential TTL is TTL serial carried over a differential pair with complement levels, providing much enhanced noise tolerance. Both RS-422 and RS-485 signals can be produced using TTL levels.\nccTalk is based on TTL voltage levels.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47770", "revid": "1741963", "url": "https://en.wikipedia.org/wiki?curid=47770", "title": "TTL", "text": "TTL may refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nOther uses.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "47771", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=47771", "title": "Roman curia", "text": ""}
{"id": "47772", "revid": "1782949", "url": "https://en.wikipedia.org/wiki?curid=47772", "title": "Instruction set architecture", "text": "Model that describes the programmable interface of a computer processor\nAn instruction set architecture (ISA) is an abstract model that defines the programmable interface of the CPU of a computer; how software can control a computer. A device (i.e. CPU) that interprets instructions described by an ISA is an implementation of that ISA. Generally, the same ISA is used for a family of related CPU devices.\nIn general, an ISA defines the instructions, data types, registers, and the programming interface for managing main memory such as addressing modes, virtual memory, and memory consistency mechanisms. The ISA also includes the input/output model of the programmable interface.\nAn ISA specifies the behavior implied by machine code running on an implementation of that ISA in a fashion that does not depend on the characteristics of that implementation, providing binary compatibility between implementations. This enables multiple implementations of an ISA that differ in characteristics such as performance, physical size, and monetary cost (among other things), but that are capable of running the same machine code, so that a lower-performance, lower-cost machine can be replaced with a higher-cost, higher-performance machine without having to replace software. It also enables the evolution of the microarchitectures of the implementations of that ISA, so that a newer, higher-performance implementation of an ISA can run software that runs on previous generations of implementations.\nIf an operating system maintains a standard and compatible application binary interface (ABI) for a particular ISA, machine code will run on future implementations of that ISA and operating system. However, if an ISA supports running multiple operating systems, it does not guarantee that machine code for one operating system will run on another operating system, unless the first operating system supports running machine code built for the other operating system.\nAn ISA can be extended by adding instructions or other capabilities, or adding support for larger addresses and data values; an implementation of the extended ISA will still be able to execute machine code for versions of the ISA without those extensions. Machine code using those extensions will only run on implementations that support those extensions.\nThe binary compatibility that they provide makes ISAs one of the most fundamental abstractions in computing.\nOverview.\nAn instruction set architecture is distinguished from a microarchitecture, which is the set of processor design techniques used, in a particular processor, to implement the instruction set. Processors with different microarchitectures can share a common instruction set. For example, the Intel Pentium and the AMD Athlon implement nearly identical versions of the x86 instruction set, but they have radically different internal designs.\nThe concept of an \"architecture\", distinct from the design of a specific machine, was developed by Fred Brooks at IBM during the design phase of System/360. &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Prior to NPL [System/360], the company's computer designers had been free to honor cost objectives not only by selecting technologies but also by fashioning functional and architectural refinements. The SPREAD compatibility objective, in contrast, postulated a single architecture for a series of five processors spanning a wide range of cost and performance. None of the five engineering design teams could count on being able to bring about adjustments in architectural specifications as a way of easing difficulties in achieving cost and performance objectives.\nSome virtual machines that support bytecode as their ISA such as Smalltalk, the Java virtual machine, and Microsoft's Common Language Runtime, implement this by translating the bytecode for commonly used code paths into native machine code. In addition, these virtual machines execute less frequently used code paths by interpretation (see: Just-in-time compilation). Transmeta implemented the x86 instruction set atop very long instruction word (VLIW) processors in this fashion.\nClassification of ISAs.\nAn ISA may be classified in a number of different ways. A common classification is by architectural \"complexity\". A complex instruction set computer (CISC) has many specialized instructions, some of which may only be rarely used in practical programs. A reduced instruction set computer (RISC) simplifies the processor by efficiently implementing only the instructions that are frequently used in programs, while the less common operations are implemented as subroutines, having their resulting additional processor execution time offset by infrequent use.\nOther types include VLIW architectures, and the closely related and \"explicitly parallel instruction computing\" (EPIC) architectures. These architectures seek to exploit instruction-level parallelism with less hardware than RISC and CISC by making the compiler responsible for instruction issue and scheduling.\nArchitectures with even less complexity have been studied, such as the minimal instruction set computer (MISC) and one-instruction set computer (OISC). These are theoretically important types, but have not been commercialized.\nInstructions.\nMachine language is built up from discrete \"statements\" or \"instructions\". On the processing architecture, a given instruction may specify:\nregisters\nliteral/constant values\naddressing modes used to access memory\nMore complex operations are built up by combining these simple instructions, which are executed sequentially, or as otherwise directed by control flow instructions.\nInstruction types.\nExamples of operations common to many instruction sets include:\nSome examples of coprocessor instructions include those for the IBM 3090 Vector facility and the Intel 8087.\nComplex instructions.\nProcessors may include \"complex\" instructions in their instruction set. A single \"complex\" instruction does something that may take many instructions on other computers. Such instructions are typified by instructions that take multiple steps, control multiple functional units, or otherwise appear on a larger scale than the bulk of simple instructions implemented by the given processor. Some examples of \"complex\" instructions include:\nComplex instructions are more common in CISC instruction sets than in RISC instruction sets, but RISC instruction sets may include them as well. RISC instruction sets generally do not include ALU operations with memory operands, or instructions to move large blocks of memory, but most RISC instruction sets include SIMD or vector instructions that perform the same arithmetic operation on multiple pieces of data at the same time. SIMD instructions have the ability of manipulating large vectors and matrices in minimal time. SIMD instructions allow easy parallelization of algorithms commonly involved in sound, image, and video processing. Various SIMD implementations have been brought to market under trade names such as MMX, 3DNow!, and AltiVec.\nInstruction encoding.\nOn traditional architectures, an instruction includes an opcode that specifies the operation to perform, such as \"add contents of memory to register\"\u2014and zero or more operand specifiers, which may specify registers, memory locations, or literal data. The operand specifiers may have addressing modes determining their meaning or may be in fixed fields. In very long instruction word (VLIW) architectures, which include many microcode architectures, multiple simultaneous opcodes and operands are specified in a single instruction.\nSome exotic instruction sets do not have an opcode field, such as transport triggered architectures (TTA), only operand(s).\nMost stack machines have \"0-operand\" instruction sets in which arithmetic and logical operations lack any operand specifier fields; only instructions that push operands onto the evaluation stack or that pop operands from the stack into variables have operand specifiers. The instruction set carries out most ALU actions with postfix (reverse Polish notation) operations that work only on the expression stack, not on data registers or arbitrary main memory cells. This can be very convenient for compiling high-level languages, because most arithmetic expressions can be easily translated into postfix notation.\nConditional instructions.\nConditional instructions often have a predicate field\u2014a few bits that encode the specific condition to cause an operation to be performed rather than not performed. For example, a conditional branch instruction will transfer control if the condition is true, so that execution proceeds to a different part of the program, and not transfer control if the condition is false, so that execution continues sequentially. Some instruction sets also have conditional moves, so that the move will be executed, and the data stored in the target location, if the condition is true, and not executed, and the target location not modified, if the condition is false. Similarly, IBM z/Architecture has a conditional store instruction. A few instruction sets include a predicate field in every instruction. Having predicates on instructions is called predication, and can \"include\" conditional-branches, such as on the SuperH.\nNumber of operands.\nInstruction sets may be categorized by the maximum number of operands \"explicitly\" specified in instructions.\n C = A+B\nDue to the large number of bits needed to encode the three registers of a 3-operand instruction, RISC architectures that have 16-bit instructions are invariably 2-operand designs, such as the Atmel AVR, TI MSP430, and some versions of ARM Thumb. RISC architectures that have 32-bit instructions are usually 3-operand designs, such as the ARM, AVR32, MIPS, Power ISA, and SPARC architectures. However even 3-operand RISC architectures will, at considerable cost, have Fused multiply-and-add 4-operand instructions out of necessity, due to the increased accuracy provided. Modern examples include Power ISA and RISC-V.\nEach instruction specifies some number of operands (registers, memory locations, or immediate values) \"explicitly\". Some instructions give one or both operands implicitly, such as by being stored on top of the stack or in an implicit register. If some of the operands are given implicitly, fewer operands need be specified in the instruction. When a \"destination operand\" explicitly specifies the destination, an additional operand must be supplied. Consequently, the number of operands encoded in an instruction may differ from the mathematically necessary number of arguments for a logical or arithmetic operation (the arity). Operands are either encoded in the \"opcode\" representation of the instruction, or else are given as values or addresses following the opcode.\nRegister pressure.\n\"Register pressure\" measures the availability of free registers at any point in time during the program execution. Register pressure is high when a large number of the available registers are in use. Thus, the higher the register pressure, the more often the register contents must be spilled into cache or memory which, given their slower speed, exacts a heavy price. Increasing the number of registers in an architecture decreases register pressure but increases the cost.\nWhile embedded instruction sets such as Thumb suffer from extremely high register pressure because they have small register sets, general-purpose RISC ISAs like MIPS and Alpha enjoy low register pressure. CISC ISAs like x86-64 offer low register pressure despite having smaller register sets. This is due to the many addressing modes and optimizations (such as sub-register addressing, memory operands in ALU instructions, absolute addressing, PC-relative addressing, and register-to-register spills) that CISC ISAs offer.\nInstruction length.\nThe size or length of an instruction varies widely, from as little as four bits in some microcontrollers to many hundreds of bits in some VLIW systems. Processors used in personal computers, mainframes, and supercomputers have minimum instruction sizes between 8 and 64 bits. The longest possible instruction on x86 is 15 bytes (120 bits). Within an instruction set, different instructions may have different lengths. In some architectures, notably most reduced instruction set computers (RISC), &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;instructions are a fixed length, typically corresponding with that architecture's word size. In other architectures, instructions have variable length, typically integral multiples of a byte or a halfword. Some, such as the ARM with \"Thumb-extension\" have \"mixed\" variable encoding, that is two fixed, usually 32-bit and 16-bit encodings, where instructions cannot be mixed freely but must be switched between on a branch (or exception boundary in ARMv8).\nFixed-length instructions are less complicated to handle than variable-length instructions for several reasons (not having to check whether an instruction straddles a cache line or virtual memory page boundary, for instance), and are therefore somewhat easier to optimize for speed.\nCode density.\nIn early 1960s computers, main memory was expensive and very limited, even on mainframes. Minimizing the size of a program to make sure it would fit in the limited memory was often central. Thus the size of the instructions needed to perform a particular task, the \"code density\", was an important characteristic of any instruction set. It remained important on the initially-tiny memories of minicomputers and then microprocessors. Density remains important today, for smartphone applications, applications downloaded into browsers over slow Internet connections, and in ROMs for embedded applications. A more general advantage of increased density is improved effectiveness of caches and instruction prefetch. \nComputers with high code density often have complex instructions for procedure entry, parameterized returns, loops, etc. (therefore retroactively named \"Complex Instruction Set Computers\", CISC). However, more typical, or frequent, \"CISC\" instructions merely combine a basic ALU operation, such as \"add\", with the access of one or more operands in memory (using addressing modes such as direct, indirect, indexed, etc.). Certain architectures may allow two or three operands (including the result) directly in memory or may be able to perform functions such as automatic pointer increment, etc. Software-implemented instruction sets may have even more complex and powerful instructions.\n\"Reduced instruction-set computers\", RISC, were first widely implemented during a period of rapidly growing memory subsystems. They sacrifice code density to simplify implementation circuitry, and try to increase performance via higher clock frequencies and more registers. A single RISC instruction typically performs only a single operation, such as an \"add\" of registers or a \"load\" from a memory location into a register. A RISC instruction set normally has a fixed instruction length, whereas a typical CISC instruction set has instructions of widely varying length. However, as RISC computers normally require more and often longer instructions to implement a given task, they inherently make less optimal use of bus bandwidth and cache memories.\nCertain embedded RISC ISAs like Thumb and AVR32 typically exhibit very high density owing to a technique called code compression. This technique packs two 16-bit instructions into one 32-bit word, which is then unpacked at the decode stage and executed as two instructions.\nMinimal instruction set computers (MISC) are commonly a form of stack machine, where there are few separate instructions (8\u201332), so that multiple instructions can be fit into a single machine word. These types of cores often take little silicon to implement, so they can be easily realized in an FPGA (field-programmable gate array) or in a multi-core form. The code density of MISC is similar to the code density of RISC; the increased instruction density is offset by requiring more of the primitive instructions to do a task.\nThere has been research into executable compression as a mechanism for improving code density. The mathematics of Kolmogorov complexity describes the challenges and limits of this.\nIn practice, code density is also dependent on the compiler. Most optimizing compilers have options that control whether to optimize code generation for execution speed or for code density. For instance GCC has the option codice_35 to optimize for small machine code size, and codice_36 to optimize for execution speed at the cost of larger machine code.\nRepresentation.\nThe instructions constituting a program are rarely specified using their internal, numeric form (machine code); they may be specified by programmers using an assembly language or, more commonly, may be generated from high-level programming languages by compilers.\nDesign.\nThe design of instruction sets is a complex issue. There were two stages in history for the microprocessor. The first was the CISC (complex instruction set computer), which had many different instructions. In the 1970s, however, places like IBM did research and found that many instructions in the set could be eliminated. The result was the RISC (reduced instruction set computer), an architecture that uses a smaller set of instructions. A simpler instruction set may offer the potential for higher speeds, reduced processor size, and reduced power consumption. However, a more complex set may optimize common operations, improve memory and cache efficiency, or simplify programming.\nSome instruction set designers reserve one or more opcodes for some kind of system call or software interrupt. For example, MOS Technology 6502 uses 00H, Zilog Z80 uses the eight codes C7,CF,D7,DF,E7,EF,F7,FFH while Motorola 68000 use codes in the range 4E40H-4E4FH.\nFast virtual machines are much easier to implement if an instruction set meets the Popek and Goldberg virtualization requirements.\nThe NOP slide used in immunity-aware programming is much easier to implement if the \"unprogrammed\" state of the memory is interpreted as a NOP.\nOn systems with multiple processors, non-blocking synchronization algorithms are much easier to implement if the instruction set includes support for something such as \"fetch-and-add\", \"load-link/store-conditional\" (LL/SC), or \"atomic compare-and-swap\".\nInstruction set implementation.\nA given instruction set can be implemented in a variety of ways. All ways of implementing a particular instruction set provide the same programming model, and all implementations of that instruction set are able to run the same executables. The various ways of implementing an instruction set give different tradeoffs between cost, performance, power consumption, size, etc.\nWhen designing the microarchitecture of a processor, engineers use blocks of \"hard-wired\" electronic circuitry (often designed separately) such as adders, multiplexers, counters, registers, ALUs, etc. Some kind of register transfer language is then often used to describe the decoding and sequencing of each instruction of an ISA using this physical microarchitecture.\nThere are two basic ways to build a control unit to implement this description (although many designs use middle ways or compromises):\nSome microcoded CPU designs with a writable control store use it to allow the instruction set to be changed (for example, the Rekursiv processor and the Imsys Cjip).\nCPUs designed for reconfigurable computing may use field-programmable gate arrays (FPGAs).\nAn ISA can also be emulated in software by an interpreter. Naturally, due to the interpretation overhead, this is slower than directly running programs on the emulated hardware, unless the hardware running the emulator is an order of magnitude faster. Today, it is common practice for vendors of new ISAs or microarchitectures to make software emulators available to software developers before the hardware implementation is ready.\nOften the details of the implementation have a strong influence on the particular instructions selected for the instruction set. For example, many implementations of the instruction pipeline only allow a single memory load or memory store per instruction, leading to a load\u2013store architecture (RISC). For another example, some early ways of implementing the instruction pipeline led to a delay slot.\nThe demands of high-speed digital signal processing have pushed in the opposite direction\u2014forcing instructions to be implemented in a particular way. For example, to perform digital filters fast enough, the MAC instruction in a typical digital signal processor (DSP) must use a kind of Harvard architecture that can fetch an instruction and two data words simultaneously, and it requires a single-cycle multiply\u2013accumulate multiplier.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47774", "revid": "47161853", "url": "https://en.wikipedia.org/wiki?curid=47774", "title": "Maclisp", "text": "Dialect of Lisp programming language\nMaclisp (or MACLISP, sometimes styled MacLisp or MacLISP) is a programming language, a dialect of the language Lisp. It originated at the Massachusetts Institute of Technology's (MIT) Project MAC (from which it derived its prefix) in the late 1960s and was based on Lisp 1.5. Richard Greenblatt was the main developer of the original codebase for the PDP-6; Jon L. White was responsible for its later maintenance and development. The name \"Maclisp\" began being used in the early 1970s to distinguish it from other forks of PDP-6 Lisp, notably BBN Lisp.\nHistory.\nMaclisp is a descendant of Lisp 1.5. Maclisp departs from Lisp 1.5 by using a \"value cell\" to access and store the dynamic values of variables; Lisp 1.5 used a linear search of an association list to determine a variable's value. The Maclisp variable evaluation is faster but has different variable semantics. Maclisp also employed reader macros to make more readable \"input\" and \"output\", termed input/output (I/O). Instead of entering codice_1, one could enter codice_2 to get the same s-expression. Although both implementations put functions on the property list, Maclisp uses different syntax to define functions. Maclisp also has a load-on-demand feature.\nMaclisp began on Digital Equipment Corporation PDP-6 and PDP-10 computers running the Incompatible Timesharing System (ITS); later it was ported to all other PDP-10 operating systems, for example, \"Timesharing / Total Operating System\", TOPS-10 and TOPS-20. The original implementation was in assembly language, but a later implementation on Multics used PL/I. Maclisp developed considerably in its lifetime. Major features were added which in other language systems would typically correspond to major release numbers.\nMaclisp was used to implement the Macsyma computer algebra system (CAS) or symbolic algebra program. Macsyma's development also drove several features in Maclisp. The SHRDLU blocks-world program was written in Maclisp, and so the language was in widespread use in the artificial intelligence (AI) research community through the early 1980s. It was also used to implement other programming languages, such as Planner and Scheme. Multics Maclisp was used to implement the first Lisp-based Emacs.\nMaclisp was an influential Lisp implementation, but is no longer maintained actively. It now runs on PDP-10 emulators and can be used for experimenting with early AI programs.\nCharacteristics.\nMaclisp began with a small, fixed number of data types: cons cell, atom (later termed \"symbol\"), integer, and floating-point number. Later additions included: arrays, which were never first-class data types; arbitrary-precision integers (bignums); strings; and tuples. All objects (except inums) were implemented as pointers, and their data type was determined by the block of memory into which it pointed, with a special case for small numbers (inums).\nPrograms could be \"interpreted\" or \"compiled\". Compiled behavior was the same as interpreted except that local variables were lexical by default in compiled code, unless declared SPECIAL, and no error checking was done for inline operations such as CAR and CDR. The Ncomplr compiler (mid-1970s) introduced fast numeric support to Lisp languages, generating machine code (instructions) for arithmetic rather than calling interpretive routines which dispatched on data type. This made Lisp arithmetic comparable in speed to Fortran for scalar operations (though Fortran array and loop implementation remained much faster).\nThe original version was limited by the 18-bit word memory address of the PDP-10, and considerable effort was expended in keeping the implementation lean and simple. Multics Maclisp had a far larger address space, but was costly to use. When the memory and processing power of the PDP-10 were exceeded, the Lisp Machine was invented: Lisp Machine Lisp is the direct descendant of Maclisp. Several other Lisp dialects were also in use, and the need to unify the community resulted in the modern Common Lisp language.\nName.\nMaclisp was named for Project MAC, and is unrelated to Apple's Macintosh (Mac) computer, which it predates by decades or to John McCarthy. The various Lisp systems for the Macintosh have no particular similarity to Maclisp.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47775", "revid": "42002101", "url": "https://en.wikipedia.org/wiki?curid=47775", "title": "Lisp Machine Lisp", "text": "Lisp Machine Lisp is a programming language, a dialect of the language Lisp. A direct descendant of Maclisp, it was initially developed in the mid to late 1970s as the system programming language for the Massachusetts Institute of Technology (MIT) Lisp machines. Lisp Machine Lisp was also the Lisp dialect with the most influence on the design of Common Lisp.\nLisp Machine Lisp branched into three dialects. Symbolics named their variant ZetaLisp. Lisp Machines, Inc. and later Texas Instruments (with the TI Explorer) would share a common code base, but their dialect of Lisp Machine Lisp would differ from the version maintained at the MIT AI Lab by Richard Stallman and others.\nManual.\nThe Lisp Machine Manual describes the Lisp Machine Lisp language in detail. The manual was popularly termed the \"Chine Nual\", because the full title was printed across the front and back covers such that only those letters appeared on the front. This name is sometimes further abbreviated by blending the two words into \"Chinual\".\nTraits.\nLisp Machine Lisp features include:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47778", "revid": "20585603", "url": "https://en.wikipedia.org/wiki?curid=47778", "title": "Maskun", "text": "Maskun may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "47779", "revid": "49402000", "url": "https://en.wikipedia.org/wiki?curid=47779", "title": "Pohnpei", "text": "Island in Micronesia\nPohnpei (formerly known as Ponape or Ascension, from Pohnpeian: \"upon (\"pohn\") a stone altar (\"pei\")\") is an island of the Senyavin Islands which are part of the larger Caroline Islands group. It belongs to Pohnpei State, one of the four states in the Federated States of Micronesia (FSM). Major population centers on Pohnpei include Palikir, the FSM's capital, and Kolonia, the capital of Pohnpei State. Pohnpei is the largest island in the FSM, with an area of , and a highest point of , the most populous with 36,832 people, and the most developed single island in the FSM.\nPohnpei is home to the megaliths and ruined city of Nan Madol, built of artificial islands off the island's eastern shore beginning in the 8th or 9th century. An important archaeological site, it was declared a national historic site in 1985.\nPohnpei contains a wealth of biodiversity. It is one of the wettest places on Earth with annual recorded rainfall exceeding each year in certain mountainous locations. It is home to the ka tree (\"Terminalia carolinensis\") found only in Pohnpei and Kosrae.\nName.\nThe name \"Pohnpei\" comes from the Pohnpeian language, literally meaning \"upon a stone altar\". It derives from a Proto-Chuukic-Pohnpeic phrase \"*fawo ni pei\" of the same meaning. Cognates in other Micronesian languages include Mokilese \"Pohnpei\" and Chuukese \"F\u00f3\u00f3nupi\".\nHistory.\nThe natives of Pohnpei, especially the 'older' generations, often refer to events in their past as having occurred, e.g., in \"German times\" or \"before the Spaniards,\" which identifies the historical periods:\nPre-colonial history.\nThe earliest settlers were probably Lapita culture people from the Southeast Solomon Islands or the Vanuatu archipelago. Pre-colonial history is divided into three eras: \"Mwehin Kawa\" or \"Mwehin Aramas\" (Period of Building, or Period of Peopling, before c.\u20091100); \"Mwehin Sau Deleur\" (Period of the Lord of Deleur, c.\u20091100 to c.\u20091628); and \"Mwehin Nahnmwarki\" (Period of the Nahnmwarki, c.\u20091628 to c.\u20091885). Pohnpeian legend recounts that the Saudeleur rulers, the first to bring government to Pohnpei, were of foreign origin. The Saudeleur centralized form of absolute rule is characterized in Pohnpeian legend as becoming increasingly oppressive over several generations. Arbitrary and onerous demands, as well as a reputation for offending Pohnpeian deities, sowed resentment among Pohnpeians. The Saudeleur Dynasty ended with the invasion of Isokelekel, another semi-mythical foreigner, who replaced the Saudeleur rule with the more decentralized \"nahnmwarki\" system in existence today.\nPohnpeian historic society was highly structured into five tribes, various clans and sub-clans; each tribe headed by two principal chiefs. The tribes were organized on a feudal basis. In theory, \"all land belonged to the chiefs, who received regular tribute and whose rule was absolute.\" Punishments administered by chiefs included death and banishment. Tribal wars included looting, destruction of houses and canoes and killing of prisoners. Pre-Spanish population estimates are deemed unreliable.\nEarliest European contacts.\nPohnpei's first European visitor was Spanish navigator \u00c1lvaro de Saavedra Cer\u00f3n on 14 September 1529 shortly before his death, when trying to find the way back to New Spain. He charted it as \"San Bartolom\u00e9\" and called this one and the surrounding islands as \"Los Pintados\" (literally, \"the painted ones\" in Spanish) because the natives were frequently tattooed. It was later visited by the navigator Pedro Fernandes de Queir\u00f3s, commanding the Spanish ship \"San Jeronimo\". on 23 December 1595; his description is brief, he made no attempt to land.\n19th-century visitors.\nThere is good documentation about Australian sailor John Henry Rowe, who arrived in his barque \"John Bull\" on 10 September 1825, though he did not land as his vessel was chased off by native canoes. The first lengthy description of the island and its inhabitants is presented by the Russian explorer Fyodor Litke, whose ship \"Senyavin\" gave the island group of Pohnpei, Ant and Pakin its name. From 14 to 19 January 1828, his boats attempted to land but could not due to the hostility shown by the islanders, but natives then came aboard his ship, \"some trading occurred, a short vocabulary was compiled, and a map made.\" F.H. von Kittlitz, a member of the Litke expedition made a further descriptive account, including the offshore ruins of Nan Madol, and the two reports together provided the first real knowledge of Pohnpei. It is not clear who the next visitors were; however, when Capt. J.H. Eagleston of the barque \"Peru\" sighted the island on 3 January 1832, it was already on his charts as \"Ascension Island.\" Riesenberg writes that it is uncertain who first called it Ascension Island, but the name became established until the Spanish period.\nMiscreants and missionaries.\nFrom this time onward, whaling and trading vessels came in increasing numbers. Very soon a \"large colony of beachcombers, escaped convicts, and ship's deserters became established ashore,\" identified as \"chiefly bad characters,\" according to the log of the Swedish frigate \"Eugenie\". The first missionary to arrive was Father Louis D\u00e9sir\u00e9 Maigret, a Roman Catholic priest. He had sailed from Honolulu on the schooner \"Notre Dame de Paix\" and began his efforts in December 1837, but he departed on 29 July 1838 for Valpara\u00edso after seven unsuccessful months. In his company were \"several Mangarevans and Tahitians,\" some of whom remained on Pohnpei and left descendants. Ten years later Maigret returned to the Hawaiian Kingdom as Bishop of Honolulu. A group of Protestant missionaries from New England established themselves permanently on Pohnpei in 1852. Their letters and journals contain a wealth of information about the island and are preserved at Harvard University.\nA drastic population decline occurred after 1854, due to a smallpox epidemic.\nDuring the American Civil War, to counteract the Union Navy blockade of their ports, Confederate States Navy ships hunted Yankee merchant shipping. On 1 April 1865, the \"CSS Shenandoah\" surprised four United States whalers at Ascension Island (Pohnpei) and destroyed them all. The local king, Nananierikie, was delighted to receive much of the spoils from this action.\nSpanish rule.\nBy 1886 the Spaniards claimed the Caroline Islands which were part of the Manila-based Spanish East Indies and began to exert political authority. They founded the city \"Santiago de la Ascensi\u00f3n\" in what today is \"Kolonia\" (from Spanish \"colonia\" or colony). The Spanish built several government buildings, a fort, a church and a school. Spanish Capuchin friars were also sent from Manila to Pohnpei to preach the Catholic faith. After the 1898 Spanish\u2013American War, the German Empire purchased the Caroline island group from Spain in 1899 together with the Marianas (except Guam) and four years later the Marshall Islands for 17 million goldmark.\nGerman rule and land reform.\nDuring the German administration a fundamental change in land ownership was implemented on Pohnpei and throughout the Carolines. Beginning in 1907, the feudal system, in which all land is held in fief, was gradually replaced with the issuance of individual deeds to land. The chief's economic advantages were thus reduced, and only force of tradition granted a first harvest tribute to chiefs.\nWith land holding, taxes came due and new owners, in lieu of payment, were obliged to work 15 days per year on public projects, such as wharf construction, road building, etc. One such work for taxes engagement sparked the Sokehs rebellion. It began as an insubordination event during road construction on Sokehs Island, then escalated into the murder of nine people, the subsequent apprehension and trial of 36 Sokehs rebels, the execution of 15 insurgents, and banishment for others to Babelthuap in the German Palau Islands.\nThe German census of 1911\u201312 shows 3,190 Pohnpeians, 585 Central Carolinians and 279 Melanesians. Many of the outer islands were resettled (mainly on Sokehs Island) as a consequence of destructive typhoons in their home islands.\nA special census conducted in late 1947 shows a total population of 5,628, of which 4,451 were Pohnpeians, and 1,177 were natives of other Pacific islands. By 1963, the population had grown to nearly 10,000.\nJapanese rule.\nWith the Treaty of Versailles, Japan as mandatory power assumed control of all German colonial possessions north of the equator, having occupied Pohnpei along with the rest of the Carolines, the Marshalls, the Marianas (except for American-owned Guam) and Kiautschou Bay during World War I. In subsequent years and during World War II the Japanese garrison strength was composed of about 2,000 men of the IJN under Captain Jun Naito and 5,984 IJA men under Lieutenant General Masao Watanabe. However, Pohnpei was bypassed by the United States Navy during the island-hopping amphibious campaigns of 1943\u20131945.\nThe island was shelled on several occasions, including by the battleships USS \"Massachusetts\", USS \"Alabama\", and , as well as air attacks launched from USS \"Cowpens\". Japan surrendered in 1945, and the Pohnpei was turned over to the United States without a battle. After the war, Japanese nationals were repatriated to Japan by the US Navy. The people on Pohnpei would be in a United Nations trusteeship to determine their own fate.\nUnited States administration, under United Nations oversight.\nThe Federated States of Micronesia achieved independence in 1986 after being administered by the United States under UN auspices since 1947 as part of the Trust Territory of the Pacific Islands. Pohnpei is an island part of Federated States of Micronesia, which is recognized by the United Nations. It has maintained a defense and aid agreement with the United States after becoming independent.\nGeography.\nThe highest point of the island is Mount Nanlaud at 772 or 782 metres. Pohnpei is home to several dozen bird species including four endemic species, the Pohnpei lorikeet, the Pohnpei fantail, the Pohnpei flycatcher and the long-billed white-eye. A fifth endemic, the Pohnpei starling, is thought to have recently gone extinct.\nThe only land reptiles are a few species of lizard. Originally the only mammals were bats. Pigs, rats and dogs were introduced; pigs have become feral. The lagoons are rich in fish, molluscs, turtles and other marine fauna.\nClimate.\nPohnpei belongs to the tropical rainforest climate zone (K\u00f6ppen: \"Af\"). It is one of the wettest places on Earth with an average annual recorded rainfall of in towns along the coast and about each year in certain mountainous locations.\nDemographics.\nThe population of the state in 2010 was approximately 36,196. While the majority of the population consider themselves ethnic Pohnpeians, Pohnpei is more ethnically diverse than any other island in the FSM. This is largely due to more than a century of foreign colonial occupation, bringing in Spanish, German, Japanese, Chamorro, Filipino, US, Australian, other western Europeans, and it being home to the capital of the national government, which employs hundreds of people from the other three FSM States (Yap, Chuuk, Kosrae) having distinct ethnic and cultural origins. The indigenous makeup also includes the multiple regional ethnicities of the outer islands within Pohnpei State, resulting in a mix of Australasian Pacific Islanders and hence making Pohnpei Island the FSM's melting pot.\nLanguages.\nThe Pohnpeian language (formerly called \"Ponapean\") and its dialects are the indigenous languages of Pohnpei. The Federated States of Micronesia government also uses Pohnpeian as a regional language.\nEnglish and Spanish are spoken in the island.\nAdministrative divisions.\nThe municipalities on the island of Pohnpei are:\nTransportation.\nPohnpei International Airport (IATA code PNI) is located near Kolonia, on a small island named Deketik off the northern coast of the main island.\nSport.\nThe FSM is part of the international Olympic movement, originally the work of James Tobin, who now sits on the IOC Executive Board, sending teams to the summer games beginning in 2000 with the Sydney games and continuing every four years to the present with athletes participating in track and field, swimming and weightlifting. The most notable Pohnpeian athlete is marathon runner Elias Rodriguez who ran for the FSM at the Sydney Olympics. Rodriguez finished last in the marathon but was cheered on by tens of thousands of spectators and watched by millions of television viewers as he entered the Olympic stadium for a final lap immediately prior to the closing ceremony which was delayed to allow his finish.\nPohnpei's state football team were coached by the world's youngest national football coach, the Englishman Paul Watson, who led the team on a tour of nearby Guam, winning one match against a local team. The annual Micronesian Futsal Cup has been established on the island, also the work of Watson.\nPohnpei in fiction.\nPohnpei (as Ponape) plays a role in several stories of the Cthulhu Mythos by H. P. Lovecraft and others. Its role in \"Out of the Aeons\", by Lovecraft and Hazel Heald, was inspired by the ruins of Nan Madol (see above), which had already been used as the setting for a lost race story by Abraham Merritt, \"The Moon Pool\", in which the islands are called Nan-Matal.\nPohnpei is a central location in \"South Sea Adventure\" (1952), the second of Willard Price's Young Adult Adventure Series books featuring Hal and Roger Hunt.\nPohnpei, or \"Ponape\" as it is spelled, is stated as the home island of \"Mike\" on the popular blog \"Dunce Upon A Time\", authored by BC Woods.\nEducation.\nPohnpei State Department of Education operates public schools.\nPublic high schools:\nPrivate schools:\nPohnpei Catholic School\nPost secondary education:\nLidorkini Museum was located in Kolonia, until its closure in 2012.\nNotable residents.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nExplanatory notes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47780", "revid": "20585603", "url": "https://en.wikipedia.org/wiki?curid=47780", "title": "Ponape", "text": "Ponape may refer to:\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "47781", "revid": "197953", "url": "https://en.wikipedia.org/wiki?curid=47781", "title": "Cherilyn LaPierre", "text": ""}
{"id": "47782", "revid": "50748674", "url": "https://en.wikipedia.org/wiki?curid=47782", "title": "Bia\u0142ystok", "text": "Bia\u0142ystok is the largest city in northeastern Poland and the capital of the Podlaskie Voivodeship. It is the tenth-largest city in Poland, second in terms of population density, and thirteenth in area.\nBia\u0142ystok is located in the Bia\u0142ystok Uplands of the Podlachian Plain on the banks of the Bia\u0142a River, (124\u00a0mi) northeast of Warsaw. It has historically attracted migrants from elsewhere in Poland and beyond, particularly from Central and Eastern Europe. This is facilitated by the nearby border with Belarus also being the eastern border of the European Union, as well as the Schengen Area. The city and its adjacent municipalities constitute Metropolitan Bia\u0142ystok. The city has a , characterized by warm summers and long frosty winters. Forests are an important part of Bia\u0142ystok's character and occupy around (18% of the administrative area of the city) which places it as the fifth-most forested city in Poland.\nThe first settlers arrived in the 14th century. The town grew and received its municipal charter in 1692. Bia\u0142ystok has traditionally been one of the leading centers of academic, cultural, and artistic life in Podlachia, and the most important economic center in northeastern Poland. Bia\u0142ystok was once an important center for light industry, which was the reason for the substantial growth of the city's population. The city continues to reshape itself into a modern middle-sized city. Bia\u0142ystok, in 2010, was on the short-list, but ultimately lost the competition, to become a finalist for European Capital of Culture in 2016.\nEtymology.\nAlthough nowadays \"stok\" is translated as \"slope\", the initial name of the settlement came from the river flowing through it. In old Polish, \"bia\u0142y stok\" was white river (\"bia\u0142y\" - white, \"stok\" - stream; river that \"slides\" down the slope). So inconspicuous today, the Bia\u0142a River (usually called Bia\u0142ka), flowing through the city center, gave it its name.\nDue to changing borders and demographics over the centuries, the city has been known as (\"Byelastok\"?, \"Bie\u0142astok\"? ), (\"Byalistok\", \"Bjalistok\"), , and (\"Belostok\", \"Byelostok\").\nHistory.\nEarly history.\nArchaeological discoveries show that the first settlements in the area of present-day Bia\u0142ystok occurred during the Stone Age. Tombs of ancient settlers can be found in the district of Dojlidy. In the early Iron Age, people settled in the area producing kurgans, the tombs of the chiefs in the area located in the current village of Rosto\u0142ty. Since then, the Bia\u0142ystok area has been at the crossroads of cultures. Trade routes linking the Baltic to the Black Sea favored the development of settlements with Yotvingia-Ruthenian-Polish cultural characteristics.\nSurviving documents attest that around 1437 a representative of the Raczk\u00f3w family, Jakub Tabutowicz of the coat of arms \u0141ab\u0119d\u017a, received from Michael \u017dygimantaitis, son of the Grand Duke of Lithuania Sigismund K\u0119stutaitis, a wilderness area along the river Bia\u0142a that marked the beginning of Bia\u0142ystok as a settlement. Thereafter, Bia\u0142ystok was part of Lithuania for 132 years.\nPolish\u2013Lithuanian Commonwealth.\nThe Union of Lublin in 1569 transferred the city to Poland, but it remained very close to its border with the Grand Duchy of Lithuania until the last partition of the Polish\u2013Lithuanian Commonwealth in 1795. Bia\u0142ystok was administratively part of the Podlaskie Voivodeship, after 1569 also part of the Lesser Poland Province of the Kingdom of Poland.\nFrom 1547, the settlement was owned by the Wiesio\u0142owski family, which founded the first school. The first brick church and a castle were built between 1617 and 1826. The two-floor castle, designed on a rectangular plan in the Gothic-Renaissance style, was the work of Job Bretfus. Extension of the castle was continued by Krzysztof Wiesio\u0142owski, starost of Tykocin, Grand Marshal of Lithuania since 1635, and husband of Aleksandra Marianna Sobieska. In 1637 he died childless, and as a result, Bia\u0142ystok came under the management of his widow. After her death in 1645 the Wiesio\u0142owski estate, including Bia\u0142ystok, passed to the Crown to cover the costs of maintaining Tykocin Castle. In the years 1645\u20131659 Bia\u0142ystok was managed by the starosts of Tykocin.\nIn 1661 it was given to Stefan Czarniecki as a reward for his service in the victory over the Swedes during the Deluge. Four years later, it was given as a dowry of his daughter Aleksandra, who married Marshal of the Crown Court Jan Klemens Branicki, thus passing into the hands of the Branicki family. In 1692, Stefan Miko\u0142aj Branicki, the son of Jan Klemens Branicki, obtained city rights for Bia\u0142ystok from King John III Sobieski. He constructed the Branicki Palace on the foundations of the castle of the Wiesio\u0142owski family. In the first half of the eighteenth century the ownership of the city was inherited by Field Crown Hetman Jan Klemens Branicki. It was he who transformed the palace built by his father into a magnificent residence of a great noble, which was frequently visited by Polish kings and poets.\nIn 1745 the first military technical school in Poland was founded in Bia\u0142ystok, and in 1748, one of the oldest theaters in Poland, the \"Komedialnia\", was founded in the city. New schools were established, including a ballet school in connection with the foundation of the theater. In 1749, King Augustus III of Poland extended the city limits. In 1770, under the auspices of Izabella Poniatowska, a midwifery school was founded, based on which the Institute of Obstetrics was established in 1805. Bia\u0142ystok was a regional brewing center with 33 breweries as of 1771, with the Podlachian Beer now listed as a protected traditional beverage by the Ministry of Agriculture and Rural Development of Poland.\nPartition era and industrial growth.\nThe end of the eighteenth century saw the division of the Polish\u2013Lithuanian Commonwealth, in three partitions, among Poland's neighboring states. The Kingdom of Prussia subjugated Bia\u0142ystok and the surrounding region during the 1795 third partition. That year, the city became the capital of the New East Prussia province.\nNapoleon Bonaparte's victory in the War of the Fourth Coalition freed the territory but as a result in the Treaties of Tilsit in 1807 the area was transferred to the Russian Empire (rather than Congress Poland), which organized the region into the Belostok Oblast, with the city as the regional center. Schooling and higher learning in Bia\u0142ystok, which was intensively developed in the 18th century, was stopped as a result of partitions.\nBia\u0142ystok received city rights the latest from all of Podlasie's cities, but at the end of the 19th century it outgrown all the surrounding cities. The rapid development in the 19th century is related to two historical events: the creation of a customs border between the Russian Empire and the Congress Kingdom of Poland, and the opening in 1862 of the Warsaw Saint Petersburg railway line, connecting Bia\u0142ystok with Warsaw, Grodno, Vilnius and Saint Petersburg. Very convenient communication conditions influenced the development and concentration of Bia\u0142ystok's production plants at that time. Along with the administrative function, Bia\u0142ystok received many economic institutions. In the second half of the 19th century, Bia\u0142ystok grew into a significant center of the textile industry, the largest after \u0141\u00f3d\u017a in then-partitioned Poland. Bia\u0142ystok was the largest industrial center between Warsaw and \u0141\u00f3d\u017a in the west, Saint Petersburg in the north and Moscow in the east, and was nicknamed \"Manchester of the North\". After the failed November and January uprisings, Russification policies and anti-Polish repressions intensified, and after 1870 a ban on the use of Polish in public places was introduced. In 1912, a Tsarist prison was built, which also served as a transit prison for Poles deported to Siberia.\nAt the end of the nineteenth century, as a result of the influx due to Russian discriminatory regulations, the majority of the city's population was Jewish. According to Russian census of 1897, out of the total population of 66,000, Jews constituted 41,900 (so around 63% percent). This heritage can be seen on the Jewish Heritage Trail in Bia\u0142ystok. The Bia\u0142ystok pogrom occurred between 14 and 16 June 1906 with some 81 to 88 Jews killed by the Russians, and about 80 wounded.\nThe first anarchist groups to attract a significant following of Russian workers or peasants were the anarcho-communist Chernoe-Znamia groups, founded in Bia\u0142ystok in 1903.\nDuring World War I the Bialystok-Grodno District was the administrative division of German-controlled territory of Ober-Ost. It comprised the city, as the capital, and the surrounding Podlaskie region, roughly corresponding to the territory of the earlier Belostok Oblast.\nSecond Polish Republic.\nAt the end of World War I the city became part of the newly independent Second Polish Republic, as the capital of the Bia\u0142ystok Voivodeship. Bia\u0142ystok and the surroundings areas regained independence only on 19 February 1919, three months after the rest of Poland, due to delay in the departure of the German Army from the city. During the 1919\u20131920 Polish\u2013Soviet War, possession of the city by the Red Army and the Provisional Polish Revolutionary Committee occurred during the lead up to the Battle of Warsaw. During the resultant counteroffensive, the city returned to Polish control after the Battle of Bia\u0142ystok.\nAfter the wars and the reestablishment of independent Poland, Polish education in Bia\u0142ystok was restored and the textile industry was revived. A municipal public library was established, sports clubs were founded, including Jagiellonia Bia\u0142ystok, and in the 1930s a drama theater was built.\nWorld War II.\nWith the beginning of World War II, Poland was invaded by Nazi Germany and the Soviet Union. City president Seweryn Nowakowski established the Citizens' Guard. Due to the need to evacuate the police forces, the Guard took over its duties after September 11. In addition to the Police, a group of officials left along with selected archives. However, most of the residents of Bia\u0142ystok remained in the city. Initially Bia\u0142ystok was briefly occupied by Germany, and the German \"Einsatzgruppe IV\" entered the city on 20\u201321 September 1939 to commit crimes against the population. After occupying Bia\u0142ystok, the Germans established the Military City Command, which ordered the surrender of weapons and ammunition and the disbandment of the Citizens' Guard. On September 20, a brutal murder was committed in the courtyard of Primary School No. 1, where a transit camp for prisoners had been set up earlier. Wehrmacht soldiers murdered 8 people \"for disobedience\". The next day, German troops began to withdraw from the city, where they were replaced by Red Army units, as a result of the Molotov\u2013Ribbentrop Pact.\nUnder Soviet occupation, it was incorporated into the Byelorussian SSR from 1939 to 1941 as the capital of Belastok Region. Polish people were subject to deportations deep into the USSR (Siberia, Kazakhstan, Far North). Pre-war mayor Seweryn Nowakowski was arrested by the NKVD in October 1939 and probably also deported to the USSR, however his fate remains unknown. The NKVD took over the local prison. The Polish resistance movement was active in the city, which was the seat of one of the six main commands of the Union of Armed Struggle in occupied Poland (alongside Warsaw, Krak\u00f3w, Pozna\u0144, Toru\u0144 and Lw\u00f3w). Bia\u0142ystok native and future President of Poland in exile Ryszard Kaczorowski was a member of the local Polish resistance and was arrested in the city by the NKVD in 1940. Initially the Soviets sentenced him to death, but eventually he was sentenced to 10 years in forced labor camps and deported to Kolyma, from where he was released in 1942, when he joined the Anders' Army.\nIn the course of the German invasion of the Soviet Union in 1941, Bia\u0142ystok was occupied by the German Army on 27 June 1941, during the Battle of Bia\u0142ystok\u2013Minsk, and the city became the capital of Bezirk Bia\u0142ystok, a separate region in German occupied Poland, until 1944. Between July and June the 1941 Bia\u0142ystok massacres took place. The Great Synagogue was burnt down by Germans on 27 June 1941, with an estimated number of 2,000 Jews inside. From the very beginning, the Nazis pursued a ruthless policy of pillage and removal of the non-German population. The Germans operated a Nazi prison in the city, and a forced labour camp for Jewish men. Since 1943, the \"Sicherheitspolizei\" carried out deportations of Poles including teenage boys from the local prison to the Stutthof concentration camp. The 56,000 Jewish residents of the town were confined in a ghetto. On 15 August 1943, the Bia\u0142ystok Ghetto Uprising began, and several hundred Polish Jews and members of the Anti-Fascist Military Organisation () started an armed struggle against the German troops who were carrying out the planned liquidation of the ghetto with deportations to the Treblinka extermination camp. Ultimately the ghetto was liquidated, and the vast majority of its remaining 40,000 occupants including men, woman and children, were murdered by the Nazis and their collaborators, primarily at the Treblinka death camp.\nThe city fell under the control of the Red Army on 27 July 1944. The Soviets carried out mass arrests of Polish resistance members in the city and region, and imprisoned them in Bia\u0142ystok. On 20 September 1944 the city was transferred back to Poland, although with a Soviet-installed communist regime, which stayed in power until the Fall of Communism in the 1980s, and the Soviet NKVD and SMERSH continued the persecution of the Polish resistance in the following months. From November 1944 to January 1945, the Russians deported nearly 5,000 Poles from the local prison to the Soviet Union. Later on, the Soviet-appointed communists held political prisoners and other members of the Polish resistance in the local prison, and until 1956, they also carried out burials of executed Polish resistance members there.\nPost-war period.\nAfter the war, the city became capital of the initial Bia\u0142ystok Voivodeship of the People's Republic of Poland. After the 1975 administrative reform, the city was the capital of the now smaller Bia\u0142ystok Voivodeship. Since 1999 it has been the capital of the Podlaskie Voivodeship, Republic of Poland.\nFrom the European Regional Development Fund, contracted within the framework of the Integrated Regional Development Operational Programme (ZPORR), Bia\u0142ystok received approximately PLN 43 million for a project to improve the quality of the transport system. The implementation of Part I of the project allowed for the purchase of 43 new buses for public transport in 2005\u20132006, and new streets were built in Bacieczki district. The Bia\u0142ystok Waterworks implemented a project to improve water quality. Cycle paths in Bia\u0142ystok were expanded and a path to Supra\u015bl was built.\nGeography.\nBia\u0142ystok is situated in the Bia\u0142ystok Uplands () of the Podlaskie Plain (), part of what is known collectively as the \"Green Lungs of Poland\". It is situated by road northeast of Warsaw. It is the biggest Polish city close to Belarus and Lithuania. The Bia\u0142a River, a left tributary of the Supra\u015bl River, passes through the city. The landscape of the Bia\u0142ystok Upland is diverse, with high moraine hills and kame in excess of above sea level. Vast areas of outwash, a glacial plain formed of sediments deposited by meltwater at the terminus of a glacier, are covered by forests.\nThe highest point of the city lies at a height of on the Pietrasze Forest. The lowest point lies at a height of on the river valley of the Bia\u0142a. A characteristic element of the relief of the city area are clear depressions in the surface of the moraine plateau, which are used by the rivers Bia\u0142a, Horodnianka, and Czaplinianka.\nForests are an important part of the city character, they currently occupy approximately (18% of the administrative area of the city) which places it as the fifth most \"wooded\" city in Poland; behind Katowice (38%), Bydgoszcz (30%), Toru\u0144 (22.9%) and Gda\u0144sk (17.6%).\nThere are a total of 9 parks in the city (on municipal plots), of which 5 are historic parks with a total area of about 59.06 ha, entered into the municipal register of monuments, and 4 are city parks with an area of about 21.68 ha.\nPart of Knyszyn Forest is preserved within the city limits by two nature reserves\u2014a total area of . The Zwierzyniecki Forest Nature Reserve, which is contained within the city limits, is a fragment, , of the riparian forest with a dominant assemblage of oak and hornbeam. The Antoniuk Nature Reserve () is a park in the city that preserves the natural state of a forest fragment characteristic of the Bia\u0142ystok Upland, with a dominant mixed forest of hazel and spruce.\nThe of forests lying in the vicinity of the Dojlidy Ponds are administered by the Bia\u0142ystok Central Sports and Recreation Center ( \u2013 BOSiR). The Dojlidy Ponds recreation area includes a public beach, walking trails, birdwatching and fishing.\nClimate.\nThe city has a warm-summer or hemiboreal climate (\"Dfb\") according to the K\u00f6ppen climate classification system under the isotherm for the average temperature of the coldest month, or an oceanic climate (\"Cfb\") if the isotherm is used. The city would have been classified as being in the \"Dfb\" zone regardless of the accepted isotherm for climatological normals as recent as 1981\u20132010, but as a consequence of climate change, the winters have warmed up so that the climate in the city may be classified as oceanic. Bia\u0142ystok is one of the coldest cities in Poland by annual temperature and one with the climate having the most continental characteristics, as is the case for much of north-eastern Poland, with the mean yearly temperature of and the length of the growing season amounting to 205 days, shorter than elsewhere in Poland.\nWhile winters are rather mild compared to other cities on the similar latitude, such as Samara, Barnaul, or Edmonton, they are colder than in Western Europe (in cities like Bremen and Dublin). Winters usually have little sunshine, with weather patterns changing from those influenced by the low-pressure systems generated by the Icelandic Low (when the weather is often cloudy, cool, damp, rainy and/or snowy) to the occasional intrusions of cold air masses from Siberia or the Arctic (Siberian High), which, due to the city's northeasterly location, are more frequent than in other parts of Poland. Winters thus tend to be several degrees colder than elsewhere in Poland. Freezing conditions below are possible in winter but are rare. Snow cover is present on the ground for more than half of winter. Summers tend to be warm, sunny and pleasant and are occasionally hot, but they are still a little cooler than in most of Poland. More rain falls in summer months than in any other period of the year.\nThe centre of Bia\u0142ystok, as most urban areas, experiences the urban heat island effect, therefore for most of the time, the city is warmer than the surrounding countryside. The temperatures in the city centre are, on average, higher than in the surrounding villages, with greater differences at night and during the warmer half of the year, particularly in spring.\nUrban layout.\nBia\u0142ystok is roughly circular, centered around the Central market square and Branicki Palace. The decisive influence on the development of the city was exerted by natural and human factors - the course of roads, the Bia\u0142a and its tributaries and the layout of railway lines. The choice of land for the construction of the factory was also determined by the price of the plot. The layout of the city, in accordance with the 18th century palace and park layout, emphasizing the magnificence of the residence, hindered the development of the city in width. Two railway lines: Bia\u0142ystok-Suwa\u0142ki and Bia\u0142ystok-S\u0142onim, separated its northern and eastern parts from the rest of the city: Dziesi\u0119ciny, Wygoda, Zacisze, Pieczurki. Originally, the city's territory was about 50 hectares. In its early days Bia\u0142ystok was located at the intersection of two local roads and had two most important monuments: a church (with the current brick church from 1626) with an accompanying market square and a Gothic castle owned by the noble Wiesio\u0142owski family, the former owners of the town. The project which was aimed at rebuilding the layout of the city was initiated by Stefan Miko\u0142aj Branicki at the end of the 17th and early 18th centuries. He established a new market () (part of the western side of Kosciuszki Square with the town hall, located on the western side of Sienkiewicza Street). The route leading towards Sura\u017c was moved to a new location (today's Suraska Street) forming straight road section ending in the southern corner of the market square and creating a new viewing corridor. This design decision made it possible to erect new buildings so that the old part of the settlement and the Jewish quarter were no longer visible. The second viewing corridor was created by shifting the existing route leading towards Choroszcz to the northern corner of the market square.\nThe communication system serving the entire city was made of streets radiating out from the central market square. An inventory plan made by Becker in 1799 was needed by the Prussian authorities in connection with the negotiations on the acquisition of Bia\u0142ystok for a royal residence. The plan is of fundamental importance as it shows the development of the city in the first period of its creation. The area of the city did not exceed 1.5 km2, and the population was approx. 3.5 thousand. The entire urban area was closed with 6 loose-fitting gates and buildings situated on regular plots. Compact buildings were found only in the market square, the frontages of which were 1- 2-storey buildings with brick front elevations. Choroska and Zamkowa Streets were built up with only brick houses. The city was dominated by the palace complex, which, together with the park, covered a substantial area. The residence palace was designed on a European scale and created new development opportunities for Bia\u0142ystok. Following the handover of the city from the Prussian Kingdom to the Russian Empire in the early 19th century, the city began growing in a very fast pace as a result of intensive industrialization, losing its original Baroque composition.\nAfter the First World War, the first attempts were made to organize the city, which had so far developed without plans - between the palace grounds and arable land. At the request of the Association of Polish Cities, in the years 1938-1939 a general urban concept of the city was created by Ignacy T\u0142oczek. The plan called for the creation of new communication routes, relieve the center, demolish the Chanajki district, create a housing estate and connect with it the unique green areas around the city with new tree plantings. The Second World War prevented the comprehensive implementation of this plan. In addition, in 1919 the city's territory was significantly expanded, incorporating the surrounding villages with plans of expanding the city.\nThe center is dominated by buildings not exceeding 25 meters in height, and the outskirts of the city are mainly occupied by low-rise single-family houses. Taller buildings dominate in some residential districts such as the districts of Piasta I and II (located to the south of the city center), Dziesi\u0119ciny I and II estates (located to the northwest of the city center) as well as Wysoki Stoczek and S\u0142oneczny Stok. Dominants in Bia\u0142ystok are located mainly in the center and they are also there located two most important city icons: the St. Roch's Church and the Bia\u0142ystok Cathedral, which are on one axis. Each of the districts also has its dominant, which is usually a Catholic or an Orthodox church. The most important space in the city is Ko\u015bciuszko Square - the main square in the shape of a triangle. The space is delimited by two axes, one is part of the axis along Lipowa Street connecting the two largest churches, and the other runs towards the west of the central district along Suraska Street and ends at M\u0142ynowa Street. An important spatial arrangement in Bia\u0142ystok is the Branicki Palace complex. The Baroque layout of the palace complex is symmetrically shaped according to one compositional axis with a coherent garden layout.\nThroughout the years it expanded to include nearby villages: In the mid-eighteenth century Bojary which was located on the right bank of the Biala River was incorporated to it. On 10 May 1919, in accordance with the decision of the Sejm, Bialostoczek, Horodniany, Zwierzyniec-Letnisko, Starosielce, S\u0142oboda (which was founded at the end of the 17th century, between the current Pogodna and \u015awierkowa Streets), Ogrodniki, Pieczurki, Wysoki Stoczek were incorporated also, as well as two mill villages Marczuk and Antoniuk. By the onset of World War II the city's territory amounted to . The reconstruction of the city following the end of World War II and establishment of the People's Republic of Poland saw further expansion: the villages Bacieczki, Bacieczki Kolonia, Korycin and part of the village Klepacze, Krupniki, Fasty, Za\u015bcianki and Zawady were incorporated into the city. The 70s saw another wave of expansion with the villages of Bagn\u00f3wka, area of Zak\u0142ady Silikatowe, areas of state forests, Dojlidy Ponds and the orthodox cemetery at Dojlidy. At the onset of the millennium, in 2002, the village Zawady was included in the city's limits and at the last enlargement, in 2006, the villages Dojlidy G\u00f3rne, Zag\u00f3rki and Kolonia Halickie were incorporated and the city reached its current territory of .\nDistricts.\nThe city of Bia\u0142ystok is divided into 29 administrative units, known in Polish as \"osiedla\". The first 27 of these were created on 25 October 2004. The 28th, Dojlidy G\u00f3rne, was created by on 23 October 2006, out of three settlements which had been incorporated into the city: Dojlidy G\u00f3rne, Kolonia Halickie, and Zag\u00f3rki. A new district called Bagn\u00f3wka was created at the beginning of 2021.\nThe center of the city, Osiedle Centrum, surrounds Lipowa Street, the main street of the city. Lipowa Street extends from Rynek Ko\u015bciuszki (the corner of Sp\u00f3\u0142dzielcza Street) to Plac Niepodleg\u0142o\u015bci im. Romana Dmowskiego (the corner of Krakowska Street). Over the centuries the name of this street has taken on a number of different names; Choroska, Nowolipie, Lipowa, J\u00f3zef Pi\u0142sudski, Joseph Stalin, Adolf Hitler and Joseph Stalin, once again, to return, after the end of World War II, to its original name \u2013 Lipowa Street.\nThe city covers of which is agricultural land, is urbanized areas, is surface waters and is wasteland. The composition of the districts vary from residential near the city center, with a combination of multi-story apartment buildings and individual houses on small parcels, to industrial and agricultural at the city edges.\nMetropolitan Bia\u0142ystok.\nMetropolitan Bia\u0142ystok was designated by the Voivodeship of the Regulation No. 52/05 of 16 May 2005 to help develop the region economically. In 2006, the metropolitan area population was 450,254 inhabitants. The municipalities adjacent to Bia\u0142ystok are slowly losing their agricultural character, becoming residential suburban neighborhoods with single-family housing and small businesses.\nDemographics.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nIn June 2020, the population of the city was 296,958. Among the cities of Poland, Bia\u0142ystok is second in terms of population density, tenth in population, and thirteenth in area. \nHistorically, Bia\u0142ystok has been a destination for internal and foreign immigration, especially from Central and Eastern Europe. In addition to the Polish minority, there was formerly a Jewish majority in Bia\u0142ystok. The Jewish share in the population of Bia\u0142ystok grew from 22.4% (761) in 1765 to 66.6% (6,000) in 1808 and 76% (47,783) in 1895. According to the Russian census of 1897, out of the total population of 66,000, Jews constituted 41,900 (around 63% percent). According to the German census of 1916, Jews comprised about 72% of the inhabitants (no less than 40,000). The demographic situation changed due to the influx of Polish repatriants, intelligentsia and civil servants, and the enlargement of the city after the World War I. According to the 1931 census, the population of Bia\u0142ystok totalled 91,101: 45.5% (41,493) Roman Catholics, 43% (39,165) Jews (by religion), and 8.2% (7,502) Eastern Orthodox believers.\nIn 1936, Bia\u0142ystok had a population of 99,722, of whom: 50.9% (50,758) were Poles, 42.6% (42,482) Jews, 2.1% (2,094) Germans and 0.4% (359) Russians; 46.6% (45,474) adhered to the Catholic religion, 43% (42,880) to Judaism, 8.2% (8,177) to Eastern Orthodoxy and 2.9% (2,892) to Evangelicalism. World War II changed all of this: in 1939, around 107,000 people lived in Bia\u0142ystok, but by 1946, the population had dropped to 56,759, with much less ethnic diversity than it had had previously, due primarily to the murder of its large Jewish population. Currently the city's population is 97% Polish, 2.5% Belarusian and 0.5% of a number of minorities including Russians, Lithuanians, and Ukrainians. Most of the modern-day population growth is based on internal migration within Poland and urbanization of surrounding areas.\nPolitics.\nCity government.\nBia\u0142ystok, like other major cities in Poland, is a city county (). The Legislative power in the city is vested in the unicameral Bia\u0142ystok City Council (), which has 28 members. Council members are elected directly every four years, one of whom is the mayor, or President of Bia\u0142ystok (). Like most legislative bodies, the City Council divides itself into committees which have the oversight of various functions of the city government. Bills passed by a simple majority are sent to the mayor, who may sign them into law. If the mayor vetoes a bill, the Council has 30 days to override the veto by a two-thirds majority vote. The current President of Bia\u0142ystok, elected for his first term in 2006, is Tadeusz Truskolaski won the elections as the Civic Platform's candidate, however, he has no official connection with the party. In the first round of the elections he received 49% of the votes (42,889 votes altogether). In the later runoff he defeated his rival candidate Marek Kozlowski from Law and Justice (), receiving 67% of the votes cast (53,018 votes).\nFor the 2010\u20132011 fiscal year the city received revenue (taxes levied + investments) of 1,409,565,525 z\u0142, expended 1,676,459,102 z\u0142 leaving a budget deficit of 266,893,577 z\u0142. The deficit was covered by short-term borrowing of 166,893,577 z\u0142 and the issuance of 100 million z\u0142 in municipal bonds.\nOther levels of governmental representation\nIt is also the seat of government for the Podlaskie Voivodeship. The city is represented by several members of both houses of the Polish Parliament (Sejm and Senat) from the Bia\u0142ystok constituency. Bia\u0142ystok is represented by the Podlaskie and Warmian-Masurian constituency of the European Parliament.\nInternational relations.\nThere are thirteen consulates in Bia\u0142ystok, a Consulate General of Belarus and Honorary Consulates of Romania, Finland, Bosnia and Herzegovina, Bulgaria, Croatia, Estonia, Kazakhstan, Latvia, Lithuania, Luxembourg, Malta and Serbia. The City of Bia\u0142ystok is a member of several organizations such as Union of Polish Metropolises (), Euroregion Niemen, Polish Green Lungs Foundation, and Eurocities.\nBia\u0142ystok is twinned with:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFormer twin towns:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nOn 3 March 2022, Bia\u0142ystok ended its partnership with the Russian cities of Irkutsk, Kaliningrad, Pskov and Tomsk, and also with the Belarusian city of Grodno as a reaction to the 2022 Russian invasion of Ukraine.\nEastern Partnership cities:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nFormer partnership:\nThe village of Belostok () in Russia, founded by Polish settlers, is named after the city.\nMilitary garrison.\nThe construction of the Saint Petersburg\u2013Warsaw Railway which passed through the city and was the strategic nerve of the \nRussian Empire, resulted in the rising of the military importance of the city: In 1879, construction of the barracks of the W\u0142odzimierski Infantry Regiment began (currently it is the area of the Voivodeship hospital between Wojskowa, Sk\u0142odowskiej-Curie and Wo\u0142odyjowskiego Streets). In 1884, barracks of the Kazan Infantry Regiment were established at Traugutta Street in Wygoda. In 1887, barracks of the Mariampole Dragon Regiment were erected at 100 Bema Street. In 1890, the barracks of the 4th Kharkov Uhlan Regiment were built at Kawaleryjska Street.\nThroughout the interwar period and the existence of the Second Polish Republic, the city enjoyed the presence of the 42nd Infantry Regiment (barracks at Wygoda), 10th Lithuanian Uhlan Regiment (Kawaleryjska Street) and the 14th Horse Artillery Divizion (Bema Street), the command of the Podlaska Cavalry Brigade and spare center (Sk\u0142odowskiej-Curie street, then Piwna), units of the Armed Forces of the Second Polish Republic.\nDuring December 1993 an order of the Chief of the General Staff of the Polish Armed Forces created the 18th Mechanized Brigade () at the garrison in Bia\u0142ystok. The unit was formed from the 3rd Mechanized Regiment () and was subordinated to the commander of the 1st Warsaw Mechanised Division (). On 31 December 2001, as a result of the restructuring of the Armed Forces, the 18th Mechanized Brigade was disbanded and in its place was created the 18th Territorial Defense Battalion. 31 December 2001, as a result of the restructuring of the Armed Forces, 18th Mechanized Brigade () was disbanded and in its place created the 18th Territorial Defense Battalion ()., itself reorganized into the 18th Reconnaissance Regiment () of the Polish Land Forces is based in Bia\u0142ystok.\nThe Cavalry Brigade \"Bia\u0142ystok\" (BK \"Bia\u0142ystok\") of the Polish Army of the Second Republic was formed in February 1929. On 1 April 1937, BK \"Bia\u0142ystok\" was renamed the Podlaska Cavalry Brigade (). Its headquarters was located in Bia\u0142ystok and operated as part of Independent Operational Group Narew. It was formed from the Cavalry Brigade \"Bia\u0142ystok\", which existed between February 1929, and 30 March 1937. After the Soviet invasion of Poland, remnants of the Brigade fought both Wehrmacht and Red Army troops, capitulating on 6 October 1939.\nEconomy.\nIn the nineteenth century, Bia\u0142ystok was an important center for light industry, which was the reason for the substantial growth of the city's population. The tradition continued with many garment factories established in the twentieth century, such as \"Fasty\" in the district of Bacieczki. However, after the fall of communism in 1989 many of these factories faced severe problems and subsequently closed down.\nThe unemployment rate for November 2020 in Bia\u0142ystok was 6.8%.\nThe 2009 average household had a monthly per capita income of 1018.77 z\u0142 and monthly per capita expenses of 823.56 z\u0142\nThe city has a number of nearby border crossings. The border with Belarus is only away, the nearest border crossings are located in; Bobrowniki (road crossing located about from the city limits), Ku\u017anica Bia\u0142ostocka (road and rail crossing located from the city limits), Siemian\u00f3wka (railway \u2013 freight traffic), Po\u0142owce (road) and Czeremcha (railway). Since the border with Belarus is also the eastern border of the European Union, as well as the Schengen Area the city is a center for trade in mainly from the east.\nThe leading industries in the city's economy are food processing (production of meat products, fruit and vegetable products, the production of spirits, the production of frozen food, grain processing), electrical engineering (production tools and equipment for machine tools, production of electric heaters, manufacture and production mixers household appliances). There is also a developed machine industry (electronics, machinery and metal), plastic processing (production of household appliances), textiles (textiles and upholstery, manufacture of underwear, clothing accessories, footwear and backpacks), Wood (production plywood and furniture) building materials.\nSome major employers who are based in Bia\u0142ystok include:\nInnovations.\nIn order to increase the attractiveness of the city of Bia\u0142ystok for investments based on modern technologies, the Bia\u0142ystok Science and Technology Park was opened in 2014, which is to initiate the development of infrastructure conducive to increasing innovation among local and regional enterprises.\nAmongst companies based in the Park are the Institute of Innovative Technologies EMAG, the Department of Prevention of Metabolic Diseases Institute of Animal Reproduction and Food Research of the Polish Academy of Sciences, and a biometric photographs company PhotoAid.\nPublic utilities.\nWater supply is provided by \"Wodoci\u0105gi Bia\u0142ostockie\", the municipal water company. In 2015, the length of the active water supply network in Bia\u0142ystok was . Compared to 2010, this length increased by , and compared to the previous year by . At the end of 2015, there were 20,508 residential buildings in the city connected to the water supply system. In the years 2010 - 2015, this number was constantly increasing. For comparison, at the end of 2010, there were 18,654 residential buildings connected to the water supply network, 19,307 at the end of 2012, and 20,171 at the end of 2014. Electricity in the city is supplied by PGE Polska Grupa Energetyczna (formerly Zak\u0142ad Energetyczny Bia\u0142ystok). Apartment buildings in the city are connected to the municipal heating system which was operated until its privatization by the Heating Energy Municipal Enterprise (). From November 2017 following its privatization, it was renamed Enea Ciep\u0142o, being a subsidiary of the energy conglomerate Enea SA. The energy for the municipal heating is produced by the Bia\u0142ystok Power Station using cogeneration. Gas in the city is provided by PGNiG. In November 1947, following the end of World War II, a decision was approved to construct in the city gas system, yet the city was finally connected to the gas system in 1962. Waste collection in the city is done by MPO Bia\u0142ystok, the municipal-owned cleaning enterprise as well as by other companies which are handling waste collection in some of the city districts, such as Koma. Collected waste is processed since 2015 at the Municipal Waste Treatment Plant () located at 40F Genera\u0142a W\u0142adys\u0142awa Andersa Street, replacing the landfill in Hryniewicze.\nCulture and tourism.\nBia\u0142ystok is one of the largest cultural centers in the Podlaskie Voivodeship. The attractions include performing arts groups, art museums, historical museums, walking tours of architectural/cultural aspects and a wide variety of parks and green spaces. Bia\u0142ystok in 2010 was on the short-list, but ultimately lost the competition, to become a finalist for European Capital of Culture in 2016.\nPerforming arts.\nThe city has a number of performing arts facilities including:\nThe Bia\u0142ystok Puppet Theatre (), established in 1953, is one of the oldest Polish puppet theaters. The facility is located at Kalinowskiego 1 in Bia\u0142ystok. The repertoire includes performances for both children and puppet adaptations of world literature for adults. Because of the high artistic level of productions, the theater has been recognized as one of the best puppetry arts centers in Poland.\nThe Aleksandra W\u0119gierki Drama Theatre, housed in a building designed by Jaros\u0142aw Girina, was built in the years 1933\u20131938.\nThe Podlaskie Opera and Philharmonic \u2013 European Art Centre in Bia\u0142ystok is the largest institute of arts in Northeastern Poland and the most modern cultural center in this region of Europe. In its amphitheatre every year at the end of June Halfway Festival takes place.\nMuseums.\nThere are a number of museums in the city including:\nThe Historical Museum in Bia\u0142ystok () is part of the Podlaskie Museum. The facility has a rich collection of archival materials and iconography illustrating the history of Bia\u0142ystok and Podlasie, and a number of middle-class cultural relics, especially in the field of craft utility. There are also the Numismatic Cabinet of the collection of 16 000 coins, medals and securities. The museum is in possession of the only collections in the country memorabilia connected with the Tatar settlement in the Polish\u2013Lithuanian\u2013Belarusian region.\nThe Army Museum in Bia\u0142ystok () was established in September 1968 as a branch of the Podlaskie Museum to house the research and collections of many people connected with the military history of north-eastern Poland.\nThe Ludwik Zamenhof Centre () has a permanent exhibition, \"Bialystok of Young Ludwik Zamenhof\", and various temporary exhibitions, concerts, film projections, and theatre performances. The Centre has a branch of \u0141ukasz G\u00f3rnicki's Podlaska Library dedicated to the Esperanto language.\nThe Sybir Memorial Museum () is a historical museum opened in 2021 and dedicated to the memory of Poles, as well as people from other nationalities, the victims of forced deportations to Siberia perpetrated by the Russian Empire and the Soviet Union.\nThe Alfons Karny Sculpture Museum contains a collection of sculptures by Bia\u0142ystok native Alfons Karny.\nThe Medical University of Bia\u0142ystok operates the Museum of the History of Medicine and Pharmacy ().\nThe Galeria Arsena\u0142 is a contemporary art gallery, located at a former 18th-century arsenal in the city center.\nParks and green spaces.\nAround 32% of the city is occupied by parks, squares and forest preserves which creates a unique and healthy climate. The green spaces include:\nBranicki Palace () is a historical edifice and park in Bia\u0142ystok. It was developed on the site of an earlier building in the first half of the eighteenth century by Jan Klemens Branicki, wealthy Polish Crown Hetman (highest military leader of Poland), into a residence suitable for a man whose ambition was to be elected king of Poland. The palace complex with gardens, pavillons, sculptures, outbuildings and other structures and the city with churches, city hall and monastery, all built almost at the same time according to French models was the reason why the city was known in the eighteenth century as Versailles of Podlachia ().\nPlanty is a park created between 1930 and 1938, under the auspices of the then voivode Marian Zyndram-Ko\u015bcia\u0142kowski in the areas adjacent to Branicki Palace. The modernist composition of the park was designed by Stanislav Gralla.\nArchitecture.\nThe various historically driven changes have had a very significant influence on the architectural space of the city. Most other Polish cities have suffered similarly, but the processes in Bia\u0142ystok, have had a particularly intense course. Numerous historic works of architecture no longer exist, while many others have been rebuilt to their original configuration. Very few historic buildings of the city have been preserved \u2013 the sights are merely an echo of the old historical shape of Bia\u0142ystok.\nMain sights include:\nLocal cuisine.\nIn additional to traditional nationwide Polish cuisine and regional Podlaskie cuisine, a local type of boza, a traditional fermented drink more common in the Balkans, Central Asia and the Caucasus, is produced in Bia\u0142ystok, and the bialy bread roll, popular in New York City, originated here, with both listed as traditional foods and beverages by the Ministry of Agriculture and Rural Development of Poland.\nSports.\nThe city has both professional and amateur sports teams, and a number of venues where they are based. Jagiellonia Bia\u0142ystok is a Polish football club, based in Bia\u0142ystok, in the Ekstraklasa (Poland's top division) that plays at the Bia\u0142ystok Municipal Stadium. Jagiellonia Bia\u0142ystok won the Polish Cup and Super Cup in 2010, and the Polish Championship in 2024. A new 22,500-seat stadium was completed at the beginning of 2015. There is also a futsal team S\u0142oneczny Stok Jagiellonia Bia\u0142ystok, which plays in the Futsal Ekstraklasa, Poland's top division (as of 2022\u201323).\nPodlasie Bia\u0142ystok is one of the top athletics clubs in Poland, multiple times Polish Team Champions, most recently in 2022.\nLowlanders Bia\u0142ystok is an American football club, that plays in the Polish Football League (), and are three-times Polish Bowl champions.\nOther notable clubs include men's football team Hetman Bia\u0142ystok (with additional boxing and contract bridge sections), basketball club \u017bubry Bia\u0142ystok, and football club W\u0142\u00f3kniarz Bia\u0142ystok with both men's and women's sections, however, all of the aforementioned teams play in the lower leagues as of 2022\u201323.\nMedia.\nBia\u0142ystok has a wide variety of media outlets serving the city and surrounding region. There are two locally published daily newspapers, Gazeta Wsp\u00f3\u0142czesna (36.3% market share) and Kurier Poranny (20.3% market share). In addition two national papers have local bureaus. There are a number of national and locally produced television and radio channels available both over-the-air from the nearby RTCN Bia\u0142ystok (Krynice) Mast, the seventh highest structure in Poland, in addition to transmitter sites within the city. TVP Bia\u0142ystok is one of the locally produced, regional branches of the TVP, Poland's public television broadcaster. There is also a cable television system available within the city. The city has two campus radio stations; \"Radiosupe\u0142\" at the Medical University of Bia\u0142ystok and \"Radio Akadera\" at Bia\u0142ystok Technical University.\nReligion.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nIn the early 1900s, Bia\u0142ystok was reputed to have the largest concentration of Jews of all the cities in the world. In 1931, 40,000 Jews lived in the city, nearly half the city's inhabitants.\nThe city is the seat of the Roman Catholic Archdiocese of Bia\u0142ystok. Pope John Paul II on 5 June 1991, during a visit to Bia\u0142ystok, announced the establishment of the Archdiocese of Bia\u0142ystok which ended the period of the temporary church administration of the portion of the Archdiocese of Vilnius that had, after World War II, remained within the Polish borders. The city is also the seat of the Bia\u0142ystok-Gda\u0144sk Diocese of the Autocephalous Polish Orthodox Church. Bia\u0142ystok is the largest concentration of Orthodox believers in Poland. In Bia\u0142ystok, the following Protestant churches exist: a Lutheran parish, two Pentecostal churches, Baptist church, a congregation of the Church of God in Christ and a Seventh Day Adventist church.\nBia\u0142ystok is home to more than two thousand Muslims (mainly Tatars). There is an Islamic Centre, a House of Prayer, and various organisations. There is a magazine issued \u2013 \"\" (\"Memory and persistence\").\nThe city is the site of the Divine Mercy Sanctuary with the main relics of Micha\u0142 Sopo\u0107ko.\nTransport.\nThe city is and has been for centuries, the main hub of transportation for the Podlaskie Voivodeship and the entire northeastern section of Poland. It is a major city on the European Union roadways (Via Baltica) and railways (Rail Baltica) to the Baltic Republics and Finland. It is also a main gateway of trade with Belarus due to its proximity to the border and its current and longstanding relationship with Grodno, Belarus.\nA traffic management system has been operating in Bia\u0142ystok since 2015. At 120 intersections, traffic lights are coordinated in such a way that cars and buses covered the route as quickly as possible. Special cameras record traffic, travel time. Drivers receive this information on 19 boards set among others at the intersections on Wasilkowska Street, Antoniuk-Fabryczny Street and Kleeberga Street.\nRailways.\nPassenger trains connect from Suwa\u0142ki, Grodno and Lithuania to Warsaw and the rest of the European passenger network. Passenger services are provided by two rail service providers, PKP Intercity that provides intercity passengers trains (express, intercity, eurocity, hotel and TLK) and Polregio that operates only regional passenger trains financed by the voivodeship. Passenger trains are mostly run using electrical multiple units (on electrified lines) or rail buses.\nBuses.\nThere is an extensive bus network that covers the entire city by three bus services, but no tram or subway exists. The three bus operators (KPKM, KPK and KZK) are owned by the city and each shares approximately a third of the lines and the bus fleet.\nRoads and highways.\nThe National Roads () running through Bia\u0142ystok:\nThe expressways () near Bia\u0142ystok:\nThe Voivodeship roads () running through Bia\u0142ystok::\nIn Bia\u0142ystok Country () there are also Poviat roads () which connect Bia\u0142ystok with other towns in the area:\n&lt;templatestyles src=\"Template:Hidden begin/styles.css\"/&gt;Poviat roads* Poviat Road 1431 B: Bia\u0142ystok (42 Pu\u0142ku Piechoty Street) - Sowlany\nBicycle.\nBy 2020, there were already over of bicycle paths in Bia\u0142ystok.\nThe municipal bicycle renting system is called BiKeR and was opened in 2014. The system was initially based on 30 stations equipped with 300 bikes. The city has four public bicycle repair stations, in which one can fix their private bikes. The stations are located in places where the highest traffic of city bikes was observed.\nAirports.\nA civil airport, Bia\u0142ystok-Krywlany Airport, lies within the city limits, but does not provide regularly scheduled service. There were plans in 2011 to build a new regional airport, \"Bia\u0142ystok-Saniki Airport\", that would have provided flights within Europe.\nEducation.\nHigher education in the city can be traced back to the second half of the eighteenth century when the ownership of the city was inherited by Field Crown Hetman Jan Klemens Branicki. As a patron of the arts and sciences, Branicki encouraged numerous artists and scientists to settle in Bia\u0142ystok to take advantage of Branicki's patronage. In 1745 Branicki established Poland's first military college, the School of Civil and Military Engineering, in the city.\nSince the fall of communism many privately funded institutions of higher educations have been founded and their number is still increasing. Currently Bia\u0142ystok is home to one principal public university (University of Bia\u0142ystok) and two other public specialist universities (Bialystok University of Technology and Medical University of Bia\u0142ystok). Some institutions, such as Musical Academy in Bia\u0142ystok, are branches of their parent institutions in other cities, usually in Warsaw.\nNotable residents.\nOver the centuries, a number of people from Bia\u0142ystok have been prominent in the fields of science, language, politics, religion, sports, finance, visual arts and performing arts. This environment was created in the mid-eighteenth century by the patronage of Jan Klemens Branicki for the arts and sciences. These include Ryszard Kaczorowski, last \u00e9migr\u00e9 President of the Republic of Poland, L. L. Zamenhof, the creator of Esperanto, Albert Sabin, co-developer of the polio vaccine, Izabella Scorupco, actress, Max Weber, painter. Tomasz Bagi\u0144ski illustrator, animator and director Oscar nominee in 2002 for \"The Cathedral\". Leo Melamed pioneered creation of the International Monetary Market and financial futures.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47783", "revid": "29463730", "url": "https://en.wikipedia.org/wiki?curid=47783", "title": "575", "text": "Calendar year\nYear 575 (DLXXV) was a common year starting on Tuesday of the Julian calendar. The denomination 575 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy topic.\nReligion.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47785", "revid": "47390504", "url": "https://en.wikipedia.org/wiki?curid=47785", "title": "Dr. Mario", "text": "1990 video game\nDr. Mario is a 1990 puzzle video game developed and published by Nintendo for the Nintendo Entertainment System and Game Boy. A spin-off of the \"Mario\" series, it is a falling block puzzle game in which the player's objective is to destroy the viruses populating the on-screen playing field by using colored capsules that are automatically tossed into the field by Dr. Mario. The player manipulates the falling capsules, to align the same colors, which destroys viruses. The player progresses through the game by eliminating all the viruses on the screen in each level. The game was produced by Gunpei Yokoi and programmed by Takahiro Harada, with the soundtrack composed by Hirokazu Tanaka.\n\"Dr. Mario\" was a commercial success, with more than 10 million copies sold worldwide across all platforms. It received generally positive reviews, appearing on several lists of \"Best Nintendo Games of All Time\". It has been ported, remade, or had a sequel on every Nintendo home console since the NES, and on most portable consoles, including a re-release in 2004 on the Game Boy Advance in the \"Classic NES Series\". It was modified into minigames in ', ', and \"\". \"Dr. Luigi\" is a spin-off for Wii U, released on December 31, 2013, as part of the Year of Luigi celebration.\nGameplay.\n\"Dr. Mario\" is a falling block tile-matching video game. Mario assumes the role of a doctor, tossing two-colored medical capsules into a medicine bottle representing the playing field. This area is populated by viruses of three colors \u2014 red, yellow, and blue \u2014 which stay in their starting positions until removed. In a style similar to \"Tetris\", the player manipulates each capsule as it vertically falls, able to move it left or right and rotate it 90 degrees clockwise or counter-clockwise. When matching colors of capsule halves and viruses touch sequentially 4-in-a-row, they disappear. Any remaining half or whole capsules which are not supported will fall to the bottom of the playing field or until hitting another supported object, and any new 4-in-a-row alignments also disappear. The main objective is to eliminate all viruses from the playing field, finishing each level. A game over occurs if capsules fill the playing field in a way that obstructs the bottle's narrow neck. After each 5th level is completed on Medium or High difficulty, up to level 20, a cutscene shows the virus trio sitting on a tree as music plays and an object flies across the screen.\nThe options screen configures the starting level, game speed, and music. The player chooses a starting level between 0 and 20 that determines the number of viruses to clear, and one of three speeds of the falling capsules. The player's score is based on the elimination of viruses and the chosen game speed, with bonus points for clearing more than 1 in a single line. \"Dr. Mario\" offers a multiplayer gaming mode in which two players compete in separate playing fields. Each player's goal is to clear the private playing field of viruses first. Eliminating multiple viruses or initiating chain reactions can add capsules to the opponent's playing field. A player wins a single game upon eliminating all the viruses or upon the other player's bottle filling. The first player to win three games wins overall.\nThe NES and Game Boy versions of the games have slight differences. The Game Boy version has a smaller playfield than the NES one and the games feature different cutscenes showcasing the viruses in different locations. If the player manages a chain of four or more in the Game Boy version, then the Invincible Music from \"Super Mario Bros.\" (1985) will play briefly.\nDevelopment.\n\"Dr. Mario\" was produced by Gunpei Yokoi, creator of the Game Boy and Game &amp; Watch handheld systems. Takahiro Harada, producer of the \"\", was its programmer. Its music was composed by Hirokazu Tanaka, and has been re-used and arranged such as in the \"Super Smash Bros.\" series.\nRe-releases.\n\"Dr. Mario\" spawned several remakes and ports that were released on various Nintendo consoles. The original version's multiplayer portion was ported to two Nintendo arcade systems: the Nintendo VS. System (as \"Vs. Dr. Mario\") and the PlayChoice-10. \"Vs. Dr. Mario\" was first shown at Nintendo's Seventh Annual Distributor Meeting in San Diego, and both versions were released simultaneously in August 1990. An enhanced remake of \"Dr. Mario\" was paired with \"Tetris\" in the Super Nintendo Entertainment System compilation game \"Tetris &amp; Dr. Mario\", released on 30 December 1994. This was re-released in Japan on 30 March 1997, as a downloadable game for the Super Famicom's Satellaview peripheral, with the name \"Dr. Mario BS Version.\" It was re-released again in Japan for the Super Famicom's and Game Boy's downloadable Nintendo Power cartridges.\nThe NES version was ported twice to the Game Boy Advance: first in 2004 as one of thirty games in the \"Classic NES Series\" (\"Famicom Mini Series\" in Japan), then bundled with a version of the \"Puzzle League\" series in 2005 as \"Dr. Mario &amp; Puzzle League\", with updated graphics and new music. \"Nintendo Puzzle Collection\" and the \"Nintendo GameCube Preview Disc\", both released in 2003 for the GameCube, can copy the NES version of \"Dr. Mario\" to the Game Boy Advance using the Nintendo GameCube \u2013 Game Boy Advance link cable. The NES version was released on the Wii U Virtual Console in 2014 and was one of the launch games for the Nintendo Classics service on September 19, 2018. The original Game Boy version was re-released on the Nintendo 3DS Virtual Console in 2011 and 2012, and on the Nintendo Classics service on March 12, 2024.\nReception.\n\"Dr. Mario\" received generally positive reviews, although some parents were critical of the premise of medicine in a children's game. The Game Boy version received positive reviews from \"Joystick\" and \"Zero\" magazines, the latter comparing it favorably with \"Tetris\" and Connect Four while stating it is \"easy to play and impossible to master\". \"ACE\" criticized the uninspiring graphics, repetitive play, and \"plagiarism\" while comparing it unfavorably with \"Tetris\" and \"Connect Four\". \nIn the Japanese magazine \"Famicom Ts\u016bshin\", the four reviewers said that while the game is similar to \"Tetris\", they still found it fun with one reviewer saying it was more fun to play as a two-player game. The same four reviewers also complimented the Game Boy version of the game, with one reviewer feeling that the game was slightly worse due to the lack of color on the Game Boy making it harder to decipher some gameplay elements.\nIn Japan, 2.08 million copies were sold for the Game Boy, 1.53 million for the Famicom, and 248,045 for the Game Boy Advance, for a total of 3,858,045 cartridges sold in Japan. In North America, 2.5 million copies were sold within six weeks of release. Worldwide, 5.34 million copies were sold for the Game Boy and 4.85 million for the Nintendo Entertainment System, for a total of cartridges sold worldwide across all platforms.\nRetrospective reception.\n\"Allgame\" praised the NES version, stating that on its release, \"when puzzle games were flooding the market, \"Dr. Mario\" stands out as one of the best, combining a smooth learning curve, playful graphics and memorable tunes\" and \"fundamental concepts may be simple, but the addictive gameplay becomes progressively more complex as the speed increases and additional viruses are added.\"\n\"Dr. Mario\" was rated the 134th best game on a Nintendo system in \"Nintendo Power\"'s Top 200 Games list, the 7th best \"Mario\" game of all time on \"ScrewAttack's Top 10\", and the 51st best NES game of all time by \"IGN\". \"IGN\" also rated the soundtrack, composed by Hirokazu Tanaka, as seventh in its list of the top ten greatest 8-bit soundtracks. \"GamesRadar\" ranked it the 13th best NES game ever made, calling it \"one of the most celebrated of the [puzzle] genre\". \"Game Informer\"'s Ben Reeves called it the seventh best Game Boy game. In 2019, \"PC Magazine\" included Dr. Mario on their \"The 10 Best Game Boy Games\".\nThe Game Boy Advance re-release in the \"Classic NES Series\" is rated 66/100 on Metacritic based on 10 reviews. Most reviews pointed out the game's addictiveness and praise the addition of wireless multiplayer, but some questioned the relevance of the standalone re-release. \"Eurogamer\" said the game was \"still as playable, addictive, and maddening as it was back in 1990\" but criticized Nintendo for re-releasing classic games as standalone games in the \"Classic NES Series\" instead of as a compilation, like Atari's \"Atari Anthology\" or Midway's \"Midway Arcade Treasures\".\nCraig Harris of \"IGN\" sarcastically expressed unease over the game's use of medicine. He enjoyed the addictive gameplay, but criticized the black-and-white manual which made it difficult to understand the colored gameplay mechanics. \"1UP.com\" noted that the game's \"color-matching action is more engrossing than \"Mario Bros. turtle-punching platform hopping\", but strongly questioned whether this re-release is worth its sale price by itself when a version of \"Dr. Mario\" was included in another Game Boy Advance game, '.\nHenk Rogers of the Tetris Company spoke negatively about the game in an interview published in 2018, saying he \"was pissed off about that game, \"Dr. Mario\" was a blatant attempt to come up with a \"Tetris\" replacement and I thought they did it in a cheesy way.\"\nLegacy.\nAfter the commercial success of \"Dr. Mario\", Nintendo released several follow-up games. \"Dr. Mario 64\", released in 2001 for the Nintendo 64, features Wario and several \"Wario Land 3\" characters, and offers numerous game modes, including a story-focused single-player mode. The game supports simultaneous multiplayer for up to four players. \"Dr. Mario 64\" was subsequently released in Japan in \"Nintendo Puzzle Collection\" for the GameCube. \"Dr. Mario Online Rx\", released in 2008 on WiiWare, offers online multiplayer via Nintendo Wi-Fi Connection. \"Dr. Mario Express\", released in 2009 for the Nintendo DSi, does not support multiplayer gameplay. \"Dr. Luigi\" was released in 2013 for the Wii U, with Luigi as a playable character, all the modes in \"Dr. Mario Online Rx\", and a new mode with L-shaped capsules. The latest installment, \"\", was released in 2015 for the Nintendo 3DS, and introduced power-ups to the series. \"Dr. Mario World\" was a mobile game that was released on 2019 for iOS and Android smart devices, and features new mechanics, such as brand new doctors with special abilities, assistants, and a gacha system. \"Dr. Mario World\" was discontinued in November 2021.\nVarious games in the \"Super Smash Bros.\" series have remixed musical tracks from \"Dr. Mario\", or Dr. Mario as an unlockable playable character. \"Dr. Wario\" replaces Mario with Wario, as an unlockable minigame in '. A simplified version of \"Dr. Mario\" is in ' as the \"Virus Buster\" minigame, using the touch screen to drag the capsules around the playing field. The viruses are enemies in ' and '. They change colors when attacked, and are all defeated when they are all the same color. In 2018, the Classic Tetris World Championship featured a \"Dr. Mario\" championship as a side event.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47786", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=47786", "title": "Environmental finance", "text": "Field of finance focused on environmental policy\nEnvironmental finance is a field within finance that employs market-based environmental policy instruments to improve the ecological impact of investment strategies. The primary objective of environmental finance is to regress the negative impacts of climate change through pricing and trading schemes. The field of environmental finance was established in response to the poor management of economic crises by governmental bodies globally. Environmental finance aims to reallocate business resources to improve the sustainability of investments whilst also retaining profit margins.\nHistory.\nIn 1992, Richard L. Sandor proposed a new course outlining emission markets at the University of Chicago Booth School of Business, that would later be known as the course, \"Environmental Finance\". Sandor anticipated a social shift in perspectives on the effects of global warming and wanted to be on the frontier of new research.\nPrior to this in 1990, Sandor had been involved with the passing of the Clean Air Act Amendment for the Chicago Board of Trade, which aimed to reduce high sulfur dioxide levels following WW2. Inspired by the theory of social cost, Sandor focused on cap-and-trade strategies such as emission trading schemes and more flexible mechanisms including taxes and subsidies to manage environmental crisis. The implementation of cap-and-trade mechanisms was a contributing factor to the success of the Clean Air Act Amendment.\nFollowing the Clean Air Act in 1990, the United Nations Conference on Trade and Development approached the Chicago Board of Trade in 1991, to enquire about how the market-based instruments used to combat high atmospheric sulfur dioxide concentrations could be applied to the increasing levels of atmospheric carbon dioxide. Sandor created a framework consisting of four characteristics which could be used to describe the carbon market:\nIn 1997 the Kyoto Protocol was enacted and later enforced in 2005 by the United Nations Framework Convention on Climate Change. Included nations agreed to focus on reducing global greenhouse gas emissions through the market-based mechanism of emissions trading. Reductions averaged approximately 5% by 2012 which equates to almost 30% in reduction of total emissions. Some nations made significant progress under the Kyoto protocol, however as it only became law in 2005, nations such as the United States and China reported increased emissions, substantially offsetting progress made by other regions.\nIn 1999, the Dow Jones Sustainability Index was introduced to evaluate the ecological and social impact of stocks so shareholders could invest more sustainably. The index acts as an incentive for firms to improve their environmental footprint to attract more shareholders.\nLater in 2000, the United Nations introduced the Millennium Development Goal scheme which sought to promote a sustainable framework for large multinational corporations and countries to follow to improve the environmental impact of financial investments. This framework facilitated the development of the United Nations Sustainable Development Goal scheme in 2015, which aimed to increase funding environmentally responsible investments in developing nations. Funding was targeted to improve areas such as primary education, gender equality, maternal health, and nutrition, with the overall goal of creating beneficial national relationships to decrease the ecological footprint of developing economies\".\" Implementation of these frameworks has promoted greater participation and accountability of corporate environmental sustainability, with over 230 of the largest global firms reporting their sustainability metrics to the United Nations.\nThe United Nations Environment Program (UNEP) has had a detailed history in providing infrastructure to improve the environmental effects of financial investments. In 2004, the institute provided training on responsible environmental credit budgeting and management for Eastern European nations. After the 2008 financial crisis, the UNEP provided substantial support for future sustainable investment choices for economies such as Greece which were impacted severely. The Portfolio Decarbonisation Coalition established in 2014 is a significantly notable initiative in the history of environmental finance as it aims to establish an economy that is not dependent on investments with large carbon footprints. This goal is achieved through large-scale stakeholder reinvestment and securing long-term, responsible, investment commitments. Most recently, the UNEP has recommended OECD nations to align investment strategies alongside the objectives of the Paris Agreement, to improve long-term investments with significant ecological effects.\nIn 2008 the Climate Change Act enacted by the UK Government established a framework to limit greenhouse gasses and carbon emissions through a budgeting scheme, which motivated firms and businesses to reduce their carbon output for a financial reward. Specifically, by 2050 it seeks to reduce carbon emissions by 80% compared to levels in 1980. The Act seeks to achieve this goal by reviewing carbon budgeting schemes such emission trading credits, every 5 years to continually reassess and recalibrate relevant policies. The cost of reaching the 2050 goal has been estimated at approximately 1.5% of GDP, although the positive environmental impact of reducing carbon footprint and increased in investment into the renewable energy sector will offset this cost. A further implicated cost in the pursuit of the Act is a predicted \u00a3100 increase in annual household energy costs, however this price increase is set to be outweighed by an improved energy efficiency which will decrease fuel costs. \u00a0 \u00a0\nThe 2010 cap and trade scheme introduced in the metropolitan regions of Tokyo was mandatory for businesses heavily dependent on fuel and electricity, who accounted for almost 20% of total carbon emissions in the area. \u00a0The scheme aimed to reduce emissions by 17% by the end of 2019. \u00a0\nIn 2011 the Clean Energy Act was enacted by the Australian Government. The act introduced the Carbon Tax which aimed to reduce greenhouse gas emission by charging large firms for their carbon tonnage. The Clean Energy Act facilitated the transition to an emissions trading scheme in 2014\".\" The scheme also aims to fulfill the Australian Government's obligations in respect to the Kyoto Protocol and the Climate Change Convention. Additionally, the Act seeks to reduce emissions in a manner that will foster economic growth through increased market competition and investment into renewable energy sources. The Australian National Registry of Emissions Units regulates and monitors the use of emission credits utilised by the Act. Firms must enroll in the registry to buy and sell credits to compensate for their relevant reduction or over-consumption of carbon emissions.\nThe Republic of Korea's 2015 emission trading scheme aims to reduce carbon emissions by 37% by 2030. It strives to achieve this through allocating a quota of carbon emission to the largest carbon emitting businesses, resetting at the beginning of the schemes 3 separate phases.\nIn 2017 the National Mitigation Plan was passed by the Irish Government which aimed to regress climate change by decreasing emission levels through revised investment strategies and frameworks for power generation, agriculture, and transport The plan involves 106 separate guidelines for short and long term climate change mitigation.\nThe European Union Emission Trading Scheme concluding at the end of 2020 is the longest single global carbon pricing scheme, which has been improved over its three 5-year phases. Current improvements include a centralised emission credit trading system, auctioning of credits, addressing a broader range of green house gasses and the introduction of a European-wide credit cap instead of national caps.\nStrategies.\nSocietal shifts from fossil fuels to renewable energy caused by an increased awareness of climate change has made government bodies and firms re-evaluate investment strategies to avoid irreparable ecological damage. Shifts away from fossil fuels also increase demand into alternate energy sources which requires revised investment strategies.\nThe initial stage to mitigate climate change through financial tools involves ecological and economic forecasting to model future impacts of current investment methodologies on the environment. This allows for an approximate estimation of future environments; however, the impacts of continued harmful business trends need to be observed under a non-linear perspective.\nCap-and-trade mechanisms limit the total amount of emissions a particular region or country can emit. Firms are issued with tradeable permits which they can buy or sell. This acts as a financial incentive to reduce emissions and as a disincentive to exceed emission caps.\nIn 2005, the European Union Emission Trading Scheme was established and is now the largest emission trading scheme globally.\nIn 2013, the Qu\u00e9bec Cap-and-trade scheme was established and is currently the primary mitigation strategy for the area.\nDirect foreign investment into developing nations provide more efficient and sustainable energy sources.\nIn 2006, the Clean Development Mechanism was formed under the Kyoto Protocol, providing solar power and new technologies to developing nations. Countries who invest into developing nations can receive emission reduction credits as a reward. \u00a0\nRemoval of atmospheric carbon dioxide has been proposed as a solution to mitigate climate change, by increasing tree densities to absorb carbon dioxide. Other methods involve new technologies which are still in research development stages.\nResearch in environmental finance has sought how to strategically invest in clean technologies. When paired with international legislation, such as the case of the Montreal Protocol on Substances that Deplete the Ozone Layer, environmentally based investments have stimulated emerging industries and reduced the consequences of climate change. The international collaboration would ultimately lead to the changes that repaired the hole in the ozone layer.\nImpact.\nThe European Union Emission Trading Scheme from 2008-2012 was responsible for a 7% reduction in emissions for the states within the scheme. In 2013, allowances were reviewed to accommodate for new emission reduction targets. The new annual recommended target was a reduction of 1.72%. It is estimated that reducing the amount of quoted credits was restricted more tightly, emissions could have been reduced by a total of 25%. Nations such as Romania, Poland and Sweden experienced significant revenue, benefiting from selling credits. \u00a0Despite successfully reducing emissions, the European Union Emission Trading Scheme has been critiqued for its lack of flexibility to accommodate to major shifts in the economic landscape and reassess currents contexts to provide a revised cap on trading credits, potentially undermining the original objective of the scheme.\nThe New Zealand Emissions Trading Scheme of 2008 was modelled to increase annual household energy expenditure to 0.8% and increase fuel prices by approximately 6%. The price of agricultural products such as beef and dairy were modelled to decrease by almost 1%. Price increases in carbon intensive sectors such as foresting and mining were also expected, incentivising a shift towards renewable energy system and improved investment strategies with a less harmful environmental impact.\nIn 2016, the Qu\u00e9bec Cap-and-trade scheme was responsible for an 11% reduction in emissions compared to 1990 emission levels\".\" Due to the associated increased energy costs, fuel prices rose 2-3 cents per litre over the duration of the cap and trade scheme.\nIn 2014, the Clean Development Mechanism was responsible for a 1% reduction in global greenhouse gas emissions. \u00a0The Clean Development Mechanism has been responsible for removing 7 billion tons of greenhouse gasses from the atmosphere through the efforts of almost 8000 individual projects. Despite this success, as the economies of developing nations participating in Clean Development Mechanisms improves, the financial payout to the country supplying such infrastructure increases at a greater rate than economic growth, thus leading to an unoptimised and counterproductive system.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47788", "revid": "34957223", "url": "https://en.wikipedia.org/wiki?curid=47788", "title": "214", "text": "Calendar year\nYear 214 (CCXIV) was a common year starting on Saturday of the Julian calendar. At the time, it was known as the Year of the Consulship of Messalla and Suetrius (or, less frequently, year 967 \"Ab urbe condita\"). The denomination 214 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\nEvents.\n&lt;onlyinclude&gt;\nBy place.\nChina.\n&lt;/onlyinclude&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47789", "revid": "50255754", "url": "https://en.wikipedia.org/wiki?curid=47789", "title": "Quality of life", "text": "Degree of individual well-being\nQuality of life (QOL) is defined by the World Health Organization as \"an individual's perception of their position in life in the context of the culture and value systems in which they live and in relation to their goals, expectations, standards and concerns\". \nStandard indicators of the quality of life include wealth, employment, the environment, physical and mental health, education, recreation and leisure time, social belonging, religious beliefs, safety, security and freedom. QOL has a wide range of contexts, including the fields of international development, healthcare, politics and employment. Health related QOL (HRQOL) is an evaluation of QOL and its relationship with health.\nEngaged theory.\nOne approach, called the engaged theory, outlined in the journal of \"Applied Research in the Quality of Life\", posits four domains in assessing quality of life: ecology, economics, politics and culture. In the domain of culture, for example, it includes the following subdomains of quality of life:\nUnder this conception, other frequently related concepts include freedom, human rights, and happiness. However, since happiness is subjective and difficult to measure, other measures are generally given priority. It has also been shown that happiness, as much as it can be measured, does not necessarily increase correspondingly with the comfort that results from increasing income. As a result, the standard of living should not be taken to be a measure of happiness. Also, sometimes considered related is the concept of human security, though the latter may be considered at a more basic level and for all people.\nQuantitative measurement.\nUnlike \"per capita\" GDP or standard of living, both of which can be measured in financial terms, it is harder to make objective or long-term measurements of the quality of life experienced by nations or other groups of people. Researchers have begun in recent times to distinguish two aspects of personal well-being: \"Emotional well-being\", in which respondents are asked about the quality of their everyday emotional experiences\u00a0\u2013 the frequency and intensity of their experiences of, for example, joy, stress, sadness, anger and affection\u00a0\u2013 and \"life evaluation\", in which respondents are asked to think about their life in general and evaluate it against a scale. Such and other systems and scales of measurement have been in use for some time. Research has attempted to examine the relationship between quality of life and productivity. \nThere are many different methods of measuring quality of life in terms of health care, wealth, and materialistic goods. However, it is much more difficult to measure meaningful expression of one's desires. One way to do so is to evaluate the extent to which individuals have fulfilled their own ideals. Quality of life can simply mean happiness, which is the subjective state of mind. By using that mentality, citizens of a developing country appreciate more since they are content with the basic necessities of health care, education and child protection.\nAccording to ecological economist Robert Costanza:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;While Quality of Life (QOL) has long been an explicit or implicit policy goal, adequate definition and measurement have been elusive. Diverse \"objective\" and \"subjective\" indicators across a range of disciplines and scales, and recent work on subjective well-being (SWB) surveys and the psychology of happiness have spurred renewed interest.\nHuman Development Index.\nPerhaps the most commonly used international measure of development is the Human Development Index (HDI), which combines measures of life expectancy, education, and standard of living, in an attempt to quantify the options available to individuals within a given society. The HDI is used by the United Nations Development Programme in their Human Development Report. However, since 2010, The Human Development Report introduced an Inequality-adjusted Human Development Index (IHDI). While the original HDI remains useful, it stated that \"the IHDI is the actual level of human development (accounting for inequality), while the original HDI can be viewed as an index of 'potential' human development (or the maximum level of HDI) that could be achieved if there was no inequality.\"\nWorld Happiness Report.\nThe World Happiness Report is a landmark survey on the state of global happiness. It ranks 156 countries by their happiness levels, reflecting growing global interest in using happiness and substantial well-being as an indicator of the quality of human development. Its growing purpose has allowed governments, communities and organizations to use appropriate data to record happiness in order to enable policies to provide better lives. The reports review the state of happiness in the world today and show how the science of happiness explains personal and national variations in happiness. \nDeveloped once again by the United Nations and published recently, along with the HDI, this report combines both objective and subjective measures to rank countries by happiness, which is deemed the ultimate outcome of a high quality of life. It uses surveys from Gallup, real GDP per capita, healthy life expectancy, having someone to count on, perceived freedom to make life choices, freedom from corruption, and generosity to derive the final score. Happiness is already recognized as an important concept in global public policy. The World Happiness Report indicates that some regions have, in recent years, been experiencing progressive inequality of happiness.\nOther measures.\nThe Physical Quality of Life Index (PQLI) is a measure developed by sociologist M. D. Morris in the 1970s, based on basic literacy, infant mortality, and life expectancy. Although not as complex as other measures, and now essentially replaced by the Human Development Index, the PQLI is notable for Morris's attempt to show a \"less fatalistic pessimistic picture\" by focusing on three areas where global quality of life was generally improving at the time, while ignoring gross national product and other possible indicators that were not improving.\nThe Happy Planet Index, introduced in 2006, is unique among quality of life measures in that, in addition to standard determinants of well-being, it uses each country's ecological footprint as an indicator. As a result, European and North American nations do not dominate this measure. The 2012 list is instead topped by Costa Rica, Vietnam and Colombia.\nIn 2010, Gallup researchers trying to find the world's happiest countries found Denmark to be at the top of the list. For the period 2014\u20132016, Norway surpasses Denmark to be at the top of the list.\nA 2010 study by two Princeton University professors looked at 1,000 randomly selected U.S. residents over an extended period. It concludes that their \"life evaluations\" \u2013 that is, their considered evaluations of their life against a stated scale of one to ten \u2013 rise steadily with income. On the other hand, their reported quality of \"emotional daily experiences\" (their reported experiences of joy, affection, stress, sadness, or anger) levels off after a certain income level (approximately $75,000 per year in 2010); income above $75,000 does not lead to more experiences of happiness nor to further relief of unhappiness or stress. Below this income level, respondents reported decreasing happiness and increasing sadness and stress, implying the pain of life's misfortunes, including disease, divorce, and being alone, is exacerbated by poverty.\nGross national happiness and other subjective measures of happiness are being used by the governments of Bhutan and the United Kingdom. The World Happiness report, issued by Columbia University is a meta-analysis of happiness globally and provides an overview of countries and grassroots activists using GNH. The OECD issued a guide for the use of subjective well-being metrics in 2013. In the U.S., cities and communities are using a GNH metric at a grassroots level.\nThe Social Progress Index measures the extent to which countries provide for the social and environmental needs of their citizens. Fifty-two indicators in the areas of basic human needs, foundations of wellbeing, and opportunity show the relative performance of nations. The index uses outcome measures when there is sufficient data available or the closest possible proxies.\nDay-Reconstruction Method was another way of measuring happiness, in which researchers asked their subjects to recall various things they did on the previous day and describe their mood during each activity. Being simple and approachable, this method required memory and the experiments have confirmed that the answers that people give are similar to those who repeatedly recalled each subject. The method eventually declined as it called for more effort and thoughtful responses, which often included interpretations and outcomes that do not occur to people who are asked to record every action in their daily lives.\nThe Digital Quality of Life Index - a yearly study on digital well-being across 121 countries created by Surfshark. It indexes each country according to five pillars that impact a population's digital quality of life: internet affordability, internet quality, electronic infrastructure, electronic security, and electronic government.\nLivability.\nThe term \"quality of life\" is also used by politicians and economists to measure the livability of a given city or nation. Two widely known measures of livability are the Economist Intelligence Unit's Where-to-be-born Index and Mercer's Quality of Living Reports. These two measures calculate the livability of countries and cities around the world, respectively, through a combination of subjective life-satisfaction surveys and objective determinants of quality of life such as divorce rates, safety, and infrastructure. Such measures relate more broadly to the population of a city, state, or country, not to individual quality of life. Livability has a long history and tradition in urban design, and neighborhoods design standards such as LEED-ND are often used in an attempt to influence livability. \nCrimes.\nSome crimes against property (e.g., graffiti and vandalism) and some \"victimless crimes\" have been referred to as \"quality-of-life crimes\". American sociologist James Q. Wilson encapsulated this argument as the broken windows theory, which asserts that relatively minor problems left unattended (such as litter, graffiti, or public urination by homeless individuals) send a subliminal message that disorder, in general, is being tolerated, and as a result, more serious crimes will end up being committed (the analogy being that a broken window left broken shows an image of general dilapidation).\nWilson's theories have been used to justify the implementation of zero tolerance policies by many prominent American mayors, most notably Oscar Goodman in Las Vegas, Richard Riordan in Los Angeles, Rudolph Giuliani in New York City and Gavin Newsom in San Francisco. Such policies refuse to tolerate even minor crimes; proponents argue that this will improve the quality of life of local residents. However, critics of zero tolerance policies believe that such policies neglect investigation on a case-by-case basis and may lead to unreasonably harsh penalties for crimes.\nIn healthcare.\nWithin the field of healthcare, quality of life is often regarded in terms of how a certain ailment affects a patient on an individual level. This may be a debilitating weakness that is not life-threatening; life-threatening illness that is not terminal; terminal illness; the predictable, natural decline in the health of an elder; an unforeseen mental/physical decline of a loved one; or chronic, end-stage disease processes. Researchers at the University of Toronto's Quality of Life Research Unit define quality of life as \"The degree to which a person enjoys the important possibilities of his or her life\" (UofT). Their Quality of Life Model is based on the categories \"being\", \"belonging\", and \"becoming\"; respectively who one is, how one is connected to one's environment, and whether one achieves one's personal goals, hopes, and aspirations.\nExperience sampling studies show substantial between-person variability in within-person associations between somatic symptoms and quality of life. Hecht and Shiel measure quality of life as \"the patient's ability to enjoy normal life activities\" since life quality is strongly related to wellbeing without suffering from sickness and treatment.\nIn international development.\nQuality of life has been deemed an important concept in the field of international development because it allows development to be analyzed on a measure that is generally accepted as more comprehensive than standard of living. Within development theory, however, there are varying ideas concerning what constitutes desirable change for a particular society. The different ways that quality of life is defined by institutions, therefore, shape how these organizations work for its improvement as a whole.\nOrganisations such as the World Bank, for example, declare a goal of \"working for a world free of poverty\", with poverty defined as a lack of basic human needs, such as food, water, shelter, freedom, access to education, healthcare, or employment. In other words, poverty is defined as a low quality of life. Using this definition, the World Bank works towards improving quality of life through the stated goal of lowering poverty and helping people afford a better quality of life.\nOther organizations, however, may also work towards improved global quality of life using a slightly different definition and substantially different methods. Many NGOs do not focus at all on reducing poverty on a national or international scale, but rather attempt to improve the quality of life for individuals or communities. One example would be sponsorship programs that provide material aid for specific individuals. Although many organizations of this type may still talk about fighting poverty, the methods are significantly different.\nImproving quality of life involves action not only by NGOs but also by governments. Global health has the potential to achieve greater political presence if governments were to incorporate aspects of human security into foreign policy. Stressing individuals' basic rights to health, food, shelter, and freedom addresses prominent inter-sectoral problems negatively impacting today's society, and may lead to greater action and resources. Integration of global health concerns into foreign policy may be hampered by approaches that are shaped by the overarching roles of defense and diplomacy.\nSee also.\nIndices.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47790", "revid": "8729451", "url": "https://en.wikipedia.org/wiki?curid=47790", "title": "First Nations of Canada", "text": ""}
{"id": "47791", "revid": "1934512", "url": "https://en.wikipedia.org/wiki?curid=47791", "title": "Mars program", "text": "Space program of the Soviet Union\nThe Mars program was a series of uncrewed spacecraft launched by the Soviet Union between 1960 and 1973. The spacecraft were intended to explore Mars, and included flyby probes, landers and orbiters.\nEarly Mars spacecraft were small, and launched by Molniya rockets. Starting with two failures in 1969, the heavier Proton-K rocket was used to launch larger 5 tonne spacecraft, consisting of an orbiter and a lander to Mars. The orbiter bus design was likely somewhat rushed into service and immature, considering that it performed very unreliably in the Venera variant after 1975. This reliability problem was common to much Soviet space hardware from the late 1960s and early 1970s and was largely corrected with a deliberate policy, implemented in the mid-1970s, of consolidating (or \"debugging\") existing designs rather than introducing new ones. The names of the \"Mars\" missions do not need to be translated, as the word \"Mars\" is spelled and pronounced approximately the same way in English and Russian.\nIn addition to the Mars program, the Soviet Union also sent a probe to Mars as part of the Zond program; Zond 2, however it failed en route. Two more spacecraft were sent during the Phobos program; both failed. In 1996, Russia launched Mars 96, its first interplanetary mission since the dissolution of the Soviet Union, however it failed to depart Earth orbit.\nSpacecraft.\nMars 1M.\nThe first Soviet attempts to send a probe to Mars were the two Mars 1M spacecraft, which each had a mass of about 650\u00a0kg. Both were launched in 1960 and failed to achieve orbit. The spacecraft were dubbed \"Marsnik\" by the Western media.\nMars 2MV.\nMars 1 was launched in 1962 but failed en route to Mars. Two other Soviet launches at around the same time, Mars 2MV-4 No.1 and Mars 2MV-3 No.1 were spacecraft, however both failed to leave Earth orbit due to problems with the upper stages of their carrier rockets.\nMars 2M.\nMars 2M No.521 and Mars 2M No.522, known in the West as Mars 1969A and B, were heavier spacecraft with masses of . They were launched by Proton-K rockets, and consisted of orbiters. Both were destroyed during launch.\nMars 4M.\nThe Mars 4M spacecraft; Mars 2 and Mars 3 missions consisted of identical spacecraft, each with an orbiter and an attached lander, which became the first spacecraft to reach the surface of Mars.\nThe orbiters' primary scientific objectives were to image the Martian surface and clouds, determine the temperature on Mars, study the topography, composition and physical properties of the surface, measure properties of the atmosphere, monitor the solar wind and the interplanetary and Martian magnetic fields, and act as communications relays to send signals from the landers to Earth.\nBoth landers had a small Mars rover, PrOP-M, on board, which would move across the surface on skis while connected to the lander with a 15-meter umbilical. Two small metal rods were used for autonomous obstacle avoidance, as radio signals from Earth would take too long to drive the rovers using remote control. Each rover had both a densitometer and a dynamic penetrometer, to test the density and the bearing strength of the soil. Because of the demise of the landers, neither rover saw action.\nThe Mars 2 and 3 orbiters sent back a large volume of data covering the period from December 1971 to March 1972, although transmissions continued through August. It was announced that Mars 2 and 3 had completed their missions by August 22, 1972, after 362 orbits completed by Mars 2 and 20 orbits by Mars 3. The probes sent back a total of 60 pictures. The images and data enabled creation of surface relief maps, and gave information on the Martian gravity and magnetic fields.\nMars 3MS.\nThe Mars 3MS were orbiter-only spacecraft launched three times between 1971 and 1973. The first of which,\nKosmos 419, was intended to become the first spacecraft to orbit Mars, beating NASA's Mariner 8 and Mariner 9, however it failed to leave low Earth orbit. Two additional 3MS missions, Mars 4 and Mars 5, were launched in 1973 to act as communications relay for Mars 6 and 7.\nMars 3MP.\nIn 1973 the speed required to place a spacecraft in an interplanetary trajectory had to be increased. Thus the Proton could not deliver spacecraft with an orbiter and an attached lander to the necessary trajectory to reach Mars, as had been possible in 1971. To resolve this problem, four spacecraft were launched. The Mars 4 and 5 orbiters, which had been launched separately, were used to relay communications, and to complete mission objectives which would have been completed by landers. Two landers were launched with orbiter type buses (Mars 6 and 7), but without fuel to enter orbit of the Mars satellite.\nMars 4NM and 5NM.\nThe Mars 4NM and Mars 5NM projects would have seen heavier spacecraft launched by N1 rockets. They would have deployed heavy Marsokhod rovers onto the surface, and conducted sample return missions. The N1 failed on all four of its test flights, and was never used to launch any Mars spacecraft.\nMars 5M.\nMars 5M (Mars 79) was a sample return mission developed in 1977 to be double launched in 1979 by Proton launchers and then docked in Earth orbit for a joint flight of orbital and return modules to Mars. The project was canceled due to the low reliability of the Igla automatic docking system.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47792", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=47792", "title": "Martian", "text": ""}
{"id": "47795", "revid": "37017796", "url": "https://en.wikipedia.org/wiki?curid=47795", "title": "Voyager program", "text": "Ongoing NASA interstellar program\nThe Voyager program is an American scientific program that employs two interstellar probes, \"Voyager 1\" and \"Voyager 2\". They were launched in 1977 to take advantage of a favorable planetary alignment to explore the two gas giants Jupiter and Saturn and potentially also the ice giants, Uranus and Neptune\u2014to fly near them while collecting data for transmission back to Earth. After \"Voyager 1\" successfully completed its flyby of Saturn and its moon Titan, it was decided to send \"Voyager 2\" on flybys of Uranus and Neptune. \nAfter the planetary flybys were complete, decisions were made to keep the probes in operation to explore interstellar space and the outer regions of the Solar System. On 25 August 2012, data from \"Voyager 1\" indicated that it had entered interstellar space. On 5 November 2019, data from \"Voyager 2\" indicated that it also had entered interstellar space. On 4 November 2019, scientists reported that on 5 November 2018, the \"Voyager 2\" probe had officially reached the interstellar medium (ISM), a region of outer space beyond the influence of the solar wind, as did \"Voyager 1\" in 2012. In August 2018, NASA confirmed, based on results by the \"New Horizons\" spacecraft, the existence of a \"hydrogen wall\" at the outer edges of the Solar System that was first detected in 1992 by the two Voyager spacecraft.\nAs of 2024,[ [update]] the Voyagers are still in operation beyond the outer boundary of the heliosphere in interstellar space. \"Voyager 1\" is moving with a velocity of , or 17\u00a0km/s, (10.5 miles/second) relative to the Sun, and is from the Sun reaching a distance of from Earth as of May 25, 2024. As of 2024[ [update]], \"Voyager 2\" is moving with a velocity of , or 15\u00a0km/s, relative to the Sun, and is from the Sun reaching a distance of from Earth as of May 25, 2024. \nThe two Voyagers are the only human-made objects to date that have passed into interstellar space \u2014 a record they will hold until at least the 2040s \u2014 and \"Voyager 1\" is the farthest human-made object from Earth.\nHistory.\nMariner Jupiter-Saturn.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Voyager did things no one predicted, found scenes no one expected, and promises to outlive its inventors. Like a great painting or an abiding institution, it has acquired an existence of its own, a destiny beyond the grasp of its handlers.\u2014\u200a\nThe two Voyager space probes were originally conceived as part of the Planetary Grand Tour planned during the late 1960s and early 70s that aimed to explore Jupiter, Saturn, Saturn's moon Titan, Uranus, Neptune, and Pluto. The mission originated from the Grand Tour program, conceptualized by Gary Flandro, an aerospace engineer at the Jet Propulsion Laboratory, in 1964, which leveraged a rare planetary alignment occurring once every 175 years. This alignment allowed a craft to reach all outer planets using gravitational assists. The mission was to send several pairs of probes and gained momentum in 1966 when it was endorsed by NASA's Jet Propulsion Laboratory. However, in December 1971, the Grand Tour mission was canceled when funding was redirected to the Space Shuttle program.\nIn 1972, a scaled-down (four planets, two identical spacecraft) mission was proposed, utilizing a spacecraft derived from the Mariner series, initially intended to be Mariner 11 and Mariner 12. The gravity-assist technique, successfully demonstrated by Mariner 10, would be used to achieve significant velocity changes by maneuvering through an intermediate planet's gravitational field to minimize time towards Saturn. The spacecrafts were then moved into a separate program named Mariner Jupiter-Saturn (also Mariner Jupiter-Saturn-Uranus, MJS, or MJSU), part of the Mariner program, later renamed because it was thought that the design of the two space probes had progressed sufficiently beyond that of the Mariner family to merit a separate name.\nVoyager probes.\nOn March 4, 1977, NASA announced a competition to rename the mission, believing the existing name was not appropriate as the mission had differed significantly from previous Mariner missions. \"Voyager\" was chosen as the new name, referencing an earlier suggestion by William Pickering, who had proposed the name \"Navigator\". Due to the name change occurring close to launch, the probes were still occasionally referred to as Mariner 11 and Mariner 12, or even Voyager 11 and Voyager 12.\nTwo mission trajectories were established: JST aimed at Jupiter, Saturn, and enhancing a Titan flyby, while JSX served as a contingency plan. JST focused on a Titan flyby, while JSX provided a flexible mission plan. If JST succeeded, JSX could proceed with the Grand Tour, but in case of failure, JSX could be redirected for a separate Titan flyby, forfeiting the Grand Tour opportunity. The second probe, now Voyager 2, followed the JSX trajectory, granting it the option to continue on to Uranus and Neptune. Upon Voyager 1 completing its main objectives at Saturn, Voyager 2 received a mission extension, enabling it to proceed to Uranus and Neptune. This allowed Voyager 2 to diverge from the originally planned JST trajectory.\nThe probes would be launched in August or September 1977, with their main objective being to compare the characteristics of Jupiter and Saturn, such as their atmospheres, magnetic fields, particle environments, ring systems, and moons. They would fly by planets and moons in either a JST or JSX trajectory. After completing their flybys, the probes would communicate with Earth, relaying vital data using their magnetometers, spectrometers, and other instruments to detect interstellar, solar, and cosmic radiation. Their radioisotope thermoelectric generators (RTGs) would limit the maximum communication time with the probes to roughly a decade. Following their primary missions, the probes would continue to drift into interstellar space.\n\"Voyager 2\" was the first to be launched. Its trajectory was designed to allow flybys of Jupiter, Saturn, Uranus, and Neptune. \"Voyager 1\" was launched after \"Voyager 2\", but along a shorter and faster trajectory that was designed to provide an optimal flyby of Saturn's moon Titan, which was known to be quite large and to possess a dense atmosphere. This encounter sent \"Voyager 1\" out of the plane of the ecliptic, ending its planetary science mission. Had \"Voyager 1\" been unable to perform the Titan flyby, the trajectory of \"Voyager 2\" could have been altered to explore Titan, forgoing any visit to Uranus and Neptune. \"Voyager 1\" was not launched on a trajectory that would have allowed it to continue to Uranus and Neptune, but could have continued from Saturn to Pluto without exploring Titan.\nDuring the 1990s, \"Voyager 1\" overtook the slower deep-space probes Pioneer 10 and Pioneer 11 to become the most distant human-made object from Earth, a record that it will keep for the foreseeable future. The \"New Horizons\" probe, which had a higher launch velocity than \"Voyager 1\", is travelling more slowly due to the extra speed \"Voyager 1\" gained from its flybys of Jupiter and Saturn. \"Voyager 1\" and Pioneer 10 are the most widely separated human-made objects anywhere since they are travelling in roughly opposite directions from the Solar System.\nIn December 2004, \"Voyager 1\" crossed the termination shock, where the solar wind is slowed to subsonic speed, and entered the heliosheath, where the solar wind is compressed and made turbulent due to interactions with the interstellar medium. On 10 December 2007, \"Voyager 2\" also reached the termination shock, about closer to the Sun than from where \"Voyager 1\" first crossed it, indicating that the Solar System is asymmetrical.\nIn 2010 \"Voyager 1\" reported that the outward velocity of the solar wind had dropped to zero, and scientists predicted it was nearing interstellar space. In 2011, data from the Voyagers determined that the heliosheath was not smooth, but filled with giant magnetic bubbles. It was theorized that they formed when the magnetic field of the Sun became warped at the edge of the Solar System.\nIn June 2012, scientists at NASA reported that \"Voyager 1\" was very close to entering interstellar space, which was indicated by a sharp rise in high-energy particles from outside the Solar System. In September 2013, NASA announced that \"Voyager 1\" had crossed the heliopause on 25 August 2012, making it the first spacecraft to enter interstellar space.\nIn December 2018, NASA announced that \"Voyager 2\" had crossed the heliopause on 5 November 2018, making it the second spacecraft to enter interstellar space.\nAs of 2017[ [update]] \"Voyager 1\" and \"Voyager 2\" continued to monitor conditions in the outer expanses of the Solar System. The Voyager spacecraft were expected to be able to operate science instruments through 2020, when limited power would require instruments to be deactivated one by one. It was expected that circa 2025 there would no longer be sufficient power to operate any scientific instruments.\nIn July 2019, a revised power management plan was implemented for the two probes' dwindling power supplies.\nSpacecraft design.\nThe Voyager spacecraft each weighed at launch, but after fuel usage are now about . Of this weight, each spacecraft carries of scientific instruments. The identical Voyager spacecraft use three-axis-stabilized guidance systems that use gyroscopic and accelerometer inputs to their attitude control computers to point their high-gain antennas towards the Earth and their scientific instruments towards their targets, sometimes with the help of a movable instrument platform for the smaller instruments and the electronic photography system.\nThe diagram shows the high-gain antenna (HGA) with a diameter dish attached to the hollow decagonal electronics container. There is also a spherical tank that contains the hydrazine monopropellant fuel.\nThe Voyager Golden Record is attached to one of the bus sides. The angled square panel to the right is the optical calibration target and excess heat radiator. The three radioisotope thermoelectric generators (RTGs) are mounted end-to-end on the lower boom.\nThe scan platform comprises: the Infrared Interferometer Spectrometer (IRIS) (largest camera at top right); the Ultraviolet Spectrometer (UVS) just above the IRIS; the two Imaging Science Subsystem (ISS) vidicon cameras to the left of the UVS; and the Photopolarimeter System (PPS) under the ISS.\nOnly five investigation teams are still supported, though data is collected for two additional instruments.\nThe Flight Data Subsystem (FDS) and a single eight-track digital tape recorder (DTR) provide the data handling functions.\nThe FDS configures each instrument and controls instrument operations. It also collects engineering and science data and formats the data for transmission. The DTR is used to record high-rate Plasma Wave Subsystem (PWS) data, which is played back every six months.\nThe Imaging Science Subsystem made up of a wide-angle and a narrow-angle camera is a modified version of the slow scan vidicon camera designs that were used in the earlier Mariner flights. The Imaging Science Subsystem consists of two television-type cameras, each with eight filters in a commandable filter wheel mounted in front of the vidicons. One has a low resolution focal length wide-angle lens with an aperture of f/3 (the wide-angle camera), while the other uses a higher resolution narrow-angle f/8.5 lens (the narrow-angle camera).\nThree spacecraft were built, \"Voyager 1\" (VGR 77-1), \"Voyager 2\" (VGR 77-3), and test spare model (VGR 77-2).\nComputers and data processing.\nThere are three different computer types on the Voyager spacecraft, two of each kind, sometimes used for redundancy. They are proprietary, custom-built computers built from CMOS and TTL medium-scale CMOS integrated circuits and discrete components, mostly from the 7400 series of Texas Instruments. Total number of words among the six computers is about 32K. Voyager\u00a01 and Voyager\u00a02 have identical computer systems.\nThe Computer Command System (CCS), the central controller of the spacecraft, has two 18-bit word, interrupt-type processors with 4096 words each of non-volatile plated-wire memory. During most of the Voyager mission the two CCS computers on each spacecraft were used non-redundantly to increase the command and processing capability of the spacecraft. The CCS is nearly identical to the system flown on the Viking spacecraft.\nThe Flight Data System (FDS) is two 16-bit word machines with modular memories and 8198 words each.\nThe Attitude and Articulation Control System (AACS) is two 18-bit word machines with 4096 words each.\nUnlike the other on-board instruments, the operation of the cameras for visible light is not autonomous, but rather it is controlled by an imaging parameter table contained in one of the on-board digital computers, the Flight Data Subsystem (FDS). More recent space probes, since about 1990, usually have completely autonomous cameras.\nThe computer command subsystem (CCS) controls the cameras. The CCS contains fixed computer programs such as command decoding, fault detection, and correction routines, antenna-pointing routines, and spacecraft sequencing routines. This computer is an improved version of the one that was used in the \"Viking\" orbiter. The hardware in both custom-built CCS subsystems in the Voyagers is identical. There is only a minor software modification for one of them that has a scientific subsystem that the other lacks.\nAccording to Guinness Book of Records, CCS holds record of \"longest period of continual operation for a computer\". It has been running continuously since 20 August 1977.\nThe Attitude and Articulation Control Subsystem (AACS) controls the spacecraft orientation (its attitude). It keeps the high-gain antenna pointing towards the Earth, controls attitude changes, and points the scan platform. The custom-built AACS systems on both craft are identical.\nIt has been erroneously reported on the Internet that the Voyager space probes were controlled by a version of the RCA\u00a01802 (RCA CDP1802 \"COSMAC\" microprocessor), but such claims are not supported by the primary design documents. The CDP1802 microprocessor was used later in the \"Galileo\" space probe, which was designed and built years later. The digital control electronics of the Voyagers were not based on a microprocessor integrated-circuit chip.\nCommunications.\nThe uplink communications are executed via S-band microwave communications. The downlink communications are carried out by an X-band microwave transmitter on board the spacecraft, with an S-band transmitter as a back-up. All long-range communications to and from the two Voyagers have been carried out using their high-gain antennas. The high-gain antenna has a beamwidth of 0.5\u00b0 for X-band, and 2.3\u00b0 for S-band. (The low-gain antenna has a 7\u00a0dB gain and 60\u00b0 beamwidth.)\nBecause of the inverse-square law in radio communications, the digital data rates used in the downlinks from the Voyagers have been continually decreasing the farther that they get from the Earth. For example, the data rate used from Jupiter was about 115,000 bits per second. That was halved at the distance of Saturn, and it has gone down continually since then. Some measures were taken on the ground along the way to reduce the effects of the inverse-square law. In between 1982 and 1985, the diameters of the three main parabolic dish antennas of the Deep Space Network were increased from dramatically increasing their areas for gathering weak microwave signals.\nWhilst the craft were between Saturn and Uranus the onboard software was upgraded to do a degree of image compression and to use a more efficient Reed-Solomon error-correcting encoding.\nThen between 1986 and 1989, new techniques were brought into play to combine the signals from multiple antennas on the ground into one, more powerful signal, in a kind of an antenna array. This was done at Goldstone, California, Canberra (Australia), and Madrid (Spain) using the additional dish antennas available there. Also, in Australia, the Parkes Radio Telescope was brought into the array in time for the fly-by of Neptune in 1989. In the United States, the Very Large Array in New Mexico was brought into temporary use along with the antennas of the Deep Space Network at Goldstone. Using this new technology of antenna arrays helped to compensate for the immense radio distance from Neptune to the Earth.\nPower.\nElectrical power is supplied by three MHW-RTG radioisotope thermoelectric generators (RTGs). They are powered by plutonium-238 (distinct from the Pu-239 isotope used in nuclear weapons) and provided approximately 470 W at 30 volts DC when the spacecraft was launched. Plutonium-238 decays with a half-life of 87.74 years, so RTGs using Pu-238 will lose a factor of 1\u22120.5(1/87.74) = 0.79% of their power output per year.\nIn 2011, 34 years after launch, the thermal power generated by such an RTG would be reduced to (1/2)(34/87.74) \u2248 76% of its initial power. The RTG thermocouples, which convert thermal power into electricity, also degrade over time reducing available electric power below this calculated level.\nBy 7 October 2011 the power generated by \"Voyager 1\" and \"Voyager 2\" had dropped to 267.9 W and 269.2 W respectively, about 57% of the power at launch. The level of power output was better than pre-launch predictions based on a conservative thermocouple degradation model. As the electrical power decreases, spacecraft loads must be turned off, eliminating some capabilities. There may be insufficient power for communications by 2032.\nVoyager Interstellar Mission.\nThe Voyager primary mission was completed in 1989, with the close flyby of Neptune by \"Voyager 2\". The Voyager Interstellar Mission (VIM) is a mission extension, which began when the two spacecraft had already been in flight for over 12 years. The Heliophysics Division of the NASA Science Mission Directorate conducted a Heliophysics Senior Review in 2008. The panel found that the VIM \"is a mission that is absolutely imperative to continue\" and that VIM \"funding near the optimal level and increased DSN (Deep Space Network) support is warranted.\"\nThe main objective of the VIM was to extend the exploration of the Solar System beyond the outer planets to the heliopause (the farthest extent at which the Sun's radiation predominates over interstellar winds) and if possible even beyond. Voyager 1 crossed the heliopause boundary in 2012, followed by Voyager 2 in 2018. Passing through the heliopause boundary has allowed both spacecraft to make measurements of the interstellar fields, particles and waves unaffected by the solar wind. Two significant findings so far have been the discovery of a region of magnetic bubbles and no indication of an expected shift in the Solar magnetic field.\nThe entire \"Voyager 2\" scan platform, including all of the platform instruments, was switched off in 1998. All platform instruments on \"Voyager 1\", except for the ultraviolet spectrometer (UVS) have also been switched off.\nThe \"Voyager 1\" scan platform was scheduled to go off-line in late 2000 but has been left on to investigate UV emission from the upwind direction.\nUVS data are still captured but scans are no longer possible.\nGyro operations ended in 2016 for \"Voyager 2\" and in 2017 for \"Voyager 1\". Gyro operations are used to rotate the probe 360 degrees six times per year to measure the magnetic field of the spacecraft, which is then subtracted from the magnetometer science data.\nOn 14 November 2023, Voyager 1 stopped sending all telemetry and data, though the signal was still present. After months of experiments, made considerably more difficult by the 45 hour round trip time, the cause was traced to a bad memory chip. New software was written to avoid the bad memory block, and engineering data resumed on 20 April 2024. Science data from two instruments resumed in May 2024, and full recovery (of all science instruments that were still powered up) was in June 2024. For more details of this intricate operation, see Voyager 1.\nThe two spacecraft continue to operate, with some loss in subsystem redundancy but retain the capability to return scientific data from a full complement of Voyager Interstellar Mission (VIM) science instruments.\nBoth spacecraft also have adequate electrical power and attitude control propellant to continue operating and collecting science data through at least 2026. Though additional science instruments may need to be turned off, the spacecraft are expected to be able to communicate until 2036, in the absence of additional failures.\nMission details.\nBy the start of VIM, \"Voyager 1\" was at a distance of 40 AU from the Earth, while \"Voyager 2\" was at 31 AU. VIM is in three phases: termination shock, heliosheath exploration, and interstellar exploration phase. The spacecraft began VIM in an environment controlled by the Sun's magnetic field, with the plasma particles being dominated by those contained in the expanding supersonic solar wind. This is the characteristic environment of the termination shock phase. At some distance from the Sun, the supersonic solar wind will be held back from further expansion by the interstellar wind. The first feature encountered by a spacecraft as a result of this interaction \u2013 between interstellar wind and solar wind \u2013 was the termination shock, where the solar wind slows to subsonic speed, and large changes in plasma flow direction and magnetic field orientation occur. \"Voyager 1\" completed the phase of termination shock in December 2004 at a distance of 94 AU, while \"Voyager 2\" completed it in August 2007 at a distance of 84 AU. After entering into the heliosheath, the spacecraft were in an area that is dominated by the Sun's magnetic field and solar wind particles. After passing through the heliosheath, the two Voyagers began the phase of interstellar exploration. The outer boundary of the heliosheath is called the heliopause. This is the region where the Sun's influence begins to decrease and interstellar space can be detected. \n\"Voyager 1\" is escaping the Solar System at the speed of 3.6 AU per year 35\u00b0 north of the ecliptic in the general direction of the solar apex in Hercules, while \"Voyager 2\"'s speed is about 3.3 AU per year, heading 48\u00b0 south of the ecliptic. The Voyager spacecraft will eventually go on to the stars. In about 40,000 years, \"Voyager 1\" will be within 1.6 light years (ly) of AC+79 3888, also known as Gliese 445, which is approaching the Sun. In 40,000 years \"Voyager 2\" will be within 1.7 ly of Ross 248 (another star which is approaching the Sun), and in 296,000 years it will pass within 4.6 ly of Sirius, which is the brightest star in the night-sky. The spacecraft are not expected to collide with a star for 1 sextillion (1020) years.\nIn October 2020, astronomers reported a significant unexpected increase in density in the space beyond the Solar System, as detected by the Voyager space probes. According to the researchers, this implies that \"the density gradient is a large-scale feature of the VLISM (very local interstellar medium) in the general direction of the heliospheric nose\".\nVoyager Golden Record.\nBoth spacecraft carry a golden phonograph record that contains pictures and sounds of Earth, symbolic directions on the cover for playing the record, and data detailing the location of Earth. The record is intended as a combination time capsule and an interstellar message to any civilization, alien or far-future human, that may recover either of the Voyagers. The contents of this record were selected by a committee that included Timothy Ferris and was chaired by Carl Sagan.\n\"Pale Blue Dot\".\n\"Pale Blue Dot\" is a photograph of Earth taken on February 14, 1990, by the \"Voyager 1\" space probe from a distance of approximately 6 billion kilometers (3.7 billion miles, 40.5 AU), as part of that day's \"Family Portrait\" series of images of the Solar System.\nThe Voyager program's discoveries during the primary phase of its mission, including new close-up color photos of the major planets, were regularly documented by print and electronic media outlets. Among the best-known of these is an image of the Earth as a \"Pale Blue Dot\", taken in 1990 by \"Voyager 1\", and popularized by Carl Sagan,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Consider again that dot. That's here. That's home. That's us...The Earth is a very small stage in a vast cosmic arena... To my mind, there is perhaps no better demonstration of the folly of human conceits than this distant image of our tiny world. To me, it underscores our responsibility to deal more kindly and compassionately with one another and to preserve and cherish that pale blue dot, the only home we've ever known.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nNASA sites\nNASA instrument information pages:\nNon-NASA sites"}
{"id": "47796", "revid": "50560774", "url": "https://en.wikipedia.org/wiki?curid=47796", "title": "Patience", "text": "Ability to endure difficult circumstances\nPatience, or forbearance, is the ability to endure difficult or undesired long-term circumstances. Patience involves patience or tolerance in the face of delay, provocation, or stress without responding negatively, such as reacting with disrespect or anger. Patience is also used to refer to the character trait of being disciplined and steadfast. Antonyms of patience include impatience, , and impetuousness.\nScientific perspectives.\nIn psychology and in cognitive neuroscience, patience is studied as a decision-making problem, involving the choice of either a small reward in the short-term, versus a more valuable reward in the long-term.\nIn a 2005 study, common marmosets and cottontop tamarins chose between taking an immediate small reward and waiting a variable amount of time for a large reward. Under these conditions, marmosets waited significantly longer for food than tamarins. This difference cannot be explained by life history, social behaviour, or brain size. It can, however, be explained by feeding ecology: marmosets rely on gum, a food product acquired by waiting for exudate to flow from trees, whereas tamarins feed on insects, a food product requiring impulsive action. Foraging ecology, therefore, may provide a selective pressure for the evolution of self-control.\nPatience of human users in the online world has been a subject of research. In a 2012 study of tens of millions of users who watched videos on the Internet, Krishnan and Sitaraman showed that users lose patience in as little as two seconds while waiting for their chosen video to start playing. Users who connect to the Internet at faster speeds are less patient than their counterparts at slower speeds, demonstrating a link between the human expectation of speed and human patience. These and other studies of patience led commentators to conclude that the rapid pace of technology is rewiring humans to be less patient.\nReligious perspectives.\nJudaism.\nPatience and fortitude are prominent themes in Judaism. The Talmud extols patience as an important personal trait. The story of Micah, for example, is that he suffers many challenging conditions and yet endures, saying \"I will wait for the God who saves me.\" Patience in God, it is said, will aid believers in finding the strength to be delivered from the evils that are inherent in the physical life.\nIn the Hebrew Torah, patience is referred to in several proverbs, such as \"The patient man shows much good sense, but the quick-tempered man displays folly at its height\" (); \"An ill-tempered man stirs up strife, but a patient man allays discord.\" (); and \"A patient man is better than a warrior, and he who rules his temper, than he who takes a city.\" (). Patience is also discussed in other sections, such as Ecclesiastes: \"Better is the patient spirit than the lofty spirit. Do not in spirit become quickly discontented, for discontent lodges in the bosom of a fool.\" ().\nChristianity.\nIn the Christian religion, patience is one of the most valuable virtues. The Holy Ghost increases patience in the Christian who has accepted the gift of salvation. While patience is not one of the traditional biblical three theological virtues or one of the traditional cardinal virtues, it is part of the fruit of the Holy Spirit, according to the Apostle Paul in his Epistle to the Galatians. Patience was included in later formulations of the seven virtues.\nIn the Christian Bible, patience is referred to in several sections. The Book of Proverbs notes that \"through patience a ruler can be persuaded, and a gentle tongue can break a bone\" (, NIV); Ecclesiastes points out that the \"end of a matter is better than its beginning, and patience is better than pride\" (, NIV); and 1 Thessalonians states that we should \"be patient with all. See that no one returns evil for evil; rather, always seek what is good for each other and for all\" (, NAB). In the Epistle of James, the Bible urges Christians to be patient, and \"see how the farmer waits for the precious fruit of the earth... until it receives the early and the late rains.\" (, NAB). In Galatians, patience is listed as part of the \"fruit of the Spirit\": \"love, joy, peace, patience, kindness, goodness, faithfulness, gentleness, and self-control. Against such things there is no law\" (, NIV). In Timothy, the Bible states that \"Jesus might display his unlimited patience as an example for those who would believe on him and receive eternal life\" ( NIV).\nIslam.\nPatience with steadfast belief in Allah is called (), one of the best virtues in Islam. Through , a Muslim believes that an individual can grow closer to God and thus attain true peace. Islam stresses that Allah is with those who are patient, more specifically during calamity and suffering. Several verses in Quran urge Muslims to seek Allah's help when faced with fear and loss, with patient prayers and perseverance for Allah. For example:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We will certainly test you with a touch of fear and famine and loss of property, life, and crops. Give good news to those who patiently endure\u2014 who, when faced with a disaster, say, \u201cSurely to Allah we belong and to Him we will \u02f9all\u02fa return.\u201d\nSimilarly, patience is mentioned in hadith Sahih Bukhari:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Narrated Aisha: I asked Allah's ras\u016bl about the plague. He said, \"That was a means of torture which Allah used to send upon whomsoever He wished, but He made it a source of mercy for the believers, for anyone who is residing in a town in which this disease is present, and remains there and does not leave that town, but has patience and hopes for Allah's reward, and knows that nothing will befall him except what Allah has written for him, then he will get such reward as that of a martyr.\"\u2014\u200a\nIn Islamic tradition, Job (Arabic: , romanized: ) demonstrated patience and steadfast belief in Allah. Ibn Kathir narrates the story in this manner: Job was a very rich person with much land, and many animals and children \u2014 all of which were lost and soon he was struck with disease as a test from Allah. He remained steadfast and patient in his prayers to Allah, so Allah eventually relieved him of the disease, gave him double the money he lost, and raised to life twice the number of children who had died before him.\nBuddhism.\nIn Buddhism, patience (Skt.: ; Pali: ) is one of the \"perfections\" () that a bodhisattva trains in and practices to realize perfect enlightenment (). The Buddhist concept of patience is distinct from the English definition of the word. In Buddhism, patience refers to not returning harm, rather than merely enduring a difficult situation. It is the ability to control one's emotions even when being criticized or attacked. Verse 184 of the Dhammapada says \"enduring patience is the highest austerity\".\nTibetan Buddhist Thubten Zopa recommended that people train in forbearance by taking advantage of encounters with difficult people:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Ask yourself, \"Where did I learn this patience that I practice? I learned it from those who have been angry at me... Therefore, all the peace and happiness that I enjoy in this and future lives as a result of my practice of patience has come from the angry person... How kind this person is! How much benefit this person has given me!\"\nHinduism.\nPatience/forbearance is considered an essential virtue in Hinduism. In ancient literature of Hinduism, the concept of patience is referred to with the word (patience and forbearance, Sanskrit: ), and several other words such as (patient toleration, Sanskrit: ), (forbearance, Sanskrit: ), or (suffer with patience, Sanskrit: , ) and several others.\nPatience, in Hindu philosophy, is the cheerful endurance of trying conditions and the consequence of one's action and deeds (karma). It is also the capacity to wait, to endure opposites\u2014such as pain and pleasure, cold and heat, sorrows and joys\u2014calmly, without anxiety, and without a desire to seek revenge. In interpersonal relationships, virtuous means that if someone attacks or insults without cause, one must endure it without feeling enmity, anger, resentment, or anxiety. Patience is explained as being more than trust, as a value that reflects the state of one's body and mind. The term is sometimes also translated as test or exam, in other contexts. Some of these concepts have been carried into the spiritual understanding of yoga. Sandilya Upanishad of Hinduism identifies ten sources of patience and forbearance. In each of these ten forbearances, the virtuous implicit belief is that our current spirit and the future for everyone, including oneself, will be stronger if these forbearances are one's guide. The ten are:\nThe classical literature of Hinduism exists in many Indian languages. For example, \"Tirukku\u1e5ba\u1e37\" written between \u00a0BCE and \u00a0CE, and sometimes called the Tamil Veda, is one of the most cherished classics on Hinduism written in a South Indian language. It too discusses patience and forbearance, dedicating Chapter 16 of Book 1 to that topic. \"Tirukku\u1e5ba\u1e37\" suggests \"patience\" is necessary for an ethical life and for one's long term happiness, even if patience is sometimes difficult in the short term. Excerpts from this book include: \"our conduct must always foster forbearance\"; \"one must patiently endure rude remarks, because it delivers us to purity\"; \"if we are unjustly wronged by others, it is best to conquer our hurt with patience, accept suffering, and refrain from unrighteous retaliation\"; \"it is good to patiently endure injuries done to you, but to forget them is even better\"; \"just as the Earth bears those who dig into her, one must with patience bear with those who despise us\", and so on.\nMeher Baba.\nThe spiritual teacher Meher Baba stated that \"[O]ne of the first requirements of the [spiritual] aspirant is that he should combine \"unfailing enthusiasm with unyielding patience\"... Spiritual effort demands not only physical endurance and courage, but also unshrinking forbearance and unassailable moral courage.\"\nPhilosophical perspectives.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;(What cannot be quite cured, is made easier by patience)\u2014\u200a\nIn his 1878 book \"Human, All Too Human\", philosopher Friedrich Nietzsche argued that \"being able to wait is so hard that the greatest poets did not disdain to make the inability to wait the theme of their poetry\". He notes that \"Passion will not wait\", and gives the example of cases of duels, in which the \"advising friends have to determine whether the parties involved might be able to wait a while longer. If they cannot, then a duel is reasonable [because]... to wait would be to continue suffering the horrible torture of offended honor...\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47798", "revid": "20957809", "url": "https://en.wikipedia.org/wiki?curid=47798", "title": "Trogon", "text": "Family of birds\nThe trogons and quetzals are birds in the order Trogoniformes which contains only one family, the Trogonidae. The family Trogonidae contains 49 species in seven genera. The fossil record of the trogons dates back 49 million years to the Early Eocene. They might constitute a member of the basal radiation of the order Coraciiformes and order Passeriformes or be closely related to mousebirds and owls. The word \"trogon\" is Greek for \"nibbling\" and refers to the fact that these birds gnaw holes in trees to make their nests.\nTrogons are residents of tropical forests worldwide. The greatest diversity is in the Neotropics, where four genera, containing 34 species, occur. The genus \"Apaloderma\" contains the three African species. The genera \"Harpactes\" and \"Apalharpactes\", containing twelve species, are found in southeast Asia.\nThey feed on insects and fruit, and their broad bills and weak legs reflect their diet and arboreal habits. Although their flight is fast, they are reluctant to fly any distance. Trogons are generally not migratory, although some species undertake partial local movements. Trogons have soft, often colourful, feathers with distinctive male and female plumage. They are the only type of animal with a heterodactyl toe arrangement. They nest in holes dug into trees or termite nests, laying 2\u20134 white or pastel-coloured eggs.\nEvolution and taxonomy.\nThe position of the trogons within the class Aves has been a long-standing mystery. A variety of relations have been suggested, including the parrots, cuckoos, toucans, jacamars and puffbirds, rollers, owls and nightjars. More recent morphological and molecular evidence has suggested a relationship with the Coliiformes. The unique arrangement of the toes on the foot (see morphology and flight) has led many to consider the trogons to have no close relatives; this would place them in their own order, possibly with the similarly atypical mousebirds as their closest relatives.\nThe earliest formally described fossil specimen is a cranium from the Fur Formation Lower Eocene in Denmark (54 mya). Other trogoniform fossils have been found in the Messel pit deposits from the mid-Eocene in Germany (49 mya), and in Oligocene and Miocene deposits from Switzerland and France respectively. The oldest New World fossil of a trogon is from the comparatively recent Pleistocene (less than 2.588 mya).\nThe family had been thought to have an Old World origin notwithstanding the current richness of the family, which is more diverse in the Neotropical New World. DNA evidence seemed to support an African origin for the trogons, with the African genus \"Apaloderma\" seemingly basal in the family, and the other two lineages, the Asian and American, breaking off 20\u201336 million years ago. More recent studies show that the DNA evidence gives contradictory results concerning the basal phylogenetic relationships; so it is currently unknown if all extant trogons are descended from an African ancestor, an American ancestor or neither.\nThe trogons are split into three subfamilies, each reflecting one of these splits. Aplodermatinae is the African subfamily and contains a single genus, \"Apaloderma\". Harpactinae is the Asian subfamily and contains two genera, \"Harpactes\" and \"Apalharpactes\". \"Apalharpactes\", consisting of two species in Java and Sumatra, has only recently been accepted as a separate genus from \"Harpactes\". The remaining subfamily, the Neotropical Trogoninae, contains the remaining four genera, \"Trogon\", \"Priotelus\", \"Pharomachrus\" and \"Euptilotis\".\nThe two Caribbean species of \"Priotelus\" are extremely ancient. The two quetzal genera, \"Pharomachrus\" and \"Euptilotis\" are possibly derived from the final and most numerous genus of trogons in the Neotropics, \"Trogon\". A 2008 study of the genetics of \"Trogon\" suggested the genus originated in Central America and radiated into South America after the formation of the Isthmus of Panama (as part of the Great American Interchange), thus making trogons relatively recent arrivals in South America.\nDistribution and habitat.\nThe majority of trogons are birds of tropical and subtropical forests. They have a cosmopolitan distribution in the worlds wet tropics, being found in the Americas, Africa and Asia. A few species are distributed into the temperate zone, with one species, the elegant trogon, reaching the south of the United States, specifically southern Arizona and the surrounding area. The Narina trogon of Africa is slightly exceptional in that it utilises a wider range of habitats than any other trogon, ranging from dense forest to fairly open savannah, and from the Equator to southern South Africa. It is the most widespread and successful of all the trogons. The eared quetzal of Mexico is also able to use more xeric habitats, but preferentially inhabits forests. Most other species are more restricted in their habitat, with several species being restricted to undisturbed primary forest. Within forests they tend to be found in the mid-story, occasionally in the canopy.\nSome species, particularly the quetzals, are adapted to cooler montane forest. There are a number of insular species; these include a number of species found in the Greater Sundas, one species in the Philippines as well as two species endemic to Cuba and Hispaniola respectively. Outside of South East Asia and the Caribbean, however, trogons are generally absent from islands, especially oceanic ones.\nTrogons are generally sedentary, with no species known to undertake long migrations. A small number of species are known to make smaller migratory movements, particularly montane species which move to lower altitudes during different seasons. This has been demonstrated using radio tracking in the resplendent quetzal in Costa Rica and evidence has been accumulated for a number of other species. The Narina trogon of Africa is thought to undertake some localised short-distance migrations over parts of its range, for example birds of Zimbabwe's plateau savannah depart after the breeding season. A complete picture of these movements is however lacking. Trogons are difficult to study as their thick tarsi (feet bones) make ringing studies difficult.\nMorphology and flight.\nThe trogons as a family are fairly uniform in appearance, having compact bodies and long tails (very long in the case of the quetzals), and short necks. Trogons range in size from the , scarlet-rumped trogon to the , resplendent quetzal (not including the male quetzal's tail streamers). Their legs and feet are weak and short, and trogons are essentially unable to walk beyond a very occasional shuffle along a branch. They are even incapable of turning around on a branch without using their wings. The ratio of leg muscle to body weight in trogons is only 3%, the lowest known ratio of any bird. The arrangement of toes on the feet of trogons is also unique among birds, although essentially resembling the zygodactyl's two forward two backward arrangement of parrots and other near-passerines, the actual toes are arranged with usually inner hallux being the outer hind toe, an arrangement that is referred to as heterodactylous. The strong bill is short and the gape wide, particularly in the fruit eating quetzals, with a slight hook at the end. There is also a notch at the end of the bill and many species have slight serrations in the mandibles. The skin is exceptionally tender, making preparation of study skins difficult for museum curators. The skeletons of trogons are surprisingly slender, particularly the skulls which are very thin. The plumage of many species is iridescent, although not in most of the Asian species. The African trogons are generally green on the back with red bellies. The New World trogons similarly have green or deep blue upperparts but are more varied in their lowerparts. The Asian species tend towards red underparts and brown backs.\nThe wings are short but strong, with the wing muscle ratio being around 22% of the body weight. In spite of the strength of their flight, trogons do not fly often or for great distances, generally flying no more than a few hundred metres at a time. Only the montane species tend to make long-distance flights. Shorter flights tend to be direct and swift, but longer flights are slightly undulating. Their flight can be surprisingly silent (for observers), although that of a few species is reportedly quite noisy.\nCalls.\nThe calls of trogons are generally loud and uncomplex, consisting of monosyllabic hoots and whistles delivered in varying patterns and sequences. The calls of the quetzals and the two Caribbean genera are the most complex. Among the Asian genera the Sumatran trogon (\"Apalharpactes\") has the most atypical call of any trogon, research has not yet established whether the closely related Javan trogon has a similar call. The calls of the other Asian genus, \"Harpactes\", are remarkably uniform. In addition to the territorial and breeding calls given by males and females during the breeding seasons, trogons have been recorded as having aggression calls given by competing males and alarm calls.\nBehaviour.\nTrogons are generally inactive outside of infrequent feeding flights. Among birdwatchers and biologists it has been noted that \"[a]part from their great beauty [they] are notorious ... for their lack of other immediately engaging qualities\". Their lack of activity is possibly a defence against predation; trogons on all continents have been reported to shift about on branches to always keep their less brightly coloured backs turned towards observers, while their heads, which like owls can turn through 180 degrees, keep a watch on the watcher. Trogons have reportedly been preyed upon by hawks and predatory mammals; one report was of a resplendent quetzal taken while brooding young by a margay.\nDiet and feeding.\nTrogons feed principally on insects, other arthropods, and fruit; to a lesser extent some small vertebrates such as lizards are taken. Among the insect prey taken one of the more important types are caterpillars; along with cuckoos, trogons are one of the few birds groups to regularly prey upon them. Some caterpillars are known to be poisonous to trogons though, like \"Arsenura armida. \"The extent to which each food type is taken varies depending on geography and species. The three African trogons are exclusively insectivorous, whereas the Asian and American genera consume varying amounts of fruit. Diet is somewhat correlated with size, with larger species feeding more on fruit and smaller species focusing on insects.\nPrey is almost always obtained on the wing. The most commonly employed foraging technique is a sally-glean flight, where a trogon flies from an observation perch to a target on another branch or in foliage. Once there the birds hovers or stalls and snatches the item before returning to its perch to consume the item. This type of foraging is commonly used by some types of bird to obtain insect prey; in trogons and quetzals it is also used to pluck fruit from trees. Insect prey may also be taken on the wing, with the trogon pursuing flying insects in a similar manner to drongos and Old World flycatchers. Frogs, lizards and large insects on the ground may also be pounced on from the air. More rarely some trogons may shuffle along a branch to obtain insects, insect eggs and very occasionally nestling birds. Violaceous trogons will consume wasps and wasp larvae encountered while digging nests.\nBreeding.\nTrogons are territorial and monogamous. Males will respond quickly to playbacks of their calls and will repel other members of the same species and even other hole-nesting species from around their nesting sites. Males attract females by singing, and, in the case of the resplendent quetzal, undertaking display flights. Some species have been observed in small flocks of 3\u201312 individuals prior to and sometimes during the breeding season, calling and chasing each other, but the function of these flocks is unclear.\nTrogons are cavity nesters. Nests are dug into rotting wood or termite nests, with one species, the violaceous trogon, nesting in wasp nests. Nest cavities can either be deep upward slanting tubes that lead to fully enclosed chambers, or much shallower open niches (from which the bird is visible). Nests are dug with the beak, incidentally giving the family its name. Nest digging may be undertaken by the male alone or by both sexes. In the case of nests dug into tree trunks, the wood must be strong enough not to collapse but soft enough to dig out. Trogons have been observed landing on dead tree trunks and slapping the wood with their tails, presumably to test the firmness.\nThe nests of trogons are thought to usually be unlined. Between two and four eggs are laid in a nesting attempt. These are round and generally glossy white or lightly coloured (buff, grey, blue or green), although they get increasingly dirty during incubation. Both parents incubate the eggs (except in the case of the bare-cheeked trogon, where apparently the male takes no part), with the male taking one long incubation stint a day and the female incubating the rest of the time. Incubation seems to begin after the last egg is laid. The incubation period varies by species, usually lasting between 16\u201319 days. On hatching the chicks are altricial, blind and naked. The chicks acquire feathers rapidly in some of the montane species, in the case of the mountain trogon in a week, but more slowly in lowland species like the black-headed trogon, which may take twice as long. The nestling period varies by species and size, with smaller species generally taking 16 to 17 days to fledge, whereas larger species may take as long as 30 days, although 23\u201325 days is more typical.\nRelationship with people.\nTrogons and quetzals are considered to be \"among the most beautiful of birds\", yet they are also often reclusive and seldom seen. Little is known about much of their biology, and much of what is known about them comes from the research of neotropical species by the ornithologist Alexander Skutch. Trogons are nevertheless popular birds with birdwatchers, and there is a modest ecotourism industry in particular to view quetzals in Central America.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "47801", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=47801", "title": "H.M.S. Pinafore", "text": "1878 comic opera by Gilbert &amp; Sullivan\nH.M.S. Pinafore; or, The Lass That Loved a Sailor is a comic opera in two acts, with music by Arthur Sullivan and a libretto by W. S. Gilbert. It opened at the Opera Comique in London on 25 May 1878, and ran for 571\u00a0performances, which was the second-longest run of any musical theatre piece up to that time. \"H.M.S. Pinafore\" was Gilbert and Sullivan's fourth operatic collaboration and their first international sensation.\nThe story takes place aboard the Royal Navy ship HMS \"Pinafore\". The captain's daughter, Josephine, is in love with a lower-class sailor, Ralph Rackstraw, although her father intends her to marry Sir Joseph Porter, the First Lord of the Admiralty. She abides by her father's wishes at first, but Sir Joseph's advocacy of the equality of humankind encourages Ralph and Josephine to overturn conventional social order. They declare their love for each other and eventually plan to elope. The Captain discovers this plan, but, as in many of the Gilbert and Sullivan operas, a surprise disclosure changes things dramatically near the end of the story.\nDrawing on several of his earlier \"Bab Ballad\" poems, Gilbert imbued this plot with mirth and absurdity. The opera's humour focuses on love between members of different social classes and lampoons the British class system in general. \"Pinafore\" also pokes good-natured fun at patriotism, party politics, the Royal Navy, and the rise of unqualified people to positions of authority. The title of the piece comically applies the name of a garment for girls and women, a pinafore, to the fearsome symbol of a warship.\n\"Pinafore\"'s extraordinary popularity in Britain, America and elsewhere was followed by the similar success of a series of Gilbert and Sullivan works, including \"The Pirates of Penzance\" and \"The Mikado\". Their works, later known as the Savoy operas, dominated the musical stage on both sides of the Atlantic for more than a decade and continue to be performed today. The structure and style of these operas, particularly \"Pinafore\", were much copied and contributed significantly to the development of modern musical theatre.\nBackground.\nIn 1875, Richard D'Oyly Carte, who was then managing the Royalty Theatre for Selina Dolaro, brought Gilbert and Sullivan together to write their second show, a one-act opera entitled \"Trial by Jury\". This proved a success, and in 1876 D'Oyly Carte assembled a group of financial backers to establish the Comedy Opera Company, which was devoted to the production and promotion of family-friendly English comic opera. With this theatre company, Carte finally had the financial resources, after many failed attempts, to produce a new full-length Gilbert and Sullivan opera. This next opera was \"The Sorcerer\", which opened in November 1877. It too was successful, running for 178\u00a0performances. Sheet music from the show sold well, and street musicians played the melodies.\nInstead of writing a piece for production by a theatre proprietor, as was usual in Victorian theatres, Gilbert, Sullivan and Carte produced the show with their own financial support. They were therefore able to choose their own cast of performers, rather than being obliged to use the actors already engaged at the theatre. They chose talented actors, most of whom were not well-known stars and did not command high fees, and to whom they could teach a more naturalistic style of performance than was commonly used at the time. They then tailored their work to the particular abilities of these performers. The skill with which Gilbert and Sullivan used their performers had an effect on the audience; as critic Herman Klein wrote: \"we secretly marvelled at the naturalness and ease with which [the Gilbertian quips and absurdities] were said and done. For until then no living soul had seen upon the stage such weird, eccentric, yet intensely human beings.\u00a0... [They] conjured into existence a hitherto unknown comic world of sheer delight.\"\nThe success of \"The Sorcerer\" paved the way for another collaboration by Gilbert and Sullivan. Carte agreed on terms for a new opera with the Comedy Opera Company, and Gilbert began work on \"H.M.S. Pinafore\" before the end of 1877. Gilbert's father had been a naval surgeon, and the nautical theme of the opera appealed to him. He drew on several of his earlier \"Bab Ballad\" poems (many of which also have nautical themes), including \"Captain Reece\" (1868) and \"General John\" (1867). Some of the characters also have prototypes in the ballads: Dick Deadeye is based on a character in \"Woman's Gratitude\" (1869); an early version of Ralph Rackstraw can be seen in \"Joe Go-Lightly\" (1867), with its sailor madly in love with the daughter of someone who far outranks him; and Little Buttercup is taken almost wholesale from \"The Bumboat Woman's Story\" (1870). On 27 December 1877, while Sullivan was on holiday on the French Riviera, Gilbert sent him a plot sketch accompanied by the following note:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I have very little doubt whatever but that you will be pleased with it.\u00a0... there is a good deal of fun in it which I haven't set down on paper. Among other things a song (a kind of 'Judge's Song') for the First Lord \u2013 tracing his career as office-boy\u00a0... clerk, traveller, junior partner and First Lord of Britain's Navy.\u00a0... Of course there will be no \"personality\" in this \u2013 the fact that the First Lord in the Opera is a \"Radical\" of the most pronounced type will do away with any suspicion that W. H. Smith is intended.\nDespite Gilbert's disclaimer, audiences, critics and even the Prime Minister, Benjamin Disraeli, identified Sir Joseph Porter with W. H. Smith, a politician who had recently been appointed First Lord of the Admiralty despite having neither military nor nautical experience. Sullivan was delighted with the sketch, and Gilbert read a first draft of the plot to Carte in mid-January.\nFollowing the example of his mentor, T. W. Robertson, Gilbert strove to ensure that the costumes and sets were as realistic as possible. When preparing the sets for \"H.M.S. Pinafore\", Gilbert and Sullivan visited Portsmouth in April 1878 to inspect ships. Gilbert made sketches of H.M.S. \"Victory\" and H.M.S. \"St Vincent\" and created a model set for the carpenters to work from. This was far from standard procedure in Victorian drama, in which naturalism was still a relatively new concept, and in which most authors had very little influence on how their plays and libretti were staged. This attention to detail was typical of Gilbert's stage management and would be repeated in all of his Savoy operas. Gilbert's focus on visual accuracy provided a \"right-side-up for topsy-turvydom\", that is, a realistic point of reference that serves to heighten the whimsicality and absurdity of the situations. Sullivan was \"in the full swing\" of work on the piece by the middle of April 1878. The bright and cheerful music of \"Pinafore\" was composed during a time when Sullivan suffered from excruciating pain from a kidney stone. The cast began music rehearsals on 24 April, and at the beginning of May 1878, the two collaborators worked closely together at Sullivan's flat to finalise the piece.\nIn \"Pinafore\", Gilbert, Sullivan and Carte used several of the principal cast members whom they had assembled for \"The Sorcerer\". As Gilbert had suggested to Sullivan in December 1877, \"Mrs. Cripps [Little Buttercup] will be a capital part for Everard\u00a0... Barrington will be a capital captain, and Grossmith a first-rate First Lord.\" However, Mrs Howard Paul, who had played Lady Sangazure in \"The Sorcerer\", was declining vocally. She was under contract to play the role of Cousin Hebe in \"Pinafore\". Gilbert made an effort to write an amusing part for her despite Sullivan's reluctance to use her, but by mid-May 1878, both Gilbert and Sullivan wanted her out of the cast; unhappy with the role, she left. With only a week to go before opening night, Carte hired a concert singer, Jessie Bond, to play Cousin Hebe. Since Bond had little experience as an actress, Gilbert and Sullivan cut the dialogue out of the role, except for a few lines in the last scene, which they turned into recitative. Other new cast members were Emma Howson and George Power in the romantic roles, who were improvements on the romantic soprano and tenor in \"The Sorcerer\".\nGilbert acted as stage director for his own plays and operas. He sought realism in acting, just as he strove for realistic visual elements. He deprecated self-conscious interaction with the audience and insisted on a style of portrayal in which the characters were never aware of their own absurdity but were coherent internal wholes. Sullivan conducted the music rehearsals. As was to be his usual practice in his later operas, Sullivan left the overture for the last moment, sketching it out and entrusting it to the company's music director, in this case Alfred Cellier, to complete. \"Pinafore\" opened on 25 May 1878 at the Opera Comique.\nSynopsis.\nAct I.\nThe British warship H.M.S. \"Pinafore\" is at anchor off Portsmouth. The sailors are on the quarterdeck, proudly \"cleaning brasswork, splicing rope, etc.\"\nLittle Buttercup, a Portsmouth \"bumboat woman\" (dockside vendor) \u2013 who is the rosiest, roundest, and \"reddest beauty in all Spithead\" \u2013 comes on board to sell her wares to the crew. She hints that she may be hiding a dark secret under her \"gay and frivolous exterior\". Ralph Rackstraw, \"the smartest lad in all the fleet\", enters, declaring his love for the Captain's daughter, Josephine. His fellow sailors (excepting Dick Deadeye, the grim and ugly realist of the crew) offer their sympathies, but they can give Ralph little hope that his love will ever be returned.\nThe gentlemanly and popular Captain Corcoran greets his \"gallant crew\" and compliments them on their politeness, saying that he returns the favour by never (\"well, hardly ever\") using bad language, such as \"a big, big D\". After the sailors leave, the Captain confesses to Little Buttercup that Josephine is reluctant to consider a marriage proposal from Sir Joseph Porter, the First Lord of the Admiralty. Buttercup says that she knows how it feels to love in vain. As she leaves, the Captain remarks that she is \"a plump and pleasing person\". Josephine enters and reveals to her father that she loves a humble sailor in his crew, but she assures him that she is a dutiful daughter and will never reveal her love to this sailor.\nSir Joseph comes on board, accompanied by his \"admiring crowd of sisters, cousins, and aunts\". He recounts how he rose from humble beginnings to be \"ruler of the Queen's Navee\" through persistence, although he has no naval qualifications. He then delivers a humiliating lesson in etiquette, telling the Captain that he must always say \"if you please\" after giving an order; for \"A British sailor is any man's equal\" \u2013 excepting Sir Joseph's. Sir Joseph has composed a song to illustrate that point, and he gives a copy of it to Ralph. Shortly afterwards, elated by Sir Joseph's views on equality, Ralph decides that he will declare his love to Josephine. This delights his shipmates, except Dick Deadeye, who contends that \"when people have to obey other people's orders, equality's out of the question\". Shocked by his words, the other sailors force Dick to listen to Sir Joseph's song before they exit, leaving Ralph alone on deck. Josephine now enters, and Ralph confesses his love in terms surprisingly eloquent for a \"common sailor\". Josephine is touched, but although she has found Sir Joseph's attentions nauseating, she knows that it is her duty to marry Sir Joseph instead of Ralph. Disguising her true feelings, she \"haughtily rejects\" Ralph's \"proffered love\".\nRalph summons his shipmates (Sir Joseph's female relatives also arrive) and tells them that he is bent on suicide. The crew expresses sympathy, except for Dick, who provides a stark counterpoint of dissent. Ralph puts a pistol to his head, but as he is about to pull the trigger, Josephine enters, admitting that she loves him after all. Ralph and Josephine plan to sneak ashore to elope that night. Dick Deadeye warns them to \"forbear, nor carry out the scheme\", but the joyous ship's company ignores him.\nAct II.\nLater that night, under a full moon, Captain Corcoran reviews his concerns: his \"kindly crew rebels\", his \"daughter to a tar is partial\", his friends seem to desert him, and Sir Joseph has threatened a court-martial. Little Buttercup offers sympathy. He tells her that, if it were not for the difference in their social standing, he would have returned her affection. She prophesies that things are not all as they seem and that \"a change\" is in store for him, but he does not understand her cryptic warning.\nSir Joseph enters and complains that Josephine has not yet agreed to marry him. The Captain speculates that she is probably dazzled by his \"exalted rank\" and that if Sir Joseph can persuade her that \"love levels all ranks\", she will accept his proposal. They withdraw, and Josephine enters, still feeling guilty about her planned elopement with Ralph and fearful of giving up a life of luxury. When Sir Joseph makes the argument that \"love levels all ranks\", a delighted Josephine says that she \"will hesitate no longer\". The Captain and Sir Joseph rejoice, but Josephine is now more determined than ever to marry Ralph.\nDick Deadeye intercepts the Captain and tells him of the lovers' plans to elope. The Captain confronts Ralph and Josephine as they try to leave the ship. The pair declare their love, justifying their actions because \"He is an Englishman!\" The furious Captain is unmoved and blurts out, \"Why, damme, it's too bad!\" Sir Joseph and his relatives, who have overheard this oath, are shocked to hear swearing on board a ship, and Sir Joseph orders the Captain confined to his cabin.\nWhen Sir Joseph asks what had provoked the usually polite officer's outburst, Ralph replies that it was his declaration of love for Josephine. Furious in his turn at this revelation, and ignoring Josephine's plea to spare Ralph, Sir Joseph has the sailor \"loaded with chains\" and taken to the ship's brig. Little Buttercup now comes forward to reveal her long-held secret. Many years ago, when she \"practised baby-farming\", she had cared for two babies, one \"of low condition\", the other \"a regular patrician\". She confesses that she \"mixed those children up.\u00a0... The wellborn babe was Ralph; your Captain was the other.\"\nSir Joseph now realises that Ralph should have been the Captain, and the Captain should have been Ralph. He summons both, and they emerge wearing each other's uniforms: Ralph as Captain, in command of the \"Pinafore\", and Corcoran as a common sailor. Sir Joseph's marriage with Josephine is now \"out of the question\" in his eyes: \"love levels all ranks\u00a0... to a considerable extent, but it does not level them as much as that.\" He hands her to Captain Rackstraw. The former Captain's now-humble social rank leaves him free to marry Buttercup. Sir Joseph settles for his cousin Hebe, and all ends in general rejoicing.\nMusical numbers.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nProductions.\n\"Pinafore\" opened on 25 May 1878 at the Opera Comique, before an enthusiastic audience, with Sullivan conducting. Soon, however, the piece suffered from weak ticket sales, generally ascribed to a heat wave that made the Opera Comique particularly uncomfortable. The historian Michael Ainger questions this explanation, at least in part, stating that the heat waves in the summer of 1878 were short and transient. By mid-August, Sullivan wrote to his mother that cooler weather had arrived, which was good for the show. In the meantime, the four partners of the Comedy Opera Company lost confidence in the opera's viability and posted closing notices. Carte publicised the piece by presenting a matinee concert performance on 6 July 1878 at the enormous Crystal Palace.\nIn late August 1878, Sullivan used some of the \"Pinafore\" music, arranged by his assistant Hamilton Clarke, during several successful promenade concerts at Covent Garden that generated interest and stimulated ticket sales. By September, \"Pinafore\" was playing to full houses at the Opera Comique. The piano score sold 10,000\u00a0copies, and Carte soon sent two additional companies out to tour in the provinces.\nCarte, Gilbert and Sullivan now had the financial resources to produce shows themselves, without outside backers. Carte persuaded the author and composer that a business partnership among the three would be to their advantage, and they hatched a plan to separate themselves from the directors of the Comedy Opera Company. The contract between Gilbert and Sullivan and the Comedy Opera Company gave the latter the right to present \"Pinafore\" for the duration of the initial run. The Opera Comique was obliged to close for drain and sewer repairs, and it was renovated by E. W. Bradwell, from Christmas 1878 to the end of January 1879. Gilbert, Sullivan and Carte believed that this break ended the initial run, and, therefore, ended the company's rights. Carte put the matter beyond doubt by taking a six-month personal lease of the theatre beginning on 1 February 1879, the date of its re-opening, when \"Pinafore\" resumed. At the end of the six months, Carte planned to give notice to the Comedy Opera Company that its rights in the show and the theatre had ended.\nMeanwhile, numerous versions of \"Pinafore\", unauthorised by its creators, began playing in America with great success, beginning with a production in Boston that opened on 25 November 1878. \"Pinafore\" became a source of popular quotations on both sides of the Atlantic, such as the exchange:\n&lt;poem style=\"margin-left: 2em;\"&gt;\"What, never?\"\n\"No, never!\"\n\"What, \"never?\"\"\n\"Well, hardly ever!\"&lt;/poem&gt;\nIn February 1879, \"Pinafore\" resumed operations at the Opera Comique. The opera also resumed touring in April, with two companies crisscrossing the British provinces by June, one starring Richard Mansfield as Sir Joseph, the other W. S. Penley in the role. Hoping to join in on the profits to be made in America from \"Pinafore\", Carte left in June for New York to make arrangements for an \"authentic\" production there to be rehearsed personally by the author and composer. He arranged to rent a theatre and auditioned chorus members for the American production of \"Pinafore\" and a new Gilbert and Sullivan opera to be premiered in New York, and for tours.\nSullivan, as had been arranged with Carte and Gilbert, gave notice to the partners of the Comedy Opera Company in early July 1879 that he, Gilbert and Carte would not be renewing the contract to produce \"Pinafore\" with them and that he would be withdrawing his music from the Comedy Opera Company on 31 July. In return, the Comedy Opera Company gave notice that they intended to play \"Pinafore\" at another theatre and brought a legal action against Carte and company. They offered the London and touring casts of \"Pinafore\" more money to play in their production, and although some choristers accepted their offer, only one principal player, Aeneas Joseph Dymott, accepted. They engaged the Imperial Theatre but had no scenery. On 31 July, they sent a group of thugs to seize the scenery and props during Act II of the evening performance at the Opera Comique. Gilbert was away, and Sullivan was recovering from an operation for kidney stones. Stagehands and cast members managed to ward off their backstage attackers and protect the scenery, although the stage manager, Richard Barker, and others, were injured. The cast went on with the show until someone shouted \"Fire!\" George Grossmith, playing Sir Joseph, went before the curtain to calm the panicked audience. The police arrived to restore order, and the show continued. Gilbert sued to stop the Comedy Opera Company from staging their rival production of \"H.M.S. Pinafore\". The court permitted the production to go on at the Imperial, beginning on 1 August 1879, and it transferred to the Olympic Theatre in September. Pauline Rita was one of a series of Josephines. The production received good notices and initially sold well but was withdrawn in October after 91\u00a0performances. The matter was eventually settled in court, where a judge ruled in Carte's favour about two years later.\nAfter his return to London, Carte formed a new partnership with Gilbert and Sullivan to divide profits equally after the expenses of each of their shows. Meanwhile, \"Pinafore\" continued to play strongly. On 20 February 1880, \"Pinafore\" completed its initial run of 571\u00a0performances. Only one other work of musical theatre in the world had ever run longer, Robert Planquette's operetta \"Les cloches de Corneville\".\nTaking \"Pinafore\" to the United States.\nApproximately 150\u00a0unauthorised productions of \"Pinafore\" sprang up in the United States in 1878 and 1879, and none of these paid royalties to the authors. Gilbert and Sullivan called them \"pirated\", although the creators did not have any international copyright protection. The first of these productions, opening at the Boston Museum on 25 November 1878, made such a splash that the piece was quickly produced in major cities and on tour by dozens of companies throughout the country. Boston alone saw at least a dozen productions, including a juvenile version described by Louisa May Alcott in her 1879 story, \"Jimmy's Cruise in the Pinafore\". In New York, different productions of the piece played simultaneously in eight theatres within five blocks of each other and in six theatres in Philadelphia. A production by Gorman's Philadelphia Church Choir Company, orchestrated by John Philip Sousa and starring Louis De Lange as Sir Joseph, played on Broadway and toured in the U.S. throughout 1879; Sousa's orchestration was also used in Australasia. The first production of \"Pinafore\" in Canada was at the Royal Opera House in Toronto, in February 1879, produced by the Holman Opera Company.\nThese unauthorised performances took many forms, including burlesques, productions with men playing women's roles and vice versa, spoofs, variety acts, Minstrel show versions, all-black and Catholic productions, German, Yiddish and other foreign-language versions, performances on boats or by church choirs, and productions starring casts of children. Few purported to play the opera as written. Sheet music arrangements were popular, there were \"Pinafore\"-themed dolls and household items, and references to the opera were common in advertising, news and other media. Gilbert, Sullivan and Carte brought lawsuits in the U.S. and tried for many years to control the American performance copyrights over their operas, or at least to claim some royalties, without success. They made a special effort to claim American rights for their next work after \"Pinafore\", \"The Pirates of Penzance\", by giving the official premiere in New York.\nGilbert, Sullivan and Carte met by 24 April 1879 to make plans for a production of \"Pinafore\" in America. Carte travelled to New York in the summer of 1879 and made arrangements with theatre manager John T. Ford to present, at the Fifth Avenue Theatre, the first authorised American production of \"Pinafore\". In November, Carte returned to America with Gilbert, Sullivan and a company of strong singers, including J. H. Ryley as Sir Joseph, Blanche Roosevelt as Josephine, Alice Barnett as Little Buttercup, Furneaux Cook as Dick Deadeye, Hugh Talbot as Ralph Rackstraw and Jessie Bond as Cousin Hebe. To these, he added some American singers, including Signor Brocolini as Captain Corcoran. Alfred Cellier came to assist Sullivan, while his brother Fran\u00e7ois remained in London to conduct \"Pinafore\" there.\n\"Pinafore\" opened in New York on 1 December 1879 (with Gilbert onstage in the chorus) and ran for the rest of December. After a reasonably strong first week, audiences quickly fell off, since most New Yorkers had already seen local productions of \"Pinafore\". In the meantime, Gilbert and Sullivan raced to complete and rehearse their new opera, \"The Pirates of Penzance\", which premiered with much success on 31 December. Shortly thereafter, Carte sent three touring companies around the United States East Coast and Midwest, playing \"Pinafore\" alongside \"Pirates\".\nChildren's production.\nThe unauthorised juvenile productions of \"Pinafore\" were so popular that Carte mounted his own children's version, played at matinees at the Opera Comique beginning on 16 December 1879. Fran\u00e7ois Cellier, who had taken over from his brother as Carte's music director in London, adapted the score for children's voices. Between its two Christmas seasons in London, the children's production went on a provincial tour from 2 August 1880 to 11 December 1880.\nCarte's children's production earned enthusiastic reviews from the critic Clement Scott and the other London critics, as well as the audiences, including children. However, Captain Corcoran's curse \"Damme!\" was uncensored, shocking such prominent audience members as Lewis Carroll, who later wrote: \"a bevy of sweet innocent-looking girls sing, with bright and happy looks, the chorus 'He said, Damn me! He said, Damn me!' I cannot find words to convey to the reader the pain I felt in seeing those dear children taught to utter such words to amuse ears grown callous to their ghastly meaning\u00a0... How Mr. Gilbert could have stooped to write, or Sir Arthur Sullivan could have prostituted his noble art to set to music, such vile trash, it passes my skill to understand\".\nSubsequent productions.\nAfter the opera became successful in London, Richard D'Oyly Carte quickly sent touring companies into the British provinces. At least one D'Oyly Carte company, and sometimes as many as three, played \"Pinafore\" under Carte's aegis every year between 1878 and 1888, including its first London revival in 1887. The opera was then given a rest, returning to the touring repertory between 1894 and 1900 and again for most of the time between 1903 and 1940. Gilbert directed all the revivals during his lifetime, and after his death, the D'Oyly Carte Opera Company had exclusive performing rights to the Savoy operas until 1962. It continued to hew closely to Gilbert's directions throughout that period, as recorded in Gilbert's prompt books, and it also required its licensees to follow them closely.\nUntil 1908, revivals of the opera were given in contemporary dress, with ladies' costumes executed by couture houses such as Redfern. After that, designers such as Percy Anderson, George Sheringham and Peter Goffin created Victorian costume designs. The 1887 set was designed by Hawes Craven. In the winter of 1940\u201341, the D'Oyly Carte Opera Company's scenery and costumes for \"Pinafore\" and three other operas were destroyed by German bombs during World War II. The opera was revived in London in the summer of 1947. It was then included in the D'Oyly Carte repertory in every season from then on, until the company's closure in 1982. The D'Oyly Carte company performed \"Pinafore\" before Queen Elizabeth II and the royal family at Windsor Castle on 16 June 1977, during the queen's Silver Jubilee year, the first royal command performance of a Gilbert and Sullivan opera since 1891.\nThe D'Oyly Carte Opera Company did not allow any other professional company to present the Savoy operas in Britain and the Commonwealth until the copyrights expired at the end of 1961, although it licensed many amateur and school societies to do so, beginning in the 19th century. Other professional productions since the copyrights expired have included Tyrone Guthrie's 1960 production from Stratford, Ontario, seen on Broadway in 1960 and in London in 1962 and a New Sadler's Wells Opera Company production first seen on 4 June 1984 at Sadler's Wells Theatre, which was seen also in New York. Scottish Opera, Welsh National Opera and many of the other British opera companies have mounted productions, as did the reconstituted D'Oyly Carte Opera Company between 1990 and its closure in 2003. In recent decades, the Carl Rosa Opera Company has produced \"Pinafore\" several times, including in 2009, Opera della Luna has toured it repeatedly, English National Opera presented it in 2021, it is regularly given by the National Gilbert &amp; Sullivan Opera Company, and other British companies continue to mount the piece.\nThe extraordinary initial success of \"Pinafore\" in America was seen first-hand by J. C. Williamson. He soon made arrangements with D'Oyly Carte to present the opera's first authorised production in Australia, opening on 15 November 1879 at the Theatre Royal, Sydney. Thereafter, his opera company played frequent seasons of the work (and the subsequent Savoy operas) until at least 1963. In the U.S., the piece never lost popularity. The Internet Broadway Database links to a non-exhaustive list of 29 productions on Broadway alone. Among the professional repertory companies continuing to present \"Pinafore\" regularly in the U.S. are Opera a la Carte, based in California, Ohio Light Opera and the New York Gilbert and Sullivan Players, which tours the opera annually and often includes it in its New York seasons. \"Pinafore\" is still performed around the world by opera companies such as the Royal Theatre, Copenhagen; Australian Opera (and Essgee Entertainment and others in Australia); in Kassel, Germany; and even Samarkand, Uzbekistan.\nThe following table shows the history of the D'Oyly Carte productions (excluding tours) in Gilbert's lifetime:\nReception.\nInitial critical reception.\nThe early reviews were mostly favourable. \"The Era\" wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Seldom indeed have we been in the company of a more joyous audience.\u00a0... [Gilbert and Sullivan] have on previous occasions been productive of such legitimate amusement, such novel forms of drollery, such original wit, and unexpected whimsicality, that nothing was more natural than for the audience to anticipate an evening of thorough enjoyment. The expectation was fulfilled completely. Those who believed in the power of Mr Gilbert to tickle the fancy with quaint suggestions and unexpected forms of humour were more than satisfied, and those who appreciate Mr Arthur Sullivan's inexhaustible gift of melody were equally gratified; while that large class of playgoers who are pleased with brilliant dresses and charming stage effects declared themselves delighted. The result, therefore, was \"a hit, a palpable hit\"\u00a0... there were some slight drawbacks [such] as the severe cold that affected Mr. Rutland Barrington [the captain], and almost prevented his singing.\n\"The Era\" also lavishly praised Emma Howson as Josephine. \"The Entr'acte and Limelight\" commented that the opera was reminiscent of \"Trial by Jury\" and \"Sorcerer\" but found it diverting and called the music \"very charming. To hear so-called grand opera imitated through the medium of the most trifling lyrics, is funny\". The paper praised Grossmith as Sir Joseph, noting with amusement that he was made up to look like portraits of Horatio Nelson, \"and his good introductory song seems levelled at\" W. H. Smith. It opined, further, that \"He Is an Englishman\" is \"an excellent satire on the proposition that a man must necessarily be virtuous to be English\". It found the piece, as a whole, well presented and predicted that it would have a long run.\nSimilarly, \"The Illustrated London News\" concluded that the production was a success and that the plot, though slight, served as a good vehicle for Gilbert's \"caustic humour and quaint satire\". It found that there was \"much to call forth hearty laughter in the occasional satirical hits.\u00a0... Dr. Sullivan's music is as lively as the text to which it is set, with here and there a touch of sentimental expression\u00a0... The piece is well performed throughout.\" The \"Daily News\", \"The Globe\", \"The Times\" (which particularly praised Grossmith, Barrington and Everard) and \"The Standard\" concurred, the last commenting favourably on the chorus acting, which, it said, \"adds to the reality of the illusion\". \"The Times\" also noted that the piece was an early attempt at the establishment of a \"national musical stage\" with a libretto free from risqu\u00e9 French \"improprieties\" and without the \"aid\" of Italian and German musical models.\n\"The Daily Telegraph\" and the \"Athenaeum\", however, greeted the opera with only mixed praise. \"The Musical Times\" complained that the ongoing collaboration between Gilbert and Sullivan was \"detrimental to the art-progress of either\" because, although it was popular with audiences, \"something higher is demanded for what is understood as 'comic opera'\". The paper commented that Sullivan had \"the true elements of an artist, which would be successfully developed were a carefully framed libretto presented to him for composition\". It concluded, however, by saying how much it enjoyed the opera: \"Having thus conscientiously discharged our duties as art-critics, let us at once proceed to say that \"H.M.S. Pinafore\" is an amusing piece of extravagance, and that the music floats it on merrily to the end\". \"The Times\" and several of the other papers agreed that, while the piece was entertaining, Sullivan was capable of higher art. Only \"The Figaro\" was actively hostile to the new piece. Upon the publication of the vocal score, a review by \"The Academy\" joined the chorus of regret that Sullivan had sunk so low as to compose music for \"Pinafore\" and hoped that he would turn to projects \"more worthy of his great ability\". This criticism would follow Sullivan throughout his career.\nThe many unauthorised American productions of 1878\u201379 were of widely varying quality, and many of them were adaptations of the opera. One of the more \"authentic\" ones was the production by the Boston Ideal Opera Company, which was first formed to produce \"Pinafore\". It engaged well-regarded concert singers and opened on 14 April 1879 at the 3,000-seat Boston Theatre. The critics agreed that the company fulfilled its goals of presenting an \"ideal\" production. The \"Boston Journal\" reported that the audience was \"wrought up by the entertainment to a point of absolute approval\". The paper observed that it is a mistake to consider \"Pinafore\" a burlesque, \"for while irresistibly comical it is not \"bouffe\" and requires to be handled with great care lest its delicate proportions be marred and its subtle quality of humor be lost\". The \"Journal\" described the opera as \"classical\" in method and wrote that its \"most exquisite satire\" lay in its \"imitation of the absurdities\" of grand opera. The company went on to become one of the most successful touring companies in America. The first children's version in Boston became a sensation with both children and adult audiences, extending its run through the summer of 1879. The \"Boston Herald\" wrote that \"the large audience of children and their elders went fairly wild with delight\u00a0... shrieks of laughter were repeatedly heard\".\nSubsequent reception.\nWhen \"Pinafore\" was first revived in London in 1887, it was already treated as a classic. \"The Illustrated London News\" observed that the opera had not been updated with new dialogue, jokes and songs, but concluded that this was for the best, as the public would have missed the \"time-honoured jokes, such as 'Hardly Ever.' The Savoy has once more got a brilliant success.\" \"The Theatre\" concurred, stating that since the opera \"has been heard in almost every part of this habitable globe and been enjoyed everywhere, there is not much occasion to descant\". It called the revival a \"most brilliant\" success and predicted another long run.\nReviewing the 1899 revival, \"The Athenaeum\" managed to praise the piece while joining in the musical establishment's critique of Sullivan. On the one hand, \"The \"Pinafore\"\u00a0... sounds fresher than ever. The musical world has become serious \u2013 very serious \u2013 and it is indeed refreshing to hear a merry, humorous piece, and music, unassuming in character\u00a0... it is delicately scored, and in many ways displays ability of a high order\". On the other hand, it wrote that if Sullivan had pursued the path of composing more serious music, like his symphony, \"he would have produced still higher results; in like manner \"Pinafore\" set us wondering what the composer would have accomplished with a libretto of somewhat similar kind, but one giving him larger scope for the exercise of his gifts\".\nIn 1911, H. L. Mencken wrote: \"No other comic opera ever written \u2013 no other stage play, indeed, of any sort \u2013 was ever so popular.\u00a0... \"Pinafore\"\u00a0... has been given, and with great success, wherever there are theaters \u2013 from Moscow to Buenos Aires, from Cape Town to Shanghai; in Madrid, Ottawa and Melbourne; even in Paris, Rome, Vienna and Berlin.\" After the deaths of Gilbert and Sullivan, the D'Oyly Carte Opera Company retained exclusive rights to perform their operas in Great Britain until 1962, touring throughout Britain for most of the year and, beginning in 1919, often performing in London for a season of about four months. \"The Times\" gave the company's 1920 London production an enthusiastic review, saying that the audience was \"enraptured\", and regretting that \"Pinafore\" would be played for only two weeks. It praised the cast, singling out Leo Sheffield as the Captain, Henry Lytton as Sir Joseph, Elsie Griffin as Josephine, James Hay as Ralph, Bertha Lewis as Little Buttercup and the \"splendid\" choral tone. It concluded that the opera made a \"rollicking climax to the season\". Two years later, it gave an even more glowing report of that season's performances, calling Derek Oldham an \"ideal hero\" as Ralph, noting that Sydney Granville \"fairly brought down the house\" with his song, that Darrell Fancourt's Deadeye was \"an admirably sustained piece of caricature\" and that it was a \"great pleasure\" to hear the returning principals. A 1961 review of the company's \"Pinafore\" is much the same.\nIn 1879, J. C. Williamson acquired the exclusive performing rights to \"Pinafore\" in Australia and New Zealand. His first production earned public and critical acclaim. Williamson played Sir Joseph, and his wife, Maggie Moore played Josephine. Praising the production, Williamson, Moore and the other performers, the \"Sydney Morning Herald\" noted that the production, though \"abounding in fun\", was dignified and precise, especially compared with a previous \"boisterous\" unauthorized production, and that many numbers were encored and the laughter and applause from the \"immense audience\u00a0... was liberally bestowed\". Williamson's company continued to produce \"Pinafore\" in Australia, New Zealand and on tour into the 1960s with much success. Williamson said, \"If you need money, then put on G&amp;S\". Meanwhile, \"Pinafore\" continued to garner praise outside Britain. The 1950s Danish version in Copenhagen, for example, was revived repeatedly, playing for well over 100\u00a0performances to \"packed houses\". Translations into German, Yiddish and many other languages, and professional productions in places as remote as Samarkand in Uzbekistan have been successful.\nIn the U.S., where Gilbert and Sullivan's performance copyright was never in force, \"Pinafore\" continued to be produced continuously by both professional and amateur companies. \"The New York Times\", in a 1914 review, called a large-scale production at the 6,000-seat New York Hippodrome a \"royal entertainment [that] comes up smiling\". The opera had been turned into a \"mammoth spectacle\" with a chorus of hundreds and the famous Hippodrome tank providing a realistic harbour. Buttercup made her entrance by rowing over to the three-masted \"Pinafore\", and Dick Deadeye was later thrown overboard with a real splash. The critic praised the hearty singing but noted that some subtlety is lost when the dialogue needs to be \"shouted\". The production took some liberties, including interpolated music from other Sullivan works. The paper concluded, \"the mild satire of \"Pinafore\" is entertaining because it is universal\". The same newspaper deemed Winthrop Ames' popular Broadway productions of \"Pinafore\" in the 1920s and 1930s \"spectacular\". Modern productions in America continue to be generally well received. \"The New York Times\" review of the New York Gilbert and Sullivan Players' 2008 season at New York City Center commented, \"Gilbert's themes of class inequality, overbearing nationalism and incompetent authorities remain relevant, however absurdly treated. But the lasting appeal of \"Pinafore\" and its ilk is more a matter of his unmatched linguistic genius and Sullivan's generous supply of addictive melodies.\"\nWith the expiry of the copyrights, companies around the world have been free to produce Gilbert and Sullivan works and to adapt them as they please for almost 50 years. Productions of \"Pinafore\", both amateur and professional, range from the traditional, in the D'Oyly Carte vein, to the broadly adapted, such as that of the very successful Essgee Entertainment (formed by Simon Gallaher) in Australia and Opera della Luna in Britain. Since its original production, \"H.M.S. Pinafore\" has remained one of Gilbert and Sullivan's most popular comic operas. Productions continue in large numbers around the world. In 2003 alone, The D'Oyly Carte Opera Company rented 224 sets of orchestra parts, mostly for productions of \"Pinafore\", \"Pirates\" and \"Mikado\". This does not take into account other rental companies and the theatre companies that borrow scores or have their own, or that use only one or two pianos instead of an orchestra. Hundreds of productions of \"Pinafore\" are presented every year worldwide.\nAnalysis.\nTheatre historian John Bush Jones wrote that \"Pinafore\" has \"everything a musical theatregoer could ask for. An engaging and even relatively suspenseful story is populated with varied and well-drawn characters who speak and sing witty, literate, and often outrageously funny dialogue and lyrics [and] has a score that\u00a0... has plenty of tunes for the audience to go away humming\". George Power, the tenor who created the role of Ralph Rackstraw, opined in later life that the secret of the success of the Savoy operas is the way in which \"Sullivan entered into the spirit of Gilbert's topsy-turvy humour, and was pompous when Gilbert was sprightly, or, when Gilbert's satire was keenest and most acid, consciously wallowed in sentiment.\" Another commentator has suggested that the opera's enduring success lies in its focus on \"mirth and silliness\". Even the title of the piece is silly, applying the name of a little girl's garment, a pinafore, to the fearsome symbol of a naval warship, which usually bore names like \"Victory\", \"Goliath\", \"Audacious\" and \"Minotaur\".\nSatiric and comic themes.\nGilbert's biographer Jane Stedman wrote that \"Pinafore\" is \"satirically far more complex\" than \"The Sorcerer\". She commented that Gilbert uses several ideas and themes from his Bab Ballads, including the idea of gentlemanly behaviour of a captain towards his crew from \"Captain Reece\" (1868) and the exchange of ranks due to exchange at birth from \"General John\" (1867). Dick Deadeye, based on a character in \"Woman's Gratitude\" (1869), represents another of Gilbert's favorite (and semi-autobiographical) satiric themes: the misshapen misanthrope whose forbidding \"face and form\" makes him unpopular although he represents the voice of reason and common sense. Gilbert also borrows from his 1870 opera, \"The Gentleman in Black\" which includes the device of baby-switching.\nHistorian H. M. Walbrook wrote in 1921 that \"Pinafore\" \"satirizes the type of nautical drama of which Douglas Jerrold's \"Black-Eyed Susan\" is a typical instance, and the 'God's Englishman' sort of patriotism which consists in shouting a platitude, striking an attitude, and doing little or nothing to help one's country\". G. K. Chesterton agreed that the satire is pointed at the selfishness of \"being proud of yourself for being a citizen\" of one's country, which requires no virtuous effort of will to resist the \"temptations to belong to other nations\" but is merely an excuse for pride. In 2005, Australian opera director Stuart Maunder noted the juxtaposition of satire and nationalism in the opera, saying, \"they all sing 'He is an Englishman', and you know damn well they're sending it up, but the music is so military\u00a0... that you can't help but be swept up in that whole jingoism that is the British Empire.\" In addition, he argued that the song ties this theme into the main satire of class distinctions in the opera: \"\"H.M.S. Pinafore\" is basically a satire on\u00a0... the British love of the class system.\u00a0... [O]f course [Ralph] can marry [the Captain's] daughter, because he's British, and therefore he's great'\". Jacobs notes that Gilbert is lampooning the tradition of nautical melodrama in which the sailor's \"patriotism guarantees his virtue\".\nOne of Gilbert's favourite comic themes is the elevation of an unqualified person to a position of high responsibility. In \"The Happy Land\" (1873), for example, Gilbert describes a world in which government offices are awarded to the person who has the least qualification to hold each position. In particular, the one who has never heard of a ship is appointed to the cabinet post of First Lord of the Admiralty. In \"Pinafore\", Gilbert revisits this theme in the character of Sir Joseph, who rises to the same position by \"never go[ing] to sea\". In later Gilbert and Sullivan operas, the characters Major-General Stanley in \"Pirates\", and Ko-Ko in \"The Mikado\", are similarly appointed to high office though lacking the necessary qualifications. Gilbert also pokes fun at party politics, implying that when Sir Joseph \"always voted at [his] party's call\", he sacrificed his personal integrity. The \"commercial middle class\" (which was Gilbert's main audience) is treated as satirically as are social climbers and the great unwashed. In addition, the apparent age difference between Ralph and the Captain, even though they were babies nursed together, satirises the variable age of Thaddeus in \"The Bohemian Girl\". \"The Times\" wrote, in reviewing the 1929 production, that \"Pinafore\" was quintessentially Gilbertian in that the absurdities of a \"paternal\" Captain and the \"ethics\u00a0... of all romanticism\" are accepted \"unflinchingly\" and taken to their logical conclusion: \"It is the reference to actuality that is essential; without it, the absurdity will not stand starkly out\".\nA theme that pervades the opera is the treatment of love across different social ranks. In the previous Gilbert and Sullivan opera, \"The Sorcerer\", a love potion causes trouble by inducing the villagers and wedding guests to fall in love with people of different social classes. In \"Pinafore\", the captain's daughter, Josephine, loves and is loved by a common sailor, but she dutifully tells him, \"your proffered love I haughtily reject\". He expresses his devotion to her in a poetic and moving speech that ends with \"I am a British sailor, and I love you\". It finally turns out that he is of a higher rank than she. This is a parody of the Victorian \"equality\" drama, such as Lord Lytton's \"The Lady of Lyons\" (1838), where the heroine rejects a virtuous peasant who makes a similarly moving speech, ending with \"I am a peasant!\" It then turns out that he has become her social superior. Furthermore, in \"Pinafore\", Sir Joseph assures Josephine that \"love levels all ranks\". In Tom Taylor's \"The Serf\", the heroine again loves a worthy peasant who turns out to be of high rank, and she declares happily at the end that \"love levels all\". In a satire of the libertarian traditions of nautical melodrama, Sir Joseph tells the crew of the Pinafore that they are \"any man's equal\" (excepting his), and he writes a song for them that glorifies the British sailor. Conversely, he brings the proud captain down a notch by making him \"dance a hornpipe on the cabin table\". Jones notes that the union between Ralph and Josephine \"becomes acceptable only through the absurd second-act revelation of Buttercup's inadvertent switching of the infants\" and concludes that Gilbert is a \"conservative satirist [who] ultimately advocated preserving the status quo\u00a0... [and] set out to show [that] love definitely \"does not\" level all ranks\".\nThere is a divide among Gilbert and Sullivan scholars as to whether Gilbert is, as Jones argues, a supporter of the status quo whose focus is merely to entertain or, on the other hand, predominantly to satirise and protest \"against the follies of his age\". The Gilbert scholar Andrew Crowther posits that this disagreement arises from Gilbert's \"techniques of inversion \u2013 with irony and topsyturvydom\", which lead to \"the surface meaning of his writings\" being \"the opposite of their underlying meaning\". Crowther argues that Gilbert desires to \"celebrate\" society's norms while, at the same time, satirising these conventions. In \"Pinafore\", which established many patterns for the later Savoy operas, Gilbert found a way to express his own conflict that \"also had tremendous appeal to the general public\". He creates \"a highly intelligent parody of nautical melodrama\u00a0... [though] controlled by the conventions it mocks\". While nautical melodrama exalts the common sailor, in \"Pinafore\" Gilbert makes the proponent of equality, Sir Joseph, a pompous and misguided member of the ruling class who, hypocritically, cannot apply the idea of equality to himself. The hero, Ralph, is convinced of his equality by Sir Joseph's foolish pronouncements and declares his love for his Captain's daughter, throwing over the accepted \"fabric of social order\". At this point, Crowther suggests, the logic of Gilbert's satiric argument should result in Ralph's arrest. But to satisfy convention, Gilbert creates an obvious absurdity: the captain and Ralph were switched as babies. By an \"accident of birth\", Ralph is suddenly an appropriate husband for Josephine, and both the social order and the desire for a romantic happy ending are satisfied at once. Crowther concludes, \"We have an opera which uses all the conventions of melodrama and ridicules them; but in the end it is difficult to see which has won out, the conventions or the ridicule.\" Thus, \"Pinafore\" found broadbased success by appealing to the intellectual theatregoer seeking satire, the middle-class theatre-goer looking for a comfortable confirmation of the \"existing social order\" and the working-class audience who saw a satisfying melodramatic victory for the common man.\nSongs and musical analysis.\nAccording to musicologist Arthur Jacobs, Gilbert's plot \"admirably sparked off Sullivan's genius\". Sullivan embraces the nautical setting; in \"We Sail the Ocean Blue\", for example, he \"presents his twist on a traditional sea shanty\". In the Captain's opening song, \"I am the Captain of the Pinafore\", he admits that his gentlemanliness \"never\u00a0... well, hardly ever\" gives way to swearing at his men, and although he has experience at sea, he \"hardly ever\" suffers from seasickness. Sullivan \"unerringly found the right musical setting for the key phrase 'What never?'\u00a0... cunningly sharpened\u00a0... through the chromatic touch on the bassoon.\" Audrey Williamson argued that the music of \"Pinafore\" is quintessentially English and free of European influences throughout most of the score, from the \"glee\" for Ralph, the Boatswain and the Carpenter, to \"For He Is an Englishman\".\nThe best-known songs from the opera include \"I'm called Little Buttercup\", a waltz tune introducing the character, which Sullivan repeats in the entr'acte and in the Act II finale to imprint the melody on the mind of the audience; and \"A British tar\" (a glee for three men describing the ideal sailor), composed by Sir Joseph \"to encourage independent thought and action in the lower branches of the service, and to teach the principle that a British sailor is any man's equal, excepting mine\". Sullivan's voicing advances the satiric lyric, which mocks the \"equality\" plays while underlining the hypocrisy of Sir Joseph. Another popular number is Sir Joseph's song \"When I was a Lad\", recounting the meteoric rise of his career, which bears similarities to that of W. H. Smith, the civilian news entrepreneur who had risen to the position of First Lord of the Admiralty in 1877.\nIn \"Pinafore\", Sullivan exploits minor keys for comic effect, for instance in \"Kind Captain, I've important information\". Further, he achieves a musical surprise when he uses the subdominant minor in \"Sorry her lot\". The musicologist Gervase Hughes was impressed with the introduction to the opening chorus which includes \"a rousing nautical tune\u00a0... in a key of no nonsense, C major\u00a0... a modulation to the mediant minor, where to our surprise a plaintive oboe gives us the first verse of \"Sorry her lot\" in 2/4 [time]. After this closes on the local dominant B major the violins (still in 2/4) introduce us to Little Buttercup\u00a0... meeting her under these conditions one would hardly expect her to blossom out later as a queen of the waltz.\" He continues, \"the bassoon and basses\u00a0... assert vigorously who is the Captain of the Pinafore\u00a0... in the improbable key of A flat minor.\u00a0... Buttercup makes a last despairing attempt to make herself heard in D flat minor, but the others have never known that such an outlandish key existed. So in a flash they all go back to C major on a good old 6/4\".\nAccording to Jacobs, \"Ralph, Captain Corcoran, Sir Joseph and Josephine all live in their interactive music (particularly 'Never mind the why and wherefore'), and almost as much musical resource is lavished on two characters parodied from opera or melodrama, Little Buttercup with 'gypsy blood in her veins' and the heavy-treading Dick Deadeye.\" Jacobs also opined that the leading tone that begins \"Never mind the why and wherefore\" \"serves to emphasize the phrase like a Johann Strauss-ian grace-note\". The Sullivan scholar David Russell Hulme noted Sullivan's parody of operatic styles, \"particularly the Handelian recitatives and the elopement scene (evocative of so many nocturnal operatic conspiracies), but best of all is the travesty of the patriotic tune in 'For he is an Englishman!'\" Buttercup's Act II song, in which she reveals the dark secret of the baby-switching is preceded by a quote from Franz Schubert's \"Erlk\u00f6nig\" and also parodies the opera \"Il trovatore\". Jacobs notes that Sullivan also adds his own humorous touches to the music by setting commonplace expressions in \"Donizettian recitative\". But on the serious side, he enhances the moments of true emotional climax, as in Josephine's Act II aria, and added musical interest to concerted numbers by \"subtly shifting the rhythms and bar groupings.\"\nRevisions and cut material.\nBallad for Captain Corcoran, \"Reflect, my child\".\nDuring rehearsals for the original production, Gilbert added a ballad for Captain Corcoran in which he urged his daughter to forget the common sailor with whom she is in love, because \"at every step, he would commit solecisms that society would never pardon.\" The ballad was meant to be sung between No. 5 and No. 6 of the current score, but it was cut before opening night. The words survive in the libretto that was deposited with the Lord Chamberlain for licensing. Before 1999, all that was known to survive of Sullivan's setting was a copy of the leader violin part.\nIn April 1999, Sullivan scholars Bruce I. Miller and Helga J. Perry announced that they had discovered a nearly complete orchestration \u2013 lacking only the second violin part \u2013 in a private collection of early band parts. These materials, with a conjectural reconstruction of the partially lost vocal lines and second violin part, were later published and professionally recorded. This piece has now been performed a number of times by amateur and professional companies, although it has not become a standard addition to the traditional scores or recordings.\nDialogue for Cousin Hebe.\nIn the licensing copy of the libretto, Sir Joseph's cousin Hebe had lines of dialogue in several scenes in Act II. In the scene that follows No. 14 (\"Things are seldom what they seem\"), she accompanied Sir Joseph onstage and echoed the First Lord's dissatisfaction with Josephine. After several interruptions, Sir Joseph urged her to be quiet, eliciting the response \"Crushed again!\" Gilbert would later re-use this passage for Lady Jane in \"Patience\". Hebe was also assigned several lines of dialogue after No. 18 (\"Carefully on tiptoe stealing\") and again after No. 19 (\"Farewell, my own\").\nLate in rehearsals for the original production, Jessie Bond assumed the role of Hebe, replacing Mrs Howard Paul. Bond, who at this point in her career was known primarily as a concert singer and had little experience as an actress, did not feel capable of performing dialogue, and these passages were revised to cut Hebe's dialogue. Hebe's cut dialogue is occasionally restored in modern performances.\nRecitative preceding the Act II finale.\nThe dialogue preceding the Act II finale, starting with \"Here, take her sir, and mind you treat her kindly\", was originally recitative. The music for this passage was printed in the first edition of the vocal score as No. 20a. Shortly after opening night, the recitative was dropped, and the lines thereafter were performed as spoken dialogue. In modern productions, the recitative is occasionally restored in place of the dialogue.\nRecordings.\nThere have been numerous recordings of \"Pinafore\" since 1907. Ian Bradley counted seventeen recordings of the opera available on CD in 2005.\nThe 1930 recording is notable for preserving the performances of the D'Oyly Carte Opera Company stars of the era. The 1960 D'Oyly Carte recording, which contains all the dialogue, has been repeatedly praised by reviewers. The 1994 Mackerras recording, featuring grand opera singers in the principal roles, is musically well regarded. The 2000 D'Oyly Carte recording also contains complete dialogue and the first recording of the \"lost\" ballad for Captain Corcoran, \"Reflect, my child\", as a bonus track. A 1957 Danish-language recording of the opera is one of the few foreign-language professional recordings of Gilbert and Sullivan.\nIn 1939, \"Pinafore\" was chosen by NBC as one of the earliest operas ever broadcast on American television, but no recording is known to have been saved. The 1973 D'Oyly Carte video recording, directed by Michael Heyland, features the company's staging of the period, but some reviewers find it dull. It is, however, one of only three video or film recordings of a Gilbert and Sullivan opera by the D'Oyly Carte Opera Company. In 1982, Brent Walker Productions produced \"Pinafore\" as part of its series of Gilbert and Sullivan television films. According to discographer Marc Shepherd, the \"Pinafore\" video \"is widely considered one of the worst\" in the series. More recent professional productions have been recorded on video by the International Gilbert and Sullivan Festival.\nAdaptations.\n\"H.M.S. Pinafore\" has been adapted many times. W. S. Gilbert wrote a 1909 children's book called \"The Pinafore Picture Book\", illustrated by Alice Woodward, which retells the story of \"Pinafore\", giving considerable backstory details not found in the libretto. Many other children's books have since been written retelling the story of \"Pinafore\" or adapting characters or events from \"Pinafore\".\nMany musical theatre adaptations have been produced since the original opera. Notable examples include a 1945 Broadway musical adapted by George S. Kaufman, called \"Hollywood Pinafore\", using Sullivan's music. This was revived several times, including in London in 1998. Another 1945 Broadway musical adaptation, \"Memphis Bound\", was written by Don Walker and starred Bill Robinson and an all-black cast. In 1940, the American Negro Light Opera Association produced the first of several productions set in the Caribbean Sea, \"Tropical Pinafore\". An early Yiddish adaptation of \"Pinafore\", called \"Der Shirtz\" (Yiddish for \"apron\") was written by Miriam Walowit in 1949 for a Brooklyn Hadassah group; they toured the adaptation, and they recorded 12 of the songs. In the 1970s, Al Grand was inspired by this recording and urged the Gilbert and Sullivan Long Island Light Opera Company to perform these songs. He later translated the missing songs and dialogue, with Bob Tartell, and the show has been toured widely under the name \"Der Yiddisher Pinafore\". The group have continued to produce this adaptation for over two decades, in which \"He is an Englishman\" becomes \"Er Iz a Guter Yid\" (\"He is a good Jew\").\nEssgee Entertainment produced an adapted version of \"Pinafore\" in 1997 in Australia and New Zealand that has been much revived. Another musical adaptation is \"Pinafore! (A Saucy, Sexy, Ship-Shape New Musical)\", adapted by Mark Savage. It was first performed at the Celebration Theater in Los Angeles on 7 September 2001, directed by Savage, where it ran with great success for nine months. It then played in Chicago and New York in 2003. In this adaptation, only one character is female, and all but one of the male characters are gay. An original cast recording was issued in 2002 by Belva Records. \"Pinafore Swing\" is a musical with music arranged by Sarah Travis. It premiered at the Watermill Theatre in England in 2004 in a production directed by John Doyle. The adaptation, set in 1944, changes the characters into members of a band entertaining the sailors on a World War II troop ship in the Atlantic. The reduced-size acting cast also serve as the orchestra for the singing roles, and the music is infused with swing rhythms. Numerous productions in recent decades have been set to parody \"Star Trek\" or \"Star Wars\". An adaptation titled \"H.M.S. Pinafore, or Dauntless Dick Deadeye\", was produced in 2005 at the Regent's Park Open Air Theatre; extensive additional Gilbert-style dialogue by Herbert Appleman makes \"raconteur\" Deadeye the central character. Ian Talbot directed, and Gary Wilmot starred as Deadeye, with Scarlett Strallen as Josephine, Desmond Barrit as Sir Joseph and Leslie Nichol as Buttercup. Both the production and Strallen were nominated for 2006 Olivier Awards.\nCultural impact.\nDevelopment of the modern musical.\nAmong its other influences on popular culture, \"Pinafore\" had perhaps its most profound influence on the development of musical theatre. According to theatre historian John Kenrick, \"Pinafore\" \"became an international sensation, reshaping the commercial theater in both England and the United States.\" The music writer Andrew Lamb notes, \"The success of \"H.M.S. Pinafore\" in 1879 established British comic opera alongside French op\u00e9ra bouffe throughout the English-speaking world\". The historian John Bush Jones opines that \"Pinafore\" and the other Savoy operas demonstrate that musical theatre \"can address contemporary social and political issues without sacrificing entertainment value\" and that \"Pinafore\" created the model for a new kind of musical theatre, the \"integrated\" musical, where \"book, lyrics, and music combined to form an integral whole\". He adds that its \"unprecedented\u00a0... popularity fostered an American audience for musical theatre, while the show itself became a model for form, content, and even intention of\u00a0... musicals ever since, especially socially relevant musicals.\" Its popularity also led to the musical theatre adaptations of \"Pinafore\" described above, musicals in which the story line involves a production of \"Pinafore\" and other musicals that parody the opera or that use or adapt its music. The first such parody was a short-lived burlesque presented at the Opera Comique in 1882, called \"The Wreck of the Pinafore\" by William Horace Lingard and Luscombe Searelle; the opera's characters are shipwrecked on a desert island. It was described by \"The Era\" as \"chiefly remarkable for its impudence\".\nLiterary and political references.\nThe opera's popularity has led to the widespread parody and pastiche of its songs in comedy routines, literature and other media. Many comedians have used \"Pinafore\" songs for comic and satiric effect. For example, in his comedy album \"My Son, the Celebrity\", Allan Sherman parodies \"When I Was a Lad\" from the point of view of a young man who goes to an Ivy League school and then rises to prominence in business. At the end of the song, he \"thanks old Yale\", \"thanks the Lord\" and thanks his father, \"who is chairman of the board\". Literary references to \"Pinafore\" songs include Harris's attempt to sing \"When I Was a Lad\" in Jerome K. Jerome's \"Three Men in a Boat\". Another is found in the story \"Runaround\" from \"I, Robot\" by Isaac Asimov, where a robot sings part of \"I'm Called Little Buttercup\". \"Pinafore\" and its songs have been performed by rock musicians such as Todd Rundgren, Taj Mahal and Michele Gray Rundgren, who performed \"Never Mind the Why and Wherefore\" on \"Night Music\" (\"Sunday Night\") in 1989.\nPolitical references include a 1996 satiric pastiche of \"When I Was a Lad\" aimed at Tony Blair by Virginia Bottomley, heritage secretary under John Major. Sporting references include a racehorse named \"H.M.S. Pinafore\". \"Pinafore\" songs and images have been used extensively in advertising. According to Jones, \"\"Pinafore\" launched the first media blitz in the United States\" beginning in 1879, and recent ads include a television campaign for Terry's Chocolate Orange featuring a pastiche of \"When I Was a Lad\". \"Pinafore\"-themed merchandise includes trading cards that were created in the 1880s.\nFilm and television references.\nSongs from \"Pinafore\" have been used to give period flavor to such films as the 1981 historical film \"Chariots of Fire\", in which the protagonist, Harold Abrahams, and others from Cambridge University, sing \"He Is an Englishman\". This song also features at the end of the 1983 BBC drama \"An Englishman Abroad\". In the 2003 movie \"Peter Pan\", the Darling family sings \"When I Was a Lad\". In \"Wyatt Earp\" (1994), the famed lawman meets his future wife when he sees her playing in an early production of \"Pinafore\". A 1953 biopic, \"The Story of Gilbert and Sullivan\", uses music from \"Pinafore\".\nCharacters also sing songs from \"Pinafore\" in such popular films as \"Raiders of the Lost Ark\" (1981) and \"\" (1998), where Captain Picard and Lt. Commander Worf sing part of \"A British Tar\" to distract a malfunctioning Lt. Commander Data. \"The Good Shepherd\" (2006) depicts an all-male version of \"Pinafore\" at Yale University in 1939; Matt Damon's character plays Little Buttercup, singing in falsetto. Judy Garland sings \"I Am the Monarch of the Sea\" in the 1963 film \"I Could Go On Singing\". The soundtrack of the 1992 thriller \"The Hand that Rocks the Cradle\" prominently features songs and music from \"Pinafore\", and the father and daughter characters sing \"I Am the Captain of the Pinafore\" together. The 1976 animated film by Ronald Searle called \"Dick Deadeye, or Duty Done\" is based on the character and songs from \"Pinafore\". In the 1988 drama \"Permanent Record\", a high school class performs \"Pinafore\".\nTelevision series that include substantial \"Pinafore\" references include \"The West Wing\", for example in the 2000 episode \"And It's Surely to Their Credit\", where \"He Is an Englishman\" is used throughout and quoted (or paraphrased) in the episode's title. Among other notable examples of the use of songs from \"Pinafore\" on television are several popular animated shows. In the \"Cape Feare\" episode of \"The Simpsons\", Bart stalls his would-be killer Sideshow Bob with a \"final request\" that Bob sing him the entire score of \"Pinafore\". Similarly, the 1993 \"HMS Yakko\" episode of \"Animaniacs\" consists of pastiches of songs from \"H.M.S. Pinafore\" and \"The Pirates of Penzance\". In a \"Family Guy\" episode, \"The Thin White Line\" (2001), Stewie sings a pastiche of \"My Gallant Crew\". Stewie also sings \"I Am the Monarch of the Sea\" (including the ladies' part, in falsetto) in \"\". A 1986 \"Mr. Belvedere\" episode, \"The Play\", concerns a production of \"H.M.S. Pinafore\", and several of the songs are performed. In 1955, NBC broadcast a variety special including a 20-minute compressed jazz version, \"H.M.S. Pinafore in Jazz\", produced and directed by Max Liebman, starring Perry Como, Buddy Hackett, Kitty Kallen, Bill Hayes, Pat Carroll and Herb Shriner.\nHistorical casting.\nThe following tables show the most prominent cast members of significant D'Oyly Carte Opera Company productions and tours at various times through to the company's 1982 closure:\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nNotes, references and sources.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\nInformation\nImages\nAudio/visual"}
{"id": "47802", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=47802", "title": "General Telephone and Electronics", "text": ""}
{"id": "47804", "revid": "6209803", "url": "https://en.wikipedia.org/wiki?curid=47804", "title": "Extracorporeal shock wave lithotripsy", "text": ""}
{"id": "47805", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=47805", "title": "Vector quantization", "text": "Classical quantization technique from signal processing\nVector quantization (VQ) is a classical quantization technique from signal processing that allows the modeling of probability density functions by the distribution of prototype vectors. Developed in the early 1980s by Robert M. Gray, it was originally used for data compression. It works by dividing a large set of points (vectors) into groups having approximately the same number of points closest to them. Each group is represented by its centroid point, as in k-means and some other clustering algorithms. In simpler terms, vector quantization chooses a set of points to represent a larger set of points.\nThe density matching property of vector quantization is powerful, especially for identifying the density of large and high-dimensional data. Since data points are represented by the index of their closest centroid, commonly occurring data have low error, and rare data high error. This is why VQ is suitable for lossy data compression. It can also be used for lossy data correction and density estimation.\nVector quantization is based on the competitive learning paradigm, so it is closely related to the self-organizing map model and to sparse coding models used in deep learning algorithms such as autoencoder.\nTraining.\nThe simplest training algorithm for vector quantization is:\nA more sophisticated algorithm reduces the bias in the density matching estimation, and ensures that all points are used, by including an extra sensitivity parameter :\nIt is desirable to use a cooling schedule to produce convergence: see Simulated annealing. Another (simpler) method is LBG which is based on K-Means.\nThe algorithm can be iteratively updated with 'live' data, rather than by picking random points from a data set, but this will introduce some bias if the data are temporally correlated over many samples.\nApplications.\nVector quantization is used for lossy data compression, lossy data correction, pattern recognition, density estimation and clustering.\nLossy data correction, or prediction, is used to recover data missing from some dimensions. It is done by finding the nearest group with the data dimensions available, then predicting the result based on the values for the missing dimensions, assuming that they will have the same value as the group's centroid.\nFor density estimation, the area/volume that is closer to a particular centroid than to any other is inversely proportional to the density (due to the density matching property of the algorithm).\nUse in data compression.\nVector quantization, also called \"block quantization\" or \"pattern matching quantization\" is often used in lossy data compression. It works by encoding values from a multidimensional vector space into a finite set of values from a discrete subspace of lower dimension. A lower-space vector requires less storage space, so the data is compressed. Due to the density matching property of vector quantization, the compressed data has errors that are inversely proportional to density.\nThe transformation is usually done by projection or by using a codebook. In some cases, a codebook can be also used to entropy code the discrete value in the same step, by generating a prefix coded variable-length encoded value as its output.\nThe set of discrete amplitude levels is quantized jointly rather than each sample being quantized separately. Consider a \"k\"-dimensional vector formula_12 of amplitude levels. It is compressed by choosing the nearest matching vector from a set of \"n\"-dimensional vectors formula_13, with \"n\" &lt; \"k\".\nAll possible combinations of the \"n\"-dimensional vector formula_13 form the vector space to which all the quantized vectors belong.\nOnly the index of the codeword in the codebook is sent instead of the quantized values. This conserves space and achieves more compression.\nTwin vector quantization (VQF) is part of the MPEG-4 standard dealing with time domain weighted interleaved vector quantization.\nVideo codecs based on vector quantization.\nThe usage of video codecs based on vector quantization has declined significantly in favor of those based on motion compensated prediction combined with transform coding, e.g. those defined in MPEG standards, as the low decoding complexity of vector quantization has become less relevant.\nUse in pattern recognition.\nVQ was also used in the eighties for speech and speaker recognition.\nRecently it has also been used for efficient nearest neighbor search \nand on-line signature recognition. \nIn pattern recognition applications, one codebook is constructed for each class (each class being a user in biometric applications) using acoustic vectors of this user. In the testing phase the quantization distortion of a testing signal is worked out with the whole set of codebooks obtained in the training phase. The codebook that provides the smallest vector quantization distortion indicates the identified user.\nThe main advantage of VQ in pattern recognition is its low computational burden when compared with other techniques such as dynamic time warping (DTW) and hidden Markov model (HMM). The main drawback when compared to DTW and HMM is that it does not take into account the temporal evolution of the signals (speech, signature, etc.) because all the vectors are mixed up. In order to overcome this problem a multi-section codebook approach has been proposed. The multi-section approach consists of modelling the signal with several sections (for instance, one codebook for the initial part, another one for the center and a last codebook for the ending part).\nUse as clustering algorithm.\nAs VQ is seeking for centroids as density points of nearby lying samples, it can be also directly used as a prototype-based clustering method: each centroid is then associated with one prototype. \nBy aiming to minimize the expected squared quantization error and introducing a decreasing learning gain fulfilling the Robbins-Monro conditions, multiple iterations over the whole data set with a concrete but fixed number of prototypes converges to the solution of k-means clustering algorithm in an incremental manner.\nGenerative Adversarial Networks (GAN).\nVQ has been used to quantize a feature representation layer in the discriminator of Generative adversarial networks. The feature quantization (FQ) technique performs implicit feature matching. It improves the GAN training, and yields an improved performance on a variety of popular GAN models: BigGAN for image generation, StyleGAN for face synthesis, and U-GAT-IT for unsupervised image-to-image translation.\nSee also.\nSubtopics\nRelated topics\n\"Part of this article was originally based on material from the Free On-line Dictionary of Computing and is used with under the GFDL.\""}
{"id": "47813", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=47813", "title": "University of California at Los Angeles", "text": ""}
{"id": "47815", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=47815", "title": "OAS (disambiguation)", "text": ""}
{"id": "47822", "revid": "1244354499", "url": "https://en.wikipedia.org/wiki?curid=47822", "title": "Elk (disambiguation)", "text": "The elk (\"Cervus canadensis\") is a large antlered mammal within the deer family.\nElk may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
