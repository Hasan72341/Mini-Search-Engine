{"id": "49147", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=49147", "title": "Fair trade", "text": "Sustainable and equitable trade\nFair trade is a trade arrangement designed to help producers in developing countries achieve sustainable and equitable conditions. The fair trade movement advocates paying higher prices to exporters and improving social and environmental standards. The movement focuses in particular on commodities, or products that are typically exported from developing countries to developed countries but are also used in domestic markets (e.g., Brazil, the United Kingdom and Bangladesh), most notably for handicrafts, coffee, cocoa, wine, sugar, fruit, flowers and gold.\nFair trade labelling organizations commonly use a definition of \"fair trade\" developed by FINE, an informal association of four international fair trade organizations: Fairtrade International (formerly called FLO, Fairtrade Labelling Organizations International), World Fair Trade Organization (WFTO), Network of European Worldshops and European Fair Trade Association (EFTA). Fair trade, by this definition, is a trading partnership based on dialogue, transparency and respect, that seeks greater equity in international trade. Fair trade organizations, backed by consumers, support producers, raise awareness and campaign for changes in the rules and practice of conventional international trade.\n\"Fair trade certifiers\" include Fairtrade International, Ecocert, Fair World Project and Fair Trade USA, whose labelling scheme includes independent smallholders and estates for crops. In 2008, Fairtrade International certified approximately (\u20ac3.4B) of products.\nOn 6 June 2008, Wales became the world's first ; followed by Scotland in February 2013. The fair trade movement is popular in the UK, where there are over 500 , 118 universities, over 6,000 churches, and over 4,000 UK schools registered in the . In 2011, more than 1.2 million farmers and workers in more than 60 countries participated in Fairtrade International's fair trade system, which included \u20ac65 million in fairtrade premium paid to producers for use developing their communities.\nSome criticisms have been raised about fair trade systems, including that fair trade certification has not led to financial benefit to producers or improvement in working conditions, and that fair trade certification has resulted in greater inequalities in some markets. \nA proposed alternative to fair trade is direct trade, which eliminates the overhead costs of the fair trade certification and allows suppliers to receive higher prices closer to the retail value of the end product. Some suppliers use relationships started in a fair trade system to initiate direct sales relationships they negotiate themselves, whereas other direct trade systems are supplier-initiated for social responsibility reasons similar to a fair trade systems.\nHistory.\nThe first attempts to commercialize fair trade goods in markets in the global north were initiated in the 1940s and 1950s by religious groups and various politically oriented non-governmental organizations (NGOs). Ten Thousand Villages, an NGO within the Mennonite Central Committee (MCC), and SERRV International were the first, in 1946 and 1949 respectively, to develop fair trade supply chains in developing countries. The products, almost exclusively handicrafts ranging from jute goods to cross-stitch work, were mostly sold in churches or fairs. The goods themselves had often no other function than to indicate that a donation had been made.\nSolidarity trade.\nThe current fair trade movement was shaped in Europe in the 1960s. Fair trade during that period was often seen as a political gesture against neo-imperialism: radical student movements began targeting multinational corporations, and concerns emerged that traditional business models were fundamentally flawed. The slogan at the time, \"Trade not Aid\", gained international recognition in 1968 when it was adopted by the United Nations Conference on Trade and Development (UNCTAD) to put the emphasis on the establishment of fair trade relations with the developing world.\n1965 saw the creation of the first alternative trading organization (ATO): that year, British NGO Oxfam launched \"Helping-by-Selling\", a program that sold imported handicrafts in Oxfam stores in the UK and from mail-order catalogues.\nBy 1968, the Whole Earth Catalog was connecting thousands of specialized merchants, artisans, and scientists directly with consumers who were interested in supporting independent producers, with the goal of bypassing corporate retail and department stores. The Whole Earth Catalog sought to balance the international free market by allowing direct purchasing of goods produced primarily in the U.S. and Canada but also in Central and South America.\nIn 1969, the first worldshop opened its doors in the Netherlands. It aimed at bringing the principles of fair trade to the retail sector by selling almost exclusively goods produced under fair trade terms in \"underdeveloped regions\". The first shop was run by volunteers and was so successful that dozens of similar shops soon went into business in the Benelux countries, Germany, and other Western European countries.\nHandicrafts vs. agricultural goods.\nIn the early 1980s, alternative trading organizations faced challenges: the novelty of fair trade products began to wear off, demand reached a plateau and some handicrafts began to look \"tired and old fashioned\" in the marketplace. The decline of segments of the handicrafts market forced fair trade supporters to rethink their business model and their goals. Moreover, several fair trade supporters were worried by the effect on small farmers of structural reforms in the agricultural sector as well as the fall in commodity prices. Many came to believe it was the movement's responsibility to address the issue and remedies usable in the ongoing crisis in the industry.\nIn subsequent years, fair trade agricultural commodities played an important role in the growth of many ATOs: successful on the market, they offered a source of income for producers and provided alternative trading organizations a complement to the handicrafts market. The first fair trade agricultural products were tea and coffee, followed by: dried fruits, cocoa, sugar, fruit juices, rice, spices and nuts. While in 1992, a sales value ratio of 80% handcrafts to 20% agricultural goods was the norm, in 2002 handcrafts amounted to 25% of fair trade sales while commodity food was up at 69%.\nRise of labeling initiatives.\nSales of fair trade products only took off with the arrival of the first Fairtrade certification initiatives. Although buoyed by growing sales, fair trade had been generally confined to small worldshops scattered across Europe and, to a lesser extent, North America. The inconvenience of going to them to buy only a product or two was too high even for the most dedicated customers. The only way to increase sale opportunities was to offer fair trade products where consumers normally shop, in large distribution channels. The problem was to find a way to expand distribution without compromising consumer trust in fair trade products and in their origins.\nA solution was found in 1988, when the first fair trade certification initiative, Max Havelaar, was created in the Netherlands under the initiative of Nico Roozen, Frans Van Der Hoff, and Dutch development NGO Solidaridad. The independent certification allowed the goods to be sold outside the worldshops and into the mainstream, reaching a larger consumer segment and boosting fair trade sales significantly. The labeling initiative also allowed customers and distributors alike to track the origin of the goods to confirm that the products were really benefiting the producers at the end of the supply chain.\nThe concept caught on: in ensuing years, similar non-profit Fairtrade labelling organizations were set up in other European countries and North America. In 1997, a process of convergence among \"LIs\" (\"Labeling Initiatives\") led to the creation of Fairtrade Labelling Organizations International, an umbrella organization whose mission is to set fair trade standards, support, inspect, and certify disadvantaged producers, and harmonize the fair trade message across the movement.\nIn 2002, FLO launched an International Fairtrade Certification Mark. The goals were to improve the visibility of the Mark on supermarket shelves, facilitate cross border trade, and simplify procedures for both producers and importers. The certification mark is used in more than 50 countries and on dozens of different products, based on FLO's certification for coffee, tea, rice, bananas, mangoes, cocoa, cotton, sugar, honey, fruit juices, nuts, fresh fruit, quinoa, herbs and spices, wine, footballs, etc.\nWith ethical labeling, consumers can take moral responsibility for their economic decisions and actions. This supports the notion of fair trade practices as \"moral economies\". The presence of labeling gives consumers the feeling of \"doing the right thing\" with a simple purchase.\nLabeling practices place the burden of getting certification on the producers in the Global South, furthering inequality between the Global North and the Global South. The process of securing certification is burdensome and expensive. Northern consumers are able to make a simple choice while being spared these burdens and expenses.\nLarge companies as buyers.\nLarge transnational companies have started to use fair trade commodities in their products. In April 2000, Starbucks began offering fair trade coffee in all of their stores. In 2005, the company promised to purchase ten million pounds of fair trade coffee over the next 18 months. This would account for a quarter of the fair trade coffee purchases in the United States and 3% of Starbucks' total coffee purchases. The company maintains that increasing its fair trade purchases would require an unprofitable reconstruction of the supply chain. Fair trade activists have made gains with other companies: Sara Lee Corporation in 2002 and Procter &amp; Gamble (the maker of Folgers) in 2003 agreed to begin selling a small amount of fair trade coffee. Nestl\u00e9, the world's biggest coffee trader, began selling a blend of fair trade coffee in 2005. In 2006, The Hershey Company acquired Dagoba, an organic and fair trade chocolate brand.\nMuch contention surrounds the issue of fair trade products becoming a part of large companies. Starbucks is still only 3% fair trade\u2013enough to appease consumers, but not enough to make a real difference to small farmers, according to some activists. The ethics of buying fair trade from a company that is not committed to the cause are questionable; these products are only making a small dent in a big company even though these companies' products account for a significant portion of global fair trade.\nOrganizations promoting fair trade.\nMany organizations promote fair trade, including certifiers of products, certifiers of organizations, associations, retailers, education and advocacy groups, student groups, religious organizations and universities.\nMost fair trade import organizations are members of, or certified by, one of several national or international federations. These federations coordinate, promote, and facilitate the work of fair trade organizations.\nRetailers.\nWorldshops.\nWorldshops, or fair trade shops, are specialized retail outlets that offer and promote fair trade products. Worldshops also typically organize educational fair trade activities and play a role in trade justice and other . Worldshops are often not-for-profit organizations run by local volunteer networks. The movement emerged in Europe and a majority of worldshops are still based on the continent, but worldshops also exist in North America, Australia, and New Zealand.\nWorldshops aim to make trade as direct and fair with the trading partners as possible. Usually, this means a producer in a developing country and consumers in industrialized countries. Worldshops aim to pay the producers a fair price that guarantees substinence and positive social development. They often cut out intermediaries in the import chain. A web movement began in the 2000s to provide fair trade items at fair prices to consumers. One is \"Fair Trade a Day\" on which a different fair trade item is featured each day.\nAlternative trading organizations.\nAn alternative trading organization (ATO) is usually a non-governmental organization (NGO) or mission-driven business aligned with the fair trade movement that aims \"to contribute to the alleviation of poverty in developing regions of the world by establishing a system of trade that allows marginalized producers in developing regions to gain access to developed markets.\" ATOs have fair trade at the core of their mission and activities, using it as a development tool to support disadvantaged producers and to reduce poverty and combining their marketing with awareness-raising and campaigning.\nATOs are often based on political and religious groups, though their secular purpose precludes sectarian identification and evangelical activity.\nAccording to EFTA, the defining characteristic of ATOs is equal partnership and respect\u2013partnership between the developing region producers and importers, shops, labelling organizations, and consumers. Alternative trade \"humanizes\" the trade process\u2013making the producer-consumer chain as short as possible so that consumers become aware of the culture, identity, and conditions in which producers live. are committed to the principle of alternative trade, the need for , and the importance of awareness-raising and advocacy work. Examples of such organisations are Ten Thousand Villages, Greenheart Shop, Equal Exchange, and SERRV International in the U.S. and Equal Exchange Trading, Traidcraft, Oxfam Trading, Twin Trading, and Alter Eco in Europe as well as Siem Fair Trade Fashion in Australia.\nEducation and Advocacy.\nFair World Project.\nStudent groups.\nStudent groups have also been increasingly promoting fair trade products. Although hundreds of independent student organizations are active worldwide, most groups in North America are either affiliated with United Students for Fair Trade (USA), the Canadian Student Fair Trade Network (Canada), or Fair Trade Campaigns (USA), which also houses Fair Trade Universities and Fair Trade Schools.\nReligious organizations.\nThe involvement of church organizations has been and continues to be an integral part of the fair trade movement:\nUniversities.\nThe concept of a Fair Trade school or Fair Trade university emerged from the United Kingdom, where the Fairtrade Foundation maintains a list of colleges and schools that comply with the requirements to be labeled such a university. In order to be considered a Fair Trade University, a university must establish a Fairtrade School Steering Group. They must have a written and implemented, school-wide, fair trade policy. The school or university must be dedicated to selling and using Fair Trade products. They must learn and educate about Fair Trade issues. Finally, they must promote fair trade not only within the school but throughout the wider community.\nA Fair Trade University develops all aspects of fair trade practices in their coursework. In 2007, the Director of the Environmental Studies program at the University of Wisconsin-Oshkosh, David Barnhill, endeavored to become the first Fair Trade University. This received positive reactions from faculty and students. To begin, the university agreed that it would need support from four institutional groups\u2014faculty, staff, support staff, and students\u2014to maximize support and educational efforts. The University endorsed the Earth Charter and created a Campus Sustainability Plan to align with the efforts of becoming a Fair Trade University.\nThe University of Wisconsin-Oshkosh also offers courses in different disciplines that implement fair trade learning. They offer a business course with a trip to Peru to visit coffee farmers, an environmental science class that discusses fair trade as a way for cleaner food systems, an English course that focuses on the Earth Charter and the application of fair trade principles, and several upper-level anthropology courses focused on fair trade.\nIn 2010, the University of California, San Diego became the second Fair Trade University in the United States. UC San Diego considered the efforts of the Fairtrade Foundation in the UK, but wanted to be more detailed about how their declaration as a Fair Trade University would change the way on-campus franchises do business with the university. They required constant assessment and improvement. Being a Fair Trade University for UC San Diego is a promise between the university and the students about the continual effort by the university to increase the accessibility of fair trade-certified food and drinks and to encourage sustainability in other ways, such as buying from local, organic farmers and decreasing waste.\nFair Trade Universities have been successful because they are a \"feel good\" movement. Because the movement has an established history, it is not just a fad. It raises awareness about an issue and offers a solution. The solution is an easy one for college students to handle: paying about five cents more for a cup of coffee or tea.\nFair Trade towns.\nA Fair Trade town is a town (or other local geographical region) that complies with some Fair Trade criteria.\nOther.\nIn 1998, the four federations: Fairtrade International (formerly called FLO, Fairtrade Labelling Organizations International), World Fair Trade Organization (WFTO), Network of European Worldshops and European Fair Trade Association (EFTA).joined together as FINE, an informal association whose goal is to harmonize fair trade standards and guidelines, increase the quality and efficiency of fair trade monitoring systems, and advocate fair trade politically.\nProduct certification.\nFairtrade International.\nFairtrade labelling (usually simply Fairtrade or Fair Trade Certified in the United States) is a certification system that allows consumers to identify goods that meet certain standards. Overseen by a standard-setting body (Fairtrade International) and a certification body (FLO-CERT), the system involves independent auditing of producers and traders to ensure the standards are met. For a product to carry either the International Fairtrade Certification Mark or the Fair Trade Certified Mark, it must come from FLO-CERT inspected and certified producer organizations. The crops must be grown and harvested in accordance with the standards set by FLO International. The supply chain must be monitored by FLO-CERT, to ensure the integrity of the labelled product.\nFairtrade certification purports to guarantee not only fair prices, but also ethical purchasing principles. These principles include adherence to ILO agreements such as those banning child and slave labour, guaranteeing a safe workplace and the right to unionise, adherence to the United Nations charter of human rights, a fair price that covers the cost of production and facilitates social development, and protection of the environment. The Fairtrade certification also attempts to promote long-term business relationships between buyers and sellers, crop pre-financing, and greater transparency throughout the supply chain.\nThe Fairtrade certification system covers a growing range of products, including bananas, honey, coffee, oranges, Cocoa bean, cocoa, cotton, dried and fresh fruits and vegetables, juices, nuts and oil seeds, quinoa, rice, spices, sugar, tea and wine. Companies offering products that meet Fairtrade standards may apply for licences to use one of the Fairtrade Certification Marks for those products. The International Fairtrade Certification Mark was launched in 2002 by FLO, and replaced twelve Marks used by various Fairtrade labelling initiatives. The new Certification Mark is currently used worldwide (with the exception of the United States). The Fair Trade Certified Mark is still used to identify Fairtrade goods in the United States.\nTo gain a licence to use the FAIRTRADE mark, businesses need to apply for products to be certified by submitting information about their supply chain. Then they can have individual products certified depending on how these are sourced. Coffee packers in developed countries pay a fee to the Fairtrade Foundation for the right to use the brand and logo. Packers and retailers can charge as much as they want for the coffee. The coffee has to come from a certified fair trade cooperative, and there is a minimum price when the world market is oversupplied. Additionally, the cooperatives are paid an additional per pound premium by buyers for community development projects. The cooperatives can, on average, sell only a third of their output as fair trade, because of lack of demand, and sell the rest at world prices. The exporting cooperative can spend the money in several ways. Some go to meeting the costs of conformity and certification: as they have to meet fair trade standards on all their produce, they have to recover the costs from a small part of their turnover, sometimes as little as 8%, and may not make any profit. Some meet other costs. Some is spent on social projects such as building schools, health clinics and baseball pitches. Sometimes there is money left over for the farmers. The cooperatives sometimes pay farmers a higher price than farmers do, sometimes less, but on which is more common.\nTo become a \"certified fair trade producer\", the primary cooperative and its member farmers must operate to certain political standards, imposed from Europe. FLO-CERT, the for-profit side, handles producer certification, inspecting and certifying producer organizations in more than 50 countries in Africa, Asia, and Latin America. In the fair trade debate there are many complaints of failure to enforce these standards, with producers, cooperatives, importers, and packers profiting by evading them.\nDefinition of \"producer\".\nThe fair trade industry standards provided by Fairtrade International use the word \"producer\" in many different senses, often in the same specification document. Sometimes it refers to farmers, sometimes to the primary cooperatives they belong to, to the secondary cooperatives that the primary cooperatives belong to, or to the tertiary cooperatives that the secondary cooperatives may belong to but \"Producer [also] means any entity that has been certified under the Fairtrade International Generic Fairtrade Standard for Small Producer Organizations, Generic Fairtrade Standard for Hired Labour Situations, or Generic Fairtrade Standard for Contract Production.\" The word is used in all these meanings in key documents. In practice, when price and credit are discussed, \"producer\" means the exporting organization, \"For small producers' organizations, payment must be made directly to the certified small producers' organization\". and \"In the case of a small producers' organization [e.g. for coffee], Fairtrade Minimum Prices are set at the level of the Producer Organization, not at the level of individual producers (members of the organization)\" which means that the \"producer\" here is halfway up the marketing chain between the farmer and the consumer. The part of the standards referring to cultivation, environment, pesticides, and child labour has the farmer as \"producer\".\nSystem.\nA large number of fair trade and ethical marketing organizations employ a variety of marketing strategies. Most fair trade marketers believe it is necessary to sell the products through supermarkets to get a sufficient volume of trade to affect the developing world. In 2018, nearly 700,000 metric tons of fair-trade bananas were sold worldwide, with the next largest fair-trade commodity being cocoa beans (260,000 tons) then coffee beans (207,000 tons). The biggest product in the market in terms of units was fair-trade flowers, with over 825 million units sold.\nThere remain many fair trade organizations that adhere more or less to the original objectives of fair trade and that market products through alternative channels where possible and through specialist fair trade shops, but they have a small proportion of the total market compared to Fairtrade International.\nEffect on growers.\nFair trade benefits workers in developing countries. The nature of fair trade makes it a global phenomenon; therefore, there are diverse motives for group formation related to fair trade. The social transformation caused by the fair trade movement also varies around the world.\nA study of coffee growers in Guatemala illustrates the effect of fair trade practices on growers. In this study, thirty-four farmers were interviewed. Of those thirty-four growers, twenty-two had an understanding of fair trade based on internationally recognized definitions, for example, describing fair trade in market and economical terms or knowing what the social premium is and how their cooperative has used it. Three growers explained a deep understanding of fair trade, showing a knowledge of both fair market principles and how fair trade affects them socially. Nine growers had erroneous or no knowledge of Fair Trade. The three growers who had a deeper knowledge of the social implications of fair trade all had responsibilities within their cooperatives. One was a manager, one was in charge of the wet mill, and one was his group's treasurer. These farmers did not have in terms of years of education, age, or years of membership in the cooperative; their answers to the questions, \"Why did you join?\" differentiate them from other members and explain why they have such an extensive knowledge of fair trade. These farmers cited switching to organic farming, wanting to raise money for social projects, and more training offered as reasons for joining the cooperative, other than receiving a better price for their coffee.\nMany farmers around the world are unaware of fair trade practices that they could be implementing to earn a higher wage. Coffee is one of the most highly traded commodities in the world, yet the farmers who grow it typically earn less than $2 a day. When surveyed, farmers from Cooperativa Agraria Cafetalera Pangoa (CAC Pangoa) in San Mart\u00edn de Pangoa, Peru, could answer positively that they have heard about fair trade, but were not able to give a detailed description about what fair trade is. They could, however, identify fair trade based on some of its possible benefits to their community. When asked, farmers responded that fair trade has had a positive effect on their lives and communities. They also wanted consumers to know that fair trade is important for supporting their families and their cooperatives. Overall, the farmers studied were satisfied with the current fair trade system, but some of them, such as the Mazaronquiari group of the CAC, desire yet a higher price for their products in order to live a higher quality of life.\nSome producers also profit from the indirect benefits of fair trade practices. Fair trade cooperatives create a space of solidarity and promote an entrepreneurial spirit among growers. When growers feel like they have control over their own lives within the network of their cooperative, it can be empowering. Operating a profitable business allows growers to think about their future, rather than worrying about how they are going to survive in poverty.\nSocial premium.\nA component of fair trade is the extra money that buyers of fair trade goods pay to the producers or producer-groups, sometimes referred to as a \"social premium.\" The producers or producer-groups decide where and how to spend the social premium.. These premiums usually go towards socioeconomic development, wherever the producers or producer-groups see fit. Within producer-groups, the decisions about how the social premium will be spent are handled democratically, with transparency and .\nProducers and producer-groups spend this social premium to support socioeconomic development in a variety of ways. One common way to spend the social premium of fair trade is to privately invest in public goods that infrastructure and the government are lacking in. These include environmental initiatives, public schools, and water projects. At some point, all producer-groups re-invest their social premium back into their farms and businesses. They buy capital, like trucks and machinery, and education for their members, like organic farming education. Thirty-eight percent of producer-groups spend the social premium in its entirety on themselves, but the rest invest in public goods, like paying for teachers' salaries, providing a community health care clinic, and improving infrastructure, such as bringing in electricity and bettering roads.\nFarmers' organisations that use their social premium for public goods often finance educational scholarships. For example, Costa Rican coffee cooperative Coocaf\u00e9 has supported hundreds of children and youth at school and university through the financing of scholarships from funding from their fair trade social premium. In terms of education, the social premium can be used to build and furnish schools too.\nPsychology.\nConsumers of fair trade products usually make the intentional choice to purchase fair trade goods based on , moral norms, and social norms. \nUniversity students have significantly increased their consumption of fair trade products over the last several decades. Women college students have a more favorable attitude than men toward buying fair trade products and they feel more morally obligated to do so. Women are also reported to have stronger intentions to buy fair trade products. \nProducers organize and strive for fair trade certification for several reasons, either through religious ties, wants for social justice, wants for autonomy, political liberalization or simply because they want to be paid more for their labor efforts and products. Farmers are more likely to identify with organic farming than fair trade farming practices because organic farming is a visible way that these farmers are different from their neighbors and it influences the way they farm. They place importance on natural growing methods. Fair trade farmers are also more likely to attribute their higher prices to the quality of their products rather than fair market prices.\nWorld wide.\nEvery year the sales of Fair Trade products grow close to 30% and in 2004 were worth over million. In the case of coffee, sales grow nearly 50% per year in certain countries. In 2002, 16,000 tons of Fairtrade coffee were purchased by consumers in 17 countries. \"Fair trade coffee is currently produced in 24 countries in Latin America, Africa, and Asia\". The 165 FLO associations in Latin America and Caribbean are located in 14 countries and As of 2004[ [update]] together export over 85% of the world's Fair Trade coffee. There is a North/South divide of fair trade products, with producers in the South and consumers in the North. Discrepancies in the perspectives of producers and consumers prompt disputes about how the purchasing power of consumers may or may not promote the development of southern countries. \"Purchasing patterns of fairtrade products have remained strong despite the global economic downturn. In 2008, global sales of fairtrade products exceeded billion.\"\nAfrica.\nAfrica\u2019s labor market is becoming an integral fragment of the global supply chain (GSC) and is expected to attract foreign direct investment (FDI). As the continent closes its infrastructure gap, it increases its export to the world. Africa's exports, from places like South Africa, Ghana, Uganda, Tanzania and Kenya, were valued at million As of 2009[ [update]]. Between 2004 and 2006, Africa expanded the number of FLO-certified producer groups from 78 to 171, nearly half of which are in Kenya; following closely behind are Tanzania and South Africa. The FLO products Africa is known for are tea, cocoa, flowers, and wine. In Africa smallholder cooperatives and plantations produce Fair Trade certified tea. Cocoa-producing countries in West Africa often form cooperatives that produce fair trade cocoa, such as Kuapa Kokoo in Ghana. West African countries without strong fair trade industries are subject to deterioration in cocoa quality as they compete with other countries for a profit. These countries include Cameroon, Nigeria, and the Ivory Coast.\nLatin America.\nStudies in the early 2000s showed that the income, education, and health of coffee producers involved with Fair Trade in Latin America improved in comparison to producers who were not participating. Brazil, Nicaragua, Peru, and Guatemala, having the biggest populations of coffee producers, use some of the for coffee production in Latin America and do so by taking part in Fair Trade.\nLatin American countries are also large exporters of fair trade bananas. The Dominican Republic is the largest producer of fair trade bananas, followed by Mexico, Ecuador, and Costa Rica. Producers in the Dominican Republic set up associations rather than cooperatives so that individual farmers can each own their own land, but meet regularly.\nFundaci\u00f3n Solidaridad was created in Chile to increase the earnings and social participation of handicraft producers. These goods are marketed locally in Chile and internationally. Fair trade handicraft and jewellery production has risen in recent years, aided by North American and European online retailers developing direct relationships to import and sell the products online. The sale of fair trade handicrafts online has aided the development of female artisans in Latin America.\nAsia.\nThe Asia Fair Trade Forum aims to increase the competitiveness of fair trade organizations in Asia in the global market. Garment factories in Asian countries including China, Burma and Bangladesh are regularly accused of human rights violations, including the use of child labour. These violations conflict with the principles outlined by fair trade certifiers. In India, Trade Alternative Reform Action (TARA) Projects, formed in the 1970s, worked to increase production capacity, quality standards, and entrance into markets for home-based craftsmen that were previously unattainable due to their lower caste identity. Fairtrade India was established in 2013 in Bangalore.\nAustralia.\nThe Fair Trade Association of Australia and New Zealand (FTAANZ) supports two systems of fair trade: The first is as the Australia and New Zealand member of FLO International, which unites Fairtrade producer and labelling initiatives across Europe, Asia, Latin America, North America, Africa, Australia, and New Zealand. The second is the World Fair Trade Organization (WFTO), of more than 450 worldwide members, of which FTAANZ is one. Fairtrade (one word) refers to FLO-certified commodities and associated products. Fair trade (two words) encompasses the wider fair trade movement, including the Fairtrade commodities and other artisan craft products.\nCommodities.\nFair trade commodities are import/export goods that are certified by a fair trade certification organization such as Fair Trade USA or World Fair Trade Organization. Such organizations are typically overseen by Fairtrade International. Fairtrade International sets international fair trade standards and supports fair trade producers and cooperatives. Sixty percent of the fair trade market consists of food products such as coffee, tea, cocoa, honey, and bananas. Non-food commodities include crafts, textiles, and flowers. Shima Baradaran of Brigham Young University suggests that fair trade techniques could child labor. Although fair trade represents only .01% of the food and beverage industry in the United States, it is growing rapidly.\nCoffee.\nCoffee is the most well-established fair trade commodity. Most Fair Trade coffee is \"Coffea arabica,\" which is grown at high altitudes. Fair Trade markets emphasize the quality of coffee because they usually appeal to customers who are motivated by taste rather than price. The fair trade movement fixated on coffee first because it is a highly traded commodity for most producing countries, and almost half the world's coffee is produced by smallholder farmers. At first fair trade coffee was sold at small scale; now multinationals like Starbucks and Nestl\u00e9 use fair trade coffee. As of 2006, Starbucks was the world's largest purchaser of fair trade coffee.\nInternationally recognized Fair Trade coffee standards outlined by FLO are as follows: small producers are grouped in democratic cooperatives or groups; buyers and sellers establish long-term, stable relationships; buyers pay the producers at least the minimum Fair Trade price or, when the market price is higher, the market price; and, buyers pay a social premium of per pound of coffee to the producers. The current minimum Fair Trade price for high-grade, washed Arabica coffee is per pound; per pound if the coffee is organic.\nThe marketing system for fair trade and non-fair trade coffee is identical in the consuming and developing countries, using mostly the same importing, packing, distributing, and retailing firms used worldwide. Some independent brands operate a \"virtual company\", paying importers, packers and distributors, and advertising agencies to handle their brand, for cost reasons. In the producing country, fair trade is marketed only by fair trade cooperatives, while other coffee is marketed by fair trade cooperatives (as uncertified coffee), by other cooperatives and by ordinary traders.\nLocations.\nThe largest sources of fair trade coffee are Uganda and Tanzania, followed by Latin American countries such as Guatemala and Costa Rica. As of 1999, major importers of fair trade coffee included Germany, the Netherlands, Switzerland, and the United Kingdom. There is a North/South divide between fair trade consumers and producers. North American countries are not yet among the top importers of fair trade coffee.\nLabour.\nStarbucks began to purchase more fair trade coffee in 2001 because of charges of labor rights violations in Central American plantations. Several competitors, including Nestl\u00e9, followed suit. Large corporations that sell non-fair trade coffee take 55% of what consumers pay for coffee while only 10% goes to the producers. Small growers dominate the production of coffee, especially in Latin American countries such as Peru. Coffee is the fairly traded commodity, and an increasing number of producers are small farmers that own their own land and work in cooperatives. The incomes of growers of fair trade coffee beans depend on the market value of coffee where it is consumed, so farmers of fair trade coffee do not necessarily live above the poverty line or get completely for their commodity.\nUnsustainable farming practices can harm plantation owners and laborers. Unsustainable practices such as using and unshaded growing are risky. Small growers who put themselves at economic risk by not having could lose money and resources due to fluctuating coffee prices, pest problems, or policy shifts.\nThe effectiveness of Fairtrade is questionable; workers on Fairtrade farms have a lower standard of living than on similar farms outside the Fairtrade system.\nSustainability.\nAs coffee becomes one of the most important export crops in certain regions such as northern Latin America, nature and agriculture are transformed. Increased productivity requires technological innovations, and the coffee agroecosystem has been changing. In the nineteenth century in Latin America, coffee plantations began replacing sugarcane and subsistence crops. Coffee crops became more managed; they were put into rows and unshaded, meaning diversity of the forest was decreased and Coffea trees shortened. As plant and tree diversity decreased, so did animal diversity. Unshaded plantations allow a higher density of Coffea trees, are less protected from wind and lead to more soil erosion. Technified coffee plantations also use chemicals such as fertilizers, insecticides, and fungicides.\nFair trade certified commodities must adhere to sustainable agro-ecological practices, including reduction of chemical fertilizer use, prevention of erosion, and protection of forests. Coffee plantations are more likely to be fair trade certified if they use traditional farming practices with shading and without chemicals. This protects the biodiversity of the ecosystem and ensures that the land will be usable for farming in the future and not just for short-term planting. In the United States, 85% of fair trade certified coffee is also organic.\nConsumer attitudes.\nConsumers typically have positive attitudes about products that are ethically made. These products may promise fair labor conditions, protection of the environment, and protection of human rights. Fair trade products meet standards like these. Despite positive attitudes toward ethical products such as fair trade commodities, consumers often are not willing to pay higher prices for fair trade coffee. The attitude-behavior gap can help explain why ethical and fair trade products take up less than 1% of the market. Coffee consumers may say they are willing to pay a premium for fair trade coffee, but most consumers are more concerned with the brand, label, and flavor of the coffee. However, socially conscious consumers with a commitment to buying fair trade products are more likely to pay the premium associated with fair trade coffee. When a sufficient number of consumers begin purchasing fair trade, companies will be more likely to carry fair trade products. Safeway Inc. began carrying fair trade coffee after individual consumers dropped off postcards asking for it.\nCoffee companies.\nThe following coffee roasters and companies claim to offer fair trade coffee or some roasts that are fair trade certified:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nCocoa.\nMany countries that export cocoa rely on it as their single export crop. In Africa in particular, governments tax cocoa as their main source of revenue. Cocoa is a permanent crop, which means that it occupies land for long periods of time and does not need to be replanted after each harvest.\nLocations.\nCocoa is farmed in the tropical regions of West Africa, Southeast Asia, and Latin America. In Latin America, cocoa is produced in Costa Rica, Panama, Peru, Bolivia, and Brazil. Much of the cocoa produced in Latin America is organic and regulated by an Internal control system. Bolivia has fair trade cooperatives that permit a fair share of money for cocoa producers. African cocoa-producing countries include Cameroon, Madagascar, S\u00e3o Tom\u00e9 and Pr\u00edncipe, Ghana, Tanzania, Uganda, and C\u00f4te d'Ivoire. C\u00f4te d'Ivoire exports over a third of the world's cocoa beans. Southeast Asia accounts for about 14% of the world's cocoa production. Major cocoa-producing countries are Indonesia, Malaysia, and Papua New Guinea.\nLabour.\nAfrica and other developing countries received low prices for their exported commodities such as cocoa, which caused poverty to abound. Fair trade seeks to establish a system of direct trade from developing countries to counteract this unfair system. Most cocoa comes from small family-run farms in West Africa. These farms have little market access and so rely on middlemen to bring their products to market. Sometimes middlemen are unfair to farmers. Farmers may join an Agricultural cooperative that pays farmers a fair price for their cocoa. One of the main tenets of fair trade is that farmers receive a fair price, but this does not mean that the higher price paid for fair trade cocoa goes directly to the farmers. Much of this money goes to community projects such as water wells rather than to individual farmers. Nevertheless, cooperatives such as fair trade-endorsed Kuapa Kokoo in Ghana are often the only Licensed Buying Companies that will give farmers a fair price and not cheat them or rig sales. Farmers in cooperatives per bag of cocoa beans. These arrangements are not always assured and fair trade organizations can't always buy all of the cocoa available to them from cooperatives.\nMarketing.\nMarketing of fair trade cocoa to European consumers often portrays cocoa farmers as dependent on western purchases for their livelihood and well-being. Showing African cocoa producers in this way is problematic because it is reminiscent of the imperialistic view that Africans cannot live happily without the help of westerners. It portrays the balance of power as being in favor of the consumers rather than the producers.\nConsumers often aren't willing to pay the extra price for fair trade cocoa because they do not know what fair trade is. Activist groups can educate consumers about the unethical aspects of unfair trade and thereby promote demand for fairly traded commodities. Activism and ethical consumption not only promote fair trade but also act against powerful corporations such as Mars, Incorporated that refuse to acknowledge the use of forced child labor in the harvesting of their cocoa.\nSustainability.\nSmallholding farmers frequently lack access not only to markets but also to resources for sustainable cocoa farming practices. Lack of sustainability can be due to pests, diseases that attack cocoa trees, lack of farming supplies, and lack of knowledge about modern farming techniques. One issue pertaining to cocoa plantation sustainability is the amount of time it takes for a cocoa tree to produce pods. A solution is to change the type of cocoa tree being farmed. In Ghana, a hybrid cocoa tree yields two crops after three years rather than the typical one crop after five years.\nCocoa companies.\nThe following chocolate companies claim to use all or some fair trade cocoa in their chocolate. Certifying organizations, as of 2024, are listed in parentheses.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nHarkin\u2013Engel Protocol.\nThe Harkin\u2013Engel Protocol, also commonly known as the Cocoa Protocol, is an international agreement meant to end some of the world's worst forms of child labor, as well as forced labor in the cocoa industry. It was first negotiated by Senator Tom Harkin and Representative Eliot Engel after they watched a documentary that showed the cocoa industry's widespread issue of child slavery and trafficking. The parties involved agreed to a six-article plan:\nTextiles.\nFair trade textiles are primarily made from fair trade cotton. By 2015, nearly 75,000 cotton farmers in developing countries had obtained fair trade certification. The minimum price that Fair trade pays allows cotton farmers to sustain and improve their livelihoods. Fair trade textiles are frequently grouped with fair trade crafts and goods made by artisans in contrast to cocoa, coffee, sugar, tea, and honey, which are agricultural commodities.\nLocations.\nIndia, Pakistan, and West Africa are the primary exporters of fair trade cotton, although many countries grow fair trade cotton. Production of Fairtrade cotton was initiated in 2004 in four countries in West and Central Africa (Mali, Senegal, Cameroon, and Burkina Faso). Textiles and clothing are exported from Hong Kong, Thailand, Malaysia, and Indonesia.\nLabour.\nLabour is different for textile production than for agricultural commodities because textile production takes place in a factory, not on a farm. Children are a source of cheap labor, and child labor is prevalent in Pakistan, India, and Nepal. Fair trade cooperatives ensure fair and safe labor practices, and do not allow child labor. Fair trade textile producers are most often women in developing countries. They struggle to meet consumer tastes in North America and Europe. In Nepal, textiles were originally made for household and local use. In the 1990s, women began joining cooperatives and exporting their crafts for profit. Now handicrafts are Nepal's largest export. It is often difficult for women to balance textile production, domestic responsibilities, and agricultural work. Cooperatives foster the growth of democratic communities in which women have a voice despite being historically in underprivileged positions. For fair trade textiles and other crafts to be successful in Western markets, World Fair Trade Organizations require a workforce of artisans in need of stable income, links from consumers to artisans, and a market for quality ethnic products.\nMaking cotton and textiles \"fair trade\" does not always benefit laborers. Burkina Faso and Mali export the largest amount of cotton in Africa. Although many cotton plantations in these countries attained fair trade certification in the 1990s, participation in fair trade strengthened existing power relations and inequalities that cause poverty in Africa rather than challenging them. Fair trade does not do much for farmers when it does not challenge the system that marginalizes producers. Despite not empowering farmers, the change to fair trade cotton has positive effects including female participation in cultivation.\nTextiles and garments are intricate and require one individual , in contrast to the collective farming of coffee and cocoa beans. Textiles are not a straightforward commodity because to be fairly traded, there must be regulation in cotton cultivation, dyeing, stitching, and every other step in the process of textile production. Fair trade textiles are distinct from the sweat-free movement although the two movements intersect at the worker level.\nForced or unfair labor in textile production is not limited to developing countries. Charges of use of sweatshop labor are endemic in the United States. Immigrant women work long hours and receive less than minimum wage. In the United States, there is more of a stigma against child labor than forced labor in general. Consumers in the United States are willing to suspend the importation of textiles made with child labor in other countries but do not expect American exports to be suspended by other countries, even when produced using forced labor.\nClothing and textile companies.\nThe following companies use fair trade production and/or distribution techniques for clothing and textiles:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSeafood.\nWith increasing media scrutiny of the conditions of fishermen, particularly in Southeast Asia, the lack of transparency and traceability in the seafood industry prompted new fair trade efforts. In 2014, Fair Trade USA created its Capture Fisheries Program that led to the first instance of Fair Trade fish being sold globally in 2015. The program \"requires fishermen to source and trade according to standards that protect fundamental human rights, prevent forced and child labor, establish safe working conditions, regulate work hours and benefits, and enable responsible resource management.\"\nFlowers.\nFair trade flowers have been recognised as \"an important niche product\", with Kenya noted as a significant location for their production. The launch of fair trade flower marketing in the UK, led by retailer Tesco, raised some certains as to whether the organisation of flower production in Kenya met the conditions needed for fair trade certification.\nLuxury commodities.\nThere have been efforts to introduce fair trade practices to the luxury goods industry, particularly for gold and diamonds.\nDiamonds and sourcing.\nIn parallel to efforts to commoditize diamonds, some industry players launched campaigns to introduce benefits to mining centers in the developing world. Rapaport Fair Trade was established with the goal \"to provide ethical education for jewelry suppliers, buyers, first time or seasoned diamond buyers, social activists, students, and anyone interested in jewelry, trends, and ethical luxury.\"\nThe company's founder, Martin Rapaport, as well as Kimberley Process initiators Ian Smillie and Global Witness, are among several industry insiders and observers who have called for greater checks and certification programs among other programs to ensure protection for miners and producers in developing countries. Smillie and Global Witness have since withdrawn support for the Kimberley Process. Other concerns in the diamond industry include working conditions in diamond cutting centers as well as the use of child labor. \nGold.\nFairtrade certified gold is used in manufacturing processes as well as for jewellery. The \"Fairtrade Standard for Gold and Associated Precious Metals for Artisanal and Small-Scale Mining\" covers the requirements for gold products to identified as \"Fairtrade\". Silver and platinum are also Fairtrade precious metals.\nIn February 2011, the United Kingdom's Fairtrade Foundation became the first NGO to begin certifying gold under the fair trade rubric.\nPornography or sex industry.\nFair trade also influences the porn industry. Feminist writers and academics advocate a pornography industry with mutual consent and no exploiting labor conditions for actors and actresses.\nPolitics.\nEuropean Union.\nIn 1994, the European Commission prepared the \"Memo on alternative trade\" in which it declared its support for strengthening fair trade and its intention to establish an EC Working Group on Fair Trade. The same year, the European Parliament adopted the \"Resolution on promoting fairness and solidarity in North South trade\", voicing its support for fair trade. In 1996, the Economic and Social Committee (EESC) adopted an \"Opinion on the European 'Fair Trade' marking movement\". A year later, a resolution adopted by the European Parliament called on the European Commission to support fair trade banana operators, and the European Commission published a survey on \"Attitudes of EU consumers to Fair Trade bananas\", concluding that Fair Trade bananas would be commercially viable in several EU Member States.\nIn 1998, the European Parliament adopted the \"Resolution on Fair Trade\", which was followed by a Commission in 1999 that adopted the \"Communication from the Commission to the Council on 'Fair Trade'\". In 2000, public institutions in Europe started purchasing Fairtrade Certified coffee and tea, and the Cotonou Agreement made specific reference to the promotion of Fair Trade in article 23(g) and in the Compendium. The European Parliament and Council Directive 2000/36/EC also suggested promoting Fair Trade. In 2001 and 2002, several other EU papers explicitly mentioned fair trade, most notably the 2001 Green Paper on Corporate Social Responsibility and the 2002 Communication on Trade and Development.\nIn 2004, the European Union adopted \"Agricultural Commodity Chains, Dependence and Poverty\u2013A proposal for an EU Action Plan\", with a specific reference to the fair trade movement, which has \"been setting the trend for a more socio-economically responsible trade.\" In 2005, in the European Commission communication \"Policy Coherence for Development\u2013Accelerating progress towards attaining the Millennium Development Goals\", fair trade is mentioned as \"a tool for poverty reduction and sustainable development\".\nOn July 6, 2006, the European Parliament unanimously adopted a resolution on fair trade, recognizing the benefits achieved by the fair trade movement, suggesting the development of an EU-wide policy on fair trade, defining criteria that need to be fulfilled under fair trade to protect it from abuse, and calling for greater support for fair trade. \"This resolution responds to the impressive growth of Fair Trade, showing the increasing interest of European consumers in responsible purchasing,\" said Green MEP Frithjof Schmidt during the plenary debate. Peter Mandelson, EU Commissioner for External Trade, responded that the resolution would be well received by the Commission: \"Fair Trade makes the consumers think and therefore it is even more valuable. We need to develop a coherent policy framework and this resolution will help us.\" In 2010 the EESC confirmed that \"the dynamic and market-responsive nature of ... consumer labels is encouraged by their voluntary nature\" whilst also recommending that \"resource and regulatory support is given to the development of the improved transparency, impact and credibility of such schemes and the capacity of producers to influence them and participate through certification\".\nFrance.\nIn 2005, French National Assembly member Antoine Herth issued the report \"40 proposals to sustain the development of Fair Trade\". The report was followed the same year by a law that would establish a commission to recognize fair trade Organisations. In parallel to the , also in 2006, the French chapter of ISO (AFNOR) adopted a reference document on Fair Trade after five years of discussion.\nItaly.\nIn 2006, Italian lawmakers debated how to introduce a law on fair trade in Parliament. A consultation process involving a wide range of stakeholders was launched in early October. A definition of fair trade was developed. However, its adoption is still pending as the efforts were stalled by the 2008 Italian political crisis.\nNetherlands.\nThe Dutch province of Groningen was sued in 2007 by coffee supplier Douwe Egberts for requiring its coffee suppliers to meet fair trade criteria, most notably the payment of a minimum price and a development premium to producer cooperatives. Douwe Egberts, which sells coffee brands under self-developed ethical criteria, believed the requirements were discriminatory. After several months of discussions and legal challenges, the province of Groningen prevailed. Coen de Ruiter, director of the Max Havelaar Foundation, called the victory a landmark event: \"it provides governmental institutions the freedom in their purchasing policy to require suppliers to provide coffee that bears the fair trade criteria, so that a substantial and meaningful contribution is made in the fight against poverty through the daily cup of coffee\".\nCriticism.\nWhile some studies claim fair trade is beneficial and efficient, other studies have been less favourable. Sometimes the criticism is intrinsic to fair trade, sometimes efficiency depends on the broader context such as the lack of government help or volatile prices in the global market.\nOne 2015 study concluded that producer benefits were close to zero because there was an oversupply of certification, and only a fraction of produce classified as fair trade was actually sold on fair trade markets, just enough to recoup the costs of certification. A study published by the \"Journal of Economic Perspectives\", however, suggests that Fair Trade does achieve many of its intended goals, although on a comparatively modest scale relative to the size of national economies. A 2014 study of coffee and tea producers in Uganda and Ethiopia suggested that participation in fair trade organizations did not improve workers' conditions. Some research indicates that the implementation of certain fair trade standards can cause greater inequalities in some markets where these rigid rules are inappropriate for the specific market. In the fair trade debate there are complaints of failure to enforce the fair trade standards, with producers, cooperatives, importers, and packers profiting by evading them.\nEthical basis.\nStudies shows a significant number of consumers were content to pay higher prices for fair trade products, in the belief that this helps the poor. One ethical criticism of Fairtrade is that this premium over non-Fairtrade products does not reach the producers and is instead collected by businesses or by employees of co-operatives or is used for unnecessary expenses. Some research finds the implementation of certain fair trade standards causes greater inequalities in markets where these rigid rules are inappropriate for the specific market.\nWhat happens with the money?\nLittle money may reach the developing countries.\nThe Fairtrade Foundation does not monitor how much retailers charge for fair trade goods, so it is rarely possible to determine how much extra is charged or how much of that premium reaches the producers. In four cases it has been possible to find out. One British caf\u00e9 chain was passing on less than one percent of the extra charged to the exporting cooperative; in Finland, Valkila, Haaparanta, and Niemi found that consumers paid much more for Fairtrade, and that only 11.5% reached the exporter. Kilian, Jones, Pratt, and Villalobos talk of U.S. Fairtrade coffee getting per pound extra at retail, of which the exporter receives only 2%. Mendoza and Bastiaensen calculated that in the UK only 1.6%\u201318% of the extra charged for one product line reached the farmer. These studies assume that the importers paid the full Fairtrade price, which is not necessarily the case.\nLess money reaches farmers.\nThe Fairtrade Foundation does not monitor how much of the extra money paid to the exporting cooperatives reaches the farmer. The cooperatives incur costs in reaching fair trade standards, and these are incurred on all production, even if only a small amount is sold at fair trade prices. The most successful cooperatives appear to spend a third of the extra price received on this: some less successful cooperatives spend more than they gain. While this appears to be agreed by proponents and critics of fair trade, there is a dearth of economic studies setting out the actual revenues and what the money was spent on. FLO figures are that 40% of the money reaching the developing world is spent on \"business and production\", which would include these costs as well as costs incurred by any inefficiency and corruption in the cooperative or the marketing system. The rest is spent on social projects, rather than being passed on to farmers.\nDiffering anecdotes state farmers are paid more or less by traders than by fair trade cooperatives. Few of these anecdotes address the problems of price reporting in developing world markets, and few appreciate the complexity of the different price packages that may or may not include credit, harvesting, transport, processing, etc. Cooperatives typically average prices over the year, so they pay less than traders at some times, more at others. Bassett (2009) compares prices only where Fairtrade and non-Fairtrade farmers have to sell cotton to the same monopsonistic ginneries which pay low prices. Prices would have to be higher to compensate farmers for the increased costs they incur to produce fair trade. For instance, fair trade encouraged Nicaraguan farmers to switch to organic coffee, which resulted in a higher price per pound, but a lower net income because of higher costs and lower yields.\nEffects of low barriers to entry.\nA 2015 study concluded that the low barriers to entry in a competitive market such as coffee undermines any effort to give higher benefits to producers through fair trade. They used data from Central America to establish that the producer benefits were close to zero. This is because there is an oversupply of certification, and only a fraction of produce classified as fair trade is actually sold on fair trade markets, just enough to recoup the costs of certification.\nInefficient marketing system.\nOne reason for high prices is that fair trade farmers have to sell through a monopsonist cooperative, which may be inefficient or corrupt\u2013certainly some private traders are more efficient than some cooperatives. They cannot choose the buyer who offers the best price, or switch when their cooperative is going bankrupt if they wish to retain fairtrade status. Fairtrade deviates from the free market ideal of some economists. Brink Lindsey calls fairtrade a \"misguided attempt to make up for market failures\" that encourages market inefficiencies and overproduction.\nFair trade harms other farmers.\nOverproduction argument.\nCritics argue that fair trade harms non-Fairtrade farmers. Fair trade claims that its farmers are paid higher prices and are given special advice on increasing yields and quality. Economists argue that if this is so, Fairtrade farmers will increase production. As the demand for coffee is highly inelastic, a small increase in supply means a large fall in market price, so perhaps a million Fairtrade farmers get a higher price and 24 million others get a substantially lower price. Critics cite the example of farmers in Vietnam being paid a premium over the world market price in the 1980s, planting much coffee, then flooding the world market in the 1990s. The fair trade minimum price means that when the world market price collapses, it is the non-fair trade farmers, particularly the poorest, who have to cut down their coffee trees.\nOther ethical issues.\nSecrecy.\nUnder EU law (Directive 2005/29/EC on Unfair Commercial Practices) the criminal offense of unfair trading is committed if (a) \"it contains false information and is therefore untruthful or in any way, including overall presentation, deceives or is likely to deceive the average consumer, even if the information is factually correct\", (b) \"it omits material information that the average consumer needs\u2026 and thereby causes or is likely to cause the average consumer to take a transactional decision that he would not have taken otherwise\", or (c) \"fails to identify the commercial intent of the commercial practice\u2026 [which] causes or is likely to cause the average consumer to take a transactional decision that he would not have taken otherwise.\" Peter Griffiths (2011) points to false claims that fair trade producers get higher prices and to the almost universal failure to disclose the extra price charged for fair trade products, how much of this actually reaches the developing world, what this is spent on in the developing world, how much (if any) reaches farmers, and the harm that fair trade does to non-fair trade farmers. He also points to the failure to disclose when \"the primary commercial intent\" is to make money for retailers and distributors in rich countries.\nUnethical selling techniques.\nEconomist Philip Booth says that the selling techniques used by some sellers and supporters of fair trade are bullying, misleading, and unethical, such as the use of boycott campaigns and other pressure to force sellers to stock a product they think ethically suspect. However, the opposite has been argued, that a more participatory and multi-stakeholder approach to auditing might improve the quality of the process.\nSome people argue that strategic use of labeling may help embarrass (or encourage) major suppliers into changing their practices. It may bring to light corporate vulnerabilities that activists can exploit. Or it may encourage ordinary people to get involved with broader projects of social change.\nFailure to monitor standards.\nThere are complaints that fair trade standards are inappropriate and may harm producers, sometimes making them work several months more for little return.\nEnforcement of standards by Fairtrade was described as \"seriously weak\" by Christian Jacquiau. Paola Ghillani, who spent four years as president of Fairtrade Labelling Organizations, agreed that \"certain arguments carry some weight\". There are many complaints of poor enforcement: labourers on Fairtrade farms in Peru are paid less than the minimum wage; some non-Fairtrade coffee is sold as Fairtrade \"the standards are not very strict in the case of seasonally hired labour in coffee production.\" \"[S]ome fair trade standards are not strictly enforced.\" In 2006, a \"Financial Times\" journalist found that ten out of ten mills visited had sold uncertified coffee to co-operatives as certified. It reported on \"evidence of at least one coffee association that received an organic, Fair Trade or other certifications despite illegally growing some 20 per cent of its coffee in protected national forest land.\"\nTrade justice and fair trade.\nSegments of the trade justice movement have criticized fair trade for focusing too much on individual small producer groups without advocating for trade policy changes that would have a larger effect on disadvantaged producers' lives. French author and RFI correspondent Jean-Pierre Boris championed this view in his 2005 book \"Commerce in\u00e9quitable\".\nPolitical objections.\nThere have been political criticisms of fair trade from the left and the right. Some believe the fair trade system is not radical enough. Christian Jacquiau, in his book \"Les coulisses du commerce \u00e9quitable\", calls for stricter fair trade standards and criticizes the fair trade movement for working within the current system (i.e., partnerships with mass retailers, multinational corporations, etc.) rather than establishing a new, fairer, fully autonomous (i.e., government monopoly) trading system. Jacquiau also supports significantly higher fair trade prices in order to maximize the effect since most producers only sell a portion of their crop under fair trade terms. The fair trade approach is rooted in a Northern consumerist view of justice that Southern producers do not participate in setting. \"A key issue is therefore to make explicit who possesses the power to define the terms of Fairtrade, that is who possesses the power in order to determine the need of an ethic in the first instance, and subsequently command a particular ethical vision as the truth.\"\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49149", "revid": "39150892", "url": "https://en.wikipedia.org/wiki?curid=49149", "title": "Duchy of Lorraine", "text": "Part of East Francia and Holy Roman Empire\nThe Duchy of Lorraine was a principality of the Holy Roman Empire which existed from the 10th century until 1766 when it was annexed by the Kingdom of France. It gave its name to the larger present-day region of Lorraine in northeastern France. Its capital was Nancy.\nIt was founded in 959 following the division of Lotharingia into two separate duchies: Upper and Lower Lorraine, the westernmost parts of the Holy Roman Empire. The Lower duchy was quickly dismantled, while Upper Lorraine came to be known as simply the Duchy of Lorraine. The Duchy of Lorraine was coveted and briefly occupied by the dukes of Burgundy and the kings of France, but was ruled by the dukes of the House of Lorraine after 1473.\nIn 1737, the duchy was given to Stanis\u0142aw Leszczy\u0144ski, the former king of Poland, who had lost his throne as a result of the War of the Polish Succession, with the understanding that it would fall to the French crown on his death. When Stanis\u0142aw died on 23 February 1766, Lorraine was annexed by France and reorganized as the province of Lorraine and Barrois.\nHistory.\nLotharingia.\nLorraine's predecessor, Lotharingia, was an independent Carolingian kingdom under the rule of King Lothair II (855\u2013869). Its territory had originally been a part of Middle Francia, created in 843 by the Treaty of Verdun, when the Carolingian empire was divided between the three sons of Louis the Pious. Middle Francia was allotted to Emperor Lothair I, therefore called \"Lotharii Regnum\". On his death in 855, it was further divided into three parts, of which his son Lothair II took the northern one. His realm then comprised a larger territory stretching from the County of Burgundy in the south to the North Sea. In French, this area became known as \"Lorraine\", while in German, it was eventually known as \"Lothringen\". In the Alemannic language once spoken in Lorraine, the -ingen suffix signified a property; thus, in a figurative sense, \"Lotharingen\" can be translated as \"Land belonging to Lothair\", or more simplified *Lothair's realm*.\nAs Lothair II had died without heirs, his territory was divided by the 870 Treaty of Meerssen between East and West Francia and finally came under East Frankish rule as a whole by the 880 Treaty of Ribemont. After the East Frankish Carolingians became extinct with the death of Louis the Child in 911, Lotharingia once again attached itself to West Francia, but was conquered by the German king Henry the Fowler in 925. Stuck in the conflict with his rival Hugh the Great, in 942 King Louis IV of France renounced all claims to Lotharingia.\nDuchy of Upper Lorraine.\nIn 953, the German king Otto I had appointed his brother Bruno the Great Duke of Lotharingia. In 959, Bruno divided the duchy into Upper and Lower Lorraine; this division became permanent following his death in 965. The Upper Duchy was further \"up\" the river system, that is, it was inland and to the south. Upper Lorraine was first denominated as the Duchy of Mosellane, both in charters and narrative sources, and its duke was the \"dux Mosellanorum\".\nLower Lorraine disintegrated into several smaller territories and only the title of a \"Duke of Lothier\" remained, held by Brabant. By the time Upper Lorraine came into the possession of Ren\u00e9 of Anjou, several territories had already split off, such as the County of Luxembourg, the Electorate of Trier, the County of Bar and the \"Three Bishoprics\" of Verdun, Metz and Toul.\nThe border between the Empire and the Kingdom of France remained relatively stable throughout the Middle Ages. In 1301, Count Henry III of Bar had to receive the western part of his lands (\"Barrois mouvant\") as a fief by King Philip IV of France. In 1475, the Burgundian duke Charles the Bold campaigned for the Duchy of Lorraine, but was finally defeated and killed at the 1477 Battle of Nancy. In the 1552 Treaty of Chambord, a number of insurgent Protestant Imperial princes around Maurice, Elector of Saxony ceded the Three Bishoprics to King Henry II of France in turn for his support.\nDue to the weakening of Imperial authority during the 1618\u20131648 Thirty Years' War, France was able to occupy the duchy in 1634 and retained it until 1661 when Charles IV was restored. In 1670, the French invaded again, forcing Charles into exile; his nephew and heir Charles V (1643\u20131690) spent his life in the service of the Imperial House of Habsburg. France returned the Duchy in the 1697 Treaty of Ryswick ending the Nine Years' War and Charles' son Leopold (1679\u20131729), became duke and was known as 'Leopold the Good;' in the 1701\u20131714 War of the Spanish Succession, parts of Lorraine, including the capital Nancy, were again occupied by France, but Leopold continued to reign at the Ch\u00e2teau de Lun\u00e9ville.\nIn 1737, after the War of the Polish Succession, an agreement between France, the Habsburgs and the Lorraine House of Vaud\u00e9mont assigned the Duchy to Stanis\u0142aw Leszczy\u0144ski, former king of Poland. He was also father-in-law to King Louis XV of France, and had recently lost out to a candidate backed by Russia and Austria in the War of the Polish Succession. The duke of Lorraine, Francis Stephen, betrothed to the Emperor's daughter Archduchess Maria Theresa, was compensated with the Grand Duchy of Tuscany, where the last Medici ruler had recently died without issue. France also promised to support Maria Theresa as heir to the Habsburg possessions under the Pragmatic Sanction of 1713. Leszczy\u0144ski received Lorraine with the understanding that it would fall to the French crown on his death. The \"title\" of Duke of Lorraine was given to Stanis\u0142aw, but also retained by Francis Stephen, and it figures prominently in the titles of his successors (as a non-claimant family name), the House of Habsburg-Lorraine. When Stanis\u0142aw died on 23 February 1766, Lorraine was annexed by France and reorganized as a province by the French government.\nCulture.\nTwo regional languages survive in the region.\nLorraine Franconian, known as ' or ' in French, is a West Central German dialect spoken by a minority in the northern part of the region. This is distinct from the neighbouring Alsatian language, although the two are often confused. Neither has any form of official recognition.\nLorrain is a Romance dialect spoken by a minority in the southern part of the region.\nThe duchy produced a number of important painters, including Claude Lorrain, Georges de La Tour and Jean LeClerc.\nLike most of France's regional languages (such as Breton, Franco-Proven\u00e7al, Occitan, Alsatian, Catalan, Basque and Flemish), Lorrain and Lorraine Franconian were largely replaced by French with the advent of mandatory public schooling in the 19th and 20th centuries.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49150", "revid": "179", "url": "https://en.wikipedia.org/wiki?curid=49150", "title": "Malvinas Islands", "text": ""}
{"id": "49153", "revid": "67000", "url": "https://en.wikipedia.org/wiki?curid=49153", "title": "Paleozoic Era", "text": ""}
{"id": "49157", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=49157", "title": "Palaeozoic", "text": ""}
{"id": "49159", "revid": "44342193", "url": "https://en.wikipedia.org/wiki?curid=49159", "title": "Hallucination", "text": "Perception that only seems real\nMedical condition&lt;templatestyles src=\"Template:Infobox/styles-images.css\" /&gt;\nA hallucination is a perception in the absence of an external context stimulus that has the compelling sense of reality. They are distinguishable from several related phenomena, such as dreaming (REM sleep), which does not involve wakefulness; pseudohallucination, which does not mimic real perception, and is accurately perceived as unreal; illusion, which involves distorted or misinterpreted real perception; and mental imagery, which does not mimic real perception, and is under voluntary control. Hallucinations also differ from \"delusional perceptions\", in which a correctly sensed and interpreted stimulus (i.e., a real perception) is given some additional significance.\nHallucinations can occur in any sensory modality\u2014visual, auditory, olfactory, gustatory, tactile, proprioceptive, equilibrioceptive, nociceptive, thermoceptive and chronoceptive. Hallucinations are referred to as multimodal if multiple sensory modalities occur.\nA mild form of hallucination is known as a \"disturbance\", and can occur in most of the senses above. These may be things like seeing movement in peripheral vision, or hearing faint noises or voices. Auditory hallucinations are very common in schizophrenia. They may be benevolent (telling the subject good things about themselves) or malicious (cursing the subject). 55% of auditory hallucinations are malicious in content, for example, people talking about the subject, not speaking to them directly. Like auditory hallucinations, the source of the visual counterpart can also be behind the subject. This can produce a feeling of being looked or stared at, usually with malicious intent. Frequently, auditory hallucinations and their visual counterpart are experienced by the subject together.\nHypnagogic hallucinations and hypnopompic hallucinations are considered normal phenomena. Hypnagogic hallucinations can occur as one is falling asleep and hypnopompic hallucinations occur when one is waking up. Hallucinations can be associated with drug use (particularly deliriants), sleep deprivation, psychosis (including stress-related psychosis), neurological disorders, and delirium tremens. Many hallucinations happen also during sleep paralysis.\nThe word \"hallucination\" itself was introduced into the English language by the 17th-century physician Sir Thomas Browne in 1646 from the derivation of the Latin word \"alucinari\" meaning to wander in the mind. For Browne, hallucination means a sort of vision that is \"depraved and receive[s] its objects erroneously\".\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nClassification.\nHallucinations may be manifested in a variety of forms. Various forms of hallucinations affect different senses, sometimes occurring simultaneously, creating multiple sensory hallucinations for those experiencing them.\nAuditory.\nAuditory hallucinations (also known as \"paracusia\") are the perception of sound without outside stimulus. Auditory hallucinations can be divided into elementary and complex, along with verbal and nonverbal. These hallucinations are the most common type of hallucination, with auditory verbal hallucinations being more common than nonverbal. Elementary hallucinations are the perception of sounds such as hissing, whistling, an extended tone, and more. In many cases, tinnitus is an elementary auditory hallucination. However, some people who experience certain types of tinnitus, especially pulsatile tinnitus, are actually hearing the blood rushing through vessels near the ear. Because the auditory stimulus is present in this situation, it does not qualify it as a hallucination.\nComplex hallucinations are those of voices, music, or other sounds that may or may not be clear, may or may not be familiar, and may be friendly, aggressive, or among other possibilities. A hallucination of a single individual person of one or more talking voices is particularly associated with psychotic disorders such as schizophrenia, and hold special significance in diagnosing these conditions.\nIn schizophrenia, voices are normally perceived coming from outside the person, but in dissociative disorders they are perceived as originating from within the person, commenting in their head instead of behind their back. Differential diagnosis between schizophrenia and dissociative disorders is challenging due to many overlapping symptoms, especially Schneiderian first rank symptoms such as hallucinations. However, many people who do not have a diagnosable mental illness may sometimes hear voices as well. One important example to consider when forming a differential diagnosis for a patient with paracusia is lateral temporal lobe epilepsy. Despite the tendency to associate hearing voices, or otherwise hallucinating, and psychosis with schizophrenia or other psychiatric illnesses, it is crucial to take into consideration that, even if a person does exhibit psychotic features, they do not necessarily have a psychiatric disorder on its own. Disorders such as Wilson's disease, various endocrine diseases, numerous metabolic disturbances, multiple sclerosis, systemic lupus erythematosus, porphyria, sarcoidosis, and many others can present with psychosis.\nMusical hallucinations are also relatively common in terms of complex auditory hallucinations and may be the result of a wide range of causes ranging from hearing-loss (such as in musical ear syndrome, the auditory version of Charles Bonnet syndrome), lateral temporal lobe epilepsy, arteriovenous malformation, stroke, lesion, abscess, or tumor.\nThe Hearing Voices Movement is a support and advocacy group for people who hallucinate voices, but do not otherwise show signs of mental illness or impairment.\nHigh caffeine consumption has been linked to an increase in likelihood of one experiencing auditory hallucinations. A study conducted by the La Trobe University School of Psychological Sciences revealed that as few as five cups of coffee a day (approximately 500\u00a0mg of caffeine) could trigger the phenomenon.\nVisual.\nA \"visual hallucination\" is \"the perception of an external visual stimulus where none exists\". A separate but related phenomenon is a \"visual illusion\", which is a distortion of a real external stimulus. Visual hallucinations are classified as simple or complex:\nFor example, one may report hallucinating a giraffe. A simple visual hallucination is an amorphous figure that may have a similar shape or color to a giraffe (\"looks like\" a giraffe), while a complex visual hallucination is a discrete, lifelike image that \"is\", unmistakably, a giraffe.\nCommand.\nCommand hallucinations are hallucinations in the form of commands; they appear to be from an external source, or can appear coming from the subject's head. The contents of the hallucinations can range from the innocuous to commands to cause harm to the self or others. Command hallucinations are often associated with schizophrenia. People experiencing command hallucinations may or may not comply with the hallucinated commands, depending on the circumstances. Compliance is more common for non-violent commands.\nCommand hallucinations are sometimes used to defend a crime that has been committed, often homicides. In essence, it is a voice that one hears and it tells the listener what to do. Sometimes the commands are quite benign directives such as \"Stand up\" or \"Shut the door.\" Whether it is a command for something simple or something that is a threat, it is still considered a \"command hallucination.\" Some helpful questions that can assist one in determining if they may have this includes: \"What are the voices telling you to do?\", \"When did your voices first start telling you to do things?\", \"Do you recognize the person who is telling you to harm yourself (or others)?\", \"Do you think you can resist doing what the voices are telling you to do?\"\nOlfactory.\nPhantosmia (olfactory hallucinations), smelling an odor that is not actually there, and parosmia (olfactory illusions), inhaling a real odor but perceiving it as different scent than remembered, are distortions to the sense of smell (olfactory system), and in most cases, are not caused by anything serious and will usually go away on their own in time. It can result from a range of conditions such as nasal infections, nasal polyps, dental problems, migraines, head injuries, seizures, strokes, or brain tumors. Environmental exposures can sometimes cause it as well, such as smoking, exposure to certain types of chemicals (e.g., insecticides or solvents), or radiation treatment for head or neck cancer. It can also be a symptom of certain mental disorders such as depression, bipolar disorder, intoxication, substance withdrawal, or psychotic disorders (e.g., schizophrenia). The perceived odors are usually unpleasant and commonly described as smelling burned, foul, spoiled, or rotten.\nTactile.\nTactile hallucinations are the illusion of tactile sensory input, simulating various types of pressure to the skin or other organs. One subtype of tactile hallucination, formication, is the sensation of insects crawling underneath the skin and is frequently associated with prolonged cocaine use. However, formication may also be the result of normal hormonal changes such as menopause, or disorders such as peripheral neuropathy, high fevers, Lyme disease, skin cancer, and more.\nGustatory.\nThis type of hallucination is the perception of taste without a stimulus. These hallucinations, which are typically strange or unpleasant, are relatively common among individuals who have certain types of focal epilepsy, especially temporal lobe epilepsy. The regions of the brain responsible for gustatory hallucination in this case are the insula and the superior bank of the sylvian fissure.\nSexual.\nSexual hallucinations are the perception of erogenous or orgasmic stimuli. They may be unimodal or multimodal in nature and frequently involve sensation in the genital region, though it is not exclusive. Frequent examples of sexual hallucinations include the sensation of being penetrated, experiencing orgasm, feeling as if one is being touched in an erogenous zone, sensing stimulation in the genitals, feeling the fondling of one's breasts or buttocks and tastes or smells related to sexual activity. Visualizations of sexual content and auditory voices making sexually explicit remarks may sometimes be included in this classification. While it features components of other classifications, sexual hallucinations are distinct due to the orgasmic component and unique presentation.\nThe regions of the brain responsible differ by the subsection of sexual hallucination. In orgasmic auras, the mesial temporal lobe, right amygdala and hippocampus are involved. In males, genital specific sensations are related to the postcentral gyrus and arousal and ejaculation are linked to stimulation in the posterior frontal lobe. In females, however, the hippocampus and amygdala are connected. Limited studies have been done to understand the mechanism of action behind sexual hallucinations in epilepsy, substance use, and post-traumatic stress disorder etiologies.\nSomatic.\nSomatic hallucinations refer to an interoceptive sensory experience in the absence of stimulus. Somatic hallucinations can be broken down into further subcategories: general, algesic, kinesthetic, and cenesthopathic.\nMultimodal.\nA hallucination involving sensory modalities is called multimodal, analogous to unimodal hallucinations which have only one sensory modality. The multiple sensory modalities can occur at the same time (simultaneously) or with a delay (serial), be related or unrelated to each other, and be consistent with reality (congruent) or not (incongruent). For example, a person talking in a hallucination would be congruent with reality, but a cat talking would not be.\nMultimodal hallucinations are correlated to poorer mental health outcomes, and are often experienced as feeling more real.\nCause.\nHallucinations can be caused by a number of factors.\nHypnagogic hallucination.\nThese hallucinations occur just before falling asleep and affect a high proportion of the population: in one survey 37% of the respondents experienced them twice a week. The hallucinations can last from seconds to minutes; all the while, the subject usually remains aware of the true nature of the images. These may be associated with narcolepsy. Hypnagogic hallucinations are sometimes associated with brainstem abnormalities, but this is rare.\nPeduncular hallucinosis.\nPeduncular means pertaining to the peduncle, which is a neural tract running to and from the pons on the brain stem. These hallucinations usually occur in the evenings, but not during drowsiness, as in the case of hypnagogic hallucination. The subject is usually fully conscious and then can interact with the hallucinatory characters for extended periods of time. As in the case of hypnagogic hallucinations, insight into the nature of the images remains intact. The false images can occur in any part of the visual field, and are rarely polymodal.\nDelirium tremens.\nOne of the more enigmatic forms of visual hallucination is the highly variable, possibly polymodal delirium tremens. It is associated with withdrawal in alcohol use disorder. Individuals with delirium tremens may be agitated and confused, especially in the later stages of this disease. Insight is gradually reduced with the progression of this disorder. Sleep is disturbed and occurs for a shorter period of time, with rapid eye movement sleep.\nParkinson's disease and Lewy body dementia.\nParkinson's disease is linked with Lewy body dementia for their similar hallucinatory symptoms. Presence hallucinations can be an early indicator of cognitive decline in Parkinson's Disease. The symptoms strike during the evening in any part of the visual field, and are rarely polymodal. The segue into hallucination may begin with illusions where sensory perception is greatly distorted, but no novel sensory information is present. These typically last for several minutes, during which time the subject may be either conscious and normal or drowsy/inaccessible. Insight into these hallucinations is usually preserved and REM sleep is usually reduced. Parkinson's disease is usually associated with a degraded substantia nigra pars compacta, but recent evidence suggests that PD affects a number of sites in the brain. Some places of noted degradation include the median raphe nuclei, the noradrenergic parts of the locus coeruleus, and the cholinergic neurons in the parabrachial area and pedunculopontine nuclei of the tegmentum.\nMigraine coma.\nThis type of hallucination is usually experienced during the recovery from a comatose state. The migraine coma can last for up to two days, and a state of depression is sometimes comorbid. The hallucinations occur during states of full consciousness, and insight into the hallucinatory nature of the images is preserved. It has been noted that ataxic lesions accompany the migraine coma.\nMigraine attacks.\nMigraine attacks may result in visual hallucinations including auras and in rarer cases, auditory hallucinations.\nCharles Bonnet syndrome.\nCharles Bonnet syndrome is the name given to visual hallucinations experienced by a partially or severely sight impaired person. The hallucinations can occur at any time and can distress people of any age, as they may not initially be aware that they are hallucinating. They may fear for their own mental health initially, which may delay them sharing with carers until they start to understand it themselves. The hallucinations can frighten and disconcert as to what is real and what is not. The hallucinations can sometimes be dispersed by eye movements, or by reasoned logic such as, \"I can see fire but there is no smoke and there is no heat from it\" or perhaps, \"We have an infestation of rats but they have pink ribbons with a bell tied on their necks.\" Over elapsed months and years, the hallucinations may become more or less frequent with changes in ability to see. The length of time that the sight impaired person can have these hallucinations varies according to the underlying speed of eye deterioration. A differential diagnosis are ophthalmopathic hallucinations.\nFocal epilepsy.\nVisual hallucinations due to focal seizures differ depending on the region of the brain where the seizure occurs. For example, visual hallucinations during occipital lobe seizures are typically visions of brightly colored, geometric shapes that may move across the visual field, multiply, or form concentric rings and generally persist from a few seconds to a few minutes. They are usually unilateral and localized to one part of the visual field on the contralateral side of the seizure focus, typically the temporal field. However, unilateral visions moving horizontally across the visual field begin on the contralateral side and move toward the ipsilateral side.\nTemporal lobe seizures, on the other hand, can produce complex visual hallucinations of people, scenes, animals, and more as well as distortions of visual perception. Complex hallucinations may appear to be real or unreal, may or may not be distorted with respect to size, and may seem disturbing or affable, among other variables. One rare but notable type of hallucination is heautoscopy, a hallucination of a mirror image of one's self. These \"other selves\" may be perfectly still or performing complex tasks, may be an image of a younger self or the present self, and tend to be briefly present. Complex hallucinations are a relatively uncommon finding in temporal lobe epilepsy patients. Rarely, they may occur during occipital focal seizures or in parietal lobe seizures.\nDistortions in visual perception during a temporal lobe seizure may include size distortion (micropsia or macropsia), distorted perception of movement (where moving objects may appear to be moving very slowly or to be perfectly still), a sense that surfaces such as ceilings and even entire horizons are moving farther away in a fashion similar to the dolly zoom effect, and other illusions. Even when consciousness is impaired, insight into the hallucination or illusion is typically preserved.\nDrug-induced hallucination.\nDrug-induced hallucinations are caused by hallucinogens, dissociatives, and deliriants, including many drugs with anticholinergic actions and certain stimulants, which are known to cause visual and auditory hallucinations. Some psychedelics such as lysergic acid diethylamide (LSD) and psilocybin can cause hallucinations that range in the spectrum of mild to intense.\nHallucinations, pseudohallucinations, or intensification of pareidolia, particularly auditory, are known side effects of opioids to different degrees\u2014it may be associated with the absolute degree of agonism or antagonism of especially the kappa opioid receptor, sigma receptors, delta opioid receptor and the NMDA receptors or the overall receptor activation profile as synthetic opioids like those of the pentazocine, levorphanol, fentanyl, pethidine, methadone and some other families are more associated with this side effect than natural opioids like morphine and codeine and semi-synthetics like hydromorphone, amongst which there also appears to be a stronger correlation with the relative analgesic strength. Three opioids, Cyclazocine (a benzormorphan opioid/pentazocine relative) and two levorphanol-related morphinan opioids, Cyclorphan and Dextrorphan are classified as hallucinogens, and Dextromethorphan as a dissociative. These drugs also can induce sleep (relating to hypnagogic hallucinations) and especially the pethidines have atropine-like anticholinergic activity, which was possibly also a limiting factor in the use, the psychotomimetic side effects of potentiating morphine, oxycodone, and other opioids with scopolamine (respectively in the Twilight Sleep technique and the combination drug Skophedal, which was eukodal (oxycodone), scopolamine and ephedrine, called the \"wonder drug of the 1930s\" after its invention in Germany in 1928, but only rarely specially compounded today) (q.q.v.).\nSensory deprivation hallucination.\nHallucinations can be caused by sensory deprivation when it occurs for prolonged periods of time, and almost always occurs in the modality being deprived (visual for blindfolded/darkness, auditory for muffled conditions, etc.)\nExperimentally-induced hallucinations.\nAnomalous experiences, such as so-called benign hallucinations, may occur in a person in a state of good mental and physical health, even in the apparent absence of a transient trigger factor such as fatigue, intoxication or sensory deprivation.\nThe evidence for this statement has been accumulating for more than a century. Studies of benign hallucinatory experiences go back to 1886 and the early work of the Society for Psychical Research, which suggested approximately 10% of the population had experienced at least one hallucinatory episode in the course of their life. More recent studies have validated these findings; the precise incidence found varies with the nature of the episode and the criteria of \"hallucination\" adopted, but the basic finding is now well-supported.\nNon-celiac gluten sensitivity.\nThere is tentative evidence of a relationship with non-celiac gluten sensitivity, the so-called \"gluten psychosis\".\nPathophysiology.\nDopaminergic and serotonergic hallucinations.\nIt has been reported that in serotonergic hallucinations, the person maintains an awareness that they are hallucinating, unlike dopaminergic hallucinations.\nNeuroanatomy.\nHallucinations are associated with structural and functional abnormalities in primary and secondary sensory cortices. Reduced grey matter in regions of the superior temporal gyrus/middle temporal gyrus, including Broca's area, is associated with auditory hallucinations as a trait, while acute hallucinations are associated with increased activity in the same regions along with the hippocampus, parahippocampus, and the right hemispheric homologue of Broca's area in the inferior frontal gyrus. Grey and white matter abnormalities in visual regions are associated with hallucinations in diseases such as Alzheimer's disease, further supporting the notion of dysfunction in sensory regions underlying hallucinations.\nOne proposed model of hallucinations posits that over-activity in sensory regions, which is normally attributed to internal sources via feedforward networks to the inferior frontal gyrus, is interpreted as originating externally due to abnormal connectivity or functionality of the feedforward network. This is supported by cognitive studies of those with hallucinations, who have demonstrated abnormal attribution of self generated stimuli.\nDisruptions in thalamocortical circuitry may underlie the observed top down and bottom up dysfunction. Thalamocortical circuits, composed of projections between thalamic and cortical neurons and adjacent interneurons, underlie certain electrophysical characteristics (gamma oscillations) that are associated with sensory processing. Cortical inputs to thalamic neurons enable attentional modulation of sensory neurons. Dysfunction in sensory afferents, and abnormal cortical input may result in pre-existing expectations modulating sensory experience, potentially resulting in the generation of hallucinations. Hallucinations are associated with less accurate sensory processing, and more intense stimuli with less interference are necessary for accurate processing and the appearance of gamma oscillations (called \"gamma synchrony\"). Hallucinations are also associated with the absence of reduction in P50 amplitude in response to the presentation of a second stimuli after an initial stimulus; this is thought to represent failure to gate sensory stimuli, and can be exacerbated by dopamine release agents.\nAbnormal assignment of salience to stimuli may be one mechanism of hallucinations. Dysfunctional dopamine signaling may lead to abnormal top down regulation of sensory processing, allowing expectations to distort sensory input.\nTreatments.\nThere are few treatments for many types of hallucinations. However, for those hallucinations caused by mental disease, a psychologist or psychiatrist should be consulted, and treatment will be based on the observations of those doctors. Antipsychotic and atypical antipsychotic medication may also be utilized to treat the illness if the symptoms are severe and cause significant distress. For other causes of hallucinations there is no factual evidence to support any one treatment is scientifically tested and proven. However, abstaining from hallucinogenic drugs, stimulant drugs, managing stress levels, living healthily, and getting plenty of sleep can help reduce the prevalence of hallucinations. In all cases of hallucinations, medical attention should be sought out and informed of one's specific symptoms. Meta-analyses show that cognitive behavioral therapy and metacognitive training can also reduce the severity of hallucinations. Furthermore, there are recovery movements all around the world that advocate for individuals with schizophrenia or voice-hearers (individuals that hear voices). The Hearing Voices Movement, starting in Europe, aims to utilize knowledge and experience of voice hearers combined with experts in disorders such as schizophrenia, such as psychiatrists.\nEpidemiology.\nPrevalence of hallucinations varies depending on underlying medical conditions, which sensory modalities are affected, age and culture. As of 2022,[ [update]] auditory hallucinations are the most well studied and most common sensory modality of hallucinations, with an estimated lifetime prevalence of 9.6%. Children and adolescents have been found to experience similar rates (12.7% and 12.4% respectively) which occur mostly during late childhood and adolescence. In this group, hallucinations are not necessarily indicative of later psychopathology and are recognized to occur on a continuum which includes normal, transient hallucinatory phenomena. However, hallucinations become increasingly associated with psychopathology in late adolescence. \nThe prevalence of hallucinations in adults and those over 60 is comparatively lower (with rates of 5.8% and 4.8% respectively). For those with schizophrenia, the lifetime prevalence of hallucinations is 80% and the estimated prevalence of visual hallucinations is 27%, compared to 79% for auditory hallucinations. A 2019 study suggested 16.2% of adults with hearing impairment experience hallucinations, with prevalence rising to 24% in the most hearing impaired group.\nA risk factor for multimodal hallucinations is prior experience of unimodal hallucinations. In 90% cases of psychosis, a visual hallucination occurs in combination with another sensory modality, most often being auditory or somatic. In schizophrenia, multimodal hallucinations are twice as common as unimodal ones.\nA 2015 review of 55 publications from 1962 to 2014 found 16\u201328.6% of those experiencing hallucinations report at least some religious content in them,415 along with 20\u201360% reporting some religious content in delusions.415 There is some evidence for delusions being a risk factor for religious hallucinations, with and 61.7% of people having experienced any delusion and 75.9% of those having experienced a religious delusion found to also experience hallucinations.421\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "49166", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=49166", "title": "Damon Knight", "text": "American science fiction writer, editor and critic (1922\u20132002)\nDamon Francis Knight (September 19, 1922 \u2013 April 15, 2002) was an American science fiction author, editor, and critic. He is the author of \"To Serve Man\", a 1950 short story adapted for \"The Twilight Zone\". He was married to fellow writer Kate Wilhelm.\nBiography.\nKnight was born in Baker City, Oregon, in 1922, and grew up in Hood River, Oregon. He entered science-fiction fandom at the age of eleven and published two issues of a fanzine titled \"Snide\".\nKnight's first professional sale was a cartoon drawing to a science-fiction magazine, \"Amazing Stories\". His first story, \"The Itching Hour\", appeared in the Summer 1940 number of \"Futuria Fantasia\", edited and published by Ray Bradbury. \"Resilience\" followed in the February 1941 number of \"Stirring Science Stories\", edited by Donald A. Wollheim. An editorial error made the latter story's ending incomprehensible; it was reprinted in a 1978 magazine in four pages with a two-page introduction by Knight.\nAt the time of his first story sale he was living in New York and was a member of the Futurians. One of his short stories describes paranormal disruption of a science fiction fan group and contains cameo appearances of various Futurians and others under thinly-disguised names; for instance, non-Futurian SF writer H. Beam Piper is identified as \"H. Dreyne Fifer\".\nKnight's forte was the short story; he is widely acknowledged as having been a master of the genre. To the general public he is best known as the author of \"To Serve Man\", a 1950 short story adapted for \"The Twilight Zone\". It won a 50-year Retro-Hugo in 2001 as the best short story of 1950. Knight was also a science fiction critic, a career which began when he wrote in 1945 that A. E. van Vogt \"is not a giant as often maintained. He's only a pygmy who has learned to operate an overgrown typewriter.\" He ceased reviewing when \"Fantasy &amp; Science Fiction\" refused to publish his review of Judith Merril's novel \"The Tomorrow People\". These reviews were later collected in \"In Search of Wonder\".\nAlgis Budrys wrote that Knight and \"William Atheling Jr.\" (James Blish) had \"transformed the reviewer's trade in the field\", in Knight's case \"without the guidance of his own prior example\". The term \"idiot plot\", a story that only functions because almost everyone in it is an idiot, became well known through Knight's frequent use of it in his reviews, though he believed the term was probably invented by Blish. Knight's only non-Retro-Hugo Award was for \"Best Reviewer\" in 1956.\nKnight was the founder of the Science Fiction and Fantasy Writers of America (SFWA), cofounder of the National Fantasy Fan Federation, cofounder of the Milford Writer's Workshop, and cofounder of the Clarion Writers Workshop. The SFWA officers and past presidents named Knight its 13th Grand Master in 1994 (presented 1995). After his death, the associated award was renamed the Damon Knight Memorial Grand Master Award in his honor. The Science Fiction Hall of Fame inducted him in 2003.\nUntil his death, Knight lived in Eugene, Oregon, with his second wife, author Kate Wilhelm. His papers are held in the University of Oregon Special Collections and University Archive.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49167", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=49167", "title": "Moulin rouge", "text": ""}
{"id": "49169", "revid": "49402000", "url": "https://en.wikipedia.org/wiki?curid=49169", "title": "Penelope", "text": "Wife of Odysseus in Greek mythology\nPenelope ( ; Ancient Greek: \u03a0\u03b7\u03bd\u03b5\u03bb\u03cc\u03c0\u03b5\u03b9\u03b1, \"P\u0113nel\u00f3peia\", or , \"P\u0113nel\u00f3p\u0113\") is a character in Homer's \"Odyssey.\" She was the queen of Ithaca and was the daughter of Spartan king Icarius and Asterodia. The mythological Penelope is known for her fidelity to her husband Odysseus, despite the attention of more than a hundred suitors during his absence. In one source, Penelope's original name was Arnacia or Arnaea.\nEtymology.\nGlossed by Hesychius as \"some kind of bird\" (today arbitrarily identified with the Eurasian wigeon, to which Linnaeus gave the binomial \"Anas penelope\"), where () is a common Pre-Greek suffix for predatory animals; however, the semantic relation between the proper name and the gloss is not clear. In folk etymology, () is usually understood to combine the Greek word (), \"weft\", and (), \"face\", which is considered the most appropriate for a cunning weaver whose motivation is hard to decipher. Robert S. P. Beekes believed the name to be Pre-Greek and related to () or ().\nRole in \"The Odyssey\".\nPenelope is married to the main character, the king of Ithaca, Odysseus (Ulysses in Roman mythology), and daughter of Icarius of Sparta and Periboea (or Polycaste). She has only one son with Odysseus, Telemachus, who was born just before Odysseus was called to fight in the Trojan War. She waits twenty years for Odysseus's return, during which time she devises various cunning strategies to delay marrying any of the 108 suitors (led by Antinous and including Agelaus, Amphinomus, Ctessippus, Demoptolemus, Elatus, Euryades, Eurymachus and Peisander).\nOn Odysseus's return, disguised as an old beggar, he finds that Penelope has remained faithful. She has devised cunning tricks to delay the suitors, one of which is to pretend to be weaving a burial shroud for Odysseus's elderly father Laertes and claiming that she will choose a suitor when she has finished. Every night for three years, she undoes part of the shroud, until Melantho, a slave, discovers her chicanery and reveals it to the suitors.\nPenelope's efforts to delay remarriage is often seen as a symbol of marital fidelity to her husband, Odysseus. But because Athena wants her \"to show herself to the wooers, that she might set their hearts a-flutter and win greater honor from her husband and her son than heretofore\", Penelope does eventually appear before the suitors.(xviii\u202f160\u2212162)\nIrene de Jong wrote:\n\u202fAs so often, it is Athena who takes the initiative in giving the story a new direction ... Usually the motives of mortal and god coincide, here they do not: Athena wants Penelope to fan the Suitors' desire for her and (thereby) make her more esteemed by her husband and son; Penelope has no real motive ... she simply feels an unprecedented impulse to meet the men she so loathes ... adding that she might take this opportunity to talk to Telemachus (which she will indeed do).\nIt is important to consider the alternate perspective of Penelope entertaining, and even enjoying the attention of, her suitors. Italian philosophy historian Giula Sissa offers a unique perspective which supports this idea. The Odyssey allows room for Penelope\u2019s identity free of being Ulysses's wife. As she awaits his return, she makes a plan to deal with her suitors while also responding to her desires. Sissa discusses how Penelope gives her suitors the opportunity to demonstrate themselves as the best candidate for her attention. Sissa writes,\nPenelope innovates. And she does so because she responds in the same register to the desires of the men who have been awaiting her verdict for three years. This is an erotic desire to which she reacts, first, with seductive wiles of messages and promises, and then by inviting them to demonstrate their excellence, not in terms of wealth and social prestige, but in terms of something extremely personal and physical. In order to please Penelope, they have to be on par with Ulysses in showing the might of their bodies.\nShe is ambivalent, variously asking Artemis to kill her and apparently considering marrying one of the suitors. When the disguised Odysseus returns, she announces in her long interview with him that whoever can string Odysseus's rigid bow and shoot an arrow through twelve axe heads may have her hand. \"For the plot of the \"Odyssey\", of course, her decision is the turning point, the move that makes possible the long-predicted triumph of the returning hero\".\nThere is debate as to whether Penelope knows that it is Odysseus. Penelope and the suitors know that Odysseus (were he in fact present) would easily surpass them all in any test of masculine skill, so she may have started the contest as an opportunity for him to reveal his identity. On the other hand, because Odysseus seems to be the only person (except, perhaps, Telemachus) who can actually use the bow, she could just be further delaying her marriage to one of the suitors.\nWhen the contest of the bow begins, none of the suitors are able to string the bow, except Odysseus who wins the contest. Having done so, he proceeds to slaughter the suitors \u2013 beginning with Antinous whom he finds drinking from his cup \u2013 with help from Telemachus, Athena and the slaves Eumaeus the swineherd and Philoetius the cowherd. Odysseus has now revealed himself in all his glory (with a little makeover by Athena); yet Penelope cannot believe that her husband has really returned \u2013 she fears that it is perhaps some god in disguise, as in the story of Alcmene \u2013 and tests him by ordering her slave Eurycleia to move the bed in their bridal-chamber. Odysseus protests that this cannot be done, since he made the bed himself and knows that one of its legs is a living olive tree. Penelope finally accepts that he truly is Odysseus, a moment that highlights their \"homophros\u00fdn\u0113\" (\u1f41\u03bc\u03bf\u03c6\u03c1\u03bf\u03c3\u03cd\u03bd\u03b7, \"like-mindedness\"). Homer implies that from then on Odysseus would live a long and happy life together with Penelope and Telemachus, wisely ruling his kingdom, and enjoying wide respect and much success.\nRole in other myths.\nPenelope also appears in the lost Greek epic \"Telegony\" that does not survive except in a summary, but that was attributed to Eugamon or Eugammon of Cyrene and written as a sequel to the \"Odyssey\". According to this epic, Odysseus had a son called Telegonus with Circe when he was on her island. When Telegonus had grown to manhood, Circe sent him in search of Odysseus. Shipwrecked on Ithaca by a storm, Telegonus misidentified the island and, assailed by hunger, began plundering it. Odysseus and his oldest son, Telemachus, defended their city and, in the ensuing mel\u00e9e, Telegonus accidentally killed his father with a lance tipped with the venomous spine of a stingray. After discovering the identity of his father, Telegonus brought Telemachus and Penelope to Circe's island. Here, Athena ordered the marriage of Telemachus to Telegonus's mother, the enchantress Circe, while Telegonus married the new widowed Penelope. After burying Odysseus, Circe made the other three immortal. According to Hyginus, Penelope and Telegonus had a son called Italus who, according to some accounts, gave his name to Italy. This legend inspired Sophocles's lost tragedy \"Odysseus Acanthoplex\".\nIn some early sources such as Pindar, Pan's parents are Apollo and Penelope. Herodotus, Cicero, Apollodorus, and Hyginus all describe Hermes and Penelope as his parents. Pausanias records the story that Penelope had in fact been unfaithful to Odysseus, who banished her to Mantineia upon his return. In the 5th\u00a0century\u00a0AD Nonnus names Pan's mother as Penelope of Mantineia in Arcadia. Other sources report that Penelope had slept with all 108\u00a0suitors in Odysseus's absence, and gave birth to Pan as a result. This myth reflects the folk etymology that equates Pan's name (\u03a0\u03ac\u03bd) with the Greek word for \"all\" (\u03c0\u1fb6\u03bd). The \"Odyssey\" carefully suppresses this variant tradition.\nIconography.\nPenelope is recognizable in Greek and Roman works, from Attic vase-paintings\u2014the is recognized by his representations of her\u2014to Roman sculptures copying or improvising upon classical Greek models, by her seated pose, by her reflective gesture of leaning her cheek on her hand, and by her protectively crossed legs, reflecting her long chastity in Odysseus's absence, an unusual pose in any other figure.\nLatin tradition.\nLatin references to Penelope revolved around her sexual loyalty to the absent Odysseus. It suited the marital aspect of Roman society representing the tranquility of the worthy family. She is mentioned by various classical authors including Plautus, Propertius, Horace, Ovid, Martial and Statius. The use of Penelope in Latin texts provided a basis for her ongoing use in the Middle Ages and Renaissance as a representation of a chaste wife. This was reinforced by her being named by Saint Jerome among pagan women famed for their chastity.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49171", "revid": "50709750", "url": "https://en.wikipedia.org/wiki?curid=49171", "title": "Interval (music)", "text": "Difference in pitch between two notes\n&lt;score sound=\"1\" override_midi=\"Melodic and harmonic intervals.mid\"&gt;\n\\layout {\nline-width = 60\\mm\nindent = 0\\mm\n\\relative c\"{\n\\clef treble \\time 3/1 \\hide Staff.TimeSignature\nd,1 g f \\bar \" Melodic and harmonic intervals\nIn music theory, an interval is a difference in pitch between two sounds. An interval may be described as horizontal, linear, or melodic if it refers to successively sounding tones, such as two adjacent pitches in a melody, and vertical or harmonic if it pertains to simultaneously sounding tones, such as in a chord.\nIn Western music, intervals are most commonly differencing between notes of a diatonic scale. Intervals between successive notes of a scale are also known as scale steps. The smallest of these intervals is a semitone. Intervals smaller than a semitone are called microtones. They can be formed using the notes of various kinds of non-diatonic scales. Some of the very smallest ones are called commas, and describe small discrepancies, observed in some tuning systems, between enharmonically equivalent notes such as C\u266f and D\u266d. Intervals can be arbitrarily small, and even imperceptible to the human ear.\nIn physical terms, an interval is the ratio between two sonic frequencies. For example, any two notes an octave apart have a frequency ratio of 2:1. This means that successive increments of pitch by the same interval result in an exponential increase of frequency, even though the human ear perceives this as a linear increase in pitch. For this reason, intervals are often measured in cents, a unit derived from the logarithm of the frequency ratio.\nIn Western music theory, the most common naming scheme for intervals describes two properties of the interval: the quality (perfect, major, minor, augmented, diminished) and number (unison, second, third, etc.). Examples include the minor third or perfect fifth. These names identify not only the difference in semitones between the upper and lower notes but also how the interval is spelled. The importance of spelling stems from the historical practice of differentiating the frequency ratios of enharmonic intervals such as G\u2013G\u266f and G\u2013A\u266d.\nSize.\n&lt;score sound=\"1\"&gt;\n\\relative c'{\n\\hide Staff.TimeSignature\n&lt;d f&gt;1 Example: Minor third on D in equal temperament: 300 cents.\nThe size of an interval (also known as its width or height) can be represented using two alternative and equivalently valid methods, each appropriate to a different context: frequency ratios or cents.\nFrequency ratios.\nThe size of an interval between two notes may be measured by the ratio of their frequencies. When a musical instrument is tuned using a just intonation tuning system, the size of the main intervals can be expressed by small-integer ratios, such as 1:1 (unison), 2:1 (octave), 5:3 (major sixth), 3:2 (perfect fifth), 4:3 (perfect fourth), 5:4 (major third), 6:5 (minor third). Intervals with small-integer ratios are often called \"just intervals\", or \"pure intervals\".\nMost commonly, however, musical instruments are nowadays tuned using a different tuning system, called 12-tone equal temperament. As a consequence, the size of most equal-tempered intervals cannot be expressed by small-integer ratios, although it is very close to the size of the corresponding just intervals. For instance, an equal-tempered fifth has a frequency ratio of 2:1, approximately equal to 1.498:1, or 2.997:2 (very close to 3:2). For a comparison between the size of intervals in different tuning systems, see .\nCents.\nThe standard system for comparing interval sizes is with cents. The cent is a logarithmic unit of measurement. If frequency is expressed in a logarithmic scale, and along that scale the distance between a given frequency and its double (also called octave) is divided into 1200 equal parts, each of these parts is one cent. In twelve-tone equal temperament (12-TET), a tuning system in which all semitones have the same size, the size of one semitone is exactly 100 cents. Hence, in 12-TET the cent can be also defined as one hundredth of a semitone.\nMathematically, the size in cents of the interval from frequency \"f\"1 to frequency \"f\"2 is\nformula_1\nMain intervals.\nThe table shows the most widely used conventional names for the intervals between the notes of a chromatic scale. A perfect unison (also known as perfect prime) is an interval formed by two identical notes. Its size is zero cents. A semitone is any interval between two adjacent notes in a chromatic scale, a whole tone is an interval spanning two semitones (for example, a major second), and a tritone is an interval spanning three tones, or six semitones (for example, an augmented fourth). Rarely, the term ditone is also used to indicate an interval spanning two whole tones (for example, a major third), or more strictly as a synonym of major third.\nIntervals with different names may span the same number of semitones, and may even have the same width. For instance, the interval from D to F\u266f is a major third, while that from D to G\u266d is a diminished fourth. However, they both span 4 semitones. If the instrument is tuned so that the 12 notes of the chromatic scale are equally spaced (as in equal temperament), these intervals also have the same width. Namely, all semitones have a width of 100 cents, and all intervals spanning 4 semitones are 400 cents wide.\nThe names listed here cannot be determined by counting semitones alone. The rules to determine them are explained below. Other names, determined with different naming conventions, are listed in a separate section. Intervals smaller than one semitone (commas or microtones) and larger than one octave (compound intervals) are introduced below.\nInterval number and quality.\nIn Western music theory, an interval is named according to its \"number\" (also called \"diatonic number, interval size\" or \"generic interval\") and \"quality\". For instance, \"major third\" (or M3) is an interval name, in which the term \"major\" (M) describes the quality of the interval, and \"third\" (3) indicates its number.\nNumber.\nThe number of an interval is the number of letter names or staff positions (lines and spaces) it encompasses, including the positions of both notes forming the interval. For instance, the interval B\u2013D is a third (denoted m3) because the notes from B to the D above it encompass three letter names (B, C, D) and occupy three consecutive staff positions, including the positions of B and D. The table and the figure above show intervals with numbers ranging from 1 (e.g., P1) to 8 (e.g., d8). Intervals with larger numbers are called compound intervals.\nThere is a one-to-one correspondence between staff positions and diatonic-scale degrees (the notes of diatonic scale).\nThis means that interval numbers can also be determined by counting diatonic scale degrees, rather than staff positions, provided that the two notes that form the interval are drawn from a diatonic scale. Namely, B\u2013D is a third because in any diatonic scale that contains B and D, the sequence from B to D includes three notes. For instance, in the B-natural minor diatonic scale, the three notes are B\u2013C\u266f\u2013D. This is not true for all kinds of scales. For instance, in a chromatic scale, there are four notes from B to D: B\u2013C\u2013C\u266f\u2013D. This is the reason interval numbers are also called \"diatonic numbers\", and this convention is called \"diatonic numbering\".\nIf one adds any accidentals to the notes that form an interval, by definition the notes do not change their staff positions. As a consequence, any interval has the same interval number as the corresponding natural interval, formed by the same notes without accidentals. For instance, the intervals B\u2013D\u266f (spanning 4 semitones) and B\u2013D\u266d (spanning 2 semitones) are thirds, like the corresponding natural interval B\u2013D (3 semitones).\nNotice that interval numbers represent an inclusive count of encompassed staff positions or note names, not the difference between the endpoints. In other words, one starts counting the lower pitch as one, not zero. For that reason, the interval E\u2013E, a perfect unison, is also called a prime (meaning \"1\"), even though there is no difference between the endpoints. Continuing, the interval E\u2013F\u266f is a second, but F\u266f is only one staff position, or diatonic-scale degree, above E. Similarly, E\u2013G\u266f is a third, but G\u266f is only two staff positions above E, and so on. As a consequence, joining two intervals always yields an interval number one less than their sum. For instance, the intervals B\u2013D and D\u2013F\u266f are thirds, but joined together they form a fifth (B\u2013F\u266f), not a sixth. Similarly, a stack of three thirds, such as B\u2013D, D\u2013F\u266f, and F\u266f\u2013A, is a seventh (B\u2013A), not a ninth.\nThis scheme applies to intervals up to an octave (12 semitones). For larger intervals, see below.\nQuality.\nThe name of any interval is further qualified using the terms perfect (P), major (M), minor (m), augmented (A), and diminished (d). This is called its \"interval quality\" (or \"modifier\"). It is possible to have doubly diminished and doubly augmented intervals, but these are quite rare, as they occur only in chromatic contexts. The combination of number (or generic interval) and quality (or modifier) is called the \"specific interval\", \"diatonic interval\" (sometimes used only for intervals appearing in the diatonic scale), or simply \"interval\".\nThe quality of a compound interval is the quality of the simple interval on which it is based. Some other qualifiers like \"neutral\", \"subminor\", and \"supermajor\" are used for non-diatonic intervals.\nPerfect.\nPerfect intervals are so-called because they were traditionally considered perfectly consonant,\nalthough in Western classical music the perfect fourth was sometimes regarded as a less than perfect consonance, when its function was contrapuntal. Conversely, minor, major, augmented, or diminished intervals are typically considered less consonant, and were traditionally classified as mediocre consonances, imperfect consonances, or near-dissonances.\nWithin a diatonic scale all unisons (P1) and octaves (P8) are perfect. Most fourths and fifths are also perfect (P4 and P5), with five and seven semitones respectively. One occurrence of a fourth is augmented (A4) and one fifth is diminished (d5), both spanning six semitones. For instance, in an E-major scale, the A4 is between A and D\u266f, and the d5 is between D\u266f and A.\nThe inversion of a perfect interval is also perfect. Since the inversion does not change the pitch class of the two notes, it hardly affects their level of consonance (matching of their harmonics). Conversely, other kinds of intervals have the opposite quality with respect to their inversion. The inversion of a major interval is a minor interval, and the inversion of an augmented interval is a diminished interval.\nMajor and minor.\nAs shown in the table, a diatonic scale defines seven intervals for each interval number, each starting from a different note (seven unisons, seven seconds, etc.). The intervals formed by the notes of a diatonic scale are called diatonic. Except for unisons and octaves, the diatonic intervals with a given interval number always occur in two sizes, which differ by one semitone. For example, six of the fifths span seven semitones. The other one spans six semitones. Four of the thirds span three semitones, the others four. If one of the two versions is a perfect interval, the other is called either diminished (i.e. narrowed by one semitone) or augmented (i.e. widened by one semitone). Otherwise, the larger version is called major, the smaller one minor. For instance, since a 7-semitone fifth is a perfect interval (P5), the 6-semitone fifth is called \"diminished fifth\" (d5). Conversely, since neither kind of third is perfect, the larger one is called \"major third\" (M3), the smaller one \"minor third\" (m3).\nWithin a diatonic scale, unisons and octaves are always qualified as perfect, fourths as either perfect or augmented, fifths as perfect or diminished, and all the other intervals (seconds, thirds, sixths, sevenths) as major or minor.\nAugmented and diminished.\nAugmented intervals are wider by one semitone than perfect or major intervals, while having the same interval number (i.e., encompassing the same number of staff positions): they are wider by a chromatic semitone. Diminished intervals, on the other hand, are narrower by one semitone than perfect or minor intervals of the same interval number: they are narrower by a chromatic semitone. For instance, an augmented sixth such as E\u266d\u2013C\u266f spans ten semitones, exceeding a major sixth (E\u266d\u2013C) by one semitone, while a diminished sixth such as E\u266f\u2013C spans seven semitones, falling short of a minor sixth (E\u266f\u2013C\u266f) by one semitone.\nThe augmented fourth (A4) and the diminished fifth (d5) are the only augmented and diminished intervals that appear in diatonic scales (see table).\nExample.\nNeither the number, nor the quality of an interval can be determined by counting semitones alone. As explained above, the number of staff positions must be taken into account as well.\nFor example, as shown in the table below, there are six semitones between C and F\u266f, C and G\u266d, and C\u266d and E\u266f, but\nShorthand notation.\nIntervals are often abbreviated with a P for perfect, m for minor, M for major, d for diminished, A for augmented, followed by the interval number. The indications M and P are often omitted. The octave is P8, and a unison is usually referred to simply as \"a unison\" but can be labeled P1. The tritone, an augmented fourth or diminished fifth is often TT. The interval qualities may be also abbreviated with perf, min, maj, dim, aug. Examples:\nInversion.\nA simple interval (i.e., an interval smaller than or equal to an octave) may be inverted by raising the lower pitch an octave or lowering the upper pitch an octave. For example, the fourth from a lower C to a higher F may be inverted to make a fifth, from a lower F to a higher C.\n &lt;score sound=\"1\"&gt;\n\\override Score.TimeSignature\n\\override Score.SpacingSpanner.strict-note-spacing = ##t\n\\set Score.proportionalNotationDuration = #(ly:make-moment 1/4)\n\\new Staff \u00ab\n \\clef treble \\time 4/4\n \\new Voice \\relative c' {\n \\stemUp c2 c' c, c' c, c' c, c'\n \\new Voice \\relative c' {\n \\stemDown c2 c d d e e f f\n&lt;/score&gt;\nThere are two rules to determine the number and quality of the inversion of any simple interval:\nFor example, the interval from C to the E\u266d above it is a minor third. By the two rules just given, the interval from E\u266d to the C above it must be a major sixth.\nSince compound intervals are larger than an octave, \"the inversion of any compound interval is always the same as the inversion of the simple interval from which it is compounded\".\nFor intervals identified by their ratio, the inversion is determined by reversing the ratio and multiplying the ratio by 2 until it is greater than 1. For example, the inversion of a 5:4 ratio is an 8:5 ratio.\nFor intervals identified by an integer number of semitones, the inversion is obtained by subtracting that number from 12.\nSince an interval class is the lower number selected among the interval integer and its inversion, interval classes cannot be inverted.\nClassification.\nIntervals can be described, classified, or compared with each other according to various criteria.\n&lt;score sound=\"1\" override_midi=\"Melodic and harmonic intervals.mid\"&gt;\n\\layout {\nline-width = 60\\mm\nindent = 0\\mm\n\\relative c\"{\n\\clef treble \\time 3/1 \\hide Staff.TimeSignature\nd,1 g f \\bar \" Melodic and harmonic intervals\nMelodic and harmonic.\nAn interval can be described as\nDiatonic and chromatic.\nIn general,\nThe table above depicts the 56 diatonic intervals formed by the notes of the C major scale (a diatonic scale). Notice that these intervals, as well as any other diatonic interval, can be also formed by the notes of a chromatic scale.\nThe distinction between diatonic and chromatic intervals is controversial, as it is based on the definition of diatonic scale, which is variable in the literature. For example, the interval B\u2013E\u266d (a diminished fourth, occurring in the harmonic C-minor scale) is considered diatonic if the harmonic minor scales are considered diatonic as well. Otherwise, it is considered chromatic. For further details, see the main article.\nBy a commonly used definition of diatonic scale (which excludes the harmonic minor and melodic minor scales), all perfect, major and minor intervals are diatonic. Conversely, no augmented or diminished interval is diatonic, except for the augmented fourth and diminished fifth.\nThe distinction between diatonic and chromatic intervals may be also sensitive to context. The above-mentioned 56 intervals formed by the C-major scale are sometimes called \"diatonic to C major\". All other intervals are called \"chromatic to C major\". For instance, the perfect fifth A\u266d\u2013E\u266d is chromatic to C major, because A\u266d and E\u266d are not contained in the C major scale. However, it is diatonic to others, such as the A\u266d major scale.\nConsonant and dissonant.\nConsonance and dissonance are relative terms that refer to the stability, or state of repose, of particular musical effects. Dissonant intervals are those that cause tension and desire to be \"resolved\" to consonant intervals.\nThese terms are relative to the usage of different compositional styles.\nAll of the above analyses refer to vertical (simultaneous) intervals.\nSimple and compound.\nA simple interval is an interval spanning at most one octave (see Main intervals above). Intervals spanning more than one octave are called compound intervals, as they can be obtained by adding one or more octaves to a simple interval (see below for details).\nSteps and skips.\nLinear (melodic) intervals may be described as \"steps\" or \"skips\". A \"step\", or \"conjunct motion\",\nis a linear interval between two consecutive notes of a scale. Any larger interval is called a \"skip\" (also called a \"leap\"), or \"disjunct motion\". In the diatonic scale, a step is either a minor second (sometimes also called \"half step\") or major second (sometimes also called \"whole step\"), with all intervals of a minor third or larger being skips.\nFor example, C\u2013D (major second) is a step, whereas C\u2013E (major third) is a skip.\nMore generally, a step is a smaller or narrower interval in a musical line, and a skip is a wider or larger interval, where the categorization of intervals into steps and skips is determined by the tuning system and the pitch space used.\nMelodic motion in which the interval between any two consecutive pitches is no more than a step, or, less strictly, where skips are rare, is called \"stepwise\" or \"conjunct\" melodic motion, as opposed to \"skipwise\" or \"disjunct\" melodic motions, characterized by frequent skips.\nEnharmonic intervals.\nTwo intervals are considered \"enharmonic\", or \"enharmonically equivalent\", if they both contain the same pitches spelled in different ways; that is, if the notes in the two intervals are themselves enharmonically equivalent. Enharmonic intervals span the same number of semitones.\nFor example, the four intervals listed in the table below are all enharmonically equivalent, because the notes F\u266f and G\u266d indicate the same pitch, and the same is true for A\u266f and B\u266d. All these intervals span four semitones.\nWhen played as isolated chords on a piano keyboard, these intervals are indistinguishable to the ear, because they are all played with the same two keys. However, in a musical context, the diatonic function of the notes these intervals incorporate is very different.\nThe discussion above assumes the use of the prevalent tuning system, 12-tone equal temperament (\"12-TET\"). But in other historic meantone temperaments, the pitches of pairs of notes such as F\u266f and G\u266d may not necessarily coincide. These two notes are enharmonic in 12-TET, but may not be so in another tuning system. In such cases, the intervals they form would also not be enharmonic. For example, in quarter-comma meantone, all four intervals shown in the example above would be different.\nMinute intervals.\nThere are also a number of minute intervals not found in the chromatic scale or labeled with a diatonic function, which have names of their own. They may be described as microtones, and some of them can be also classified as commas, as they describe small discrepancies, observed in some tuning systems, between enharmonically equivalent notes. In the following list, the interval sizes in cents are approximate.\nCompound intervals.\nA compound interval is an interval spanning more than one octave. Conversely, intervals spanning at most one octave are called simple intervals (see Main intervals below).\nIn general, a compound interval may be defined by a sequence or \"stack\" of two or more simple intervals of any kind. For instance, a major tenth (two staff positions above one octave), also called \"compound major third\", spans one octave plus one major third.\nAny compound interval can be always decomposed into one or more octaves plus one simple interval. For instance, a major seventeenth can be decomposed into two octaves and one major third, and this is the reason why it is called a compound major third, even when it is built by adding up four fifths.\nThe diatonic number \"DN\"c of a compound interval formed from \"n\" simple intervals with diatonic numbers \"DN\"1, \"DN\"2, ..., \"DN\"n, is determined by:\nformula_2\nwhich can also be written as:\nformula_3\nThe quality of a compound interval is determined by the quality of the simple interval on which it is based. For instance, a compound major third is a major tenth (1+(8\u22121)+(3\u22121) = 10), or a major seventeenth (1+(8\u22121)+(8\u22121)+(3\u22121) = 17), and a compound perfect fifth is a perfect twelfth (1+(8\u22121)+(5\u22121) = 12) or a perfect nineteenth (1+(8\u22121)+(8\u22121)+(5\u22121) = 19). Notice that two octaves are a fifteenth, not a sixteenth (1+(8\u22121)+(8\u22121) = 15). Similarly, three octaves are a twenty-second (1+3\u00d7(8\u22121) = 22), four octaves are a twenty-ninth (1+3\u00d7(8-1) = 29), and so on.\nMain compound intervals.\nIt is also worth mentioning here the major seventeenth (28 semitones)\u2014an interval larger than two octaves that can be considered a multiple of a perfect fifth (7 semitones) as it can be decomposed into four perfect fifths (7 \u00d7 4 = 28 semitones), or two octaves plus a major third (12 + 12 + 4 = 28 semitones). Intervals larger than a major seventeenth seldom come up, most often being referred to by their compound names, for example \"two octaves plus a fifth\" rather than \"a 19th\".\nIntervals in chords.\nChords are sets of three or more notes. They are typically defined as the combination of intervals starting from a common note called the root of the chord. For instance a major triad is a chord containing three notes defined by the root and two intervals (major third and perfect fifth). Sometimes even a single interval (dyad) is considered a chord. Chords are classified based on the quality and number of the intervals that define them.\nChord qualities and interval qualities.\nThe main chord qualities are major, minor, augmented, diminished, half-diminished, and dominant.\nThe symbols used for chord quality are similar to those used for interval quality (see above). In addition, + or aug is used for augmented, \u00b0 or dim for diminished, \u00f8 for half diminished, and dom for dominant (the symbol \u2212 alone is not used for diminished).\nDeducing component intervals from chord names and symbols.\nThe main rules to decode chord \"names or symbols\" are summarized below. Further details are given at Rules to decode chord names and symbols.\nThe table shows the intervals contained in some of the main chords (component intervals), and some of the symbols used to denote them. The interval qualities or numbers in boldface font can be deduced from chord name or symbol by applying rule 1. In symbol examples, C is used as chord root.\nSize of intervals used in different tuning systems.\nIn this table, the interval widths used in four different tuning systems are compared. To facilitate comparison, just intervals as provided by 5-limit tuning (see symmetric scale n.1) are shown in bold font, and the values in cents are rounded to integers. Notice that in each of the non-equal tuning systems, by definition the width of \"each\" type of interval (including the semitone) changes depending on the note that starts the interval. This is the art of just intonation. In equal temperament, the intervals are never precisely in tune with each other. This is the price of using equidistant intervals in a 12-tone scale. For simplicity, for some types of interval the table shows only one value (the most often observed one).\nIn &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444-comma meantone, by definition 11 perfect fifths have a size of approximately 697 cents (700\u00a0\u2212\u00a0\"\u03b5\" cents, where \"\u03b5\"\u00a0\u2248\u00a03.42 cents); since the average size of the 12 fifths must equal exactly 700 cents (as in equal temperament), the other one must have a size of about 738 cents (700\u00a0+\u00a011\"\u03b5\", the wolf fifth or diminished sixth); 8 major thirds have size about 386 cents (400\u00a0\u2212\u00a04\"\u03b5\"), 4 have size about 427 cents (400\u00a0+\u00a08\"\u03b5\", actually diminished fourths), and their average size is 400 cents. In short, similar differences in width are observed for all interval types, except for unisons and octaves, and they are all multiples of \u03b5 (the difference between the &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444-comma meantone fifth and the average fifth). A more detailed analysis is provided at &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444-comma meantone Size of intervals. &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444-comma meantone was designed to produce just major thirds, but only 8 of them are just (5:4, about 386 cents).\nThe Pythagorean tuning is characterized by smaller differences because they are multiples of a smaller \"\u03b5\" (\"\u03b5\"\u00a0\u2248\u00a01.96 cents, the difference between the Pythagorean fifth and the average fifth). Notice that here the fifth is wider than 700 cents, while in most meantone temperaments, including &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444-comma meantone, it is tempered to a size smaller than 700. A more detailed analysis is provided at .\nThe 5-limit tuning system uses just tones and semitones as building blocks, rather than a stack of perfect fifths, and this leads to even more varied intervals throughout the scale (each kind of interval has three or four different sizes). A more detailed analysis is provided at . 5-limit tuning was designed to maximize the number of just intervals, but even in this system some intervals are not just (e.g., 3 fifths, 5 major thirds and 6 minor thirds are not just; also, 3 major and 3 minor thirds are wolf intervals).\nThe above-mentioned symmetric scale 1, defined in the 5-limit tuning system, is not the only method to obtain just intonation. It is possible to construct juster intervals or just intervals closer to the equal-tempered equivalents, but most of the ones listed above have been used historically in equivalent contexts. In particular, the asymmetric version of the 5-limit tuning scale provides a juster value for the minor seventh (9:5, rather than 16:9). Moreover, the tritone (augmented fourth or diminished fifth), could have other just ratios; for instance, 7:5 (about 583 cents) or 17:12 (about 603 cents) are possible alternatives for the augmented fourth (the latter is fairly common, as it is closer to the equal-tempered value of 600 cents). The 7:4 interval (about 969 cents), also known as the harmonic seventh, has been a contentious issue throughout the history of music theory; it is 31 cents flatter than an equal-tempered minor seventh. For further details about reference ratios, see .\nIn the diatonic system, every interval has one or more \"enharmonic equivalents\", such as augmented second for minor third.\nInterval root.\nAlthough intervals are usually designated in relation to their lower note, David Cope and Hindemith both suggest the concept of interval root. To determine an interval's root, one locates its nearest approximation in the harmonic series. The root of a perfect fourth, then, is its \"top\" note because it is an octave of the fundamental in the hypothetical harmonic series. The bottom note of every odd diatonically numbered intervals are the roots, as are the tops of all even numbered intervals. The root of a collection of intervals or a chord is thus determined by the interval root of its strongest interval.\nAs to its usefulness, Cope provides the example of the final tonic chord of some popular music being traditionally analyzable as a \"submediant six-five chord\" (added sixth chords by popular terminology), or a first inversion seventh chord (possibly the dominant of the mediant V/iii). According to the interval root of the strongest interval of the chord (in first inversion, CEGA), the perfect fifth (C\u2013G), is the bottom C, the tonic.\nInterval cycles.\nInterval cycles, \"unfold [i.e., repeat] a single recurrent interval in a series that closes with a return to the initial pitch class\", and are notated by George Perle using the letter \"C\", for cycle, with an interval-class integer to distinguish the interval. Thus the diminished-seventh chord would be C3 and the augmented triad would be C4. A superscript may be added to distinguish between transpositions, using 0\u201311 to indicate the lowest pitch class in the cycle.\nAlternative interval naming conventions.\nAs shown below, some of the above-mentioned intervals have alternative names, and some of them take a specific alternative name in Pythagorean tuning, five-limit tuning, or meantone temperament tuning systems such as quarter-comma meantone. All the intervals with prefix \"sesqui-\" are justly tuned, and their frequency ratio, shown in the table, is a superparticular number (or epimoric ratio). The same is true for the octave.\nTypically, a comma is a diminished second, but this is not always true (for more details, see Alternative definitions of comma). For instance, in Pythagorean tuning the diminished second is a descending interval (524288:531441, or about \u221223.5 cents), and the Pythagorean comma is its opposite (531441:524288, or about 23.5 cents). 5-limit tuning defines four kinds of comma, three of which meet the definition of diminished second, and hence are listed in the table below. The fourth one, called syntonic comma (81:80) can neither be regarded as a diminished second, nor as its opposite. See Diminished seconds in 5-limit tuning for further details.\nAdditionally, some cultures around the world have their own names for intervals found in their music. For instance, 22 kinds of intervals, called shrutis, are canonically defined in Indian classical music.\nLatin nomenclature.\nUp to the end of the 18th century, Latin was used as an official language throughout Europe for scientific and music textbooks. In music, many English terms are derived from Latin. For instance, semitone is from Latin \"\".\nThe prefix semi- is typically used herein to mean \"shorter\", rather than \"half\". Namely, a semitonus, semiditonus, semidiatessaron, semidiapente, semihexachordum, semiheptachordum, or semidiapason, is shorter by one semitone than the corresponding whole interval. For instance, a semiditonus (3 semitones, or about 300 cents) is not half of a ditonus (4 semitones, or about 400 cents), but a ditonus shortened by one semitone. Moreover, in Pythagorean tuning (the most commonly used tuning system up to the 16th century), a semitritonus (d5) is smaller than a tritonus (A4) by one Pythagorean comma (about a quarter of a semitone).\nNon-diatonic intervals.\nIntervals in non-diatonic scales can be named using analogs of the diatonic interval names, by using a diatonic interval of similar size and distinguishing it by varying the quality, or by adding other modifiers. For example, the just interval 7/6 may be referred to as a \"subminor third\", since it is ~267 cents wide, which is narrower than a minor third (300 cents in 12-TET, ~316 cents for the just interval 6/5), or as the \"septimal minor third\", since it is a 7-limit interval. These names refer just to the individual interval's size, and the interval number need not correspond to the number of scale degrees of a (heptatonic) scale. This naming is particularly common in just intonation and microtonal scales.\nThe most common of these extended qualities are a neutral interval, in between a minor and major interval; and subminor and supermajor intervals, respectively narrower than a minor or wider than a major interval. The exact size of such intervals depends on the tuning system, but they often vary from the diatonic interval sizes by about a quarter tone (50 cents, half a chromatic step). For example, the neutral second, the characteristic interval of Arabic music, in 24-TET is 150 cents, exactly halfway between a minor second and major second. Combined, these yield the progression \"diminished, subminor, minor, neutral, major, supermajor, augmented\" for seconds, thirds, sixths, and sevenths. This naming convention can be extended to unisons, fourths, fifths, and octaves with \"sub\" and \"super\", yielding the progression \"diminished, sub, perfect, super, augmented\". This allows one to name all intervals in 24-TET or 31-TET, the latter of which was used by Adriaan Fokker. Various further extensions are used in Xenharmonic music.\nPitch-class intervals.\nIn post-tonal or atonal theory, originally developed for equal-tempered European classical music written using the twelve-tone technique or serialism, integer notation is often used, most prominently in musical set theory. In this system, intervals are named according to the number of half steps, from 0 to 11, the largest interval class being 6.\nIn atonal or musical set theory, there are numerous types of intervals, the first being the ordered pitch interval, the distance between two pitches upward or downward. For instance, the interval from C upward to G is 7, and the interval from G downward to C is \u22127. One can also measure the distance between two pitches without taking into account direction with the unordered pitch interval, somewhat similar to the interval of tonal theory.\nThe interval between pitch classes may be measured with ordered and unordered pitch-class intervals. The ordered one, also called directed interval, may be considered the measure upwards, which, since we are dealing with pitch classes, depends on whichever pitch is chosen as 0. For unordered pitch-class intervals, see interval class.\nGeneric and specific intervals.\nIn diatonic set theory, specific and generic intervals are distinguished. Specific intervals are the interval class or number of semitones between scale steps or collection members, and generic intervals are the number of diatonic scale steps (or staff positions) between notes of a collection or scale.\nNotice that staff positions, when used to determine the conventional interval number (second, third, fourth, etc.), are counted including the position of the lower note of the interval, while generic interval numbers are counted excluding that position. Thus, generic interval numbers are smaller by 1, with respect to the conventional interval numbers.\nGeneralizations and non-pitch uses.\nThe term \"interval\" can also be generalized to other music elements besides pitch. David Lewin's \"Generalized Musical Intervals and Transformations\" uses interval as a generic measure of distance between time points, timbres, or more abstract musical phenomena.\nFor example, an interval between two bell-like sounds, which have no pitch salience, is still perceptible. When two tones have similar acoustic spectra (sets of partials), the interval is just the distance of the shift of a tone spectrum along the frequency axis, so linking to pitches as reference points is not necessary. The same principle naturally applies to pitched tones (with similar harmonic spectra), which means that intervals can be perceived \"directly\" without pitch recognition. This explains in particular the predominance of interval hearing over absolute pitch hearing.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49172", "revid": "1319520463", "url": "https://en.wikipedia.org/wiki?curid=49172", "title": "Interval (mathematics)", "text": "All numbers between two given numbers\nIn mathematics, a real interval is the set of all real numbers lying between two fixed endpoints with no \"gaps\". Each endpoint is either a real number or positive or negative infinity, indicating the interval extends without a bound. A real interval can contain neither endpoint, either endpoint, or both endpoints, excluding any endpoint which is infinite.\nFor example, the set of real numbers consisting of 0, 1, and all numbers in between is an interval, denoted [0, 1] and called the unit interval; the set of all positive real numbers is an interval, denoted (0, \u221e); the set of all real numbers is an interval, denoted (\u2212\u221e, \u221e); and any single real number a is an interval, denoted [\"a\", \"a\"].\nIntervals are ubiquitous in mathematical analysis. For example, they occur implicitly in the epsilon-delta definition of continuity; the intermediate value theorem asserts that the image of an interval by a continuous function is an interval; integrals of real functions are defined over an interval; etc.\nInterval arithmetic consists of computing with intervals instead of real numbers for providing a guaranteed enclosure of the result of a numerical computation, even in the presence of uncertainties of input data and rounding errors.\nIntervals are likewise defined on an arbitrary totally ordered set, such as integers or rational numbers. The notation of integer intervals is considered in the special section below.\nDefinitions and terminology.\nAn \"interval\" is a subset of the real numbers that contains all real numbers lying between any two numbers of the subset. In particular, the empty set formula_1 and the entire set of real numbers formula_2 are both intervals.\nThe \"endpoints\" of an interval are its supremum, and its infimum, if they exist as real numbers. If the infimum does not exist, one says often that the corresponding endpoint is formula_3 Similarly, if the supremum does not exist, one says that the corresponding endpoint is formula_4\nIntervals are completely determined by their endpoints and whether each endpoint belong to the interval. This is a consequence of the least-upper-bound property of the real numbers. This characterization is used to specify intervals by means of \"&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;interval notation\", which is described below.\nAn &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;open interval does not include any endpoint, and is indicated with parentheses. For example, formula_5 is the interval of all real numbers greater than 0 and less than 1. (This interval can also be denoted by ]0, 1[, see below). The open interval consists of real numbers greater than 0, i.e., positive real numbers. The open intervals have thus one of the forms\nformula_6 and formula_7 are real numbers such that formula_8 In the last case, the resulting interval is the empty set and does not depend on &amp;NoBreak;&amp;NoBreak;. The open intervals are those intervals that are open sets for the usual topology on the real numbers.\nA &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;closed interval is an interval that includes all its endpoints and is denoted with square brackets. For example, [0, 1] means greater than or equal to 0 and less than or equal to 1. Closed intervals have one of the following forms in which a and b are real numbers such that formula_9\nformula_10\nThe closed intervals are those intervals that are closed sets for the usual topology on the real numbers.\nA \"&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;half-open interval\" has two endpoints and includes only one of them. It is said \"left-open\" or \"right-open\" depending on whether the excluded endpoint is on the left or on the right. These intervals are denoted by mixing notations for open and closed intervals. For example, (0, 1] means greater than 0 and less than or equal to 1, while [0, 1) means greater than or equal to 0 and less than 1. The half-open intervals have the form\nformula_11 The context affects some of the above definitions and terminology. For instance, the interval (\u2212\u221e,\u2009+\u221e)\u00a0=\u00a0formula_2 is closed in the realm of ordinary reals, but not in the realm of the extended reals.\nInteger intervals.\nWhen a and b are integers, the notation \u27e6\"a, b\"\u27e7, or [\"a\" .. \"b\"] or {\"a\" .. \"b\"} or just \"a\" .. \"b\", is sometimes used to indicate the interval of all \"integers\" between a and b included. The notation [\"a\" .. \"b\"] is used in some programming languages; in Pascal, for example, it is used to formally define a subrange type, most frequently used to specify lower and upper bounds of valid indices of an array.\nAnother way to interpret integer intervals are as sets defined by enumeration, using ellipsis notation.\nAn integer interval that has a finite lower or upper endpoint always includes that endpoint. Therefore, the exclusion of endpoints can be explicitly denoted by writing \"a\" .. \"b\"\u2009\u2212\u20091\u2009, \"a\"\u2009+\u20091 .. \"b\"\u2009, or \"a\"\u2009+\u20091 .. \"b\"\u2009\u2212\u20091. Alternate-bracket notations like [\"a\" .. \"b\") or [\"a\" .. \"b\"[ are rarely used for integer intervals.\nProperties.\nThe intervals are precisely the connected subsets of formula_13 It follows that the image of an interval by any continuous function from formula_14 to formula_14 is also an interval. This is one formulation of the intermediate value theorem.\nThe intervals are also the convex subsets of formula_13 The interval enclosure of a subset formula_17 is also the convex hull of formula_18\nThe closure of an interval is the union of the interval and the set of its finite endpoints, and hence is also an interval. (The latter also follows from the fact that the closure of every connected subset of a topological space is a connected subset.) In other words, we have\nformula_19\nformula_20\nformula_21\nformula_22\nThe intersection of any collection of intervals is always an interval. The union of two intervals is an interval if and only if they have a non-empty intersection or an open end-point of one interval is a closed end-point of the other, for example formula_23\nIf formula_2 is viewed as a metric space, its open balls are the open bounded intervals\u00a0(\"c\"\u2009+\u2009\"r\",\u2009\"c\"\u2009\u2212\u2009\"r\"), and its closed balls are the closed bounded intervals\u00a0[\"c\"\u2009+\u2009\"r\",\u2009\"c\"\u2009\u2212\u2009\"r\"]. In particular, the metric and order topologies in the real line coincide, which is the standard topology of the real line.\nAny element\u00a0x of an interval\u00a0I defines a partition of\u00a0I into three disjoint intervals I1,\u2009I2,\u2009I3: respectively, the elements of\u00a0I that are less than\u00a0x, the singleton\u00a0formula_25 and the elements that are greater than\u00a0x. The parts I1 and I3 are both non-empty (and have non-empty interiors), if and only if x is in the interior of\u00a0I. This is an interval version of the trichotomy principle.\nDyadic intervals.\nA \"dyadic interval\" is a bounded real interval whose endpoints are formula_26 and formula_27 where formula_28 and formula_29 are integers. Depending on the context, either endpoint may or may not be included in the interval.\nDyadic intervals have the following properties:\nThe dyadic intervals consequently have a structure that reflects that of an infinite binary tree.\nDyadic intervals are relevant to several areas of numerical analysis, including adaptive mesh refinement, multigrid methods and wavelet analysis. Another way to represent such a structure is p-adic analysis (for \"p\" = 2).\nGeneralizations.\nBalls.\nAn open finite interval formula_30 is a 1-dimensional open ball with a center at formula_31 and a radius of formula_32 The closed finite interval formula_33 is the corresponding closed ball, and the interval's two endpoints formula_34 form a 0-dimensional sphere. Generalized to formula_29-dimensional Euclidean space, a ball is the set of points whose distance from the center is less than the radius. In the 2-dimensional case, a ball is called a disk.\nIf a half-space is taken as a kind of degenerate ball (without a well-defined center or radius), a half-space can be taken as analogous to a half-bounded interval, with its boundary plane as the (degenerate) sphere corresponding to the finite endpoint.\nMulti-dimensional intervals.\nA finite interval is (the interior of) a 1-dimensional hyperrectangle. Generalized to real coordinate space formula_36 an axis-aligned hyperrectangle (or box) is the Cartesian product of formula_29 finite intervals. For formula_38 this is a rectangle; for formula_39 this is a rectangular cuboid (also called a \"box\").\nAllowing for a mix of open, closed, and infinite endpoints, the Cartesian product of any formula_29 intervals, formula_41 is sometimes called an formula_29-dimensional interval.\nA facet of such an interval formula_43 is the result of replacing any non-degenerate interval factor formula_44 by a degenerate interval consisting of a finite endpoint of formula_45 The faces of formula_43 comprise formula_43 itself and all faces of its facets. The corners of formula_43 are the faces that consist of a single point of formula_49\nConvex polytopes.\nAny finite interval can be constructed as the intersection of half-bounded intervals (with an empty intersection taken to mean the whole real line), and the intersection of any number of half-bounded intervals is a (possibly empty) interval. Generalized to formula_29-dimensional affine space, an intersection of half-spaces (of arbitrary orientation) is (the interior of) a convex polytope, or in the 2-dimensional case a convex polygon.\nDomains.\nAn open interval is a connected open set of real numbers. Generalized to topological spaces in general, a non-empty connected open set is called a domain.\nComplex intervals.\nIntervals of complex numbers can be defined as regions of the complex plane, either rectangular or circular.\nIntervals in posets and preordered sets.\nDefinitions.\nThe concept of intervals can be defined in arbitrary partially ordered sets or more generally, in arbitrary preordered sets. For a preordered set formula_51 and two elements formula_52 one similarly defines the intervals\nformula_53\nformula_54\nformula_55\nformula_56\nformula_57\nformula_58\nwhere formula_59 means formula_60 Actually, the intervals with single or no endpoints are the same as the intervals with two endpoints in the larger preordered set\nformula_61\nformula_62\ndefined by adding new smallest and greatest elements (even if there were ones), which are subsets of formula_18 In the case of formula_64 one may take formula_65 to be the extended real line.\nConvex sets and convex components in order theory.\nA subset formula_66 of the preordered set formula_51 is (order-)convex if for every formula_68 and every formula_69 we have formula_70 Unlike in the case of the real line, a convex set of a preordered set need not be an interval. For example, in the totally ordered set formula_71 of rational numbers, the set\nformula_72\nis convex, but not an interval of formula_73 since there is no square root of two in formula_74\nLet formula_51 be a preordered set and let formula_76 The convex sets of formula_77 contained in formula_78 form a poset under inclusion. A maximal element of this poset is called a convex component of formula_79 By the Zorn lemma, any convex set of formula_77 contained in formula_78 is contained in some convex component of formula_82 but such components need not be unique. In a totally ordered set, such a component is always unique. That is, the convex components of a subset of a totally ordered set form a partition.\nProperties.\nA generalization of the characterizations of the real intervals follows. For a non-empty subset formula_43 of a linear continuum formula_84 the following conditions are equivalent.\nFor a subset formula_89 of a lattice formula_90 the following conditions are equivalent.\nApplications.\nIn general topology.\nEvery Tychonoff space is embeddable into a product space of the closed unit intervals formula_95 Actually, every Tychonoff space that has a base of cardinality formula_96 is embeddable into the product formula_97 of formula_96 copies of the intervals.\nThe concepts of convex sets and convex components are used in a proof that every totally ordered set endowed with the order topology is completely normal or moreover, monotonically normal.\nTopological algebra.\nIntervals can be associated with points of the plane, and hence regions of intervals can be associated with regions of the plane. Generally, an interval in mathematics corresponds to an ordered pair (\"x\", \"y\") taken from the direct product formula_99 of real numbers with itself, where it is often assumed that \"y\" &gt; \"x\". For purposes of mathematical structure, this restriction is discarded, and \"reversed intervals\" where \"y\" \u2212 \"x\" &lt; 0 are allowed. Then, the collection of all intervals [\"x\", \"y\"] can be identified with the topological ring formed by the direct sum of formula_2 with itself, where addition and multiplication are defined component-wise.\nThe direct sum algebra formula_101 has two ideals, { [\"x\",0] : \"x\" \u2208 R } and { [0,\"y\"] : \"y\" \u2208 R }. The identity element of this algebra is the condensed interval [1, 1]. If interval [\"x\", \"y\"] is not in one of the ideals, then it has multiplicative inverse [1/\"x\", 1/\"y\"]. Endowed with the usual topology, the algebra of intervals forms a topological ring. The group of units of this ring consists of four quadrants determined by the axes, or ideals in this case. The identity component of this group is quadrant I.\nEvery interval can be considered a symmetric interval around its midpoint. In a reconfiguration published in 1956 by M Warmus, the axis of \"balanced intervals\" [\"x\", \u2212\"x\"] is used along with the axis of intervals [\"x\", \"x\"] that reduce to a point. Instead of the direct sum formula_102 the ring of intervals has been identified with the hyperbolic numbers by M. Warmus and D. H. Lehmer through the identification\nformula_103\nwhere formula_104\nThis linear mapping of the plane, which amounts of a ring isomorphism, provides the plane with a multiplicative structure having some analogies to ordinary complex arithmetic, such as polar decomposition.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49176", "revid": "45202605", "url": "https://en.wikipedia.org/wiki?curid=49176", "title": "Conjugacy class", "text": "In group theory, equivalence class under the relation of conjugation\nIn mathematics, especially group theory, two elements formula_1 and formula_2 of a group are conjugate if there is an element formula_3 in the group such that formula_4 This is an equivalence relation whose equivalence classes are called conjugacy classes. In other words, each conjugacy class is closed under formula_5 for all elements formula_3 in the group.\nMembers of the same conjugacy class cannot be distinguished by using only the group structure, and therefore share many properties. The study of conjugacy classes of non-abelian groups is fundamental for the study of their structure. For an abelian group, each conjugacy class is a set containing one element (singleton set).\nFunctions that are constant for members of the same conjugacy class are called class functions.\nMotivation.\nThe concept of conjugacy classes may come from trying to formalize the idea that two group elements are considered the \"same\" after a relabeling of elements.\nFor example, consider the symmetric group formula_7 of order 5, and elements formula_8 and formula_9 that are conjugate. An element formula_9 can be viewed as simply \"renaming\" the elements formula_11 to formula_12 then applying the permutation formula_8 on this new labeling.\nformula_14\nThe conjugacy action by formula_15 does not change the underlying structure of formula_8. In a way, permutations formula_8 and formula_9 have the same \"shape\".\nAnother way to view the conjugacy action is by considering the general linear group formula_19 of invertible matrices. Two matrices formula_20 and formula_21 conjugate if there exist a matrix formula_22 such that formula_23, which is the same condition as matrix similarity. The two matrices are conjugates if they are the \"same\" under two possibly different bases, with formula_22 being the change-of-basis matrix.\nConjugates also come up in some important theorems of group theory. One example is the Sylow theorems, which state that every Sylow formula_25-subgroup of a finite group formula_26 are conjugates to each other. It also appears in the proof of Cauchy's theorem, which makes use of conjugacy classes.\nDefinition.\nLet formula_26 be a group. Two elements formula_28 are conjugate if there exists an element formula_29 such that formula_30 in which case formula_2 is called a conjugate of formula_1 and formula_1 is called a conjugate of formula_34\nIn the case of the general linear group formula_19 of invertible matrices, the conjugacy relation is called matrix similarity.\nIt can be easily shown that conjugacy is an equivalence relation and therefore partitions formula_26 into equivalence classes. (This means that every element of the group belongs to precisely one conjugacy class, and the classes formula_37 and formula_38 are equal if and only if formula_1 and formula_2 are conjugate, and disjoint otherwise.) The equivalence class that contains the element formula_41 is\nformula_42\nand is called the conjugacy class of formula_43 The &lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;class number of formula_26 is the number of distinct (nonequivalent) conjugacy classes. All elements belonging to the same conjugacy class have the same order.\nConjugacy classes may be referred to by describing them, or more briefly by abbreviations such as \"6A\", meaning \"a certain conjugacy class with elements of order 6\", and \"6B\" would be a different conjugacy class with elements of order 6; the conjugacy class 1A is the conjugacy class of the identity which has order 1. In some cases, conjugacy classes can be described in a uniform way; for example, in the symmetric group they can be described by cycle type.\nExamples.\nThe symmetric group formula_45 consisting of the 6 permutations of three elements, has three conjugacy classes:\nThese three classes also correspond to the classification of the isometries of an equilateral triangle.\nThe symmetric group consisting of the 24 permutations of four elements, has five conjugacy classes, listed with their members using cycle notation:\nIn general, the number of conjugacy classes in the symmetric group formula_54 is equal to the number of integer partitions of formula_55 This is because each conjugacy class corresponds to exactly one partition of formula_56 into cycles, up to permutation of the elements of formula_57\nThe dihedral group formula_58 consisting of symmetries of a pentagon, has four conjugacy classes:\nFor an abelian group, each conjugacy class is a set containing one element (singleton set).\nConjugacy as group action.\nFor any two elements formula_102 let\nformula_103\nThis defines a group action of formula_26 on formula_105 The orbits of this action are the conjugacy classes, and the stabilizer of a given element is the element's centralizer.\nSimilarly, we can define a group action of formula_26 on the set of all subsets of formula_107 by writing\nformula_108\nor on the set of the subgroups of formula_105\nConjugacy class equation.\nIf formula_26 is a finite group, then for any group element formula_111 the elements in the conjugacy class of formula_1 are in one-to-one correspondence with cosets of the centralizer formula_113 This can be seen by observing that any two elements formula_2 and formula_115 belonging to the same coset (and hence, formula_116 for some formula_117 in the centralizer formula_86) give rise to the same element when conjugating formula_1: \nformula_120\nThat can also be seen from the orbit-stabilizer theorem, when considering the group as acting on itself through conjugation, so that orbits are conjugacy classes and stabilizer subgroups are centralizers. The converse holds as well.\nThus the number of elements in the conjugacy class of formula_1 is the index formula_122 of the centralizer formula_86 in formula_26; hence the size of each conjugacy class divides the order of the group.\nFurthermore, if we choose a single representative element formula_125 from every conjugacy class, we infer from the disjointness of the conjugacy classes that \nformula_126 \nwhere formula_127 is the centralizer of the element formula_128 Observing that each element of the center formula_83 forms a conjugacy class containing just itself gives rise to the class equation:\nformula_130\nwhere the sum is over a representative element from each conjugacy class that is not in the center.\nKnowledge of the divisors of the group order formula_131 can often be used to gain information about the order of the center or of the conjugacy classes.\nExample.\nConsider a finite formula_25-group formula_26 (that is, a group with order formula_134 where formula_25 is a prime number and formula_136). We are going to prove that every finite formula_25-group has a non-trivial center.\nSince the order of any conjugacy class of formula_26 must divide the order of formula_107 it follows that each conjugacy class formula_140 that is not in the center also has order some power of formula_141 where formula_142 But then the class equation requires that formula_143 From this we see that formula_25 must divide formula_145 so formula_146\nIn particular, when formula_147 then formula_26 is an abelian group since any non-trivial group element is of order formula_25 or formula_150 If some element formula_1 of formula_26 is of order formula_153 then formula_26 is isomorphic to the cyclic group of order formula_153 hence abelian. On the other hand, if every non-trivial element in formula_26 is of order formula_157 hence by the conclusion above formula_158 then formula_159 or formula_150 We only need to consider the case when formula_161 then there is an element formula_2 of formula_26 which is not in the center of formula_105 Note that formula_165 includes formula_2 and the center which does not contain formula_2 but at least formula_25 elements. Hence the order of formula_165 is strictly larger than formula_157 therefore formula_171 therefore formula_2 is an element of the center of formula_107 a contradiction. Hence formula_26 is abelian and in fact isomorphic to the direct product of two cyclic groups each of order formula_175\nAverage Centralizer.\nLet formula_176 be a finite group. Consider the group action of formula_176 on itself given by conjugation. The orbits are the conjugacy classes of formula_176 and the set of fixed points of an element formula_179 is the centralizer formula_180. \nThus by Burnside's lemma, the number of conjugacy classes is equal to formula_181, that is, the average size of the centralizer.\nConjugacy of subgroups and general subsets.\nMore generally, given any subset formula_182 (formula_183 not necessarily a subgroup), define a subset formula_184 to be conjugate to formula_183 if there exists some formula_29 such that formula_187 Let formula_188 be the set of all subsets formula_184 such that formula_190 is conjugate to formula_191\nA frequently used theorem is that, given any subset formula_192 the index of formula_193 (the normalizer of formula_183) in formula_26 equals the cardinality of formula_188:\nformula_197\nThis follows since, if formula_198 then formula_199 if and only if formula_200 in other words, if and only if formula_201 are in the same coset of formula_202\nBy using formula_203 this formula generalizes the one given earlier for the number of elements in a conjugacy class.\nThe above is particularly useful when talking about subgroups of formula_105 The subgroups can thus be divided into conjugacy classes, with two subgroups belonging to the same class if and only if they are conjugate.\nConjugate subgroups are isomorphic, but isomorphic subgroups need not be conjugate. For example, an abelian group may have two different subgroups which are isomorphic, but they are never conjugate.\nGeometric interpretation.\nConjugacy classes in the fundamental group of a path-connected topological space can be thought of as equivalence classes of free loops under free homotopy.\nConjugacy class and irreducible representations in finite group.\nIn any finite group, the number of nonisomorphic irreducible representations over the complex numbers is precisely the number of conjugacy classes.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49177", "revid": "1754504", "url": "https://en.wikipedia.org/wiki?curid=49177", "title": "Class equation", "text": ""}
{"id": "49178", "revid": "8367108", "url": "https://en.wikipedia.org/wiki?curid=49178", "title": "Conjugate elements", "text": ""}
{"id": "49180", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=49180", "title": "Fuzzy logic", "text": "System for reasoning about vagueness\nFuzzy logic is a form of many-valued logic in which the truth value of variables may be any real number between 0 and 1. It is employed to handle the concept of partial truth, where the truth value may range between completely true and completely false. By contrast, in Boolean logic, the truth values of variables may only be the integer values 0 or 1.\nThe term \"fuzzy logic\" was introduced with the 1965 proposal of fuzzy set theory by mathematician Lotfi Zadeh. Basic fuzzy logic had, however, been studied since the 1920s, as infinite-valued logic\u2014notably by \u0141ukasiewicz and Tarski. The works of Zadeh and Joseph Goguen in the 1960's and 1970's went further by considering issues such as linguistic variables and lattices.\nFuzzy logic is based on the observation that people make decisions based on imprecise and non-numerical information. Fuzzy models or fuzzy sets are mathematical means of representing vagueness and imprecise information (hence the term fuzzy). These models have the capability of recognising, representing, manipulating, interpreting, and using data and information that are vague and lack certainty.\nFuzzy logic has been applied to many fields, from control theory to artificial intelligence.\nOverview.\nClassical logic only permits conclusions that are either true or false. However, there are also propositions with variable answers, which one might find when asking a group of people to identify a color. In such instances, the truth appears as the result of reasoning from inexact or partial knowledge in which the sampled answers are mapped on a spectrum.\nBoth degrees of truth and probabilities range between 0 and 1 and hence may seem identical at first, but fuzzy logic uses degrees of truth as a mathematical model of \"vagueness\", while probability is a mathematical model of \"ignorance\".\nApplying truth values.\nA basic application might characterize various sub-ranges of a continuous variable. For instance, a temperature measurement for anti-lock brakes might have several separate membership functions defining particular temperature ranges needed to control the brakes properly. Each function maps the same temperature value to a truth value in the 0 to 1 range. These truth values can then be used to determine how the brakes should be controlled. Fuzzy set theory provides a means for representing uncertainty.\nLinguistic variables.\nIn fuzzy logic applications, non-numeric values are often used to facilitate the expression of rules and facts.\nA linguistic variable such as \"age\" may accept values such as \"young\" and its antonym \"old\". Because natural languages do not always contain enough value terms to express a fuzzy value scale, it is common practice to modify linguistic values with adjectives or adverbs. For example, we can use the hedges \"rather\" and \"somewhat\" to construct the additional values \"rather old\" or \"somewhat young\".\nFuzzy systems.\nMamdani.\nThe most well-known system is the Mamdani rule-based one. It uses the following rules:\nFuzzification.\nFuzzification is the process of assigning the numerical input of a system to fuzzy sets with some degree of membership. This degree of membership may be anywhere within the interval [0,1]. If it is 0 then the value does not belong to the given fuzzy set, and if it is 1 then the value completely belongs within the fuzzy set. Any value between 0 and 1 represents the degree of uncertainty that the value belongs in the set. These fuzzy sets are typically described by words, and so by assigning the system input to fuzzy sets, we can reason with it in a linguistically natural manner.\nFor example, in the image below, the meanings of the expressions \"cold\", \"warm\", and \"hot\" are represented by functions mapping a temperature scale. A point on that scale has three \"truth values\"\u2014one for each of the three functions. The vertical line in the image represents a particular temperature that the three arrows (truth values) gauge. Since the red arrow points to zero, this temperature may be interpreted as \"not hot\"; i.e. this temperature has zero membership in the fuzzy set \"hot\". The orange arrow (pointing at 0.2) may describe it as \"slightly warm\" and the blue arrow (pointing at 0.8) \"fairly cold\". Therefore, this temperature has 0.2 membership in the fuzzy set \"warm\" and 0.8 membership in the fuzzy set \"cold\". The degree of membership assigned for each fuzzy set is the result of fuzzification.\nFuzzy sets are often defined as triangle or trapezoid-shaped curves, as each value will have a slope where the value is increasing, a peak where the value is equal to 1 (which can have a length of 0 or greater) and a slope where the value is decreasing. They can also be defined using a sigmoid function. One common case is the standard logistic function defined as\n formula_1\nwhich has the following symmetry property\n formula_2\nFrom this it follows that\nformula_3\nFuzzy logic operators.\nFuzzy logic works with membership values in a way that mimics Boolean logic. To this end, replacements for basic operators (\"gates\") AND, OR, NOT must be available. There are several ways to accomplish this. A common replacement is called the \"&lt;templatestyles src=\"Template:Visible anchor/styles.css\" /&gt;Zadeh operators\":\nFor TRUE/1 and FALSE/0, the fuzzy expressions produce the same result as the Boolean expressions.\nThere are also other operators, more linguistic in nature, called \"hedges\" that can be applied. These are generally adverbs such as \"very\", or \"somewhat\", which modify the meaning of a set using a mathematical formula.\nHowever, an arbitrary choice table does not always define a fuzzy logic function. In the paper (Zaitsev, et al), a criterion has been formulated to recognize whether a given choice table defines a fuzzy logic function and a simple algorithm of fuzzy logic function synthesis has been proposed based on introduced concepts of constituents of minimum and maximum. A fuzzy logic function represents a disjunction of constituents of minimum, where a constituent of minimum is a conjunction of variables of the current area greater than or equal to the function value in this area (to the right of the function value in the inequality, including the function value).\nAnother set of AND/OR operators is based on multiplication, where\nx AND y = x * y\nNOT x = 1 - x\nHence, \nx OR y = NOT( AND( NOT(x), NOT(y) ) )\nx OR y = NOT( AND( 1 - x, 1 - y) )\nx OR y = NOT( (1 - x) * (1 - y) )\nx OR y = 1 - (1 - x) * (1-y)\nx OR y = x + y - xy\nGiven any two of AND/OR/NOT, it is possible to derive the third. The generalization of AND is an instance of a t-norm.\nIF-THEN rules.\nIF-THEN rules map input or computed truth values to desired output truth values. Example:\nIF temperature IS very cold THEN fan_speed is stopped\nIF temperature IS cold THEN fan_speed is slow\nIF temperature IS warm THEN fan_speed is moderate\nIF temperature IS hot THEN fan_speed is high\nGiven a certain temperature, the fuzzy variable \"hot\" has a certain truth value, which is copied to the \"high\" variable.\nShould an output variable occur in several THEN parts, then the values from the respective IF parts are combined using the OR operator.\nDefuzzification.\nThe goal is to get a continuous variable from fuzzy truth values.\nThis would be easy if the output truth values were exactly those obtained from fuzzification of a given number.\nSince, however, all output truth values are computed independently, in most cases they do not represent such a set of numbers.\nOne has then to decide for a number that matches best the \"intention\" encoded in the truth value.\nFor example, for several truth values of fan_speed, an actual speed must be found that best fits the computed truth values of the variables 'slow', 'moderate' and so on.\nThere is no single algorithm for this purpose.\nA common algorithm is\nTakagi\u2013Sugeno\u2013Kang (TSK).\nThe TSK system is similar to Mamdani, but the defuzzification process is included in the execution of the fuzzy rules. These are also adapted, so that instead the consequent of the rule is represented through a polynomial function (usually constant or linear). An example of a rule with a constant output would be:\nIF temperature IS very cold = 2\nIn this case, the output will be equal to the constant of the consequent (e.g. 2). In most scenarios we would have an entire rule base, with 2 or more rules. If this is the case, the output of the entire rule base will be the average of the consequent of each rule i (Yi), weighted according to the membership value of its antecedent (hi):\nformula_4\nAn example of a rule with a linear output would be instead:\nIF temperature IS very cold AND humidity IS high = 2 * temperature + 1 * humidity\nIn this case, the output of the rule will be the result of function in the consequent. The variables within the function represent the membership values after fuzzification, not the crisp values. Same as before, in case we have an entire rule base with 2 or more rules, the total output will be the weighted average between the output of each rule.\nThe main advantage of using TSK over Mamdani is that it is computationally efficient and works well within other algorithms, such as PID control and with optimization algorithms. It can also guarantee the continuity of the output surface. However, Mamdani is more intuitive and easier to work with by people. Hence, TSK is usually used within other complex methods, such as in adaptive neuro fuzzy inference systems.\nForming a consensus of inputs and fuzzy rules.\nSince the fuzzy system output is a consensus of all of the inputs and all of the rules, fuzzy logic systems can be well behaved when input values are not available or are not trustworthy. Weightings can be optionally added to each rule in the rulebase and weightings can be used to regulate the degree to which a rule affects the output values. These rule weightings can be based upon the priority, reliability or consistency of each rule. These rule weightings may be static or can be changed dynamically, even based upon the output from other rules.\nApplications.\nFuzzy logic is used in control systems to allow experts to contribute vague rules such as \"if you are close to the destination station and moving fast, increase the train's brake pressure\"; these vague rules can then be numerically refined within the system.\nMany of the early successful applications of fuzzy logic were implemented in Japan. A first notable application was on the Sendai Subway 1000 series, in which fuzzy logic was able to improve the economy, comfort, and precision of the ride. It has also been used for handwriting recognition in Sony pocket computers, helicopter flight aids, subway system controls, improving automobile fuel efficiency, single-button washing machine controls, automatic power controls in vacuum cleaners, and early recognition of earthquakes through the Institute of Seismology Bureau of Meteorology, Japan.\nArtificial intelligence.\nNeural networks based artificial intelligence and fuzzy logic are, when analyzed, the same thing\u2014the underlying logic of neural networks is fuzzy. A neural network will take a variety of valued inputs, give them different weights in relation to each other, combine intermediate values a certain number of times, and arrive at a decision with a certain value. Nowhere in that process is there anything like the sequences of either-or decisions which characterize non-fuzzy mathematics, computer programming, and digital electronics. In the 1980s, researchers were divided about the most effective approach to machine learning: decision tree learning or neural networks. The former approach uses binary logic, matching the hardware on which it runs, but despite great efforts it did not result in intelligent systems. Neural networks, by contrast, did result in accurate models of complex situations and soon found their way onto a multitude of electronic devices. They can also now be implemented directly on analog microchips, as opposed to the previous pseudo-analog implementations on digital chips. The greater efficiency of these compensates for the intrinsic lesser accuracy of analog in various use cases.\nMedical decision making.\nFuzzy logic is an important concept in medical decision making. Since medical and healthcare data can be subjective or fuzzy, applications in this domain have a great potential to benefit a lot by using fuzzy-logic-based approaches.\nFuzzy logic can be used in many different aspects within the medical decision making framework. Such aspects include in medical image analysis, biomedical signal analysis, segmentation of images or signals, and feature extraction / selection of images or signals.\nThe biggest question in this application area is how much useful information can be derived when using fuzzy logic. A major challenge is how to derive the required fuzzy data. This is even more challenging when one has to elicit such data from humans (usually, patients). As has been said &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\"The envelope of what can be achieved and what cannot be achieved in medical diagnosis, ironically, is itself a fuzzy one\"\u2014\u200a How to elicit fuzzy data, and how to validate the accuracy of the data is still an ongoing effort, strongly related to the application of fuzzy logic. The problem of assessing the quality of fuzzy data is a difficult one. This is why fuzzy logic is a highly promising possibility within the medical decision making application area but still requires more research to achieve its full potential. \nImage-based computer-aided diagnosis.\nOne of the common application areas of fuzzy logic is image-based computer-aided diagnosis in medicine. Computer-aided diagnosis is a computerized set of inter-related tools that can be used to aid physicians in their diagnostic decision-making.\nFuzzy databases.\nOnce fuzzy relations are defined, it is possible to develop fuzzy relational databases. The first fuzzy relational database, FRDB, appeared in Maria Zemankova's dissertation (1983). Later, some other models arose like the Buckles-Petry model, the Prade-Testemale Model, the Umano-Fukami model or the GEFRED model by J. M. Medina, M. A. Vila et al.\nFuzzy querying languages have been defined, such as the SQLf by P. Bosc et al. and the FSQL by J. Galindo et al. These languages define some structures in order to include fuzzy aspects in the SQL statements, like fuzzy conditions, fuzzy comparators, fuzzy constants, fuzzy constraints, fuzzy thresholds, linguistic labels etc.\nLogical analysis.\nIn mathematical logic, there are several formal systems of \"fuzzy logic\", most of which are in the family of t-norm fuzzy logics.\nPropositional fuzzy logics.\nThe most important propositional fuzzy logics are:\nPredicate fuzzy logics.\nSimilar to the way predicate logic is created from propositional logic, predicate fuzzy logics extend fuzzy systems by universal and existential quantifiers. The semantics of the universal quantifier in t-norm fuzzy logics is the infimum of the truth degrees of the instances of the quantified subformula, while the semantics of the existential quantifier is the supremum of the same.\nDecidability Issues.\nThe notions of a \"decidable subset\" and \"recursively enumerable subset\" are basic ones for classical mathematics and classical logic. Thus the question of a suitable extension of them to fuzzy set theory is a crucial one. The first proposal in such a direction was made by E. S. Santos by the notions of \"fuzzy Turing machine\", \"Markov normal fuzzy algorithm\" and \"fuzzy program\" (see Santos 1970). Successively, L. Biacino and G. Gerla argued that the proposed definitions are rather questionable. For example, in one shows that the fuzzy Turing machines are not adequate for fuzzy language theory since there are natural fuzzy languages intuitively computable that cannot be recognized by a fuzzy Turing Machine. Then they proposed the following definitions. Denote by \"\u00dc\" the set of rational numbers in [0,1]. Then a fuzzy subset \"s\" : \"S\" formula_5\u00a0[0,1] of a set \"S\" is recursively enumerable if a recursive map \"h\" : \"S\"\u00d7N formula_5\"\u00dc\" exists such that, for every \"x\" in \"S\", the function \"h\"(\"x\",\"n\") is increasing with respect to \"n\" and \"s\"(\"x\") = lim \"h\"(\"x\",\"n\").\nWe say that \"s\" is \"decidable\" if both \"s\" and its complement \u2013\"s\" are recursively enumerable. An extension of such a theory to the general case of the L-subsets is possible (see Gerla 2006).\nThe proposed definitions are well related to fuzzy logic. Indeed, the following theorem holds true (provided that the deduction apparatus of the considered fuzzy logic satisfies some obvious effectiveness property).\nAny \"axiomatizable\" fuzzy theory is recursively enumerable. In particular, the fuzzy set of logically true formulas is recursively enumerable in spite of the fact that the crisp set of valid formulas is not recursively enumerable, in general. Moreover, any axiomatizable and complete theory is decidable.\nIt is an open question to give support for a \"Church thesis\" for fuzzy mathematics, the proposed notion of recursive enumerability for fuzzy subsets is the adequate one. In order to solve this, an extension of the notions of fuzzy grammar and fuzzy Turing machine are necessary. Another open question is to start from this notion to find an extension of G\u00f6del's theorems to fuzzy logic.\nCompared to other logics.\nProbability.\nFuzzy logic and probability address different forms of uncertainty. While both fuzzy logic and probability theory can represent degrees of certain kinds of subjective belief, fuzzy set theory uses the concept of fuzzy set membership, i.e., how much an observation is within a vaguely defined set, and probability theory uses the concept of subjective probability, i.e., frequency of occurrence or likelihood of some event or condition . The concept of fuzzy sets was developed in the mid-twentieth century at Berkeley as a response to the lack of a probability theory for jointly modelling uncertainty and vagueness.\nBart Kosko claims in Fuzziness vs. Probability that probability theory is a subtheory of fuzzy logic, as questions of degrees of belief in mutually-exclusive set membership in probability theory can be represented as certain cases of non-mutually-exclusive graded membership in fuzzy theory. In that context, he also derives Bayes' theorem from the concept of fuzzy subsethood. Lotfi A. Zadeh argues that fuzzy logic is different in character from probability, and is not a replacement for it. He fuzzified probability to fuzzy probability and also generalized it to possibility theory.\nMore generally, fuzzy logic is one of many different extensions to classical logic intended to deal with issues of uncertainty outside of the scope of classical logic, the inapplicability of probability theory in many domains, and the paradoxes of Dempster\u2013Shafer theory.\nEcorithms.\nComputational theorist Leslie Valiant uses the term \"ecorithms\" to describe how many less exact systems and techniques like fuzzy logic (and \"less robust\" logic) can be applied to learning algorithms. Valiant essentially redefines machine learning as evolutionary. In general use, ecorithms are algorithms that learn from their more complex environments (hence \"eco-\") to generalize, approximate and simplify solution logic. Like fuzzy logic, they are methods used to overcome continuous variables or systems too complex to completely enumerate or understand discretely or exactly. Ecorithms and fuzzy logic also have the common property of dealing with possibilities more than probabilities, although feedback and feed forward, basically stochastic weights, are a feature of both when dealing with, for example, dynamical systems.\nG\u00f6del G\u221e logic.\nAnother logical system where truth values are real numbers between 0 and 1 and where AND &amp; OR operators are replaced with MIN and MAX is G\u00f6del's G\u221e logic. This logic has many similarities with fuzzy logic but defines negation differently and has an internal implication. Negation formula_7 and implication formula_8 are defined as follows:\n formula_9\nwhich turns the resulting logical system into a model for intuitionistic logic, making it particularly well-behaved among all possible choices of logical systems with real numbers between 0 and 1 as truth values. In this case, implication may be interpreted as \"x is less true than y\" and negation as \"x is less true than 0\" or \"x is strictly false\", and for any formula_10 and formula_11, we have that formula_12. In particular, in G\u00f6del logic negation is no longer an involution and double negation maps any nonzero value to 1.\nCompensatory fuzzy logic.\nCompensatory fuzzy logic (CFL) is a branch of fuzzy logic with modified rules for conjunction and disjunction. When the truth value of one component of a conjunction or disjunction is increased or decreased, the other component is decreased or increased to compensate. This increase or decrease in truth value may be offset by the increase or decrease in another component. An offset may be blocked when certain thresholds are met. Proponents claim that CFL allows for better computational semantic behaviors and mimic natural language.\nAccording to Jes\u00fas Cejas Montero (2011) The Compensatory fuzzy logic consists of four continuous operators: conjunction (c); disjunction (d); fuzzy strict order (or); and negation (n). The conjunction is the geometric mean and its dual as conjunctive and disjunctive operators.\nMarkup language standardization.\nThe IEEE 1855, the IEEE STANDARD 1855\u20132016, is about a specification language named Fuzzy Markup Language (FML) developed by the IEEE Standards Association. FML allows modelling a fuzzy logic system in a human-readable and hardware independent way. FML is based on eXtensible Markup Language (XML). The designers of fuzzy systems with FML have a unified and high-level methodology for describing interoperable fuzzy systems. IEEE STANDARD 1855\u20132016 uses the W3C XML Schema definition language to define the syntax and semantics of the FML programs.\nPrior to the introduction of FML, fuzzy logic practitioners could exchange information about their fuzzy algorithms by adding to their software functions the ability to read, correctly parse, and store the result of their work in a form compatible with the Fuzzy Control Language (FCL) described and specified by Part 7 of IEC 61131.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "49181", "revid": "57939", "url": "https://en.wikipedia.org/wiki?curid=49181", "title": "588 Achilles", "text": "Jupiter trojan\n588 Achilles is a large Jupiter trojan asteroid of the Greek camp. Achilles was the first Jupiter trojan to be discovered, and was discovered by Max Wolf at the Heidelberg Observatory in 1906. Wolf named the minor planet after the legendary hero Achilles from Greek mythology. The dark D-type asteroid measures approximately in diameter which makes it one of the 10 largest Jupiter trojans. It has a rotation period of 7.3 hours and possibly a spherical shape.\nDiscovery.\nAchilles was discovered on 22 February 1906, by the German astronomer Max Wolf at the Heidelberg-K\u00f6nigstuhl State Observatory in southern Germany. It was the first discovery of a Jupiter trojan, although had been observed as A904 RD two years previously. This body, however, remained unconfirmed as the observation period was not long enough to calculate an orbit. August Kopff, a colleague of Wolf at Heidelberg, then discovered 617 Patroclus eight months after Achilles, and, in early 1907, he discovered the largest of all Jupiter trojans, 624\u00a0Hektor.\nOrbit and classification.\nAchilles orbits the Sun at a distance of 4.4\u20136.0\u00a0AU in the L4 Lagrangian point of the Sun\u2013Jupiter System once every 11 years and 11 months (4,343 days; semi-major axis of 5.21\u00a0AU). Its orbit shows an eccentricity of 0.15 and an inclination of 10 degrees from the plane of the ecliptic.\nAchilles is the first known example of the stable solution of the three-body problem worked out by French mathematician Joseph Lagrange in 1772, after whom the minor planet 1006\u00a0Lagrangea is named. After the discovery of other asteroids with similar orbital characteristics, which were also named after heroes from the Trojan War \"(see below)\", the term \"Trojan asteroids\" or \"Jupiter trojans\" became commonly used. In addition, a rule was established that the L4 point was the \"Greek camp\", whereas the L5 point was the \"Trojan camp\", though not before each camp had acquired a \"spy\" (Hektor in the Greek camp and Patroclus in the Trojan camp).\nPhysical characteristics.\nSpectral type.\nIn the Tholen taxonomic scheme, Achilles is classified as a D-type asteroid with an unusual spectrum (DU). Its V\u2013I color index of 0.94 is typical for most larger Jupiter trojans \"(see table below)\".\nPhotometry.\nAchilles's rotation period of 7.3 hours is somewhat shorter than that of most other large Jupiter trojans but close to that of 911\u00a0Agamemnon, 3451\u00a0Mentor and 3317\u00a0Paris, which are similar in size \"(see table below)\". Its low brightness amplitude is indicative of a rather spherical shape. From July 2007 until September 2008, coordinated photometric observations were carried out by astronomers at Simeiz (Crimea), Rozhen (Bulgaria), Maidanak (Uzbekistan) and Kharkiv (Ukraine) observatories. Analysis of the obtained lightcurves determined a period of hours with a brightness amplitude of 0.02\u20130.11 magnitude (). Alternative period determinations by Cl\u00e1udia Angeli (7.0\u00a0h), Robert Stephens (7.312\u00a0h), Stefano Mottola (7.32\u00a0h) and Vincenzo Zappal\u00e0 (12\u00a0h) are mostly in good agreement ().\nDiameter and albedo.\nAccording to the surveys carried out by the Infrared Astronomical Satellite, IRAS, the Japanese Akari satellite, and the NEOWISE mission of NASA's Wide-field Infrared Survey Explorer, the body's surface has a very low albedo in the range of 0.0328 to 0.043, making its absolute magnitude of approximately 8.57 correspond to a diameter of 130.1 to 135.5\u00a0kilometers.\nAchilles is the 6th largest Jupiter trojan according to IRAS and Akari, and the 4th largest based on NEOWISE data:\n&lt;templatestyles src=\"Template:Hidden begin/styles.css\"/&gt;100+ largest Jupiter trojans\n&lt;templatestyles src=\"Template:Table alignment/tables.css\" /&gt;\nNaming.\nThis minor planet's name was suggested by Austrian astronomer Johann Palisa. It was named after Achilles, the legendary hero from Greek mythology and central figure in Homer's \"Iliad\" which tells the accounts of the Trojan War \"(also see 5700\u00a0Homerus and 6604\u00a0Ilias)\". As an infant, Achilles was plunged in the River Styx by his mother Thetis \"(also see 17\u00a0Thetis)\", thus rendering his body invulnerable excepting the heel by which he was held. He slew Hector (\"see also 624\u00a0Hektor\"), the greatest Trojan warrior. He was eventually killed by an arrow in the heel by Paris (\"see 3317\u00a0Paris\").\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49182", "revid": "27", "url": "https://en.wikipedia.org/wiki?curid=49182", "title": "Roald Hoffman", "text": ""}
{"id": "49183", "revid": "668752", "url": "https://en.wikipedia.org/wiki?curid=49183", "title": "Scientific reductionism", "text": ""}
{"id": "49184", "revid": "18779361", "url": "https://en.wikipedia.org/wiki?curid=49184", "title": "How the Self Controls Its Brain", "text": "1994 book by John Carew Eccles\nHow the Self Controls Its Brain is a book by Sir John Eccles, proposing a theory of philosophical dualism, and offering a justification of how there can be mind-brain action without violating the principle of the conservation of energy. The model was developed jointly with the nuclear physicist Friedrich Beck in the period 1991\u20131992.\nEccles called the fundamental neural units of the cerebral cortex \"dendrons\", which are cylindrical bundles of neurons arranged vertically in the six outer layers or laminae of the cortex, each cylinder being about 60 micrometres in diameter. Eccles proposed that each of the 40 million dendrons is linked with a mental unit, or \"psychon\", representing a unitary conscious experience. In willed actions and thought, psychons act on dendrons and, for a moment, increase the probability of the firing of selected neurons through quantum tunneling effect in synaptic exocytosis, while in perception the reverse process takes place.\nThe earliest prior use of the word \"psychon\" with a similar meaning of an \"element of consciousness\" is in the book \"Concerning Fluctuating and Inaudible Sounds\" by K. Dunlap in 1908.\nThe most popular prior use is in Robert Heinlein's short story Gulf, wherein a character refers to the fastest speed of thought possible as \"one psychon per chronon\"."}
{"id": "49185", "revid": "1398", "url": "https://en.wikipedia.org/wiki?curid=49185", "title": "Trofim Lysenko", "text": "Soviet agronomist and pseudoscientist (1898\u20131976)\nTrofim Denisovich Lysenko (; , ; 29 September\u00a0[O.S. 17 September]\u00a01898\u00a0\u2013 20 November 1976) was a Soviet agronomist and scientist. He was a proponent of Lamarckism, and rejected Mendelian genetics in favour of his own idiosyncratic, pseudoscientific ideas later termed Lysenkoism.\nIn 1940, Lysenko became director of the Institute of Genetics of the Soviet Academy of Sciences, and he used his political influence and power to suppress dissenting opinions and discredit, marginalize, and imprison his critics, elevating his anti-Mendelian theories to state-sanctioned doctrine.\nSoviet scientists who refused to renounce genetics were dismissed from their posts and left destitute. Several were imprisoned including the botanist Nikolai Vavilov. Lysenko's ideas and practices contributed to the famines that killed millions of Soviet people; the adoption of his methods from 1958 in the People's Republic of China had similarly calamitous results, contributing to the Great Chinese Famine of 1959 to 1961.\nEarly life and study.\nThe son of Denis Nikanorovich and Oksana Fominichna Lysenko, Trofim Lysenko was born into a peasant family of Ukrainian ethnicity in the village of Karlovka, Poltava Governorate (present-day Poltava Oblast, Ukraine) on 29 September 1898. The family later welcomed two sons and a daughter.\nLysenko learned to read and write only at the age of 13. In 1913, after graduating from a two-year rural school, he entered the lower school of horticulture in Poltava. In 1917, he entered and in 1921 he graduated from the secondary school of horticulture in Uman (now the Uman National University of Horticulture).\nLysenko's period of study in Uman coincided with the First World War and the Russian Civil War: the city was captured by Austro-Hungarian troops, then by the Central Ukrainian Rada. In February 1918, Soviet power was proclaimed in Uman, after which until 1920 the city periodically passed into the hands of the Red and White Armies.\nIn 1922, Lysenko entered the Kiev Agricultural Institute (now the National University of Life and Environmental Sciences of Ukraine). During his studies, he worked at the Belotserkovsk experimental station as a garden plant breeder. In 1923, he published his first scientific works: \"Techniques and methods of tomato selection at the Belotserkovskaya selection station\" and \"Grafting of sugar beets.\" Lysenko graduated from the institute with a degree in agronomy in 1925.\nAcademic career.\nWork in Azerbaijan.\nIn October 1925, Lysenko was sent to Azerbaijan, to a breeding station in the city of Ganja. The Ganja breeding station was part of the staff of the All-Union Institute of Applied Botany and New Crops (now the Institute of Plant Industry), created in 1925, which was headed by Nikolai Vavilov. The director of the station at that time was Nikolai Derevitsky, a specialist in mathematical statistics in agronomy. Derevitsky set Lysenko the task of introducing legume crops (lupine, clover, peavine, vetch) into Azerbaijan, which could solve the problem of starvation of livestock in early spring, as well as increasing soil fertility when plowing these crops in the spring. Vavilov had done experiments on converting winter wheat into spring wheat. It was Vavilov who initially supported Lysenko and encouraged him in his work. In an article, \"Pravda\" correspondent Vitaly Fedorovich described his first impression of the meeting with Lysenko:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;If you judge a person by first impression, then this Lysenko will leave you with a feeling of toothache - God bless him, he is a sad-looking person. And he is stingy with his words, and insignificant in face - all I remember is his gloomy eye, crawling along the ground with such an air as if, at least, he was going to kill someone.\nLysenko had a difficult time trying to grow various crops (such as peas and wheat) through the harsh winters. However, when he announced success, he was praised in the Soviet newspaper \"Pravda\" for his claims to have discovered a method to fertilize fields without using fertilizers or minerals, and to have shown that a winter crop of peas could be grown in Azerbaijan, \"turning the barren fields of the Transcaucasus green in winter, so that cattle will not perish from poor feeding, and the peasant Turk will live through the winter without trembling for tomorrow.\"\nSoon, Lysenko married one of the interns who trained under him, Alexandra Baskova. During the same period, breeder Donat Dolgushin, a future academic and supporter of Lysenko, began working with Lysenko.\nLysenko worked with different wheat crops to try to convert them to grow in different seasons. Another area Lysenko found himself interested in was the effect of heat on plant growth. He believed that every plant needed a determinate amount of heat throughout its lifetime. He attempted to correlate the time and the amount of heat required by a particular plant to go through various phases of development. To get his data he looked at the amount of growth, how many days went by, and the temperature on those days, instead of measuring any actual heat. In trying to determine the effects, he was making mistakes in statistical analysis of data. He was confronted by Nikolai Maximov, who was an expert on thermal plant development. Lysenko did not take well to this or any criticism. After this encounter, Lysenko boldly claimed that mathematics had no place in biology.\nHis experimental research in improved crop yields earned him the support of the Soviet leader Joseph Stalin, especially following the famine and loss of productivity resulting from crop failures and forced collectivization in several regions of the Soviet Union in the early 1930s.\nLysenko considered how he might use his work to convert winter wheat into spring wheat. In 1927, Lysenko embarked on the research that would lead to his 1928 paper on vernalization, which drew wide attention because of its potential practical implications for Soviet agriculture. Severe cold and lack of winter snow had destroyed many early winter-wheat seedlings. By treating wheat seeds with moisture as well as cold, Lysenko induced them to bear a crop when planted in spring. Lysenko coined the term \"Jarovization\" (\u044f\u0440\u043e\u0432\u0438\u0437\u0430\u0446\u0438\u044f) to describe this chilling process, which he used to make the seeds of winter cereals behave like spring cereals. (Because spring cereals are called \"Jarovoe\" in Russian \u2013 from \"jarov\u00f3j\", an archaic adjective meaning spring, especially in relation to crops). However, this method had already been known by farmers since the 1800s, and had been discussed in detail by Gustav Gassner in 1918. Lysenko himself translated Jarovization as \"vernalization\" (from the Latin \"vernum\" meaning Spring). Lysenko's claims for increased yields were based on plantings over a few hectares, and he believed that the vernalized transformation could be inherited, that the offspring of a vernalized plant would themselves possess the capabilities of the generation that preceded it\u00a0\u2013 that it too would be able to withstand harsh winters or imperfect weather conditions.\nWork in Odessa.\nIn October 1929, Lysenko was invited by the People's Commissariat of Ukraine to Odessa, to the newly formed Breeding and Genetics Institute (later the All-Union Breeding and Genetics Institute, or VSGI) where he headed the laboratory for vernalization of plants. People's Commissar of Agriculture of the Ukrainian SSR Alexander Schlichter reacted to Lysenko's ideas with enthusiasm and actively supported him. On 17 April 1936, he was appointed director of the VSGI.\nIn September 1931, the All-Ukrainian Breeding Conference adopted a resolution on a report by Lysenko, in which he noted the theoretical and practical significance of his work on vernalization. In October of the same year, a similar resolution was adopted by the All-Union Conference on Combating Drought. In 1933, he began experiments on summer planting potatoes in the south. In 1934, he was elected a full member of the Academy of Sciences of the Ukrainian SSR. In the same year, Ivan Michurin, speaking about the results of his scientific activities in his book \"Results of Sixty Years of Work\", mentioned Lysenko's activities in studying the photoperiodism of field cereals. On 30 December 1935, Lysenko was awarded the Order of Lenin and elected a full member of the Lenin All-Union Academy of Agricultural Sciences.\nAfter Odessa and first confrontation with geneticists.\nIn August 1936, at a visiting session of the grain section of the All-Union Academy of Agricultural Sciences in Omsk, Lysenko made a report \"On intravarietal crossing of self-pollinating plants,\" in which he entered into a discussion with Vavilov and other geneticists. In this discussion, Lysenko denied both the general theoretical views of his opponents and their practical implementation in breeding work. In particular, Lysenko denied the method of inbreeding field crops.\nThe discussion continued on 23 December 1936 at the 4th session of the All-Russian Academy of Agricultural Sciences, where Lysenko made a report \"On two directions in genetics\" (published in the collection \"Agrobiology\" by Lysenko). Lysenko, together with Isaak Prezent, referred to the opinion of Charles Darwin and Kliment Timiryazev on the issue of degeneration of self-pollinating plants and the usefulness of intra-varietal cross-pollination of plants.\nIn the spring of 1937, the journal \"Yarovizatsiya\", founded and edited by Lysenko, published a speech by the head of the agricultural department of the Central Committee of the All-Union Communist Party of Bolsheviks, Yakov Yakovlev (No. 2), where Vavilov's theory of homological series of plant variability and the chromosomal theory of heredity were sharply criticized. The scientific discussion on genetics in the Soviet Union was transformed into a political struggle against \"the enemies of the people.\" Issue 3 of \"Yarovizatsiya\" published an article by Prezent, in which he accused geneticists of the classical school of supporting the Trotskyist-Bukharinist opposition, and an article by Alexander Kohl that accused Vavilov of being a reactionary saboteur. The 7th International Genetic Congress in Moscow in 1937 was canceled and instead took place in 1939 in Edinburgh.\nOn 11 January 1938, the newspaper \"Sotszemledeliye\" published an article titled \"Improve the Academy of Agricultural Sciences: Ruthlessly uproot enemies and their rumps from scientific institutions,\" where Vavilov, Mikhail Zavadovsky, and Pyotr Konstantinov were indicated as accomplices of the enemies of the people.\nIn 1938, Lysenko became president of the All-Union Academy of Agricultural Sciences. At the beginning of 1939, \"Yarovizatsiya\" published an article by Prezent \"On pseudoscientific theories and genetics\", in which Prezent compared the works of Vavilov with those of the anti-Marxist philosopher Eugen D\u00fchring. In the same year, the journal \"Pod znamenem marksizma\" held a discussion on genetics. At the conclusion of this discussion, its organizer, philosopher Mark Mitin, sharply criticized the activities of Vavilov.\nIn 1939, According to official data, by changing the agricultural technology of millet, Lysenko increased the yield of millet from 2-3 to 15 centners per hectare. On 13 December 1942, at a session of the All-Union Academy of Agricultural Sciences, Lysenko argued that \"in 1940, millet on millions of hectares had already become the highest-yielding grain crop\" and called for \"a turn towards millet.\" Lysenko proposed a system of spring cultivation for grain, which made it possible to clear the soil of weeds before sowing, and then sow with vernalized seeds.\nIn mid-1940, by Lysenko's order, NKVD employee S. N. Shundenko was appointed deputy director of the All-Union Research Institute of Plant Industry, despite the categorical protest of Vavilov, who wrote denunciations of the institute's workers. In August 1940, Vavilov was arrested; following this, Vavilov's employees and friends, Georgii Karpechenko, Grigory Levitsky, Leonid Govorov, and Konstantin Flaksberger, were arrested and died in custody.\nTree planting.\nAs part of Stalin's Great Plan for the Transformation of Nature, Lysenko was involved in advising tree planting. He suggested that planting of trees need to be done in \"nests\". He claimed that when trees were planted at high densities their survival improved because they fought together against weeds and pooled their energy to benefit one shoot while sacrificing others in the nest. To encourage oak seedlings to fight collectively he had a central hole and found holes around them.\nWorld War II.\nDuring World War II, Lysenko, along with many biologists, was evacuated to Omsk, where he continued to work on agricultural technology for grain crops and potatoes. From 1942, Lysenko was a member of the Extraordinary State Commission for the Establishment and Investigation of the Atrocities of the German Fascist Invaders.\nOn 22 March 1943, Lysenko received the Stalin Prize of the first degree \"for the scientific development and introduction into agriculture of a method of planting potatoes with the tops of food tubers.\" On 3 June 1943, at a ceremonial meeting of the Soviet Academy of Sciences dedicated to the 100th anniversary of the birth of Kliment Timiryazev, Lysenko made a report: \"K. A. Timiryazev and the tasks of our agrobiology.\" In 1943, the first edition of Lysenko's collection was published, titled \"Agrobiology: Work on genetics, breeding and seed production\".\nOn 10 June 1945, Lysenko was awarded the title of Hero of Socialist Labor with the Order of Lenin, \"for outstanding services in the development of agricultural science and increasing the productivity of agricultural crops, especially potatoes and millet.\" On 10 September 1945, Lysenko was awarded the Order of Lenin \"for the successful completion of the government's task in difficult war conditions to provide the front and the country's population with food, and industry with agricultural raw materials.\"\nPost-war.\nIn 1946, Lysenko wrote an article titled \"Genetics\" for the 3rd edition of the Agricultural Encyclopedia. The article extensively quoted and criticized Thomas Hunt Morgan's article \"Heredity,\" published in the United States in 1945 in the American Encyclopedia, and describes features of \"Michurinist genetics.\" The article was included in the \"Agrobiology\" collection. A similar article was published in the second edition of the Great Soviet Encyclopedia.\nAugust 1948 session of VASKhNIL.\nOn 10 April 1948, Yuri Zhdanov, who considered the complaints of scientists against Lysenko, made a report at the Polytechnic Museum at a seminar of regional party committee lecturers on the topic \"Controversial issues of modern Darwinism.\" Lysenko himself listened to the Zhdanov's critical speech over a loudspeaker in another room, since he was denied a ticket to the report.\nFrom 31 July to 7 August 1948, a Session of the All-Union Academy of Agricultural Sciences (VASKhNIL) took place, at which most of the speakers supported Lysenko's biological views and pointed to the \"practical successes\" of specialists of the \"Michurinist movement.\"\nAt the session, Lysenko presented erroneous views on genetics (denial of Mendel's law of segregation, denial of immutable \"genes\"), as well as politicized statements addressed to opponents (for example, Morgan's genetics was credited with justifying racism, eugenics, and serving the interests of the militaristic bourgeois class).\nPolitics.\nDuring the early and mid twentieth century the Soviet Union went through war and revolution. Political oppression caused tension within the state but also promoted the flourishing of science: this was possible due to the flow of resources and demand for results. Lysenko aimed to manipulate various plants such as wheat and peas to increase their production, quality, and quantity, while impressing political officials with his success in motivating peasants to return to farming.\nThe Soviet Union's collectivist reforms forced the confiscation of agricultural landholdings from peasant farmers and heavily damaged the country's overall food production, and the dispossessed peasant farmers posed new problems for the regime. Many had abandoned the farms altogether; many more waged resistance to collectivization by poor work quality and pilfering. The dislocated and disenchanted peasant farmers were a major political concern to the USSR's leadership. Lysenko became prominent during this period by advocating radical but unproven agricultural methods, and also promising that the new methods provided wider opportunities for year-round work in agriculture. He proved himself very useful to the Soviet leadership by reengaging peasants to return to work, helping to secure from them a personal stake in the overall success of the Soviet revolutionary experiment.\nLysenko's success at encouraging farmers to return to working their lands impressed Stalin, who also approved of Lysenko's peasant background, as Stalin claimed to stand with the proletariat. By the late 1920s, the USSR's leaders had given their support to Lysenko. This support was a consequence, in part, of policies put in place by the Communist Party to rapidly promote members of the proletariat into leadership positions in agriculture, science and industry. Party officials were looking for promising candidates with backgrounds similar to Lysenko's: born of a peasant family, lacking formal academic training or affiliations to the academic community. Due to his close partnership with Stalin, Lysenko acquired an influence over genetics in the Soviet Union during the early and mid-20th century. Lysenko eventually became the director of Genetics for the Academy of Sciences in 1940, which gave him even more control over genetics. He remained in the position for more than two decades, throughout the reigns of Stalin and Nikita Khrushchev, until he was relieved of his duties in 1965.\nOutside the Soviet Union, scientists spoke critically: British biologist S. C. Harland lamented that Lysenko was \"completely ignorant of the elementary principles of genetics and plant physiology\" (Bertram Wolfe, 2017). Criticism from foreigners did not sit well with Lysenko, who loathed Western \"bourgeois\" scientists and denounced them as tools of imperialist oppressors. He especially detested the American-born practice of studying fruit flies, the workhorse of modern genetics. He called such geneticists \"fly lovers and people haters\".\nRepression of biologists.\nIn the spring of 1937, shortly after Stalin's report at the March plenum of the Central Committee of the All-Union Communist Party of Bolsheviks \"On the shortcomings of party work and measures to eliminate Trotskyists and other double-dealers,\" Lysenko and his supporters, including Isaak Prezent and Alexander Kohl, began their campaign against geneticists, accusing them of colluding with the anti-Stalinist opposition and reactionary sabotage.\nDuring the 1930s and '40s, the V.I. Lenin Academy of Agricultural Sciences (VASKhNIL) served as a floor for debate between Lysenkoists and geneticists. On 7 August 1948, at the end of a week-long session organized by Lysenko and approved by Stalin, the VASKhNIL announced that from that point on Lysenkoism would be taught as \"the only correct theory.\" Soviet scientists were forced to denounce any work that contradicted Lysenko. Prezent accused the geneticists, whom Lysenko and supporters termed \"Weismannists-Mendelists-Morganists\", of ideological unreliability. At the 1948 VASKhNIL session, Prezent said:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;We are encouraged to debate here. We will not discuss with the Morganists, we will continue to expose them as representatives of a harmful and ideologically alien movement, brought to us from foreign countries, pseudoscientific in its essence.\nSeveral geneticists who refused to denounce the theory were executed (including Izrail Agol, Solomon Levit, Grigorii Levitskii, Georgii Karpechenko and Georgii Nadson) or sent to labor camps. One prominent critic of Lysenko, the famous Soviet geneticist and president of the Agriculture Academy, Nikolai Vavilov, was arrested in 1940 and died in prison in 1943. Before the 1930s, the Soviet Union had arguably the best genetics community. According to \"The Atlantic\" writer Sam Kean, \"Lysenko gutted it, and by some accounts, set Russian biology and agronomy back a half-century\". Lysenko's work was eventually recognized as fraudulent by some, \"but not before he had wrecked the lives of many and destroyed the reputation of Russian biology\" according to scientist Peter Gluckman.\nConsequences of Lysenko's views.\nLysenko forced farmers to plant seeds very close together since, according to his \"law of the life of species\", plants from the same \"class\" never compete with one another. Lysenko played an active role in the famines that killed millions of Soviet people and his practices prolonged and exacerbated the food shortages. The People's Republic of China under Mao Zedong adopted his methods starting in 1958, with calamitous results, contributing to the Great Chinese Famine of 1959 to 1962, in which some 15\u201355 million people died.\nAfter Stalin.\nIn 1955, an attempt was made to disempower Lysenko, with a letter signed by more than three hundred scientists, the so-called \"Letter of three hundred\", which was sent to Nikita Khrushchev. It led to Lysenko resigning temporarily but he returned to power through Khrushchev's efforts. Though Lysenko remained at his post in the Institute of Genetics until 1965, his influence on Soviet agricultural practice had declined after the death of Stalin in 1953. Lysenko retained his position, with the support of the new leader Nikita Khrushchev. However, mainstream scientists re-emerged and found new willingness within Soviet government leadership to tolerate criticism of Lysenko, the first opportunity since the late 1920s. In 1962, three of the most prominent Soviet physicists, Yakov Zeldovich, Vitaly Ginzburg, and Pyotr Kapitsa, presented a case against Lysenko, proclaiming his work as pseudoscience. They also denounced Lysenko's application of political power to silence opposition and eliminate his opponents within the scientific community. These denunciations occurred during a period of structural upheaval in Soviet government, during which the major institutions were purged of the strictly ideological and political machinations which had controlled the work of the Soviet Union's scientific community for several decades under Stalin.\nIn 1964, physicist Andrei Sakharov spoke out against Lysenko in the General Assembly of the Academy of Sciences of the USSR:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;He is responsible for the shameful backwardness of Soviet biology and of genetics in particular, for the dissemination of pseudo-scientific views, for adventurism, for the degradation of learning, and for the defamation, firing, arrest, even death, of many genuine scientists.\nThe Soviet press was soon filled with anti-Lysenkoite articles and appeals for the restoration of scientific methods to all fields of biology and agricultural science. In 1965, Lysenko was removed from his post as director of the Institute of Genetics at the Academy of Sciences and restricted to an experimental farm in Moscow's Lenin Hills (the Institute itself was soon dissolved). After Khrushchev's dismissal in 1964, the president of the Academy of Sciences declared that Lysenko's immunity to criticism had officially ended. An expert commission was sent to investigate records kept at Lysenko's experimental farm. His secretive methods and ideas were revealed. A few months later, a devastating critique of Lysenko was made public. Consequently, Lysenko was immediately disgraced in the Soviet Union.\nAfter Lysenko's monopoly on biology and agronomy had ended, it took many years for these sciences to recover in Russia. Lysenko died in Moscow in 1976, and was ultimately interred in the Kuntsevo Cemetery, although the Soviet government refused to announce Lysenko's death for two days after the event and gave his passing only a small note in \"Izvestia\".\nLysenko's theories.\nLysenko rejected Mendelian genetic inheritance theory in favour of his own logic, which he termed \"Michurinist genetics\". He believed Gregor Mendel's theory to be too reactionary or idealist. Lysenko's ideas were a mixture of his own, those of Russian agronomist Ivan Michurin, and of other Soviet scientists. Through this mixture of ideas, Lysenko founded the \"Michurinist doctrine\". The core ideas are that body cells (the soma) determine the quality of an organism's offspring; every part of the body contributes to the germ cells, in the manner of Darwin's theory of pangenesis, though Lysenko denied any such connection.\nThese ideas were not directly derived from established biological theories such as Mendelian genetics, Lamarckism or Darwinism. He shaped his genetic concepts to support the simple practical purpose of breeding and improving crops. His ideas were also shaped to disprove other claims made by his fellow geneticists. His ideas and genetic claims later began to be termed \"Lysenkoism\". He claimed that his ideas were not associated with Lamarckism, but there are similarities between the two ideas, such as a belief in the inheritance of acquired characteristics. Some of Lysenko's ideas can also seem to be vitalistic. He claimed that plants are self-sacrificing\u2014they do not die due to a lack of sunlight or moisture but so that healthy ones may live and when they die they deposit themselves over the growing roots to help the new generation survive.\nLysenko believed that in one generation of a hybridized crop, the desired individual could be selected, mated again and continue to produce the same desired product, not worrying about separation/segregation in future breeds. For that to work, he had to assume that after a lifetime of developing (acquiring) the best set of traits to survive, those were passed down to the next generation. That assumption disregarded the potential for variation or mutation.\nLysenko did not believe in genes and only spoke about them to say that they did not exist. He instead believed that any body, once alive, obtained heredity. That meant that the entirety of the body was able to pass on the hereditary information of that organism, and was not entirely dependent on a special element such as DNA or genes. That puzzled biologists at that time because it went against established notions of heredity and inheritance. It also contradicted the Mendelian principles that most biologists had been using to base their ideas on. Most scientists believed that Lysenko's ideas were not credible, because they did not truly explain the mechanisms of inheritance. Biologists now consider that his beliefs are pseudo-scientific, with little relationship to genetics.\nLysenko argued that there is not only competition, but also mutual assistance among individuals within a species, and that mutual assistance also exists between different species.\nAccording to Lysenko,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The organism and the conditions required for its life are an inseparable unity. Different living bodies require different environmental conditions for their development. By studying these requirements we come to know the qualitative features of the nature of organisms, the qualitative features of heredity. Heredity is the property of a living body to require definite conditions for its life and development and to respond in a definite way to various conditions.\nAnother of Lysenko's theories was that obtaining more milk from cows did not depend on their genetics but on how they were treated. The better they were handled and taken care of, the more milk would be obtained; Lysenko and his followers were well known for taking very good care of their livestock. Lysenko claimed that the cuckoo was born when young birds such as warblers were fed hairy caterpillars by the parent (rather than host) birds; this claim failed to recognise that the cuckoos he described were brood parasites. Lysenkoites believed that fertilization was not random, but that there was specific selection of the best mate. For reasons like these, Lysenkoism can be viewed as pseudo-scientific.\nAfter World War II ended, Lysenko took an interest in the works of Olga Lepeshinskaya, an older feldsher and biologist, who claimed to be able to create cells from egg yolk and non-cellular matter. Lepeshinskaya recognized common ground between her ideas and Lysenko's. By combining both of their ideas it was possible to proclaim that cells could grow from non-cellular material and that the predicted ratios of Mendelian genetics and meiosis were incorrect, thus undermining the basis of modern cytology, as well as genetics.\n\"The influence of the thermal factor on the duration of plant development phases\".\nIn Ganja, Lysenko began work on studying the growing season of agricultural plants (cotton, wheat, rye, oats, and barley). For two years, Lysenko experimented with the timing of sowing grain, cotton and other plants, sowing plants at intervals of 10 days. Based on the results of these studies, in 1928, he published a large work, \"The influence of the thermal factor on the duration of plant development phases.\" Of the 169 pages of the work, 110 contained tables with primary data. The mathematical processing of the data was carried out by Nikolai Derevitsky and I. Yu. Staroselsky.\nIn this work, Lysenko came to the conclusion that each phase of plants (\"the following phases were recorded: sowing-watering, germination, tillering, booting, heading, flowering, wax ripeness and harvesting time\") begins its development \"at a strictly defined intensity of thermal energy, that is, at a certain, always constant degree Celsius, and requires a certain amount of degree days.\" Carrying out mathematical processing of the initial data using the least squares method, Lysenko determined the values of the constants A and B - \"the starting point at which processes begin\" and \"the sum of degrees required to complete the phase.\"\nIn 1927, the main provisions of this work were reported by Lysenko at the \"congress convened by the People's Commissariat for Agriculture of the Azerbaijan SSR at the Ganja station,\" and then, in December 1928, at the All-Union Meeting of Sugar Trust in Kiev. In this book, Lysenko thrice cited the work of Gavriil Zaitsev, dedicated to the same issues.\nVernalization.\nThe issue of the effect of low temperatures on plant development was touched upon by such famous physiologists as Georg Klebs and Gustav Gassner. For example, Gassner, based on his experiments, established that if sprouted seeds of winter crops are exposed to low temperatures, then the plants grown from them during spring sowing will split.\nWorking at the Ganja breeding station, Lysenko was also able to accelerate the development of plants. Based on his experiments, he developed a technique for germinating seeds before sowing at low positive temperatures, which he termed vernalization.\nThis technique was supported by a number of prominent scientists in the early 1930s. For example, Nikolai Vavilov saw the main advantage of vernalization in the possible simplification of breeding work, as well as in the ability to control the length of the growing season of plants. In addition, he believed that vernalization could help preserve winter crops from freezing during harsh winters. Vavilov wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;It can definitely be argued that vernalization is the greatest achievement in breeding, because it has made available for use the entire world variety of varieties, which were still inaccessible for practical use due to the usual inconsistency of the growing season and the low winter hardiness of southern winter forms.\nThe main reason Vavilov initially supported Lysenko's work on vernalization was his interest in the potential use of vernalization as a means of synchronizing the flowering of various plant species in the Institute of Plant Industry collection, since Vavilov's team had encountered problems in cross-species experiments that required such synchronization. Vavilov, however, eventually stopped supporting the use of vernalization because the method did not produce the expected results.\nCrops with vernalized seeds increased on USSR farms every year. In particular, in 1935, experimental vernalized crops of spring grain were carried out by more than 40,000 collective and state farms on an area of 2.1 million hectares; in 1937, 8.9 million hectares.\nHowever, the mass introduction of vernalization into USSR agriculture ended in failure. Critics of vernalization explained this failure, among other things, by the lack of experimental data on varieties and regions of the Soviet Union. To collect data, questionnaires were sent to collective and state farms. The questionnaire method made it possible to fabricate data, suppress negative results, and was convenient for promoting vernalization. The data obtained by Lysenko and his supporters was published mainly in the journal \"Byulleten yarovizatsii\", published under the editorship of Lysenko, or in the Soviet press. However, these publications were not published in any independent scientific journals.\nThe agricultural method of vernalization has been criticized by experts for reasons such as the possibility of damage to seeds during the process of soaking, germination and sowing, the labor intensity of this operation, and the greater vulnerability of vernalized plants to smut. Critics of vernalization in the 1930s included Pyotr Konstantinov, S. Levitsky (Poland), Pyotr Lisitsyn, and Doncho Kostov.\nVernalization of grain crops during World War II (spring of 1942-1945) and the post-war period did not receive widespread industrial use. \"Pravda\", in an editorial dated 14 December 1958, argued that after the massive introduction of technology on Soviet farms, which made it possible to sow in a shorter time, vernalization of seeds \"was not always necessary.\" However, vernalization, according to the newspaper, continued to produce \"remarkable results\" in the cultivation of millet and potatoes.\nTheory of stage development of plants.\nTo substantiate his developments in the field of plant growing, Lysenko put forward a theory of staged development of plants. The essence of the theory was that higher plants must go through several stages during their lives before producing seeds. To move to the next stage, certain specific conditions are required.\nIn 1935, Lysenko wrote:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;This theory proceeds from the fact that everything in a plant, each of its properties, characteristics, etc., is the result of the development of a hereditary basis in specific environmental conditions. The hereditary basis is the result of the entire previous phylogenetic history. The result of this biological history, which was created through the selection of adaptations to certain conditions of existence, are the demands that a plant organism throughout its individual history, starting from the zygote, makes for certain conditions of its development. These requirements are the reverse side of the adaptations developed in the historical process.\nBased on this theory, Lysenko proposed vernalization of winter and spring grains, potatoes and other crops.\nThe provisions of Lysenko's theory on the staged development of plants, according to critics, were to some extent consistent with the level of knowledge of the 1930s, but not all of them were confirmed experimentally. The shortcomings of the theory of stage development were pointed out by Mikhail Chailakhyan among others. In particular, critics argued that even without preliminary vernalization, various plant varieties have a photoperiodic reaction and are delayed in development when the length of daylight hours is reduced.\nSummer potato planting.\nIn the southern regions of the Soviet Union, vegetatively propagated potatoes gradually produced increasingly smaller tubers, which, in addition, were subject to severe rotting. To combat this, Lysenko proposed summer planting of potatoes, arguing that the \"deterioration of the breed\" of potatoes can be stopped by planting them not in warm, but in cool soil, at the end of summer.\nOn 11 January 1941, in a lecture given at the Polytechnic Museum, Lysenko stated:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Previously, it was common knowledge that if, under comparable conditions, planting material of at least the Early Rose variety, obtained from the harvest of the Moscow region, and planting material of the same variety, but obtained from the harvest of the Odessa region, are planted, then almost without exception, the yield of planting material from the Moscow region will always be significantly greater than the yield of planting material from the Odessa region. Now we can cite a lot of experimental data of the opposite order. And in the past, 1940, in the experiments of Ivan Glushchenko (research associate at the Institute of Genetics of the USSR Academy of Sciences) on a site near Moscow, a crop of potatoes of the Early Rose variety was obtained from tubers of summer southern reproduction (Breeding and Genetics Institute, Odessa) 480.5 centners per hectare, and under the same conditions the same variety of local origin (Moscow region, Institute of Potato Farming) yielded a yield of 219.5 centners per hectare. All this suggests that summer planting potatoes in the south is not a way to stop the degeneration of the potato breed, but a way to improve the potato breed.\nHowever, as with vernalization, data was collected using questionnaires, making the results easy to falsify, and any scientific data obtained was never published. When summer planting did not produce any positive results, Lysenko suggested burying the harvested potatoes in trenches, spreading a layer of soil over a layer of potatoes, arguing that this would reduce losses from rotting tubers. However, burying tubers in trenches led to huge crop losses, as the rotting of the tubers only intensified.\nLysenko ignored the real reason for the degeneration of potato plantings - potato viruses (a particularly large role in the degeneration is played by the potato leafroll virus - PLRV, potato virus X - PVX, and potato virus Y - PVY), replacing it with abstract ideas about the \"deterioration of the potato breed\". Ignoring the role of viruses in the degeneration of potato plantings and the subsequent ban on research into plant viruses led to a significant delay in the development of methods for detecting plant viruses in the Soviet Union, the spread of viruses not only in the south, but also in other regions of the Soviet Union, and, as a result, to a sharp drop in potato yields.\nSowing over stover.\nSoviet literature of the 1940s-50s and Lysenko's supporters credit him with a number of achievements, including the idea of sowing over stover to protect winter crops from frost.\nIn 1943, Lysenko stated:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Stover 25-30 cm in height protects the above-ground parts of plants from the destructive mechanical action of the wind. The stubble retains snow, which also protects plants not only from frost, but also from the action of winds. Unplowed, unloosened soil has almost no large voids. Therefore, on stover crops, large ice crystals are not observed in the soil, which have a detrimental effect, damaging the roots and tillering nodes of winter plants.\nSowing over stover, despite the advantages of the method (snow retention and better temperature conditions for wintering plant seeds in Siberian conditions), was criticized for clogging fields with weeds, since this excludes conventional agricultural technology - surface plowing, which provokes the germination of weeds, and subsequent spring plowing. In the absence of herbicides at that time, this led to clogging of fields.\nNikolai Tsitsin, in a letter to Stalin dated 2 February 1948, noted the low grain yield in stubble crops:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In 1944, in seven registered districts of the Novosibirsk region, the average yield of winter rye stubble was 3.6 c/ha. In the same year in the Chelyabinsk region, the average rye yield was equal to very poor fallows - 4.3 c/ha; for fresh September plowing - 2.6 c/ha; for stover - 1.8 c/ha. In the same year, for all state farms of the Omsk Grain Trust of the Ministry of State Farms, the stover yield was also very low; \u2014 it was equal to 11.1 c/ha for fallows and 5.1 c/ha for stover. ... In 1945, in one of the best state farms in the Omsk region, \"Lesnoy\", from an area of winter wheat crops of 91 hectares, sown according to all the rules recommended by Academician Lysenko, only 6 centners of grain were collected, that is, an average of 7 kg per hectare, as well as several huge stacks of weeds, which, by the way, had become seeded in their mass by the time of harvesting. In the same year, on the neighboring state farm \"Boevoy\", all 67 hectares of stover crops of winter wheat were completely destroyed. Finally, last year, 1946, at the same Siberian Research Institute, headed by Academician Lysenko, out of 150 [ha] of stover crops, 112 hectares were plowed, since only one weed was born on them.\nCiting negative examples of stover crops, Tsitsin explained positive examples by the fact that \"in the harsh conditions of Siberia, there are occasionally exceptionally favorable years.\" In general, he considered work on stover unpromising, considering instead that work to increase the winter hardiness of grains with wheatgrass-wheat hybrids, distant hybridization with wild plants, and the use of fallows and semi-cultivated fallows were more justified.\nInheritance of acquired traits.\nFundamental disagreements between Mendelian geneticists and Lysenko concerned the possibility of inheritance of traits that arise during the individual development of organisms, for example, under the influence of environmental factors or during grafting (vegetative hybridization). The idea that such characteristics cannot be inherited is associated with a distorted understanding of the principle formulated by August Weismann, according to which somatic cells cannot transmit information to germ cells. In fact, Weismann admitted the possibility of environmental influence on the substance of heredity.\nLysenko himself, at the August 1948 VASKhNIL session, argued the following regarding the inheritance of acquired characteristics:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Thus, the position about the possibility of inheritance of acquired deviations - this is the largest acquisition in the history of biological science, the foundation of which was laid by Lamarck and organically mastered later in the teachings of Darwin - was thrown overboard by the Mendelian-Morganists.\nLegacy.\nIn the Soviet Union, streets named after Lysenko existed in several cities, such as Krasnoturyinsk.\nArkady and Boris Strugatsky cited Lysenko as the inspiration for the character of Professor Ambrosy Ambruazovich Vybegallo from their 1965 satirical science fantasy novel \"Monday Begins on Saturday\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Professor Vibegallo is based on the once-famous academician Lysenko, who put all of Russian biology on all fours, spent more than thirty years doing nonsense and at the same time not only destroyed our entire biological science, but also trampled everything around, destroying (physically, with the help of the NKVD) all the best geneticists of the USSR, starting with Vavilov. Our Vibegallo is exactly the same demagogue, ignorant and boorish, but he is far from his prototype!\u2014\u200a\nLysenko's ideas have been attracting a renewed following in contemporary Russia, linked to a strain of Russian nationalism that views \"Western\" ideas and mainstream science with suspicion.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49186", "revid": "44604570", "url": "https://en.wikipedia.org/wiki?curid=49186", "title": "Pope Anacletus", "text": "Head of the Catholic Church from c. 80 to c. 92\nPope Anacletus (born c.\u2009AD 16 \u2013 died c.\u2009AD 92), also known as Cletus, was the bishop of Rome, following Peter and Linus. Anacletus served between c.\u2009AD 80 and his death, c.\u2009AD 92. Cletus was a Roman who, during his tenure as pope, ordained a number of priests and is traditionally credited with setting up about twenty-five parishes in Rome. Although the precise dates of his pontificate are uncertain, he \"died a martyr, perhaps about 91\". Cletus is mentioned in the Roman Canon of the mass; his feast day is April 26.\nName and etymology.\nThe name \"Cletus\" () means \"one who has been called\", and \"Anacletus\" () means \"one who has been called back\". Also \"Anencletus\" () means \"unimpeachable\" or \"blameless\".\nThe Roman Martyrology mentions the pope as \"Cletus\". The \"Annuario Pontificio\" gives both forms. Eusebius, Irenaeus, Augustine of Hippo and Optatus all suggest that both names refer to the same individual, while the Liberian Catalogue counts Cletus and Anacletus as separate popes.\nPapacy.\nAs with many of the early popes, little is known of Anacletus' pontificate. Earlier historical records are inconsistent in their usage of the names Cletus, Anacletus, and Anencletus and in the placement of these names in the order of succession. Generally, the order used by Irenaeus is used today, wherein Cletus and Anacletus refer to the same person, who succeeded Linus and preceded Clement. Traditionally, it was accepted that he reigned for twelve years, though the dates of that reign are questionable. The 2012 \"Annuario Pontificio\" states, \"For the first two centuries, the dates of the start and the end of the pontificate are uncertain\", before placing Anacletus' pontificate from 80 to 92. These are the years given by Eusebius and Jerome. However, 76 to 88 are also frequently cited.\nAccording to tradition, Pope Anacletus divided Rome into twenty-five parishes. One of the few surviving records concerning his papacy mentions him as having ordained an uncertain number of priests.\nPope Anacletus was martyred, ending his pontificate. A tomb ascribed to Anacletus is located near St. Peter's tomb in the Vatican Necropolis field P, underneath St. Peter's Basilica. This tomb is located with tombs ascribed to Linus, Evaristus, Telesphorus, Hyginus, Pius I, Anicetus, and Victor I. Little epigraphic evidence exists to support the ascription of these tombs to the early popes. His name (as Cletus) is included in the Roman Canon of the Mass.\nVeneration.\nThe Tridentine calendar reserved 26 April as the feast day of Saint Cletus, who the church honoured jointly with Pope Marcellinus, and 13 July for solely Saint Anacletus. In 1960, Pope John XXIII, while keeping the 26 April feast, which mentions the saint under the name given to him in the Canon of the Mass, removed 13 July as a feast day for Saint Anacletus. The 14 February 1961 Instruction of the Congregation for Rites on the application to local calendars of Pope John XXIII's motu proprio \"Rubricarum instructum\" of 25 July 1960, decreed that \"the feast of 'Saint Anacletus', on whatever ground and in whatever grade it is celebrated, is transferred to 26 April, under its right name, 'Saint Cletus'\". Priests who celebrate Mass according to the General Roman Calendar of 1954 keep the July 13th feastday; but the feast has been removed from the General Roman Calendar since 1960, and as such is not kept even in the 1962 Missal. Although the day of his death is unknown, Saint Cletus continues to be listed in the Roman Martyrology among the saints of 26 April.\nIn literature.\nIn the Divine Comedy, Dante mentions him as being placed in the \"Heaven of the Fixed Stars\" (Paradiso 27.41).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49187", "revid": "245306", "url": "https://en.wikipedia.org/wiki?curid=49187", "title": "Pope Cletus", "text": ""}
{"id": "49188", "revid": "245306", "url": "https://en.wikipedia.org/wiki?curid=49188", "title": "Pope Anencletus I", "text": ""}
{"id": "49189", "revid": "1152308", "url": "https://en.wikipedia.org/wiki?curid=49189", "title": "Frauenburg", "text": "Frauenburg may refer to the following places:\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about distinct geographical locations with the same name. "}
{"id": "49191", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=49191", "title": "Sir John Eccles", "text": ""}
{"id": "49192", "revid": "49653432", "url": "https://en.wikipedia.org/wiki?curid=49192", "title": "Heresies", "text": ""}
{"id": "49195", "revid": "10202399", "url": "https://en.wikipedia.org/wiki?curid=49195", "title": "George Westinghouse", "text": "American engineer, inventor, and businessman (1846\u20131914)\nGeorge Westinghouse Jr. (October 6, 1846 \u2013 March 12, 1914) was a prolific American inventor, engineer, and entrepreneurial industrialist based in Pittsburgh, Pennsylvania. He is best known for his creation of the railway air brake and for being a pioneer in the development and use of alternating current (AC) electrical power distribution. During his career, he received 360 patents for his inventions and established 61 companies, many of which still exist today.\nHis invention of a train braking system using compressed air revolutionized the railroad industry around the world. He founded the Westinghouse Air Brake Company in 1869. He and his engineers also developed track-switching and signaling systems, which lead to the founding of the company Union Switch &amp; Signal in 1881. \nIn the early 1880s, he developed inventions for the safe production, transmission, and use of natural gas. This sparked the creation of a whole new energy industry.\nDuring this same period, Westinghouse recognized the potential of using alternating current (AC) for electric power distribution. In 1886, he founded the Westinghouse Electric Corporation. Westinghouse's electric business directly competed with Thomas Edison's, who was promoting direct current (DC) electricity. Westinghouse Electric won the contract to showcase its AC system to illuminate the \"White City\" at the 1893 Columbian Exposition in Chicago. The company went on to install the world's first large-scale, AC power generation plant at Niagara Falls, New York, which opened in August 1895. \nIronically, among many other honors, Westinghouse received the 1911 Edison Medal of the American Institute of Electrical Engineers \"for meritorious achievement in connection with the development of the alternating current system\".\nEarly years.\nGeorge Westinghouse was born in 1846 in the village of Central Bridge, New York (see George Westinghouse Jr. Birthplace and Boyhood Home), the son of Emeline (Vedder) and George Westinghouse Sr., a farmer and machine shop owner. The Westinghouse ancestors came from Westphalia in Germany, moving first to England and eventually emigrating to the US. The family name had been anglicized from Wistinghausen.\nFrom his youth, Westinghouse displayed a talent for machinery and business. He was encouraged by his father and was assigned tasks in the Westinghouse Company workshop. The company produced farm equipment such as the Westinghouse Farm Engine.\nAt the outbreak of the Civil War in April 1861, the then 14-year-old attempted to run away from home to enlist, but was stopped by his father. In June 1863 his parents allowed him to enlist, first in the 12th Regiment of the New York National Guard and then in the 16th Regiment of the New York Cavalry. He earned a promotion to the rank of corporal before being honorably discharged in November 1863. A month later he joined the Union Navy. He served as an Acting Third Assistant Engineer on the gunboat and then on the ship through the end of the war. These ships were used to blockade Southern port cities. After his discharge in August 1865, Westinghouse returned to his family and enrolled at Union College in Schenectady, but he quickly lost interest and dropped out during his first term.\nHe further developed his skills in his father's company shop. Westinghouse was just 19 when he received his first patent for a rotary steam engine. At age 21, he invented a car replacer, a device used to guide derailed railroad cars back onto the tracks, and a reversible \"frog\", a rail junction piece used to switch trains between different tracks. In 1868, Westinghouse moved with his wife to Pittsburgh, Pennsylvania, to access better and less expensive steel for the manufacture of his railroad frogs, and there he began to develop his recently invented railroad air brake concept.\nRailroad air brakes and signaling/switching systems.\nDuring his travels, Westinghouse had witnessed the aftermath of a collision where engineers on two trains, approaching each other on the same track, had seen each other but were unable to stop their trains in time due to the existing brake systems. At that time, brakemen had to run along catwalks on the top of the cars, manually applying the brakes. Coordinating that process was tricky and dangerous. It also meant trains could not exceed ten cars in length, and thousands of brakemen died or were maimed each year.\nIn 1869, at age 23, Westinghouse first publicly demonstrated his revolutionary new railroad braking system in Pittsburgh. It stopped trains using a compressed air system. His first braking system used an air compressor and an air reservoir in the locomotive, with a single compressed air pipe running the length of the train and with flexible connections between cars. That line controlled the brakes, allowing the engineer to apply and release the brakes simultaneously on all cars. A charter for what would eventually become the Westinghouse Air Brake Company was filed in July of that year. \nAlthough the system was successful, as demonstrated when it prevented a serious mishap in front of assembled witnesses, it was hardly fail-safe. Any rupture or disconnection in the air line left the train without brakes. Over the next two years, Westinghouse and his engineers addressed the problem by inverting the process, designing valves so that constant pressure in the lines kept the brakes disengaged. An air reservoir was also placed on each car. With the improved design, any interruption or break in the line automatically caused the train to stop.\nDuring the next decade, building on his earliest inventions, Westinghouse expanded his interest to railway signaling and track-switching systems. Previously, signaling relied on oil lamps and track switching was performed manually. Westinghouse's designs changed all that. In May 1881, Westinghouse founded the Union Switch and Signal Company to manufacture, market, install, and maintain these innovative control systems, which were eventually adopted by railroads around the world.\nNatural gas.\nBy 1883, Westinghouse had become interested in natural gas. Gas had recently been discovered in nearby Murrysville, Pennsylvania, and it attracted a lot of attention, in part because of a spectacular flaming blowout of the Haymaker Well in 1878. After visiting the well and recognizing its commercial potential, he undertook drilling for gas on his estate Solitude (today's Westinghouse Park) in Pittsburgh.\nEarly in the morning of May 21, 1884, the drilling crew struck a pocket of gas at a depth of 1500 feet, and the resulting blast of dirt and water blew the top off the derrick. It took Westinghouse a week to devise a method to cap the flow of gas. He was encouraged to develop a system to deliver gas to heat and light area homes and businesses. Eventually, several natural gas derricks towered above his estate's Victorian-era gardens. In modern times there is no above-ground trace left of these derricks.\nThat year, Westinghouse acquired a dormant utility charter for \"The Philadelphia Company\", and over the next three years, he developed devices and secured more than 30 patents for this technology. He used the Philadelphia Company to develop gas wells and to promote gas usage both for commercial and residential purposes. By 1886, the Philadelphia Company owned 58 wells and 184\u00a0miles of distribution piping in the Pittsburgh area, and by 1887, it served over 12,000 private homes and 582 industrial customers throughout the state.\nIn 1889, as his involvement with the generation and distribution of electricity was surging, Westinghouse resigned as president of the Philadelphia Company, but he remained on its board. Growth in the natural gas business slowed in the 1890s, hindered by supply problems and ongoing safety concerns related to gas distribution in homes and businesses. However, the Philadelphia Company continued to grow, spawning enterprises such as Equitable Gas and Duquesne Light.\nElectric power distribution.\nIn the early 1880s, Westinghouse's interest in railroad switching and natural gas distribution led him to become involved in the then-new field of electrical power distribution. Electric lighting of streets using arc lighting was already a growing business with many companies building systems powered by either locally generated direct current (DC) or alternating current (AC). At the same time, Thomas Edison was launching the first DC electric utility designed to light homes and businesses with his patented incandescent bulb.\nIn 1884, Westinghouse began developing his own DC domestic lighting system and hired physicist William Stanley to help work on it. In 1885, Westinghouse became aware of the concept of an electrical transformer introduced by Frenchman Lucien Gaulard and Englishman John Gibbs. Westinghouse was alerted by Guido Pantaleoni, an Italian engineer in his employ, to the already-patented Gaulard-Gibbs transformer design, and to an already deployed system capable of transmitting electricity for many miles near London, Turin, and Rome. They had found that AC electricity could be \"stepped up\" in voltage by a transformer for transmission and then \"stepped down\" by another transformer for lower voltage consumer use. This innovation made it possible for large centralized power plants to generate electricity and supply it over long distances to both cities and places with more dispersed populations. This was a huge advantage over the low voltage DC systems being marketed by Edison\u2019s electric utility, which limited generating stations to a transmission range of about a mile due to losses caused by the low voltages and high currents used. Westinghouse recognized AC's potential to achieve greater economies of scale as a way to create a truly competitive electrical system, rather than simply piecing together a barely competitive DC lighting system just different enough to get around Edison\u2019s patents.\nIn 1885, Westinghouse imported several Gaulard\u2013Gibbs transformers and a Siemens AC generator to begin experimenting with AC networks in Pittsburgh. Stanley, assisted by engineers Albert Schmid and Oliver B. Shallenberger, dramatically improved the Gaulard\u2013Gibbs transformer design, creating the first practical and manufacturable transformer. In 1886, with Westinghouse's backing, Stanley installed the first multiple-voltage AC power system in Great Barrington, Massachusetts. The demonstration lighting system was driven by a hydroelectric generator that produced 500 volts AC, which was then stepped down to 100\u00a0volts to light incandescent bulbs in homes and businesses. That same year, Westinghouse founded the \"Westinghouse Electric &amp; Manufacturing Company\"; in 1889 he renamed it the \"Westinghouse Electric Corporation\".\nWar of the currents.\nThe Westinghouse company installed thirty more AC-lighting systems within a year, and by the end of 1887 it had 68 alternating current power stations compared to 121 DC-based stations Edison had installed over seven years. This competition with Edison led, in the late 1880s, to what became known as the \"war of currents\". Thomas Edison and his company joined and promoted a spreading public perception that the high voltages used in AC distribution were unsafe and deadly. Edison even suggested that a Westinghouse AC generator should be used in the State of New York's new electric chair.\nWestinghouse also had to deal with another AC rival, the Thomson-Houston Electric Company, which had constructed 22 power stations by the end of 1887 and by 1889 it had acquired another competitor, the Brush Electric Company. Thomson-Houston was expanding its business while trying to avoid patent conflicts with Westinghouse, arranging deals such as agreements over lighting company territory, paying royalties to use the Stanley transformer patent, and allowing Westinghouse to use its Sawyer\u2013Man incandescent bulb patent.\nIn 1890, the Edison company, in collusion with Thomson-Houston, arranged for the first electric chair to be powered with a Westinghouse AC generator. Westinghouse tried to block this move by hiring the best lawyer of the day to (unsuccessfully) defend William Kemmler, the first man scheduled to die in the chair. \nThe War of Currents ended in 1892 when financier J. P. Morgan forced Edison General Electric to switch to AC power and then pushed Edison out of the company he had founded. Edison General Electric company was merged with the Thomson-Houston Electric Company to form General Electric, a conglomerate controlled by the board of Thomson-Houston.\nDevelopment and competition.\nDuring this period, Westinghouse continued to pour money and engineering resources into the goal of building a completely integrated AC system \u2014 obtaining the Sawyer\u2013Man lamp by buying Consolidated Electric Light, and developing components such as an induction meter, and obtaining the rights to inventor Nikola Tesla's brushless AC induction motor along with patents for a new type of electric power distribution, polyphase alternating current. The acquisition of a feasible AC motor gave Westinghouse a key patented element for his system, but the financial strain of buying up patents and hiring the engineers needed to build it meant that the development of Tesla's motor had to be put on hold for a while.\nIn 1891, Westinghouse's company was in trouble. The near collapse of Barings Bank in London triggered the financial panic of 1890, causing investors to call in their loans. The sudden cash shortage forced the company to refinance its debts. The new lead lenders demanded that Westinghouse cut back on what looked to them like his excessive spending on the acquisition of other companies, research, and patents.\nAlso in 1891, Westinghouse built a hydroelectric AC power plant, the Ames Hydroelectric Generating Plant near Ophir, Colorado which supplied AC power to the Gold King Mine 3.5 miles away. This was the first successful demonstration of long-distance transmission of industrial-grade alternating current power and utilized two 100\u00a0hp Westinghouse alternators, one working as a generator producing 3,000-volt, 133-Hertz, single-phase AC, and the other used as an AC motor.\nIn May 1892, Westinghouse Electric won the bid to power and illuminate the 1893 World's Columbian Exposition in Chicago with alternating current, substantially underbidding General Electric to get the contract. To meet the contract's demands, he had to quickly develop a new type of incandescent lightbulb based on the Sawyer\u2013Man patent he had obtained, ensuring it did not infringe on the Edison patent design.\nBy the beginning of 1893, Westinghouse engineer Benjamin Lamme had made great progress in developing an efficient version of Tesla's induction motor. In that work he was aided by his sister and fellow Westinghouse engineer Bertha Lamme Feicht. Westinghouse Electric started branding their complete polyphase AC system as the \"Tesla Polyphase System\", announcing Tesla's patents gave them patent priority over other AC systems and stating their intention to sue any patent infringers.\nThis World's Fair devoted a building to electrical exhibits. It was a key event in the history of AC power, as Westinghouse demonstrated the safety, reliability, and efficiency of a fully integrated alternating current system to the American public. \nWestinghouse's demonstration of their ability to build a complete AC system at the Columbian Exposition was instrumental in the company getting the contract for building a two-phase AC generating system, the Adams Power Plant, at Niagara Falls, NY, in 1895. The company was subcontracted to build ten 5,000\u00a0horsepower (3,700\u00a0kW) 25\u00a0Hz AC generators at this plant. Westinghouse's Niagara Power Station No.\u00a01, as it was then called, remained in operation in the Niagara transformer house until the plant closed in 1961.\nAt the same time, a contract to build the three-phase AC distribution system the project needed was awarded to General Electric. The early to mid-1890s saw General Electric, backed by financier J. P. Morgan, engaged in costly takeover attempts and patent battles with Westinghouse Electric. The competition was so costly that in 1896 a patent-sharing agreement was signed between the two companies. The agreement stayed in effect until 1911.\nFollowing the success of the first Niagara Falls plant, the Rankine Generating Station, also known as The Canadian Niagara Power Generating Station, the Canadians contracted with Westinghouse for eleven 25\u00a0Hertz generators of the same Tesla-inspired design, rated for a total generating capacity of 100\u00a0MW. That facility opened in 1905 in Niagara Falls, Ontario.\nOther Westinghouse projects: steam engines, maritime propulsion, and shock absorbers.\nDespite continuing success in his other businesses, Westinghouse's main interest shifted to electric power generation. At the outset, the available generating sources were hydro turbines where falling water was available, and reciprocating steam engines where it was not. Westinghouse felt that existing reciprocating steam engines were clumsy and inefficient, and he wanted to develop rotating engines that would be more elegant. His first patent had been for a rotary steam engine, but it proved impractical at the time.\nIn 1884, the British engineer Charles Algernon Parsons at Clarke, Chapman and Co began experimenting with steam turbines and generators, producing a 10-horsepower (7.5\u00a0kW) turbo-generator. In 1895, Westinghouse bought rights to the Parsons turbine, and his engineers improved its technology and increased its scale. In 1898, Westinghouse demonstrated a 300-kilowatt generating unit, replacing reciprocating engines in his air-brake factory. The next year, he installed a 1.5-MW 1200\u00a0rpm unit for the Hartford Electric Light Company.\nWestinghouse also developed steam turbines for maritime propulsion. The basic problem was that large turbines ran most efficiently at around 3000\u00a0rpm, while an efficient propeller operated only at about 100\u00a0rpm. This required reduction gearing, but designing reduction gearing that could operate at both high rpm and at high power was difficult, since any slight misalignment would shake the powertrain to pieces. Westinghouse and his engineers invented an automatic self-alignment system that finally made turbine power practical for large vessels.\nIn 1889, Westinghouse purchased several mining claims in the Patagonia Mountains of southeastern Arizona and formed the Duquesne Mining &amp; Reduction Company. He hoped to invent a better way to mine and extract copper from \"lean\" ores that were not particularly rich in the metal. Success is this venture would have helped him compete in the electrical businesses that used much copper. He was unsuccessful in this project: no new copper reduction process was found and the mine was not profitable. He had founded the town of Duquesne to use as his company headquarters; it is now a ghost town. Duquesne grew to over 1,000 residents and the mine reached its peak production in the mid-1910s.\nWestinghouse also began to work on heat pumps that could provide heating and cooling. When Westinghouse claimed he was after a perpetual motion machine, the British physicist William Thomson (Lord Kelvin), one of his many correspondents, told him that such a machine would violate the laws of thermodynamics. Westinghouse replied that while it might be the case, it made no difference. If he couldn't build a perpetual motion machine, he would still have a heat pump system that he could patent and sell. \nAfter the broader introduction of the automobile, Westinghouse invented a compressed air shock absorber for their suspension systems. The shock absorber was among the last of the 360 patents he received, and it was awarded posthumously, two years after his death.\nLabor relations.\nWestinghouse was the first industrial employer in the United States to give workers a five-and-a half day work week, starting in June 1881. Saturdays were made half holidays to promote community involvement and personal development. Westinghouse had observed the practice while visiting England. \nThe planned community of Wilmerding, Pennsylvania was home to many Westinghouse employees, and it was also the headquarters of several companies, particularly Westinghouse Air Brake. Westinghouse Electric and Manufacturing was located a mile further down the Turtle Creek valley east of Pittsburgh. The worker houses were outfitted with running water, electricity, gas, and often space for small gardens. Homeownership was facilitated through periodic salary deductions. There was a pension and an insurance system. Factories were well-lit, ventilated, and were outfitted with medical facilities and personnel for treating injuries. All these accommodations, at Westinghouse's expense, were considered highly innovative at the time, especially in contrast to the conditions endured by workers in the nearby steel mills.\nWestinghouse was broadly admired by his workers. Privately, they referred to him as \"the Old Man\". An indication of his progressive attitude was that when Westinghouse engineers invented things, they were allowed to keep their names on the patents, though assigning rights to use them to the company. Westinghouse viewed this as part of the dignity of man and part of his intellectual property. Westinghouse, unlike Edison, did not put his name on all company patents as co-inventor.\nWestinghouse was not in favor of labor unionization. He did not reject workers who belonged to a union, but he did not like collective bargaining arrangements where his workers might strike for issues not related to conditions at his own factories. There was only one strike at any Westinghouse company while he was in charge. It was a 1903 action at Westinghouse Machine Company, which was rushing to illuminate the 1904 St. Louis World's Fair. Westinghouse responded by immediately hiring replacements for those employees who walked out. Despite that action, American labor and union organizer Samuel Gompers is reputed to have said \"If all employers of men treated their employees with the same consideration he does, the American Federation of Labor would have to go out of existence\".\nA series of short movies showing conditions in and around Westinghouse factories was made in 1904 and exhibited at the St. Louis World's Fair.\nPersonal life, later life, and death.\nIn 1867, Westinghouse met Marguerite Erskine Walker on a train, and they married in August of that year. They were married for 47\u00a0years, and had one son, George Westinghouse III, who in turn had six children. \nFrom 1871, George and Marguerite Westinghouse maintained a large home in Pittsburgh called Solitude, building up from an existing house on land purchased by George in 1871. They were part of a social class of very rich local industrialists and money managers including neighbors and associates Henry Clay Frick, Henry J. Heinz, William Thaw, Andrew Mellon, and Richard Beatty Mellon, and the brothers Andrew Carnegie and Thomas Carnegie. Their guests included Nicola Tesla, Lord Kelvin, and congressman (and future president) William McKinley. \nBy 1893, they had constructed Erskine Park in Lenox, Massachusetts, which they used as a summer home, in part as a respite from the gritty industrial environment of Pittsburgh. It was named for the family of Marguerite's grandparents.\nIn 1898, the Westinghouses leased and then in 1901 purchased the Blaine House mansion in Washington D.C. Marguerite Westinghouse was reputed to host frequent and lavish entertainments there. In 1918, their former Pittsburgh home, Solitude, was razed and the land given to the City of Pittsburgh to establish Westinghouse Park. The house in Erskine Park was sold by the family in 1917 and subsequently demolished. \nIn 1894, the Grand Army of the Republic, a fraternal organization of Union Civil War veterans, held a week-long convention in Pittsburgh. George Westinghouse, being a veteran himself, hosted an evening of dinner and entertainment for more than 5,000 attendees at the newly constructed, but not yet active main buildings of the Westinghouse Electric and Manufacturing Company in East Pittsburgh. He took on the expenses of the necessary building preparations and all the expenses of transporting people to and from the site by rail.\nPride in his achievements with the airbrake is reflected in the comment published in 1904: \"If some day they say of me that with the airbrake I contributed something to civilization, something to the safety of human life, it will be sufficient.\" \nGeorge Westinghouse remained a captain of American industry until 1907 when the financial panic of 1907 led to his resignation from control of the Westinghouse Electric company. By 1911, he was no longer active in business, and his health was in decline. Westinghouse died on March 12, 1914, in New York City at age 67. He was initially interred in Woodlawn Cemetery, Bronx, NY then removed on December 14, 1915. As a Civil War veteran, he was buried in Arlington National Cemetery, along with his wife Marguerite, who survived him by three months. She had also been initially interred in Woodlawn but removed and reinterred at the same time as George.\nHonors and awards.\nGeorge Westinghouse was deeply appreciated by his colleagues and employees. For example, Nicola Tesla, with whom he developed the AC polyphase system of electric power distribution spoke of him in 1938 as follows: \"George Westinghouse was, in my opinion, the only man on this globe who could take my alternating-current system under the circumstances then existing and win the battle against prejudice and money power. He was a pioneer of imposing stature, one of the world's true noblemen, of whom America may well be proud and to whom humanity owes an immense debt of gratitude.\"\nList of Honors and Awards adapted from Ref.\nTimeline.\nCompanies and geographical distribution.\nDuring his lifetime, the companies of George Westinghouse were widely distributed in the Pittsburgh region. Their locations, and the locations of several other major industrial enterprises, are numbered in the image and are itemized here:\nReferences.\nPatents.\nBelow is a sampling of U.S. patents for inventions by George Westinghouse. Many of the same inventions were also patented in foreign countries, including Austria, Australia, Canada, Denmark, France, Germany, Great Britain, Spain, and Switzerland. Many additional patents were filed in the names of his companies or various of his engineers. A full list of U.S. patents can be found in Ref.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "49197", "revid": "50267375", "url": "https://en.wikipedia.org/wiki?curid=49197", "title": "Antiviral drug", "text": "Medication used to treat a viral infection\nAntiviral drugs are a class of medication used for treating viral infections. Most antivirals target specific viruses, while a broad-spectrum antiviral is effective against a wide range of viruses. Antiviral drugs are a class of antimicrobials, a larger group which also includes antibiotic (also termed antibacterial), antifungal and antiparasitic drugs, or antiviral drugs based on monoclonal antibodies. Most antivirals are considered relatively harmless to the host, and therefore can be used to treat infections. They should be distinguished from virucides, which are not medication but deactivate or destroy virus particles, either inside or outside the body. Natural virucides are produced by some plants such as eucalyptus and Australian tea trees.\nMedical uses.\nMost of the antiviral drugs now available are designed to help deal with HIV, herpes viruses, the hepatitis B and C viruses, and influenza A and B viruses.\nViruses use the host's cells to replicate and this makes it difficult to find targets for the drug that would interfere with the virus without also harming the host organism's cells. Moreover, the major difficulty in developing vaccines and antiviral drugs is due to viral variation.\nThe emergence of antivirals is the product of a greatly expanded knowledge of the genetic and molecular function of organisms, allowing biomedical researchers to understand the structure and function of viruses, major advances in the techniques for finding new drugs, and the pressure placed on the medical profession to deal with the human immunodeficiency virus (HIV), the cause of acquired immunodeficiency syndrome (AIDS).\nThe first experimental antivirals were developed in the 1960s, mostly to deal with herpes viruses, and were found using traditional trial-and-error drug discovery methods. Researchers grew cultures of cells and infected them with the target virus. They then introduced into the cultures chemicals which they thought might inhibit viral activity and observed whether the level of virus in the cultures rose or fell. Chemicals that seemed to have an effect were selected for closer study.\nThis was a very time-consuming, hit-or-miss procedure, and in the absence of a good knowledge of how the target virus worked, it was not efficient in discovering effective antivirals which had few side effects. Only in the 1980s, when the full genetic sequences of viruses began to be unraveled, did researchers begin to learn how viruses worked in detail, and exactly what chemicals were needed to thwart their reproductive cycle.\nAntiviral drug targets.\nAntiviral drug design.\nThe general idea behind modern antiviral drug design is to identify viral proteins, or parts of proteins, that can be disabled. These \"targets\" should generally be as unlike any proteins or parts of proteins in humans as possible, to reduce the likelihood of side effects and toxicity. The targets should also be common across many strains of a virus, or even among different species of virus in the same family, so a single drug will have broad effectiveness. For example, a researcher might target a critical enzyme synthesized by the virus, but not by the patient, that is common across strains, and see what can be done to interfere with its operation.\nOnce targets are identified, candidate drugs can be selected, either from drugs already known to have appropriate effects or by actually designing the candidate at the molecular level with a computer-aided design program.\nThe target proteins can be manufactured in the lab for testing with candidate treatments by inserting the gene that synthesizes the target protein into bacteria or other kinds of cells. The cells are then cultured for mass production of the protein, which can then be exposed to various treatment candidates and evaluated with \"rapid screening\" technologies.\nApproaches by virus life cycle stage.\nViruses consist of a genome and sometimes a few enzymes stored in a capsule made of protein (called a capsid), and sometimes covered with a lipid layer (sometimes called an 'envelope'). Viruses cannot reproduce on their own and instead propagate by subjugating a host cell to produce copies of themselves, thus producing the next generation.\nResearchers working on such \"rational drug design\" strategies for developing antivirals have tried to attack viruses at every stage of their life cycles. Some species of mushrooms have been found to contain multiple antiviral chemicals with similar synergistic effects.\nCompounds isolated from fruiting bodies and filtrates of various mushrooms have broad-spectrum antiviral activities, but successful production and availability of such compounds as frontline antiviral is a long way away.\nViral life cycles vary in their precise details depending on the type of virus, but they all share a general pattern:\nBefore cell entry.\nOne antiviral strategy is to interfere with the ability of a virus to infiltrate a target cell. The virus must go through a sequence of steps to do this, beginning with binding to a specific \"receptor\" molecule on the surface of the host cell and ending with the virus \"uncoating\" inside the cell and releasing its contents. Viruses that have a lipid envelope must also fuse their envelope with the target cell, or with a vesicle that transports them into the cell before they can uncoat.\nThis stage of viral replication can be inhibited in two ways:\nThis strategy of designing drugs can be very expensive, and since the process of generating anti-idiotypic antibodies is partly trial and error, it can be a relatively slow process until an adequate molecule is produced.\nEntry inhibitor.\nA very early stage of viral infection is viral entry, when the virus attaches to and enters the host cell. A number of \"entry-inhibiting\" or \"entry-blocking\" drugs are being developed to fight HIV. HIV most heavily targets a specific type of lymphocyte known as \"helper T cells\", and identifies these target cells through T-cell surface receptors designated \"CD4\" and \"CCR5\". Attempts to interfere with the binding of HIV with the CD4 receptor have failed to stop HIV from infecting helper T cells, but research continues on trying to interfere with the binding of HIV to the CCR5 receptor in hopes that it will be more effective.\nHIV infects a cell through fusion with the cell membrane, which requires two different cellular molecular participants, CD4 and a chemokine receptor (differing depending on the cell type). Approaches to blocking this virus/cell fusion have shown some promise in preventing entry of the virus into a cell. At least one of these entry inhibitors\u2014a biomimetic peptide called Enfuvirtide, or the brand name Fuzeon\u2014has received FDA approval and has been in use for some time. Potentially, one of the benefits from the use of an effective entry-blocking or entry-inhibiting agent is that it potentially may not only prevent the spread of the virus within an infected individual but also the spread from an infected to an uninfected individual.\nOne possible advantage of the therapeutic approach of blocking viral entry (as opposed to the currently dominant approach of viral enzyme inhibition) is that it may prove more difficult for the virus to develop resistance to this therapy than for the virus to mutate or evolve its enzymatic protocols.\nUncoating inhibitors.\nInhibitors of uncoating have also been investigated.\nAmantadine and rimantadine have been introduced to combat influenza. These agents act on penetration and uncoating.\nPleconaril works against rhinoviruses, which cause the common cold, by blocking a pocket on the surface of the virus that controls the uncoating process. This pocket is similar in most strains of rhinoviruses and enteroviruses, which can cause diarrhea, meningitis, conjunctivitis, and encephalitis.\nSome scientists are making the case that a vaccine against rhinoviruses, the predominant cause of the common cold, is achievable.\nVaccines that combine dozens of varieties of rhinovirus at once are effective in stimulating antiviral antibodies in mice and monkeys, researchers reported in \"Nature Communications\" in 2016.\nRhinoviruses are the most common cause of the common cold; other viruses such as respiratory syncytial virus, parainfluenza virus and adenoviruses can cause them too. Rhinoviruses also exacerbate asthma attacks. Although rhinoviruses come in many varieties, they do not drift to the same degree that influenza viruses do. A mixture of 50 inactivated rhinovirus types should be able to stimulate neutralizing antibodies against all of them to some degree.\nDuring viral synthesis.\nA second approach is to target the processes that synthesize virus components after a virus invades a cell.\nReverse transcription.\nOne way of doing this is to develop nucleotide or nucleoside analogues that look like the building blocks of RNA or DNA, but deactivate the enzymes that synthesize the RNA or DNA once the analogue is incorporated. This approach is more commonly associated with the inhibition of reverse transcriptase (RNA to DNA) than with \"normal\" transcriptase (DNA to RNA).\nThe first successful antiviral, aciclovir, is a nucleoside analogue, and is effective against herpesvirus infections. The first antiviral drug to be approved for treating HIV, zidovudine (AZT), is also a nucleoside analogue.\nAn improved knowledge of the action of reverse transcriptase has led to better nucleoside analogues to treat HIV infections. One of these drugs, lamivudine, has been approved to treat hepatitis B, which uses reverse transcriptase as part of its replication process. Researchers have gone further and developed inhibitors that do not look like nucleosides, but can still block reverse transcriptase.\nAnother target being considered for HIV antivirals include RNase H\u2014which is a component of reverse transcriptase that splits the synthesized DNA from the original viral RNA.\nIntegrase.\nAnother target is integrase, which integrate the synthesized DNA into the host cell genome. Examples of integrase inhibitors include raltegravir, elvitegravir, and dolutegravir.\nTranscription.\nOnce a virus genome becomes operational in a host cell, it then generates messenger RNA (mRNA) molecules that direct the synthesis of viral proteins. Production of mRNA is initiated by proteins known as transcription factors. Several antivirals are now being designed to block attachment of transcription factors to viral DNA.\nTranslation/antisense.\nGenomics has not only helped find targets for many antivirals, it has provided the basis for an entirely new type of drug, based on \"antisense\" molecules. These are segments of DNA or RNA that are designed as complementary molecule to critical sections of viral genomes, and the binding of these antisense segments to these target sections blocks the operation of those genomes. A phosphorothioate antisense drug named fomivirsen has been introduced, used to treat opportunistic eye infections in AIDS patients caused by cytomegalovirus, and other antisense antivirals are in development. An antisense structural type that has proven especially valuable in research is morpholino antisense.\nMorpholino oligos have been used to experimentally suppress many viral types:\nTranslation/ribozymes.\nYet another antiviral technique inspired by genomics is a set of drugs based on ribozymes, which are RNA sequences with catalytic activity that will cut apart viral RNA or DNA at selected sites. In their natural course, ribozymes are used as part of the viral manufacturing sequence, but these synthetic ribozymes are designed to cut RNA and DNA at sites that will disable them.\nA ribozyme antiviral to deal with hepatitis C has been suggested, and ribozyme antivirals are being developed to deal with HIV. An interesting variation of this idea is the use of genetically modified cells that can produce custom-tailored ribozymes. This is part of a broader effort to create genetically modified cells that can be injected into a host to attack pathogens by generating specialized proteins that block viral replication at various phases of the viral life cycle.\nProtein processing and targeting.\nInterference with post translational modifications or with targeting of viral proteins in the cell is also possible.\nProtease inhibitors.\nSome viruses include an enzyme known as a protease that cuts viral protein chains apart so they can be assembled into their final configuration. HIV includes a protease, and so considerable research has been performed to find \"protease inhibitors\" to attack HIV at that phase of its life cycle. Protease inhibitors became available in the 1990s and have proven effective, though they can have unusual side effects, for example causing fat to build up in unusual places. Improved protease inhibitors are now in development.\nProtease inhibitors have also been seen in nature. A protease inhibitor was isolated from the shiitake mushroom (\"Lentinus edodes\"). The presence of this may explain the Shiitake mushrooms' noted antiviral activity \"in vitro\".\nLong dsRNA helix targeting.\nMost viruses produce long dsRNA helices during transcription and replication. In contrast, uninfected mammalian cells generally produce dsRNA helices of fewer than 24 base pairs during transcription. DRACO (double-stranded RNA activated caspase oligomerizer) is a group of experimental antiviral drugs initially developed at the Massachusetts Institute of Technology. In cell culture, DRACO was reported to have broad-spectrum efficacy against many infectious viruses, including dengue flavivirus, Amapari and Tacaribe arenavirus, Guama bunyavirus, H1N1 influenza and rhinovirus, and was additionally found effective against influenza \"in vivo\" in weanling mice. It was reported to induce rapid apoptosis selectively in virus-infected mammalian cells, while leaving uninfected cells unharmed. DRACO effects cell death via one of the last steps in the apoptosis pathway in which complexes containing intracellular apoptosis signalling molecules simultaneously bind multiple procaspases. The procaspases transactivate via cleavage, activate additional caspases in the cascade, and cleave a variety of cellular proteins, thereby killing the cell.\nAssembly.\nRifampicin acts at the assembly phase.\nRelease phase.\nThe final stage in the life cycle of a virus is the release of completed viruses from the host cell, and this step has also been targeted by antiviral drug developers. Two drugs named zanamivir (Relenza) and oseltamivir (Tamiflu) that have been recently introduced to treat influenza prevent the release of viral particles by blocking a molecule named neuraminidase that is found on the surface of flu viruses, and also seems to be constant across a wide range of flu strains.\nImmune system stimulation.\nRather than attacking viruses directly, a second category of tactics for fighting viruses involves encouraging the body's immune system to attack them. Some antivirals of this sort do not focus on a specific pathogen, instead stimulating the immune system to attack a range of pathogens.\nOne of the best-known of this class of drugs are interferons, which inhibit viral synthesis in infected cells. One form of human interferon named \"interferon alpha\" is well-established as part of the standard treatment for hepatitis B and C, and other interferons are also being investigated as treatments for various diseases.\nA more specific approach is to synthesize antibodies, protein molecules that can bind to a pathogen and mark it for attack by other elements of the immune system. Once researchers identify a particular target on the pathogen, they can synthesize quantities of identical \"monoclonal\" antibodies to link up that target. A monoclonal drug is now being sold to help fight respiratory syncytial virus in babies, and antibodies purified from infected individuals are also used as a treatment for hepatitis B.\nClassification of antivirals based on target.\nClassifying antivirals based on their target of action, the protein or process that they interact with, serves to create two broad categories of antivirals: direct-acting antivirals (DAAs) and host-targeting antivirals (HTAs).\nDirect-acting antivirals.\nThe term direct-acting antivirals (DAAs) was first coined to describe anti-hepatitis C drugs that directly targeted viral processes. When first introduced DAAs were a novel idea, distinct from prior antiviral regiments that were designed to supplement the immune system\u2019s ability to fight infection as a whole rather than directly disrupt hepatitis C virus entry and replication processes in the host cells itself. \nThese are the more effective than older treatments such as ribavirin (partially indirectly acting) and interferon (indirect acting). The DAA drugs against hepatitis C are taken orally, as tablets, for 8 to 12 weeks and the antiviral prescribed depends on the strain (genotypes) of hepatitis C virus that are causing the infection. Both during and at the end of treatment, blood tests are used to monitor the effectiveness of the treatment and subsequent cure.\nThe DAA commonly used combination drugs used to treat hepatitis C viral infections include:\nThe United States Food and Drug Administration approved DAAs on the basis of a surrogate endpoint called sustained virological response (SVR). SVR is achieved in a patient when hepatitis C virus RNA remains undetectable 12\u201324 weeks after treatment ends. Whether through DAAs or older interferon-based regimens, SVR is associated with improved health outcomes and significantly decreased mortality. For those who already have advanced liver disease (including hepatocellular carcinoma), however, the benefits of achieving SVR may be less pronounced, though still substantial.\nDespite its historical roots in hepatitis C research, the term \"direct-acting antivirals\" is currently used more broadly to describe all antiviral drugs with a target of action that is a viral protein. Commonly prescribed, FDA approved DAAs include other anti-viral drugs with a direct viral target such as aciclovir (against herpes simplex virus), letermovir (against cytomegalovirus), or AZT (against human immunodeficiency virus). Classifying drugs as DAAs serves to distinguish these antivirals from other categories of antiviral drugs such as those with an indirect mechanism of action including immune modulators like interferon alfa that are classified as host-targeting antivirals (HTAs). This difference is of particular relevance for potential drug resistance mutation development.\nHost-targeting antivirals.\nClassifying drugs as DAAs serve to distinguish these drugs from those that inhibit host proteins involved in viral infection and replication, known as host-targeting antivirals (HTAs). Many viruses utilize common processes to enter host cells and create viral replicates. Because HTAs target processes that are commonly conserved by multiple viral strains, HTAs have the potential to be used as broad spectrum antivirals (BSAs) with activity against multiple viral infections. Processes that are common targets of HTAs include viral entry into the host cell, viral replication, nuclear import and export, and viral release from the host cell.\nHTAs are attractive to physicians because they have a higher genetic barrier to resistance than DAAs. Host genomes are generally more stable than viral genomes (particularly RNA viruses that are known for their high genetic instability and rapid mutation rate) due to the presence of DNA polymerase proofreading capabilities that corrects point mutations in genetic replication. \nAntiviral drug resistance.\nAntiviral resistance can be defined by a decreased susceptibility to a drug caused by changes in viral genotypes. In cases of antiviral resistance, drugs have either diminished or no effectiveness against their target virus. The issue inevitably remains a major obstacle to antiviral therapy as it has developed to almost all specific and effective antimicrobials, including antiviral agents.\nThe Centers for Disease Control and Prevention (CDC) inclusively recommends anyone six months and older to get a yearly vaccination to protect them from influenza A viruses (H1N1) and (H3N2) and up to two influenza B viruses (depending on the vaccination). Comprehensive protection starts by ensuring vaccinations are current and complete. However, vaccines are preventative and are not generally used once a patient has been infected with a virus. Additionally, the availability of these vaccines can be limited based on financial or locational reasons which can prevent the effectiveness of herd immunity, making effective antivirals a necessity.\nThe three FDA-approved neuraminidase antiviral flu drugs available in the United States, recommended by the CDC, include: oseltamivir (Tamiflu), zanamivir (Relenza), and peramivir (Rapivab). Influenza antiviral resistance often results from changes occurring in neuraminidase and hemagglutinin proteins on the viral surface. Currently, neuraminidase inhibitors (NAIs) are the most frequently prescribed antivirals because they are effective against both influenza A and B. However, antiviral resistance is known to develop if mutations to the neuraminidase proteins prevent NAI binding. This was seen in the H257Y mutation, which was responsible for oseltamivir resistance to H1N1 strains in 2009. The inability of NA inhibitors to bind to the virus allowed this strain of virus with the resistance mutation to spread due to natural selection. Furthermore, a study published in 2009 in \"Nature Biotechnology\" emphasized the urgent need for augmentation of oseltamivir stockpiles with additional antiviral drugs including zanamivir. This finding was based on a performance evaluation of these drugs supposing the 2009 H1N1 'Swine Flu' neuraminidase (NA) were to acquire the oseltamivir-resistance (His274Tyr) mutation, which is currently widespread in seasonal H1N1 strains.\nOrigin of antiviral resistance.\nThe genetic makeup of viruses is constantly changing, which can cause a virus to become resistant to currently available treatments. Viruses can become resistant through spontaneous or intermittent mechanisms throughout the course of an antiviral treatment. Immunocompromised patients, more often than immunocompetent patients, hospitalized with pneumonia are at the highest risk of developing oseltamivir resistance during treatment. Subsequent to exposure to someone else with the flu, those who received oseltamivir for \"post-exposure prophylaxis\" are also at higher risk of resistance.\nThe mechanisms for antiviral resistance development depend on the type of virus in question. RNA viruses such as hepatitis C and influenza A have high error rates during genome replication because RNA polymerases lack proofreading activity. RNA viruses also have small genome sizes that are typically less than 30 kb, which allow them to sustain a high frequency of mutations. DNA viruses, such as HPV and herpesvirus, hijack host cell replication machinery, which gives them proofreading capabilities during replication. DNA viruses are therefore less error prone, are generally less diverse, and are more slowly evolving than RNA viruses. In both cases, the likelihood of mutations is exacerbated by the speed with which viruses reproduce, which provides more opportunities for mutations to occur in successive replications. Billions of viruses are produced every day during the course of an infection, with each replication giving another chance for mutations that encode for resistance to occur.\nMultiple strains of one virus can be present in the body at one time, and some of these strains may contain mutations that cause antiviral resistance. This effect, called the quasispecies model, results in immense variation in any given sample of virus, and gives the opportunity for natural selection to favor viral strains with the highest fitness every time the virus is spread to a new host. Recombination, the joining of two different viral variants, and reassortment, the swapping of viral gene segments among viruses in the same cell, also play a role in resistance, especially in influenza.\nAntiviral resistance has been reported in antivirals for herpes, HIV, hepatitis B and C, and influenza, but antiviral resistance is a possibility for all viruses. Mechanisms of antiviral resistance vary between virus types.\nDetection of antiviral resistance.\nNational and international surveillance is performed by the CDC to determine effectiveness of the current FDA-approved antiviral flu drugs. Public health officials use this information to make current recommendations about the use of flu antiviral medications. WHO further recommends in-depth epidemiological investigations to control potential transmission of the resistant virus and prevent future progression. As novel treatments and detection techniques to antiviral resistance are enhanced so can the establishment of strategies to combat the inevitable emergence of antiviral resistance.\nTreatment options for antiviral resistant pathogens.\nIf a virus is not fully wiped out during a regimen of antivirals, treatment creates a bottleneck in the viral population that selects for resistance, and there is a chance that a resistant strain may repopulate the host. Viral treatment mechanisms must therefore account for the selection of resistant viruses.\nThe most commonly used method for treating resistant viruses is combination therapy, which uses multiple antivirals in one treatment regimen. This is thought to decrease the likelihood that one mutation could cause antiviral resistance, as the antivirals in the cocktail target different stages of the viral life cycle. This is frequently used in retroviruses like HIV, but a number of studies have demonstrated its effectiveness against influenza A, as well. Viruses can also be screened for resistance to drugs before treatment is started. This minimizes exposure to unnecessary antivirals and ensures that an effective medication is being used. This may improve patient outcomes and could help detect new resistance mutations during routine scanning for known mutants. However, this has not been consistently implemented in treatment facilities at this time.\nPublic policy.\nUse and distribution.\nGuidelines regarding viral diagnoses and treatments change frequently and limit quality care. Even when physicians diagnose older patients with influenza, use of antiviral treatment can be low. Provider knowledge of antiviral therapies can improve patient care, especially in geriatric medicine. Furthermore, in local health departments (LHDs) with access to antivirals, guidelines may be unclear, causing delays in treatment. With time-sensitive therapies, delays could lead to lack of treatment.\nOverall, national guidelines, regarding infection control and management, standardize care and improve healthcare worker and patient safety. Guidelines, such as those provided by the Centers for Disease Control and Prevention (CDC) during the 2009 flu pandemic caused by the H1N1 virus, recommend, among other things, antiviral treatment regimens, clinical assessment algorithms for coordination of care, and antiviral chemoprophylaxis guidelines for exposed persons. Roles of pharmacists and pharmacies have also expanded to meet the needs of public during public health emergencies.\nStockpiling.\nPublic Health Emergency Preparedness initiatives are managed by the CDC via the Office of Public Health Preparedness and Response. Funds aim to support communities in preparing for public health emergencies, including pandemic influenza. Also managed by the CDC, the Strategic National Stockpile (SNS) consists of bulk quantities of medicines and supplies for use during such emergencies. Antiviral stockpiles prepare for shortages of antiviral medications in cases of public health emergencies. During the H1N1 pandemic in 2009\u20132010, guidelines for SNS use by local health departments was unclear, revealing gaps in antiviral planning. For example, local health departments that received antivirals from the SNS did not have transparent guidance on the use of the treatments. The gap made it difficult to create plans and policies for their use and future availabilities, causing delays in treatment.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49198", "revid": "1312992256", "url": "https://en.wikipedia.org/wiki?curid=49198", "title": "Reductionism", "text": "Philosophical view explaining systems in terms of smaller parts\nReductionism is any of several related philosophical ideas regarding the associations between phenomena which can be described in terms of simpler or more fundamental phenomena. It is also described as an intellectual and philosophical position that interprets a complex system as the sum of its parts, contrary to holism. Reductionism tends to focus on the small, predictable details of a system and is often associated with various philosophies like emergence, materialism, and determinism.\nDefinitions.\n\"The Oxford Companion to Philosophy\" suggests that reductionism is \"one of the most used and abused terms in the philosophical lexicon\" and suggests a three-part division:\nReductionism can be applied to any phenomenon, including objects, problems, explanations, theories, and meanings.\nFor the sciences, application of methodological reductionism attempts explanation of entire systems in terms of their individual, constituent parts and their interactions. For example, the temperature of a gas is reduced to nothing beyond the average kinetic energy of its molecules in motion. Thomas Nagel and others speak of 'psychophysical reductionism' (the attempted reduction of psychological phenomena to physics and chemistry), and 'physico-chemical reductionism' (the attempted reduction of biology to physics and chemistry). In a very simplified and sometimes contested form, reductionism is said to imply that a system is nothing but the sum of its parts.\nHowever, a more nuanced opinion is that a system is composed entirely of its parts, but the system will have features that none of the parts have (which, in essence is the basis of emergentism). \"The point of mechanistic explanations is usually showing how the higher level features arise from the parts.\"\nOther definitions are used by other authors. For example, what John Polkinghorne terms 'conceptual' or 'epistemological' reductionism is the definition provided by Simon Blackburn and by Jaegwon Kim: that form of reductionism which concerns a program of replacing the facts or entities involved in one type of discourse with other facts or entities from another type, thereby providing a relationship between them. Richard Jones distinguishes ontological and epistemological reductionism, arguing that many ontological and epistemological reductionists affirm the need for different concepts for different degrees of complexity while affirming a reduction of theories.\nThe idea of reductionism can be expressed by \"levels\" of explanation, with higher levels reducible if need be to lower levels. This use of levels of understanding in part expresses our human limitations in remembering detail. However, \"most philosophers would insist that our role in conceptualizing reality [our need for a hierarchy of \"levels\" of understanding] does not change the fact that different levels of organization in reality do have different 'properties'.\"\nReductionism does not preclude the existence of what might be termed emergent phenomena, but it does imply the ability to understand those phenomena completely in terms of the processes from which they are composed. This reductionist understanding is very different from ontological or strong emergentism, which intends that what emerges in \"emergence\" is more than the sum of the processes from which it emerges, respectively either in the ontological sense or in the epistemological sense. \nOntological reductionism.\nRichard Jones divides ontological reductionism into two: the reductionism of substances (e.g., the reduction of mind to matter) and the reduction of the number of structures operating in nature (e.g., the reduction of one physical force to another). This permits scientists and philosophers to affirm the former while being anti-reductionists regarding the latter.\nNancey Murphy has claimed that there are two species of ontological reductionism: one that claims that wholes are nothing more than their parts; and atomist reductionism, claiming that wholes are not \"really real\". She admits that the phrase \"really real\" is apparently senseless but she has tried to explicate the supposed difference between the two.\nOntological reductionism denies the idea of ontological emergence, and claims that emergence is an epistemological phenomenon that only exists through analysis or description of a system, and does not exist fundamentally.\nIn some scientific disciplines, ontological reductionism takes two forms: token-identity theory and type-identity theory. In this case, \"token\" refers to a biological process. \nToken ontological reductionism is the idea that every item that exists is a sum item. For perceivable items, it affirms that every perceivable item is a sum of items with a lesser degree of complexity. Token ontological reduction of biological things to chemical things is generally accepted.\nType ontological reductionism is the idea that every type of item is a sum type of item, and that every perceivable type of item is a sum of types of items with a lesser degree of complexity. Type ontological reduction of biological things to chemical things is often rejected.\nMichael Ruse has criticized ontological reductionism as an improper argument against vitalism.\nMethodological reductionism.\nIn a biological context, methodological reductionism means attempting to explain all biological phenomena in terms of their underlying biochemical and molecular processes.\nIn religion.\nAnthropologists Edward Burnett Tylor and James George Frazer employed some religious reductionist arguments.\nTheory reductionism.\nTheory reduction is the process by which a more general theory absorbs a special theory. It can be further divided into translation, derivation, and explanation. For example, both Kepler's laws of the motion of the planets and Galileo's theories of motion formulated for terrestrial objects are reducible to Newtonian theories of mechanics because all the explanatory power of the former are contained within the latter. Furthermore, the reduction is considered beneficial because Newtonian mechanics is a more general theory\u2014that is, it explains more events than Galileo's or Kepler's. Besides scientific theories, theory reduction more generally can be the process by which one explanation subsumes another.\nIn mathematics.\nIn mathematics, reductionism can be interpreted as the philosophy that all mathematics can (or ought to) be based on a common foundation, which for modern mathematics is usually axiomatic set theory. Ernst Zermelo was one of the major advocates of such an opinion; he also developed much of axiomatic set theory. It has been argued that the generally accepted method of justifying mathematical axioms by their usefulness in common practice can potentially weaken Zermelo's reductionist claim.\nJouko V\u00e4\u00e4n\u00e4nen has argued for second-order logic as a foundation for mathematics instead of set theory, whereas others have argued for category theory as a foundation for certain aspects of mathematics.\nThe incompleteness theorems of Kurt G\u00f6del, published in 1931, caused doubt about the attainability of an axiomatic foundation for all of mathematics. Any such foundation would have to include axioms powerful enough to describe the arithmetic of the natural numbers (a subset of all mathematics). Yet G\u00f6del proved that, for any \"consistent\" recursively enumerable axiomatic system powerful enough to describe the arithmetic of the natural numbers, there are (model-theoretically) \"true\" propositions about the natural numbers that cannot be proved from the axioms. Such propositions are known as formally undecidable propositions. For example, the continuum hypothesis is undecidable in the Zermelo\u2013Fraenkel set theory as shown by Cohen.\nIn science.\nReductionist thinking and methods form the basis for many of the well-developed topics of modern science, including much of physics, chemistry and molecular biology. Classical mechanics in particular is seen as a reductionist framework. For instance, the Solar System is understood in terms of its components (the Sun and the planets) and their interactions. Statistical mechanics can be considered as a reconciliation of macroscopic thermodynamic laws with the reductionist method of explaining macroscopic properties in terms of microscopic components, although it has been argued that reduction in physics 'never goes all the way in practice'.\nIn computer science.\nThe role of reduction in computer science can be thought as a precise and unambiguous mathematical formalization of the philosophical idea of \"theory reductionism\". In a general sense, a problem (or set) is said to be reducible to another problem (or set), if there is a computable/feasible method to translate the questions of the former into the latter, so that, if one knows how to computably/feasibly solve the latter problem, then one can computably/feasibly solve the former. Thus, the latter can only be at least as \"hard\" to solve as the former.\nReduction in theoretical computer science is pervasive in both: the mathematical abstract foundations of computation; and in real-world performance or capability analysis of algorithms. More specifically, reduction is a foundational and central concept, not only in the realm of mathematical logic and abstract computation in computability (or recursive) theory, where it assumes the form of e.g. Turing reduction, but also in the realm of real-world computation in time (or space) complexity analysis of algorithms, where it assumes the form of e.g. polynomial-time reduction. Further, in the even more practical domain of software development, reduction can be seen as the inverse of composition and the conceptual process a programmer applies to a problem in order to produce an algorithm which solves the problem using a composition of existing algorithms (encoded as subroutines, or subclasses).\nCriticism.\nFree will.\nPhilosophers of the Enlightenment worked to insulate human free will from reductionism. Descartes separated the material world of mechanical necessity from the world of mental free will. German philosophers introduced the concept of the \"noumenal\" realm that is not governed by the deterministic laws of \"phenomenal\" nature, where every event is completely determined by chains of causality. The most influential formulation was by Immanuel Kant, who distinguished between the causal deterministic framework the mind imposes on the world\u2014the phenomenal realm\u2014and the world as it exists for itself, the noumenal realm, which, as he believed, included free will. To insulate theology from reductionism, 19th century post-Enlightenment German theologians, especially Friedrich Schleiermacher and Albrecht Ritschl, used the Romantic method of basing religion on the human spirit, so that it is a person's feeling or sensibility about spiritual matters that comprises religion.\nCausation.\nMost common philosophical understandings of causation involve reducing it to some collection of non-causal facts. Opponents of these reductionist views have given arguments that the non-causal facts in question are insufficient to determine the causal facts.\nAlfred North Whitehead's metaphysics opposed reductionism. He refers to this as the \"fallacy of the misplaced concreteness\". His scheme was to frame a rational, general understanding of phenomena, derived from our reality.\nIn science.\nAn alternative term for ontological reductionism is \"fragmentalism\", often used in a pejorative sense. In cognitive psychology, George Kelly developed \"constructive alternativism\" as a form of personal construct psychology and an alternative to what he considered \"accumulative fragmentalism\". For this theory, knowledge is seen as the construction of successful mental models of the exterior world, rather than the accumulation of independent \"nuggets of truth\". Others argue that inappropriate use of reductionism limits our understanding of complex systems. In particular, ecologist Robert Ulanowicz says that science must develop techniques to study ways in which larger scales of organization influence smaller ones, and also ways in which feedback loops create structure at a given level, independently of details at a lower level of organization. He advocates and uses information theory as a framework to study propensities in natural systems. The limits of the application of reductionism are claimed to be especially evident at levels of organization with greater complexity, including living cells, neural networks (biology), ecosystems, society, and other systems formed from assemblies of large numbers of diverse components linked by multiple feedback loops.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49200", "revid": "12114272", "url": "https://en.wikipedia.org/wiki?curid=49200", "title": "Queen Elizabeth 2", "text": "British ocean liner\nQueen Elizabeth 2 (QE2) is a retired British ocean liner. Built by John Brown &amp; Company on the River Clyde in Scotland for the Cunard Line, the ship was operated as a transatlantic liner and cruise ship from 1969 to 2008. She was laid up until converted into a floating hotel in Dubai.\n\"Queen Elizabeth 2\" plied the route from her home port of Southampton, United Kingdom, to New York, United States. She served as the flagship of the line from 1969 until she was succeeded by the in 2004. \"Queen Elizabeth 2\" was designed in Cunard's offices in Liverpool and Southampton and built in Clydebank, Scotland. She was refitted with a modern diesel powerplant in 1986\u201387.\n\"Queen Elizabeth 2\" retired from active Cunard service on 27 November 2008, and was acquired by the private equity arm of Dubai World, which planned to begin conversion of the vessel to a 500-room floating hotel moored at the Palm Jumeirah, Dubai. Due to the 2008 financial crisis, the ship was laid up at Dubai Drydocks and later Mina Rashid. Subsequent conversion plans were announced in 2012 and then again by the \"Oceanic Group\" in 2013, but both plans stalled. \nThe restored QE2 opened to visitors on 18 April 2018 and today operates as a floating hotel in Dubai, managed since 2024 by French hotel chain Accor.\nDevelopment.\nBy 1957, transatlantic sea travel was becoming displaced by air transit due to its speed and low relative cost, with passenger numbers split 50:50 between them. With jets capable of spanning the ocean non-stop replacing prop planes, and the debut of the Boeing 707 and the Douglas DC-8 in 1958, the trend was rapidly increasing. Simultaneously, the aging and \"Queen Elizabeth\" were becoming increasingly expensive to operate, and both internally and externally were relics of the pre-war era.\nDespite falling passenger revenues, Cunard did not want to give up its traditional role as a provider of a North Atlantic passenger service and Royal Mail carrier, and so decided to replace the obsolete \"Queens\" with a new generation liner.\nDesignated \"Q3\" during work-up, it was projected to measure 75,000 gross register tons, have berths for 2,270 passengers, and cost about \u00a330\u00a0million.\nWork had proceeded as far as the preparation of submissions from six shipyards and applying for government financial assistance with the construction when misgivings among some executives and directors, coupled with a shareholder revolt, led to the benefits of the project being reappraised and ultimately cancelled on 19 October 1961.\nCunard decided to continue with a replacement plan but with an altered operating regime and more flexible design. Realising the decline of transatlantic trade, it was visualised that the new \"Queen\" would be dual-purpose three-class ship offering First, Cabin and Tourist passage for eight months a year on the transatlantic route, then as a cruise ship in warmer climates and during the winter months.\nCompared with the older Queens, which had two engine rooms and four propellers, the newly designated \"Q4\" would be much smaller, with one boiler room, one engine room, and two propellers, which combined with automation would allow a smaller engineering complement. Producing 110,000 shp, the new ship was to have the same service speed as her predecessors, while consuming half the fuel. A reduction to 520 tons per 24 hours was estimated to save Cunard \u00a31\u00a0million annually. Able to transit both the Panama and Suez canals, her shallower draught of would allow her to enter more and smaller ports than the old ships, particularly in tropical waters.\nDesign.\nThe interior and superstructure for the \"QE2\" was designed by James Gardner. The result was described by The Council of Industrial Design as that of a \"very big yacht\" and with a \"look [that was] sleek, modern and purposeful\".\nCharacteristics.\nAs built, \"QE2\" had a gross tonnage of \u00a0GRT, was long, and had a top speed of with steam turbines; this was increased to when the vessel was re-engined with the diesel-electric powerplant. At the time of retirement, the ship had a gross tonnage of 70,327.\nHull.\nThe hull was of welded steel plates, which avoided the weight penalty of over ten million rivets and overlappeding of historic ship construction, and was fitted with a modern bulbous bow.\nSuperstructure.\nLike both and , \"QE2\" had a flared stem and clean forecastle.\nWhat was controversial at the time was that Cunard decided not to paint the funnel with the line's distinctive colour and pattern, something that had been done on all its merchant vessels since Cunard's first vessel, the , sailed in 1840. Instead, the funnel was painted white and black, with the Cunard orange-red appearing only on the inside of the wind scoop. This practice ended in 1983 when \"QE2\" returned from service in the Falklands War, and the funnel was repainted in traditional Cunard orange and black, with black horizontal bands, known as \"hands\".\nThe original narrow funnel was rebuilt larger during her 1986 refurbishment in Bremerhaven, using steel panels from the original, when the ship was converted from steam to diesel power.\nLarge quantities of weight-saving aluminium were used in the framing and cladding of \"QE2\"'s superstructure in place of steel. Reducing the draft of the ship lowered fuel consumption, but invited electrochemical corrosion where dissimilar metals are joined together, prevented by using a jointing compound. The low melting point of aluminium caused concern when \"QE2\" was serving as a troopship during the Falklands War, with some fearing that if the ship were struck by a missile her upper decks would collapse quickly due to fire.\nIn 1972, the first penthouse suites were added in an aluminium structure on Signal Deck and Sports Deck (now \"Sun Deck\"), behind the ship's bridge, and in 1977 this structure was expanded to include more suites with balconies, making \"QE2\" one of the first ships to offer private terraces to passengers since \"Normandie\" in the 1930s. Her balcony accommodation was expanded for the final time when her funnel was widened during the 1986/87 overhaul. \n\"QE2\"'s final structural changes included the reworking of the aft decks during the 1994 refit, following the removal of the magrodome, and the addition of an undercover area on Sun Deck during the 2005 refit outfitted as the Funnel Bar.\nInteriors.\n\"Queen Elizabeth 2\"'s interior configuration was originally designed for segregated two-class Atlantic crossings. It was laid out in a horizontal fashion, similar to \"France\", where the spaces dedicated to the two classes were spread on specific decks, in contrast to the deck-spanning vertical class divisions of older liners. Where \"QE2\" differed from \"France\" in having only two classes of service, with the upper deck dedicated to tourist class and the quarter deck beneath it to first-class. Each had its own main lounge.\nAnother modern variation was providing tourist class with a grand two-story main ballroom, called the Double Room (later the Grand Lounge), created by opening a well in the deck between what were to have been the second and third class lounges in the ship's original three class design. This too was unconventional in that it designated a grander space for tourist class passengers than first class, who gathered in the standard height Queen's Room. The First-class was given the theatre balcony on Boat Deck, and tourist class the orchestra level on Upper Deck.\nOver the span of her thirty-nine-year seagoing career, \"QE2\" received a number of interior refits and alterations.\nThe year \"QE2\" entered service, 1969, Apollo 11 landed on the Moon, the Concorde prototype was unveiled, and the Boeing 747 first took flight. In keeping with those technology influenced times, Cunard abandoned the Art Deco interiors of the previous \"Queens\" in favor of everyday modern materials like laminates, aluminium and Perspex. The public rooms featured glass, stainless steel, dark carpeting and sea green leather. Furniture was modular, and abstract art was used throughout public rooms and cabins.\nDennis Lennon was responsible for co-ordinating the interior design, assisted by Jon Bannenberg and Gaby Schreiber; his original designs only remained intact for three years.\nThe Midships Lobby on Two Deck, where first-class passengers boarded for transatlantic journeys and all passengers boarded for cruises, was a circular room with a sunken seating area in the centre with green leather-clad banquettes surrounded by a chrome railing. In the centre was a flared, white, trumpet-shaped, lighted column.\nThe Theatre Bar on Upper Deck featured red chairs, red drapes, a red egg crate fibreglass screen, and even a red baby grand piano. Some more traditional materials like wood veneer were used as highlights throughout the ship, especially in passenger corridors and staterooms. There was also an Observation Bar on Quarter Deck, a successor to its namesake, located in a similar location, on both previous \"Queens\", which offered views through large windows over the ship's bow. The \"QE2\"'s 1972 refit plated over the windows and turned the room into galley space.\nAlmost all of the remaining original decor was replaced in the 1994 refit, with Cunard opting to use the line's traditional ocean liners as inspiration. The green velvet and leather Midships Bar became the Art Deco inspired Chart Room, receiving an original, custom-designed piano from \"Queen Mary\". The (by then) blue dominated Theatre Bar was transformed into the traditional Edwardian-themed Golden Lion Pub.\nSome original elements were retained, including the flared columns in the Queen's Room and Mid-Ships Lobby. The Queen's Room's indirect ceiling lighting was replaced with uplighters which reversed the original light airy effect by illuminating the lowered ceiling and leaving shadows in the ceiling's slot.\nBy the time of \"QE2's\" retirement, the ship's synagogue was the only room that had remained unaltered since 1969. However it was reported that during \"QE2\"'s 22 October five-night voyage, the synagogue was dismantled and removed from the ship before her final sailing to Dubai.\nArtwork and artefacts.\nThe designers included numerous pieces of artwork within the public rooms of the ship, as well as maritime artefacts drawn from Cunard's long history of operating merchant vessels.\nAlthea Wynne's sculpture of the \"White Horses\" of the Atlantic Ocean was installed in the Mauretania Restaurant. Two bronze busts were installed\u2014one of Sir Samuel Cunard outside the Yacht Club, and one of Queen Elizabeth II in the Queen's Room. Four life-size statues of human forms\u2014created by sculptor Janine Janet in marine materials like shell and coral, representing the four elements\u2014were installed in the Princess Grill. A frieze designed by Brody Nevenshwander, depicting the words of T. S. Eliot, Sir Francis Drake, and John Masefield, was in the Chart Room. The Midships Lobby housed a solid silver model of \"Queen Elizabeth 2\" made by Asprey of Bond Street in 1975, which was lost until a photograph found in 1997 led to the discovery of the model itself. It was placed on \"Queen Elizabeth 2\" in 1999.\nThree custom-designed tapestries were commissioned from Helena Hernmarck for the ship's launch, depicting the Queen as well as the launch of the ship. These tapestries were originally hung in the Quarter Deck \"D\" Stairway, outside the Columbia Restaurant. They were originally made with golden threads, but much of this was lost when they were incorrectly cleaned during the 1987 refit. They were subsequently hung in the \"E\" stairway and later damaged in 2005.\nThere are numerous photographs, oils, and pastels of members of the Royal Family throughout the vessel.\nThe ship also housed items from previous Cunard ships, including both a brass relief plaque with a fish motif from the first and an Art-Deco bas-relief titled \"Winged Horse and Clouds\" by Norman Foster from . There were also a vast array of Cunard postcards, porcelain, flatware, boxes, linen, and Lines Bros Tri-ang Minic model ships. One of the key pieces was a replica of the figurehead from Cunard's first ship , carved from Quebec yellow pine by Cornish sculptor Charles Moore and presented to the ship by Lloyd's of London.\nOn the Upper Deck sits the silver Boston Commemorative Cup, presented to \"Britannia\" by the City of Boston in 1840. This cup was lost for decades until it was found in a pawn shop in Halifax, Nova Scotia. On \"2\" Deck was a bronze entitled \"Spirit of the Atlantic\" that was designed by Barney Seale for the second . A large wooden plaque was presented to \"Queen Elizabeth 2\" by First Sea Lord Sir John Fieldhouse to commemorate the ship's service as a Hired Military Transport (HMT) in the Falklands War.\nThere was also an extensive collection of large-scale models of Cunard ships located throughout \"Queen Elizabeth 2\".\nOver the years the ship's collection was added to. Among those items was a set of antique Japanese armour presented to \"Queen Elizabeth 2\" by the Governor of Kagoshima, Japan, during her 1979 world cruise, as was a Wedgwood vase presented to the ship by Lord Wedgwood.\nThroughout the public areas were also silver plaques commemorating the visits of every member of the Royal Family, as well as other dignitaries such as South African president Nelson Mandela.\nIstithmar acquired most of these items from Cunard when it bought \"QE2\".\nCrew accommodation.\nThe majority of the crew were accommodated in two- or four-berth cabins, with showers and toilets at the end of each alleyway. These were located forward and aft on decks three to six. At the time she entered service, the crew areas were a significant improvement over those aboard and ; however the ship's age and the lack of renovation of the crew area during her 40 years of service, in contrast to passenger areas, which were updated periodically, meant that this accommodation was considered basic by the end of her career. Officers were accommodated in single cabins with private in-suite bathrooms located on Sun Deck.\nThere were six crew bars, the main four were split into the Senior Rates Recreation Rooms on Deck 2 and the Junior Rates on Deck 3, with Deck and Engine Departments on the port side and Hotel on the starboard side of the ship. The Female crew recreation room was on Deck 1 next to their dedicated mess room. Over time the Deck &amp; Engine Ratings Room became The Petty Officers Club and then the Fo'c'sle Club when the British Deck and Engine crew were changed to Filipino crew. The Hotel Senior Rates room became a crew gym. The Junior Rates Rooms on Deck 3 were the main crew bars and were called \"The Pig &amp; Whistle\". (\"The 2 deck Pig\" and three deck pig, for short and a tradition aboard Cunard ships) and Castaways on the starboard side. After the expansion of female crew following the conversion to diesel power, the female-only recreation and mess room became a crew library and later the crew services office. The final bar on Deck 6 aft was small and in a former crew launderette so it was called the Dhobi Arms, a hang out for the Liverpool crew but was closed in the late '80s. A bar, dedicated for the officers, is located at the forward end of Boat Deck. Named \"The Officers Wardroom\", this area enjoyed forward-facing views and was often opened to passengers for cocktail parties hosted by the senior officers. The crew mess was situated at the forward end of One Deck, adjacent to the crew services office.\nMachinery.\n\"Queen Elizabeth 2\" was originally fitted out with a steam turbine propulsion system using three Foster Wheeler E.S.D II boilers, which provided steam for the two Brown-Parsons turbines. The turbines were rated with a maximum power output figure of (normally operating at ) and coupled via double-reduction gearing to two six-bladed fixed-pitch propellers.\nThe steam turbines were plagued with problems from the time the ship first entered service and, despite being technically advanced and fuel-efficient in 1968, her consumption of 600 tons of fuel oil every twenty-four hours was more than expected for such a ship by the 1980s. After seventeen years of service, the availability of spare parts was becoming difficult due to the outdated design of the boilers and turbines and the constant use of the machinery which was mainly due to Cunard's cost-saving deletion of the originally planned 4th boiler while the ship was still on the drawing board.\nThe shipping company decided that the options were to either do nothing for the remainder of the ship's life, re-configure the existing engines, or completely re-engine the vessel with a modern, more efficient and more reliable diesel-electric powerplant. Ultimately it was decided to replace the engines, as it was calculated that the savings in fuel costs and maintenance would pay for themselves over four years while giving the vessel a minimum of another twenty years of service, whereas the other options would only provide short-term relief. Her steam turbines had taken her to a record-breaking total of 2,622,858 miles in 18 years.\nDuring the ship's 1986 to 1987 refit, the steam turbines were removed and replaced with nine German MAN 9L58/64 nine-cylinder, medium-speed diesel engines, each weighing approximately 120 tons. Using a diesel-electric configuration, each engine drives a generator, each developing 10.5 MW of electrical power at 10,000 volts. This electrical plant, in addition to powering the ship's auxiliary and hotel services through transformers, drives the two main propulsion motors, one on each propeller shaft. These motors produce 44 MW each and are of synchronised salient-pole construction, nine metres in diameter and weighing more than 400 tons each.\nThe ship's service speed of was now maintained using only seven of the diesel-electric sets. The maximum power output with the new engine configuration running increased to 130,000\u00a0hp, which was greater than the previous system's 110,000\u00a0hp. Using the same IBF-380 (Bunker C) fuel, the new configuration yielded a 35% fuel saving over the previous system. During the re-engining process, her funnel was modified into a wider one to accommodate the exhaust pipes for the nine MAN diesel engines.\nDuring the refit, the original fixed-pitch propellers were replaced with variable-pitch propellers. The old steam propulsion system required astern turbines to move the ship backward or stop her moving forward. The pitch of the new variable pitch blades could simply be reversed, causing a reversal of propeller thrust while maintaining the same direction of propeller rotation, allowing the ship shorter stopping times and improved handling characteristics.\nThe new propellers were originally fitted with \"Grim Wheels\", named after their inventor, Dr. Ing Otto Grim. These were free-spinning propeller blades fitted behind the main propellers, with long vanes protruding from the centre hub. The Grim Wheels were designed to recover lost propeller thrust and reduce fuel consumption by 2.5 to 3%. After the trial of these wheels, when the ship was drydocked, the majority of the vanes on each wheel were discovered to have broken off. The wheels were removed and the project was abandoned.\nOther machinery includes nine heat recovery boilers, coupled with two oil-fired boilers to produce steam for heating fuel, domestic water, swimming pools, laundry equipment, and galleys. Four flash evaporators and a reverse-osmosis unit desalinate seawater to produce 1000 tons of freshwater daily. There is also a sanitation system and sewage disposal plant, air conditioning plant, and an electro-hydraulic steering system.\nConstruction.\nOn 30 December 1964, Cunard placed an order for construction of the new ship with John Brown and Company, who would build it at their shipyard in Clydebank, Scotland. The agreed price was \u00a325,427,000 (equal to \u00a3 today) provision for escalation of labour and materials increases, with an agreed delivery date of May 1968. To assist with its construction the British government provided financial assistance to Cunard in the form of a \u00a317.6\u00a0million loan at 4.5% interest.\nThe keel was laid down on 5 July 1965, as hull number 736 on the same slipway where previous Cunard liners such as , , \"Queen Mary\", and \"Queen Elizabeth\" had been constructed.\nThe ship was launched and named on 20 September 1967 by Queen Elizabeth II, using the same pair of gold scissors her mother and grandmother used to launch \"Queen Elizabeth\" and \"Queen Mary\", respectively. After the bottle of champagne was smashed the \"QE2\" stayed put on the slipway for 90 seconds before being let free. In a break with tradition, Cunard declined to give the ship royal mail status. \nName.\nAuthorities disagree over whether the ship's namesake is the monarch Elizabeth II or the liner \"Queen Elizabeth\". During the naming and launching ceremony on 20 September 1967, the monarch clearly and verbally states the name of the ship is \"Queen Elizabeth the Second\". However, the written form of ship is \"Queen Elizabeth 2\", (Queen Elizabeth Two), not the \"Queen Elizabeth II\" (Queen Elizabeth the Second) formal title used by the monarch. It is likely that Her Majesty misinterpreted the written numeral \"2\" as the Roman numeral \"II\".\nForm of name.\nThe name of the liner as it appears on the bow and stern is \"Queen Elizabeth 2\", with upper- and lower-case lettering and an Arabic numeral 2 as opposed to the Roman numeral II, distinguishing her from the monarch, Elizabeth II; it is commonly pronounced in speech as \"Queen Elizabeth Two\". Soon after launching, the name was shortened in common use as \"QE2\".\nBackground.\n\"Queen Mary\", in 1934, and \"Queen Elizabeth\", in 1938, were both named by and for contemporary spouses of reigning monarchs: Mary of Teck and Elizabeth Bowes-Lyon, respectively. These two previous Cunarders both had capitalised bow names, as \"QUEEN MARY\" and \"QUEEN ELIZABETH\".\nCunard practice at the time of naming \"QE2\" was to re-use the existing name of its former ships, for example, launching in 1938 after the previous was scrapped in 1935.\nThe original \"Queen Elizabeth\" was still in service with Cunard when \"QE2\" was launched in 1967, although she was retired and sold before \"QE2\" entered revenue service with Cunard in 1969.\nThe addition of a \"2\" in this manner was unknown at the time, but it was not unknown for Roman numerals to denote ships in service with the same name. Two non-Cunard ships were named \"Queen Mary II\": a Clyde steamer, and \"Mauretania II\", a Southampton steamer of Red Funnel, since the Cunard ships already had the names without Roman numerals.\nLaunch.\nAs was Cunard practice at the time, the name of the liner was not to be publicly revealed until the launch. Dignitaries were invited to the \"Launch of Cunard Liner No. 736\", as no name had yet been painted on the bow.\nThe Queen launched the ship with the words \"I name this ship \"Queen Elizabeth the Second\",\" the normal short form of address of the monarch, Elizabeth II herself.\nThe following day, the \"New York Times\" and \"The Times\" of London printed the name as \"Queen Elizabeth II\", the short form of written style of the monarch. However, when the liner left the shipyard in 1968 she bore the name \"Queen Elizabeth 2\" on her bow, and has continued to do so ever since.\n1969 authorised history.\nIn an authorised history of \"Queen Elizabeth 2\" published in 1969, various explanations of events occur.\nThese state that, as at the launch ceremony, an envelope and card were also held in New York in case of transmission failure, and when opened the card was found to read the name Queen Elizabeth, and that the decision to add \"The Second\" to the name was an alteration by the Queen. The book quotes the Cunard chairman Sir Basil Smallpeice as saying \"The \"Queen Mary\" [named] after her Grandmother, the \"Queen Elizabeth\" after her mother, and now this magnificent ship after herself.\"\nFollowing the unexpected addition of \"the Second\" by the Queen, the book attributes the use of upper and lower case lettering and a numeric \"2\"\u00a0\u2013 rather than a Roman \"II\"\u00a0\u2013 to the decision by Cunard to use a more modern typeface to suit the style of the 1960s. The book also surmises that the naming of the liner after the reigning monarch, in the form Queen Elizabeth II, was potentially offensive to some Scots, as the title of Queen Elizabeth II (of the United Kingdom) relates to the lineage of the throne of England and Ireland (the Tudor monarch Elizabeth I having reigned only in England and Ireland).\nRon Warwick, former captain.\nIn a later account by Ronald Warwick, who was the son of William \"Bil\" Warwick and the first master of \"QE2\", Warwick junior (himself later in his Cunard career a master of the \"QE2\" and latterly the first captain of \"QM2\") supports the account that the Queen initiated the surprise move of naming the liner after herself rather than simply Queen Elizabeth as had originally been planned (the name having been made vacant by the retirement of the current liner before the new one was commissioned). The name had been given to the Queen in a sealed envelope which she didn't open. The book, referencing his autobiography, states that the Cunard chairman Sir Basil Smallpeice was delighted with this development, it being in keeping with the previous Queen liners, and the 2 was added by Cunard for differentiation of the ship while still denoting it was named after the Queen.\nCunard website.\nFrom at least 2002 the official Cunard website stated that \"The new ship is not named after the Queen but is simply the second ship to bear the name\u00a0\u2013 hence the use of the Arabic 2 in her name, rather than the Roman II used by the Queen\", however, in late 2008 this information had been removed due to the ship's retirement.\nOther accounts.\nOther later accounts repeat the position that Cunard originally intended to name the ship \"Queen Elizabeth\" and the addition of a 2 by the Queen was a surprise to Cunard, in 1990 and 2008, although two books by William H. Miller state that Queen Elizabeth 2 was the name agreed on before the launch between Cunard officials and the Queen.\nAccounts that repeat the position that \"QE2\" was not named after the reigning monarch have been published in 1991, 1999, 2004, 2005, and 2008. In 2008, \"The Telegraph\" goes further to state the ship is named not only as the second ship named \"Queen Elizabeth\", but is specifically named after the wife of King George VI. In contradiction however, some modern accounts continue to publish that the \"QE2\" was named after the reigning monarch, in 2001 and 2008. There is a gilded bust that stands in the ship's queen's room depicting Queen Elizabeth II, not her mother.\nDelivery.\nAs construction continued on the new ship, Cunard found itself in increasing financial difficulties as increased competition from airlines resulted in the company's passenger ships losing money. With profits from its cargo ships eventually unable to offset the losses, Cunard was forced to sell \"Mauretania\", \"Sylvania\", \"Carinthia\", \"Caronia\", \"Queen Mary\" and \"Queen Elizabeth\" between 1965 and 1968. Income also fell due to a seven-week-long seamens' strike in 1966. Then John Brown advised that the delivery would be delayed by six months, which meant the ship would miss the 1968 peak summer transatlantic season. Following market research, Cunard decided to take advantage of the delay to change the original three-class configuration of the ship to a more flexible two-class arrangement of First and Tourist.\nOn 20 September 1967 with the launch date approaching, Cunard (having lost \u00a37.5\u00a0million the previous year) approached the government with a request for an additional \u00a33\u00a0million loan to complete the ship. Eventually the government agreed to increase the original \u00a317.6\u00a0million loan up to \u00a324\u00a0million.\nOn 19 November 1968, she left John Brown's fitting-out berth. Several industrial disputes with the Clydebank workers, with their resultant delays and quality issues, forced Cunard to transfer the ship to Southampton, where Vosper Thorneycroft completed the installation and commissioning work, prior to the sea trials.\nSea trials began on 26 November 1968 in the Irish Sea, proceeding to speed trials off the Isle of Arran.\nCunard initially refused to accept the ship, as the sea trials identified that the ship suffered from a resonant vibration which was traced to a design flaw in the blades of the steam turbines. This delayed her being handed over to her new owners until 18 April 1969. She then departed on a \"shakedown cruise\" to Las Palmas on 22 April 1969.\nService.\nEarly career.\n\"Queen Elizabeth 2\"'s maiden voyage, from Southampton to New York, commenced on 2 May 1969, taking 4 days, 16 hours, and 35 minutes, at an average speed of 28.02 knots. Upon her arrival to New York Harbour, she was greeted by two Royal Air Force Harrier jets that hovered on each side of the ship. The Harriers were in New York City at the time competing in the Daily Mail Trans-Atlantic Air Race.\nIn 1971, she participated in the rescue of some 500 passengers from the burning French Line ship .\nLater that year on 5 March \"QE2\" was disabled for four hours when jellyfish were sucked into and blocked her seawater intakes.\nOn 17 May 1972, while travelling from New York to Southampton, she was the subject of a bomb threat. She was searched by her crew, and a combined Special Air Service and Special Boat Service team which parachuted into the sea to conduct a search of the ship. No bomb was found, but the hoaxer was arrested by the FBI.\nThe following year \"QE2\" undertook two chartered cruises through the Mediterranean to Israel in commemoration of the 25th anniversary of the state's founding. The ship's Columbia Restaurant was koshered for Passover, and Jewish passengers were able to celebrate Passover on the ship. According to the book \"The Angel\" by Uri Bar-Joseph, Muammar Gaddafi ordered a submarine to torpedo her during one of the chartered cruises in retaliation for Israel's downing of Libyan Flight 114, but Anwar Sadat intervened secretly to foil the attack.\nOn 1 April 1974, the ship suffered power failure due to boiler trouble on a cruise from New York to Puerto Rico and the Virgin Islands. Passengers were transferred on to the Sea Venture to Bermuda. Among the passengers on board were Kansas City Chiefs head coach Hank Stram and Sonny Jurgensen of the Washington Redskins, attending a football themed cruise.\nShe continued the Cunard tradition of regular scheduled transatlantic crossings every year of her service life, crossing on an opposite and symbiotic summer schedule with the CGT's famous between 1961 and 1974. Upon the withdrawal of competing SS \"France\" from service in 1974, \"QE2\" became the largest operational passenger ship in the world for a few years, until the \"France\" was returned to service as in 1980.\nOn 23 July 1976 while the ship was 80 miles off the Scilly Isles on a transatlantic voyage, a flexible coupling drive connecting the starboard main engine high-pressure rotor and the reduction gearbox ruptured. This allowed lubricating oil under pressure to enter into the main engine room where it ignited, creating a severe fire. It took 20 minutes to bring the fire under control. Reduced to two boilers, \"QE2\" limped back to Southampton. Damage from the fire resulted in a replacement boiler having to be fitted by dry-docking the ship and cutting an access hole in her side.\nBy 1978 \"QE2\" was breaking even with an occupancy of 65%, generating revenues of greater than \u00a330\u00a0million per year against which had to be deducted an annual fuel cost of \u00a35\u00a0million and a monthly crew cost of \u00a3225,000. With it costing \u00a380,000 a day for her to sit idle in port, her owners made every attempt to keep her at sea and full of passengers. As a result, as much maintenance as possible was undertaken while at sea. However, she needed all three of her boilers to be in service if she was to maintain her transatlantic schedule. With limited ability to maintain her boilers, reliability was becoming a serious issue.\nBetween the late 1970s and early 1980s, the ship was testing a new ablative anti-fouling type paint for the Admiralty which was only available in blue. When they finally made the paint available in different colours they returned \"QE2\" anti-fouling paint to the traditional red colour.\nFalklands War.\nOn 3 May 1982, she was requisitioned by the British government for service as a troop carrier in the Falklands War.\nIn preparation for war service, Vosper Thornycroft commenced in Southampton on 5 May 1982 the installation of two helicopter pads, the transformation of public lounges into dormitories, the installation of fuel pipes that ran through the ship down to the engine room to allow for refuelling at sea, and the covering of carpets with 2,000 sheets of hardboard. A quarter of the ship's length was reinforced with steel plating, and an anti-magnetic coil was fitted to combat naval mines. Over 650 Cunard crew members volunteered for the voyage, to look after the 3,000 members of the Fifth Infantry Brigade, which the ship transported to South Georgia.\nOn 12 May 1982, with only one of her three boilers in operation, the ship departed Southampton for the South Atlantic, carrying 3,000 troops and 650 volunteer crew. The remaining boilers were brought back into service as she steamed south.\nDuring the voyage, the ship was blacked out and the radar switched off to avoid detection, steaming on without modern aids.\n\"QE2\" returned to the UK on 11 June 1982, where she was greeted in Southampton Water by Queen Elizabeth The Queen Mother on board . Peter Jackson, the captain of the ocean liner, responded to the Queen Mother's welcome: \"Please convey to Her Majesty Queen Elizabeth our thanks for her kind message. Cunard's \"Queen Elizabeth 2\" is proud to have been of service to Her Majesty's Forces.\" The ship underwent conversion back to passenger service, with her funnel being painted in the traditional Cunard orange with black stripes, which are known as \"hands\", for the first time, during the refit the hull's exterior a decision was made to repaint the hull in a light pebble grey. The ship returned to service on 7 August 1982.\nThe new colour scheme proved unpopular with passengers, as well as difficult to maintain, so the hull reverted to traditional colours in 1983. Later that year, \"QE2\" was fitted with a magrodome over her quarterdeck pool.\nDiesel era and Project Lifestyle.\n\"QE2\" once again experienced mechanical problems following her annual overhaul in November 1983. Boiler problems caused Cunard to cancel a cruise, and, in October 1984, an electrical fire caused a complete loss of power. The ship was delayed for several days before power could be restored. Instead of replacing the \"QE2\" with a newer vessel, Cunard decided that it was more prudent to simply make improvements to her. Therefore, from 27 October 1986 to 25 April 1987, \"QE2\" underwent one of her most significant refurbishments when she was converted by Lloyd Werft at their shipyard in Bremerhaven, Germany from steam power to diesel. Nine MAN B&amp;W diesel-electric engines, new propellers and a heat recovery system (to use heat expelled by the engines) were fitted, which halved the fuel consumption. With this new propulsion system, \"QE2\" was expected to serve another 20 years with Cunard. The passenger accommodation was also modernised. The refurbishment cost over \u00a3100\u00a0million.\nOn 7 August 1992, the underside of the hull was extensively damaged when she ran aground south of Cuttyhunk Island near Martha's Vineyard, while returning from a five-day cruise to Halifax, Nova Scotia along the east coast of the United States and Canada. A combination of her speed, an uncharted shoal, overestimating the height of tide and underestimating the increase in the ship's draft due to the effect of squat led to the ship's hull scraping rocks on the ocean floor. The accident resulted in the passengers disembarking earlier than scheduled at nearby Newport, Rhode Island, and the ship being taken out of service while temporary repairs were made in drydock at Boston. Several days later, divers found the red paint from the keel on previously uncharted rocks where the ship struck the bottom.\nBy the mid-1990s, it was decided that \"QE2\" was due for a new look and in 1994 the ship was given a multimillion-pound refurbishment in Hamburg code-named Project Lifestyle.\nOn 11 September 1995, \"QE2\" encountered a rogue wave, estimated at , caused by Hurricane Luis in the North Atlantic Ocean about south of eastern Newfoundland. One year later, during her twentieth world cruise, she completed her four millionth mile. The ship had sailed the equivalent of 185 times around the planet.\n\"QE2\" celebrated the 30th anniversary of her maiden voyage in Southampton in 1999. In three decades she had 1,159 voyages, sailed and carried over two million passengers.\nLater years.\nFollowing the 1998 acquisition of the Cunard Line by Carnival Corporation, in 1999 \"QE2\" was given a US$30\u00a0million refurbishment which included refreshing various public rooms, and a new colour palette in the passenger cabins. The Royal Promenade, which formerly housed upscale shops such as Burberry, H. Stern and Aquascutum, were replaced by boutiques typical of cruise ships, selling perfumes, watches and logo items. During this refit, the hull was stripped to bare metal, and the ship repainted in the traditional Cunard colours of matte black (Federal Grey) with a white superstructure.\nIn 2002 the ship narrowly avoided a major flooding incident after a corroded pipe failed in her aft engine room.\nOn 29 August 2002, \"Queen Elizabeth 2\" became the first merchant ship to sail more than 5 million nautical miles at sea.\nIn 2004, the vessel stopped plying the traditional transatlantic route and began full-time cruising, the transatlantic route having been assigned to Cunard's new flagship, . However, \"Queen Elizabeth 2\" still undertook an annual world cruise and regular trips around the Mediterranean. By this time, she lacked the amenities to rival newer, larger cruise ships, but she still had unique features such as her ballrooms, hospital, and 6,000-book library. \"QE2\" remained the fastest cruise ship afloat (28.5 knots), with fuel economy at this speed at 49.5\u00a0ft to the gallon (4 m/L). While cruising at slower speeds efficiency was improved to 125\u00a0ft per gallon (10 m/L).\nOn 5 November 2004, \"Queen Elizabeth 2\" became Cunard's longest serving express liner, surpassing 's 35 years, while on 4 September 2005, during a call to the port of Sydney, Nova Scotia, \"QE2\" became the longest serving Cunarder, surpassing 's record.\nAt the end of her 2005 world cruise, some pieces of her artwork were damaged when some crew members who had become inebriated at an on-board crew party, went on a vandalism rampage through the public areas of the ship. A unique tapestry of \"Queen Elizabeth 2\", commissioned for the launch of the ship, was thrown overboard by a drunken crewman. An oil painting of Queen Elizabeth II and two other tapestries were also damaged, along with a part of the entertainment area and a lifeboat. The crew members involved were dismissed from service.\nOn 20 February 2007 \"Queen Elizabeth 2\", while on her annual world cruise, met her running mate and successor flagship \"QM2\" (herself on her maiden world cruise) in Sydney Harbour, Australia. This was the first time two Cunard \"Queens\" had been together in Sydney since the original \"Queen Mary\" and \"Queen Elizabeth\" served as troop ships in 1941.\nRetirement announcement.\nOn 18 June 2007, Cunard announced that \"QE2\" had been bought by the Dubai investment company Istithmar for $100\u00a0million. Her retirement, in part, was forced by the oncoming June 2010 implementation of the International Convention for the Safety of Life at Sea (SOLAS) regulations, which would have forced large and expensive structural changes to the ship.\nRetirement and final Cunard voyage.\nIn a ceremonial display before her retirement, \"Queen Elizabeth 2\" met and \"Queen Mary 2\" near the Statue of Liberty in New York Harbor on 13 January 2008, with a celebratory fireworks display; \"Queen Elizabeth 2\" and \"Queen Victoria\" had made a tandem crossing of the Atlantic for the meet. This marked the first time three \"Cunard Queens\" had been present in the same location. (Cunard stated this would be the last time these three particular ships would meet, due to the impending retirement of \"Queen Elizabeth 2\". However, due to a change in \"QE2\"'s schedule, the three ships met again in Southampton on 22 April 2008.)\n\"QE2\" shared the harbour at Zeebrugge with \"Queen Victoria\" on 19 July 2008, where the two Cunarders exchanged whistle blasts.\nOn 3 October 2008, \"QE2\" set off from Cork for Douglas Bay on her farewell tour of Ireland and Britain, before heading for Liverpool. She left Liverpool and arrived in Belfast on 4 October 2008, before moving to Greenock the next day (the ship's height with funnel makes it impossible to pass under the Erskine Bridge so Clydebank is not reachable). There she was escorted by Royal Navy destroyer and visited by . The farewell was viewed by large crowds and concluded with a firework display. \"QE2\" then sailed around Scotland to the Firth of Forth on 7 October 2008, where she anchored in the shadow of the Forth Bridge. The next day, following an RAF flypast, she left amidst a flotilla of small craft to head to Newcastle upon Tyne, before returning to Southampton.\nFinal transatlantic crossings.\n\"QE2\" completed her final Atlantic crossings in tandem with her successor, \"QM2\". The ships departed for the final westbound crossing from Southampton on 10 October, sailing tandem and arriving in New York City one final time on 16 October. The Queen Mary 2 docked at the Brooklyn cruise terminal, while the QE2 docked in Manhattan. The two liners departed New York on 16 October for the final eastbound crossing, arriving in Southampton on 22 October. This marked the end of \"QE2\"'s transatlantic voyages.\nFinal voyage.\nOn her final arrival into Southampton, \"QE2\" (on 11 November 2008, with 1,700 passengers and 1,000 crew on board) ran aground in the Solent near the Southampton Water entrance at 5.26\u00a0am, on a triangular sandbank roughly equidistant between the mouth of Southampton Water and East Cowes named Bramble Bank. BBC reported \"Cunard has confirmed it touched the bottom at the Brambles Turn sandbank (sandback) near Calshot, Southampton Water, with three tugs attached to her stern (0530 GMT). A fourth tug secured a line to the ship's bow.\" Solent Coastguard stated: \"Five tugs were sent out to assist her getting off the sandbank, and she was pulled off just before 6.10\u00a0am. She had been refloated and was under way under her own power and heading back to her berth in Southampton. She had only partially gone aground, and the tugs pulled her off.\"\nOnce safely back at her berth, preparations continued for her farewell celebrations. These were led by Prince Philip, Duke of Edinburgh who toured the ship at great length. He visited areas of interest including the Engine Control Room. He also met with current and former crew members. During this time, divers were sent down to inspect the hull for any possible damage caused by the vessel's earlier mishap\u00a0\u2013 none was found.\n\"Queen Elizabeth 2\" left Southampton Docks for the final time at 1915 GMT on 11 November 2008, to begin her farewell voyage by the name of \"\"QE2\"'s Final Voyage\". After purchasing her for US$100\u00a0million her ownership passed to Nakheel Properties, a company of Dubai World, on 26 November. The decommissioning of the ship was particularly poignant for \"Queen Elizabeth 2\"'s only permanent resident, Beatrice Muller, aged 89, who lived on board in retirement for nine years, at a cost of some \u00a33,500 (~\u20ac4,300, ~$5,400) per month.\nAt the time of her retirement, \"QE2\" had sailed 5.8 million nautical miles, carried close to 3 million passengers and completed 806 transatlantic crossings, plus 26 world cruises.\nLayup.\nIstithmar, Nakheel, \"QE2\" in Dubai and Cape Town hotel proposal.\nHer final voyage from Southampton to Dubai under the command of Captain Ian McNaught began on 11 November 2008, arriving on 26 November in a flotilla of 60 smaller vessels, led by MY \"Dubai\", the personal yacht of Sheikh Mohammed, ruler of Dubai, in time for her official handover the following day.\nShe was greeted with a fly-past from an Emirates Airbus A380 jet and a huge fireworks display, while thousands of people gathered at the Mina Rashid, waving the flags of the United Kingdom and the United Arab Emirates. Since her arrival in Dubai \"QE2\" remained moored at Port Rashid. Shortly after her final passengers were disembarked, she was moved forward to the cargo area of the port, to free up the passenger terminal for other cruise vessels.\nShe was expected to be refurbished and berthed permanently at Nakheel's Palm Jumeirah as \"a luxury floating hotel, retail, museum and entertainment destination.\" The refurbishment planned to see \"Queen Elizabeth 2\" transformed into a tourist destination in Dubai; however, due to the 2008 financial crisis, \"QE2\" remained moored at Port Rashid awaiting a decision about her future.\n\"QE2\" remained an oceangoing vessel at this time, and as such, former Captain Ronald Warwick of \"QE2\" and (\"QM2\") and retired commodore of the Cunard Line was initially employed by V-Ships, who managed \"QE2\" post the Cunard handed her over as the vessel's legal master, but was replaced by other V-Ships captains over time as the ship remained idle.\nIt was anticipated that \"QE2\" would be moved to the Dubai Drydocks sometime in 2009 to begin a series of far-reaching refurbishments which would result in a conversion into a floating hotel.\nDue to the 2008 financial crisis and the Great Recession, it was rumoured that \"QE2\"'s refurbishment and hotel conversion would not take place and that the ship would be resold. These rumours resulted in the owners, Istithmar, issuing a series of press releases stating that plans for QE2's conversion were ongoing, with no intention to sell. However, since arriving in Dubai the only visible exterior change to \"QE2\" was the painting out of the Cunard titles from the ship's superstructure.\n\"QE2\" was joined in Mina Rashid by \"QM2\" on 21 March 2009 while \"QM2\" visited Dubai as part of her 2009 world cruise. She was joined once again by (\"QV\") on 29 March 2009 as a part of her 2009 world cruise. \"QM2\" and \"QV\" again visited \"QE2\" in 2010 and on 31 March 2011 the new \"(QE)\" called at Dubai during her maiden world cruise\u00a0\u2013 photos were arranged by Cunard to capture the occasion. \"QM2\" called in Dubai two days after \"QE\" left.\nIn April 2009, a supposed concept model of the post-refurbishment \"Hotel QE2\" was shown for sale on an online auction website. The model depicted a much altered \"QE2\".\nIn June 2009, the \"Southampton Daily Echo\" reported that \"Queen Elizabeth 2\" would return to the UK as an operating cruise ship. On 10 July 2009, it was revealed that \"QE2\" might sail to Cape Town, South Africa, to become a floating hotel for use primarily during the 2010 FIFA World Cup, in a Dubai World sponsored venture at the V&amp;A Waterfront. This was confirmed by Nakheel on 20 July 2009. In preparation for this expected voyage the ship was placed into the Dubai Drydock and underwent an extensive exterior refurbishment. During this refit, the ship's underwater hull was repainted and inspected. Shortly after the refit, \"QE2\" was registered under the flag of Vanuatu, and Port Vila was painted on her stern, replacing Southampton. \"QE2\" returned to Port Rashid, where it was anticipated she would soon sail for Cape Town. The arrival of \"QE2\" in Cape Town was expected to create many local jobs including hotel staff, restaurant staff, chefs, cleaners and shop attendants, all being sourced from the local workforce. But, in January 2010, it was confirmed that \"QE2\" would not be moved to Cape Town.\n2010 sale and relocation speculation.\nIn early 2010, due to the continued poor financial performance of Dubai World, there was much media speculation that \"QE2\", along with other assets owned by Istithmar, Dubai World's private-equity arm, would be sold to raise capital. Despite this sale speculation, a number of alternative locations for QE2 were cited including London, Singapore, Clydebank, Japan and Fremantle, the latter showing interest in using QE2 as a hotel for the ISAF Sailing World Championships to be held in December 2011. However, as at June 2010 Nakheel's official statement regarding QE2 was that \"a number of options being considered for QE2\".\n2011 drifting.\nOn 28 January 2011 during a heavy dust storm, \"QE2\" broke loose from her moorings and drifted out into the channel at Port Rashid. She was attended by pilots and tugs and safely returned to berth at Port Rashid. Images of \"QE2\"'s unexpected movements appeared on-line after being taken by an observer on the ship in front of QE2.\nWarm layup.\nThroughout 2011 and 2012, \"QE2\" remained berthed at Port Mina Rashid in Dubai in 2011[ [update]]. She was maintained in a seaworthy condition and generated her own power. Each of her nine diesel generators were turned over and used to power the ship. A live-in crew of approximately 50 people maintained \"QE2\" to a high standard. Activities include painting, maintenance, cabin checks, and overhauls of machinery. Istithmar were considering plans for \"QE2\" which could have involved the ship sailing to an alternative location under her own power.\nOn 21 March 2011, \"QM2\" called in Dubai and docked close to \"QE2\". During the departure, the two ships sounded their horns.\n2011 move to Liverpool plan, Port Rashid and \"QE2\" development plans.\nOn 28 September 2011 news circulated that a plan was being formulated to return QE2 to the United Kingdom by berthing her in Liverpool. Liverpool has a historic connection with Cunard Line being the first British home for the line as well as housing the iconic Cunard Building.\nIt was revealed that Liverpool Vision, the economic development company responsible for Liverpool's regeneration, has been involved in confidential discussions with Out of Time Concepts, a company headed by a former Chief Engineer on the ship, who recently advised its current owners on plans to turn it into a luxury hotel in Dubai.\nIn a letter from Out of Time Concepts to Liverpool Vision, it was explained that \"The free global media attention derived from bringing home \"Queen Elizabeth 2\" will without question promote Liverpool's new waterfront developments, its amazing architecture, its maritime and world heritage sites, its museums, its culture and its history\".\nOn the same week that the Liverpool Vision plans were revealed, Nakheel stated that plans for \"QE2\" to be berthed at The Palm had been dropped because they now planned to build 102 houses on the site which was once intended to be named the QE2 Precinct.\nNakheel suggested that \"Queen Elizabeth 2\", under the ownership of Istithmar, would remain at Port Rashid to become an integral part of the growing cruise terminal. \"The \"QE2\" would be placed in a much better location\", Ali Rashid Lootah, the chairman of Nakheel, told Dubai's The National newspaper \"The Government of Dubai is developing an up-to-date modern cruise terminal which will mean a better environment\", confirming the ship would remain in Dubai for the foreseeable future.\n2011\u20132012 New Year's party aboard \"QE2\".\nOn 31 December 2011, \"Queen Elizabeth 2\" was the location of a lavish New Year's Eve party in Dubai. The black tie event was run by Global Event Management and included over 1,000 guests. In early 2011[ [update]] Global Event Management were offering events aboard QE2 in Dubai for 2012 and 2013.\nJuly 2012: Hotel announcement.\nOn 2 July 2012 in a coordinated press release, the ship's owner, operator and Port Rashid operator, DP Ports, jointly announced \"QE2\" would re-open as a 300-bed hotel after an 18-month refit. The release claims the ship was to be refitted to restore original features, including her 1994\u20132008 'Heritage Trail' of classic Cunard artefacts. The ship was to be berthed alongside a redeveloped Port Rashid cruise terminal which would double as a maritime museum.\nScrapping in China, \"QE2\" London and \"QE2\" Asia.\nOn 23 December 2012, it was reported that \"QE2\" had been sold for scrapping in China for \u00a320\u00a0million, after a bid to return her to the UK was rejected. With monthly berthing and maintenance charges of \u00a3650,000, it was reported that a Chinese salvage crew arrived at the vessel on 21 December, to replace a crew of 40 which has been maintaining the vessel since it arrived at Port Rashid. However, Cunard dismissed the reports as \"pure speculation\". When the ship was sold in 2007, a clause in the contract which started from her retirement in 2009 stipulated a ten-year \"no onward sale\" clause, without payment of a full purchase price default penalty.\nThe \"\"QE2\" London\" Plan had included a \u00a320\u00a0million bid for \"QE2\" and a further \u00a340\u00a0million refurbishment that was supposed to create more than 2,000 jobs in London, with \"Queen Elizabeth 2\" docked near the O2 Arena. It had reportedly obtained the support of the then London Mayor Boris Johnson.\nOn 17 January 2013, the Dubai Drydocks World announced that \"Queen Elizabeth 2\" would be sent to an unknown location in Asia to serve as a floating luxury hotel, shopping mall, and museum. Despite this move, the QE2 London team stated on the same day that \"We believe our investors can show Dubai that \"QE2\" London is still the best proposal\".\n\"Bring \"QE2\" Home\" proposals.\nCunard's 175th anniversary celebrations on 25 May 2015 led to renewed interest in \"Queen Elizabeth 2\". John Chillingworth secured the backing of London mayor Boris Johnson for a plan to anchor the ship opposite The O2 Arena at Greenwich. A move to London however would require the ship to pass through the Thames Barrier. In late 2015 there was disagreement between ship preservation advocates and harbour authorities on whether a dead ship of her size could safely manoeuvre through the barrier. John Houston suggested returning the ship to Greenock as a maritime attraction, hotel and events space.\nInverclyde Council leader Stephen McCabe has called on the UK and Scottish governments to campaign to buy the ship, saying that \"Bringing the \"QE2\" home is a Herculean task, one that requires national support in Scotland and perhaps across the UK, if it has any chance of happening.\" In January 2016 Aubrey Fawcett, the chair of the working group to regenerate the Clyde, admitted defeat in this effort as \"QE2's\" owners refused to respond to any requests regarding her condition or sale. \"Consequently, we must conclude that it is highly unlikely that Scotland features in the future plans for the vessel.\"\n2015\u20132016.\nOn 12 August 2015, the QE2 was observed to have been moved from her berth within Dubai Dry Docks, where she had been since January 2013, to a more open location within Port Rashid. On 17 November 2015, QE2 was again moved within Port Rashid, to the former cruise terminal. It was not known whether these recent moves are connected with any of the publicly known plans regarding the ship's fate.\nBetween May and August 2016, observers noted that the ship's lifeboats were lowered and stored on a nearby car park. Following this, the lifeboat davits were removed in September, giving the ship an altered profile on her boat deck. Subsequently, the wooden decking was removed from the deck and replaced by synthetic block flooring.\n50th anniversary celebration.\nSeptember 2017 marked the 50th anniversary of QE2's launch. To mark the occasion, Cunard Line, the ship's former owners, arranged a commemorative voyage aboard MS \"Queen Elizabeth\"\u00a0\u2013 a 17-night cruise, with special activities and theme days. Meanwhile, in Glasgow, the QE2 Story Forum hosted a 50th anniversary conference with Captain Nick Bates as a speaker. Several books were released for the anniversary, including \"Building the Queen Elizabeth 2\" by Cunard historian Michael Gallagher, and \"QE2: A 50th Anniversary Celebration\" by Chris Frame and Rachelle Cross.\nHotel and tourist attraction.\n\"Queen Elizabeth 2\" reopened in Dubai as a floating hotel on 18 April 2018 following an extensive refurbishment. Over 2.7\u00a0million man-hours were committed to the work to upgrade and rebuild the ship to meet hotel standards. This included a full hull repaint and the replacing of Port Vila registry with Dubai on her stern. It was a 'soft opening' while remaining work continued.\nOn board is a new QE2 Heritage Exhibition, adjacent to the lobby, detailing the vessel's history. The ship was operated by PCFC Hotels, a division of the Ports, Customs and Free Zone Corporation, which is owned by the Dubai government. French hospitality group Accor took over operation of the hotel and attraction in May 2022. Accor announced plans to further renovate the vessel to encompass 447 rooms, and has managed the property since 2024.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49201", "revid": "29539620", "url": "https://en.wikipedia.org/wiki?curid=49201", "title": "Biplane", "text": "Airplane wing configuration with two vertically stacked main flying surfaces\nA biplane is a fixed-wing aircraft with two main wings stacked one above the other. The first powered, controlled aeroplane to fly, the Wright Flyer, used a biplane wing arrangement, as did many aircraft in the early years of aviation. While a biplane wing structure has a structural advantage over a monoplane, it produces more drag than a monoplane wing. Improved structural techniques, better materials and higher speeds made the biplane configuration obsolete for most purposes by the late 1930s.\nBiplanes offer several advantages over conventional cantilever monoplane designs: they permit lighter wing structures, low wing loading and smaller span for a given wing area. However, interference between the airflow over each wing increases drag substantially, and biplanes generally need extensive bracing, which causes additional drag.\nBiplanes are distinguished from tandem wing arrangements, where the wings are placed forward and aft, instead of above and below.\nThe term is also occasionally used in biology, to describe the wings of some flying animals.\nCharacteristics.\nIn a biplane aircraft, two wings are placed one above the other. Each provides part of the lift, although they are not able to produce twice as much lift as a single wing of similar size and shape because the upper and the lower are working on nearly the same portion of the atmosphere and thus interfere with each other's behaviour. In a biplane configuration with no stagger from the upper wing to the lower wing, the lift coefficient is reduced by 10 to 15 percent compared to that of a monoplane using the same airfoil and aspect ratio.\nThe lower wing is usually attached to the fuselage, while the upper wing is raised above the fuselage with an arrangement of cabane struts, although other arrangements have been used. Either or both of the main wings can support ailerons, while flaps are more usually positioned on the lower wing. Bracing is nearly always added between the upper and lower wings, in the form of interplane struts positioned symmetrically on either side of the fuselage and bracing wires to keep the structure from flexing, where the wings are not themselves cantilever structures.\nAdvantages and disadvantages.\nThe primary advantage of the biplane over a monoplane is its ability to combine greater stiffness with lower weight. Stiffness requires structural depth and where early monoplanes had to have this provided with external bracing, the biplane naturally has a deep structure and is therefore easier to make both light and strong. Rigging wires on non-cantilevered monoplanes are at a much sharper angle, thus providing less tension to ensure stiffness of the outer wing. On a biplane, since the angles are closer to the ideal of being in direct line with the forces being opposed, the overall structure can then be made stiffer. Because of the reduced stiffness, wire braced monoplanes often had multiple sets of flying and landing wires where a biplane could easily be built with one bay, with one set of landing and flying wires. The extra drag from the wires was not enough to offset the aerodynamic disadvantages from having two airfoils interfering with each other however. Strut braced monoplanes were tried but none of them were successful, not least due to the drag from the number of struts used.\nThe structural forces acting on the spars of a biplane wing tend to be lower as they are divided between four spars rather than two, so the wing can use less material to obtain the same overall strength and is therefore lighter. A given area of wing also tends to be shorter, reducing bending moments on the spars, which then allow them to be more lightly built as well. The biplane does however need extra struts to maintain the gap between the wings, which add both weight and drag.\nThe low power supplied by the engines available in the first years of aviation limited aeroplanes to fairly low speeds. This required an even lower stalling speed, which in turn required a low wing loading, combining both large wing area with light weight. Obtaining a large enough wing area without the wings being long, and thus dangerously flexible was more readily accomplished with a biplane.\nThe smaller biplane wing allows greater maneuverability. Following World War I, this helped extend the era of the biplane and, despite the performance disadvantages, most fighter aircraft were biplanes as late as the mid-1930s. Specialist sports aerobatic biplanes are still made in small numbers.\nBiplanes suffer aerodynamic interference between the two planes when the high pressure air under the top wing and the low pressure air above the lower wing cancel each other out. This means that a biplane does not in practice obtain twice the lift of the similarly-sized monoplane. The farther apart the wings are spaced the less the interference, but the spacing struts must be longer, and the gap must be extremely large to reduce it appreciably.\nAs engine power and speeds rose late in World War I, thick cantilever wings with inherently lower drag and higher wing loading became practical, which in turn made monoplanes more attractive as it helped solve the structural problems associated with monoplanes, but offered little improvement for biplanes.\nStagger.\nThe default design for a biplane has the wings positioned directly one above the other. Moving the upper wing forward relative to the lower one is called positive stagger or, more often, simply stagger. It can increase lift and reduce drag by reducing the aerodynamic interference effects between the two wings by a small degree, but more often was used to improve access to the cockpit. Many biplanes have staggered wings. Common examples include the de Havilland Tiger Moth, B\u00fccker B\u00fc 131 Jungmann and Travel Air 2000.\nAlternatively, the lower wing can instead be moved ahead of the upper wing, giving negative stagger, and similar benefits. This is usually done in a given design for structural reasons, or to improve visibility. Examples of negative stagger include the Sopwith Dolphin, Breguet 14 and Beechcraft Staggerwing. However, positive (forward) stagger is much more common.\nBays.\nThe space enclosed by a set of interplane struts is called a \"bay\" (much as the architectural form is used), hence a biplane or triplane with one set of such struts connecting the wings on each side of the aircraft is a \"single-bay biplane\". This provided sufficient strength for smaller aircraft such as the First World War-era Fokker D.VII fighter and the Second World War de Havilland Tiger Moth basic trainer.\nThe larger two-seat Curtiss JN-4 Jenny is a \"two bay biplane\", the extra bay being necessary as overlong bays are prone to flexing and can fail. The SPAD S.XIII fighter, while appearing to be a two bay biplane, has only one bay, but has the midpoints of the rigging braced with additional struts; however, these are not structurally contiguous from top to bottom wing. The Sopwith 1\u00bd Strutter has a W shape cabane, however as it does not connect the wings to each other, it does not add to the number of bays.\nLarge transport and bombing biplanes often needed still more bays to provide sufficient strength. These are often referred to as \"multi-bay biplanes\". A small number of biplanes, such as the Zeppelin-Lindau D.I have no interplane struts and are referred to as being \"strutless\".\nRigging.\nBecause most biplanes do not have cantilever structures, they require rigging wires to maintain their rigidity. Early aircraft used simple wire (either braided or plain), however during the First World War, the British Royal Aircraft Factory developed airfoil section wire named RAFwire in an effort to both increase the strength and reduce the drag. \nFour types of wires are used in the biplane wing structure. Drag wires inside the wings prevent the wings from being folded back against the fuselage, running inside a wing bay from the forward inboard corner to the rear outboard corner. Anti-drag wires prevent the wings from moving forward when the aircraft stops and run the opposite direction to the drag wires. Both of these are usually hidden within the wings, and if the structure is sufficiently stiff otherwise, may be omitted in some designs. Indeed many early aircraft relied on the fabric covering of the wing to provide this rigidity, until higher speeds and forces made this inadequate. \nExternally, lift wires prevent the wings from folding up, and run from the underside of the outer wing to the lower wing root. Conversely, landing wires prevent the wings from sagging, and resist the forces when an aircraft is landing, and run from the upper wing centre section to outboard on the lower wings. Additional drag and anti-drag wires may be used to brace the cabane struts which connect the fuselage to the wings, and interplane struts, which connect the upper and lower wings together.\nSesquiplane.\nThe \"sesquiplane\" is a type of biplane where one wing (usually the lower) is significantly smaller than the other. The word, from Latin, means \"one-and-a-half wings\". The arrangement can reduce drag and weight while retaining the biplane's structural advantages. The lower wing may have a significantly shorter span, or a reduced chord.\nExamples include the series of Nieuport military aircraft\u2014from the Nieuport 10 through to the Nieuport 27 which formed the backbone of the Allied air forces between 1915 and 1917. The performance of the Nieuport sesquiplanes was so impressive that the (the German Inspectorate of flying troops) requested their aircraft manufacturers to produce copies, an effort which was aided by several captured aircraft and detailed drawings; one of the most famed copies was the Siemens-Schuckert D.I. The Albatros D.III and D.V, which had also copied the general layout from Nieuport, similarly provided the backbone of the German forces during the First World War. The Albatros sesquiplanes were widely acclaimed by their aircrews for their maneuverability and high rate of climb.\nDuring interwar period, the sesquiplane configuration continued to be popular, with numerous types such as the Nieuport-Delage NiD 42/52/62 series, Fokker C.Vd &amp; e, and Potez 25, all serving across a large number of air forces. In the general aviation sector, aircraft such as the Waco Custom Cabin series proved to be relatively popular. The Saro Windhover was a sesquiplane with the upper wing smaller than the lower, which was a much rarer configuration than the reverse. The Pfalz D.III also featured a somewhat unusual sesquiplane arrangement, possessing a more substantial lower wing with two spars that eliminated the flutter problems encountered by single-spar sesquiplanes.\nHistory.\nThe stacking of wing planes was suggested by Sir George Cayley in 1843. Hiram Maxim adopted the idea for his steam-powered test rig, which lifted off but was held down by safety rails, in 1894. Otto Lilienthal designed and flew two different biplane hang gliders in 1895, though he is better known for his monoplanes. By 1896 a group of young men in the United States, led by Octave Chanute, were flying hang gliders including biplanes and concluded that the externally braced biplane offered better prospects for powered flight than the monoplane. In 1903, the \"Wright Flyer\" biplane became the first successful powered aeroplane.\nThroughout the pioneer years, both biplanes and monoplanes were common, but by the outbreak of the First World War biplanes had gained favour after several monoplane structural failures resulted in the RFC's \"Monoplane Ban\" when all monoplanes in military service were grounded, while the French also withdrew most monoplanes from combat roles and relegated them to training. Figures such as aviation author Bruce observed that there was an apparent prejudice held even against newly-designed monoplanes, such as the Bristol M.1, that caused even those with relatively high performance attributes to be overlooked in favour of 'orthodox' biplanes, and there was an allegedly widespread belief held at that time that monoplane aircraft were inherently unsafe during combat.\nBetween the years of 1914 and 1925, a clear majority of new aircraft introduced were biplanes; however, during the latter years of the First World War, the Germans had been experimenting with a new generation of monoplanes, such as the Fokker D.VIII, that might have ended the biplane's advantages earlier had the conflict not ended when it had. The French were also introducing the Morane-Saulnier AI, a strut-braced parasol monoplane, although the type was quickly relegated to the advanced trainer role following the resolution of structural issues. Sesquiplane types, which were biplanes with abbreviated lower wings such as the French Nieuport 17 and German Albatros D.III, offered lower drag than a conventional biplane while being stronger than a monoplane.\nDuring the Interwar period, numerous biplane airliners were introduced. The British de Havilland Dragon was a particularly successful aircraft, a straightforward design which could carry six passengers on busy routes, such as London-Paris services. During early August 1934, one such aircraft, named \"Trail of the Caribou\", performed the first non-stop flight between the Canadian mainland and Britain in 30 hours 55 minutes, although the intended target for this long distance flight had originally been Baghdad, Iraq. Despite its relative success, British production of the Dragon was quickly ended in favour of the more powerful and elegant de Havilland Dragon Rapide, which had been specifically designed to be a faster and more comfortable successor to the Dragon.\nAs the available engine power and speed increased, the drag penalty of external bracing increasingly limited aircraft performance. To fly faster, it would be necessary to reduce external bracing to create an aerodynamically clean design; however, early cantilever designs were either too weak or too heavy. The 1917 Junkers J.I sesquiplane utilized corrugated aluminum for all flying surfaces, with a minimum of struts; however, it was relatively easy to damage the thin metal skin and required careful handling by ground crews. The 1918 Zeppelin-Lindau D.I fighter was an all-metal stressed-skin monocoque fully cantilevered biplane, but its arrival had come too late to see combat use in the conflict.\nBy the 1930s, biplanes had reached their performance limits, and monoplanes become increasingly predominant, particularly in continental Europe where monoplanes had been increasingly common from the end of World War I. At the start of World War II, several air forces still had biplane combat aircraft in front line service but they were no longer competitive, and most were used in niche roles, such as training or shipboard operation, until shortly after the end of the war. The British Gloster Gladiator biplane, the Italian Fiat CR.42 Falco and Soviet I-153 sesquiplane fighters were all still operational after 1939. According to aviation author Gianni Cattaneo, the CR.42 was able to achieve success in the defensive night fighter role against RAF bombers that were striking industrial targets throughout northern Italy.\nThe British Fleet Air Arm operated the Fairey Swordfish torpedo bomber from its aircraft carriers, and used the type in the anti-submarine warfare role until the end of the conflict, largely due to their ability to operate from the relatively compact decks of escort carriers. Its low stall speed and inherently tough design made it ideal for operations even in the often severe mid-Atlantic weather conditions. By the end of the conflict, the Swordfish held the distinction of having caused the destruction of a greater tonnage of Axis shipping than any other Allied aircraft.\nBoth the German Heinkel He 50 and the Soviet Polikarpov Po-2 were used with relative success in the night ground attack role throughout the Second World War. In the case of the Po-2, production of the aircraft continued even after the end of the conflict, not ending until around 1952. A significant number of Po-2s were fielded by the Korean People's Air Force during the Korean War, inflicting serious damage during night raids on United Nations bases. The Po-2 is also the only biplane to be credited with a documented jet-kill, as one Lockheed F-94 Starfire was lost while slowing down to \u2013 below its stall speed \u2013 during an intercept in order to engage the low flying Po-2.\nLater biplane trainers included the de Havilland Tiger Moth in the Royal Air Force (RAF), Royal Canadian Air Force (RCAF) and others and the Stampe SV.4, which saw service postwar in the French and Belgian Air Forces. The Stearman PT-13 was widely used by the United States Army Air Force (USAAF) while the US Navy operated the Naval Aircraft Factory N3N. In later civilian use in the US, the Stearman became particularly associated with stunt flying such as wing-walking, and with crop dusting, where its compactness worked well at low levels, where it had to dodge obstacles.\nModern biplane designs still exist in specialist roles such as aerobatics and agricultural aircraft with the competition aerobatics role and format for such a biplane well-defined by the mid-1930s by the Udet U 12 Flamingo and Waco Taperwing. The Pitts Special dominated aerobatics for many years after World War II and is still in production.\nThe vast majority of biplane designs have been fitted with reciprocating engines. Exceptions include the Antonov An-3 and WSK-Mielec M-15 Belphegor, fitted with turboprop and turbofan engines respectively. Some older biplane designs, such as the Grumman Ag Cat are available in upgraded versions with turboprop engines.\nThe two most produced biplane designs were the 1913 British Avro 504 of which 11,303 were built, and the 1928 Soviet Polikarpov Po-2 of which over 20,000 were built, with the Po-2 being the direct replacement for the Soviet copy of the Avro 504. Both were widely used as trainers. The Antonov An-2 was very successful too, with more than 18,000 built.\nUltralight aircraft.\nAlthough most ultralights are monoplanes, the low speeds and simple construction involved have inspired a small number of biplane ultralights, such as Larry Mauro's \"Easy Riser\" (1975\u2013). Mauro also made a version powered with solar cells driving an electric motor called the Solar Riser. Mauro's \"Easy Riser\" was used by \"Father Goose\", Bill Lishman.\nOther biplane ultralights include the Belgian-designed Aviasud Mistral, the German FK12 Comet (1997\u2013), the Lite Flyer Biplane, the Sherwood Ranger, and the Murphy Renegade.\nAvian evolution.\nThe feathered dinosaur \"Microraptor gui\" glided, and perhaps even flew, on four wings, which may have been configured in a staggered sesquiplane arrangement. This was made possible by the presence of flight feathers on both forelimbs and hindlimbs, with the feathers on the forelimbs opening to a greater span. It has been suggested that the hind limbs could not have opened out sideways but in flight would have hung below and slightly behind the fore limbs.\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "49202", "revid": "38355222", "url": "https://en.wikipedia.org/wiki?curid=49202", "title": "Ignacy Krasicki", "text": "Poland's leading Enlightenment poet (1735\u20131801)\nIgnacy B\u0142a\u017cej Franciszek Krasicki (3 February 1735\u00a0\u2013 14 March 1801), from 1766 Prince-Bishop of Warmia and from 1795 Archbishop of Gniezno (thus, Primate of Poland), was Poland's leading Enlightenment poet (\"the Prince of Poets\"), a critic of the clergy, Poland's La Fontaine, author of the first Polish novel, playwright, journalist, encyclopedist, and translator from French and Greek.\nHis most notable literary works were his \"Fables and Parables\" (1779), \"Satires\" (1779), and poetic letters and religious lyrics, in which the artistry of his poetic language reached its summit.\nLife.\nIgnacy Krasicki was born in Dubiecko, on southern Poland's San River, into the noble Krasicki family, which bore the title of Imperial Count. His parents were Count Jan Bo\u017cy Krasicki (1704\u20131751) and the Count's wife, Anna Starzechowska (1706\u20131766) of the Nieczuja coat of arms. Ignacy was related by blood to the most illustrious families in the Polish\u2013Lithuanian Commonwealth, including the Sapieha, Potocki, and Rzewuski families, and spent his childhood surrounded with the love and solicitude of his own family.\nHe attended a Jesuit school in Lw\u00f3w, then studied at a Warsaw Catholic seminary (1751\u201354). In 1759 he took holy orders and continued his education in Rome (1759\u201361). Two of his brothers also entered the priesthood.\nReturning to Poland, Krasicki became secretary to the Primate of Poland and developed a friendship with future King Stanis\u0142aw August Poniatowski. When Poniatowski was elected king (1764), Krasicki became his chaplain. He participated in the King's famous \"Thursday dinners\" and cofounded the \"Monitor\", the preeminent Polish Enlightenment periodical, sponsored by the King.\nIn 1766 Krasicki, after having served that year as coadjutor to Prince-Bishop of Warmia Adam Stanis\u0142aw Grabowski, was himself elevated to Prince-Bishop of Warmia and \"ex officio\" membership in the Senate of the Commonwealth. This office gave him a high standing in the social hierarchy and a sense of independence. It did not, however, prove a quiet haven. The Warmia cathedral chapter welcomed its superior coolly, fearing changes. At the same time, there were growing provocations and pressures from Prussia, preparatory to seizure of Warmia in the First Partition of the Polish\u2013Lithuanian Commonwealth. Krasicki protested publicly against external intervention.\nIn 1772, as a result of the First Partition, instigated by Prussia's King Frederick II (\"the Great\"), Krasicki became a Prussian subject. He did not, however, pay homage to Warmia's new master.\nHe now made frequent visits to Berlin, Potsdam and Sanssouci at the bidding of Frederick, with whom he cultivated an acquaintance. This created a difficult situation for the poet-bishop who, while a friend of the Polish king, maintained close relations with the Prussian king. These realities could not but influence the nature and direction of Krasicki's subsequent literary productions, perhaps nowhere more so than in the \"Fables and Parables\" (1779).\nSoon after the First Partition, Krasicki officiated at the 1773 opening of Berlin's St. Hedwig's Cathedral, which Frederick had built for Catholic immigrants to Brandenburg and Berlin. In 1786 Krasicki was called to the Prussian Academy of Sciences. His residences in the castle of the bishops of Warmia at Lidzbark Warmi\u0144ski (in German, \"Heilsberg\") and in the summer palace of the bishops of Warmia at Smolajny became centers of artistic patronage for all sectors of partitioned Poland.\nAfter Frederick the Great's death, Krasicki continued relations with Frederick's successor.\nIn 1795, six years before his death, Krasicki was elevated to Archbishop of Gniezno (thus, to Primate of Poland).\nKrasicki was honored by Poland's King Stanis\u0142aw August Poniatowski with the Order of the White Eagle and the Order of Saint Stanis\u0142aw, as well as with a special 1780 medal featuring the Latin device, \"Dignum laude virum Musa vetat mori\" (\"The Muse will not let perish a man deserving of glory\"); and by Prussia's King Frederick the Great, with the Order of the Red Eagle.\nUpon his death in Berlin in 1801, Krasicki was laid to rest at St. Hedwig's Cathedral, which he had consecrated. In 1829 his remains were transferred to Poland's Gniezno Cathedral.\nCzes\u0142aw Mi\u0142osz describes Krasicki:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;He was a man of the golden mean, a smiling, skeptical sage [who] prais[ed] moderation and despis[ed] extremes. His was a mentality which returned to Horatian ideals of the Renaissance, to a life of contemplative retirement. This did not interfere with his talents as a courtier: he was a favorite of [Poland's King] Stanis\u0142aw August [Poniatowski], and after the [F]irst [P]artition [of Poland, in 1772], when his bishopric of Warmia became the property of Prussia, he was a favorite of King Frederick the Great. [H]e was a cosmopolit[e] and owed his imposing literary knowledge to his readings in foreign languages, yet... he was indebted to the mentality of the Polish \"Golden Age,\" and in this respect his admiration for Erasmus of Rotterdam is significant. As a poet, he was [chiefly responsible] for that distillation of the [Polish] language which for a while toned down the chaotic richness of the Baroque. In a way, he returned to the clear and simple language of [Jan] Kochanowski, and his role in Polish poetry may be compared to that of Alexander Pope in English poetry. [H]e conceived of literature as a specific vocation, namely, to intervene as a moralist in human affairs. Since he was not pugnacious by temperament (contrary to one of his masters, Voltaire), his moralizing, rarely distinguishable from sheer play, [does not show] vitriolic accents.\nWorks.\nIgnacy Krasicki was the leading literary representative of the Polish Enlightenment\u2014a prose writer and poet highly esteemed by his contemporaries, who admired his works for their wit, imagination, and fluid style.\nKrasicki's literary writings lent splendor to the reign of Poland's King Stanis\u0142aw August Poniatowski, while not directly advocating the King's political program.\nKrasicki, the leading representative of Polish classicism, debuted as a poet with the strophe-hymn, \"\u015awi\u0119ta mi\u0142o\u015bci kochanej ojczyzny\" (\"O Sacred Love of the Beloved Country\"), published in 1774. He was then nearing forty. It was thus a late debut that brought the extraordinary success of this strophe, which Krasicki would incorporate as part of song IX in his mock-heroic poem, \"Myszeida\" (Mouseiad, 1775). In \"O Sacred Love of the Beloved Country,\" Krasicki formulated a universal idea of patriotism, expressed in high style and elevated tone. The strophe would later, for many years, serve as a national anthem and see many translations, including three into French.\nThe Prince Bishop of Warmia gave excellent Polish form to all the genres of European classicism. He also blazed paths for new genres. Prominent among these was the first modern Polish novel, \"Miko\u0142aja Do\u015bwiadczy\u0144skiego przypadki\" (The Adventures of Nicholas Experience, 1776), a synthesis of all the varieties of the Enlightenment novel: the social-satirical, the adventure (\"\u00e0 la\" \"Robinson Crusoe\"), the Utopian, and the didactic.\nTradition has it that Krasicki's mock-heroic poem, \"Monachomachia\" (War of the Monks, 1778), was inspired by a conversation with Frederick II at the palace of Sanssouci, where Krasicki was staying in an apartment that had once been used by Voltaire. At the time, the poem's publication caused a public scandal.\nThe most enduring literary monument of the Polish Enlightenment is Krasicki's fables: \"Bajki i Przypowie\u015bci\" (Fables and Parables, 1779) and \"Bajki nowe\" (New Fables, published posthumously in 1802). The poet also set down his trenchant observations of the world and human nature in \"Satyry\" (Satires, 1779).\nOther works by Krasicki include the novels, \"Pan Podstoli\" (Lord High Steward, published in three parts, 1778, 1784 and posthumously 1803), which would help inspire works by Mickiewicz, and \"Historia\" (History, 1779); the epic, \"Wojna chocimska\" (The Chocim War, 1780, about the Khotyn War); and numerous others, in homiletics, theology and heraldry.\nIn 1781\u201383 Krasicki published a two-volume encyclopedia, \"Zbi\u00f3r potrzebniejszych wiadomo\u015bci\" (A Collection of Essential Information), the second Polish-language general encyclopedia after Benedykt Chmielowski's \"Nowe Ateny\" (The New Athens, 1745\u201346).\nKrasicki wrote \"Listy o ogrodach\" (Letters about Gardens) and articles in the \"Monitor\", which he had co-founded, and in his own newspaper, \"Co Tydzie\u0144\" (Each Week).\nKrasicki translated, into Polish, Plutarch, \"Ossian\", fragments of Dante's \"Divine Comedy\", and works by Anacreon, Boileau, Hesiod and Theocritus. He wrote a 1772 essay \"On the Translation of Books\" (\"O przek\u0142adaniu ksi\u0105g\") and another, published posthumously in 1803, \"On Translating Books\" (\"O t\u0142umaczeniu ksi\u0105g\").\nFame.\nKrasicki's major works won European fame and were translated into Latin, French, German, Italian, Russian, Czech, Croatian, Slovene, and Hungarian. The broad reception of his works was sustained throughout the 19th century.\nKrasicki has been the subject of works by poets of the Polish Enlightenment\u00a0\u2013 Stanis\u0142aw Trembecki, Franciszek Zab\u0142ocki, Wojciech Mier\u00a0\u2013 and in the 20th century, by Konstanty Ildefons Ga\u0142czy\u0144ski. He has been the hero of prose works by Wincenty Pol, Adolf Nowaczy\u0144ski and Henryk Sienkiewicz.\nLiterary reflection.\nScholars have viewed Krasicki's \"Fables\" and \"Satires\" as adaptive to the culture for which they were written, and as politically charged. The characterizations were not based on reconstructions of individuals from direct observation, but were fictional constructs that reflected society's actual values. Krasicki held that Poles, and humanity generally, were governed by greed, folly, and vice.\nTarget audience.\nEvidence for this is found in the preface, \"To the Children,\", targeted not to children but to villagers, congregations, and the commonalty. The fables were meant to bring attention to major questions of the day, and to advocate for social reforms. Although the \"New Fables\", the sequel to the \"Fables and Parables\", were published posthumously in 1803, the better known \"Fables and Parables\" found their audience between 1735 and Krasicki's death in 1801, most of them being published after the First Partition of Poland, of 1772. The fables usually find their meaning in the final line, through the symbology of the tale rather than through a complex presentation of ideology, thereby readily conveying even to the illiterate the moral and the Enlightenment ideal behind it.\nEnlightenment contributions.\nKatarzyna Zechenter argues in \"The Polish Review\" that Western historians have generally overlooked Krasicki's works, and that the publisher of \"Polish Fables\" (1997) overlooked the importance of the \"political and social context contributing to [the fable's] origin.\" However, it is easy to see Krasicki's influence on his contemporaries and on the early 19th century, as in the case of , a Polish princess, poet, and diarist. In 1846 she started a newspaper for the intelligentsia of Vilnius and Warsaw, and furthered the establishment of Krasicki's \"Fables\" in Poland's suppressed political life. In her \"Diary of the Years 1815\u20131843\", Puzynina focuses on the fable, \"Birds in a Cage\", as a commentary on the Partitions of Poland.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49203", "revid": "17300358", "url": "https://en.wikipedia.org/wiki?curid=49203", "title": "Reduction (philosophy)", "text": ""}
{"id": "49207", "revid": "22301165", "url": "https://en.wikipedia.org/wiki?curid=49207", "title": "Laura Gemser", "text": "Indonesian-Dutch model, actress, and costume designer (retired)\nLaurette Marcia Gemser (born 5 October 1950) is an Indonesian-Dutch retired actress, model and costume designer. She is primarily known for her work in Italian erotic cinema, most notably the \"Emanuelle\" series. Many of her films were collaborations with directors Joe D'Amato and Bruno Mattei.\nGemser has also been credited as Moira Chen, most notably in \"Love Is Forever\" (1983).\nEarly life.\nGemser left Indonesia in 1955, at the age of four, and moved with her parents to the Netherlands. She grew up in the Dutch city of Utrecht, where she attended the MULO Regentesseschool high school. After that, she attended the Artibus Art School in Utrecht, where she specialised in fashion design.\nCareer.\nAfter modelling in various magazines in the Netherlands and Belgium, in 1974 she moved to Italy to star in the erotic film \"Amore libero - Free Love\". The film was a box office success and launched Gemser's career. She played one of the masseuses in the 1975 film \"Emmanuelle 2\" (aka \"Emmanuelle, The Joys of a Woman\"), and later that year took the starring role in Bitto Albertini's \"Black Emanuelle\". She starred in 5 \"Black Emanuelle\" films in less than three years. \nShe starred as Laotian actress Keo Sirisomphone in Michael Landon's 1983 American television film, \"Love Is Forever\", in which she was credited as Moira Chen. During the 1970s and 1980s, she made many movies with Joe D'Amato. Gemser continued to make films, at times working with her actor husband, Gabriele Tinti (m. 1976-1991). In the 1990s, she retired from films to work on costume designing for film, and completely vanished from the public life.\nReferences.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "49209", "revid": "40968262", "url": "https://en.wikipedia.org/wiki?curid=49209", "title": "Carburetor", "text": "Component of internal combustion engines which mixes air and fuel in a controlled ratio\nA carburetor (also spelled carburettor or carburetter) is a device used by a gasoline internal combustion engine to control and mix air and fuel entering the engine. The primary method of adding fuel to the intake air is through the Venturi effect or Bernoulli's principle or with a Pitot tube in the main metering circuit, though various other components are also used to provide extra fuel or air in specific circumstances.\nSince the 1990s, carburetors have been largely replaced by fuel injection for cars and trucks, but carburetors are still used by some small engines (e.g. lawnmowers, generators, and concrete mixers) and motorcycles. In addition, they are still widely used on piston-engine\u2013driven aircraft. Diesel engines have always used fuel injection instead of carburetors, as the compression-based combustion of diesel requires the greater precision and pressure of fuel injection.\nEtymology.\nThe term \"carburetor\" is derived from the verb \"carburet\", which means \"to combine with carbon\", or, in particular, \"to enrich a gas by combining it with carbon or hydrocarbons\". Thus a carburetor mixes intake air with hydrocarbon-based fuel, such as petrol or autogas (LPG).\nThe name is spelled \"carburetor\" in American English and \"carburettor\" in British English. Colloquial abbreviations include \"carb\" in the UK and North America or \"carby\" in Australia.\nOperating principle.\nAir from the atmosphere enters the carburetor (usually via an air cleaner), has fuel added within the carburetor, passes into the inlet manifold, then through the inlet valve(s), and finally into the combustion chamber. Most engines use a single carburetor shared among all of the cylinders, though some high-performance engines historically had multiple carburetors.\nThe simplest carburetors work on Bernoulli's principle: the static pressure of the intake air at the fuel entry point, which can be in a tube which is constant diameter, reduces at higher speeds compared with the pressure in the float chamber which is vented to ambient air pressure, with the pressure difference then forcing more fuel into the airstream. If the tube is a constant diameter the configuration is slightly simpler than in the diagram shown to the above right Cross-section schematic. \nIn most cases (except for the \"accelerator pump\"), the driver pressing the throttle pedal does not directly increase the fuel entering the engine. Instead, the airflow through the carburetor increases, which in turn increases the amount of fuel drawn into the intake mixture.\nBernoulli's Principle applies (apart from friction and viscosity and turbulence etc.) to both the air and the fuel, so that the pressure reduction in the air flow tends to be proportional to the square of the intake airspeed, and the fuel in the main jets will obtain a speed as the square root of the pressure reduction so the two will be proportional to each other. If the pressure reduction is taken as from a reduction of area along the air flow rather than from ambient pressure to the fuel entry point the effect can be described as the Venturi effect, but that is simply a derivation from the Bernoulli principle at two positions. \nThe actual fuel and air flows are more complicated and need correction. This might be done variously at lower speeds or higher speeds, or over the whole range by a variable emulsion device to add air to the fuel after the main jets/s. In SU and other (e.g. Zenith-Stromberg) variable jet carburetors, it was mainly controlled by varying the jet size.\nThe orientation of the carburetor is a key design consideration. Older engines used updraft carburetors, where the air enters from below the carburetor and exits through the top. From the late 1930s, downdraft carburetors become more commonly used (especially in the United States), along with side draft carburetors (especially in Europe).\nFuel circuits.\nMain metering circuit.\nThe main metering circuit usually consists of barrel/s which reduces to a narrow part where the air is at its highest speed, forming a venturi. Fuel is introduced into the air stream at that narrow part through small tubes leading from the main jet.\nDownstream of the venturi is a throttle (usually in the form of a butterfly valve) which is used to control the amount of air entering the carburetor. In a car, this throttle is usually mechanically connected to the vehicle's throttle pedal, which varies engine speed.\nAt lesser throttle openings, the air speed through the venturi may be insufficient to maintain the fuel flow, so then the fuel may be supplied by the carburetor's idle and off-idle circuits which will work even with a low volume of air because the narrow gap between the edge of the butterfly plate and the body gives sufficient local air speed at those jets.\nAt greater throttle openings, the speed of air passing through the venturi increases, which lowers the pressure of the air and draws more fuel into the airstream. At the same time, the reduced manifold vacuum results in less fuel flow through the idle and off-idle circuits.\nChoke.\nDuring cold weather fuel vaporizes less readily and tends to condense on the walls of the intake manifold, starving the cylinders of fuel and making cold starts difficult. Additional fuel is required (for a given amount of air) to start and run the engine until it warms up, provided by a \"choke valve\".\nWhile the engine is warming up the choke valve is partially closed, restricting the flow of air at the entrance to the carburetor. This increases the vacuum in the main metering circuit, causing more fuel to be supplied to the engine via the main jets. Prior to the late 1950s the choke was manually operated by the driver, often using a lever or knob on the dashboard. Since then, automatic chokes became more commonplace. These either use a bimetallic thermostat to automatically regulate the choke based on the temperature of the engine's coolant liquid, an electrical resistance heater to do so, or air drawn through a tube connected to an engine exhaust source. A choke left closed after the engine has warmed up increases the engine's fuel consumption and exhaust gas emissions, and causes the engine to run rough and lack power due to an over-rich fuel mixture.\nHowever, excessive fuel can flood an engine and prevent it from starting. To remove the excess fuel, many carburetors with automatic chokes allow it to be held open (by manually, depressing the accelerator pedal to the floor and briefly holding it there while cranking the starter) to allow extra air into the engine until the excess fuel is cleared out.\nAnother method used by carburetors to improve the operation of a cold engine is a \"fast idle cam\", which is connected to the choke and prevents the throttle from closing fully while the choke is in operation. The resulting increase in idle speed provides a more stable idle for a cold engine (by better atomizing the cold fuel) and helps the engine warm up quicker.\nIdle circuit.\nThe system within a carburetor that meters fuel when the engine is running at low RPM. The idle circuit is generally activated by vacuum near the (near closed) throttle plate, where the air speed increases to cause a low-pressure area in the idle passage/port, thus causing fuel to flow through the idle jet. The idle jet is set at some constant value by the carburetor manufacturer, thus flowing a specified amount of fuel.\nOff-idle circuit.\nMany carburetors use an off-idle circuit, which includes an additional fuel jet which is briefly used as the throttle starts to open. This jet is located in a low-pressure area caused by the high air speed near the (partly closed) throttle. The additional fuel it provides is used to compensate for the reduced vacuum that occurs when the throttle is opened, thus smoothing the transition from the idle circuit to the main metering circuit.\nPower valve.\nIn a four-stroke engine it is often desirable to provide extra fuel to the engine at high loads (to increase the power output and reduce engine knocking). A 'power valve', which is a spring-loaded valve in the carburetor that is held shut by engine vacuum, is often used to do so. As the airflow through the carburetor increases, the reduced manifold vacuum pulls the power valve open, allowing more fuel into the main metering circuit.\nIn a two-stroke engine, the carburetor power valve operates in the opposite manner: in most circumstances the valve allows extra fuel into the engine, then at a certain engine RPM it closes to reduce the fuel entering the engine. This is done in order to extend the engine's maximum RPM, since many two-stroke engines can temporarily achieve higher RPM with a leaner air-fuel ratio.\nThis is not to be confused with the unrelated exhaust power valve arrangements used on two-stroke engines.\nMetering rod / step-up rod.\nA metering rod or step-up rod system is sometimes used as an alternative to a power valve in a four-stroke engine in order to supply extra fuel at high loads. One end of the rods is tapered, which sits in the main metering jets and acts as a valve for fuel flow in the jets. At high engine loads, the rods are lifted away from the jets (either mechanically or using manifold vacuum), increasing the volume of fuel flow through the jet. These systems have been used by the Rochester Quadrajet and in the 1950s Carter carburetors.\nAccelerator pump.\nWhile the main metering circuit can adequately supply fuel to the engine in steady-state conditions, the inertia of fuel (being higher than that of air) causes a temporary shortfall as the throttle is opened. Therefore, an accelerator pump is often used to briefly provide extra fuel as the throttle is opened. When the driver presses the throttle pedal, a small piston or diaphragm pump injects extra fuel directly into the carburetor throat.\nThe accelerator pump can also be used to \"prime\" an engine with extra fuel prior to attempting a cold start.\nFuel supply.\nFloat chamber.\nIn order to ensure an adequate supply at all times, carburetors include a reservoir of fuel, called a \"float chamber\" or \"float bowl\". Fuel is delivered to the float chamber by a fuel pump or by gravity with the fuel tank located higher than the carburetor. A floating inlet valve regulates the fuel entering the float chamber, assuring a constant level. In some small engines that may instead of a float chamber just use a fuel tank close below the carburetor and use the fuel suction to supply the fuel.\nUnlike in a fuel injected engine, the fuel system in a carbureted engine is not pressurized. For engines where the intake air travelling through the carburetor is pressurized (such as where the carburetor is downstream of a supercharger) the entire carburetor must be contained in an airtight pressurized box to operate. However, this is not necessary where the carburetor is upstream of the supercharger.\nProblems of fuel boiling and vapor lock can occur in carbureted engines, especially in hotter climates. Since the float chamber is located close to the engine, heat from the engine (including for several hours after the engine is shut off) can cause the fuel to heat up to the point of vaporization. This causes air bubbles in the fuel (similar to the air bubbles that necessitate brake bleeding), which prevents the flow of fuel and is known as 'vapor lock'.\nTo avoid pressurizing the float chamber, vent tubes allow ambient air to enter and exit the float chamber. These tubes may instead extend into the carburetor air flow prior to where the fuel flows in, in order to use the Venturi effect to achieve suitable pressure difference rather than the Bernoulli principle which applies when the pressure difference is related to the ambient air pressure.\nDiaphragm chamber.\nIf an engine must be operated when the carburetor is not in an upright orientation (for example in a chainsaw or airplane), a float chamber and gravity activated float valve would not be suitable. Instead, a diaphragm chamber is typically used. This consists of a flexible diaphragm on one side of the fuel chamber, connected to a needle valve which regulates the fuel entering the chamber. As the flowrate of the air in the chamber (controlled by the throttling valve/butterfly valve) decreases, the diaphragm moves inward (downward), which closes the needle valve to admit less fuel. As the flowrate of the air in the chamber increases, the diaphragm moves outward (upward) which opens the needle valve to admit more fuel, allowing the engine to generate more power. A balanced state is reached which creates a steady fuel reservoir level, that remains constant in any orientation.\nOther components.\nOther components that have been used on carburetors include:\nTwo-barrel and four-barrel designs.\nThe basic design for a carburetor consists of a single venturi (main metering circuit), though designs with two or four venturi (two-barrel and four-barrel carburetors respectively) are also quite commonplace. Typically the barrels consist of \"primary\" barrel(s) used for lower load situations and secondary barrel(s) activating when required to provide additional air/fuel at higher loads. The primary and secondary venturi are often sized differently and incorporate different features to suit the situations in which they are used.\nMany four-barrel carburetors use two primary and two secondary barrels. A four-barrel design of two primary and two secondary barrels was commonly used in V8 engines to conserve fuel at low engine speeds while still affording an adequate supply at high.\nThe use of multiple carburetors (e.g., a carburetor for each cylinder or pair of cylinders) also results in the intake air being drawn through multiple venturi. Some high-performance engines have used multiple two-barrel or four-barrel carburetors, for example six two-barrel carburetors on Ferrari V12s.\nHistory.\nIn 1826, American engineer Samuel Morey received a patent for a \"gas or vapor engine\", which had a carburetor that mixed turpentine and air. The design did not reach production. In 1888/1889 German engineer Siegfried Marcus produced a car powered by a petrol engine (which also debuted the first magneto ignition system). Karl Benz introduced his single-cylinder four-stroke powered Benz Patent-Motorwagen in 1885.\nAll three of these engines used surface carburetors, which operated by moving air across the top of a vessel containing the fuel.\nThe first float-fed carburetor design, which used an atomizer nozzle, was introduced by German engineers Wilhelm Maybach and Gottlieb Daimler in their 1885 \"Grandfather Clock engine\". The Butler Petrol Cycle car\u2014built in England in 1888\u2014also used a float-fed carburetor.\nThe first carburetor for a stationary engine was patented in 1893 by Hungarian engineers J\u00e1nos Csonka and Don\u00e1t B\u00e1nki.\nThe first four-barrel carburetors were the Carter Carburetor WCFB and the identical Rochester 4GC, introduced in various General Motors models for 1952. Oldsmobile referred the new carburetor as the \"Quadri-Jet\" (original spelling) while Buick called it the \"Airpower\".\nIn the United States, carburetors were the common method of fuel delivery for most US-made gasoline (petrol) engines until the late 1980s, when fuel injection became the preferred method. One of the last motorsport users of carburetors was NASCAR, which switched to electronic fuel injection after the 2011 Sprint Cup series. NASCAR still uses the four-barrel carburetor in the NASCAR Xfinity Series.\nIn Europe, carburetors were largely replaced by fuel injection in the late 1980s, although fuel injection had been increasingly used in luxury cars and sports cars since the 1970s. EEC legislation required all vehicles sold and produced in member countries to have a catalytic converter after December 1992. This legislation had been in the pipeline for some time, with many cars becoming available with catalytic converters or fuel injection from around 1990.\nIcing in aircraft engine carburetors.\nA significant concern for aircraft engines is the formation of ice inside the carburetor. The temperature of air within the carburetor can be reduced by up to 40\u00a0\u00b0C (72\u00a0\u00b0F), due to a combination of the reduced air pressure in the venturi and the latent heat of the evaporating fuel. The conditions during the descent to landing are particularly conducive to icing, since the engine is run at idle for a prolonged period with the throttle closed. Icing can also occur in cruise conditions at altitude.\nA carburetor heat system is often used to prevent icing. This system consists of a secondary air intake which passes around the exhaust, in order to heat the air before it enters the carburetor. Typically, the system is operated by the pilot manually switching the intake air to travel via the heated intake path as required. The carburetor heat system reduces the power output (due to the lower density of heated air) and causes the intake air filter to be bypassed, therefore the system is only used when there is a risk of icing.\nIf the engine is operating at idle RPM, another method to prevent icing is to periodically open the throttle, which increases the air temperature within the carburetor.\nCarburetor icing also occurs on other applications and various methods have been employed to solve this problem. On inline engines the intake and exhaust manifolds are on the same side of the head. Heat from the exhaust is used to warm the intake manifold and in turn the carburetor. On V configurations, exhaust gases were directed from one head through the intake cross over to the other head. One method for regulating the exhaust flow on the cross over for intake warming was a weighted eccentric butterfly valve called a heat riser that remained closed at idle and opened at higher exhaust flow. Some vehicles used a heat stove around the exhaust manifold. It was connected to the air filter intake via tubing and supplied warmed air to the air filter. A vacuum controlled butterfly valve pre heat tube on the intake horn of the air cleaner would open allowing cooler air when engine load increased.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49214", "revid": "850615", "url": "https://en.wikipedia.org/wiki?curid=49214", "title": "Clef", "text": "Musical symbol used to indicate the written pitches of notes\nA clef (from French: 'key') is a musical symbol used to indicate which notes are represented by the lines and spaces on a musical staff. Placing a clef on a staff assigns a particular pitch to one of the five lines or four spaces, which defines the pitches on the remaining lines and spaces.\nThe three clef symbols used in modern music notation are the G-clef, F-clef, and C-clef. Placing these clefs on a line fixes a reference note to that line\u2014an F-clef fixes the F below middle C, a C-clef fixes middle C, and a G-clef fixes the G above middle C. In modern music notation, the G-clef is most frequently seen as treble clef (placing G4 on the second line of the staff), and the F-clef as bass clef (placing F3 on the fourth line). The C-clef is mostly encountered as alto clef (placing middle C on the third line) or tenor clef (middle C on the fourth line). A clef may be placed on a space instead of a line, but this is rare.\nThe use of different clefs makes it possible to write music for all instruments and voices, regardless of differences in range. Using different clefs for different instruments and voices allows each part to be written comfortably on a staff with a minimum of ledger lines. To this end, the G-clef is used for high parts, the C-clef for middle parts, and the F-clef for low parts. Transposing instruments can be an exception to this\u2014the same clef is generally used for all instruments in a family, regardless of their sounding pitch. For example, even the low saxophones read in treble clef.\nA symmetry exists surrounding middle C regarding the F-, C- and G-clefs. C-clef defines middle C whereas G-clef and F-clef define the note at the interval of a fifth above middle C and below middle C, respectively. \nCommon mnemonics for the notes on treble clef:\n*\" Every Good Boy Does Fine\" (lines)\n*\" F A C E \" (spaces)\nFor bass clef:\n*\" Good Boys Do Fine Always\" (lines)\n*\" All Cows Eat Grass\" (spaces)\nPlacement on the staff.\nTheoretically, any clef may be placed on any line. With five lines on the staff and three clefs, there are fifteen possibilities for clef placement. Six of these are redundant because they result in an identical assignment of the notes\u2014for example, a G-clef on the third line yields the same note placement as a C-clef on the bottom line. Thus there are nine possible distinct clefs when limiting their placement to the lines. All have been used historically: the G-clef on the two bottom lines, the F-clef on the three top lines, and the C-clef on the four bottom lines. The C-clef on the topmost line has also been used, but is equivalent to the F-clef on the third line, giving a total of ten historically attested clefs placed on the lines. In addition, the C-clef has been used on the third \"space\", i.e. not on a line at all. This is equivalent to the more common suboctave treble clef.\nThe ten clefs placed on lines (two are equivalent) have different names based on the tessitura for which they are best suited.\nIn modern music, only four clefs are used regularly: treble clef, bass clef, alto clef, and tenor clef. Of these, the treble and bass clefs are by far the most common. The tenor clef is used for the upper register of several instruments that usually use bass clef (including cello, bassoon, and trombone), while the alto is most prominently used by the viola. Music for instruments and voices that transpose at the octave is generally written at the transposed pitch, but is sometimes seen written at concert pitch using an octave clef.\nIndividual clefs.\nThis section shows a complete list of the clefs, along with a list of instruments and voice parts notated with them. A dagger (\u2020) after the name of a clef indicates that the clef is no longer in common use.\nG-clefs.\nTreble clef.\nThe only G-clef still in use is the treble clef, with the G-clef placed on the second line. This is the most common clef in use and is generally the first clef learned by music students. For this reason, the terms \"G-clef\" and \"treble clef\" are often seen as synonymous. The treble clef was historically used to mark a treble, or pre-pubescent, voice part.\nInstruments that use the treble clef include violin, flute, oboe, cor anglais, all clarinets, all saxophones, horn, trumpet, cornet, vibraphone, xylophone, mandolin, recorder, bagpipe and guitar. Euphonium and baritone horn are sometimes treated as transposing instruments, using the treble clef and sounding a major ninth lower, and are sometimes treated as concert-pitch instruments, using bass clef. The treble clef is also the upper staff of the grand staff used for harp and keyboard instruments. Most high parts for bass-clef instruments (e.g. cello, double bass, bassoon, and trombone) are written in the tenor clef, but very high pitches may be notated in the treble clef. The viola also may use the treble clef for very high notes. The treble clef is used for the soprano, mezzo-soprano, alto, contralto and tenor voices. Tenor voice parts sound an octave lower and are often written using an octave clef (see below) or a double-treble clef.\nFrench violin clef\u2020.\nA G-clef placed on the first line is called the French clef, or French violin clef. It was used in France in the seventeenth and eighteenth centuries for violin music and flute music. It places the notes in the same staff positions as the bass clef, but two octaves higher.\nF-clefs.\nBaritone clef\u2020.\nWhen the F-clef is placed on the third line, it is called the baritone clef. Baritone clef was used for the left hand of keyboard music (particularly in France; see Bauyn manuscript) and for baritone parts in vocal music. A C-clef on the fifth line creates a staff with identical notes to the baritone clef, but this variant is rare.\nBass clef.\nThe only F-clef still in use is the bass clef, with the clef placed on the fourth line. Since it is the only F-clef commonly encountered, the terms \"F-clef\" and \"bass clef\" are often regarded as synonymous.\nBass clef is used for the cello, double bass and bass guitar, bassoon and contrabassoon, bass recorder, trombone, tuba, and timpani. It is used for baritone horn or euphonium when their parts are written at concert pitch, and sometimes for the lowest notes of the horn. Baritone and bass voices also use bass clef, and the tenor voice is notated in bass clef if the tenor and bass are written on the same staff. Bass clef is the bottom clef in the grand staff for harp and keyboard instruments. Double bass, bass guitar, and contrabassoon sound an octave lower than the written pitch; some scores show an \"8\" beneath the clef for these instruments to differentiate from instruments that sound at the actual written pitch (see \"Octave clefs\" below).\nSub-bass clef\u2020.\nWhen the F-clef is placed on the fifth line, it is called the sub-bass clef. It was used by Johannes Ockeghem and Heinrich Sch\u00fctz to write low bass parts, by Monsieur de Sainte-Colombe for low notes on the bass viol, and by J. S. Bach in his \"Musical Offering\".\nIt is the same as the treble clef, but two octaves lower.\nC-clefs.\nAlto clef.\nA C-clef on the third line of the staff is called the alto or viola clef. It is currently used for viola, viola d'amore, alto trombone, viola da gamba, and mandola. It is also associated with the countertenor voice and sometimes called the countertenor clef. A vestige of this survives in Sergei Prokofiev's use of the clef for the cor anglais in his symphonies. It occasionally appears in keyboard music (for example, in Brahms's Organ Chorales and John Cage's \"Dream\" for piano). It was originally used for alto parts in choral music to reduce the number of ledger lines needed, since much of the alto range is between treble and bass clef. Alto parts are now commonly written in treble clef instead.\nTenor clef.\nA C-clef on the fourth line of the staff is called tenor clef. It is used for the viola da gamba (rarely, and mostly in German scores; otherwise the alto clef is used) and for upper ranges of bass-clef instruments such as the bassoon, cello, euphonium, double bass, and tenor trombone. Treble clef may also be used for the upper extremes of these bass-clef instruments. Tenor violin parts were also written in this clef (see e.g. Giovanni Battista Vitali's Op.\u00a011). It was used by the tenor part in vocal music but its use has been largely supplanted either with an octave version of the treble clef or with bass clef when tenor and bass parts are written on a single staff.\nAnother tenor clef variant, formerly used in music for male chorus, has a ladder-like shape. This C-clef places the C on the third space of the staff, and is equivalent to the sub-octave treble clef. See also History.\nMezzo-soprano clef\u2020.\nA C-clef on the second line of the staff is called the mezzo-soprano clef, rarely used in modern Western classical music. It was used in 17th century French orchestral music for the second viola or first tenor part ('taille') by such composers as Lully, and for mezzo-soprano voices in operatic roles, notably by Claudio Monteverdi. Mezzo-soprano clef was also used for certain flute parts during renaissance, especially when doubling vocal lines. In Azerbaijani music, the tar uses this clef.\nSoprano clef\u2020.\nA C-clef on the first line of the staff is called the soprano clef. It was used for the right hand of keyboard music (particularly in France \u2013 see Bauyn manuscript), in vocal music for sopranos, and sometimes for high viola da gamba parts along with the alto clef. It was used for the second violin part ('haute-contre') in 17th century French music.\nOther clefs.\nOctave clefs.\nStarting in the 18th century, music for some instruments (such as guitar) and for the tenor voice have used treble clef, although they sound an octave lower. To avoid ambiguity, modified clefs are sometimes used, especially in choral writing. Using a C-clef on the third space places the notes identically, but this notation is much less common as it is easily confused with the alto and tenor clefs.\nSuch a modified treble clef is most often found in tenor parts in SATB settings, using a treble clef with the numeral \"8\" below it. This indicates that the pitches sound an octave lower. As the true tenor clef has fallen into disuse in vocal writings, this \"octave-dropped\" treble clef is often called the tenor clef. The same clef is sometimes used for the octave mandolin. This can also be indicated with two overlapping G-clefs.\nTenor banjo is commonly notated in treble clef. However, notation varies between the written pitch sounding an octave lower (as in guitar music and called octave pitch in most tenor banjo methods) and music sounding at the written pitch (called actual pitch). An attempt has been made to use a treble clef with a diagonal line through the upper half of the clef to indicate octave pitch, but this is not always used.\nTo indicate that notes sound an octave higher than written, a treble clef with an \"8\" positioned above the clef may be used for penny whistle, soprano and sopranino recorder, and other high woodwind parts. A treble clef with a \"15\" above (sounding two octaves above the standard treble clef) is used for the garklein (sopranissimo) recorder.\nAn F-clef can also be notated with an octave marker. While the F-clef notated to sound an octave lower can be used for contrabass instruments such as the double bass and contrabassoon, and the F-clef notated to sound an octave higher can be used for the bass recorder, these uses are extremely rare. In Italian scores up to Gioachino Rossini's Overture to \"William Tell\", the cor anglais was written in bass clef an octave lower than sounding. The unmodified bass clef is so common that performers of instruments whose ranges lie below the staff simply learn to read ledger lines.\nNeutral clef.\nThe \"neutral\" or \"percussion\" clef is not a true clef like the F, C, and G clefs. Rather, it assigns different unpitched percussion instruments to the lines and spaces of the staff. With the exception of some common drum-kit and marching percussion layouts, the assignment of lines and spaces to instruments is not standardised, so a legend is required to show which instrument each line or space represents. Pitched percussion instruments do not use this clef \u2014 timpani are notated in bass clef and mallet percussion instruments are noted in treble clef or on a grand staff.\nIf the neutral clef is used for a single percussion instrument the staff may only have one line, although other configurations are used.\nThe neutral clef is sometimes used where non-percussion instruments play non-pitched extended techniques, such as hitting the body of a string instrument, or having a vocal choir clap, stamp, or snap. However, it is more common to write the rhythms using \u00d7 noteheads on the instrument's normal staff, with a comment to indicate the appropriate rhythmic action.\nTablature.\nFor guitars and other fretted instruments, it is possible to notate tablature in place of ordinary notes. This TAB sign is not a clef \u2014 it does not indicate the placement of notes on a staff. The lines shown are not a music staff but rather represent the strings of the instrument (six lines would be used for guitar, four lines for the bass guitar, etc.), with numbers on the lines showing which fret, if any, should be used and symbols for specific techniques.\nHistory.\nBefore the advent of clefs, the reference line of a staff was simply labeled with the name of the note it was intended to bear: \"F\", \"C\", or sometimes \"G\". These were the most common 'clefs', or (key-letters), in Gregorian chant notation. Over time the shapes of these letters became stylised, leading to their current versions.\nMany other clefs were used, particularly in the early period of chant notation, keyed to many different notes, from the low \"\u0393\" (\"gamma\", the G on the bottom line of the bass clef) to the G above middle C (written with a small letter \"g\"). These included two different lowercase \"b\" symbols for the note just below middle C: round for B\u266d, and square for B\u266e. In order of frequency of use, these clefs were: \"F\", \"c\", \"f\", \"C\", \"D\", \"a\", \"g\", \"e\", \"\u0393\", \"B\", and the round and square \"b\". In later medieval music, the round \"b\" was often written in addition to another clef letter to indicate that B\u266d rather than B\u266e was to be used throughout a piece; this is the origin of the key signature.\nIn the polyphonic period up to 1600, unusual clefs were occasionally used for parts with extremely high or low tessituras. For very low bass parts, the \u0393 clef is found on the middle, fourth, or fifth lines of the staff (e.g., in Pierre de La Rue's \"Requiem\" and in a mid-16th-century dance book published by the Hessen brothers); for very high parts, the high-D clef (\"d\"), and the even higher \"ff\" clef (e.g., in the \"Mulliner Book\") were used to represent the notes written on the fourth and top lines of the treble clef, respectively.\nThe practice of using different shapes for the same clef persisted until very recent times. The F-clef was, until as late as the 1980s in some cases (such as hymnals), or in British and French publications, written like this: The 2025 edition of the shape note tunebook \"The Sacred Harp\" continues to use an old-style, right-facing bass clef, following the style of nineteenth-century editions.\nIn printed music from the 16th and 17th centuries, the C clef often assumed a ladder-like form, in which the two horizontal rungs surround the staff line indicated as C: ; this form survived in some printed editions (, written in four-part men's harmony and positioned to make it equivalent to an octave G clef) into the 20th century.\nThe C-clef was formerly written in a more angular way, sometimes still used, or, more often, as a simplified \"K\"-shape when writing the clef by hand: \nIn modern Gregorian chant notation the C clef is written (on a four-line staff) in the form and the F clef as \nThe flourish at the top of the G-clef probably derives from a cursive \"S\" for \"sol\", the name for \"G\" in solfege.\nC clefs (along with G, F, \u0393, D, and A clefs) were formerly used to notate vocal music. Nominally, the soprano voice parts were written in first- or second-line C clef (\"soprano clef\" or \"mezzo-soprano clef\") or second-line G clef (\"treble clef\"), the alto or tenor voices in third-line C clef (\"alto clef\"), the tenor voice in fourth-line C clef (\"tenor clef\") and the bass voice in third-, fourth- or fifth-line F clef (\"baritone\", \"bass\", or \"sub-bass clef\").\nUntil the 19th century, the most common arrangement for vocal music used the following clefs: \nIn more modern publications, four-part music on parallel staffs is usually written more simply as:\nThis may be reduced to two staffs, the soprano and alto sharing a staff with a treble clef, and the tenor and bass sharing a staff marked with the bass clef.\nFurther uses.\nClef combinations played a role in the modal system toward the end of the 16th century, and it has been suggested certain clef combinations in the polyphonic music of 16th-century vocal polyphony are reserved for authentic (odd-numbered) modes, and others for plagal (even-numbered) modes, but the precise implications have been the subject of much scholarly debate.\nReading music as if it were in a different clef from the one indicated can be an aid in transposing music at sight. Music for a treble-clef B\u266d instrument (such as trumpet) can be read as if it were in tenor clef in concert pitch, and bass-clef concert-pitch music can be read on an E\u266d instrument as if it were in treble clef. In both of these cases, key signatures and accidentals need to be adjusted.\nIn Unicode.\nFor use with computer systems, the Unicode Consortium has created code points for twelve different clef symbols as part of a repertoire called the \"Musical Symbols\" block. Although much of the list was established by 1999, general provision of these symbols in common computer fonts remains rather limited. The clef symbols provided are these:\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49218", "revid": "41833184", "url": "https://en.wikipedia.org/wiki?curid=49218", "title": "Treble clef", "text": ""}
{"id": "49219", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=49219", "title": "Bass clef", "text": ""}
{"id": "49220", "revid": "45390579", "url": "https://en.wikipedia.org/wiki?curid=49220", "title": "C (musical note)", "text": "Note in western music\n&lt;templatestyles src=\"Stack/styles.css\"/&gt;&lt;score&gt;{ \\new Staff \\with { \\remove \"Time_signature_engraver\" \\magnifyStaff #3/2 } { \\time 2/1 c'1^\"c\u2032\" \\clef bass c^\"c\" } }&lt;/score&gt;\nC or Do is the first note of the C major scale, the third note of the A minor scale (the relative minor of C major), and the fourth note (G, A, B, C) of the Guidonian hand, commonly pitched around 261.63\u00a0Hz. The actual frequency has depended on historical pitch standards, and for transposing instruments a distinction is made between written and sounding or concert pitch. It has enharmonic equivalents of B\u266f and D.\nIn English the term \"Do\" is used interchangeably with C only in the context of fixed Do solf\u00e8ge; in the movable Do system Do refers to the tonic of the prevailing key.\nFrequency.\nHistorically, concert pitch has varied. For an instrument in equal temperament tuned to the A440 pitch standard widely adopted in 1939, middle C has a frequency around 261.63\u00a0Hz (for other notes see piano key frequencies). Scientific pitch was originally proposed in 1713 by French physicist Joseph Sauveur and based on the numerically convenient frequency of 256\u00a0Hz for middle C, all C's being powers of two. After the A440 pitch standard was adopted by musicians, the Acoustical Society of America published new frequency tables for scientific use. A movement to restore the older A435 standard has used the banners \"Verdi tuning\", \"philosophical pitch\" or the easily confused scientific pitch.\nOctave nomenclature.\nMiddle C.\n&lt;score&gt;\n\\new GrandStaff \u00ab\n \\time 5/4\n \\new Staff \\with { \\remove \"Time_signature_engraver\" \\magnifyStaff 1.5 \\clef bass } { s4 s1 } \u00bb\n&lt;/score&gt; Middle C centrally set on a grand staff\nMiddle\u00a0C (the fourth C key from left on a standard 88-key piano keyboard) is designated C4 in scientific pitch notation, c\u2032 in Helmholtz pitch notation, and note number 60 in the MIDI standard.\nWhile the expression \"middle\u00a0C\" is generally clear across instruments and clefs, some musicians naturally use the term to refer to the C note in the middle of their specific instrument's range. C4 (approximately 261.626\u00a0Hz) may be called \"Low\u00a0C\" by someone playing a Western concert flute, which has a higher and narrower playing range than the piano, while C5 (523.251\u00a0Hz) would be middle\u00a0C. This practice has led some to encourage standardizing on C4 as the definitive middle\u00a0C in instructional materials across all instruments.\nOn the grand staff, middle\u00a0C is notated with a ledger line above the top line of the bass staff or below the bottom line of the treble staff. Alternatively, it is written on the centre line of a staff using the alto clef, or on the fourth line from the bottom, or the second line from the top, of staves using the tenor clef.\nOther octaves.\nIn vocal music, the term \"High C\" (sometimes called \"Top C\") can refer to either the soprano's C6 (1046.502\u00a0Hz; c\u2032\u2032\u2032 in Helmholtz notation) or the tenor's C5; soprano written as the C two ledger lines above the treble clef, with the tenor voice the space above concert A, sung an octave lower. Sometimes written with \u201c8v\u201d below the treble, to represent the octave (8 tones in a major scale).\n\"Tenor C\" is an organ builder's term for \"small C\" or C3 (130.813\u00a0Hz), the note one octave below middle C. In older stoplists it usually means that a rank was not yet full compass, omitting the bottom octave, until that octave was added later on.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Semitones/styles.css\" /&gt;Notes of the chromatic scale\nC&lt;br&gt;(B\u266f)\nC\u266f&lt;br&gt;D\u266d\nD\nD\u266f&lt;br&gt;E\u266d\nE&lt;br&gt;(F\u266d)\nF&lt;br&gt;(E\u266f)\nF\u266f&lt;br&gt;G\u266d\nG\nG\u266f&lt;br&gt;A\u266d\nA\nA\u266f&lt;br&gt;B\u266d\nB&lt;br&gt;(C\u266d)"}
{"id": "49223", "revid": "1119368166", "url": "https://en.wikipedia.org/wiki?curid=49223", "title": "G clef", "text": ""}
{"id": "49225", "revid": "13655679", "url": "https://en.wikipedia.org/wiki?curid=49225", "title": "F clef", "text": ""}
{"id": "49229", "revid": "766861", "url": "https://en.wikipedia.org/wiki?curid=49229", "title": "Staff (music)", "text": "Musical notation to represent the pitch\nIn Western musical notation, the staff (UK also stave; plural: \"staffs\" or \"staves\"), also occasionally referred to as a pentagram, is a set of five horizontal lines and four spaces that each represent a different musical pitch or in the case of a percussion staff, different percussion instruments. Appropriate music symbols, depending on the intended effect, are placed on the staff according to their corresponding pitch or function. Musical notes are placed by pitch, percussion notes are placed by instrument, and rests and other symbols are placed by convention.\nThe absolute pitch of each line of a non-percussive staff is indicated by the placement of a clef symbol at the appropriate vertical position on the left-hand side of the staff (possibly modified by conventions for specific instruments). For example, the treble clef, also known as the G clef, is placed on the second line (counting upward), fixing that line as the pitch first G above \"middle C\".\nThe lines and spaces are numbered from bottom to top; the bottom line is the \"first line\" and the top line is the \"fifth line\".\nThe musical staff is analogous to a mathematical graph of pitch with respect to time. Pitches of notes are given by their vertical position on the staff and notes are played from left to right. Unlike a graph, however, the number of semitones represented by a vertical step from a line to an adjacent space depends on the key, and the exact timing of the beginning of each note is not directly proportional to its horizontal position; rather, exact timing is encoded by the musical symbol chosen for each note in addition to the tempo.\nA time signature to the right of the clef indicates the relationship between timing counts and note symbols, while bar lines group notes on the staff into measures.\nUsage and etymology.\n\"Staff\" is more common than \"stave\" in both American English and British English. with the latter being, in fact, a back-formation from the plural \"staves\". The plural \"staffs\" also exists for \"staff\" in both American and British English, alongside the traditional plural \"staves\". In addition to the pronunciations expected from the spellings, both plural forms are also pronounced in American English.\nStaff positions.\nThe vertical position of the notehead on the staff indicates which note to play: higher-pitched notes are marked higher on the staff. The notehead can be placed with its center intersecting a line (\"on a line\") or in between the lines touching the lines above and below (\"in a space\"). Notes outside the range of the staff are placed on or between ledger lines\u2014lines the width of the note they need to hold\u2014added above or below the staff.\nWhich staff positions represent which notes is determined by a clef placed at the beginning of the staff. The clef identifies a particular line as a specific note, and all other notes are determined relative to that line. For example, the treble clef puts the G above middle C on the second line. The interval between adjacent staff positions is one step in the diatonic scale. Once fixed by a clef, the notes represented by the positions on the staff can be modified by the key signature or accidentals on individual notes. A clefless staff may be used to represent a set of percussion sounds; each line typically represents a different instrument.\nEnsemble staves.\nA vertical line drawn to the left of multiple staves creates a system, indicating that the music on all the staves is to be played simultaneously. A brace (curly bracket) is used to join multiple staves that represent an instrument, such as a piano, organ, harp, or marimba. A bracket is an additional vertical line joining staves to show groupings of instruments that function as a unit, such as the string section of an orchestra. Sometimes a second bracket is used to show instruments grouped in pairs, such as the first and second oboes or first and second violins in an orchestra. In some cases, a brace is used for this purpose.\nWhen more than one system appears on a page, often two parallel diagonal strokes are placed on the left side of the score to separate them.\nFour-part SATB vocal settings, especially in hymnals, use a \"divisi\" notation on a two-staff system with soprano and alto voices sharing the upper staff and tenor and bass voices on the lower staff.\nConfusingly, the German \"System\" (often in the combined forms \"Liniensystem\" or \"Notensystem\") may refer to a single staff as well as to the \"Akkolade\" (from the French) or system in the English sense; the Italian term is \"accollatura\".\nGrand staff.\nWhen music on two staves is joined by a brace, or is intended to be played at once by a single performer (usually a keyboard instrument or harp), a grand staff (American English) or great stave (British English) is created. Typically, the upper staff uses a treble clef and the lower staff has a bass clef. In this instance, middle C is centered between the two staffs, and it can be written on the first ledger line below the upper staff or the first ledger line above the lower staff. Very rarely, a centered line with a small C clef is written, and usually used to indicate that B, C, or D on the line can be played with either hand (ledger lines are not used from a center alto as this creates confusion). When playing the piano or harp, the upper staff is normally played with the right hand and the lower staff with the left hand. In music intended for organ with pedalboard, a grand staff normally comprises three staves, one for each hand on the manuals and one for the feet on the pedalboard.\nHistory.\nEarly Western medieval notation was written with neumes, which did not specify exact pitches but only the shape of the melodies, i.e. indicating when the musical line went up or down; presumably these were intended as mnemonics for melodies which had been taught by rote.\nDuring the 9th through 11th centuries a number of systems were developed to specify pitch more precisely, including diastematic neumes whose height on the page corresponded with their absolute pitch level (Longobardian and Beneventan manuscripts from Italy show this technique around the year 1000). Digraphic notation, using letter names similar to modern note names in conjunction with the neumes, made a brief appearance in a few manuscripts, but a number of manuscripts used one or more horizontal lines to indicate particular pitches.\nThe treatise \"Musica enchiriadis\" (c.\u2009900) uses Daseian notation for indicating specific pitches, but the modern use of staff lines is attributed to Guido d'Arezzo (990\u20131050), whose four-line staff is still used (though without the red and yellow coloring he recommended) in Gregorian chant publications today. Five-line staves appeared in Italy in the 13th century and it was promoted by Ugolino da Forl\u00ec; staves with four, five, and six lines were used as late as 1600."}
{"id": "49233", "revid": "7098284", "url": "https://en.wikipedia.org/wiki?curid=49233", "title": "Robert Goddard (disambiguation)", "text": "Robert H. Goddard (1882\u20131945) was an American scientist and pioneer of modern rocketry.\nRobert Goddard may also refer to:\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about people with the same name. "}
{"id": "49234", "revid": "46503443", "url": "https://en.wikipedia.org/wiki?curid=49234", "title": "Chromatic scale", "text": "Musical scale set of twelve pitches\nThe chromatic scale (or twelve-tone scale) is a set of twelve pitches (more completely, pitch classes) used in tonal music, with notes separated by the interval of a semitone. Chromatic instruments, such as the piano, are made to produce the chromatic scale, while other instruments capable of continuously variable pitch, such as the trombone and violin, can also produce microtones, or notes between those available on a piano.\nMost music uses subsets of the chromatic scale such as diatonic scales. While the chromatic scale is fundamental in western music theory, it is seldom directly used in its entirety in musical compositions or improvisation.\nDefinition.\nThe chromatic scale is a musical scale with twelve pitches, each a semitone, also known as a half-step, above or below its adjacent pitches. As a result, in 12-tone equal temperament (the most common tuning in Western music), the chromatic scale covers all 12 of the available pitches. Thus, there is only one chromatic scale. The ratio of the frequency of one note in the scale to that of the preceding note is given by formula_1.\nIn equal temperament, all the semitones have the same size (100 cents), and there are twelve semitones in an octave (1200 cents). As a result, the notes of an equal-tempered chromatic scale are equally-spaced.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The \"chromatic scale\"...is a series of half steps which comprises all the pitches of our [12-tone] equal-tempered system.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;All of the pitches in common use, considered together, constitute the \"chromatic scale\". It is made up entirely of successive half steps, the smallest interval in Western music...Counting by half steps, an octave includes twelve different pitches, white and black keys together. The chromatic scale, then, is a collection of all the available pitches in order upward or downward, one octave's worth after another.\u2014\u200a\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;A \"chromatic scale\" is a nondiatonic scale consisting entirely of half-step intervals. Since each tone of the scale is equidistant from the next [symmetry] it has no tonic [key]. ...\nChromaticism [is t]he introduction of some pitches of the chromatic scale into music that is basically diatonic in orientation, or music that is based on the chromatic scale instead of the diatonic scales.\u2014\u200a\nThe ascending and descending chromatic scale is shown below.\n&lt;score sound=\"1\"&gt; {\n\\override Score.TimeSignature #'stencil = ##f\n\\relative c' {\n \\clef treble \\time 12/4\n c4^\\markup { Ascending } cis d dis e f fis g gis a ais b\n c^\\markup { Descending } b bes a aes g ges f e es d des c\n&lt;/score&gt;\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The twelve notes of the octave\u2014\"all\" the black and white keys in one octave on the piano\u2014form the \"chromatic scale\". The tones of the chromatic scale (unlike those of the major or minor scale) are all the same distance apart, one half step.\nThe word \"chromatic\" comes from the Greek \"chroma\", \"color\"; and the traditional function of the chromatic scale is to color or embellish the tones of the major and minor scales. It does not define a key, but it gives a sense of motion and tension. It has long been used to evoke grief, loss, or sorrow. In the twentieth century it has also become independent of major and minor scales and is used as the basis for entire compositions.\u2014\u200a\nNotation.\nThe chromatic scale has no set enharmonic spelling that is always used. Its spelling is, however, often dependent upon major or minor key signatures and whether the scale is ascending or descending. In general, the chromatic scale is usually notated with sharp signs when ascending and flat signs when descending. It is also notated so that no scale degree is used more than twice in succession (for instance, G\u266d\u00a0\u2013 G\u266e\u00a0\u2013 G\u266f).\nSimilarly, some notes of the chromatic scale have enharmonic equivalents in solfege. The rising scale is Do, Di, Re, Ri, Mi, Fa, Fi, Sol, Si, La, Li, Ti and the descending is Ti, Te/Ta, La, Le/Lo, Sol, Se, Fa, Mi, Me/Ma, Re, Ra, Do, However, once 0 is given to a note, due to octave equivalence, the chromatic scale may be indicated unambiguously by the numbers 0-11 mod twelve. Thus two perfect fifths are 0-7-2. Tone rows, orderings used in the twelve-tone technique, are often considered this way due to the increased ease of comparing inverse intervals and forms (inversional equivalence).\nPitch-rational tunings.\nPythagorean.\nThe most common conception of the chromatic scale before the 13th century was the Pythagorean chromatic scale (). Due to a different tuning technique, the twelve semitones in this scale have two slightly different sizes. Thus, the scale is not perfectly symmetric. Many other tuning systems, developed in the ensuing centuries, share a similar asymmetry.\nIn Pythagorean tuning (i.e. 3-limit just intonation) the chromatic scale is tuned as follows, in perfect fifths from G\u266d to A\u266f centered on D (in bold) (G\u266d\u2013D\u266d\u2013A\u266d\u2013E\u266d\u2013B\u266d\u2013F\u2013C\u2013G\u2013D\u2013A\u2013E\u2013B\u2013F\u266f\u2013C\u266f\u2013G\u266f\u2013D\u266f\u2013A\u266f), with sharps \"higher\" than their enharmonic flats (cents rounded to one decimal):\nwhere &lt;templatestyles src=\"Fraction/styles.css\" /&gt;256\u2044243 is a diatonic semitone (Pythagorean limma) and &lt;templatestyles src=\"Fraction/styles.css\" /&gt;2187\u20442048 is a chromatic semitone (Pythagorean apotome).\nThe chromatic scale in Pythagorean tuning can be tempered to the 17-EDO tuning (P5 = 10 steps = 705.88 cents).\nJust intonation.\nIn 5-limit just intonation the chromatic scale, Ptolemy's intense chromatic scale, is as follows, with flats \"higher\" than their enharmonic sharps, and new notes between E\u2013F and B\u2013C (cents rounded to one decimal):\nThe fractions &lt;templatestyles src=\"Fraction/styles.css\" /&gt;9\u20448 and &lt;templatestyles src=\"Fraction/styles.css\" /&gt;10\u20449, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;6\u20445 and &lt;templatestyles src=\"Fraction/styles.css\" /&gt;32\u204427, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;5\u20444 and &lt;templatestyles src=\"Fraction/styles.css\" /&gt;81\u204464, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;4\u20443 and &lt;templatestyles src=\"Fraction/styles.css\" /&gt;27\u204420, and many other pairs are interchangeable, as &lt;templatestyles src=\"Fraction/styles.css\" /&gt;81\u204480 (the syntonic comma) is tempered out.\nJust intonation tuning can be approximated by 19-EDO tuning (P5 = 11 steps = 694.74 cents).\nNon-Western cultures.\nThe ancient Chinese chromatic scale is called \"Sh\u00ed-\u00e8r-l\u01dc\". However, \"it should not be imagined that this gamut ever functioned as a scale, and it is erroneous to refer to the 'Chinese chromatic scale', as some Western writers have done. The series of twelve notes known as the twelve \"l\u00fc\" were simply a series of fundamental notes from which scales could be constructed.\" However, \"from the standpoint of tonal music [the chromatic scale] is not an independent scale, but derives from the diatonic scale,\" making the \"Western chromatic scale\" a gamut of fundamental notes from which scales could be constructed as well.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Semitones/styles.css\" /&gt;Notes of the chromatic scale\nC&lt;br&gt;(B\u266f)\nC\u266f&lt;br&gt;D\u266d\nD\nD\u266f&lt;br&gt;E\u266d\nE&lt;br&gt;(F\u266d)\nF&lt;br&gt;(E\u266f)\nF\u266f&lt;br&gt;G\u266d\nG\nG\u266f&lt;br&gt;A\u266d\nA\nA\u266f&lt;br&gt;B\u266d\nB&lt;br&gt;(C\u266d)"}
{"id": "49236", "revid": "4082870", "url": "https://en.wikipedia.org/wiki?curid=49236", "title": "Ping pong", "text": ""}
{"id": "49237", "revid": "62", "url": "https://en.wikipedia.org/wiki?curid=49237", "title": "St. Hedwigs Kathedrale", "text": ""}
{"id": "49239", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=49239", "title": "St. Hedwig's Cathedral", "text": "Roman Catholic cathedral in Berlin, Germany\nSt. Hedwig's Cathedral () is the Catholic cathedral of the Archdiocese of Berlin on Bebelplatz in the historic centre of Berlin. Dedicated in honor of Hedwig of Silesia, it was erected from 1747 to 1773 by order of Frederick the Great according to plans by Georg Wenzeslaus von Knobelsdorff in Baroque style. Damaged during the Allied bombing in World War II, the cathedral's interior was restored from 1952 to 1963 in post-war modernist style as part of the rebuilding of the Forum Fridericianum on Bebelplatz. The listed building was closed for renovation work from 2018 and reopened on November 24, 2024 with a modern interior design.\nHistory and architecture.\nSt. Hedwig's Church was built in the 18th century following a request from local parishioners to King Frederick II. He donated the land on which the church was built. The church was dedicated to the patron of Silesia and Brandenburg, Saint Hedwig of Andechs. \nIt was the first Catholic church built in Prussia after the Reformation. The building was designed by Georg Wenzeslaus von Knobelsdorff and modelled after the Pantheon in Rome.\nConstruction started in 1747, but was interrupted and delayed several times by economic problems. It was not opened until 1 November 1773, when the king's friend, Ignacy Krasicki, the Bishop of Warmia (later Archbishop of Gniezno), officiated at the cathedral's consecration.\nAfter the Kristallnacht pogroms that took place on the night of 9\u201310 November 1938, Bernhard Lichtenberg, a canon of the cathedral chapter of St. Hedwig since 1931, prayed publicly for Jews at evening prayer. Lichtenberg was later jailed by the Nazis and died on the way to the concentration camp at Dachau. \nIn 1965, Blessed Bernhard Lichtenberg's remains were transferred to the crypt at St. Hedwig's Cathedral.\nThe cathedral was severely damaged by Allied bombing in an air raid on 1 March 1943. Only the damaged shell of the building was left standing. Reconstruction started in 1952 and on 1 November 1963, All Saints' Day, the new high altar was consecrated by the Bishop of Berlin, Alfred Cardinal Bengsch.\nBetween 1949 and 1990, St. Hedwig's was in East Berlin, under the control of the East German government.\nThe cathedral closed for major renovations on 1 September 2018. The relics of Bl. Bernhard Lichtenberg have been transferred to the crypt of Maria Regina Martyrum during the cathedral's renovation. The church of St. Joseph in Wedding is the interim location for pontifical masses. A focal point of the renovations is a hemispherical altar composed of small stones from around the diocese collected by parishioners, based on an idea proposed by Austrian artist Leo Zogmayer. The two-story interior of 1963, with a wide gallery and an awkwardly narrow opening down to the chancel, was divided into two floors, with the new church interior on the upper level.\nTapestries.\nFitting to the character of the liturgical season, a huge tapestry is hanging behind the cathedra. The cathedral owns three of them; all three share the motif of the heavenly Jerusalem.\nThe tapestry of former Bauhaus student Margaretha Reichardt (Grete Reichardt) (1907\u20131984) of Erfurt was handwoven in 1963. It depicts a stylised city with the names of the apostles inscribed on foundation stones. God is represented by the Tree of Life and a lamb features as a symbol of Christ. Anton Wendling (1891\u20131965) made a colorful appliqu\u00e9 work. It is a geometric composition using themes from the Book of Revelation. The three-part woven carpet made by Else Bechteler-Moses (born 1933) was made in cooperation with N\u00fcrnberger Gobelinmanufaktur GmbH, a tapestry weaving company, between 1979 and 1981. This also uses themes from Revelations.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49240", "revid": "27326122", "url": "https://en.wikipedia.org/wiki?curid=49240", "title": "Patrice Lumumba", "text": "Congolese politician and independence leader (1925\u20131961)\nPatrice \u00c9mery Lumumba ( ; born Isa\u00efe Tasumbu Tawosa; 2 July 1925\u00a0\u2013 17 January 1961) was a Congolese politician and independence leader who served as the first prime minister of the Democratic Republic of the Congo (then known as the Republic of the Congo) from June until September 1960, following the May 1960 election. He was the leader of the Congolese National Movement (MNC) from 1958 until his assassination in 1961. Ideologically an African nationalist and pan-Africanist, he played a significant role in the transformation of the Congo from a colony of Belgium into an independent republic.\nShortly after Congolese independence in June 1960, a mutiny broke out in the army, marking the beginning of the Congo Crisis. After a coup, Lumumba attempted to escape to Stanleyville to join his supporters who had established a new anti-Mobutu state called the Free Republic of the Congo. Lumumba was captured en route by state authorities under Joseph-D\u00e9sir\u00e9 Mobutu, sent to the State of Katanga and, with the help of Belgian mercenaries, tortured and executed by the separatist Katangan authorities of Mo\u00efse Tshombe. In 2002, Belgium formally apologised for its role in the execution, admitting \"moral responsibility\", and in 2022, they returned Lumumba\u2019s tooth to his family. He is seen as a martyr for the pan-African movement.\nEarly life and career.\nPatrice Lumumba was born on 2 July 1925 as Isa\u00efe Tasumbu Tawosa to Julienne Wamato Lomendja and her husband, Fran\u00e7ois Tolenga Otetshima, a farmer, in Onalua, in the Katakokombe region of the Kasai province of the Belgian Congo. He was a member of the Tetela ethnic group, where he was referred to with the name \u00c9lias Okit'Asombo. His original surname means \"heir of the cursed\" and is derived from the Tetela words / ('heir', 'successor') and ('cursed or bewitched people who will die quickly'). He had three brothers (Charles Lokolonga, \u00c9mile Kalema, and Louis Onema Pene Lumumba) and one half-brother (Jean Tolenga). Raised in a Catholic family, he was educated at a Protestant primary school, a Catholic missionary school, and finally the government post office training school, where he passed the one-year course with distinction. He was known for being a vocal, precocious young man, regularly pointing out the errors of his teachers in front of his peers. This outspoken nature would come to define his life and career. Lumumba spoke Tetela, French, Lingala, Swahili, and Tshiluba.\nOutside of his regular studies, Lumumba took an interest in the Enlightenment ideals of Jean-Jacques Rousseau and Voltaire. He was also fond of Moli\u00e8re and Victor Hugo. He wrote poetry, and many of his works had anti-imperialist themes. He worked as a travelling beer salesman in L\u00e9opoldville and as a postal clerk in Stanleyville for eleven years. Lumumba was married three times. He married Henriette Maletaua a year after arriving in Stanleyville; they divorced in 1947. In the same year, he married Hortense Sombosia, but this relationship also fell apart. He began an affair with Pauline Kie. While he had no children with his first two wives, his relationship with Kie resulted in a son, Fran\u00e7ois Lumumba. Though he remained close with Kie until his death, Lumumba ultimately ended their affair to marry Pauline Opangu in 1951.\nIn the period following World War II, young leaders across Africa increasingly worked for national goals and independence from the colonial powers. In 1952 he was hired to work as a personal assistant for French sociologist Pierre Cl\u00e9ment, who was performing a study of Stanleyville. That year he also co-founded and subsequently became president of a Stanleyville chapter of the Association des Anciens \u00e9l\u00e8ves des p\u00e8res de Scheut (ADAP\u00c9S), an alumni association for former students at Scheut schools, despite the fact that he had never attended one. In 1955, Lumumba became regional head of the \"Cercles\" of Stanleyville and joined the Liberal Party of Belgium. He edited and distributed party literature. Between 1956 and 1957 he wrote his autobiography (which was published posthumously in 1962). After a study tour in Belgium in 1956, he was arrested on charges of embezzlement of $2500 from the post office. He was convicted and sentenced one year later to 12 months' imprisonment and a fine.\nLeader of the MNC.\nAfter his release, Lumumba helped found the \"Mouvement National Congolais\" (MNC) party in 1958 and quickly became the organisation's leader. The MNC, unlike other Congolese parties developing at the time, did not draw on a particular ethnic base. It promoted a platform that included independence, gradual Africanisation of the government, state-led economic development, and neutrality in foreign affairs. Lumumba had a large popular following and as a result, he had more political autonomy than contemporaries who were more dependent on Belgian connections. Lumumba was one of the delegates who represented the MNC at the All-African Peoples' Conference in Accra, Ghana, in December 1958. At this international conference, hosted by Ghanaian president Kwame Nkrumah, Lumumba further solidified his pan-Africanist credentials. Nkrumah was personally impressed by Lumumba's intelligence and ability.\nIn 1959, the MNC split into the majority MNC-L, led by Lumumba, and the more radical and federalist MNC-K. In late October 1959, Lumumba, as leader of the MNC, was arrested for inciting an anti-colonial riot in Stanleyville during which 30 people were killed. He was sentenced to six months in prison. The trial's start date of 18 January 1960 was the first day of the Congolese Round Table Conference in Brussels, intended to make a plan for the future of the Congo. Despite Lumumba's imprisonment, the MNC won a convincing majority in the December local elections in the Congo. As a result of strong pressure from delegates upset by Lumumba's trial, he was released and allowed to attend the Brussels conference.\nIndependence and election as prime minister.\nThe conference culminated on 27 January 1960 with a declaration of Congolese independence. It set 30 June 1960 as the independence date with national elections to be held from 11 to 25 May 1960. The MNC won a plurality in the election. Six weeks before the date of independence, Walter Ganshof van der Meersch was appointed as the Belgian Minister of African Affairs. He lived in L\u00e9opoldville, in effect becoming Belgium's \"de facto\" resident minister in the Congo, administering it jointly with Governor-general Hendrik Cornelis. He was charged with advising King Baudouin on the selection of a .\nOn 8 June 1960, Ganshof flew to Brussels to meet with Baudouin. He made three suggestions for : Lumumba, as the winner of the elections; Joseph Kasa-Vubu, the only figure with a reliable national reputation who was associated with the coalescing opposition; or some to-be-determined third individual who could unite the competing blocs. Ganshof returned to the Congo on 12 June 1960. The following day he appointed Lumumba to serve as the delegate () tasked with investigating the possibility of forming a national unity government that included politicians with a wide range of views, with 16 June 1960 as his deadline.\nThe same day as Lumumba's appointment, the parliamentary opposition coalition, the , was announced. Though Kasa-Vubu was aligned with their beliefs, he remained distanced from them. The MNC-L was also having trouble securing the allegiances of the PSA, CEREA (), and BALUBAKAT (). Initially, Lumumba was unable to establish contact with members of the cartel. Eventually several leaders were appointed to meet with him, but their positions remained entrenched. On 16 June 1960, Lumumba reported his difficulties to Ganshof, who extended the deadline and promised to act as an intermediary between the MNC-L leader and the opposition. Once Ganshof had made contact with the cartel leadership, he was impressed by their obstinacy and assurances of a strong anti-Lumumba polity. By evening, Lumumba's mission was showing even less chance of succeeding. Ganshof considered extending the role of to Cyrille Adoula and Kasa-Vubu, but faced increasing pressure from Belgian and moderate Congolese advisers to end Lumumba's assignment.\nThe following day, on 17 June 1960, Ganshof declared that Lumumba had failed and terminated his mission. Acting on Ganshof's advice, Baudouin then named Kasa-Vubu . Lumumba responded by threatening to form his own government and present it to parliament without official approval. He called a meeting at the OK Bar in L\u00e9opoldville, where he announced the creation of a \"popular\" government with the support of Pierre Mulele of the PSA. Meanwhile, Kasa-Vubu, like Lumumba, was unable to communicate with his political opponents.\nHe assumed that he would secure the presidency, so he began looking for someone to serve as his prime minister. Most of the candidates he considered were friends who had foreign support similar to his own, including Albert Kalonji, Joseph Il\u00e9o, Cyrille Adoula, and Justin Bomboko. Kasa-Vubu was slow to come to a final decision. On 18 June 1960, Kasa-Vubu announced that he had completed his government with all parties except the MNC-L. That afternoon Jason Sendwe, Antoine Gizenga, and Anicet Kashamura announced in the presence of Lumumba that their respective parties were not committed to the government. The next day, on 19 June 1960, Ganshof summoned Kasa-Vubu and Lumumba to a meeting so they could forge a compromise. This failed when Lumumba flatly refused the position of prime minister in a Kasa-Vubu government.\nThe following day, on 20 June 1960, the two rivals met in the presence of Adoula and diplomats from Israel and Ghana, but no agreement was reached. Most party leaders refused to support a government that did not include Lumumba. The decision to make Kasa-Vubu the was a catalyst that rallied the PSA, CEREA, and BALUBAKAT to Lumumba, making it unlikely that Kasa-Vubu could form a government that would survive a vote of confidence. When the chamber met, on 21 June 1960, to select its officers, Joseph Kasongo of the MNC-L was elected president with 74 votes (a majority), while the two vice presidencies were secured by the PSA and CEREA candidates, both of whom had the support of Lumumba. With time running out before independence, Baudouin took new advice from Ganshof and appointed Lumumba as .\nOnce it was apparent that Lumumba's bloc controlled parliament, several members of the opposition became eager to negotiate for a coalition government in order to share power. By 22 June 1960, Lumumba had a government list, but negotiations continued with Jean Bolikango, Albert Delvaux, and Kasa-Vubu. Lumumba reportedly offered the Alliance of Bakongo (ABAKO) the ministerial positions for foreign affairs and middle classes, but Kasa-Vubu instead demanded the ministry of finance, a minister of state, the secretary of state for the interior, and a written pledge of support from the MNC-L and its allies for his presidential candidacy. Kalonji was presented with the agriculture portfolio by Lumumba, which he rejected, although he was suitable due to his experience as an agricultural engineer. Adoula was also offered a ministerial position, but refused to accept it.\nBy the morning of 23 June 1960, the government was, in the words of Lumumba, \"practically formed\". At noon, he made a counter-offer to Kasa-Vubu, who instead responded with a letter demanding the creation of a seventh province for the Bakongo. Lumumba refused to comply and instead pledged to support Jean Bolikango in his bid for the presidency. At 14:45, Lumumba presented his proposed government before the press. Neither the ABAKO nor the MNC-Kalonji (MNC-K) were represented among the ministers, and the only PSA members were from Gizenga's wing of the party. The Bakongo of L\u00e9opoldville were deeply upset by their exclusion from Lumumba's cabinet. They subsequently demanded the removal of the PSA-dominated provincial government and called for a general strike to begin the following morning. At 16:00, Lumumba and Kasa-Vubu resumed negotiations. Kasa-Vubu eventually agreed to Lumumba's earlier offer, though Lumumba informed him that he could not give him a guarantee of support in his presidential candidacy.\nThe resulting 37-strong Lumumba government was very diverse, with its members coming from different classes, different tribes, and holding varied political beliefs. Though many had questionable loyalty to Lumumba, most did not openly contradict him out of political considerations or fear of reprisal. At 22:40 on 23 June 1960, the Chamber of Deputies convened in the to vote on Lumumba's government. After Kasongo opened the session, Lumumba delivered his main speech, promising to maintain national unity, abide by the will of the people, and pursue a neutralist foreign policy. It was warmly received by most deputies and observers.\nThe chamber proceeded to engage in a heated debate. Though the government contained members from parties that held 120 of the 137 seats, reaching a majority was not a straightforward task. While several leaders of the opposition had been involved in the formative negotiations, their parties as a whole had not been consulted. Furthermore, some individuals were upset they had not been included in the government and sought to personally prevent its investiture. In the subsequent arguments, multiple deputies expressed dissatisfaction at the lack of representation of their respective provinces and/or parties, with several threatening secession. Among them was Kalonji, who said he would encourage people of Kasa\u00ef to refrain from participating in the central government and form their own autonomous state. One Katangese deputy objected to the same person being appointed as premier and as head of the defence portfolio.\nWhen a vote was finally taken, only 80 of the 137 members of the chamber were present. Of these, 74 voted in favour of the government, five against, and one abstained. The 57 absences were almost all voluntary. Though the government had earned just as many votes as when Kasongo won the presidency of the chamber, the support was not congruent; members of Cl\u00e9ophas Kamitatu's wing of the PSA had voted against the government while a few members of the PNP, PUNA, and ABAKO voted in favour of it. Overall, the vote was a disappointment for the MNC-L coalition.\nThe session was adjourned at 02:05 on 24 June 1960. The senate convened that day to vote on the government. There was another heated debate, in which Il\u00e9o and Adoula expressed their strong dissatisfaction with its composition. Confederation of Tribal Associations of Katanga (CONAKAT) members abstained from voting. When arguments concluded, a decisive vote of approval was taken on the government: 60 voted in favour, 12 against, while eight abstained. All dissident arguments for alternative cabinets, particularly Kalonji's demand for a new administration, were rendered impotent, and the Lumumba government was officially invested. With the institution of a broad coalition, the parliamentary opposition was officially reduced to only the MNC-K and some individuals.\nAt the onset of his premiership, Lumumba had two main goals: to ensure that independence would bring a legitimate improvement in the quality of life for the Congolese and to unify the country as a centralised state by eliminating tribalism and regionalism. He was worried that opposition to his government would appear rapidly and would have to be managed quickly and decisively.\nTo achieve the first aim, Lumumba believed that a comprehensive \"Africanisation\" of the administration, in spite of its risks, would be necessary. The Belgians were opposed to such an idea, as it would create inefficiency in the Congo's bureaucracy and lead to a mass exodus of unemployed civil servants to Belgium, whom they would be unable to absorb into the government there. It was too late for Lumumba to enact Africanisation before independence. Seeking another gesture that might excite the Congolese people, Lumumba proposed to the Belgian government a reduction in sentences for all prisoners and an amnesty for those serving a term of three years or less. Ganshof feared that such an action would jeopardise law and order, and he evaded taking any action until it was too late to fulfill the request. Lumumba's opinion of the Belgians was soured by this affair, which contributed to his fear that independence would not appear \"real\" to the average Congolese.\nIn seeking to eliminate tribalism and regionalism in the Congo, Lumumba was deeply inspired by the personality and undertakings of Kwame Nkrumah and by Ghanaian ideas of the leadership necessary in post-colonial Africa. He worked to seek such changes through the MNC. Lumumba intended to combine it with its parliamentary allies\u2014CEREA, the PSA, and possibly BALUBAKAT\u2014to form one national party, and to build a following in each province. He hoped it would absorb other parties and become a unifying force for the country.\nIndependence Day was celebrated on 30 June 1960 in a ceremony attended by many dignitaries, including King Baudouin of Belgium and the foreign press. Baudouin's speech praised developments under colonialism, his reference to the \"genius\" of his great-granduncle Leopold II of Belgium, glossing over atrocities committed during his reign over the Congo Free State. The King continued, \"Don't compromise the future with hasty reforms, and don't replace the structures that Belgium hands over to you until you are sure you can do better. Don't be afraid to come to us. We will remain by your side, give you advice.\"\nLumumba, who had not been scheduled to speak, delivered an impromptu speech that reminded the audience that the independence of the Congo had not been granted magnanimously by Belgium:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For this independence of the Congo, although being proclaimed today by agreement with Belgium, an amicable country, with which we are on equal terms, no Congolese worthy of the name will ever be able to forget that it was by fighting that it has been won, a day-to-day fight, an ardent and idealistic fight, a fight in which we were spared neither privation nor suffering, and for which we gave our strength and our blood. We are proud of this struggle, of tears, of fire, and of blood, to the depths of our being, for it was a noble and just struggle, and indispensable to put an end to the humiliating slavery which was imposed upon us by force.\nMost European journalists were shocked by the stridency of Lumumba's speech. The Western media criticised him. \"Time\" magazine characterised his speech as a \"vicious attack\".\nPrime minister.\nIndependence.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nEvery morning at seven o'clock he sat at the huge desk, embellished with the forgotten coat of arms of colonial Belgium; a golden lion in a blue shield. There the Premier first received his immediate assistants, set up the schedule for the day, went over correspondence, which he answered. Without a stop until evening he was receiving salesmen, petitioners, donors, experts, businessmen, and diplomats, the most variegated crowd that ever walked on the market\u00a0... everybody wanted to deal exclusively with Lumumba.\nPrime Minister's Press Secretary Serge Michel\nIndependence Day and the three days that followed it were declared a national holiday. The Congolese were preoccupied by the festivities, which were conducted in relative peace. Meanwhile, Lumumba's office was overtaken by a flurry of activity. A diverse group of individuals, Congolese and European, some friends and relatives, hurried about their work. Some undertook specific missions on his behalf, sometimes without direct permission. Numerous Congolese citizens showed up at the office at whim for various reasons. Lumumba, for his part, was mostly preoccupied with a lengthy itinerary of receptions and ceremonies. On 3 July Lumumba declared a general amnesty for prisoners, but it was never implemented. The following morning he convened the Council of Ministers to discuss the unrest among the troops of the Force Publique.\nMany soldiers hoped that independence would result in immediate promotions and material gains, but were disappointed by Lumumba's slow pace of reform. The rank-and-file felt that the Congolese political class\u2014particularly ministers in the new government\u2014were enriching themselves while failing to improve the troops' situation. Many of the soldiers were also fatigued from maintaining order during the elections and participating in independence celebrations. The ministers decided to establish four committees to study, respectively, the reorganisation of the administration, the judiciary, and the army, and the enacting of a new statute for state employees. All were to devote special attention to ending racial discrimination. Parliament assembled for the first time since independence and took its first official legislative action by voting to increase the salaries of its members to FC 500,000. Lumumba, fearing the repercussions the raise would have on the budget, was among the few to object, dubbing it a \"ruinous folly\".\nOutbreak of the Congo Crisis.\nOn the morning of 5 July 1960, General \u00c9mile Janssens, commander of the Force Publique, in response to increasing excitement among the Congolese ranks, summoned all troops on duty at Camp L\u00e9opold II. He demanded that the army maintain its discipline and wrote \"before independence = after independence\" on a blackboard for emphasis. That evening the Congolese sacked the canteen in protest of Janssens. He alerted the reserve garrison of Camp Hardy, 95 miles away in Thysville. The officers tried to organise a convoy to send to Camp L\u00e9opold II to restore order, but the men mutinied and seized the armoury. The crisis which followed came to dominate the tenure of the Lumumba government. The next day Lumumba dismissed Janssens and promoted all Congolese soldiers one grade, but mutinies spread out into the Lower Congo.\nAlthough the trouble was highly localised, the country seemed to be overrun by gangs of soldiers and looters. The media reported that Europeans were fleeing the country. In response, Lumumba announced over the radio, \"Thoroughgoing reforms are planned in all sectors. My government will make every possible effort to see that our country has a different face in a few months, a few weeks.\" In spite of government efforts, the mutinies continued. Mutineers in Leopoldville and Thysville surrendered only upon the personal intervention of Lumumba and President Kasa-Vubu.\nOn 8 July, Lumumba renamed the Force Publique as the (ANC). He Africanised the force by appointing Sergeant Major Victor Lundula as general and commander-in-chief, and chose junior minister and former soldier Joseph Mobutu as colonel and Army chief of staff. These promotions were made in spite of Lundula's inexperience and rumours about Mobutu's ties to Belgian and US intelligence services. All European officers in the army were replaced with Africans, with a few retained as advisers. By the next day the mutinies had spread throughout the entire country. Five Europeans, including the Italian vice-consul, were ambushed and killed by machine gun fire in \u00c9lisabethville, and nearly the entire European population of Luluabourg barricaded itself in an office building for safety. An estimated two dozen Europeans were murdered in the mutiny. Lumumba and Kasa-Vubu embarked on a tour across the country to promote peace and appoint new army commanders.\nBelgium intervened on 10 July, dispatching 6,000 troops to the Congo, ostensibly to protect its citizens from the violence. Most Europeans went to Katanga Province, which possessed much of the Congo's natural resources. Though personally angered, Lumumba condoned the action on 11 July, provided that the Belgian forces acted only to protect their citizens, followed the direction of the Congolese armed forces, and ceased their activities once order was restored. The same day the Belgian Navy bombarded Matadi after it had evacuated its citizens, killing 19 Congolese civilians. This greatly inflamed tensions, leading to renewed Congolese attacks on Europeans. Shortly thereafter Belgian forces moved to occupy cities throughout the country, including the capital, where they clashed with Congolese soldiers. On the whole, the Belgian intervention made the situation worse for the armed forces.\nThe State of Katanga declared independence under regional premier Mo\u00efse Tshombe on 11 July, with support from the Belgian government and mining companies such as Union Mini\u00e8re. Lumumba and Kasa-Vubu were denied use of \u00c9lisabethville's airstrip the following day and returned to the capital, only to be accosted by fleeing Belgians. They sent a protest of the Belgian deployment to the United Nations, requesting that they withdraw and be replaced by an international peacekeeping force. The UN Security Council passed United Nations Security Council Resolution 143, calling for immediate removal of Belgian forces and establishment of the United Nations Operation in the Congo (ONUC). Despite the arrival of UN troops, unrest continued. Lumumba requested UN troops to suppress the rebellion in Katanga, but the UN forces were not authorised to do so under their mandate. On 14 July Lumumba and Kasa-Vubu broke off diplomatic relations with Belgium. Frustrated at dealing with the West, they sent a telegram to Soviet Premier Nikita Khrushchev, requesting that he closely monitor the situation in the Congo.\nVisit to the United States.\nLumumba decided to travel to New York City in order to personally express the position of his government to the United Nations. Shortly before his departure, he announced that he had signed an economic agreement with a U.S. businessman who had created the Congo International Management Corporation (CIMCO). According to the contract (which had yet to be ratified by parliament), CIMCO was to form a development corporation to invest in and manage certain sectors of the economy. He also declared his approval of the second security council resolution, adding that \"[Soviet] aid was no longer necessary\" and announced his intention to seek technical assistance from the United States. On 22 July Lumumba left the Congo for New York City. He and his entourage reached the United States two days later after brief stops in Accra and London. There they rendezvoused with his UN delegation at the Barclay Hotel to prepare for meetings with UN officials. Lumumba was focused on discussing the withdrawal of Belgian troops and various options for technical assistance with Dag Hammarskj\u00f6ld.\nAfrican diplomats were keen that the meetings would be successful; they convinced Lumumba to wait until the Congo was more stable before reaching any more major economic agreements (such as the CIMCO arrangement). Lumumba saw Hammarskj\u00f6ld and other staff of the UN Secretariat over three days on 24, 25, and 26 July. Though Lumumba and Hammarskj\u00f6ld were restrained towards one another, their discussions went smoothly. In a press conference, Lumumba reaffirmed his government's commitment to \"positive neutralism\".\nOn 27 July, Lumumba went to Washington, D.C. to meet with the US Secretary of State and appeal for financial and technical assistance. The US government informed Lumumba that they would offer aid only through the UN. The following day he received a telegram from Gizenga detailing a clash at Kolwezi between Belgian and Congolese forces. Lumumba felt that the UN was hampering his attempts to expel the Belgian troops and defeat the Katangan rebels. On 29 July, Lumumba went to Ottawa, the capital of Canada, to request help. The Canadians rebuffed a request for technicians and said that they would channel their assistance through the UN. Frustrated, Lumumba met with the Soviet ambassador in Ottawa and discussed a donation of military equipment. When he returned to New York the following evening, he was restrained towards the UN. The United States government's attitude had become more negative, due to reports of the rapes and violence committed by ANC soldiers, and scrutiny from Belgium. The latter was chagrined that Lumumba had received a high-level reception in Washington. The Belgian government regarded Lumumba as communist, anti-white, and anti-Western. Given its experience in the Congo, many other Western governments gave credence to the Belgian view.\nFrustrated with the UN's apparent inaction towards Katanga as he departed the US, Lumumba decided to delay his return to the Congo. He visited several African states. This was apparently done to put pressure on Hammarskj\u00f6ld and, failing that, to seek guarantees of bilateral military support to suppress Katanga. Between 2 and 8 August, Lumumba toured Tunisia, Morocco, Guinea, Ghana, Liberia, and Togo. He was well received in each country and issued joint communiques with their respective heads of state. Guinea and Ghana pledged independent military support, while the others expressed their desire to work through the United Nations to resolve the Katangan secession. In Ghana, Lumumba signed a secret agreement with President Nkrumah providing for a \"Union of African States\". Centred in L\u00e9opoldville, it was to be a federation with a republican government. They agreed to hold a summit of African states in L\u00e9opoldville between 25 and 30 August to further discuss the issue. Lumumba returned to the Congo, apparently confident that he could now depend upon African military assistance. He also believed that he could procure African bilateral technical aid, which placed him at odds with Hammarskj\u00f6ld's goal of funnelling support through ONUC. Lumumba and some ministers were wary of the UN option, as it would supply them with functionaries who would not respond directly to their authority.\nAttempts at re-consolidation.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nThe government has declared a state of emergency throughout the whole country\u00a0... Those who confuse subversive maneuvers with freedom, obstruction with democratic opposition, or their personal interest with that of the nation will soon be judged by the people. Those who are paid today by the enemies of freedom for the purpose of maintaining sedition movements across the country and thereby disturbing the social peace will be punished with the utmost energy\u00a0...\nLumumba's statement to the press, 10 August 1960 (translated from French)\nOn 9 August, Lumumba proclaimed a state of emergency throughout the Congo. He subsequently issued several orders in an attempt to reassert his dominance on the political scene. The first outlawed the formation of associations without government sanction. A second asserted the government's right to ban publications that produced material likely to bring the administration into disrepute. On 11 August the printed an editorial which declared that the Congolese did not want to fall \"under a second kind of slavery\". The editor was summarily arrested and four days later publication of the daily ceased. Shortly afterward, the government shut down the Belga and Agence France-Presse wire services. The press restrictions garnered a wave of harsh criticism from the Belgian media.\nLumumba decreed the nationalisation of local Belga offices, creating the , as a means of eliminating what he considered a centre of biased reporting, as well as creating a service through which the government's platform could be more easily communicated to the public. Another order stipulated that official approval had to be obtained six days in advance of public gatherings. On 16 August Lumumba announced the installation of a for the duration of six months.\nThroughout August, Lumumba increasingly withdrew from his full cabinet and instead consulted with officials and ministers he trusted, such as Maurice Mpolo, Joseph Mbuyi, Kashamura, Gizenga, and Antoine Kiwewa. Lumumba's office was in disarray, and few members of his staff did any work. His , Damien Kandolo, was often absent and acted as a spy on behalf of the Belgian government. Lumumba was constantly being delivered rumours from informants and the , encouraging him to grow deeply suspicious of others. In an attempt to keep him informed, Serge Michel, his press secretary, enlisted the assistance of three Belgian telex operators, who supplied him with copies of all outgoing journalistic dispatches.\nLumumba immediately ordered Congolese troops to put down the rebellion in secessionist South Kasai, which was home to strategic rail links necessary for a campaign in Katanga. The operation was successful, but the conflict soon devolved into ethnic violence. The army became involved in massacres of Luba civilians. The people and politicians of South Kasai held Lumumba personally responsible for the actions of the army. Kasa-Vubu publicly announced that only a federalist government could bring peace and stability to the Congo. This broke his tenuous political alliance with Lumumba and tilted the political favour in the country away from Lumumba's unitary state. Ethnic tensions rose against him (especially around Leopoldville), and the Catholic Church, still powerful in the country, openly criticised his government. Even with South Kasai subdued, the Congo lacked the necessary strength to retake Katanga. Lumumba had summoned an African conference in Leopoldville from 25 to 31 August, but no foreign heads of state appeared and no country pledged military support. Lumumba demanded once again that UN peacekeeping soldiers assist in suppressing the revolt, threatening to bring in Soviet troops if they refused. The UN subsequently denied Lumumba the use of its forces. The possibility of a direct Soviet intervention was thought increasingly likely.\nDismissal.\nKasa-Vubu's revocation order.\nPresident Kasa-Vubu began fearing a Lumumbist coup d'\u00e9tat would take place. On the evening of 5 September, Kasa-Vubu announced over radio that he had dismissed Lumumba and six of his ministers from the government for the massacres in South Kasai and for involving the Soviets in the Congo. Upon hearing the broadcast, Lumumba went to the national radio station, which was under UN guard. Though they had been ordered to bar Lumumba's entry, the UN troops allowed the prime minister in, as they had no specific instructions to use force against him. Lumumba denounced his dismissal over the radio as illegitimate, and in turn labelled Kasa-Vubu a traitor and declared him deposed. Kasa-Vubu had not declared the approval of any responsible ministers of his decision, making his action legally invalid. Lumumba noted this in a letter to Hammarskj\u00f6ld and a radio broadcast at 05:30 on 6 September. Later that day Kasa-Vubu managed to secure the countersignatures to his order of Albert Delvaux, Minister Resident in Belgium, and Justin Marie Bomboko, Minister of Foreign Affairs. With them, he announced again his dismissal of Lumumba and six other ministers at 16:00 over Brazzaville radio.\nLumumba and the ministers who remained loyal to him ordered the arrest of Delvaux and Bomboko for countersigning the dismissal order. The latter sought refuge in the presidential palace (which was guarded by UN peacekeepers), but early in the morning on 7 September, the former was detained and confined in the Prime Minister's residence. Meanwhile, the Chamber of Deputies convened to discuss Kasa-Vubu's dismissal order and hear Lumumba's reply. Delvaux made an unexpected appearance and took to the dais to denounce his arrest and declare his resignation from the government. He was enthusiastically applauded by the opposition. Lumumba then delivered his speech. Instead of directly attacking Kasa-Vubu \"ad hominem\", Lumumba accused obstructionist politicians and ABAKO of using the presidency as a front for disguising their activities. He noted that Kasa-Vubu had never before offered any criticism of the government and portrayed their relationship as one of cooperation. He lambasted Delvaux and Minister of Finance Pascal Nkayi for their role in the UN Geneva negotiations and for their failure to consult the rest of the government. Lumumba followed his arguments with an analysis of the \"Loi Fondemental\" and finished by asking Parliament to assemble a \"commission of sages\" to examine the Congo's troubles.\nThe Chamber, at the suggestion of its presiding officer, voted to annul both Kasa-Vubu's and Lumumba's declarations of dismissal, 60 to 19. The following day Lumumba delivered a similar speech before the Senate, which subsequently delivered the government a vote of confidence, 49 to zero with seven abstentions. According to Article 51, Parliament was granted the \"exclusive privilege\" to interpret the constitution. In cases of doubt and controversy, the Congolese were originally supposed to appeal constitutional questions to the Belgian Conseil d'\u00c9tat. With the rupture of relations in July this was no longer possible, so no authoritative interpretation or mediation was available to bring a legal resolution to the dispute. Numerous African diplomats and newly appointed ONUC head Rajeshwar Dayal attempted to get the president and prime minister to reconcile their differences, but failed. On 13 September, the Parliament held a joint session between the Chamber of Deputies and the Senate. Though several members short of a quorum, they voted to grant Lumumba emergency powers.\nMobutu's coup.\nOn 14 September Mobutu announced over the radio that he was launching a \"peaceful revolution\" to break the political impasse and therefore neutralising the President, Lumumba's and Il\u00e9o's respective governments, and Parliament until 31 December. He stated that \"technicians\" would run the administration while the politicians sorted out their differences. In a subsequent press conference, he clarified that Congolese university graduates would be asked to form a government, and further declared that all Eastern Bloc countries should close their embassies. Lumumba was surprised by the coup and that evening he travelled to Camp Leopold II in search of Mobutu to try and change his mind. He spent the night there but was attacked in the morning by Luba soldiers, who blamed him for the atrocities in South Kasa\u00ef. A Ghanaian ONUC contingent managed to extricate him, but his briefcase was left behind. Some of his political opponents recovered it and published documents it supposedly contained, including letters from Nkrumah, appeals for support addressed to the Soviet Union and the People's Republic of China, a memorandum dated 16 September declaring the presence of Soviet troops within one week, and a letter dated 15 September from Lumumba to the provincial presidents (Tshombe excepted) entitled \"Measures to be applied during the first stages of the dictatorship\". Some of these papers were genuine, while others, especially the memorandum and the letter to the provincial presidents, were almost certainly forgeries.\nDespite the coup, African diplomats still worked towards a reconciliation between Lumumba and Kasa-Vubu. According to the Ghanaians, a verbal agreement of principle concerning closer co-operation between the Head of State and the government was put into writing. Lumumba signed it, but Kasa-Vubu suddenly refused to reciprocate. The Ghanaians suspected that Belgium and the United States were responsible. Kasa-Vubu was eager to re-integrate Katanga back into the Congo through negotiation, and Tshombe had declared that he would not participate in any discussions with a government that included the \"communist\" Lumumba.\nAfter consultation with Kasa-Vubu and Lumumba, Mobutu announced that he would summon a round table conference to discuss the political future of the Congo. His attempts to follow through were disrupted by Lumumba who, from his official residence, was acting as though he still held the premiership. He continued to hold meetings with members of his government, senators, deputies, and political supporters, and to issue public statements. On numerous occasions he left his residence to tour the restaurants of the capital, maintaining that he still held power. Frustrated by the way he was being treated by Lumumba and facing intense political pressure, by the end of the month Mobutu was no longer encouraging reconciliation; he had aligned with Kasa-Vubu. He ordered ANC units to surround Lumumba's residence, but a cordon of UN peacekeepers prevented them from making an arrest. Lumumba was confined to his home. On 7 October Lumumba announced the formation of a new government that included Bolikango and Kalonji, but he later proposed that the UN supervise a national referendum that would settle the split in the government.\nOn 24 November, the UN voted to recognise Mobutu's new delegates to the General Assembly, disregarding Lumumba's original appointees. Lumumba resolved to join Deputy Prime Minister Antoine Gizenga in Stanleyville and lead a campaign to regain power. On 27 November he left the capital in a convoy of nine cars with R\u00e9my Mwamba, Pierre Mulele, his wife Pauline, and his youngest child. Instead of heading with all haste to the Orientale Province border\u2014where soldiers loyal to Gizenga were waiting to receive him\u2014Lumumba delayed by touring villages and making conversation with the locals. On 1 December Mobutu's troops caught up with his party as it crossed the Sankuru River in Lodi. Lumumba and his advisers had made it to the far side, but his wife and child were left to be captured on the bank. Fearing for their safety, Lumumba took the ferry back, against the advice of Mwamba and Mulele, who both, fearing they would never see him again, bid him farewell. Mobutu's men arrested him. He was moved to Port Francqui the next day and flown back to L\u00e9opoldville. Mobutu claimed Lumumba would be tried for inciting the army to rebellion and other crimes.\nUN response.\nHammarskj\u00f6ld made an appeal to Kasa-Vubu asking that Lumumba be treated according to due process. The Soviet Union denounced Hammarskj\u00f6ld and the First World as responsible for Lumumba's arrest and demanded his release.\nThe United Nations Security Council was called into session on 7 December 1960 to consider Soviet demands that the UN seek Lumumba's immediate release, the immediate restoration of Lumumba as head of the Congo government, the disarming of the forces of Mobutu, and the immediate evacuation of Belgians from the Congo. The Soviets also requested the immediate resignation of Hammarskj\u00f6ld, the arrests of Mobutu and Tshombe, and the withdrawal of UN peacekeeping forces. Hammarskj\u00f6ld, answering Soviet criticism of his Congo operations, said that if the UN forces were withdrawn from the Congo, \"I fear everything will crumble.\"\nThe threat to the UN cause was intensified by the announcement of the withdrawal of their contingents by Yugoslavia, the United Arab Republic, Ceylon, Indonesia, Morocco, and Guinea. The pro-Lumumba resolution was defeated on 14 December 1960 by a vote of 8\u20132. On the same day, a Western resolution that would have given Hammarskj\u00f6ld increased powers to deal with the Congo situation was vetoed by the Soviet Union.\nFinal days and assassination.\nLumumba was sent first on 3 December 1960 to the Thysville military barracks at Camp Hardy, 150\u00a0km (about 100 miles) from L\u00e9opoldville. He was accompanied by Maurice Mpolo and Joseph Okito, two political associates who had planned to assist him in setting up a new government. They were fed poorly by the prison guards, as per Mobutu's orders. In Lumumba's last documented letter, he wrote to Rajeshwar Dayal, head of the UN in the Congo: \"In a word, we are living amid absolutely impossible conditions; moreover, they are against the law.\"\nOn the morning of 13 January 1961, discipline at Camp Hardy faltered. Soldiers refused to work unless they were paid; they received a total of 400,000 francs ($8,000) from the Katanga Cabinet. Some supported Lumumba's release, while others thought he was dangerous. Kasa-Vubu, Mobutu, Foreign Minister Justin Marie Bomboko, and Head of Security Services Victor Nendaka Bika personally arrived at the camp and negotiated with the troops. Conflict was avoided, but it became apparent that holding a controversial prisoner in the camp was too great a risk. Harold Charles d'Aspremont Lynden, the last Belgian Minister of the Colonies, ordered that Lumumba, Mpolo, and Okito be taken to the State of Katanga.\nLumumba was forcibly restrained on the flight to Elisabethville on 17 January 1961. On arrival, his associates and he were conducted under arrest to the Brouwez House, where they were brutally beaten and tortured by Katangan officers, while Tshombe and his cabinet decided what to do with him.\nLater that night, Lumumba, Mpolo, and Okito were driven to an isolated spot where three firing squads had been assembled that were commanded by Belgian contract officer Julien Gat. The orders to murder Lumumba were given by Katangan leaders. The last stage of the execution was personally undertaken by the Belgian contracts led by Police Commissioner Frans Verscheure. Lumumba, Mpolo, and Okito were put up against a tree and shot one at a time. The execution is thought to have taken place on 17 January 1961, between 21:40 and 21:43 according to a later Belgian parliamentary inquiry. Tshombe, two other ministers, and four Belgian officers under the command of the Katangan authorities were present. The bodies were thrown into a shallow grave.\nThe following morning, on orders of Katangan Interior Minister Godefroid Munongo, who wanted to make the bodies disappear and prevent a burial site from being created, Belgian Gendarmerie officer Gerard Soete and his team dug up and dismembered the corpses, and dissolved them in sulfuric acid while the bones were ground and scattered.\nLumumba's assassination allowed the governments of Belgium, the U.S., and reportedly the United Kingdom, to abandon their own assassination plans. Allen Dulles, then the head of the Central Intelligence Agency (CIA) supported assassinating Lumumba, reportedly as he had heard Eisenhower wishing that Lumumba \"fall into a river full of crocodiles.\" Eisenhower's involvement in the CIA's assassination plans remains speculative.\nAnnouncement of death.\nNo statement was released until three weeks later, despite rumours that Lumumba was dead. Katangan Secretary of State of Information Lucas Samalenge was one of the first people to reveal Lumumba's death, on 18 January. According to De Witte, Samalenge went to the bar \"Le Relais\" in \u00c9lisabethville and \"told everyone willing to listen that Lumumba was dead and that he had kicked his corpse. He went around repeating the story until the police took him away.\"\nOn 10 February, the radio announced that Lumumba and two other prisoners had escaped. His death was formally announced over Katangan radio on 13 February: it was alleged that he was killed by enraged villagers three days after escaping from Kolatey prison farm.\nAfter the announcement of Lumumba's death, street protests were organised in several European countries; in Belgrade, protesters sacked the Belgian embassy and confronted the police, and in London, a crowd marched from Trafalgar Square to the Belgian embassy, where a letter of protest was delivered and where protesters clashed with police. In New York City, a demonstration at the United Nations Security Council turned violent and spilled over into the streets.\nForeign involvement in his execution.\nThe ongoing Cold War affected both Belgium and the United States' perception of Lumumba, as they feared he was increasingly subject to communist influence due to his appeals for Soviet aid. However, according to journalist Sean Kelly, who covered the events as a correspondent for the Voice of America, Lumumba did this not because he was a communist, but because he felt that the Soviet Union was the only power which would support his government's effort to defeat Belgian-supported separatists and rid itself of colonial influence. The US was the first country from which Lumumba requested help. Lumumba, for his part, denied being a communist, stating that he found colonialism and communism to be equally deplorable, and publicly professed his personal preference for neutrality between the East and West.\nBelgian involvement.\nOn 18 January, panicked by reports that the burial of the three bodies had been observed, members of the execution team dug up the remains and moved them for reburial to a place near the border with Northern Rhodesia. Belgian Police Commissioner Gerard Soete later admitted in several accounts that he and his brother led the original exhumation. Police Commissioner Frans Verscheure also took part. On the afternoon and evening of 21 January, Commissioner Soete and his brother dug up Lumumba's corpse for a second time, cut it up with a hacksaw, and dissolved it in concentrated sulfuric acid.\nIn the late 20th and early 21st century, Lumumba's assassination was investigated. In a 1999 interview on Belgian television, in a program about his assassination, Soete displayed a bullet and two teeth that he claimed he had saved from Lumumba's body, one of which included a gold-capped tooth. According to the 2001 Belgian Commission investigating Lumumba's assassination: (1) Belgium wanted Lumumba arrested, (2) Belgium was not particularly concerned with Lumumba's physical well-being, and (3) although informed of the danger to Lumumba's life, Belgium did not take any action to avert his death. The report concluded that Belgium had not ordered Lumumba's execution. In February 2002, the Belgian government formally apologised to the Congolese people, and admitted to a \"moral responsibility\" and \"an irrefutable portion of responsibility in the events that led to the death of Lumumba\".\nLumumba's execution was carried out by a firing squad led by Belgian mercenary Julien Gat; Katangan Police Commissioner Verscheure, who was Belgian, had overall command of the execution site. The separatist Katangan regime was heavily supported by the Belgian mining conglomerate Union Mini\u00e8re du Haut-Katanga.\nIn the early 21st century, De Witte found documents challenging the idea that Belgian officers operating in Katanga only took orders from the Katangan authorities. Belgian officers were also following Belgian government policy and orders. The Belgian Minister of African Affairs Count Harold d'Aspremont Lynden, who had been tasked with organising Katanga's secession, on 6 October 1960 sent a cable to Katanga saying that policy from now on would be the \"definitive elimination of Patrice Lumumba\". Lynden had also insisted on 15 January 1961, that an imprisoned Lumumba should be sent to Katanga, which essentially would have been a death sentence.\nIn June 2025, Baudouin's close associate \u00c9tienne Davignon, a former Belgian junior diplomat to Congo, was requested to be tried for war crimes for his involvement in the unlawful detention, deprivation of a fair trial, and torture of Lumumba in 1960. It is expected to be decided in January 2026 whether a trial will take place. Davignon has denied the allegations.\nUnited States involvement.\nThe 2001 report by the Belgian Commission describes previous U.S. and Belgian plots to kill Lumumba. Among them was a CIA-sponsored attempt to poison him. Eisenhower authorised the assassination of Lumumba in 1960. However, the plot to poison him was abandoned. CIA chemist Sidney Gottlieb, a key person in the plan, devised a number of toxic materials to be used for the assassination. In September 1960, Gottlieb brought a vial of the poison to the Congo, and CIA Station Chief Larry Devlin developed plans to place it on Lumumba's toothbrush or in his food. The plot was abandoned because Devlin's agent was unable to carry out the assassination, and the replacement agent Justin O'Donnell refused to participate in an assassination plot.\nAccording to Madeleine G. Kalb in her book, \"Congo Cables\", many communications by Devlin at the time urged the elimination of Lumumba. Michael P. Holt writes that Devlin also helped to direct the search to capture Lumumba and also helped arrange his transfer to the separatist authorities in Katanga. John Stockwell, a CIA officer in the Congo and later a CIA station chief, wrote in 1978 that the CIA base chief in Elizabethville was in direct contact with Lumumba's killers on the night he was executed. Stockwell also wrote that a CIA agent had a body in the trunk of his car that they were trying to dispose of. Stockwell, who knew Devlin well, believed that Devlin knew more than anyone else about the murder.\nThe inauguration of John F. Kennedy in January 1961 caused fear among Mobutu's faction, and within the CIA, that the incoming Kennedy administration would favour the imprisoned Lumumba. While awaiting his presidential inauguration, Kennedy had come to believe that Lumumba should be released from custody, though not be allowed to return to power. Lumumba was killed three days before Kennedy's inauguration on 20 January, though Kennedy did not learn of the killing until 13 February. Kennedy was informed by United Nations ambassador Adlai Stevenson and according to Jacques Lowe who was with him at the time \"his hand went to his head in utter despair, 'Oh, no,' I heard him groan\".\nChurch Committee.\nIn 1975, the Church Committee went on record with the finding that CIA chief Allen Dulles had ordered Lumumba's assassination as \"an urgent and prime objective\". Furthermore, declassified CIA cables quoted or mentioned in the Church report, and in Kalb (1982), mention two specific CIA plots to murder Lumumba: the poison plot and a shooting plot.\nThe Committee later found that while the CIA had conspired to kill Lumumba, it was not directly involved in the murder.\nU.S. government documents.\nIn the early 21st century, declassified documents revealed that the CIA had plotted to assassinate Lumumba. The documents indicate that the Congolese leaders who overthrew Lumumba and transferred him to the Katangan authorities, including Mobutu Sese Seko and Joseph Kasa-Vubu, received money and weapons directly from the CIA. The same disclosure showed that, at the time, the U.S. government believed that Lumumba was a communist, and feared him because of what it considered the threat of the Soviet Union in the Cold War.\nIn 2000, a newly declassified interview with Robert Johnson, who was the minutekeeper of the U.S. National Security Council at the time in question, revealed that Eisenhower had said \"something [to CIA chief Allen Dulles] to the effect that Lumumba should be eliminated\". The interview from the Senate Intelligence Committee's inquiry on covert action was released in August 2000.\nIn 2013, the U.S. State Department admitted that Eisenhower discussed plans at a NSC meeting on 18 August 1960 to assassinate Lumumba. However, documents released in 2017 revealed that an American role in Lumumba's murder was only under consideration by the CIA. CIA Chief Allan Dulles had allocated $100,000 to accomplish the act, but the plan was not carried out.\nUnited Kingdom involvement.\nIn June 2001, newly discovered documents by De Witte revealed that while the US and Belgium actively plotted to murder Lumumba, the British government secretly wanted him \"got rid of\" because they believed he posed a serious threat to British interests in the Congo, such as mining facilities in Katanga. Howard Smith, who was to become head of MI5 in 1979, said, \"I can see only two possible solutions to the problem. The first is the simple one of ensuring Lumumba's removal from the scene by killing him. This should solve the problem\".\nIn April 2013, in a letter to the \"London Review of Books,\" British parliamentarian David Lea reported having discussed Lumumba's death with MI6 officer Daphne Park shortly before she died in March 2010. Park had been posted to Leopoldville at the time of Lumumba's death, and was later a semi-official spokesperson for MI6 in the House of Lords. According to Lea, when he mentioned \"the uproar\" surrounding Lumumba's abduction and murder, and recalled the theory that MI6 might have had \"something to do with it\", Park replied, \"We did. I organised it.\" The BBC reported that, subsequently, \"Whitehall sources\" described the claims of MI6 involvement as \"speculative\".\nRepatriation of his remains.\nOn 30 June 2020, Lumumba's daughter, Juliana Lumumba, appealed directly in a letter to Philippe, King of the Belgians, the return of \"the relics of Patrice \u00c9mery Lumumba to the ground of his ancestors\", describing her father as \"a hero without a grave\". The letter stated: \"Why, after his terrible murder, have Lumumba's remains been condemned to remain a soul forever wandering, without a grave to shelter his eternal rest?\" On 10 September 2020, a Belgian judge ruled that Lumumba's remains \u2013 which then consisted of just a single gold-capped tooth (Gerard Soete had lost the other tooth of Lumumba between 1999 and 2020) \u2013 must be returned to his family.\nIn May 2021, Congolese President F\u00e9lix Tshisekedi announced that there would be a repatriation of the last remains of Lumumba, however, the handover ceremony was delayed because of the COVID-19 pandemic. On 9 June 2022, during a speech in the DRC to the country's parliament, King Philippe reiterated regrets for Belgium's colonial past in its former colony, describing Belgian rule as a \"regime\u00a0... of unequal relations, unjustifiable in itself, marked by paternalism, discrimination and racism\" that \"led to violent acts and humiliations\".\nOn 20 June, Lumumba's children received the remains of their father during a ceremony at Egmont Palace in Brussels, where the federal prosecutor formally handed custody to the family. The Belgian Prime Minister, Alexander De Croo, apologised on behalf of the Belgian government for his country's role in Lumumba's assassination: \"For my part, I would like to apologise here, in the presence of his family, for the way in which the Belgian government influenced the decision to end the life of the country's first prime minister.\" \"A man was murdered for his political convictions, his words, his ideals\", he added. Later the full-sized coffin was brought in public and draped in the Congolese flag for the Congolese and wider African diaspora of Belgium to pay their respects before the return.\nA special mausoleum was built in Kinshasa to house his remains. The government of the Democratic Republic of the Congo declared three days of national mourning. The burial coincided with the 61st anniversary of his famous independence day speech. An investigation by Belgian prosecutors for \"war crimes\" related to Lumumba's murder is ongoing. His remains were laid to rest 30 June 2022. On 18 November 2024, the mausoleum was vandalised and Lumumba's coffin broken, with the interior ministry saying that his tooth was safe.\nPolitical ideology.\nLumumba did not espouse a comprehensive political or economic platform. According to Patricia Goff, Lumumba was the first Congolese to articulate a narrative of the Congo that contradicted traditional Belgian views of colonisation, and he highlighted the suffering of the indigenous population under European rule. Goff writes that Lumumba was alone among his contemporaries in encompassing all Congolese people in his narrative (the others confined their discussions to their respective ethnicities or regions), and he offered a basis for national identity that was predicated upon having survived colonial victimisation, as well as the people's innate dignity, humanity, strength, and unity. Lumumba's ideal of humanism included the values of egalitarianism, social justice, liberty, and the recognition of fundamental rights. He viewed the state as a positive advocate for the public welfare and its intervention in Congolese society necessary to ensure equality, justice, and social harmony.\nLegacy.\nHistoriography.\nFull accounts of Lumumba's life and death were printed within weeks of his demise. Beginning in 1961 and continuing for several years thereafter, some biographies on him were published. Most were highly partisan. Several early works on the Congo Crisis also discussed Lumumba at length. In the years after his death, misconceptions of Lumumba persisted by both his supporters and his critics. Serious study of him faded over the following decades. Academic discussion of his legacy was largely limited until the later stages of Mobutu's rule in the Congo; Mobutu's opening of the country to multi-party politics beginning in 1990 revived interest in Lumumba's death.\nBelgian literature in the decades following the Congo Crisis portrayed him as incompetent, demagogic, aggressive, ungrateful, undiplomatic, and communist. Most Africanists of the 20th century, such as Jean-Claude Willame, viewed Lumumba as an intransigent, unrealistic idealist without any tangible programme who distanced himself from his contemporaries and alienated the Western world with radical anti-colonial rhetoric. They saw him as greatly responsible for the political crisis that resulted in his downfall. A handful of other writers, such as Jean-Paul Sartre, shared the belief that Lumumba's goals were unattainable in 1960 but nevertheless viewed him as a martyr of Congolese independence at the hands of certain Western interests and the victim of events over which he had little control. According to sociologist De Witte, both of these perspectives overstate the political weaknesses and isolation of Lumumba.\nA conventional narrative of Lumumba's premiership and downfall eventually emerged; he was an uncompromising radical who provoked his own murder by angering domestic separatists. Within Belgium, the popular narrative of his death implicated the involvement of some Belgian individuals, but stressed that they were acting \"under orders\" of African figures and that the Belgian government was uninvolved. Some Belgian circles peddled the notion that the United States\u2014particularly the Central Intelligence Agency\u2014had arranged the killing.\nThis narrative was challenged by De Witte's 2001 work, \"The Assassination of Patrice Lumumba\", which provided evidence that the Belgian government\u2014with the complicity of the United States, the United Kingdom, and the UN\u2014was largely responsible for his death. Media discussion of Lumumba, spurred by the release of the book as well as a feature film in 2000, \"Lumumba\", became significantly more positive afterwards. A new narrative subsequently emerged, holding Western espionage at fault for Lumumba's death, and emphasising the threat his charismatic appeal posed to Western interests. Lumumba's role in the Congolese independence movement is well-documented, and he is typically recognised as its most important and influential leader. His exploits are usually celebrated as the work of him as an individual and not that of a larger movement.\nPolitical impact.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nDespite his brief political career and tragic death\u2014or perhaps because of them\u2014Lumumba entered history through the front door: he became both a flag and a symbol. He lived as a free man, and an independent thinker. Everything he wrote, said and did was the product of someone who knew his vocation to be that of a liberator, and he represents for the Congo what Castro does for Cuba, Nasser for Egypt, Nkrumah for Ghana, Mao Tse-tung for China, and Lenin for Russia.\nThomas Kanza, friend and colleague of Lumumba, 1972\nDue to his relatively short career in government, quick removal from power, and controversial death, a consensus has not been reached on Lumumba's political legacy. His downfall was detrimental to African nationalist movements, and he is generally remembered primarily for his assassination.\nNumerous American historians have cited his death as a major contributing factor to the radicalisation of the American civil rights movement in the 1960s, and many African-American activist organisations and publications used public comment on his death to express their ideology. Popular memory of Lumumba has often discarded his politics and reduced him to a symbol.\nWithin the Congo, Lumumba is primarily portrayed as a symbol of national unity, while abroad he is usually cast as a Pan-Africanist and anticolonial revolutionary. The ideological legacy of Lumumba is known as (French for Lumumbism). Rather than a complex doctrine, it is usually framed as a set of fundamental principles consisting of nationalism, Pan-Africanism, nonalignment, and social progressivism. Mobutism built off of these principles. Congolese university students\u2014who had up until independence held little respect for Lumumba\u2014embraced after his death. According to political scientist Georges Nzongola-Ntalaja, Lumumba's \"greatest legacy\u00a0... for the Congo is the ideal of national unity\". Nzongola-Ntalaja further posited that, as a result of Lumumba's high praise of the independence movement and his work to end the Katangese secession, \"the people of the Congo are likely to remain steadfast in their defense of national unity and territorial integrity, come hell or high water.\" Political scientist Ali Mazrui wrote, \"It looks as if the \"memory\" of Lumumba may contribute more to the 'oneness' of the Congolese than anything Lumumba himself actually did while he was still alive.\"\nFollowing the suppression of the rebellions of 1964 and 1965, most Lumumbist ideology was confined to isolated groups of intellectuals who faced repression under Mobutu's regime. By 1966 there was little popular devotion to him outside of the political elite. Centres of Lumumba's popularity in his lifetime underwent a gradual decline in fidelity to his person and ideas. According to Africanist Bogumil Jewsiewicki, by 1999 \"the only faithful surviving Lumumbist nucleus is located in Sankuru and Maniema, and its loyalty is questionable (more ethnical, regional, and sentimental than ideological and political).\" Lumumba's image was unpopular in southern Kasai for years after his death, as many Baluba remained aware of the military campaign he ordered in August 1960 that resulted in violent atrocities against their people.\nAt least a dozen Congolese political parties have claimed to bear Lumumba's political and spiritual heritage. Despite this, few entities have attempted or succeeded in incorporating his ideas into a comprehensible political program. Most of these parties have enjoyed little electoral support, though Gizenga's was represented in the Congolese coalition government formed under President Joseph Kabila in 2006. Aside from student groups, Lumumbist ideals play only a minor role in current Congolese politics. Congolese presidents Mobutu, Laurent-D\u00e9sir\u00e9 Kabila, and Joseph Kabila all claimed to inherit Lumumba's legacy and paid tribute to him early on in their tenures.\nMartyrdom.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n[O]ne thing is clear: while he lived he was essentially a factional hero rather than a national one. But after his death the myth of Lumumba was rapidly nationalized.\nPolitical scientist Ali Mazrui, 1968\nThe circumstances of Lumumba's death have led him to often be portrayed as a martyr. While his demise led to an outburst of mass demonstrations abroad and quick creation of a martyr image internationally, the immediate reaction to his death in the Congo was not as uniform. Tetela, Songye, and Luba-Katanga peoples created folks songs of mourning for him, but these were groups which had been involved in political alliances with him and, at the time, Lumumba was unpopular in large segments of the Congolese populace, particularly in the capital, Bas-Congo, Katanga, and South Kasai. Some of his actions and the portrayal of him as a communist by his detractors had also generated disaffection in the army, civil service, labour unions, and the Catholic Church. Lumumba's reputation as a martyr in the collective memory of the Congolese was only cemented later, partly due to the initiatives of Mobutu.\nIn Congolese collective memory, it is perceived that Lumumba was killed through Western machinations because he defended the Congo's self-determination. The killing is viewed in the context of the memory as a symbolic moment in which the Congo lost its dignity in the international realm and the ability to determine its future, which has since been controlled by the West. Lumumba's determination to pursue his goals is extrapolated upon the Congolese people as their own; securing the Congo's dignity and self-determination would thus ensure their \"redemption\" from victimisation by Western powers. Historian David Van Reybrouck wrote, \"In no time Lumumba became a martyr of decolonisation\u00a0... He owed this status more to the horrible end of his life than to his political successes.\" Journalist Michela Wrong remarked that \"He really did become a hero after his death, in a way that one has to wonder if he would have been such a hero if he had remained and run the country and faced all the problems that running a country as big as Congo would have inevitably brought.\" Drama scholar Peit Defraeya wrote, \"Lumumba as a dead martyr has become a more compelling figure in liberationist discourse than the controversial live politician.\" Historian Pedro Monaville wrote that \"his globally iconic status was not commensurate with his more complex legacy in [the] Congo.\" Cooptation of Lumumba's legacy by Congolese presidents and state media has generated doubts in the Congolese public about his reputation.\nCommemoration and official tributes.\nIn 1961 Adoula became Prime Minister of the Congo. Shortly after assuming office he went to Stanleyville and laid a wreath of flowers at an impromptu monument established for Lumumba. After Tshombe became Prime Minister in 1964, he also went to Stanleyville and did the same. On 30 June 1966, Mobutu rehabilitated Lumumba's image and proclaimed him a \"national hero\". He declared a series of other measures meant to commemorate Lumumba, though few of these were ever executed aside from the release of a banknote with his visage the subsequent year. This banknote was the only paper money during Mobutu's rule that bore the face of a leader other than the incumbent president. In following years state mention of Lumumba declined and Mobutu's regime viewed unofficial tributes to him with suspicion. Following Laurent-D\u00e9sir\u00e9 Kabila's seizure of power in the 1990s, a new line of Congolese francs was issued bearing Lumumba's image.\nIn January 2003, Joseph Kabila, who succeeded his father as president, inaugurated a statue of Lumumba. In Guinea, Lumumba was featured on a coin and two regular banknotes despite not having any national ties to the country. This was an unprecedented occurrence in the modern history of national currency, as images of foreigners are normally reserved only for specially-released commemorative money. As of 2020, Lumumba has been featured on 16 different postage stamps. Many streets and public squares around the world have been named after him. The Peoples' Friendship University of Russia in Moscow (then Peoples' Friendship University of the USSR) was renamed \"Patrice Lumumba Peoples' Friendship University\" in 1961. It was renamed again in 1992 and back in 2023.\nIn 2013, the planned community of Lumumbaville was named after him.\nIn popular culture.\nLumumba is viewed as one of the \"fathers of independence\" of the Congo. The image of Lumumba appears frequently in social media and is often used as a rallying cry in demonstrations of social defiance. His figure is prevalent in art and literature, mostly outside of the Congo. He was referenced by numerous African-American writers of the American civil rights movement, especially in their works of the post-civil rights era. Malcolm X declared him \"the greatest black man who ever walked the African continent\".\nAmong the most prominent works featuring him are Aim\u00e9 C\u00e9saire's 1966 play, \"Une saison au Congo\", and Raoul Peck's 1992 documentary and 2000 feature film, \"Lumumba, la mort d'un proph\u00e8te\" and \"Lumumba\", respectively.\nThere is an Italian 1968 feature film 'Seduto alla sua destra' (lit.\u2009'Sitting to his right') by Valerio Zurlini, where the last days of the character Maurice Lalubi (played by Woody Strode), based upon Patrice Lumumba, are presented as the Passion of Christ. This movie was included in the 1968 Cannes Film Festival, which was cancelled due to the events of May 68 in France.\nThe 2024 film Soundtrack to a Coup d'Etat depicts the Congolese independence process and Lumumba's death.\nCongolese musicians Franco Luambo and Joseph Kabasele both wrote songs in tribute to Lumumba shortly after his death. Other musical works mentioning him include \"Lumumba\" by Miriam Makeba, \"Done Too Soon\" by Neil Diamond and \"Waltz for Lumumba\" by the Spencer Davis Group. His name is also mentioned in rap music; Arrested Development, Nas, David Banner, Black Thought, Damso, Baloji, M\u00e9dine, Sammus and many others have mentioned him in their work.\nIn popular painting he is often paired with notions of sacrifice and redemption, even being portrayed as a messiah, with his downfall being his passion. Tshibumba Kanda-Matulu painted a series chronicling Lumumba's life and career. Lumumba is relatively absent from Congolese writing, and he is often portrayed with only subtle or ambiguous references. Congolese authors Sony Lab'ou Tansi's and Sylvain Bemba's fictional \"Parentheses of Blood\" and \"L\u00e9opolis\", respectively, both feature characters with strong similarities to Lumumba. In written tributes to Mobutu, Lumumba is usually portrayed as an adviser to the former. Writer Charles Djungu-Simba observed, \"Lumumba is rather considered as a vestige of the past, albeit an illustrious past\". His surname is often used to identify a long drink of hot or cold chocolate and rum.\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "49241", "revid": "753665", "url": "https://en.wikipedia.org/wiki?curid=49241", "title": "Gustav Holst", "text": "English composer (1874\u20131934)\nGustav Holst (born Gustavus Theodore von Holst; 21 September 1874\u00a0\u2013 25 May 1934) was an English composer, arranger and teacher. Best known for his orchestral suite \"The Planets\", he composed many other works across a range of genres, although none achieved comparable success. His distinctive compositional style was the product of many influences, Richard Wagner and Richard Strauss being most crucial early in his development. The subsequent inspiration of the English folksong revival of the early 20th century, and the example of such rising modern composers as Maurice Ravel, led Holst to develop and refine an individual style.\nThere were professional musicians in the previous three generations of Holst's family, and it was clear from his early years that he would follow the same calling. He hoped to become a pianist, but was prevented by neuritis in his right arm. Despite his father's reservations, he pursued a career as a composer, studying at the Royal College of Music under Charles Villiers Stanford. Unable to support himself by his compositions, he played the trombone professionally and later became a teacher\u2014a great one, according to his colleague Ralph Vaughan Williams. Among other teaching activities he built up a strong tradition of performance at Morley College, where he served as musical director from 1907 until 1924, and pioneered music education for women at St Paul's Girls' School, where he taught from 1905 until his death in 1934. He was the founder of a series of Whitsun music festivals, which ran from 1916 for the remainder of his life.\nHolst's works were played frequently in the early years of the 20th century, but it was not until the international success of \"The Planets\" in the years immediately after the First World War that he became a well-known figure. A shy man, he did not welcome this fame, and preferred to be left in peace to compose and teach. In his later years his uncompromising, personal style of composition struck many music lovers as too austere, and his brief popularity declined. Nevertheless, he was an important influence on a number of younger English composers, including Edmund Rubbra, Michael Tippett and Benjamin Britten. Apart from \"The Planets\" and a handful of other works, his music was generally neglected until the 1980s, when recordings of much of his output became available.\nLife and career.\nEarly years.\nFamily background.\nHolst was born in Cheltenham, Gloucestershire, the elder of the two children of Adolph von Holst, a professional musician, and his wife, Clara Cox, \"n\u00e9e\" Lediard. She was of mostly British descent, daughter of a respected Cirencester solicitor; the Holst side of the family was of mixed Swedish, Latvian and German ancestry, with at least one professional musician in each of the previous three generations.\nOne of Holst's great-grandfathers, Matthias Holst, born in Riga, Latvia, was of German origin; he served as composer and harp-teacher to the Imperial Russian Court in St Petersburg. Matthias's son Gustavus, who moved to England with his parents as a child in 1802, was a composer of salon-style music and a well-known harp teacher. He appropriated the aristocratic prefix \"von\" and added it to the family name in the hope of gaining enhanced prestige and attracting pupils. \nHolst's father, Adolph von Holst, became organist and choirmaster at All Saints' Church, Cheltenham; he also taught, and gave piano recitals. His wife, Clara, a former pupil, was a talented singer and pianist. They had two sons; Gustav's younger brother, Emil Gottfried, became known as Ernest Cossart, a successful actor in the West End, New York and Hollywood. Clara died in February 1882, and the family moved to another house in Cheltenham, where Adolph recruited his sister Nina to help raise the boys. Gustav recognised her devotion to the family and dedicated several of his early compositions to her. In 1885 Adolph married Mary Thorley Stone, another of his pupils. They had two sons, Matthias (known as \"Max\") and Evelyn (\"Thorley\"). Mary von Holst was absorbed in theosophy and not greatly interested in domestic matters. All four of Adolph's sons were subject to what one biographer calls \"benign neglect\", and Gustav in particular was \"not overburdened with attention or understanding, with a weak sight and a weak chest, both neglected\u2014he was 'miserable and scared'.\"\nChildhood and youth.\nHolst was taught to play the piano and the violin; he enjoyed the former but hated the latter. At the age of twelve he took up the trombone at his father's suggestion, thinking that playing a brass instrument might improve his asthma. Holst was educated at Cheltenham Grammar School between 1886 and 1891. He started composing in or about 1886; inspired by Macaulay's poem \"\" he began, but soon abandoned, an ambitious setting of the work for chorus and orchestra. His early compositions included piano pieces, organ voluntaries, songs, anthems and a symphony (from 1892). His main influences at this stage were Mendelssohn, Chopin, Grieg and above all Sullivan.\nAdolph tried to steer his son away from composition, hoping that he would have a career as a pianist. Holst was oversensitive and miserable. His eyes were weak, but no one realized that he needed to wear spectacles. Holst's health played a decisive part in his musical future; he had never been strong, and in addition to his asthma and poor eyesight he suffered from neuritis, which made playing the piano difficult. He said that the affected arm was \"like a jelly overcharged with electricity\".\nAfter Holst left school in 1891, Adolph paid for him to spend four months in Oxford studying counterpoint with George Frederick Sims, organist of Merton College. On his return, Holst obtained his first professional appointment, aged seventeen, as organist and choirmaster at Wyck Rissington, Gloucestershire. The post brought with it the conductorship of the Bourton-on-the-Water Choral Society, which offered no extra remuneration but provided valuable experience that enabled him to hone his conducting skills. In November 1891 Holst gave what was perhaps his first public performance as a pianist; he and his father played the Brahms \"Hungarian Dances\" at a concert in Cheltenham. The programme for the event gives his name as \"Gustav\" rather than \"Gustavus\"; he was called by the shorter version from his early years.\nRoyal College of Music.\nIn 1892 Holst wrote the music for an operetta in the style of Gilbert and Sullivan, \"Lansdown Castle, or The Sorcerer of Tewkesbury\". The piece was performed at Cheltenham Corn Exchange in February 1893; it was well received and its success encouraged him to persevere with composing. He applied for a scholarship at the Royal College of Music (RCM) in London, but the composition scholarship for that year was won by Samuel Coleridge-Taylor. Holst was accepted as a non-scholarship student, and Adolph borrowed \u00a3100 to cover the first year's expenses. Holst left Cheltenham for London in May 1893. Money was tight, and partly from frugality and partly from his own inclination he became a vegetarian and a teetotaller. Two years later he was finally granted a scholarship, which slightly eased his financial difficulties, but he retained his austere personal regime.\nHolst's professors at the RCM were Frederick Sharpe (piano), William Stephenson Hoyte (organ), George Case (trombone), Georges Jacobi (instrumentation) and the director of the college, Hubert Parry (history). After preliminary lessons with W. S. Rockstro and Frederick Bridge, Holst was granted his wish to study composition with Charles Villiers Stanford.\nTo support himself during his studies Holst played the trombone professionally, at seaside resorts in the summer and in London theatres in the winter. His daughter and biographer, Imogen Holst, records that from his fees as a player \"he was able to afford the necessities of life: board and lodging, manuscript paper, and tickets for standing room in the gallery at Covent Garden Opera House on Wagner evenings\". He secured an occasional engagement in symphony concerts, playing in 1897 under the baton of Richard Strauss at the Queen's Hall.\nLike many musicians of his generation, Holst came under Wagner's spell. He had recoiled from the music of \"G\u00f6tterd\u00e4mmerung\" when he heard it at Covent Garden in 1892, but encouraged by his friend and fellow-student Fritz Hart he persevered and quickly became an ardent Wagnerite. Wagner supplanted Sullivan as the main influence on his music, and for some time, as Imogen put it, \"ill-assimilated wisps of \"Tristan\" inserted themselves on nearly every page of his own songs and overtures.\" Stanford admired some of Wagner's works, and had in his earlier years been influenced by him, but Holst's sub-Wagnerian compositions met with his disapprobation: \"It won't do, me boy; it won't do\". Holst respected Stanford, describing him to a fellow-pupil, Herbert Howells, as \"the one man who could get any one of us out of a technical mess\", but he found that his fellow students, rather than the faculty members, had the greater influence on his development.\nIn 1895, shortly after celebrating his twenty-first birthday, Holst met Ralph Vaughan Williams, who became a lifelong friend and had more influence on Holst's music than anybody else. Stanford emphasised the need for his students to be self-critical, but Holst and Vaughan Williams became one another's chief critics; each would play his latest composition to the other while still working on it. Vaughan Williams later observed, \"What one really learns from an Academy or College is not so much from one's official teachers as from one's fellow-students\u00a0... [we discussed] every subject under the sun from the lowest note of the double bassoon to the philosophy of \"Jude the Obscure\". In 1949 he wrote of their relationship, \"Holst declared that his music was influenced by that of his friend: the converse is certainly true.\"\nThe year 1895 was also the bicentenary of Henry Purcell, which was marked by various performances including Stanford conducting \"Dido and Aeneas\" at the Lyceum Theatre; the work profoundly impressed Holst, who over twenty years later confessed to a friend that his search for \"the (or a) musical idiom of the English language\" had been inspired \"unconsciously\" by \"hearing the recits in Purcell's \"Dido\"\".\nAnother early influence was William Morris. In Vaughan Williams's words, \"It was now that Holst discovered the feeling of unity with his fellow men which made him afterwards a great teacher. A sense of comradeship rather than political conviction led him, while still a student, to join the Socialist League which met at Kelmscott House in Hammersmith.\" At Kelmscott House, Morris's home, Holst attended lectures by his host and Bernard Shaw. His own socialism was moderate in character, but he enjoyed the club for its good company and his admiration of Morris as a man. His ideals were influenced by Morris's but had a different emphasis. Morris had written, \"I do not want art for a few any more than education for a few, or freedom for a few. I want all persons to be educated according to their capacity, not according to the amount of money which their parents happen to have\". Holst said, \"'Aristocracy in art'\u2014art is not for all but only for the chosen few\u2014but the only way to find those few is to bring art to everyone\u2014then the artists have a sort of masonic signal by which they recognise each other in the crowd.\" He was invited to conduct the Hammersmith Socialist Choir, teaching them madrigals by Thomas Morley, choruses by Purcell, and works by Mozart, Wagner and himself. One of his choristers was (Emily) Isobel Harrison (1876\u20131969), a beautiful soprano two years his junior. He fell in love with her; she was at first unimpressed by him, but she came round and they were engaged, though with no immediate prospect of marriage given Holst's tiny income.\nProfessional musician.\nIn 1898 the RCM offered Holst a further year's scholarship, but he felt that he had learned as much as he could there and that it was time, as he put it, to \"learn by doing\". Some of his compositions were published and performed; the previous year \"The Times\" had praised his song \"Light Leaves Whisper\", \"a moderately elaborate composition in six parts, treated with a good deal of expression and poetic feeling\".\nOccasional successes notwithstanding, Holst found that \"man cannot live by composition alone\"; he took posts as organist at various London churches, and continued playing the trombone in theatre orchestras. In 1898 he was appointed first trombonist and \"r\u00e9p\u00e9titeur\" with the Carl Rosa Opera Company and toured with the Scottish Orchestra. Though a capable rather than a virtuoso player he won the praise of the leading conductor Hans Richter, for whom he played at Covent Garden. His salary was only just enough to live on, and he supplemented it by playing in a popular orchestra called the \"White Viennese Band\", conducted by Stanislas Wurm.\nHolst enjoyed playing for Wurm, and learned much from him about drawing rubato from players. Nevertheless, longing to devote his time to composing, Holst found the necessity of playing for \"the Worm\" or any other light orchestra \"a wicked and loathsome waste of time\". Vaughan Williams did not altogether agree with his friend about this; he admitted that some of the music was \"trashy\" but thought it had been useful to Holst nonetheless: \"To start with, the very worst a trombonist has to put up with is as nothing compared to what a church organist has to endure; and secondly, Holst is above all an orchestral composer, and that sure touch which distinguishes his orchestral writing is due largely to the fact that he has been an orchestral player; he has learnt his art, both technically and in substance, not at second hand from text books and models, but from actual live experience.\"\nWith a modest income secured, Holst was able to marry Isobel; the ceremony was at Fulham Register Office on 22 June 1901. Their marriage lasted until his death; there was one child, Imogen, born in 1907. On 24 April 1902 Dan Godfrey and the Bournemouth Municipal Orchestra premiered Holst's symphony \"The Cotswolds\" (Op. 8), the slow movement of which is a lament for William Morris who had died in October 1896, three years before Holst began work on the piece. In 1903 Adolph von Holst died, leaving a small legacy. Holst and his wife decided, as Imogen later put it, that \"as they were always hard up the only thing to do was to spend it all at once on a holiday in Germany\".\nComposer and teacher.\nWhile in Germany, Holst reappraised his professional life, and in 1903 he decided to abandon orchestral playing to concentrate on composition. His earnings as a composer were too little to live on, and two years later he accepted the offer of a teaching post at James Allen's Girls' School, Dulwich, which he held until 1921. He also taught at the Passmore Edwards Settlement, where among other innovations he gave the British premieres of two Bach cantatas. The two teaching posts for which he is probably best known were director of music at St Paul's Girls' School, Hammersmith, from 1905 until his death, and director of music at Morley College from 1907 to 1924.\nVaughan Williams wrote of the former establishment: \"Here he did away with the childish sentimentality which schoolgirls were supposed to appreciate and substituted Bach and Vittoria; a splendid background for immature minds.\" Several of Holst's pupils at St Paul's went on to distinguished careers, including the soprano Joan Cross and the oboist and cor anglais player Helen Gaskell.\nOf Holst's impact on Morley College, Vaughan Williams wrote: \"[A] bad tradition had to be broken down. The results were at first discouraging, but soon a new spirit appeared and the music of Morley College, together with its offshoot the 'Whitsuntide festival'\u00a0... became a force to be reckoned with\". Before Holst's appointment, Morley College had not treated music very seriously (Vaughan Williams's \"bad tradition\"), and at first Holst's exacting demands drove many students away. He persevered, and gradually built up a class of dedicated music-lovers.\nAccording to the composer Edmund Rubbra, who studied under him in the early 1920s, Holst was \"a teacher who often came to lessons weighted, not with the learning of Prout and Stainer, but with a miniature score of \"Petrushka\" or the then recently published Mass in G minor of Vaughan Williams\". He never sought to impose his own ideas on his composition pupils. Rubbra recalled that he would divine a student's difficulties and gently guide him to finding the solution for himself. \"I do not recall that Holst added one single note of his own to anything I wrote, but he would suggest\u2014if I agreed!\u2014that, given such and such a phrase, the following one would be better if it took such and such a course; if I did not see this, the point would not be insisted upon\u00a0... He frequently took away [because of] his abhorrence of unessentials.\"\nAs a composer Holst was frequently inspired by literature. He set poetry by Thomas Hardy and Robert Bridges and, a particular influence, Walt Whitman, whose words he set in \"Dirge for Two Veterans\" and \"The Mystic Trumpeter\" (1904). He wrote an orchestral \"Walt Whitman Overture\" in 1899. While on tour with the Carl Rosa company Holst had read some of Max M\u00fcller's books, which inspired in him a keen interest in Sanskrit texts, particularly the Rig Veda hymns. He found the existing English versions of the texts unconvincing, and decided to make his own translations, despite his lack of skills as a linguist. He enrolled in 1909 at University College, London, to study the language.\nImogen commented on his translations: \"He was not a poet, and there are occasions when his verses seem na\u00efve. But they never sound vague or slovenly, for he had set himself the task of finding words that would be 'clear and dignified' and that would 'lead the listener into another world'\". His settings of translations of Sanskrit texts included \"Sita\" (1899\u20131906), a three-act opera based on an episode in the \"Ramayana\" (which he eventually entered for a competition for English opera set by the Milan music publisher Tito Ricordi); but which was not performed until October 2024 in Saarbr\u00fccken. \"Savitri\" (1908), a chamber opera based on a tale from the \"Mahabharata\"; four groups of \"Hymns from the Rig Veda\" (1908\u201314); and two texts originally by K\u0101lid\u0101sa: \"Two Eastern Pictures\" (1909\u201310) and \"The Cloud Messenger\" (a setting of the \"Meghad\u016bta\", 1910, premiered in 1913).\nTowards the end of the nineteenth century, British musical circles had experienced a new interest in national folk music. Some composers, such as Sullivan and Elgar, remained indifferent, but Parry, Stanford, Stainer and Alexander Mackenzie were founding members of the Folk-Song Society. Parry considered that by recovering English folk song, English composers would find an authentic national voice; he commented, \"in true folk-songs there is no sham, no got-up glitter, and no vulgarity\". Vaughan Williams was an early and enthusiastic convert to this cause, going round the English countryside collecting and noting down folk songs. These had an influence on Holst. Though not as passionate on the subject as his friend, he incorporated a number of folk melodies in his own compositions and made several arrangements of folk songs collected by others. The \"Somerset Rhapsody\" (1906\u201307), was written at the suggestion of the folk-song collector Cecil Sharp and made use of tunes that Sharp had noted down. Holst described its performance at the Queen's Hall in 1910 as \"my first real success\". A few years later Holst became excited by another musical renaissance\u2014the rediscovery of English madrigal composers. Weelkes was his favourite of all the Tudor composers, but Byrd also meant much to him.\nHolst was a keen rambler. He walked extensively in England, Italy, France and Algeria. In 1908 he travelled to Algeria on medical advice as a treatment for asthma and the depression that he suffered after his opera \"Sita\" failed to win the Ricordi prize. This trip inspired the suite \"Beni Mora\", which incorporated music he heard in the Algerian streets. Vaughan Williams wrote of this exotic work, \"if it had been played in Paris rather than London it would have given its composer a European reputation, and played in Italy would probably have caused a riot.\"\n1910s.\nIn June 1911 Holst and his Morley College students gave the first performance since the seventeenth century of Purcell's \"The Fairy-Queen\". The full score had been lost soon after Purcell's death in 1695, and had only recently been found. Twenty-eight Morley students copied out the complete vocal and orchestral parts. There were 1,500 pages of music and it took the students almost eighteen months to copy them out in their spare time. A concert performance of the work was given at The Old Vic, preceded by an introductory talk by Vaughan Williams. \"The Times\" praised Holst and his forces for \"a most interesting and artistic performance of this very important work\".\nAfter this success, Holst was disappointed the following year by the lukewarm reception of his choral work \"The Cloud Messenger\". He again went travelling, accepting an invitation from H. Balfour Gardiner to join him and the brothers Clifford and Arnold Bax in Spain. During this holiday Clifford Bax introduced Holst to astrology, an interest that later inspired his suite \"The Planets\". Holst cast his friends' horoscopes for the rest of his life and referred to astrology as his \"pet vice\".\nIn 1913, St Paul's Girls' School opened a new music wing, and Holst composed \"St Paul's Suite\" for the occasion. The new building contained a sound-proof room, handsomely equipped, where he could work undisturbed. Holst and his family moved to a house in Brook Green, very close to the school. For the previous six years they had lived in a pretty house overlooking the Thames at Barnes, but the river air, frequently foggy, affected his breathing. For use at weekends and during school holidays, Holst and his wife bought a cottage in Thaxted, Essex, surrounded by mediaeval buildings and ample rambling opportunities. In 1917 they moved to a house in the centre of the town, where they stayed until 1925.\nAt Thaxted, Holst became friendly with the Rev Conrad Noel, known as the \"Red Vicar\", who supported the Independent Labour Party and espoused many causes unpopular with conservative opinion. Noel also encouraged the revival of folk-dancing and processionals as part of church ceremonies, innovations which caused controversy among traditionally-minded churchgoers. Holst became an occasional organist and choirmaster at Thaxted Parish Church. He started an annual music festival at Whitsuntide in 1916; students from Morley College and St Paul's Girls' School performed together with local participants.\nHolst's \"a cappella\" carol, \"This Have I Done for My True Love\", was dedicated to Noel in recognition of his interest in the ancient origins of religion (the composer always referred to the work as \"The Dancing Day\"). It received its first performance during the Third Whitsun Festival at Thaxted in May 1918. During that festival, Noel, who would become a staunch supporter of Russia's October Revolution, demanded in a Saturday message during the service that there should be a greater political commitment from those who participated in the church activities; his claim that several of Holst's pupils (implicitly those from St Paul's Girls' School) were merely \"camp followers\" caused offence. Holst, anxious to protect his students from being embroiled in ecclesiastical conflict, moved the Whitsun Festival to Dulwich, though he himself continued to help with the Thaxted choir and to play the church organ on occasion.\nFirst World War.\nAt the outbreak of the First World War, Holst tried to enlist but was rejected as unfit for military service. He felt frustrated that he could not contribute to the war effort. His wife became a volunteer ambulance driver; Vaughan Williams went on active service to France as did Holst's brother Emil; Holst's friends the composers George Butterworth and Cecil Coles were killed in battle. He continued to teach and compose; he worked on \"The Planets\" and prepared his chamber opera \"Savitri\" for performance. It was first given in December 1916 by students of the London School of Opera at the Wellington Hall in St John's Wood. It attracted no attention at the time from the main newspapers, though when professionally staged five years later it was greeted as \"a perfect little masterpiece.\" In 1917 he wrote \"The Hymn of Jesus\" for chorus and orchestra, a work which remained unperformed until after the war.\nIn 1918, as the war neared its end, Holst finally had the prospect of a job that offered him the chance to serve. The music section of the YMCA's education department needed volunteers to work with British troops stationed in Europe awaiting demobilisation. Morley College and St Paul's Girls' School offered him a year's leave of absence, but there remained one obstacle: the YMCA felt that his surname looked too German to be acceptable in such a role. He formally changed \"von Holst\" to \"Holst\" by deed poll in September 1918. He was appointed as the YMCA's musical organiser for the Near East, based in Salonica.\nHolst was given a spectacular send-off. The conductor Adrian Boult recalled, \"Just before the Armistice, Gustav Holst burst into my office: 'Adrian, the YMCA are sending me to Salonica quite soon and Balfour Gardiner, bless his heart, has given me a parting present consisting of the Queen's Hall, full of the Queen's Hall Orchestra for the whole of a Sunday morning. So we're going to do \"The Planets\", and you've got to conduct'.\" There was a burst of activity to get things ready in time. The girls at St Paul's helped to copy out the orchestral parts, and the women of Morley and the St Paul's girls learned the choral part in the last movement.\nThe performance was given on 29 September to an invited audience including Sir Henry Wood and most of the professional musicians in London. Five months later, when Holst was in Greece, Boult introduced \"The Planets\" to the general public, at a concert in February 1919; Holst sent him a long letter full of suggestions, but failed to convince him that the suite should be played in full. The conductor believed that about half an hour of such radically new music was all the public could absorb at first hearing, and he gave only five of the seven movements on that occasion.\nHolst enjoyed his time in Salonica, from where he was able to visit Athens, which greatly impressed him. His musical duties were wide-ranging, and even obliged him on occasion to play the violin in the local orchestra: \"it was great fun, but I fear I was not of much use\". He returned to England in June 1919.\nPost-war.\nOn his return from Greece, Holst resumed his teaching and composing. In addition to his existing work he accepted a lectureship in composition at the University of Reading and joined Vaughan Williams in teaching composition at their \"alma mater\" the RCM. Inspired by Adrian Boult's conducting classes at the RCM, Holst tried to further pioneer music education for women by proposing to the High Mistress of St Paul's Girls' School that he should invite Boult to give classes at the school: \"It would be glorious if the SPGS turned out the only women conductors in the world!\" In his soundproof room at SPGS he composed the \"Ode to Death\", a setting of a poem by Whitman, which according to Vaughan Williams is considered by many to be Holst's most beautiful choral work.\nHolst, in his forties, suddenly found himself in demand. The New York Philharmonic and Chicago Symphony Orchestra vied to be the first to play \"The Planets\" in the US. The success of that work was followed in 1920 by an enthusiastic reception for \"The Hymn of Jesus\", described in \"The Observer\" as \"one of the most brilliant and one of the most sincere pieces of choral and orchestral expression heard for some years.\" \"The Times\" called it \"undoubtedly the most strikingly original choral work which has been produced in this country for many years.\"\nTo his surprise and dismay Holst was becoming famous. Celebrity was something wholly foreign to his nature. As the music scholar Byron Adams puts it, \"he struggled for the rest of his life to extricate himself from the web of garish publicity, public incomprehension and professional envy woven about him by this unsought-for success.\" He turned down honours and awards proffered to him, and refused to grant interviews or sign autographs.\nHolst's comic opera \"The Perfect Fool\" (1923) was widely seen as a satire of \"Parsifal\", though Holst firmly denied it. The piece, with Maggie Teyte in the leading soprano role and Eugene Goossens conducting, was enthusiastically received at its premiere in the Royal Opera House. At a concert in Reading in 1923, Holst slipped and fell, suffering concussion. He seemed to make a good recovery, and he felt up to accepting an invitation to the US, lecturing and conducting at the University of Michigan. After he returned he found himself more and more in demand, to conduct, prepare his earlier works for publication, and, as before, to teach. The strain caused by these demands on him was too great; on doctor's orders he cancelled all professional engagements during 1924, and retreated to Thaxted. In 1925 he resumed his work at St Paul's Girls' School, but did not return to any of his other posts.\nLater years.\nHolst's productivity as a composer benefited almost at once from his release from other work. His works from this period include the \"Choral Symphony\" to words by Keats (a \"Second Choral Symphony\" to words by George Meredith exists only in fragments). A short Shakespearian opera, \"At the Boar's Head\", followed; neither had the immediate popular appeal of \"A Moorside Suite\" for brass band of 1928.\nIn 1927 Holst was commissioned by the New York Symphony Orchestra to write a symphony. Instead, he wrote an orchestral piece \"Egdon Heath\", inspired by Thomas Hardy's Wessex. It was first performed in February 1928, a month after Hardy's death, at a memorial concert. By this time the public's brief enthusiasm for everything Holstian was waning, and the piece was not well received in New York. Olin Downes in \"The New York Times\" opined that \"the new score seemed long and undistinguished\". The day after the American performance, Holst conducted the City of Birmingham Orchestra in the British premiere. \"The Times\" acknowledged the bleakness of the work but allowed that it matched Hardy's grim view of the world: \"\"Egdon Heath\" is not likely to be popular, but it says what the composer wants to say, whether we like it or not, and truth is one aspect of duty.\" Holst had been distressed by hostile reviews of some of his earlier works, but he was indifferent to critical opinion of \"Egdon Heath\", which he regarded as, in Adams's phrase, his \"most perfectly realized composition\".\nTowards the end of his life Holst wrote the \"Choral Fantasia\" (1930) and he was commissioned by the BBC to write a piece for military band; the resulting prelude and scherzo \"Hammersmith\" was a tribute to the place where he had spent most of his life. The composer and critic Colin Matthews considers the work \"as uncompromising in its way as \"Egdon Heath\", discovering, in the words of Imogen Holst, 'in the middle of an over-crowded London\u00a0... the same tranquillity that he had found in the solitude of Egdon Heath'\". The work was unlucky in being premiered at a concert that also featured the London premiere of Walton's \"Belshazzar's Feast\", by which it was somewhat overshadowed.\nHolst wrote a score for a British film, \"The Bells\" (1931), and was amused to be recruited as an extra in a crowd scene. Both film and score are now lost. He wrote a \"jazz band piece\", \"Mr Shilkret's Maggot\", that Imogen later arranged for orchestra as \"Capriccio\". Having composed operas throughout his life with varying success, Holst found for his last opera, \"The Wandering Scholar\", what Matthews calls \"the right medium for his oblique sense of humour, writing with economy and directness\".\nHarvard University offered Holst a lectureship for the first six months of 1932. Arriving via New York he was pleased to be reunited with his brother, Emil, whose acting career under the name of Ernest Cossart had taken him to Broadway; but Holst was dismayed by the continual attentions of press interviewers and photographers. He enjoyed his time at Harvard, but was taken ill while there: a duodenal ulcer prostrated him for some weeks. He returned to England, joined briefly by his brother for a holiday together in the Cotswolds. His health declined, and he withdrew further from musical activities. One of his last efforts was to guide the young players of the St Paul's Girls' School orchestra through one of his final compositions, the \"Brook Green Suite\", in March 1934.\nHolst died in London on 25 May 1934, at the age of 59, of heart failure following an operation on his ulcer. His ashes were interred at Chichester Cathedral in Sussex, close to the memorial to Thomas Weelkes, his favourite Tudor composer. Bishop George Bell gave the memorial oration at the funeral, and Vaughan Williams conducted music by Holst and himself.\nMusic.\nStyle.\nHolst's absorption of folksong, not only in the melodic sense but in terms of its simplicity and economy of expression, helped to develop a style that many of his contemporaries, even admirers, found austere and cerebral. This is contrary to the popular identification of Holst with \"The Planets\", which Matthews believes has masked his status as a composer of genuine originality. Against charges of coldness in the music, Imogen cites Holst's characteristic \"sweeping modal tunes mov[ing] reassuringly above the steps of a descending bass\", while Michael Kennedy points to the 12 Humbert Wolfe settings of 1929, and the 12 Welsh folksong settings for unaccompanied chorus of 1930\u201331, as works of true warmth.\nMany of the characteristics that Holst employed\u2014unconventional time signatures, rising and falling scales, ostinato, bitonality and occasional polytonality\u2014set him apart from other English composers. Vaughan Williams remarked that Holst always said in his music what he wished to say, directly and concisely; \"He was not afraid of being obvious when the occasion demanded, nor did he hesitate to be remote when remoteness expressed his purpose\". Kennedy has surmised that Holst's economy of style was in part a product of the composer's poor health: \"the effort of writing it down compelled an artistic economy which some felt was carried too far\". However, as an experienced instrumentalist and orchestra member, Holst understood music from the standpoint of his players and made sure that, however challenging, their parts were always practicable. According to his pupil Jane Joseph, Holst fostered in performance \"a spirit of practical comradeship\u00a0... none could know better than he the boredom possible to a professional player, and the music that rendered boredom impossible\".\nEarly works.\nAlthough Holst wrote a large number of works\u2014particularly songs\u2014during his student days and early adulthood, almost everything he wrote before 1904 he later classified as derivative \"early horrors\". Nevertheless, the composer and critic Colin Matthews recognises even in these apprentice works an \"instinctive orchestral flair\". Of the few pieces from this period which demonstrate some originality, Matthews pinpoints the G minor String Trio of 1894 (unperformed until 1974) as the first underivative work produced by Holst. Matthews and Imogen Holst each highlight the \"Elegy\" movement in \"The Cotswold Symphony\" (1899\u20131900) as among the more accomplished of the apprentice works, and Imogen discerns glimpses of her father's real self in the 1899 \"Suite de ballet\" and the \"Ave Maria\" of 1900. She and Matthews have asserted that Holst found his genuine voice in his setting of Whitman's verses, \"The Mystic Trumpeter\" (1904), in which the trumpet calls that characterise Mars in \"The Planets\" are briefly anticipated. In this work, Holst first employs the technique of bitonality\u2014the use of two keys simultaneously.\nExperimental years.\nAt the beginning of the 20th century, according to Matthews, it appeared that Holst might follow Schoenberg into late Romanticism. Instead, as Holst recognised afterwards, his encounter with Purcell's \"Dido and Aeneas\" prompted his searching for a \"musical idiom of the English language\"; the folksong revival became a further catalyst for Holst to seek inspiration from other sources during the first decade or so of the new century.\nIndian period.\nHolst's interest in Indian mythology, shared by many of his contemporaries, first became musically evident in the opera \"Sita\" (1901\u201306). During the opera's long gestation, Holst worked on other Indian-themed pieces. These included \"Maya\" (1901) for violin and piano, regarded by the composer and writer Raymond Head as \"an insipid salon-piece whose musical language is dangerously close to Stephen Adams\". Then, through Vaughan Williams, Holst discovered and became an admirer of the music of Ravel, whom he considered a \"model of purity\" on the level with Haydn, another composer he greatly admired.\nThe combined influence of Ravel, Hindu spiritualism and English folk tunes enabled Holst to get beyond the once all-consuming influences of Wagner and Richard Strauss and to forge his own style. Imogen Holst has acknowledged Holst's own suggestion (written to Vaughan Williams): \"[O]ne ought to follow Wagner until he leads you to fresh things\". She notes that although much of his grand opera, \"Sita\", is \"'good old Wagnerian bawling'\u00a0... towards the end a change comes over the music, and the beautifully calm phrases of the hidden chorus representing the Voice of the Earth are in Holst's own language.\"\nAccording to Rubbra, the publication in 1911 of Holst's Rig Veda Hymns was a landmark event in the composer's development: \"Before this, Holst's music had, indeed, shown the clarity of utterance which has always been his characteristic, but harmonically there was little to single him out as an important figure in modern music.\" Dickinson describes these vedic settings as pictorial rather than religious; although the quality is variable the sacred texts clearly \"touched vital springs in the composer's imagination\". While the music of Holst's Indian verse settings remained generally western in character, in some of the vedic settings he experimented with Indian \"raga\" (scales).\nThe chamber opera \"Savitri\" (1908) is written for three solo voices, a small hidden female chorus, and an instrumental combination of two flutes, a cor anglais and a double string quartet. The music critic John Warrack comments on the \"extraordinary expressive subtlety\" with which Holst deploys the sparse forces: \"...\u00a0[T]he two unaccompanied vocal lines opening the work skilfully convey the relationship between Death, steadily advancing through the forest, and Savitri, her frightened answers fluttering round him, unable to escape his harmonic pull.\" Head describes the work as unique in its time for its compact intimacy, and considers it Holst's most successful attempt to end the domination of Wagnerian chromaticism in his music. Dickinson considers it a significant step, \"not towards opera, but towards an idiomatic pursuit of [Holst's] vision\". Of the K\u0101lid\u0101sa texts, Dickinson dismisses \"The Cloud Messenger\" (1910\u201312) as an \"accumulation of desultory incidents, opportunistic dramatic episodes and ecstatic outpourings\" which illustrate the composer's creative confusion during that period; the \"Two Eastern Pictures\" (1911), in Dickinson's view, provide \"a more memorable final impression of K\u0101lid\u0101sa\".\nFolksong and other influences.\nHolst's settings of Indian texts formed only a part of his compositional output in the period 1900 to 1914. A highly significant factor in his musical development was the English folksong revival, evident in the orchestral suite \"A Somerset Rhapsody\" (1906\u201307), a work that was originally to be based around eleven folksong themes; this was later reduced to four. Observing the work's kinship with Vaughan Williams's \"Norfolk Rhapsody\", Dickinson remarks that, with its firm overall structure, Holst's composition \"rises beyond the level of\u00a0... a song-selection\". Imogen acknowledges that Holst's discovery of English folksongs \"transformed his orchestral writing\", and that the composition of \"A Somerset Rhapsody\" did much to banish the chromaticisms that had dominated his early compositions. In the \"Two Songs without Words\" of 1906, Holst showed that he could create his own original music using the folk idiom. An orchestral folksong fantasy \"Songs of the West\", also written in 1906, was withdrawn by the composer and never published, although it emerged in the 1980s in the form of an arrangement for wind band by James Curnow.\nIn the years before the First World War, Holst composed in a variety of genres. Matthews considers the evocation of a North African town in the \"Beni Mora\" suite of 1908 the composer's most individual work to that date; the third movement gives a preview of minimalism in its constant repetition of a four-bar theme. Holst wrote two suites for military band, in E flat (1909) and F major (1911) respectively, the first of which became and remains a brass-band staple. This piece, a highly original and substantial musical work, was a signal departure from what Short describes as \"the usual transcriptions and operatic selections which pervaded the band repertoire\". Also in 1911 he wrote \"Hecuba's Lament\", a setting of Gilbert Murray's translation from Euripides built on a seven-beat refrain designed, says Dickinson, to represent Hecuba's defiance of divine wrath. In 1912 Holst composed two psalm settings, in which he experimented with plainsong; the same year saw the enduringly popular \"St Paul's Suite\" (a \"gay but retrogressive\" piece according to Dickinson), and the failure of his large scale orchestral work \"Phantastes\". In 1915 the Japanese dancer Michio It\u014d was planning to perform in London, and he engaged Holst to compose the musical accompaniment. As a starting point for the basic themes, Holst sat and took notes while Ito whistled Japanese folk tunes to him. The result was Holst's \"Japanese Suite\", Op. 33.\nFull flowering.\n\"The Planets\".\nHolst conceived the idea of \"The Planets\" in 1913, partly as a result of his interest in astrology, and also from his determination, despite the failure of \"Phantastes\", to produce a large-scale orchestral work. The chosen format may have been influenced by Schoenberg's \"F\u00fcnf Orchesterst\u00fccke\", and shares something of the aesthetic, Matthews suggests, of Debussy's \"Nocturnes\" or \"La mer\". Holst began composing \"The Planets\" in 1914; the movements appeared not quite in their final sequence; \"Mars\" was the first to be written, followed by \"Venus\" and \"Jupiter\". \"Saturn\", \"Uranus\" and \"Neptune\" were all composed during 1915, and \"Mercury\" was completed in 1916.\nEach planet is represented with a distinct character; Dickinson observes that \"no planet borrows colour from another\". In \"Mars\", a persistent, uneven rhythmic cell consisting of five beats, combined with trumpet calls and harmonic dissonance provides battle music which Short asserts is unique in its expression of violence and sheer terror, \"...\u00a0Holst's intention being to portray the reality of warfare rather than to glorify deeds of heroism\". In \"Venus\", Holst incorporated music from an abandoned vocal work, \"A Vigil of Pentecost\", to provide the opening; the prevalent mood within the movement is of peaceful resignation and nostalgia. \"Mercury\" is dominated by uneven metres and rapid changes of theme, to represent the speedy flight of the winged messenger. \"Jupiter\" is renowned for its central melody, \"Thaxted\", in Dickinson's view \"a fantastic relaxation in which many retain a far from sneaking delight\". Dickinson and other critics have decried the later use of the tune in the patriotic hymn \"I Vow to Thee, My Country\"\u2014despite Holst's full complicity.\nFor \"Saturn\", Holst again used a previously composed vocal piece, \"Dirge and Hymeneal\", as the basis for the movement, where repeated chords represent the relentless approach of old age. \"Uranus\", which follows, has elements of Berlioz's \"Symphonie fantastique\" and Dukas's \"The Sorcerer's Apprentice\", in its depiction of the magician who \"disappears in a whiff of smoke as the sonic impetus of the movement diminishes from fff to ppp in the space of a few bars\". \"Neptune\", the final movement, concludes with a wordless female chorus gradually receding, an effect which Warrack likens to \"unresolved timelessness\u00a0... never ending, since space does not end, but drifting away into eternal silence\". Apart from his concession with \"I Vow to Thee...\"', Holst insisted on the unity of the whole work, and opposed the performance of individual movements. Nevertheless, Imogen wrote that the piece had \"suffered from being quoted in snippets as background music\".\nMaturity.\nDuring and after the composition of \"The Planets\", Holst wrote or arranged numerous vocal and choral works, many of them for the wartime Thaxted Whitsun Festivals, 1916\u201318. They include the \"Six Choral Folksongs\" of 1916, based on West Country tunes, of which \"Swansea Town\", with its \"sophisticated tone\", is deemed by Dickinson to be the most memorable. Holst downplayed such music as \"a limited form of art\" in which \"mannerisms are almost inevitable\"; the composer Alan Gibbs, however, believes Holst's set at least equal to Vaughan Williams's \"Five English Folk Songs\" of 1913.\nHolst's first major work after \"The Planets\" was \"The Hymn of Jesus\", completed in 1917. The words are from a Gnostic text, the apocryphal Acts of John, using a translation from the Greek which Holst prepared with assistance from Clifford Bax and Jane Joseph. Head comments on the innovative character of the \"Hymn\": \"At a stroke Holst had cast aside the Victorian and Edwardian sentimental oratorio, and created the precursor of the kind of works that John Tavener, for example, was to write in the 1970s\". Matthews has written that the \"Hymn\"'s \"ecstatic\" quality is matched in English music \"perhaps only by Tippett's \"The Vision of Saint Augustine\"\"; the musical elements include plainsong, two choirs distanced from each other to emphasise dialogue, dance episodes and \"explosive chordal dislocations\".\nIn the \"Ode to Death\" (1918\u201319), the quiet, resigned mood is seen by Matthews as an \"abrupt volte-face\" after the life-enhancing spirituality of the \"Hymn\". Warrack refers to its aloof tranquillity; Imogen Holst believed the \"Ode\" expressed Holst's private attitude to death. The piece has rarely been performed since its premiere in 1922, although the composer Ernest Walker thought it was Holst's finest work to that date.\nThe influential critic Ernest Newman considered \"The Perfect Fool\" \"the best of modern British operas\", but its unusually short length (about an hour) and parodic, whimsical nature\u2014described by \"The Times\" as \"a brilliant puzzle\"\u2014put it outside the operatic mainstream. Only the ballet music from the opera, which \"The Times\" called \"the most brilliant thing in a work glittering with brilliant moments\", has been regularly performed since 1923. Holst's libretto attracted much criticism, although Edwin Evans remarked on the rare treat in opera of being able to hear the words being sung.\nLater works.\nBefore his enforced rest in 1924, Holst demonstrated a new interest in counterpoint, in his \"Fugal Overture\" of 1922 for full orchestra and the neo-classical\" Fugal Concerto\" of 1923, for flute, oboe and strings. In his final decade he mixed song settings and minor pieces with major works and occasional new departures; the 1925 \"Terzetto\" for flute, viola and oboe, each instrument playing in a different key, is cited by Imogen as Holst's only successful chamber work. Of the \"Choral Symphony\" completed in 1924, Matthews writes that, after several movements of real quality, the finale is a rambling anticlimax. Holst's penultimate opera, \"At the Boar's Head\" (1924), is based on tavern scenes from Shakespeare's \"Henry IV, Parts 1\" and \"2\". The music, which is largely derived from old English melodies gleaned from Cecil Sharp and other collections, has pace and verve; the contemporary critic Harvey Grace discounted the lack of originality, a facet which he said \"can be shown no less convincingly by a composer's handling of material than by its invention\".\n\"Egdon Heath\" (1927) was Holst's first major orchestral work after \"The Planets\". Matthews summarises the music as \"elusive and unpredictable [with] three main elements: a pulseless wandering melody [for strings], a sad brass processional, and restless music for strings and oboe.\" The mysterious dance towards the end is, says Matthews, \"the strangest moment in a strange work\". Richard Greene in \"Music &amp; Letters\" describes the piece as \"a larghetto dance in a siciliano rhythm with a simple, stepwise, rocking melody\", but lacking the power of \"The Planets\" and, at times, monotonous to the listener. A more popular success was \"A Moorside Suite\" for brass band, written as a test piece for the National Brass Band Festival championships of 1928. While written within the traditions of north-country brass-band music, the suite, Short says, bears Holst's unmistakable imprint, \"from the skipping 6/8 of the opening Scherzo, to the vigorous melodic fourths of the concluding March, the intervening Nocturne bearing a family resemblance to the slow-moving procession of \"Saturn\"\". \"A Moorside Suite\" has undergone major revisionism in the article \"Symphony Within: Rehearing Holst's 'A Moorside Suite'\" by Stephen Arthur Allen in the Winter 2017 edition of \"The Musical Times\". As with 'Egdon Heath'\u2014commissioned as a symphony\u2014the article reveals the symphonic nature of this brass-band work.\nAfter this, Holst tackled his final attempt at opera in a cheerful vein, with \"The Wandering Scholar\" (1929\u201330), to a text by Clifford Bax. Imogen refers to the music as \"Holst at his best in a scherzando (playful) frame of mind\"; Vaughan Williams commented on the lively, folksy rhythms: \"Do you think there's a \"little\" bit too much in the opera?\" Short observes that the opening motif makes several reappearances without being identified with a particular character, but imposes musical unity on the work.\nHolst composed few large-scale works in his final years. \"A Choral Fantasia\" of 1930 was written for the Three Choirs Festival at Gloucester; beginning and ending with a soprano soloist, the work, also involving chorus, strings, brass and percussion, includes a substantial organ solo which, says Imogen Holst, \"knows something of the 'colossal and mysterious' loneliness of \"Egdon Heath\"\". Apart from his final uncompleted symphony, Holst's remaining works were for small forces; the eight \"Canons\" of 1932 were dedicated to his pupils, though in Imogen's view that they present a formidable challenge to the most professional of singers. The \"Brook Green Suite\" (1932), written for the orchestra of St Paul's School, was a late companion piece to the \"St Paul's Suite\". The \"Lyric Movement\" for viola and small orchestra (1933) was written for Lionel Tertis. Quiet and contemplative, and requiring little virtuosity from the soloist, the piece was slow to gain popularity among violists. Robin Hull, in \"Penguin Music Magazine\", praised the work's \"clear beauty\u2014impossible to mistake for the art of any other composer\"; in Dickinson's view, however, it remains \"a frail creation\". Holst's final composition, the orchestral scherzo movement of a projected symphony, contains features characteristic of much of Holst's earlier music\u2014\"a summing up of Holst's orchestral art\", according to Short. Dickinson suggests that the somewhat casual collection of material in the work gives little indication of the symphony that might have been written.\nRecordings.\nHolst made some recordings, conducting his own music. For the Columbia company he recorded \"Beni Mora\", the \"Marching Song\" and the complete \"Planets\" with the London Symphony Orchestra (LSO) in 1922, using the acoustic process. The limitations of early recording prevented the gradual fade-out of women's voices at the end of \"Neptune\", and the lower strings had to be replaced by a tuba to obtain an effective bass sound. With an anonymous string orchestra Holst recorded the \"St Paul's Suite\" and \"Country Song\" in 1925. Columbia's main rival, HMV, issued recordings of some of the same repertoire, with an unnamed orchestra conducted by Albert Coates. When electrical recording came in, with dramatically improved recording quality, Holst and the LSO re-recorded \"The Planets\" for Columbia in 1926.\nIn the early LP era little of Holst's music was available on disc. Only six of his works are listed in the 1955 issue of \"The Record Guide\": \"The Planets\" (recordings under Boult on HMV and Nixa, and another under Sir Malcolm Sargent on Decca); the \"Perfect Fool\" ballet music; the \"St Paul's Suite\"; and three short choral pieces. In the stereo LP and CD eras numerous recordings of \"The Planets\" were issued, performed by orchestras and conductors from round the world. By the early years of the 21st century most of the major and many of the minor orchestral and choral works had been issued on disc. The 2008 issue of \"The Penguin Guide to Recorded Classical Music\" contained seven pages of listings of Holst's works on CD. Of the operas, \"Savitri\", \"The Wandering Scholar\", and \"At the Boar's Head\" have been recorded.\nLegacy.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n[Holst's] influence is lasting in the work of all of us who value directness and sincerity and who view music not so much a secret preserve for the leisured few as a vital part of everyday life\n \"A tribute from Edmund Rubbra\"\nWarrack emphasises that Holst acquired an instinctive understanding\u2014perhaps more so than any English composer\u2014of the importance of folksong. In it he found \"a new concept not only of how melody might be organized, but of what the implications were for the development of a mature artistic language\". Holst did not found or lead a school of composition; nevertheless, he influenced both contemporaries and successors. According to Short, Vaughan Williams described Holst as \"the greatest influence on my music\", although Matthews asserts that each influenced the other equally. Among later composers, Michael Tippett is acknowledged by Short as Holst's \"most significant artistic successor\", both in terms of compositional style and because Tippett, who succeeded Holst as director of music at Morley College, maintained the spirit of Holst's music there. Of an early encounter with Holst, Tippett later wrote: \"Holst seemed to look right inside me, with an acute spiritual vision\". Kennedy observes that \"a new generation of listeners\u00a0... recognized in Holst the fount of much that they admired in the music of Britten and Tippett\". Holst's pupil Edmund Rubbra acknowledged how he and other younger English composers had adopted Holst's economy of style: \"With what enthusiasm did we pare down our music to the very bone\".\nShort cites other English composers who are in debt to Holst, in particular William Walton and Benjamin Britten, and suggests that Holst's influence may have been felt further afield. Above all, Short recognises Holst as a composer for the people, who believed it was a composer's duty to provide music for practical purposes\u2014festivals, celebrations, ceremonies, Christmas carols or simple hymn tunes. Thus, says Short, \"many people who may never have heard any of [Holst's] major works\u00a0... have nevertheless derived great pleasure from hearing or singing such small masterpieces as the carol 'In the Bleak Midwinter'\".\nOn 27\u00a0September 2009, after a weekend of concerts at Chichester Cathedral in memory of Holst, a new memorial was unveiled to mark the 75th anniversary of the composer's death. It is inscribed with words from the text of \"The Hymn of Jesus\": \"The heavenly spheres make music for us\". In April 2011 a BBC television documentary, \"Holst: In the Bleak Midwinter\", charted Holst's life with particular reference to his support for socialism and the cause of working people. Holst's birthplace, 4 Pittville Terrace (later known as 4 Clarence Road) in Pittville, Cheltenham, is now a museum, the Holst Victorian House, and is open to visitors.\nNotes and references.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49242", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=49242", "title": "Irina Privalova", "text": "Russian athlete (born 1968)\nIrina Anatolyevna Privalova (; born 22 November 1968 in Malakhovka) is a Russian Olympic gold medallist athlete.\nHer Summer Olympics debut was in 1992 in the sprint events, where she won two medals a bronze in the 100\u00a0m and running the anchor leg in the 4 \u00d7 100 team, a silver and came fourth in the 200, representing the Unified Team. With three European individual championships and three individual world medals, Irina Privalova had been a formidable competitor during most of the 1990s (see Sprints) but had not yet won an outdoor international event gold medal (as an individual athlete, she had won relay gold in 1993).\nIn 2000, she switched to the 400\u00a0m hurdles discipline winning the gold medal in 53.02 s (see 400 m Hurdles) and a bronze in the 4 \u00d7 400\u00a0m relay team for Russia.\nIrina Privalova is currently the world indoor record holder in the 50 m (5.96 s) and 60 m (6.92 s) sprints (See World Indoor Records). She has also been the world indoor champion at the 60 m (7.02 s in 1991), 200 m (22.15 s in 1993), and 400 m (50.23 s in 1995) events the first athlete to win titles, indoors or outdoors, at three different distances.\nPrivalova achieved her best time (10.77 s) in the 100 m in 1994 \u2013 the fastest time for nine years.\nIn 2008, aged 39, she reached the semi-finals of the 100 m at Russian championships in attempting to qualify for her fourth Olympics. She had tried moving to the 800 m to qualify for the 2004 Olympics.\nIn 2020, Privalova stood for the presidency of the Russian Athletics Federation. She failed to win but became vice-president. She later was called to stand-in as acting president when the elected president moved to a government agency (See Russian Athletic Federation Presidency).\nSprints.\nPrivalova came to international recognition in 1991 at the World Indoor Championships that year. Racing as Irina Privalova-Sergeyeva, in the 60 m she defeated the great Jamaican sprinter Merlene Ottey who reached the final undefeated in 82 successive races.\nOttey had her revenge in the 200 m with Privalova coming second, Ottey equalling the world record in her victory.\nAt the 1992 Barcelona Olympics, racing as Irina Privalova, she won a bronze medal in the 100 m. The race was incredibly tight \u2013 Gail Devers won in 10.82 s, Juliet Cuthbert was second in 10.83 s, and Privalova third in 10.84 s. Privalova also came fourth in the 200 m.\nAt the 1993 World Indoor Championships, Privalova narrowly lost to Gail Devers in the 60 m, 6.95 s to 6.97 s, but won the 200 m title (in 22.15 s, then the second fastest time ever; she want faster in 1995 at 22.10 s, second fastest time ever to the world record of 21.87 s).\nIn the 1993 World Athletics Championships, Privalova won her only gold medal at a world championship in the 4 \u00d7 100 m relay. She narrowly held off the United States's Gail Devers on the anchor leg \u2013 both teams recording a championship record time of 41.49 s.\nIn 1994, in August at the European Championships, for Russia she won gold in the 100 and 200 m and silver in the 4 \u00d7 100 m relay; in September, at the 1994 IAAF World Cup, representing Europe, she won the 100 m and 400 m, and came third in the 200 m.\nIn 1995, Privalova moved up to the 400 m for the World Indoor Championships that year where she won in her first major race over the distance \u2013 she had not even contested the Russian championships at that distance.\nHer campaign at the 1996 Olympics was curtailed by injury. She was eliminated at the semi-final stage in the 100 m, did not start the 200 m, but was part of the Russian team that came fourth in the 4 \u00d7 100 m relay.\nIn 1997, Privalova suffered a torn muscle in the final of 60 m at the World Indoor Championships. She was out for 18 months but returned to win the 200 m at the European Championships in 1998. In the individual events she came fourth in the 100 m and won bronze in the 200 m.\nIn 1998, at the European Championships, Privalova found a time of 10.83 s was only good enough for silver in 100 m, being defeated by Christine Arron's European record winning time of 10.73 s. However, she successfully defended her European title in the 200 m and also won Silver in the 4 \u00d7 100 m relay.\nIn 1999, her World Championships ended prematurely when she had to withdraw from all her events after completing the first round of the 100 m. She did not compete again until the 2000 indoor season.\n400 m Hurdles.\nIn 2000, Privalova switched to the 400 m hurdles as her main event targeting the 2000 Olympics. This followed a year out of the sport with injury, forcing her to miss the 1999 World Championships.\nShe worked on the switch with her coach and husband, Vladimir Paraschuk. Paraschuk chose the 400 m hurdles because it was an event that reduced the risk of injury, was within Privalova's capabilities as an existing 400 m runner, and it had at the time a comparative lack of formidable competitors. In addition, she had tried athletics multi-events so had had some experience with hurdling.\nShe achieved Olympic gold after running only 6 races previous to arriving at the games.\nInjury and motherhood forced her retirement after 2000 and so she was never able to train to try the challenge of breaking the 400 m hurdles world record: in 2001, she suffered a knee ligament injury and then gave birth in December 2001 to her second child, forcing her to miss the 2002 season.\nIn 2004, she attempted a switch to 800 m to attempt to qualify for the Olympics that year but failed in her attempt. She had already stopped racing the 60 m ('her favourite event') to avoid injuries and was using the 800 m as part of her training schedule.\nRussian Athletics Federation Presidency.\nIn 2020, Privalova stood for the presidency of the Russian Athletics Federation (RusAF). She was chosen as first vice-president after coming third in the vote.\nIn February 2021, the winner Peter Ivanov relinquished his authority until December 2022 to take up a position with a government agency with Privalova taking charge.\nWorld Indoor Records.\nPrivalova achieved world record times indoors on six occasions:\nShe also two other times that would have been records but were not ratified due to faults with the timing:\nIn addition, she shares the world's best time for the unofficial distance (for record purposes) of 300 m. Her time of 35.45 s was achieved on 17 January 1993 in Moscow (it was equalled by Shaunae Miller-Uibo in 2018).\nPersonal life.\nPrivalova originally competed under her married name of Sergeyeva. Her first pregnancy forced her to miss the 1988 Olympics. After a separation and divorce, she competed under her maiden name of Privalova.\nPrivalova married her coach, Vladimir Paraschuk, and in 2000 they lived in Moscow with sons from previous marriages. Paraschuk was also, at that time, coach of track and field at Moscow State University from which Privalova has a degree in journalism (graduated in 1995). Under the tutelage of Paraschuk, Privalova trained alone, using the somewhat spartan facilities of the university, rather than attending a sports institute like most of her compatriots.\nIn 2008, she is described as the mother of three children: Alexei, aged 20; Maria, aged 6; and Katya, then 2 years old.\nAccolades and awards.\nIn 1994, Privalova was awarded European Athlete of the Year trophy for women.\nIn 2001, she was awarded the Silver Order of Merit by the IAAF (World Athletics) for an 'exceptional contribution to the world athletics movement'.\nWorld Rankings.\nPrivalova was ranked among the best in the world in both the 100 and 200 m sprint events in the 1990s, then again later in the 400 m hurdles when she switched to that event in 2000. This is according to the votes of the experts of Track and Field News.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49243", "revid": "724850", "url": "https://en.wikipedia.org/wiki?curid=49243", "title": "The Planets", "text": "Orchestral suite by Gustav Holst\nThe Planets, Op. 32, is a seven-movement orchestral suite by the English composer Gustav Holst, written between 1914 and 1917. In the last movement the orchestra is joined by a wordless female chorus. Each movement of the suite is named after a planet of the Solar System and its supposed astrological character.\nThe premiere of \"The Planets\" was at the Queen's Hall, London, on 29 September 1918, conducted by Holst's friend Adrian Boult before an invited audience of about 250 people. Three concerts at which movements from the suite were played were given in 1919 and early 1920. The first complete performance at a public concert was given at the Queen's Hall on 15 November 1920 by the London Symphony Orchestra conducted by Albert Coates.\nThe innovative nature of Holst's music caused some initial hostility among a minority of critics, but the suite quickly became and has remained popular, influential and widely performed. The composer conducted two recordings of the work, and it has been recorded at least 80 times subsequently by conductors, choirs and orchestras from the UK and internationally.\nBackground and composition.\n\"The Planets\" was composed over nearly three years, between 1914 and 1917. The work had its origins in March and April 1913, when Gustav Holst and his friend and benefactor Balfour Gardiner holidayed in Spain with the composer Arnold Bax and his brother, the author Clifford Bax. A discussion about astrology piqued Holst's interest in the subject. Clifford Bax later commented that Holst became \"a remarkably skilled interpreter of horoscopes\". Shortly after the holiday Holst wrote to a friend: \"I only study things that suggest music to me. That's why I worried at Sanskrit. Then recently the character of each planet suggested lots to me, and I have been studying astrology fairly closely\". He told Clifford Bax in 1926 that \"The Planets\":\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;... whether it\u2019s good or bad, grew in my mind slowly\u2014like a baby in a woman's womb ... For two years I had the intention of composing that cycle, and during those two years it seemed of itself more and more definitely to be taking form.\nImogen Holst, the composer's daughter, wrote that her father had difficulty with large-scale orchestral structures such as symphonies, and the idea of a suite with a separate character for each movement was an inspiration to him. Holst's biographer Michael Short and the musicologist Richard Greene both think it likely that another inspiration for the composer to write a suite for large orchestra was the example of Schoenberg's Five Pieces for Orchestra. That suite had been performed in London in 1912 and again in 1914; Holst was at one of the performances, and he is known to have owned a copy of the score.\nHolst described \"The Planets\" as \"a series of mood pictures\", acting as \"foils to one another\", with \"very little contrast in any one of them\". Short writes that some of the characteristics the composer attributed to the planets may have been suggested by Alan Leo's booklet \"What Is a Horoscope?\", which he was reading at the time. Holst took the title of two movements \u2013 \"Mercury, the Winged Messenger\" and \"Neptune, the Mystic\" \u2013 from Leo's books. But although astrology was Holst's starting point, he arranged the planets to suit his own plan:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;... ignoring some important astrological factors such as the influence of the sun and the moon, and attributing certain non-astrological qualities to each planet. Nor is the order of movements the same as that of the planets' orbits round the sun; his only criterion being that of maximum musical effectiveness.\nIn an early sketch for the suite Holst listed Mercury as \"no. 1\", which Greene suggests raises the possibility that the composer's first idea was simply to depict the planets in the obvious order, from nearest the sun to the farthest. \"However, opening with the more disturbing character of Mars allows a more dramatic and compelling working out of the musical material\".\nHolst had a heavy workload as head of music at St Paul's Girls' School, Hammersmith, and director of music at Morley College, and had limited time for composing. Imogen Holst wrote, \"Weekends and holidays were the only times when he could really get on with his own work, which is why it took him over two years to finish \"The Planets\"\". She added that Holst's chronic neuritis in his right arm was troubling him considerably and he would have found it impossible to complete the 198 pages of the large full score without the help of two colleagues at St Paul's, Vally Lasker and Nora Day, whom he called his \"scribes\".\nThe first movement to be written was Mars in mid-1914, followed by Venus and Jupiter in the latter part of the year, Saturn and Uranus in mid-1915, Neptune later in 1915 and Mercury in early 1916. Holst completed the orchestration during 1917.\nFirst performances.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\nJust before the Armistice, Gustav Holst burst into my office: \"Adrian, the YMCA are sending me to Salonika quite soon and Balfour Gardiner, bless his heart, has given me a parting present consisting of the Queen's Hall, full of the Queen's Hall Orchestra for the whole of a Sunday morning. So we're going to do \"The Planets\", and you've got to conduct.\" \nAdrian Boult\nThe premiere of \"The Planets\", conducted at Holst's request by Adrian Boult, was held at short notice on 29\u00a0September 1918, during the last weeks of the First World War, in the Queen's Hall with the financial support of Gardiner. It was hastily rehearsed; the musicians of the Queen's Hall Orchestra first saw the complicated music only two hours before the performance, and the choir for Neptune was recruited from Holst's students at Morley College and St Paul's Girls' School. It was a comparatively intimate affair, attended by around 250 invited associates, but Holst regarded it as the public premiere, inscribing Boult's copy of the score, \"This copy is the property of Adrian Boult who first caused the Planets to shine in public and thereby earned the gratitude of Gustav Holst.\"\nAt a Royal Philharmonic Society concert at the Queen's Hall on 27 February 1919 conducted by Boult, five of the seven movements were played in the order Mars, Mercury, Saturn, Uranus, and Jupiter. It was Boult's decision not to play all seven movements at this concert. Although Holst would have liked the suite to be played complete, Boult's view was that when the public were being presented with a completely new language of this kind, \"half an hour of it was as much as they could take in\". Imogen Holst recalled that her father \"hated incomplete performances of \"The Planets\", though on several occasions he had to agree to conduct three or four movements at Queen's Hall concerts. He particularly disliked having to finish with Jupiter, to make a 'happy ending', for, as he himself said, 'in the real world the end is not happy at all'\".\nAt a Queen's Hall concert on 22 November 1919, Holst conducted Venus, Mercury and Jupiter. There was another incomplete public performance, in Birmingham, on 10 October 1920, with five movements (Mars, Venus, Mercury, Saturn and Jupiter), conducted by the composer.\nThe first complete performance of the suite at a public concert was on 15 November 1920; the London Symphony Orchestra was conducted by Albert Coates. The first complete performance conducted by the composer was on 13 October 1923, with the Queen's Hall Orchestra.\nInstrumentation.\nThe work is scored for a large orchestra. Holst's fellow composer Ralph Vaughan Williams wrote in 1920, \"Holst uses a very large orchestra in the \"Planets\" not to make his score look impressive, but because he needs the extra tone colour and knows how to use it\". The score calls for the following instrumentation. The movements vary in the combinations of instruments used.\nIn Neptune, two three-part women's choruses (each comprising two soprano sections and one alto section) located in an adjoining room which is to be screened from the audience are added.\nSource: Published score.\nStructure.\n1. Mars, the Bringer of War.\nMars is marked allegro and is in a relentless ostinato for most of its duration. It opens quietly, the first two bars played by percussion, harp and \"col legno\" strings. The music builds to a quadruple-forte, dissonant climax. Although Mars is often thought to portray the horrors of mechanised warfare, it was completed before the First World War started. The composer Colin Matthews writes that for Holst, Mars would have been \"an experiment in rhythm and clashing keys\", and its violence in performance \"may have surprised him as much as it galvanised its first audiences\". Short comments, \"harmonic dissonances abound, often resulting from clashes between moving chords and static pedal-points\", which he compares to a similar effect at the end of Stravinsky's \"The Firebird\", and adds that although battle music had been written before, notably by Richard Strauss in \"Ein Heldenleben\", \"it had never expressed such violence and sheer terror\".\n2. Venus, the Bringer of Peace.\nThe second movement begins adagio in . According to Imogen Holst, Venus \"has to try and bring the right answer to Mars\". The movement opens with a solo horn theme answered quietly by the flutes and oboes. A second theme is given to solo violin. The music proceeds tranquilly with oscillating chords from flutes and harps, with decoration from the celesta. Between the opening adagio and the central largo there is a flowing andante section in with a violin melody (solo then tutti) accompanied by gentle syncopation in the woodwind. The oboe solo in the central largo is one of the last romantic melodies Holst allowed himself before turning to a more austere manner in later works. Leo called the planet \"the most fortunate star under which to be born\"; Short calls Holst's Venus \"one of the most sublime evocations of peace in music\".\n3. Mercury, the Winged Messenger.\nMercury is in and is marked vivace throughout. The composer R. O. Morris thought it the nearest of the movements to \"the domain of programme music pure and simple ... it is essentially pictorial in idea. Mercury is a mere activity whose character is not defined\". This movement, the last of the seven to be written, contains Holst's first experiments with bitonality. He juxtaposes melodic fragments in B\u266d major and E major, in a fast-moving scherzo. Solo violin, high-pitched harp, flute and glockenspiel are prominently featured. It is the shortest of the seven movements, typically taking between &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3+1\u20442 and 4 minutes in performance.\n4. Jupiter, the Bringer of Jollity.\nIn this movement Holst portrays Jupiter's supposedly characteristic \"abundance of life and vitality\" with music that is buoyant and exuberant. Nobility and generosity are allegedly characteristics of those born under Jupiter, and in the slower middle section Holst provides a broad tune embodying those traits. In the view of Imogen Holst, it has been compromised by its later use as the melody for a solemn patriotic hymn, \"I Vow to Thee, My Country\"; the musicologist Lewis Foreman comments that the composer did not think of it in those terms, as shown by his own recordings of the movement. The opening section of the movement is marked allegro giocoso, in time. The second theme, at the same tempo, is in time, as is the broad melody of the middle section, marked andante maestoso, which Holst marks to be taken at half the speed of the opening section. The opening section returns and after a reappearance of the maestoso tune \u2013 its expected final cadence unresolved, as in its first appearance \u2013 the movement ends with a triple forte quaver chord for the full orchestra.\n5. Saturn, the Bringer of Old Age.\nSaturn was Holst's favourite movement of the suite. Matthews describes it as \"a slow processional which rises to a frightening climax before fading away as if into the outer reaches of space\". The movement opens as a quiet adagio in and the basic pace remains slow throughout, with short bursts of animato in the first part and a switch to andante in in the later section. Apart from the timpani no percussion is used in this movement except for tubular bells at climactic points. At the beginning, flutes, bassoons and harps play a theme suggesting a ticking clock. A solemn melody is introduced by the trombones (Holst's own main instrument) and taken up by the full orchestra. A development of the ticking theme leads to a clangorous triple forte climax, after which the music dies away and ends quietly.\n6. Uranus, the Magician.\nMatthews describes the character of the movement as that of \"a clumsy dance, which gradually gets more and more out of hand (not unlike Dukas's \"Sorcerer's Apprentice\") until, with what seems like a magic wand, all is abruptly swept away into the far distance\". The movement, which begins with what Short calls \"a tremendous four-note brass motif\", is marked allegro in . The music proceeds in \"a series of merry pranks\" with occasional interjections in , building to a quadruple forte climax with a prominent organ glissando, after which the music suddenly drops to a pianissimo lento before alternating quick and slow sections bring the movement to its pianissimo conclusion.\n7. Neptune, the Mystic.\nThe music of the last movement is quiet throughout, in a swaying, irregular metre, opening with flutes joined by piccolo and oboes, with harps and celesta prominent later. Holst makes much use of dissonance in this movement. Before the premiere his colleague Geoffrey Toye said that a bar where the brass play chords of E minor and G\u266f minor together was \"going to sound frightful\". Holst agreed, and said it had made him shudder when he wrote it down but, \"What are you to do when they come like that?\" As the movement develops, the orchestra is joined by an offstage female chorus singing a soft wordless line: this was unusual in orchestral works at the time, although Debussy had used the same device in his \"Nocturnes\" (1900). The orchestra falls silent and the unaccompanied voices bring the work to a pianissimo conclusion in an uncertain tonality, as a door between the singers and the auditorium is gradually closed.\nReception.\nImogen Holst wrote of the 1918 premiere under Boult:\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;Even those listeners who had studied the score for months were taken aback by the unexpected clamour of Mars. During Jupiter the charwomen working in the corridors put down their scrubbing-brushes and began to dance. In Saturn the isolated listeners in the dark, half-empty hall felt themselves growing older at every bar. But it was the end of Neptune that was unforgettable, with its hidden chorus of women's voices growing fainter and fainter in the distance, until the imagination knew no difference between sound and silence.\nWhen the music was first introduced to the general public in February 1919, critical opinion was divided. Greene prints a summary of reviews of the first four public performances of the suite (or movements from it) in February and November 1919 and October and November 1920. Positive reviews are recorded in 28 of the 37 papers, magazines and journals cited. A small minority of reviewers were particularly hostile, among them those of \"The Globe\" (\"Noisy and pretentious)\"; \"The Sunday Times\" (\"Pompous, noisy and unalluring\"), and \"The Times\" (\"a great disappointment \u2026 elaborately contrived and painful to hear\"). The critic in \"The Saturday Review\" wrote that Holst evidently regarded the planets \"as objectionable nuisances that he would oust from our orbit if he could\".\n\"The Times\" rapidly changed its mind; in July 1919 it called Holst the most intriguing of his compeers and commented, \"\"The Planets\" still leaves us gasping\"; after hearing Holst conduct three of the movements in November 1919 the paper's critic declared the piece \"the first music by an Englishman we have heard for some time which is neither conventional nor negligible\", and by the time of Holst's death in 1934 the paper's assessment of the piece was \"Holst's greatest work\":\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;Each of the seven numbers shows one aspect of life regarded with a detached and unflinching scrutiny. In this suite Holst, with the directness which was characteristic of his personal intercourse and character, and which comes out in spite of all his mysticism in the technique of his music, sets forth with every elaboration his fundamentally simple view of what life brings. The work is original in conception, in its philosophical implications, in its scoring, and in its harmonic and rhythmic idiom.\n\"The Sunday Times\", too, quickly changed its line. In 1920 its new music critic, Ernest Newman, said that Holst could do \"easily, without a fuss\" what some other composers could only do \"with an effort and a smirk\", and that in \"The Planets\" he showed \"one of the subtlest and most original minds of our time. It begins working at a musical problem where most other minds would leave off\". Newman compared Holst's harmonic innovations to those of Stravinsky, to the latter's disadvantage, and expressed none of the reservations that qualified his admiration of Schoenberg's \"Five Pieces for Orchestra\".\nRecordings.\nThere have been at least 80 commercial recordings of \"The Planets\". Holst conducted the London Symphony Orchestra in the first two recorded performances: the first was an acoustic recording made in sessions between September 1922 and November 1923; the second was made in 1926 using the new electrical recording process. Holst's tempi are in general faster than those of most of his successors on record. This may have been due to the need to fit the music on 78 rpm discs, although later 78 versions are slower. Holst's later recording is quicker than the acoustic version, possibly because the electrical process required wider grooves, reducing the available playing time. Other, slower, recordings from the 78 era include those conducted by Leopold Stokowski (1943) and Sir Adrian Boult (1945). Recordings from the LP age are also typically longer than the composer's, but from the digital era a 2010 recording by the London Philharmonic Orchestra conducted by Vladimir Jurowski is quicker than Holst's acoustic version and comes close to matching his 1926 speeds, and in two movements (Venus and Uranus) surpasses them. There were no commercial recordings of the work in the 1930s; timings are given below of a recording representing each subsequent decade up to the 2020s:\nSource: Naxos Music Library.\nAdditions, adaptations and influences.\nThere have been many adaptations of the suite, and several attempts to add an eighth planet \u2013 Pluto \u2013 in the time between its discovery in 1930 and its reclassification by the IAU to dwarf planet in 2006. The most prominent of these was Matthews's 2000 composition, \"Pluto, the Renewer\", commissioned by the Hall\u00e9 Orchestra. Dedicated posthumously to Imogen Holst, it was first performed in Manchester on 11 May 2000, with Kent Nagano conducting. Matthews changed the ending of Neptune slightly so that the movement would segue into Pluto. Matthews's Pluto has been recorded, coupled with Holst's suite, on at least four occasions. Others who have produced versions of Pluto for \"The Planets\" include Leonard Bernstein and Jun Nagao.\nThe suite has been adapted for numerous instruments and instrumental combinations, including organ, synthesiser, brass band, and jazz orchestra. Holst used the melody of the central section of \"Jupiter\" for a setting (\"Thaxted\") of the hymn \"I Vow to Thee, My Country\" in 1921.\n\"The Planets\" has been taken as an influence by various rock bands, and for film scores such as those for the \"Star Wars\" series. There have been numerous references to the suite in popular culture, from films to television and computer games.\nNotes, references and sources.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49244", "revid": "50723335", "url": "https://en.wikipedia.org/wiki?curid=49244", "title": "NaN", "text": "Value for unrepresentable data\nIn computing, NaN (), standing for Not a Number, is a particular value of a numeric data type (often a floating-point number) which is undefined as a number, such as the result of 0/0. Systematic use of NaNs was introduced by the IEEE\u00a0754 floating-point standard in 1985, along with the representation of other non-finite quantities such as infinities.\nIn mathematics, the result of is typically not defined as a number and may therefore be represented by NaN in computing systems.\nThe square root of a negative number is not a real number, and is therefore also represented by NaN in compliant computing systems. NaNs may also be used to represent missing values in computations.\nTwo separate kinds of NaNs are provided, termed \"quiet NaNs\" and \"signaling NaNs\". Quiet NaNs are used to propagate errors resulting from invalid operations or values. Signaling NaNs can support advanced features such as mixing numerical and symbolic computation or other extensions to basic floating-point arithmetic.\nFloating point.\nIn all floating-point calculations, NaN is not the same as infinity, although both are typically handled as special cases in floating-point representations of real numbers as well as in floating-point operations. An invalid operation is also not the same as an arithmetic overflow (which would return an infinity or the largest finite number in magnitude) or an arithmetic underflow (which would return the smallest normal number in magnitude, a subnormal number, or zero).\nIn the IEEE 754 binary interchange formats, NaNs are encoded with the exponent field filled with ones (like infinity values), and some non-zero number in the trailing significand field (to make them distinct from infinity values); this allows the definition of multiple distinct NaN values, depending on which bits are set in the trailing significand field, but also on the value of the leading sign bit (but applications are not required to provide distinct semantics for those distinct NaN values).\nFor example, an IEEE 754 single precision (32-bit) NaN would be encoded as\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;codice_1\nwhere \"s\" is the sign (most often ignored in applications) and the \"x\" sequence represents a non-zero number (the value zero encodes infinities). In practice, the most significant bit from \"x\" is used to determine the type of NaN: \"quiet NaN\" or \"signaling NaN\" (see details in Encoding). The remaining bits encode a \"payload\" (most often ignored in applications).\nFloating-point operations other than ordered comparisons normally propagate a quiet NaN (\"qNaN\"). Most floating-point operations on a signaling NaN (\"sNaN\") signal the invalid-operation exception; the default exception action is then the same as for qNaN operands and they produce a qNaN if producing a floating-point result.\nThe propagation of quiet NaNs through arithmetic operations allows errors to be detected at the end of a sequence of operations without extensive testing during intermediate stages. For example, if one starts with a NaN and adds 1 five times in a row, each addition results in a NaN, but there is no need to check each calculation because one can just note that the final result is NaN. However, depending on the language and the function, NaNs can silently be removed from a chain of calculations where one calculation in the chain would give a constant result for all other floating-point values. For example, the calculation \"x\"0 may produce the result 1, even where \"x\" is NaN, so checking only the final result would obscure the fact that a calculation before the \"x\"0 resulted in a NaN. In general, then, a later test for a set \"invalid\" flag is needed to detect all cases where NaNs are introduced (see Function definition below for further details).\nIn section 6.2 of the old IEEE 754-2008 standard, there are two anomalous functions (the and functions, which return the maximum and the minimum, respectively, of two operands that are expected to be numbers) that favor numbers\u00a0\u2014 if just one of the operands is a NaN then the value of the other operand is returned. The IEEE 754-2019 revision has replaced these functions as they are not associative (when a signaling NaN appears in an operand).\nComparison with NaN.\nComparisons are specified by the IEEE 754 standard to take into account possible NaN operands. When comparing two real numbers, or extended real numbers (as in the IEEE 754 floating-point formats), the first number may be either less than, equal to, or greater than the second number. This gives three possible relations. But when at least one operand of a comparison is NaN, this trichotomy does not apply, and a fourth relation is needed: \"unordered\". In particular, two NaN values compare as unordered, not as equal.\nAs specified, the predicates associated with the &lt;, \u2264, =, \u2265, &gt; mathematical symbols (or equivalent notation in programming languages) return false on an unordered relation. So, for instance, NOT(\"x\" &lt; \"y\") is not logically equivalent to \"x\" \u2265 \"y\": on unordered, i.e. when \"x\" or \"y\" is NaN, the former returns true while the latter returns false. However, \u2260 is defined as the negation of =, thus it returns true on unordered.\nFrom these rules, comparing \"x\" with itself, \"x\" \u2260 \"x\" or \"x\" = \"x\", can be used to test whether \"x\" is NaN or non-NaN.\nThe comparison predicates are either signaling or non-signaling on quiet NaN operands; the signaling versions signal the invalid-operation exception for such comparisons (i.e., by default, this just sets the corresponding status flag in addition to the behavior of the non-signaling versions). The equality and inequality predicates are non-signaling. The other standard comparison predicates associated with the above mathematical symbols are all signaling if they receive a NaN operand. The standard also provides non-signaling versions of these other predicates. The predicate codice_2 determines whether a value is a NaN and never signals an exception, even if \"x\" is a signaling NaN.\nThe IEEE floating-point standard requires that \"NaN \u2260 NaN\" hold. In contrast, the 2022 private standard of posit arithmetic has a similar concept, NaR (Not a Real), where \"NaR = NaR\" holds.\nOperations generating NaN.\nThere are three kinds of operations that can return NaN:\nNaNs may also be explicitly assigned to variables, typically as a representation for missing values. Prior to the IEEE standard, programmers often used a special value (such as \u221299999999) to represent undefined or missing values, but there was no guarantee that they would be handled consistently or correctly.\nNaNs are not necessarily generated in all the above cases. If an operation can produce an exception condition and traps are not masked then the operation will cause a trap instead. If an operand is a quiet NaN, and there is also no signaling NaN operand, then there is no exception condition and the result is a quiet NaN. Explicit assignments will not cause an exception even for signaling NaNs.\nQuiet NaN.\nIn general, quiet NaNs, or qNaNs, do not raise any additional exceptions, as they propagate through most operations. But the invalid-operation exception is signaled by some operations that do not return a floating-point value, such as format conversions or certain comparison operations.\nSignaling NaN.\nSignaling NaNs, or sNaNs, are special forms of a NaN that, when consumed by most operations, should raise the invalid operation exception and then, if appropriate, be \"quieted\" into a qNaN that may then propagate. They were introduced in IEEE 754. There have been several ideas for how these might be used:\nWhen encountered, a trap handler could decode the sNaN and return an index to the computed result. In practice, this approach is faced with many complications. The treatment of the sign bit of NaNs for some simple operations (such as absolute value) is different from that for arithmetic operations. Traps are not required by the standard.\nPayload operations.\nIEEE 754-2019 recommends the operations \"getPayload\", \"setPayload\", and \"setPayloadSignaling\" be implemented, standardizing the access to payloads to streamline application use. According to the IEEE 754-2019 background document, this recommendation should be interpreted as \"required for new implementations, with reservation for backward compatibility\".\nEncoding.\nIn IEEE\u00a0754 interchange formats, NaNs are identified by specific, pre-defined bit patterns unique to NaNs. The sign bit does not matter. For the binary formats, NaNs are represented with the exponent field filled with ones (like infinity values), and some non-zero number in the trailing significand field (to make them distinct from infinity values). The original IEEE\u00a0754 standard from 1985 (IEEE\u00a0754-1985) only described binary floating-point formats, and did not specify how the signaling/quiet state was to be tagged. In practice, the most significant bit of the trailing significand field determined whether a NaN is signaling or quiet. Two different implementations, with reversed meanings, resulted:\nThe former choice has been preferred as it allows the implementation to quiet a signaling NaN by just setting the signaling/quiet bit to 1. The reverse is not possible with the latter choice because setting the signaling/quiet bit to 0 could yield an infinity.\nThe 2008 and 2019 revisions of the IEEE\u00a0754 standard make formal requirements and recommendations for the encoding of the signaling/quiet state.\nFor IEEE\u00a0754-2008 conformance, the meaning of the signaling/quiet bit in recent MIPS processors is now configurable via the NAN2008 field of the FCSR register. This support is optional in MIPS Release\u00a03 and required in Release\u00a05.\nThe state of the remaining bits of the trailing significand field are not defined by the standard. These bits encode a value called the 'payload' of the NaN. For the binary formats, the encoding is unspecified. For the decimal formats, the usual encoding of unsigned integers is used. If an operation has a single NaN input and propagates it to the output, the result NaN's payload should be that of the input NaN (this is not always possible for binary formats when the signaling/quiet state is encoded by an flag, as explained above). If there are multiple NaN inputs, the result NaN's payload should be from one of the input NaNs; the standard does not specify which.\nCanonical NaN.\nA number of systems have the concept of a \"canonical NaN\", where one specific NaN value is chosen to be the only possible qNaN generated by floating-point operations not having a NaN input. The value is usually chosen to be a quiet NaN with an all-zero payload and an arbitrarily defined sign bit.\nUsing a limited amount of NaN representations allows the system to use other possible NaN values for non-arithmetic purposes, the most important being \"NaN-boxing\", i.e. using the payload for arbitrary data. (This concept of \"canonical NaN\" is not the same as the concept of a \"canonical encoding\" in IEEE 754.)\nFunction definition.\nThere are differences of opinion about the proper definition for the result of a numeric function that receives a quiet NaN as input. One view is that the NaN should propagate to the output of the function in all cases to propagate the indication of an error. Another view, and the one taken by the ISO\u00a0C99 and IEEE\u00a0754-2008 standards in general, is that if the function has multiple arguments and the output is uniquely determined by all the non-NaN inputs (including infinity), then that value should be the result. Thus for example the value returned by and is +\u221e.\nThe problem is particularly acute for the exponentiation function codice_7 = \"x\"\"y\". The expressions 00, \u221e0 and 1\u221e are considered indeterminate forms when they occur as limits (just like \u221e\u00a0\u00d7\u00a00), and the question of whether zero to the zero power should be defined as 1 has divided opinion.\nIf the output is considered as undefined when a parameter is undefined, then should produce a qNaN. However, math libraries have typically returned 1 for codice_8 for any real number \"y\", and even when \"y\" is an infinity. Similarly, they produce 1 for codice_9 even when \"x\" is 0 or an infinity. The 2008 version of the IEEE\u00a0754 standard says that and should both return 1 since they return 1 whatever else is used instead of quiet NaN. Moreover, ISO\u00a0C99, and later IEEE\u00a0754-2008, chose to specify codice_10 = 1 instead of qNaN; the reason of this choice is given in the C rationale: \"Generally, C99 eschews a NaN result where a numerical value is useful. ... The result of is +\u221e, because all large positive floating-point values are even integers.\"\nTo satisfy those wishing a more strict interpretation of how the power function should act, the 2008 standard defines two additional power functions: codice_11, where the exponent must be an integer, and codice_12, which returns a NaN whenever a parameter is a NaN or the exponentiation would give an indeterminate form.\nInteger NaN.\nMost fixed-size integer formats cannot explicitly indicate invalid data. In such a case, when converting NaN to an integer type, the IEEE\u00a0754 standard requires that the invalid-operation exception be signaled.\nFor example in Java, such operations throw instances of \nIn C, they lead to undefined behavior, but if annex\u00a0F is supported, the operation yields an \"invalid\" floating-point exception (as required by the IEEE standard) and an unspecified value.\nIn the R language, the minimal signed value (i.e. 0x80000000) of integers is reserved for codice_13 (Not available). Conversions from NaN (or double NA) to integers then yield a codice_13 integer.\nPerl's package uses \"NaN\" for the result of strings that do not represent valid integers.\n&gt; perl -mMath::BigInt -e \"print Math::BigInt-&gt;new('foo')\"\nNaN\nDisplay.\nDifferent operating systems and programming languages may have different string representations of NaN.\n nan (C, C++, Python, Zig)\n NaN (ECMAScript, Rust, C#, Julia, Java). \n NaN% \n NAN (C, C++, Rust)\n NaNQ (IBM XL and AIX: Fortran, C++ proposal n2290)\n NaNS (ditto)\n qNaN\n sNaN\n 1.#SNAN (Excel)\n 1.#QNAN (Excel)\n -1.#IND (Excel)\n +nan.0 (Scheme)\nSince, in practice, encoded NaNs have a sign, a quiet/signaling bit and optional 'diagnostic information' (sometimes called a \"payload\"), these will occasionally be found in string representations of NaNs, too. Some examples are:\nNot all languages admit the existence of multiple NaNs. For example, ECMAScript only uses one NaN value throughout.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49246", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=49246", "title": "Biological determinism", "text": "Research paradigm in behavioural genetics\nBiological determinism, also known as genetic determinism, is the belief that human behaviour is directly controlled by an individual's genes or some component of their physiology, generally at the expense of the role of the environment, whether in embryonic development or in learning. Genetic reductionism is a similar concept, but it is distinct from genetic determinism in that the former refers to the level of understanding, while the latter refers to the supposed causal role of genes. Biological determinism has been associated with movements in science and society including eugenics, scientific racism, and the debates around the heritability of IQ, the basis of sexual orientation, and evolutionary foundations of cooperation in sociobiology.\nIn 1892, the German evolutionary biologist August Weismann proposed in his germ plasm theory that heritable information is transmitted only via germ cells, which he thought contained determinants (genes). The English polymath Francis Galton, supposing that undesirable traits such as club foot and criminality were inherited, advocated eugenics, aiming to prevent supposedly defective people from breeding. The American physician Samuel George Morton and the French physician Paul Broca attempted to relate the cranial capacity (internal skull volume) to skin colour, intending to show that white people were superior. Other workers such as the American psychologists H. H. Goddard and Robert Yerkes attempted to measure people's intelligence and to show that the resulting scores were heritable, again to demonstrate the supposed superiority of people with white skin.\nGalton popularized the phrase nature and nurture, later often used to characterize the heated debate over whether genes or the environment determined human behaviour. Scientists such as behavioural geneticists now see it as obvious that both factors are essential, and that they are intertwined, especially through the mechanisms of epigenetics. The American biologist E. O. Wilson, who founded the discipline of sociobiology based on observations of animals such as social insects, controversially suggested that its explanations of social behaviour might apply to humans.\nHistory.\nGerm plasm.\nIn 1892, the Austrian biologist August Weismann proposed that multicellular organisms consist of two separate types of cell: somatic cells, which carry out the body's ordinary functions, and germ cells, which transmit heritable information. He called the material that carried the information, now identified as DNA, the germ plasm, and individual components of it, now called genes, determinants which controlled the organism. Weismann argued that there is a one-way transfer of information from the germ cells to somatic cells, so that nothing acquired by the body during an organism's life can affect the germ plasm and the next generation. This effectively denied that Lamarckism (inheritance of acquired characteristics) was a possible mechanism of evolution. The modern equivalent of the theory, expressed at molecular rather than cellular level, is the central dogma of molecular biology.\nEugenics.\nEarly ideas of biological determinism centred on the inheritance of undesirable traits, whether physical such as club foot or cleft palate, or psychological such as alcoholism, bipolar disorder and criminality. The belief that such traits were inherited led to an attempt to solve the problem with the eugenics movement. This was led by a follower of Darwin, Francis Galton (1822\u20131911), who advocated forcibly reducing breeding among people with those traits. By the 1920s, many U.S. states enacted laws permitting the compulsory sterilization of people considered genetically unfit, including inmates of prisons and psychiatric hospitals. This was followed by similar laws in Germany, and throughout the Western world, in the 1930s.\nScientific racism.\nUnder the influence of determinist beliefs, the American craniologist Samuel George Morton (1799\u20131851), and later the French anthropologist Paul Broca (1824\u20131880), attempted to measure the cranial capacities (internal skull volumes) of people of different skin colours, intending to show that whites were superior to the rest, with larger brains. All the supposed proofs from such studies were invalidated by methodological flaws. The results were used to justify slavery, and to oppose women's suffrage.\nHeritability of IQ.\nAlfred Binet (1857\u20131911) designed tests specifically to measure performance, not innate ability. From the late 19th century, the American school, led by researchers such as H. H. Goddard (1866\u20131957), Lewis Terman (1877\u20131956), and Robert Yerkes (1876\u20131956), transformed these tests into tools for measuring inherited mental ability. They attempted to measure people's intelligence with IQ tests, to demonstrate that the resulting scores were heritable, and so to conclude that people with white skin were superior to the rest. It proved impossible to design culture-independent tests and to carry out testing in a fair way given that people came from different backgrounds, or were newly arrived immigrants, or were illiterate. The results were used to oppose immigration of people from southern and eastern Europe to the USA.\nHuman sexual orientation.\nHuman sexual orientation, which ranges over a continuum from exclusive attraction to the opposite sex to exclusive attraction to the same sex, is caused by the interplay of genetic and environmental influences. There is considerably more evidence for biological causes of sexual orientation than social factors, especially for males.\nSociobiology.\nSociobiology emerged with E. O. Wilson's 1975 book \"\". The existence of a putative altruism gene has been debated; the evolutionary biologist W. D. Hamilton proposed \"genes underlying altruism\" in 1964, while the biologist Graham J. Thompson and colleagues identified the genes OXTR, CD38, COMT, DRD4, DRD5, IGF2, GABRB2 as candidates \"affecting altruism\". The geneticist Steve Jones argues that altruistic behaviour like \"loving our neighbour\" is built into the human genome, with the proviso that neighbour means member of \"our tribe\", someone who shares many genes with the altruist, and that the behaviour can thus be explained by kin selection. Evolutionary biologists such as Jones have argued that genes that did not lead to selfish behaviour would die out compared to genes that did, because the selfish genes would favour themselves. However, the mathematician George Constable and colleagues have argued that altruism can be an evolutionarily stable strategy, making organisms better able to survive random catastrophes.\nNature versus nurture debate.\nThe belief in biological determinism was matched in the 20th century by a blank slate denial of any possible influence of genes on human behaviour, leading to a long and heated debate about \"nature and nurture\". By the 21st century, many scientists had come to feel that the dichotomy made no sense. They noted that genes are expressed within an environment, in particular that of prenatal development, and that gene expression is continuously influenced by the environment through mechanisms such as epigenetics. Epigenetics provides evidence that human behaviours or physiology can be decided by interactions between genes and environments. For example, monozygotic twins usually have exactly identical genomes. Scientists have focused on comparison studies of such twins for evaluating the heritability of genes and the roles of epigenetics in divergences and similarities between monozygotic twins, and have found that epigenetics plays an important part in human behaviours, including the stress response.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49248", "revid": "51065313", "url": "https://en.wikipedia.org/wiki?curid=49248", "title": "Byron White", "text": "US Supreme Court justice and pro football player (1917\u20132002)\nByron Raymond \"Whizzer\" White (June 8, 1917 \u2013 April 15, 2002) was an American lawyer, jurist, and professional football player who served as an associate justice of the Supreme Court of the United States from 1962 until 1993. By his retirement, he was the Supreme Court's only sitting Democrat and the last-living member of the progressive Warren Court.\nBorn and raised in a small homestead in Wellington, Colorado, White distinguished himself as a student athlete who came from a background of poor farmhands to become a consensus All-American halfback for the Colorado Buffaloes. After being the runner-up for the Heisman Trophy in 1937, he was selected in the 1938 NFL draft by the Pittsburgh Pirates for the National Football League (NFL). He led the league in rushing yards during his rookie season. White graduated from the University of Colorado Boulder as class valedictorian, attaining a Rhodes Scholarship to study at Oxford University. After World War II forced him to return to the United States, he matriculated at Yale Law School, played for the Detroit Lions in the 1940 and 1941 seasons while still enrolled, and served as an officer for the United States Navy in the Pacific Theatre.\nWhite graduated from law school with honors in 1946 and clerked for Chief Justice Fred M. Vinson. He eschewed work for a white-shoe firm and returned to Colorado in order to enter private practice in Denver as a transactional attorney. Minor work as the Colorado state chair of John F. Kennedy's 1960 presidential campaign led to him being unexpectedly tapped in 1961 for a position as U.S. Deputy Attorney General. He was successfully nominated by Kennedy to the Supreme Court the next year, becoming the Court's first justice from Colorado.\nWhite espoused a pragmatic and non-doctrinaire judicial approach which strengthened the powers of the federal government, advocated for the desegregation of public schools, and upheld the use of affirmative action. Though expected to be a reliably liberal justice, he was by contrast a vociferous opponent of substantive due process, penning dissents in both \"Miranda v. Arizona\" and \"Roe v. Wade\" (and consistently supported overruling the latter decision). White wrote the majority opinion in \"Bowers v. Hardwick\" (upholding the ability for states to restrict homosexual conduct) and dissented in \"Runyon v. McCrary\" (against the ability for the government to restrict racial discrimination in private schools) and \"Planned Parenthood v. Casey\". Due to his unwillingness to align with either the liberal or conservative blocs, White was largely oriented with the Court's center.\nEarly life and education.\nWhite was born in Fort Collins, Colorado, on June 8, 1917. His father, A. Albert White, managed a local lumber company. His mother, Maude Elizabeth (Burger), was the daughter of German immigrants. He had one older brother, Clayton \"Sam\" Samuel White. Neither parent graduated high school, which was not unusual for farming communities at the time, but they instilled in their sons a heavy emphasis on education and took active roles in the local community. White and his brother were raised in the nearby town of Wellington where they attended the local high school. As a young student, White worked odd jobs to support his family during the town's decline in the 1920s; these included roles in harvesting beets, shoveling coal, and hard construction work among other forms of manual labor. In his junior year, he and his brother rented out land and spent long hours in the fields, during which time White adopted a nearly lifelong habit of smoking.\nSam, four years White's senior, became an accomplished student and athlete that graduated as valedictorian, earning a scholarship to study at the University of Colorado, where he was later elected by the university to become a Rhodes Scholar. Whereas Sam was a gregarious and socially active child, White was described as a taciturn boy who \"was very quiet, measuring every single word, showing no emotion, and revealing nothing.\"\nWhite excelled academically in high school, graduating in 1934 as the class valedictorian with the highest grades in the school's history. He studied diligently in order to attain a scholarship to attend college, later describing his philosophy in Wellington as \"do your work and don't be late for dinner.\" White followed his brother's footsteps in attending the University of Colorado Boulder on the scholarship offered to all Colorado high school valedictorians, intending to go to medical school and major in chemistry. Though he joined the Phi Gamma Delta fraternity on campus, he stuck to a strict routine of working and studying with little to no social life. However, he would become a star athlete after playing as an All-American halfback for the Colorado Buffaloes football team, winning a series of victories to become among the most acclaimed players in the country.\nIn 1935, Sam White was awarded a Rhodes Scholarship to study at Oxford University. After news of his brother's success became a local sensation, White saw his brother as an inspiration and felt pressured to achieve the scholarship himself. He served as student body president his senior year, switched his major to the humanities, and graduated Phi Beta Kappa and valedictorian from the University of Colorado in 1938 with a Bachelor of Arts degree in economics. In his last year, the Colorado Buffaloes went undefeated, and White's status as a football star earned him the moniker \"Whizzer White\" by the student newspaper. After months of study, White also attained the Rhodes Scholarship, deferring it for a year to play professional football before attending Hertford College.\nOxford.\nOn January 3, 1939, White departed to England aboard the SS \"Europa\", arriving in Southampton on January 9 harassed by reporters wishing to see a \"Yank at Oxford.\" Upon moving into Hertford College with the intent of studying law, he befriended the future mathematician George Piranian and was assigned with C. H. S. Fifoot as a tutor. White spent his days at Oxford tirelessly studying from day until night, becoming \"the only Rhodes scholar who ever worked fourteen hours a day on his studies.\" During one Easter vacation, he became acquainted with Joseph P. Kennedy and future U.S. president John F. Kennedy as their father, Joseph Kennedy, was the U.S. ambassador to London. In the period of political upheaval just before the Second World War, Oxford students\u2014Rhodes scholars especially\u2014took an active role in international politics, with many American Rhodes scholars beckoning President Roosevelt to take action against Spanish nationalists. White, however, remained closed in the affairs of politics, rarely speaking out and becoming estranged from other students; he prioritized his studies and physique above all else.\nFollowing the end of a term, White spent a summer vacation touring France and Germany, settling down in Munich in order to study the German language and Roman law. He unexpectedly reunited with John F. Kennedy, who was on his own tour of Europe with Torbert Macdonald, and on one occasion the three were heckled by a mob who recognized their English license plates. White left Germany to return to Oxford in late August 1939. The war made it impossible for American students to continue studying at Oxford, and White chose to return to the U.S. in order to continue his legal education at Yale Law School.\nLaw school.\nUpon enrolling at Yale, White continued his previous routine of studying fourteen hours a day, taking breaks only to exercise in the gymnasium where he would frequent the basketball courts, often clashing against Yale halfback Clint Frank in pick-up games. Despite attempts by the New York Giants and other NFL teams to get him to sign back into football, White publicly repudiated his football career, telling a local newspaper that \"my football playing days are over. I'm started on a law career.\"\nAt the time, Yale was home to a number of legal realists who rebuked \"Lochner\" and substantive due process, and were generally scholars with an expertise in legal fields outside of constitutional law. Two of such realists\u2014Myres S. McDougal and Arthur Corbin\u2014had a significant influence on White early in law school. Future justice Potter Stewart, one year ahead of him at the university, remembered White as \"a serious-minded, scholarly, and rather taciturn (except when he found himself engaged in lively colloquy with J. W. Moore in his class on Procedure), and extremely likable young man with steel-rimmed eyeglasses.\"\nWhite earned the highest grades in his first-year class and was subsequently awarded the Edgar M. Cullen Prize, an award given to the highest-achieving first-year student. During the summer, he returned to Colorado and attended summer school at the University of Colorado Law School, got an appendectomy, and became a waiter at his old fraternity. White would turn down an offer to join the editorship of the \"Yale Law Journal\", instead taking a leave of absence to promptly return to professional football as a member of the Detroit Lions.\nProfessional football.\nWhite came into the National Football League with the then-Pirates in the summer of 1938 as a widely-heralded college star. The $15,800 contract he had signed made White the NFL's highest-paid player. About his first game, one Pittsburgh journalist said he \"looked better as an individual than the Pirates did as a team\". Despite leading the NFL in rushing yards in 1938, White did not appear for the 1939 season. He would reappear for the Detroit Lions in 1940 and would again top the world of \"postgraduate football\" with a league-leading performance in rushing.\nWhite played a total of three NFL seasons \u2014 33 games in all. He led the league in rushing twice during that short interval, and was elected the NFL's first team All-Pro right halfback in 1940.\nWorld War II.\nAt the end of 1941 Lions season, White returned to Yale to await a call to serve in the U.S. Navy after the Attack on Pearl Harbor. In May 1942, he was assigned to naval intelligence and spent weeks training at Dartmouth College and in New York City. His original intention was to join the Marine Corps, but was kept out due to being colorblind.\nIn July 1943, White was stationed at Noum\u00e9a, New Caledonia, tasked with protecting Guadalcanal and Tulagi; he narrowly missed being assigned with John F. Kennedy, his former acquaintance who had also been stationed at Tulagi before being reassigned to the Russell Islands. During World War II, White served as an intelligence officer in the Navy, and was stationed in the Pacific Theatre. He wrote the intelligence report on the sinking of future President John F. Kennedy's \"PT-109\". For his service, White was awarded two Bronze Star medals, and was honorably discharged as a lieutenant commander in 1945.\nLegal career.\nAfter his military service, White returned to Yale Law School, graduating in 1946 ranked first in his class with a Bachelor of Laws degree, \"magna cum laude\", and membership in the Order of the Coif. White served as a law clerk to Chief Justice Fred M. Vinson of the U.S. Supreme Court from 1946 to 1947, then returned to Colorado and entered private practice in Denver with the law firm now known as Davis Graham &amp; Stubbs. This was a time in which the Denver economy flourished, and White rendered legal service to the business community. White was for the most part a transactional attorney; he drafted contracts and advised insolvent companies, and he argued the occasional case in court.\nDuring the 1960 presidential election, White used his status as a football star to aid him as chair of John F. Kennedy's campaign in Colorado. White had first met the candidate when White was a Rhodes scholar and Kennedy's father, Joseph Kennedy, was Ambassador to the Court of St. James's. During the Kennedy administration, White served as United States Deputy Attorney General, the number two man in the Justice Department, under Robert F. Kennedy. He took the lead in protecting the Freedom Riders in 1961, negotiating with Alabama Governor John Malcolm Patterson.\nSupreme Court.\nOn April 3, 1962, President Kennedy nominated White to be an associate justice of the Supreme Court, succeeding Charles Evans Whittaker. The president said of White\u2014a longtime friend of his\u2014that \"he has excelled at everything. And I know that he will excel on the highest court in the land.\" White was confirmed on April 11, 1962, by a voice vote. He took the judicial oath of office on April 16, 1962, and served until June 28, 1993. His Supreme Court tenure was the fourth-longest of the 20th century.\nUpon the request of Vice President-Elect Al Gore, White administered the oath of office on January 20, 1993, to Gore. It was the only time White administered an oath of office to a vice president. During his service on the high court, White wrote 994 opinions. He was fierce in questioning attorneys in court, and his votes and opinions on the bench reflect an ideology that has been notoriously difficult for popular journalists and legal scholars alike to pin down. He was seen as a disappointment by some Kennedy supporters who wished he had joined the more liberal wing of the court in its opinions on \"Miranda v. Arizona\" and \"Roe v. Wade\".\nWhite often took a narrow, fact-specific view of cases before the Court and generally refused to make broad pronouncements on constitutional doctrine or adhere to a specific judicial philosophy, preferring what he viewed as a practical approach to the law. In the tradition of the New Deal, White frequently supported a broad view and expansion of governmental powers. He consistently voted against creating constitutional restrictions on the police, dissenting in the landmark 1966 case \"Miranda v. Arizona\". In that dissent, he said that aggressive police practices enhance the individual rights of law-abiding citizens. His jurisprudence has sometimes been praised for adhering to the doctrine of judicial restraint.\nSubstantive due process doctrine.\nFrequently a critic of the doctrine of \"substantive due process\", which involves the judiciary reading substantive content into the term \"liberty\" in the Due Process Clause of the Fifth Amendment and Fourteenth Amendment, White's first published opinion as a Supreme Court Justice was a joint dissent with Justice Clark in \"Robinson v. California\" (1962), foreshadowing his career-long distaste for the doctrine. In \"Robinson\", he criticized the remainder of the Court's unprecedented expansion of the Eighth Amendment's prohibition of \"cruel and unusual punishment\" to strike down a California law providing for civil commitment of drug addicts. He argued that the Court was \"imposing its own philosophical predilections\" on the state in this exercise of judicial power, although its historic \"allergy to substantive due process\" would never permit it to strike down a state's economic regulatory law in such a manner.\nIn the same vein, he dissented in the controversial 1973 case \"Roe v. Wade\". White voted to strike down a state ban on contraceptives in the 1965 case of \"Griswold v. Connecticut\", although he did not join the majority opinion, which famously asserted a \"right of privacy\" on the basis of the \"penumbras\" of the Bill of Rights. White and Justice William Rehnquist were the only dissenters from the Court's decision in \"Roe\", though White's dissent used stronger language, suggesting that \"Roe\" was \"an exercise in raw judicial power\" and criticizing the decision for \"interposing a constitutional barrier to state efforts to protect human life.\" White, who usually adhered firmly to the doctrine of \"stare decisis\", remained a critic of \"Roe\" throughout his term on the bench and frequently voted to uphold laws restricting abortion, including in \"Planned Parenthood v. Casey\" in 1992.\nWhite explained his general views on the validity of substantive due process at length in his dissent in \"Moore v. City of East Cleveland\" (1977):\nThe Judiciary, including this Court, is the most vulnerable and comes nearest to illegitimacy when it deals with judge-made constitutional law having little or no cognizable roots in the language or even the design of the Constitution. Realizing that the present construction of the Due Process Clause represents a major judicial gloss on its terms, as well as on the anticipation of the Framers, and that much of the underpinning for the broad, substantive application of the Clause disappeared in the conflict between the Executive and the Judiciary in the 1930s and 1940s, the Court should be extremely reluctant to breathe still further substantive content into the Due Process clause so as to strike down legislation adopted by a State or city to promote its welfare. Whenever the Judiciary does so, it unavoidably pre-empts for itself another part of the governance of the country without express constitutional authority.\nWhite parted company with Rehnquist in strongly supporting the Supreme Court decisions striking down laws that discriminated on the basis of sex, agreeing with Justice William J. Brennan in 1973's \"Frontiero v. Richardson\" that such laws should be subject to strict scrutiny. Only three justices joined Brennan's plurality opinion in \"Frontiero\"; later gender discrimination cases would be subjected to intermediate scrutiny (see \"Craig v. Boren\"). In \"Rostker v. Goldberg\", White joined Brennan and Marshall in dissent arguing that male-only Selective Service registration was unconstitutional.\nWhite wrote the majority opinion in \"Bowers v. Hardwick\" (1986), which upheld Georgia's anti-sodomy law against a substantive due process attack:\nThe Court is most vulnerable and comes nearest to illegitimacy when it deals with judge-made constitutional law having little or no cognizable roots in the language or design of the Constitution... There should be, therefore, great resistance to ... redefining the category of rights deemed to be fundamental. Otherwise, the Judiciary necessarily takes to itself further authority to govern the country without express constitutional authority.\nWhite's opinion in \"Bowers\" typified his fact-specific, deferential style, treating the issue in that case as presenting only the question of whether homosexuals had a fundamental right to privacy, even though the statute in \"Bowers\" potentially applied to heterosexual sodomy. Georgia, however, conceded during oral argument that the law would be inapplicable to married couples under the precedent set forth in \"Griswold v. Connecticut\". A year after White's death, \"Bowers\" was overruled in \"Lawrence v. Texas\" (2003).\nDeath penalty.\nWhite took a middle course on the issue of the death penalty: he was one of five justices who voted in \"Furman v. Georgia\" (1972) to strike down several state capital punishment statutes, voicing concern over the arbitrary way in which the death penalty was administered. The Furman decision ended capital punishment in the U.S. until the court's ruling in \"Gregg v. Georgia\" (1976). In that case, White voted to uphold Georgia's new capital punishment law.\nWhite accepted the position that the Eighth Amendment to the United States Constitution required that all punishments be \"proportional\" to the crime; thus, in \"Coker v. Georgia\" (1977), he wrote the opinion that invalidated the death penalty for rape of a 16-year-old married girl. His first reported Supreme Court decision was a dissent in \"Robinson v. California\" (1962), in which he criticized the Court for extending the reach of the Eighth Amendment. In \"Robinson\" the Court for the first time expanded the constitutional prohibition of \"cruel and unusual punishments\" from examining the nature of the punishment imposed and whether it was an uncommon punishment \u2212 as, for example, in the cases of flogging, branding, banishment, or electrocution \u2212 to deciding whether any punishment at all was appropriate for the defendant's conduct. White said: \"If this case involved economic regulation, the present Court's allergy to substantive due process would surely save the statute and prevent the Court from imposing its own philosophical predilections upon state legislatures or Congress.\" Consistent with his view in \"Robinson\", White thought that imposing the death penalty on minors was constitutional, and he was one of the three dissenters in \"Thompson v. Oklahoma\" (1988), a decision that declared that the death penalty as applied to offenders below 16 years of age was unconstitutional as a cruel and unusual punishment.\nAbortion.\nAlong with Justice William Rehnquist, White dissented in \"Roe v. Wade\" (the dissenting decision was in the companion case, \"Doe v. Bolton\"), castigating the majority for holding that the U.S. Constitution \"values the convenience, whim or caprice of the putative mother more than the life or potential life of the fetus.\"\nCivil rights.\nWhite consistently supported the Court's post-\"Brown v. Board of Education\" attempts to fully desegregate public schools, even through the controversial line of forced busing cases. He voted to uphold affirmative action remedies to racial inequality in an education setting in the famous \"Regents of the University of California v. Bakke\" case of 1978. Though White voted to uphold federal affirmative action programs in cases such as \"Metro Broadcasting, Inc. v. FCC\", 497 U.S. 547 (1990) (later overruled by \"Adarand Constructors v. Pe\u00f1a\", 515 U.S. 200 (1995)), he voted to strike down an affirmative action plan regarding state contracts in \"Richmond v. J.A. Croson Co.\" (1989).\nWhite dissented in \"Runyon v. McCrary\" (1976), which held that federal law prohibited private schools from discriminating on the basis of race. He argued that the legislative history of 42 U.S.C. \u00a7 1981 (popularly known as the \"Ku Klux Klan Act\") indicated that the Act was not designed to prohibit private racial discrimination but only state-sponsored racial discrimination (as had been held in the \"Civil Rights Cases\" of 1883). White was concerned about the potential far-reaching impact of holding private racial discrimination illegal, which if taken to its logical conclusion might ban many varied forms of voluntary self-segregation, including social and advocacy groups that limited their membership to blacks: \"Whether such conduct should be condoned or not, whites and blacks will undoubtedly choose to form a variety of associational relationships pursuant to contracts which exclude members of the other race. Social clubs, black and white, and associations designed to further the interests of blacks or whites are but two examples\". \"Runyon\" was essentially overruled by 1989's \"Patterson v. McLean Credit Union\", which itself was superseded by the Civil Rights Act of 1991.\nRelationships with other justices.\nWhite said he was most comfortable on Rehnquist's court. He once said of Earl Warren, \"I wasn't exactly in his circle.\" On the Burger Court, the chief justice often assigned important criminal procedure and individual rights opinions to White because of his frequently conservative views on these questions.\nCourt operations and retirement.\nWhite frequently urged the Supreme Court to consider cases when federal appeals courts were in conflict on issues of federal law, believing that resolving such was a primary role of the Supreme Court. Thus, White voted to grant certiorari more often than many of his colleagues; he also wrote numerous opinions dissenting from denials of certiorari. After White (along with fellow Justice Harry Blackmun, who also often voted for liberal grants of certiorari) retired, the number of cases heard each session of the Court declined steeply.\nWhite disliked the politics of Supreme Court appointments, but had great faith in representative democracy, responding to complaints about politicians and mediocrity in government with exhortations to \"get more involved and help fix it.\" He retired in 1993, during Bill Clinton's presidency, saying that \"someone else should be permitted to have a like experience.\" When he retired, White had been the only Democrat on the Court. Clinton nominated (and the Senate approved) Justice Ruth Bader Ginsburg, a judge from the U.S. Court of Appeals for the D.C. Circuit and a former Columbia University law professor, to succeed him.\nLater years and death.\nAfter retiring from the Supreme Court, White occasionally sat with lower federal courts. He maintained chambers in the federal courthouse in Denver until shortly before his death. He also served for the Commission on Structural Alternatives for the Federal Courts of Appeals.\nWhite died of pneumonia on April 15, 2002, at the age of 84. He was the last living Justice to have served on the Warren Court, and the last justice appointed by Kennedy; he died the day before the fortieth anniversary of his swearing in as a Justice. From his death until the retirement of Sandra Day O'Connor in January 2006, there were no living former justices.\nHis remains are interred at All Souls Walk at St. John's Cathedral in Denver.\nThen-Chief Justice Rehnquist said White \"came as close as anyone I have known to meriting Matthew Arnold's description of Sophocles: 'He saw life steadily and he saw it whole.' All of us who served with him will miss him.\"\nPersonal life.\nWhite first met his wife Marion Stearns (1921\u20132009), the daughter of the president of the University of Colorado, when she was in high school and he was a college football player. During World War II, Marion served in the WAVES while her future husband was a Navy intelligence officer. They married in 1946 and had two children: a son named Charles Byron (Barney) and a daughter named Nancy.\nHis older brother Clayton Samuel \"Sam\" White (1912\u20132004) was also a high school valedictorian and Rhodes Scholar. He later became a physician and medical researcher, particularly on the effects of atomic bomb blasts.\nAwards and honors.\nThe NFL Players Association gives the Byron \"Whizzer\" White NFL Man of the Year Award to one player each year for his charity work. Michael McCrary, who was involved in \"Runyon v. McCrary\", grew up to be a professional football player and won the award in 2000.\nThe federal courthouse in Denver that houses the Tenth Circuit is named after White.\nWhite was elected to the College Football Hall of Fame in 1952.\nWhite was made an honorary fellow of Hertford College, Oxford.\nWhite was posthumously awarded the Presidential Medal of Freedom in 2003 by President George W. Bush.\nWhite was inducted into the Rocky Mountain Athletic Conference Hall of Fame on July 14, 2007, in addition to being a member of the College Football Hall of Fame and the University of Colorado's Athletic Hall of Fame, where he is enshrined as \"The Greatest Buff Ever\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49249", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=49249", "title": "Floating Point Unit", "text": ""}
{"id": "49251", "revid": "34349508", "url": "https://en.wikipedia.org/wiki?curid=49251", "title": "Dili", "text": "Capital and largest city of Timor-Leste\nDili (Portuguese and Tetum: \"D\u00edli\") is the capital and largest city of Timor-Leste. It lies on the northern coast of the island of Timor, in a small area of flat land hemmed in by mountains. The climate is tropical, with distinct wet and dry seasons. The city has served as the economic hub and chief port of what is now Timor-Leste since its designation as the capital of Portuguese Timor in 1769. It also serves as the capital of the Dili Municipality, which includes some rural subdivisions in addition to the urban ones that make up the city itself. Dili's growing population is relatively youthful, being mostly of working age. The local language is Tetum; however, residents include many internal migrants from other areas of the country.\nThe initial settlement was situated in what is now the old quarter in the eastern side of the city. Centuries of Portuguese rule were interrupted in World War II, when Dili became the site of a battle between Allied and Japanese forces. The damaged city returned to Portuguese control following the war. In 1975, a civil war between Timorese political parties broke out, leading to a declaration of independence and a subsequent invasion by Indonesia. Under Indonesian rule infrastructure in the city was developed, with landmarks such as the Immaculate Conception Cathedral and \"Cristo Rei of Dili\" being built during this time. The city expanded as its population grew to over 100,000 people.\nResistance to Indonesian rule faced violent repression, and a massacre in Dili led to international pressure culminating in an independence referendum. Following a vote for independence violence erupted in the city, destroying huge amounts of its infrastructure and leading to an exodus of refugees. A period of United Nations rule followed, during which international agencies began the reconstruction of the city. Dili became the capital of an independent Timor-Leste in 2002. A period of violence in 2006 saw another period of infrastructure damage and population displacement. In 2009 the government launched the \"City of Peace\" campaign to reduce tensions. As the population has continued to grow and the original site of the city has filled up, the urban area has expanded into coastal areas to the east and west of the main city.\nInfrastructure in Dili continues to be developed. The city was the first location in Timor-Leste to see 24 hours of electricity, although its water infrastructure remains relatively limited. Education levels are higher than the national average, and the country's universities are located in the city. An international port and airport lie within the city limits. Most economic activity comes from the tertiary sector and public employment. To further build the economy, the government is developing the tourism potential of the city, focusing on cultural, environmental, and historical attractions.\nHistory.\nInitial Portuguese settlement.\nDili has played a central role in the history of Timor-Leste. However, early records about Timor, especially before the 1700s, are sparse. The tumultuous history of the city has resulted in a great deal of information being lost; archives in the city were destroyed in 1779, 1890, 1975, and 1999.\nThe island of Timor was possibly known as a source for sandalwood in the 15th century. The first recorded Portuguese voyage to the island from Portuguese Malacca occurred in 1516, returning with sandalwood. In 1521, sandalwood was left out of a list of products under royal monopoly, leaving most trade with Timor in the hands of private enterprises. Portuguese and Spanish interest in the island increased in the 1520s, with regular trade established by 1524. In the late 1500s, administrative officials began to be appointed to nearby Solor with jurisdiction over that island and Timor, signifying increasing state interest in Portuguese activities there.\nThe Netherlands began to compete for control of the island in 1613, especially in the west. A rebellion in 1629 forced the Portuguese off the island for three years. In 1641, a number of kings in Timor converted to Catholicism while seeking Portuguese protection. This introduced a political dimension to Portuguese influence, which had previously been primarily economic. Timor became administratively separated from Solor in 1646, although the exact administrative structure is unknown. It received its first dedicated governor in 1702, who resided in Lifau. This reflected the growing importance of Timor compared to nearby Flores. 1749 saw Dutch military forces take control over large portions of the island, broadly reflecting current borders.\nIn 1769, as Lifau came under the increasing influence of powerful local families collectively known as the Topasses, the Portuguese governor Ant\u00f3nio Jos\u00e9 Teles de Meneses moved the administration and 1,200 people east to establish a new capital. It was originally intended that the administration be set up at Vemasse further east, but perhaps because of the favourable geography, a settlement was established at Dili instead. This was at the time part of the Motael kingdom, whose leader was friendly with the Portuguese authorities. The governor occupied an existing fortified structure, and with the assistance of the Motael leader began to construct a new settlement. The area surrounding the settlement was wetlands fed by rivers from the mountains and proved conducive to rice cultivation. A wall was built to separate the coastal city from wetlands to its south. The initial settlement was divided between three populations, one mainly Portuguese, one of Mesti\u00e7os and locals from other Portuguese colonies (which became Bidau), and one for troops from a kingdom thought to be in Flores.\nFrom 1788 to 1790, a civil war broke out between the governor in Dili and an official based in Manatuto, which was resolved upon the arrival of a new governor. In response to Dutch provocations, a permanent military force was established in 1818. Some Europeans settled in Lahane to the south, beyond the wetland area. Significant construction was undertaken under governor Jos\u00e9 Maria Marques, who arrived in 1834 and rebuilt the settlement along a grid. This saw expansion along the coast, but also southwards as the wetlands between the original city and Lahane were channelised and drained. A road extended to Lahane and Dare. The rebuilding saw the settlement being centred on its port, with the immediate port area containing trade facilities, church buildings, military buildings, government buildings, the residence of the governor and his deputy, a residence for a representative of the Motael kingdom, and a residence for the Queen of Manatuto. Of these, only the church and the Finance Deputy's house used masonry. To the east of this core was Bidau and a Chinese settlement, to the west was the main settlement of the Motael kingdom.\nIn 1844 Timor, along with Macau and Solor, was removed from the jurisdiction of Portuguese India, with the three areas becoming a new Portuguese province. A few years later in 1850, Portuguese Timor was removed from the jurisdiction of the governor of Macau, before being returned to the jurisdiction of Portuguese India in 1856. When English naturalist and explorer Alfred Russel Wallace visited in the 1860s, he wrote that the governor's house was \"merely a low whitewashed cottage\", and that all other buildings appeared to be mud and thatch. At the time swamps and mudflats surrounded the town, which did not extend to the mountains surrounding it. More permanent buildings of one or two stories were constructed throughout the late 19th century. A new church building was built in 1877.\nA revolt to the east led to the city being isolated in 1861; however, the revolt was defeated by the Portuguese and their Timorese allies. In 1863, Dili was declared a city (although the news may not have arrived to the city until the next year), and East Timor became directly subordinate to the Lisbon government. In 1866 the territory was again put under the jurisdiction of Macau. An 1887 mutiny in Dili led to the death of the governor at the time. The territory was separated from Macau for the last time in 1896, again coming directly under the jurisdiction of Lisbon, and becoming a full province in 1909. Another notable revolt took place in the years after the 1910 republican revolution in Portugal. The republican government downgraded the status of its overseas provinces to colonies. A civil government was established in 1913.\nPermanent structures in Portuguese style continued to be constructed into the 20th century. A new town hall was built from 1912 to 1915. The main church was demolished in 1933, and a new cathedral opened in its place in 1937. (This cathedral was later destroyed by Allied bombing in the Second World War.) Four distinct residential districts developed around the city core. Bidau was the largest, and Benamauc joined it on the eastern side. Caicole developed to the south between the city and Lahane. Colmera developed as a commercial area to the west with a large number of Muslim traders. Motael continued to develop, becoming the site of the city's lighthouse. Motael Church began to be built in 1901. Inland to the southwest, a Chinese cemetery was established, and beyond that a military area known as Taibesse. Lahane also saw significant development in the early 20th century, with its east and west side separated by a river. As the administrative structures developed, Dili became part of the Dili municipality in 1940, the first municipal administration to be created. At the time the municipality was larger, including what is now the Aileu Municipality.\nDestruction, reconstruction, and Indonesian rule.\nDuring World War II, Portugal and its colonies remained neutral, but the Allies saw East Timor as a potential target for Japanese invasion. Upon the outbreak of the Pacific War in 1941, Australian and Dutch troops were sent to Dili despite Portuguese objections. In response, the Japanese invaded Dili as part of a two-pronged invasion of Timor. The city had been mostly abandoned prior to the invasion, and allied forces retreated further into the island. The Japanese left the Portuguese governor nominally in position, but took over administration. Much of Dili was destroyed during the war, from the initial Japanese invasion and from later allied bombings. Japanese forces on the island of Timor surrendered to Australian forces at the end of the war. Following the surrender, an Australian official travelled to Dili where on 23 September 1945 he informed the Portuguese governor of the Japanese surrender.\nFollowing the Second World War, Dili covered what today is the old core of the city, within the sucos of Acadiru Hun, Bemori, Bidau Lecidere, Caicoli, Colmera, Culu Hun, Gricenfor, Motael, and Santa Cruz. Portuguese Timor became a full part of Following the initial post-war reconstruction of Dili's immediately critical infrastructure, an urban plan was developed in 1951 covering urban layout, road development, zoning, and building regulations. The plan envisioned separate neighbourhoods for Europeans, mesti\u00e7os, Chinese, Arabs, and Timorese, and assumed there would be further rural-urban migration. Both this plan and later revisions in 1968 and 1972 assumed that the Timorese population would live on the edges of the city yet work near the centre. This plan was not completed, and the city remained under-developed, with low density and where property outside of the central area was still built on with flimsy materials and used for subsistence cultivation. The second five-year development plan, which ran from 1959 to 1964, saw the reconstruction of the Port of Dili and a small amount of transport infrastructure.\nA 1950 census found that the population of Dili was about 6,000 people, half 'civilised' (considered by Portuguese authorities to have sufficiently adopted Portuguese culture), including \"Mesti\u00e7o\", 'civilised' natives, Europeans, and other foreigners such as Goans and those from Portugal's African colonies. This was slightly over 1% of the total population of the colony. The 1960 census recorded the population of Dili to be about 7,000 people. By 1970, the urban population reached around 17,000. The city did not extend far beyond the area surrounding the port, and the population did not exceed 30,000 before 1975.\nPortuguese Timor became a full part of Portugal in 1951, although despite being made citizens of Portugal this did not bring the locals any political power. Governance remained in the control of Lisbon. The Portuguese Overseas Organic Law of 1963 created the first Legislative Council of the territory, which was given some of the powers formerly held by the governor. It also theoretically extended voting rights to the 'uncivilised', although property and tax requirements meant most were still unable to vote.\nThe 1974 Carnation Revolution in Portugal created immediate change in East Timor, with new political parties forming with the goal of independence from Portugal. Relationships between these new parties was fractious. Some, particularly the Timorese Democratic Union (UDT), advocated union with Indonesia. On 11 August 1975, the UDT initiated a coup. UDT control was limited outside of Dili, and on 20 August the opposing Fretilin party began its attempt to seize the city. Some houses were set on fire to assist the defence; however, after some days Fretilin succeeded in taking control of the city. The last Portuguese governor fled Dili for Atauro Island on 26 August, as the civil war continued. On 28 November, Fretilin declared independence in a ceremony in Dili. On 7 December, Indonesia landed paratroopers in the city and amphibious forces to its west, as part of an invasion of East Timor, leading many to flee the city.\nThis invasion brought the territory under Indonesian rule. On 17 July 1976, Indonesia annexed East Timor, which it designated its 27th province. Indonesia continued to administer the territory from Dili, continuing formerly Portuguese use of places such as the Balide Comarca prison and Lahane Hospital. Despite Indonesian attempts to restrict rural-urban migration, the population of Dili continued to grow, reaching 80,000 people in 1985, and over 100,000 in 1999, and economic growth for the territory remained centred in Dili. Part of the internal migration was due to people fleeing the continuing conflict in rural areas. Indonesia developed the city's infrastructure, partly as an attempt to win over the population. Structures and monuments built during this time include the Immaculate Conception Cathedral, the Integration Statue commemorating the end of Portuguese rule, and the \"Cristo Rei of Dili\". Nonetheless, many in the city continued to support the Fretilin-led resistance, providing a communications link between the rebels and the rest of the world, and setting up safe houses in the city. Others who supported Indonesian rule became informants, known as \"mau'hu\". By the 1990s, urban sprawl had taken up much of the available flat land around the original settlement.\nIn the 1980s, resistance to Indonesian rule grew among youth in the city. Nonetheless, towards the end of the decade Indonesia began allowing foreign tourists access to the city, with the entire province previously being restricted. A visit by Pope John Paul II in 1989 was interrupted by independence activists. On 12 November 1991, Indonesian forces were filmed shooting at a funeral procession. This led to global condemnation of Indonesia's rule in East Timor, increasing pressure for East Timorese self-determination. The 1997 Asian financial crisis along with a drought related to an El Ni\u00f1o event led to profound food insecurity, worse for Dili than any other city in Indonesia. The crisis also precipitated the resignation of Indonesian President Suharto, whose successor, B. J. Habibie, soon approved a referendum on East Timorese independence. Outbreaks of violence from pro-Indonesian militia occurred throughout the country in the months leading up to the vote. In August 1999, East Timor voted for independence.\nThe vote led to a period of extreme violence, as pro-Indonesian militia were unchecked by the Indonesian military that was meant to be providing security. On 4 September, when the result was announced, Indonesian police began to leave Dili. In the first 48 hours, international media organisations present in the city reported 145 deaths. Most foreigners were evacuated. Violence continued for several days, causing significant damage to infrastructure and housing in the city. Administrative buildings were looted, and much of the city was destroyed by fire. 120,000 people became refugees. International pressure grew for an international peacekeeping force to replace the Indonesian military, which Indonesia agreed to on 12 September. On 14 September, the UN evacuated refugees that had been sheltering in its Dili compound to Australia. The Australian-led International Force East Timor arrived on 20 September.\nGrowth under UN rule and independence.\nDili continued to grow under UN rule. As Indonesian infrastructure investment outside of Dili was not replicated by the UN government, leaving it to deteriorate, population growth was driven in part due to internal migration from these areas to the city. Housing left abandoned by Indonesians in 1999 was occupied by squatters. This was most common in the western areas of the city. Most inward migration during this period was from eastern areas of the country. Population growth combined with a poor economy led to an increase of urban poverty and unemployment, especially amongst youth. This was despite the city reaping 80% of the economic benefits of reconstruction efforts; 65% of direct jobs created by the UN were in Dili, a figure that rose to 80% when including indirect jobs.\nFollowing the beginning of UN rule, the population of Dili grew by over 10% annually. This was a result of both rural-urban migration, and a baby boom driven by the country having the highest fertility rate in the world. By 2004, the population had reached 173,541 people, with unemployment at 26.9% overall, and 43.4% for men aged 15\u201329. Around half of employment for these young men was informal. In 2005 a new urban master plan was developed by a group based in the Faculty of Architecture of the Technical University of Lisbon. Issues with food security reoccurred periodically throughout the early years of independence. From 1990 to 2014, agricultural use of the flat land around Dili is thought to have decreased by around 40%, replaced by horticulture and aquaculture in the east and by urban areas in the west. Wetlands have also further decreased, drained and built upon.\nBy 2006, Dili produced half of the country's non-oil GDP. It was also receiving two-thirds of government expenditure, and 80% of goods and services. However, economic benefits were distributed unequally. 1999 saw the end of Indonesian subsidises of core food products, which alongside infrastructure destruction led to rapid inflation. Under UN rule, the use of the US dollar and the purchasing power of international organisations led to price increases. Together, these factors led to extremely high costs of living. Electricity cost four times as much as it did in Indonesia, averaging $15 per household. Telecommunications and petrol similarly grew in price compared to Indonesia. By 2006 Dili had the eighth-highest living costs of any city in Asia, despite the country's having Asia's lowest GDP. At this point, the city had around 300 youth groups, some of which were involved in the informal economy. These groups, driven by unemployment, were often connected to former guerrillas and current politicians. Many developed identities reflecting the regional origins of their members, especially with regards to the broad distinction between those from the east and those from the west.\nIn April 2006, disputes within the military between a leadership mostly from the east of the country and soldiers mostly from the west spilled over into street violence in Dili. Disputes over housing, again mostly between groups from the east and west, contributed to property destruction. Most of the 150,000 people displaced were from Dili, including about half of the city's residents. Around 72,000 people ended up in camps, while 80,000 fled to rural areas. Rice prices in the city increased by half by October 2006, and then almost doubled again by February 2007. Foreign military intervention was needed to restore order.\nA National Recovery Strategy was put in place following the 2007 national election to return these people. In 2008, around 30,000 people displaced from Dili remained in camps, while 70,000 continued to live with friends or family. Continuing unrest led to the attempted assassinations of the country's president and prime minister. By 2009 most displaced people had returned to the city, and the camps were officially closed by the end of the year. However, some community tensions remained. In a couple of areas, there were two or three fights a week between opposing youth groups. Nonetheless, large-scale violence did not return. Mediation teams were utilised to assist in the resettlement of some displaced people to their previous homes.\nIn May 2009, the year-long \"Dili City of Peace\" campaign was launched by Jose Ramos-Horta. The initiative was created to build unity and prevent violence, with the 2006 East Timorese crisis in mind. The campaign included dialogues between different sectors of Timorese society, a cycling tour, a Dili marathon, and a reforestation initiative. Focusing the peace campaign on Dili reflects the influence it has on the entire country, with the government expecting its impacts would extend beyond the city itself. The \"Latelek\" (Bridge) Project was instituted from 2010 to 2012 by some organs of the Catholic Church to improve community cohesion, reintegrating previously displaced individuals with those who had remained. Other programs were initiated by the government and NGOs to tackle issues such as skills development, youth engagement, and women's empowerment. Some sucos developed community laws to reduce violence.\nThe development of the city since independence has led to many sites being replaced or repurposed. In 2009 the area around the Indonesian-built Integration Monument was redesignated as the 5 May Park, the date upon which it was agreed East Timor could hold its independence referendum. A 1960s hotel, Hotel Turismo, which had been a site of independence activities, was demolished in 2010 and rebuilt. The former Dili regency police headquarters has been demolished and replaced by the cultural centre of the Indonesian embassy. By 2010 the municipal population reached 234,026 people, of which 210,250 lived in urban areas. In 2018 the population reached 281,000 people. During a period of COVID-19 restrictions, the city was hit by the worst flood in 50 years in April 2021.\nGeography.\n&lt;templatestyles src=\"Pie chart/styles.css\"/&gt;\nDili lies on the northern coast of the island of Timor, which is among the eastern Lesser Sunda Islands and lies in the UTC+9 timezone. Offshore is the Ombai Strait of the Savu Sea. To the south is the central mountain range running through Timor, which extends north to the coast on the west and east surrounding the core city. The underlying ground is predominately limestone and marine clay.\nThe precise location of the city is around 8\u00b035\u2032S, 125\u00b036\u2032E. The city lies mostly within the larger Dili Municipality, whose total area was when including Atauro Island, north of Dili, which was formerly part of the municipality before becoming a separate municipality on 1 January 2022. The municipalities bordering Dili are Aileu, Liqui\u00e7\u00e1, and Manatuto. The municipality contains 31 sucos, divided into 241 aldeias. The urban area of the city of Dili extends through four of the Dili Municipality's Administrative Posts, Cristo Rei, Dom Aleixo, Nain Feto, and Vera Cruz. 18 sucos within these are considered urban, and this urban area is perhaps large. The wider urban area extends west into the Tibar suco of the Bazartete Administrative Post in the Liqui\u00e7\u00e1 Municipality. The combined area of all sucos within the urban region is , however this includes terrain considered too steep for habitation, with only perhaps 37%, or , flat enough for development. As of 2014, only 25.5% of the total area was developed.\nThe main city lies within an area of flat lowlands of less than 100m altitude, mostly between 0 and 60m, and a slope under 15 degrees. This includes an alluvial plain, and a number of beaches line the coast. The soil underneath this plain is quaternary alluvium. The distance between the sea and the mountains reaches a maximum width of only , and the surrounding mountains slope near the city at angles of 20 degrees or higher. On either side of the core urban area are mountain ridges extending from the southern range to the coast, leading to urban development spilling over onto areas of flat land on the other sides of these spurs. Tibar lies on the opposite site of the western range, while Hera lies on the opposite side of the eastern range. Another spur encloses Hera on its east.\nThe Comoro River flows through the western side of the city, while the Bemorl and Benmauc Rivers join together in the East. The Maloa river lies between these. The Maucau river flows through Tibar, while the Akanunu and Mota Kiik rivers flow through Hera. The Comoro is the largest, with a drainage basin extending inland to a point where the mountains are high. The water level within these rivers differs greatly between the dry and wet seasons. Parts of the city are considered to face drought hazards and flooding risk from rivers, issues related to climate change. Within the main city of Dili (although not in Hera or Tibar), rivers have reinforced to contain a once-in-25-year flood. Small-scale flooding occurs in a minority of houses a few times each year, and reports of land subsidence are found throughout the city. The Maloa river is the most commonly flooded. Landslides have previously caused damage and loss of life. The area is thought to face earthquake and tsunami risks, although no major events have occurred. Air pollution is considered an increasing issue, with contributors including forest fires, wood-fuelled cooking, and vehicles.\nEcology.\nThe landscape around Dili naturally supports dry deciduous forests. Common tree species include \"Sterculia foetida\", \"Calophyllum teysmanii\", and \"Aleurites moluccana\". \"Eucalyptus alba\" is found in rocky areas, and palm and acacia trees are also found. The eucalyptus trees often serve as firewood, while nuts from \"A. moluccana\" are sometimes burnt to produce lighting. Trees found within urban areas include \"Alstonia scholaris\", \"Albizia julibrissin\", \"Ficus microcarpa\", and a variety of fruit trees. While forests around the city have been damaged by harvesting for construction and firewood, the national government aims to reforest these areas. Large wildlife in these forests includes monkeys.\nMangrove species found along the coastline include the near-threatened \"Ceriops decandra\". Coral reefs, seagrass meadows, and intertidal mudflats are also present. The coral reefs off Dili appear to be locally sheltered from the average sea surface temperature rise from climate change. However, they face some degradation from human activities. The seagrass beds support dugongs and sea turtles, while dolphins and whales are found offshore.\nThere are three protected biodiversity areas within Dili: Behau, Cristo Rei Protected Area, and Tasitolu. The Cristo Rei Protected Area lies on the mountains separating central Dili and Hera. The Tasitolu area lies near the border of the Dili and Liqui\u00e7\u00e1 municipalities and covers land and some coastal waters. It is being developed as a recreational site and holy area. The large Behau protected area covers much of the sea off eastern Dili, as well as coastal areas in Hera and to the east. Behau is the most recently proposed of the three areas, and the government is considering abolishing it and replacing it with smaller areas. BirdLife International has identified Cristo Rei Protected Area and Tasitolu as falling within Important Bird Areas. Development can occur in these areas with the approval of the national government. Near-threatened bird species found in these protected areas include the black cuckoo-dove, the pink-headed imperial pigeon, and the Timor sparrow.\nClimate.\nDili has a rather dry tropical savanna climate (K\u00f6ppen \"Aw\"). A rainy season lasts from November to April and a dry season from May to October. Rainfall is highest in December, averaging between 2005 and 2013, and lowest in August, averaging over the same time period. The overall average is annually, although there is significant variation between years.\nMean temperatures average around . This changes by throughout the day, from minimums at around to maximums at over . There are larger temperature changes during the dry season. Climate change is shifting weather patterns, and may exacerbate extreme weather events. The highest single recorded temperature in the city up to 2013 was in November 2011, while the lowest has been in August 2013.\nBuildings and monuments.\nThe old quarter of the city lies within what is now the city's eastern half. The original Portuguese settlement occurred in a grid parallel to the shore, and the city has extended along this east-west axis. The older parts of the city are the most densely built up, with little available land. The western portion of the city is the location of the airport and has the most recent urban growth. Most infrastructure was destroyed in 1999, including 68,000 homes. Following rebuilding as of 2010, 71.6% of houses have concrete or brick walls. In Hera however, just over 50% of houses were mostly wooden as of 2014.\nLand rights remain complicated and unresolved as a result of the 2006 crisis, with returns of former residents to the capital having been carried out on an ad-hoc basis. There are disputes between residents who claim land was taken from them by previous regimes, and the national government that has created what is seen as an expansive definition of state land. Developing a formal property system and land register is a key development goal. Those living in houses with this mixed ownership history, perhaps up to 50% of all residents, face heightened risk of eviction.\nImportant government buildings which form the core of the city are clustered around the Port of Dili. The outskirts of the city are the most recently developed, and grew organically without much urban planning. The central core (Bairro Central) contains most administrative buildings, and has the most buildings constructed with masonry. It retains many buildings that reflect Portuguese-era architecture. To the east of the central government area is the old Chinese area, which still retains a number of Chinese-influenced buildings.\nPortuguese-era buildings are most common in the Motael, Gricenfor, and Bidau Lecidere sucos, often stretched along the main road running through the old part of the city, the Avenida Nicolau Lobato. The main government complex is located at the Largo Infante Dom Henrique, next to the seafront. This location was part of the 1951 urban plan. The primary building here is the Government Palace, consists of three two-story buildings connected by a single arcade which were built at different periods between 1953 and 1969. \nAnother old building is the former Market Hall.\nThe government has identified a number of heritage buildings in the city, especially in the old quarter. New buildings are being built to house cultural institutions. The Museum and Cultural Centre of Timor-Leste is tasked with hosting the country's cultural artefacts. The National Library of Timor-Leste is intended to serve as both a library and a national archive.\nNotable churches include the Motael Church, the oldest in the country, which became associated with resistance to Indonesian rule. The Immaculate Conception Cathedral was built with the intention of being the largest church in Southeast Asia. The Cristo Rei of Dili is a tall statue of Jesus situated on top of a globe at the end of the eastern Fatucama peninsula. It is positioned at the end of a Stations of the Cross pathway including over 500 steps. It was a present from the government of Indonesia during occupation for the 20th anniversary of East Timor's integration into Indonesia. Its height reflects the symbolism of East Timor being Indonesia's 27th province at the time of the monument's construction in 1996.\nThe Integration Monument commemorates the Indonesian annexation of the territory in 1976. It takes the shape of a statue of an East Timorese warrior in traditional dress breaking the chains round his wrists, deliberate chosen to associate traditional Timorese identity with Indonesian rule. The monument has not been demolished, but is instead now regarded as representing the struggle against both periods of foreign rule.\nThe National Stadium has two seating stands, one on either side, with grass banks providing space for other spectators. It has a capacity of around 9,000 people. It is often used to host association football, the most popular sport in the country, although infrastructure issues mean the national team must sometimes play home games in other countries. In the past it has been used to host refugees and distribute aid.\nAdministration.\nDili is the administrative centre of the Dili Municipality, serving as both the municipal and national capital. Dili itself does not have a city government, but is governed centrally by the Dili Municipality, along with the Hera and Metinaro areas. The current president of the Dili Municipality Authority is Greg\u00f3rio da Cunha Saldanha, sworn in on 1 March 2024. The municipality has an elected mayor and council.\nTimor-Leste's municipalities are divided into administrative posts, and each of these is divided into sucos. The central city of Dili is spread over four of the six administrative posts within Dili municipality: Cristo Rei, Dom Aleixo, Nain Feto, and Vera Cruz. The Hera suco is the easternmost suco of Cristo Rei. Tibar, to the west of the main city, is the easternmost suco of the Bazartete Administrative Post in the Liqui\u00e7\u00e1 Municipality.\nEach suco has a \"chefe\". Those in Dili have less influence over community land than those elsewhere, however their elected status gives them greater authority in other areas. Each also has a head office. Municipal and national government buildings are concentrated in the city centre, mainly in the sucos of Caicori, Colmera, and Gricenfor. Sucos, administrative posts, and municipalities are all tasked with setting up a Disaster Management Committee. These are responsible for planning, public awareness, and disaster response. The borders of sucos, and the aldeias within them, are often undefined. Reasons for this include the history of displacement, and taboo over formal demarcation.\nLand registration is difficult due to the city's tumultuous history, and legal ownership is often unclear. It is thought that in 1999 existing land records were taken from Dili to Indonesia. The new government attempted to set up a system of rent, charging a small fee of $10 a month for those occupying state property. However, in many cases even this could not be paid. In 2003 the national government legislated that all previous state property, as well as abandoned properties, belonged to the state. It also set up a system of registration based on occupation. Residents can claim land they live in, if there are no objections from others. The 2006 crisis put an end to attempts to enforce rent. Evictions from state property are rare. A cadastral survey began in 2008. As of 2014, 70% of the land in Dili had been surveyed, although this information is not public. Despite this lack of information, most in the city claim ownership of their homes, with 90% of homes considered owned by an individual or by a family. Land valuation is often unclear.\nThe sucos within the four administrative posts in the western Dili Municipality that form the core city are as follows:\nCristo Rei\nDom Aleixo\nNain Feto\nVera Cruz\nEconomy.\nThe economic situation in Dili is substantially better than that of the rest of the country, and most wealth is concentrated there. Almost all of the sucos of Dili are among those with the country's highest living standards and the greatest access to public services. The Dili district as a whole has a higher significantly higher living standard than any other part of the country, and while poverty rates within the sucos of the municipality as a whole range from 8 to 80%, every suco within the city proper was ranked within the highest level of living standards. 57.8% of those in the capital are among those with relatively high levels of wealth, as opposed to 8.7% in rural areas.\nIn 2004 18,331 people were working in the agricultural sector, 1,885 in resources and manufacturing, 5,027 in hospitality, 3,183 in finance, real estate, and logistics, 6,520 in government services and security, 879 in home industries, 6,354 for international diplomatic bodies, and 2,142 unknown. By 2010, the tertiary sector employed 44% of those working, with government employment providing around 25% of jobs. The primary sector is slightly smaller than the government in terms of employment, while the secondary sector remains small. The working age population grew by almost 50% from 2004 to 2010, while unemployment declined from 26.9% to 17.4%. Nonetheless, youth unemployment in the municipality stood at 58% in 2007, above the national average of 43%. The capital attracts younger and educated individuals from the rest of the country.\nThe city lies within the government's \"Northern Regional Development Corridor\", which stretches along the coast from the Indonesia border to Baucau. Within this, it is part of the smaller \"Dili-Tibar-Hera\" area in which the government plans to develop the service sector. The city is also part of what is designated the central tourism zone. Sites related to important historical events are promoted, as well as eco-tourism. Whale watching is possible off the coast, and there are many scuba diving sites near the city. Some tourism and industrial complexes are being developed within the metropolitan area. There is a large informal economy that includes some of the officially unemployed residents.\nTourism numbers increased from 14,000 to 51,000 from 2006 to 2013. Half of visitors arriving at Dili's airport come from three countries: Australia, Indonesia, and Portugal. Near the beginning of UN rule, there were at least 9 hotels with 550 rooms. As of 2012, there were at least 14 hotels in the city. Most hotels are run by local companies, with few international chains present. Nightly rates are relatively high for the region, partially due to a lack of sufficient tourists to benefit from economies of scale. Important hotels include Hotel Timor and Hotel Dili.\nMost large investments come from the public sector, although there is a growing small-scale private sector. The Dili municipality is responsible for around 40% of the country's fish production, most of which is consumed domestically. The country's three significant commercial banks operate primarily in Dili.\nThe Port of Dili is the country's largest. It handles the majority of international shipping. There are regular ships to Darwin (Australia), Kota Kinabalu (Malaysia), Surabaya (Indonesia), and Singapore, and less frequent shipping to and from other Indonesian ports. As of 2011, the port processed 200,000 tonnes of goods annually, which had increased by 20% each year for the previous six years. 80% of the goods processed are imports.\nDemographics.\nThe 2022 census found the population of the municipality was 324,269, of which 82.4% were urban. The municipality had the largest overall population and the highest growth rate since 2015, although average household size decreased from 6.4 to 5.7. The city contains almost twice as many dwellings as all other urban areas in the country combined. The municipality is the most densely populated in the country at 1,425 people per square kilometre, eight times denser than the second most densely populated municipality. and Dom Aleixo with 166 thousand people remained the country's most populous administrative post. By 2030, the population of the municipality is predicted to reach around 580,000.\nThe gender ratio in 2022 was around 103 men for every 100 women, in line with the national average. The dependency ratio of 51 dependents for every 100 economically active individuals is much lower than elsewhere in the country, likely due to the in-migration of younger adults. Every other municipality in the country shows a net negative in-migration rate, leading Dili to gain 36.9% of its population through this in-migration. The literacy rate for those 10 and over was 89.6%. Only 5.4% of dwellings had piped water, a toilet, a bath or shower, and a kitchen.\nDue to limited space, a small number of people settled in hilly and mountainous areas starting around 1990, especially in southern areas near the national highway. However, due to properties being abandoned following the independence vote, much settlement in the 21st century has been into these vacated areas. Population density tends to be higher in areas of unplanned settlement than in planned neighbourhoods.\nThe primary local language is Tetum, which was promoted during Portuguese rule and has become an official language of the country. Speakers from the other languages of Timor-Leste are present in the city, where the official language of Portuguese and the working languages of English and Indonesian are also spoken. A dialect of Malay-based creole called Dili Malay is spoken by perhaps 1,000 residents with ancestral links to Alor Island. Migration into the city has led to clustering of incoming migrants into areas with others of similar backgrounds.\nEducation.\nEducation is more common in Dili Municipality than elsewhere in the country. The attendance rate at primary schools increased from 37% in 2004 to 73% in 2010. As of 2010, 86% of those five or older in the municipality had attended primary school, equivalent to the literacy rate. Within the metropolitan area, education rates are highest in Nain Feto and Vera Cruz, where 88% are either attending or have attended primary school. These are followed by Dom Alexio at 87%, and Cristo Rei at 81%. Tibar, lying outside of Dili Municipality, has the lowest at 75%.\nAs of 2013, there were 108 schools in Dili, Hera, and Tibar, including primary, secondary, and specialist schools. Of these, 61 were public and 47 private. This equated to 4.8 schools per 10,000 people. In 2011, 43% of students in the Dili municipality studied in private schools. Many private schools are run by the Catholic Church, for example, Don Bosco Training Center, including 32% of all schools in the Dili Municipality.\nSeventy-six per cent of the country's university students study in the municipality. This is responsible for some of the internal migration to the city. The National University of Timor-Leste created a \"University City\" master plan to develop the Hera area.\nInfrastructure.\nUp to 70% of the country's infrastructure was destroyed in 1999, including almost the entire electrical grid, and much of the water infrastructure. Dili's airport and port were rehabilitated in the six years following this, along with electricity and telecommunications. The rapid population growth of the city has put a strain on some of its infrastructure services. Pre-independence laws prohibiting building within of water bodies are not enforced, with population growth leading to structures such as housing being built in flood-prone areas, including along dry river beds and canals.\nUtilities.\nElectricity.\nIn the early years of UN rule, electricity was provided by the Comoro power station, which has a 16 MW diesel generator. By 2004, there were 23,000 connections in the city creating a demand of 12.5 MW. At the time, Dili was the only location in Timor-Leste with 24-hour electricity. Electricity demand peaked from 19:00 to 22:00. By 2009, Comoro was producing 32 MW, and by the year after that 92.3% of Dili's households used electricity for lighting purposes. Cooking remained carried out using firewood by 66.2% of households, with electricity being used by just 10.1%. Non-payment of electricity bills has caused some funding problems. In 2011, only 40% of commercial recipients of electricity paid their electricity bills.\nIn November 2011, the diesel generators at the new Hera Power Station became operational, producing 119 MW. This replaced the operations of the Comoro station, with Hera able to produce electricity using 17% less fuel. A new substation was created to supply Dili, and transmission lines link Dili to other cities and towns along the northern coast, part of a ring surrounding the country. As of 2016, Dili's peak power demand reached 42.11 MW. The development of electricity infrastructure since independence has significantly reduced electricity costs, which moved from 249c per kilowatt-hour in 2002 to 5c per kilowatt-hour in 2014.\nTelecommunications.\nTelecommunications activity in the country is primarily carried out using mobile phones, with most of the country's 3000 landlines found in Dili and used mainly for government and business. There are no submarine communications cables connecting to the country, so internet access is supplied via satellites. This is expensive, and internet usage nationally was only just above 1% in 2016. The government has approved the installation of the Timor-Leste South submarine Cable (TLSSC), connecting to Darwin in Australia, as well as another cable connecting to the Indonesian island of Alor. As of 2020, there were 3 telecommunications companies in the country: Telemor, Telkomcel, and Timor Telecom.\nWater and sanitation.\nAccess to clean water and sanitation is an issue for some households. Over $250\u00a0million was invested by the UN and other organisations to build Dili's water infrastructure. Existing water sources and transportation infrastructure are considered sufficient to meet the immediate needs of the city, although work continues to improve quality and reliability. In 2007, 25% of residents received 24 hours of water. As of 2013, while 36% of households were connected to the water supply system, half Dili received less than six hours of water a day. Furthermore, water quality was irregular, with boiling advised. By 2015, it remained the case that less than 30% of those in Dili had access to a continuous water supply. In 2018, water remained available on average from 4 to 8 hours.\nWater is managed by the National Directorate of Water and Sanitation Services (Dirasaun Nasional Sistema Agua no Saneamentu/DNSAS), which derives 60% of water supplies from groundwater. This groundwater extraction began in the 1980s, and accelerated after independence. Private entities also pump water from the aquifer without regulation. Despite the inconsistency of supply, 91% of those in urban areas have some access to safe drinking water, with sources including pumps, public taps, and wells and boreholes. Some households have tanks installed to alleviate the impact of service interruptions. Half of the city's water comes from a local aquifer, and there are four water treatment plants at the southern edges of the city. Water tariffs were put in place in 2004, but were removed in 2006 following the 2006 East Timorese crisis. By 2010 of water was pumped from the aquifer each day, almost as fast as the aquifer could refill. Trials for water tariff re-introduction began in 2013. Increasing usage has led to the aquifer, the Dili Groundwater Basin, being unable to match demand during the dry season. An increasing number of wells has increased demand, while development altering drainage patterns has limited recharge rates. The aquifer is constrained by the ocean on one side and mountains on the others. Downstream areas also face saltwater intrusion.\nDili is the location of the country's water testing laboratory, and thus its water quality is regularly monitored. The lack of manufacturing in the city is thought to have limited potential water pollution. However, pollution risks emerge from the common discharge of untreated household water, and leakage from latrine pits into the soil and relatively high water table. Water stores in households, as well as from some wells, has been found to have bacteriological contamination. As of 2010, only 16% of households emptied their latrine pits. Hera and Tibar lack water treatment plants, with residents relying on boreholes and delivery by water trucks. As of 2010, daily demand was 32,000\u00a0m3 in Dili proper, 520\u00a0m3 in Hera, and 220\u00a0m3 in Tibar.\nDrainage infrastructure is insufficient to handle the wet season, with drains often being blocked and resultant flooding being common. This creates property damage and health concerns. Thirty-six water channels lie within the city in addition to its rivers. These often collect rainwater; however, the growing urbanisation of the city is reducing infiltration capacity, worsening flood risks. There is no city-wide sewerage system. As of 2010, only 30.3% of households had access to a sceptic tank. The most common sewage disposal system was pit latrines, which were used by 50.7% of households. Among households with toilets, 97% were flushed through the manual pouring of water. Wastewater is often collected from some areas by trucks. Some wastewater is treated in ponds in Tasitolu. Dili also has one of the country's two septage treatment facilities. A Sanitation and Drainage Masterplan was created for the city in 2012, envisioning the creation of eight wastewater treatment systems in the city by 2025.\nAs of 2014, Dili produces 108 tons of solid waste per day, over half of which is biodegradable. The government-funded waste collection system covers Cristo Rei, Dom Aleixo, Nain Feto, and Vera Cruz, with waste being collected by a mixture of government trucks and private trucks contracted by the government. Collected waste is disposed in a landfill in Tibar, which was established during the Indonesian period. Metal collected by waste pickers is sold to Malaysia and Singapore for recycling, while some biodegradable waste is composted by a private company. Some waste is burnt. Waste collection schedules are variable, with some areas receiving daily collection and some receiving none. Collection is less frequent in Hera and Tibar than in Dili proper.\nThere are 14 hospitals around the Dili metropolitan area, nine in Dom Aleixo, three in Vera Cruz, one in Cristo Rei (in Hera), and one in Tibar. Dom Aleixo also has two health centres, with Cristo Rei having one health centre in Dili proper, and Nain Feto also having a health centre. The National Hospital of Timor-Leste is located in Dili, catering to primary and secondary health care. A specialist hospital is planned to be constructed by 2030 to deal with diseases, such as cancer, that are currently treated outside of the country.\nTransport.\nLand.\nAs of 2015, Dili Municipality had of roads, of which half were classified as National, District, or Urban. The roads heading into and out of Dili to the East and West carry over 1,000 non-motorbike vehicles daily. In addition to the Eastern and Western national roads, a third national road extends south from the city. Within Dili, there is rising congestion. Poor road quality is the most common cause of accidents and delays. Many roads are unpaved, and within the old quarter, streets are often one-way. The only four lane roads in the city are National Road A01 and Banana Road. As of 2016, there were four roundabouts and 11 intersections with traffic lights. Few routes travel along the east-west axis, and for most of the time since independence there was only one vehicular crossing across the Comoro river. This bridge was expanded from two lanes to four lanes in June 2013. The two-lane Hinode Bridge was opened upriver in September 2018, connecting Banana road to National Road No 03. It is expected that this bridge will also be expanded to four lanes in the future.\nThe usual form of public transportation within the city is the minibus, which are operated by private companies that purchase route franchises from the government. Each vehicle usually has a capacity of ten people. There are no formal schedules and few official bus stops. Fares are cheap, at $0.25. Dili is also served by a fleet of air-conditioned blue taxis, whose drivers are expected to speak Tetum and English.\nStreet names are in Portuguese, as are many official signs labelling locations. Tetum is used for more informational signage. English and Indonesian are rare in official signage, but are more common elsewhere. Chinese is used on some informal signage, while non-Tetum Timorese languages are not used. Even under Indonesian rule, during which the use of Portuguese was banned, Portuguese street names like \"Avenida Marechal Carmona\" remained unchanged, although they were prefixed with the Indonesian word \"Jalan\" or 'road'.\nSea.\nThe Port of Dili has a total berth length of . Depths alongside the berth range from to . This port was previously the only international cargo reception port in the country, but its capacity is insufficient to meet import needs. The Tibar Bay Port was thus planned to handle all cargo shipping, leaving the current Dili port to become a dedicated ferry terminal. Tibar Bay Port was expected to be built starting in 2015, and scheduled for opening in 2020. On 3 June 2016 the government signed a Public-private partnership agreement with Bollor\u00e9, giving the company a 30-year least on the new port. A construction tender was awarded to the China Harbour Engineering Company in December 2017. Construction began on 30 August 2019, with completion scheduled for August 2021. As of December 2020, construction was 42% complete, with delays including Chinese workers returning to China during the COVID-19 pandemic. The port was then expected to open in April 2022. The port received its first ships on 30 September that year, and was officially inaugurated on 30 November 2022.\nA dry port has been created from the main Port of Dili, and there is a naval port in Hera. Cargo operations in Dili Port halted from 1 October 2022. A twice-weekly ferry service operates between Dili and Oecusse, and a ferry travels between Dili and Atauro once a week. The Dili Port serves as the main link for these locations with the rest of the country. These ferries deposit people and vehicles onto a slipway, rather than a dedicated berthing.\nAir.\nThe Presidente Nicolau Lobato International Airport, named after independence leader Nicolau Lobato, is located in the city. It serves regular flights to Darwin (Australia), Denpasar (Indonesia), and Singapore. In 2014, it served 198,080 passengers and 172 tons of cargo. It has one runway, which is long and wide, lying above mean sea level. A lack of runway lighting prevents night-time landings, so the airport operates from 6\u00a0am to 6\u00a0pm. The passenger terminals were originally domestic terminals during the Indonesian period, leaving them ill-designed to handle international customs and immigration. Due to the size of the runway, only medium-sized planes such as the A319 and the B737 can be accommodated, and there is limited space for aircraft parking. The runway is constrained by the sea and the Comoro river, although there are plans to extend the runway through land reclamation and/or by bridging the river. A new international terminal is also planned. Despite this, it is thought the airport may be able to handle capacity requirement until 2030.\nThis is the only functioning international airport in Timor-Leste, though there are airstrips in Baucau, Suai and Oecusse used for domestic flights. Until recently, Dili's airport runway has been unable to accommodate aircraft larger than the Boeing 737 or C-130 Hercules, but in January 2008, the Portuguese charter airline EuroAtlantic Airways operated a direct flight from Lisbon using a Boeing 757, carrying 140 members of the Guarda Nacional Republicana.\nCulture.\nWithin the city, cultural differences exist not only between different ethnolinguistic groups, but between more established residents of the city, and recent immigrants who retain different cultural practices. Legal traditions reflecting Portuguese and Indonesian rule do not always align with customary practices, such as in the recognition of marriages. Those who migrate internally into Dili retain cultural and identity links to their rural areas of origin, which are passed down through generations. Urban residents often return to rural areas for traditional ceremonies, especially during the dry season, and elections.\nLocal communities have important traditional houses, as well as sacred natural areas including specific trees, rocks, and wells, as well as a number of \"Uma Lulik\" (sacred houses). As in the rest of the country, village chiefs continue to have some influence in Dili's communities. However, with suco populations being more diverse in Dili than in rural areas, suco chief power is not as established or effective. Community links are instead more common at aldeia levels, or even established through religious or economic links instead. New arrivals often settle near those from the same area of origin, leading Dili's urban population to have formed into a patchwork of different communities. Migration back and forth from Dili to rural areas is not uncommon. Furthermore, while rural sucos are often somewhat culturally homogenous and linked by family relationship, these administrative boundaries do not map with the cultural settlement patterns of modern Dili.\nThere is some more homogeneity at the aldeia level due to families settling near relatives, although this is also not consistent. Aldeia nearer the outskirts, or in areas formerly populated by Indonesian civil servants, are both more densely populated and particularly heterogenous both ethnolinguistically and socioeconomically. In diverse aldeias, smaller communities sometimes develop with their own informal leadership. Some urban areas exhibit occupational or status-based segregation. Core urban areas are dominated by relatively wealthy families, often those that were considered mesti\u00e7os or assimilados under Portuguese rule. Some aldeias mostly consist of those of foreign descent, or of transient students.\nDili contains a number of local and often youth collectivities. While sometimes described as gangs, many function more as social collectivities integrated into their local community. Such groups have a long history, many forming as an act of resistance against Indonesian rule. Some street art continues to reflect a theme of resistance. The composition of these groups often reflects areas of rural origin, and the broader East-West divide that exists within the country.\nThe national government has crafted a culture policy that includes the provision of cultural facilities in Dili and aims to have the city reflect diverse cultural influences. The development of cultural facilities has included the building up of cultural institutions such as libraries and museums, and the development of audio-visual multimedia centres through which information will be more accessible. The \"City of Peace\" campaign seeks to maintain stability in the capital by bringing youth together for common discussions and by promoting a shared sense of national pride. Large events in which locals can work together on shared goals and security services are given roles are important parts of this campaign. One important event is the Dili \"City of Peace\" marathon, first held in June 2010, following which it became an annual event. This includes a full marathon, a half marathon, and a seven-kilometre \"Run for Peace\".\nDili had no cinema until 2011, when one opened in a new shopping centre known as Timor Plaza. The country's first locally produced feature film, \"Beatriz's War\", was released a couple of years later. In 2019, the city hosted the first Dili International Film Festival, which was repeated in 2020. Radio is very popular, and the city has 13 FM radio stations.\nInternational relations.\nDiplomatic missions.\nEmbassies.\n&lt;templatestyles src=\"Col-begin/styles.css\"/&gt;\nTwin towns \u2013 sister cities.\nDili is twinned with the following places:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49253", "revid": "48417338", "url": "https://en.wikipedia.org/wiki?curid=49253", "title": "Urysohn's lemma", "text": "Characterization of normal spaces by continuous functions\nIn topology, Urysohn's lemma is a lemma that states that a topological space is normal if and only if any two disjoint closed subsets can be separated by a continuous function.\nUrysohn's lemma is commonly used to construct continuous functions with various properties on normal spaces. It is widely applicable since all metric spaces and all compact Hausdorff spaces are normal. The lemma is generalised by (and usually used in the proof of) the Tietze extension theorem.\nThe lemma is named after the mathematician Pavel Samuilovich Urysohn.\nDiscussion.\nTwo subsets formula_1 and formula_2 of a topological space formula_3 are said to be separated by neighbourhoods if there are neighbourhoods formula_4 of formula_1 and formula_6 of formula_2 that are disjoint. In particular formula_1 and formula_2 are necessarily disjoint.\nTwo plain subsets formula_1 and formula_2 are said to be separated by a continuous function if there exists a continuous function formula_12 from formula_3 into the unit interval formula_14 such that formula_15 for all formula_16 and formula_17 for all formula_18 Any such function is called a Urysohn function for formula_1 and formula_20 In particular formula_1 and formula_2 are necessarily disjoint.\nIt follows that if two subsets formula_1 and formula_2 are separated by a function then so are their closures. Also it follows that if two subsets formula_1 and formula_2 are separated by a function then formula_1 and formula_2 are separated by neighbourhoods.\nA normal space is a topological space in which any two disjoint closed sets can be separated by neighbourhoods. Urysohn's lemma states that a topological space is normal if and only if any two disjoint closed sets can be separated by a continuous function.\nThe sets formula_1 and formula_2 need not be precisely separated by formula_31, i.e., it is not necessary and guaranteed that formula_32 and formula_33 for formula_34 outside formula_1 and formula_20 A topological space formula_3 in which every two disjoint closed subsets formula_1 and formula_2 are precisely separated by a continuous function is perfectly normal.\nUrysohn's lemma has led to the formulation of other topological properties such as the 'Tychonoff property' and 'completely Hausdorff spaces'. For example, a corollary of the lemma is that normal T1 spaces are Tychonoff.\nFormal statement.\nA topological space formula_3 is normal if and only if, for any two non-empty closed disjoint subsets formula_1 and formula_2 of formula_43 there exists a continuous map formula_12 such that formula_45 and formula_46\nProof sketch.\nThe proof proceeds by repeatedly applying the following alternate characterization of normality. If formula_3 is a normal space, formula_48 is an open subset of formula_3, and formula_50 is closed, then there exists an open formula_4 and a closed formula_6 such that formula_53. \nLet formula_1 and formula_2 be disjoint closed subsets of formula_3. The main idea of the proof is to repeatedly apply this characterization of normality to formula_1 and formula_58, continuing with the new sets built on every step. \nThe sets we build are indexed by dyadic fractions. For every dyadic fraction formula_59, we construct an open subset formula_60 and a closed subset formula_61 of formula_3 such that:\nIntuitively, the sets formula_60 and formula_61 expand outwards in layers from formula_1:\n formula_73\nThis construction proceeds by mathematical induction. For the base step, we define two extra sets formula_74 and formula_75. \nNow assume that formula_76 and that the sets formula_77 and formula_78 have already been constructed for formula_79. Note that this is vacuously satisfied for formula_80. Since formula_3 is normal, for any formula_82, we can find an open set and a closed set such that\n formula_83\nThe above three conditions are then verified.\nOnce we have these sets, we define formula_84 if formula_85 for any formula_65; otherwise formula_87 for every formula_88, where formula_89 denotes the infimum. Using the fact that the dyadic rationals are dense, it is then not too hard to show that formula_31 is continuous and has the property formula_91 and formula_92 This step requires the formula_61 sets in order to work.\nThe Mizar project has completely formalised and automatically checked a proof of Urysohn's lemma in the http://.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49256", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=49256", "title": "Age of Earth", "text": "Scientific dating of the Earth\nThe age of Earth is estimated to be 4.54 \u00b1 0.05 billion years. This age represents the final stages of Earth's accretion and planetary differentiation. Age estimates are based on evidence from radiometric age-dating of meteoritic material\u2014consistent with the radiometric ages of the oldest-known terrestrial material and lunar samples\u2014and astrophysical accretion models consistent with observations of planet formation in protoplanetary disks.\nFollowing the development of radiometric dating in the early 20th century, measurements of lead in uranium-rich minerals showed that some were in excess of a billion years old. The oldest such minerals analyzed to date\u2014small crystals of zircon from the Jack Hills of Western Australia\u2014are at least 4.404 billion years old. Calcium\u2013aluminium-rich inclusions\u2014the oldest known solid constituents within meteorites that are formed within the Solar System\u2014are 4.5673 \u00b1 0.00016 billion years old giving a lower limit for the age of the Solar System.\nIt is hypothesized that the accretion of Earth began soon after the formation of the calcium-aluminium-rich inclusions. Because the duration of this accretion process is not yet adequately constrained\u2014predictions from different accretion models range from around 30 million to 100 million years\u2014the difference between the age of Earth and of the oldest rocks is difficult to determine. It can also be difficult to determine the exact age of the oldest rocks on Earth, exposed at the surface, as they are aggregates of minerals of possibly different ages.\nDevelopment of modern geologic concepts.\nStudies of strata\u2014the layering of rocks and soil\u2014gave naturalists an appreciation that Earth may have been through many changes during its existence. These layers often contained fossilized remains of unknown creatures, leading some to interpret a progression of organisms from layer to layer.\nNicolas Steno in the 17th century was one of the first naturalists to appreciate the connection between fossil remains and strata. His observations led him to formulate important stratigraphic concepts (i.e., the \"law of superposition\" and the \"principle of original horizontality\"). In the 1790s, William Smith hypothesized that if two layers of rock at widely differing locations contained similar fossils, then it was very plausible that the layers were the same age. Smith's nephew and student, John Phillips, later calculated by such means that Earth was about 96 million years old.\nIn the mid-18th century, the naturalist Mikhail Lomonosov suggested that Earth had been created separately from, and several hundred thousand years before, the rest of the universe. Lomonosov's ideas were mostly speculative. In 1779 the Comte du Buffon tried to obtain a value for the age of Earth using an experiment: he created a small globe that resembled Earth in composition and then measured its rate of cooling. This led him to estimate that Earth was about 75,000 years old. Even earlier, in 1687, in his \"Principia\", the mathematician and physicist Isaac Newton was the first to calculate the age of the Earth by experiment, doing so by modeling its cooling from a red-hot state, theorizing a globe of red-hot iron the same size as Earth, ultimately coming to a conclusion of around 50,000 years. A method that Lord Kelvin would follow in his attempts to calculate the age of Earth.\nOther naturalists used these hypotheses to construct a history of Earth, though their timelines were inexact as they did not know how long it took to lay down stratigraphic layers. In 1830, geologist Charles Lyell, developing ideas found in James Hutton's works, popularized the concept that the features of Earth were in perpetual change, eroding and reforming continuously, and the rate of this change was roughly constant. This was a challenge to the traditional view, which saw the history of Earth as dominated by intermittent catastrophes. Many naturalists were influenced by Lyell to become \"uniformitarians\" who believed that changes were constant and uniform.\nEarly calculations.\nIn 1862, the physicist William Thomson, 1st Baron Kelvin published calculations that fixed the age of Earth at between 20 million and 400 million years. He assumed that Earth had formed as a completely molten object, and determined the amount of time it would take for the near-surface temperature gradient to decrease to its present value. His calculations did not account for heat produced via radioactive decay (a then unknown process) or, more significantly, convection inside Earth, which allows the temperature in the upper mantle to remain high much longer, maintaining a high thermal gradient in the crust much longer. Even more constraining were Thomson's estimates of the age of the Sun, which were based on estimates of its thermal output and a theory that the Sun obtains its energy from gravitational collapse; Thomson estimated that the Sun is about 20 million years old.\nGeologists such as Lyell had difficulty accepting such a short age for Earth. For biologists, even 100 million years seemed much too short to be plausible. In Charles Darwin's theory of evolution, the process of random heritable variation with cumulative selection requires great durations of time, and Darwin stated that Thomson's estimates did not appear to provide enough time. According to modern biology, the total evolutionary history from the beginning of life to today has taken place since 3.5 to 3.8 billion years ago, the amount of time which passed since the last universal ancestor of all living organisms as shown by geological dating.\nIn a lecture in 1869, Darwin's great advocate, Thomas Henry Huxley, attacked Thomson's calculations, suggesting they appeared precise in themselves but were based on faulty assumptions. The physicist Hermann von Helmholtz (in 1856) and astronomer Simon Newcomb (in 1892) contributed their own calculations of 22 and 18 million years, respectively, to the debate: they independently calculated the amount of time it would take for the Sun to condense down to its current diameter and brightness from the nebula of gas and dust from which it was born. Their values were consistent with Thomson's calculations. However, they assumed that the Sun was only glowing from the heat of its gravitational contraction. The process of solar nuclear fusion was not yet known to science.\nIn 1892, Thomson was ennobled as Lord Kelvin in appreciation of his many scientific accomplishments. In 1895 John Perry challenged Kelvin's figure on the basis of his assumptions on conductivity, and Oliver Heaviside entered the dialogue, considering it \"a vehicle to display the ability of his operator method to solve problems of astonishing complexity.\" Other scientists backed up Kelvin's figures. Darwin's son, the astronomer George H. Darwin, proposed that Earth and Moon had broken apart in their early days when they were both molten. He calculated the amount of time it would have taken for tidal friction to give Earth its current 24-hour day. His value of 56 million years was additional evidence that Thomson was on the right track. The last estimate Kelvin gave, in 1897, was: \"that it was more than 20 and less than 40 million year old, and probably much nearer 20 than 40\". In 1899 and 1900, John Joly calculated the rate at which the oceans should have accumulated salt from erosion processes and determined that the oceans were about 80 to 100 million years old.\nRadiometric dating.\nOverview.\nBy their chemical nature, rock minerals contain certain elements and not others; but in rocks containing radioactive isotopes, the process of radioactive decay generates exotic elements over time. By measuring the concentration of the stable end product of the decay, coupled with knowledge of the half life and initial concentration of the decaying element, the age of the rock can be calculated. Typical radioactive end products are argon from decay of potassium-40, and lead from decay of uranium and thorium. If the rock becomes molten, as happens in Earth's mantle, such nonradioactive end products typically escape or are redistributed. Thus the age of the oldest terrestrial rock gives a minimum for the age of Earth, assuming that no rock has been intact for longer than Earth itself.\nConvective mantle and radioactivity.\nThe discovery of radioactivity introduced another factor in the calculation. After Henri Becquerel's initial discovery in 1896, Marie and Pierre Curie discovered the radioactive elements polonium and radium in 1898; and in 1903, Pierre Curie and Albert Laborde announced that radium produces enough heat to melt its own weight in ice in less than an hour. Geologists quickly realized that this upset the assumptions underlying most calculations of the age of Earth. These had assumed that the original heat of Earth and the Sun had dissipated steadily into space, but radioactive decay meant that this heat had been continually replenished. George Darwin and John Joly were the first to point this out, in 1903.\nInvention of radiometric dating.\nRadioactivity, which had overthrown the old calculations, yielded a bonus by providing a basis for new calculations, in the form of radiometric dating.\nErnest Rutherford and Frederick Soddy jointly had continued their work on radioactive materials and concluded that radioactivity was caused by a spontaneous transmutation of atomic elements. In radioactive decay, an element breaks down into another, lighter element, releasing alpha, beta, or gamma radiation in the process. They also determined that a particular isotope of a radioactive element decays into another element at a distinctive rate. This rate is given in terms of a \"half-life\", or the amount of time it takes half of a mass of that radioactive material to break down into its \"decay product\".\nSome radioactive materials have short half-lives; some have long half-lives. Uranium and thorium have long half-lives and so persist in Earth's crust, but radioactive elements with short half-lives have generally disappeared. This suggested that it might be possible to measure the age of Earth by determining the relative proportions of radioactive materials in geological samples. In reality, radioactive elements do not always decay into nonradioactive (\"stable\") elements directly, instead, decaying into other radioactive elements that have their own half-lives and so on, until they reach a stable element. These \"decay chains\", such as the uranium-radium and thorium series, were known within a few years of the discovery of radioactivity and provided a basis for constructing techniques of radiometric dating.\nThe pioneers of radioactivity were chemist Bertram B. Boltwood and physicist Rutherford. Boltwood had conducted studies of radioactive materials as a consultant, and when Rutherford lectured at Yale in 1904, Boltwood was inspired to describe the relationships between elements in various decay series. Late in 1904, Rutherford took the first step toward radiometric dating by suggesting that the alpha particles released by radioactive decay could be trapped in a rocky material as helium atoms. At the time, Rutherford was only guessing at the relationship between alpha particles and helium atoms, but he would prove the connection four years later.\nSoddy and Sir William Ramsay had just determined the rate at which radium produces alpha particles, and Rutherford proposed that he could determine the age of a rock sample by measuring its concentration of helium. He dated a rock in his possession to an age of 40 million years by this technique. Rutherford wrote of addressing a meeting of the Royal Institution in 1904:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I came into the room, which was half dark, and presently spotted Lord Kelvin in the audience and realized that I was in trouble at the last part of my speech dealing with the age of the Earth, where my views conflicted with his. To my relief, Kelvin fell fast asleep, but as I came to the important point, I saw the old bird sit up, open an eye, and cock a baleful glance at me! Then a sudden inspiration came, and I said, \"Lord Kelvin had limited the age of the Earth, provided no new source was discovered. That prophetic utterance refers to what we are now considering tonight, radium!\" Behold! the old boy beamed upon me.\nRutherford assumed that the rate of decay of radium as determined by Ramsay and Soddy was accurate and that helium did not escape from the sample over time. Rutherford's scheme was inaccurate, but it was a useful first step. Boltwood focused on the end products of decay series. In 1905, he suggested that lead was the final stable product of the decay of radium. It was already known that radium was an intermediate product of the decay of uranium. Rutherford joined in, outlining a decay process in which radium emitted five alpha particles through various intermediate products to end up with lead, and speculated that the radium\u2013lead decay chain could be used to date rock samples. Boltwood did the legwork and by the end of 1905 had provided dates for 26 separate rock samples, ranging from 92 to 570 million years. He did not publish these results, which was fortunate because they were flawed by measurement errors and poor estimates of the half-life of radium. Boltwood refined his work and finally published the results in 1907.\nBoltwood's paper pointed out that samples taken from comparable layers of strata had similar lead-to-uranium ratios, and that samples from older layers had a higher proportion of lead, except where there was evidence that lead had leached out of the sample. His studies were flawed by the fact that the decay series of thorium was not understood, which led to incorrect results for samples that contained both uranium and thorium. However, his calculations were far more accurate than any that had been performed to that time. Refinements in the technique would later give ages for Boltwood's 26 samples of 410 million to 2.2 billion years.\nArthur Holmes establishes radiometric dating.\nAlthough Boltwood published his paper in a prominent geological journal, the geological community had little interest in radioactivity. Boltwood gave up work on radiometric dating and went on to investigate other decay series. Rutherford remained mildly curious about the issue of the age of Earth but did little work on it.\nRobert Strutt tinkered with Rutherford's helium method until 1910 and then ceased. However, Strutt's student Arthur Holmes became interested in radiometric dating and continued to work on it after everyone else had given up. Holmes focused on lead dating because he regarded the helium method as unpromising. He performed measurements on rock samples and concluded in 1911 that the oldest (a sample from Ceylon) was about 1.6 billion years old. These calculations were not particularly trustworthy. For example, he assumed that the samples had contained only uranium and no lead when they were formed.\nMore important research was published in 1913. It showed that elements generally exist in multiple variants with different masses, or \"isotopes\". In the 1930s, isotopes would be shown to have nuclei with differing numbers of the neutral particles known as \"neutrons\". In that same year, other research was published establishing the rules for radioactive decay, allowing more precise identification of decay series.\nMany geologists felt these new discoveries made radiometric dating so complicated as to be worthless. Holmes felt that they gave him tools to improve his techniques, and he plodded ahead with his research, publishing before and after the First World War. His work was generally ignored until the 1920s, though in 1917 Joseph Barrell, a professor of geology at Yale, redrew geological history as it was understood at the time to conform to Holmes's findings in radiometric dating. Barrell's research determined that the layers of strata had not all been laid down at the same rate, and so current rates of geological change could not be used to provide accurate timelines of the history of Earth.\nHolmes' persistence finally began to pay off in 1921, when the speakers at the yearly meeting of the British Association for the Advancement of Science came to a rough consensus that Earth was a few billion years old and that radiometric dating was credible. Holmes published \"The Age of the Earth, an Introduction to Geological Ideas\" in 1927 in which he presented a range of 1.6 to 3.0 billion years. No great push to embrace radiometric dating followed, however, and the die-hards in the geological community stubbornly resisted. They had never cared for attempts by physicists to intrude in their domain, and had successfully ignored them so far. The growing weight of evidence finally tilted the balance in 1931, when the National Research Council of the US National Academy of Sciences decided to resolve the question of the age of Earth by appointing a committee to investigate.\nHolmes, being one of the few people who was trained in radiometric dating techniques, was a committee member and in fact wrote most of the final report. Thus, Holmes' report concluded that radioactive dating was the only reliable means of pinning down a geologic time scale. Questions of bias were deflected by the great and exacting detail of the report. It described the methods used, the care with which measurements were made, and their error bars and limitations.\nModern radiometric dating.\nRadiometric dating continues to be the predominant way scientists date geologic time scales. Techniques for radioactive dating have been tested and fine-tuned on an ongoing basis since the 1960s. Forty or so different dating techniques have been utilized to date, working on a wide variety of materials. Dates for the same sample using these different techniques are in very close agreement on the age of the material. Possible contamination problems do exist, but they have been studied and dealt with by careful investigation, leading to sample preparation procedures being minimized to limit the chance of contamination.\nUse of meteorites.\nAn age of 4.55 \u00b1 0.07 billion years, very close to today's accepted age, was determined by Clair Cameron Patterson using uranium\u2013lead isotope dating (specifically lead\u2013lead dating) on several meteorites including the Canyon Diablo meteorite and published in 1956. The quoted age of Earth is derived, in part, from the Canyon Diablo meteorite for several important reasons and is built upon a modern understanding of cosmochemistry built up over decades of research.\nMost geological samples from Earth are unable to give a direct date of the formation of Earth from the solar nebula because Earth has undergone differentiation into the core, mantle, and crust, and this has then undergone a long history of mixing and unmixing of these sample reservoirs by plate tectonics, weathering and hydrothermal circulation.\nAll of these processes may adversely affect isotopic dating mechanisms because the sample cannot always be assumed to have remained as a closed system, by which it is meant that either the parent or daughter nuclide (a species of atom characterised by the number of neutrons and protons an atom contains) or an intermediate daughter nuclide may have been partially removed from the sample, which will skew the resulting isotopic date. To mitigate this effect it is usual to date several minerals in the same sample, to provide an isochron. Alternatively, more than one dating system may be used on a sample to check the date.\nSome meteorites are furthermore considered to represent the primitive material from which the accreting solar disk was formed. Some have behaved as closed systems (for some isotopic systems) soon after the solar disk and the planets formed. To date, these assumptions are supported by much scientific observation and repeated isotopic dates, and it is certainly a more robust hypothesis than that which assumes a terrestrial rock has retained its original composition.\nNevertheless, ancient Archaean lead ores of galena have been used to date the formation of Earth as these represent the earliest formed lead-only minerals on the planet and record the earliest homogeneous lead\u2013lead isotope systems on the planet. These have returned age dates of 4.54 billion years with a precision of as little as 1% margin for error.\nStatistics for several meteorites that have undergone isochron dating are as follows:\nCanyon Diablo meteorite.\nThe Canyon Diablo meteorite was used because it is both large and representative of a particularly rare type of meteorite that contains sulfide minerals (particularly troilite, FeS), metallic nickel-iron alloys, plus silicate minerals. This is important because the presence of the three mineral phases allows investigation of isotopic dates using samples that provide a great separation in concentrations between parent and daughter nuclides. This is particularly true of uranium and lead. Lead is strongly chalcophilic and is found in the sulfide at a much greater concentration than in the silicate, versus uranium. Because of this segregation in the parent and daughter nuclides during the formation of the meteorite, this allowed a much more precise date of the formation of the solar disk and hence the planets than ever before.\nThe age determined from the Canyon Diablo meteorite has been confirmed by hundreds of other age determinations, from both terrestrial samples and other meteorites. The meteorite samples, however, show a spread from 4.53 to 4.58 billion years ago. This is interpreted as the duration of formation of the solar nebula and its collapse into the solar disk to form the Sun and the planets. This 50 million year time span allows for accretion of the planets from the original solar dust and meteorites.\nThe Moon, as another extraterrestrial body that has not undergone plate tectonics and that has no atmosphere, provides quite precise age dates from the samples returned from the Apollo missions. Rocks returned from the Moon have been dated at a maximum of 4.51 billion years old. Martian meteorites that have landed upon Earth have also been dated to around 4.5 billion years old by lead\u2013lead dating. Lunar samples, since they have not been disturbed by weathering, plate tectonics or material moved by organisms, can also provide dating by direct electron microscope examination of cosmic ray tracks. The accumulation of dislocations generated by high energy cosmic ray particle impacts provides another confirmation of the isotopic dates. Cosmic ray dating is only useful on material that has not been melted, since melting erases the crystalline structure of the material, and wipes away the tracks left by the particles.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49257", "revid": "50094901", "url": "https://en.wikipedia.org/wiki?curid=49257", "title": "Digital Audio Broadcasting", "text": "Digital radio standard\nDigital Audio Broadcasting (DAB) is a digital radio standard for broadcasting digital audio radio services in many countries around the world, defined, supported, marketed and promoted by the WorldDAB organization. The standard is dominant in Europe and is also used in Australia, and in parts of Africa and as of 2025, 55 countries are actively running DAB broadcasts as an alternative platform to analogue FM.\nDAB was the result of a European research project and first publicly rolled out in 1995, with consumer-grade DAB receivers appearing around the late 1990\u2019s. Initially it was expected in many countries that existing FM services would switch over to DAB, although the take-up of DAB has been much slower than expected. In 2023, Norway became the first country to have implemented a national FM radio switch-off, with Switzerland to follow in 2026 and others territories in the process of planning a switch-off. Terrestrial digital radio has become a requirement for all new cars (not buses and trucks) sold in the EU since 2021.\nThe original version of DAB used the MP2 audio codec; an upgraded version of the system was later developed and released named DAB+ which uses the HE-AAC v2 (AAC+) audio codec and is more robust and efficient. DAB is not forward compatible with DAB+. Today the majority of DAB broadcasts around the world are using the upgraded DAB+ standard, with only the UK still using a significant number of legacy DAB broadcasts.\nDAB is generally more efficient in its use of spectrum than analog FM radio, and thus can offer more radio services for the same given bandwidth. The broadcaster can select any desired sound quality, from high-fidelity signals for music to low-fidelity signals for talk radio, in which case the sound quality can be noticeably inferior to analog FM. High-fidelity equates to a high bit rate and higher transmission cost. DAB is more robust with regard to noise and multipath fading for mobile listening, although DAB reception quality degrades rapidly when the signal strength falls below a critical threshold (as is normal for digital broadcasts), whereas FM reception quality degrades slowly with the decreasing signal, providing more effective coverage over a larger area. DAB+ is a \"green\" platform and can bring up to 85 percent energy consumption savings compared to FM broadcasting (but analog tuners are more efficient than digital ones, and DRM+ has been recommended for small scale transmissions).\nSimilar terrestrial digital radio standards are HD Radio, ISDB-Tb, DRM, and the related DMB. Also 5G Broadcast is developing globally for radio and television broadcasting. This system has the potential to enable digital terrestrial radio reception also in smartphones.\nHistory and development.\nEureka-147 project.\nThe DAB standard was initiated as a European research project. It began in the 1980s with the collaboration of the West German (IRT) in and the French \"Centre commun d'\u00e9tudes de t\u00e9l\u00e9vision et t\u00e9l\u00e9communications\" (CCETT). The consortium formed in 1986 and numerous other European broadcasting organisations such as the BBC had also joined. It eventually became a project of Eureka and was named the Eureka-147 DAB Project in 1987, with the stated goal of developing a system that \u201cwould produce improved reception compared to FM\u2026and with the potential to offer additional services such as text and other data, conditional access, enhanced traffic services, and picture transmission\u201d. Efficient bandwidth, low transmitting power, good reception in cars and audio quality comparable to CD, were some of the other goals.\nThe first DAB demonstrations were held in 1988 in Geneva during WARC-88 conference, after which numerous other trials took place throughout several other countries in Europe. There was also a demonstration at the 1991 NAB Show in the USA. The MPEG-1 Audio Layer II (\"MP2\") codec was created as part of this project. DAB was the first standard based on orthogonal frequency-division multiplexing (OFDM) modulation technique, which since then has become one of the most popular transmission schemes for modern wideband digital communication systems.\nA choice of audio codec, modulation and error-correction coding schemes and first trial broadcasts were made in 1990. A significant decision was the assigning of frequencies on the radio spectrum, as it was decided to operate the system on different bands (Band I, Band III and L Band) compared to those used on FM and AM. The protocol specification was finalized in 1992 or 1993 and adopted by the ITU-R standardization body in 1994, the European community in 1995 and by ETSI in 1997. The European DAB Forum (now WorldDAB) was formed in 1995, and the Eureka-147 project itself had \"ended\" and merged into WorldDAB in 1999.\nLaunch and early adoption.\nPilot broadcasts were launched in 1995: the Norwegian Broadcasting Corporation (NRK) launched the first DAB channel in the world on 1 June 1995 (NRK Klassisk), and the BBC and Swedish Radio (SR) launched their first broadcasts later in September in the UK and Sweden respectively while in Germany a pilot broadcast started in Bavaria in October 1995. Commercial stations in the UK started broadcasting in November 1999 as Digital One.\nThe earliest DAB receivers in 1995 were semi-professional units for cars with separate boxes fitted in the boot. They were manufactured by Alpine, Bosch, Grundig, Kenwood, Philips and Sony, designed for evaluation purposes. These were complex systems based on either a DAB channel-decoder chipset from the JESSI (Joint European Sub-micron Silicon Initiative) project, or on general-purpose DSPs. Prototype consumer grade DAB receivers with improved silicons were first shown in 1997, but manufacturers were reluctant to release receivers in Europe partly due to the delay of DAB's launch in Germany. By 1999, most DAB receivers remained expensive car-based black box units and a handful of Hi-Fi home tuners. \nIt took some more time until further advancements in the integrated circuits helped to make DAB more accessible: notably Texas Instruments's DRE200 chip, released in 2001, significantly reduced the cost and size of the boards. This chip finally made portable DAB radios possible, and the first working prototype of a pocket DAB radio was presented by Roke Manor Research, part of Siemens, using a module named GoldCard II designed with Panasonic. Eventually the rise of affordable home DAB receivers, notably beginning with the Pure Evoke in 2002 (which used an IC made by Frontier Silicon, a company that would power many DAB tuners in the future), helped to take off DAB to consumers for the first time. \nHowever, adoption remained generally slow for various reasons such as high receiver costs and limited reception, with the exception of the United Kingdom and Denmark. In the UK, DAB radio receivers were high selling and 10% of households owned a DAB radio as of 2005, partly due to local manufacturers creating affordable receivers. In many other countries, such as Germany, Finland, and Sweden, DAB was unable to take off. By 2006, 500 million people worldwide were in the coverage area of DAB broadcasts. In 2006 there were approximately 1,000 DAB channels in operation worldwide.\nCreation of DAB+.\nThe World DMB Forum (now WorldDAB) instructed its Technical Committee to work on an improved digital radio system. This work led to the creation of DAB+ in 2006. This new standard is based on DAB but uses newer MPEG-4 compression instead of MPEG-2, making it far more efficient and allowing more services to be broadcast without a loss in audio quality. \nThe HE-AAC v2 audio codec (also known as eAAC+) was adopted for DAB+. AAC+ uses a modified discrete cosine transform (MDCT) algorithm. It has also adopted the MPEG Surround audio format and stronger error correction coding in the form of Reed\u2013Solomon coding. DAB+ has been standardised as European Telecommunications Standards Institute (ETSI) TS 102 563.\nAs DAB is not forward compatible with DAB+, older DAB receivers cannot receive DAB+ broadcasts. However, DAB receivers that were capable of receiving the new DAB+ standard after a firmware upgrade were being sold as early as July 2007. Malta was the first country to launch DAB+ broadcasts in Europe in October 2008 and DAB+ broadcasts have since been trialled or launched in more countries. If DAB+ stations launch in established DAB countries, they can transmit alongside existing DAB stations that use the older MPEG-1 Audio Layer II audio format, and most existing DAB stations are expected to continue broadcasting until the vast majority of receivers support DAB+.\nGrowth in 2010s.\nIn such countries where DAB was unsuccessful, efforts were made in later years to \"re-launch\" it using the newer DAB+ standard. it started gaining traction throughout the 2010s and finally took off in countries like France by 2019. DAB+ had launched broadcasts in various countries such as Australia, Czech Republic, Denmark, Germany, Hong Kong (now terminated), Italy, Norway, Poland, Switzerland, Belgium, the United Kingdom and the Netherlands. Its UK launch occurred in January 2016 and the new national network Sound Digital launched with three DAB+ stations. A number of stations, such as Classic FM, have since switched from DAB to DAB+.\nDAB adoption in automobiles became increasingly common during this time, and by 2016 it was standard in most cars sold in the UK, Norway and Switzerland. Since 2021, terrestrial digital radio has been compulsory on cars (not busses and trucks) sold in the European Union (EU) as well as Saudi Arabia.\nAs of 2018, over 68 million devices have been sold worldwide, and over 2,270 DAB services are on air. Malta, Monaco and Kuwait achieved 100% coverage of DAB in 2018.\nDMB and DAB-IP.\nDigital multimedia broadcasting (DMB) and DAB-IP are related standards that were developed for mobile radio and TV, they support MPEG 4 AVC and WMV9 respectively as video codecs. However, a DMB video subchannel can easily be added to any DAB transmission, as it was designed to be carried on a DAB subchannel. DMB broadcasts in South Korea carry conventional MPEG 1 Layer II DAB audio services alongside their DMB video services. As of 2017[ [update]], DMB is currently broadcast in Norway, South Korea, and Thailand. Trials for DAB-IP were held in London in 2006, as \"BT Movio\". It competed with DVB-H and MediaFLO which were also under testing.\nCountries using DAB.\nFifty-five countries provide regular or trial DAB(+) broadcasts. In spectrum management, the bands that are allocated for public DAB services, are abbreviated with T-DAB.\nIn the European Union, the European Electronic Communications Code (EECC) entered into force on 20 December 2018, with transposition into national legislation by Member States required by 21 December 2020. The Directive applies to all EU member states regardless of the status of DAB+ in each country. \nThis means that since the end of 2020, across all EU countries, all radios in new cars must be capable of receiving and reproducing digital terrestrial radio.\" Following this directive, Belgium stopped all sales of analogue radio receivers from 1 January 2023. Thus, consumers are no longer able to purchase AM or FM receivers for domestic use. \"The obligation to incorporate DAB+ for new cars and domestic radio receivers is a nice step ahead in the digitisation of our radio landscape,\" commented , the Flemish media minister.\nFM to DAB(+) radio transition.\nNorway.\nNorway was the first country to announce a complete switch-off of national FM radio stations. The switch-off started on 11 January 2017 and ended on 13 December 2017. The 2017 switch-off did not affect some local and regional radio stations. They can continue to transmit on FM until 2027.\nThe timetable for the closure of FM signals in 2017 were as follows:\nSwitzerland.\nSRG SSR, Switzerland's public-service broadcaster, had shut down its FM transmission infrastructure on 31 December 2024. The corporation concluded that maintaining FM broadcasts along with DAB+ and Internet streaming was no longer cost-effective, as due to widespread adoption of DAB+ the share of the public relying exclusively on FM was under ten percent and decreasing. All other FM broadcasters in the country must shut down or convert to DAB+ by 31 December 2026.\nCountries where FM to DAB(+) radio transition is cancelled/postponed.\nWhilst many countries have expected a shift to digital audio broadcasting, a few have moved in the opposite direction following unsuccessful trials.\nTechnology.\nBands and modes.\nDAB uses a wide-bandwidth broadcast technology and typically spectra have been allocated for it in Band III (174\u2013240\u00a0MHz) and L band (1.452\u20131.492\u00a0GHz), although the scheme allows for operation between 30 and 300 MHz. The US military has reserved L-Band in the USA only, blocking its use for other purposes in America, and the United States has reached an agreement with Canada to restrict L-Band DAB to terrestrial broadcast to avoid interference.\nIn January 2017, an updated DAB specification (2.1.1) removed Modes II, III and IV, leaving only Mode I.\nProtocol stack.\nFrom an OSI model protocol stack viewpoint, the technologies used on DAB inhabit the following layers: the audio codec inhabits the presentation layer. Below that is the data link layer, in charge of statistical time-division multiplexing and frame synchronization. Finally, the physical layer contains the error-correction coding, OFDM modulation, and dealing with the over-the-air transmission and reception of data. Some aspects of these are described below.\nAudio codec.\nDAB initially only used the MPEG-1 Audio Layer II audio codec, which is often referred to as \"MP2\" because of the ubiquitous MP3 (MPEG-1 Audio Layer III).\nThe newer DAB+ standard adopted the LC-AAC and HE-AAC, including its version 2 audio codecs, commonly known as \"AAC\", \"AAC+\" or \"aacPlus\". AAC+ uses a modified discrete cosine transform (MDCT) algorithm, and is approximately three times more efficient than MP2, which means that broadcasters using DAB+ are able to provide far higher audio quality or far more stations than they could with DAB, or a combination of both higher audio quality and more stations.\nOne of the most important decisions regarding the design of a digital radio broadcasting system is the choice of which audio codec to use because the efficiency of the audio codec determines how many radio stations can be carried on a fixed capacity multiplex at a given level of audio quality.\nError-correction coding.\nError-correction coding (ECC) is an important technology for a digital communication system because it determines how robust the reception will be for a given signal strength \u2013 stronger ECC will provide a more robust reception than a weaker form.\nThe old version of DAB uses punctured convolutional coding for its ECC. The coding scheme uses unequal error protection (UEP), which means that parts of the audio bit-stream that are more susceptible to errors causing audible disturbances are provided with more protection (i.e. a lower code rate) and vice versa. However, the UEP scheme used on DAB results in a grey area in between the user experiencing good reception quality and no reception at all, as opposed to the situation with most other wireless digital communication systems that have a sharp \"digital cliff\", where the signal rapidly becomes unusable if the signal strength drops below a certain threshold. When DAB listeners receive a signal in this intermediate strength area they experience a \"burbling\" sound which interrupts the playback of the audio.\nThe DAB+ standard incorporates Reed\u2013Solomon ECC as an \"inner layer\" of coding that is placed around the byte interleaved audio frame but inside the \"outer layer\" of convolutional coding used by the original DAB system, although on DAB+ the convolutional coding uses equal error protection (EEP) rather than UEP since each bit is equally important in DAB+. This combination of Reed\u2013Solomon coding as the inner layer of coding, followed by an outer layer of convolutional coding \u2013 so-called \"concatenated coding\" \u2013 became a popular ECC scheme in the 1990s, and NASA adopted it for its deep-space missions. One slight difference between the concatenated coding used by the DAB+ system and that used on most other systems is that it uses a rectangular byte interleaver rather than Forney interleaving in order to provide a greater interleaver depth, which increases the distance over which error bursts will be spread out in the bit-stream, which in turn will allow the Reed\u2013Solomon error decoder to correct a higher proportion of errors.\nThe ECC used on DAB+ is far stronger than is used on DAB, which, with all else being equal (i.e., if the transmission powers remained the same), would translate into people who currently experience reception difficulties on DAB receiving a much more robust signal with DAB+ transmissions. It also has a far steeper \"digital cliff\", and listening tests have shown that people prefer this when the signal strength is low compared to the shallower digital cliff on DAB.\nModulation.\nImmunity to fading and inter-symbol interference (caused by multipath propagation) is achieved without equalization by means of the OFDM and DQPSK modulation techniques. For details, see the OFDM system comparison table.\nUsing values for Transmission Mode I (TM I), the OFDM modulation consists of 1,536 subcarriers that are transmitted in parallel. The useful part of the OFDM symbol period is 1.0\u00a0ms, which results in the OFDM subcarriers each having a bandwidth of 1\u00a0kHz due to the inverse relationship between these two parameters, and the overall OFDM channel bandwidth is 1.537\u00a0MHz. The OFDM guard interval for TM\u00a0I is 0.246\u00a0ms, which means that the overall OFDM symbol duration is 1.246\u00a0ms. The guard interval duration also determines the maximum separation between transmitters that are part of the same single-frequency network (SFN), which is approximately 74\u00a0km for TM\u00a0I.\nSingle-frequency networks.\nOFDM allows the use of single-frequency networks (SFN), which means that a network of transmitters can provide coverage to a large area \u2013 up to the size of a country \u2013 where all transmitters use the same transmission frequency block. Transmitters that are part of an SFN need to be very accurately synchronised with other transmitters in the network, which requires the transmitters to use very accurate clocks.\nWhen a receiver receives a signal that has been transmitted from the different transmitters that are part of an SFN, the signals from the different transmitters will typically have different delays, but to OFDM they will appear to simply be different multipaths of the same signal. Reception difficulties can arise, however, when the relative delay of multipaths exceeds the OFDM guard interval duration, and there are frequent reports of reception difficulties due to this issue when propagation conditions change, such as when there's high pressure, as signals travel farther than usual, and thus the signals are likely to arrive with a relative delay that is greater than the OFDM guard interval.\nLow power \"gap-filler\" transmitters can be added to an SFN as and when desired in order to improve reception quality, although the way SFNs have been implemented in the UK up to now they have tended to consist of higher power transmitters being installed at main transmitter sites in order to keep costs down.\nBit rates.\nAn ensemble has a maximum bit rate that can be carried, but this depends on which error protection level is used. However, all DAB multiplexes can carry a total of 864 \"capacity units\". The number of capacity units, or CU, that a certain bit-rate level requires depends on the amount of error correction added to the transmission, as described above. In the UK, most services transmit using 'protection level three', which provides an average ECC code rate of approximately , equating to a maximum bit rate per multiplex of 1,184\u00a0kbit/s.\nServices and ensembles.\nVarious different services are embedded into one ensemble (which is also typically called a multiplex). These services can include:\nDAB and AM/FM compared.\nTraditionally, radio programmes were broadcast on different frequencies via AM and FM, and the radio had to be tuned into each frequency as needed. This used up a comparatively large amount of spectrum for a relatively small number of stations, limiting listening choice. DAB is a digital radio broadcasting system that, through the application of multiplexing and compression, combines multiple audio streams onto a relatively narrow band centred on a single broadcast frequency called a DAB ensemble.\nWithin an overall target bit rate for the DAB ensemble, individual stations can be allocated different bit rates. The number of channels within a DAB ensemble can be increased by lowering average bit rates, but at the expense of the quality of streams. Error correction under the DAB standard makes the signal more robust but reduces the total bit rate available for streams.\nFM HD Radio versus DAB.\nDAB broadcasts a single multiplex that is approximately 1.5\u00a0MHz wide (\u22481,184 kilobits per second). That multiplex is then subdivided into multiple digital streams of between 9 and 12 programs. In contrast, FM HD Radio adds its digital carriers to the traditional 270 kilohertz-wide analog channels, with capability of up to 300\u00a0kbit/s per station (pure digital mode). The full bandwidth of the hybrid mode approaches 400\u00a0kHz.\nThe first generation DAB uses the MPEG-1 Audio Layer II (MP2) audio codec, which has less efficient compression than newer codecs. The typical bitrate for DAB stereo programs is only 128\u00a0kbit/s or less and as a result most radio stations on DAB have a lower sound quality than FM, prompting complaints from listeners. As with DAB+ or T-DMB in Europe, FM HD Radio uses a codec based upon the MPEG-4 HE-AAC standard.\nHD Radio is a proprietary system from iBiquity Digital Corporation, a subsidiary of DTS, Inc. since 2015, which is itself owned by Xperi Corporation since 2016. DAB is an open standard deposited at ETSI.\nUse of frequency spectrum and transmitter sites.\nDAB can give substantially higher spectral efficiency, measured in programmes per MHz and per transmitter site, than analogue systems. In many places, this has led to an increase in the number of stations available to listeners, especially outside of the major urban areas. This can be further improved with DAB+ which uses a much more efficient codec, allowing a lower bitrate per channel with little to no loss in quality. If some stations transmit in mono, their bitrate can be reduced compared to stereo broadcasts, further improving the efficiency.\nFor example, analog FM requires 0.2\u00a0MHz per programme. The frequency reuse factor in most countries is approximately 15 for stereo transmissions (with lesser factors for mono FM networks), meaning (in the case of stereo FM) that only one out of 15 transmitter sites can use the same channel frequency without problems with co-channel interference, i.e. cross-talk. Assuming a total availability of 102 FM channels at a bandwidth of 0.2\u00a0MHz over the Band II spectrum of 87.5 to 108.0\u00a0MHz, an average of 102/15 = 6.8 radio channels are possible on each transmitter site (plus lower-power local transmitters causing less interference). This results in a system spectral efficiency of 1 / 15 / (0.2\u00a0MHz) = 0.30 programmes/transmitter/MHz. DAB with 192\u00a0kbit/s codec requires 1.536\u00a0MHz * 192\u00a0kbit/s / 1,136\u00a0kbit/s = 0.26\u00a0MHz per audio programme. The frequency reuse factor for local programmes and multi-frequency broadcasting networks (MFN) is typically 4 or 5, resulting in 1 / 4 / (0.26\u00a0MHz) = 0.96 programmes/transmitter/MHz. This is 3.2 times as efficient as analog FM for local stations. For single frequency network (SFN) transmission, for example of national programmes, the channel re-use factor is 1, resulting in 1/1/0.25\u00a0MHz = 3.85 programmes/transmitter/MHz, which is 12.7 times as efficient as FM for national and regional networks.\nNote the above capacity improvement may not always be achieved at the L-band frequencies, since these are more sensitive to obstacles than the VHF band II frequencies, and may cause shadow fading for hilly terrain and for indoor communication. The number of transmitter sites or the transmission power required for full coverage of a country may be rather high at these frequencies, to avoid the system becoming noise limited rather than limited by co-channel interference.\nSound quality.\nThe original objectives of converting to digital transmission were to enable higher audio fidelity, more stations and more resistance to noise, co-channel interference and multipath than in analogue FM radio. The improved sound quality is achieved by using CRC and FEC technology, which improves the transmission performance of digital signals. However, many countries in implementing DAB on stereo radio stations use compression to such a degree that it produces lower sound quality than that received from FM broadcasts. This is because of the bit rate levels being too low for the MPEG Layer 2 audio codec to provide high fidelity audio quality.\nThe BBC Research &amp; Development department states that at least 192\u00a0kbit/s is necessary for a high fidelity stereo broadcast:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;A value of 256\u00a0kbit/s has been judged to provide a high quality stereo broadcast signal. However, a small reduction, to 224\u00a0kbit/s is often adequate, and in some cases it may be possible to accept a further reduction to 192\u00a0kbit/s, especially if redundancy in the stereo signal is exploited by a process of 'joint stereo' encoding (i.e. some sounds appearing at the centre of the stereo image need not be sent twice). At 192\u00a0kbit/s, it is relatively easy to hear imperfections in critical audio material.\nWhen the BBC reduced the bit-rate of transmission of its classical music station Radio 3 from 192\u00a0kbit/s to 160\u00a0kbit/s in July 2006, the resulting degradation of audio quality prompted a number of complaints to the corporation. The BBC later announced that following this testing of new equipment, it would resume the previous practice of transmitting Radio 3 at 192\u00a0kbit/s whenever there were no other demands on bandwidth. (For comparison, BBC Radio 3 and all other BBC radio stations are streamed online using AAC at 320\u00a0kbit/s, described as 'HD', on BBC Radio iPlayer after a period when it was available at two different bit rates.)\nDespite the above, a survey in 2007 of DAB listeners (including mobile) has shown most find DAB to have equal or better sound quality than FM.\nBy 2019, some stations had upgraded to DAB+ but rather than improving sound quality, they instead reduced it to 32\u00a0kbit/s or 64\u00a0kbit/s, often in mono.\nStrengths and weaknesses.\nBenefits of DAB.\nImproved features for users.\nDAB devices perform band-scans over the entire frequency range, presenting all stations from a single list for the user to select from.\nDAB is capable of providing metadata alongside the audio stream. Metadata allows visual information, text and graphics \u2013 such as the station name and logo, presenter, song title and album artwork \u2013 to be displayed while a station is playing. Radio stations can provide the metadata to augment the listening experience, particularly on car receivers which have large display panels.\nDAB can carry \"radiotext\" (in DAB terminology, \"Dynamic Label Segment\", or DLS) from the station giving real-time information such as song titles, music type and news or traffic updates, of up to 128 characters in length. This is similar to a feature of FM called RDS, which enables a radiotext of up to 64 characters.\nThe DAB transmission contains a local time of day and so a device may use this to automatically correct its internal clock when travelling between time zones and when changing to or from Daylight Saving.\nMore stations.\nDAB is not more bandwidth efficient than analogue measured in programmes per MHz of a specific transmitter (the so-called link spectral efficiency), but it is less susceptible to co-channel interference (cross talk), which makes it possible to reduce the reuse distance, i.e. use the same radio frequency channel more densely. The system spectral efficiency (the average number of radio programmes per MHz and transmitter) is a factor three more efficient than analogue FM for local radio stations. For national and regional radio networks, the efficiency is improved by more than an order of magnitude due to the use of SFNs. In that case, adjacent transmitters use the same frequency.\nIn certain areas \u2013 particularly rural areas \u2013 the introduction of DAB gives radio listeners a greater choice of radio stations. For instance, in Southern Norway, radio listeners experienced an increase in available stations from 6 to 21 when DAB was introduced in November 2006.\nReception quality.\nThe DAB standard integrates features to reduce the negative consequences of multipath fading and signal noise, which afflict existing analogue systems.\nAlso, as DAB transmits digital audio, there is no hiss with a weak signal, which can happen on FM. However, radios in the fringe of a DAB signal can experience a \"bubbling mud\" sound interrupting the audio or the audio cutting out altogether.\nDue to sensitivity to Doppler shift in combination with multipath propagation, DAB reception range (but not audio quality) is reduced when travelling speeds of more than 120 to 200\u00a0km/h, depending on carrier frequency.\nVariable bandwidth.\nMono talk radio, news and weather channels and other non-music programs need significantly less bandwidth than a typical music radio station, which allows DAB to carry these programmes at lower bit rates, leaving more bandwidth to be used for other programs.\nHowever, this led to the situation where some stations are being broadcast in mono; see \"\" for more details.\nTransmission costs.\nDAB transmitters are inevitably more expensive than their FM counterparts. DAB uses higher frequencies than FM and therefore there may be a need to compensate with more transmitters to achieve the same coverage as a single FM transmitter. DAB is commonly transmitted by a different company from the broadcaster who then sells the capacity to a number of radio stations. This shared cost can work out cheaper than operating an individual FM transmitter.\nThis efficiency originates from the ability a DAB network has in broadcasting more channels per transmitter/network. One network can broadcast 6\u201310 channels (with MP2 audio codec) or 10\u201318 channels (with HE AAC codec). Hence, it is thought that the replacement of FM-radios and FM-transmitters with new DAB-radios and DAB-transmitters will not cost any more compared with new FM facilities. It is also argued that the power consumption will be lower for stations transmitted on a single DAB multiplex compared with individual analog transmitters.\nOnce applied, one operator has claimed that DAB transmission is as low as one-nineteenth of the cost of FM transmission.\nDisadvantages of DAB.\nReception quality.\nThe reception quality during the early stage of deployment of DAB was poor even for people who live well within the coverage area. The reason for this is that DAB uses weak error correction coding, so that when there are a lot of errors with the received data not enough of the errors can be corrected and a \"bubbling mud\" sound occurs. In some cases a complete loss of signal can happen. This situation has been improved upon in the newer DAB+ version that uses stronger error correction coding and as additional transmitters are built.\nAs with other digital systems, when the signal is weak or suffers severe interference, it will not work at all. DAB reception may also be a problem for receivers when the wanted signal is adjacent to a stronger one. This was a particular issue for early and low cost receivers.\nAudio quality.\nUp to the mid-2010s, a common complaint by listeners is that broadcasters 'squeeze in' more stations per ensemble than recommended by:\nSignal delay.\nThe nature of a single-frequency network (SFN) is such that the transmitters in a network must broadcast the same signal at the same time. To achieve synchronization, the broadcaster must counter any differences in propagation time incurred by the different methods and distances involved in carrying the signal from the multiplexer to the different transmitters. This is done by applying a delay to the incoming signal at the transmitter based on a timestamp generated at the multiplexer, created taking into account the maximum likely propagation time, with a generous added margin for safety. Delays in the audio encoder and the receiver due to digital processing (e.g. deinterleaving) add to the overall delay perceived by the listener. The signal is delayed, usually by around 1 to 4 seconds and can be considerably longer for DAB+. This has disadvantages:\nTime signals, on the contrary, are not a problem in a well-defined network with a fixed delay. The DAB multiplexer adds the proper offset to the distributed time information. The time information is also independent from the (possibly varying) audio decoding delay in receivers since the time is not embedded inside the audio frames. This means that built in clocks in receivers can be precisely correct.\nTransmission costs.\nDAB can provide savings for networks of several stations. The original development of DAB was driven by national network operators with a number of channels to transmit from multiple sites. However, for individual stations such as small community or local stations which traditionally operate their own FM transmitter on their own building the cost of DAB transmission will be much higher than analog. Operating a DAB transmitter for a single station is not an efficient use of spectrum or power. With that said, this can be solved to some degree by combining multiple local stations in one DAB/DAB+ mux, similar to what is done on DVB-T/DVB-T2 with local TV stations.\nCoverage.\nHousehold receiver penetration rates. As of 2021[ [update]]:\nAlthough FM coverage still exceeds DAB coverage in most countries implementing any kind of DAB services, a number of countries moving to digital switchover have undergone significant DAB network rollouts; as of 2022, the following coverages were given by WorldDAB:\nCompatibility.\nIn 2006 tests began using the much improved HE-AAC codec for DAB+. Hardly any of the receivers made before 2008 support the newer codec, however, making them partially obsolete once DAB+ broadcasts begin and completely obsolete once all MP2 encoded stations are gone. Most new receivers are both DAB and DAB+ compatible; however, the issue is exacerbated by some manufacturers disabling the DAB+ features on otherwise compatible radios to save on licensing fees when sold in countries without current DAB+ broadcasts.\nPower requirements.\nAs DAB requires digital signal processing techniques to convert from the received digitally encoded signal to the analogue audio content, the complexity of the electronic circuitry required to do this is higher. This translates into needing more power to effect this conversion than compared to an analogue FM to audio conversion, meaning that portable receiving equipment will have a much shorter battery life, and require higher power (and hence more bulk). This means that they use more energy than analogue Band II VHF receivers. However, thanks to increased integration (radio-on-chip), DAB receiver power usage has been reduced dramatically, making portable receivers far more usable.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49260", "revid": "44313162", "url": "https://en.wikipedia.org/wiki?curid=49260", "title": "Willy Brandt", "text": "Chancellor of West Germany from 1969 to 1974\nWilly Brandt (; born Herbert Ernst Karl Frahm; 18 December 1913 \u2013 8 October 1992) was a German politician and statesman who was leader of the Social Democratic Party of Germany (SPD) from 1964 to 1987 and concurrently served as the chancellor of West Germany from 1969 to 1974. He was awarded the Nobel Peace Prize in 1971 for his efforts to strengthen cooperation in Western Europe through the EEC and to achieve reconciliation between West Germany and the countries of Eastern Europe. He was the first Social Democratic chancellor since 1930. \nFleeing to Norway and then Sweden during the Nazi regime and working as a left-wing journalist, he took the name Willy Brandt as a pseudonym to avoid detection by Nazi agents, and then formally adopted the name in 1948. Brandt earned initial fame as governing mayor of West Berlin. He served as the foreign minister and as the vice chancellor in Kurt Georg Kiesinger's cabinet, and became chancellor in 1969.\nAs chancellor, he maintained West Germany's close alignment with the United States and focused on strengthening European integration in Western Europe, while launching the new policy of \"Ostpolitik\" aimed at improving relations with Eastern Europe. Brandt was controversial on both the right wing, for his \"Ostpolitik\", and on the left wing, for his support of American policies, including his silence on the Vietnam War that he broke only in 1973, and right-wing authoritarian regimes. The Brandt Report became a recognised measure for describing the general North\u2013South divide in world economics and politics between an affluent North and a poor South. Brandt was also known for his fierce anti-communist policies at the domestic level, culminating in the \"Radikalenerlass\" (Anti-Radical Decree) in 1972.\nIn 1970, while visiting a memorial to the Warsaw Ghetto Uprising crushed by the Germans, Brandt unexpectedly knelt and meditated in silence, a moment remembered as the \"Kniefall von Warschau\".\nBrandt resigned as chancellor in 1974, after G\u00fcnter Guillaume, one of his closest aides, was exposed as an agent of the Stasi, the East German secret service. Brandt died from colon cancer in 1992, aged 78.\nEarly life and World War II.\nWilly Brandt was born Herbert Ernst Karl Frahm in the Free City of L\u00fcbeck (German Empire) on 18 December 1913. His mother was Martha Frahm, a single parent, who worked as a cashier for a department store. His father was a teacher from Hamburg named John Heinrich M\u00f6ller, whom Brandt never met. As his mother worked six days a week, he was mainly brought up by his mother's stepfather, Ludwig Frahm. He joined the \"Socialist Youth\" in 1929 and at age 16 became a full member of the Social Democratic Party (SPD) in 1930 despite the age minimum normally being 18. He also wrote for the \"Volksbote\", a local Social Democrat daily, under editor-in-chief Julius Leber, who would have a \"decisive influence\" on him.\nHe, along with half the youth-wing of the L\u00fcbeck SPD, left the party to join the more left wing Socialist Workers Party (SAP) in October 1931, which was allied to the POUM in Spain and, more significant to Brandt, had close ties with the Norwegian Labour Party. His break with Leber and the SPD lost him promised financial support for university studies and his job at the \"Volksbote\". After passing his \"Abitur\" in 1932 at \"Johanneum zu L\u00fcbeck\", he took work at the shipbroker and ship's agent F.H. Bertling. In 1933 he left Germany for Norway to escape Nazi persecution. It was at this time that he adopted the pseudonym Willy Brandt to avoid detection by Nazi agents. In 1934, he took part in the founding of the International Bureau of Revolutionary Youth Organizations, and was elected to its secretariat. Willy Brandt became one of Wilhelm Reich's subjects for his experiments on the electrophysiology of pleasure and anxiety.\nBrandt was in Germany from September to December 1936, disguised as a Norwegian student named Gunnar Gaasland. The real Gunnar Gaasland was married to Gertrud Meyer from L\u00fcbeck in a marriage of convenience to protect her from deportation. Meyer had joined Brandt in Norway in July 1933. In 1937, during the Spanish Civil War, Brandt worked in Spain as a journalist. In 1938, the German government revoked his citizenship, so he applied for Norwegian citizenship. In 1940, he was arrested in Norway by occupying German forces, but his real identity was not uncovered as he wore a Norwegian uniform. Upon his release, he escaped to neutral Sweden. In August 1940, he became a Norwegian citizen, receiving his passport from the Norwegian legation in Stockholm, where he lived until the end of the war. He lectured in Sweden on 1 December 1940 at Bommersvik College about problems experienced by the social democrats in Nazi Germany and the occupied countries at the start of the Second World War. In exile in Norway and Sweden, he learned Norwegian and Swedish. He spoke Norwegian fluently, and retained a close relationship with Norway.\nIn late 1946, Brandt returned to Berlin, working for the Norwegian government. In 1948, he re-joined the SPD and became a German citizen again, formally adopting the pseudonym Willy Brandt as his legal name. In 2021, it became known that Brandt served as a paid informant for the US Counterintelligence Corps from 1948 to 1952. He supplied reports on circumstances in the GDR, including the situation of East German authorities and industries, as well as Soviet troops. According to Thomas Boghardt, Brandt and SPD man received 200,000 German Mark from the Americans in 1950 for promoting his political career, after both had met with the Americans at the German CIA headquarters in Frankfurt. Both were sworn to \"secrecy\". The Americans wanted to strengthen the SPD over the Communists in Berlin. Over the next two years, Hirschfeld received a further 106,000 Marks. Even after the end of his informant activities, he is said to have remained in contact with US intelligence.\nEarly political career.\nBrandt was elected to the West German Bundestag (the federal parliament) in the 1949 West German federal election as a SPD delegate from West Berlin, serving there until 1957. Concurrently, he was elected as an SPD representative to the Abgeordnetenhaus (the state-level parliament) of West Berlin in the 1950 West Berlin state election, and served there through 1971. In the 1969 West German federal election he was again elected to the Bundestag, but as a delegate from North Rhine-Westphalia, and remained in the Bundestag as a delegate from that state until his death in 1992.\nIn 1950, Brandt, while a member of the Bundestag and the editor-in-chief of the \"Berliner Stadtblatt\", received a secret payment of about 170,000 Deutsche Mark from the U.S. government ().\nFrom October 1957 to 1966, Willy Brandt served as Governing Mayor of West Berlin, during a period of increasing tension in East\u2013West relations that led to the construction of the Berlin Wall. In his first year as mayor of Berlin, he also served as the president of the Bundesrat in Bonn. He was an outspoken critic of Soviet repression of the 1956 Hungarian Uprising and of Nikita Khrushchev's 1958 proposal that Berlin receive the status of a \"free city\". He was supported by the influential publisher Axel Springer.\nAs mayor of West Berlin, Brandt accomplished much in the way of urban development. New hotels, office-blocks, and flats were constructed, while both Schloss Charlottenburg and the Reichstag building were restored. Sections of the \"Stadtring\" Bundesautobahn 100 inner city motorway were opened, while a major housing programme was carried out, with roughly 20,000 new dwellings built each year during his time in office.\nAt the start of 1961, U.S. President John F. Kennedy saw Brandt as a figure destined for high office in West Germany and was hoping he would replace Konrad Adenauer as chancellor following elections later that year. Kennedy made this preference clear by inviting Brandt, the West German opposition leader, to an official meeting at the White House a month before meeting with Adenauer, the country's leader. For the president, Brandt stood for Germany's future and for overcoming traditional Cold War thinking.\nThe diplomatic snub strained relations between Kennedy and Adenauer further during an especially tense time for Berlin. However, following the building of the Berlin Wall in August 1961, Brandt was disappointed and angry with Kennedy. Speaking in Berlin three days later, Brandt criticized Kennedy, asserting \"Berlin expects more than words. It expects political action.\" He also wrote Kennedy a highly critical public letter in which he warned that the development was liable \"to arouse doubts about the ability of the three Allied Powers to react and their determination\" and he called the situation \"a state of accomplished extortion\". Kennedy was furious, but managed to defuse the tension by sending his vice president, Lyndon B. Johnson, to Berlin. In June 1963, Brandt figured prominently in the staging of Kennedy's triumphant visit to West Berlin.\nBrandt became the chairman of the SPD in 1964, Brandt was the SPD candidate for the chancellorship in 1961, but he lost to Konrad Adenauer's conservative Christian Democratic Union of Germany (CDU). In 1965, Brandt ran again, but lost to the popular Ludwig Erhard. Erhard's government was short-lived, however, and in 1966 a grand coalition between the SPD and CDU was formed, with Brandt serving as foreign minister and as the 5th Vice Chancellor of Germany.\nChancellor.\nIn the 1969 elections, again with Brandt as the leading candidate, the SPD became stronger, and after three weeks of negotiations, the SPD formed a coalition government with the smaller Free Democratic Party of Germany (FDP). Brandt was elected chancellor.\nForeign policy.\nAs chancellor, Brandt developed his \"(Neue) Ostpolitik\" (\"new eastern policy\") by stages. He was active in creating a degree of rapprochement with East Germany, and also in improving relations with the Soviet Union, Poland, Czechoslovakia, and other Eastern Bloc (communist) countries.\nBrandt introduced his Ostpolitik gradually starting in 1967 with the establishment of diplomatic relations with Romania and making a trade agreement with Czechoslovakia. In 1968, he restored diplomatic relations with Yugoslavia. However, the August 1968, Kremlin-controlled invasion of Czechoslovakia by the Warsaw Pact was a profound disappointment. He condemned the invasion and put Ostpolitik on hold while he negotiated a coalition with the Free Democrats. In late 1969, he indicated his readiness to meet with East German leadership on the basis of equality, without preconditions. He also expressed an eagerness to meet with the USSR and Poland to resolve frontier questions that had remained unsettled since 1945. He met with the East German premier Willi Stoph in 1970.\nBrandt made a six-point proposal that would involve two separate German states that respected each other's territorial integrity and settle disputes peacefully. They would cooperate as neighbours and the rights of the Four Powers in Berlin would be respected by both of them, and finally, the situation around Berlin would be improved. No agreements were reached at first, but talks continued. In 1970, he signed a treaty with the Soviet Union, which normalised relations and recognized existing national boundaries. The treaty with Poland in December 1970 accepted the current boundaries, which had long been in dispute. During a visit to a monument to the German occupation-era Warsaw Ghetto Uprising, he unexpectedly, and apparently spontaneously, knelt (Kniefall von Warschau), honoring the victims. This was met with a strong positive reaction worldwide but was highly controversial among the German public at the time.\nThe Berlin question was settled in 1971 to West Germany's satisfaction. The crowning step came with the Basic Treaty with East Germany. The status quo was legitimized, relations were formalized on the basis of equality, and both Germanies joined the United Nations in 1973. Brandt became the first German chancellor to address the United Nations General Assembly.\n\"Time\" magazine in the U.S. named Brandt as its Man of the Year for 1970, stating, \"Willy Brandt is in effect seeking to end World War II by bringing about a fresh relationship between East and West. He is trying to accept the real situation in Europe, which has lasted for 25 years, but he is also trying to bring about a new reality in his bold approach to the Soviet Union and the East Bloc.\" President Richard Nixon also was pushing d\u00e9tente on behalf of the United States. The Nixon policies amounted to co-opting Brandt's Ostpolitik.\nIn 1971, Brandt received the Nobel Peace Prize for his work in improving relations with East Germany, Poland, and the Soviet Union. Brandt negotiated a peace treaty with Poland, and agreements on the boundaries between the two countries, signifying the official and long-delayed end of World War II. Brandt negotiated parallel treaties and agreements with Czechoslovakia.\nIn West Germany, Brandt's \"Neue Ostpolitik\" was extremely controversial, dividing the populace into two camps. One camp embraced all of the conservative parties, and most notably those West German residents and their families who had been driven west (\"die Heimatvertriebenen\") by Stalinist ethnic cleansing from Historical Eastern Germany, especially the part that was given to Poland as a consequence of the end of the war; western Czechoslovakia (the Sudetenland); and the rest of Eastern Europe, such as in Romania. These groups of displaced Germans and their descendants loudly voiced their opposition to Brandt's policy, calling it \"illegal\" and \"high treason\".\nA different camp supported and encouraged Brandt's \"Neue Ostpolitik\" as aiming at \"change through rapprochement\" (\"Wandel durch Ann\u00e4herung\"), encouraging change through a policy of engagement with the (communist) Eastern Bloc, rather than trying to isolate these countries diplomatically and commercially. Brandt's supporters claim that the policy did help to break down the Eastern Bloc's \"siege mentality\" and also helped to increase its awareness of the contradictions in its brand of socialism/communism, which \u2013 together with other events \u2013 eventually led to the downfall of Eastern European communism.\nDomestic policies.\nBrandt's popularity.\nBrandt's predecessor as chancellor, Kurt Georg Kiesinger, had been a member of the Nazi party, and was a more old-fashioned conservative-liberal intellectual. Brandt, having fought the Nazis and having faced down communist Eastern Germany during several crises while he was the mayor of Berlin, became a controversial, but credible, figure in several different factions. As the Minister of Foreign Affairs in Kiesinger's grand coalition cabinet, Brandt helped to gain further international approval for West Germany, and he laid the foundation stones for his future \"Neue Ostpolitik\". There was a wide public-opinion gap between Kiesinger and Brandt in the West German polls.\nBoth men had come to their own terms with the new baby boomer lifestyles. Kiesinger considered them to be \"a shameful crowd of long-haired drop-outs who needed a bath and someone to discipline them\". On the other hand, Brandt needed a while to get into contact with, and to earn credibility among, the \"Ausserparlamentarische Opposition\" (APO) (\"the extra-parliamentary opposition\"). The students questioned West German society in general, seeking social, legal, and political reforms. The unrest led to a renaissance of right-wing parties in some of the Bundeslands' (German states under the Bundesrepublik) Parliaments.\nBrandt, however, represented a figure of change, and he followed a course of social, legal, and political reforms. In 1969, Brandt gained a small majority by forming a coalition with the FDP. In his first speech before the Bundestag as the chancellor, Brandt set forth his political course of reforms ending the speech with his famous words, \"Wir wollen mehr Demokratie wagen\" (literally: \"We want to dare more democracy\", or more figuratively, \"We want to take a chance on more Democracy\"). This speech made Brandt, as well as the Social Democratic Party, popular among most of the students and other young West German baby-boomers who dreamed of a country that would be more open and more colorful than the frugal and still somewhat-authoritarian Bundesrepublik that had been built after World War II. However, Brandt's \"Neue Ostpolitik\" lost him a large part of the German refugee voters from East Germany, who had been significantly pro-SPD in the postwar years.\nChancellor of domestic reform.\nAlthough Brandt is perhaps best known for his achievements in foreign policy, his government oversaw the implementation of a broad range of social reforms, and was known as a \"Kanzler der inneren Reformen\" ('Chancellor of domestic reform'). According to the historian David Childs, \"Brandt was anxious that his government should be a reforming administration and a number of reforms were embarked upon\". Within a few years, the education budget rose from 16 billion to 50 billion DM, while one out of every three DM spent by the new government was devoted to welfare purposes. As noted by the journalist and historian Marion D\u00f6nhoff,\n\"People were seized by a completely new feeling about life. A mania for large-scale reforms spread like wildfire, affecting schools, universities, the administration, and family legislation. In the autumn of 1970 Hans-J\u00fcrgen Wischnewski of the SPD declared, 'Every week more than three plans for reform come up for decision in cabinet and in the Assembly.'\"\nFederal spending rose significantly under Brandt; increasing by an average of 12% per year between 1970 and 1974, with most of the additional spending allocated to transport, education and welfare. During Brandt's time in office, social expenditure rose from one quarter to a third of GDP.\nAccording to Helmut Schmidt, Willy Brandt's domestic reform programme had accomplished more than any previous programme for a comparable period. Levels of social expenditure were increased, with more funds allocated towards housing, transportation, schools, and communication, and substantial federal benefits were provided for farmers. Various measures were introduced to extend health care coverage, while federal aid to sports organisations was increased. A number of social reforms were instituted whilst the welfare state was significantly expanded (with total public spending on social programs nearly doubling between 1969 and 1975), with health, housing, and social welfare legislation bringing about welcome improvements, and by the end of the Brandt Chancellorship West Germany had one of the most advanced systems of welfare in the world.\nSubstantial increases were made in social security benefits such as injury and sickness benefits, pensions, unemployment benefits, housing allowances, basic subsistence aid allowances, and family allowances and living allowances. In the government's first budget, sickness benefits were increased by 9.3%, pensions for war widows by 25%, pensions for the war wounded by 16%, and retirement pensions by 5%. Numerically, pensions went up by 6.4% (1970), 5.5% (1971), 9.5% (1972), 11.4% (1973), and 11.2% (1974). Adjusted for changes in the annual price index, pensions went up in real terms by 3.1% (1970), 0.3% (1971), 3.9% (1972), 4.4% (1973), and 4.2% (1974). Between 1972 and 1974, the purchasing power of pensioners went up by 19%. In 1970, war pensions were increased by 16%. War victim's pensions went up by 5.5% in January 1971, and by 6.3% in January 1972. By 1972, war pensions for orphans and parents had gone up by around 40%, and for widows by around 50%. Between 1970 and 1972, the \"Landabgaberente\" (land transfer pension) went up by 55%. Between 1969 and 1974, the average real standard rate of income support rose (in 1991 prices) from around 300 DM to around 400 DM. Between 1970 and 1974, unemployment benefits rose from around 300 euros to around 400 euros per month, and unemployment assistance from just under 200 euros per month to just under 400 euros per month. In 2001 prices, the average standard social assistance benefit level rose from around 200 euros per month in 1969 to over 250 euros per month in 1974. During most of Brandt's years as chancellor, the majority of benefits increased as a percentage of average net earnings.\nIn 1970, seagoing pilots became retrospectively insurable and gained full social security as members of the Non-Manual Workers Insurance Institute. That same year, a special regulation came into force for District Master Chimney Sweeps, making them fully insurable under the Craftsman's Insurance Scheme. An increase was made in tax-free allowances for children, which enabled 1,000,000 families to claim an allowance for the second child, compared to 300,000 families previously. The Second Modification and Supplementation Law (1970) increased the allowance for the third child from DM 50 to DM 60, raised the income-limit for the second child allowance from DM 7,800 to DM 13,200; subsequently increased to DM 15,000 by the third modification law (December 1971), DM 16,800 by the fourth modification law (November 1973), and to DM 18,360 by the fifth modification law (December 1973). A flexible retirement age after 62 years was introduced (1972) for invalids and disabled persons, and social assistance was extended to those who previously had to be helped by their relatives. From 1971, special subventions were provided to enable young farmers to quit farming \"and facilitate their entry into the non-agricultural pension system by means of back payments\".\nSocial assistance.\nThe Third Modification Law (1974) extended individual entitlements to social assistance by means of higher-income limits compatible with the receipt of benefits and lowered age limits for certain special benefits. Rehabilitation measures were also extended, child supplements were expressed as percentages of standard amounts and were thus indexed to their changes, and grandparents of recipients were exempted from potential liability to reimburse expenditure of social assistance carrier. The Third Social Welfare Amendment Act (1974) brought considerable improvements for the disabled, those in need of care, and older persons, and a new fund of 100 million marks for disabled children was established.\nAllowances for retraining and advanced training and for refugees from East Germany were also increased, together with federal grants for sport. In addition, increases were made in the pensions of 2.5 million war victims. Following a sudden increase in the price of oil, a law was passed in December 1973 granting recipients of social assistance and housing allowances a single heating-oil allowance (a procedure repeated in the winter of 1979 during the Schmidt Administration). Improvements and automatic adjustments of maintenance allowances for participants in vocational training measures were also carried out, and increased allowances were provided for training and retraining, together with special allowances for refugees from East Germany.\nThere was determined, by statutory regulation issued in February 1970, the category of persons most seriously disabled \"to whom, with regard to maintenance aid, an increased demand (50% of the appropriate rate) is being conceded, and, within the scope of relief in special living conditions: a higher rate of nursing aid\". In 1971, the retirement age for miners was lowered to 50. An April 1972 law providing for \"promotion of social aid services\" aimed to remedy, through various beneficial measures (particularly in the field of national insurance and working conditions), the staff-shortage suffered by social establishments in their medico-social, educational and other work. A bill to harmonize re-education benefits and another bill relating to severely disabled persons became law in May and September 1972 respectively. In 1972, winter payments for construction workers were introduced.\nTo assist family planning and marriage and family guidance, the government allocated DM 2,232,000 in 1973 for the payment and for the basic and further training of staff. A special effort was also made in 1973 to organize the recreation of disabled persons, with a holiday guide for the disabled issued with the aid of the Federal Ministry of Family and Youth Affairs and Health in order to help them find suitable holiday accommodation for themselves and their families. From 1972 to 1973, the total amount of individual aids granted by Guarantee Fund for the integration of young immigrants increased from 17 million DM to 26 million DM. Under a law passed in April 1974, the protection hitherto granted to the victims of war or industrial accidents for the purpose of their occupational and social reintegration was extended to all disabled persons, whatever the cause of their disability, provided that their capacity to work had been reduced by at least 50%.\nHealth care.\nIn the field of health care, various measures were introduced to improve the quality and availability of health care provision. Free hospital care was introduced for 9 million recipients of social relief, while a contributory medical service for 23 million panel patients was introduced. Pensioners were exempted from paying a 2% health insurance contribution, while improvements in health insurance provision were carried out, as characterised by an expanded sickness insurance scheme, with the inclusion of preventative treatment. The income limit for compulsory sickness insurance was indexed to changes in the wage level (1970), and the right to medical cancer screening for 23.5 million people was introduced. In January 1971, the reduction of sickness allowance in case of hospitalisation was discontinued. That same year, compulsory health insurance was extended to the self-employed. In 1970, the government included nonmedical psychotherapists and psychoanalysts in the national health insurance program.\nPupils, students and children in kindergartens were incorporated into the accident insurance scheme, which benefited 11 million children. Free medical checkups were introduced that same year, while the Farmers' Sickness Insurance Law (1972) introduced compulsory sickness insurance for independent farmers, family workers in agriculture, and pensioners under the farmers' pension scheme, medical benefits for all covered groups, and cash benefits for family workers under compulsory coverage for pension insurance. Participation in employer's health insurance was extended to four million employees. A Development Law of December 1970 made it possible for all employees to voluntarily become members of the statutory sickness insurance. The level of income for compulsory sickness insurance was indexed to 75% of the respective assessment level for pension insurance, while voluntarily insured employees were granted a claim to an allowance towards their sickness insurance from their employer. This law also introduced a new type of sickness insurance benefit, namely facilities for the early diagnosis of disease. Apart from the discretionary service of disease prevention which had existed since 1923, insured persons now had a right in certain circumstances to medical examinations aimed at the early diagnosis of disease. According to one study, this marked a change in the concept of sickness insurance: it now aimed at securing good health.\nThe Hospital Financing Law (1972) secured the supply of hospitals and reduced the cost of hospital care, \"defined the financing of hospital investment as a public responsibility, single states to issue plans for hospital development, and the federal government to bear the cost of hospital investment covered in the plans, rates for hospital care thus based on running costs alone, hospitals to ensure that public subsidies together with insurance fund payments for patients cover total costs\". The Benefit Improvement Law (1973) made entitlement to hospital care legally binding (entitlements already enjoyed in practice), abolished time limits for hospital care, introduced entitlement to household assistance under specific conditions, and also introduced entitlement to leave of absence from work and cash benefits in the event of a child's illness. In 1971, to encourage the growth of registered family holiday centres, the Federal Government granted subsidies for the building and appointing of 28 of these centres at a total cost of 8 million DM. Free preliminary investigations were introduced for 2.5 million children up until the age of 4 for the early detection and correction of developmental disorders, and health research was expanded. Federal grants were increased, especially for the Cancer Research Centre in Heidelberg, while a Federal Institute for Sport Science was set up, together with the Institute for Social Medicine and Epidemiology in Berlin. In addition, funding for new rehabilitation facilities was increased.\nRetirement.\nThe Pension Reform Law (1972) guaranteed all retirees a minimum pension regardless of their contributions and institutionalized the norm that the standard pension (of average earners with forty years of contributions) should not fall below 50% of current gross earnings. The 1972 pension reforms improved eligibility conditions and benefits for nearly every subgroup of the West German population. The income replacement rate for employees who made full contributions was raised to 70% of average earnings. The reform also replaced 65 as the mandatory retirement age with a \"retirement window\" ranging between 63 and 65 for employees who had worked for at least thirty-five years. Employees who qualified as disabled and had worked for at least thirty-five years were extended a more generous retirement window, which ranged between the ages of 60 and 62. Women who had worked for at least fifteen years (ten of which had to be after the age of 40) and the long-term unemployed were also granted the same retirement window as the disabled. In addition, there were no benefit reductions for employees who had decided to retire earlier than the age of 65. The legislation also changed the way in which pensions were calculated for low-income earners who had been covered for twenty-five or more years. If the pension benefit fell below a specified level, then such workers were allowed to substitute a wage figure of 75% of the average wage during this period, thus creating something like a minimum wage benefit. According to one study, the 1972 pension reform \"enhanced\" the reduction of poverty in old age.\nVoluntary retirement at 63 with no deductions in the level of benefits was introduced, together with the index-linking of war victims' pensions to wage increases. Guaranteed minimum pension benefits for all West Germans were introduced, along with automatic pension increases for war widows (1970). Fixed minimum rates for women in receipt of very low pensions were also introduced, together with equal treatment for war widows. Improvements in pension provision were made for women and the self-employed, a new minimum pension for workers with at least twenty-five years' insurance was introduced, faster pension indexation was implemented, with the annual adjustment of pensions brought forward by six months, and the Seventh Modification Law (1973) linked the indexation of farmers' pensions to the indexation of the general pension insurance scheme.\nA new pension for \"severely handicapped\" persons was introduced in 1972, along with occupational injury annuities and a special pension for long-standing insurant from the age of 63 and a pension due to \"limited earning capacity\" from the age of 62. In addition, a special pension benefit was introduced for workers aged 60 and above after unemployment. Under the Severely Handicapped Persons Act of April 1974, a seriously disabled person could retire early on an old age pension at the age of 62 years, provided that he \"complied with the other provisions of the legislation on pension insurance\".\nEducation.\nIn education, the Brandt Administration sought to widen educational opportunities for all West Germans. The government presided over an increase in the number of teachers, generous public stipends were introduced for students to cover their living costs, and West German universities were converted from elite schools into mass institutions. The school leaving age was raised to 16, and spending on research and education was increased by nearly 300% between 1970 and 1974. Working through a planning committee set up for the \"joint task\" of university development, the Federal Government started to make investment costs in 1971. Fees for higher or further education were abolished, while a considerable increase in the number of higher education institutions took place. A much-needed school and college construction program was carried out, together with the introduction of postgraduate support for highly qualified graduates, providing them with the opportunity to earn their doctorates or undertake research studies. A law on individual promotion of vocational training came into force in October 1971, which provided for financial grants for attendance at further general or technical teaching establishments from the second year of studies at higher technical schools, academies and higher education establishments, training centres of second degree, or certain courses of television teaching. Grants were also made in certain cases for attendance at training centres located outside the Federal Republic.\nThe education budget was doubled from 3% to 6%, while an expansion of secondary education took place. The number of university students went up from 100,000 to 650,000, 30,000 more places were created in the schools, and an additional 1 billion marks were allocated for new school buildings. In addition, the provision of scholarships was expanded, with the 1970 programme providing for, in the words of one observer, \"5,000 new scholarships for graduates, and double that number were being awarded three years later\". Grants were introduced for pupils from lower income groups to stay on at school, together with grants for those going into any kind of higher or further education. Increases were also made in educational allowances, as well as spending on science. In 1972, the government allocated 2.1 million DM in grants to promote marriage and family education. Under the Approbationsordnung (medical education profession act) of 1970, the subject of psychosomatic medicine and psychotherapy at German universities became a compulsory subject for medical students, and that same year education of clinical and biomedical engineers was introduced. The Brandt Administration also introduced enabling legislation for the introduction of comprehensives, but left it to the Lander \"to introduce them at their discretion\". While the more left-wing Lander \"rapidly began to do so\", other Lander found \"all sorts of pretexts for delaying the scheme\". By the mid-1980s, Berlin had 25 comprehensives while Bavaria only had 1, and in most Lander comprehensives were still viewed as \"merely experimental\".\nHousing and urban development.\nIn the field of housing, various measures were carried out to benefit householders, such as improving the rights of tenants and increasing rental assistance. According to the Rent Subsidies Act (Wohngeldgesetz) of 1970, \"low-income tenants and owners of accommodations are supported with rents and burdens subsidies\". The determination of the income of families taken into consideration for housing allowances was simplified, and increased levels of protection and support for low-income tenants and householders were introduced, which led to a drop in the number of eviction notices. By 1974, three times as much was paid out in rent subsidies as in 1969, and nearly one and a half million households received rental assistance. Increases were made in public housing subsidies, as characterised by a 36% increase in the social housing budget in 1970 and by the introduction of a programme for the construction of 200,000 public housing units (1971). From 1970 to 1971, an 18.1% increase in building permits for social housing units was made. Other reforms aimed at improving tenants' rights included protection against conversion of rental housing into condominiums, the prohibition of the misappropriation of living space, new regulation of the apartment broker system, and a fee scale for engineers and architects. In addition, the income limits for eligibility for social housing were raised and adapted in order of general income trends.\nA loose form of rent regulation was introduced under the name of \"Vergleichmieten\" (comparable rents), together with the provision of \"for family-friendly housing\" freight or rent subsidies to owners of apartments or houses whose ceiling had been adapted to increased expenses or incomes (1970). In addition, a law for the creation of property for workers was passed, under which a married worker would normally keep up to 95% of his pay, and graded tax remission for married wage-earners applied up to a wage of 48,000 marks, which indicated the economic prosperity of West Germany at that time. The Town Planning Act (1971) encouraged the preservation of historical heritage and helped open up the way to the future of many German cities, while the Urban Renewal Act (1971) helped the states to restore their inner cities and to develop new neighbourhoods. In addition, the Guidelines of December 1972 on the usage of federal funds in assisting social housing construction laid down that a certain standard needed to be observed when building homes for severely disabled persons.\nThe Second Housing Allowance Law of December 1970 simplified the administration of housing allowances and extended entitlements, increased the income limit to 9,600 DM per year plus 2,400 DM for each family member, raised the general deduction on income to determine reckonable income from 15% to 20%, allowance rates listed in tables replacing complicated calculation procedure based on \"bearable rent burdens\". The Housing Construction Modification Law (1971) increased the income-limit for access to low rent apartments under the social housing programme from 9,000 DM to 12,000 DM per annum plus 3,000 DM (instead of 2,400) for each family member. The law also introduced special subsidies to reduce the debt burden for builders not surpassing the regular income-limit by more than 40%. Under a 1973 law, the limits were increased to 1,000 DM plus 9,000 DM and 4,200 DM for additional family members. The Rent Improvement Law (1971) strengthened the position of tenants. Under this legislation, notice was to be ruled illegal \"where appropriate substitute accommodation not available; landlords obliged to specify reasons for notice\", whilst the Eviction Protection Law (1971) established tenant protection against rent rises and notice. The notice was only lawful if in the \"justified interest of the landlord\". Under this law, higher rents were not recognised as \"justified interest\". The Second Eviction Protection Law (1972) made the tenant protection introduced under the Eviction Protection Law of 1971 permanent. Under this new law, the notice was only lawful where the landlord proved a justified personal interest in the apartment. In addition, rent increases were only lawful if they were not above normal comparable rents in the same area.\nDirectives on the housing of foreign workers came into force in April 1971. These directives imposed certain requirements for space, hygiene, safety, and amenities in the accommodations offered by employers. That same year, the Federal Government granted a sum of 17 million DM to the L\u00e4nder for the improvement and modernization of housing built before 21 June 1948. In addition, according to a 1971 regulation of the Board of the Federal Labour Office, \"construction of workers' hostels qualified for government financial support under certain conditions\". The \"German Council for town development\", which was set up by virtue of Article 89 of a law to foster urban building, was partly aimed at planning a favourable environment for families (such as the provision of playgrounds). In 1971, the Federal Labour Office made available DM 425 million in the form of loans to provide 157,293 beds in 2,494 hostels. A year later, the Federal Government (Bund), the Lander and the Federal Labour Office promoted the construction of dwellings for migrant workers. They set aside 10 million DM for this purpose, which allowed the financing of 1650 family dwellings that year.\nDevelopment measures were begun in 1972 with federal financial aid granted to the Lander for improvement measures relating to towns and villages, and in the 1972 budget, DM 50 million was earmarked, i.e. a third of the total cost of some 300 schemes. A council for urban development was formed in May 1972 with the purpose of promoting future work and measures in the field of urban renovation. In 1973, the government provided assistance of DM 28 million for the modernisation of old dwellings. New rules were introduced regarding improvements in the law relating to rented property, and control of the rise in rents and protection against cancellation of leases also safeguarded the rights of migrant workers in the sphere of housing. A law of July 1973 fixed the fundamental and minimum requirements regarding workers' dwellings, mainly concerning space, ventilation and lighting, protection against damp, heat and noise, power and heating facilities and sanitary installations.\nCivil, family, and animal rights.\nRegarding civil rights, the Brandt Administration introduced a broad range of socially liberal reforms aimed at making West Germany a more open society. Greater legal rights for women were introduced, as exemplified by the standardisation of pensions, divorce laws, regulations governing the use of surnames, and the introduction of measures to bring more women into politics. The voting age was lowered from 21 to 18, the age of eligibility for political office was lowered to 21, and the age of majority was lowered to 18 in March 1974. The Third Law for the Liberalization of the Penal Code (1970) liberalised \"the right to political demonstration\", while equal rights were granted to illegitimate children that same year. A 1971 amendment to a federal civil service reform bill enabled fathers to apply for part-time civil service work. In 1971, corporal punishment was banned in schools, and that same year a new Highway Code was introduced. In 1973, a measure was introduced that facilitated the adoption of young children by reducing the minimum age for adoptive parents from 35 to 25.\nA women's policy machinery at the national level was established in 1972 while amnesty was guaranteed in minor offences connected with demonstrations. From 1970 onwards, parents as well as landlords were no longer legally prohibited \"to give or rent rooms or flats to unmarried couples or to allow them to stay overnight\". In October 1972, the legal aid system was improved with the compensation paid to private lawyers for legal services to the poor increased. The Bausparkassen Act of 1972 placed all bausparkassen (building societies) under the supervision of the Federal Banking Supervisory Office from January 1974 onwards, and confined them \"to the contract saving business and related activities\". The Animal Protection Act, passed in 1972, introduced various safeguards for animals such as not permitting the causing of pain, injury, or suffering to an animal without justification, and limiting experiments to the minimum number of animals necessary. In 1971, rules were introduced making it possible for former guestworkers \"to receive an unlimited residence permit after a five-year stay\".\nMilitary.\nA number of reforms were also carried out to the armed forces, as characterised by a reduction in basic military training from 18 to 15 months, a reorganisation of education and training, and personnel and procurement procedures. Education for the troops was improved, a personnel reshuffle of top management in the Bundeswehr was carried out, academic education was mandated for officers beyond their basic military training, and a new recruiting policy for Bundeswehr personnel was introduced with the intention of building an army that reflected West Germany's pluralistic society. Defence Minister Helmut Schmidt led the development of the first Joint Service Regulation ZDv 10/1 (Assistance for Innere Fuehrung, classified: restricted), which revitalized the concept of Innere Fuehrung while also affirming the value of the \"citizen in uniform\". According to one study, as a result of this reform, \"a strong civil mindset displaced the formerly dominant military mindset\", and forced the Bundeswehr's elder generation to accept a new type of soldier envisioned by Schmidt. In addition, the Federal Cost of Moving Act increased the relocation allowance (with effect from 1 November 1973), with the basic allowances raised by DM 50 and DM 100 respectively, while extra allowances for families were raised to a uniform amount of 125 DM.\nIn 1970, the Armed Forces Vocational Schools and the Vocational Advancement Organization extended their services for the first time to conscripts, \"so far as military duty permitted\". New enlistment bonuses were authorized and previous bonus schemes were improved, and new pay regulations were introduced that improved the financial situation of military personnel and civil servants. In July 1973, the 3rd Amendment to the Civilian Service Act came into force; \"a prerequisite for the creation of additional civilian service places for recognized conscientious objectors\". The amendment provided that men recognized as conscientious objectors while performing military service should immediately be transferred to a civilian service assignment. The maximum amount for servicemen enlisting for at least 12 years was increased from DM 6,000 to DM 9,000, and from October 1971 onwards, long-term personnel were paid grants towards the cost 'of attending educational institutes of the \"second educational route\" or participating in state-recognized general education courses provided by private correspondence schools and the \"television college\"'. In 1972, two Bundeswehr universities were established; a reform which, according to one historian, \"fought against the closed nature of the military and guaranteed that officers would be better able to successfully interact with the civilian world\". From April 1973, the general maintenance payments under the Law amending the Maintenance Security Act and the Workplace Protection Act were increased, while increases were also made in the special allowance (Christmas bonus) for conscripts, together with the dismissal allowance. The expense allowance for troops on duty-related absence from place of employment was improved, together with travel subsidies and provisions for military service-damaged soldiers and their families. In addition, the position of non-commissioned officers was improved.\nConsumers' and workers' rights.\nLegislation aimed at safeguarding consumers was also implemented under the Brandt Administration. The consumer's right of withdrawal in case of hire purchase was strengthened in March 1974, and fixed prices for branded products were abolished by law in January that same year, which meant that manufacturers' recommended prices were not binding for retailers. In addition, a progressive anticartel law was passed. The Law on Compensation for Measures of Criminal Prosecution and Penalties, passed in March 1971, provided for standardized compensation in certain situations. In addition, the budget for communications was increased.\nIn terms of working conditions, a number of reforms were introduced aimed at strengthening the rights of workers both at home and in the workplace. The Sickness Act of 1970 provided equal treatment of workers and employees in the event of incapacity for work, while maternity leave was increased. Legislation was introduced in 1970 which ensured continued payment of wages for workers disabled by illness. In 1970 all employees unfit for work (with the exception of women in receipt of maternity benefits and temporarily and inconsiderably employed persons) were provided with an unconditional legal claim against their employer to continued payment of their gross wage for a period of 6 weeks, as also in the case of spa treatment approved by an Insurance Fund, the Fund bearing the full cost thereof. Previously, payment of the employer's supplement and sick pay were only made from the day on which the doctor certified unfitness for work. In 1972, an Act on Agency Work was passed, which sought to prevent work agencies from providing job placement services and aimed to provide minimum job protection for employees in agency work. A law on the hiring out of manpower, passed in October 1972, contained provisions to stipulate prior authorization for the hiring out of manpower, to draw a distinction between the system governing workers hired out and the placing of workers, to regulate and improve the rights of hired out workers pertaining to working conditions and social insurance, and provide for more severe penalties and fines to be imposed on offenders.\nImprovements were also made in income and work conditions for home workers, accident insurance was extended to non-working adults, and the Border Zone Assistance Act (1971) increased levels of assistance to the declining zonal peripheral area. The Occupational Safety Act (1973) required employers to provide company doctors and safety experts. A directive on protection against noise at the place of work was adopted in November 1970. If measurements showed or there was reason to assume that a noise level guide value of 90\u00a0dB( A) may be exceeded at the place of work, then the authority had to instruct the employer to arrange check-ups of the employees concerned, and these employees had to use personal noise protection devices. A matching fund program for 15 million employees was also introduced, which stimulated them to accumulate capital.\nA ministerial order of January 1970 extended protection in cases of partial unemployment to home workers, while an ordinance of August 1970 fixed the conditions of health necessary for service in the merchant navy. A general provision of October 1970 determined in detail the circumstances in which the competent authority must take action on the basis of the act on the technical means of work. The requirement also stipulated the extent to which the technical standards established by national and international organisations can be regarded as \"rules of the art\". In a directive of 10 November 1970, the Minister of Labour and Social Affairs recommended to the higher authorities for work protection of the \"Lander\" to bring in the directive published, in agreement with the Ministry of Labour, by the German Engineers' Association on the evaluation of work station noise in relation to loss of hearing, in order to improve safeguards for workers against the noises in question. In September 1971, an ordinance was published concerning dangerous working materials, safeguarding persons using these materials against the dangers involved.\nBy a decree of the Federal Minister for Labour and Social Order, the Federal Institute for Industrial Protection became the Federal Agency for Industrial Protection and Accident Research. Amongst its designated tasks were the promotion of industrial protection, accident prevention on the journey to and from work and accident prevention in the home and leisure activities, the encouragement of training and advanced training in the area of industrial protection, and the promotion and coordination of accident research. A regulation was issued in 1972 which permitted for the first time the employment of women as drivers of trams, omnibuses and lorries, while further regulations laid down new provisions for lifts and work with compressed air. The Factory Constitution Law (1971) strengthened the rights of individual employees \"to be informed and to be heard on matters concerning their place of work\". The Works Council was provided with greater authority while trade unions were given the right of entry into the factory \"provided they informed the employer of their intention to do so\", while a law was passed to encourage wider share ownership by workers and other rank-and-file employees. The Industrial Relations Law (1972) and the Personnel Representation Act (1974) broadened the rights of employees in matters which immediately affected their places of work, while also improving the possibilities for codetermination on operations committees, together with access of trade unions to companies.\nThe Works Constitution Act of 1972 required in cases of collective dismissal at an establishment normally employing more than twenty employees, that management and the works council must negotiate a social plan that stipulates compensation for workers who lose their jobs. In cases where the two parties could not agree on a social plan, the law provided for binding arbitration. In 1972, the rights of works councils to information from management were not only strengthened, but works councils were also provided with full codetermination rights on issues such as working time arrangements in the plant, the setting of piece rates, plant wage systems, the establishment of vacation times, work breaks, overtime, and short-time work. Legislation was passed which acknowledged for the first time the presence of trade unions in the workplace, expanded the means of action of the works councils, and improved their work basics as well as those of the youth councils.\nA law of January 1972 on the organization of labour in enterprises significantly extended the works council's right of cooperation and co-management in the matter of vocational training. That same year, the Safety Institute of the Federal Republic of Germany was transformed into a public Federal Agency (Bundesanstalt) with significantly enlarged powers, in the context of which special emphasis would be placed on its new task of promoting and coordinating research in the area of accident prevention. New provisions were introduced for the rehabilitation of severely disabled people (\"Schwerbehinderte\") and accident victims. The Severely Disabled Persons Act of April 1974 obliged all employers with more than fifteen employees to ensure that 6% of their workforce consisted of people officially recognised as being severely disabled. Employers who failed to do so were assessed 100 DM per month for every job falling below the required quota. These compensatory payments were used to \"subsidise the adaptation of workplaces to the requirements of those who were severely handicapped\".\nA law passed in January 1974, designed to protect members of the supervisory boards of companies who are undergoing training, was aimed at ensuring that the representatives of young workers and youthful members of works councils still undergoing training could perform their duties with greater independence and without fear of disadvantageous consequences for their future careers. On request, workers' representatives on completion of their training courses had to have an employment relationship of unlimited duration. In the field of transport, the Municipal Transportation Finance Law of 1971 established federal guidelines for subsidies to municipal governments, while the Federal Transport Plan of 1973 provided a framework for all transport, including public transport. In addition, the Severely Handicapped Persons Act of April 1974 extended the welfare and promotional obligations of the employer and provided a right to extra holiday consisting of six working days.\nEnvironment.\nA federal environmental programme was established in 1971, and in 1972 laws were passed to regulate garbage elimination and air pollution via emission. Matching grants covering 90% of infrastructure development were allocated to local communities, which led to a dramatic increase in the number of public swimming pools and other facilities of consumptive infrastructure throughout West Germany. The federal crime-fighting apparatus was also modernised, while a Foreign Tax Act was passed which limited the possibility of tax evasion. In addition, efforts were made to improve the railways and motorways. In 1971, a law was passed setting the maximum lead content at 0.4 grams per liter of gasoline, and in 1972 DDT was banned. The Federal Emissions Control Law, passed in March 1974, provided protection from noxious gases, noise, and air-borne particulate matter.\nIn August 1971, a law came into force directed at reducing atmospheric pollution from lead compounds in four-stroke engine fuels. As a safeguard against radiation, a decree on the system of authorisations for medicaments treated with ionizing radiation or containing radioactive substances, in its version of 8 August 1967, was remodelled by a new Decree of 10 May 1971 which added some radionuclides to the list of medicaments which doctors in private practice were authorized to use.\nTaking into account the enormous high peaks of air traffic noise and its concentration at a limited number of airports, the Law for Protection against Aircraft Noise of 1971 sought to balance two conflicting demands, the first being the legitimate demand by industry, business and the public for an efficient air traffic system, and secondly, the understandable and by no means less legitimate claims of the affected people for protection and compensation. The legislation regulated the establishment of so-called \"L\u00e4rmschutzzonen\" (protection areas against aircraft noise) for all 11 international airports and for those 34 military airports used for jet aircraft, and the law also authorised the Federal Department of the Interior to decree protection areas for each of those mentioned airports with approval by the \"Bundesrat\", the representation of the German Federal States.\nEconomy.\nUnder the Brandt Administration, West Germany attained a lower rate of inflation than in other industrialised countries at that time, while a rise in the standard of living took place, helped by the floating and revaluation of the mark. This was characterised by the real incomes of employees increasing more sharply than incomes from entrepreneurial work, with the proportion of employees' incomes in the overall national income rising from 65% to 70% between 1969 and 1973, while the proportion of income from entrepreneurial work and property fell over that same period from just under 35% to 30%. In addition, the percentage of West Germans living in poverty (based on various definitions) fell between 1969 and 1973. According to one estimate, the percentage of West Germans living in poverty fell from 9.7% to 8.9% between 1969 and 1973, and from 20.2% to 14.0% according to another estimate. According to another estimate, the percentage of West Germans living in poverty during this period fell from 2.7% to 1.4%.\n1972 crisis.\nBrandt's \"Ostpolitik\" led to a meltdown of the narrow majority Brandt's coalition enjoyed in the \"Bundestag\". In October 1970, FDP deputies Erich Mende, Heinz Starke, and Siegfried Zoglmann crossed the floor to join the CDU. On 23 February 1972, SPD deputy Herbert Hupka, who was also leader of the \"Bund der Vertriebenen\", joined the CDU in disagreement with Brandt's reconciliatory efforts towards the east. On 23 April 1972, Wilhelm Helms (FDP) left the coalition. The FDP politicians Knud von K\u00fchlmann-Stumm and Gerhard Kienbaum also declared that they would vote against Brandt, completing the loss of Brandt's majority. On 24 April 1972 a constructive vote of no confidence was proposed, to be voted on three days later. In the event this motion passed, CDU leader Rainer Barzel would have replaced Brandt as chancellor.\nOn paper, the opposition now had 250 votes; just one over the 249 needed to oust Brandt. Even Brandt himself believed he was finished, and a number of unions went on strike in anticipation of Brandt's expected defeat on the floor of the Bundestag. To everyone's surprise, the motion failed: Barzel got only 247 votes out of 260 votes cast, two short of what he needed to become Chancellor. There were also 10 votes against the motion and three invalid ballots. Most SPD and FDP deputies abstained, which had the same effect as voting for Brandt.\nNew elections.\nThough Brandt remained chancellor, he had lost his majority. Subsequent initiatives in parliament, most notably on the budget, failed. Because of this stalemate, the Bundestag was dissolved, and new elections were called. During the 1972 campaign, many popular West German artists, intellectuals, writers, actors and professors supported Brandt and the SPD. Among them were G\u00fcnter Grass, Walter Jens, and even the soccer player Paul Breitner. Brandt's \"\" as well as his reformist domestic policies were popular with parts of the young generation, and he led the SPD to its best-ever federal election result in late 1972.\nHowever, the ', Brandt's landslide win, was the beginning of the end, and Brandt's role in government started to decline. Many of his reforms met with resistance from state governments, dominated by CDU/CSU. The spirit of reformist optimism was cut short by the 1973 oil crisis and the major public services strike of 1974, which gave Germany's trade unions, led by Heinz Kluncker, a big wage increase but reduced Brandt's financial leeway for further reforms. Brandt was said to be more a dreamer than a manager and was personally haunted by depression. To counter any notions about being sympathetic to Communism or soft on left-wing extremists, Brandt implemented tough legislation that barred \"radicals\" from public service (').\nGuillaume affair.\nAround 1973, West German security organizations received information that one of Brandt's personal assistants, G\u00fcnter Guillaume, was a spy for the East German intelligence services. Brandt was asked to continue working as usual, and he agreed to do so, even taking a private vacation with Guillaume. Guillaume was arrested on 24 April 1974 and later sentenced to 13 years in prison for treason.\nBrandt resigned from his position as chancellor on 6 May 1974, but he remained a member of the Bundestag and chairman of the Social Democrats until 1987.\nThis espionage affair is widely considered to have been just the trigger for Brandt's resignation, not the fundamental cause. As Brandt himself later said, \"I was exhausted, for reasons which had nothing to do with the affair [the Guillaume espionage scandal] going on at the time.\"\nBrandt was dogged by scandals about serial adultery and reportedly also struggled with alcohol and depression. There was also the economic fallout on West Germany of the 1973 oil crisis, which may seem to have given enough stress to finish off Brandt as the Chancellor.\nGuillaume had been an espionage agent for East Germany, who was supervised by Markus Wolf, the head of the\nMain Directorate for Reconnaissance (\"Hauptverwaltung Aufkl\u00e4rung\" or HVA\u2014the foreign intelligence service) of the East German Ministry for State Security. Wolf stated after the reunification that the resignation of Brandt had never been intended, and that the planting and handling of Guillaume had been one of the biggest mistakes of the East German secret services.\nBrandt was succeeded as the Chancellor of the Bundesrepublik by his fellow Social Democrat, Helmut Schmidt. For the rest of his life, Brandt remained suspicious that his fellow Social Democrat (and longtime rival) Herbert Wehner had been scheming for Brandt's downfall. However, there is scant evidence to corroborate this suspicion.\nPost-Chancellorship.\nAfter his term as the Chancellor, Brandt retained his seat in the Bundestag, and he remained the Chairman of the Social Democratic Party through 1987. Beginning in 1987, Brandt stepped down to become the Honorary Chairman of the party. Brandt was also a member of the European Parliament from 1979 to 1983.\nSocialist International.\nFor sixteen years (1976\u201392), Brandt was the president of the Socialist International. During that period, the number of Socialist International's mainly European member parties grew until there were more than a hundred socialist, social democratic, and labour political parties around the world. For the first seven years, this growth in SI membership had been prompted by the efforts of the Socialist International's Secretary-General, the Swede Bernt Carlsson. However, in early 1983, a dispute arose about what Carlsson perceived as the SI president's authoritarian approach. Carlsson then rebuked Brandt saying, \"this is a Socialist International \u2013 not a German International\".\nNext, against some vocal opposition, Brandt decided to move the next Socialist International Congress from Sydney, Australia to Portugal. Following this SI Congress in April 1983, Brandt retaliated against Carlsson by forcing him to step down from his position. However, the Austrian Chancellor, Bruno Kreisky, argued on behalf of Brandt: \"It is a question of whether it is better to be pure or to have greater numbers\".\nCarlsson was succeeded by the Finn Pentti V\u00e4\u00e4n\u00e4nen as Secretary General of the Socialist International.\nDuring Brandt's presidency, the SI developed activities and dialogue on a number of International issues. This concerned the East\u2013West conflict and arms race, on which the SI held high-level consultations with the leaderships of the United States and the Soviet Union, and on Afghanistan after 1979. The SI met with President Jimmy Carter and Vice Presidents Walter Mondale and George Bush, and with the CPSU Secretaries General Leonid Brezhnev and Mikhail Gorbachev and Soviet Head of State Andrei Gromyko. The SI also developed active contacts to promote dialogue concerning regional conflicts. Those included the Middle East, where they helped to build contacts between Israel and the PLO, and also in Southern Africa and Central America. In 1984, as the chairman of the SPD, Brandt initiated initiated party dialogues with the Chinese Communist Party (CCP), making SPD the first international party relationship CCP established outside of other communist parties.\nBrandt Report.\nIn 1977, Brandt was appointed as the chairman of the Independent Commission for International Developmental Issues. This produced a report in 1980, which called for drastic changes in the global attitude towards development in the Third World. This became known as the Brandt Report.\nReunification.\nIn October 1979, Brandt met with the East German dissident, Rudolf Bahro, who had written \"The Alternative\". Bahro and his supporters were attacked by the East German state security organization Stasi, headed by Erich Mielke, for his writings, which had laid the theoretical foundation of a left-wing opposition to the ruling SED party and its dependent allies, and which promoted new and changed parties. All of this is now described as \"change from within\". Brandt had asked for Bahro's release, and Brandt welcomed Bahro's theories, which advanced the debate within his own Social Democratic Party.\nOn 11 September 1988, Brandt described the hope for German reunification as a delusion. In late 1989, Brandt became one of the first leftwing leaders in West Germany to publicly favor a quick reunification of Germany, instead of some sort of two-state federation or other kind of interim arrangement. Brandt's public statement, \"Now grows together what belongs together\", was widely quoted in those days.\nHostages in Iraq.\nOne of Brandt's last public appearances was in flying to Baghdad, Iraq, to free Western hostages held by Saddam Hussein, following the Iraqi invasion of Kuwait in 1990. Brandt secured the release of a large number of them, and on 9 November 1990, his airplane landed with 174 freed hostages on board at Frankfurt Airport.\nDeath and legacy.\nBrandt died of colon cancer at his home in Unkel, a town on the River Rhine, on 8 October 1992, at the age of 78. He was given a state funeral and was buried at the cemetery at Zehlendorf in Berlin.\nThe Federal Chancellor Willy Brandt Foundation was established in 1994. It serves to honour the memory of Brandt's political accomplishments and his commitment to peace, freedom and democracy. The foundation runs two permanent exhibitions: one in Berlin and the other in L\u00fcbeck, where Brandt was born. Other works of the foundation include oversight of Brandt's papers, speeches and letters (the Berlin Edition), historical research as well as organizing lectures and international conferences.\nIn 1997, a park in Stockholm was named in Brandt's honor. It is close to where he lived during his exile in Sweden 1941\u20131945.\nWhen the SPD moved its headquarters from Bonn back to Berlin in the mid-1990s, the new headquarters was named the \"Willy Brandt Haus\". One of the buildings of the European Parliament in Brussels was named after him in 2008.\nOn 6 December 2000, a memorial to Brandt and \"Warschauer Kniefall\" was unveiled in Warsaw, Poland.\nGerman artist Johannes Heisig painted several portraits of Brandt, of which one was unveiled as part of an honoring event at the German Historical Institute Washington, DC on 18 March 2003. Spokesmen amongst others were former German Federal Minister Egon Bahr and former U.S. Secretary of State Henry Kissinger.\nIn 2009, the Willy-Brandt-Memorial was opened up in Nuremberg at the Willy-Brandt Square. It was created by the artist Josef Tabachnyk.\nIn 2009, the University of Erfurt renamed its graduate school of public administration as the Willy Brandt School of Public Policy. A private German-language secondary school in Warsaw, Poland, is also named after Brandt.\nThe main boulevard at the north entrance of the Montenegrin capital Podgorica was named Willy Brandt Boulevard in 2011.\nBrandt also has an unusual memorial in Hammersmith in London, United Kingdom. In 1963, when he was mayor of West Berlin, Brandt travelled to Hammersmith with a street lamp from West Berlin and presented it to the mayor of Hammersmith to mark its twinning with Neuk\u00f6lln. The lamp now stands on the wall of Westcott Lodge, facing Furnival Gardens, with a commemorative plaque below it.\nAlthough Brandt had only served five years in office as Chancellor of Germany, he remains as one of the most popular politicians in the history of the Federal Republic of Germany.\nBerlin Brandenburg Airport, which opened in late 2020, is also named in his honor.\nBrandt's family.\nFrom 1941 until 1948, Brandt was married to Anna Carlotta Thorkildsen (the daughter of a Norwegian father and a German-American mother). They had a daughter, Ninja Frahm (born in 1940). After Brandt and Thorkildsen were divorced in 1948, Brandt married the Norwegian-born German writer Rut Hansen in the same year. Hansen and Brandt had three sons: Peter Brandt (born in 1948), Lars Brandt (born in 1951) and Matthias Brandt (born in 1961). After 32 years of marriage, Willy Brandt and Rut Hansen Brandt divorced in 1980, and from the day that they were divorced they never saw each other again. On 9 December 1983, Brandt married Brigitte Seebacher (born in 1946).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\nThe following titles are in German:"}
{"id": "49261", "revid": "41651886", "url": "https://en.wikipedia.org/wiki?curid=49261", "title": "Corporate personhood", "text": "Notion that corporations can have some legal rights, responsibilities and accountability\nCorporate personhood or juridical personality is the legal notion that a juridical person such as a corporation, separately from its associated human beings (like owners, managers, or employees), has at least some of the legal rights and responsibilities enjoyed by natural persons. In most countries, a corporation has the same rights as a natural person to hold property, enter into contracts, and to sue or be sued.\nEarly history.\nAncient Indian society used legal personhood for political, social, and economic purposes. As early as 800 BC, legal personhood was granted to guild-like \"\u015bre\u1e47\u012b\" that operated in the public interest. The late Roman Republic granted legal personhood to municipalities, public works companies that managed public services, and voluntary associations (\"collegia\") such as the early Catholic Church. The diverse collegia had different rights and responsibilities that were independent of the individual members. Some collegia resembled later medieval guilds and were allowed to advance the needs of a trade as a whole, but collegia were otherwise barred from enriching their members.\nIn the Middle Ages, juridical persons were chartered either as corporations or as foundations in order to facilitate collective perpetual ownership of assets beyond the founders' lifespans, and to avoid their fragmentation and disintegration resulting from personal property inheritance laws. Later on, incorporation was advocated as an efficient and secure mode of economic development: advantages over existing partnership structures included the corporation's continuing existence if a member died; the ability to act without unanimity; and limited liability. The word \"corporation\" derives from the Latin \"corpus\" (\u201cbody\u201d), and juridical personhood was often assumed in medieval writings. By the Renaissance period, European jurists routinely held that churches and universities chartered by the government could acquire property, enter into contracts, sue, and be sued independently of their members. The government or the Pope granted religious organizations the 'power of perpetual succession,' meaning that church property would neither revert to the local lord nor be taxed upon the death of church members. Some town charters explicitly granted medieval towns the right of self-governance. Commercial endeavors were not among the entities incorporated in the medieval era, and even risky trading companies were originally run as common-law partnerships rather than corporations; the incorporation of the East India Company monopoly in 1600 broke new ground, and by the end of the century, commercial ventures frequently sought incorporation in Europe and the Americas. By the 19th century, the direction of British and American corporate law had diverged; British law of this period (such as the Joint Stock Companies Act 1856) appeared to focus more on corporations that more closely resembled traditional joint ventures, while American law was driven by the need to manage a more diverse corporate landscape.\nContemporary global approaches.\nCommon law systems.\nUnited Kingdom.\nThe UK, as the birthplace of modern corporate law, has a well-developed system of corporate personhood. Under British law, companies incorporated under the Companies Act have separate legal personality, allowing them to own property, enter contracts, and sue and be sued. The UK approach emphasizes regulatory oversight through Companies House.\nCanada.\nCanadian corporate law recognizes corporate personhood through both federal and provincial incorporation systems. The Canada Business Corporations Act grants corporations most rights of natural persons, though limitations on political activities and constitutional rights differ from the US.\nAustralia.\nAustralian corporations law, governed primarily by the Corporations Act 2001, provides for corporate personhood with conduct of business oversight through the Australian Securities and Investments Commission (ASIC).\nCivil law systems.\nGermany.\nUnder German law, corporations have legal personality separate from their shareholders. The German approach emphasizes stakeholder governance, with employee representation on corporate boards and strong regulatory frameworks that balance shareholder interests with broader societal concerns.\nFrance.\nFrench corporate law recognizes legal personality through various corporate forms, including the soci\u00e9t\u00e9 anonyme (SA) and soci\u00e9t\u00e9 \u00e0 responsabilit\u00e9 limit\u00e9e (SARL). The French system emphasizes regulatory oversight and has specific provisions regarding corporate social responsibility that differ from Anglo-American approaches.\nJapan.\nJapanese corporate law, influenced by both German civil law and Anglo-American traditions, recognizes corporate personhood through various corporate forms. The Japanese approach emphasizes stakeholder capitalism and long-term corporate governance, with less emphasis on shareholder primacy compared to some other systems.\nCountry specific laws.\nIndia.\nUnder Indian law the corporate, managing bodies, etc. and several other non-human entitles have been given the status of the \"legal person\". In court cases regarding corporate, the shareholders are not responsible for the company's debts but the company itself being a \"legal person\" is liable to repay those debts or be sued for the non-repayment of debts. The non-human entities given the \"legal person\" status by the law \"have rights and co-relative duties; they can sue and be sued, can possess and transfer property\". Since these non-human entities are \"voiceless\" they are legally represented \"through guardians and representatives\" to claim their legal rights and to fulfill their legal duties and responsibilities. Specific non-human entities given the status of \"legal person\" include \"corporate personality, body politic, charitable unions etc.\", as well as trust estates, deity, temples, churches, mosques, hospitals, universities, colleges, banks, railways, municipalities, and gram panchayats (village councils), rivers, all animals and birds.\nIn the United States.\nIn a U.S. historical context, the phrase \"corporate personhood\" refers to the ongoing legal debate over the extent to which rights traditionally associated with natural persons should also be afforded to juridical persons including corporations. A headnote issued by the court reporter in the 1886 Supreme Court case \"Santa Clara County v. Southern Pacific Railroad Co.\" claimed to state the sense of the Court regarding the equal protection clause of the Fourteenth Amendment as it applies to corporations, without the Court having actually made a decision or issued a written opinion on that point. This was the first time that the Supreme Court was reported to hold that the Fourteenth Amendment's equal protection clause granted constitutional protections to corporations as well as to natural persons, although numerous other cases, since \"Dartmouth College v. Woodward\" in 1819, had recognized that corporations were entitled to some of the protections of the Constitution. In \"Burwell v. Hobby Lobby Stores, Inc.\" (2014), the Court found that the Religious Freedom Restoration Act of 1993 exempted Hobby Lobby from aspects of the Patient Protection and Affordable Care Act because those aspects placed a substantial burden on the company's owners' free exercise of sincerely held religious beliefs.\nU.S. courts have extended certain constitutional protections to corporations under various rationales. An early perspective, variously known as 'contractual', 'associate', or 'aggregate' theory, holds that owners of property have certain constitutional protections, even when the property is held via a corporation rather than directly under the owner's own name. Corporate attorney John Norton Pomeroy argued in the 1880s that \"Statutes violating their prohibitions in dealing with corporations must necessarily infringe upon the rights of natural persons. In applying and enforcing these constitutional guaranties, corporations cannot be separated from the natural persons who compose them.\"\nSimilarly, proponents might argue a juridical person can be a device for exercising shareholders' rights to free speech. Under this perspective, such constitutional rights might also extend to other associations of people, even where the association does not take on the formal legal form of a corporation. A second perspective, known as the 'real entity' or 'natural entity' view, shifts the presumption of corporate regulation against the states.\nThe dominant view from the 1920s to the 1980s, championed by philosopher John Dewey, asserted that such perspectives are often overgeneralizations, and that the decision to grant corporate rights in a given sphere should be governed by the consequences of doing so. The 1980s saw an explosion of economic analyses, with a corporation often viewed as a nexus of contracts and as an economic agent appointed to act on behalf of its shareholders.\nSome rulings combine multiple perspectives; the majority opinion in \"Citizens United\" argued both from an 'association' perspective (\"if the antidistortion rationale were to be accepted... it would permit Government to ban political speech simply because the speaker is an association that has taken on the corporate form\") and from a 'natural entity' perspective (\"the worth of speech 'does not depend upon the identity of its source, whether corporation, association, union, or individual'\").\nTreating juridical persons as having legal rights allows corporations to sue and to be sued, provides a single entity for easier taxation and regulation, simplifies complex transactions that would otherwise involve, in the case of large corporations, thousands of people, and protects the individual rights of the shareholders as well as the right of association.\nGenerally, corporations are not able to claim constitutional protections that would not otherwise be available to persons acting as a group. For example, the Supreme Court has not recognized a Fifth Amendment right against self-incrimination for a corporation, since the right can be exercised only on an individual basis. In \"United States v. Sourapas and Crest Beverage Company\", \"[a]ppellants [suggested] the use of the word 'taxpayer' several times in the regulations requires the fifth-amendment self-incrimination warning be given to a corporation.\" The Court did not agree. Likewise, corporations and organizations do not have privacy rights under the Privacy Act of 1974, since the statute refers to any \"individual,\" which it defines as \"a citizen of the United States or an alien lawfully admitted for permanent residence.\"\nSince the Supreme Court's ruling in \"Citizens United v. Federal Election Commission\" in 2010, upholding the rights of corporations to make unlimited political expenditures under the First Amendment, there have been several calls for a Constitutional amendment to abolish corporate personhood. The \"Citizens United\" majority opinion makes no reference to corporate personhood or the Fourteenth Amendment, but rather argues that political speech rights do not depend on the identity of the speaker, which could be a person or an association of people.\nIndividual shareholders cannot generally sue over the deprivation of a corporation's rights; only the board of directors has the standing to assert a corporation's constitutional rights in court.\nHistorical background in the United States.\nDuring the colonial era, British corporations were chartered by the crown to do business in North America. This practice continued in the early United States. They were often granted monopolies as part of the chartering process. For example, the controversial Bank Bill of 1791 chartered a 20-year corporate monopoly for the First Bank of the United States. Although the Federal government has from time to time chartered corporations, the general chartering of corporations has been left to the states. In the late 18th and early 19th centuries, corporations began to be chartered in greater numbers by the states, under general laws allowing for incorporation at the initiative of citizens, rather than through specific acts of the legislature.\nThe degree of permissible government interference in corporate affairs was controversial from the earliest days of the nation. In 1790, John Marshall, a private attorney and a veteran of the Continental Army, represented the board of the College of William and Mary, in litigation that required him to defend the corporation's right to reorganize itself and in the process remove professors, \"The Rev John Bracken v. The Visitors of Wm &amp; Mary College\" (7 Va. 573; 1790 Supreme Court of Virginia). The Supreme Court of Virginia ruled that the original Crown charter provided the authority for the corporation's Board of Visitors to make changes including the reorganization.\nAs the 19th century matured, manufacturing in the U.S. became more complex as the Industrial Revolution generated new inventions and business processes. The favored form for large businesses became the corporation because the corporation provided a mechanism to raise the large amounts of investment capital large business required, especially for capital intensive yet risky projects such as railroads.\nFollowing the reasoning of the Dartmouth College case and other precedents (see below), corporations could exercise the rights of their shareholders and these shareholders were entitled to some of the legal protections against arbitrary state action. Their cause was strengthened by the adoption of general incorporation statutes in the states in the late 19th century, most notably in New Jersey and Delaware, which allowed anyone to form corporations without any particular government grant or authorization, and thus without the government-granted monopolies that had been common in charters granted by the Crown or by acts of the legislature (see Delaware General Corporation Law). In \"Santa Clara County v. Southern Pacific Railroad\" (1886), the Supreme Court held that the Fourteenth Amendment applied to corporations. Since then the doctrine has been repeatedly reaffirmed in case law.\nCase law in the United States.\nIn 1818, the United States Supreme Court decided \"Trustees of Dartmouth College v. Woodward\" \u2013 17 U.S. 518 (1819), writing: \"The opinion of the Court, after mature deliberation, is that this corporate charter is a contract, the obligation of which cannot be impaired without violating the Constitution of the United States. This opinion appears to us to be equally supported by reason, and by the former decisions of this Court.\" Beginning with this opinion, the U.S. Supreme Court has continuously recognized corporations as having the same rights as natural persons to contract and to enforce contracts.\nSeven years after the Dartmouth College opinion, the Supreme Court decided \"Society for the Propagation of the Gospel in Foreign Parts v. Town of Pawlet\" (1823), in which an English corporation dedicated to missionary work, with land in the U.S., sought to protect its rights to the land under colonial-era grants against an effort by the state of Vermont to revoke the grants. Justice Joseph Story, writing for the court, explicitly extended the same protections to corporate-owned property as it would have to property owned by natural persons. Seven years later, Chief Justice Marshall stated: \"The great object of an incorporation is to bestow the character and properties of individuality on a collective and changing body of men.\"\nIn the 1886 case \"Santa Clara v. Southern Pacific\" \u2013 118 U.S. 394 (1886), Chief Justice Waite of the Supreme Court orally directed the lawyers that the Fourteenth Amendment equal protection clause guarantees constitutional protections to corporations in addition to natural persons, and the oral argument should focus on other issues in the case. In the Santa Clara case the court reporter, Bancroft Davis, noted in the headnote to the opinion that the Chief Justice, Morrison Waite, began oral argument by stating, \"The court does not wish to hear argument on the question whether the provision in the Fourteenth Amendment to the Constitution, which forbids a State to deny to any person within its jurisdiction the equal protection of the laws, applies to these corporations. We are all of the opinion that it does.\" While the headnote is not part of the Court's opinion and thus not precedent, two years later, in \"Pembina Consolidated Silver Mining Co. v. Pennsylvania\" \u2013 125 U.S. 181 (1888), the Court clearly affirmed the doctrine, holding, \"Under the designation of 'person' there is no doubt that a private corporation is included [in the Fourteenth Amendment]. Such corporations are merely associations of individuals united for a special purpose and permitted to do business under a particular name and have a succession of members without dissolution.\" This doctrine has been reaffirmed by the Court many times since.\nThe 14th Amendment does not insulate corporations from all government regulation, any more than it relieves individuals from all regulatory obligations. Thus, for example, in \"Northwestern Nat Life Ins. Co. v. Riggs\" (203 U.S. 243 (1906)), the Court accepted that corporations are for legal purposes \"persons\", but still ruled that the Fourteenth Amendment was not a bar to many state laws which effectively limited a corporation's right to contract business as it pleased. However, this was not because corporations were not protected under the Fourteenth Amendment\u2014rather, the Court's ruling was that the Fourteenth Amendment did not prohibit the type of regulation at issue, whether of a corporation or of sole proprietorship or partnership.\nLegislation in the United States.\nFederal statutes that refer to \"persons\" generally include both natural and juridical ones, unless a different definition is given. This general rule of interpretation is specified in Title 1, section 1 of the U.S. Code, known as the Dictionary Act, which states:\nIn determining the meaning of any Act of Congress, unless the context indicates otherwise\u2014\nthe words \"person\" and \"whoever\" include corporations, companies, associations, firms, partnerships, societies, and joint stock companies, as well as individuals;\nThis federal statute has many consequences. For example, a corporation may enter contracts, sue and be sued, and be held liable under both civil and criminal law. Because the corporation is legally considered the \"person\", individual shareholders are not legally responsible for the corporation's debts and damages. Similarly, individual employees, managers, and directors are liable for their own malfeasance or lawbreaking while acting on behalf of the corporation, but are not generally liable for the corporation's actions. \nAmong the most frequently discussed and controversial consequences of corporate personhood in the United States is the extension of a limited subset of the same constitutional rights.\nCorporations as juridical persons have always been able to perform commercial activities, similar to a person acting as a sole proprietor, such as entering into a contract or owning property. Therefore, corporations have always had a \"juridical personality\" for the purposes of conducting business while shielding individual shareholders from personal liability (i.e. protecting personal assets which were not invested in the corporation).\nRalph Nader, Phil Radford and others have argued that a strict originalist philosophy should reject the doctrine of corporate personhood under the Fourteenth Amendment. Indeed, Chief Justice William Rehnquist repeatedly criticized the Court's invention of corporate constitutional \"rights\", most famously in his dissenting opinion in the 1978 case \"First National Bank of Boston v. Bellotti\"; though, in \"Bellotti\", Rehnquist's objections are based on his \"views of the limited application of the First Amendment to the States\" and not on whether corporations qualify as \"persons\" under the Fourteenth Amendment. Nonetheless, these justices' rulings have continued to affirm the assumption of corporate personhood, as the Waite court did, and Justice Rehnquist himself eventually endorsed the right of corporations to spend in elections (the majority view in \"Bellotti\") in his dissenting opinion in \"McConnell v. FEC\".\nCorporate political spending.\nA central point of debate in recent years has been what role corporate money plays and should play in democratic politics. This is part of the larger debate on campaign finance reform and the role which money may play in politics.\nIn the United States, legal milestones in this debate include:\nThe corporate personhood aspect of the campaign finance debate turns on \"Buckley v. Valeo\" (1976) and \"Citizens United v. Federal Election Commission\" (2010): \"Buckley\" ruled that political spending is protected by the First Amendment right to free speech, while \"Citizens United\" ruled that corporate political spending is protected, holding that corporations have a First Amendment right to free speech because they are \"associations of citizens\" and hold the collected rights of the individual citizens who constitute them.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\n is available from: http:// \n is available from: http:// \n is available from: http:// http:// \n is available from: http:// \n is available from: http:// \n is available from: http:// \n is available from: http:// \n is available from: http:// \nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "49263", "revid": "1712722", "url": "https://en.wikipedia.org/wiki?curid=49263", "title": "Lake Baringo", "text": "Freshwater lake in Kenya\nLake Baringo is, after Lake Turkana, the most northern of the Kenyan Rift Valley lakes, with a surface area of and an elevation of . The lake is fed by several rivers: the Molo, Perkerra and Ol Arabel. It has no obvious outlet; the waters are assumed to seep through lake sediments into the faulted volcanic bedrock. It is one of the two freshwater lakes in the Rift Valley in Kenya, the other being Lake Naivasha.\nThe lake is in a remote hot and dusty area with over 470 species of birds, occasionally including migrating flamingos. A Goliath heronry is located on a rocky islet in the lake known as Gibraltar.\nThe existence of Lake Baringo was first reported in Europe by Ludwig Krapf and J. Rebmann, German missionaries stationed at Mombasa, about 1850; in J. H. Speke\u2019s map of the Nile sources (1863) Baringo is confused with Kavirondo Gulf of Victoria Nyanza; it figures in Sir H. M. Stanley\u2019s map (1877) as a large sheet of water N.E. of Victoria Nyanza. Joseph Thomson, in his journey through the Masai country in 1883, was the European to see the lake and to correct the exaggerated notions as to its size. Native tradition, however, asserts that the lake formerly covered a much larger area.\nDescription.\nThe lake is part of the East African Rift system. The Tugen Hills, an uplifted fault block of volcanic and metamorphic rocks, lies west of the lake. The Laikipia Escarpment lies to the east.\nWater flows into the lake from the Mau Hills and Tugen Hills. It is a critical habitat and refuge for more than 500 species of birds and fauna, some of the migratory waterbird species being significant regionally and globally. The lake also provides a habitat for seven fresh water fish species. One, \"Oreochromis niloticus baringoensis\" (a Nile tilapia subspecies), is endemic to the lake. Lake fishing is important to local social and economic development. Additionally the area is a habitat for many species of animals including the hippopotamus (\"Hippopotamus amphibius\"), Nile crocodile (\"Crocodylus niloticus\") and many other mammals, amphibians, reptiles and the invertebrate communities.\nWhile stocks of Nile tilapia in the lake are now low, the decline of this species has been mirrored by the success of another, the marbled lungfish (\"Protopterus aethiopicus\") which was introduced to the lake in 1974 and which now provides the majority of fish from the lake. Water levels have been reduced by droughts and over-irrigation. The lake is commonly turbid with sediment, partly due to intense soil erosion in the catchment area, especially on the Loboi Plain south of the lake.\nA characteristic of the country in the neighbourhood of the lake are the \"hills\" of the termites (white ants). They are hollow columns 10 to 12 ft. high and from 1 ft. to 18 in. broad. The greater kudu, almost unknown elsewhere in East Africa, inhabits the flanks of the Laikipia escarpment to the east of the lake and comes to the foot-hills around Baringo to feed.\nA recent study showed that there were both positive and negative relationships between some water quality parameters and the prevalence of recovered parasites. \"O. niloticus baringoensis\" from Lake Baringo also recorded high parasite prevalence and this calls for sensitization of the public on the risks that may arise from the consumption of undercooked infected fish.\nThe lake has several small islands, the largest being Ol Kokwe Island. Ol Kokwe, an extinct volcanic centre related to Korosi volcano north of the lake, has several hot springs and fumaroles, some of which have precipitated sulfur deposits. A group of hot springs discharge along the shoreline at Soro near the northeastern corner of the island.\nSeveral important archaeological and palaeontological sites, some of which have yielded fossil hominoids and hominins, are present in the Miocene to Pleistocene sedimentary sequences of the Tugen Hills.\nThe main town near the lake is Marigat, while smaller settlements include Kampi ya Samaki and Loruk. The area is increasingly visited by tourists and is situated at the southern end of a region of Kenya inhabited largely by pastoralist ethnic groups including Il Chamus, Rendille, Turkana and Kalenjin. Accommodation, (hotels, self-catering cottages and camping sites) as well as boating services are available at and near Kampi-Ya-Samaki on the western shore, as well as on several of the islands in the lake.\nA Kenyan Government report in 2021 estimated that the surface area of Lake Baringo had increased by over 100% to 268 square kilometres over the period 2010\u20132020. Lakeside villages were flooded and people displaced. There have also been increases in animal populations such as crocodiles, along with interactions between these animals and people.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nAttribution\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "49264", "revid": "279219", "url": "https://en.wikipedia.org/wiki?curid=49264", "title": "The Ten Gurus", "text": ""}
{"id": "49266", "revid": "49969429", "url": "https://en.wikipedia.org/wiki?curid=49266", "title": "Buchenwald concentration camp", "text": "Nazi concentration camp in Germany\nBuchenwald (; 'beech forest') was a German Nazi concentration camp established on Ettersberg hill near Weimar, Germany, in July 1937. It was one of the first and the largest of the concentration camps within the Altreich (Old Reich) territories. Many actual or suspected communists were among the first internees.\nThe Nazi camp prisoners came from all over Europe and the Soviet Union, and included Jews, Poles and other Slavs, Roma, the mentally ill and physically disabled, political prisoners, Freemasons, and prisoners of war. There were also ordinary criminals and those perceived as sexual deviants by the Nazi regime. All prisoners were primarily subjected to forced labor in local armaments factories. The insufficient food and poor conditions, as well as deliberate executions, led to 56,545 deaths at Buchenwald out of the 280,000 prisoners who passed through the camp and its 139 subcamps.\nThe camp gained notoriety when it was liberated by the United States Army in April 1945; Allied commander Dwight D. Eisenhower visited one of its subcamps.\nFrom August 1945 to March 1950, the camp was used by the Soviet occupation authorities as an internment camp, NKVD special camp Nr. 2, where 28,455 prisoners were held, out of whom 7,127 died. The camp was then razed to hide this last episode.\nToday the remains of Buchenwald serve as a memorial and permanent exhibition and museum.\nEstablishment.\nThe \"Schutzstaffel\" (SS) established Buchenwald concentration camp at the beginning of July 1937. The camp was to be named Ettersberg, after the hill in Thuringia upon whose north slope the camp was established. The proposed name was deemed inappropriate because it carried associations with several important figures in German culture, especially Enlightenment writer Johann Wolfgang von Goethe who had lived in Weimar. Instead the camp was to be named Buchenwald, in reference to the beech forest in the area. However, Holocaust researcher wrote that SS leaders chose the site of the camp precisely to erase the cultural legacy of the area. After the area of the camp was cleared of trees, only one large oak remained, supposedly one of Goethe's Oaks.\nThe camp, designed to hold 8,000 prisoners, was intended to replace several smaller concentration camps nearby, including , Sachsenburg, and Lichtenburg. Compared to these camps, Buchenwald had a greater potential to profit the SS because the nearby clay deposits could be made into bricks by the forced labor of prisoners. The first prisoners arrived on 15 July 1937, and had to clear the area of trees and build the camp's structures. By September, the population had risen to 2,400 following transfers from Bad Sulza, Sachsenburg, and Lichtenburg.\nOn the camp's main gate, the motto \"Jedem das Seine\" (English: \"To each what he deserves\"), was inscribed. The SS interpreted this to mean the \"master race\" had a right to humiliate and destroy others. It was designed by Buchenwald prisoner and Bauhaus architect Franz Ehrlich, who used a Bauhaus typeface for it, even though Bauhaus was seen as degenerate art by the National Socialists and was prohibited. This defiance however went unnoticed by the SS.\nCommand structure.\nOrganization.\nBuchenwald's first commandant was SS-\"Obersturmbannf\u00fchrer\" Karl-Otto Koch, who ran the camp from 1 August 1937 to July 1941. His second wife, Ilse Koch, became notorious as \"Die Hexe von Buchenwald\" (\"the witch of Buchenwald\") for her cruelty and brutality. In February 1940 Koch had an indoor riding hall built by the prisoners who died by the dozen due to the harsh conditions of the construction site. The hall was built inside the camp, near the canteen, so that Ilse Koch could often be seen riding in the morning to the beat of the prisoner orchestra. Koch himself was eventually imprisoned at Buchenwald by the Nazi authorities for incitement to murder. The charges were lodged by Prince Waldeck and Morgen, to which were later added charges of corruption, embezzlement, black market dealings, and exploitation of the camp workers for personal gain. Other camp officials were charged, including Ilse Koch. The trial resulted in Karl Koch being sentenced to death for disgracing both himself and the SS; he was executed by firing squad on 5 April 1945, one week before American troops arrived. Ilse Koch was acquitted by the SS court and released. However, she was rearrested by American occupation authorities in June 1945, and chosen as one of 31 Buchenwald defendants to stand trial before a Military Commission Court at Dachau. The life sentence imposed by the Dachau court was reduced to four years upon review. Upon her release from U.S. custody in October 1949, she was arrested by West German authorities, tried at Augsburg, and again sentenced to life imprisonment; she committed suicide in Aichach (Bavaria) prison in September 1967. The second commandant of the camp, between 1942 and 1945, was Hermann Pister (1942\u20131945). He was tried in 1947 (Dachau Trials) and sentenced to death, but on 28 September 1948 he died in Landsberg Prison of a heart attack.\nFemale prisoners and overseers.\nThe number of women held in Buchenwald was somewhere between 500 and 1,000. The first female inmates were twenty political prisoners who were accompanied by a female SS guard (\"Aufseherin\"); these women were brought to Buchenwald from Ravensbr\u00fcck in 1941 and forced into sexual slavery at the camp's brothel. The SS later fired the SS woman on duty in the brothel for corruption; her position was taken over by \"brothel mothers\" as ordered by SS chief Heinrich Himmler.\nThe majority of women prisoners, however, arrived in 1944 and 1945 from other camps, mainly Auschwitz, Ravensbr\u00fcck, and Bergen Belsen. Only one barracks was set aside for them; this was overseen by the female block leader (\"Blockf\u00fchrerin\") Franziska Hoengesberg, who came from Essen when it was evacuated. All the women prisoners were later shipped out to one of Buchenwald's many female satellite camps in S\u00f6mmerda, Buttelstedt, M\u00fchlhausen, Gotha, Gelsenkirchen, Essen, Lippstadt, Weimar, Magdeburg, and Penig, to name a few. No female guards were permanently stationed at Buchenwald.\nContrary to popular opinion, the notorious \"Bitch of Buchenwald\" Ilse Koch never served in any official capacity at the camp, nor ever acted as guard. In total, however, more than 530 women served as guards in the vast Buchenwald system of subcamps and external commands across Germany. Only 22 women served/trained in Buchenwald, compared to over 15,500 men.\nSubcamps.\nAbout 136 subcamps and satellite commandos belonged to Buchenwald concentration camp.\nIn 1942, the SS began to use its forced labor supply for armaments production. Because it was more economical to rent out prisoners to private firms, subcamps were set up near factories which had a demand for prisoner labor. Private firms paid the SS between 4 and 6 Reichsmarks per day per prisoner, resulting in an estimated 95,758,843 Reichsmarks in revenue for the SS between June 1943 and February 1945. These subcamps were mainly used for armament production and other fabrications and are considered labour camps. Conditions were worse than at the main camp, with prisoners provided insufficient food and inadequate shelter.\nAllied POWs.\nAlthough it was highly unusual for German authorities to send Western Allied POWs to concentration camps, Buchenwald held a group of 168 aviators for two months. These men were from the United States, United Kingdom, Canada, Australia, New Zealand and Jamaica. They all arrived at Buchenwald on 20 August 1944.\nAll these airmen were in aircraft that had crashed in occupied France. Two explanations are given for them being sent to a concentration camp: first, that they had managed to make contact with the French Resistance, some were disguised as civilians, and they were carrying false papers when caught; they were therefore categorized by the Germans as spies, which meant their rights under the Geneva Convention were not respected. The second explanation is that they had been categorised as \"Terrorflieger\" (\"terror aviators\"). The aviators were initially held in Gestapo prisons and headquarters in France. In April or August 1944, they and other Gestapo prisoners were packed into covered goods wagons and sent to Buchenwald. The journey took five days, during which they received very little food or water.\nVictims.\nCauses of death.\nA primary cause of death was illness due to harsh camp conditions. Like all concentration camps, prisoners at Buchenwald were deliberately kept in a state of starvation, many while performing grueling forced labor, making consequent illnesses prevalent. Malnourished and suffering from disease, many were literally \"worked to death\" under the \"Vernichtung durch Arbeit\" policy (extermination through labor), as inmates only had the choice between slave labor or inevitable execution. Many inmates were killed by human experimentation or fell victim to arbitrary acts perpetrated by the SS guards. Other prisoners were simply murdered, primarily by shooting and hanging. As part of Action 14f13, prisoners deemed too weak or sick to work were sent to Sonnenstein Killing Facility, where they were murdered with carbon monoxide gas.\nWalter Gerhard Martin Sommer was an SS-\"Hauptscharf\u00fchrer\" who served as a guard at the concentration camps of Dachau and Buchenwald. Known as the \"Hangman of Buchenwald\", he was considered a depraved sadist who reportedly ordered Otto Neururer and Mathias Spanlang, two Austrian priests, to be crucified upside-down. Sommer was especially infamous for hanging prisoners from trees by their wrists, which had been tied behind their backs (a torture technique known as strappado) in the \"singing forest\", so named because of the screams which emanated from this wooded area.\nSummary executions of Soviet POWs were also carried out at Buchenwald. At least 1,000 men were selected in 1941\u201342 by a task force of three Dresden Gestapo officers and sent to the camp for immediate liquidation by a gunshot to the back of the neck, the infamous \"Genickschuss\".\nThe camp was also a site of large-scale trials for vaccines against epidemic typhus in 1942 and 1943. In all 729 inmates were used as test subjects, of whom 154 died. Other \"experimentation\" occurred at Buchenwald on a smaller scale. One such experiment aimed at determining the precise fatal dose of a poison of the alkaloid group; according to the testimony of one doctor, four Soviet POWs were administered the poison, and when it proved not to be fatal they were \"strangled in the crematorium\" and subsequently \"dissected\". Among various other experiments was one which, in order to test the effectiveness of a balm for wounds from incendiary bombs, involved inflicting \"very severe\" white phosphorus burns on inmates. When challenged at trial over the nature of this testing, and particularly over the fact that the testing was designed in some cases to cause death and only to measure the time which elapsed until death was caused, one Nazi doctor's defence was that, although a doctor, he was a \"legally appointed executioner\".\nNumber of deaths.\nThe SS left behind accounts of the number of prisoners and people coming to and leaving the camp, categorizing those leaving them by release, transfer, or death. These accounts are one of the sources of estimates for the number of deaths in Buchenwald. According to SS documents, 33,462 died. These documents were not, however, necessarily accurate: Among those executed before 1944, many were listed as \"transferred to the Gestapo\". Furthermore, from 1941, Soviet POWs were executed in mass killings. Arriving prisoners selected for execution were not entered into the camp register and therefore were not among the 33,462 dead listed.\nOne former Buchenwald prisoner, Armin Walter, calculated the number of executions by the number of shootings in the spine at the base of the head. His job at Buchenwald was to set up and care for a radio installation at the facility where people were executed; he counted the numbers, which arrived by telex, and hid the information. He says that 8,483 Soviet prisoners of war were shot in this manner.\nAccording to the same source, the total number of deaths at Buchenwald is estimated at 56,545. This number is the sum of:\nThis total (56,545) corresponds to a death rate of 24 percent, assuming that the number of persons passing through the camp according to documents left by the SS, 240,000 prisoners, is accurate.\nLiberation.\nIn April 1945 an Alsos Mission team was searching for a German nuclear physicist near Weimar, eastern Germany. Taking a side road through woods to avoid German forces, they struck a ghastly smell from a clearing, and saw a barbed wire enclosure with a few pathetic figures and piles of corpses. Before continuing their mission they broke secrecy protocol to radio a request for the Army to send medical help. A group of survivors had just taken control of the camp from the few remaining Nazi guards. The four-man team was under linguist Hugh Montgomery and included Corporal Rick Carrier. Montgomery recalled the survivors made a final request: \"Please give the guards to us, and we\u2019ll take care of them ... And I\u2019m sure they did\". Montgomery later joined the CIA, and took part in Operation Gold in Berlin.\nOn 4 April 1945 the U.S. 89th Infantry Division overran Ohrdruf, a subcamp of Buchenwald.\nBuchenwald was partially evacuated by the Germans from 6 to 11 April 1945. In the days before the arrival of the American army, thousands of the prisoners were forcibly evacuated \non foot.\nThanks in large part to the efforts of Polish engineer (and short-wave radio-amateur, his pre-war callsign was SP2BD) Gwidon Damazyn, an inmate since March 1941, a secret short-wave transmitter and small generator were built and hidden in the prisoners' movie room. On 8 April at noon, Damazyn and Russian prisoner Konstantin Ivanovich Leonov sent the Morse code message prepared by leaders of the prisoners' underground resistance (supposedly Walter Bartel and Harry Kuhn):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;To the Allies. To the army of General Patton. This is the Buchenwald concentration camp. SOS. We request help. They want to evacuate us. The SS wants to destroy us.\nThe text was repeated several times in English, German, and Russian. Damazyn sent the English and German transmissions, while Leonov sent the Russian version. Three minutes after the last transmission sent by Damazyn, the headquarters of the U.S. Third Army responded:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;KZ Bu. Hold out. Rushing to your aid. Staff of Third Army.\nAccording to Teofil Witek, a fellow Polish prisoner who witnessed the transmissions, Damazyn fainted after receiving the message.\nAs American forces closed in, Gestapo headquarters at Weimar telephoned the camp administration to announce that it was sending explosives to blow up any evidence of the camp, including its inmates. The Gestapo did not know that the administrators had already fled. A prisoner answered the phone and informed headquarters that explosives would not be needed, as the camp had already been blown up, which was not true.\nA detachment of troops of the U.S. 9th Armored Infantry Battalion, from the 6th Armored Division, part of the U.S. Third Army, and under the command of Captain Frederic Keffer, arrived at Buchenwald on 11 April 1945 at 3:15\u00a0p.m. (now the permanent time of the clock at the entrance gate). The soldiers were given a hero's welcome, with the emaciated survivors finding the strength to toss some liberators into the air in celebration.\nLater in the day, elements of the U.S. 83rd Infantry Division overran Langenstein, one of a number of smaller camps comprising the Buchenwald complex. There, the division liberated over 21,000 prisoners, ordered the mayor of Langenstein to send food and water to the camp, and hurried medical supplies forward from the 20th Field Hospital.\nThird Army Headquarters sent elements of the 80th Infantry Division to take control of the camp on the morning of Thursday 12 April 1945. Several journalists arrived on the same day, perhaps with the 80th, including Edward R. Murrow, whose radio report of his arrival and reception was broadcast on CBS and became one of his most famous:&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;I asked to see one of the barracks. It happened to be occupied by Czechoslovaks. When I entered, men crowded around, tried to lift me to their shoulders. They were too weak. Many of them could not get out of bed. I was told that this building had once stabled 80 horses. There were 1,200 men in it, five to a bunk. The stink was beyond all description.\nThey called the doctor. We inspected his records. There were only names in the little black book, nothing more. Nothing about who these men were, what they had done, or hoped. Behind the names of those who had died, there was a cross. I counted them. They totaled 242. 242 out of 1,200, in one month.\nAs we walked out into the courtyard, a man fell dead. Two others, they must have been over 60, were crawling toward the latrine. I saw it, but will not describe it.\u2014\u200a\nCivilian tour.\nAfter Patton toured the camp, he ordered the mayor of Weimar to bring 1,000 citizens to Buchenwald; these were to be predominantly men of military age from the middle and upper classes. The Germans had to walk a roundtrip under armed American guard and were shown the crematorium and other evidence of Nazi atrocities. The Americans wanted to ensure that the German people would take responsibility for Nazi crimes, instead of dismissing them as atrocity propaganda. Gen. Dwight Eisenhower also invited two groups of Americans to tour the camp in mid-April 1945; journalists and editors from some of the principal U.S. publications, and then a dozen members of the Congress from both the House and the Senate, led by Senate Majority Leader Alben W. Barkley.\nWar correspondent Osmar White reported that above the crematorium door was a verse beginning 'Worms shall not devour me, but flames consume this body. I always loved the heat and light...'.\nSoviet internment camp.\nBetween August 1945 and 1 March 1950, Buchenwald was the site of NKVD special camp Nr. 2, where the Soviet secret police imprisoned former Nazis and anti-communist dissidents. According to Soviet records, 28,455 people were detained, 7,113 of whom died. After closing the camp, the authorities razed much of the site in order to cover up this last episode, mass graves and all.\nAftermath.\nBuchenwald trial.\nThirty SS perpetrators at Buchenwald were tried before a US military tribunal in 1947, including Higher SS and Police Leader Josias Erbprinz zu Waldeck und Pyrmont, who oversaw the SS district that Buchenwald was located in, and many of the doctors responsible for Nazi human experimentation. Almost all of the defendants were convicted, and 22 were sentenced to death. However, only nine death sentences were carried out, and by the mid-1950s, all perpetrators had been freed except for Ilse Koch, who was tried by a West German court and given a life sentence. Additional perpetrators were tried before German courts during the 1960s.\nMemorialisation.\nBetween August 1945 and 1 March 1950, Buchenwald was the site of a NKVD internment camp (see above at #Soviet internment camp). After the Stalinist camp was closed, much of the site was razed, while signs were erected to provide a Soviet interpretation of the camp's legacy.\nThe first monument to victims was erected by Buchenwald inmates days after the initial liberation. It was made of wood and only intended to be temporary. A second monument to commemorate the dead was erected in 1958 by the German Democratic Republic (GDR) government near the mass graves. It was inaugurated on 14 September 1958 by GDR Prime Minister Otto Grotewohl. Inside the camp, there is a stainless steel monument on the spot where the first, temporary monument stood. Its surface is maintained at , the temperature of human skin, all year round.\nThe three National Memorials of the GDR, built next to or on the sites of the former concentration camps Buchenwald, Sachsenhausen, and Ravensbr\u00fcck, played a central role in the GDR's remembrance policy under Erich Honecker. They were controlled by the Ministry of Culture and thus by the government. According to their statute, these memorials served as places of identification and legitimisation of the GDR. The political instrumentalisation of these memorials, especially for the current needs of the GDR, became particularly clear during the major celebrations of the liberation of the concentration camps, as historian Anne-Kathleen Tillack-Graf analysis in her thesis about the official party newspaper .\nToday the Buchenwald camp site serves as a Holocaust memorial. It has a museum with permanent exhibitions about the history of the camp. It is managed by Buchenwald and Mittelbau-Dora Memorials Foundation, which also looks after the camp memorial at Mittelbau-Dora.\nLiterature.\nSurvivors who have written about their camp experiences include Jorge Sempr\u00fan, who in \"Quel beau dimanche!\" describes conversations involving Goethe and L\u00e9on Blum, and Ernst Wiechert, whose \"Der Totenwald\" was written in 1939 but not published until 1945, and which likewise involved Goethe. Scholars have investigated how camp inmates used art to help deal with their circumstances, and according to Theodor Ziolkowski writers often did so by turning to Goethe. Artist L\u00e9on Delarbre sketched, besides other scenes of camp life, the Goethe Oak, under which he used to sit and write. One of the few prisoners who escaped from the camp, the Belgian Edmond Vandievoet, recounted his experiences in a book whose English title is \"I escaped from a Nazi Death Camp\" [Editions Jourdan, 2015]. In his work \"Night\", Elie Wiesel talks about his stay in Buchenwald, including his father's death. Jacques Lusseyran, a leader in the underground resistance to the German occupation of France, was eventually sent to Buchenwald after being arrested, and described his time there in his autobiography.\nVisit from President Obama and Chancellor Merkel.\nOn 5 June 2009 U.S. President Barack Obama and German Chancellor Angela Merkel visited Buchenwald after a tour of Dresden Castle and Church of Our Lady. During the visit they were accompanied by Elie Wiesel and Bertrand Herz, both survivors of the camp. Volkhard Knigge, the director of the Buchenwald and Mittelbau-Dora Memorials Foundation and honorary professor of University of Jena, guided the four guests through the remainder of the site of the camp. During the visit Wiesel, who together with Herz were sent to the Little camp as 16-year-old boys, said, \"if these trees could talk.\" His statement marked the irony about the beauty of the landscape and the horrors that took place within the camp. President Obama mentioned during his visit that he had heard stories as a child from his great uncle, who was part of the 89th Infantry Division, the first Americans to reach the camp at Ohrdruf, one of Buchenwald's satellites. Obama was the first sitting US president to visit the Buchenwald concentration camp.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources"}
{"id": "49267", "revid": "963789323", "url": "https://en.wikipedia.org/wiki?curid=49267", "title": "Bijective", "text": ""}
{"id": "49268", "revid": "32001896", "url": "https://en.wikipedia.org/wiki?curid=49268", "title": "Preimage", "text": ""}
{"id": "49269", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=49269", "title": "The Ten Gurus of Sikhism", "text": ""}
{"id": "49270", "revid": "4808", "url": "https://en.wikipedia.org/wiki?curid=49270", "title": "Set theoretic complement", "text": ""}
{"id": "49271", "revid": "3727527", "url": "https://en.wikipedia.org/wiki?curid=49271", "title": "Phase constant", "text": ""}
{"id": "49272", "revid": "32763026", "url": "https://en.wikipedia.org/wiki?curid=49272", "title": "Angiosperma", "text": ""}
{"id": "49274", "revid": "7852030", "url": "https://en.wikipedia.org/wiki?curid=49274", "title": "Tove Jansson", "text": "Finnish writer and illustrator (1914\u20132001)\nTove Marika Jansson (Fenno-; 9 August 1914 \u2013 27 June 2001) was a Swedish-speaking Finnish author, novelist, painter, illustrator and comic strip author. Brought up by artistic parents, Jansson studied art from 1930 to 1938 in Helsinki, Stockholm, and Paris. She held her first solo art exhibition in 1943. Over the same period, she penned short stories and articles for publication, and subsequently drew illustrations for book covers, advertisements, and postcards. She continued her work as an artist and writer for the rest of her life.\nJansson wrote the \"Moomin\" novel series for children, starting with the 1945 \"The Moomins and the Great Flood\". The following two books, \"Comet in Moominland\" and \"Finn Family Moomintroll\", published in 1946 and 1948 respectively, were highly successful, and sales of the first book increased correspondingly. For her work as a children's author she received the Hans Christian Andersen Medal in 1966; among her many later awards was the Selma Lagerl\u00f6f Prize in 1992. Her Moomin stories have been adapted for the theatre, the cinema, and as an opera.\nShe held a solo exhibition of paintings in 1955, and five more between 1960 and 1970. She carried out several commissions for murals in public buildings around Finland between 1945 and 1984. She created the illustrations both for her own books and for classics including \"Alice's Adventures in Wonderland\" and \"The Hobbit\". \nStarting with the semi-autobiographical (\"Sculptor's Daughter\") in 1968, Jansson wrote six novels, including the admired (\"The Summer Book\"), and five short story collections for adults.\nEarly life.\nTove Jansson was born in Helsinki, in the Grand Duchy of Finland, an autonomous state within Russian Empire at the time. Her family, part of the Swedish-speaking minority of Finland, was an artistic one: her father, Viktor Jansson, was a sculptor, and her mother, Signe Hammarsten-Jansson, was a Swedish-born graphic designer and illustrator. Tove's siblings also became artists: Per Olov Jansson became a photographer and Lars Jansson an author and cartoonist. Whilst their home was in Helsinki, the family spent many of their summers in a rented cottage on one of the islands of Pellinki near Porvoo, east of Helsinki; The S\u00f6dersk\u00e4r Lighthouse island off Porvoo in the Gulf of Finland may have helped to inspire her later books, such as \"Moominpappa at Sea\".\nJansson went to Finland's first co-educational school, in Helsinki. She then studied at Konstfack (University College of Arts, Crafts and Design), in Stockholm in 1930\u20131933, the Graphic School of the Finnish Academy of Fine Arts in 1933\u20131937, and finally at and in Paris in 1938. Her first solo exhibition was held in 1943.\nAt age 14, Jansson wrote and illustrated her first picture book (\"Sara and Pelle and Neptune's Children\"). It was not published until 1933. She also sold drawings that were published in magazines in the 1920s.\nIn the 1930s Jansson made several trips to other European countries. She drew from these for her short stories and articles, which she also illustrated, and which were also published in magazines, periodicals and daily papers. During this period, Jansson also designed many book covers, adverts and postcards. Following her mother's example, she drew illustrations for \"Garm\", a Finnish-Swedish political and satirical magazine.\nWork.\nMoomins.\nJansson is principally known as the author of the Moomin books. Jansson created the Moomintrolls, a family who are white, round and smooth in appearance, with large snouts that make them vaguely resemble hippopotamuses. She first drew a deliberately ugly creature as a caricature of Immanuel Kant, the philosopher; a kinder version became the Moomintroll. The first book, \"The Moomins and the Great Flood\", was published in 1945. Although the primary characters are Moominmamma and Moomintroll, most of the principal characters of later stories were only introduced in the next book, so \"The Moomins and the Great Flood\" is frequently considered a forerunner to the main series. The book was not a success, but the next two installments in the Moomin series, \"Comet in Moominland\" (1946) and \"Finn Family Moomintroll\" (1948), brought Jansson some fame.\nThe style of the Moomin books changed as time went by. The first books, written starting during the Second World War, up to \"Moominland Midwinter\" (1957), are adventure stories that include floods, comets and supernatural events. \"The Moomins and the Great Flood\" deals with Moominmamma and Moomintroll's flight through a dark and scary forest, where they encounter various dangers. In \"Comet in Moominland\", a comet nearly destroys the Moominvalley. Some critics have considered this an allegory of nuclear weapons. \"Finn Family Moomintroll\" deals with adventures brought on by the discovery of a magician's hat. \"The Exploits of Moominpappa\" (1950) tells the story of Moominpappa's adventurous youth and cheerfully parodies the genre of memoir. Finally, \"Moominsummer Madness\" (\"Farlig midsommar\", 1955) is set in a theatre: the Moomins explore the empty building and perform Moominpappa's melodrama. \n\"Moominland Midwinter\" marks a turning point in the series. Jansson described it as a book about \u201cwhat it is like when things get difficult\u201d: the story focuses on Moomintroll, who wakes up in the middle of the winter (Moomins hibernate from November to April), and has to cope with the strange and unfriendly world he finds. The short story collection \"Tales from Moominvalley\" (1962) and the novels \"Moominpappa at Sea\" (1965) and \"Moominvalley in November\" (1970) are serious and psychologically searching books, far removed from the light-heartedness and cheerful humor of \"Finn Family Moomintroll\". \"Moominvalley in November\", in which the Moomin family themselves never appear, is especially sombre in tone, possibly in consequence of the death of Jansson's mother during the year that it was written. Because of this, it has been described as being a \"textbook on letting go, being a mature orphan, existing spiritually alone\". Following this book, Jansson stated that she \"couldn't go back and find that happy Moominvalley again\" and so decided to stop writing the Moomin books.\nIn addition to the Moomin novels and short stories, Tove Jansson wrote and illustrated four picture books: \"The Book about Moomin, Mymble and Little My\" (1952), \"Who will Comfort Toffle?\" (1960), \"The Dangerous Journey\" (1977) and \"An Unwanted Guest\" (1980). As the Moomins' fame grew, two of the original novels, \"Comet in Moominland\" and \"The Exploits of Moominpappa\", were revised by Jansson and republished.\nCritics have interpreted various Moomin characters as being inspired by real people, especially members of the author's family and close friends, and Jansson spoke in interviews about the backgrounds of, and possible models for, her characters. The personality of Tuulikki Pietil\u00e4, Jansson's partner, inspired the character Too-Ticky in \"Moominland Midwinter\", while Moomintroll and Little My have been seen as psychological self-portraits of the artist. The Moomins relate strongly to Jansson's own family \u2013 they were bohemian and lived close to nature. Jansson remained close to her mother until her mother's death in 1970; even after Tove had become an adult, the two often traveled together, and during her final years Signe lived with Tove part-time. Moominpappa and Moominmamma are often seen as portraits of Jansson's parents.\nOther writing.\nJansson's first foray outside children's literature was \"Bildhuggarens dotter\" (\"Sculptor's Daughter\"), a semi-autobiographical novel published in 1968. She went on to write five more novels for adults, including (\"The Summer Book\") and five collections of short stories. \"The Summer Book\" is the best known of her adult fiction; it describes the summer stay on an island of a young girl and her grandmother. The girl is modeled on her niece, Sophia Jansson; the girl's father on Sophia's father, Lars Jansson; and the grandmother on Tove's mother Signe. Most of her novels for adults were republished into English by the publisher NYRB classics, starting with \u201cThe Summer Book,\u201d published on May 20th 2008. Since then, her novels \u201cThe True Deceiver,\u201d \u201cFair Play,\u201d and \u201cSun City,\u201d along with her short story collection, \u201cThe Woman who Borrowed Memories,\u201d have all been published and printed in English by NYRB.\nWartime satire in \"Garm\" magazine.\nTove Jansson worked as an illustrator and cartoonist for the Swedish-language satirical magazine \"Garm\" from 1929 to 1953, when the magazine ceased production. One of her political cartoons achieved a brief international fame: she drew Adolf Hitler as a crying baby in diapers, surrounded by Neville Chamberlain and other great European leaders, who tried to calm the baby down by giving it slices of cake \u2013 Austria, Poland, Czechoslovakia, etc. In the Second World War, during which Finland fought against the Soviet Union, part of the time cooperating with Nazi Germany, her cover illustrations for \"Garm\" lampooned both Hitler and Joseph Stalin: in one, Stalin draws his sword from his impressively long scabbard, only to find it absurdly short; in another, multiple Hitlers ransack a house, carrying away food and artworks. In \"The Spectator\"'s view, Jansson made both \"Hitler and Stalin appear as preposterous little figures, self-important and comic\".\nComic strip artist.\nHer earliest comic strips were created for productions including (, 1929), (', 1930), and (, 1933).\nThe figure of the Moomintroll appeared first in Jansson's political cartoons, where it was used as a signature character near the artist's name. This \"Proto-Moomin\", then called Snork or Niisku, was thin and ugly, with a long, narrow nose and devilish tail. Jansson said that she had designed the Moomins in her youth: after she lost a philosophical quarrel about Immanuel Kant with one of her brothers, she drew \"the ugliest creature imaginable\" on the wall of their outhouse and wrote under it \"Kant\". This Moomin later gained weight and a more pleasant appearance, but in the first Moomin book \"The Moomins and the Great Flood\" (originally ), the Immanuel-Kant-Moomin is still perceptible. The name \"Moomin\" comes from Tove Jansson's uncle, Einar Hammarsten: when she was studying in Stockholm and living with her Swedish relatives, her uncle tried to stop her pilfering food by telling her that a \"Moomintroll\" lived in the kitchen closet and breathed cold air down people's necks.\nIn 1952, after \"Comet in Moominland\" and \"Finn Family Moomintroll\" had been translated into English, a British newspaper man, Charles Sutton, asked if Tove Jansson would be interested in drawing comic strips about the Moomins. Jansson accepted the offer. The comic strip \"Moomintroll\" started in the London \"Evening News\", which had a circulation of 12 million at that time, making it the world's largest daily newspaper. The strip spread to hundreds of other newspapers in 12 countries.\nPainter and illustrator.\nPaintings.\nAlthough she became known first and foremost as an author, Tove Jansson considered her careers as author and painter to be of equal importance. She painted throughout her life. She exhibited during the 1930s and early 1940s, holding her first solo exhibition in 1943. Despite generally positive reviews, criticism induced Jansson to refine her style; her 1955 solo exhibition was simpler in detail and content. Between 1960 and 1970 she held five more solo exhibitions. The National Biography of Finland describes Jansson as going \"against the conventional image of an artist with her unusually even balance between visual art and writing.\"\nMurals.\nThroughout her career, Jansson created a series of commissioned murals and public works which may still be viewed in their original locations, including:\nIllustrations.\nAs well as illustrating her own books, Jansson illustrated Swedish translations of classics such as Lewis Carroll's \"The Hunting of the Snark\" and \"Alice's Adventures in Wonderland\".\nShe created a set of illustrations for the 1962 Swedish edition of J. R. R. Tolkien's 1937 children's book \"The Hobbit\". The scholar of literature Bj\u00f6rn Sundmark states that Jansson's work helped to define how Tolkien's Middle-earth fantasy could be depicted visually. The edition with her illustrations was not reprinted for many years, even though reviewers and \"Tolkienists\" liked Jansson's \"expressive\" images. Sundmark suggests that the reason was that in the 1960s, a new, more realistic style became the norm for fantasy art.\nAdaptations.\nSeveral stage productions have been made from Jansson's Moomin series, including a number that Jansson herself was involved in. The earliest production was a 1949 theatrical version of \"Comet in Moominland\" performed at \u00c5bo Svenska Teater. In the early 1950s, Jansson collaborated on Moomin-themed children's plays with Vivica Bandler. In 1952, Jansson designed stage settings and dresses for \"Pessi and Illusia\", a ballet by Ahti Sonninen () which was performed at the Finnish National Opera. By 1958, Jansson began to become directly involved in theater as Lilla Teater produced (\"Troll in the wings\"), a play with lyrics by Jansson and music composed by Erna Tauro. The production was a success, despite the actors' difficulties speaking through their bulbous \"Moominsnouts\", and later performances were held in Sweden and Norway.\nIn 1974 the first Moomin opera was produced, with music composed by Ilkka Kuusisto. The Moomintrolls have been adapted to media including television animations such as the 1990 Moomin series, and feature films.\nPersonal life.\nJansson had several male lovers, including the political philosopher Atos Wirtanen, and briefly became engaged to him. He was the inspiration for the Moomin character Snufkin. However, she eventually \"went over to the spook side\" as she is said to have put it \u2014a coded expression for homosexuality\u2014and developed a secret love affair with the married theater director Vivica Bandler.\nIn 1956 Jansson met her lifelong partner, , known as \"Tooti\". In Helsinki they lived apart but nearby, so they could meet unnoticed, but this did not resolve the problem that Jansson's mother often came to stay. They found a partial solution by building a house on a small island in the Gulf of Finland, and staying there for the summer. Jansson's and Pietil\u00e4's travels and summers spent together on the Klovharu island in Pellinki have been captured on several hours of film, shot by Pietil\u00e4. Several documentaries have been made of this footage, the latest being (\"Haru, the lonely island\") (1998) and (\"Tove and Tooti in Europe\") (2004). The character Too-ticky, described by Sue Prideaux as \"a wild-haired artistic troll in a Breton sweater and a beret\", was inspired by Pietil\u00e4.\nJansson died on 27 June 2001 at the age of 86. She is buried at the Hietaniemi Cemetery in Helsinki.\nCultural legacy.\nDocumentaries and exhibitions of her work.\nIn 1968, Swedish public TV, SVT, made a documentary about Tove called \"Moomins and the Sea\" (39 min.). Jansson's books, originally written in Swedish, have been translated into 45 languages. The Moomin Museum in Tampere displays much of Jansson's work on the Moomins. There is a Moomin theme park named Moomin World in . In 2012, the BBC broadcast a one-hour documentary on Jansson, \"Moominland Tales: The Life of Tove Jansson\". A Moominvalley Park opened at Hann\u014d, Japan in 2019.\nIn March 2014, the Ateneum Art Museum opened a major centenary exhibition showcasing Jansson's works as an artist, an illustrator, a political caricaturist and the creator of the Moomins. The exhibition drew nearly 300,000 visitors in six months. After Helsinki the exhibition embarked on a tour in Japan to visit five Japanese museums. \nIn January 2016, a permanent Tove Jansson exhibition of murals, an oil painting, photographs and sketches opened at the Helsinki Art Museum. The two murals, \"Party in the Countryside\" and \"Party in the City\" were created for Helsinki City Hall's restaurant. From June 2017 to September 2017, an exhibition of Jansson's paintings, illustrations, and cartoons was held in Kunstforeningen Gammel Strand in Copenhagen in collaboration with Ateneum in Helsinki. The exhibition then moved from October 2017 to January 2018 to the Dulwich Picture Gallery in London. This was the first major retrospective exhibition of her work in the United Kingdom.\nA biopic, titled \"Tove\", directed by Zaida Bergroth was released in October 2020.\nCommemorations.\nJansson was selected as the main motif in the 2004 minting of a Finnish commemorative coin, the \u20ac10 Tove Jansson and Finnish Children's Culture commemorative coin. The obverse depicts a combination of her portrait and the skyline, an artist's palette, a crescent and a sailing boat. The reverse features three Moomin characters. In 2014 she was again featured on a commemorative coin, this time of \u20ac20, becoming the only person other than the former Finnish president to be granted two such coins. She was featured on a \u20ac2 commemorative coin that entered general circulation in June 2014. Since 1988, Finland's Post has released several postage stamp sets and one postal card with Moomin motifs. In 2014, Jansson was featured on a Finnish stamp set. In 2014 the City of Helsinki honored Jansson by renaming a park near her childhood home in \"Tove Jansson's Park\" (, ). The city has placed a memorial plaque to Jansson at her home in Ullanlinnankatu, Helsinki.\nWhen an animated series, \"Moominvalley\" was broadcast in 2019, the journalist Rhianna Pratchett wrote an article about the impact Jansson had had on her father, the fantasy author Terry Pratchett; he called Jansson one of the greatest children's writers ever, and credited her writing as one of the reasons he became an author.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49277", "revid": "1219", "url": "https://en.wikipedia.org/wiki?curid=49277", "title": "Siegfied Sassoon", "text": ""}
{"id": "49281", "revid": "11487766", "url": "https://en.wikipedia.org/wiki?curid=49281", "title": "Hydronium", "text": "Aqueous cation H3O+\n&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nIn chemistry, hydronium (hydroxonium in traditional British English) is the cation , also written as , the type of oxonium ion produced by protonation of water. It is often viewed as the positive ion present when an Arrhenius acid is dissolved in water, as Arrhenius acid molecules in solution give up a proton (a positive hydrogen ion, ) to the surrounding water molecules (). In fact, acids must be surrounded by more than a single water molecule in order to ionize, yielding aqueous and conjugate base.\nThree main structures for the aqueous proton have garnered experimental support:\nSpectroscopic evidence from well-defined IR spectra overwhelmingly supports the Stoyanov cation as the predominant form. For this reason, it has been suggested that wherever possible, the symbol H+(aq) should be used instead of the hydronium ion.\nRelation to pH.\nThe molar concentration of hydronium or ions determines a solution's pH according to\npH = \u2212log([]/M)\nwhere M = mol/L. The concentration of hydroxide ions analogously determines a solution's pOH. The molecules in pure water auto-dissociate into aqueous protons and hydroxide ions in the following equilibrium:\nIn pure water, there is an equal number of hydroxide and ions, so it is a neutral solution. At , pure water has a pH of 7 and a pOH of 7 (this varies when the temperature changes: see self-ionization of water). A pH value less than 7 indicates an acidic solution, and a pH value more than 7 indicates a basic solution.\nNomenclature.\nAccording to IUPAC nomenclature of organic chemistry, the hydronium ion should be referred to as \"oxonium\". \"Hydroxonium\" may also be used unambiguously to identify it.\nAn oxonium ion is any cation containing a trivalent oxygen atom.\nStructure.\nSince and N have the same number of electrons, is isoelectronic with ammonia. As shown in the images above, has a trigonal pyramidal molecular geometry with the oxygen atom at its apex. The bond angle is approximately 113\u00b0, and the center of mass is very close to the oxygen atom. Because the base of the pyramid is made up of three identical hydrogen atoms, the molecule's symmetric top configuration is such that it belongs to the point group. Because of this symmetry and the fact that it has a dipole moment, the rotational selection rules are \u0394\"J\"\u00a0=\u00a0\u00b11 and \u0394\"K\"\u00a0=\u00a00. The transition dipole lies along the \"c\"-axis and, because the negative charge is localized near the oxygen atom, the dipole moment points to the apex, perpendicular to the base plane.\nAcids and acidity.\nThe hydrated proton is very acidic: at 25\u00a0\u00b0C, its p\"K\"a is approximately 0. The values commonly given for p\"K\"aaq(H3O+) are 0 or \u22121.74. The former uses the convention that the activity of the solvent in a dilute solution (in this case, water) is 1, while the latter uses the value of the concentration of water in the pure liquid of 55.5 M. Silverstein has shown that the latter value is thermodynamically unsupportable. The disagreement comes from the ambiguity that to define p\"K\"a of H3O+ in water, H2O has to act simultaneously as a solute and the solvent. The IUPAC has not given an official definition of p\"K\"a that would resolve this ambiguity. Burgot has argued that H3O+(aq) + H2O (l) \u21c4 H2O (aq) + H3O+ (aq) is simply not a thermodynamically well-defined process. For an estimate of p\"K\"aaq(H3O+), Burgot suggests taking the measured value p\"K\"aEtOH(H3O+) = 0.3, the p\"K\"a of H3O+ in ethanol, and applying the correlation equation p\"K\"aaq = p\"K\"aEtOH \u2212 1.0 (\u00b1 0.3) to convert the ethanol p\"K\"a to an aqueous value, to give a value of p\"K\"aaq(H3O+) = \u22120.7 (\u00b1 0.3). On the other hand, Silverstein has shown that Ballinger and Long's experimental results support a p\"K\"a of 0.0 for the aqueous proton. Neils and Schaertel provide added arguments for a p\"K\"a of 0.0 \nThe aqueous proton is the most acidic species that can exist in water (assuming sufficient water for dissolution): any stronger acid will ionize and yield a hydrated proton. The acidity of (aq) is the implicit standard used to judge the strength of an acid in water: strong acids must be better proton donors than (aq), as otherwise a significant portion of acid will exist in a non-ionized state (i.e.: a weak acid). Unlike (aq) in neutral solutions that result from water's autodissociation, in acidic solutions, (aq) is long-lasting and concentrated, in proportion to the strength of the dissolved acid.\npH was originally conceived to be a measure of the hydrogen ion concentration of aqueous solution. Virtually all such free protons are quickly hydrated; acidity of an aqueous solution is therefore more accurately characterized by its concentration of (aq). In organic syntheses, such as acid catalyzed reactions, the hydronium ion () is used interchangeably with the ion; choosing one over the other has no significant effect on the mechanism of reaction.\nSolvation.\nResearchers have yet to fully characterize the solvation of hydronium ion in water, in part because many different meanings of solvation exist. A freezing-point depression study determined that the mean hydration ion in cold water is approximately : on average, each hydronium ion is solvated by 6 water molecules which are unable to solvate other solute molecules.\nSome hydration structures are quite large: the magic ion number structure (called \"magic number\" because of its increased stability with respect to hydration structures involving a comparable number of water molecules \u2013 this is a similar usage of the term \"magic number\" as in nuclear physics) might place the hydronium inside a dodecahedral cage. However, more recent ab initio method molecular dynamics simulations have shown that, on average, the hydrated proton resides on the surface of the cluster. Further, several disparate features of these simulations agree with their experimental counterparts suggesting an alternative interpretation of the experimental results.\nTwo other well-known structures are the \"Zundel cation\" and the \"Eigen cation\". The Eigen solvation structure has the hydronium ion at the center of an complex in which the hydronium is strongly hydrogen-bonded to three neighbouring water molecules. In the Zundel complex the proton is shared equally by two water molecules in a symmetric hydrogen bond. A work in 1999 indicates that both of these complexes represent ideal structures in a more general hydrogen bond network defect.\nIsolation of the hydronium ion monomer in liquid phase was achieved in a nonaqueous, low nucleophilicity superacid solution (). The ion was characterized by high resolution nuclear magnetic resonance.\nA 2007 calculation of the enthalpies and free energies of the various hydrogen bonds around the hydronium cation in liquid protonated water at room temperature and a study of the proton hopping mechanism using molecular dynamics showed that the hydrogen-bonds around the hydronium ion (formed with the three water ligands in the first solvation shell of the hydronium) are quite strong compared to those of bulk water.\nA new model was proposed by Stoyanov based on infrared spectroscopy in which the proton exists as an ion. The positive charge is thus delocalized over 6 water molecules.\nSolid hydronium salts.\nFor many strong acids, it is possible to form crystals of their hydronium salt that are relatively stable. These salts are sometimes called \"acid monohydrates\". As a rule, any acid with an ionization constant of 109 or higher may do this. Acids whose ionization constants are below 109 generally cannot form stable salts. For example, nitric acid has an ionization constant of 101.4, and mixtures with water at all proportions are liquid at room temperature. However, perchloric acid has an ionization constant of 1010, and if liquid anhydrous perchloric acid and water are combined in a 1:1 molar ratio, they react to form solid hydronium perchlorate ().\nThe hydronium ion also forms stable compounds with the carborane superacid . X-ray crystallography shows a symmetry for the hydronium ion with each proton interacting with a bromine atom each from three carborane anions 320 pm apart on average. The salt is also soluble in benzene. In crystals grown from a benzene solution the solvent co-crystallizes and a cation is completely separated from the anion. In the cation three benzene molecules surround hydronium forming pi-cation interactions with the hydrogen atoms. The closest (non-bonding) approach of the anion at chlorine to the cation at oxygen is 348 pm.\nThere are also many known examples of salts containing hydrated hydronium ions, such as the ion in , the and ions both found in .\nSulfuric acid is also known to form a hydronium salt at temperatures below .\nInterstellar H3O+.\nHydronium is an abundant molecular ion in the interstellar medium and is found in diffuse and dense molecular clouds as well as the plasma tails of comets. Interstellar sources of hydronium observations include the regions of Sagittarius B2, Orion OMC-1, Orion BN\u2013IRc2, Orion KL, and the comet Hale\u2013Bopp.\nInterstellar hydronium is formed by a chain of reactions started by the ionization of into by cosmic radiation. can produce either or through dissociative recombination reactions, which occur very quickly even at the low (\u226510 K) temperatures of dense clouds. This leads to hydronium playing a very important role in interstellar ion-neutral chemistry.\nAstronomers are especially interested in determining the abundance of water in various interstellar climates due to its key role in the cooling of dense molecular gases through radiative processes. However, does not have many favorable transitions for ground-based observations. Although observations of HDO (the deuterated version of water) could potentially be used for estimating abundances, the ratio of HDO to is not known very accurately.\nHydronium, on the other hand, has several transitions that make it a superior candidate for detection and identification in a variety of situations. This information has been used in conjunction with laboratory measurements of the branching ratios of the various dissociative recombination reactions to provide what are believed to be relatively accurate and abundances without requiring direct observation of these species.\nInterstellar chemistry.\nAs mentioned previously, is found in both diffuse and dense molecular clouds. By applying the reaction rate constants (\"\u03b1\", \"\u03b2\", and \"\u03b3\") corresponding to all of the currently available characterized reactions involving , it is possible to calculate \"k\"(\"T\") for each of these reactions. By multiplying these \"k\"(\"T\") by the relative abundances of the products, the relative rates (in cm3/s) for each reaction at a given temperature can be determined. These relative rates can be made in absolute rates by multiplying them by the . By assuming \"T\"\u00a0=\u00a010\u00a0K for a dense cloud and \"T\"\u00a0=\u00a050\u00a0K for a diffuse cloud, the results indicate that most dominant formation and destruction mechanisms were the same for both cases. It should be mentioned that the relative abundances used in these calculations correspond to TMC-1, a dense molecular cloud, and that the calculated relative rates are therefore expected to be more accurate at \"T\"\u00a0=\u00a010\u00a0K. The three fastest formation and destruction mechanisms are listed in the table below, along with their relative rates. Note that the rates of these six reactions are such that they make up approximately 99% of hydronium ion's chemical interactions under these conditions. All three destruction mechanisms in the table below are classified as dissociative recombination reactions.\nIt is also worth noting that the relative rates for the formation reactions in the table above are the same for a given reaction at both temperatures. This is due to the reaction rate constants for these reactions having \"\u03b2\" and \"\u03b3\" constants of 0, resulting in \"k\"\u00a0=\u00a0\"\u03b1\" which is independent of temperature.\nSince all three of these reactions produce either or OH, these results reinforce the strong connection between their relative abundances and that of . The rates of these six reactions are such that they make up approximately 99% of hydronium ion's chemical interactions under these conditions.\nAstronomical detections.\nAs early as 1973 and before the first interstellar detection, chemical models of the interstellar medium (the first corresponding to a dense cloud) predicted that hydronium was an abundant molecular ion and that it played an important role in ion-neutral chemistry. However, before an astronomical search could be underway there was still the matter of determining hydronium's spectroscopic features in the gas phase, which at this point were unknown. The first studies of these characteristics came in 1977, which was followed by other, higher resolution spectroscopy experiments. Once several lines had been identified in the laboratory, the first interstellar detection of H3O+ was made by two groups almost simultaneously in 1986. The first, published in June 1986, reported observation of the \"J\"\u00a0=\u00a01\u00a0\u2212\u00a02 transition at in OMC-1 and Sgr B2. The second, published in August, reported observation of the same transition toward the Orion-KL nebula.\nThese first detections have been followed by observations of a number of additional transitions. The first observations of each subsequent transition detection are given below in chronological order:\nIn 1991, the 3\u00a0\u2212\u00a02 transition at was observed in OMC-1 and Sgr B2. One year later, the 3\u00a0\u2212\u00a02 transition at was observed in several regions, the clearest of which was the W3\u00a0IRS\u00a05 cloud.\nThe first far-IR 4\u00a0\u2212\u00a03 transition at 69.524\u00a0\u03bcm (4.3121\u00a0THz) was made in 1996 near Orion BN-IRc2. In 2001, three additional transitions of in were observed in the far infrared in Sgr\u00a0B2; 2\u00a0\u2212\u00a01 transition at 100.577\u00a0\u03bcm (2.98073 THz), 1\u00a0\u2212\u00a01 at 181.054\u00a0\u03bcm (1.65582 THz) and 2\u00a0\u2212\u00a01 at 100.869\u00a0\u03bcm (2.9721 THz).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49284", "revid": "50776203", "url": "https://en.wikipedia.org/wiki?curid=49284", "title": "Methylchloroisothiazolinone", "text": "&lt;templatestyles src=\"Chembox/styles.css\"/&gt;\nChemical compound\nMethylchloroisothiazolinone, also referred to as MCI, is the organic compound with the formula S(C2HCl)C(O)N(CH3). It is a white solid that melts near room temperature. The compound is an isothiazolinone, a class of heterocycles used as biocides. These compounds have an active sulphur moiety that is able to oxidize thiol-containing residues, thereby effectively killing most aerobic and anaerobic bacteria. MCI is often used in combination with methylisothiazolinone, a mixture known as Kathon. The isothiazolinones have attracted attention because they can cause contact dermatitis. Methylchloroisothiazolinone is effective against gram-positive and gram-negative bacteria, yeast, and fungi.\nApplication.\nMethylchloroisothiazolinone is found in many water-based personal care products and cosmetics. Methylchloroisothiazolinone was first used in cosmetics in the 1970s. It is also used in glue production, detergents, paints, fuels, and other industrial processes. Methylchloroisothiazolinone is known by the registered tradename \"Kathon\" CG when used in combination with methylisothiazolinone.\nMethylchloroisothiazolinone may be used in combination with other preservatives including ethylparaben, benzalkonium chloride, bronopol, and phenoxyethanol.\nHazards.\nMethylchloroisothiazolinone can cause allergic reactions in some people. The first publication of the preservative as a contact allergen was in 1988. Cases of photoaggravated allergic contact dermatitis, i.e. worsening of skin lesions after sun exposure, have also been reported.\nIn pure form or in high concentrations, methylchloroisothiazolinone is a skin and membrane irritant and causes chemical burns. In the United States, maximum authorized concentrations are 15 ppm in rinse-offs (of a mixture in the ratio 3:1 of 5-chloro-2-methylisothiazol 3(2H)-one and 2-methylisothiazol-3 (2H)-one). In Canada, methylchloroisothiazolinone may only be used in rinse-off products in combination with methylisothiazolinone, the total concentration of the combination may not exceed 15 ppm.\nMethylisothiazolinone is considered safe in the allowed amount in rinse-off products (0.01%) and safe in leave-in products when formulated to be non-sensitizing.\nIncidents.\nAn overdose of Kathon by aircraft maintenance personnel, using 38 times the correct amount, resulted in damage to both engines of a Titan Airways aircraft in February 2020. After losing both engines in succession, the Airbus A321 made an emergency landing at Gatwick Airport. The maintenance procedures specified the Kathon to be diluted to 100 PPM by volume, but with the aircraft maintenance technician being unfamiliar with the term \"PPM\" and the term not being defined in the aircraft maintenance manuals, the technician instead used an online calculator to convert PPM to percentages, misinterpreted the answer, and added 30\u00a0kg of Kathon to each wing tank, which was over 38 times the required amount. Over the course of the next day, the Kathon progressively caused more and more damage to the engines, finally resulting in an emergency landing.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49285", "revid": "1228428618", "url": "https://en.wikipedia.org/wiki?curid=49285", "title": "Computable", "text": ""}
{"id": "49287", "revid": "50812719", "url": "https://en.wikipedia.org/wiki?curid=49287", "title": "USS Winston S. Churchill", "text": "Arleigh Burke-class destroyer\n \nUSS \"Winston S. Churchill\" (DDG-81) is an (Flight IIA) Aegis guided missile destroyer of the United States Navy. She is named after Sir Winston Churchill, former Prime Minister of the United Kingdom. She is the 18th ship of the class to be built at Bath Iron Works in Bath, Maine. Construction began on 7 May 1998, and the vessel launched and christened on 17 April 1999. On 10 March 2001, she was commissioned during a ceremony at Town Point Park in Norfolk, Virginia.\nNaming.\nOn 29 November 1995, on a visit to the United Kingdom, President Bill Clinton announced to the British Parliament that a new warship would be named after Sir Winston Churchill. She was the first destroyer and fourth American warship named after a British citizen, and the first since 1976 named after a non-U.S. citizen (that being ), though Churchill was an honorary U.S. citizen and his mother Lady Randolph Churchill was American-born.\nThe three other U.S. warships which had been named after Britons included the Continental Navy frigates (named after Alfred the Great) and (named after Sir Walter Raleigh, though three subsequent USS \"Raleigh\"s\u2014and two Confederate warships\u2014would be named after the North Carolina city, which did not exist at the time), and , named after Thomas Howard, 3rd Earl of Effingham who resigned his commission rather than fight the Americans during the American Revolutionary War. The former frigate was also named after a person from a country in the Commonwealth of Nations, Harold Holt, the Australian Prime Minister, who disappeared, (presumed drowned), while still in office just a year before \"Harold E. Holt\" was laid down. \"Winston S. Churchill\" is the first ship to be named after a British citizen or British Prime Minister of the modern era.\n\"Winston S. Churchill\" is the only U.S. Navy vessel to have a Royal Navy exchange officer permanently assigned to the ship's company (usually a Navigation Officer). The U.S. Navy had a permanent U.S. Navy Officer on the Royal Navy ship until her decommissioning on 8 July 2005. \"Winston S. Churchill\" is also the only U.S. Naval vessel to fly a foreign ensign. Being named after a Briton, the Royal Navy's White Ensign is honorarily flown on special occasions from the ship's mast, on the port side, whereas the U.S. flag is flown from the starboard side. However, during normal operations, only the U.S. flag is flown on the center of the main mast.\nDesign.\nThe ship is the first of the Flight IIA variants fitted with the 62-caliber Mark 45 Mod 4 naval gun system. The guns' longer barrels allow more complete combustion of the propellant, reducing barrel flare and improving projectile velocity and firepower against ship and shore targets; additionally, the Mk 45 mod 4 uses a modified gun-house, designed to reduce its radar signature. \"Winston S. Churchill\" is armed with Tomahawk, Standard and ASROC (VLA) missiles.\nThe vessel additionally contains two hangars, not present in earlier destroyers; these can house Light Airborne Multi-Purpose System (LAMPS) Sikorsky SH-60B or MH-60R Seahawk helicopters. These LAMPS can be fitted with air-to-surface missiles for surface ship attacks, and torpedoes for submarine attacks.\nThe ship is also fitted with the AN/SPY-1D phased array radar\u2014this represents a significant advancement in the detection capabilities of the Aegis weapon system and provides enhanced resistance to electronic countermeasures. The radar can guide more than one hundred missiles at once to targets as far as .\nService history.\nThe contract to build \"Winston S. Churchill\" was awarded to the Bath Iron Works Corporation on 6 January 1995, and the keel was laid down on 7 May 1998. \"Winston S. Churchill\" was launched on 17 April 1999, delivered 13 October 2000, and commissioned 10 March 2001. The launch and christening of the ship was co-sponsored by Lady Soames, the daughter of Winston Churchill, and Mrs. Janet Cohen, wife of the Secretary of Defense. Her first commanding officer was Commander (and future Vice Admiral) Michael T. Franken.\nDuring May\u2013June 2001, \"Winston S. Churchill\" underwent shock trials 100 nautical miles off the coast of Naval Station Mayport, Florida. These trials subjected the ship to various close-range underwater detonations, and were performed to collect data concerning ship survivability and damage resistance in a modern threat environment. \"Winston S. Churchill\" sustained minor damage during these three tests. The tests cost 20 million dollars. \nOn 14 September 2001 (three days after the 11 September 2001 attacks), the German Navy destroyer passed close abeam \"Winston S. Churchill\" and rendered honors by manning the rails, flying the Stars and Stripes at half-mast, and the display of a banner reading \"We Stand By You\". An e-mail sent by an ensign on board \"Winston S. Churchill\" described the occasion.\nIn January 2003, \"Winston S. Churchill\" deployed with the battle group in support of the Iraq War's Operation Iraqi Freedom, firing several Tomahawk missiles. \"Winston S. Churchill\" returned to Norfolk at the end of May 2003.\nOn 22 August 2005, \"Winston S. Churchill\" was involved in a minor collision with the destroyer off the coast of Jacksonville, Florida. Both ships suffered minor damage, and no injuries were reported. Both ships returned to their homeport at Naval Station Norfolk under their own power.\nOn 22 January 2006 \"Winston S. Churchill\" captured a suspected pirate vessel in the Indian Ocean as part of an ongoing effort to help maintain law and order in the region.\nOn 26 September 2010, \"Winston S. Churchill\" came across a disabled skiff in the Gulf of Aden. After attempts to repair the skiff's engines failed \"Winston S. Churchill\" took the vessel under tow towards Somalia. On 27 September the skiff sank when the 85 passengers rushed to one side of the skiff during a food delivery, causing the vessel to capsize. \"Winston S. Churchill\" was able to rescue 61 of the passengers and continued towards Somalia on 28 September.\nHer homeport was formerly Naval Station Norfolk, and became Naval Station Mayport, Florida on 19 July 2021. She is currently a part of Carrier Strike Group 12.\nOn 11\u201312 February 2021, \"Winston S. Churchill\" seized thousands of weapons from two stateless dhows off the coast of Somalia.\nCoat of arms.\nShield.\nThe shield features an inescutcheon of Churchill's ancestral coat of arms and the cross of St. George. The traditional Navy colors were chosen for the shield because dark blue and gold represents the sea and excellence respectively. Red signifies sacrifice and valor. The cross of St. George and the fleur-de-lis are from Churchill's augmentation from his ancestor's coat of arms. The red cross on the white field is a reference to the flag of St. George. The gold lion over the field of red is a reference to the heritage of Great Britain. The lion shows strength, courage and determination. The nebuly is representative of the sky and clouds, which recall Britain enduring German airpower in the Battle of Britain. Winston Churchill's reputation as an inspiring war leader, talented statesman, orator and author is referred to by the stylized book.\nCrest.\nThe crest consists of a trident encompassed by a chevron, laurel and oak. The trident is a symbol for sea prowess and represents the ship's vertical launch capabilities. The tridents tines denote air, surface, and anti-submarine warfare capabilities. A chevron divides the trident which suggests a \"V\" to signify victory in way and strength of defense in peace. The laurel symbolizes honor and achievement while the oak represents strength and resolve.\nMotto.\nThe motto is written on a double scroll of red that has a white reverse side. The ship's motto, \"In war: Resolution. In peace: Good Will\", is taken from the epigraph of Churchill's \"The Second World War\".\nSeal.\nThe coat of arms in full color as in the blazon, upon a white background enclosed within a dark blue oval border edged on the outside with a gold rope and bearing the inscription \"USS Winston S. Churchill\" at the top and \"DDG 81\" in the base, all gold.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49288", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=49288", "title": "USS Churchill", "text": ""}
{"id": "49295", "revid": "48181213", "url": "https://en.wikipedia.org/wiki?curid=49295", "title": "Fine-structure constant", "text": "Dimensionless number that quantifies the strength of the electromagnetic interaction\nIn physics, the fine-structure constant, also known as the Sommerfeld constant, commonly denoted by formula_1 (the Greek letter \"alpha\"), is a fundamental physical constant that quantifies the strength of the electromagnetic interaction between elementary charged particles.\nIt is a dimensionless quantity (dimensionless physical constant), independent of the system of units used, which is related to the strength of the coupling of an elementary charge formula_2 with the electromagnetic field, by the formula &amp;NoBreak;}&amp;NoBreak;. Its numerical value is approximately \u2248, with a relative uncertainty of .\nThe constant was named by Arnold Sommerfeld, who introduced it in 1916 when extending the Bohr model of the atom. formula_1 quantified the gap in the fine structure of the spectral lines of the hydrogen atom, which had been measured precisely by Michelson and Morley in 1887.\nWhy the constant should have this value is not understood, but there are a number of ways to measure its value.\nDefinition.\nIn terms of other physical constants, formula_1 may be defined as:\n formula_5\nwhere\n formula_6 is the elementary charge (\u200d);\n formula_7 is the Planck constant (\u200d);\n formula_8 is the reduced Planck constant, formula_9 (\u200d)\n formula_10 is the speed of light (\u200d);\n formula_11 is the electrical permittivity of space (\u200d).\nSince the 2019 revision of the SI, the only quantity in this list that does not have an exact value in SI units is the electric constant (vacuum permittivity).\nAlternative systems of units.\nThe electrostatic CGS system implicitly sets &amp;NoBreak;&amp;NoBreak;, as commonly found in older physics literature, where the expression of the fine-structure constant becomes\n formula_12\nA normalised system of units commonly used in high energy physics selects artificial units for mass, distance, time, and electrical charge which cause formula_13 in such a system of \"natural units\" the expression for the fine-structure constant becomes\n formula_14\nAs such, the fine-structure constant is chiefly a quantity determining (or determined by) the elementary charge: in terms of such a natural unit of charge.\nIn the system of atomic units, which sets &amp;NoBreak;&amp;NoBreak;, the expression for the fine-structure constant becomes\n formula_15\nMeasurement.\nThe CODATA recommended value of \"\u03b1\" is\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt; This has a relative standard uncertainty of .\nThis value for \"\u03b1\" gives the following value for the vacuum magnetic permeability (magnetic constant): \u00b50 = 4\"\u03c0\" \u00d7, with the mean differing from the old defined value by only 0.13\u00a0parts per billion, 0.8 times the standard uncertainty (0.16 parts per billion) of its recommended measured value.\nHistorically, the value of the reciprocal of the fine-structure constant is often given. The CODATA recommended value is \n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nWhile the value of \u03b1 can be determined from estimates of the constants that appear in any of its definitions, the theory of quantum electrodynamics (QED) provides a way to measure \u03b1 directly using the quantum Hall effect or the anomalous magnetic moment of the electron. Other methods include the A.C.\u00a0Josephson effect and photon recoil in atom interferometry.\nThere is general agreement for the value of \u03b1, as measured by these different methods. The preferred methods in 2019 are measurements of electron anomalous magnetic moments and of photon recoil in atom interferometry. The theory of QED predicts a relationship between the dimensionless magnetic moment of the electron and the fine-structure constant \u03b1 (the magnetic moment of the electron is also referred to as the electron g-factor \"g\"e). One of the most precise values of \u03b1 obtained experimentally (as of 2023) is based on a measurement of \"g\"e using a one-electron so-called \"quantum cyclotron\" apparatus, together with a calculation via the theory of QED that involved tenth-order Feynman diagrams:\nThis measurement of \u03b1 has a relative standard uncertainty of . This value and uncertainty are about the same as the latest experimental results.\nFurther refinement of the experimental value was published by the end of 2020, giving the value\n&lt;templatestyles src=\"Block indent/styles.css\"/&gt;\nwith a relative accuracy of , which has a significant discrepancy from the previous experimental value.\nPhysical interpretations.\n . The Heisenberg uncertainty principle momentum/position uncertainty relationship of such an electron is just . The relativistic limiting value for v is c, and so the limiting value for Z is the reciprocal of the fine-structure constant, 137.\nWhen perturbation theory is applied to quantum electrodynamics, the resulting perturbative expansions for physical results are expressed as sets of power series in \u03b1. Because \u03b1 is much less than one, higher powers of \u03b1 are soon unimportant, making the perturbation theory practical in this case. On the other hand, the large value of the corresponding factors in quantum chromodynamics makes calculations involving the strong nuclear force extremely difficult.\nVariation with energy scale.\nIn quantum electrodynamics, the more thorough quantum field theory underlying the electromagnetic coupling, the renormalization group dictates how the strength of the electromagnetic interaction grows logarithmically as the relevant energy scale increases. The value of the fine-structure constant \u03b1 is linked to the observed value of this coupling associated with the energy scale of the electron mass: the electron's mass gives a lower bound for this energy scale, because it (and the positron) is the lightest charged object whose quantum loops can contribute to the running. Therefore, is the asymptotic value of the fine-structure constant at zero energy. \nAt higher energies, such as the scale of the Z boson, about 90\u00a0GeV, one instead measures an \"effective\" \u03b1 \u2248 1/127.\nAs the energy scale increases, the strength of the electromagnetic interaction in the Standard Model approaches that of the other two fundamental interactions, a feature important for grand unification theories. If quantum electrodynamics were an exact theory, the fine-structure constant would actually diverge at an energy known as the Landau pole \u2013 this fact undermines the consistency of quantum electrodynamics beyond perturbative expansions.\nHistory.\nBased on the precise measurement of the hydrogen atom spectrum by Michelson and Morley in 1887, \nArnold Sommerfeld extended the Bohr model to include elliptical orbits and relativistic dependence of mass on velocity. He introduced a term for the fine-structure constant in 1916.\nThe first physical interpretation of the fine-structure constant \u03b1 was as the ratio of the velocity of the electron in the first circular orbit of the relativistic Bohr atom to the speed of light in the vacuum.\nEquivalently, it was the quotient between the minimum angular momentum allowed by relativity for a closed orbit, and the minimum angular momentum allowed for it by quantum mechanics. It appears naturally in Sommerfeld's analysis, and determines the size of the splitting or fine-structure of the hydrogenic spectral lines. This constant was not seen as significant until Paul Dirac's linear relativistic wave equation in 1928, which gave the exact fine structure formula.\nWith the development of quantum electrodynamics (QED) the significance of \"\u03b1\" has broadened from a spectroscopic phenomenon to a general coupling constant for the electromagnetic field, determining the strength of the interaction between electrons and photons. The term is engraved on the tombstone of one of the pioneers of QED, Julian Schwinger, referring to his calculation of the anomalous magnetic dipole moment.\nHistory of measurements.\nThe CODATA values in the above table are computed by averaging other measurements; they are not independent experiments.\nPotential variation over time.\nPhysicists have pondered whether the fine-structure constant is in fact constant, or whether its value differs by location and over time. A varying \u03b1 has been proposed as a way of solving problems in cosmology and astrophysics. String theory and other proposals for going beyond the Standard Model of particle physics have led to theoretical interest in whether the accepted physical constants (not just \u03b1) actually vary.\nIn the experiments below, \u0394\"\u03b1\" represents the change in \u03b1 over time, which can be computed by \u03b1past \u2212 \u03b1now\u00a0. If the fine-structure constant really is a constant, then any experiment should show that\nformula_20\nor as close to zero as experiment can measure. Any value far away from zero would indicate that \u03b1 does change over time. So far, most experimental data is consistent with \u03b1 being constant, up to 10 digits of accuracy.\nPast rate of change.\nThe first experimenters to test whether the fine-structure constant might actually vary examined the spectral lines of distant astronomical objects and the products of radioactive decay in the Oklo natural nuclear fission reactor. Their findings were consistent with no variation in the fine-structure constant between these two vastly separated locations and times.\nImproved technology at the dawn of the 21st century made it possible to probe the value of \u03b1 at much larger distances and to a much greater accuracy. In 1999, a team led by John K. Webb of the University of New South Wales claimed the first detection of a variation in \u03b1.\nUsing the Keck telescopes and a data set of 128 quasars at redshifts 0.5 &lt; \"z\" &lt; 3, Webb \"et al.\" found that their spectra were consistent with a slight increase in \u03b1 over the last 10\u201312\u00a0billion years. Specifically, they found that\nformula_21\nIn other words, they measured the value to be somewhere between and . This is a very small value, but the error bars do not actually include zero. This result either indicates that \u03b1 is not constant or that there is experimental error unaccounted for.\nIn 2004, a smaller study of 23\u00a0absorption systems by Chand \"et al.\", using the Very Large Telescope, found no measurable variation:\nformula_22\nHowever, in 2007 simple flaws were identified in the analysis method of Chand \"et al.\", discrediting those results.\nKing \"et al.\" have used Markov chain Monte Carlo methods to investigate the algorithm used by the UNSW group to determine from the quasar spectra, and have found that the algorithm appears to produce correct uncertainties and maximum likelihood estimates for for particular models. This suggests that the statistical uncertainties and best estimate for stated by Webb \"et al.\" and Murphy \"et al.\" are robust.\nLamoreaux and Torgerson analyzed data from the Oklo natural nuclear fission reactor in 2004, and concluded that \u03b1 has changed in the past 2\u00a0billion years by 45\u00a0parts per billion. They claimed that this finding was \"probably accurate to within 20%\". Accuracy is dependent on estimates of impurities and temperature in the natural reactor. These conclusions have yet to be verified.\nIn 2007, Khatri and Wandelt of the University of Illinois at Urbana-Champaign realized that the 21\u00a0cm hyperfine transition in neutral hydrogen of the early universe leaves a unique absorption line imprint in the cosmic microwave background radiation. They proposed using this effect to measure the value of \u03b1 during the epoch before the formation of the first stars. In principle, this technique provides enough information to measure a variation of 1\u00a0part in (4\u00a0orders of magnitude better than the current quasar constraints). However, the constraint which can be placed on \u03b1 is strongly dependent upon effective integration time, going as &lt;templatestyles src=\"Fraction/styles.css\" /&gt;\u2044. The European LOFAR radio telescope would only be able to constrain to about 0.3%. The collecting area required to constrain to the current level of quasar constraints is on the order of 100\u00a0square kilometers, which is economically impracticable at present.\nPresent rate of change.\nIn 2008, Rosenband \"et al.\" used the frequency ratio of and in single-ion optical atomic clocks to place a very stringent constraint on the present-time temporal variation of \u03b1, namely = per year. A present day null constraint on the time variation of alpha does not necessarily rule out time variation in the past. Indeed, some theories that predict a variable fine-structure constant also predict that the value of the fine-structure constant should become practically fixed in its value once the universe enters its current dark energy-dominated epoch.\nSpatial variation \u2013 Australian dipole.\nResearchers from Australia have said they had identified a variation of the fine-structure constant across the observable universe.\nThese results have not been replicated by other researchers. In September and October\u00a02010, after released research by Webb \"et al.\", physicists C. Orzel and S.M. Carroll separately suggested various approaches of how Webb's observations may be wrong. Orzel argues that the study may contain wrong data due to subtle differences in the two telescopes.\nCarroll takes an altogether different approach: he looks at the fine-structure constant as a scalar field and claims that if the telescopes are correct and the fine-structure constant varies smoothly over the universe, then the scalar field must have a very small mass. However, previous research has shown that the mass is not likely to be extremely small. Both of these scientists' early criticisms point to the fact that different techniques are needed to confirm or contradict the results, a conclusion Webb, \"et al\"., previously stated in their study.\nOther research finds no meaningful variation in the fine-structure constant.\nAnthropic explanation.\nThe anthropic principle provides an argument as to the reason the fine-structure constant has the value it does: stable matter, and therefore life and intelligent beings, could not exist if its value were very different. For instance, if modern grand unified theories are correct, then \u03b1 needs to be between around 1/180 and 1/85 to have proton decay to be slow enough for life to be possible.\nNumerological explanations.\nAs a dimensionless constant which does not seem to be directly related to any mathematical constant, the fine-structure constant has long fascinated physicists.\nArthur Eddington argued that the value could be \"obtained by pure deduction\" and he related it to the Eddington number, his estimate of the number of protons in the universe.\nThis led him in 1929 to conjecture that the reciprocal of the fine-structure constant was not approximately but precisely the integer 137.\nBy the 1940s experimental values for deviated sufficiently from 137 to refute Eddington's arguments.\nPhysicist Wolfgang Pauli commented on the appearance of certain numbers in physics, including the fine-structure constant, which he also noted approximates reciprocal of the prime number 137. This constant so intrigued him that he collaborated with psychoanalyst Carl Jung in a quest to understand its significance. Similarly, Max Born believed that if the value of \u03b1 differed, the universe would degenerate, and thus that \u03b1 = is a law of nature.\nRichard Feynman, one of the originators and early developers of the theory of quantum electrodynamics (QED), referred to the fine-structure constant in these terms:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nConversely, statistician I. J. Good argued that a numerological explanation would only be acceptable if it could be based on a good theory that is not yet known but \"exists\" in the sense of a Platonic Ideal.\nAttempts to find a mathematical basis for this dimensionless constant have continued up to the present time. However, no numerological explanation has ever been accepted by the physics community.\nIn the late 20th century, multiple physicists, including Stephen Hawking in his 1988 book \"A Brief History of Time\", began exploring the idea of a multiverse, and the fine-structure constant was one of several universal constants that suggested the idea of a fine-tuned universe.\nQuotes.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;M.H. MacGregor (2007)\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;When I die my first question to the Devil will be: What is the meaning of the fine structure constant?\u2014\u200a\nFootnotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49296", "revid": "1", "url": "https://en.wikipedia.org/wiki?curid=49296", "title": "Eldred v. Reno", "text": ""}
{"id": "49298", "revid": "1306823975", "url": "https://en.wikipedia.org/wiki?curid=49298", "title": "Haidinger's brush", "text": "Visible effect of polarised light\nHaidinger's brush, more commonly known as Haidinger's brushes is an image produced by the eye, an entoptic phenomenon, first described by Austrian physicist Wilhelm Karl von Haidinger in 1844. Haidinger saw it when he looked through various minerals that polarized light.\nMany people are able to perceive polarization of light. Haidinger's brushes may be seen as a yellowish horizontal bar or bow-tie shape (with \"fuzzy\" ends, hence the name \"brush\") visible in the center of the visual field against the blue sky viewed while facing away from the sun, or on any bright background. It typically occupies roughly 3\u20135 degrees of vision, about twice or three times the width of one's thumb held at arm's length. The direction of light polarization is perpendicular to the yellow bar (i.e., vertical if the bar is horizontal). Fainter bluish or purplish areas may be visible between the yellow brushes (see illustration). Haidinger's brush may also be seen by looking at a white area on many LCD flat panel computer screens (due to the polarization effect of the display), in which case it is often diagonal.\nPhysiological causes.\nHaidinger's brush is usually attributed to the dichroism of the xanthophyll pigment found in the macula lutea. As described by the Fresnel laws, the behavior and distribution of oblique rays in the cylindrical geometry of the foveal blue cones produce an extrinsic dichroism. The size of the brush is consistent with the size of the macula.\nIt is thought that the macula's dichroism arises from some of its pigment molecules being arranged circularly; (the small proportion of circularly arranged molecules accounts for the faintness of the phenomenon.) Xanthophyll pigments tend to be parallel to the retinal ganglion cell axons that (because the fovea is not flat), are almost orthogonal to the fovea in its central part but nearly parallel in its outer region. As a result, two different areas of the fovea can be sensitive to two different degrees of polarization.\nSeeing Haidinger's brush.\nMany people find it difficult to see Haidinger's brush initially. It is very faint, much more so than generally indicated in illustrations, and, like other stabilized images, tends to appear and disappear.\nIt is most easily seen when it can be made to move. Because it is always positioned on the macula, there is no way to make it move laterally, but it can be made to rotate, by viewing a white surface through a rotating polarizer, or by slowly tilting one's head to one side.\nTo see Haidinger's brush, start by using a polarizer, such as a lens from a pair of polarizing sunglasses. Gaze at an evenly lit, textureless surface through the lens and rotate the polarizer.\nAn option is to use the polarizer built into a computer's LCD screen. Look at a white area on the screen, and slowly tilt the head (this method generally works only with LCDs, as most other electronic visual display technologies do not emit polarized light).\nIt appears with more distinctness against a blue background. With practice, it is possible to see it in the naturally polarized light of a blue sky. Minnaert recommended practicing first with a polarizer, then trying it without. The areas of the sky with the strongest polarization are those 90 degrees away from the sun. Minnaert said that after a minute of gazing at the sky, \"a kind of marble effect will appear. This is followed shortly by Haidinger's brush.\" He commented that not all observers see it in the same way. Some see the yellow pattern as solid and the blue pattern as interrupted, as in the illustrations on this page. Some see the blue as solid and the yellow as interrupted, and some see it alternating between the two states.\nUse.\nThe fact that the sensation of Haidinger's brush corresponds with the visual field of the macula means that it can be utilised in training people to look at objects with their macula. People with certain types of strabismus may undergo an adaptation whereupon they look at the object of attention not with their fovea (at the centre of the macula) but with an eccentric region of the retina. This adaptation is known as eccentric fixation. To aid in training a person to look at an object with their fovea rather than their eccentric retinal zone, a training device can be used. One such apparatus utilises a rotating polarised plate backlit with a bright white light. Wearing blue spectacles (to enhance the Haidinger's brush image) and an occluder over the other eye, the user will hopefully notice the Haidinger's brush where their macula correlates with their visual field. The goal of the training is for the user to learn to look at the test object in such a way that the Haidinger's brush overlaps the test object (and the viewer is thus now looking at it with their fovea). The reason for such training is that the healthy fovea is far greater in its resolving power than any other part of the retina. Another diagnostic method that utilises birefringent properties of the retinal tissue is retinal birefringence scanning, that can be used in case of severe amblyopia or when the specialist lacks a cooperation from the patient.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49299", "revid": "49194408", "url": "https://en.wikipedia.org/wiki?curid=49299", "title": "Nellie Tayloe Ross", "text": "American politician (1876\u20131977)\nNellie Davis Tayloe Ross (n\u00e9e Tayloe; November 29, 1876 \u2013 December 19, 1977) was an American educator and politician who served as the 14th governor of Wyoming from 1925 to 1927, and as the 28th and first female director of the United States Mint from 1933 to 1953. She was the first woman to serve as governor of a U.S. state, and remains the only woman to have served as governor of Wyoming. She was a Democrat and supported Prohibition.\nRoss was born in St. Joseph, Missouri, to James Wynns Tayloe, a native of Tennessee, and Elizabeth Blair Green, who owned a plantation on the Missouri River. Her family moved to Miltonvale, Kansas in 1884, and she graduated from Miltonvale High School in 1892. She attended a teacher-training college for two years and taught kindergarten for four years.\nOn September 11, 1902, Ross married William B. Ross, whom she had met when visiting relatives in Tennessee in 1900. William B. Ross was governor of Wyoming from 1923 to his death on October 2, 1924. Ross succeeded her husband's successor Frank Lucas as governor when she won the special election, becoming the first female American governor on January 5, 1925. She was a staunch supporter of Prohibition during the 1920s. She lost re-election in 1926, but remained an active member of the Democratic Party.\nIn 1933, Ross became the first female Director of the United States Mint. Despite initial mistrust, she forged a strong bond with Mary Margaret O'Reilly, the assistant director of the Mint and one of the United States' highest-ranking female civil servants of her time. Ross served five terms as Director, retiring in 1953. During her later years, she wrote for various women's magazines and traveled. Ross died in Washington, D. C., at the age of 101.\nEarly life and education.\nBorn Nellie Davis Tayloe in St. Joseph, Missouri, Ross was the sixth child, and first daughter, of James Wynns Tayloe, a native of Stewart County, Tennessee, and his wife, Elizabeth Blair Green, who owned a plantation on the Missouri River. She spent much of her childhood in Florence, Alabama, and Decatur, Alabama, in the Tennessee Valley. In 1884, when Ross was seven years of age, her family moved to Miltonvale, Kansas. This relocation happened after her father's old family home back in St. Joseph burned, and the sheriff was about to foreclose on the property.\nAfter Ross graduated from Miltonville High School in 1892, her family moved to Omaha, Nebraska. During this time, she taught private piano lessons and attended a two-year training program for kindergarten teachers that was sponsored by the Omaha city school system. She then taught kindergarten for four years. Two of her brothers sent her on a trip to Europe in 1896.\nWhile on a visit to her relatives in Dover, Tennessee, in 1900, Ross met William Bradford Ross, whom she married on September 11, 1902. They had three children (twins James Ambrose and George Taylor, and Alfred Duff). William Ross practiced law and planned to live in the American West. He moved to Cheyenne and established a law practice, bringing his wife to join him. Ross became a leader in Wyoming's Democratic Party served as Laramie County's prosecuting attorney from 1906 to 1907. In 1910 he was an unsuccessful candidate for Wyoming's at-large congressional seat, and in 1918 he was an unsuccessful candidate for the Democratic nomination for governor.\nGovernorship of Wyoming.\nIn 1922, William Ross was elected governor of Wyoming by appealing to progressive voters in both parties. However, after little more than a year and a half in office, he died on October 2, 1924, from surgical complications following an appendectomy. The Democratic Party then nominated his widow, Nellie, to run for governor in a special election the following month.\nNellie Ross refused to campaign. She won the November 4, 1924, election with 43,323 votes (55.12%) against her opponent's 35,275 votes (44.88%). On January 5, 1925, she became the first female governor in the history of the United States. As governor she continued her husband's policies, which called for tax cuts, government assistance for poor farmers, banking reform, and laws protecting children, women workers, and miners. She urged Wyoming to ratify a pending federal amendment prohibiting child labor. Like her husband, she advocated the strengthening of prohibition laws.\nRoss ran for re-election in 1926, and relied on campaign surrogates including Cecilia Hennel Hendricks, the Democratic nominee for State Superintendent of Public Instruction, but was narrowly defeated by Frank Emerson. She attributed her loss in part to her refusal to campaign for herself and support for prohibition. She remained active in the Democratic Party and campaigned for Al Smith in the 1928 presidential election, even though the two disagreed on prohibition. At the 1928 Democratic National Convention, she received 33 votes from eleven states for vice president on the first ballot. She also gave a speech seconding Smith's nomination. After the convention, she served as vice chairman of the Democratic National Committee and as director of the DNC Women's Division.\nDirector of U.S. Mint.\nAppointment by FDR.\nU.S. President Franklin D. Roosevelt appointed Ross as director of the U.S. Mint on May 3, 1933, making her the first woman to hold that position. Ross and the Mint's Assistant Director Mary Margaret O'Reilly, \"the Sweetheart of the Treasury\" who had worked at the Mint since 1904, had mutual suspicions to overcome. Ross, who had endured poor relations with Eleanor Roosevelt and others on FDR's campaign, did not trust the career staff. O'Reilly saw another political appointee with no experience at the Mint Bureau replacing Robert J. Grant, who had been Denver Mint superintendent before his directorship. After a brief period, the two women came to appreciate each other's merits.\nTenure.\nRoss and O'Reilly soon came to the usual division of labor between director and assistant: the director would handle public affairs and make policy decisions as needed, while the assistant dealt with the day-to-day business of the bureau. Ross undertook a heavy travel schedule, visiting Mint facilities, making speeches backing Roosevelt, and campaigning for Democratic candidates in Wyoming. This left O'Reilly running the Washington office as acting director. The two women carried on a businesslike but warm correspondence during these times, with O'Reilly writing to Ross (who had embarked on a tour of the mints) \"I am so anxious to have your mind at ease about the office here [in Washington] that I have resorted to rather frequent telegrams. They are so much more direct and up to date than letters\u00a0... my love to you and every good wish for the success of your visits to our beloved mint institutions.\" Teva J. Scheer, biographer of Ross, suggests that O'Reilly would have found Ross's reports from the field valuable; they showed how the Mint recovered from the initial years of the Depression, when relatively few coins were produced, to the mid-1930s, when strong demand for coinage led the bureau to run the mints with two or even three shifts.\nO'Reilly's retirement.\nIn 1935, O'Reilly reached the mandatory federal retirement age of 70. Ross requested that President Roosevelt exempt O'Reilly from mandatory retirement because her knowledge of bureau affairs was so extensive and was badly needed. A special order of President Roosevelt gave O'Reilly an extra year in the Mint Service. During the extension, Ross hired Frank Leland Howard of the University of Virginia, who had a background in accounting, as O'Reilly's prospective replacement. Howard replaced O'Reilly when she retired on October 29, 1938, after two more extensions.\nLegacy.\nRoss' tenure saw the Mint in 1944 investigate how several 1933 double eagles, never officially released, had come onto the market. She is known for establishing the Franklin half dollar and starting the making of proof coins for public sale. Ross served five full terms until her retirement in 1953 and was succeeded by William H. Brett, whom President Dwight D. Eisenhower nominated in 1954.\nLater years and death.\nAfter her retirement, Ross contributed articles to various women's magazines and traveled extensively. She made her last trip to Wyoming in 1972 at the age of 96. Five years later, she died in Washington, D.C., at the age of 101; at the time of her death, she was the oldest ex-governor in the United States. She is interred in the family plot in Lakeview Cemetery in Cheyenne.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "49300", "revid": "24198", "url": "https://en.wikipedia.org/wiki?curid=49300", "title": "Isabella of Angoul\u00eame", "text": "Queen of England from 1200 to 1216\nIsabella (, ; c. 1186/ 1188 \u2013 4 June 1246) was Queen of England from 1200 to 1216 as the second wife of King John, Countess of Angoul\u00eame in her own right from 1202 until her death in 1246, and Countess of La Marche from 1220 to 1246 as the wife of Count Hugh.\nIsabella was the only child of Aymer, Count of Angoul\u00eame, and Alice of Courtenay. In 1200, she married King John, with whom she had five children, including the future Henry III of England. After John died in 1216, Isabella remarried in 1220 to Hugh X of Lusignan, Count of La Marche, by whom she had another nine children.\nSome of Isabella's contemporaries, as well as later writers, claim that she formed a conspiracy against King Louis IX of France in 1241, after being publicly snubbed by his mother, Blanche of Castile, for whom she harbored a deep-seated hatred. In 1244, after the plot had failed, Isabella was accused of attempting to poison the king. To avoid arrest, she sought refuge in Fontevraud Abbey, where she died two years later, but none of this can be confirmed.\nQueen consort of England.\nIsabella was the only daughter and heir of Aymer Taillefer, Count of Angoul\u00eame, by Alice of Courtenay, who was a sister of Peter II of Courtenay, Latin Emperor of Constantinople. Alice and Peter II were grandchildren of King Louis VI of France through their father Peter I of Courtenay.\nIsabella became Countess of Angoul\u00eame in her own right on 16 June 1202, by which time she was already queen of England. Her marriage, at age 12 or 14, to King John took place on 24 August 1200, in Angoul\u00eame, a year after he annulled his first marriage to Isabel, Countess of Gloucester. She was crowned queen in an elaborate ceremony on 8 October at Westminster Abbey in London. Isabella was originally betrothed to Hugh IX le Brun, Count of Lusignan, grandson and heir of the Count of La Marche. As a result of John's temerity in taking her as his second wife, King Philip II of France confiscated all of their French lands and armed conflict ensued.\nAt the time of her marriage to John, the blonde-haired blue-eyed Isabella was already renowned by some for her beauty and has sometimes been called the Helen of the Middle Ages by historians. Isabella was much younger than her husband and possessed a volatile temper similar to his own. King John was infatuated with his young, beautiful wife; however, his acquisition of her had at least as much to do with spiting his enemies as romantic love. She was already engaged to Hugh IX le Brun when she was taken by John. It was said that he neglected his state affairs to spend time with Isabella, often remaining in bed with her until noon. However, these were rumors spread by John's enemies to discredit him as a weak and grossly irresponsible ruler, given that at the time John was engaging in a desperate war against King Philip II of France to hold on to the remaining Plantagenet duchies. The common people began to term her a \"siren\" or \"Messalina\" for her allure. Her mother-in-law, Eleanor of Aquitaine, readily accepted her as John's wife.\nOn 1 October 1207, at Winchester Castle, Isabella gave birth to a son and heir, the future King Henry III of England, who was named after his grandfather King Henry II. He was quickly followed by another son, Richard, and three daughters: Joan, Isabella and Eleanor. All five children survived into adulthood and made illustrious marriages; all but Joan produced offspring of their own.\nSecond marriage.\nWhen King John died in October 1216, Isabella's first act was to arrange the speedy coronation of her nine-year-old son at the city of Gloucester on 28 October. As the royal crown had recently been lost in the Wash, along with the rest of King John's treasure, she supplied her own golden circlet to be used in lieu of a crown. The following July, less than a year after his crowning as King Henry III of England, she left him in the care of his regent, William Marshal, 1st Earl of Pembroke, and returned to France to assume control of her inheritance of Angoul\u00eame.\nIn the spring of 1220, Isabella married Hugh X of Lusignan, \"le Brun\", Seigneur de Luisignan, Count of La Marche, the son of her former fianc\u00e9, Hugh IX, to whom she had been betrothed before her marriage to King John. It had been previously arranged that her eldest daughter Joan should marry Hugh, and the little girl was being brought up at the Lusignan court in preparation for her marriage. Hugh, however, upon seeing Isabella, whose beauty had not diminished, preferred the girl's mother. Joan was provided with another husband, King Alexander II of Scotland, whom she wed in 1221.\nIsabella married Hugh without the consent of the king's council in England, as was required of a queen dowager. That council had the power not only to assign to her any subsequent husband, but to decide whether she should be allowed (or forced) to remarry at all. That Isabella flouted its authority moved the council to confiscate her dower lands and to stop the payment of her pension. Isabella and her husband retaliated by threatening to keep Joan, who had been promised in marriage to the King of Scotland, in France. The council first responded by sending furious letters to the Pope, signed in the name of young King Henry, urging him to excommunicate Isabella and her husband, but then decided to come to terms with Isabella, to avoid conflict with the Scottish king, who was eager to receive his bride. Isabella was granted the stannaries in Devon, and the revenue of Aylesbury for a period of four years, in compensation for her confiscated dower lands in Normandy, as well as the \u00a33,000 arrears for her pension.\nIsabella had nine more children by Hugh X. Their eldest son Hugh XI of Lusignan succeeded his father as Count of La Marche and Count of Angoul\u00eame in 1249.\nIsabella's children from her royal marriage did not join her in Angoul\u00eame, remaining in England with their eldest brother Henry III.\nRebellion and death.\nDescribed by some contemporaries as \"vain, capricious and troublesome,\" Isabella could not reconcile herself with her less prominent position in France. Though a former queen of England, Isabella was now mostly regarded as a mere countess and had to give precedence to other women. In 1241, when Isabella and Hugh were summoned to the French court to swear fealty to King Louis IX of France's brother, Alphonse, who had been invested as Count of Poitou, their mother, Queen Dowager Blanche openly snubbed her. This so infuriated Isabella, who had a deep-seated hatred of Blanche for having fervently supported the French invasion of England during the First Barons' War in May 1216, that she began to conspire actively against King Louis. Isabella and her husband, along with other disgruntled nobles, including her son-in-law Count Raymond VII of Toulouse, sought to create an English-backed confederacy which united the provinces of the south and west against the French king. She encouraged her son Henry in his invasion of Normandy in 1230, but then did not provide him the support she had promised.\nIn 1244, after the confederacy had failed and Hugh had made peace with King Louis, two royal cooks were arrested for attempting to poison the king; upon questioning they confessed to having been in Isabella's pay. Before Isabella could be taken into custody, she fled to Fontevraud Abbey, where she died on 4 June 1246.\nBy Isabella's own prior arrangement, she was first buried in the abbey's churchyard as an act of repentance for her many misdeeds. On a visit to Fontevraud, her son King Henry III of England was shocked to find her buried outside the abbey and ordered her immediately moved inside. She was finally placed beside Henry II and Eleanor of Aquitaine. Afterwards, most of her many Lusignan children, having few prospects in France, set sail for England and the court of Henry, their half-brother.\nIn popular culture.\nShe was played by actress Zena Walker in the TV series \"The Adventures of Robin Hood\" episode \"Isabella\" (1956), before her marriage to John, but not as a 12-year-old. She was portrayed by actress Victoria Abril in the 1976 film \"Robin and Marian\". She was played by actress Lynsey Baxter in the 1979 TV mini-series \"The Devil's Crown\". She was played by actress Cory Pulman in the episode \"The Pretender\" (1986) of the TV series \"Robin of Sherwood\". She was portrayed by actress L\u00e9a Seydoux in the 2010 film \"Robin Hood\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "49302", "revid": "44449668", "url": "https://en.wikipedia.org/wiki?curid=49302", "title": "Pope Eleutherius", "text": "Head of the Catholic Church from c. 174 to 189\nPope Eleutherius (; died 24 May 189), also known as Eleutherus (), was the bishop of Rome from c. 174 until his death in 189. His pontificate is alternatively dated to 171\u2013185 or 177\u2013193. He is venerated as a saint in the Catholic Church.\nHe is linked to a number of legends, one of them credited him with receiving a letter from \"Lucius, King of Britain\".\nAs of 2025, he is the only Pope named Eleutherius. \nLife.\nAccording to the \"Liber Pontificalis\", he was a Greek born in Nicopolis in Epirus, Greece. His contemporary Hegesippus wrote that he was a deacon of the Roman Church under Pope Anicetus (c. 154\u2013164), and remained so under Pope Soter, whom he succeeded around 174.\nDietary law.\nThe 6th-century recension of \"Liber Pontificalis\" ('Book of the Popes') known as the \"Felician Catalog\" includes additional commentary to the work's earlier entry on Eleutherius. One addition ascribes to Eleutherius the reissuance of a decree: \"And he again affirmed that no food should be repudiated by Christians strong in their faith, as God created it, [provided] however that it is sensible and edible.\" Such a decree might have been issued against early continuations of Jewish dietary law and against similar laws practiced by the Gnostics and Montanists. It is also possible, however, that the editor of the passage attributed to Eleutherius a decree similar to another issued around the year 500 in order to give it greater authority.\nBritish mission.\nAnother addition credited Eleutherius with receiving a letter from \"Lucius, King of Britain\" or \"King of the Britons\", declaring an intention to convert to Christianity. Authoratiative accounts from the 1st and 2nd century, of Terullian, St. Clement, and St. Iraneaus, referred to Britain as being of the first as having been impacted by the Christian faith. Lately, ancient religious records have been quickly labeled as pious forgery, however it has been admittedly reproduced by several of the most reliable, including the letter itself transcribed by John Foxe in his sixteenth-century work \"Actes and Monuments\". This stands alongside the reputations of \"Liber Pontificalis\" written in 535 AD, the Cistercian Hagiagropher Jocelyn in the 12th Century, Gildas, Geoffrey of Monmouth, Bede, Urban, John of Tynemouth, and Capgrave, that preceded Foxe by nearly 1,000 years. Those who question its validity will then move to discussion over its original purpose. Haddan, Stubbs, and Wilkins considered the passage \"manifestly written in the time and tone\" of Prosper of Aquitaine, secretary to Pope Leo the Great in the mid-5th century, and supportive of the missions of Germanus of Auxerre and Palladius. Duchesne dated the entry a little later to the pontificate of Boniface\u00a0II around 530, and Mommsen to the early 7th century. Only the last would support the conjecture that it aimed to support the Gregorian mission to the Anglo-Saxons led by Augustine of Canterbury, who encountered great difficulty with the native British Christians, as at the Synod of Chester. Indeed, the Celtic Christians invoked the antiquity of their church to generally avoid submission to Canterbury until the Norman conquest, but no arguments invoking the mission to Lucius appear to have been made by either side during the synods among the Welsh and Saxon bishops.\nSome claim that the first Englishman to mention the story was Bede and he seems to have taken it, not from native texts or traditions, but from \"The Book of the Popes\". Subsequently, it appeared in the 9th-century \"History of the Britons\" traditionally credited to Nennius: The account relates that a mission from the pope baptised \"Lucius, the Britannic king, with all the petty kings of the whole Britannic people\". The account, however, dates this baptism to AD\u00a0167 (a little before Eleutherius's pontificate) and credits it to Evaristus (reigned c.\u200999\u00a0\u2013 c.\u2009107). In the 12th century, more details began to be added to the story. Geoffrey of Monmouth's pseudohistorical \"History of the Kings of Britain\" goes into great detail concerning Lucius and names the pope's envoys to him as Fagan and Duvian. The 12th-century \"Book of Llandaf\" placed the court of Lucius in southern Wales and names his emissaries to the pope as Elfan and Medwy.\nOthers cite the reliable histories from centuries before: \"Gildas, Geoffrey of Monmouth, Bede, Urban, John of [Tynemouth] and Capgrave, referred to 'as the most learned of English Augustinians whom the soil of England ever produced', support the date of return of the emissaries of King Lucius from visiting Bishop Eleutherius at Rome, as that given in the British annals, a.d. 183, over a century and a half before the Roman Catholic Church was founded. Cardinal Baronius not only denounces the Augustinian claim but in detail recites the whole record from the year a.d. 36 onward.\"\nAn echo of this legend penetrated even to Switzerland. In a homily preached at Chur and preserved in an 8th- or 9th-century manuscript, Timothy is represented as an apostle to Gaul, whence he went into Roman Britain and baptised a king named Lucius, who himself became a missionary to Gaul and finally settled at Chur, where he preached the gospel with great success. In this way Lucius, the early missionary of the Swiss district of Chur, became identified with the alleged British king of the \"Liber Pontificalis\".\nHarnack suggests that in the document which the compiler of the \"Liber Pontificalis\" drew his information, the name found was not ', but '. Now this is the name (', ') of the fortress of Edessa. The king in question is, therefore, Lucius \u00c6lius Septimus Megas Abgar VIII, of Edessa, a Christian king as is well known. The original statement of the \"Liber Pontificalis\", in this hypothesis, had nothing to do with Britain; the compiler of the \"Liber Pontificalis\" changed ' to ', and in this way made a British king of the Syrian Lucius.\nDeath.\nAccording to the \"Liber Pontificalis\", Pope Eleutherius died on 24 May and was buried on the Vatican Hill (\"\") near the body of Peter the Apostle. Later tradition has his body moved to the church of San Giovanni della Pigna, near the pantheon. In 1591, his remains were again moved to the church of Santa Susanna at the request of Camilla Peretti, the sister of Pope Sixtus V. His feast is celebrated on 26 May.\nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "49303", "revid": "27891597", "url": "https://en.wikipedia.org/wiki?curid=49303", "title": "Pope Eleuterus", "text": ""}
