{"id": "52797", "revid": "42114038", "url": "https://en.wikipedia.org/wiki?curid=52797", "title": "Digital camera", "text": "Camera that captures photographs or video in digital format\nA digital camera, also called a digicam, is a camera that captures photographs in digital memory. Most cameras produced since the turn of the 21st century are digital, largely replacing those that capture images on photographic film or film stock. Digital cameras are now widely incorporated into mobile devices like smartphones with the same or more capabilities and features of dedicated cameras. High-end, high-definition dedicated cameras are still commonly used by professionals and those who desire to take higher-quality photographs.\nDigital cameras and film-based cameras have similar optical systems, typically using a lens with a variable diaphragm to focus light onto an image pickup device. The diaphragm and shutter admit a controlled amount of light to the image, just as with film, but the image pickup device is electronic rather than chemical. However, unlike film cameras, digital cameras can display images on a screen immediately after being recorded, and store and delete images from memory. Many digital cameras can also record moving videos with sound. Some digital cameras can crop and stitch pictures and perform other kinds of image editing.\nHistory.\nThe first semiconductor image sensor was the charge-coupled device (CCD), invented by Willard S. Boyle and George E. Smith at Bell Labs in 1969, based on MOS capacitor technology. The NMOS active-pixel sensor was later invented by Tsutomu Nakamura's team at Olympus in 1985, which led to the development of the CMOS active-pixel sensor (CMOS sensor) at the NASA Jet Propulsion Laboratory in 1993.\nIn the 1960s, Eugene F. Lally of the Jet Propulsion Laboratory was thinking about how to use a mosaic photosensor to capture digital images. His idea was to take pictures of the planets and stars while travelling through space to give information about the astronauts' position. As with Texas Instruments employee Willis Adcock's filmless camera (US patent 4,057,830) in 1972, the technology had yet to catch up with the concept.\nIn 1972, the https:// started taking digital images of Earth. The MSS, designed by Virginia Norwood at Hughes Aircraft Company starting in 1969, captured and transmitted image data from green, red, and two infrared bands with 6 bits per channel, using a mechanical rocking mirror and an array of 24 detectors.\u00a0Operating for six years, it transmitted more than 300,000 digital photographs of Earth while orbiting the planet about 14 times per day.\nAlso in 1972, Thomas McCord from MIT and James Westphal from Caltech together developed a https://.\u00a0Their 1972 https://\" used an analog-to-digital converter and a digital frame memory to store 256 x 256-pixel images of planets and stars, which were then recorded on digital magnetic tape.\u00a0CCD sensors were not yet commercially available, and the camera used a silicon diode vidicon tube detector, which was cooled using dry ice to reduce dark current, allowing exposure times of up to one hour.\u00a0 \u00a0\nThe Cromemco Cyclops was an all-digital camera introduced as a commercial product in 1975. Its design was published as a hobbyist construction project in the February 1975 issue of \"Popular Electronics\" magazine. It used a 32\u00d732 metal\u2013oxide\u2013semiconductor (MOS) image sensor, which was a modified MOS dynamic RAM (DRAM) memory chip.\nSteven Sasson, an engineer at Eastman Kodak, built a self-contained electronic camera that used a monochrome Fairchild CCD image sensor in 1975. Around the same time, Fujifilm began developing CCD technology in the 1970s. Early uses were mainly military and scientific, followed by medical and news applications.\nThe first filmless SLR (single lens reflex) camera was publicly demonstrated by Sony in August 1981.\u00a0The Sony Mavica (magnetic still video camera) used a color-striped 2/3\" format CCD sensor with 280K pixels, along with analogue video signal processing and recording. The Mavica electronic still camera recorded FM-modulated analog video signals on a newly developed 2\" magnetic floppy disk, dubbed the \"Mavipak\". The disk format was later standardized as the \"Still Video Floppy\", or \"SVF\".\nThe Canon RC-701, introduced in May 1986, was the first SVF camera (and the first electronic SLR camera) sold in the US. It employed an SLR viewfinder, included a 2/3\" format color CCD sensor with 380K pixels, and was sold along with a removable 11-66mm and 50-150mm zoom lens. Over the next few years, many other companies began selling SVF cameras. These analog electronic cameras included the Nikon QV-1000C, which had an SLR viewfinder and a 2/3\" format monochrome CCD sensor with 380K pixels and recorded analog black-and-white images on a Still Video Floppy.\nAt Photokina 1988, Fujifilm introduced the FUJIX DS-1P, the first fully digital camera, which recorded digital images using a semiconductor memory card. The camera's memory card had a capacity of 2\u00a0MB of SRAM (static random-access memory) and could hold up to ten photographs. In 1989, Fujifilm released the FUJIX DS-X, the first fully digital camera to be commercially released. In 1996, Toshiba's 40\u00a0MB flash memory card was adopted for several digital cameras.\nThe first commercial camera phone was the Kyocera Visual Phone VP-210, released in Japan in May 1999. It was called a \"mobile videophone\" at the time, and had a 110,000-pixel front-facing camera. It stored up to 20 JPEG digital images, which could be sent over e-mail, or the phone could send up to two images per second over Japan's Personal Handy-phone System (PHS) cellular network. The Samsung SCH-V200, released in South Korea in June 2000, was also one of the first phones with a built-in camera. It had a TFT liquid-crystal display (LCD) and stored up to 20 digital photos at 350,000-pixel resolution. However, it could not send the resulting image over the telephone function but required a computer connection to access photos. The first mass-market camera phone was the J-SH04, a Sharp J-Phone model sold in Japan in November 2000. It could instantly transmit pictures via cell phone telecommunication. \nBy the mid-2000s, higher-end cell phones had an integrated digital camera, and by the early 2010s, almost all smartphones had an integrated digital camera. In the early 2020's a revival of digital cameras produced from the early 2000s occurred as a TikTok trend and other online marketplaces such as eBay and Etsy. The trend was noted with Gen Z as being nostalgic and homage to Y2K aesthetic.\nImage sensors.\nThe two major types of digital image sensors are CCD and CMOS. A CCD sensor has one amplifier for all the pixels, while each pixel in a CMOS active-pixel sensor has its own amplifier. Compared to CCDs, CMOS sensors use less power. Cameras with a small sensor use a back-side-illuminated CMOS (BSI-CMOS) sensor. The image processing capabilities of the camera determine the outcome of the final image quality much more than the sensor type.\nSensor resolution.\nThe resolution of a digital camera is often limited by the image sensor that turns light into discrete signals. The brighter the image at a given point on the sensor, the larger the value that is read for that pixel.\nDepending on the physical structure of the sensor, a color filter array may be used, which requires demosaicing to recreate a full-color image. The number of pixels in the sensor determines the camera's \"pixel count\".\nIn a typical sensor, the pixel count is the product of the number of rows and the number of columns. For example, a 1,000 by 1,000-pixel sensor would have 1,000,000 pixels, or 1 megapixel.\nResolution options.\nFirmwares' resolution selector allows the user to optionally lower the resolution to reduce the file size per picture and extend lossless digital zooming. The bottom resolution option is typically 640\u00d7480 pixels (0.3 megapixels).\nA lower resolution extends the number of remaining photos in free space, postponing the exhaustion of space storage, which is of use where no further data storage device is available and for captures of lower significance, where the benefit from less space storage consumption outweighs the disadvantage from reduced detail.\nImage sharpness.\nAn image's sharpness is presented through the crisp detail, defined lines, and its depicted contrast. Sharpness is a factor of multiple systems throughout the DSLR camera by its ISO, resolution, lens, and the lens settings, the environment of the image, and its post-processing. Images have a possibility of being too sharp, but they can never be too in focus.\nA digital camera resolution is determined by a digital sensor. The digital sensor indicates a high level of sharpness can be produced through the amount of noise and grain that is tolerated through the lens of the camera. Resolution within the field of digital stills and digital movies is indicated through the camera's ability to determine detail based on the distance, which is then measured by frame size, pixel type, number, and organization. Although some DSLR cameras have limited resolutions, it is almost impossible to not have the proper sharpness for an image. The ISO choice when taking a photo affects the quality of the image, as high ISO settings equate to an image that is less sharp due to the increased amount of noise allowed into the image, along with too little noise, which can also produce an image that is not sharp.\nMethods of image capture.\nSince the first digital backs were introduced, there have been three main methods of capturing the image, each based on the hardware configuration of the sensor and color filters.\n\"Single-shot\" capture systems use either one sensor chip with a Bayer filter mosaic, or three separate image sensors (one each for the primary additive colors red, green, and blue) which are exposed to the same image via a beam splitter (see Three-CCD camera).\n\"Multi-shot\" exposes the sensor to the image in a sequence of three or more openings of the lens aperture. There are several methods of application of the multi-shot technique. The most common was originally to use a single image sensor with three filters passed in front of the sensor in sequence to obtain the additive color information. Another multiple-shot method is called microscanning. This method uses a single sensor chip with a Bayer filter and physically moves the sensor on the focus plane of the lens to construct a higher resolution image than the native resolution of the chip. A third version combines these two methods without a Bayer filter on the chip.\nThe third method is called \"scanning\" because the sensor moves across the focal plane much like the sensor of an image scanner. The \"linear\" or \"tri-linear\" sensors in scanning cameras utilize only a single line of photosensors, or three lines for the three colors. Scanning may be accomplished by moving the sensor (for example, when using color co-site sampling) or by rotating the whole camera. A digital rotating line camera offers images consisting of a total resolution that is very high.\nImprovements in single-shot cameras and image file processing at the beginning of the 21st century made single-shot cameras almost completely dominant, even in high-end commercial photography.\nFilter mosaics, interpolation, and aliasing.\nMost current consumer digital cameras use a Bayer filter mosaic in combination with an optical anti-aliasing filter to reduce the aliasing due to the reduced sampling of the different primary-color images.\nA demosaicing algorithm is used to interpolate color information to create a full array of RGB image data.\nCameras that use a beam-splitter single-shot 3CCD approach, three-filter multi-shot approach, color co-site sampling or Foveon X3 sensor do not use anti-aliasing filters, nor demosaicing.\nFirmware in the camera, or a software in a raw converter program such as Adobe Camera Raw, interprets the raw data from the sensor to obtain a full-color image, because the RGB color model requires three intensity values for each pixel: one each for the red, green, and blue (other color models, when used, also require three or more values per pixel).\nA single sensor element cannot simultaneously record these three intensities, so a color filter array (CFA) must be used to selectively filter a particular color for each pixel.\nThe Bayer filter pattern is a repeating 2x2 mosaic pattern of light filters, with green ones at opposite corners and red and blue in the other two positions. The high proportion of green takes advantage of the properties of the human visual system, which determines brightness mostly from green and is far more sensitive to brightness than to hue or saturation. Sometimes a 4-color filter pattern is used, often involving two different hues of green. That provides potentially more accurate color, but requires a slightly more complicated interpolation process.\nThe color intensity values not captured for each pixel can be interpolated from the values of adjacent pixels which represent the color being calculated.\nSensor size and angle of view.\nCameras with digital image sensors that are smaller than the typical 35\u00a0mm film size have a smaller field or angle of view when used with a lens of the same focal length. This is because the angle of view is a function of both focal length and the sensor or film size used.\nThe crop factor is relative to the 35mm film format. If a smaller sensor is used, as in most digicams, the field of view is cropped by the sensor to smaller than the 35\u00a0mm full-frame format's field of view. This narrowing of the field of view may be described as crop factor, a factor by which a longer focal length lens would be needed to get the same field of view on a 35\u00a0mm film camera. Full-frame digital SLRs utilize a sensor of the same size as a frame of 35\u00a0mm film.\nCommon values for field of view crop in DSLRs using active pixel sensors include 1.3x for some Canon (APS-H) sensors, 1.5x for Sony APS-C sensors used by Nikon, Pentax and Konica Minolta and for Fujifilm sensors, 1.6 (APS-C) for most Canon sensors, ~1.7x for Sigma's Foveon sensors and 2x for Kodak and Panasonic 4/3-inch sensors currently used by Olympus and Panasonic. Crop factors for non-SLR consumer compact and bridge cameras are larger, frequently 4x or more.\nSensor resolution.\nThe resolution of a digital camera is often limited by the image sensor which turns light into discrete signals. The brighter the image at a given point on the sensor, the larger the value that is read for that pixel. Depending on the physical structure of the sensor, a color filter array may be used, which requires demosaicing to recreate a full-color image. The number of pixels in the sensor determines the camera's \"pixel count\". In a typical sensor, the pixel count is the product of the number of rows and the number of columns. Pixels are square and is often equal to 1, for example, a 1,000 by 1,000-pixel sensor would have 1,000,000 pixels, or 1 megapixel. On full-frame sensors (i.e., 24 mm 36 mm), some cameras propose images with 20\u201325 million pixels that were captured by 7.5\u2013m photosites, or a surface that is 50 times larger. \u00a0\nTypes of digital cameras.\nDigital cameras come in a wide range of sizes, prices, and capabilities. In addition to general-purpose digital cameras, specialized cameras including multispectral imaging equipment and astrographs are used for scientific, military, medical, and other special purposes.\nCompacts.\nCompact cameras are intended to be portable (pocketable) and are particularly suitable for casual \"snapshots\". Point-and-shoot cameras usually fall under this category.\nMany incorporate a retractable lens assembly that provides optical zoom. In most models, an auto-actuating lens cover protects the lens from elements. Most ruggedized or water-resistant models do not retract, and most with superzoom capability do not retract fully.\nCompact cameras are usually designed to be easy to use. Almost all include an automatic mode, or \"auto mode\", which automatically makes all camera settings for the user. Some also have manual controls. Compact digital cameras typically contain a small sensor that trades-off picture quality for compactness and simplicity; images can usually only be stored using lossy compression (JPEG). Most have a built-in flash usually of low power, sufficient for nearby subjects. A few high-end compact digital cameras have a hot shoe for connecting to an external flash. Live preview is almost always used to frame the photo on an integrated LCD. In addition to being able to take still photographs almost all compact cameras have the ability to record video.\nCompacts often have macro capability and zoom lenses, but the zoom range (up to 30x) is generally enough for candid photography but less than is available on bridge cameras (more than 60x), or the interchangeable lenses of DSLR cameras available at a much higher cost. Autofocus systems in compact digital cameras generally are based on a contrast-detection methodology using the image data from the live preview feed of the main imager. Some compact digital cameras use a hybrid autofocus system similar to what is commonly available on DSLRs.\nTypically, compact digital cameras incorporate a nearly silent leaf shutter into the lens but play a simulated camera sound for skeuomorphic purposes. For low cost and small size, the cameras typically use image sensor formats with a diagonal between 6 and 11\u00a0mm, corresponding to a crop factor between 7 and 4. This gives them weaker low-light performance, greater depth of field, generally closer focusing ability, and smaller components than cameras using larger sensors. Some cameras use a larger sensor including, at the high end, a pricey full-frame sensor compact camera, such as Sony Cyber-shot DSC-RX1, but have the capability near that of a DSLR.\nA variety of additional features are available depending on the model of the camera. Such features include GPS, compass, barometers and altimeters. Starting in 2010, some compact digital cameras can take 3D still photos. These 3D compact stereo cameras are able to capture 3D panoramic photos with dual lens or even a single lens for playback on a 3D TV.\nIn 2013, Sony released two add-on camera models without display, to be used with a smartphone or tablet, controlled by a mobile application via WiFi.\nRugged compacts.\nRugged compact cameras typically include protection against submersion, hot and cold conditions, shock, and pressure. Terms used to describe such properties include waterproof, freeze-proof, heatproof, shockproof, and crushproof, respectively. Nearly all major camera manufacturers have at least one product in this category. Some are waterproof to a considerable depth up to 100 feet (30\u00a0m); others only 10 feet (3\u00a0m), but only a few will float. Ruggeds often lack some of the features of ordinary compact camera, but they have video capability and the majority can record sound. Most have image stabilization and built-in flash. Touchscreen LCD and GPS do not work underwater.\nAction cameras.\nGoPro and other brands offer action cameras which are rugged, small, and can be easily attached to helmets, arms, bicycles, etc. Most have a wide angle and fixed focus and can take still pictures and video, typically with sound.\n360-degree cameras.\nThe 360-degree camera can take picture or video 360 degrees using two lenses back-to-back and shooting at the same time. Some of the cameras are Ricoh Theta S, Nikon Keymission 360 and Samsung Gear 360. Nico360 was launched in 2016 and claimed as the world's smallest 360-degree camera with size 46 x 46 x 28\u00a0mm (1.8 x 1.8 x 1.1 in) and price less than $200. With virtual reality mode built-in stitching, Wifi, and Bluetooth, live streaming can be done. Due to it also being water resistant, the Nico360 can be used as action camera.\nBridge cameras.\nBridge cameras physically resemble DSLRs, and are sometimes called DSLR-shape or DSLR-like. They provide some similar features but, like compacts, they use a fixed lens and a small sensor. Some compact cameras have also PSAM mode. Most use live preview to frame the image. Their usual autofocus is by the same contrast-detect mechanism as compacts, but many bridge cameras have a manual focus mode and some have a separate focus ring for greater control.\nThe big physical size and small sensor allow superzoom and wide aperture. Bridge cameras generally include an image stabilization system to enable longer handheld exposures, sometimes better than DSLR for low light conditions.\nAs of 2014, bridge cameras come in two principal classes in terms of sensor size, firstly the more traditional 1/2.3\" sensor (as measured by image sensor format) which gives more flexibility in lens design and allows for handholdable zoom from 20 to 24\u00a0mm (35\u00a0mm equivalent) wide angle all the way up to over 1000\u00a0mm supertele, and secondly a 1\" sensor that allows better image quality particularly in low light (higher ISO) but puts greater constraints on lens design, resulting in zoom lenses that stop at 200\u00a0mm (constant aperture, e.g. Sony RX10) or 400\u00a0mm (variable aperture, e.g. Panasonic Lumix FZ1000) equivalent, corresponding to an optical zoom factor of roughly 10 to 15.\nSome bridge cameras have a lens thread to attach accessories such as wide-angle or telephoto converters as well as filters such as UV or Circular Polarizing filter and lens hoods. The scene is composed by viewing the display or the electronic viewfinder (EVF). Most have a slightly longer shutter lag than a DSLR. Many of these cameras can store images in a raw format in addition to supporting JPEG. The majority have a built-in flash, but only a few have a hotshoe.\nIn bright sun, the quality difference between a good compact camera and a digital SLR is minimal but bridge cameras are more portable, cost less and have a greater zoom ability. Thus a bridge camera may better suit outdoor daytime activities, except when seeking professional-quality photos.\nMirrorless interchangeable-lens cameras.\nIn late 2008, a new type of camera emerged, called a \"mirrorless interchangeable-lens camera\". It is technically a DSLR camera that does not require a reflex mirror, a key component of the former. While a typical DSLR has a mirror that reflects light from the lens up to the optical viewfinder, in a mirrorless camera, there is no optical viewfinder. The image sensor is exposed to light at all times, giving the user a digital preview of the image either on the built-in rear LCD screen or an electronic viewfinder (EVF).\nThese are simpler and more compact than DSLRs due to not having a lens reflex system. MILCs, or mirrorless cameras for short, come with various sensor sizes depending on the brand and manufacturer, these include: a small 1/2.3\u00a0inch sensor, as is commonly used in bridge cameras such as the original Pentax Q (more recent Pentax Q versions have a slightly larger 1/1.7\u00a0inch sensor); a 1-inch sensor; a Micro Four Thirds sensor; an APS-C sensor found in Sony NEX series and \u03b1 \"DSLR-likes\", Fujifilm X series, Pentax K-01, and Canon EOS M; and some, such as the Sony \u03b17, use a full frame (35\u00a0mm) sensor, with the Hasselblad X1D being the first medium format mirrorless camera. Some MILCs have a separate electronic viewfinder to compensate the lack of an optical one. In other cameras, the back display is used as the primary viewfinder in the same way as in compact cameras. One disadvantage of mirrorless cameras compared to a typical DSLR is its battery life due to the energy consumption of the electronic viewfinder, but this can be mitigated by a setting inside the camera in some models. Many mirrorless cameras have a hotshoe.\nOlympus and Panasonic released many Micro Four Thirds cameras with interchangeable lenses that are fully compatible with each other without any adapter, while others have proprietary mounts. In 2014, Kodak released its first Micro Four Third system camera.\nAs of \u00a02014[ [update]], mirrorless cameras are fast becoming appealing to both amateurs and professionals alike due to their simplicity, compatibility with some DSLR lenses, and features that match most DSLRs today.\nModular cameras.\nWhile most digital cameras with interchangeable lenses feature a lens-mount of some kind, there are also a number of modular cameras, where the shutter and sensor are incorporated into the lens module.\nThe first such modular camera was the Minolta Dim\u00e2ge V in 1996, followed by the Minolta Dim\u00e2ge EX 1500 in 1998 and the Minolta MetaFlash 3D 1500 in 1999. In 2009, Ricoh released the Ricoh GXR modular camera.\nAt CES 2013, Sakar International announced the Polaroid iM1836, an 18MP camera with 1\"-sensor with interchangeable sensor-lens. An adapter for Micro Four Thirds, Nikon and K-mount lenses was planned to ship with the camera.\nThere are also a number of add-on camera modules for smartphones, they are called \"lens-style\" cameras (lens camera or smart lens). They contain all the essential components of a digital camera inside a DSLR lens-shaped module, hence the name, but lack any sort of viewfinder and most controls of a regular camera. Instead, they are connected wirelessly and/or mounted to a smartphone to be used as its display output and operate the camera's various controls.\nLens-style cameras include:\nDigital single-lens reflex cameras (DSLR).\nDigital single-lens reflex cameras (DSLR) is a camera with a digital sensor that utilizes a reflex mirror to split or direct light into the viewfinder to produce an image. The reflex mirror finds the image by blocking light to the camera's sensor and then reflecting it into the camera's pentaprism which allows it to be seen through the viewfinder. When the shutter release is fully pressed the reflex mirror pulls out horizontally below the pentaprism briefly darkening the viewfinder and then opening up the sensor for exposure which creates the photo. The digital image is produced by the sensor which is an array of photoreceptors on a microchip capable of recording light values. Many modern DSLRs offer the ability for \"live view\" or the framing of the subject emitted from the sensor onto a digital screen, and many have a hotshoe.\nThe sensor also known as a full-frame sensor is much larger than the other types, typically 18mm to 36mm on the diagonal (crop factor 2, 1.6, or 1). The larger sensor permits more light to be received by each pixel; this, combined with the relatively large lenses provides superior low-light performance. For the same field of view and the same aperture, a larger sensor gives shallower focus. DSLRs can equip interchangeable lenses for versatility by removing it from the lens mount of the camera, typically a silver ring on the front side of DSLRs. These lenses work in tandem with the mechanics of the DSLR to adjust aperture and focus. Autofocus is accomplished using sensors in the mirror box and on most modern lenses can be activated from the lens itself which will trigger upon shutter release.\nView cameras.\nIn 2019, Phase One launched its IQ4 series of digital camera backs at 100MP to 150MP resolution (included with both the Phase One XF IQ4 150MP Camera (MSRP $51,990 without lens, 1 fps, DSLR) and the Phase One XT IQ4 150MP Camera (MSRP $56,990 without lens, 1 fps, mirrorless)), with the 150MP generating 120.26 x 90.19 cm (47.35\" x 35.5\") 16-bit color images at 300dpi.\nIn 2025, a variety of lower-cost medium format digital cameras were available in the 50 to 100MP resolution range. Available 100MP cameras included the FujiFilm GFX 100 II (MSRP $7,499 without lens, 8K video at 30p/4K video at 60p), the FujiFilm GFX 100S (MSRP $5,999 without lens, 4K video at 30p), the FujiFilm GFX 100S II (MSRP $4,999 without lens, 8 fps with autofocus, 4K video at 30p) and the Hasselblad X2D II 100C (MSRP $7,399 including a XCD 75mm f/3.4 lens; no video capability).\nDigital Still Cameras (DSC).\nDigital Still Camera (DSC), such as the Sony DSC cameras, is a type of camera that does not use a reflex mirror. DSCs are like point-and-shoot cameras and are the most common type of cameras, due to their comfortable price and its quality.\nHere are a list of DSCs: List of Sony Cyber-shot cameras\nFixed-mirror DSLT cameras.\nCameras with fixed semi-transparent mirrors, also known as DSLT cameras, such as the Sony SLT cameras, are single-lens without a moving reflex mirror as in a conventional DSLR. A semi-transparent mirror transmits some of the light to the image sensor and reflects some of the light along the path to an autofocus sensor. The total amount of light is not changed, just some of the light travels one path and some of it travels the other. The consequences are that DSLT cameras should shoot a half stop differently from DSLR. One advantage of using a DSLT camera is the blind moments a DSLR user experiences while the reflecting mirror is moved to send the light to the sensor instead of the viewfinder. The \"blackouts\" do not exist for DSLT cameras since they use an EVF (electronic viewfinder). Since there is no time at which light is not traveling along both paths, DSLT cameras get the benefit of continuous autofocus tracking. This is especially beneficial for burst-mode shooting in low-light conditions and also for tracking when taking video.\nDigital rangefinders.\nA rangefinder is a device to measure subject distance, with the intent to adjust the focus of a camera's objective lens accordingly (open-loop controller). The rangefinder and lens focusing mechanism may or may not be coupled. In common parlance, the term \"rangefinder camera\" is interpreted very narrowly to denote manual-focus cameras with a visually-read out optical rangefinder based on parallax. Most digital cameras achieve focus through analysis of the image captured by the objective lens and distance estimation, if it is provided at all, is only a byproduct of the focusing process (closed-loop controller).\nLine-scan camera systems.\nA line-scan camera traditionally has a single row of pixel sensors, instead of a matrix of them. The lines are continuously fed to a computer that joins them to each other and makes an image. That is most commonly done by connecting the camera output to a frame grabber which resides in a PCI slot of an industrial computer. The frame grabber acts to buffer the image and sometimes provide some processing before delivering to the computer software for processing. Industrial processes often require height and width measurements performed by digital line-scan systems.\nMultiple rows of sensors may be used to make colored images, or to increase sensitivity by TDI (time delay and integration). Many industrial applications require a wide field of view. Traditionally maintaining consistent light over large 2D areas is quite difficult. With a line scan camera all that is necessary is to provide even illumination across the \"line\" currently being viewed by the camera. This makes sharp pictures of objects that pass the camera at high speed.\nSuch cameras are also commonly used to make photo finishes, to determine the winner when multiple competitors cross the finishing line at nearly the same time. They can also be used as industrial instruments for analyzing fast processes.\nLine-scan cameras are also extensively used in imaging from satellites (see push broom scanner). In this case the row of sensors is perpendicular to the direction of satellite motion. Line-scan cameras are widely used in scanners. In this case, the camera moves horizontally.\nSuperzoom cameras.\nDigital superzoom cameras are digital cameras which can zoom in very far. The superzoom cameras are suitable for people who have nearsightedness. The HX series is a series containing Sony's superzoom cameras like HX20V, HX90V and the newest HX99. HX stands for HyperXoom.\nLight-field camera.\nThis type of digital camera captures information about the light field emanating from a scene; that is the intensity of light in a scene, and also the direction that the light rays are traveling in space. This contrasts with a conventional digital camera, which records only light intensity.\nEvent camera.\nInstead of measuring the intensity of light over some predetermined time interval (the exposure time), event cameras detect when the intensity of light changes by some threshold for each pixel independently, usually with microsecond precision.\nIntegration into other devices.\nMany devices have a built-in digital camera, including, for example, smartphones, mobile phones, PDAs and laptop computers. Built-in cameras generally store the images in the JPEG file format, although cameras in Apple's iPhone line have used the HEIC format since 2017. \nMobile phones incorporating digital cameras were introduced in Japan in 2001 by J-Phone. In 2003 camera phones outsold stand-alone digital cameras, and in 2006 they outsold film and digital stand-alone cameras. Five billion camera phones were sold in five years, and by 2007 more than half of the installed base of all mobile phones were camera phones. Sales of separate cameras peaked in 2008.\nNotable digital camera manufacturers.\nSeveral manufacturers lead in digital camera (commonly DSLRs) production. Each brand embodies different mission statements that differentiate it from the others besides the equipment it manufactures. Most manufacturers share modern features in the cameras they produce. However, some specialize in specific details, either physically on camera or within the system and image quality. \nMarket trends.\nSales of traditional digital cameras have declined due to the increasing use of smartphones for casual photography, which also enable easier manipulation and sharing of photos through the use of apps and web-based services. \"Bridge cameras\", in contrast, have held their ground with functionality that most smartphone cameras lack, such as optical zoom and other advanced features. DSLRs have also lost ground to Mirrorless interchangeable-lens camera (MILC)s offering the same sensor size in a smaller camera. A few expensive ones use a full-frame sensor, just like DSLR professional cameras.\nIn response to the convenience and flexibility of smartphone cameras, some manufacturers produced \"smart\" digital cameras that combine features of traditional cameras with those of a smartphone. In 2012, Nikon and Samsung released the Coolpix S800c and Galaxy Camera, the first two digital cameras to run the Android operating system. Since this software platform is used in many smartphones, they can integrate with some of the same services (such as e-mail attachments, social networks and photo sharing sites) that smartphones do and use other Android-compatible software.\nIn an inversion, some phone makers have introduced smartphones with cameras designed to resemble traditional digital cameras. Nokia released the 808 PureView and Lumia 1020 in 2012 and 2013; the two devices respectively run the Symbian and Windows Phone operating systems, and both include a 41-megapixel camera (along with a camera grip attachment for the latter). Similarly, Samsung introduced the Galaxy S4 Zoom, having a 16-megapixel camera and 10x optical zoom, combining traits from the Galaxy S4 Mini with the Galaxy Camera. Panasonic Lumix DMC-CM1 is an Android KitKat 4.4 smartphone with 20MP, 1\" sensor, the largest sensor for a smartphone ever, with Leica fixed lens equivalent of 28\u00a0mm at F2.8, can take RAW image and 4K video, has 21\u00a0mm thickness. Furthermore, in 2018 Huawei P20 Pro is an android Oreo 8.1 has triple Leica lenses in the back of the smartphone with 40MP 1/1.7\" RGB sensor as first lens, 20MP 1/2.7\" monochrome sensor as second lens and 8MP 1/4\" RGB sensor with 3x optical zoom as third lens. Combination of first lens and second lens will produce bokeh image with larger high dynamic range, whereas combination of mega pixel first lens and optical zoom will produce maximum 5x digital zoom without loss of quality by reducing the image size to 8MP.\nAfter a big dip of sales in 2012, consumer digital camera sales declined again in 2013 by 36 percent. In 2011, compact digital cameras sold 10 million per month. In 2013, sales fell to about 4 million per month. DSLR and MILC sales also declined in 2013 by 10\u201315% after almost ten years of double digit growth.\nWorldwide unit sales of digital cameras is continuously declining from 148 million in 2011 to 58 million in 2015 and tends to decrease more in the following years.\nFilm camera sales hit their peak at about 37 million units in 1997, while digital camera sales began in 1989. By 2008, the film camera market had died and digital camera sales hit their peak at 121 million units in 2010. In 2002, cell phones with an integrated camera had been introduced and in 2003 the cell phone with an integrated camera had sold 80 million units per year. By 2011, cell phones with an integrated camera were selling hundreds of millions per year, which were causing a decline in digital cameras. In 2015, digital camera sales were 35 million units or only less than a third of digital camera sales numbers at their peak and also slightly less than film camera sold number at their peak.\nConnectivity.\nTransferring photos.\nMany digital cameras can connect directly to a computer to transfer data:-\nA common alternative is the use of a card reader which may be capable of reading several types of storage media, as well as high speed transfer of data to the computer. Use of a card reader also avoids draining the camera battery during the download process. An external card reader allows convenient direct access to the images on a collection of storage media. But if only one storage card is in use, moving it back and forth between the camera and the reader can be inconvenient. Many computers have a card reader built in, at least for SD cards.\nPrinting photos.\nMany modern cameras support the PictBridge standard, which allows them to send data directly to a PictBridge-capable printer without the need for a computer. PictBridge uses PTP to transfer images and control information.\nWireless connectivity can also provide for printing photos without a cable connection.\nAn \"instant-print camera\", is a digital camera with a built-in printer. This confers a similar functionality as an instant camera which uses instant film to quickly generate a physical photograph. Such non-digital cameras were popularized by Polaroid with the SX-70 in 1972.\nDisplaying photos.\nMany digital cameras include a video output port. Usually sVideo, it sends a standard-definition video signal to a television, allowing the user to show one picture at a time. Buttons or menus on the camera allow the user to select the photo, advance from one to another, or automatically send a \"slide show\" to the TV.\nHDMI has been adopted by many high-end digital camera makers, to show photos in their high-resolution quality on an HDTV.\nIn January 2008, Silicon Image announced a new technology for sending video from mobile devices to a television in digital form. MHL sends pictures as a video stream, up to 1080p resolution, and is compatible with HDMI. Some DVD recorders and television sets can read memory cards used in cameras; alternatively several types of flash card readers have TV output capability.\nWeather-sealing and waterproofing.\nCameras can be equipped with a varying amount of environmental sealing to provide protection against splashing water, moisture (humidity and fog), dust and sand, or complete waterproofness to a certain depth and for a certain duration. The latter is one of the approaches to allow underwater photography, the other approach being the use of waterproof housings. Many waterproof digital cameras are also shockproof and resistant to low temperatures.\nSome waterproof cameras can be fitted with a waterproof housing to increase the operational depth range. The Olympus 'Tough' range of compact cameras is an example.\nModes.\nMany digital cameras have preset modes for different applications. Within the constraints of correct exposure various parameters can be changed, including exposure, aperture, focusing, light metering, white balance, and equivalent sensitivity. For example, a portrait might use a wider aperture to render the background out of focus, and would seek out and focus on a human face rather than other image content.\nFew cameras are equipped with a voice note (audio-only) recording feature.\nScene modes.\nVendors implement a variety scene modes in cameras' firmwares for various purposes, such as a \"landscape mode\" which prevents focusing on rainy and/or stained window glass such as a windshield, and a \"sports mode\" which reduces motion blur of moving subjects by reducing exposure time with the help of increased light sensitivity. Firmwares may be equipped with the ability to select a suitable scene mode automatically through artificial intelligence.\nImage data storage.\nMany camera phones and most stand alone digital cameras store image data in flash memory cards or other removable media. Most stand-alone cameras use SD format, while a few use CompactFlash, CFexpress or other types. In January 2012, a faster XQD card format was announced. In early 2014, some high end cameras have two hot-swappable memory slots. Photographers can swap one of the memory card with camera-on. Each memory slot can accept either Compact Flash or SD Card. All new Sony cameras also have two memory slots, one for its Memory Stick and one for SD Card, but not hot-swapable.\nThe approximate count of remaining photos until space exhaustion is calculated by the firmware throughout use and indicated in the viewfinder, to prepare the user for an impending necessary hot swap of the memory card, and/or file offload.\nA few cameras used other removable storage such as Microdrives (very small hard disk drives), CD single (185\u00a0MB), and 3.5\" floppy disks (e.\u00a0g. Sony Mavica). Other unusual formats include:\nMost manufacturers of digital cameras do not provide drivers and software to allow their cameras to work with Linux or other free software. Still, many cameras use the standard USB mass storage and/or Media Transfer Protocol, and are thus widely supported. Other cameras are supported by the gPhoto project, and many computers are equipped with a memory card reader.\nFile formats.\nThe Joint Photography Experts Group standard (JPEG) is the most common file format for storing image data. Other file types include Tagged Image File Format (TIFF), High Efficiency Image File Format (HEIF), and various Raw image formats.\nMany cameras, especially high-end ones, support a raw image format. A raw image is the unprocessed set of pixel data directly from the camera's sensor, often saved in a proprietary format. Adobe Systems has released the DNG format, a royalty-free raw image format used by at least 10 camera manufacturers.\nRaw files initially had to be processed in specialized image editing programs, but over time many mainstream editing programs, such as Google's Picasa, have added support for raw images. Rendering to standard images from raw sensor data allows more flexibility in making major adjustments without losing image quality or retaking the picture.\nFormats for movies are AVI, DV, MPEG, MOV (often containing motion JPEG), WMV, and ASF (basically the same as WMV). Recent formats include MP4, which is based on the QuickTime format and uses newer compression algorithms to allow longer recording times in the same space.\nOther formats that are used in cameras (but not for pictures) are the Design Rule for Camera Format (DCF), an ISO specification, used in almost all camera since 1998, which defines an internal file structure and naming. Also used is the Digital Print Order Format (DPOF), which dictates what order images are to be printed in and how many copies. The DCF 1998 defines a logical file system with 8.3 filenames and makes the usage of either FAT12, FAT16, FAT32 or exFAT mandatory for its physical layer in order to maximize platform interoperability.\nMost cameras include Exif data that provides metadata about the picture. Exif data may include aperture, exposure time, focal length, date and time taken. Some are able to tag the location.\nDirectory and file structure.\nIn order to guarantee interoperability, DCF specifies the file system for image and sound files to be used on formatted DCF media (like removable or non-removable memory) as FAT12, FAT16, FAT32, or exFAT. Media with a capacity of more than 2 GB must be formatted using FAT32 or exFAT.\nThe filesystem in a digital camera contains a DCIM (Digital Camera IMages) directory, which can contain multiple subdirectories with names such as \"123ABCDE\" that consist of a unique directory number (in the range 100...999) and five alphanumeric characters, which may be freely chosen and often refer to a camera maker. These directories contain files with names such as \"ABCD1234.JPG\" that consist of four alphanumeric characters (often \"100_\", \"DSC0\", \"DSCF\", \"IMG_\", \"MOV_\", or \"P000\"), followed by a number. Handling of directories with possibly user-created duplicate numbers may vary among camera firmwares.\nDCF 2.0 adds support for DCF optional files recorded in an optional color space (that is, Adobe RGB rather than sRGB). Such files must be indicated by a leading \"_\" (as in \"_DSC\" instead of \"100_\" or \"DSC0\").\nThumbnail files.\nTo enable loading many images in miniature view quickly and efficiently, and to retain meta data, some vendors' firmwares generate accompanying low-resolution thumbnail files for videos and raw photos. For example, those of Canon cameras end with codice_1. JPEG can already store a thumbnail image standalone.\nBatteries.\nDigital cameras have become smaller over time, resulting in an ongoing need to develop a battery small enough to fit in the camera and yet able to power it for a reasonable length of time.\nDigital cameras utilize either proprietary or standard consumer batteries. As of March 2014[ [update]], most cameras use proprietary lithium-ion batteries while some use standard AA batteries or primarily use a proprietary Lithium-ion rechargeable battery pack but have an optional AA battery holder available.\nProprietary.\nThe most common class of battery used in digital cameras is proprietary battery formats. These are built to a manufacturer's custom specifications. Almost all proprietary batteries are lithium-ion. In addition to being available from the OEM, aftermarket replacement batteries are commonly available for most camera models.\nStandard consumer batteries.\nDigital cameras which utilize off-the-shelf batteries are typically designed to be able to use both single-use disposable and rechargeable batteries, but not with both types in use at the same time. The most common off-the-shelf battery size used is AA. CR2, CR-V3 batteries, and AAA batteries are also used in some cameras. The CR2 and CR-V3 batteries are lithium based, intended for a single use. Rechargeable RCR-V3 lithium-ion batteries are also available as an alternative to non-rechargeable CR-V3 batteries.\nSome battery grips for DSLRs come with a separate holder to accommodate AA cells as an external power source.\nConversion of film cameras to digital.\nWhen digital cameras became common, many photographers asked whether their film cameras could be converted to digital. The answer was not immediately clear, as it differed among models. For the majority of 35\u00a0mm film cameras the answer is no, the reworking and cost would be too great, especially as lenses have been evolving as well as cameras. For most a conversion to digital, to give enough space for the electronics and allow a liquid crystal display to preview, would require removing the back of the camera and replacing it with a custom built digital unit.\nMany early professional SLR cameras, such as the Kodak DCS series, were developed from 35\u00a0mm film cameras. The technology of the time, however, meant that rather than being digital \"backs\" the bodies of these cameras were mounted on large, bulky digital units, often bigger than the camera portion itself. These were factory built cameras, however, not aftermarket conversions.\nA notable exception is the Nikon E2 and Nikon E3, using additional optics to convert the 35 mm format to a 2/3 CCD-sensor.\nA few 35\u00a0mm cameras have had digital camera backs made by their manufacturer, Leica being a notable example with the Leica R8\u2013R9. Medium format and large format cameras (those using film stock greater than 35\u00a0mm), have a low unit production, and typical digital backs for them cost over $10,000. These cameras also tend to be highly modular, with handgrips, film backs, winders, and lenses available separately to fit various needs.\nThe very large sensor these backs use leads to enormous image sizes. For example, Phase One's P45 39\u00a0MP image back creates a single TIFF image of size up to 224.6\u00a0MB, and even greater pixel counts are available. Medium format digitals such as this are geared more towards studio and portrait photography than their smaller DSLR counterparts; the ISO speed in particular tends to have a maximum of 400, versus 6400 for some DSLR cameras. (Canon EOS-1D Mark IV and Nikon D3S have ISO 12800 plus Hi-3 ISO 102400 with the Canon EOS-1Dx's ISO of 204800).\nDigital camera backs.\nIn the industrial and high-end professional photography market, some camera systems use modular (removable) image sensors. For example, some medium format SLR cameras, such as the Mamiya 645D series, allow installation of either a digital camera back or a traditional photographic film back.\nLinear array cameras are also called scan backs.\nMost earlier digital camera backs used linear array sensors, moving vertically to digitize the image. Many of them only capture grayscale images. The relatively long exposure times, in the range of seconds or even minutes generally limit scan backs to studio applications, where all aspects of the photographic scene are under the photographer's control.\nSome other camera backs use CCD arrays similar to typical cameras. These are called single-shot backs.\nSince it is much easier to manufacture a high-quality linear CCD array with only thousands of pixels than a CCD matrix with millions, very high resolution linear CCD camera backs were available much earlier than their CCD matrix counterparts. For example, you could buy an (albeit expensive) camera back with over 7,000 pixel horizontal resolution in the mid-1990s. However, as of 2004[ [update]], it is still difficult to buy a comparable CCD matrix camera of the same resolution. Rotating line cameras, with about 10,000 color pixels in its sensor line, are able, as of 2005[ [update]], to capture about 120,000 lines during one full 360 degree rotation, thereby creating a single digital image of 1,200 Megapixels.\nMost modern digital camera backs use CCD or CMOS matrix sensors. The matrix sensor captures the entire image frame at once, instead of incrementing scanning the frame area through the prolonged exposure. For example, Phase One produces a 39 million pixel digital camera back with a 49.1 \u00d7 36.8\u00a0mm CCD in 2008. This CCD array is a little smaller than a frame of 120 film and much larger than a 35 mm frame (36 \u00d7 24\u00a0mm). In comparison, consumer digital cameras use arrays ranging from 36 \u00d7 24\u00a0mm (full frame on high end consumer DSLRs) to 1.28 \u00d7 0.96\u00a0mm (on camera phones) CMOS sensor.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52799", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=52799", "title": "John Bellairs", "text": "American fantasy novelist (1938\u20131991)\nJohn Anthony Bellairs (January 17, 1938 \u2013 March 8, 1991) was an American author best known for his fantasy novel \"The Face in the Frost\" and many Gothic mystery novels for children featuring the characters Lewis Barnavelt, Rose Rita Pottinger, Johnny Dixon, and Anthony Monday. Most of his books were illustrated by Edward Gorey. At the time of his death, Bellairs' books had sold a quarter-million copies in hard cover and more than a million and a half copies in paperback.\nBiography.\nEarly life and education.\nBellairs was born in Marshall, Michigan, the son of Virginia (Monk) and Frank Edward Bellairs, who ran a cigar store and bowling alley in Marshall. He was raised a strict Roman Catholic and initially planned to become a priest. His hometown inspired the fictional town of New Zebedee, Michigan, where he set his trilogy about Lewis Barnavelt and Rose Rita Pottinger. Shy, overweight, and often bullied as a child, he had become a voracious reader and a self-described \"bottomless pit of useless information\" by the time he graduated from Marshall High School and entered the University of Notre Dame in 1955.\nBellairs graduated with a Bachelor of Arts degree in English \"magna cum laude\" from the University of Notre Dame in 1959. At Notre Dame, he competed in the College Bowl and wrote a regular humor column for the student magazine \"Scholastic\". Bellairs went on to receive a Master of Arts degree in English from the University of Chicago in 1960. He received a Woodrow Wilson Fellowship in 1959.\nCareer and interests.\nBellairs taught English at the College of Saint Teresa (1963\u201365), Shimer College (1966\u201367), Emmanuel College (1968\u201369), and Merrimack College (1969\u201371) before turning full-time to writing in 1971. During the late 1960s, he spent six months living and writing in Bristol, United Kingdom, where he began writing \"The Face in the Frost\". Bristol would later feature in his 1990 novel \"The Secret of the Underground Room\".\nHis personal interests included archaeology, architecture, history, Latin, baseball, kitschy antiques, bad poetry, visits to the UK, and trivia of all kinds. His favorite authors included Charles Dickens, Henry James, M.R. James, Garrett Mattingly, and C. V. Wedgwood.\nAlongside Christopher Tolkien, Bellairs was a guest of honor at the 18th Annual Mythopoeic Conference at Marquette University in 1987, hosted by the Mythopoeic Society.\nDeath and legacy.\nBellairs died suddenly of cardiovascular disease at his home in Haverhill, Massachusetts, on March 8, 1991, at the age of 53. He was survived by his ex-wife, Priscilla (Braids) Bellairs, whom he had married on June 24, 1968, and their son Frank J. Bellairs. Frank Bellairs died in Cambridge, Massachusetts, on August 19, 1999, at the age of 29. Priscilla Bellairs lives in Newburyport.\nIn 1992, a historical marker was placed in front of the historic Cronin House in Bellairs's hometown of Marshall, Michigan. Built in 1870 for local merchant Jeremiah Cronin, this imposing Italianate mansion with its 60-foot tower had inspired the titular house of his 1973 book.\nBellairs was inducted into the Haverhill Citizens Hall of Fame in 2000.\nWritings.\nBooks for adults.\nBellairs' first published work, \"St. Fidgeta and Other Parodies\" (1966), is a collection of short stories satirizing the rites and rituals of Second Vatican Council-era Catholicism. The title story of St. Fidgeta grew out of humorous stories Bellairs made up and shared with friends while living in Chicago. After committing one such story to paper, he sent it to the Chicago-based Catholic magazine \"The Critic\", which published the story in summer 1965. The following year, the hagiography of St. Fidgeta was supplemented by eleven other humorous stories, including an essay on lesser-known popes of antiquity, a cathedral constructed over the course of centuries, and a spoof letter from a modern-day Xavier Rynne about the escapades at the fictional Third Vatican Council. \"Library Journal\" hailed \"St. Fidgeta\" as \"religious burlesque\" that delivered \"strokes of inspired foolishness.\" A writer for the \"National Catholic Reporter\" called it a \"gem.\"\n\"The Pedant and the Shuffly\", his second book, is a short illustrated fable featuring the evil magician Snodrog (the titular pedant), who ensnares his victims with inescapable (and nonsensical) logic until the kindly sorcerer, Sir Bertram Crabtree-Gore, enlists the help of a magical Shuffly to defeat Snodrog. The book was originally published in 1968 and rereleased in 2001 and 2009.\nBellairs undertook his third book, \"The Face in the Frost\" (1969), while living in Britain and after reading J.R.R. Tolkien's \"The Lord of the Rings\". Bellairs said of his third book: \"\"The Face in the Frost\" was an attempt to write in the Tolkien manner. I was much taken by \"The Lord of the Rings\" and wanted to do a modest work on those lines. In reading the latter book I was struck by the fact that Gandalf was not much of a person\u2014just a good guy. So I gave Prospero, my wizard, most of my phobias and crotchets. It was simply meant as entertainment and any profundity will have to be read in.\" Writing in 1973, Lin Carter described \"The Face in the Frost\" as one of the three best fantasy novels to appear since \"The Lord of the Rings\". Carter stated that Bellairs was planning a sequel to \"The Face in the Frost\" at the time. An unfinished sequel titled \"The Dolphin Cross\" was included in the anthology \"Magic Mirrors\" (New England Science Fiction Association Press, 2009).\nBooks for children.\nBellairs's next novel was originally written as a contemporary adult fantasy. To improve the novel's marketability, his publisher suggested rewriting it as a young readers' book. The result was \"The House with a Clock in Its Walls\" (1973), which was named as one of \"The New York Times\" Outstanding Books of 1973 and nominated for other awards.\nFollowing the success of \"The House with a Clock in Its Walls\", Bellairs focused on writing Gothic fantasy adventures aimed at elementary and middle-school children. \"I write scary thrillers for kids because I have the imagination of a 10-year-old,\" remarked Bellairs. \"I love haunted houses, ghosts, witches, mummies, incantations, secret rituals performed by the light of the waning moon, coffins, bones, cemeteries and enchanted objects.\" Bellairs also wrote his hometown influenced his creative bent: \u201cIn my imagination I repeatedly walk up and down the streets of the beautiful old Michigan town where I grew up. It\u2019s full of old Victorian mansions and history, and it would work on the creative mind of any kid.\u201d\nWriting for \"The New York Times\", Marilyn Stasio characterized Bellairs' children's books as fast-paced, spooky adventures involving \"believable and likeable\" characters, generally a child and an older person (usually a \"lovable eccentric\") who are friends and must go on adventures and solve a mystery involving supernatural elements such as ghosts and wicked sorcerers. Beyond these supernatural elements, Bellairs's novels evoked \"a child's concern with comfort and security in his \"real\" world,\" addressing childhood fears of abandonment, loneliness, and bullying, as well as coming of age. His stories are described as spooky but ultimately reassuring as the characters conquer evil through friendship.\nThe books have proved especially popular among middle-grade readers between the ages of 9 and 13 but also have significant young adult and adult readerships.\nPosthumous sequels.\nOn his death in 1991, Bellairs left behind two unfinished manuscripts and two one-page synopses for future adventures. The Bellairs estate commissioned Brad Strickland to complete the two unfinished manuscripts and to write novels based on the two one-page outlines. These became \"The Ghost in the Mirror\"; \"The Vengeance of the Witch-finder\"; \"The Drum, the Doll, and the Zombie\"; and \"The Doom of the Haunted Opera\", respectively. Starting in 1996 with \"The Hand of the Necromancer\", Strickland began writing his own stories based on the established characters.\nStrickland announced in spring 2005 that new adventures of the Bellairs' characters were under way, following contract negotiations with the Bellairs' estate and a two-year absence since his last-published novel. The first of these new adventures was \"The House Where Nobody Lived\", which was published on October 5, 2006. All told, thirteen sequels to Bellairs' books have been written by Strickland.\nCritical analysis.\nCritical attention has focused on \"The House With the Clock in Its Walls\" as exemplar of Bellairs' literary merit and style. Critics have argued that Bellairs wrestled with notions of masculinity, femininity, and queerness in his works. Professor Gary D. Schmidt contended that Bellairs' Lewis Barnavelt and Rose Rita Pottinger trilogy traced the \"emerging acceptance of self\" by the two main characters, who struggled with internalized gender norms. Elizabeth Wein analyzes Bellairs's use of the haunted house motif in \"The House With a Clock in Its Walls\". One of the most substantial academic treatments of Bellairs comes from Dawn Heinecken, professor of women's and gender studies at the University of Louisville. Heinecken situates Bellairs in 1970s-era anxieties about gender and changing discourses around masculinity, which were reflected in the era's children's literature.\nConservative critic William Kilpatrick observed of Bellairs that \"While his books are quite frightening, they are well written and undergirded by a moral vision\" and recommended them to parents who wish to expose their children to age-appropriate literature that both entertains and edifies. English education instructor Randi Dickson suggested that Bellairs' oeuvre evidenced greater literary merit than the works of R. L. Stine, whose horror fiction appeals to a youthful demographic similar to Bellairs's. Educators have used \"The House With the Clock in Its Walls\" as a case study for using storytelling techniques to draw in reluctant readers and assigned \"The Curse of the Blue Figurine\" to students in a book club.\nBellairs' books have been translated into Czech, French, German, Japanese, Polish, and Spanish, among other languages.\nIllustrators.\nEdward Gorey provided cover illustrations and frontispieces for all but three of Bellairs's 15 children's novels and continued to illustrate the Strickland novels until Gorey's death in 2000. The novel \"The Beast Under the Wizard's Bridge\" featured Gorey's last published artwork before his death. Despite the strong association of the novels with Gorey's illustrations, Bellairs and Gorey never met and probably never even corresponded. The Gorey covers are no longer in print, though some newer editions of the novels still contain interior Gorey illustrations.\nS. D. Schindler and Bart Goldman have created cover art for the Strickland books published since 2001.\nMarilyn Fitschen provided the covers and illustrations for Bellairs' first three books: \"St Fidgeta and Other Parodies\", \"The Pedant and the Shuffly\", and \"The Face in the Frost\".\n \u2020 Some Lewis Barnavelt and Johnny Dixon books were outlined by Bellairs and completed by Strickland, who subsequently created new stories in both series.\nAdaptations.\nFilms.\nOn November 18, 2011, Mythology Entertainment, founded by Brad Fischer, co-president of production at Phoenix Pictures; Laeta Kalogridis; and James Vanderbilt announced that they hired Eric Kripke, creator of \"Supernatural\" and \"Revolution\", to write and produce a feature film based on John Bellairs' work through a partnership with John's estate. \"Jamie, Laeta and I are thrilled to launch Mythology Entertainment and to be partnering with Eric Kripke and the estate of John Bellairs for our first feature project,\u201d Fischer said.\u201cAs a kid, Eric was inspired by Bellairs\u2019 work and these books have stayed with him through the years\u2026. As a company, we aspire to be a haven for artists and friends who believe in the power of myth and remember that feeling we all got as kids, when the lights went down and the images came up and anything was possible.\u201d\nThe film adaptation of Bellairs' novel \"The House with a Clock in Its Walls\" stars Jack Black as Uncle Jonathan, Cate Blanchett as Mrs. Zimmerman, and Owen Vaccaro as Lewis Barnavelt, and was directed by Eli Roth. It was released on September 21, 2018.\nAudiobooks.\nAs of September 2022, Blackstone Publishing has re-issued Face In the Frost and all 12 Lewis Barnavelt books on CD and digital formats. Beginning in May 2022 and continuing until mid-2023, Blackstone commissioned audiobooks of the Johnny Dixon books, read by Johnny Heller.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52800", "revid": "40592933", "url": "https://en.wikipedia.org/wiki?curid=52800", "title": "Georges-Eug\u00e8ne Haussmann", "text": "French official who renovated Paris (1809\u20131891)\nGeorges-Eug\u00e8ne Haussmann (; 27 March 1809\u00a0\u2013 11 January 1891), known as Baron Haussmann (), was a French official who supervised a radical urban renewal programme of new boulevards, parks, and public works in Paris, referred to as Haussmann's renovation of Paris, aimed at introducing \"grandeur\" in the city. First a prefect in Var (1849\u20131850), Yonne (1850\u20131851), and Gironde (1851\u20131853), his skills as an administrator led to his appointment in Paris by Emperor Napoleon III in 1853.\nThe signature architectural landmark of his works was the Paris Opera, the largest theatre in the world, designed by Charles Garnier, crowning the centre of Napoleon III's new Paris. Haussmann completely rebuilt Paris above and below ground; on his own estimation by 1870 one in five streets in central Paris were his creation, while revamped sewers now ran alongside miles of pipes to distribute gas for thousands of new streetlights. With his right-hand Adolphe Alphand and at the Emperor's direction, a plan was laid out for four major parks at the cardinal points of the compass around the city: the Bois de Boulogne to the west, Bois de Vincennes to the east, Parc des Buttes Chaumont to the north, and Parc Montsouris to the south. The major parks and their smaller counterparts in the city were an immediate success with all classes of Parisians.\nCritics forced his dismissal as prefect of Seine in 1870, but his vision of the city still defines much of Paris today. He was made a senator in 1857 and a grand cross of the Legion of Honour in 1862. The Boulevard Haussmann as well as Haussmann\u2013Saint-Lazare station in Paris bear his name.\nBiography.\nOrigins and early career.\nHaussmann was born on 27 March 1809, at 53 Rue du Faubourg-du-Roule, in the Beaujon neighbourhood of Paris, the son of Nicolas-Valentin Haussmann and \u00c8ve-Marie-Henriette-Caroline Dentzel, both of Alsatian families. His paternal grandfather Nicolas Haussmann was a deputy of the Legislative Assembly and National Convention, an administrator of the department of Seine-et-Oise and a commissioner to the army. His maternal grandfather was a general and a deputy of the National Convention: Georges Fr\u00e9d\u00e9ric Dentzel, a baron of Napoleon's First Empire.\nHe began his schooling at the Coll\u00e8ge Henri-IV and the Lyc\u00e9e Condorcet in Paris and then began to study law. At the same time, he studied music as a student at the Paris Conservatory, as he was a talented musician. Haussmann joined his father as an insurgent in the July Revolution of 1830, which deposed the Bourbon king Charles X in favor of his cousin, Louis Philippe, Duke of Orl\u00e9ans.\nHe was married to Octavie de Laharpe on 17 October 1838 in Bordeaux. They had two daughters: Henriette, who married the banker Camille Dollfus in 1860, and Valentine, who married Vicomte Maurice Pern\u00e9ty, the chief of staff of his department, in 1865. Valentine divorced Pern\u00e9ty in 1891 and then married Georges Renouard (1843\u20131897).\nOn 21 May 1831, Haussmann began his career in public administration. He was named the secretary-general of the prefecture of the department of Vienne at Poitiers. On 15 June 1832, he became the deputy prefect of Yssingeaux. Despite proving himself as a hard worker and able representative of the government, his arrogance, dictatorial manner, and habit of impeding his superiors led to his being continually passed over for promotion to prefect. He was posted as deputy prefect to the Lot-et-Garonne department at N\u00e9rac on 9 October 1832, the Ari\u00e8ge department at Saint-Girons on 19 February 1840, and the Gironde department at Blaye on 23 November 1841. \nAfter the 1848 Revolution swept away the July Monarchy, establishing the Second Republic in its place, Haussmann's fortunes changed. In 1848, Louis-Napol\u00e9on Bonaparte, the nephew of Napol\u00e9on Bonaparte, became the first elected President of France. In January 1849, Haussmann travelled to Paris to meet the Minister of the Interior and the new President. He was deemed to be a loyal holdover from the civil service of the July Monarchy, and shortly after their meeting Louis-Napol\u00e9on granted Haussmann a promotion to prefect of the Var department at Draguignan. In 1850, he became the prefect of the Yonne department. In 1851 was appointed as prefect of Gironde out of Bordeaux.\nIn 1850, Louis Napol\u00e9on started an ambitious project to connect the Louvre to the H\u00f4tel de Ville in Paris, by extending the Rue de Rivoli and create a new park, the Bois de Boulogne, on the outskirts of the city, but he was exasperated by the slow progress made by the incumbent prefect of Seine, Jean-Jacques Berger. Louis-Napoleon was highly popular, but he was blocked from running for re-election by the constitution of the Second French Republic. While he had a majority of the votes in the legislature at his disposal, he did not have the two-thirds majority needed to change the constitution.\nAt the end of December 1851, he staged a \"coup d'\u00e9tat\", and in 1852 declared himself Emperor of the French under the title Napoleon III. In November 1852, a plebiscite overwhelmingly approved Napoleon's assumption of the throne, and he soon began searching for a new prefect of Seine to carry out his Paris reconstruction program.\nThe Emperor's Minister of the Interior, Victor de Persigny, interviewed the prefects of Rouen, Lille, Lyon, Marseille and Bordeaux for the Paris post. In his memoirs, he described his interview with Haussmann:\n\"It was Monsieur Haussmann who impressed me the most. It was a strange thing, but it was less his talents and his remarkable intelligence that appealed to me, but the defects in his character. I had in front of me one of the most extraordinary men of our time; big, strong, vigorous, energetic, and at the same time clever and devious, with a spirit full of resources. This audacious man wasn't afraid to show who he was.\u00a0... He told me all of his accomplishments during his administrative career, leaving out nothing; he could have talked for six hours without a break, since it was his favourite subject, himself. I wasn't at all displeased.\u00a0... It seemed to me that he was exactly the man I needed to fight against the ideas and prejudices of a whole school of economics, against devious people and skeptics coming from the Stock Market, against those who were not very scrupulous about their methods; he was just the man. Whereas a gentleman of the most elevated spirit, cleverness, with the most straight and noble character, would inevitably fail, this vigorous athlete\u00a0... full of audacity and skill, capable of opposing expedients with better expedients, traps with more clever traps, would certainly succeed. I told him about the Paris works and offered to put him in charge.\"\nPersigny sent him to Napoleon III with the recommendation that he was exactly the man needed to carry out his renewal plans for Paris. On 22 June 1853, Napoleon III made him prefect of Seine. On 29 June, the Emperor gave him the mission of making the city healthier, less congested and grander. Haussmann held this post until 1870.\nRebuilding of Paris.\nNapoleon III and Haussmann launched a series of enormous public works projects in Paris, hiring tens of thousands of workers to improve the sanitation, water supply and traffic circulation of the city. Napoleon III installed a huge map of Paris in his office, marked with coloured lines where he wanted new boulevards to be. To a degree the boulevard system was planned as a mechanism for the easy deployment of troops and artillery, but its main purpose was to help relieve traffic congestion in a dense city and interconnect its landmark buildings. He and Haussmann met almost every day to discuss the projects and overcome the enormous obstacles and opposition they faced as they built the new Paris.\nThe population of Paris had doubled since 1815, with no increase in its area. To accommodate the growing population and those who would be forced from the centre by the new boulevards and squares Napoleon III planned to build, he issued a decree annexing eleven surrounding communes, and increasing the number of arrondissements from twelve to twenty, which enlarged the city to its modern boundaries.\nFor the nearly two decades of Napoleon III's reign, and for a decade afterwards, most of Paris was an enormous construction site. To bring fresh water to the city, his hydraulic engineer, Eug\u00e8ne Belgrand, built a new aqueduct to bring clean water from the Vanne River in Champagne, and a new huge reservoir near the future Parc Montsouris. These two works increased the water supply of Paris from 87,000 to 400,000 cubic metres of water a day. \nHe laid hundreds of kilometres of pipes to distribute the water throughout the city. He built a second network, using the less-clean water from the Ourq and the Seine, to wash the streets and water the new park and gardens. He completely rebuilt the Paris sewers, and installed miles of pipes to distribute gas for thousands of new streetlights along the Paris streets.\nBeginning in 1854, in the centre of the city, Haussmann's workers tore down hundreds of old buildings and cut eighty kilometres of new avenues, connecting the central points of the city. Buildings along these avenues were required to be the same height and in a similar style, and to be faced with cream-coloured stone, creating the uniform look of Paris boulevards. Victor Hugo mentioned that it was hardly possible to distinguish what the house in front of you was for: theatre, shop or library. Haussmann managed to rebuild the city in just 17 years, although some works were completed after him leaving office as prefect. \"On his own estimation the new boulevards and open spaces displaced 350,000 people;\u00a0... by 1870 one-fifth of the streets in central Paris were his creation; he had spent\u00a0... 2.5 billion francs on the city;\u00a0... one in five Parisian workers was employed in the building trade\".\nTo connect the city with the rest of France, Napoleon III built two new railroad stations: the Gare de Lyon (1855) and the Gare du Nord (1864). He completed Les Halles, the great iron and glass produce market in the centre of the city, and built a new municipal hospital, the H\u00f4tel-Dieu, in the place of crumbling medieval buildings on the \u00cele de la Cit\u00e9. The signature architectural landmark was the Paris Opera, or Palais Garnier, the largest theatre in the world, designed by Charles Garnier (hence its name), crowning the centre of Napoleon III's new Paris, at the end of the newly-designed Avenue de l'Op\u00e9ra. When the Empress Eugenie saw the model of the opera house, and asked the architect what the style was, Garnier said simply, \"Napoleon the Third.\"\nNapoleon III also wanted to build new parks and gardens for the recreation and relaxation of the Parisians, particularly those in the new neighbourhoods of the expanding city.\nNapoleon III's new parks were inspired by his memories of the parks in London, especially Hyde Park, where he had strolled and promenaded in a carriage while in exile, but he wanted to build on a much larger scale. Working with Haussmann and Adolphe Alphand, the engineer who headed the new Service of Promenades and Plantations, he laid out a plan for four major parks at the cardinal points of the compass around the city. Thousands of workers and gardeners began to dig lakes, build cascades, plant lawns, flowerbeds, trees, and construct chalets and grottoes. Napoleon III created the Bois de Boulogne (1852\u201358) to the west of Paris, the Bois de Vincennes (1860\u201365) to the east, the Parc des Buttes Chaumont (1865\u201367) to the north, and Parc Montsouris (1865\u201378) to the south.\nIn addition to building the four large parks, Haussmann had the city's older parks, including Parc Monceau, formerly owned by the Orleans family, and the Jardin du Luxembourg, refurbished and replanted. He created twenty small parks and gardens in the neighbourhoods, as miniature versions of his large parks. Alphand termed these small parks \"green and flowering salons.\" The intention of Napoleon's plan was to have one park in each of the eighty neighbourhoods of Paris, so no one was more than 10 minutes walk from a park. The parks were an immediate success with all classes of Parisians.\nHaussmann's works resulted in 64 km (39.7 mi) of new streets; France's annual budget was spent on rebuilding the city over the course of just over two decades.\nBaron Haussmann.\nTo thank Haussmann for his work, Napoleon III proposed in 1857 to make Haussmann a member of the French Senate and to give him an honorary title, as he had done for some of his generals. Haussmann asked for the title of baron, which, as he said in his memoirs, had been the title of his maternal grandfather, Georges Fr\u00e9d\u00e9ric, Baron Dentzel, a general under Napoleon I, of whom Haussmann was the only living male descendant. According to his memoirs, he joked that he might consider the title \"aqueduc\" (a pun on the French words for 'duke' and 'aqueduct') but that no such title existed. This use of \"baron\", however, was not officially sanctioned, and he remained, legally, Monsieur Haussmann.\nDownfall.\nDuring the first half of the reign of Napoleon III, the French legislature had little real power. All decisions were made by the Emperor. Beginning in 1860, however, Napoleon decided to liberalise the Empire and give legislators power. The members of the opposition in the parliament increasingly aimed their criticism of Napoleon III at Haussmann, criticising his spending and high-handed attitude toward the parliament.\nThe cost of the reconstruction projects was also rising rapidly. In December 1858 the Council of State ruled that a property owner whose land was expropriated could retain the land that was not specifically needed for the street, greatly increasing the cost of expropriation. Property owners also became much more clever in claiming higher payments for their buildings, often by creating sham shops and businesses within their buildings. The cost of expropriations jumped from 70 million francs for the first projects to about 230 million francs for the second wave of projects.\nIn 1858, the Cour des Comptes, which oversaw the finances of the Empire, ruled that the Caisses des Grands Travaux was operating illegally by making \"disguised loans\" to private companies. The court ruled that such loans had to be approved by the parliament. The parliament was asked to approve a loan of 250 millions francs in 1865, and another 260 million francs in 1869.\nMembers of the opposition were particularly outraged when in 1866 he took away part of the Luxembourg to make room for the new avenue between the Luxembourg Gardens and the Observatory, and destroyed the old garden nursery which lay between Rue Auguste-Comte, the Rue d'Assas and Avenue de l'Observatoire. When the Emperor and Empress attended a performance at the Od\u00e9on Theatre, near the Luxembourg Gardens, members of the audience shouted \"Dismiss Haussmann!\" and jeered the Emperor. Nonetheless, the Emperor stood by Haussmann.\nOne of the leaders of the parliamentary opposition to Napoleon, Jules Ferry, ridiculed the accounting practices of Haussmann as \"Les Comptes fantastiques de Haussmann\", or \"The fantastic accounts of Haussmann\", in 1867, a play on words of \"Les Contes Fantastiques de Hoffmann\", The Fantastical Tales of Hoffmann. The republican opposition to Napoleon III won many parliamentary seats in the 1869 elections, and increased its criticism of Haussmann. \nNapoleon III gave in to the criticism and named an opposition leader and fierce critic of Haussmann, \u00c9mile Ollivier, as his new prime minister. Haussmann was invited to resign. Haussmann refused to resign, and was relieved of his duties by the Emperor. Six months later, during the Franco-German War, Napoleon III was captured by the Germans, and the Empire was overthrown.\nIn his memoires, Haussmann had this comment on his dismissal: \"In the eyes of the Parisians, who like routine in things but are changeable when it comes to people, I committed two great wrongs; over the course of seventeen years I disturbed their daily habits by turning Paris upside down, and they had to look at the same face of the Prefect in the H\u00f4tel de Ville. These were two unforgivable complaints.\"\nAfter the fall of Napoleon III, Haussmann spent about a year abroad, but he re-entered public life in 1877, when he became Bonapartist deputy for Ajaccio. His later years were occupied with the preparation of his \"M\u00e9moires\" (three volumes, 1890\u20131893).\nDeath.\nHaussmann died in Paris on 11 January 1891 at age 81 and was buried in P\u00e8re Lachaise Cemetery. His wife, Louise-Octavie de la Harpe, had died just eighteen days earlier. At the time of their deaths, they had resided in an apartment at 12 Rue Boissy d'Anglas, near the Place de la Concorde. The will transferred their estate to the family of their only surviving daughter, Valentine Haussmann. \nLegacy.\nHaussmann's plan for Paris inspired the urban planning and creation of similar boulevards, squares and parks in Cairo, Buenos Aires, Brussels, Rome, Vienna, Stockholm, Madrid, and Barcelona. After the Paris International Exposition of 1867, William I, the King of Prussia, carried back to Berlin a large map showing Haussmann's projects, which influenced the future planning of that city. \nHis work also inspired the City Beautiful Movement in the United States. Frederick Law Olmsted, the designer of Central Park in New York, visited the Bois de Boulogne eight times during his 1859 study trip to Europe, and was also influenced by the innovations of the Parc des Buttes Chaumont. The American architect Daniel Burnham borrowed liberally from Haussmann's plan and incorporated the diagonal street designs in his 1909 Plan of Chicago.\nHaussmann had been made senator in 1857, member of the Academy of Fine Arts in 1867, and grand cross of the Legion of Honour in 1862. His name is preserved in the Boulevard Haussmann.\nControversies.\nFinancing the reconstruction of Paris.\nThe reconstruction of the centre of Paris was the largest such public works project ever undertaken in Europe. Never before had a major city been completely rebuilt when it was still intact. London, Rome, Copenhagen and Lisbon had been rebuilt after major fires or earthquakes. Napoleon III began his grand projects when he was prince-president, when the government had a full treasury. In his 1851 plan, he proposed to extend the Rue de Rivoli to connect the Louvre with the H\u00f4tel de Ville, to build a wide new avenue, the Boulevard de Strasbourg on a north-south axis, and to complete the central produce market, Les Halles, long unfinished. \nHe approached the Parliament and received authorisation to borrow fifty million francs. The Emperor's ambitions were much greater. He wanted to finish the building of the Louvre and to create an enormous new park, the Bois de Boulogne, to the west of Paris. His prefect of Seine, Berger, protested that Paris did not have the money. At this point, Napoleon dismissed Berger and hired Haussmann, and Haussmann looked for a better way to finance his projects.\nNapoleon III was especially anxious to finish the extension of the Rue de Rivoli from the Louvre to the H\u00f4tel de Ville, before the opening of the Paris Universal Exposition of 1855. Napoleon III demanded the construction of a new luxury hotel, to house his imperial guests during the Exposition. Napoleon III and Haussmann turned for funding to two Parisian bankers, the Pereire brothers, who had created a bank called Cr\u00e9dit Mobilier.\nIn December 1854, with no time to lose before the opening of the exposition, the Pereire brothers created a new company to construct the street and the hotel. They sold 240,000 shares for one hundred francs each, with 106,665 shares purchased by Cr\u00e9dit Mobilier, 42,220 by the Pereire brothers, and the rest to private investors. In 1850 and 1851, at Napoleon's request, new laws were passed making it easier for Paris to expropriate private land for public purposes. They allowed the city to expropriate, in the public interest, land for new streets, and all of the building sites on both sides of the new streets, an asset of enormous value.\nThe government expropriated the land, with buildings, that it needed to build the new street and hotel. The owners were paid a price set by an arbitration board. The government then sold the land and buildings to the company established by the Pereire brothers, which tore down the old buildings and constructed a new street, sidewalks and a new square, the Place du Palais-Royal. They built new buildings along the new street, and sold them or rented them to new owners.\nThey constructed the Hotel du Louvre, one of the largest buildings in the city and one of the first modern luxury hotels in Paris. The company also built rows of luxury shops under a covered arcade along the Rue de Rivoli and around the hotel, which they rented to shopkeepers. Construction began immediately. Three thousand workers laboured both day and night for two years to complete the street and hotel, which were finished in time for the Exposition.\nThis was the basic method adopted by Haussmann to finance the reconstruction of Paris. The government expropriated the old buildings and compensated the owners, and private companies built the new streets and buildings, following the standards set by Haussmann. The private companies were often paid for the construction work they did, with city land, which they could then develop and sell.\nIn 1854, the Parliament approved another loan of sixty million francs, but Haussmann needed far more for his future projects. On 14 November 1858, Napoleon and Haussmann created the \"Caisse des travaux de la Ville\", specifically to finance the reconstruction projects. It borrowed money at a higher rate of interest than regular city bonds, and used the money to pay private companies, such as that of Pereire brothers, to rebuild the city. \"It was a great relief for the city's finances,\" Haussmann wrote later in his \"Memoirs\" \"which allowed the city to carry out several grand operations at the same time, with rapid execution, in short more economically.\" It functioned entirely independently of the parliament, which greatly irritated the members of parliament.\nCriticism of the renovation.\nHaussmann spent 2.5 billion francs on rebuilding Paris, a sum that staggered his critics. Jules Ferry and other political rivals of Napoleon alleged that Haussmann had recklessly squandered money, and planned poorly. They alleged he had falsified accounts. While Napoleon had hired Haussmann, the political attacks were so intense that he forced Haussmann to become a scapegoat, hoping his resignation would satisfy the bourgeois parties which had become increasingly angered during the economic depression of the late 1860s.\nHaussmann's plans, with their radical redevelopment, coincided with a time of intense political activity in Paris. Many Parisians were troubled by the destruction of \"old roots\". Historian Robert Herbert says that \"the impressionist movement depicted this loss of connection in such paintings as Manet's \"A Bar at the Folies-Berg\u00e8re\".\" The subject of the painting is talking to a man, seen in the mirror behind her, but seems disengaged. According to Herbert, this is a symptom of living in Paris at this time: the citizens became detached from one another. \"The continuous destruction of physical Paris led to a destruction of social Paris as well.\" The poet Charles Baudelaire witnessed these changes and wrote the poem \"The Swan\" in response. The poem is a lament for, and critique of the destruction of the medieval city in the name of \"progress\":\n \"Old\" Paris is gone (no human heart&lt;br&gt;\nchanges half so fast as a city's face)\u00a0...&lt;br&gt;\nThere used to be a poultry market here,&lt;br&gt;\nand one cold morning\u00a0... I saw&lt;br&gt;\n&lt;br&gt;a swan that had broken out of its cage,&lt;br&gt;\nwebbed feet clumsy on the cobblestones,&lt;br&gt;\nwhite feathers dragging through uneven ruts,&lt;br&gt;\nand obstinately pecking at the drains\u00a0...&lt;br&gt;&lt;br&gt;\nParis changes\u00a0... but in sadness like mine&lt;br&gt;\nnothing stirs\u2014new buildings, old&lt;br&gt;\nneighbourhoods turn to allegory,&lt;br&gt;\nand memories weigh more than stone.\nHaussmann was also criticized for the great cost of his project. Napoleon III deposed Haussmann on 5 January 1870 in order to improve his own flagging popularity. Haussmann was a favourite target of the Situationist's critique. Besides pointing out the repressive aims that were achieved by Haussmann's urbanism, Guy Debord and his friends, who considered urbanism to be a \"state science\" or inherently \"capitalist\" science, also underlined that he nicely separated leisure areas from work places, thus announcing modern functionalism, as illustrated by Le Corbusier's precise zone tripartition, with one zone for circulation, one for housing, and one for labour.\nSome of the contemporary critics of Haussmann softened their views over time. Jules Simon was an ardent republican who had refused to take an oath to Napoleon III, and had been a fierce critic of Haussmann in parliament but in 1882, he wrote of Haussmann in the \"Gaulois\":\n\"He tried to make Paris a magnificent city, and he succeeded completely. When he took Paris in hand and managed our affairs, rue Saint-Honore and rue Saint-Antoine were still the largest streets in the city. We had no other promenades than the Grands Boulevards and the Tuileries; the Champs-\u00c9lys\u00e9es was most of the time a sewer; the Bois-de-Boulogne was at the end of the world. We were lacking water, markets, light, in those far-off times, which are only thirty years past. He demolished neighbourhoods- one could say, entire cities. They cried that he would create a plague; he let us cry and, on the contrary, through his intelligent piercing of streets, he gave us air, health and life. Here he created a street; there he created an avenue or a boulevard; here a Place, a Square; a Promenade. Out of emptiness he made the Champs-\u00c9lys\u00e9es, the Bois de Boulogne, the Bois de Vincennes. He introduced, into his beautiful capital, trees and flowers, and populated it with statues.\"\nThe debate about the military function of Haussmann's boulevards.\nSome critics and historians in the 20th century, notably Lewis Mumford, argued that the real purpose of Haussmann's boulevards was to make it easier for the army to crush popular uprisings. According to these critics, the wide boulevards gave the army greater mobility, a wider range of fire for their cannon, and made it harder to block streets with barricades. They argued that the boulevards built by Haussmann allowed the French army to easily suppress the Paris Commune in 1871.\nOther historians disputed this argument. They noted that while Haussmann sometimes mentioned the military advantages of the boulevards when seeking funding for his projects, it was never the main purpose. Their main purpose, according to Napoleon III and Haussmann, was to improve traffic circulation, provide space and light and views of the city landmarks, and to beautify Paris.\nHaussmann did not deny the military value of the wider streets. In his \"Memoires\", he wrote that his new boulevard Sebastopol resulted in the \"gutting of old Paris, of the quarter of riots and barricades.\" He admitted he sometimes used this argument with the parliament to justify the high cost of his projects, arguing that they were for national defense and should be paid for, at least partially, by the state. He wrote: \"But, as for me, I who was the promoter of these additions made to original project, I declare that I never thought in the least, in adding them, of their greater or lesser strategic value.\" \nThe Paris urban historian Patrice de Moncan wrote: \"To see the works created by Haussmann and Napoleon III only from the perspective of their strategic value is very reductive. The Emperor was a convinced follower of Saint-Simon. His desire to make Paris, the economic capital of France, a more open, more healthy city, not only for the upper classes but also for the workers, cannot be denied, and should be recognised as the primary motivation.\"\nDuring the suppression of the Paris Commune in 1871, the newly built-boulevards were not a major factor in the Commune's defeat. The Communards were defeated in one week, not because of Haussmann's boulevards, but because they were outnumbered by five to one. They had fewer weapons and fewer men trained to use them, they had no plan for the defense of the city. They had very few experienced officers and there was no single commander, with each neighborhood left to defend itself, and they had no hope of military support from outside of Paris.\nReferences.\nNotes and citations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52803", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=52803", "title": "The Hunchback of Notre-Dame", "text": "1831 novel by Victor Hugo\nThe Hunchback of Notre-Dame (, originally titled Notre-Dame de Paris. 1482) is a French Gothic novel by Victor Hugo, published in 1831. The title refers to the Notre-Dame Cathedral, which features prominently throughout the novel. It focuses on the unfortunate story of Quasimodo, the Romani street dancer Esmeralda, and Quasimodo's guardian the Archdeacon Claude Frollo in 15th-century Paris. All its elements\u2014the Renaissance setting, impossible love affairs and marginalised characters\u2014make the work a model of the literary themes of Romanticism.\nThe novel is considered a classic of French literature and has been adapted repeatedly for film, stage and television. Some prominent examples include a 1923 silent film with Lon Chaney, a 1939 sound film with Charles Laughton, a 1956 film with Anthony Quinn, and a 1996 Disney animated film with Tom Hulce.\nWritten during a time of cultural upheaval, the novel champions historical preservation. Hugo solidified Notre-Dame de Paris as a national icon, arguing for the preservation of Gothic architecture as an element of France's cultural heritage.\nTitle.\nThe novel's French title, \"Notre-Dame de Paris\", refers to Notre-Dame Cathedral. Frederic Shoberl's 1833 English translation was published as \"The Hunchback of Notre-Dame\". This became the generally used title in English, referring to Quasimodo, Notre-Dame's bell-ringer. Victor Hugo was allegedly upset that this translation placed focus on only one character, seeing his novel as a broader plea for the preservation of France's gothic architecture.\nBackground.\nVictor Hugo initially agreed to write \"Notre-Dame de Paris\" in 1828. Due to Hugo's other literary projects, the novel fell by the wayside until 1830. A primary theme of the novel is that of the value of Gothic architecture, which was neglected and often destroyed to be replaced by new buildings or defaced by replacement of parts of buildings in a newer style. For instance, the medieval stained glass panels of Notre-Dame de Paris had been replaced by white glass to let more light into the church. A few years earlier, Hugo had already published a paper entitled \"Guerre aux D\u00e9molisseurs\" (\"War [declared] on the Demolishers\") specifically aimed at saving Paris's medieval architecture. The agreement with his original publisher, Gosselin, was that the book would be finished that same year, but Hugo was constantly delayed due to the demands of other projects. In the summer of 1830, Gosselin demanded that Hugo complete the book by February 1831. Beginning in September 1830, Hugo worked nonstop on the project thereafter.\nLegend has it that Hugo locked himself in his room, getting rid of his clothes to write the novel on time, the idea being he could not go outside without clothes.\nPlot.\nIn 1482 Paris, during the 21st year of the reign of Louis XI, 10 years before Christopher Columbus landed in the Americas, sixteen-year-old Roma dancer Esmeralda is the romantic and sexual interest of many men, including Captain Phoebus de Chateaupers; poet Pierre Gringoire; the deformed cathedral bell-ringer Quasimodo, and his guardian Archdeacon Claude Frollo. Frollo is torn between his obsessive lust for Esmeralda and the rules of Notre-Dame Cathedral. He orders Quasimodo to kidnap her, but Quasimodo is captured by Phoebus and his guards. After he saves her, Esmeralda becomes infatuated with Phoebus. Gringoire, who attempted to help Esmeralda but was knocked out by Quasimodo, unwittingly wanders into the \"Court of Miracles\", populated by the Roma and the truands (beggars). They are about to hang him for being an outsider, but Esmeralda saves him by agreeing to marry him. She only does it to save his life, however, and much to Gringoire's annoyance, refuses to allow him to touch her.\nThe following day, Quasimodo is sentenced to be flogged and turned on the pillory for two hours, followed by another hour's public exposure. He calls for water. Seeing his thirst, Esmeralda approaches the public stocks and offers him a drink of water. It saves him, and she captures his heart.\nFrollo learns from Gringoire, with whom he has a passing acquaintance, that Esmeralda has taught her pet goat, Djali, who sometimes performs with her on stage, to spell \"PHOEBUS\" using movable letters, and that she often whispers the name Phoebus when she thinks she is alone. Frollo suspects Phoebus may be a name. As it happens, Phoebus is a drinking companion of Frollo's dissolute younger brother, Jehan. After seeing them set out for a local tavern, Frollo follows them. He learns that Phoebus has arranged an assignation with Esmeralda at a local boarding-house, and follows Phoebus there. He observes the meeting from an adjoining room. Esmeralda begs Phoebus to marry her, but Phoebus only wants to lie with her, and eventually seduces her. Inflamed with jealousy, Frollo stabs Phoebus, though not fatally. Esmeralda briefly faints, though not before she has caught a glimpse of Frollo. When she recovers, Frollo has fled, and she is found near Phoebus' body. Esmeralda is arrested and charged with the attempted murder of Phoebus and also with witchcraft, and is sentenced to death by hanging. The prison's torturer hurts her so badly that she falsely confesses to Phoebus' attempted murder. While imprisoned, awaiting her execution, Esmeralda is visited by Frollo. The Archdeacon professes his love for her and promises to help her escape if she reciprocates. However, recognising him as Phoebus' true attacker, she angrily rebuffs him. As Esmeralda is being led to the gallows, Quasimodo swings down from Notre-Dame and carries her off to the cathedral, temporarily protecting her\u00a0\u2013 under the law of sanctuary\u00a0\u2013 from arrest.\nFrollo delves deeper into his obsession and becomes frustrated with his plan failing. Upon seeing Esmeralda and Quasimodo when going to meet the latter, he grows jealous. That night he breaks into Esmeralda's cell with his master-key and attempts to rape her. Quasimodo intervenes and beats him, almost throwing him off the cathedral before the moonlight reveals his identity. Frollo kicks Quasimodo and declares to Esmeralda that if he cannot have her, no one shall.\nFrollo later informs Gringoire that the Court of Parlement has voted to remove Esmeralda's right to sanctuary so she can no longer seek shelter in the cathedral and will be taken away to be executed. Clopin Trouillefou, the leader of the Roma, hears the news from Gringoire and rallies the Court of Miracles to charge Notre-Dame and rescue Esmeralda.\nQuasimodo incorrectly assumes the approaching Roma intend to harm Esmeralda and drives them off. As Quasimodo defends the cathedral against the invaders, the uproar reaches the king, who is incorrectly informed that those attacking the cathedral are eager for Esmeralda's hanging rather than trying to rescue her. The king orders the authorities to dispatch the invaders and calls for Esmeralda's immediate execution to settle the unrest. In the chaos, Esmeralda is taken from the cathedral by Frollo and Gringoire.\nThe king's men come to Notre-Dame searching for Esmeralda. Quasimodo believes they intend to rescue her and helps them, meaning that if she had still been there, he would have inadvertently betrayed her.\nFrollo once again attempts to win Esmeralda's love, but she asserts that she would rather die than be with him. Frollo goes to alert the authorities while trapping Esmeralda with Sister Gudule, a reclusive anchoress who bears an extreme hatred for the Roma, as she believes they cannibalised her infant daughter. However, it is revealed that Esmeralda is Gudule's long-lost daughter Agn\u00e8s, abducted and raised by the Roma. The two women's joyous reunion is cut short when the king's men arrive to take Esmeralda to the gallows. A desperate Gudule clings to Esmeralda even as she is taken to the place of execution. The guards pull the old woman off her daughter, and she falls to the pavement and dies from the harsh impact.\nFrom the tower of Notre-Dame, Frollo and Quasimodo witness as Esmeralda is hanged. Upon observing this, Quasimodo pushes the Archdeacon from the height of the cathedral to his death. With nothing left to live for, Quasimodo vanishes and is never seen again.\nA deformed skeleton is found many years later embracing another in the charnel house at Montfaucon, implying that Quasimodo had sought Esmeralda among the decaying corpses and laid down to die while holding her. As the guards attempt to pull the skeletons apart, his skeleton crumbles to dust.\nMajor themes.\nThe novel's original French title, \"Notre-Dame de Paris\", indicates that the cathedral itself is the most significant aspect of the novel, both the main setting and the focus of the story's themes. The building had fallen into disrepair at the time of writing, which was something Hugo felt strongly about. The book portrays the Romantic era as one of extremes in architecture, passion, and religion. The theme of determinism (fate and destiny, as set up in the preface of the novel through the introduction of the word \"ANANKE\") is explored, as well as revolution and social strife.\nArchitecture.\nArchitecture is a major concern of Hugo's in \"Notre-Dame de Paris\", not just as embodied in the cathedral itself, but as representing throughout Paris and the rest of Europe an artistic genre which, Hugo argued, was about to disappear with the arrival of the printing press. Claude Frollo's portentous phrase, \"\" (\"This will kill that\", as he looks from a printed book to the cathedral building), sums up this thesis, which is expounded on in Book V, chapter 2. Hugo writes that \"\" (\"whoever was born a poet became an architect\"), arguing that while the written word was heavily censored and difficult to reproduce, architecture was extremely prominent and enjoyed considerable freedom.\n&lt;templatestyles src=\"Verse translation/styles.css\" /&gt;\n\u2014Book V, Chapter 2\n&lt;templatestyles src=\"Screen reader-only/styles.css\" /&gt;Translation:\nWith the recent introduction of the printing press, it became possible to reproduce one's ideas much more easily on paper, and Hugo considered this period to represent the last flowering of architecture as a great art form. As with many of his books, Hugo was interested in a time that seemed to him to be on the cusp of two types of society.\nThe major theme of the third book is that over time the cathedral has been repaired but these repairs and additions have made the cathedral worse: \"And who put the cold, white panes in the place of those windows\" and \"...who substituted for the ancient Gothic altar, splendidly encumbered with shrines and reliquaries, that heavy marble sarcophagus, with angels' heads and clouds\" are a few examples of this. This chapter also discusses how, after repairs to the cathedral after the French Revolution, there was not a significant style in what was added. It seems as if the new architecture is now uglier and worse than it was before the repair.\nLiterary significance and reception.\nHugo introduced with this work the concept of the novel as Epic Theatre. A giant epic about the history of a whole people, incarnated in the figure of the great cathedral as witness and silent protagonist of that history, and the whole idea of time and life as an ongoing, organic panorama centered on dozens of characters caught in the middle of that history. It is the first novel to have beggars as protagonists.\nA significant aspect of \"Notre-Dame de Paris\" is that it encompasses the whole of life, from the King of France to Paris sewer rats, in a manner later used by Honor\u00e9 de Balzac, Gustave Flaubert and many others, including Charles Dickens. The enormous popularity of the book in France spurred the nascent historical preservation movement in that country and strongly encouraged Gothic revival architecture. Ultimately it led to major renovations at Notre-Dame in the 19th century led by Eug\u00e8ne Viollet-le-Duc.\nAllusions and references.\nAllusions to actual history, geography and current science.\nIn \"The Hunchback of Notre-Dame\", Victor Hugo makes frequent reference to the architecture of the Cathedral of Notre-Dame in Paris. He also mentions the invention of the printing press, when the bookmaker near the beginning of the work speaks of \"the German pest\".\nIn 2010, British archivist Adrian Glew discovered references to a real-life man called \"Hunchback\" who was a foreman of a government sculpting studio in Paris in the 1820s who worked on post-Revolution restorations to the cathedral.\nAllusions in other works.\nThe name Quasimodo has become synonymous with \"a courageous heart beneath a grotesque exterior\".\nAdaptations.\nTo date, all the film and TV adaptations have strayed somewhat from the original plot, some going as far as to give it a happy ending, including in the classic 1939 film and the 1996 Disney animated film. The 1956 French film is one of the few versions to end almost exactly like the novel, although it changes other sections of the story. The Disney version has an ending that is inspired by an opera created by Hugo himself.\nRadio.\nA 1934 36-part serial adaptation created by George Edwards was broadcast on Australian radio.\nJohn Carradine starred in an hour-long adaptation broadcast on a 1946 episode of \"Your Playhouse of Favorites\".\nThe book was twice adapted and broadcast on BBC Radio 4's \"Classic Serial\":\nComics.\nArtists like Noel Gloesner, Andrew Dickson, Robin Recht, Tim Conrad, Gilbert Bloch, George Evans and Dick Briefer have all created comic strip and book adaptations of \"The Hunchback of Notre Dame\". Paulo Borges, Gustavo Machado and Dan Spiegle have drawn comic strip and book versions based on the 1996 Disney film adaptation.\nEnglish translations.\n\"The Hunchback of Notre-Dame\" has been translated into English many times. Translations are often reprinted in various imprints. Some translations have been revised over time.\n \nReferences.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52805", "revid": "48911350", "url": "https://en.wikipedia.org/wiki?curid=52805", "title": "TFTP", "text": ""}
{"id": "52806", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=52806", "title": "Trivial File Transfer Protocol", "text": "Very basic transfer protocol over UDP\nThe Trivial File Transfer Protocol (TFTP) is a simple lockstep communication protocol for transmitting or receiving files in a client-server application. A primary use of TFTP is in the early stages of nodes booting on a local area network when the operating system or firmware images are stored on a file server.\nTFTP was first standardized in 1981 and updated in .\nOverview.\nDue to its simple design, TFTP can be easily implemented by code with a small memory footprint. It is, therefore, the protocol of choice for the initial stages of any network booting strategy like BOOTP, PXE, BSDP, etc., when targeting from highly resourced computers to very low resourced Single-board computers (SBC) and System on a Chip (SoC). It is also used to transfer firmware images and configuration files to network appliances like routers, firewalls, IP phones, etc. Today, TFTP is virtually unused for Internet transfers.\nTFTP's design was influenced from the earlier protocol EFTP, which was part of the PARC Universal Packet protocol suite. TFTP was first defined in 1980 by IEN 133.\nIn June 1981 The TFTP Protocol (Revision 2) was published as RFC 783 and later updated in July 1992 by RFC 1350 which fixed among other things the Sorcerer's Apprentice syndrome. In March 1995 the TFTP Option Extension RFC 1782 updated later in May 1998 by RFC 2347, defined the option negotiation mechanism which establishes the framework for file transfer options to be negotiated prior to the transfer using a mechanism that is consistent with TFTP's original specification.\nTFTP is a simple protocol for transferring files, implemented on top of the UDP/IP protocols using well-known port number 69. TFTP was designed to be small and easy to implement, and therefore it lacks most of the advanced features offered by more robust file transfer protocols. TFTP only reads and writes files from or to a remote server. It cannot list, delete, or rename files or directories and it has no provisions for user authentication.\nToday TFTP is generally only used on local area networks (LAN).\nOperation.\nA TFTP transfer is initiated by the client issuing a request to read or write a particular file on the server. The request can optionally include a set of negotiated transfer parameters proposed by the client under the terms specified by RFC 2347. If the server grants the request, the file is sent in fixed-length blocks of 512 bytes by default or the number specified in the blocksize negotiated option defined by RFC 2348. Each block of transferred data, which is usually carried within a single IP packet in order to avoid IP fragmentation, must be acknowledged before the next block can be sent. A data packet of less than 512 bytes or the agreed blocksize option signals the termination of a transfer. If a packet gets lost in the network, the intended recipient will timeout and may retransmit their last packet (which may be data or an acknowledgment), thus causing the sender of the lost packet to retransmit that lost packet. The sender has to keep just one packet on hand for retransmission since the lock step acknowledgment guarantees that all older packets have been correctly received. Notice that both devices involved in a transfer are considered senders and receivers. One sends data and receives acknowledgments, the other sends acknowledgments and receives data.\nTFTP defines three modes of transfer: netascii, octet, and mail.\nTFTP uses the User Datagram Protocol (UDP) at the transport layer. A transfer request is always initiated targeting port 69, but the data transfer ports are chosen independently by the sender and receiver during the transfer initialization. The ports are chosen at random according to the parameters of the networking stack, typically from the range of ephemeral ports.\nTFTP has typically been associated with network booting. One of the first applications was the Bootstrap Loading using TFTP standard RFC 906, published in 1984, which established the 1981 published Trivial File Transfer Protocol standard RFC 783 to be used as the standard file transfer protocol for bootstrap loading. It was followed shortly after by the Bootstrap Protocol standard RFC 951 (BOOTP), published in 1985, which allowed a disk-less client machine to discover its own IP address, the address of a TFTP server, and the name of a Network Bootstrap Program (NBP) to be TFTP transferred, loaded into memory, and executed. Dynamic Host Configuration Protocol standard RFC 2131 (DHCP) published in 1997 improved BOOTP capabilities. Finally, the Preboot Execution Environment (PXE) version 2.0 was released in December 1998, and the update 2.1 was made public in September 1999 counting on TFTP as its file transfer protocol. Intel has recently decided to widely support PXE within the new UEFI specification extending the TFTP support to all EFI/UEFI environments.\nThe original protocol has a transfer file size limit of 512 bytes/block x 65535 blocks = 32\u00a0MB. In 1998 this limit was extended to 65535 bytes/block x 65535 blocks = 4\u00a0GB by TFTP Blocksize Option RFC 2348. If the defined blocksize produces an IP packet size that exceeds the minimum MTU at any point of the network path, IP fragmentation and reassembly will occur not only adding more overhead but also leading to total transfer failure when the minimalist IP stack implementation in a host's BOOTP or PXE ROM does not (or fails to properly) implement IP fragmentation and reassembly. If TFTP packets should be kept within the standard Ethernet MTU (1500), the blocksize value is calculated as 1500 minus headers of TFTP (4 bytes), UDP (8 bytes) and IP (20 bytes) = 1468 bytes/block, this gives a limit of 1468 bytes/block x 65535 blocks = 92\u00a0MB. Today most servers and clients support block number roll-over (block counter going back to 0 or 1 after 65535) which gives an essentially unlimited transfer file size.\nSince TFTP utilizes UDP, it has to supply its own transport and session support. Each file transferred via TFTP constitutes an independent exchange. Classically, this transfer is performed in lock-step, with only one packet (either a block of data or an acknowledgment) alternatively in flight on the network at any time. Due to this single data block strategy instead of sending a larger amount of uninterrupted data blocks before pausing the transfer to wait for the corresponding acknowledge (windowing), TFTP provides low throughput especially over high latency links. Microsoft introduced windowed TFTP in Windows 2008 as part of their Windows Deployment Services (WDS), in January 2015 TFTP Windowsize Option RFC 7440 was published. This substantially improves performance for things like PXE booting without the IP fragmentation side effect sometimes observed on Blocksize Option RFC 2348\nSecurity considerations.\nTFTP includes no login or access control mechanisms. Care must be taken when using TFTP for file transfers where authentication, access control, confidentiality, or integrity checking are needed. Note that those security services could be supplied above or below the layer at which TFTP runs. Care must also be taken in the rights granted to a TFTP server process so as not to violate the security of the server's file system. TFTP is often installed with controls such that only files that have public read access are available via TFTP. Also listing, deleting, renaming, and writing files via TFTP are typically disallowed. TFTP file transfers are not recommended where the inherent protocol limitations could raise insurmountable liability concerns.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52807", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=52807", "title": "User datagram protocol", "text": ""}
{"id": "52812", "revid": "43330104", "url": "https://en.wikipedia.org/wiki?curid=52812", "title": "Humidity", "text": "Concentration of water vapour in the air\nHumidity is the concentration of water vapor present in the air. Water vapor, the gaseous state of water, is generally invisible to the naked eye. Humidity indicates the likelihood for precipitation, dew, or fog to be present.\nHumidity depends on the temperature and pressure of the system of interest. The same amount of water vapor results in higher relative humidity in cool air than warm air. A related parameter is the dew point. The amount of water vapor needed to achieve saturation increases as the temperature increases. As the temperature of a parcel of air decreases it will eventually reach the saturation point without adding or losing water mass. The amount of water vapor contained within a parcel of air can vary significantly. For example, a parcel of air near saturation may contain 8\u00a0g of water per cubic metre of air at , and 28\u00a0g of water per cubic metre of air at \nThree primary measurements of humidity are widely employed: absolute, relative, and specific. Absolute humidity is the mass of water vapor per volume of air (in grams per cubic meter). Relative humidity, often expressed as a percentage, indicates a present state of absolute humidity relative to a maximum humidity given the same temperature. Specific humidity is the ratio of water vapor mass to total moist air parcel mass.\nHumidity plays an important role for surface life. For animal life dependent on perspiration (sweating) to regulate internal body temperature, high humidity impairs heat exchange efficiency by reducing the rate of moisture evaporation from skin surfaces. This effect can be calculated using a heat index table, or alternatively using a similar humidex.\nThe notion of air \"holding\" water vapor or being \"saturated\" by it is often mentioned in connection with the concept of relative humidity. This, however, is misleading\u2014the amount of water vapor that enters (or can enter) a given space at a given temperature is almost independent of the amount of air (nitrogen, oxygen, etc.) that is present. Indeed, a vacuum has approximately the same equilibrium capacity to hold water vapor as the same volume filled with air; both are given by the equilibrium vapor pressure of water at the given temperature. There is a very small difference described under \"Enhancement factor\" below, which can be neglected in many calculations unless great accuracy is required.\nDefinitions.\nAbsolute humidity.\nAbsolute humidity usually denotes the volumetric absolute humidity, which is the total mass of water vapor (gas form of water) present in a given volume or mass of air. It does not take temperature into consideration. Absolute humidity in the atmosphere ranges from near zero to roughly per cubic metre when the air is saturated at .\nAbsolute humidity is the mass of the water vapor formula_1, divided by the volume of the air and water vapor mixture formula_2, which can be expressed as:\nformula_3\nIn the equation above, the absolute humidity of a mass of air varies with changes in air temperature or pressure. This makes the (volumetric) absolute humidity unsuitable for some applications. \nAir is a gas, and the volume of a specific amount varies with pressure and temperature, per Boyle's law. Absolute humidity is defined as water mass per volume of air, and a given mass of air will grow or shrink as the temperature or pressure varies; thus, the absolute humidity of a mass of air will vary due to changes in temperature or pressure, even when the proportion of water in that mass of air (its specific humidity) remains constant.\nBecause of the variability of absolute humidity with changes in air temperature or pressure, use of the absolute humidity as defined above is inappropriate for computations in chemical engineering, such as drying, where temperature variations might be significant. As a result, absolute humidity in chemical engineering may refer to mass of water vapor per unit mass of dry air, also known as the \"humidity ratio\" or \"mass mixing ratio\" (see also Specific humidity below), which is better suited for heat and mass balance calculations. The ratio of the mass of water per unit volume as defined in the equation above is also called the \"volumetric humidity\", which may be the preferred term in such contexts. Because of the potential confusion, British Standard BS 1339 recommends avoiding the term \"absolute humidity\", deprecating it in favor of \"volumetric humidity\", \"specific humidity\", and \"mixing ratio\". In general, when using absolute humidity, units should always be carefully checked to determine whether the volumetric or specific humidity is being used; many humidity charts are given in g/kg or kg/kg, but any mass units may be used.\nRelative humidity.\nRelative humidity is the ratio of \"how much water vapour is in the air\" to \"how much water vapour the air could potentially contain\" at a given temperature and pressure. \nIf a sample of humid air at temperature T1 contains water vapour with partial pressure Pw the relative humidity RH is:\nformula_4\nwhere Ps is the saturation pressure of water at temperature T1.\nRelative humidity varies with any change in the temperature or pressure of the air: colder air can contain less vapour, and water will tend to condense out of the air more at lower temperatures. So changing the temperature of air can change the relative humidity, even when the specific humidity remains constant. If two parcels of air have the same specific humidity and temperature but different pressures, the parcel at the higher pressure will have the higher relative humidity.\nCooling air increases the relative humidity. If the relative humidity rises to 100% (the dew point) and there is an available surface or particle, the water vapour will condense into liquid or deposit into ice. Likewise, warming air decreases the relative humidity. Warming some air containing a fog may cause that fog to evaporate, as the droplets are prone to total evaporation due to the lowering partial pressure of water vapour in that air, as the temperature rises.\nRelative humidity only considers the invisible water vapour. Mists, clouds, fogs and aerosols of water do not count towards the measure of relative humidity of the air, although their presence is an indication that a body of air may be close to the dew point.\nRelative humidity is normally expressed as a percentage; a higher percentage means that the air\u2013water mixture is more humid. At 100% relative humidity, the air is saturated and is at its dew point. In the absence of a foreign body on which droplets or crystals can nucleate, the relative humidity can exceed 100%, in which case the air is said to be supersaturated. Introduction of some particles or a surface to a body of air above 100% relative humidity will allow condensation or ice to form on those nuclei, thereby removing some of the vapour and lowering the humidity.\nIn a scientific notion, the relative humidity (formula_5 or formula_6) of an air-water mixture is defined as the ratio of the partial pressure of water vapor (formula_7) in air to the saturation vapor pressure (formula_8) of water at the same temperature, usually expressed as a percentage:\nformula_9\nRelative humidity is an important metric used in weather forecasts and reports, as it is an indicator of the likelihood of precipitation, dew, or fog. In hot summer weather, a rise in relative humidity increases the apparent temperature to humans (and other animals) by hindering the evaporation of perspiration from the skin. For example, according to the \"heat index\", a relative humidity of 75% at air temperature of would feel like .\nBecause wood changes shape with changes in humidity, relative humidity is used to evaluate moisture content and size changes in wood, such as making allowances for seasonal movement in wood floors.\nSpecific humidity.\n\"Specific humidity\" (or moisture content) is the ratio of the mass of water vapor to the total mass of the air parcel. Specific humidity is approximately equal to the mixing ratio, which is defined as the ratio of the mass of water vapor in an air parcel to the mass of \"dry\" air for the same parcel. It is typically represented with the symbol \u03c9, and is commonly used in HVAC system design.\nRelated concepts.\nThe term \"relative humidity\" is reserved for systems of water vapor in air. The term \"relative saturation\" is used to describe the analogous property for systems consisting of a condensable phase other than water in a non-condensable phase other than air.\nMeasurement.\nA device used to measure humidity of air is called a psychrometer or hygrometer. A humidistat is a humidity-triggered switch, often used to control a humidifier or a dehumidifier.\nThe humidity of an air and water vapor mixture is determined through the use of psychrometric charts if both the dry bulb temperature (\"T\") and the wet bulb temperature (\"T\"w) of the mixture are known. These quantities are readily estimated by using a sling psychrometer.\nThere are several empirical formulas that can be used to estimate the equilibrium vapor pressure of water vapor as a function of temperature. The Antoine equation is among the least complex of these, having only three parameters (\"A\", \"B\", and \"C\"). Other formulas, such as the Goff\u2013Gratch equation and the Magnus\u2013Tetens approximation, are more complicated but yield better accuracy.\nThe Arden Buck equation is commonly encountered in the literature regarding this topic:\nformula_10\nwhere formula_11 is the dry-bulb temperature expressed in degrees Celsius (\u00b0C), formula_12 is the absolute pressure expressed in millibars, and formula_13 is the equilibrium vapor pressure expressed in millibars. Buck has reported that the maximal relative error is less than 0.20% between when this particular form of the generalized formula is used to estimate the equilibrium vapor pressure of water.\nThere are various devices used to measure and regulate humidity. Calibration standards for the most accurate measurement include the gravimetric hygrometer, chilled mirror hygrometer, and electrolytic hygrometer. The gravimetric method, while the most accurate, is very cumbersome. For fast and very accurate measurement the chilled mirror method is effective. For process on-line measurements, the most commonly used sensors nowadays are based on capacitance measurements to measure relative humidity, frequently with internal conversions to display absolute humidity as well. These are cheap, simple, generally accurate and relatively robust. All humidity sensors face problems in measuring dust-laden gas, such as exhaust streams from clothes dryers.\nHumidity is also measured on a global scale using remotely placed satellites. These satellites are able to detect the concentration of water in the troposphere at altitudes between . Satellites that can measure water vapor have sensors that are sensitive to infrared radiation. Water vapor specifically absorbs and re-radiates radiation in this spectral band. Satellite water vapor imagery plays an important role in monitoring climate conditions (like the formation of thunderstorms) and in the development of weather forecasts.\nAir density and volume.\nHumidity depends on water vaporization and condensation, which, in turn, mainly depends on temperature. Therefore, when applying more pressure to a gas saturated with water, all components will initially decrease in volume approximately according to the \"ideal gas law\". However, some of the water will condense until returning to almost the same humidity as before, giving the resulting total volume deviating from what the ideal gas law predicted. \nConversely, decreasing temperature would also make some water condense, again making the final volume deviate from predicted by the ideal gas law. Therefore, gas volume may alternatively be expressed as the dry volume, excluding the humidity content. This fraction more accurately follows the ideal gas law. On the contrary the saturated volume is the volume a gas mixture would have if humidity was added to it until saturation (or 100% relative humidity).\nHumid air is less dense than dry air because a molecule of water (\"m\" \u2248 ) is less massive than either a molecule of nitrogen (\"m\" \u2248 28) or a molecule of oxygen (\"m\" \u2248 32). About 78% of the molecules in dry air are nitrogen (N2). Another 21% of the molecules in dry air are oxygen (O2). The final 1% of dry air is a mixture of other gases.\nFor any gas, at a given temperature and pressure, the number of molecules present in a particular volume is constant. Therefore, when some number N of water molecules (vapor) is introduced into a volume of dry air, the number of air molecules in that volume must decrease by the same number N for the pressure to remain constant without using a change in temperature. The numbers are exactly equal if we consider the gases as ideal. The addition of water molecules, or any other molecules, to a gas, without removal of an equal number of other molecules, will necessarily require a change in temperature, pressure, or total volume; that is, a change in \"at least\" one of these three parameters. \nIf temperature and pressure remain constant, the volume increases, and the dry air molecules that were displaced will initially move out into the additional volume, after which the mixture will eventually become uniform through diffusion. Hence the mass per unit volume of the gas\u2014its density\u2014decreases. Isaac Newton discovered this phenomenon and wrote about it in his book \"Opticks\".\nPressure dependence.\nThe relative humidity of an air\u2013water system is dependent not only on the temperature but also on the absolute pressure of the system of interest. This dependence is demonstrated by considering the air\u2013water system shown below. The system is closed (i.e., no matter enters or leaves the system).\nIf the system at State A is isobarically heated (heating with no change in system pressure), then the relative humidity of the system decreases because the equilibrium vapor pressure of water increases with increasing temperature. This is shown in State B.\nIf the system at State A is isothermally compressed (compressed with no change in system temperature), then the relative humidity of the system increases because the partial pressure of water in the system increases with the volume reduction. This is shown in State C. Above 202.64 kPa, the RH would exceed 100% and water may begin to condense.\nIf the pressure of State A was changed by simply adding more dry air, without changing the volume, the relative humidity would not change.\nTherefore, a change in relative humidity can be explained by a change in system temperature, a change in the volume of the system, or change in both of these system properties.\nEnhancement factor.\nThe enhancement factor formula_14 is defined as the ratio of the saturated vapor pressure of water in moist air formula_15 to the saturated vapor pressure of pure water:\nformula_16\nThe enhancement factor is equal to unity for ideal gas systems. However, in real systems the interaction effects between gas molecules result in a small increase of the equilibrium vapor pressure of water in air relative to equilibrium vapor pressure of pure water vapor. Therefore, the enhancement factor is normally slightly greater than unity for real systems.\nThe enhancement factor is commonly used to correct the equilibrium vapor pressure of water vapor when empirical relationships, such as those developed by Wexler, Goff, and Gratch, are used to estimate the properties of psychrometric systems.\nBuck has reported that, at sea level, the vapor pressure of water in saturated moist air amounts to an increase of approximately 0.5% over the equilibrium vapor pressure of pure water.\nEffects.\nClimate control refers to the control of temperature and relative humidity in buildings, vehicles and other enclosed spaces for the purpose of providing for human comfort, health and safety, and of meeting environmental requirements of machines, sensitive materials (for example, historic) and technical processes.\nClimate.\nWhile humidity itself is a climate variable, it also affects other climate variables. Environmental humidity is affected by winds and by rainfall.\nThe most humid cities on Earth are generally located closer to the equator, near coastal regions. Cities in parts of Asia and Oceania are among the most humid. Bangkok, Ho Chi Minh City, Kuala Lumpur, Hong Kong, Manila, Jakarta, Naha, Singapore, Kaohsiung and Taipei have very high humidity most or all year round because of their proximity to water bodies and the equator and often overcast weather. \nSome places experience extreme humidity during their rainy seasons combined with warmth giving the feel of a lukewarm sauna, such as Kolkata, Chennai and Kochi in India, and Lahore in Pakistan. Sukkur city located on the Indus River in Pakistan has some of the highest and most uncomfortable dew points in the country, frequently exceeding in the monsoon season.\nHigh temperatures combine with the high dew point to create heat index in excess of . Darwin experiences an extremely humid wet season from December to April. Houston, Miami, San Diego, Osaka, Shanghai, Shenzhen and Tokyo also have an extreme humid period in their summer months. During the South-west and North-east Monsoon seasons (respectively, late May to September and November to March), expect heavy rains and a relatively high humidity post-rainfall. \nOutside the monsoon seasons, humidity is high (in comparison to countries further from the Equator), but completely sunny days abound. In cooler places such as Northern Tasmania, Australia, high humidity is experienced all year due to the ocean between mainland Australia and Tasmania. In the summer the hot dry air is absorbed by this ocean and the temperature rarely climbs above .\nGlobal climate.\nHumidity affects the energy budget and thereby influences temperatures in two major ways. First, water vapor in the atmosphere contains \"latent\" energy. During transpiration or evaporation, this latent heat is removed from surface liquid, cooling the Earth's surface. This is the biggest non-radiative cooling effect at the surface. It compensates for roughly 70% of the average net radiative warming at the surface.\nSecond, water vapor is the most abundant of all greenhouse gases. Water vapor, like a green lens that allows green light to pass through it but absorbs red light, is a \"selective absorber\". Like the other greenhouse gasses, water vapor is transparent to most solar energy. However, it absorbs the infrared energy emitted (radiated) upward by the Earth's surface, which is the reason that humid areas experience very little nocturnal cooling but dry desert regions cool considerably at night. This selective absorption causes the greenhouse effect. It raises the surface temperature substantially above its theoretical radiative equilibrium temperature with the sun, and water vapor is the cause of more of this warming than any other greenhouse gas.\nUnlike most other greenhouse gases, however, water is not merely below its boiling point in all regions of the Earth, but below its freezing point at many altitudes. As a condensible greenhouse gas, it precipitates, with a much lower scale height and shorter atmospheric lifetime \u2014 weeks instead of decades. Without other greenhouse gases, Earth's blackbody temperature, below the freezing point of water, would cause water vapor to be removed from the atmosphere. Water vapor is thus a \"slave\" to the non-condensible greenhouse gases.\nAnimal and plant life.\nHumidity is one of the fundamental abiotic factors that defines any habitat (the tundra, wetlands, and the desert are a few examples), and is a determinant of which animals and plants can thrive in a given environment.\nThe human body dissipates heat through perspiration and its evaporation. Heat convection, to the surrounding air, and thermal radiation are the primary modes of heat transport from the body. Under conditions of high humidity, the rate of evaporation of sweat from the skin decreases. Also, if the atmosphere is as warm or warmer than the skin during times of high humidity, blood brought to the body surface cannot dissipate heat by conduction to the air. With so much blood going to the external surface of the body, less goes to the active muscles, the brain, and other internal organs. Physical strength declines, and fatigue occurs sooner than it would otherwise. Alertness and mental capacity also may be affected, resulting in \"heat stroke\" or hyperthermia.\nDomesticated plants and animals (e.g. lizards) require regular upkeep of humidity percent when grown in-home and container conditions, for optimal thriving environment.\nHuman comfort.\nAlthough humidity is an important factor for thermal comfort, humans are more sensitive to variations in temperature than they are to changes in relative humidity. Humidity has a small effect on thermal comfort outdoors when air temperatures are low, a slightly more pronounced effect at moderate air temperatures, and a much stronger influence at higher air temperatures.\nHumans are sensitive to humid air because the human body uses evaporative cooling as the primary mechanism to regulate temperature. Under humid conditions, the \"rate\" at which perspiration evaporates on the skin is lower than it would be under arid conditions. Because humans perceive the rate of heat transfer from the body rather than temperature itself, we feel warmer when the relative humidity is high than when it is low.\nHumans can be comfortable within a wide range of humidities depending on the temperature\u2014from 30 to 70%\u2014but ideally not above the Absolute (60\u00a0\u00b0F Dew Point), between 40% and 60%. In general, higher temperatures will require lower humidities to achieve thermal comfort compared to lower temperatures, with all other factors held constant. For example, with clothing level = 1, metabolic rate = 1.1, and air speed 0.1\u00a0m/s, a change in air temperature and mean radiant temperature from 20\u00a0\u00b0C to 24\u00a0\u00b0C would lower the maximum acceptable relative humidity from 100% to 65% to maintain thermal comfort conditions. The CBE Thermal Comfort Tool can be used to demonstrate the effect of relative humidity for specific thermal comfort conditions and it can be used to demonstrate compliance with ASHRAE Standard 55\u20132017.\nSome people experience difficulty breathing in humid environments. Some cases may possibly be related to respiratory conditions such as asthma, while others may be the product of anxiety. Affected people will often hyperventilate in response, causing sensations of numbness, faintness, and loss of concentration, among others.\nVery low humidity can create discomfort, respiratory problems, and aggravate allergies in some individuals. Low humidity causes tissue lining nasal passages to dry, crack and become more susceptible to penetration of rhinovirus cold viruses. Extremely low (below 20%) relative humidities may also cause eye irritation. The use of a humidifier in homes, especially bedrooms, can help with these symptoms. Indoor relative humidities kept above 30% reduce the likelihood of the occupant's nasal passages drying out, especially in winter.\nAir conditioning reduces discomfort by reducing not just temperature but humidity as well. Heating cold outdoor air can decrease relative humidity levels indoors to below 30%. According to ASHRAE Standard 55-2017: Thermal Environmental Conditions for Human Occupancy, indoor thermal comfort can be achieved through the PMV method with relative humidities ranging from 0% to 100%, depending on the levels of the other factors contributing to thermal comfort. However, the recommended range of indoor relative humidity in air conditioned buildings is generally 30\u201360%.\nHuman health.\nHigher humidity reduces the infectivity of aerosolized influenza virus. A study concluded, \"Maintaining indoor relative humidity &gt;40% will significantly reduce the infectivity of aerosolized virus.\"\nExcess moisture in buildings expose occupants to fungal spores, cell fragments, or mycotoxins. Infants in homes with mold have a much greater risk of developing asthma and allergic rhinitis. More than half of adult workers in moldy/humid buildings develop nasal or sinus symptoms due to mold exposure.\nMucociliary clearance in the respiratory tract is also hindered by low humidity. One study in dogs found that mucus transport was lower at an absolute humidity of 9\u00a0g/m3 than at 30\u00a0g/m3.\nIncreased humidity can also lead to changes in total body water that usually leads to moderate weight gain, especially if one is acclimated to working or exercising in hot and humid weather.\nBuilding construction.\nCommon construction methods often produce building enclosures with a poor thermal boundary, requiring an insulation and air barrier system designed to retain indoor environmental conditions while resisting external environmental conditions. The energy-efficient, heavily sealed architecture introduced in the 20th century also sealed off the movement of moisture, and this has resulted in a secondary problem of condensation forming in and around walls, which encourages the development of mold and mildew. Additionally, buildings with foundations not properly sealed will allow water to flow through the walls due to capillary action of pores found in masonry products. Solutions for energy-efficient buildings that avoid condensation are a current topic of architecture.\nFor climate control in buildings using HVAC systems, the key is to maintain the relative humidity at a comfortable range\u2014low enough to be comfortable but high enough to avoid problems associated with very dry air.\nWhen the temperature is high and the relative humidity is low, evaporation of water is rapid; soil dries, wet clothes hung on a line or rack dry quickly, and perspiration readily evaporates from the skin. Wooden furniture can shrink, causing the paint that covers these surfaces to fracture.\nWhen the temperature is low and the relative humidity is high, evaporation of water is slow. When relative humidity approaches 100%, condensation can occur on surfaces, leading to problems with mold, corrosion, decay, and other moisture-related deterioration. Condensation can pose a safety risk as it can promote the growth of mold and wood rot as well as possibly freezing emergency exits shut. \nCertain production and technical processes and treatments in factories, laboratories, hospitals, and other facilities require specific relative humidity levels to be maintained using humidifiers, dehumidifiers and associated control systems. \nVehicles.\nThe basic principles for buildings, above, also apply to vehicles. In addition, there may be safety considerations. For instance, high humidity inside a vehicle can lead to problems of condensation, such as misting of windshields and shorting of electrical components. In vehicles and pressure vessels such as pressurized airliners, submersibles and spacecraft, these considerations may be critical to safety, and complex environmental control systems including equipment to maintain pressure are needed.\nAviation.\nAirliners operate with low internal relative humidity, often under 20%,\nespecially on long flights. The low humidity is a consequence of drawing in the very cold air with a low absolute humidity, which is found at airliner cruising altitudes. Subsequent warming of this air lowers its relative humidity. This causes discomfort such as sore eyes, dry skin, and drying out of mucosa, but humidifiers are not employed to raise it to comfortable mid-range levels because the volume of water required to be carried on board can be a significant weight penalty. As airliners descend from colder altitudes into warmer air, perhaps even flying through clouds a few thousand feet above the ground, the ambient relative humidity can increase dramatically. \nSome of this moist air is usually drawn into the pressurized aircraft cabin and into other non-pressurized areas of the aircraft and condenses on the cold aircraft skin. Liquid water can usually be seen running along the aircraft skin, both on the inside and outside of the cabin. Because of the drastic changes in relative humidity inside the vehicle, components must be qualified to operate in those environments. The recommended environmental qualifications for most commercial aircraft components is listed in RTCA DO-160.\nCold, humid air can promote the formation of ice, which is a danger to aircraft as it affects the wing profile and increases weight. Naturally aspirated internal combustion engines have a further danger of ice forming inside the carburetor. Aviation weather reports (METARs) therefore include an indication of relative humidity, usually in the form of the dew point.\nPilots must take humidity into account when calculating takeoff distances, because high humidity requires longer runways and will decrease climb performance.\nDensity altitude is the altitude relative to the standard atmosphere conditions (International Standard Atmosphere) at which the air density would be equal to the indicated air density at the place of observation, or, in other words, the height when measured in terms of the density of the air rather than the distance from the ground. \"Density Altitude\" is the pressure altitude adjusted for non-standard temperature.\nAn increase in temperature, and, to a much lesser degree, humidity, will cause an increase in density altitude. Thus, in hot and humid conditions, the density altitude at a particular location may be significantly higher than the true altitude.\nElectronics.\nElectronic devices are often rated to operate only under certain humidity conditions (e.g., 10% to 90%). The optimal humidity for electronic devices is 30% to 65%. At the top end of the range, moisture may increase the conductivity of permeable insulators leading to malfunction. Too low humidity may make materials brittle. A particular danger to electronic items, regardless of the stated operating humidity range, is condensation. When an electronic item is moved from a cold place (e.g., garage, car, shed, air conditioned space in the tropics) to a warm humid place (house, outside tropics), condensation may coat circuit boards and other insulators, leading to short circuit inside the equipment. Such short circuits may cause substantial permanent damage if the equipment is powered on before the condensation has evaporated. A similar condensation effect can often be observed when a person wearing glasses comes in from the cold (i.e. the glasses become foggy). \nIt is advisable to allow electronic equipment to acclimatise for several hours, after being brought in from the cold, before powering on. Some electronic devices can detect such a change and indicate, when plugged in and usually with a small droplet symbol, that they cannot be used until the risk from condensation has passed. In situations where time is critical, increasing air flow through the device's internals, such as removing the side panel from a PC case and directing a fan to blow into the case, will significantly reduce the time needed to acclimatise to the new environment.\nIn contrast, a very low humidity level favors the build-up of static electricity, which may result in spontaneous shutdown of computers when discharges occur. Apart from spurious erratic function, electrostatic discharges can cause dielectric breakdown in solid-state devices, resulting in irreversible damage. Data centers often monitor relative humidity levels for these reasons.\nIndustry.\nHigh humidity can often have a negative effect on the capacity of chemical plants and refineries that use furnaces as part of a certain processes (e.g., steam reforming, wet sulfuric acid processes). For example, because humidity reduces ambient oxygen concentrations (dry air is typically 20.9% oxygen, but at 100% relative humidity the air is 20.4% oxygen), flue gas fans must intake air at a higher rate than would otherwise be required to maintain the same firing rate.\nBaking.\nHigh humidity in the oven, represented by an elevated wet-bulb temperature, increases the thermal conductivity of the air around the baked item, leading to a quicker baking process or even burning. Conversely, low humidity slows the baking process down.\nOther important facts.\nAt 100% relative humidity, air is saturated and at its dew point: the water vapor pressure would permit neither evaporation of nearby liquid water nor condensation to grow the nearby water; neither sublimation of nearby ice nor deposition to grow the nearby ice.\nRelative humidity can exceed 100%, in which case the air is supersaturated. Cloud formation requires supersaturated air. Cloud condensation nuclei lower the level of supersaturation required to form fogs and clouds \u2013 in the absence of nuclei around which droplets or ice can form, a higher level of supersaturation is required for these droplets or ice crystals to form spontaneously. In the Wilson cloud chamber, which is used in nuclear physics experiments, a state of supersaturation is created within the chamber, and moving subatomic particles act as condensation nuclei so trails of fog show the paths of those particles.\nFor a given dew point and its corresponding absolute humidity, the relative humidity will change inversely, albeit nonlinearly, with the temperature. This is because the vapor pressure of water increases with temperature\u2014the operative principle behind everything from hair dryers to dehumidifiers.\nDue to the increasing potential for a higher water vapor partial pressure at higher air temperatures, the water content of air at sea level can get as high as 3% by mass at compared to no more than about 0.5% by mass at . This explains the low levels (in the absence of measures to add moisture) of humidity in heated structures during winter, resulting in dry skin, itchy eyes, and persistence of static electric charges. Even with saturation (100% relative humidity) outdoors, heating of infiltrated outside air that comes indoors raises its moisture capacity, which lowers relative humidity and increases evaporation rates from moist surfaces indoors, including human bodies and household plants.\nSimilarly, during summer in humid climates a great deal of liquid water condenses from air cooled in air conditioners. Warmer air is cooled below its dew point, and the excess water vapor condenses. This phenomenon is the same as that which causes water droplets to form on the outside of a cup containing an ice-cold drink.\nA useful rule of thumb is that the maximum absolute humidity doubles for every increase in temperature. Thus, the relative humidity will drop by a factor of 2 for each increase in temperature, assuming conservation of absolute moisture. For example, in the range of normal temperatures, air at and 50% relative humidity will become saturated if cooled to , its dew point, and air at 80% relative humidity warmed to will have a relative humidity of only 29% and feel dry. By comparison, thermal comfort standard ASHRAE 55 requires systems designed to control humidity to maintain a dew point of though no lower humidity limit is established.\nWater vapor is a lighter gas than other gaseous components of air at the same temperature, so humid air will tend to rise by natural convection. This is a mechanism behind thunderstorms and other weather phenomena. Relative humidity is often mentioned in weather forecasts and reports, as it is an indicator of the likelihood of dew, or fog. In hot summer weather, it also increases the apparent temperature to humans (and other animals) by hindering the evaporation of perspiration from the skin as the relative humidity rises. This effect is calculated as the heat index or humidex.\nA device used to measure humidity is called a hygrometer; one used to regulate it is called a humidistat, or sometimes hygrostat. These are analogous to a thermometer and thermostat for temperature, respectively.\nThe field concerned with the study of physical and thermodynamic properties of gas\u2013vapor mixtures is named psychrometrics.\nReferences.\nGeneral sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52813", "revid": "46045043", "url": "https://en.wikipedia.org/wiki?curid=52813", "title": "Dialectic", "text": "Method of reasoning via argumentation and contradictionDialectic (; ), also known as the dialectical method, refers originally to dialogue between people holding different points of view about a subject but wishing to arrive at the truth through reasoned argument. Dialectic resembles debate, but the concept excludes subjective elements such as emotional appeal and rhetoric; the object is more an eventual and commonly-held truth than the 'winning' of an (often binary) competition. It has its origins in ancient philosophy and continued to be developed in the Middle Ages.\nHegelianism refigured \"dialectic\" to no longer refer to a literal dialogue. Instead, the term takes on the specialized meaning of development by way of overcoming internal contradictions. Dialectical materialism, a theory advanced by Karl Marx and Friedrich Engels, adapted the Hegelian dialectic into a materialist theory of history. The legacy of Hegelian and Marxian dialectics has been criticized by philosophers, such as Karl Popper and Mario Bunge, who considered it unscientific.\nDialectic implies a developmental process and so does not fit naturally within classical logic. Nevertheless, some twentieth-century logicians have attempted to formalize it.\nClassical philosophy.\nIn classical philosophy, dialectic ( ) is a form of reasoning based upon dialogue of arguments and counter-arguments, advocating \"propositions\" (theses) and \"counter-propositions\" (antitheses). The outcome of such a dialectic might be the refutation of a relevant proposition, or a synthesis, a combination of the opposing assertions, or a qualitative improvement of the dialogue. Socrates has become famous for his Socratic method of questioning conversation partners on topics until they agreed with him or admitted ignorance.\nPlatonism.\nIn Platonism, dialectic assumed an ontological and metaphysical role in that it became the process whereby the intellect passes from sensibles to intelligibles, rising from idea to idea until it finally grasps the supreme idea, the first principle which is the origin of all. The philosopher is consequently a \"dialectician\". In this sense, dialectic is a process of inquiry that does away with hypotheses up to the first principle. It slowly embraces multiplicity in unity. The philosopher Simon Blackburn wrote that the dialectic in this sense is used to understand \"the total process of enlightenment, whereby the philosopher is educated so as to achieve knowledge of the supreme good, the Form of the Good\".\nAristotle.\nAristotle has been traditionally understood as viewing dialectic as a lesser method of reasoning than \"demonstration\", which derives a necessarily true conclusion from premises assumed to be true via syllogism. Within the \"Organon\", the series comprising Aristotle's works about logic, the \"Topics\" is dedicated to dialectic\u2014which he characterizes as argument from \"endoxa\" (\"generally accredited opinions\") where positions are subject to lines of questioning, to which concessions may be made in response. While Aristotle asserts \"dialectic does not prove anything\", he considers it to be a useful art closely related to rhetoric.\nMedieval philosophy.\nDialectic was a part of Logic, one of the three liberal arts taught in medieval universities as part of the trivium; the other elements were rhetoric and grammar.\nFollowing Boethius (480\u2013524), who drew heavily on Aristotle, many scholastic philosophers made use of dialectics in their works, including Peter Abelard, William of Sherwood, Garlandus Compotista, Walter Burley, Roger Swyneshed, William of Ockham, and Thomas Aquinas.\nThis dialectic (a ) was formed as follows:\nModern philosophy.\nThe concept of dialectics was given new life at the start of the nineteenth century by Georg Wilhelm Friedrich Hegel, whose dialectical model of nature and of history made dialectics a fundamental aspect of reality, instead of regarding the contradictions into which dialectics leads as evidence of the limits of pure reason, as Immanuel Kant had argued. Hegel was influenced by Johann Gottlieb Fichte's conception of synthesis, although Hegel didn't adopt Fichte's thesis\u2013antithesis\u2013synthesis language except to describe Kant's philosophy: rather, Hegel argued that such language was \"a lifeless schema\" imposed on various contents, whereas he saw his own dialectic as flowing out of \"the inner life and self-movement\" of the content itself.\nIn the mid-nineteenth century, Hegelian dialectic was appropriated by Karl Marx and Friedrich Engels and retooled in what they considered to be a nonidealistic manner. It would also become a crucial part of later representations of Marxism as a philosophy of dialectical materialism. These representations often contrasted dramatically and led to vigorous debate among different Marxist groups.\nHegelian dialectic.\nThe Hegelian dialectic describes changes in the forms of thought through their own internal contradictions into concrete forms that overcome previous oppositions.\nThis dialectic is sometimes presented in a threefold manner, as first stated by Heinrich Moritz Chalyb\u00e4us, as comprising three dialectical stages of development: a \"thesis\", giving rise to its reaction; an \"antithesis\", which contradicts or negates the thesis; and the tension between the two being resolved by means of a \"synthesis\". However, Hegel opposed these terms.\nBy contrast, the terms \"abstract\", \"negative\", and \"concrete\" suggest a flaw or an incompleteness in any initial thesis. For Hegel, the concrete must always pass through the phase of the negative, that is, mediation. This is the essence of what is popularly called Hegelian dialectics.\nTo describe the activity of overcoming the negative, Hegel often used the term \"Aufheben\", variously translated into English as 'sublation' or 'overcoming', to conceive of the working of the dialectic. Roughly, the term indicates preserving the true portion of an idea, thing, society, and so forth, while moving beyond its limitations. What is sublated, on the one hand, is overcome, but, on the other hand, is preserved and maintained.\nAs in the Socratic dialectic, Hegel claimed to proceed by making implicit contradictions explicit: each stage of the process is the product of contradictions inherent or implicit in the preceding stage. In his view, the purpose of dialectics is \"to study things in their own being and movement and thus to demonstrate the finitude of the partial categories of understanding\".\nFor Hegel, even history can be reconstructed as a unified dialectic, the major stages of which chart a progression from self-alienation as servitude to self-unification and realization as the rational constitutional state of free and equal citizens.\nMarxist dialectic.\nMarxist dialectic is a form of Hegelian dialectic which applies to the study of historical materialism. Marxist dialectic is thus a method by which one can examine social and economic behaviors. It is the foundation of the philosophy of dialectical materialism, which forms the basis of historical materialism.\nIn the Marxist tradition, \"dialectic\" refers to regular and mutual relationships, interactions, and processes in nature, society, and human thought.257\nA dialectical relationship is a relationship in which two phenomena or ideas mutually impact each other, leading to development and negation. Development refers to the change and motion of phenomena and ideas from less advanced to more advanced or from less complete to more complete. Dialectical negation refers to a stage of development in which a contradiction between two previous subjects gives rise to a new subject. In the Marxist view, dialectical negation is never an endpoint, but instead creates new conditions for further development and negation.257\nKarl Marx and Friedrich Engels, writing several decades after Hegel's death, proposed that Hegel's dialectic is too abstract. Against this, Marx presented his own dialectic method, which he claimed to be \"direct opposite\" of Hegel's method.\nMarxist dialectics is exemplified in \"Das Kapital\". As Marx explained,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nClass struggle is the primary contradiction to be resolved by Marxist dialectics because of its central role in the social and political lives of a society. Nonetheless, Marx and Marxists developed the concept of class struggle to comprehend the dialectical contradictions between mental and manual labor and between town and country. Hence, philosophic contradiction is central to the development of dialectics: the progress from quantity to quality, the acceleration of gradual social change; the negation of the initial development of the status quo; the negation of that negation; and the high-level recurrence of features of the original status quo.\nFriedrich Engels further proposed that nature itself is dialectical, and that this is \"a very simple process, which is taking place everywhere and every day\". His dialectical \"law of the transformation of quantity into quality and vice versa\" corresponds, according to Christian Fuchs, to the concept of phase transition and anticipated the concept of emergence \"a hundred years ahead of his time\". Stalin and Mao interpreted the transformation of quantity into quality not as a separate law, but as a special instance of the unity and struggle of opposites.6\nFor Vladimir Lenin, the primary feature of Marx's \"dialectical materialism\" (Lenin's term) is its application of materialist philosophy to history and social sciences. Lenin's main contribution to the philosophy of dialectical materialism is his theory of reflection, which presents human consciousness as a dynamic reflection of the objective material world that fully shapes its contents and structure.\nLater, Stalin's works on the subject established a rigid and formalistic division of Marxist\u2013Leninist theory into dialectical materialism and historical materialism. While the first was supposed to be the key method and theory of the philosophy of nature, the second was the Soviet version of the philosophy of history.\nSoviet systems theory pioneer Alexander Bogdanov viewed Hegelian and materialist dialectic as progressive, albeit inexact and diffuse, attempts at achieving what he called tektology, or a universal science of organization.\nDialectical naturalism.\nDialectical naturalism is a term coined by American philosopher Murray Bookchin to describe the philosophical underpinnings of the political program of social ecology. Dialectical naturalism explores the complex interrelationship between social problems, and the direct consequences they have on the ecological impact of human society. Bookchin offered dialectical naturalism as a contrast to what he saw as the \"empyrean, basically antinaturalistic dialectical idealism\" of Hegel, and \"the wooden, often scientistic dialectical materialism of orthodox Marxists\".\nTheological dialectics.\nNeo-orthodoxy, in Europe also known as theology of crisis and dialectical theology, is a theological approach in Protestantism that was developed in the aftermath of the First World War (1914\u20131918). It is characterized as a reaction against doctrines of nineteenth-century liberal theology and a more positive reevaluation of the teachings of the Reformation, much of which had been in decline (especially in western Europe) since the late eighteenth century. It is primarily associated with two Swiss professors and pastors, Karl Barth (1886\u20131968) and Emil Brunner (1899\u20131966), even though Barth himself expressed his unease in the use of the term.\nIn dialectical theology, the difference and opposition between God and human beings is stressed in such a way that all human attempts at overcoming this opposition through moral, religious or philosophical idealism must be characterized as sin. In the death of Christ humanity is negated and overcome, but this judgment also points forwards to the resurrection in which humanity is reestablished in Christ. For Barth this meant that only through God's \"no\" to everything human can his \"yes\" be perceived. Applied to traditional themes of Protestant theology, such as double predestination, this means that election and reprobation cannot be viewed as a quantitative limitation of God's action. Rather it must be seen as its \"qualitative definition\".\nDialectic prominently figured in Bernard Lonergan's philosophy, in his books \"Insight\" and \"Method in Theology\". Michael Shute wrote about Lonergan's use of dialectic in \"The Origins of Lonergan's Notion of the Dialectic of History\". For Lonergan, dialectic is both individual and operative in community. Simply described, it is a dynamic process that results in something new:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;For the sake of greater precision, let us say that a dialectic is a concrete unfolding of linked but opposed principles of change. Thus there will be a dialectic if (1) there is an aggregate of events of a determinate character, (2) the events may be traced to either or both of two principles, (3) the principles are opposed yet bound together, and (4) they are modified by the changes that successively result from them.\nDialectic is one of the eight functional specialties Lonergan envisaged for theology to bring this discipline into the modern world. Lonergan believed that the lack of an agreed method among scholars had inhibited substantive agreement from being reached and progress from being made compared to the natural sciences. Karl Rahner, S. J., however, criticized Lonergan's theological method in a short article entitled \"Some Critical Thoughts on 'Functional Specialties in Theology'\" where he stated: \"Lonergan's theological methodology seems to me to be 'so generic that it really fits every science', and hence is not the methodology of theology as such, but only a very general methodology of science.\"\nCriticisms.\nFriedrich Nietzsche viewed dialectic as a method that imposes artificial boundaries and suppresses the richness and diversity of reality. He rejected the notion that truth can be fully grasped through dialectical reasoning and offered a critique of dialectic, challenging its traditional framework and emphasizing the limitations of its approach to understanding reality. He expressed skepticism towards its methodology and implications in \"Twilight of the Idols\": \"I mistrust all systematizers and I avoid them. The will to a system is a lack of integrity\". In the same book, Nietzsche criticized Socrates' dialectics because he believed it prioritized reason over instinct, resulting in the suppression of individual passions and the imposition of an artificial morality.\nIn 1937, Karl Popper wrote and delivered a paper entitled \"What Is Dialectic?\" in which he criticized the dialectics of Hegel, Marx, and Engels for their willingness \"to put up with contradictions\". He argued that accepting contradiction as a valid form of logic would lead to the principle of explosion and thus trivialism. Popper concluded the essay with these words: \"The whole development of dialectic should be a warning against the dangers inherent in philosophical system-building. It should remind us that philosophy should not be made a basis for any sort of scientific system and that philosophers should be much more modest in their claims. One task which they can fulfill quite usefully is the study of the critical methods of science.\" Seventy years later, Nicholas Rescher responded that \"Popper's critique touches only a hyperbolic version of dialectic\", and he quipped: \"Ironically, there is something decidedly dialectical about Popper's critique of dialectics.\" Around the same time as Popper's critique was published, philosopher Sidney Hook discussed the \"sense and nonsense in dialectic\" and rejected two conceptions of dialectic as unscientific but accepted one conception as a \"convenient organizing category\".\nThe philosopher of science and physicist Mario Bunge repeatedly criticized Hegelian and Marxian dialectics, calling them \"fuzzy and remote from science\" and a \"disastrous legacy\". He concluded: \"The so-called laws of dialectics, such as formulated by Engels (1940, 1954) and Lenin (1947, 1981), are false insofar as they are intelligible.\" Poe Yu-ze Wan, reviewing Bunge's criticisms of dialectics, found Bunge's arguments to be important and sensible, but he thought that dialectics could still serve some heuristic purposes for scientists. Wan pointed out that scientists such as the American Marxist biologists Richard Levins and Richard Lewontin (authors of \"The Dialectical Biologist\") and the German-American evolutionary biologist Ernst Mayr, not a Marxist himself, have found agreement between dialectical principles and their own scientific outlooks, although Wan opined that Engels' \"laws\" of dialectics \"in fact 'explain' nothing\".\nEven some Marxists are critical of the term \"dialectics\". For instance, Michael Heinrich wrote, \"More often than not, the grandiose rhetoric about dialectics is reducible to the simple fact that everything is dependent upon everything else and is in a state of interaction and that it's all rather complicated\u2014which is true in most cases, but doesn't really say anything.\"\nFormalization.\nMathematics.\nMathematician William Lawvere interpreted dialectics in the setting of categorical logic in terms of adjunctions between idempotent monads. This perspective may be useful in the context of theoretical computer science where the duality between syntax and semantics can be interpreted as a dialectic in this sense. For example, the Curry\u2013Howard correspondence is such an adjunction or more generally the duality between closed monoidal categories and their internal logic.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52814", "revid": "37005538", "url": "https://en.wikipedia.org/wiki?curid=52814", "title": "Sierra Entertainment", "text": "American video game company\nSierra Entertainment, Inc. (formerly On-Line Systems and Sierra On-Line, Inc.) was an American video game developer and publisher founded in 1979 by Ken and Roberta Williams. The company is known for pioneering the graphic adventure game genre, including the first such game, \"Mystery House\". It is known for its graphical adventure game series \"King's Quest\", \"Space Quest\", \"Police Quest\", \"Gabriel Knight\", \"Leisure Suit Larry\", and \"Quest for Glory\", and as the original publisher of Valve's \"Half-Life\" series.\nAfter seventeen years as an independent company, Sierra was acquired by CUC International in February 1996 to become part of CUC Software. However, CUC International was caught in an accounting scandal in 1998, and many of the original founders of Sierra including the Williamses left the company. Sierra remained as part of CUC Software as it was sold and renamed several times over the next few years. Sierra was formally disestablished as a company and reformed as a division of this group in August 2004. The former CUC Software group was acquired by Vivendi and branded as Vivendi Games in 2006. The Sierra division continued to operate through Vivendi Games's merger with Activision to form Activision Blizzard on July 10, 2008, but was shut down later that year. The Sierra brand was revived by Activision in 2014 to re-release former Sierra games and some independently developed games.\nFollowing the acquisition of Activision Blizzard by Microsoft, the Sierra brand is under Microsoft's ownership through its gaming division.\nHistory.\nFounding as On-Line Systems (1979\u20131982).\nSierra Entertainment was founded in 1979 as On-Line Systems in Simi Valley, California, by the husband-and-wife duo Ken and Roberta Williams. Ken, a programmer for IBM, had planned to use the company to create business software for the TRS-80 and Apple II. Ken had brought a teletype terminal home one day in 1979 and, while looking through the host system's software catalog, discovered the text adventure \"Colossal Cave Adventure\". He encouraged Roberta to join him in playing it, and she was enthralled by the game. After Ken had brought an Apple II to their home, she played through other text adventures such as those by Scott Adams and Softape to study them. Dissatisfied with the text-only format, she realized that the graphics display capability of the Apple II could enhance the adventure gaming experience. With Ken's help in some of the programming, Roberta designed \"Mystery House\", inspired by the novel \"And Then There Were None\" and the board game \"Clue\", using text commands and printout combined with rudimentary graphics depicting the current setting.\n\"Mystery House\" was released through mail-order in May 1980. It was an instant hit with about 15,000 copies sold, earning US$. It is the first computer adventure game to have graphics, although made with crude, static, monochrome, line drawings. The two shifted the focus to developing more graphical adventure games. \"Mystery House\" became the first in the \"Hi-Res Adventure\" series. The \"Hi-Res Adventure\" series continued with \"Mission Asteroid\", which was released as \"Hi-Res Adventure #0\" though being the second release. The next release, \"Wizard and the Princess\", also known as \"Adventure in Serenia\", is considered a prelude to the later \"King's Quest\" series in both story and concept. Through 1981 and 1982, more games were released in the series including \"Cranston Manor\", \"Ulysses and the Golden Fleece\", \"Time Zone\", and \"The Dark Crystal\". A simplified version of \"The Dark Crystal\", intended for a younger audience, was written by Al Lowe and released as \"Gelfling Adventure\".\nRebranding to Sierra On-Line (1982\u20131988).\nOn-Line Systems was renamed Sierra On-Line in 1982, and moved to Oakhurst, California. The \"Sierra\" name was taken from the Sierra Nevada mountain range that Oakhurst was near, and its new logo incorporated the imagery of Half Dome mountain. By early 1984, \"InfoWorld\" estimated that Sierra was the world's 12th-largest microcomputer software company, with $ in 1983 sales. It produced some non-game software, such as an Applesoft BASIC compiler.\nThe company weathered the video game crash of 1983 with only a 20% increase in sales, after analysts in 1982 had predicted a doubling in 1983 of the entire software market. The company had spent much of 1983 developing for the VIC-20 and the TI-99/4A which were both obsolete by the end of the year. Ken Williams was reportedly described as \"bewildered by the pace at which computers come into and fall out of favor\", and Williams said, \"I've learned my lesson. I'm not moving until I understand the market better.\"\nMany of Sierra's best known series began in the 1980s. In 1983, Sierra On-Line was contacted by IBM to create a game for the new PCjr. IBM offered to fund the entire development and marketing of the game, paying royalties. Ken and Roberta Williams accepted and started on the project. Roberta Williams created a story featuring classic fairy-tale elements. Her game concept includes animated color graphics, a pseudo 3D-perspective where the main character is visible on the screen, a more competent text parser that understands advanced commands from the player, and music playing in the background through the PCjr sound hardware. For the game, a complete development system called Adventure Game Interpreter (AGI) was developed. In mid-1984, \"\" was released to much acclaim, beginning the \"King's Quest\" series.\nWhile finishing \"The Black Cauldron\", programmers Mark Crowe and Scott Murphy began to plan for an adventure game of their own. After a simple demonstration to Ken Williams, he allowed them to start working on the full game, which was named \"\". The game was released in October 1986 as an instant success, spawning many sequels in the \"Space Quest\" series in the following years.\nAl Lowe, who had been working at Sierra On-Line for many years, was asked by Ken Williams to write a modern version of Chuck Benton's \"Softporn Adventure\" from 1981, the only pure text adventure that the company had ever released. \"Leisure Suit Larry in the Land of the Lounge Lizards\" was a great hit and won the Software Publishers Association's Best Adventure Game award of 1987. It can be deduced that the game first became famous as an early example of software piracy, as Sierra sold many more hintbooks than actual copies of the game. A series of \"Leisure Suit Larry\" games followed.\nKen Williams befriended a retired highway patrol officer named Jim Walls and asked him to produce an adventure series based on a police theme. Walls proceeded to create \"\", which was released in 1987. Several sequels followed, and the series was touted for adherence to police protocol (relevant parts of which were explained in the games' manuals), and presenting some real-life situations encountered by Walls during his career as an officer.\n\"Quest for Glory\" is a series of hybrid adventure/role-playing video games designed by Corey and Lori Ann Cole. The first game in the series, \"\", was released in 1989. The series combines humor, puzzle elements, themes and characters borrowed from various legends, puns, and memorable characters, creating a five-part series of the Sierra stable. Although the series was originally titled \"Hero's Quest\", Sierra failed to trademark the name. Milton Bradley successfully trademarked an electronic version of their unrelated joint Games Workshop board game, \"HeroQuest,\" which forced Sierra to change the series' title to \"Quest for Glory\". This decision caused all future games in the series, including newer releases of \"Hero's Quest I\", to switch to the new name.\nIn 1987, Sierra On-Line started to publish its own gaming magazine, about its upcoming games and interviews with the developers. The magazine was initially named \"The Sierra Newsletter\", \"The Sierra News Magazine\", and \"The Sierra/Dynamix Newsmagazine\". However, since Sierra Club already published a magazine called \"Sierra Magazine\", the name of the magazine published by Sierra On-Line was changed to \"InterAction\" in 1991. It was discontinued in 1999.\nSierra's Adventure Game Interpreter engine, introduced with \"King's Quest\", was replaced in 1988 with Sierra's Creative Interpreter in \"King's Quest IV\". The game was released under both engines, so those who had newer computers could use the new engine and better rendering technology.\nGoing public (1989\u20131995).\nSierra became a public company in 1989, trading on the NASDAQ under the stock ticker \"SIER\". Additional public investment allowed the company to engage in further acquisitions over the next several years.\nIn 1990, Sierra released \"King's Quest V\", the first Sierra On-Line game ever to have more than 500,000 copies sold and the highest selling game for five years. It won several awards, such as the Best Adventure Game of the Year from both the Software Publishers Association and \"Computer Gaming World\" magazine.\nThe Sierra Network was launched on May 6, 1991, as the first game-only online environment. Development of the network began in 1989, as Ken Williams was inspired by the launch of the Prodigy service in 1988 to create something similar for Sierra's games. As a free service other than access use charges, the network provided a \"land-based\" precursor to MMORPGs and internet chat rooms, each land theme for the type of content provided multi-player gaming and category based bulletin boards and chat rooms throughout the continental United States. By July 1993, having reached about 40,000 subscribers, AT&amp;T announced a plan to invest $ into the network and add more games, gaining partial control as part of its expansion into the growing online services. AT&amp;T later took sole possession of the network on November 15, 1994, so the name was changed to the ImagiNation Network. The network failed to find a mass audience, and was sold to America On-Line in 1996.\nIn 1991, Sierra released the first game in the \"Dr. Brain\" series, \"Castle of Dr. Brain\", a hybrid puzzle adventure education game, which has several sequels. In 1993, \"\" was released, beginning the \"Gabriel Knight\" series. The game and subsequent sequels were critically acclaimed in the mainstream press at the time.\nSierra and Broderbund started merger discussions in March 1991, but the idea was discontinued later that month.\nSierra needed a new building due to growth, and moved its headquarters and much of its key staff to Bellevue, Washington. Sierra's original location in Oakhurst was later renamed Yosemite Entertainment, and continued under that name until closing in early 1999.\nThe company was now made up of five separate and largely autonomous development divisions: Sierra Publishing, Sierra Northwest, Dynamix, Bright Star Technology, and Coktel Vision, with each group working separately on product development but sharing manufacturing, distribution, and sales resources.\n1995 was a successful year for the company. Sierra was the market-share leader in PC games for the year. With $83.4 million in sales from software-publishing, earnings improved by 19 percent, and a net income of $11.9 million. In June, Sierra and Pioneer Electric Corp. signed an agreement to create a joint venture that would develop, publish, manufacture, and market entertainment software for the Japanese software market. This joint venture created a new company called Sierra Venture. With Sierra and Pioneer investing over $12 million, the new company immediately manufactured and shipped over twenty of Sierra's most popular products to Japan and created new titles for the Japanese market. 1995 also saw Sierra acquiring a number of development companies, both small home developers and larger companies.\n\"Phantasmagoria\" was by far the largest project ever undertaken by Sierra. The anticipation for the game was high at release in late 1995. Although nearly one million copies were sold when the game was first released in August 1995, Sierra's bestselling adventure game created, the game received mixed reviews from industry critics.\nSale to CUC International (1996\u20131998).\nIn February 1996, early e-commerce pioneer CUC International, seeking to expand into interactive entertainment, offered to buy Sierra at a price of about $. Walter Forbes, the CEO of CUC International, and a member of Sierra's own Board of Directors since 1991, surprised Ken Williams with the deal after a board meeting. At this time, Sierra had modest revenues of about $ in the current fiscal year, so the sum surprised Ken. Forbes had posited the idea to Ken that this would be the start of a large company eventually to bring in LucasArts Entertainment, Broderbund, and Davidson &amp; Associates (which at the time owned Blizzard Entertainment) under one entity and be a major publisher in the video game industry, as a great boon to the Williams and to Sierra's shareholders. Roberta had expressed her concerns about the offer to Ken and to executive officers, but he remained interested in the potential that Forbes offered. Ken accepted the offer, believing it was in the best interest for Sierra's future and stockholders, and CUC announced by the end of February 1996 the beginning of closing the acquisition of both Sierra and Davidson for $ and $ in CUC stock, respectively. The deal to obtain LucasArts and Broderbund failed.\nSierra's acquisition closed on July 24, 1996. The terms included naming Ken Williams a vice-chairman of CUC International, a Member of the Office of the President of CUC, and that he would remain responsible for Sierra's R&amp;D and remain Sierra's CEO. He also requested creation of a \"software board\" consisting of him, Michael Brochu (Sierra's President and COO), Bob Davidson (founder and CEO of Davidson &amp; Associates), and Forbes. It functioned as a governing body of what would become CUC Software, regulating major decisions and product lines.\nIn September 1996, CUC announced consolidation of some functions of its game companies into a single company called CUC Software Inc., headquartered in Torrance, California. Bob Davidson, founder and CEO of Davidson &amp; Associates became the CEO for the publishing body. CUC Software consolidated manufacturing, distribution, and sales resources of all of divisions including what was to become Sierra, Davidson, Blizzard, Knowledge Adventure, and Gryphon Software.\nCUC Software utilized its various labels' market specialties. For example, in October 1996, Sierra published \"Stay Tooned!\", an adventure game developed by Funnybone Interactive (a subsidiary of Davidson &amp; Associates) as Sierra was more known as an adventure game publisher than Davidson.\nIn November 1996, Ken Williams met with the founders of Valve and negotiated Sierra's exclusive rights to publish \"Half-Life\", which Ken Williams debuted at E3 in May 1997. In December 1996, Sierra released \"The Realm Online\", an online fantasy role-playing game.\nAfter the sale, Ken Williams remained within the software division so that he could provide strategic guidance to Sierra, although he began to grow disillusioned as he soon found that his new titles at CUC meant very little and the software board met only once. He began disputes with Davidson over Davidson's conservative management style and his disdain for Sierra's more risque product lines such as \"Phantasmagoria\" and \"Leisure Suit Larry\".\nIn January 1997, Davidson stepped down as CEO of CUC Software, and CUC Executive Chris MacLeod was named as his replacement. After this, Ken Williams shifted his focus work on CUC's online product distributor, NetMarket while remaining as CEO of Sierra in name only. In November, Ken Williams departed from CUC International, while Roberta Williams remained with Sierra until the release of \"\" in December 1998. Brochu, who had been hired in 1995 by Ken Williams, to handle the daily business affairs of Sierra, replaced Ken Williams and remained as President of Sierra until October 1997, when he too departed the company.\nIn April 1997, to further expand upon their role in the edutainment business, Sierra purchased Books That Work and CUC International purchased Berkeley Systems and transferred management of the studio to Sierra as an internal developer. In December 1997, in order to secure the rights to \"Return to Krondor\", Sierra purchased PyroTechnix, who were developing the game.\nOn November 5, 1997, after the departure of Brochu in October, Sierra was split into three business units, all of which reported directly to MacLeod.\nIn 1998, Sierra divided into 5 sub-brands and corporate divisions:\nOn November 24, 1997, Sierra published \"\", the official expansion pack for the widely popular game \"Diablo\" developed by Synergistic Software, a division of Sierra.\nOn November 19, 1998, Sierra published \"Half-Life\" for the PC, developed by Valve, which became a huge success.\nDuring these events, CUC merged with Henry Silverman's HFS Incorporated in December 1997 and became the Cendant Corporation. The merger did not immediately affect operations of Sierra. However, Silverman, who served as CEO of Cendant, had become more involved with the bookkeeping of the merged companies and noticed irregularities from CUC's past bookkeeping, leading to the discovery of massive accounting fraud at CUC in March 1998. Forbes was later convicted on three charges related to fraud by the Security and Exchange Commission in 2007. With the news, Cendant announced intention to sell the computer entertainment division, and on November 20, 1998, announced the sale of the consumer software division to Paris-based Havas S.A. Sierra became a part of Havas Interactive, the interactive entertainment division of the company.\nFallout from CUC's acquisition (1999\u20132003).\nOn Monday, February 22, 1999, Sierra announced a major reorganization of the company, resulting in the shutdown of several of their development studios, cutbacks on others and the relocation of key projects, and employees from those studios, to Bellevue. This event came to be known by fans and employees of Sierra as \"Chainsaw Monday\"\u2014a nickname coined by Scott Murphy, who had been laid off over a month prior. About 250 people in total lost their jobs. Development groups within Sierra such as PyroTechnix were shut down. Others such as Books That Work were relocated to Bellevue. Also shut down was Yosemite Entertainment, the division occupying the original headquarters of Sierra On-Line. The company sold the rights of Headgate Studios back to the original owner. With the exception of the warehouse and distribution department, the entire studio was shut down. Game designers Al Lowe and Scott Murphy were laid off. Lowe had just started work on \"Leisure Suit Larry 8\". Murphy was involved in a \"Space Quest 7\" project at the time. Layoffs continued on March 1, when Sierra terminated 30 employees at the previously unaffected Dynamix, or 15 percent of their workforce.\nDespite the layoffs, Sierra continued to publish games for smaller development houses. In September 1999, they released \"Homeworld\", a real-time space-combat strategy game developed by Relic Entertainment. The game design was revolutionary for the genre, and the game received great critical acclaim and many awards.\nUK-based game developer and publisher Codemasters, in an effort to establish themselves in the United States, announced the launch of a new development studio in Oakhurst, using the abandoned Sierra facilities and hiring much of the Yosemite Entertainment's laid-off staff in mid-September 1999. In early October, the company announced plans to take over management and maintenance of the online RPG \"The Realm\" and acquiring the complete yet previously canceled \"Navy SEALs\". The company also reported they obtained the rights to continue using the name Yosemite Entertainment for the development house.\nMeanwhile, Sierra announced another reorganization, this time into three business units: Core Games, Casual Entertainment, and Home Productivity. This reorganization resulted in even more layoffs, eliminating 105 additional jobs and a number of games in production. After 1999, Sierra almost entirely ceased to be a developer of games and, as time went on, instead became a publisher of games by independent developers.\nAt the end of June 2000, a strategic business alliance between Vivendi, Seagram, and Canal+ was announced, and Vivendi Universal, a leading global media and communications company, was formed after the merger with Seagram (the parent company of Universal Studios). Havas S.A. was renamed Vivendi Universal Publishing and became the publishing division of the new group, divided into five groups: games, education, literature, health, and information. The merger was followed by many more layoffs of Sierra employees.\nIn August 2001, Sierra announced a major reorganization, which included the closure of Dynamix as well as the layoffs of 148 employees located at the company headquarters in Bellevue.\nOn February 19, 2002, Sierra On-Line officially announced the name change to Sierra Entertainment, Inc.\nIn 2002, Sierra, working with High Voltage Software, announced the development of a new chapter in the Leisure Suit Larry franchise, titled \"\". Released to mostly mixed to negative reviews; Larry's creator, Lowe, was not involved with the project.\nThe newly renamed Sierra Entertainment continued to develop mostly unsuccessful interactive entertainment products. However, hit \"Homeworld 2\" once again cemented Sierra's reputation as a respectable publisher.\nIn 2003, Sierra Entertainment released the second video game adaptation of \"The Hobbit\", as well as \"NASCAR Racing 2003 Season\".\nAcquisition and absorption under Vivendi Games (2004\u20132008).\nIn early 2004, cost-cutting measures were taken at Sierra's parent company Vivendi Universal Games due to financial troubles and because of Sierra's lack of profitability as a working developer. Sierra's last owned studios Impressions Games and the Papyrus Design Group were both shut down in early 2004, laying off 50 people; 180 Sierra-related positions were eliminated at Vivendi's Los Angeles offices; and by June 2004, Vivendi had completely shut down Sierra's Bellevue location, laid off more than 100 employees, dispersed Sierra's work to other VU Games divisions, and re-located the remains of Sierra's assets to Vivendi's corporate headquarters in Fresno, California. In total, 350 people were laid off. Some assets were retired in the process, including Print Artist, and some like the \"Hoyle\" franchise were sold to other publishers or developers. Sierra was simply a publishing label and brand name for Vivendi assets, being used in tandem with its own name for publishing. As a company, Sierra was disestablished on August 24, 2004. The business continued to operate as a division of Vivendi Games.\nIn late 2005, the Sierra brand was re-launched from Los Angeles. A new subsidiary called Sierra Online (no-relation to Sierra's former name Sierra On-Line) was also founded within this time, which focused on downloadable and online-only games.\nThroughout 2005 and 2006, Vivendi acquired several game development studios including Massive Entertainment, High Moon Studios, Radical Entertainment, Secret Lair Studios / Studio Ch'in (based in Seattle and Shanghai) and Swordfish Studios and integrated them into Sierra, alongside the creative licenses from other Vivendi divisions and from companies partnered with Vivendi and the copyrights of several notable intellectual properties, such as \"Crash Bandicoot\", \"Spyro the Dragon\", ' and '. Vivendi also ceased publishing under their own name by this point after their name change, with all major releases being under the Sierra brand name.\n\"Caesar IV\" was published September 26, 2006, in North America, in partnership with Tilted Mill Entertainment.\nIn mid 2007, Sierra Online began launching Xbox Live Arcade games for the Xbox 360. One of the first releases is the conversion of the successful \"German-style\" board game \"Carcassonne\", which had been in development at Secret Lair Studios.\nIn late 2007, Sierra released games like the first-person shooter game \"TimeShift\" (which was originally going to be published by Atari but was delayed various times during development) and the real-time tactical video game \"World in Conflict\".\nClosure and sale of properties (2008\u20132009).\nIn 2008, Sierra Entertainment's parent company Vivendi Games merged with video game publisher Activision to form Activision Blizzard. Vivendi Games was absorbed into Activision after the merger and the ownership of Sierra properties went to Activision. Later that year, Sierra was closed down for possible future sale. Leading up to the merger, Activision's management was confident that Sierra would cease operations post-merger.\nOn July 29, 2008, Activision announced a long-term strategy for its library of Sierra games and announced that they would only publish five titles: ', ', \"Prototype\", and \"\", and an unannounced new property. The rest of the properties, including the Sierra Online division, were deemed by the company to be \"non-strategic\" with its then-current business practices. A selection of earlier sales and reversions followed:\nBrand name revival under Activision (2014\u20132016).\nOn August 7, 2014, the website for Sierra, which previously redirected to Activision's website, was updated to showcase a new logo, teasing: \"More to be revealed at Gamescom 2014.\" Activision confirmed that the Sierra label would re-release some of its older games, re-imagine its older franchises, and collaborate with indie studios to create new \"innovative, edgy and graphically unique\" projects. Sierra plans to focus on publishing downloadable games through PlayStation Network, Steam, and Xbox Live. Ken Williams said, \"We're very proud of what we created all those years ago with Sierra On-Line, and today's news about carrying Sierra forward as an indie-specific brand is very encouraging. We look forward to seeing Sierra's independent spirit live on.\" That day, \"King's Quest\" and \"\" were announced as the first two games published under the revived Sierra brand. On December 5, 2014, the company was awarded with the \"Industry Icon\" award during the 2014 The Game Awards, and it introduced the first footage of the reboot of \"King's Quest\".\nIn August 2018, TJX Companies acquired the sierra.com domain from Activision, and the former subsequently shortened the name of its Sierra Trading Post subsidiary to Sierra.\nGames.\nSierra both developed its own games and published several games from its divisions and from third-party developers. As a developer, Sierra launched the video game series \"King's Quest\", \"Space Quest\", \"Police Quest\", \"Gabriel Knight\", \"Leisure Suit Larry\", and \"Quest for Glory\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52816", "revid": "14264656", "url": "https://en.wikipedia.org/wiki?curid=52816", "title": "Half-Life (video game)", "text": "1998 video game\nHalf-Life is a 1998 first-person shooter game developed by Valve Corporation and published by Sierra Studios for Windows. It was Valve's debut product and the first game in the \"Half-Life\" series. The player assumes the role of Gordon Freeman, a scientist who must escape from the Black Mesa Research Facility after it is overrun by aliens following a disastrous scientific experiment. The gameplay consists of combat, exploration and puzzles.\nValve was disappointed with the lack of innovation in the FPS genre and aimed to create an immersive world rather than a \"shooting gallery\". They developed using GoldSrc, a heavily modified version of the \"Quake\" engine, licensed from id Software. The science fiction novelist Marc Laidlaw was hired to craft the plot and assist with design. Unlike other games at the time, the player has almost uninterrupted control of the player character; the story is mostly conveyed through scripted sequences rather than cutscenes. \n\"Half-Life\" received acclaim for its graphics, gameplay and narrative and won more than 50 PC \"Game of the Year\" awards. It is considered one of the most influential FPS games and one of the greatest video games. By 2008, it had sold more than nine million copies. It was ported to the PlayStation 2 in 2001, along with the multiplayer expansion \"\", and to OS X and Linux in 2013. Valve ported \"Half-Life\" to its game engine, Source, as Half-Life: Source in 2004. In 2020, \"Black Mesa\" was released, an unofficial fan-made remake of \"Half-Life\" developed by Crowbar Collective using the Source engine.\n\"Half-Life\" inspired numerous fan-made mods, some of which became standalone games, such as \"Counter-Strike\" (2000), \"Day of Defeat\" (2003), and \"Sven Co-op\" (1999). It was followed by the expansion packs ' (1999) and ' (2001), developed by Gearbox Software, and the sequels \"Half-Life 2\" (2004), ' (2006), ' (2007) and \"\" (2020).\nGameplay.\n\"Half-Life\" is a first-person shooter (FPS) that requires the player to perform combat tasks and solve puzzles to advance. Unlike most FPS games at the time, which relied on cut-scene intermissions to detail their plotlines, \"Half-Life\"'s story is told mostly using scripted sequences (bar one short cutscene), keeping the player in control of the first-person viewpoint. In line with this, the player rarely loses the ability to control the player character, Gordon Freeman, who never speaks and is never actually seen in the game; the player sees \"through his eyes\" for the entire length of the game. \"Half-Life\" has no levels; it instead divides the game into chapters, whose titles briefly appear on screen as the player progresses through the game. With the exception of short loading pauses, progression throughout the game is continuous, with each map directly connecting to the next, although levels with teleportation are an exception.\nThe game regularly integrates puzzles, such as navigating a maze of conveyor belts or using nearby boxes to build a small staircase to the next area the player must travel to. Some puzzles involve using the environment to kill an enemy, like turning a valve to spray hot steam at their enemies. There are few bosses in the conventional sense, where the player defeats a superior opponent by direct confrontation. Instead, such organisms occasionally define chapters, and the player is generally expected to use the terrain, rather than firepower, to kill the boss. Late in the game, the player receives a \"long jump module\" for the HEV suit, which allows the player to increase the horizontal distance and speed of jumps by crouching before jumping. The player must rely on this ability to navigate various platformer-style jumping puzzles in Xen toward the end of the game.\nThe player is occasionally assisted by security guards and scientists. The guards fight alongside the player, and both guards and scientists can assist in reaching new areas and pass on plot information. Alien enemies include headcrabs, bullsquids, vortigaunts, and headcrab zombies. The player also faces hostile human soldiers and Black Ops assassins. \"Half-Life\" includes online multiplayer support for both individual and team-based deathmatch modes. It was one of the first mainstream games to use the WASD keys as the default control scheme.\nPlot.\nAt the underground Black Mesa Research Facility, the theoretical physicist Gordon Freeman participates in an experiment on a crystal of unknown origin. This triggers a \"resonance cascade\", which greatly damages the facility and teleports in hostile alien creatures through a portal between the Xen and Earth dimensions. Venturing to the surface, Freeman discovers U.S. federal government soldiers have been dispatched to cover up the incident by killing humans and aliens alike. A scientist instructs him to make his way to the Lambda Complex to stop the alien invasion.\nFreeman kills a giant creature inside a rocket engine test facility and uses an underground monorail to reach a rocket silo. He launches a satellite to help the Lambda team close the portal, but is captured by soldiers and left for dead in a trash compactor. Escaping through a waste treatment complex, Freeman travels through a part of Black Mesa filled with alien specimens, collected long before the resonance cascade.\nOverpowered by the aliens, the soldiers withdraw. Freeman fights across the rest of the facility to reach the Lambda Complex, where he discovers secret teleportation technology. There, scientists inform him that the satellite launched earlier didn't work to stop the cascade due to a powerful alien creature preventing them from closing the portal. They teleport him to the alien dimension Xen to kill it.\nFreeman encounters dead scientists who teleported there before him. He kills a large alien, the Gonarch, and finds a factory that manufactures alien soldiers. Finally, he enters the Nihilanth's lair and kills it. Freeman is detained by the G-Man, a mysterious interdimensional agent who claims his \"employers\" wish to hire Freeman. If he accepts, Freeman is placed into stasis; if not, he is teleported to his death.\nDevelopment.\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n \"Half-Life\" in many ways was a reactionary response to the trivialization of the experience of the first-person genre. Many of us had fallen in love with video games because of the phenomenological possibilities of the field and felt like the industry was reducing the experiences to least common denominators rather than exploring those possibilities. Our hope was that building worlds and characters would be more compelling than building shooting galleries.\n \u2014Valve president Gabe Newell\nValve, based in Kirkland, Washington, U.S., was founded in 1996 by the former Microsoft employees Gabe Newell and Mike Harrington. For their first product, Valve settled on a concept for a horror first-person shooter (FPS) game. They did not want to build their own game engine, as this would have created too much work for a small team and Newell planned to innovate in different areas. Instead, Valve licensed the \"Quake\" engine and the \"Quake II\" engine from id Software and combined them with their own code. Newell estimated that around 75% of the final engine code was by Valve. As the project expanded, Valve cancelled development of a fantasy role-playing game, \"Prospero\", and the \"Prospero\" team joined the \"Half-Life\" project.\n\"Half-Life\" was inspired by the FPS games \"Doom\" (1993) and \"Quake\" (1996), Stephen King's 1980 novella \"The Mist\", and a 1963 episode of \"The Outer Limits\" titled \"The Borderland\". According to the designer Harry Teasley, \"Doom\" was a major influence and the team wanted \"Half-Life\" to \"scare you like \"Doom\" did\". The project had the working title \"Quiver\", after the Arrowhead military base from \"The Mist\". The name \"Half-Life\" was chosen because it was evocative of the theme, not clich\u00e9d, and had a corresponding visual symbol: the Greek letter \u03bb (lower-case lambda), which represents the \"decay constant\" in the half-life equation.31 According to the designer Brett Johnson, the level design was inspired by environments in the manga series \"Akira\".\nValve struggled to find a publisher, as many believed the game was too ambitious for a first-time developer. Sierra On-Line signed Valve for a one-game deal as it was interested in making a 3D action game, especially one based on the \"Quake\" engine. Sierra gave Valve an advance of around $1 million in exchange for 30% of the revenue and 100% of the intellectual property; the rest of development was funded by Newell and Harrington. Valve first showed \"Half-Life\" in early 1997; it was a success at E3 that year, where Valve demonstrated the animation and artificial intelligence. Novel features of the artificial intelligence included fear and pack behavior.\nValve aimed for a November 1997 release to compete with \"Quake II\". By September 1997, the team found that, while they had built some innovative aspects in weapons, enemies, and level design, the game was not fun and there was little design cohesion. Playtesting produced \"lukewarm\" responses. Sierra would not agree to extra funding, so Newell took out a loan to fund additional development to rework the game.\nValve took a novel approach of assigning a small team to build a prototype level containing every element in the game and then spent a month iterating on the level. When the rest of the team played the level, which the designer Ken Birdwell described as \"\"Die Hard\" meets \"Evil Dead\"\", they agreed to use it as a baseline. The team developed three theories about what made the level fun. First, it had several interesting things happen in it, all triggered by the player rather than a timer so that the player would set the pace of the level. Second, the level responded to any player action, even for something as simple as adding graphic decals to wall textures to show a bullet impact. Finally, the level warned the player of imminent danger to allow them to avoid it, rather than killing the player with no warning.\nTo move forward with this unified design, Valve sought a game designer but found no one suitable. Instead, Valve created the \"cabal\", initially a group of six individuals from across all departments that worked primarily for six months straight in six-hour meetings four days a week. The cabal was responsible for all elements of design, including level layouts, key events, enemy designs, narrative, and the introduction of gameplay elements relative to the story. The collaboration proved successful, and once the cabal had come to decisions on types of gameplay elements that would be needed, mini-cabals from other departments most affected by the choice were formed to implement these elements. Membership in the main cabal rotated since the required commitment created burnout.\nThe cabal produced a 200-page design document detailing nearly every aspect of the game. They also produced a 30-page document for the narrative, and hired the science fiction novelist Marc Laidlaw to help manage the script. Laidlaw said his contribution was to add \"old storytelling tricks\" to the team's ambitious designs: \"I was in awe of [the team]. It felt to me like I was just borrowing from old standards while they were the ones doing something truly new.\" Rather than dictate narrative elements \"from some kind of ivory tower of authorial inspiration\", he worked with the team to improvise ideas, and was inspired by their experiments. For example, he conceived the opening train ride after an engineer implemented train code for another concept.\nValve initially planned to use traditional cutscenes, but switched to a continuous first-person perspective for lack of time. Laidlaw said they discovered unexpected advantages in this approach, as it created a sense of immersion and enforced a sense of loneliness in a frightening environment. Laidlaw felt that non-player characters were unnecessary to guide players if the design had sufficiently strong \"visual grammar\", and that this allowed the characters to \"feel like characters instead of signposts\". An early version of \"Half-Life\" began immediately after the disaster, with the environments already wrecked. Laidlaw worked with Johnson to create versions of the lab environment before the disaster to help set the story. He said: \"These were all economical ways of doing storytelling with the architecture\u2014which was my whole obsession. The narrative had to be baked into the corridors.\"\nWithin a month of the cabal's formation, the other team members started detailed game development, and within another month began playtesting through Sierra. The cabal was intimately involved with playtesting, monitoring the player but otherwise not interacting. They noted any confusion or inability to solve a game's puzzles and made them into action items to be fixed on the next iteration. Later, with most of the main adjustments made, the team included means to benchmark players' actions. They then collected and interpreted statistically to fine-tune levels further. Between the cabal and playtesting, Valve identified and removed parts that proved unenjoyable. Birdwell said that while there were struggles at first, the cabal approach was critical for \"Half-Life\"'s success, and was reused for \"Team Fortress 2\" from the start.\nMuch of the detail of \"Half-Life\"'s development has been lost. According to Valve employee Erik Johnson, two or three months before release, their Visual SourceSafe source control system \"exploded\". Logs of technical changes from before the final month of development were lost, and code had to be recovered from individual computers. The revised version of \"Half-Life\" shown at E3 1998 received the Game Critics Awards for \"Best PC Game\" and \"Best Action Game\".\nRelease.\nTo promote \"Half-Life\", Valve's chief marketing officer, Monica Harrington, promoted Valve's reputation in the industry, with conference talks about their advances in game development, leading to coverage in the \"Wall Street Journal\". \"Half-Life\" was released on November 19, 1998. When Sierra told Valve it was not planning to promote it beyond launch, Harrington threatened that Valve would \"walk away from our agreement and tell the industry that had fallen in love with Valve how screwed up Sierra really was\". In response, Sierra reissued \"Half-Life\" in a \"Game of the Year\" edition, boosting sales. In 2001, after renegotiating with Sierra, Valve gained the \"Half-Life\" intellectual property and online distribution rights for its games.\nValve released two \"Half-Life\" demos. The first, \"Half-Life: Day One\", contained the first fifth of the game and was distributed with certain graphic cards. The second, \"Half-Life: Uplink\", was released on February 12, 1999, and featured original content. A short film based on \"Half-Life,\" also titled \"Half-Life: Uplink\", was developed by Cruise Control, a British marketing agency, and released on February 11. The protagonist is a journalist who infiltrates the Black Mesa Research Facility, trying to discover what has happened there.\n\"Half-Life\" was censored in Germany to comply with the Federal Department for Media Harmful to Young Persons, which regulates depictions of violence against humans. Valve replaced the human characters with robots, spilling oil and gears instead of blood and body parts when killed, among other changes. In 2017, \"Half-Life\" was removed from the German censorship list. To acknowledge this, Valve released \"Half-Life Uncensored\", a free downloadable content pack, that reverts the censorship.\nOther versions.\nValve canceled a port of \"Half-Life\" for MacOS, developed by Logicware, in 2000. Newell cited several shortcomings such as the lack of an auto-updater and the lack of Team Fortress Classic, and in general was worried that Mac players would be \"second-class customers\" due to Valve being unable to justify ongoing updates to the Mac port. Rebecca Heineman, the co-founder of Logicware, said that the main reason that Valve canceled the Mac port was that Apple had angered Valve by misrepresenting sales projections (by an order of magnitude). She said the port was complete and three weeks from release when it was canceled due to preorder numbers being much lower than Valve expected. Valve released ports for OS X and Linux in 2013.\nCaptivation Digital Laboratories and Gearbox Software developed a port of \"Half-Life\" for the Dreamcast, with new character models and textures and an exclusive expansion, \"\". Following the cancellations of several third-party games in the wake of Sega's decision to discontinue the Dreamcast in March 2001, Sierra cancelled the port weeks before its scheduled release in June, citing \"changing marketing conditions\". \"Blue Shift\" was ported to Windows. The Dreamcast port became the basis of the \"Half-Life\" port for PlayStation 2, released in late 2001. This version added competitive play and a co-op expansion, \".\"\nIn 2004, Valve released \"Half-Life: Source\", a version of \"Half-Life\" ported to their new game engine, Source. It adds ragdoll physics, advanced water effects, and 5.1 surround sound. At launch, it received mediocre reviews for its lack of significant gameplay and visual enhancements, although \"IGN\" still recommended it. Retrospective reception has been more negative, owing to the game's instability and frequent glitches. The deathmatch mode was ported to Source separately in 2006 as \"Half-Life Deathmatch: Source\". Following the release of the \"Half-Life\" 25th anniversary update in 2023, both ports were delisted from Steam and do not appear in its search results. \"Black Mesa\", a third-party remake of \"Half-Life\" developed by Crowbar Collective on the Source engine, was published as a free mod in September 2012 and later approved by Valve for a commercial standalone release.\n25th anniversary update.\nIn November 2023, for the 25th anniversary of \"Half-Life\", Valve updated the Steam version to revert content to its original 1998 state, fix long-standing bugs, and add content including the \"Half-Life: Uplink\" demo, four new multiplayer maps, Steam Deck support, rendering improvements, and support for 4K resolution monitors. Valve also released an hour-long documentary on the creation of \"Half-Life\", featuring commentary from the original developers, designers and artists. Two days after the release, \"Half-Life\" reached 33,471 concurrent players on Steam, its highest-ever number.\nMods.\n\"Half-Life\" received support from independent game developers, supported and encouraged by Valve. With the game, Valve included Worldcraft, the level design tool used during development, and a software development kit, enabling developers to create mods. Both tools were updated with the release of the patch 1.1.0.0. Supporting tools (including texture editors, model editors, and level editors such as the multiple engine editor QuArK) were either created or updated to work with \"Half-Life\".\nThe \"Half-Life\" software development kit served as the development base for many mods, including the Valve-developed \"Team Fortress Classic\" and \"Deathmatch Classic\" (a remake of \"Quake\"'s multiplayer deathmatch mode in the GoldSrc engine). Other mods such as \"Counter-Strike\" and \"Day of Defeat\" (\"DOD\") began life as the work of independent developers who later received aid from Valve. Other multiplayer mods include \"Firearms\", \"Natural Selection\" and \"Sven Co-op\". Single-player mods include \"USS Darkstar\" (1999, a futuristic action-adventure on board a zoological research spaceship) and \"They Hunger\" (2000\u20132001, a survival horror total conversion trilogy involving zombies). To promote the 2003 film \"Underworld\", Sony Pictures commissioned video game developer Black Widow Games to develop a promotional tie-in mod titled \"Underworld: Bloodline\". The mod was available on Sony Pictures' official website until the end of 2007 and remains the only officially licensed Half-Life mod tied to a Hollywood film.\nSome \"Half-Life\" modifications received retail releases. \"Counter-Strike\" was the most successful, having been released in six different editions: as a standalone product (2000), as part of the \"Platinum Pack\" (2000), as an Xbox version (2003), and as a single-player spin-off, \"\" (2004), as well as in two versions using the Source engine. \"Team Fortress Classic\", \"Day of Defeat\", \"Gunman Chronicles\" (2000, a futuristic Western movie-style total conversion with emphasis on its single-player mode) and \"Sven Co-op\" were also released as standalone products. \"Half-Life\" is also the subject of the YouTube improv roleplaying series \"Half-Life VR but the AI is Self-Aware\" and \"Freeman's Mind\".\nIn 2003, Valve's network was infiltrated by hackers. Among the stolen files was the unreleased \"Half-Life\" mod \"Half-Life: Threewave\", a canceled remake of the \"Quake\" mod \"Threewave CTF\". The files were found by fans on a Vietnamese FTP server in February 2016 and unofficially distributed that September.\nReception.\nCritical reception.\n\"Half-Life\" received critical acclaim by reviewers. On the review aggregation website Metacritic, \"Half-Life\" has a score of 96 out of 100, indicating \"universal acclaim\". \"Computer Gaming World\"'s Jeff Green said it was \"not just one of the best games of the year. It's one of the best games of any year, an instant classic that is miles better than any of its immediate competition, and\u2014in its single-player form\u2014is the best shooter since the original \"Doom.\"\" \"Next Generation\" wrote: \"It is fast paced, it is dramatic, and it brings the very idea of adventure on a PC out of the dark ages and into a 3D world. All that and not a single Orc in sight.\" \"IGN\" described it as \"a tour de force in game design, the definitive single player game in a first-person shooter\". \"GameSpot\" said it was the \"closest thing to a revolutionary step the genre has ever taken\".\nSeveral reviewers cited the level of immersion and interactivity as revolutionary. \"AllGame\" said, \"It isn't everyday that you come across a game that totally revolutionizes an entire genre, but Half-Life has done just that.\" \"Hot Games\" commented on the realism, and how the environment \"all adds up to a totally immersive gaming experience that makes everything else look quite shoddy in comparison\". \"Gamers Depot\" wrote that it was the most immersive game they had played.\nThe final portion of the game, taking place in the alien world of Xen, was generally considered the weakest. Besides introducing a wholly new and alien setting, it also featured a number of low-gravity jumping puzzles. The GoldSrc engine did not provide as much precise control for the player during jumping, making these jumps difficult and often with Freeman falling into a void and the player restarting the game. \"Wired\"'s Julie Muncy called the Xen sequence \"an abbreviated, unpleasant stop on an alien world with bad platforming and a boss fight against what appeared, by all accounts, to be a giant floating infant\". \"The Electric Playground\" said that \"Half-Life\" was an \"immersive and engaging entertainment experience\" in its first half and that it \"peaked too soon\".\nDuring the AIAS' 2nd Annual Interactive Achievement Awards, \"Half-Life\" was awarded \"Computer Entertainment Title of the Year\" and \"PC Action Game of the Year\"; it also received nominations for \"Game of the Year\" and outstanding achievement in \"Art/Graphics\", \"Character or Story Development\", \"Interactive Design\", and \"Software Engineering\".\nJeff Lundrigan reviewed the PlayStation 2 version for \"Next Generation\", rating it three out of five, and wrote that \"it may be getting old, but there's still a surprising amount of life in \"Half-Life\"\". The PlayStation 2 version was a nominee for \"The Electric Playground\"'s 2001 Blister Awards for \"Best Console Shooter Game\", but lost to \"\" for Xbox.\nIn 1999, 2001, and 2005, \"PC Gamer\" named \"Half-Life\" the best PC game of all time. In 2004, \"GameSpy\" readers voted \"Half-Life\" the best game of all time. \"Gamasutra\" gave it their Quantum Leap Award in the FPS category in 2006. GameSpot inducted \"Half-Life\" into their Greatest Games of All Time list in May 2007. In 2007, \"IGN\" described \"Half-Life\" as one of the most influential video games, and in 2013 wrote that the history of the FPS genre \"breaks down pretty cleanly into pre-\"Half-Life\" and post-\"Half-Life\" eras\". In 2021, the \"Guardian\" ranked \"Half-Life\" the third-greatest game of the 1990s, writing that it \"helped write the rulebook for how games tell their stories without resorting to aping the conventions of film\".\nSales.\nAccording to Newell, \"Half-Life\" was budgeted with the expectation of lifetime sales of around 180,000 copies. However, it was a surprise hit. In the United States, \"Half-Life\" debuted at #8 on PC Data's weekly PC game sales chart for the November 15\u201321 period, with an average retail price (ARP) of $49. It rose to sixth place the following week, before dropping to position 10 for the week ending December 5. During the December 6\u201312 period, the game climbed back to sixth place; by this time, its ARP had dropped to $36. It placed between sixth and eighth on PC Data's weekly charts through the end of December, and its ARP rose back to $45 by the week ending January 2. PC Data declared \"Half-Life\" November's sixth-best-selling PC game in the United States, a position it held for the month of December. While its U.S. sales were below 100,000 copies by November 30, it sold 212,173 copies and earned revenues of $8.6 million in the United States by the end of 1998.\nIn January 1999, \"Half-Life\" debuted at #3 on Chart-Track's PC game sales rankings for the United Kingdom, and remained in PC Data's weekly top 10 for the entire month, peaking at #4. By January 19, after two full months of availability, global sales of \"Half-Life\" surpassed 500,000 units. In the United States, it was the fifth-best-selling PC game for the month of January. On PC Data's weekly charts, it rose to #2 from February 7\u201320, with an ARP of $35. Holding a position in the weekly top 10 for the rest of February, it climbed to fourth for the month. The game remained in PC Data's weekly top 10 until the week of March 21 and dropped to position 11 for March as a whole. In the United Kingdom, it placed second in February\u2014behind the debut of \"Baldur's Gate\"\u2014and fifth in March. In April, it claimed #3 on Chart-Track's rankings and dropped to #16 on those of PC Data. On April 23, Sierra announced that global sales of \"Half-Life\" had reached almost 1 million copies.\nAfter maintaining the 16th place for May in the U.S., \"Half-Life\" exited PC Data's monthly top 20 in June. \"Half-Life\" became the fifth-best-selling PC game of the first half of 1999 in the U.S. Its domestic sales during 1999 reached 290,000 copies by the end of September. During 1999, it was the fifth-best-selling PC game in the U.S., with sales of 445,123 copies. These sales brought in revenues of $16.6 million, the sixth-highest gross that year for a PC game in the U.S. The following year, it was the 16th-best-selling PC game in the U.S., selling another 286,593 copies and earning $8.98 million.\nThe PlayStation 2 version received a \"Silver\" sales award from the Entertainment and Leisure Software Publishers Association (ELSPA), indicating sales of at least 100,000 copies in the United Kingdom. \"Half-Life\"'s global sales reached 2.5 million units by July 2001. \"Edge\" noted in 2003 that \"a significant number of the 7.5m copies of the PC version were bought because the game offered such potential for community-driven expansion\". As of November 16, 2004, eight million copies of the game had been sold, and by 2008, 9.3 million copies had been sold at retail. \"Guinness World Records\" awarded \"Half-Life\" the world record for Best-Selling First-Person Shooter of All Time (PC) in the \"Guinness World Records: Gamer's Edition 2008\".\nExpansions and sequels.\n\"Half-Life\" was followed by an expansion pack, ', on November 1, 1999, developed by Gearbox Software. Players control Hazardous Environment Combat Unit (HECU) Corporal Adrian Shephard, who fights a new group of aliens called Race X and Black Ops units after being split from his team. Gearbox developed a second expansion pack, ', in which players control Barney Calhoun, a security guard at Black Mesa, as he attempts to escape the facility. It was developed as a bonus campaign for the Dreamcast port of \"Half-Life,\" but was released for Windows on June 12, 2001, after the port was canceled. Gearbox created a cooperative multiplayer expansion pack, \",\" exclusively for the PlayStation 2 port of \"Half-Life\" which is played through the perspectives of Gina Cross and Colette Green, two Black Mesa scientists.\n\"Half-Life 2\" was announced at E3 2003 and released in 2004. The player controls Freeman 20 years after the Black Mesa incident in the dystopian City 17, where he joins a rebellion against an alien regime. It was followed by the episodic sequels ' (2006) and ' (2007). After cancelling several other \"Half-Life\" projects, Valve released \"\" in 2020.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52817", "revid": "15881234", "url": "https://en.wikipedia.org/wiki?curid=52817", "title": "County Leitrim", "text": "County in Ireland\nCounty Leitrim ( ; ) is a county in Ireland. It is in the province of Connacht and is part of the Northern and Western Region. It is named after the village of Leitrim. Leitrim County Council is the local authority for the county, which had a population of 35,199 according to the 2022 census.\nThe county was based on the Gaelic territory of West Breffny () as it existed in the 1580s.\nGeography.\nLeitrim is the 26th in size of the 32 counties by area (21st of the 26 counties of the Republic) and the smallest by population. It is the smallest of Connacht's five counties in both size and population. Leitrim is bordered by the counties of Donegal to the north, Fermanagh to the north-east, Cavan to the east, Longford to the south, Roscommon to the south-west and Sligo to the west. Fermanagh is in Northern Ireland while all the other neighbouring counties are within the Republic of Ireland.\nLeitrim has a hilly and mountainous landscape in its northwest and is relatively flat in the southeast, each separated from the other by Lough Allen in the middle of the county. Leitrim has the shortest length of coastline of any Irish county that touches the sea. At Tullaghan, the coastline is only long. The Shannon is linked to the Erne via the Shannon\u2013Erne Waterway. Notable lakes include:\nHistory.\nIn ancient times Leitrim formed the western half of the Kingdom of Breifne. This region was long influenced by the O'Rourke family of Dromahair, whose heraldic lion occupies the official county shield to this day. Close ties initially existed with the O'Reilly clan in the eastern half of the kingdom, however, a split occurred in the 13th century and the kingdom was divided into East Breifne, now County Cavan, and West Breifne, now County Leitrim. The Normans invaded south Leitrim in the 13th century but were defeated at the Battle of \u00c1th an Chip in 1270.\nMuch of the county was confiscated from its owners in 1620 and given to Villiers and Hamilton. Their initial objective was to plant the county with English settlers. However, this proved unsuccessful. English Deputy Sir John Perrot had ordered the legal establishment of \"Leitrim County\" a half-century prior, in 1565. Perrott also demarcated the current county borders around 1583.\nLong ago Ireland was covered in woodland, and five great forests are traditionally said to have stood in Leitrim, with a 19th-century county survey stating- \"a hundred years ago almost the whole country was one continued, undivided forest, so that from Drumshanbo to Drumkeeran, a distance of nine or ten miles, one could travel the whole way from tree to tree by branches\". Many of these great forests were denuded for the making of charcoal for iron works around Sliabh an Iarainn. Working of the county's rich deposits of iron ore began in the 15th century and continued until the mid-18th century. Coal mining became prominent in the 19th century to the east of Lough Allen at Sliabh an Iarainn and also to the west in Arigna, on the Roscommon border. The last coal mine closed in July 1990 and there is now a visitor centre. Sandstone was also quarried in the Glenfarne region.\nWriting in 1791, the geographer Beaufort suggested the county housing population encompassed 10,026 homes with \"upwards of 50,000 inhabitants\", the primary agriculture being cattle production, and the growth of flax sustaining the linen industry. Leitrim was first hit by the recession caused by the mechanisation of linen weaving in the 1830s and its 155,000 residents (as of the 1841 census) were ravaged by the Great Famine and the population dropped to 112,000 by 1851. The population subsequently continued to decrease due to emigration. After many years, the wounds of such rapid population decline have finally started to heal. Agriculture improved over the last century. Leitrim now has the fastest growing population in Connacht.\nThe \"Book of Fenagh\" is the most famous medieval manuscript originating here. In the 19th century the poet John McDonald (of Dromod) lived in the county, and William Butler Yeats spent the turn of the twentieth century fascinated with Lough Allen and much of Leitrim. Glencar Waterfall, from Manorhamilton, inspired Yeats and is mentioned in his poem The Stolen Child.\nSubdivisions.\nGeographically, the county is almost evenly divided by Lough Allen (itself part of the River Shannon) and the River Shannon upstream from Lough Allen. While this boundary within the county runs from south to north, separating east from west in its immediate vicinity, the county extends much further north to the west of this line and much further south to the east, and the two parts of the county are commonly known as North Leitrim and South Leitrim, respectively. Uniquely among Irish counties, there is no way to cross from North Leitrim to South Leitrim as defined above (or vice versa) by road without leaving its boundaries. An alternative boundary between North and South Leitrim follows Sliabh an Iarainn east from Lough Allen rather than the River Shannon upstream from it, separating the baronies of Drumahaire to the north and Leitrim and Carrigallen to the south, as in the map in this section, although this boundary is crossed by a few roads including the regional R207 road. North Leitrim under at least one definition is slightly larger than the south, comprising 51% of County Leitrim's land area. However, South Leitrim, with towns such as Carrick-on-Shannon, Ballinamore and Drumshambo, is significantly more populous, containing approximately 65% of the county's population as of 2016.\nBaronies.\nThere are five historic baronies in the county. While baronies continue to be officially defined units, they are no longer used for many administrative purposes. Their official status is illustrated by Placenames Orders made since 2003, where official Irish names of baronies are listed under \"Administrative units\". They are Carrigallen, Drumahaire, Leitrim, Mohill and Rosclogher.\nRural districts.\nUnder the Local Government (Ireland) Act 1898, County Leitrim was divided into the rural districts of Ballyshannon No. 3 (later renamed Kinlough), Bawnboy No. 2 (later renamed Ballinamore), Carrick-on-Shannon No. 1, Manorhamilton and Mohill. The rural districts were abolished in 1925.\nLargest towns in County Leitrim.\nAs of the 2022 census:\nDemographics.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nLocal government and politics.\nLeitrim County Council is the local authority for the county. The county is divided into three local electoral areas, each of which is also a municipal district: Ballinamore (6 councillors), Carrick-on-Shannon (6 councillors), and Manorhamilton (6 councillors). Leitrim County Council has two representatives on the Northern and Western Regional Assembly.\n2024 seats summary.\nThe following were elected at the 2024 Leitrim County Council election:\nNational politics.\nLeitrim is part of the D\u00e1il constituency of Sligo\u2013Leitrim. This constituency existed from 1948 to 2007, and previously from 1923 to 1937 as Leitrim\u2013Sligo. From 1937 to 1948, the county formed the Leitrim constituency. From 2007 until 2016, County Leitrim was divided between two constituencies: Roscommon\u2013South Leitrim and Sligo\u2013North Leitrim. This proved controversial, and at the 2007 general election there was no TD elected whose domicile was in the county. Sligo\u2013Leitrim was recreated at the 2016 general election.\nReferences and notes.\nPrimary references.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSecondary sources.\nHistorical.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52819", "revid": "15881234", "url": "https://en.wikipedia.org/wiki?curid=52819", "title": "County Londonderry", "text": "County in Northern Ireland\n County Londonderry (Ulster-Scots: \"Coontie Lunnonderrie\"), also known as County Derry (), is one of the six counties of Northern Ireland, one of the thirty-two counties of Ireland and one of the nine counties of Ulster. Before the partition of Ireland, it was one of the counties of the Kingdom of Ireland from 1613 onward and then of the United Kingdom after the Acts of Union 1800. Adjoining the north-west shore of Lough Neagh, the county covers an area of and today has a population of about 252,231.\nSince 1972, the counties in Northern Ireland, including Londonderry, have no longer been used by the state as part of the local administration. Following further reforms in 2015, the area is now governed under three different districts: Derry and Strabane, Causeway Coast and Glens and Mid-Ulster. Despite no longer being used for local government and administrative purposes, it is sometimes used in a cultural context in All-Ireland sporting and cultural events (i.e. Derry GAA).\nSince 1981, it has become one of four counties in Northern Ireland that has a Catholic majority (55.56% according to the 2001 Census and 61.3% according to the 2021 Census). The county flower is the purple saxifrage.\nName.\nThe place name \"Derry\" is an anglicisation of the Old Irish \"Daire\" (Modern Irish \"Doire\"), meaning \"oak-grove\" or \"oak-wood\".\nAs with the city, its name is subject to the Derry/Londonderry name dispute, with the form \"Londonderry\" generally preferred by unionists and \"Derry\" by nationalists. Unlike with the city, however, there has never been a County Derry. County Londonderry was formed mostly from the old County Coleraine (see below). The competition is based at Coleraine and involves several other towns and villages in the county \u2013 Limavady, Portstewart and Castlerock \u2013 and in neighbouring County Antrim \u2013 Ballymoney, Portrush, Ballymena and Broughshane. The event, held in the last week of July, has attracted teams from 56 countries around the world including Europe, the US, Africa, the Far East, South America, the Middle East, Australia, Russia, New Zealand and Canada. Some of the biggest teams in the world have entered including English clubs Everton, Liverpool, Manchester United, Chelsea, Tottenham Hotspur as well as top European teams such as Feyenoord, F.C. Porto, FC Barcelona, Benfica, Bayern Munich and Dynamo Kiev.\nIn rugby union, the county is represented at senior level by Rainey RFC, based in Magherafelt, who compete in the Ulster Senior League and All-Ireland League. Limavady R.F.C, City of Derry Rugby Club, Londonderry Y.M.C.A and Coleraine Rugby Club all compete in Ulster Qualifying League One.\nCricket is popular in the north-west of Ireland, with 11 of the 20 senior clubs in the North West Cricket Union located in County Londonderry: Limavady, Eglinton, Glendermott, Brigade, Killymallaght, Ardmore, Coleraine, Bonds Glen, Drummond, Creevedonnell and The Nedd.\nIn rowing, Richard Archibald from Coleraine along with his Irish teammates qualified for the Beijing 2008 Olympics by finishing second in the lightweight fours final in Pozna\u0144, thus qualifying for the Beijing 2008 Olympics. Another Coleraine rower Alan Campbell is a World Cup gold medallist in the single sculls in 2006.\nMedia.\nThe county currently has four main radio stations:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52820", "revid": "50744825", "url": "https://en.wikipedia.org/wiki?curid=52820", "title": "Resident Evil", "text": "Japanese horror game series and media franchise\n \nResident Evil, known as in Japan, is a Japanese horror game series and media franchise created by Capcom. It consists of survival horror, third-person shooter and first-person shooter games, with players typically surviving in environments inhabited by zombies and other mutated creatures. The franchise has expanded into media including a live-action film series, animated films, television series, comic books, novels, audiobooks, and merchandise. \"Resident Evil\" is among the highest-grossing horror franchises.\nThe first \"Resident Evil\" game was created by Shinji Mikami and Tokuro Fujiwara for PlayStation, and released in 1996. It is credited for defining the survival horror genre and returning zombies to popular culture. With \"Resident Evil 4\" (2005), the franchise shifted to more dynamic shooting action, popularizing the now-ubiquitous \"over-the-shoulder\" third-person view in action-adventure games.\nThe franchise returned to survival horror with \"\" (2017) and \"Resident Evil Village\" (2021), which used a first-person perspective. Capcom has also released four \"Resident Evil\" remakes: \"Resident Evil\" (2002), \"Resident Evil 2\" (2019), \"Resident Evil 3\" (2020) and \"Resident Evil 4\" (2023). \"Resident Evil\" is Capcom's best-selling franchise and the best-selling horror game series, with over 170 million copies sold worldwide as of March 2025. The ninth main game, \"Resident Evil Requiem\", is scheduled for release on February 27, 2026.\nThe first \"Resident Evil\" film was released in 2002, starring Milla Jovovich. It was followed by five sequels and a reboot, \"Welcome to Raccoon City\" (2021). The films received mostly negative reviews, but have grossed more than $1.2 billion, making \"Resident Evil\" the third-highest-grossing video game film series.\nHistory.\nThe development of the first \"Resident Evil\", released as \"Biohazard\" in Japan, began in 1993 when Capcom's Tokuro Fujiwara told Shinji Mikami and other co-workers to create a game using elements from Fujiwara's 1989 game \"Sweet Home\" on the Family Computer (Famicom) in Japan. When in late 1994 marketing executives were setting up to release \"Biohazard\" in the United States, it was pointed out that securing the rights to the name \"Biohazard\" would be very difficult as a DOS game had been registered under that name, as well as a New York hardcore punk band called Biohazard. A contest was held among company personnel to choose a new name; this competition turned up \"Resident Evil\", the name under which it was released in the west. \"Resident Evil\" made its debut on the PlayStation in 1996 and was later ported to the Sega Saturn.\nThe first entry in the series was the first game to be dubbed a \"survival horror\", a term coined for the new genre it initiated, and its critical and commercial success led to the production of two sequels, \"Resident Evil 2\" in 1998 and ' in 1999, both for the PlayStation. A port of \"Resident Evil 2\" was released for the Nintendo 64. In addition, ports of all three were released for Windows. The next big game in the series, ', was developed for the Dreamcast and released in 2000, followed by ports of \"Resident Evil 2\" and \"Resident Evil 3: Nemesis\". \"Resident Evil \u2013 Code: Veronica\" was later re-released for Dreamcast in Japan in an updated form as \"Code: Veronica Complete\", which included slight changes, many of which revolved around story cutscenes. This updated version was later ported to the PlayStation 2 and GameCube as \"Code: Veronica X\".\nDespite earlier announcements that the next game in the series would be released for the PlayStation 2, which resulted in the creation of an unrelated game, \"Devil May Cry\", Mikami decided to make the series exclusively for the GameCube. The next three games in the series\u2014a remake of the original \"Resident Evil\" and the prequel \"Resident Evil Zero\", both released in 2002, as well as \"Resident Evil 4\" (2005)\u2014were all released initially as GameCube exclusives. \"Resident Evil 4\" was later released for Windows, PlayStation 2, and Wii.\nA trilogy of GunCon-compatible light gun games known as the \"Gun Survivor\" series featured first-person gameplay. The first, \"Resident Evil Survivor\", was released in 2000 for the PlayStation and PC but received mediocre reviews. The subsequent games, ' and ', fared somewhat better. \"Dead Aim\" is the fourth \"Gun Survivor\" game in Japan, with \"Gun Survivor 3\" being the \"Dino Crisis\" spin-off \"Dino Stalker\". In a similar vein, the \"Chronicles\" series features first-person gameplay, albeit on an on-rails path. ' was released in 2007 for the Wii, with a sequel, ' released in 2009 (both were later ported to the PlayStation 3 in 2012).\n\"Resident Evil Outbreak\" is an online game for the PlayStation 2, released in 2003, depicting a series of episodic storylines in Raccoon City set during the same period as \"Resident Evil 2\" and \"Resident Evil 3: Nemesis\". It was the first in the series and the first survival horror game to feature cooperative gameplay. It was followed by a sequel, \"\". Raccoon City is a metropolis located in the Arklay Mountains of the Midwestern United States that succumbed to the deadly T-virus outbreak and was consequently destroyed via a nuclear missile attack issued by the United States government. The town served as a critical junction for the series' progression as one of the main catalysts to Umbrella's downfall and the entry point for some of the series' most notable characters.\n\"Resident Evil Gaiden\" is an action-adventure game for the Game Boy Color featuring a role-playing-style combat system. There have been several downloadable mobile games based on the \"Resident Evil\" series in Japan. Some of these mobile games have been released in North America and Europe through T-Mobile. At the Sony press conference during E3 2009, \"Resident Evil Portable\" was announced for the PlayStation Portable, described as a new game being developed with \"the PSP Go in mind\" and \"totally different for a \"Resident Evil\" game\". No further announcements have been made, and the game is considered to have been canceled.\nIn 2009, \"Resident Evil 5\" was released for PlayStation 3, Windows and Xbox 360, becoming the best selling game of the franchise despite mixed fan reception. Capcom revealed the third-person shooter ', which was developed by Slant Six Games for the PlayStation 3, Xbox 360 and Windows and released in March 2012. A survival horror game for the Nintendo 3DS, ', was released in February 2012. In October of the same year, the next numbered entry in the main series, \"Resident Evil 6\", was released to mixed reviews, but enthusiastic pre-order sales.\nIn 2013, producer Masachika Kawata said the \"Resident Evil\" franchise would return to focus on elements of horror and suspense over action, adding that \"survival horror as a genre is never going to be on the same level, financially, as shooters and much more popular, mainstream games. At the same time, I think we need to have the confidence to put money behind these projects, and it doesn't mean we can't focus on what we need to do as a survival horror game to meet fan's needs.\" ', an episodic game set between \"Resident Evil 5\" and \"Resident Evil 6\", was released in March 2015. A series of team-based multiplayer games were developed beginning with the poorly received \"Umbrella Corps\", which was released in June 2016. ' was released in April 2020, followed by \"Resident Evil Re:Verse\" in October 2022, with both being available for free to those who bought \"Resident Evil 3\" and \"Village\" respectively.\nBuilt on the newly developed RE Engine, the series continued its shift back towards more horror elements. The next mainline game, \"\" was released for Windows, PlayStation 4 and Xbox One in January 2017. Set in a dilapidated mansion in Louisiana, the game uses a first-person perspective and emphasizes horror and exploration over action, unlike previous installments. The first-person perspective continued in the eighth mainline game \"Resident Evil Village.\" Released in May 2021, the game, set in a mysterious European village, is a direct sequel to \"Resident Evil 7: Biohazard\" although it incorporates more action elements inspired from \"Resident Evil 4\". The game also marked the franchise's debut on PlayStation 5 and Xbox Series X/S. The ninth main game, \"Resident Evil Requiem\", is scheduled for 2026.\nA new generation of remakes of older entries began in 2019 with a remake of \"Resident Evil 2\", being released for the PlayStation 4, Windows, and Xbox One. The remake outsold the original game within a year, selling over five million copies. Following in the success of the \"Resident Evil 2\" remake, Capcom revealed a remake of \"Resident Evil 3: Nemesis\" in December 2019, known as \"Resident Evil 3\". It was released in April 2020. A remake of \"Resident Evil 4\" was released on March 24, 2023, for PlayStation 4, PlayStation 5, Xbox Series X/S and Windows.\nStory overview.\nThe early \"Resident Evil\" games focused on the Umbrella Corporation, an international pharmaceutical company that secretly develops mutagenic viruses to further their \"bio-organic weapons\" (BOW) research. The company's viruses can transform humans into mindless zombies while also mutating plants and animals into horrifying monstrosities. The Umbrella Corporation uses its vast resources to effectively control Raccoon City, a fictional midwestern American city. In the original \"Resident Evil\", members of an elite police task force, Special Tactics and Rescue Service (STARS), are lured to a derelict mansion on the outskirts of Raccoon City. The STARS team is mostly decimated by zombies and other BOWs, leaving only a handful of survivors, including Chris Redfield, Jill Valentine, and Albert Wesker. Chris and Jill explore the zombie-infested mansion and uncover a secret underground Umbrella research facility. Wesker reveals himself to be a double agent for Umbrella and betrays his comrades. However, Wesker is seemingly murdered by a Tyrant, a special BOW that is the culmination of the Umbrella Corporation's research.\nChris and Jill escape the mansion, but their testimony is ridiculed by Raccoon City's officials due to Umbrella's influence. Meanwhile, a separate viral outbreak occurs in another Umbrella research facility underneath Raccoon City. Most of the city's residents are infected and become zombies. \"Resident Evil 2\" introduces two new protagonists, Leon S. Kennedy, a rookie police officer and Claire Redfield, the younger sister of Chris. Leon and Claire arrive in Raccoon City amidst the chaos of the viral outbreak. Leon is aided by Ada Wong, a spy posing as an FBI agent, while Claire rescues Sherry Birkin, the daughter of two prominent Umbrella researchers. At the same time, Jill makes her escape from the city in '. She is relentlessly pursued by a new Tyrant, Nemesis, who is deployed by Umbrella to eliminate all surviving STARS members. The U.S. Government destroys Raccoon City with a missile strike to sterilize the viral outbreak. Leon, Claire, Sherry, Ada, and Jill escape the city before its eradication. Claire continues to look for Chris, whereas Leon is recruited to work for the U.S. Government. ' follows Claire as she escapes from a prison camp in the Southern Ocean and later reunites with Chris at an Umbrella research facility in Antarctica, while Wesker is revealed to be alive. \"Resident Evil 4\" is set six years after the Raccoon City incident and focuses on Leon as he tries to rescue the U.S. President's daughter from a cult in Spain.\nA government investigation into the Umbrella Corporation reveals its involvement in the Raccoon City disaster and leads to the company's dissolution. Despite the downfall of the Umbrella Corporation, the company's research and BOWs proliferate across the black market and lead to the rise of bioterrorism. Chris and Jill establish the Bioterrorism Security Assessment Alliance (BSAA) to combat these ever-growing threats on a global scale. Wesker is involved in the development of new potent viral agents and BOWs. In \"Resident Evil 5\", Wesker seeks to unleash a highly mutagenic virus that will infect all of humanity. Chris and the BSAA confront and kill Wesker in Africa before he can fulfill his mission. \"Resident Evil 6\" features Leon and Chris meeting for the first time in the video game series. The two work separately to triage bioterrorist attacks in the United States, Eastern Europe, and China. They are assisted by Sherry, Wesker's illegitimate son Jake Muller, Ada, and many members of the BSAA and U.S. government.\n\"\" and \"Resident Evil Village\" introduce a new protagonist, Ethan Winters, who becomes entangled in a bioterrorism incident while searching for his missing wife. He encounters Chris and the BSAA, who help him rescue his wife and defeat Eveline, a powerful BOW. Ethan, Mia, and their newborn daughter, Rosemary, are relocated to Eastern Europe but are abducted by a cult. Ethan ultimately sacrifices himself to destroy a fungal colony being weaponized by bioterrorists and save his family.\nGameplay.\nThe \"Resident Evil\" franchise has had a variety of control schemes and gameplay mechanics throughout its history. Puzzle-solving has figured prominently throughout the series.\nTank controls.\nThe first game introduced a control scheme that the player community has come to refer to as \"tank controls\" to the series. In a game with tank controls, players control movement relative to the position of the player character, rather than relative to the fixed virtual camera from which the player views the current scene. Pressing up (for example on a D-pad, analog stick, or cursor movement keys) on the game controller moves the character in the direction being faced, pressing down backpedals, and left and right rotates the character. This can feel counter-intuitive when the character is facing the camera, as the controls are essentially reversed in this state. This differs from many 3D games, in which characters move in the direction the player pushes the controls from the perspective of the camera. Some critics have posited that the control scheme is intentionally clumsy, meant to enhance stress and exacerbate difficulty.\nWhile the first three entries in the series featured this control scheme, the third, \"Resident Evil 3: Nemesis\", saw some action-oriented additions. These included a 180 degree turn and dodge command that, according to \"GameSpot\", \"hinted at a new direction that the series would go in.\" Later games in the series, like \"Resident Evil 4\", would feature a more fluid over-the-shoulder third-person camera instead of a fixed camera for each room, while \"Resident Evil 7\" and \"Resident Evil Village\" are played from the first-person perspective.\nThird-person shooter gameplay.\n\"Resident Evil 4\" saw significant changes to the established gameplay, including switching from fixed camera perspectives to a tracking camera, and more action-oriented gameplay and mechanics. This was complemented by an abundance of ammunition and revised aiming and melee mechanics. Some critics claimed that this overhauled control scheme \"made the game less scary.\" The next two games in the franchise furthered the action-oriented mechanics: \"Resident Evil 5\" featured cooperative play and added strafing, while \"Resident Evil 6\" allowed players to move while aiming and shooting for the first time, fully abandoning the series' signature tank controls.\nFirst-person shooter gameplay and VR.\n\"Resident Evil 7\" is the first main \"Resident Evil\" game to use the first-person perspective and to use virtual reality. It drew comparisons to modern survival horror games such as \"Outlast\" and \"PT\". The eighth main-series game, \"Resident Evil Village\", also features a first-person perspective. A VR version of \"Resident Evil 4\" was released on the Oculus Quest 2 on October 21, 2021.\nOther media.\nThe \"Resident Evil\" franchise features video games and tie-in merchandise and products, including various live-action and animated films, comic books, and novels.\nFilms.\nLive-action films.\nFrom 2002 to 2016, six live-action \"Resident Evil\" films were produced, all written and produced by Paul W. S. Anderson. The films do not follow the games' premise but feature some game characters. The series' protagonist is Alice, an original character created for the films portrayed by Milla Jovovich. Despite a negative reaction from critics, the live-action film series has made over $1 billion worldwide. They are, to date, the only video game adaptations to increase the amount of money made with each successive film. The series holds the record for the \"Most Live-Action Film Adaptations of a Video Game\" in the 2012 \"Guinness World Records Gamer's Edition\", which also described it as \"the most successful movie series to be based on a video game.\"\nA reboot, \",\" was released on November 24, 2021, with Johannes Roberts as writer/director.\nIn January 2025, it was reported that Zach Cregger was writing and directing a new film reboot, co-produced by Constantin Film and PlayStation Productions. In March 2025, Sony Pictures won a bidding war to secure the rights to the \"Resident Evil\" franchise, including its upcoming untitled project, with Columbia Pictures serving as the film's new distributor. Sony has set a release date of September 18, 2026 for the project. In June 2025, it was reported that the project had registered to film in the Czech Republic. On August 11, 2025, Austin Abrams was confirmed to star in the film. Filming is scheduled to begin in Prague in November 2025. Cregger stated that he had never seen any of the previous \"Resident Evil\" films and that the upcoming movie will be more closely based on the video game series, particularly \"Resident Evil 2\", \"\", and \"Resident Evil 4\".\nAnimated films.\nThe first computer animated film for the franchise was \"Biohazard 4D-Executer\". It was a short 3D film produced for Japanese theme parks and did not feature any characters from the game. Starting in 2008, a series of feature-length computer-animated films have been released. These films take place in the same continuity as the games and feature characters such as Leon Kennedy, Claire Redfield, Ada Wong, Chris Redfield, Jill Valentine and Rebecca Chambers.\nTelevision.\n\"\", a four-part CG anime series, premiered on July 8, 2021, on Netflix. Starring the \"Resident Evil 2\" protagonists Leon S. Kennedy and Claire Redfield, the series features both uncovering a worldwide plot. The series released on July 8, 2021 on Netflix.\n\"Resident Evil\" premiered on July 14, 2022, on Netflix. An eight episode live-action series, two plotlines set in 2022 and 2036 follow Albert Wesker and his daughters navigating Umbrella's experiments in New Raccoon City.\nMerchandise.\nOver the years, various toy companies have acquired the \"Resident Evil\" license, with each producing their own unique line of \"Resident Evil\" action figures or models. These include, but are not limited to, Toy Biz, Palisades Toys, NECA, and Hot Toys.\nTokyo Marui also produced replicas of the guns used in the \"Resident Evil\" series in the form of gas blow-back airsoft guns. Some models included the STARS Beretta featured in \"Resident Evil 3\", and the Desert Eagle in a limited edition that came with other memorabilia in a wooden case, along with the Gold Lugers from \"Code: Veronica\" and the \"Samurai Edge\" pistol from the \"Resident Evil\" remake. Other merchandise includes an energy drink called \"T-virus Antidote\".\n\"Resident Evil Archives\" is a reference guide of the \"Resident Evil\" series written by staff members of Capcom. It was translated into English and published by BradyGames. The guide describes and summarizes all of the key events that occur in \"Resident Evil Zero\", \"Resident Evil\", \"Resident Evil 2\", \"Resident Evil 3: Nemesis\", and \"Code: Veronica\". The main plot analysis also contains character relationship charts, artwork, item descriptions, and file transcripts for all five games. A second Archives book was later released in December 2011 and covers \"Resident Evil 4\", \"Resident Evil 5\", the new scenarios detailed in \"Resident Evil: The Umbrella Chronicles\" and \"Resident Evil: The Darkside Chronicles\", and the 2008 CGI movie, \"Resident Evil: Degeneration\". The second Archives volume was also translated by Capcom and published by BradyGames.\nA \"Resident Evil\" theme restaurant called Biohazard Cafe &amp; Grill S.T.A.R.S. opened in Tokyo in 2012. Halloween Horror Nights 2013, held at Universal Orlando, featured a haunted house titled \"Resident Evil: Escape from Raccoon City\", based on \"Resident Evil 2\" and \"Resident Evil 3: Nemesis\".\nNovels.\nThe first \"Resident Evil\" novel was Hiroyuki Ariga's novella \"Biohazard: The Beginning\", published in 1997 as a portion of the book \"The True Story of Biohazard\", which was given away as a pre-order bonus with the Sega Saturn version of \"Biohazard\". The story serves as a prelude to the original \"Resident Evil\", in which Chris investigates the disappearance of his missing friend, Billy Rabbitson.\nS. D. Perry has written novelizations of the first five games, as well as two original novels taking place between games. The novels often take liberties with the games' plot by exploring events occurring outside and beyond the games. This often meant that the games would later contradict the books on a few occasions. One notable addition from the novels is the original character Trent, who often served as a mysterious behind-the-scenes string-puller who aided the main characters. Perry's novels were translated and released in Japan with new cover arts by Wolfina. Perry's novels, particularly \"The Umbrella Conspiracy\", also alluded to events in \"Biohazard: The Beginning\", such as the disappearance of Billy Rabbitson and Brian Irons' bid to run for Mayor. A reprinting of Perry's novels with new cover artwork began in 2012 to coincide with the release of \"\" and its respective novelization.\nThere are a trilogy of original \"Biohazard\" novels in Japan. was published in 1998 and was written by Ky\u016b Asakura and the staff of Flagship. Two additional novels were published in 2002, \"To the Liberty\" by Sudan Kimura and \"Rose Blank\" by Tadashi Aizawa. While no official English translation of these novels has been published yet, the last two books were translated into German and published in 2006.\nNovelizations of the films \"Genesis\", \"Apocalypse\", and \"Extinction\" were written by Keith DeCandido. \"Afterlife\" did not receive a novelization due to Capcom's decision to discontinue working with Pocket Books, who had been their primary source of publishing books up to that point, Capcom would later make Titan Books their primary publisher going forth. \"Retribution\" was written by John Shirley, while \"The Final Chapter\" was written by Tim Waggoner. \"Genesis\" was published over two years after that film's release and coincided with the publication of \"Apocalypse\", \"Genesis\" being marketed as a prequel to \"Apocalypse\", while the \"Extinction\" novel was released in late July 2007, two months before the film's release. \"The Final Chapter\" was published in December 2016 alongside the film's theatrical release. There was also a Japanese novelization of the first film, unrelated to DeCandido's version, written by Osamu Makino. Makino also wrote two novels based on the game \"Resident Evil: The Umbrella Chronicles\". The books are a two-part direct novelization of the game and are published in Japanese and German only. The first novel, titled \"Biohazard: The Umbrella Chronicles Side A\" in Japan and \"Resident Evil: The Umbrella Chronicles 1\" in Germany, was released on December 22, 2007. The second novel, titled \"Biohazard: The Umbrella Chronicles Side B\" in Japan and \"Resident Evil: The Umbrella Chronicles 2\" in Germany, was published in January 2008.\nComics.\nIn 1997, Marvel Comics published a single-issue prologue comic based on the original \"Resident Evil\", released through a promotional giveaway alongside the original PlayStation game.\nIn 1998, WildStorm began producing a monthly comic book series based on the first two games, \"Resident Evil: The Official Comic Magazine\", which lasted five issues. The first four issues were published by Image, while Wildstorm themselves published the fifth and final issue. Each issue was a compilation of short stories that were both adaptations of events from the games and related side stories. Like the Perry novels, the comics also explored events occurring beyond \"Resident Evil 2\" (the latest game during the series' publication) and thus were contradicted by later games. Wildstorm also published a four-issue miniseries, \"Resident Evil: Fire &amp; Ice\", which depicted the ordeal of Charlie Team, a third STARS team created specifically for the comic. In 2009, Wildstorm reprinted \"Fire &amp; Ice\" in a trade paperback collection.\nIn Hong Kong, there has been officially licensed \"Biohazard\" manhua adaptations of \"Biohazard 0\" by publisher Yulang Group, \"Biohazard 2\" by Kings Fountain, \"Biohazard 3 Supplemental Edition\" by Cao Zhihao and, \"Biohazard 3 The Last Escape\", and \"Biohazard Code: Veronica\" by Lee Chung Hing published by Tinhangse Publishing. The Code: Veronica manhua was translated into English, formatted to look like an American comic and distributed by WildStorm as a series of four graphic novel collections.\nIn 2009, Wildstorm began publishing a \"Resident Evil\" comic book prequel to \"Resident Evil 5\", which centers on two original members of the BSAA, Mina Gere and Holiday Sugarman. Written by Ricardo Sanchez and illustrated by Kevin Sharpe and Jim Clark, the first issue was published on March 11, 2009. On November 11, 2009, the third issue was released, and the fourth was released March 24, 2010. The sixth and final book was finally published in February 2011.\nPlays.\nIn the summer of 2000, \"Bioroid: Year Zero\" was performed in Japan. It was a musical horror-comedy but took the perspective of the infected. Super Eccentric Theater put on the production under the direction of Osamu Yagihashi. The stage play was performed from early July to late August. \"Biohazard The Stage\" was released in Japan in 2015. The play focused on Chris Redfield and Rebecca Chambers as Philosophy University in Australia is experiencing a bioterrorist attack. The production was handled by Avex Live Creative and Ace Crew Entertainment, under supervision from Capcom. The following year, \"Musical Biohazard ~Voice of Gaia~\" was released in September. It was produced by Umeda Arts Theater by director G2 and composer, Shunsuke Wada. \"Biohazard the Experience\" was the second \"Resident Evil\" play produced by Avex Live Creative and Ace Crew Entertainment. The story is set in 2015 and follows a cast of thirteen survivors who were abducted and woke up in a mansion during an outbreak.\nReception and legacy.\nMost of the games in the prominent \"Resident Evil\" series have been released to positive reviews. Some of the games, most notably \"Resident Evil\", \"Resident Evil 2\" and \"Resident Evil 4\", have been bestowed with multiple Game of the Year honors and often placed on lists of the best video games ever made.\nIn 1999, \"Next Generation\" listed the \"Resident Evil\" series as number 13 on their \"Top 50 Games of All Time\", commenting that, \"Flawless graphics, excellent music, and a top-notch storyline all combined to make a game of unparalleled atmosphere and suspense.\" In 2012, \"Complex\" ranked \"Resident Evil\" at number 22 on the list of the best video game franchises. That same year, G4tv called it \"one of the most successful series in gaming history.\"\nCommercial performance.\nBy December 2022, around 135 million \"Resident Evil\" games had been sold. The first two \"Resident Evil\" games had collectively sold approximately 11 million units worldwide by March 1999. By early 2001, the series had sold 17 million units worldwide, earning more than $. By 2011, it had sold about 46 million copies and was estimated to have grossed at least $. It is recognized by \"Guinness World Records\" as the best-selling survival horror series, with \"Resident Evil 2\" remake being the best-selling survival horror game as of 2023[ [update]]. Seven of the top ten best-selling horror games in North America are \"Resident Evil\" games.\nThe 2023 \"Resident Evil 4\" remake sold more than three million copies in its first two days of release. It sold four million copies in its first two weeks, making it one of the fastest-selling \"Resident Evil\" games. In Japan, it was the best-selling retail game in its first week, selling 89,662 copies on PlayStation 5 and 85,371 on PlayStation 4.\nThe \"Resident Evil\" film series was the highest-grossing film series based on video games by 2012. By 2011, the films had grossed over $ at the box office, bringing the franchise's estimated revenue to at least more than $ in combined video game sales and box office gross up until then. As of 2020[ [update]], the films have grossed more than $ in box office and home video sales. The success of the video games and films have made \"Resident Evil\" the highest-grossing franchise in the horror and zombie genres.\nCultural impact.\n\"GameSpot\" listed the original \"Resident Evil\" as one of the fifteen most influential video games of all time. It is credited with defining and popularizing the survival horror genre of games. It is also credited with taking video games in a cinematic direction with its B-movie style cut-scenes, including live-action full-motion video (FMV) footage. Its live-action opening, however, was controversial; it became one of the first action games to receive the \"Mature 17+\" (M) rating from the Entertainment Software Rating Board (ESRB), despite the opening cutscene being censored in North America.\nThe \"Resident Evil\" franchise is credited with sparking a revival of the zombie genre in popular culture, leading to a renewed interest in zombie films during the 2000s. \"Resident Evil\" also helped redefine the zombie genre, playing an important role in its shift from supernatural themes to scientific themes by using science to explain the origins of zombies. According to Kim Newman in the book \"Nightmare Movies\" (2011), \"the zombie revival began in the Far East\" mainly due to the 1996 Japanese zombie games \"Resident Evil\" and \"The House of the Dead\". George A. Romero, in 2013, said it was the video games \"Resident Evil\" and \"House of the Dead\" \"more than anything else\" that popularised his zombie concept in early 21st-century popular culture. In a 2015 interview with \"Huffington Post\", screenwriter-director Alex Garland credited the \"Resident Evil\" series as a primary influence on his script for the horror film \"28 Days Later\" (2002), and credited the first \"Resident Evil\" game for revitalizing the zombie genre. Screenwriter Edgar Wright cited \"Resident Evil 2\" as a primary influence on his zombie comedy film \"Shaun of the Dead\" (2004), with the film's star and co-writer Simon Pegg also crediting the first game with starting the zombie revival in popular culture. \"The Walking Dead\" comic book creator Robert Kirkman cited \"Resident Evil\" as his favorite zombie game, while \"The Walking Dead\" television series director Greg Nicotero credited \"Resident Evil\" and \"The House of the Dead\" with introducing the zombie genre \"to a whole generation of younger people who didn't grow up watching \"Night of the Living Dead\" and \"Dawn of the Dead\".\"\nThe \"Resident Evil Apocalypse\" zombies were conceptualized and choreographed by Sharon B. Moore and Derek Aasland. Through script analysis and movement research a \"scientific logic\" was devised for the T-virus accounting for each Zombie behaviour envisioned in Paul W. S. Anderson's script. Sharon B. Moore and Derek Aasland then wrote the so-called Undead Bible - a Handbook for the Undead - used as the guide for the nearly 1000 cast under the choreographic department (stunt performers, actors, dancers, extras) to ensure the Undead physicality was performed in a unified way across the picture.\u00a0 The Stunt and Core teams participated in the \"Undead Bootcamp\". \u00a0See also 2007 Documentary \"Undead Bootcamp\" starring producer Jeremy Bolt, director Alexander Witt, and choreographers Sharon B. Moore and Derek Aasland.\nOn the DVD Featurette '\"Resident Evil; Game Over\"' \"Apocalypse\" director Alexander Witt said the zombies needed to be \"more aggressive and more dangerous\" than the original film, so they were created by the film's choreographers Sharon B. Moore and Derek Aasland as \"liquid zombie[s]' in terms of their relentless forward motion: unstoppable, flowing around any kind of resistance, and then rushing in on the final attack. This is also detailed in the University of Liverpool\u00a0book Biopunk Dystopias Genetic Engineering, Society, and Science Fiction (Lars Schmeink, 2016, p.\u00a0214).\nAdditionally, the first \"Resident Evil\" film adaptation also contributed to the revival of zombie films, with the success of the film and the games resulting in zombies achieving greater mainstream prominence and several zombie films being greenlit, such as the video game film adaptation \"House of the Dead\" (2003), the remake \"Dawn of the Dead\" (2004) and Romero's \"Land of the Dead\" (2005). The \"Resident Evil\" films, \"28 Days Later\" and the \"Dawn of the Dead\" remake all set box office records for the zombie genre, reaching levels of commercial success not seen since the original \"Dawn of the Dead\" (1978). They were followed by other zombie films such as \"28 Weeks Later\" (2007), \"Zombieland\" (2009), \"Cockneys vs Zombies\" (2012), and \"World War Z\" (2013), as well as zombie-themed graphic novels and television shows such as \"The Walking Dead\" and \"The Returned\", and books such as \"World War Z\" (2006), \"Pride and Prejudice and Zombies\" (2009) and \"Warm Bodies\" (2010). The zombie revival trend was popular across different media up until the mid-2010s. Since then, zombie films have declined in popularity during the late 2010s, but zombie video games have remained popular, as seen with the commercial success of the \"Resident Evil 2\" remake and \"Days Gone\" in 2019.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52821", "revid": "15881234", "url": "https://en.wikipedia.org/wiki?curid=52821", "title": "County Tyrone", "text": "County in Northern Ireland\nCounty Tyrone (; from Irish , meaning 'land of Eoghan' ) is one of the six counties of Northern Ireland, one of the nine counties of Ulster and one of the thirty-two traditional counties of Ireland. Its county town is Omagh.\nAdjoined to the south-west shore of Lough Neagh, the county covers an area of , making it the largest of Northern Ireland's six counties by size, and the second largest county in Ulster after Donegal. With a population of 188,383 as of the 2021 census, Tyrone is the 5th most populous county in both Northern Ireland and Ulster, and the 11th most populous county on the island of Ireland. The county derives its name and general geographic location from T\u00edr Eoghain, a Gaelic kingdom under the O'Neill dynasty which existed until the 17th century.\nName.\nThe name \"Tyrone\" is derived from the Irish , meaning 'land of Eoghan', the name given to the conquests made by the from the provinces of and Ulaid. Historically, it was anglicised as \"Tirowen\" or \"Tyrowen\", which are closer to the Irish pronunciation.\nHistory.\n&lt;templatestyles src=\"Module:Historical populations/styles.css\"/&gt;\nHistorically Tyrone (then T\u00edr Eoghain or Tirowen) was much larger in size, stretching as far north as Lough Foyle, and comprised part of modern-day County Londonderry east of the River Foyle. The majority of County Londonderry was carved out of Tyrone between 1610 and 1620 when that land went to the Guilds of London to set up profit making schemes based on natural resources located there. Tyrone was the traditional stronghold of the various O'Neill clans and families, the strongest of the Gaelic Irish families in Ulster, surviving into the seventeenth century. The ancient principality of T\u00edr Eoghain, the inheritance of the O'Neills, included the whole of the present counties of Tyrone and Londonderry, and the four baronies of West Inishowen, East Inishowen, Raphoe North and Raphoe South in County Donegal.\nIn 1608 during O'Doherty's Rebellion areas of the country were plundered and burnt by the forces of Sir Cahir O'Doherty following his destruction of Derry. However, O'Doherty's men avoided the estates of the recently fled Earl of Tyrone around Dungannon, fearing Tyrone's anger if he returned from his exile.\nGeography.\nWith an area of , Tyrone is the largest county in Northern Ireland. The flat peatlands of East Tyrone border the shoreline of the largest lake in the British Isles, Lough Neagh, rising gradually across to the more mountainous terrain in the west of the county, the area surrounding the Sperrin Mountains, the highest point being Sawel Mountain at a height of . The length of the county, from the mouth of the River Blackwater at Lough Neagh to the western point near Carrickaduff hill is . The breadth, from the southern corner, southeast of Fivemiletown, to the northeastern corner near Meenard Mountain is ; giving an area of . Annaghone lays claim to be the geographical centre of Northern Ireland.\nTyrone is connected by land to the counties of Fermanagh to the southwest; Monaghan to the south; Armagh to the southeast; Londonderry to the north; and Donegal to the west. Across Lough Neagh to the east, it borders County Antrim. It is the eighth largest of Ireland's thirty-two counties by area and tenth largest by population. It is the second largest of Ulster's nine traditional counties by area and fourth largest by population.\nAdministration.\nThe county was administered by Tyrone County Council from 1899 until the abolition of county councils in Northern Ireland in 1973.\nDemography.\nIt is one of four counties in Northern Ireland which currently has a majority of the population from a Catholic community background, according to the 2021 census. In 1900 County Tyrone had a population of 197,719, while in 2021 it was 188,383. At the time of the 2021 census, 66.49% were from a Catholic background, 28.88% were from a Protestant and Other Christian (including Christian related), 0.66% were from other religions, and 3.97% had no religious background.\nIrish language and Ulster Scots.\nIn the 2021 UK census in County Tyrone:\nSubdivisions.\nBaronies\nParishes\nTownlands\nFuture railway revival.\nThere is the possibility of the line being reopened to Dungannon railway station from Portadown.\nSport.\nMajor sports in Tyrone include Gaelic games, association football, rugby union and cricket:\nNotable people.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52824", "revid": "28162084", "url": "https://en.wikipedia.org/wiki?curid=52824", "title": "Orange juice", "text": "Juice made from oranges\nOrange juice is a liquid extract of the orange tree fruit, produced by squeezing or reaming oranges. It comes in several different varieties, including blood orange, navel oranges, valencia orange, clementine, and tangerine. As well as variations in oranges used, some varieties include differing amounts of juice vesicles, known as \"pulp\" in American English, and \"(juicy) bits\" in British English. These vesicles contain the juice of the orange and can be left in or removed during the manufacturing process. How juicy these vesicles are depend upon many factors, such as species, variety, and season. In American English, the beverage name is often abbreviated as \"OJ\".\nCommercial orange juice with a long shelf life is made by pasteurizing the juice and removing the oxygen from it. This removes much of the taste, necessitating the later addition of a flavor pack, generally made from orange products. Additionally, some juice is further processed by drying and later rehydrating the juice, or by concentrating the juice and later adding water to the concentrate.\nThe health value of orange juice is debatable: it has a high concentration of vitamin C, but also a very high concentration of simple sugars, comparable to soft drinks. As a result, some government nutritional advice has been adjusted to encourage substitution of orange juice with raw fruit, which is digested more slowly, and limit daily consumption.\n&lt;templatestyles src=\"Template:TOC limit/styles.css\" /&gt;\nHistory.\nDuring World War II, American soldiers often rejected the vitamin C-packed lemon-flavored drink powder found in K-rations because of its unappetizing taste. Thus, the government searched for a better alternative that would fulfill the nutritional needs of the soldiers and prevent diseases such as scurvy while still having a desirable taste. The government and the Florida Department of Citrus worked with a group of scientists to develop a product superior to the canned orange juice available in the 1940s. The result was frozen, concentrated orange juice; this was not until three years after the war had ended.\nBy 1949, orange juice processing plants in Florida were producing over 10 million gallons of concentrated orange juice. Consumers liked concentrated canned orange juice as it was affordable, tasty, convenient, and high in vitamin C. The preparation was simple: empty the container of frozen concentrate into a measured volume of water and stir. However, by the 1980s, food scientists developed a fresher-tasting juice known as reconstituted ready-to-serve juice. Eventually in the 1990s, \"not from concentrate\" (NFC) orange juice was developed. Orange juice is a common breakfast beverage in the United States.\nDue to the importance of oranges to the economy of Florida, \"the juice obtained from mature oranges of the species \"Citrus sinensis\" and hybrids thereof\" was adopted as the official beverage of Florida in 1967.\nNutrition.\nA cup serving (250 millilitres or 8 ounces) of fresh orange juice is 88% water and contains 26 grams of carbohydrates (including 21 grams of sugar), two grams of protein, and 0.5 grams each of dietary fiber and fat (table). One cup supplies 112 calories and 149% of the Daily Value (DV) of vitamin C, with moderate amounts (11-19% DV) of potassium, thiamin, and folate (table).\nBecause of its citric acid content, orange juice is acidic, with a typical pH of around 3.5.\nAs of 2020, consumption of orange juice was under preliminary research for the potential to improve nutrition and affect cardiovascular diseases.\nCommercial orange juice and concentrate.\nFrozen concentrated orange juice.\nCommercial squeezed orange juice is pasteurized and filtered before being evaporated under vacuum and heat. After removal of most of the water, this concentrate, about 65% sugar by weight, is then stored at about . Essences, Vitamin C, and oils extracted during the vacuum concentration process may be added back to restore flavor and nutrition (see below).\nWhen water is added to freshly thawed concentrated orange juice, it is said to be \"reconstituted\".\nThe product was developed in 1948 at the University of Florida's Citrus Research and Education Center. Since, it has emerged as a soft commodity, and futures contracts have traded in New York since 1966. Options on FCOJ were introduced in 1985. From the late 1950s to the mid-1980s, the product had the greatest orange juice market share, but not-from-concentrate juices surpassed FCOJ in the 1980s.\nNot from concentrate.\nOrange juice that is pasteurized and then sold to consumers without having been concentrated is labeled as \"not from concentrate\". Just as \"from concentrate\" processing, most \"not from concentrate\" processing reduces the natural flavor from the juice. The largest producers of \"not from concentrate\" use a production process where the juice is placed in aseptic storage, with the oxygen stripped from it, for up to a year.\nRemoving the oxygen also strips out flavor-providing compounds, and so manufacturers add a flavor pack in the final step, which \"Cook's Illustrated\" magazine describes as containing \"highly engineered additives.\" Flavor pack formulas vary by region, because consumers in different parts of the world have different preferences related to sweetness, freshness and acidity. According to the citrus industry, the Food and Drug Administration does not require the contents of flavor packs to be detailed on a product's packaging.\nOne common component of flavor packs is ethyl butyrate, a natural aroma that people associate with freshness, and which is removed from juice during pasteurization and storage. \"Cook's Illustrated\" sent juice samples to independent laboratories, and found that while fresh-squeezed juice naturally contained about 1.19 milligrams of ethyl butyrate per liter, juice that had been commercially processed had levels as high as 8.53 milligrams per liter.\nCanned orange juice.\nA small fraction of fresh orange juice is canned. Canned orange juice retains vitamin C much better than bottled juice. The canned product loses flavor, however, when stored at room temperature for more than 12 weeks. In the early years of canned orange juice, the acidity of the juice caused the juice to have a metallic taste. In 1931, Dr. Philip Phillips developed a flash pasteurization process that eliminated this problem and significantly increased the market for canned orange juice.\nFreshly squeezed, unpasteurized juice.\nFresh-squeezed, the unpasteurized juice is the closest to consuming the orange itself. This version of the juice consists of oranges that are squeezed and then bottled without having any additives or flavor packs inserted. The juice is not subjected to pasteurization. Depending on storage temperature, freshly squeezed, unpasteurized orange juice can have a shelf life of 5 to 23 days.\nMajor orange juice brands.\nIn the U.S., the major orange juice brand is Tropicana Products (owned by PAI Partners and PepsiCo Inc.), which possesses nearly 65% of the market share. Tropicana also has a large presence in Latin America, Europe, and Central Asia. Competing products include Minute Maid (of The Coca-Cola Company) and Florida's Natural Growers (a Floridian agricultural cooperative that differentiates itself from the competition by being locally owned and using only Florida grown oranges; Tropicana and Simply Orange use a mixture of domestic and foreign stock).\nIn Australia, Daily Juice (owned by National Foods) is a major brand of partially fresh, partially preserved, orange juice.\nIn the United Kingdom, major orange juice brands include Del Monte and Princes.\nAdditives.\nSome producers add citric acid or ascorbic acid to juice beyond what is naturally found in the orange. Some also include other nutrients. Often, additional vitamin C is added to replace that destroyed in pasteurization. Additional calcium may be added. Vitamin D, not found naturally in oranges, may be added as well. Sometimes omega-3 fatty acids from fish oils are added to orange juice. Low-acid varieties of orange juice also are available.\nFCOJ producers generally use evaporators to remove much of the water from the juice in order to decrease its weight and decrease transportation costs. Other juice producers generally deaerate the juice so that it can be sold much later in the year.\nBecause such processes remove the distinct aroma compounds that give orange juice a fresh-squeezed taste, producers later add back these compounds in a proprietary mixture, called a \"flavor pack\", in order to improve the taste and to ensure a consistent year-round taste. The compounds in the flavor packs are derived from orange peels by squeezing the oil out of them. Producers do not mention the addition of flavor packs on the label of the orange juice.\nTypes of orange.\nCommon orange juice is made from the sweet orange. Different cultivars (for example, Valencia, Hamlin) have different properties, and a producer may mix cultivar juices to get the desired taste. Orange juice usually varies between shades of orange and yellow, although some ruby red or blood orange varieties are a reddish-orange or even pinkish. This is due to different pigmentation in ruby red oranges.\nThe blood orange is a mutant of the sweet orange. The mandarin orange and the clementine and tangerine varieties are often used for sparkling juice drinks.\nMany brands of organic orange juices have become available on the market.\nProcessing and manufacture.\nManufacture of frozen concentrated orange juice.\nThe processing of orange to frozen concentrated orange juice begins with testing the orange fruit for quality to ensure it is safe for the process. Then the fruit is cleaned and washed thoroughly and orange oil is taken from the peel of the orange. Next, the juice is extracted from the orange and is screened in order to remove seeds and large pieces of pulp. The juice is then heated to 190 to 200\u00a0\u00b0F in order to inactivate natural enzymes found in the juice. The concentration step occurs in a high vacuum evaporator where the water content in the juice is evaporated while the juice sugar compounds and solids are concentrated. The vacuum evaporator is a low temperature falling film evaporator, which operates at a temperature between 60 and 80\u00a0\u00b0F. Evaporators work in a continuous manner in that fresh juice is added as concentrate is being constantly removed. The concentration process increases the soluble solid portion of the juice from 12 \u00b0Brix to 60-70 \u00b0Brix.\nThe concentrated juice is held in a cold wall tank and is stored at or below 35\u00a0\u00b0F to prevent browning and development of undesired flavors. Next, a small amount of fresh juice is added to the concentrated juice to restore natural and fresh flavors of orange juice that have been lost through the concentration process. Specific cold-pressed orange oils are used to restore the lost aroma and volatile flavors. After the addition of fresh juice, the brix content is reduced to 42\u00a0\u00b0F. The fresh juice is referred to as \"cut-back\" in the industry and attributes to 7-10% of the total juice. Orange peel oil is also added if the oil content is below the required level. The concentrate is then further cooled in a continuous cooler or cold wall tank to 20 to 25\u00a0\u00b0F. The concentrate is canned using steam injection methods to sterilize the lid and develop a vacuum in the can. The cans then undergo final freezing where they are conveyed on a perforated belt in an air blast at -40\u00a0\u00b0F. After freezing, the product is stored at 0\u00a0\u00b0F in a refrigerated warehouse.\nManufacture of \"not from concentrate\".\nSingle strength orange juice (SSOJ) can either be \"not from concentrate\" (NFC) orange juice or juice that is reconstituted from a concentrate with the addition of water to reach a specific single strength brix level. The processing of SSOJ also begins with the selection of orange. The most common types of orange used to produce orange juice are the Pineapple orange, Valencia orange, and Washington Navel oranges from Florida and California. The manufacturing journey begins when oranges are delivered to processing plants by trucks holding about 35,000 to 40,000 pounds of fruit. The fruit is unloaded at the plant for inspection and grading to remove unsuitable fruit before the oranges enter the storage bins. An automatic sampler removes oranges for determination of acid and soluble solids. The bins are organized based on ratio of soluble solids to acids in order to blend oranges appropriate to produce juice with uniform flavor. After the fruit leaves the bins, they are scrubbed with detergent on a rotary brush washer and subsequently rinsed with potable water. Throughout the processing stages, there are multiple points with facilities that inspect oranges and discard damaged fruit.\nThe oranges then go through roller conveyors, which expose all sides of the fruit. The roller conveyors are efficiently built as they are well lighted, installed at a convenient height, and width to ensure all inspectors can reach the fruit to determine inadequacies. Some reasons why fruit may be rejected include indication of mold, rot, and ruptured peels. Afterwards, the oranges are separated based on size through machines prior to juice extraction. There are a number of different ways orange juice industry leaders extract their oranges. Some common methods include halving the fruit and pressing/reaming the orange to extract juice from the orange. One instrument inserts a tube through the orange peel and forces the juice out through the tube by squeezing the entire orange. Despite the variety of machines used to extract juices, all machines have commonalities in that they are rugged, fast, easy to clean and have the ability to reduce peel extractives into the juice. The extracted juice product does not contain the orange peel, but it may contain pulp and seeds, which are removed by finishers.\nFinishers have a screw-type design that comprises a conical helical screw enclosed in a cylindrical screen with perforations the size of 0.020 to 0.045 inches. Thereafter, the finished orange juice flows through blending tanks where the juice is tested for acid and soluble solids. At this stage, sugar can be added to the juice depending on if the product will be a sweetened or unsweetened beverage. Following blending, the orange juice is deaerated where the air is incorporated into the juice during extraction. The benefits of deaeration include the elimination of foaming, which improves the uniformity of can fill and improvement regarding the efficiency of the heat exchanger. Orange peel oil is essential for maximum flavor, but according to U.S. standards for Grades of Canned Orange Juice, 0.03% of recoverable oil is permitted. Deoiling through the use of vacuum distillation is the mechanism used to regulate the amount of peel oil in the juice. Condensation separates the oil and the aqueous distillate, which is returned to the juice.\nThe next step is one of the most vital in the processing of orange juice. Pasteurization is important in destroying naturally occurring enzymes that are associated with deterioration of the juice. Pectinesterase is infamous for its deteriorative activity in orange juice. In the pasteurization process, the juice is generally rapidly heated to 197\u00a0\u00b0F for about 40 seconds. Several industry leaders use flash pasteurization, which is carried out by tubular or plate-type heat exchangers. In order to prevent overheating, turbulent flow is vital to heat the juice rapidly. Cans are filled with the pasteurized juice and inverted immediately to allow the juice to sterilize the inside parts of the lid. The orange juice filled can is sealed and cooled to 90 to 100\u00a0\u00b0F by spinning on the conveyor belt under cool water sprays. Quality of storage is determined by time and temperature. Juice must be stored at cool temperatures to prevent deterioration.\nStandards and regulations.\nRegulations in Canada.\nFor Canadian markets, orange juice must be the fruit juice obtained from clean, sound, and mature oranges. The juice must also contain a minimum of 1.20 milliequivalents of free amino acids per 100 millilitres, contain a minimum of 115 milligrams of potassium per 10 milliliters, and possess a minimum absorbance value for total polyphenolics of 0.380. Sweeteners such as sugar, invert sugar, dextrose or glucose solids may be added. The orange juice must have a Brix reading of at least 9.7, excluding the sweetening ingredients, and contain between 0.5 and 1.8 percent of acid by weight calculated as anhydrous citric acid. Added orange essences, orange oils and orange pulp adjusted in accordance with good manufacturing practice is permitted. Orange juice is also permitted to contain sugar, invert sugar, dextrose in dry form, glucose solids, a Class II preservative, amylase, cellulase and pectinase.\nRegulations in the United States.\nIn the United States, orange juice is regulated and standardized by the Food and Drug Administration (FDA or USFDA) of the United States Department of Health and Human Services. According to the FDA, orange juice from concentrate is a mixture of water with frozen concentrated orange juice or concentrated orange juice for manufacturing. Additional ingredients into the mixture may include fresh/frozen/pasteurized orange juice from mature oranges, orange oil, and orange pulp. Furthermore, one or more of the following optional sweetening ingredients may be added: sugar, sugar syrup, invert sugar, invert sugar syrup, dextrose, corn syrup, dried corn syrup, glucose syrup, and dried glucose syrup. The orange juice must contain a minimum Brix level of 11.8, which indicates the percentage of orange juice soluble solids, excluding any added sweetening ingredients.\nRegulations in the United Kingdom.\nIn the United Kingdom, orange juice from concentrate is a product of concentrated fruit juice with the addition of water. Any lost flavour or pulp of the orange juice during the initial concentration process may be restored in the final product to be equivalent to an average type of orange juice of the same kind. Any restored flavour or pulp must come from the same species of orange. Sugar may be added to the orange juice for regulating the acidic taste or sweetening, but must not exceed 150g per litre of orange juice. Across the UK, the final orange juice from concentrate product must contain a minimum Brix level of 11.2, excluding the additional sweetening ingredients. Vitamins and minerals may be added to the orange juice in accordance with Regulation (EC) 1925/2006.\nPhysical and chemical properties.\nMolecular composition.\nOn a molecular level, orange juice is composed of organic acids, sugars, and phenolic compounds. The main organic acids found in orange juice are citric, malic, and ascorbic acid. The major sugars found in orange juice are sucrose, glucose, and fructose. There are approximately 13 phenolic compounds in orange juice including hydroxycinnamic acids, flavanones, hydroxybenzoic acids, hesperidin, narirutin, and ferulic acid.\nComposition of the cloud.\nThe cloud is the portion of suspended particles that range in size from 0.05 micrometers to a few hundred micrometers in orange juice. The cloud is responsible for several sensory attributes in orange juice including color, aroma, texture, and taste. The continuous medium of the cloud consists of a solution of sugars, pectin, and organic acids while the dispersed matter is formed through cellular tissue comminuted in fruit processing. Specifically, the cloudiness of the juice is caused by pectin, protein, lipid, hemicellulose, cellulose, hesperidin, chromoplastids, amorphous particles, and oil globules. In particular the chemical composition of the cloud consists of 4.5-32% pectin, 34-52% protein, 25% lipids, 5.7% nitrogen, 2% hemicellulose, 2% ash, and less than 2% cellulose.\nPhysical structure.\nOrange juice is a suspension that consists of heterogeneous particles in a clear serum. A serum is the clear supernatant after the precipitation of the cloud through centrifugation. The previously mentioned cloud makes up a large part of the suspension.\nIf the suspension in orange juice is not stable, the cloud particles can flocculate which causes the suspension to physically decompose. The cloud can break apart and the citrus juice will clarify if the suspension becomes unstable. The activity of pectin methyl esterase increased the interaction between pectin and cloud proteins, which led to protein-pectin flocculation. The insoluble material of the cloud clumps in conditions above and at a pH of 3-4 at which proteins coagulate and flocculate. Cloud flocculation is enhanced at pH 3.5 and can result in clarification, which is undesirable in orange juice.\nThe suspension is unstable when the zeta potential is less than 25 mv in magnitude. Zeta potential is a measure of the magnitude of electrostatic forces between particles, which affect repulsion, and attraction between particles. A low zeta value signifies that the repulsive forces will not be able to overcome Van der Waals attractions between cloud particles and thus begin to agglomerate. Agglomeration of cloud particles will prevent free flow characteristics, which is essential in the juice. A high zeta potential will inhibit particle-particle agglomeration and maintain the free flowing nature as well as uniform dispersion in orange juice.\nThe oil globules adsorbed to the cloud particles stabilize the suspension by decreasing the average density of particles to bring it closer to that of the serum. However, large amounts of oil can be problematic as they cause complete breakdown of suspensions by causing cloud particles to float to the surface. The particles in the cloud have a negative charge that decreases with decreasing pH. In accordance with cloud stability, the hydration of particles is more significant than their electrical charge.\nHeat treatment.\nWhen orange juice is heat treated there is an increase in the number of fine particles and decrease in that of coarse particles. The fine particles in particular are responsible for the appearance, color, and flavor of orange juice. Heat treatment plays a vital role on pulp volume, cloud stability, serum turbidity, and serum viscosity. Heat treatment stabilizes the cloud through enzyme inactivation and enhances the turbidity of a stable cloud formation. The increase in serum viscosity is due to the extraction of pectic substances into the serum. Based on Stokes' law, the increase in serum viscosity is the cause for the enhanced cloud stability. In relation to pulp volume, the pulp from heated juices was finer and more compact than unheated juice pulp, which was voluminous and fluffy.\nProperties of pulp.\nIn orange juice, pulp is responsible for desirable flow properties, taste, flavor, and mouth feel. However, pulpy orange juice precipitates based on a rate dependent on the diameter, density, and viscosity of the suspended particles as well as the suspending juice. In order to remain suspended in orange juice, pulp particles must have appropriate particle size, charge, and specific gravity. Depending on type of processing method, the size of pulp particles ranges from . Those that are smaller than are known to be more stable, so it is beneficial to reduce the size of particles by incorporating hydrocolloids to the juice product. Hydrocolloids would decrease the rate of sediment formation and decrease the falling rate of pulp particles.\nHydrocolloids.\nHydrocolloids are long-chain polymers that form viscous dispersions and gels if dispersed in water. They have a number of functional properties in food products including emulsifying, thickening, coating, gelling, and stabilization. The main reason hydrocolloids are used in foods is their capability to modify the rheology of food systems. Hydrocolloids impact viscosity through flow behavior and mechanical solid properties like texture. Some common hydrocolloids that are used to stabilize juice products include gellan gum, sodium carboxymethylcellulose, xanthan, guar gum, and gum Arabic. The aforementioned hydrocolloids are generally used in the production of imitation orange juices and are often referred to as synthetic hydrocolloids. Pectin is the hydrocolloid found in natural orange juices.\nProperties of pectin.\nPectin is the soluble polymeric material in the pulp of oranges, which contains 75% of carboxyl of arabinose and galactose. Pectic compounds are complex heteropolysaccharides in that their chemical composition includes a chain structure of axial-axial \u03b1-1.4-linked d-galacturonic acid unit along with blocks of L-rhamnose regions that have side chains of arabinose, galactose, and xylose. Pectin methyl-esterase is the enzyme responsible for hydrolyzing carboxymethyl esters and liberating free carboxyl groups and methyl alcohols. The free carboxyl groups interact with cations to form insoluble pectic acid divalent metal ion complexes. These metal ion complexes precipitate in the juice and carry all the colloids in orange juice with it. The enzyme would flocculate the cloud and clarify the orange juice. Thus, in order to keep the orange juice cloud intact, it is vital to inactivate pectinesterase. Pectinesterase is inactivated by heating the juice for 1 minute at .\nInteractions of pectin.\nThe solution behavior of pectin is strongly influenced by a number of factors including hydrogen bonding, ionic character, and hydrophobic character. Hydrogen bonding is favored when pH is less than pKa while the ionic character is favored when pH is greater than pKa. Ionic character relies on free carboxyl content, the presence of cations, and is favored at a high water activity. Charge-charge repulsions along with the presence of neutral side chains are essential in inhibiting intermolecular association among pectin molecules. The methyl ester content in orange juice determines hydrophobic character, which is favored at low water activity.\nThere is a specific interaction between pectin and hesperidin through the sugar moieties in the hesperidin molecule. Through acid hydrolysis, the rhamnose and glucose sugar moieties are removed from hesperidin, which breaks the interaction between hesperidin and pectin. Hydrogen bonding plays a role in the specific interaction of neutral sugars of pectin and the sugar moiety of hesperidin. A polymer that has a high structural content of neutral sugar branches interacts with hesperidin more tightly and strongly than that of a low content of neutral sugar branches. The interaction between pectin and hesperidin is one of the factors that enable the colloidal suspension in orange juice to be stable.\nConsumption.\nAccording to industry data, U.S. orange juice consumption has been steadily decreasing. In the 2008-2009 crop year, Americans consumed approximately 865,000 metric tons of orange juice. By the 2022-2023 crop year, this figure had fallen to around 500,000 metric tons, representing an average annual decline of approximately 4%. Factors contributing to this decline include rising prices for orange juice and adverse weather conditions affecting orange harvests.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52825", "revid": "28979433", "url": "https://en.wikipedia.org/wiki?curid=52825", "title": "Fountain Valley, California", "text": "City in California, United States\nFountain Valley is a suburban city in Orange County, California. The population was 57,047 at the 2020 census.\nHistory.\nIndigenous.\nThe Indigenous people of the Fountain Valley area are the Tongva. The closest village to present-day site of the city was the village of Pasbenga. The village was part of a series of villages along what the Spanish would refer to as the Santa Ana River.\nSpanish.\nEuropean settlement of the area began when Manuel Nieto was granted the land for Rancho Los Nietos, later Rancho Las Bolsas, which encompassed over , including present-day Fountain Valley. Control of the land was subsequently transferred to Mexico upon independence from Spain, and then to the United States as part of the Treaty of Guadalupe Hidalgo.\nTalbert.\nTalbert was a settlement at what is now the intersection of Talbert and Bushard. It was also known as Gospel Swamp by residents.\nThomas B. Talbert was born outside Monticello in Piatt County, Illinois, in 1878. When Talbert was 13, his family moved to Long Beach, California. Around 1896, the family purchased more than of peat and swampland in what is now Fountain Valley. The Talberts opened a general store and thus the settlement of Talbert was established.\nThe area was full of farms growing beets that were processed at some of the nation's largest plants at Huntington Beach (Holly Sugar Plant) and at Delhi, now part of southwestern Santa Ana. The post office was established in 1899, with Thomas B. Talbert serving as the first postmaster.\nThe All-Saints Church is the only structure remaining from that era. The Santa Ana\u2013Huntington Beach Line of the Pacific Electric Railway passed through Talbert and opened on July 5, 1909.\nIncorporation.\nThe city was incorporated in 1957. The name of Fountain Valley refers to the very high water table in the area at the time the name was chosen, and the many corresponding artesian wells in the area. Early settlers constructed drainage canals to make the land usable for agriculture, which remained the dominant use of land until the 1960s, when construction of large housing tracts accelerated. The first mayor of Fountain Valley was James Kanno, who with this appointment became one of the first Japanese-American mayors of a mainland United States city.\nAfter the Fall of Saigon in 1975, there was a large influx of Vietnamese refugees settling in Fountain Valley, especially in the late 1970s and throughout the 1980s, forming a large percentage of Asian Americans in the city.\nGeography.\nThe city is located southwest and northeast of the San Diego Freeway (Interstate 405), which diagonally bisects the city, and is surrounded by Huntington Beach on the south and west, Westminster and Garden Grove on the north, Santa Ana on the northeast, and Costa Mesa on the southeast. Its eastern border is the Santa Ana River.\nAccording to the United States Census Bureau, the city has a total area of , 0.14% of which is water.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\nFountain Valley first appeared as a city in the 1960 U.S. census as part of the North Coast census county division.\n2020.\nThe 2020 United States census reported that Fountain Valley had a population of 57,047. The population density was . The racial makeup of Fountain Valley was 41.9% White, 1.0% African American, 0.5% Native American, 39.8% Asian, 0.2% Pacific Islander, 6.4% from other races, and 10.1% from two or more races. Hispanic or Latino of any race were 15.5% of the population.\nThe census reported that 99.4% of the population lived in households, 0.4% lived in non-institutionalized group quarters, and 0.3% were institutionalized.\nThere were 19,157 households, out of which 30.7% included children under the age of 18, 56.2% were married-couple households, 4.4% were cohabiting couple households, 25.4% had a female householder with no partner present, and 14.1% had a male householder with no partner present. 18.7% of households were one person, and 11.2% were one person aged 65 or older. The average household size was 2.96. There were 14,498 families (75.7% of all households).\nThe age distribution was 18.6% under the age of 18, 8.6% aged 18 to 24, 22.5% aged 25 to 44, 28.6% aged 45 to 64, and 21.7% who were 65years of age or older. The median age was 45.2years. For every 100 females, there were 94.2 males.\nThere were 19,561 housing units at an average density of , of which 19,157 (97.9%) were occupied. Of these, 68.6% were owner-occupied, and 31.4% were occupied by renters.\nIn 2023, the US Census Bureau estimated that 32.0% of the population were foreign-born. Of all people aged 5 or older, 53.9% spoke only English at home, 9.7% spoke Spanish, 3.2% spoke other Indo-European languages, 29.5% spoke Asian or Pacific Islander languages, and 3.7% spoke other languages. Of those aged 25 or older, 90.4% were high school graduates and 44.9% had a bachelor's degree.\nThe median household income was $111,797, and the per capita income was $48,238. About 3.8% of families and 7.3% of the population were below the poverty line.\n2010.\nThe 2010 United States census reported that Fountain Valley had a population of 55,313. The population density was . The racial makeup of Fountain Valley was 31,225 (56.5%) White (49.2% Non-Hispanic White), 510 (0.9%) African American, 229 (0.4%) Native American, 18,418 (33.3%) Asian, 171 (0.3%) Pacific Islander, 2,445 (4.4%) from other races, and 2,315 (4.2%) from two or more races. Hispanic or Latino of any race were 7,250 persons (13.1%).\nThe Census reported that 54,876 people (99.2% of the population) lived in households, 257 (0.5%) lived in non-institutionalized group quarters, and 180 (0.3%) were institutionalized.\nThere were 18,648 households, out of which 6,341 (34.0%) had children under the age of 18 living in them, 11,142 (59.7%) were opposite-sex married couples living together, 2,102 (11.3%) had a female householder with no husband present, 970 (5.2%) had a male householder with no wife present. There were 646 (3.5%) unmarried opposite-sex partnerships, and 108 (0.6%) same-sex married couples or partnerships. 3,451 households (18.5%) were made up of individuals, and 1,772 (9.5%) had someone living alone who was 65 years of age or older. The average household size was 2.94. There were 14,214 families (76.2% of all households); the average family size was 3.34.\nThe population was spread out, with 11,643 people (21.0%) under the age of 18, 4,624 people (8.4%) aged 18 to 24, 13,310 people (24.1%) aged 25 to 44, 16,020 people (29.0%) aged 45 to 64, and 9,716 people (17.6%) who were 65 years of age or older. The median age was 42.6 years. For every 100 females, there were 94.9 males. For every 100 females age 18 and over, there were 92.2 males.\nThere were 19,164 housing units at an average density of , of which 13,458 (72.2%) were owner-occupied, and 5,190 (27.8%) were occupied by renters. The homeowner vacancy rate was 0.8%; the rental vacancy rate was 3.8%. 40,718 people (73.6% of the population) lived in owner-occupied housing units and 14,158 people (25.6%) lived in rental housing units.\nAccording to the 2010 United States census, Fountain Valley had a median household income of $81,212, with 6.7% of the population living below the federal poverty line.\nEconomy.\nAs a suburban city, most of Fountain Valley's residents commute to work in other urban centers. However, in recent years, the city has seen an increase in commercial jobs in the city, with the growth of a commercial center near the Santa Ana River known as the \"Southpark\" district.\nAlthough the economy of the area was once based mainly on agriculture, the remaining production consists of several fields of strawberries or other small crops, which are gradually being replaced by new office development. Efforts to bolster economic activity are evidenced by the city enacting policies to benefit small businesses, and even going so far as to paint a mural on the facade of a large water treatment building facing the freeway that depicts two shopping bags headlined by the words, \"Shop in Fountain Valley.\"\nFountain Valley is home to the national headquarters of Hyundai Motor America and D-Link Corporation, the global headquarters of memory chip manufacturer Kingston Technology, and the corporate headquarters of Surefire, LLC, maker of military and commercial flashlights. The Southpark commercial area is also home to offices for companies such as D-Link, Starbucks, Satura and the Orange County Register. There are also a limited number of light industrial companies in this area. In addition, Fountain Valley is the location for Noritz, a tankless water heater manufacturer, and the main west coast offices of Ceridian, a professional employer organization.\nThe increasing commercial growth can be evidenced by the frequent rush-hour traffic bottlenecks on the San Diego (405) Freeway through Fountain Valley.\nTop employers.\nAccording to the city's 2023 Annual Comprehensive Financial Report, the top ten employers in the city are:\nArts and culture.\nFountain Valley holds an annual Summerfest in June in Mile Square Regional Park. The event features a car show, rides, music, and booths.\nThe city has 18 churches, one Reform synagogue, a mosque and a public library.\nParks and recreation.\nFountain Valley is home to Mile Square Regional Park, a park containing two lakes, three 18-hole golf courses, playing fields, picnic shelters, and a urban nature area planted with California native plants, a recreation center with tennis courts, basketball courts, racquetball courts, a gymnasium, and the Kingston Boys &amp; Girls Club; There is also a community center and a senior center that opened in September 2005. A major redevelopment of the recreation center and city-administered sports fields was completed in early 2009.\nGovernment.\nIn the California State Legislature, Fountain Valley is in the senatorial district, represented by Republican Tony Strickland, and in the Assembly district, represented by Republican Tri Ta.\nIn the United States House of Representatives, Fountain Valley is in California's congressional district, represented by Democrat Derek Tran.\nPolitics.\nFountain Valley is a reliably Republican stronghold in presidential elections; however, former Secretary of State Hillary Rodham Clinton won a plurality of the city in 2016, becoming the first Democrat in over four decades to carry the municipality. However, in 2020, the city moved back into the Republican column, as Donald Trump carried the city with 51.0% of the vote, having made gains in Orange County's Vietnamese community.\nAccording to the California Secretary of State, as of October 22, 2018, Fountain Valley has 32,884 registered voters. Of those, 12,935 (39.34%) are registered Republicans, 9,674 (29.42%) are registered Democrats, and 8,967 (27.27%) have declined to state a political party/are independents.\nEducation.\nThere are three high schools, three middle schools, nine elementary schools, one K-12 school, and two K-8 schools. However, some students who live in the city of Fountain Valley actually attend schools in other cities.\nFountain Valley is also home to Coastline Community College. Community colleges in the area include Orange Coast College and Golden West College, located nearby in the cities of Costa Mesa and Huntington Beach, respectively.\nHigh schools in Huntington Beach Union High School District:\nHigh schools in Garden Grove Unified School District:\nMiddle schools in Fountain Valley School District:\nMiddle schools in Ocean View Middle School District:\nElementary schools in Garden Grove Unified School District:\nElementary schools in Fountain Valley School District:\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nPrivate schools.\nThe Lyc\u00e9e International de Los Angeles previously had its Orange County campus in Fountain Valley, but it moved to Orange by 2001.\nMedia.\nFountain Valley has its own newspaper, the \"Fountain Valley View,\" operated by the \"Orange County Register.\"\nInfrastructure.\nIn addition to the San Diego Freeway, which bisects the city, Fountain Valley is served by several bus lines operated by the Orange County Transportation Authority. Bus routes 33, 35, 37, 43, 70, 72, 76 and 543 cover the city's major streets.\nMost of the major roads are equipped with bicycle lanes, especially around Mile Square Park, which offers wide bike paths along the major streets that mark its boundary. Dedicated bike paths along the Santa Ana River run from the city of Corona to the Pacific Ocean.\nHistorically, Fountain Valley had Red Car service along the Santa Ana/Huntington Beach Pacific Electric Spur Line. This line ran along Bushard Street. Passenger service started in 1909, ended in 1922, and the lines were torn out in 1930.\nFire protection and emergency medical services are provided by two stations of the Fountain Valley Fire Department. Law enforcement is provided by the Fountain Valley Police Department. Ambulance service is provided by Care Ambulance Service.\nThe Orange County Sanitation District's administrative offices and primary plant is located in Fountain Valley next to the Santa Ana River. The agency is the third-largest sanitation district in the western United States. Fountain Valley is also home to the offices of the Municipal Water District of Orange County, a member of the Metropolitan Water District of Southern California and of the Orange County Water District. The Orange County Water District manages the groundwater basin in central and northern Orange County and operates the Groundwater Replenishment System, the world's largest water purification plant for groundwater recharge.\nFountain Valley has two fully accredited major medical centers: the Fountain Valley Regional Hospital with 400 beds available, and Orange Coast Memorial Medical Center with 230 beds, a medical clinic, and an outpatient medical building.\nNotable people.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52826", "revid": "50796652", "url": "https://en.wikipedia.org/wiki?curid=52826", "title": "Fremont, California", "text": "City in California, United States\nFremont () is a city in Alameda County, California, United States. Located in the East Bay region of the Bay Area, Fremont has a population of 230,504 as of 2020, making it the fourth most populous city in the Bay Area, behind San Jose, San Francisco, and Oakland. It is the closest East Bay city to the high-tech Silicon Valley network of businesses, and has a strong tech industry presence. Fremont is also famous for its large Tesla manufacturing plant, employing over 20,000 people.\nThe city's origins lie in the community that arose around Mission San Jos\u00e9, founded in 1797 by the Spanish under Padre Ferm\u00edn Lasu\u00e9n. Fremont was incorporated on January 23, 1956, when the former towns of Mission San Jos\u00e9, Centerville, Niles, Irvington, and Warm Springs unified into one city. Fremont is named after John C. Fr\u00e9mont, a general who helped lead the American Conquest of California from Mexico and later served as Military Governor of California and then U.S. Senator.\nHistory.\nEarly history.\nThe recorded history of the Fremont area began on June 6, 1797, when Mission San Jos\u00e9 was founded by the Spaniard Father Ferm\u00edn de Lasu\u00e9n. The Mission was established at the site of the Ohlone village of Oroysom. The tribe lived between present-day San Francisco and Monterey and more lands eastward. They lived in dome-shaped shelters made out of redwood bark or woven tule. They were primarily hunter-gatherers; men hunted and trapped waterfowl, rabbits, deer, elk, and bears, whilst women gathered nuts, berries, and root vegetables. The Ohlone tribe lived beside rivers and estuaries because of the natural resources like fish and shellfish. In warm weather, men wore mostly nothing; in the winter, they wore animal hide or feather capes. Other than the weather, ceremonies also decided what the Ohlone men wore. The women wore deerskin aprons over skirts made of tule or shredded bark.\nUntil 1769, the tribe lived peacefully but Spanish soldiers and missionaries arrived in California to expand Spanish dominion in the Americas and convert the Native Americans to Catholicism. The Ohlone people weren't intimidated by the Franciscan priests, who welcomed them into their missions to live and work. Before missions, the Natives used tools made of stone, animal bones, and wood. The missionaries taught them how to make metal tools and weapons and priests also showed them how to make adobe bricks. The bricks were then used to build missions rather than for the tribe to utilize. The Spaniards brought cattle, pigs and sheep and encouraged the Ohlone to give up hunting and gathering to try farming and ranching instead. Living in the missions meant Ohlone people were forced into converting to Christianity and told to forget the superstitious beliefs that connected them to nature. Along with that, overpopulation caused food shortages and the Spanish brought diseases to the tribe, causing a lot of deaths and trouble that made an impact on a lot of lives.\nOn their second day in the area, the Mission party killed a grizzly bear in Niles Canyon. The first English-speaking visitor to Fremont was the renowned trapper and explorer Jedediah Smith in 1827. The Mission prospered, eventually reaching a population of 1,887 inhabitants in 1831. The influence of the missionaries declined after 1834 when the Mexican government enacted secularization.\nJos\u00e9 de Jesus Vallejo, brother of Mariano Vallejo, was the grantee of the Rancho Arroyo de la Alameda Mexican land grant. His family was influential in the Fremont area in the late colonial era and owned and built a flour mill at the mouth of Niles Canyon. In 1846 the town's namesake John C. Fr\u00e9mont led a military expedition to map a trail through Mission Pass for reaching the Pacific coast and to take possession of California from Mexico for the United States.\nThe Fremont area grew rapidly at the time of the California Gold Rush. A town called Mission San Jos\u00e9 grew up around the old mission, with its own post office from 1850. Agriculture dominated the economy with grapes, nursery plants and olives as leading crops. In 1868 the 6.8-magnitude Hayward earthquake on the Hayward Fault collapsed buildings throughout the Fremont area, ruining Mission San Jos\u00e9 and its outbuildings. Until the 1906 San Francisco earthquake caused its destruction, the Fremont area's Palmdale Winery was the largest in California. The ruins of the Palmdale Winery are still visible near the Five Corners in Irvington at the intersection of Washington Boulevard and Osgood.\nFrom 1912 to 1915, the Niles section of the Fremont area was the earliest home of California's motion picture industry (see Essanay Studios). Charlie Chaplin filmed several movies in the Fremont area, most notably \"The Tramp\".\nIncorporation.\nFremont was incorporated in 1956 under the leadership of Wally Pond, chair of the incorporation committee, when five towns in the area, Irvington, Centerville, Mission San Jos\u00e9, Niles, and Warm Springs, came together to form a city. Glenmoor Gardens, the largest subdivision in Fremont, was under construction in the area, by developers Ralph E. Cotter Jr., James R. Meyer, civil engineer Fred T. Duvall, and contractors James L. Reeder, and Robert H. Reeder. When the Glenmoor Gardens Homeowners Association (GGHA) was incorporated, in March 1953, there were no more than 75 houses in the subdivision. It was probably the first such organization in the Fremont area; in its scope and structure. The five-member board of directors (which included James Meyer and James Reeder) was set up to oversee a full range of services, from police and fire protection to street maintenance (which later became the purview of the city government).\nFremont became more industrialized between 1953 and 1962. The first Fremont post office opened in 1956. A boom in high-tech employment in the 1980s to the late 1990s, especially in the Warm Springs District, caused rapid development in the city and linked the city with the Silicon Valley. The Apple factory where the first Mac computer was manufactured was located in Fremont; production ceased in 1993. Other semiconductor and telecommunications firms soon opened in the city, including Cirrus Logic, Asyst Technologies, Mattson Technology, Lam Research, Premisys Communications, and Nextlink California. Approximately 750 high-tech companies had offices, headquarters, or production facilities in Fremont by 1999. These firms included fifteen of the top one hundred fastest-growing public companies in the San Francisco Bay Area and eighteen of the top fifty companies in the East Bay. The high-tech growth in Fremont continues today and is a major industry for the city.\nThe General Motors automotive assembly plant in South Fremont was the town's largest employer, and Fremont was known for its drag strip. In the 1980s, the plant became a joint venture automotive assembly plant of Toyota and General Motors, and was renamed NUMMI. Toyota and NUMMI shut down its operations in early 2010. Part of the plant was acquired in June 2010 by Tesla Motors as its primary production plant, known as the Tesla Factory.\nSolyndra, a solar panel manufacturer, was promoted in 2010 by President Barack Obama as a model for government investment in green technology after his administration approved a $535\u00a0million Department of Energy loan guarantee and the company built a $733\u00a0million state-of-the-art robotic facility, but in 2011 the company filed for Chapter 11 bankruptcy and laid off 1,000 workers. Data storage company Seagate Technology, incorporated in the Republic of Ireland with executive offices in Cupertino, acquired the former Solyndra building, which serves as Seagate's headquarters as of 2020.\nHomeless criminalization.\nIn May 2024, the city council began considering a \"Strategic Plan to Address Homelessness\" in the city, with a five-year time span, in order to reduce the homeless population. Many of the homeless in the city live in their vehicles, but the city's Safe Parking measures of having designated parking lots for homeless people to stay were seen as only a temporary solution. This led to consideration in September 2024 of new rules that would place a ban on camping on public property and the use of large vehicles like RVs in residential areas. This would include a requirement for all parked vehicles in the city to be moved after 72 hours in a location. It was noted by \"San Francisco Chronicle\" reporter Sarah Ravani that the city's previous efforts to actually help the homeless population by expanding housing options, among other methods, had resulted in a 21% reduction over the prior year in the number of people that were homeless without needing municipal punishments to be enacted.\nThese bans were enacted by the city council in February 2025, with additional expansions to the proposed ordinance. The updated version included a $1000 fine and a misdemeanor criminal charge with six months jail time against anyone found \"aiding, abetting, or concealing\" members of the homeless population. The definition of these terms was not clarified in the ordinance. Over a dozen local civil rights groups and community organizations sent a letter petition against the ordinance, noting that the camping provision effectively made it illegal to be homeless anywhere in the city and the added abetting provision made it illegal for anyone to help homeless people by providing shelter themselves. David Bonaccorsi from the Fremont for Everyone organization pointed out that the growing number of jobs in the city due to the expanding tech center had not included an adequate expansion in housing, meaning many of the people obtaining the new jobs had no housing available to purchase in the first place.\nGeography.\nIn 1956, five small, independent towns (Centerville, Niles, Irvington, Mission San Jos\u00e9, and Warm Springs) located between the East Bay rolling hills and the San Francisco Bay were annexed into a single new, incorporated city called Fremont. Six decades later, these places have greatly expanded, are no longer separate communities, and are considered districts or community plan areas of the City of Fremont. The town of Newark was originally slated to join the annex, but ultimately its voters declined since Newark representatives suspected that they would become an industrial district; Newark became its own incorporated city in 1955. Later, Newark annexed a patch of unincorporated land between Mowry Avenue and Stevenson Boulevard, land which is now occupied by Newpark Mall and the surrounding plazas. Since incorporation, Fremont has created six more districts, which it calls \"community plan areas\" for planning purposes. These include Central, North Fremont, South Fremont, and Bayside. The two other districts, Baylands and the Hill Areas, are primarily open space.\nThe area consisting of Fremont and the cities of Newark and Union City is known collectively as the Tri-City Area (different from the adjacent Tri-Valley area encompassing Pleasanton, Dublin, and Livermore).\nCenterville District.\nCenterville was formerly the main town in Washington Township. Centerville is located at . It lies at an elevation of . Centerville was started by George Lloyd who started selling cold beer to stage passengers from a tent in 1850. Capt. George Bond set up a general store and the name Centerville was chosen. The post office opened Centreville post office in 1855 and changed the spelling to Centerville in 1893. The Centerville Pioneer Cemetery contains the burial places of many of the city's founding pioneers.\nCenterville can be traced back to its native American roots. Spanish, Mexican, Italian, Portuguese and Swiss (Swiss Park), peoples were among the early settlers that contributed greatly to the growth of Centerville.\nEarly Centerville was a quiet farming community, which consisted of large Spanish land grants divided into smaller farms. The Freitas Ranch on Thornton Ave was probably the largest of the working farms. There were acres of apricot along with other fruit and nut orchards and large fields of various types of fresh produce.\nAfter President Roosevelt issued Executive Order 9066, which authorized military commanders to exclude \"any or all persons\" from certain areas in the name of national defense, the Western Defense Command began ordering Japanese Americans living on the West Coast to present themselves for \"evacuation\" from the newly created military zones. This included many Centerville farming families.\nCenterville was also a main stop for the early railways. This gave the local farmers a way to quickly get their produce to market. With the access to railway service there was once a large cannery on Baine Ave. west of Fremont Ave. (now Peralta) next to the tracks. In 1959, the cannery was destroyed in the largest fire in Fremont's history. The fire lasted for two days, and effectively put an end to what had been the largest employer in Centerville at the time. The cannery was never rebuilt.\nHousing developments began to appear in the area after World War II. Most of the early housing stood along Fremont Blvd from Decoto Road south to Washington High school, along Thornton Ave from Fremont Blvd west to the Newark city border, and along Peralta Blvd from Fremont Blvd to Niles.\nFor city planning purposes, Centerville was enlarged to encompass most of the north central residential section of Fremont, from Mowry Ave to Decoto Rd, from I-880 to the BART line. This Centerville community plan area includes the sprawling subdivisions, developed in the 1950s and 1960s, of Glenmoor Gardens, bounded by Central Avenue, Fremont Boulevard, Mowry Avenue, and the I-880 freeway. and the Cabrillo Park subdivision bound by Thornton Ave, Fremont Blvd, Decoto Road and the I-880 freeway. Also the Brookvale subdivisions, the Quarry Lakes Regional Recreation Area, and part of Parkmont. The area is served by two high schools, Washington High School established in 1892, which for a long time was the only high school in the area and American High School established in 1972. It also has two middle schools, Centerville Middle School and Thornton Middle School, which now stands on the old main site of the Freitas ranch.\nNiles District.\nThe former town of Niles is physically divided from other parts of Fremont and neighboring Union City by Mission Boulevard (State Route 238) to the east and north, Alameda Creek to the south, Union Pacific Railroad to the west and southeast, and the Quarry Lakes to the southwest. The hills of Niles are lower than those of the area south of the Alameda Creek in Mission San Jose. Old Town Niles features its own library, post office, and silent movie theater as well as a large number of antique and craft stores. Niles is located at . It lies at an elevation of .\nThe community, once called Vallejo Mills, got its name from the Central Pacific Railroad's Niles junction and station, opened in April 1870 as part of the First transcontinental railroad and named after their railroad attorney and stockholder Addison Niles, who became associate justice on the California Supreme Court two years later. A post office was opened at Niles on Vallejo Street in 1873.\nNiles was the West Coast home (1912\u20131916) of one of the first motion picture companies, Essanay Studios. Charlie Chaplin and Broncho Billy Anderson filmed some of their most famous silent movies in Niles and the scenic Niles Canyon that stretches between Niles and Sunol. The nonprofit Niles Essanay Silent Film Museum offers both artifacts of Niles' early years and, each Saturday evening, screenings of early-twentieth-century silent films, many of which were filmed locally.\nThe Niles Canyon Railway runs along Alameda Creek in Niles Canyon and carries passengers on weekend excursions, including a holiday \"train of lights\", which is extremely popular\u00a0\u2013 tickets for these trains typically sell out by early October. The Niles Canyon Railroad has a small but well-maintained collection of historic rail stock.\nPart of historic Niles is Mayhew Spring, also known as Mayhew's Sulphur Spring, which was owned by H.A. Meyhew and located north of the Niles railroad station. In September 1869, four months after the famous golden spike ceremony at Promontory Summit, Utah, the Central Pacific Railroad completed the transcontinental rail link between Sacramento and the San Francisco Bay, with trains switching at the San Jose junction in the canyon. Central Pacific then built a junction in the valley and opened it in April 1870 as Niles.\nAlso part of Niles is 1909 Niles Junction built by the Western Pacific Railroad, located at and situated at an elevation of .\nIrvington District.\nThe Irvington District area, once the town of Irving, has cycled through many name changes over time. In the early 1850s two emancipated black men were traveling with E.L. Beard through California, reputedly in search of a fortune. The former slaves noticed the busy traffic at the crossroads of what is today the \"Five Corners\" intersection. Although now gone, there were two embarcaderos (water crossings) at this area. One of these crossings had a ferry. Realizing the financial opportunity of the area, the former slaves constructed the first building at the cross roads, a tavern with an inn. This tavern was later known as Dave's Saloon. This corner, today the intersection of Fremont and Washington Boulevards, Union and Bay Streets, is now commonly known as \"Five Corners\" or Irvington Square. Irvington Square's marker, Irvington Plaza park, is located at . The inn and several of the other original buildings were demolished by the city of Fremont in the early 1980s.\nIn 1871 Washington College, the first industrial educational institution in California was established in Washington township near the crossroads. As a result, the US Postal Service established a post office called Washington Corners at the college in 1870, which became the name of the settlement on the 1878 Alameda County map of Washington Township.\nIn 1884, realizing the need for a proper town name, local inhabitants selected the name of Irving. The name was chosen in honor of Judge Irving, the local traveling circuit judge of the time. Later, when the railroad came through the area, the published train schedule pamphlets erroneously listed the Irving train depot as \"Irvington.\" The town petitioned the railroad about the error. The railroad company notified the town that it was too costly for them to replace the train schedule pamphlets (over $100,000); and in 1887 following the recommendation, the people of Irving changed the town name to Irvington.\nThe Irvington district has two main neighborhoods: Irvington Woods and the Irvington Square. The neighborhood is ethnically mixed and is primarily working class. For city planning purposes, the Irvington area was enlarged to encompass most of the south central residential section of Fremont, from Auto Mall Parkway to Mowry Avenue, from I-880 to roughly the BART line (excluding the Central District described below). This Irvington community plan area includes the Sundale neighborhood, the South Sundale neighborhood, 28 Palms, Blacow, and Grimmer subdivisions. The area is served by three high schools: Irvington High School, Robertson High School, and John F. Kennedy High School.\nThe Irvingtonian period of North American mammals is named for this district due to the fossil sequence excavated here.\nMission San Jose District.\nAt the time of the California Gold Rush, a boom town grew up around the old Mission, to equip and transport 49ers overland to the gold fields. A post office was opened at Mission San Jose in 1850.\nThe district, like Niles, is surrounded by hills. The hills are higher and steeper than Niles, with the highest points being on the Mission Ridge. Mission San Jose district lies close to the northern two peaks, Mission Peak and Mount Allison. The height of the peaks range from 2,517 to , and they see some snowfall occasionally. Mission Peak is a popular hiking spot and attracts residents from all over the East Bay.\nFremont's community college, Ohlone College, is situated one block away from the mission and serves over 12,000 students.\nMission San Jose has the highest concentration of Asian Americans in Fremont\u00a0\u2013 over 50% of the population as of the 2000 census. The local high school is Mission San Jose High School, ranked as the 93rd best high school in the nation by U.S. News &amp; World Report, as well as 13th in California (as of 2024). The median family income for the Mission San Jose area (ZIP code 94539) exceeded $114,595 in 2005. Owing to an influx of professionals and other affluent families seeking access to the top-performing local public schools, Mission San Jose's median home value reached $831,000 in 2006, earning the community a rank of 237 on Forbes magazine's list of the 500 most affluent communities in the United States.\nMission San Jose.\nNestled at the base of Fremont's rolling hills is the Mission San Jos\u00e9, one of the oldest of the Spanish missions in California, for which this district is named. The church building that exists today is a reconstruction (dedicated in 1985 for daily Mass and tours) of the original 1809 adobe church that was destroyed by the 1868 Hayward-fault earthquake. One side of the original mission quadrangle remains, housing a museum. Mission San Jose is located at ; and lies at an elevation of .\nWarm Springs District.\nThe former town of Warm Springs is located on Rancho Agua Caliente and is so named for the springs that are located there. In early times, there was a settlement called Harrisburgh (also, Harrisburg and Peacock's) a short distance east from the small settlement of Warm Springs. A post office opened in Harrisburgh in 1865 and changed its name to Warm Springs in 1885. The name Harrisburgh commemorated Abram Harris, who settled there in 1858. The name Peacock's commemorated George W. Peacock, its first postmaster. The post office name changed to Warmsprings in 1895 and reverted to Warm Springs in 1950.\nThe Warm Springs district is the southernmost portion of Fremont whose hub is the Warm Springs and Mission Boulevard intersection. It is located at , and lies at an elevation of . Warm Springs has attracted the headquarters of many high-tech companies including Nielsen Norman Group, Lam Research, Corsair and Lexar of the US as well as foreign high-tech companies such as Elitegroup Computer Systems, and Asus. The district is also home to blue-collar industry. The San Jose mission is also present.\nWarm Springs also serves as commercial center for the mainly residential Mission San Jose district, especially since the construction of Pacific Commons, a large, modern regional shopping center. The Oakland Athletics talked about moving their stadium to this area. Warm Springs was home to one of the SF Bay Area's only two coffee houses to employ baristas who wear bikinis, Your Coffee Cups, a concept that's gained some controversy from Bay Area newspapers and news stations. This controversy led to the eventual closing of the business.\nThe BART extension to Warm Springs began construction in 2009 and Warm Springs/South Fremont station opened for service on March 25, 2017.\nCentral district.\nThe central district is surrounded by the Centerville, Niles, Mission San Jose, and Irvington communities. The central district contains retail shopping centers (e.g., the Fremont Hub), the Fremont Bay Area Rapid Transit station, health care centers and Central Park (Lake Elizabeth).\nCity planners envisioned and have begun to develop a mid-density, pedestrian friendly, transit oriented development, bounded by Mowry Ave, Fremont Blvd, Walnut Ave, and Paseo Padre Pkwy referred to as Downtown Fremont. To support enhanced access, one of the central streets, the Capital Avenue extension to Fremont Blvd, was completed in 2016, as the city pursues its plans for a Downtown Fremont.\nMost of Fremont is part of the Laguna Creek Watershed.\nNorth Fremont District.\nNorth Fremont is a primarily residential district surrounded by Union City, Centerville District, Newark, and Coyote Hills Regional Park. It is a growing community that includes the Ardenwood neighborhood, the Lakes and Birds neighborhood, and the Northgate neighborhood. It is the site of the Ardenwood Historic Farm, which has the George Washington Patterson House as one of its highlights, and the Ardenwood Technology Park. A 99 Ranch Market is one of many Asian businesses in the North Fremont District. Thornton Middle School and American High School, which are both physically located in the enlarged Centerville District, also serve as the middle and high school, respectively, for this community.\nSouth Fremont District.\nSouth Fremont is a primarily industrial district, east of Interstate 880 and west of Interstate 680, south of Auto Mall Parkway and north of Brown Rd. The area overlaps with Warm Springs, with which it shares the eponymous BART station. The composition of the area will change, because thousands of residential units were under construction as of 2016. It is sandwiched between the Irvington and Warm Springs community plan areas. It is noted as the site of the Tesla Factory as well as the site of the Warm Springs / South Fremont BART station. In 2022, a pedestrian bridge was built from the BART station to Lopes Court. It cost $41 million.\nBayside Industrial District.\nBayside Industrial is a primarily industrial and commercial district, west of Interstate 880 between Newark and Milpitas.\nHill Area District.\nHill Area is an open land district that forms the eastern edge of Fremont. It is the site of Mission Peak.\nClimate.\nFremont has a warm-summer Mediterranean climate (K\u00f6ppen: \"Csb\") typical of the San Francisco Bay Area. This climate features warm, dry summers and cool, wet winters. Like nearby San Jose, precipitation is fairly low (about per year) because the city lies in the rain shadow of the Santa Cruz Mountains to the west. The highest temperature recorded was on September 6, 2022. The lowest temperature recorded was on December 23, 1990.\nDemographics.\n&lt;templatestyles src=\"US Census population/styles.css\"/&gt;\n2020.\nAccording to the 2020 census estimate, the median income for a household in the city is $142,374. Males have a median household income of $59,274 versus $40,625 for females. The per capita income for the city was $31,411. About 4.5% of the population were below the poverty line, including 5.9% of those under age 18 and 6.2% of those age 65 or over. The most reported detailed ancestries were Indian (29.3%), Chinese (19.1%), Mexican (9.1%), Filipino (6.9%), English (4.9%), and German (4.8%).\n2010.\nThe 2010 United States census reported that Fremont had a population of 214,089. The population density was .\nThe Census reported that 212,438 people (99.2% of the population) lived in households, 969 (0.5%) lived in non-institutionalized group quarters, and 682 (0.3%) were institutionalized.\nThere were 71,004 households, out of which 31,070 (43.8%) had children under the age of 18 living in them, 45,121 (63.5%) were opposite-sex married couples living together, 7,070 (10.0%) had a female householder with no husband present, 3,382 (4.8%) had a male householder with no wife present. There were 2,779 (3.9%) unmarried opposite-sex partnerships, and 444 (0.6%) same-sex married couples or partnerships. 11,576 households (16.3%) were made up of individuals, and 3,697 (5.2%) had someone living alone who was 65 years of age or older. The average household size was 2.99. There were 55,573 families (78.3% of all households); the average family size was 3.36.\nThe population was spread out, with 53,216 people (24.9%) under the age of 18, 15,610 people (7.3%) aged 18 to 24, 66,944 people (31.3%) aged 25 to 44, 56,510 people (26.4%) aged 45 to 64, and 21,809 people (10.2%) who were 65 years of age or older. The median age was 36.8 years. For every 100 females, there were 98.9 males. For every 100 females age 18 and over, there were 96.4 males.\nThere were 73,989 housing units at an average density of , of which 71,004 were occupied, of which 44,463 (62.6%) were owner-occupied, and 26,541 (37.4%) were occupied by renters. The homeowner vacancy rate was 1.3%; the rental vacancy rate was 4.5%. 136,606 people (63.8% of the population) lived in owner-occupied housing units and 75,832 people (35.4%) lived in rental housing units.\nFremont has a large Deaf community, in large part because it is home of the Northern California campus of the California School for the Deaf. The school district is called the Fremont Unified School District which also serves parts of Union City and Hayward.\nEconomy.\nCompanies headquartered in Fremont include Antec Inc, Electronics for Imaging, Ikanos Communications, Lam Research, Seagate Technology, Fremont Bank, Nielsen Norman Group, Oplink Communications, SYNNEX, S3 Graphics, Tailored Brands and DCKAP.\nTop employers.\nAccording to the city's June 2024 Annual Comprehensive Financial Report, the top employers in the city are:\nCulture and recreation.\nThe City of Fremont has been a Tree City USA since 1996. There are approximately 55,000 trees in city parks, streets, and landscaped boulevard areas. The city operates the Olive Hyde Art Gallery, adjacent to Mission San Jose, which has featured Bay Area artists such as Wendy Yoshimura, the California Society of Printmakers and the Etsy collective. The public gallery is housed in a former home of Olive Hyde, a descendant of early San Francisco Mayor George Hyde.\nOther cultural, historical, or scientific landmarks include: Fremont Central Park and Lake Elizabeth, Ardenwood Historic Farm, California Nursery Historical Park, Don Edwards National Wildlife Refuge, Mission Peak Regional Preserve, Niles Essanay Silent Film Museum, Washington Township Museum of Local History, Quarry Lakes Regional Recreation Area, Shinn Park and Arboretum, and Coyote Hills Regional Park.\nMedia.\nFounded in 2002, the \"Tri-City Voice\" serves Fremont and the nearby cities of Union City and Newark. The weekly is based in the Fremont, and publishes the city's legal notices.\nGovernment.\nAn elected mayor heads Fremont city government for a four-year term. The mayor chairs the city council, which has four elected council members in addition to the mayor. Two new seats have been added to the council beginning in 2018, for a total of seven seats when district-based elections are phased in. The council adopts the city's budget, and decides major policies. The city council appoints a city manager and city attorney. The city manager hires city staff and manages day-to-day business. Advisory bodies work with the city council on some issues, to facilitate the council's final decisions. The mayor appoints advisory body members, subject to the approval of a majority of the council. Most members serve four-year terms of office without pay, with the exception of planning commissioners.\nThe City of Fremont directly provides services related to public safety, land use regulation, infrastructure maintenance, parks and recreation, and local social services. To provide these services, the city government is organized into 22 departments, from Animal Services to Transportation Engineering.\nAccording to a 2009 financial report, city revenues were $280 million, expenditures $200 million, assets $1,200 million, cash and investments $340 million, and liabilities $260 million. As of 2015, the annual budget was $160 million and the city had 800 employees.\nThe city council has adopted a balanced budget by July 1 of each year. Budget problems have in some past years involved cuts in services, reductions in city staffing and wage concessions by labor unions.\nSpecial districts provide water and sewer services for the city: Alameda County Water District and Union Sanitary District. A private contractor, Allied Waste, provides garbage collection and recycling services to the city.\nGrand jury investigation of record-keeping.\nIn 2015, a grand jury found that the city government did not comply with state law on public records, by deleting most emails after 30 days instead of the required two years. All emails were automatically labeled as \"unsaved drafts\" unless manually designated for retention. The city did not keep any record of councilmember emails, which used fremont.gov addresses and were relayed on to councilmembers' private email accounts. Though city officials held that automatic deletion would reduce data storage costs, the grand jury determined that the cost of complying with the state law would not be significant.\nDistrict-based elections.\nThe city phased in district-based instead of at-large elections for all but one seat on the city council, beginning in November 2018. Two new seats were added, from five seats to seven. Six of the seats required residence inside a district, while the seat held by the mayor remained at large. The council chose the new district boundaries in June 2017, a controversial vote that drew accusations of gerrymandering to favor two of the incumbents.\nThe districting was forced by the threat of a legal action from a group claiming that Latino minorities who were 14 percent of the population had not been adequately represented. Few or no Latinos were elected to the council during 1956\u20132017. Some claimed that the results of precinct voting may have been polarized along racial lines.\nPolitics.\nAccording to the California Secretary of State, as of February 20, 2024, the city of Fremont has 118,717 registered voters. Of those, 59,594 (50.19%) are registered Democrats, 17,021 (14.34%) are registered Republicans, and 37,095 (31.24%) have declined to state a political party.\nEducation.\nPrimary and secondary schools.\nThe Fremont Unified School District has five high schools for grades 9\u201312: American, Irvington, Kennedy, Mission San Jose and Washington. The 5,000 seat Tak Fudenna Stadium serves all five high schools as a venue for football, track, soccer and high school graduation ceremonies. These five high schools, along with James Logan High School in Union City and Newark Memorial High School in Newark, make up the Mission Valley Athletic League (M.V.A.L.).\nThe district has a continuation high school (Robertson); two independent study programs (Vista and COIL); an adult school; five middle schools for grades 6\u20138 (Centerville, Hopkins, Horner, Thornton and Walters); and\n29 elementary schools. The district operates the Mission Valley Regional Occupational Program jointly with Newark and New Haven Unified School Districts.\nFor the year 2019, William Hopkins JHS, Mission San Jose HS, John F. Kennedy HS, and American HS all received the California Distinguished Schools Award, administered by the California Department of Education.\nFremont Christian School and Averroes High School in Fremont are not part of FUSD. California School for the Deaf, Fremont serves Northern California and shares a campus with the statewide California School for the Blind.\nColleges and universities.\nThe Ohlone Community College District operates Ohlone College in Fremont, and a smaller campus in Newark. The University of Phoenix Bay Area Campus and San Francisco Bay University offers undergraduate and graduate programs in technology and management areas.\nPublic libraries.\nThe Alameda County Library is headquartered in Fremont. The Fremont Main Library is the largest branch with the highest circulation of the Alameda County Library, and shares its building with the Alameda County Library Administration. It has the Maurice Marks Center for Local and California History, and the Fukaya public meeting room. Alameda County Library has other branch libraries in Centerville, Irvington and Niles.\nTransportation.\nFremont is served by Interstate 880 (Nimitz Freeway) and Interstate 680 (Sinclair Freeway). Though they do not intersect, they are connected in the Warm Springs district via a very busy one-mile segment of Mission Boulevard which is SR 262. In addition, it is served by SR 84 and the segment of Mission Boulevard which is SR 238. The city is the eastern terminus of the Dumbarton Bridge.\nElevated sound levels exist along Interstate 880; Caltrans and the city have sought to mitigate sound levels by constructing noise barriers.\nRegional rail transportation is provided by BART and the Altamont Corridor Express (ACE). Fremont's BART station once served as the southernmost terminus for the BART system; a BART extension to the Warm Springs / South Fremont station opened on March 25, 2017. A southward BART extension into Santa Clara county and the Milpitas and Berryessa/North San Jos\u00e9 stations opened on June 13, 2020; a further BART extension to downtown San Jose is in progress. The Fremont-Centerville station provides a stopping point for ACE service, which travels from Stockton to San Jose, as well as for Amtrak's \"Capitol Corridor\" service. Bus service is provided by AC Transit locally.\nFuture rail.\nCaltrain is undertaking environmental and engineering review for a planned Dumbarton Rail Corridor between the Peninsula and Alameda County. It would add Caltrain stations to Union City, Fremont-Centerville, Newark, and Menlo Park/East Palo Alto.\nNotable people.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nSister cities.\nFremont was formerly a sister city to Elizabeth, South Australia until Elizabeth merged with Munno Para to form the City of Playford in 1997.\nCurrently, Fremont is twinned with the following cities:\nReferences.\nSpecific\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nGeneral"}
{"id": "52827", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=52827", "title": "Volumetric heat capacity", "text": "Thermal quality\nThe volumetric heat capacity of a material is the heat capacity of a sample of the substance divided by the volume of the sample. It is the amount of energy that must be added, in the form of heat, to one unit of volume of the material in order to cause an increase of one unit in its temperature. The SI unit of volumetric heat capacity is joule per kelvin per cubic meter, J\u22c5K\u22121\u22c5m\u22123.\nThe volumetric heat capacity can also be expressed as the specific heat capacity (heat capacity per unit of mass, in J\u22c5K\u22121\u22c5kg\u22121) times the density of the substance (in kg/L, or g/mL). It is defined to serve as an intensive property.\nThis quantity may be convenient for materials that are commonly measured by volume rather than mass, as is often the case in engineering and other technical disciplines. The volumetric heat capacity often varies with temperature, and is different for each state of matter. While the substance is undergoing a phase transition, such as melting or boiling, its volumetric heat capacity is technically infinite, because the heat goes into changing its state rather than raising its temperature.\nThe volumetric heat capacity of a substance, especially a gas, may be significantly higher when it is allowed to expand as it is heated (volumetric heat capacity \"at constant pressure\") than when is heated in a closed vessel that prevents expansion (volumetric heat capacity \"at constant volume\").\nIf the amount of substance is taken to be the number of moles in the sample (as is sometimes done in chemistry), one gets the molar heat capacity (whose SI unit is joule per kelvin per mole, J\u22c5K\u22121\u22c5mol\u22121).\nDefinition.\nThe volumetric heat capacity is defined as\nformula_1\nwhere formula_2 is the volume of the sample at temperature formula_3, and formula_4 is the amount of heat energy needed to raise the temperature of the sample from formula_3 to formula_6. This parameter is an intensive property of the substance.\nSince both the heat capacity of an object and its volume may vary with temperature, in unrelated ways, the volumetric heat capacity is usually a function of temperature too. It is equal to the specific heat formula_7 of the substance times its density (mass per volume) formula_8, both measured at the temperature formula_3. Its SI unit is joule per kelvin per cubic meter (J\u22c5K\u22121\u22c5m\u22123).\nThis quantity is used almost exclusively for liquids and solids, since for gases it may be confused with the \"specific heat capacity at constant volume\", which generally has very different values. International standards now recommend that \"specific heat capacity\" always refer to capacity per unit of mass. Therefore, the word \"volumetric\" should always be used for this quantity.\nHistory.\nDulong and Petit predicted in 1818 that the product of solid substance density and specific heat capacity (\u03c1cp) would be constant for all solids. This amounted to a prediction that volumetric heat capacity in solids would be constant. In 1819 they found that volumetric heat capacities were not quite constant, but that the most constant quantity was the heat capacity of solids adjusted by the presumed weight of the atoms of the substance, as defined by Dalton (the Dulong\u2013Petit law). This quantity was proportional to the heat capacity per atomic weight (or per molar mass), which suggested that it is the heat capacity \"per atom\" (not per unit of volume) which is closest to being a constant in solids.\nEventually it became clear that heat capacities per particle for all substances in all states are the same, to within a factor of two, so long as temperatures are not in the cryogenic range.\nTypical values.\nThe volumetric heat capacity of solid materials at room temperatures and above varies widely, from about 1.2\u00a0MJ\u22c5K\u22121\u22c5m\u22123 (for example bismuth) to 3.4\u00a0MJ\u22c5K\u22121\u22c5m\u22123 (for example iron). This is mostly due to differences in the physical size of atoms. Atoms vary greatly in density, with the heaviest often being more dense, and thus are closer to taking up the same average volume in solids than their mass alone would predict. If all atoms \"were\" the same size, molar and volumetric heat capacity would be proportional and differ by only a single constant reflecting ratios of the atomic molar volume of materials (their atomic density). An additional factor for all types of specific heat capacities (including molar specific heats) then further reflects degrees of freedom available to the atoms composing the substance, at various temperatures.\nFor most liquids, the volumetric heat capacity is narrower, for example octane at 1.64\u00a0MJ\u22c5K\u22121\u22c5m\u22123 or ethanol at 1.9. This reflects the modest loss of degrees of freedom for particles in liquids as compared with solids.\nHowever, water has a very high volumetric heat capacity, at 4.18\u00a0MJ\u22c5K\u22121\u22c5m\u22123, and ammonia is also fairly high: 3.3\u00a0MJ\u22c5K\u22121\u22c5m\u22123.\nFor gases at room temperature, the range of volumetric heat capacities per atom (not per molecule) only varies between different gases by a small factor less than two, because every ideal gas has the same molar volume. Thus, each gas molecule occupies the same mean volume in all ideal gases, regardless of the type of gas (see kinetic theory). This fact gives each gas molecule the same effective \"volume\" in all ideal gases (although this volume/molecule in gases is far larger than molecules occupy on average in solids or liquids). Thus, in the limit of ideal gas behavior (which many gases approximate except at low temperatures and/or extremes of pressure) this property reduces differences in gas volumetric heat capacity to simple differences in the heat capacities of individual molecules. As noted, these differ by a factor depending on the degrees of freedom available to particles within the molecules.\nVolumetric heat capacity of gases.\nLarge complex gas molecules may have high heat capacities per mole (of molecules), but their heat capacities per mole of atoms are very similar to those of liquids and solids, again differing by less than a factor of two per mole of atoms. This factor of two represents vibrational degrees of freedom available in solids vs. gas molecules of various complexities.\nIn monatomic gases (like argon) at room temperature and constant volume, volumetric heat capacities are all very close to 0.5\u00a0kJ\u22c5K\u22121\u22c5m\u22123, which is the same as the theoretical value of RT per kelvin per mole of gas molecules (where R is the gas constant and T is temperature). As noted, the much lower values for gas heat capacity in terms of volume as compared with solids (although more comparable per mole, see below) results mostly from the fact that gases under standard conditions consist of mostly empty space (about 99.9% of volume), which is not filled by the atomic volumes of the atoms in the gas. Since the molar volume of gases is very roughly 1000 times that of solids and liquids, this results in a factor of about 1000 loss in volumetric heat capacity for gases, as compared with liquids and solids. Monatomic gas heat capacities per atom (not per molecule) are decreased by a factor of 2 with regard to solids, due to loss of half of the potential degrees of freedom per atom for storing energy in a monatomic gas, as compared with regard to an ideal solid. There is some difference in the heat capacity of monatomic vs. polyatomic gasses, and also gas heat capacity is temperature-dependent in many ranges for polyatomic gases; these factors act to modestly (up to the discussed factor of 2) increase heat capacity per atom in polyatomic gases, as compared with monatomic gases. Volumetric heat capacities in polyatomic gases vary widely, however, since they are dependent largely on the number of atoms per molecule in the gas, which in turn determines the total number of atoms per volume in the gas.\nThe volumetric heat capacity is defined as having SI units of J/(m3\u22c5K). It can also be described in Imperial units of BTU/(ft3\u22c5\u00b0F).\nVolumetric heat capacity of solids.\nSince the bulk density of a solid chemical element is strongly related to its molar mass (usually about 3\"R\" per mole, as noted above), there exists noticeable inverse correlation between a solid's density and its specific heat capacity on a per-mass basis. This is due to a very approximate tendency of atoms of most elements to be about the same size, despite much wider variations in density and atomic weight. These two factors (constancy of atomic volume and constancy of mole-specific heat capacity) result in a good correlation between the \"volume\" of any given solid chemical element and its total heat capacity. Another way of stating this, is that the volume-specific heat capacity (volumetric heat capacity) of solid elements is roughly a constant. The molar volume of solid elements is very roughly constant, and (even more reliably) so also is the molar heat capacity for most solid substances. These two factors determine the volumetric heat capacity, which as a bulk property may be striking in consistency. For example, the element uranium is a metal which has a density almost 36 times that of the metal lithium, but uranium's volumetric heat capacity is only about 20% larger than lithium's.\nSince the volume-specific corollary of the Dulong\u2013Petit specific heat capacity relationship requires that atoms of all elements take up (on average) the same volume in solids, there are many departures from it, with most of these due to variations in atomic size. For instance, arsenic, which is only 14.5% less dense than antimony, has nearly 59% more specific heat capacity on a mass basis. In other words; even though an ingot of arsenic is only about 17% larger than an antimony one of the same mass, it absorbs about 59% more heat for a given temperature rise. The heat capacity ratios of the two substances closely follows the ratios of their molar volumes (the ratios of numbers of atoms in the same volume of each substance); the departure from the correlation to simple volumes in this case is due to lighter arsenic atoms being significantly more closely packed than antimony atoms, instead of similar size. In other words, similar-sized atoms would cause a mole of arsenic to be 63% larger than a mole of antimony, with a correspondingly lower density, allowing its volume to more closely mirror its heat capacity behavior.\nVolumetric heat capacity of liquids.\nThe volumetric heat capacity of liquids could be measured from the thermal conductivity and thermal diffusivity correlation. The volumetric heat capacity of liquids could be directly obtained during thermal conductivity analysis using thermal conductivity analyzers that use techniques like the transient plane source method.\nConstant volume and constant pressure.\nFor gases it is necessary to distinguish between volumetric heat capacity at constant volume and volumetric heat capacity at constant pressure, which is always larger due to the pressure\u2013volume work done as a gas expands during heating at constant pressure (thus absorbing heat which is converted to work). The distinctions between constant-volume and constant-pressure heat capacities are also made in various types of specific heat capacity (the latter meaning either mass-specific or mole-specific heat capacity).\nThermal inertia.\nThermal inertia is a term commonly used to describe the observed delays in a body's temperature response during heat transfers. The phenomenon exists because of a body's ability to both store and transport heat relative to its environment. Larger values of volumetric heat capacity, as may occur in association with thermal effusivity, typically yield slower temperature responses.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52828", "revid": "1613900", "url": "https://en.wikipedia.org/wiki?curid=52828", "title": "Lindsay Davenport", "text": "American former tennis player (born 1976)\nLindsay Ann Davenport Leach (born June 8, 1976) is an American former professional tennis player. She was ranked as the world No. 1 in women's singles by the Women's Tennis Association (WTA) for 98 weeks (including as the year-end No. 1 four times), and as the world No. 1 in women's doubles for 32 weeks. Davenport won 55 WTA Tour-level singles titles, including three majors (the 1998 US Open, 1999 Wimbledon Championships, and 2000 Australian Open), the gold medal at the 1996 Atlanta Olympics, and the 1999 Tour Finals. She also won 38 doubles titles, including three majors (the 1996 French Open, 1997 US Open, and the 1999 Wimbledon Championships) and three consecutive Tour Finals.\nIn 2005, \"TENNIS Magazine\" ranked Davenport as the 29th-greatest player (male or female) of the preceding 40 years. She amassed career-earnings of US$22,166,338; formerly first in the all-time rankings. Davenport was inducted into the International Tennis Hall of Fame in 2014.\nEarly life.\nLindsay Davenport is the daughter of Wink Davenport, who was a member of the U.S. volleyball team at the 1968 Summer Olympics in Mexico City, and Ann L. Davenport, the president of the Southern California Volleyball Association. Davenport was born to an athletic family. While her two older sisters, Leiann and Shannon, played volleyball, Lindsay began playing tennis at age six. She was coached by Robert Lansdorp, who had previously coached Tracy Austin. She attended Chadwick School in Palos Verdes Peninsula, California. At age 16, her family moved to Murrieta, California, where she attended and graduated from Murrieta Valley High School, and she began to work with, among others, Robert Van't Hof. At age 16, Davenport joined the United States Tennis Association junior national team. She had a rapid growth spurt \u2014 about six inches in two years \u2014 which affected her coordination, but did not hinder her performance. She excelled at junior level competitions and swept the singles and doubles titles at the National Girls' 18s and Clay Court Championships in 1991 and won the Junior U.S. Open in 1992.\nCareer.\n1990\u20131993.\nShe won the girls' 16s singles at the prestigious Ojai Tennis Tournament in 1990.\nWhile Davenport's first play dated back to 1991, she officially became a professional two years after her first professional-level matches. Davenport's doubles success in 1993 was a 17\u201316 record while she reached the top 100 in doubles rankings. She reached the third round at the 1993 Australian Open doubles competition with Chanda Rubin. Davenport entered the top 20, despite coming into her first tournament that year ranked no. 162. She qualified for the 1993 Australian Open, reaching the third round before falling to Mary Pierce.\nAt the Indian Wells Masters, Davenport reached the quarterfinals ranked no. 99, but lost to 7th-ranked and future doubles partner Mary Joe Fern\u00e1ndez. Later that year, Davenport won her first Tier III title at the WTA Swiss Open where she beat Nicole Bradtke in three sets in the finals. She reached the third round at the 1993 Wimbledon Championships, and at the 1993 US Open, the American reached the fourth round ranked no. 24. 1993 is also notable because it was the one time she faced Martina Navratilova, falling in three sets, 6\u20131, 3\u20136, 5\u20137, in the Oakland semifinals.\n1994.\nDavenport won the first professional tournament she entered in Brisbane, Australia. At the Australian Open, she reached her first Grand Slam quarterfinal, defeating no. 5 Mary Joe Fern\u00e1ndez in the fourth round, before losing in the quarterfinals to top-ranked Steffi Graf. Davenport then reached the semifinals at Indian Wells, California and Miami and won the title in Lucerne. At Wimbledon, Davenport reached her second Grand Slam quarterfinal. Ranked ninth, Davenport defeated tenth ranked Gabriela Sabatini, before losing to third ranked Conchita Mart\u00ednez, who went on to win the tournament. In November, she reached her first WTA Tour Championship final, losing to Sabatini.\nIn doubles, Davenport won Indian Wells with Lisa Raymond and reached the French Open doubles final with Raymond, where they lost to Gigi Fern\u00e1ndez and Natasha Zvereva. Davenport teamed with Arantxa S\u00e1nchez Vicario to win the title in Oakland, defeating Gigi Fern\u00e1ndez and Martina Navratilova in the final.\nIn December 1994, Davenport hired Craig Kardon as her coach.\n1995.\nDavenport started the year by reaching the final of the tournament in Sydney, where she lost to Gabriela Sabatini. Davenport again reached the Australian Open quarterfinals and the following week, lost to Kimiko Date in the final of the tournament in Tokyo.\nOn clay, Davenport won the tournament in Strasbourg on her first attempt, defeating Kimiko Date in the final. Date, however, turned the tables at the French Open, defeating Davenport in the fourth round.\nAt Wimbledon, Davenport was upset in the fourth round by Mary Joe Fern\u00e1ndez. At the final Grand Slam tournament of the year, the US Open, Davenport was again upset, this time in the second round by Zina Garrison Jackson.\nIn doubles, Davenport and Jana Novotn\u00e1 started the year by winning the tournament in Sydney. Davenport and Lisa Raymond then lost in the Australian Open semifinals to the top seeded team of Gigi Fern\u00e1ndez and Natasha Zvereva. Davenport teamed with Nicole Arendt to reach the French Open semifinals, where they lost to the top seeded team of Novotn\u00e1 and Arantxa S\u00e1nchez Vicario. At Wimbledon, Davenport and Raymond, the fourth seeded team, were upset in the first round. At the US Open, Davenport and Raymond were again the fourth seeded team and were upset in the third round by fifteenth seeded Lori McNeil and Helena Sukov\u00e1. In other tournaments, Davenport and Raymond won in Indian Wells, and Davenport and Mary Joe Fern\u00e1ndez won in Tokyo (the non-Tier I tournament) and Strasbourg.\nAfter her one-year contract with Kardon had ended, Davenport hired Robert Van't Hof as her full-time coach.\n1996.\nDavenport's year began with a runner-up finish in Sydney. She was a quarterfinalist at the Australian Open. Davenport then reached the semifinals of the tournament in Indian Wells, California, where she lost to Steffi Graf.\nOn clay, Davenport won the Strasbourg tournament and reached the French Open quarterfinals, losing to Conchita Mart\u00ednez.\nDuring the summer, Davenport won the tournament in Los Angeles, defeating Graf for the first time in her career in the semifinals, before defeating Anke Huber in the final. Davenport then won the gold medal at the Summer Olympics, defeating Mary Joe Fern\u00e1ndez in the semifinal and Arantxa S\u00e1nchez Vicario in the final.\nIn doubles, Davenport teamed with Mary Joe Fern\u00e1ndez to win the tournament in Sydney, before losing in the final of the Australian Open to Chanda Rubin and S\u00e1nchez Vicario. Davenport and Fernandez then won the French Open doubles title, defeating Gigi Fern\u00e1ndez and Natasha Zvereva in the final. The two also won the tournament in Oakland and the year-end Chase Championships together. Davenport partnered with Zvereva to win the tournament in Los Angeles.\n1997.\nDavenport lost in the fourth round of the Australian Open to Kimberly Po. She then won the tournaments in Oklahoma City and Indian Wells, California for the first time in her career.\nDavenport began her clay-court season by winning the tournament in Amelia Island, Florida. However, she lost to Iva Majoli, the eventual champion, in the fourth round at the French Open, despite being up a set and 4\u20130 in the second set.\nAt Wimbledon, Davenport lost to Denisa Chl\u00e1dkov\u00e1 in the second round. She then lost to Monica Seles in the final at Los Angeles, after beating top-ranked Martina Hingis in the semifinals. After winning in Atlanta, Davenport reached her first grand slam semifinal at the US Open, losing to Hingis. Davenport won the titles in Z\u00fcrich and Chicago, before losing the Philadelphia final to Hingis in a third set tie-break.\nIn doubles, Davenport was the runner-up in Sydney with Natasha Zvereva and at the Australian Open with Lisa Raymond. She won the US Open with Czech partner Jana Novotn\u00e1. Davenport's other doubles titles were in Tokyo, Indian Wells, Amelia Island, and Berlin.\n1998.\nDavenport started 1998 by reaching the singles semifinals of the Australian Open, which was her second consecutive Grand Slam singles semifinal. At the tournament in Tokyo, Davenport, ranked second, defeated Martina Hingis, ranked first, in the final. Davenport then lost in the Indian Wells, California, final to Hingis, after defeating Steffi Graf, and in Miami, she fell in the quarterfinals to Anna Kournikova. At the French Open, Davenport defeated defending champion Iva Majoli in the quarterfinals, before losing to Arantxa S\u00e1nchez Vicario in the semifinals. Davenport won titles in San Diego, Stanford, and Los Angeles.\nDavenport's next victory on tour was her first Grand Slam singles title at the 1998 US Open, defeating fifth-ranked Venus Williams in the semifinals and top-ranked Hingis in the final. She became the first American-born woman to win the U.S. Open since Chris Evert in 1982.\nDavenport then won Z\u00fcrich and lost to 17th-ranked Graf in Philadelphia despite attaining the no. 1 ranking. Davenport finished the year with a loss to Hingis in the final of the Chase Championships .\nIn doubles, Davenport reached the final of the 1998 Australian Open with Natasha Zvereva, where they lost to the wildcard team of Hingis and Mirjana Lu\u010di\u0107. Davenport and Zvereva lost to Hingis and Lu\u010di\u0107 again in the Tokyo final, and then won both Indian Wells and Berlin, both times defeating Alexandra Fusai and Nathalie Tauziat in the final.\nDavenport and Zvereva then lost to Hingis and Jana Novotn\u00e1 in the French Open, Wimbledon, and US Open doubles finals. Davenport won San Diego and Stanford with Zvereva and lost in the US Open doubles final. Davenport won Filderstadt, and then the year-end doubles championship with Zvereva, defeating Fusai and Tauziat in three sets. In 1998, Davenport reached all four Grand Slam doubles finals with Zvereva, losing to teams that included Hingis all four times.\n1999.\nDavenport started 1999 by winning the Sydney singles final and reaching the Australian Open singles semifinal, before losing to Am\u00e9lie Mauresmo. She teamed with Natasha Zvereva to reach the doubles final, before losing to Martina Hingis and Anna Kournikova.\nAt the Toray Pan Pacific Open in Tokyo, Davenport and Zvereva beat Hingis and Jana Novotn\u00e1, to whom they had lost in three of the four 1998 Grand Slam doubles finals. Davenport's second singles title of the year was at Madrid where she defeated lucky loser Paola Su\u00e1rez in the final.\nAt Roland Garros, she reached the quarterfinals losing to Steffi Graf. Along the way, she defeated qualifier and future four-times French Open champion Justine Henin in the second round. Davenport's next tournament championship was at Wimbledon. In the final, she defeated Steffi Graf in Graf's last career Grand Slam match. Davenport also won the doubles title at Wimbledon with Corina Morariu, defeating Mariaan de Swardt and Elena Tatarkova in the final.\nAfter Wimbledon, Davenport won the singles and doubles titles in Stanford and won San Diego in doubles with Morariu over Serena and Venus Williams in the final, the only doubles final the sisters have ever lost in their playing careers. She lost the US Open semifinal to eventual champion Serena Williams. To close the year, Davenport won two additional singles and the Chase Championships with a victory over Hingis in the final.\n2000.\nDavenport started the year by losing the Sydney singles final against Am\u00e9lie Mauresmo.\nHer next event was the 2000 Australian Open, which she won in singles without the loss of a set. Seeded second, Davenport defeated top-seeded Martina Hingis in the final. She and Corina Morariu lost in the doubles semifinals to Hingis and Mary Pierce. Two events later, at the Indian Wells, California tournament, Davenport again defeated Hingis and won the doubles title with Morariu over Anna Kournikova and Natasha Zvereva in the final. Hingis defeated Davenport in the Miami final.\nAt the French Open, Davenport was upset by the 22nd-ranked Dominique Van Roost in three sets in the first round. Van Roost again beat her at The Hastings Direct International Championships in Eastbourne.\nDavenport reached the Wimbledon final, where she was beaten by Venus Williams. Davenport once again lost to Venus in the Stanford final and to Serena Williams in the Los Angeles final. She lost in the US Open final to Venus.\nAfter losing to Hingis in the Z\u00fcrich final, Davenport won two consecutive titles in Linz, defeating Venus Williams, and in Philadelphia. She upset Arantxa S\u00e1nchez Vicario at the Chase Championships by serving her all love games, then helped the United States win the 2000 Fed Cup over Spain.\n2001.\nDavenport was at least a quarterfinalist in all seventeen of her singles events. She won seven singles titles, with victories in Tokyo, Scottsdale, Eastbourne, Los Angeles, Filderstadt, Z\u00fcrich, and Linz. After clinching the year-end number one ranking in a semifinal win over Clijsters (where she injured her knee at the end of the match), she withdrew in the final of the year-end Chase Championships against Serena Williams. She was a semifinalist at the Australian Open, a semifinalist at Wimbledon, and a quarterfinalist at the US Open. She lost in the Australian Open doubles final with Morariu to Venus and Serena Williams. She teamed with Lisa Raymond to win the doubles titles in Filderstadt and Z\u00fcrich.\n2002.\nDavenport did not win a singles title in 2002. She missed the Australian Open, French Open, and Wimbledon. She played her first singles event in July, losing in the Stanford semifinals to Kim Clijsters. Davenport then reached the semifinals of the Tier I San Diego tournament, where she lost to Venus Williams. At her next tournament in Los Angeles, she lost in the final to Chanda Rubin. She then lost to Venus in New Haven and to Serena Williams in the US Open semifinals. She reached two more finals during 2002, losing in Moscow to Magdalena Maleeva and in Z\u00fcrich to Patty Schnyder. At the year-end Chase Championships, Davenport lost to Monica Seles, after holding seven match points, her third loss to Seles, having a match point opportunity on all three occasions.\nDavenport played her first doubles tournament of the year in Filderstadt in October, where she partnered with Lisa Raymond to win the title. Her relationship with Coach Robert Van't Hof ended.\n2003.\nDavenport started the year by hiring Rick Leach as her coach, but this association lasted only a short time. She then hired Adam Peterson. She reached the final of the tournament in Sydney, where she lost to Kim Clijsters. She then reached the fourth round of the Australian Open, where she lost to Justine Henin. Davenport then won in Tokyo and lost in the Indian Wells, California final to Clijsters. At the remaining Grand Slam tournaments of the year, she lost in the French Open fourth round, the Wimbledon quarterfinals, and the US Open semifinals. She was the runner-up at tournaments in Amelia Island, Florida, Los Angeles, and New Haven.\nDavenport and Lisa Raymond reached the doubles semifinals of the Australian Open, where they lost to Serena Williams and Venus Williams. Davenport and Raymond won Indian Wells, defeating Clijsters and Ai Sugiyama. Davenport and Raymond also won in Amelia Island, over Paola Su\u00e1rez and Virginia Ruano Pascual, and in Eastbourne, over Jennifer Capriati and Mag\u00fci Serna. Davenport and Raymond lost in the Wimbledon semifinals to Clijsters and Sugiyama.\n2004.\nDavenport won a tour-high seven titles, including four straight during the summer (Stanford, Los Angeles, San Diego, and Cincinnati). She also had the most match wins on the WTA Tour, with 63. She finished the year ranked first for the third time in her career. She defeated Venus and Serena Williams for the first time since 2000, which she said instilled belief in her that she could win more Grand Slam tournaments.\n2005.\nDavenport's success continued into 2005, when she reached her first Grand Slam final, at the Australian Open, since the 2000 US Open; she fell to Serena Williams in three sets.\nAt the tournament in Indian Wells, California, in March, Davenport made history by defeating world no. 3 Maria Sharapova, 6\u20130, 6\u20130. It marked the first time that a player ranked in the top 3 had ever been \"shut out\" on the WTA tour and was the first time Sharapova had failed to win a game during a match. This turned out to be Davenport's only career victory against Sharapova.\nIn April, she won the Bausch &amp; Lomb Championships in Amelia Island, Florida for the third time, defeating Silvia Farina Elia in the final. In the quarterfinals of that tournament, Davenport defeated Venus Williams for the fourth consecutive time.\nDavenport bypassed the European clay-court season and went to the French Open without having played a professional competitive match for weeks. She confounded expectations with a run to the quarterfinals on her least favourite surface, including a come-from-behind victory over Kim Clijsters in the fourth round. Davenport lost to eventual runner-up Mary Pierce.\nAt Wimbledon, Davenport was the top seed and made it easily to the fourth round, where she was tested again by Clijsters, but came through in three sets to win her second successive match against the Belgian. Davenport then reached the semifinals, where her match against Am\u00e9lie Mauresmo was interrupted by rain and was completed over the course of two days. Davenport eventually defeated Mauresmo and faced 14th-seeded Venus Williams in an all-American final. Davenport led most of the way, as she served for the match at 6\u20135 in the second set, and had a match point at 5\u20134 in the third set. Williams went on to win, 4\u20136, 7\u20136, 9\u20137, in the longest (in terms of time) women's Wimbledon final in history. In that match, Davenport sustained a serious back injury while leading 4\u20132 (40\u201315) in the final set, although she acknowledged after the match that the injury did not cause her defeat and that Williams was the superior mentally strong player on the day. The injury forced Davenport to withdraw from Fed Cup competition. She returned to the tour at the Stanford tournament. After reinjuring her back in a warmup just hours before her match, Davenport retired while trailing 0\u20135 in the first set. This back injury then forced her to withdraw from other hard-court events in San Diego and Los Angeles.\nDavenport returned to the WTA Tour in August, winning her comeback tournament in New Haven without dropping a set. Davenport then reached the quarterfinals of the US Open, where she held a match point on Elena Dementieva, before falling in the third set tie-break. Davenport briefly lost the no. 1 ranking following the event.\nAfter the loss at the US Open, Davenport captured the title in Bali without dropping a set, and subsequently qualified for the WTA Tour Championships. She then won the title in Filderstadt, defeating Mauresmo in the final for the second consecutive year. The win made her only the tenth woman ever to win 50 career WTA singles titles.\nIn Z\u00fcrich, Davenport saved two match points while defeating Daniela Hantuchov\u00e1. The win assured Davenport of recapturing the world no. 1 ranking from Sharapova the following week. In the final, Davenport defeated sixth seeded Patty Schnyder for her fourth title in Z\u00fcrich and her sixth title of 2005, second only to Clijsters's nine. It was also the first time Davenport had saved match points en route to a victory since the 1999 U.S. Open. The Z\u00fcrich title left her with eleven Tier I titles, second among active players.\nDavenport was a semifinalist at the WTA tour year-end championships (losing to Pierce in two tie-breaks), which ensured that she finished the year ranked no. 1. 2005 was the fourth time that Davenport ended the year ranked No. 1, joining Steffi Graf, Martina Navratilova, and Chris Evert as the only female players to end a year ranked first at least four times.\nIn 2005, TENNIS Magazine ranked Davenport 29th in its list of the 40 greatest players of the tennis era.\n2006.\nOn February 22, 2006, Davenport became just the eighth woman in WTA history to win 700 singles matches, when she handed out her fourth career \"double bagel\", defeating Elena Likhovtseva in the second round of the Dubai tournament.\nAt the March tournament in Indian Wells, California, Davenport lost in the fourth round to Martina Hingis. She was then absent from the tour until August because of a back injury. She returned in Los Angeles, losing a second-round match to Samantha Stosur. It was Davenport's earliest exit from a tournament since early 2003. Davenport attributed the loss to her having resumed training only three weeks prior to the start of the tournament. Davenport had re-hired Adam Peterson as her coach, with whom she worked during her 2004\u201305 resurgence.\nAt the tournament in New Haven, Davenport defeated world no. 1 Am\u00e9lie Mauresmo in the quarterfinals, but was forced to retire with a right shoulder injury while playing Justine Henin in the final.\nDespite injury, Davenport reached the US Open quarterfinals, where she again lost to Henin.\nDavenport's last competitive match before the December announcement of her pregnancy was a quarterfinal loss in Beijing to top-ranked Mauresmo. It was Mauresmo's first win over Davenport after nine consecutive losses.\n2007.\nOn July 18, 2007, Davenport announced that she would return to the WTA Tour. At her first tournament, she partnered with Lisa Raymond in the doubles competition at New Haven, where they lost in the first round to top seeds Cara Black and Liezel Huber.\nDavenport returned to singles competition in Bali, where she won her first title since 2005, defeating Daniela Hantuchov\u00e1 in the final. En route to the title, Davenport defeated third ranked Jelena Jankovi\u0107, among others. Davenport and her partner Hantuchov\u00e1 also advanced to the semifinals in Bali, before withdrawing from the tournament.\nDavenport's second tournament was in Beijing, where she defeated fourth-seeded Russian Elena Dementieva in the quarterfinals, before losing to Jankovi\u0107 in the semifinals.\nDavenport's third tournament was in Quebec City, Canada, defeating second-seeded Vera Zvonareva in the semifinals and Julia Vakulenko in the final. This was Davenport's 53rd career singles title and lifted her to no. 73 in the WTA rankings.\n2008.\nDavenport won the ASB Classic in Auckland, New Zealand, the first WTA tour event of the year. Davenport defeated Aravane Reza\u00ef in the final. This raised her ranking to world no. 52. She was the only player in the WTA top 100 that had fewer than 10 tournaments counting towards her world ranking.\nAt the first Grand Slam tournament of the year, the Australian Open, Davenport lost in the second round to eventual champion Maria Sharapova, 1\u20136, 3\u20136. This was the first time that Davenport had lost to Sharapova in straight sets.\nOn January 14, 2008, Davenport surpassed Steffi Graf in career prize money earned on the women's tour, garnering a total of US$21,897,501.\nIn March, Davenport won her second tournament of the year and 55th career singles title by beating Olga Govortsova in the final of the Regions Morgan Keegan Championships &amp; The Cellular South Cup in Memphis, Tennessee. She tied Virginia Wade for seventh place on the list of most singles titles won during the open era. Davenport also teamed with Lisa Raymond to win the doubles title.\nAt the Tier I Pacific Life Open in Indian Wells, California, Davenport lost in the quarterfinals to Jelena Jankovi\u0107, 6\u20132, retired. She retired from the match because of a back injury sustained before the match started. At the Tier I Sony Ericsson Open in Key Biscayne, Florida, Davenport defeated world no. 2 and second-seeded Ana Ivanovic in the third round, 6\u20134, 6\u20132, before losing her fourth-round match with Dinara Safina, 3\u20136, 4\u20136.\nIn her first clay-court tournament since 2005, Davenport reached the semifinals of the Bausch &amp; Lomb Championships in Amelia Island, Florida, where she defaulted her match with Sharapova before it began, due to illness. Citing undisclosed personal reasons, Davenport withdrew from the French Open five days before the tournament began.\nAt Wimbledon, Davenport was seeded 25th, won her first-round match, and then withdrew from the tournament because of a right knee injury.\nOn August 8, 2008, Davenport withdrew from the singles competition at the Olympic Games in Beijing because of a lingering knee injury. She and her partner, world no. 1 doubles player Liezel Huber, lost in the women's doubles quarterfinals.\nAt the US Open, Davenport was seeded 23rd and lost to 12th-seeded Marion Bartoli in the third round. Davenport was scheduled to play the Fortis Championships Luxembourg in October, but withdrew before the start of the tournament.\n2009.\nDavenport announced her intention to play in the 2009 Australian Open in January, ending speculation that she would be retiring from the sport. However, she withdrew from the event when she learned that she was expecting her second child. It was announced on June 30, 2009, that Davenport had given birth to a baby girl.\n2010.\nIn her first tournament since the 2008 US Open, Davenport played mixed doubles at Wimbledon with Bob Bryan, where they received a wild card. They made it to the second round before falling to Daniel Nestor and Bethanie Mattek-Sands.\nDavenport also announced her intention to play doubles at two tournaments in the American hard-court season. The first tournament was the women's doubles event at the 2010 Bank of the West Classic, where she won the title partnering Liezel Huber. She followed this with the 2010 Mercury Insurance Open, again with Huber. They lost in the quarterfinals to Bethanie Mattek-Sands and Yan Zi.\n2011.\nAt the 2011 French Open she won the Women's Legends Doubles event with partner Martina Hingis.\nDavenport went on to win the Wimbledon Invitational Doubles event, partnering once again with Hingis. World Team Tennis announced that Davenport would not be able to compete for the season because she was pregnant with her third child.\nWorld TeamTennis.\nDavenport has played 11 seasons with World TeamTennis starting in 1993 when she debuted in the league with the Sacramento Capitals and proceeded to win three championships with the team in 1997, 1998 and 2007. She also played with the St. Louis Aces in 2001, 2010 and 2011; New York Buzz in 2002; Newport Beach Breakers 2003 and 2008; Sacramento Capitals in 1993, 1997, 1998 and 2007 and the Orange County Breakers in 2012.\nDavenport won multiple league honors during her WTT career including Female MVP 1997 and 2010; Women's Singles scoring leader 1997, 1998; Female Rookie of the Year 1993; Mixed Doubles scoring leader 1998 (w/ Brian MacPhie).\nPlaying style.\nDavenport was an aggressive baseliner, whose game was built around her powerful serve and groundstrokes, which were used to dominate play, and hit winners both crosscourt and down-the-line. Due to her aggressive and risky playing style, she typically hit large numbers of both winners and unforced errors. Gabriela Sabatini once commented that, \"[Lindsay] likes to hit the ball hard into the corner. Very, very hard\". She would typically utilise aggressive serve/groundstroke combinations to finish points quickly, and, by aiming for the corners and the lines, Davenport was able to dictate play from the baseline. Davenport has been described as one of the cleanest ball strikers in WTA history, as well as one of the most powerful; in 2021, Serena Williams described Davenport in retrospect as the \"hardest\" hitter she had ever faced, and the most \"powerful\" player of all time. Davenport possessed an exceptionally powerful first serve, which peaked at , allowing her to serve multiple aces in any given match. She also possessed powerful and effective kick and slice serves, which she deployed as second serves; these prevented double faults, and allowed her to dictate play from a defensive position. She was known for her forehand, which was hit flat with an Eastern forehand grip, affording consistent depth, power, and penetration; Gigi Fern\u00e1ndez once remarked that Davenport has developed \"a forehand as good as Steffi Graf's.\" She was also known for her powerful two-handed backhand, which was similarly hit hard and flat. Her lack of court speed and mobility was her greatest weakness throughout her career, until she overhauled her conditioning program and lost 30 pounds beginning in 1995; she was also known for her mental strength. She was a thirteen-time grand slam finalist in doubles, although she typically only approached the net in singles matches to retrieve short balls, or to finish a point when she had created an opportunity to attack with her powerful overhead smash. Throughout her career, Davenport rarely used defensive shots, instead predicating her game on pure power and aggression.\nEquipment and endorsements.\nDavenport was endorsed by Nike for clothing, shoes, and on-court apparel. She was also endorsed by Wilson for racquets throughout her career, typically utilising a racquet from the Wilson Hammer range.\nCoaching.\nDavenport became the coach of Madison Keys prior to the commencement of the 2015 season. Already the pair have made an impact together, with Keys advancing to the semi-finals of a Grand Slam tournament for the first time at the 2015 Australian Open, where she upset reigning Wimbledon champion Petra Kvitov\u00e1 en route.\nPersonal life.\nDavenport married Jon Leach, a Merrill Lynch investment banker and former University of Southern California All-American tennis player, on April 25, 2003, in Hawaii. He is the brother of her former coach Rick Leach. Davenport took a break from competitive tennis in late 2006 and much of 2007 to have a baby. In 2007, she gave birth to a son, Jagger Leach, in Newport Beach, California. She gave birth to a daughter in 2009 also in Newport Beach, California. She gave birth to her third child, a daughter, in 2012. The couple's fourth child (and third daughter) was born in 2014. She owns homes in the Irvine, California, neighborhood of Shady Canyon, in Laguna Beach, California, and in Kona, Hawaii.\nJagger Leach made his Major debut in the juniors tournament at the 2024 Australian Open. He reached the quarterfinals of the juniors tournament at Wimbledon 2024.\nCareer statistics.\nGrand Slam tournament performance timelines.\n&lt;templatestyles src=\"Template:Performance key/styles.css\"/&gt;\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;(W) winner; (F) finalist; (SF) semifinalist; (QF) quarterfinalist; (#R) rounds 4, 3, 2, 1; (RR) round-robin stage; (Q#) qualification round; (P#) preliminary round; (DNQ) did not qualify; (A) absent; (Z#) Davis/Fed Cup Zonal Group (with number indication) or (PO) play-off; (G) gold, (S) silver or (B) bronze Olympic/Paralympic medal; (NMS) not a Masters tournament; (NTI) not a Tier I tournament; (P) postponed; (NH) not held; (SR) strike rate (events won / competed); (W\u2013L) win\u2013loss record.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\nrole=\"presentation\" class=\"wikitable succession-box noprint\" style=\"margin:0.5em auto; font-size:small;clear:both;\""}
{"id": "52829", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=52829", "title": "Dutch west india company", "text": ""}
{"id": "52831", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=52831", "title": "New netherland", "text": ""}
{"id": "52837", "revid": "11521989", "url": "https://en.wikipedia.org/wiki?curid=52837", "title": "Wiki wiki", "text": ""}
{"id": "52838", "revid": "3091149", "url": "https://en.wikipedia.org/wiki?curid=52838", "title": "Charon (moon)", "text": "Largest natural satellite of Pluto\nCharon ( or ), formal designation (134340) Pluto I, is the largest of the five known natural satellites of the dwarf planet Pluto. It has a mean radius of . Charon is the sixth-largest known trans-Neptunian object after Pluto, Eris, Haumea, Makemake, and Gonggong. It was discovered in 1978 at the United States Naval Observatory in Washington, D.C., using photographic plates taken at the United States Naval Observatory Flagstaff Station (NOFS).\nWith half the diameter and one-eighth the mass of Pluto, Charon is a very large moon in comparison to its parent body. Its gravitational influence is such that the barycenter of the Plutonian system lies outside Pluto, and the two bodies are tidally locked to each other. The dwarf planet systems Pluto\u2013Charon and Eris\u2013Dysnomia and the dwarf planet candidate system Salacia-Actaea are the only known examples of mutual tidal locking in the Solar System, though it is likely that Orcus\u2013Vanth is another.\nThe reddish-brown cap of the north pole of Charon is composed of tholins, organic macromolecules that may be essential ingredients of life. These tholins were produced from methane, nitrogen, and related gases which may have been released by cryovolcanic eruptions on the moon, or may have been transferred over from the atmosphere of Pluto to the orbiting moon.\nThe \"New Horizons\" spacecraft, the only probe to visit the Pluto system, approached Charon to within in 2015.\nDiscovery.\nCharon was discovered by United States Naval Observatory astronomer James Christy, using the telescope at United States Naval Observatory Flagstaff Station (NOFS). On June 22, 1978, he had been examining highly magnified images of Pluto on photographic plates taken with the telescope two months prior. Christy noticed that a slight elongation appeared periodically. The bulge was confirmed on plates dating back to April 29, 1965. Subsequent observations of Pluto determined that the bulge was due to a smaller accompanying body. The periodicity of the bulge corresponded to Pluto's rotation period, which was previously known from Pluto's light curve. This indicated a synchronous orbit, which strongly suggested that the bulge effect was real and not spurious. This resulted in reassessments of Pluto's size, mass, and other physical characteristics because the calculated mass and albedo of the Pluto\u2013Charon system had previously been attributed to Pluto alone. The International Astronomical Union formally announced Christy's discovery to the world on July 7, 1978.\nDoubts about Charon's existence were erased when it and Pluto entered a five-year period of mutual eclipses and transits between 1985 and 1990. This occurs when the Pluto\u2013Charon orbital plane is edge-on as seen from Earth, which only happens at two intervals in Pluto's 248-year orbital period. It was fortuitous that one of these intervals happened to occur soon after Charon's discovery.\nName.\nCharon was first given the temporary designation S/1978\u00a0P\u00a01, after its discovery, following the then recently instituted convention. On June 24, 1978, Christy first suggested Oz, then the name \"Charon\" as a scientific-sounding version of his wife Charlene's nickname, \"Char\". Although colleagues at the Naval Observatory proposed \"Persephone\", Christy stuck with \"Charon\" after discovering that it was serendipitously the name of an appropriate mythological figure: Charon (; ) is the ferryman of the dead, closely associated with the god Pluto. The IAU officially adopted the name in late 1985, and it was announced on January 3, 1986.\nCoincidentally, nearly four decades before Charon's discovery, science fiction author Edmond Hamilton had invented three moons of Pluto for his 1940 novel \"Calling Captain Future\" and named them Charon, Styx, and Cerberus;\nStyx and Kerberos are the two smallest Plutonian moons, and were named in 2013.\nThere is minor debate over the preferred pronunciation of the name. The mythological figure is pronounced with a sound, and this is often followed for the moon as well. However, Christy himself pronounced the initial \u27e8ch\u27e9 as a sound, as he had named the moon after his wife Charlene. Many English-speaking astronomers follow the classical convention, but others follow Christy's, and that is the prescribed pronunciation at NASA and of the \"New Horizons\" team.\nPlanetary moons other than Earth's were never given symbols in the astronomical literature. Denis Moskowitz, a software engineer who designed most of the dwarf planet symbols, proposed a symbol for Charon () that combines the high orb of Pluto's bident symbol with a crescent, suggesting both Charon as a moon and the mythological Charon's boat crossing the river Styx. This symbol is not widely used, but it coincidentally matches a Pluto symbol used in Uranian astrology.\nOrbit.\nCharon and Pluto orbit each other every 6.387 days. The two objects are gravitationally locked to one another, so each keeps the same face towards the other. This is a case of mutual tidal locking, as compared to that of the Earth and the Moon, where the Moon always shows the same face to Earth, but not vice versa. The average distance between Charon and Pluto is about . However, Pluto moves with respect to the barycenter of the system as well, as the barycenter's distance from the center of Pluto is larger than the radius of Pluto. Therefore, Charon is not as far from the true center of the Pluto\u2013Charon system, at only .\nThe discovery of Charon allowed astronomers to calculate accurately the mass of the Plutonian system, and mutual occultations revealed their sizes. However, neither indicated the two bodies' individual masses. Those could only be estimated, until the discovery of Pluto's outer moons in late 2005. Details in the orbits of the outer moons then revealed that Charon has approximately 12% of the mass of Pluto.\nFormation.\nSimulation work published in 2005 by Robin Canup suggested that Charon could have been formed by a collision around 4.5 billion years ago, much like Earth and the Moon. In this model, a large Kuiper belt object struck Pluto at high velocity, destroying itself and blasting off much of Pluto's outer mantle, and Charon coalesced from the debris. However, such an impact should result in an icier Charon and rockier Pluto than scientists have found. It is now thought that Pluto and Charon might have been two bodies that collided before going into orbit around each other. The collision would have been violent enough to boil off volatile ices like methane (CH4) but not violent enough to have destroyed either body. The very similar density of Pluto and Charon implies that the parent bodies were not fully differentiated when the impact occurred. The two bodies would have been stuck for a while, before separating from each other again, while remaining gravitationally bound. The internal heat in both bodies, created from both the collision and then the tidal friction as they separated, would have been sufficient to create Pluto's subsurface ocean without the need for radioactive elements.\nPhysical characteristics.\nCharon's diameter is , just over half that of Pluto. Larger than the dwarf planet Ceres, it is the twelfth-largest natural satellite in the Solar System. Charon is similar in size to Uranus's moons Umbriel and Ariel. Charon's slow rotation means that there should be little flattening or tidal distortion if Charon is sufficiently massive to be in hydrostatic equilibrium. Any deviation from a perfect sphere is too small to have been detected by observations by the \"New Horizons\" mission. This is in contrast to Iapetus, a Saturnian moon similar in size to Charon but with a pronounced oblateness dating to early in its history. The lack of such oblateness in Charon could mean that it is currently in hydrostatic equilibrium, or simply that its orbit approached its current one early in its history, when it was still warm.\nBased on mass updates from observations made by \"New Horizons\" the mass ratio of Charon to Pluto is 0.1218:1. This is much larger than the Moon to the Earth: 0.0123:1. Because of the high mass ratio, the barycenter is outside of the radius of Pluto, and the Pluto\u2013Charon system has been referred to as a dwarf double planet. With four smaller satellites in orbit about the two larger worlds, the Pluto\u2013Charon system has been considered in studies of the orbital stability of circumbinary planets.\nInternal structure.\nCharon's volume and mass allow calculation of its density, , from which it can be determined that Charon is slightly less dense than Pluto and suggesting a composition of 55% rock to 45% ice (\u00b1\u00a05%), whereas Pluto is about 70% rock. The difference is considerably lower than that of most suspected collisional satellites.\nFollowing the \"New Horizons\" flyby, numerous discovered features on Charon's surface strongly indicated that Charon is differentiated, and may even have had a subsurface ocean early in its history. The past resurfacing observed on Charon's surface indicated that Charon's ancient subsurface ocean may have fed large-scale cryoeruptions on the surface, erasing many older features. As a result, two broad competing views on the nature of Charon's interior arose: the so-called \"hot start\" model, where Charon's formation is rapid and involves a violent impact with Pluto, and the \"cold start\" model, where Charon's formation is more gradual and involves a less violent impact with Pluto.\nAccording to the hot start model, Charon accreted rapidly (within ~ years) from the circumplanetary disc, resulting from a highly-disruptive giant impact scenario. This rapid time scale prevents the heat from accretion from radiating away during the formation process, leading to the partial melting of Charon's outer layers. However, Charon's crust failed to reach a melt fraction where complete differentiation occurs, leading to the crust retaining part of its silicate content upon freezing. A liquid subsurface ocean forms during or soon after Charon's accretion and persists for approximately 2 billion years before freezing, possibly driving cryovolcanic resurfacing of Vulcan Planitia. Radiogenic heat from Charon's core could then melt a second subsurface ocean composed of a eutectic water-ammonia mixture before it too freezes, possibly driving the formation of Kubrick Mons and other similar features. These freezing cycles could increase Charon's size by &gt;20 km, leading to the formation of the complex tectonic features observed in Serenity Chasma and Oz Terra.\nIn contrast, the cold start model argues that a large subsurface ocean early in Charon's history is not necessary to explain Charon's surface features, and instead proposes that Charon may have been homogeneous and more porous at formation. According to the cold start model, as Charon's interior begins to warm due to radiogenic heating and heating from serpentinization, a phase of contraction begins, largely driven by compaction in Charon's interior. Approximately 100\u2013200 million years after formation, enough heat builds up to where a subsurface ocean melts, leading to rapid differentiation, further contraction, and the hydration of core rocks. Despite this melting, a pristine crust of amorphous water ice on Charon remains. After this period, differentiation continues, but the core can no longer absorb more water, and thus freezing at the base of Charon's mantle begins. This freezing drives a period of expansion until Charon's core becomes warm enough to begin compaction, starting a final period of contraction. Serenity Chasma may have formed from the expansion episode, whilst the final contraction episode may have given rise to the arcuate ridges observed in Mordor Macula.\nSurface.\nUnlike Pluto's surface, which is composed of nitrogen and methane ices, Charon's surface appears to be dominated by the less volatile water ice.\nIn 2007, observations by the Gemini Observatory detected patches of ammonia hydrates and water crystals on the surface of Charon that suggested the presence of active cryogeysers and cryovolcanoes. The fact that the ice was still in crystalline form suggested it may have been deposited recently, as it was expected that solar radiation would have degraded it to an amorphous state after roughly thirty thousand years. However, following new data from the \"New Horizons\" flyby, no active cryovolcanoes or geysers were detected. Later research has also called into question the cryovolcanic origin for the crystalline water ice and ammonia features, with some researchers instead proposing that ammonia may be replenished passively from underground material.\nPhotometric mapping of Charon's surface shows a latitudinal trend in albedo, with a bright equatorial band and darker poles. The north polar region is dominated by a very large dark area informally dubbed \"Mordor\" by the \"New Horizons\" team. The favored explanation for this feature is that it is formed by condensation of gases that escaped from Pluto's atmosphere. In winter, the temperature is \u2212258\u00a0\u00b0C, and these gases, which include nitrogen, carbon monoxide, and methane, condense into their solid forms; when these ices are subjected to solar radiation, they chemically react to form various reddish tholins. Later, when the area is again heated by the Sun as Charon's seasons change, the temperature at the pole rises to \u2212213\u00a0\u00b0C, resulting in the volatiles sublimating and escaping Charon, leaving only the tholins behind. Over millions of years, the residual tholin builds up thick layers, obscuring the icy crust. In addition to Mordor, \"New Horizons\" found evidence of extensive past geology that suggests that Charon is probably differentiated; in particular, the southern hemisphere has fewer craters than the northern and is considerably less rugged, suggesting that a massive resurfacing event\u2014perhaps prompted by the partial or complete freezing of an internal ocean\u2014occurred at some point in the past and removed many of the earlier craters.\nCharon has a system of extensive grabens and scarps, such as Serenity Chasma, which extend as an equatorial belt for at least . Argo Chasma potentially reaches as deep as , with cliffs that may rival Verona Rupes on Miranda for the title of the tallest cliff in the Solar System.\nHypothesized exosphere.\nIn contrast to Pluto, Charon has no significant atmosphere. There has been speculation about an extremely thin exosphere surrounding the moon contributing to the formation of dark regions such as Mordor Macula. The strong seasons experienced by Pluto and Charon could provide brief periods of exosphere formation as methane sublimates on Charon, interspersed by centuries of dormancy.\nPluto does have a thin but significant atmosphere, which Charon's gravitation might pull toward Charon's surface. The gas, specifically nitrogen, is mostly caught in the combined center of gravity between the two bodies before reaching Charon, but any gas that does reach Charon is held closely against the surface. The gas is mostly made up of ions of nitrogen, but the amounts are negligible compared to the total of Pluto's atmosphere.\nThe many spectral signatures of ice formations on the surface of Charon have led some to believe that the ice formations could supply an atmosphere, but atmosphere supplying formations have not been confirmed yet. Many scientists theorize that these ice formations could be concealed out of direct sight, either in deep craters or beneath Charon's surface. Charon's relatively low gravity, due to its low mass, causes any atmosphere that might be present to rapidly escape the surface into space. Even through stellar occultation, which is used to probe the atmosphere of stellar bodies, scientists cannot confirm an existing atmosphere; this was tested in 1986 while attempting to perform stellar occultation testing on Pluto. Charon also acts as a protector for Pluto's atmosphere, blocking the solar wind that would normally collide with Pluto and damage its atmosphere. Since Charon blocks these solar winds, its own atmosphere is diminished, instead of Pluto's. This effect is also a potential explanation for Charon's lack of atmosphere; the solar winds remove gases faster than they can accumulate. It is still possible for Charon to have an atmosphere, as Pluto transfers some of its atmospheric gas to Charon, from where it tends to escape into space. Assuming Charon's density is 1.71 g/cm3, it would have a surface gravity of 0.6 of Pluto's. It also has a higher mean molecular weight than Pluto and a lower exobase surface temperature, so that the gases in its atmosphere would not escape as rapidly from Charon as they do from Pluto.\nThere has been significant proof of CO2 gas and H2O vapor on the surface of Charon, but these vapors are not sufficient for a viable atmosphere due to their low vapor pressures. Pluto's surface has abundant ice formations, but these are volatile, as they are made up of volatile substances like methane. These volatile ice structures cause a good deal of geological activity, keeping its atmosphere constant, while Charon's ice structures are mainly made up of water and carbon dioxide, much less volatile substances that can stay dormant and not affect the atmosphere much.\nObservation and exploration.\nSince the first blurred images of the moon , images showing Pluto and Charon resolved into separate disks were taken for the first time by the Hubble Space Telescope in the 1990s . The telescope was responsible for the best, yet low-quality images of the moon. In 1994, the clearest picture of the Pluto\u2013Charon system showed two distinct and well-defined disks . The image was taken by Hubble's Faint Object Camera (FOC) when the system was 4.4 billion kilometers (2.6 billion miles) away from Earth Later, the development of adaptive optics made it possible to resolve Pluto and Charon into separate disks using ground-based telescopes. Although ground-based observation is very challenging, a group of amateur astronomers in Italy used a 14-inch telescope in 2008 to successfully resolve Charon in an image of Pluto.\nIn June 2015, the \"New Horizons\" spacecraft captured consecutive images of the Pluto\u2013Charon system as it approached it. The images were put together in an animation. It was the best image of Charon to that date . In July 2015, the \"New Horizons\" spacecraft made its closest approach to the Pluto system. It is the only spacecraft to date to have visited and studied Charon. Charon's discoverer James Christy and the children of Clyde Tombaugh were guests at the Johns Hopkins Applied Physics Laboratory during the New Horizons closest approach.\nClassification.\nThe center of mass (barycenter) of the Pluto\u2013Charon system lies outside either body. Because neither object truly orbits the other, and Charon has 12.2% of the mass of Pluto, it has been argued that Charon should be considered to be part of a binary planet with Pluto. The International Astronomical Union (IAU) states that Charon is a satellite of Pluto, but the idea that Charon might be classified as a dwarf planet in its own right may be considered at a later date.\nIn a draft proposal for the 2006 redefinition of the term, the IAU proposed that a planet is defined as a body that orbits the Sun that is large enough for gravitational forces to render the object (nearly) spherical. Under this proposal, Charon would have been classified as a planet, because the draft explicitly defined a planetary satellite as one in which the barycenter lies within the major body. In the final definition, Pluto was reclassified as a dwarf planet, but a formal definition of a planetary satellite was not decided upon. Charon is not in the list of dwarf planets currently recognized by the IAU. Had the draft proposal been accepted, even the Moon would hypothetically be classified as a planet in billions of years when the tidal acceleration that is gradually moving the Moon away from Earth takes it far enough away that the center of mass of the system no longer lies within Earth.\nThe other moons of Pluto\u00a0\u2013 Nix, Hydra, Kerberos, and Styx\u00a0\u2013 orbit the same barycenter but they are not large enough to be spherical and they are simply considered to be satellites of Pluto (or of Pluto\u2013Charon).\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52839", "revid": "48736052", "url": "https://en.wikipedia.org/wiki?curid=52839", "title": "Kirkwood gap", "text": "Gap or dip in the distribution of the semi-major axes of the orbits of main-belt asteroids\nA Kirkwood gap is a gap or dip in the distribution of the semi-major axes (or equivalently of the orbital periods) of the orbits of main-belt asteroids. They correspond to the locations of orbital resonances with Jupiter. The gaps were first noticed in 1866 by Daniel Kirkwood, who also correctly explained their origin in the orbital resonances with Jupiter while a professor at Jefferson College in Canonsburg, Pennsylvania.\nFor example, there are very few asteroids with semimajor axis near 2.50 AU, period 3.95 years, which would make three orbits for each orbit of Jupiter (hence, called the 3:1 orbital resonance). Other orbital resonances correspond to orbital periods whose lengths are simple fractions of Jupiter's. The weaker resonances lead only to a depletion of asteroids, while spikes in the histogram are often due to the presence of a prominent asteroid family \"(see List of asteroid families)\".\nMost of the Kirkwood gaps are depleted, unlike the mean-motion resonances (MMR) of Neptune or Jupiter's 3:2 resonance, that retain objects captured during the giant planet migration of the Nice model. The loss of objects from the Kirkwood gaps is due to the overlapping of the \u03bd5 and \u03bd6 secular resonances within the mean-motion resonances. The orbital elements of the asteroids vary chaotically as a result and evolve onto planet-crossing orbits within a few million years. The 2:1 MMR has a few relatively stable islands within the resonance, however. These islands are depleted due to slow diffusion onto less stable orbits. This process, which has been linked to Jupiter and Saturn being near a 5:2 resonance, may have been more rapid when Jupiter's and Saturn's orbits were closer together.\nMore recently, a relatively small number of asteroids have been found to possess high eccentricity orbits which do lie within the Kirkwood gaps. Examples include the Alinda and Griqua groups. These orbits slowly increase their eccentricity on a timescale of tens of millions of years, and will eventually break out of the resonance due to close encounters with a major planet. This is why asteroids are rarely found in the Kirkwood gaps.\nMain gaps.\nThe most prominent Kirkwood gaps are located at mean orbital radii of:\nWeaker and/or narrower gaps are also found at:\nAsteroid zones.\nThe gaps are not seen in a simple snapshot of the locations of the asteroids at any one time because asteroid orbits are elliptical, and many asteroids still cross through the radii corresponding to the gaps. The actual spatial density of asteroids in these gaps does not differ significantly from the neighboring regions.\nThe main gaps occur at the 3:1, 5:2, 7:3, and 2:1 mean-motion resonances with Jupiter. An asteroid in the 3:1 Kirkwood gap would orbit the Sun three times for each Jovian orbit, for instance. Weaker resonances occur at other semi-major axis values, with fewer asteroids found than nearby. (For example, an 8:3 resonance for asteroids with a semi-major axis of 2.71\u00a0AU).\nThe main or core population of the asteroid belt may be divided into the inner and outer zones, separated by the 3:1 Kirkwood gap at 2.5\u00a0AU, and the outer zone may be further divided into middle and outer zones by the 5:2 gap at 2.82\u00a0AU:\n4 Vesta is the largest asteroid in the inner zone, 1 Ceres and 2 Pallas in the middle zone, and 10 Hygiea in the outer zone. 87 Sylvia is probably the largest Main Belt asteroid beyond the outer zone."}
{"id": "52840", "revid": "69412", "url": "https://en.wikipedia.org/wiki?curid=52840", "title": "Tom Swift", "text": "Fictional literary character\nTom Swift is the main character of six series of American juvenile science fiction and adventure novels that emphasize science, invention, and technology. Inaugurated in 1910, the sequence of series comprises more than 100\u00a0volumes. The first Tom Swift \u2013 later, Tom Swift Sr. \u2013 was created by Edward Stratemeyer, the founder of the Stratemeyer Syndicate, a book packaging firm. Tom's adventures have been written by various ghostwriters, beginning with Howard Garis. Most of the books are credited to the collective pseudonym \"Victor Appleton\". The 33 volumes of the second series use the pseudonym Victor Appleton II for the author. For this series, and some later ones, the main character is \"Tom Swift Jr.\" New titles have been published again from 2019 after a gap of about ten years, roughly the time that has passed before every resumption. Most of the series emphasized Tom's inventions. The books generally describe the effects of science and technology as wholly beneficial, and the role of the inventor in society as admirable and heroic.\nTranslated into many languages, the books have sold more than 30 million copies worldwide. Tom Swift has also been the subject of a board game and several attempted adaptations into other media.\nTom Swift has been cited as an inspiration by various scientists and inventors, including aircraft designer Kelly Johnson.\nInventions.\nIn his various incarnations, Tom Swift, usually a teenager, is inventive and science-minded, \"Swift by name and swift by nature.\" Tom is portrayed as a natural genius. In the earlier series, he is said to have had little formal education, the character modeled originally after such inventors as Henry Ford, Thomas Edison, and aviation pioneers Glenn Curtiss and Alberto Santos-Dumont. For most of the six series, each book concerns Tom's latest invention, and its role either in solving a problem or mystery, or in assisting Tom in feats of exploration or rescue. Often Tom must protect his new invention from villains \"intent on stealing Tom's thunder or preventing his success,\" but Tom is always successful in the end.\nMany of Tom Swift's fictional inventions describe actual technological developments or predate technologies now considered commonplace. \"Tom Swift Among the Diamond Makers\" (1911) was based on Charles Parsons's attempts to synthesize diamonds using electric current. \"Tom Swift and His Photo Telephone\" was published in 1914. Sending photographs by telephone was not fully developed until 1925. \"Tom Swift and His Wizard Camera\" (1912) features a portable movie camera, not invented until 1923. \"Tom Swift and His Electric Locomotive\" (1922) was published two years before the Central Railroad of New Jersey began using the first diesel electric locomotive. The house on wheels that Tom invents for 1929's \"Tom Swift and His House on Wheels\" pre-dated the first house trailer by a year. \"Tom Swift and His Diving Seacopter\" (1952) features a flying submarine similar to one planned by the United States Department of Defense four years later in 1956. Other inventions of Tom's have not happened, such as the device for silencing airplane engines that he invents in \"Tom Swift and His Magnetic Silencer\" (1941).\nAuthorship.\nThe character of Tom Swift was conceived about 1910 by Edward Stratemeyer, founder of the Stratemeyer Syndicate, a book-packaging business, although the name \"Tom Swift\" was first used in 1903 by Stratemeyer in \"Shorthand Tom the Reporter; Or, the Exploits of a Bright Boy\". Stratemeyer invented the series to capitalize on the market for children's science adventures. The Syndicate's authors created the Tom Swift stories by first preparing an outline with the plot elements, followed by drafting and editing the detailed manuscript. The books were published using the house pseudonym \"Victor Appleton\". Howard Garis wrote most of the volumes of the original series; Stratemeyer's daughter, Harriet Stratemeyer Adams, wrote the last three volumes. The first \"Tom Swift\" series ended in 1941.\nIn 1954, Harriet Adams created the \"Tom Swift, Jr.\" series, which was published using the pseudonym \"Victor Appleton II\" as author. The main character Tom Swift, Junior, was described as the son of the original Tom Swift. Most of the stories were outlined and plotted by Adams. The texts were written by various writers, among them William Dougherty, John Almquist, Richard Sklar, James Duncan Lawrence, Tom Mulvey and Richard McKenna. The \"Tom Swift, Jr.\", series ended in 1971.\nA third series was begun in 1981 and lasted until 1984. The rights to the Tom Swift character, along with the Stratemeyer Syndicate, were sold in 1984 to publishers Simon &amp; Schuster. They hired New York City book packaging business Mega-Books to produce further series. Simon &amp; Schuster has published three more Tom Swift series: one from 1991 to 1993; \"Tom Swift, Young Inventor\" from 2006 to 2007; and \"Tom Swift Inventors' Academy\" from 2019 to present\u2014eight volumes as of \"Depth Perception\" (March 2022).\nSeries.\nThe longest-running series of books to feature Tom Swift is the first, which consists of 40 volumes. Tom's son (Tom Swift Jr.) was also the name of the protagonist of the 33 volumes of the Tom Swift Jr. Adventures, the 11 volumes of the third Tom Swift series, the 13 volumes of the fourth, and 6 more for the fifth series, Tom Swift, Young Inventor, and 8 for the most recent series, Tom Swift Inventors' Academy for a total of 111 volumes for all the series. In addition to publication in the United States, Tom Swift books have been published extensively in England, and translated into Norwegian, French, Icelandic, and Finnish.\nOriginal series (1910\u20131941).\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"All right, Dad. Go ahead, laugh.\"\n\"Well, Tom, I'm not exactly laughing at you\u00a0... it's more at the idea than anything else. The idea of talking over a wire and, at the same time, having light waves, as well as electrical waves passing over the same conductors!\"\n\"All right, Dad. Go ahead and laugh. I don't mind,\" said Tom, good-naturedly. \"Folks laughed at Bell, when he said he could send a human voice over a copper string\u00a0...\"\n\u2014 \"Tom Swift and His Photo Telephone\" (1912)\nIn the original series, Tom Swift lives in fictional Shopton, New York. He is the son of Barton Swift, the founder of the Swift Construction Company. Tom's mother is deceased, but the housekeeper, Mrs. Baggert, functions as a surrogate mother. Tom usually shares his adventures with close friend Ned Newton, who eventually becomes the Swift Construction Company's financial manager. For most of the series, Tom dates Mary Nestor. It has been suggested that his eventual marriage to Mary led to the series' demise, as young boys found a married man harder to identify with than a young, single one; however, after the 1929 marriage the series continued for 12 more years and eight further volumes. Regularly appearing characters include Wakefield Damon, an older man, whose dialogue is characterized by frequent use of such whimsical expressions as \"Bless my brakeshoes!\" and \"Bless my vest buttons!\"\nThe original Tom Swift has been claimed to represent the early 20th-century conception of inventors. Tom has no formal education after high school; according to critic Robert Von der Osten, Tom's ability to invent is presented as \"somehow innate\". Tom is not a theorist but a tinkerer and, later, an experimenter who, with his research team, finds practical applications for others' research; Tom does not so much methodically develop and perfect inventions as find them by trial and error.\nTom's inventions are not at first innovative. In the first two books of the series, he fixes a motorcycle and a boat, and in the third book he develops an airship, but only with the help of a balloonist. Tom is also at times unsure of himself, asking his elders for help; as Von der Osten puts it, \"the early Tom Swift is more dependent on his father and other adults at first and is much more hesitant in his actions. When his airship bangs into a tower, Tom is uncharacteristically nonplussed and needs support.\" However, as the series progresses, Tom's inventions \"show an increasingly independent genius as he develops devices, such as an electric rifle and a photo telephone, further removed from the scientific norm\". Some of Tom's inventions are improvements of then-current technologies, while other inventions were not in development at the time the books were published, but have since been developed.\nSecond series (1954\u20131971).\n&lt;templatestyles src=\"Template:Quote_box/styles.css\" /&gt;\n\"Did you have time to learn anything?\" Bud asked the young inventor.\nTom shrugged. \"A little. I was using my new gadget as a wave trap or antenna to capture light of a single wave length from certain stars so I could study their red shift.\"\nFrom \"Tom Swift and His Polar-Ray Dynasphere\" (1965).\nIn this series, presented as an extension and continuation of the first, the Tom Swift of the original series is now the CEO of Swift Enterprises, a four-mile-square enclosed facility where inventions are conceived and manufactured. Tom's son, Tom Swift Jr., is now the primary inventive genius of the family. Stratemeyer Syndicate employee Andrew Svenson described the new series as based \"on scientific fact and probability, whereas the old Toms were in the main adventure stories mixed with pseudo-science\". Three PhDs in science were hired as consultants to the series to ensure scientific accuracy. The younger Tom does not tinker with motorcycles; his inventions and adventures extend from deep within the Earth (in \"Tom Swift and His Atomic Earth Blaster\" [1954]) to the bottom of the ocean (in \"Tom Swift and His Diving Seacopter\" [1956]) to the Moon (in \"Tom Swift in the Race to the Moon\" [1958]) and, eventually, the outer Solar System (in \"Tom Swift and His Cosmotron Express\" [1970]). Later volumes of the series increasingly emphasized the extraterrestrial \"space friends\", as they are termed throughout the series. The beings appear as early as the first volume of the series, \"Tom Swift and His Flying Lab\" (1954). The Tom Swift Jr., Adventures were less commercially successful than the first series, selling 6 million copies total, compared with sales of 14 million copies for the first series.\nIn contrast to the earlier series, many of Tom Jr.'s inventions are designed to operate in space, and his \"genius is unequivocally original as he constructs nuclear-powered flying labs, establishes outposts in space, or designs ways to sail in space on cosmic rays\". Unlike his father, Tom Jr. is not just a tinkerer; he relies on scientific and mathematical theories, and, according to critic Robert Von der Osten, \"science [in the books] is, in fact, understood to be a set of theories that are developed based on experimentation and scientific discussion. Rather than being opposed to technological advances, such a theoretical understanding becomes essential to invention.\"\nTom Swift Jr.'s Cold War-era adventures and inventions are often motivated by patriotism, as Tom repeatedly defeats the evil agents of the fictional nations \"Kranjovia\" and \"Brungaria\", the latter a place that critic Francis Molson describes as \"a vaguely Eastern European country, which is strongly opposed to the Swifts and the U.S. Hence, the Swifts' opposition to and competition with the Brungarians is both personal and patriotic.\"\nThird series (1981\u20131984).\nThe third Tom Swift series differs from the first two in that the setting is primarily outer space, although Swift Enterprises (located now in New Mexico) is occasionally mentioned. Tom Swift explores the universe in the starship \"Exedra\", using a faster-than-light drive he has reverse-engineered from an alien space probe. He is aided by Benjamin Franklin Walking Eagle, a Native American who is Tom's co-pilot, best friend, and an expert computer technician, and Anita Thorwald, a former rival of Tom's who now works with him as a technician and whose right leg has been rebuilt to contain a miniature computer.\nThis series maintains only an occasional and vague continuity with the two previous series. Tom is called the son of \"the great Tom Swift\" and said to be \"already an important and active contributor to the family business, the giant multimillion-dollar scientific-industrial complex known as Swift Enterprises\". However, as critic Francis Molson indicates, it is not explained whether this Tom Swift is the grandson of the famous Tom Swift of the first series or still the Tom Swift Jr. of the second.\nThe Tom Swift of this third series is less of an inventor than his predecessors, and his inventions are rarely the main feature of the plot. Still, according to Molson, \"Tom the inventor is not ignored. Perhaps the most impressive of his inventions and the one essential to the series as a whole is the robot he designs and builds, Aristotle, which becomes a winning and likeable character in its own right.\" The books are slower-paced than the Tom Swift Jr. adventures of the second series, and include realistic, colloquial dialogue. Each volume begins where the last one ended, and the technology is plausible and accurate.\nFourth series (1991\u20131993).\nThe fourth series featuring Tom Swift (again a \"Jr.\") is set mostly on Earth (with occasional voyages to the Moon); Swift Enterprises is now located in California. In the first book, \"The Black Dragon\", it's mentioned that Tom is the son of Tom Swift Sr. and Mary Nestor. The books deal with what Richard Pyle describes as \"modern and futuristic concepts\" and, as in the third series, feature an ethnically diverse cast of characters.\nLike the Tom Swift Jr. series, the series portrays Tom as a scientist as well as an inventor whose inventions depend on a knowledge of theory. The series differs from previous versions of the character, however, in that Tom's inventive genius is portrayed as problematic and sometimes dangerous. As Robert Von der Osten argues, Tom's inventions for this series often have unexpected and negative repercussions.\na device to create a miniature black hole which casts him into an alternative universe; a device that trains muscles but also distorts the mind of the user; and a genetic process which, combined with the effect of his black hole, results in a terrifying devolution. Genius here begins to recapitulate earlier myths of the mad scientist whose technological and scientific ambitions are so out of harmony with nature and contemporary science that the results are usually unfortunate.\nThe series features more violence than previous series; in \"The Negative Zone\", Tom blows up a motel room to escape the authorities.\nThere was a derivative of this series featuring Tom Swift and the Hardy Boys called \"A Hardy Boys &amp; Tom Swift Ultra Thriller\" that was published from 1992 to 1993, and only had two volumes released. Both books dealt with science fictional topics (time travel and aliens landing on earth).\nFifth series (2006\u20132007).\nThe fifth series, \"Tom Swift, Young Inventor\", returns Tom Swift to Shopton, New York, with Tom as the son of Tom Swift and Mary Nestor, the names of characters of the original Tom Swift series. The series features inventions that are close to current technology \"rather than ultra-futuristic\". In several of the books, Tom's antagonist is The Road Back (TRB), an anti-technology terrorist organization. Tom's personal nemesis is Andy Foger, teenage son of his father's former business partner who now owns a competing (and ethically dubious) high-technology company.\nSixth series (2019-2022).\nA sixth series, \"Tom Swift Inventors' Academy\", published by Simon and Schuster, debuted in July 2019 with #1 \"The Drone Pursuit\" and #2 \"The Sonic Breach\". A total of eight books were published, concluding with #8 \"Depth Perception\" in March 2022.\nOther media.\nParker Brothers produced a Tom Swift board game in 1966, although it was never widely distributed, and the character has appeared in one television show. Various Tom Swift radio programs, television series, and movies were planned and even written, but were either never produced or not released.\nFilm and television.\nCancelled films.\nAs early as 1914, Edward Stratemeyer proposed making a Tom Swift movie, but no such movie was made. A Tom Swift radio series was proposed in 1946. Two scripts were written, but, for unknown reasons, the series was never produced. Twentieth Century Fox planned a Tom Swift feature movie in 1968, to be directed by Gene Kelly. A script was written and approved, and filming was to have begun during 1969. However, the project was canceled owing to the poor reception of the movies \"Doctor Dolittle\" and \"Star!\"; a $500,000 airship that had been built as a prop was rumored to have been sold to a midwest amusement park. Yet another movie was planned in 1974, but, again, was cancelled.\nTelevision.\nScripts were written for a proposed television series involving both Tom Swift Jr. and his father, the hero of the original book series. A television pilot show for a series to be called \"The Adventures of Tom Swift\" was filmed in 1958, featuring Gary Vinson. However, legal problems prevented the pilot's distribution, and it was never broadcast; no copies of the pilot are known to exist, though the pilot script is available. In 1977, Glen A. Larson wrote an unproduced television pilot show entitled \"TS, I Love You: The Further Adventures of Tom Swift\". This series was to be combined with a Nancy Drew series, a Hardy Boys series, and a Dana Girls series. Nancy Drew and the Hardy Boys were eventually combined into a one-hour program \"The Hardy Boys/Nancy Drew Mysteries\" with alternating episodes.\nA Tom Swift media project finally came to fruition in 1983 when Willie Aames appeared as Tom Swift along with Lori Loughlin as Linda Craig in a television special, \"The Tom Swift and Linda Craig Mystery Hour\", which was broadcast on July 3. It was a ratings failure. In 2007, digital studio Worldwide Biggies acquired movie rights to Tom Swift and announced plans to release a feature film and video game, followed by a television series. As of 2015, these plans had not come to fruition.\nTom Swift appeared in the episode \"The Celestial Visitor\" from the second season of The CW's \"Nancy Drew\" with Tian Richards portraying the character as a black, gay, billionaire inventor. The episode is a backdoor pilot for a spin-off project titled \"Tom Swift\", in development at The CW. In August 2021, \"Tom Swift\" was ordered straight-to-series and premiered on May 31, 2022 on The CW. In February 2022, Ashleigh Murray joined the cast as Zenzi Fullington. Due to poor ratings, the series was cancelled on June 30 that year.\nDepiction of race.\n\"Tom Swift and His Electric Rifle\" (published 1911) depicts Africans as brutish, uncivilized animals, and the white protagonist as their paternal savior. &lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;In the book, as in America today, the black people are rendered as either passive, simple and childlike, or animalistic and capable of unimaginable violence. They are described in the book at various points as \"hideous in their savagery, wearing only the loin cloth, and with their kinky hair stuck full of sticks\", and as \"wild, savage and ferocious ... like little red apes\".\u2014\u200a\nCultural influence.\nThe Tom Swift books have been credited with assisting the success of American science fiction and with establishing the edisonade (stories focusing on brilliant scientists and inventors) as a basic cultural myth. Tom Swift's adventures have been popular since the character's inception in 1910: by 1914, 150,000 copies a year were being sold and a 1929 study found the series to be second in popularity only to the Bible for boys in their early teens. By 2009, Tom Swift books had sold more than 30 million copies worldwide. The success of Tom Swift also paved the way for other Stratemeyer creations, such as The Hardy Boys and Nancy Drew.\nThe series' writing style, which was sometimes adverb heavy, suggested a name for a type of adverbial pun promulgated during the 1950s and 1960s, a type of wellerism known as \"Tom Swifties\". Originally this kind of pun was called a \"Tom Swiftly\" in reference to the adverbial usage. Over time, it has come to be called a \"Tom Swifty\". Some examples are \"'I lost my crutches,' said Tom lamely\", and \"'I'll take the prisoner downstairs', said Tom condescendingly.\"\nTom Swift's fictional inventions have apparently inspired several actual inventions, among them Lee Felsenstein's \"Tom Swift Terminal\", which \"drove the creation of an early personal computer known as the Sol\", and the taser. The name \"taser\" was originally \"TSER\", for \"Tom Swift's Electric Rifle\". The invention was named for the central device in the story \"Tom Swift and His Electric Rifle\" (1911); according to inventor Jack Cover, \"an 'A' was added because we got tired of answering the phone 'TSER'.\"\nA number of scientists, inventors, and science fiction writers have also credited Tom Swift with inspiring them, including Ray Kurzweil, Robert A. Heinlein, and Isaac Asimov. \"Gone with the Wind\" author Margaret Mitchell was also known to have read the first series as a child. Filmmaker George Lucas shows the 16-year-old Indiana Jones reading a Tom Swift novel \u2014 and the author Edward Stratemeyer himself appearing as a character \u2014 in the episode \"Spring Break Adventure\" of the television series \"Young Indiana Jones\".\nThe Tom Swift Jr. series was also a source of inspiration to many. Scientist and television presenter Bill Nye said the books helped \"make me who I am\", and they inspired him to launch his own young adult series. Microsoft founders Paul Allen and Bill Gates also read the books as children, as did co-founder of competing company Apple, Steve Wozniak. Wozniak, who cited the series as his inspiration to become a scientist, said the books made him feel \"that engineers can save the world from all sorts of conflict and evil\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nCited sources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52842", "revid": "44980621", "url": "https://en.wikipedia.org/wiki?curid=52842", "title": "Valve Corporation", "text": "American video game company\nValve Corporation, also known as Valve Software, is an American video game developer, publisher, and digital distribution company headquartered in Bellevue, Washington. It is the developer of the software distribution platform Steam and the game franchises \"Half-Life\", \"Counter-Strike\", \"Portal\", \"Day of Defeat\", \"Team Fortress\", \"Left 4 Dead\" and \"Dota\".\nValve was founded in 1996 by the former Microsoft employees Gabe Newell and Mike Harrington. Their debut game, the first-person shooter (FPS) \"Half-Life\" (1998), was a critical and commercial success and had a lasting influence on the FPS genre. Harrington left in 2000. In 2003, Valve launched Steam, followed by \"Half-Life 2\" (2004), the episodic sequels ' (2006) and ' (2007), the puzzle games \"Portal\" (2007) and \"Portal 2\" (2011) and the multiplayer games \"Team Fortress 2\" (2007), \"Left 4 Dead\" (2008) and \"Dota 2\" (2013).\nIn the 2010s, Valve released fewer games and experimented with hardware and virtual reality (VR). They entered the hardware market in 2015 with the Steam Machine, a line of gaming computers, and released the HTC Vive and Valve Index VR headsets. They returned to the \"Half-Life\" series in 2020 with \"\", their flagship VR game. In 2022, Valve released the Steam Deck, a portable gaming system.\nValve uses a flat structure, whereby employees decide what to work on themselves. They develop games through playtesting and iteration, describing game design as a kind of experimental psychology. By 2012, Valve employed around 250 people and was reportedly worth over US$3 billion. Most of Valve's revenue comes from Steam, which controlled over half of the digital PC games market in 2011 and generated an estimated $3.4 billion in 2017.\nHistory.\nFounding and \"Half-Life\" (1996\u20132003).\nValve was founded in 1996 by the former Microsoft employees Gabe Newell and Mike Harrington. Newell had spent the prior 13 years at Microsoft developing Windows, including the Windows 95 port of \"Doom\" from id Software. Newell had become frustrated with game developers' approach of creating bespoke interfaces for graphics acceleration, and had also seen id outperforming Windows in sales with \"Doom\" with an alternative distribution model.\nNewell and Harrington founded Valve, L.L.C. in Kirkland, Washington, about five miles from the Microsoft campus in Redmond, on August 24, 1996, Newell's wedding day. In a break from industry style of the time, Newell did not want a company name that suggested \"testosterone-gorged muscles and the 'extreme' of anything\". Alternative names considered by Newell and Harrington include Hollow Box, Fruitfly Ensemble and Rhino Scar.\nValve's first game was \"Half-Life\", a first-person shooter (FPS) with elements of horror. The development was aided by access to the \"Quake\" engine by id Software; Valve modified this engine into their GoldSrc engine. After struggling to find a publisher, Valve eventually signed with Sierra On-Line.\n\"Half-Life\" was released in November 1998 and was a critical and commercial success. With its realism, scripted sequences and seamless narrative, it had a lasting influence; according to \"IGN\" in 2014, the history of the FPS genre \"breaks down pretty cleanly into pre-\"Half-Life\" and post-\"Half-Life\" eras\".\nValve enlisted Gearbox Software to develop three expansions for \"Half-Life\": ' (1999), ' (2001) and \"\" (2001). In 1998, Valve acquired TF Software, a group that had made the popular \"Team Fortress\" mod for \"Quake\", and remade it for GoldSrc as \"Team Fortress Classic\" in 1999. Valve released the software development kit (SDK) for the GoldSrc engine, facilitating numerous user-created mods. They acquired the developers of one popular mod, \"Counter-Strike\", to create a standalone \"Counter-Strike\" game. Happy with Valve's success, Harrington sold his stake in Valve to Newell in 2000.\nValve's publishing agreement meant Sierra owned the \"Half-Life\" intellectual property and held exclusive publishing rights to future Valve games. In 2001, Valve renegotiated by threatening to cease game development and develop other software, using an offer of a partnership from Amazon to create a digital storefront as a bargaining chip. After the agreement with Sierra was amended, Valve gained the \"Half-Life\" intellectual property and online distribution rights for its games.\nSource, Steam, and \"Half-Life 2\" (2003\u20132010).\nIn 2003, Valve moved to Bellevue, Washington, and reincorporated as Valve Corporation. In 2010, the office moved to a larger location in Bellevue. In 2016, Valve signed a nine-floor lease in the Lincoln Square complex in downtown Bellevue, doubling the size of its offices.\nValve began developing \"Half-Life 2\" six months after the release of the first \"Half-Life\", using its new in-house engine, Source. With advanced physics systems and an increased focus on story and characters, it received critical acclaim upon its release in 2004. By 2011, it had sold 12 million copies. \nIn 2002, Valve launched Steam, a digital storefront and delivery platform. Steam initially offered only Valve games, and was mandatory to install \"Half-Life 2\", but became a publisher of third-party games. As Valve became its own publisher via Steam, it transitioned to a flat organization. Outside of executive management, Valve does not have bosses and uses an open allocation system, allowing employees to move between departments at will.\nAfter having taken five years to develop \"Half-Life 2\", Valve moved to episodic development, planning to release shorter games more frequently. ', the first in a planned trilogy of episodic \"Half-Life 2\" sequels, was released in 2006. ' followed in 2007, alongside the multiplayer game \"Team Fortress 2\" and the puzzle game \"Portal\", developed from the student project \"Narbacular Drop\". In January 2008, Valve announced the acquisition of Turtle Rock Studios, which was renamed Valve South. Turtle Rock developed \"Left 4 Dead\" and \"Left 4 Dead 2\" while associated with Valve. Turtle Rock Studios spun out of Valve again in March 2010. \"Forbes\" estimated that Valve had grossed $70 million in 2005. \nTransition to services (2010\u20132014).\nIn 2009, Valve hired IceFrog, the developer of \"Defense of the Ancients\", a ' mod. IceFrog led the development of a sequel not associated with the \"Warcraft\" elements, \"Dota 2\", released in 2013. Alongside \"Dota 2\" in 2011, Valve started the International, an annual esports tournament for \"Dota 2\" with a prize pool supported by Valve and funds from microtransactions from battle passes purchased by players. Valve released \"Portal 2\" in April 2011. As with the original \"Portal\", Valve employed a Digipen student team to help develop it; the team behind ' implemented the new gel gameplay.\nThe Screen Digest analyst Ed Barton estimated Valve's 2010 revenue to be in the \"high hundreds of millions of dollars\". As of 2011, Valve had an estimated worth of $2 to 4 billion and employed 250 people; according to Newell, this made it more profitable per employee than Google or Apple. Most of Valve's revenue came from Steam, which controlled 50 to 70% of the market for downloaded PC games in 2011.\nBy 2011, Valve had replaced episodic development with a platform-oriented approach, whereby games such as \"Left 4 Dead 2\" and \"Team Fortress 2\" were continually updated through Steam updates. In June 2012, Valve hired the economist Yanis Varoufakis to study the online economies of their games. That December, Valve acquired Star Filled Studios, a two-person studio, to open a San Francisco office. Valve closed the office in August 2013 when they decided it had little benefit. At the 2013 D.I.C.E. Summit, Newell announced that he and the film director J. J. Abrams were collaborating to produce a \"Half-Life\" or \"Portal\" film, as well as a possible game.\nIn the 2010s, Valve released fewer games and invested in hardware development. Newell intended to make Valve more like Nintendo, which develops games in tandem with hardware, allowing them to create innovative games such as \"Super Mario 64\". Valve initially focused on augmented reality, but in 2013 Newell laid off many staff to focus on virtual reality (VR). In 2015, Valve released the Steam Machine, a line of gaming computers, which sold poorly. Media commentators speculated that Valve's transition to service provider with Steam, which generated an estimated $3.4 billion in 2017, had driven it away from game development. \nValve canceled games including numerous \"Half-Life\" projects (including \"\"), \"Left 4 Dead 3\", a Soulslike game, and a voxel-based game, \"A.R.T.I\". Additional VR projects included \"SimTrek\", developed by members of the \"Kerbal Space Program\" development team, and a new VR device, Vader, that was determined to be too costly for consumers. According to the designer Robin Walker, the abundance of projects that failed to gain traction, with no shared vision, damaged morale. Many players grew frustrated in anticipation of a new \"Half-Life\" game.\nSource 2, virtual reality and \"Half-Life: Alyx\" (2015\u2013present).\nValve announced the Source 2 engine in March 2015, and ported \"Dota 2\" to Source 2 in September. That year, Valve collaborated with the electronics company HTC to develop the HTC Vive, a VR headset released in 2016. Valve experimented with VR games, and in 2016 released \"The Lab\", a collection of VR minigames.\nValve recognized that many players wanted a more ambitious VR AAA game, and began exploring the development of a major VR game. They developed several prototypes, with three further VR projects under development by 2017. Finding that the portal systems of their puzzle series \"Portal\" were disorienting in VR, they settled on \"Half-Life\". Walker said that \"Half-Life 3\" had been a \"terrifyingly daunting prospect\", and the team saw VR as a way to return to the series.\nFull development of a VR \"Half-Life\" game started around late 2016, with the largest team in Valve's history. Valve acquired the 3D audio software developer Impulsonic in January 2017. In April 2018, Valve acquired the independent developer Campo Santo, known for the 2016 adventure game \"Firewatch\". Campo Santo planned to develop its own games under Valve, though they initially helped develop \"Half-Life: Alyx\".\nIn November 2018, Valve released \"Artifact\", a digital collectible card game based on \"Dota 2\", with design by Richard Garfield, the creator of \"\". \"Artifact\" had unusual pay-for mechanics to acquire new cards, and did not draw a large playerbase, losing 95% of players months after release. In April 2021, Valve abandoned efforts to reboot the project, saying they had not found enough interested players to justify development. In June 2019, Valve released its second-generation VR hardware, the Valve Index. They also released \"Dota Underlords\" into early access, an auto battler based on a \"Dota 2\" community-created mode \"Dota Auto Chess\". \nIn March 2020, Valve released ', a VR game. It received acclaim and was described as VR's first killer app. Newell said in January 2021 that the success of \"Alyx\" created desire within the company to develop more games, and that several were under development. Valve collaborated with Netflix for ', an animated television series based on \"Dota\", which premiered in March 2021. In February 2022, Valve released the Steam Deck, a portable game system that runs on Linux-based SteamOS with the Proton compatibility layer that allows most Windows games on Steam to run on Linux without modification. In September 2023, Valve released \"Counter-Strike 2\". It received generally favorable reviews, but player reception was mixed. \nIn 2024, Valve began beta-testing a new multiplayer game, \"Deadlock\", a combination of a hero shooter and MOBA. In September, staff members from Hopoo Games, developers of \"Risk of Rain\", announced that they had been employed at Valve. According to a report by \"Forbes Australia\" published in December 2024, Valve had an annual revenue of $5 billion by 2023, with a 40% profit margin. Steam accounted for around 60% of this revenue, double that of 2019.\nIn November 2025, Valve announced a new line of hardware, consisting of a redesigned Steam Controller and Steam Machine, as well as the Steam Frame, a new standalone VR headset. All three are scheduled for release in early 2026.\nStructure.\nInitially, Valve used a hierarchical structure more typical of other development firms, driven by the nature of physical game releases through publishers that required tasks to be completed by deadlines. However, as Valve became its own publisher via Steam, it found the hierarchical structure was hindering progress.\nAfter completing \"Half-Life 2\", Valve transitioned to a flat organization; outside of executive management, Valve does not have bosses, and uses an open allocation system. Valve's marketing manager, Doug Lombardi, said: \"Nobody writes a design doc and hands it to somebody and says, 'you go build this'. It's the teams that are coming up with the ideas and pushing in the directions that they want to take the product.\" This approach allows employees to work on whatever interests them, but requires them to take ownership of their product and mistakes they may make, according to Newell. Newell recognized that this structure works well for some but that \"there are plenty of great developers for whom this is a terrible place to work\". Following the difficult development of \"Half-Life 2\", Newell said he became \"obsessed\" with improving Valve's work-life balance.\nAlthough Valve has no bosses, some employees hold more influence due to seniority or relationships. De facto project leads became \"centralized conduits\" for organization and sharing information, and decisions are made collectively. Valve uses a process named Overwatch to gather feedback from senior members, which teams may use or ignore. \nThe success of Steam means that Valve is not dependent on the success of its games. The lack of organization structure has led to project cancellations, as it can be difficult to convince other employees to work on them. In 2020, Valve acknowledged that this made it difficult to gather momentum and had slowed their output during the 2010s. Their VR projects and \"Half-Life: Alyx\" became a turning point, setting short-term studio-wide goals to focus the company. According to Walker, \"We sort of had to collectively admit we were wrong on the premise that you will be happiest if you work on something you personally want to work on the most.\"\nIn January 2023, \"People Make Games\" released a report on Valve's corporate structure and culture, based on interviews with several current and former employees. They found that Valve's flat structure and stack-ranking compensation system created a poor release record and a lack of employee diversity. In 2024, \"Forbes\" estimated that Newell owned 50.1% of Valve, with the rest owned by employees.\nAs part of Wolfire Games' lawsuit over Steam policies, case documents revealed details related to Valve's employee structure. Valve had 60 employees in 2003 and had approximately 350 employees between 2012 and 2021. Employees are categorized into administration, game development, Steam development and (from 2011) hardware development.\nValve time.\nValve time is an industry term used jokingly with game releases from Valve, used to acknowledge the difference between the \"promised\" date for released content stated by Valve and to the \"actual\" release date; \"Valve Time\" includes delays but also includes some content that was released earlier than expected. Valve has acknowledged the term, including tracking known discrepancies between ideal and actual releases on their public development wiki and using it in announcements about such delays. Valve ascribes delays to their mentality of team-driven initiatives over corporate deadlines.\nPlaytesting.\nValve playtests its games extensively from the beginning of development, and iterates based on the results. The company has publicly stated, \"We believe that all game designers are, in a sense, experimental psychologists.\" The Valve writer Chet Faliszek said he initially blamed testers when they failed to engage with designs as expected, but changed his mind when multiple testers had the same problem: \"By the third or fourth time, all of a sudden you're realizing, 'I'm an idiot. This is pretty obvious this doesn't work. It's not their fault, it's our fault.'\" He gave an example from the development of \"Left 4 Dead\", wherein a texture change caused every tester to miss a ladder and become stuck.\nWalker said playtesting helped Valve maximize the experience for players. For example, when something exciting occurs by chance during a playtest, the developers attempt to have it occur for every player. Newell contrasted this approach to that of Warren Spector, whose open-ended games are designed to be replayed with different outcomes: \"You spend all of this time to build stuff that most players will never ever ever see ... If only one per cent of your customers see this cool thing that takes five per cent of your development budget, that's not a good use of resources.\"\nProducts.\nGames.\nValve is the main developer and publisher of the single-player \"Half-Life\" and \"Portal\" games and the multiplayer games \"Counter-Strike\", \"Team Fortress 2\", \"Dota 2\", \"Day of Defeat\", and \"Artifact\". Valve also published the multiplayer game \"Left 4 Dead\" and developed and published \"Left 4 Dead 2\". Unreleased and canceled Valve games include the fantasy role-playing game \"Prospero\" and numerous \"Half-Life\" projects, including \"\". Valve worked with Arkane Studios on \"The Crossing\", which was canceled in May 2009.\nEngines.\nValve has developed at least three game engines that have been used in their games. GoldSrc is based on a modified \"Quake\" engine by id Software, and used for the basis of \"Half-Life\". Source was internally built from scratch as a replacement for GoldSrc, and was used for most of Valve's games in the early 2000s, including \"Half-Life 2\", \"Team Fortress 2\", and the \"Portal\" series. Source 2 is a refinement of the Source engine initially released in 2015, and has been used for \"Dota 2\", \"CounterStrike 2\", \"The Lab\", and \"Half-Life: Alyx\".\nSteam.\nValve announced Steam, its digital distribution service, at the 2002 Game Developers Conference. It was launched in September 2003 and was first used to deliver patches and other updates to Valve's online games.\nOn August 1, 2012, Valve announced revisions to the Steam Subscriber Agreement (SSA) to prohibit class action lawsuits by users against the service provider. By July 2014, there were over 3,400 games available on Steam, with over 150 million registered accounts by January 2018.\nAlongside these changes to the SSA, the company also declared publicly the incorporation of Valve S.a.r.l., a subsidiary based in Luxembourg. Valve set up a physical office in Kirchberg, Luxembourg. According to Valve's project manager Mike Dunkle, the location was chosen for eCommerce capabilities and infrastructure, talent acquisition, tax advantages and central geographic location\u00a0\u2013 most major partners are accessible, 50% within driving distance.\nValve S.a.r.l. was used to sell games to UK users to avoid paying the full 20% value-added tax (VAT). The tax loophole was expected to close on January 1, 2015. In December 2015, the French consumer group UFC Que Choisir initiated a lawsuit against Valve for several of their Steam policies that conflict or run afoul of French law. One of the reasons was for using the tax loophole. Valve S.a.r.l. ceased business on January 1, 2017, with the main company taking over EU sales again. In August 2017, Valve announced that Steam had reached over 67 million monthly and 33 million daily active users on the platform.\nSteam Machine.\nNewell has been critical of the direction that Microsoft has taken with making Windows a closed architecture similar to Apple's products, and has stated that he believes that the changes made in Windows 8 are \"a catastrophe for everyone in the [personal computer] space\". Newell identified the open-source Linux platform as an ideal platform for Steam and said the only thing holding back its adoption is the lack of games.\nIn 2012, Valve announced that they were working on a console-PC hybrid for the living room, dubbed by media as the \"Steam Box\". A precursor to such a unit is SteamOS, a freely available Linux-based operating system that builds upon the Steam client functionality that includes media services, live streaming across home networks, game sharing within families, and parental controls. SteamOS was officially announced in September 2013 as the first of several announcements related to the Steam Machine platform as well as their unique game controller. In May 2014, Valve announced that the company's own SteamOS-powered Steam Machine would be delayed until 2015 due to problems with the game controller. In 2015, Alienware, ZOTAC, and CyberPowerPC launched their versions of the Steam Machine. By June 2016, fewer than half a million had been sold. While the Steam Machine line has been effectively canceled, Valve continued to manufacture and sell Steam Controllers until late November 2019, and publishes both mobile apps and software for the Steam Link, allowing in-home streaming.\nValve Index and virtual reality.\nAt the Game Developers Conference in March 2015, Valve and Taiwanese electronics company HTC unveiled SteamVR and the HTC Vive\u2014a virtual reality platform and a virtual reality headset. The platform would be distinguished by its \"Lighthouse\" motion tracking system, where sensors on the headset and its included motion controllers read the position of two base station devices mounted in the play area. This would allow for \"room-scale\" VR experiences, where the player would not be required to remain in a stationary position in front of a camera and would be able to freely walk around the space.\nIn November 2017, Microsoft added beta support for the SteamVR service for Windows Mixed Reality headsets. In June 2019, Valve released their own VR headset, known as the Valve Index, positioned as a higher-end device with wider field of view and higher refresh rate. They were accompanied by updated motion controllers, which are strapped against the user's palms and have sensors to detect input pressure and individual fingers. In November 2025, Valve announced the Steam Frame, a standalone VR headset.\nSteam Deck.\nAnnounced in July 2021, the Steam Deck is a hybrid game console similar to the Nintendo Switch. It is primarily a handheld device that supports playing of Steam games, but through a separate dock unit, the console can output to an external monitor and use external power, networking, and USB accessories connected to the dock. The hardware is based on customized AMD Zen 2 and RDNA 2 chipsets. Units started shipping in February 2022.\nOther projects.\nPowerPlay.\nPowerPlay was a technological initiative headed by Valve and Cisco Systems to decrease the latency for online games, announced in January 2000. It was described as a set of protocols and deployment standards at the router level to improve performance. It was claimed that a player with 1000\u00a0ms ping was able to play against another player on a LAN connection with no noticeable disadvantage. Initially the protocol was to be released with PowerPlay 1.0 focusing on quality of service (QoS) and later a revision, PowerPlay 2.0 that would focus on functionality. Cisco and Valve intended to deliver a single dial-up service in Q1 2000 in the United States with a 30-day free trial with a bundled copy of \"Team Fortress\" modified to support PowerPlay.\nThe standard was to involve purchasing PowerPlay approved Cisco hardware and infrastructure that had adequate bandwidth and QoS standards that prioritize PowerPlay gaming packets at all others' expense. Newell conceded that Internet service providers (ISPs) would bear the brunt of this expense: \"The ISPs are going to need to spend a fair amount of money to be compliant with PowerPlay. But how they get that back is up to them. Some will have a tiered service, and some will just try to recoup their investment through reduced customer churn and customer acquisition.\" Despite never deploying the dial-up plan featuring PowerPlay 1.0, Valve announced in January 2001 that the standard had indeed been finalized. 12 months after its announcement, PowerPlay was abandoned.\nPipeline.\nIn July 2013, Valve announced Pipeline, an intern project consisting of ten high school students working together to learn how to create video game content. Pipeline serves to discuss and answer questions that teenagers often ask about the video game industry, and see if it is possible to train a group of teenagers with minimal work experience to work for a company like Valve. The latter purpose breaks Valve's tradition of employing experienced developers, as the company is not good at \"teaching people straight out of school\".\nLegal disputes.\n\"Valve Corporation v. Vivendi Universal Games\".\nBetween 2002 and 2005, Valve was involved in a complex legal dispute with its publisher, Vivendi Universal Games (under Vivendi's brand Sierra Entertainment). Valve had entered into a publishing agreement with Sierra to release \"Half-Life\" and subsequent games in 1997, with the contract giving Sierra some intellectual property (IP) rights to Valve's games. After Valve began development of \"Half-Life 2\", it agreed a new contract with Sierra in 2001, removing these rights from Sierra and giving Valve some rights for digital distribution. Internally, Valve started work on Steam as a means to digitally distribute these games, and first revealed this project at the March 2002 Game Developers Conference.\nBy August 2002, Valve had found that Sierra was distributing copies of their games to Internet cafes against the terms of their contracts and filed a lawsuit against Sierra and Vivendi. In addition to claims of copyright infringement, Valve asserted that Sierra breached contract by withholding royalties and delaying the release of \"\" until after the holiday season. Vivendi and Sierra countersued, stating that Valve had misrepresented their position in the revised 2001 contract since they had been working on Steam at that point as a means to circumvent the publishing agreement. Vivendi sought intellectual property rights to \"Half-Life\" and a ruling preventing Valve from using Steam to distribute \"Half-Life 2\".\nOn November 29, 2004, Judge Thomas Samuel Zilly of the U.S. District Court for the Western District of Washington ruled in favor of Valve. The ruling stated that Vivendi Universal and its affiliates (including Sierra) were not authorized to distribute Valve games, either directly or indirectly, through cyber caf\u00e9s to end users for pay-to-play activities pursuant to the parties' publishing agreement. In addition, Judge Zilly ruled that Valve could recover copyright damages for infringements without regard to the publishing agreement's limitation of liability clause. Valve posted on the Steam website that the companies had come to a settlement in court on April 29, 2005. Electronic Arts announced on July 18, 2005, that they would partner with Valve in a multi-year deal to distribute their games, replacing Vivendi Universal. As a result of the trial, the arbitrator also awarded Valve $2,391,932.\n\"Valve Corporation v. Activision Blizzard\".\nIn April 2009, Valve sued Activision Blizzard, which acquired Sierra Entertainment after a merger with its parent company, Vivendi Universal Games. Activision had allegedly refused to honor the \"Valve v. Vivendi\" arbitration agreement. Activision had only paid Valve $1,967,796 of the $2,391,932 award, refusing to pay the remaining $424,136, claiming it had overpaid that sum in the past years.\n\"Dota\" intellectual property ownership.\n\"Defense of the Ancients\" (DotA) was a landmark mod first released in 2003 that created the basis of the genre of multiplayer online battle arena (MOBA). It was originally developed by Kyle Sommer (who goes by the alias \"Eul\") within Blizzard Entertainment's \"\" via its world editor, and spawned several similar efforts, notably \"DotA-Allstars\". While there had been several that contributed to \"DotA-Allstars\", the project was managed primarily by Steve \"Guinsoo\" Feak, and later by \"IceFrog\". IceFrog was eventually hired by Valve in 2009, with the rights to the \"DotA\" intellectual property being sold to Valve the following year. Eul was also hired into Valve by 2010. Valve then subsequently filed trademarks towards a sequel to \"DotA\", titled \"Dota 2\". DotA-Allstars, LLC, a group of former contributors to the \"DotA-Allstars\" project, filed an opposing trademark in August 2010 to contest Valve's claim it owned the property rights.\nDotA-Allstars, LLC was eventually acquired by Blizzard to start development of \"Blizzard All-Stars\". Blizzard took over the trademark challenge. The United States Patent &amp; Trademark Office initially ruled in Valve's favor. By this point, Riot Games had hired Guinsoo to help develop their own MOBA, \"League of Legends\". As with IceFrog, Feak transferred his rights to the \"Dota\" property to Riot, who in turn sold those to Blizzard. Blizzard filed a lawsuit against Valve to challenge Valve's ownership, pitting the rights assigned through IceFrog to Guinsoo at odds. The case \"Blizzard Entertainment v. Valve Corporation\" was settled out of court in May 2012; Valve retained the right to use \"Dota\" commercially, while Blizzard reserved the right for fans to use \"Dota\" non-commercially. Blizzard changed the names of its own projects to remove the \"Dota\" term, and renamed \"Blizzard All-Stars\" as \"Heroes of the Storm\". Valve's \"Dota 2\" was released in 2013.\nIn 2014, mobile developers Lilith and uCool released their games \"Dota Legends\" and \"Heroes Charge\", respectively. Both were influenced by \"Dota\" and the sequels. In 2017, Valve and Blizzard took joint action against these companies, citing copyright issues related to the \"Dota\" names. uCool argued that the \"Dota\" games were a collective work and could not be copyrighted by anyone in particular, but the presiding judge, Charles R. Breyer, felt that, due to the trio's actions as maintainers of the \"Dota\" mods, they had a rightful copyright claim to this. Separately, Lilith and uCool argued that Eul had, in a forum post from September 2004, assigned an open-source copyright license to \"Dota\", which would make Valve and Blizzard's copyright claims void. The case was later heard by a jury.\n\"ACCC v. Valve Corporation\".\nThe Australian Competition &amp; Consumer Commission (ACCC) announced it was taking action against Valve in 2014. On March 29, 2016, Valve was found guilty of breaching Australian consumer law because:\nDuring the prosecution of this case, Valve implemented a refund policy for Steam purchases, but the case still reviewed Valve's actions prior to the onset of the lawsuit. The court overseeing the case sided with the ACCC in assigning a A$ (about US$) fine against Valve in December 2016, as well as requiring Valve to inform Australian consumers of their rights when purchasing games from Steam. Valve appealed the court's determination that it \"engaged in misleading or deceptive conduct and made false or misleading representations about consumer guarantees\", as well as seeking to appeal the fine, but the Australian higher courts rejected the appeals in December 2017. In January 2018, Valve filed for a \"special leave\" of the court's decision, appealing to the High Court of Australia. The High Court dismissed this claim in April 2018, asserting that Valve still was liable under Australian law since it sold products directly to its citizens.\n\"UFC Que Choisir v. Valve Corporation\".\nConsumer rights group UFC Que Choisir, based in France, filed a lawsuit against Valve in December 2015, claiming users should be able to resell their software. The High Court of Paris ruled in favor of UFC Que Choisir in September 2019, stating that Valve must allow the resale of Steam games. Valve stated it will appeal the decision.\nSkins gambling.\nValve was named as a defendant in two lawsuits in June and July 2016 related to third-party gambling sites that use the Steamworks API to allow betting with the virtual currency of cosmetic weapon replacement textures, better known as \"skins\", from \"\", which through these sites can be converted from or to real-world money. Both suits assert Valve aiding in underaged gambling. Valve subsequently stated it has no commercial ties with these sites, and that it would demand these sites cease their use of the Steamworks API as they violate the authorized use policies. In October 2016, the Washington State Gambling Commission required Valve to stop the use of virtual skins for gambling on Steam, stating they would face legal repercussions if they failed to co-operate. On October 17, 2016, Valve sent a letter to the Washington State Gambling Commission stating that they had \"no business relationship with such gambling sites\", asserting that they come into existence, operate, and go out of existence without their knowledge and consent, adding that they were not aware of any such law that Steam or any of their games were violating.\nAnti-competitive practices.\nIn February 2017, the European Commission began investigating Valve and five other publishers\u2014Bandai Namco Entertainment, Capcom, Focus Home Interactive, Koch Media and ZeniMax Media\u2014for anti-competitive practices, specifically the use of geo-blocking through the Steam storefront and Steam product keys to prevent access to software to citizens of certain countries. Such practices would be against the Digital Single Market initiative by the European Union. While the other five companies named are in stages of settling with the EU as of August 2019, Valve has stated it plans to fight the charges, asserting that geo-blocking affects less than 3% of its games, and that it had turned off such geo-blocking within the EU in 2015.\nIn January 2021, five gamers filed a proposed class-action antitrust lawsuit in California against Valve, alleging that the company \"abuses the Steam platform's market power\" by requiring game developers and publishers to enter into a \"most favored nation\" agreement with Valve, restricting their ability to sell games for less on other platforms and thereby preventing price competition.\nIn May 2021, Wolfire Games filed a proposed class-action antitrust lawsuit against Valve, alleging that the company exerts monopoly power over the PC gaming market and uses its \"gatekeeper role\" to \"wield extreme power over publishers of PC Desktop Games\" and to extract \"an extraordinarily high cut from nearly every sale that passes through its store.\" Although a motion by Valve to dismiss the original lawsuit was granted in November 2021, Wolfire was allowed to file a revised complaint, and in May 2022 US District Court Judge John C. Coughenour ruled that that lawsuit could proceed, finding that Wolfire's allegations were \"sufficient to plausibly allege unlawful conduct.\" Wolfire's suit was consolidated with a similar lawsuit from another developer. In November 2024, it was affirmed into a class-action lawsuit, with any developer affected by Valve's revenue cut able to be part of the class.\nIn June 2024, Vicki Shotbolt, a children's digital rights activist, filed a lawsuit with the Competition Appeal Tribunal in the UK that accuses Valve of \"rigging the market\" for PC games, alleging that Valve used its market dominance to overcharge 14 million people in the UK and seeking damages of \u00a322 to \u00a344 per affected customer, or \u00a3656 million in total.\n\"Valve Corporation v. Zaiger, LLC\".\nIn 2023, Valve sued a law firm, Zaiger, alleging that it attempted to extort settlements from Valve by threatening to bring numerous antitrust arbitration cases on behalf of Steam customers, a tactic referred to as \"mass arbitration\". Valve also brought suit against a litigation financier for Zaiger over the funding of a social media campaign to recruit Steam users as clients. Valve alleged that they improperly interfered with its contracts with Steam customers and abused the arbitration process by signing up clients with the intent of obtaining settlements slightly lower than the cost of arbitration filing fees, rather than arbitrating their claims. Valve said that it was targeted due to the terms of the Steam Subscriber Agreement, in which Valve would be responsible for the fees and costs associated with arbitration. The lawsuit was dismissed without prejudice by the US District Court for the Western District of Washington in 2024 due to personal jurisdiction issues. In September 2024, Valve changed its Steam Subscriber Agreement to require disputes to proceed in court, specifically in King County, Washington, with no option of arbitration.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52843", "revid": "1288619455", "url": "https://en.wikipedia.org/wiki?curid=52843", "title": "Gesso", "text": "Paint primer composed of a white pigment and a binder\nGesso (; 'chalk', from the , from ), also known as \"glue gesso\" or \"Italian gesso\", is a white paint mixture used to coat rigid surfaces such as wooden painting panels or masonite as a permanent absorbent primer substrate for painting. It consists of a binder mixed with chalk, gypsum, pigment, or any combination of these.\nGesso is used in painting as a preparation for any number of substrates such as wood panels, canvas and sculpture as a base for paint and other materials that are applied over it.\nCharacteristics.\nThe colour of gesso is usually white or off-white. Its absorbency makes it work with all painting media, including water-based media, different types of tempera and oil paint.\nMixing and applying it is a craft in itself, as it is usually applied in ten or more extremely thin layers. The hide glue mixture used to make the traditional gesso is rather brittle and susceptible to cracking, thus making it suitable for rigid surfaces only.\nWhen painting, there are several advantages to using gesso. It provides a strong foundation for the paint to adhere to, prevents the paint from soaking into the surface, and can also be used to achieve a desired texture or surface finish. Furthermore, gesso can help to extend the life of a painting by acting as a barrier to protect it from moisture, dust, and ultraviolet (UV) light.\nComposition.\nGesso is traditionally a mix of an animal glue binder (usually rabbit-skin glue), chalk, and white pigment.\nFor priming flexible canvas, an emulsion of gesso and linseed oil, also called \"half-chalk ground\", is used.\nAcrylic gesso is a mixture of white pigment and some kind of filler (chalk, silica, etc.) and acrylic resin dispersed in water. It produces a soft, flexible non-absorbent surface that is technically not \"gesso\" (although it is commonly called that by its manufacturers). It can contain calcium carbonate (CaCO3) to increase the absorbency of the primer coat as well as titanium dioxide or \"titanium white\" as a whitening agent. It is sold premixed for both sizing and priming panels and flexible canvas for painting. Art supply manufacturers market canvases pre-primed with acrylic gesso. Acrylic gesso can be colored, either commercially by replacing the titanium white with another pigment, such as carbon black, or by the artist directly, with the addition of an acrylic paint. Acrylic gesso can be odorous, due to the presence of ammonia or formaldehyde, which are added in small amounts as preservatives. Acrylic gesso's non-absorbent acrylic polymer base makes it incompatible with media that require an absorbent substrate, such as egg tempera. \"The Painter's Handbook\" notes a problem with using oil paints over an acrylic gesso ground instead of a traditional oil ground, citing a mismatch in flexibility that over time could cause the oil paint to delaminate.\nUses.\nSculptors may use gesso to prepare the shape of a final sculpture (fused bronze) or directly as a material for sculpting. Gesso can also be used as a layer between sculpted wood and gold leaf. In this case, a layer of refined and coloured clay called bole is used to cover the gesso before applying the gold. Bole is usually red in colour.\nGesso can also serve as a base on three-dimensional surfaces for the application of paint or gold leaf.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52847", "revid": "3091149", "url": "https://en.wikipedia.org/wiki?curid=52847", "title": "Children's literature", "text": "Stories, books, magazines, and poems primarily written for children\nChildren's literature or juvenile literature includes stories, books, magazines, and poems that are created for children. In addition to conventional literary genres, modern children's literature is classified by the intended age of the reader, ranging from picture books for the very young to young adult fiction for those nearing maturity.\nChildren's literature can be traced to traditional stories like fairy tales, which have only been identified as children's literature since the eighteenth century, and songs, part of a wider oral tradition, which adults shared with children before publishing existed. The development of early children's literature, before printing was invented, is difficult to trace. Even after printing became widespread, many classic \"children's\" tales were originally created for adults and later adapted for a younger audience. Since the fifteenth century much literature has been aimed specifically at children, often with a moral or religious message. Children's literature has been shaped by religious sources, like Puritan traditions, or by more philosophical and scientific standpoints with the influences of Charles Darwin and John Locke. The late nineteenth and early twentieth centuries are known as the \"Golden Age of Children's Literature\" because many classic children's books were published then.\nDefinition.\nThere is no single or widely used definition of children's literature. It can be broadly defined as the body of written works and accompanying illustrations produced in order to entertain or instruct young people. The genre encompasses a wide range of works, including acknowledged classics of world literature, picture books and easy-to-read stories written exclusively for children, and fairy tales, lullabies, fables, folk songs, and other primarily orally transmitted materials or more specifically defined as fiction, non-fiction, poetry, or drama intended for and used by children and young people. One writer on children's literature defines it as \"all books written for children, excluding works such as comic books, joke books, cartoon books, and non-fiction works that are not intended to be read from front to back, such as dictionaries, encyclopedias, and other reference materials\". However, others would argue that children's comics should also be included: \"Children's Literature studies has traditionally treated comics fitfully and superficially despite the importance of comics as a global phenomenon associated with children\".\nThe \"International Companion Encyclopedia of Children's Literature\" notes that \"the boundaries of genre... are not fixed but blurred\". Sometimes, no agreement can be reached about whether a given work is best categorized as literature for adults or children. Some works defy easy categorization. J. K. Rowling's \"Harry Potter\" series was written and marketed for children, but it is also popular among adults. The series' extreme popularity led \"The New York Times\" to create a separate bestseller list for children's books.\nDespite the widespread association of children's literature with picture books, spoken narratives existed before printing, and the root of many children's tales go back to ancient storytellers. Seth Lerer, in the opening of \"Children's Literature: A Reader's History from Aesop to Harry Potter\", says, \"This book presents a history of what children have heard and read... The history I write of is a history of \"reception\".\"\nHistory.\nEarly children's literature consisted of spoken stories, songs, and poems, used to educate, instruct, and entertain children.\nIt was only in the eighteenth century, with the development of the concept of childhood, that a separate genre of children's literature began to emerge, with its own divisions, expectations, and canon. The earliest of these books were educational books, books on conduct, and simple ABCs\u2014often decorated with animals, plants, and anthropomorphic letters.\nIn 1962, French historian Philippe Ari\u00e8s argues in his book \"Centuries of Childhood\" that the modern concept of childhood only emerged in recent times. He explains that children were in the past not considered as greatly different from adults and were not given significantly different treatment. As evidence for this position, he notes that, apart from instructional and didactic texts for children written by clerics like the Venerable Bede and \u00c6lfric of Eynsham, there was a lack of any genuine literature aimed specifically at children before the 18th century.\nOther scholars have qualified this viewpoint by noting that there was a literature designed to convey the values, attitudes, and information necessary for children within their cultures, such as the \"Play of Daniel\" from the twelfth century. Pre-modern children's literature, therefore, tended to be of a didactic and moralistic nature, with the purpose of conveying conduct-related, educational and religious lessons.\nEarly-modern Europe.\nDuring the seventeenth century, the concept of childhood began to emerge in Europe. Adults saw children as separate beings, innocent and in need of protection and training by the adults around them. The English philosopher John Locke developed his theory of the tabula rasa in his 1690 \"An Essay Concerning Human Understanding\". In Locke's philosophy, \"tabula rasa\" was the theory that the (human) mind is at birth a \"blank slate\" without rules for processing data, and that data is added and rules for processing are formed solely by one's sensory experiences. A corollary of this doctrine was that the mind of the child was born blank and that it was the duty of the parents to imbue the child with correct notions. Locke himself emphasized the importance of providing children with \"easy pleasant books\" to develop their minds rather than using force to compel them: \"Children may be cozen'd into a knowledge of the letters; be taught to read, without perceiving it to be anything but a sport, and play themselves into that which others are whipp'd for.\" He also suggested that picture books be created for children.\nIn the nineteenth century, a few children's titles became famous as classroom reading texts. Among these were the fables of Aesop and Jean de la Fontaine and Charles Perraults's 1697 \"Tales of Mother Goose\". The popularity of these texts led to the creation of a number of nineteenth-century fantasy and fairy tales for children which featured magic objects and talking animals.\nAnother influence on this shift in attitudes came from Puritanism, which stressed the importance of individual salvation. Puritans were concerned with the spiritual welfare of their children, and there was a large growth in the publication of \"good godly books\" aimed squarely at children. Some of the most popular works were by James Janeway, but the most enduring book from this movement, still read today, especially in modernised versions, is \"The Pilgrim's Progress\" (1678) by John Bunyan.\nChapbooks, pocket-sized pamphlets that were often folded instead of being stitched, were published in Britain; illustrated by woodblock printing, these inexpensive booklets reprinted popular ballads, historical re-tellings, and folk tales. Though not specifically published for children at this time, young people enjoyed the booklets as well. Johanna Bradley says, in \"From Chapbooks to Plum Cake\", that chapbooks kept imaginative stories from being lost to readers under the strict Puritan influence of the time.\nHornbooks also appeared in England during this time, teaching children basic information such as the alphabet and the Lord's Prayer. These were brought from England to the American colonies in the mid-seventeenth century.\nThe first such book was a catechism for children, written in verse by the Puritan John Cotton. Known as \"Spiritual Milk for Boston Babes\", it was published in 1646, appearing both in England and Boston. Another early book, \"The New England Primer\", was in print by 1691 and used in schools for 100 years. The primer begins with \"The young Infant's or Child's morning Prayer\" and evening prayer. It then shows the alphabet, vowels, consonants, double letters, and syllables before providing a religious rhyme of the alphabet, beginning \"In Adam's fall We sinned all...\", and continues through the alphabet. It also contained religious maxims, acronyms, spelling help and other educational items, all decorated by woodcuts.\nIn 1634, the \"Pentamerone\" from Italy became the first major published collection of European folk tales. Charles Perrault began recording fairy tales in France, publishing his first collection in 1697. They were not well received among the French literary society, who saw them as only fit for old people and children. In 1658, John Amos Comenius in Bohemia published the informative illustrated \"Orbis Pictus\", for children under six learning to read. It is considered to be the first picture book produced specifically for children.\nThe first Danish children's book was \"The Child's Mirror\" by Niels Bredal in 1568, an adaptation of a courtesy book by the Dutch priest Erasmus. \"A Pretty and Splendid Maiden's Mirror\", an adaptation of a German book for young women, became the first Swedish children's book upon its 1591 publication. Sweden published fables and a children's magazine by 1766.\nIn Italy, Giovanni Francesco Straparola released \"The Facetious Nights of Straparola\" in the 1550s. Called the first European storybook to contain fairy-tales, it eventually had 75 separate stories and written for an adult audience. Giulio Cesare Croce also borrowed from some stories children enjoyed for his books.\nRussia's earliest children's books, primers, appeared in the late sixteenth century. An early example is \"ABC-Book\", an alphabet book published by Ivan Fyodorov in 1571. The first picture book published in Russia, Karion Istomin's \"The Illustrated Primer\", appeared in 1694. Peter the Great's interest in modernizing his country through Westernization helped Western children's literature dominate the field through the eighteenth century. Catherine the Great wrote allegories for children, and during her reign, Nikolai Novikov started the first juvenile magazine in Russia.\nOrigins of the modern genre.\nThe modern children's book emerged in mid-18th-century England. A growing polite middle-class and the influence of Lockean theories of childhood innocence combined to create the beginnings of childhood as a concept. In an article for the British Library, professor MO Grenby writes, \"in the 1740s, a cluster of London publishers began to produce new books designed to instruct and delight young readers. Thomas Boreman was one. Another was Mary Cooper, whose two-volume \"Tommy Thumb's Pretty Song Book\" (1744) is the first known nursery rhyme collection. But the most celebrated of these pioneers is John Newbery, whose first book for the entertainment of children was \"A Little Pretty Pocket-Book\".\"\nWidely considered the first modern children's book, \"A Little Pretty Pocket-Book\" was the first children's publication aimed at giving enjoyment to children, containing a mixture of rhymes, picture stories and games for pleasure. Newbery believed that play was a better enticement to children's good behavior than physical discipline, and the child was to record his or her behaviour daily. The book was child\u2013sized with a brightly colored cover that appealed to children\u2014something new in the publishing industry. Known as gift books, these early books became the precursors to the toy books popular in the nineteenth century. Newbery was also adept at marketing this new genre. According to the journal \"The Lion and the Unicorn\", \"Newbery's genius was in developing the fairly new product category, children's books, through his frequent advertisements... and his clever ploy of introducing additional titles and products into the body of his children's books.\" Professor Grenby writes, \"Newbery has become known as the 'father of children's literature' chiefly because he was able to show that publishing children's books could be a commercial success.\"\nThe improvement in the quality of books for children and the diversity of topics he published helped make Newbery the leading producer of children's books in his time. He published his own books as well as those by authors such as Samuel Johnson and Oliver Goldsmith; the latter may have written \"The History of Little Goody Two-Shoes\", Newbery's most popular book.\nAnother philosopher who influenced the development of children's literature was Jean-Jacques Rousseau, who argued that children should be allowed to develop naturally and joyously. His idea of appealing to a children's natural interests took hold among writers for children. Popular examples included Thomas Day's \"The History of Sandford and Merton\", four volumes that embody Rousseau's theories. Furthermore, Maria and Richard Lovell Edgeworth's \"Practical Education: The History of Harry and Lucy\" (1780) urged children to teach themselves.\nRousseau's ideas also had great influence in Germany, especially on German Philanthropism, a movement concerned with reforming both education and literature for children. Its founder, Johann Bernhard Basedow, authored \"Elementarwerk\" as a popular textbook for children that included many illustrations by Daniel Chodowiecki. Another follower, Joachim Heinrich Campe, created an adaptation of \"Robinson Crusoe\" that went into over 100 printings. He became Germany's \"outstanding and most modern\" writer for children. According to Hans-Heino Ewers in \"The International Companion Encyclopedia of Children's Literature\", \"It can be argued that from this time, the history of European children's literature was largely written in Germany.\"\nThe Brothers Grimm preserved and published the traditional tales told in Germany. They were so popular in their home country that modern, realistic children's literature began to be looked down on there. This dislike of non-traditional stories continued there until the beginning of the next century. In addition to their collection of stories, the Grimm brothers also contributed to children's literature through their academic pursuits. As professors, they had a scholarly interest in the stories, striving to preserve them and their variations accurately, recording their sources.\nA similar project was carried out by the Norwegian scholars Peter Christen Asbj\u00f8rnsen and J\u00f8rgen Moe, who collected Norwegian fairy tales and published them as \"Norwegian Folktales\", often referred to as \"Asbj\u00f8rnsen and Moe\". By compiling these stories, they preserved Norway's literary heritage and helped create the Norwegian written language.\nDanish author and poet Hans Christian Andersen traveled through Europe and gathered many well-known fairy tales and created new stories in the fairy tale genre.\nIn Switzerland, Johann David Wyss published \"The Swiss Family Robinson\" in 1812, with the aim of teaching children about family values, good husbandry, the uses of the natural world and self-reliance. The book became popular across Europe after it was translated into French by Isabelle de Montolieu.\nE. T. A. Hoffmann's tale \"The Nutcracker and the Mouse King\" was published in 1816 in a German collection of stories for children, \"Kinder-M\u00e4rchen\". It is the first modern short story to introduce bizarre, odd and grotesque elements in children's literature and thereby anticipates Lewis Carroll's tale, \"Alice's Adventures in Wonderland\". There are not only parallels concerning the content (the weird adventures of a young girl in a fantasy land), but also the origin of the tales as both are dedicated and given to a daughter of the author's friends.\nGolden age.\nThe shift to a modern genre of children's literature occurred in the mid-19th century; didacticism of a previous age began to make way for more humorous, child-oriented books, more attuned to the child's imagination. The availability of children's literature greatly increased as well, as paper and printing became widely available and affordable, the population grew and literacy rates improved.\n\"Tom Brown's School Days\" by Thomas Hughes appeared in 1857, and is considered to be the founding book in the school story tradition. However, it was Lewis Carroll's fantasy, \"Alice's Adventures in Wonderland\", published in 1865 in England, that signaled the change in writing style for children to an imaginative and empathetic one. Regarded as the first \"English masterpiece written for children\" and as a founding book in the development of fantasy literature, its publication opened the \"First Golden Age\" of children's literature in Britain and Europe that continued until the early 1900s. The fairy-tale absurdity of Wonderland has solid historical ground as a satire of the serious problems of the Victorian era. Lewis Carroll is ironic about the prim and all-out regulated life of the \"golden\" Victorian century. One other noteworthy publication was Mark Twain's book \"Tom Sawyer\" (1876), which was one of the first \"boy books\", intended for children but enjoyed by both children and adults alike. These were classified as such for the themes they contained, consisting of fighting and work. Another important book of that decade was \"The Water-Babies, A Fairy Tale for a Land Baby\", by Rev. Charles Kingsley (1862), which became extremely popular and remains a classic of British children's literature.\nIn 1883, Carlo Collodi wrote the first Italian fantasy novel, \"The Adventures of Pinocchio\", which was translated many times. In that same year, Emilio Salgari, the man who would become \"the adventure writer par excellence for the young in Italy\" first published his legendary character \"Sandokan\". In Britain, \"The Princess and the Goblin\" and its sequel \"The Princess and Curdie\", by George MacDonald, appeared in 1872 and 1883, and the adventure stories \"Treasure Island\" and \"Kidnapped\", both by Robert Louis Stevenson, were extremely popular in the 1880s. Rudyard Kipling's \"The Jungle Book\" was first published in 1894, and J. M. Barrie told the story of Peter Pan in the novel \"Peter and Wendy\" in 1911. Johanna Spyri's two-part novel \"Heidi\" was published in Switzerland in 1880 and 1881.\nIn the US, children's publishing entered a period of growth after the American Civil War in 1865. Boys' book writer Oliver Optic published over 100 books. In 1868, the \"epoch-making\" \"Little Women\", the fictionalized autobiography of Louisa May Alcott, was published. This \"coming of age\" story established the genre of realistic family books in the United States. Mark Twain released \"Tom Sawyer\" in 1876. In 1880 another bestseller, \"\", a collection of African American folk tales adapted and compiled by Joel Chandler Harris, appeared.\nIn the late nineteenth and early twentieth centuries, a plethora of children's novels began featuring realistic, non-magical plotlines. Certain titles received international success such as Robert Louis Stevenson's \"Treasure Island\" (1883), L. M. Montgomery's \"Anne of Green Gables\" (1908), and Louisa May Alcott's \"Little Women\" (1869).\nNational traditions.\nUnited Kingdom.\nLiterature for children had developed as a separate category of literature especially in the Victorian era, with some works becoming internationally known, such as Lewis Carroll's \"Alice's Adventures in Wonderland\" (1865) and its sequel \"Through the Looking-Glass\" (1871). Another classic of the period is Anna Sewell's animal novel \"Black Beauty\" (1877). At the end of the Victorian era and leading into the Edwardian era, author and illustrator Beatrix Potter published \"The Tale of Peter Rabbit\" in 1902. Potter went on to produce 23 children's books and become very wealthy. A pioneer of character merchandising, in 1903 she patented a Peter Rabbit doll, making Peter the first licensed character. Michael O. Tunnell and James S. Jacobs, professors of children's literature at Brigham Young University, write, \"Potter was the first to use pictures as well as words to tell the story, incorporating coloured illustration with text, page for page.\"\nRudyard Kipling published \"The Jungle Book\" in 1894. A major theme in the book is abandonment followed by fostering, as in the life of Mowgli, echoing Kipling's own childhood. In the latter years of the 19th century, precursors of the modern picture book were illustrated books of poems and short stories produced by English illustrators Randolph Caldecott, Walter Crane, and Kate Greenaway. These had a larger proportion of pictures to words than earlier books, and many of their pictures were in colour. Some British artists made their living illustrating novels and children's books, among them Arthur Rackham, Cicely Mary Barker, W. Heath Robinson, Henry J. Ford, John Leech, and George Cruikshank. In the 1890s, some of the best known fairy tales from England were compiled in Joseph Jacobs' \"English Fairy Tales\", including \"Jack and the Beanstalk\", \"Goldilocks and the Three Bears\", \"The Three Little Pigs\", \"Jack the Giant Killer\" and \"Tom Thumb\".\nThe Kailyard School of Scottish writers, notably J. M. Barrie, creator of \"Peter Pan\" (1904), presented an idealised version of society and brought fantasy and folklore back into fashion. In 1908, Kenneth Grahame wrote the children's classic \"The Wind in the Willows\" and the Scouts founder Robert Baden-Powell's first book, \"Scouting for Boys\", was published. Inspiration for Frances Hodgson Burnett's novel \"The Secret Garden\" (1910) was the Great Maytham Hall Garden in Kent. While fighting in the trenches for the British Army in World War I, Hugh Lofting created the character of Doctor Dolittle, who appears in a series of twelve books.\nThe Golden Age of Children's Literature ended with World War I. The period before World War II was much slower in children's publishing. The main exceptions in England were the publications of \"Winnie-the-Pooh\" by A. A. Milne in 1926, \"Tales of Toytown\" by S.G. Hulme Beaman in 1928, the first \"Mary Poppins\" book by P. L. Travers in 1934, \"The Hobbit\" by J. R. R. Tolkien in 1937, and the Arthurian \"The Sword in the Stone\" by T. H. White in 1938. Children's mass paperback books were first released in England in 1940 under the Puffin Books imprint, and their lower prices helped make book buying possible for children during World War II. Enid Blyton's books have been among the world's bestsellers since the 1930s, selling more than 600 million copies. Blyton's books are still enormously popular and have been translated into almost 90 languages. She wrote on a wide range of topics including education, natural history, fantasy, mystery, and biblical narratives and is best remembered today for her Noddy, \"The Famous Five\", The Secret Seven, and \"The Adventure Series\". The first of these children's stories, \"Five on a Treasure Island\", was published in 1942.\nIn the 1950s, the book market in Europe began to recover from the effects of the two world wars. An informal literary discussion group associated with the English faculty at the University of Oxford, were the \"Inklings\", with the major fantasy novelists C. S. Lewis and J. R. R. Tolkien as its main members. C. S. Lewis published the first installment of \"The Chronicles of Narnia\" series in 1950, while Tolkien is best known, in addition to \"The Hobbit\", as the author of \"The Lord of the Rings\" (1954). Another writer of fantasy stories is Alan Garner author of \"Elidor\" (1965), and \"The Owl Service\" (1967). The latter is an adaptation of the myth of Blodeuwedd from the \"Mabinogion\", set in modern Wales \u2013 it won Garner the annual Carnegie Medal from the Library Association, recognising the year's best children's book by a British author.\nMary Norton wrote \"The Borrowers\" (1952), featuring tiny people who borrow from humans. Dodie Smith's \"The Hundred and One Dalmatians\" was published in 1956. Philippa Pearce's \"Tom's Midnight Garden\" (1958) has Tom opening the garden door at night and entering into a different age.\nRoald Dahl wrote children's fantasy novels which were often inspired from experiences from his childhood, with often unexpected endings, and unsentimental, dark humour. Dahl was inspired to write \"Charlie and the Chocolate Factory\" (1964), featuring the eccentric chocolatier Willy Wonka, having grown up near two chocolate makers in England who often tried to steal trade secrets by sending spies into the other's factory. His other works include \"James and the Giant Peach\" (1961), \"Fantastic Mr. Fox\" (1970), \"The BFG\" (1982), \"The Witches\" (1983), and \"Matilda\" (1988). Starting in 1958, Michael Bond published more than twenty humorous stories about Paddington Bear.\nBoarding schools in literature are centred on older pre-adolescent and adolescent school life, and are most commonly set in English boarding schools. Popular school stories from this period include Ronald Searle's comic \"St Trinian's\" (1949\u20131953) and his illustrations for Geoffrey Willans's \"Molesworth\" series, Jill Murphy's \"The Worst Witch\", and the \"Jennings\" series by Anthony Buckeridge.\nRuth Manning-Sanders's first collection, \"A Book of Giants\", retells a number of giant stories from around the world. Susan Cooper's \"The Dark Is Rising\" is a five-volume fantasy saga set in England and Wales. Raymond Briggs' children's picture book \"The Snowman\" (1978) has been adapted as an animation, shown every Christmas on British television. The Reverend. W. Awdry and son Christopher's \"The Railway Series\" features Thomas the Tank Engine. Margery Sharp's series \"The Rescuers\" is based on a heroic mouse organisation. The third Children's Laureate Michael Morpurgo published \"War Horse\" in 1982. Dick King-Smith's novels include \"The Sheep-Pig\" (1984). Diana Wynne Jones wrote the young adult fantasy novel \"Howl's Moving Castle\" in 1986. Anne Fine's \"Madame Doubtfire\" (1987) is based around a family with divorced parents. Anthony Horowitz's \"Alex Rider\" series begins with \"Stormbreaker\" (2000).\nPhilip Pullman's \"His Dark Materials\" is an epic trilogy of fantasy novels consisting of \"Northern Lights\" (1995, published as \"The Golden Compass\" in North America), \"The Subtle Knife\" (1997), and \"The Amber Spyglass\" (2000). It follows the coming of age of two children, Lyra Belacqua and Will Parry, as they wander through a series of parallel universes. The three novels have won a number of awards, most notably the 2001 Whitbread Book of the Year prize, won by \"The Amber Spyglass\". \"Northern Lights\" won the Carnegie Medal for children's fiction in 1995.\nJ. K. Rowling's \"Harry Potter\" fantasy sequence of seven novels chronicles the adventures of the adolescent wizard Harry Potter. The series began with \"Harry Potter and the Philosopher's Stone\" in 1997 and ended with the seventh and final book \"Harry Potter and the Deathly Hallows\" in 2007; becoming the best selling book-series in history. The series has been translated into 67 languages, so placing Rowling among the most translated authors in history.\nNeil Gaiman wrote the dark fantasy novella \"Coraline\" (2002). His 2008 fantasy, \"The Graveyard Book\", traces the story of a boy who is raised by the supernatural occupants of a graveyard. In 2001, Terry Pratchett received the Carnegie Medal (his first major award) for \"The Amazing Maurice and His Educated Rodents\". Cressida Cowell's \"How to Train Your Dragon\" series was published between 2003 and 2015.\nAdventure fiction.\nWhile Daniel Defoe wrote \"Robinson Crusoe\" in 1719 (spawning so many imitations it defined a genre, Robinsonade), adventure stories written specifically for children began in the nineteenth century. Early examples from British authors include Frederick Marryat's \"The Children of the New Forest\" (1847) and Harriet Martineau's \"The Peasant and the Prince\" (1856).\nThe Victorian era saw the development of the genre, with W. H. G. Kingston, R. M. Ballantyne and G. A. Henty specializing in the production of adventure fiction for boys. This inspired writers who normally catered to adult audiences to write for children, a notable example being Robert Louis Stevenson's classic pirate story \"Treasure Island\" (1883).\nIn the years after the First World War, writers such as Arthur Ransome developed the adventure genre by setting the adventure in Britain rather than distant countries. In the 1930s he began publishing his Swallows and Amazons series of children's books about the school-holiday adventures of children, mostly in the English Lake District and the Norfolk Broads. Many of them involve sailing; fishing and camping are other common subjects. Biggles was a popular series of adventure books for young boys, about James Bigglesworth, a fictional pilot and adventurer, by W. E. Johns. Between 1941 and 1961 there were 60 issues with stories about Biggles, and in the 1960s occasional contributors included the BBC astronomer Patrick Moore. Between 1940 and 1947, W. E. Johns contributed sixty stories featuring the female pilot Worrals. \nWilliam Golding's 1954 dystopian adventure novel \"Lord of the Flies\" focuses on a group of British boys stranded on an uninhabited island and their disastrous attempt to govern themselves. Evoking epic themes, Richard Adams's 1972 survival and adventure novel \"Watership Down\" follows a small group of rabbits who escape the destruction of their warren and seek to establish a new home.\nGeoffrey Trease and Rosemary Sutcliff brought a new sophistication to the historical adventure novel. Philip Pullman in the Sally Lockhart novels and Julia Golding in the Cat Royal series have continued the tradition of the historical adventure.\nMagazines and comics.\nAn important aspect of British children's literature has been comic books and magazines. Amongst the most popular and longest running comics have been \"The Beano\" and \"The Dandy\", both first published in the 1930s. British comics in the 20th century evolved from illustrated penny dreadfuls of the Victorian era (featuring Sweeney Todd, Dick Turpin and \"Varney the Vampire\"). First published in the 1830s, according to \"The Guardian\", penny dreadfuls were \"Britain's first taste of mass-produced popular culture for the young.\" Robin Hood featured in a series of penny dreadfuls in 1838 which sparked the beginning of the mass circulation of Robin stories.\nDennis the Menace debuted in \"The Beano\" in 1951, while the popular stop-motion characters, Wallace and Gromit, guest-starred in the comic every four weeks from 2013. Important early magazines or story papers for older children were the \"Boy's Own Paper\", published from 1879 to 1967 and \"The Girl's Own Paper\" published from 1880 until 1956. In the 1890s, half-penny publications succeeded the penny dreadfuls in popularity among British children. These included \"The Half-penny Marvel\" and \"Union Jack\". From 1896, the cover of the half-penny comic \"Illustrated Chips\" featured the long-running comic strip of the tramps Weary Willie and Tired Tim, with its readers including a young Charlie Chaplin.\nOther story papers for older boys were \"The Hotspur\" (1933 to 1959) and \"The Rover\", which started in 1922 and was absorbed into \"Adventure\" in 1961 and \"The Wizard\" in 1963, and eventually folded in 1973. Many prominent authors contributed to the \"Boy's Own Paper\": cricketer W.G. Grace wrote for several issues, along with authors Sir Arthur Conan Doyle and R. M. Ballantyne, as well as Robert Baden-Powell, founder of the Scout Movement. Contributors to \"The Girl's Own Paper\" included Noel Streatfeild, Rosa Nouchette Carey, Sarah Doudney (1841\u20131926), Angela Brazil, Richmal Crompton, Fanny Fern, and Baroness Orczy.\nThe \"Eagle\" was a popular British comic for boys, launched in 1950 by Marcus Morris, an Anglican vicar from Lancashire. Revolutionary in its presentation and content, it was enormously successful; the first issue sold about 900,000 copies. Featured in colour on the front cover was its most recognisable story, \"Dan Dare, Pilot of the Future\", created with meticulous attention to detail. It was first published from 1950 to 1969, and relaunched from 1982 to 1994. Its sister comic was \"Girl\", whose early issues from 1951 featured the strip \"Kitty Hawke and her All-Girl Air Crew\". \"Roy of the Rovers\", an immensely popular comic strip featuring Roy Race, a striker for the fictional football team Melchester Rovers, first appeared in the \"Tiger\" in 1954. First published by Martin Handford in 1987, more than 73 million \"Where's Wally?\" picture puzzle books had been sold around the world by 2007.\nUnited States.\nChildren's literature has been a part of American culture since Europeans first settled in America. The earliest books were used as tools to instill self-control in children and preach a life of morality in Puritan society. Eighteenth-century American youth began to shift away from the social upbringing of its European counterpart, bringing about a change in children's literature. It was in this time that \"A Little Book for Little Children\" was written by T. W. in 1712. It includes what is thought to be the earliest nursery rhyme and one of the earliest examples of a textbook approaching education from the child's point of view, rather than the adult's.\nChildren's magazines in the United States began with the \"Young\" \"Misses' Magazine\" (1806) of Brooklyn, New York.\nOne of the most famous books of American children's literature is L. Frank Baum's fantasy novel \"The Wonderful Wizard of Oz\", published in 1900. \"By combining the English fondness for word play with the American appetite for outdoor adventure\", Connie Epstein in \"International Companion Encyclopedia Of Children's Literature\" says Baum \"developed an original style and form that stands alone\". Baum wrote fourteen more Oz novels, and other writers continued the Oz series into the twenty-first century.\nDemand continued to grow in North America between World War I and World War II, helped by the growth of libraries in both Canada and the United States. Children's reading rooms in libraries, staffed by specially trained librarians, helped create demand for classic juvenile books. Reviews of children's releases began appearing regularly in \"Publishers Weekly\" and in \"The Bookman\" magazine began to publish regular reviews of children's releases. The first Children's Book Week was launched in 1919. In that same year, Louise Seaman Bechtel became the first person to head a juvenile book publishing department in the country. She was followed by May Massee in 1922, and Alice Dalgliesh in 1934. During this period, Black authors began writing and publishing books for African American children. Writers like Helen Adele Whiting (1885\u20131959) and Jane Dabney Shackelford (1895\u20131979) produced books designed to instill pride in Black history and culture.\nThe American Library Association began awarding the Newbery Medal, the first children's book award, in 1922. The Caldecott Medal for illustration followed in 1938. The first book by Laura Ingalls Wilder about her life on the American frontier, \"Little House in the Big Woods\" appeared in 1932. In 1937 Dr. Seuss published his first book, entitled, \"And to Think That I Saw It on Mulberry Street\". The young adult book market developed during this period, thanks to sports books by popular writer John R. Tunis', the novel \"Seventeenth Summer\" by Maureen Daly, and the \"Sue Barton\" nurse book series by Helen Dore Boylston.\nThe already vigorous growth in children's books became a boom in the 1950s, and children's publishing became big business. In 1952, American journalist E. B. White published \"Charlotte's Web\", which was described as \"one of the very few books for young children that face, squarely, the subject of death\". Maurice Sendak illustrated more than two dozen books during the decade, which established him as an innovator in book illustration. The Sputnik crisis that began in 1957, provided increased interest and government money for schools and libraries to buy science and math books and the non-fiction book market \"seemed to materialize overnight\".\nThe 1960s saw an age of new realism in children's books emerge. Given the atmosphere of social revolution in 1960s America, authors and illustrators began to break previously established taboos in children's literature. Controversial subjects dealing with alcoholism, death, divorce, and child abuse were now being published in stories for children. Maurice Sendak's \"Where the Wild Things Are\" in 1963 and Louise Fitzhugh's \"Harriet the Spy\" in 1964 are often considered the first stories published in this new age of realism.\nEsther Forbes in \"Johnny Tremain\" (1943) and Mildred D. Taylor in \"Roll of Thunder, Hear My Cry\" (1976) continued the tradition of the historical adventure in an American setting. The modern children's adventure novel sometimes deals with controversial issues like terrorism, as in Robert Cormier's \"After the First Death\" in 1979, and warfare in the Third World, as in Peter Dickinson's \"AK\" in 1990.\nIn books for a younger age group, Bill Martin and John Archambault's \"Chicka Chicka Boom Boom\" (1989) presented a new spin on the alphabet book. Laura Numeroff published \"If You Give a Mouse a Cookie\" in 1985 and went on to create a series of similarly named books that is still popular for children and adults to read together.\nLloyd Alexander's \"The Chronicles of Prydain\" (1964\u20131968) was set in a fictionalized version of medieval Britain.\nContinental Europe.\nJohann David Wyss wrote the adventure novel \"The Swiss Family Robinson\" (1812). The period from 1890 until World War I is considered the Golden Age of Children's Literature in Scandinavia. Erik Werenskiold, Theodor Kittelsen, and Dikken Zwilgmeyer were especially popular, writing folk and fairy tales as well as realistic fiction. The 1859 translation into English by George Webbe Dasent helped increase the stories' influence. One of the most influential and internationally most successful Scandinavian children's books from this period is Selma Lagerl\u00f6fs \"The Wonderful Adventures of Nils\". Astrid Lindgren (\"Pippi Longstocking\") and Jostein Gaarder (\"Sophie's World\") are two of the best-known Scandinavian writers internationally. In Finland, some of the most significant children's book writers include Tove Jansson (\"Moomins\"), Oiva Paloheimo (\"Tirlittan\") and Elina Karjalainen (\"Uppo-Nalle\").\nThe interwar period saw a slow-down in output similar to Britain's, although \"one of the first mysteries written specifically for children\", \"Emil and the Detectives\" by Erich K\u00e4stner, was published in Germany in 1930. German writers Michael Ende (\"The Neverending Story\") and Cornelia Funke (\"Inkheart\") achieved international success with their fantasy books.\nThe period during and following World War II became the Classic Age of the picture book in Switzerland, with works by Alois Carigiet, Felix Hoffmann, and Hans Fischer. Nineteen sixty-three was the first year of the Bologna Children's Book Fair in Italy, which was described as \"the most important international event dedicated to the children's publishing\". For four days it brings together writers, illustrators, publishers, and book buyers from around the world.\nRussia and the Soviet Union.\nRussian folktales were collected by Aleksandr Afanasyev in his three-volume \"Narodnye russkie skazki\", and a selection of these were published in \"\u0420\u0443\u0441\u0441\u043a\u0438\u0435 \u0434\u0435\u0442\u0441\u043a\u0438\u0435 \u0441\u043a\u0430\u0437\u043a\u0438\" (Russian Children's Fairy Tales) in 1871. By the 1860s, literary realism and non-fiction dominated children's literature. More schools were started, using books by writers like Konstantin Ushinsky and Leo Tolstoy, whose \"Russian Reader\" included an assortment of stories, fairy tales, and fables. Books written specifically for girls developed in the 1870s and 1880s. Publisher and journalist Evgenia Tur wrote about the daughters of well-to-do landowners, while Alexandra Nikitichna Annenskaya's stories told of middle-class girls working to support themselves. Vera Zhelikhovsky, Elizaveta Kondrashova, and Nadezhda Lukhmanova also wrote for girls during this period.\nChildren's non-fiction gained great importance in Russia at the beginning of the century. A ten-volume children's encyclopedia was published between 1913 and 1914. Vasily Avenarius wrote fictionalized biographies of important people like Nikolai Gogol and Alexander Pushkin around the same time, and scientists wrote for books and magazines for children. Children's magazines flourished, and by the end of the century there were 61. Lidia Charskaya and Klavdiya Lukashevich continued the popularity of girls' fiction. Realism took a gloomy turn by frequently showing the maltreatment of children from lower classes. The most popular boys' material was Sherlock Holmes, and similar stories from detective magazines.\nThe state took control of children's literature during the October Revolution. Maksim Gorky edited the first children's \"Northern Lights\" under Soviet rule. People often label the 1920s as the Golden Age of Children's Literature in Russia. Samuil Marshak led that literary decade as the \"founder of (Soviet) children's literature\". As head of the children's section of the State Publishing House and editor of several children's magazines, Marshak exercised enormous influence by recruiting Boris Pasternak and Osip Mandelstam to write for children.\nIn 1932, professional writers in the Soviet Union formed the USSR Union of Writers, which served as the writer's organization of the Communist Party. With a children's branch, the official oversight of the professional organization brought children's writers under the control of the state and the police. Communist principles like collectivism and solidarity became important themes in children's literature. Authors wrote biographies about revolutionaries like Lenin and Pavlik Morozov. Alexander Belyayev, who wrote in the 1920s and 1930s, became Russia's first science fiction writer. According to Ben Hellman in the \"International Companion Encyclopedia of Children's Literature\", \"war was to occupy a prominent place in juvenile reading, partly compensating for the lack of adventure stories\", during the Soviet Period. More political changes in Russia after World War II brought further change in children's literature. Today, the field is in a state of flux because some older authors are being rediscovered and others are being abandoned.\nChina.\nThe 1911 Revolution and World War II brought political and social change that revolutionized children's literature in China. Western science, technology, and literature became fashionable. China's first modern publishing firm, Commercial Press, established several children's magazines, which included \"Youth Magazine\", and \"Educational Pictures for Children\". The first Chinese children's writer was Sun Yuxiu, an editor of Commercial Press, whose story \"The Kingdom Without a Cat\" was written in the language of the time instead of the classical style used previously. Yuxiu encouraged novelist Shen Dehong to write for children as well. Dehong went on to rewrite 28 stories based on classical Chinese literature specifically for children. In 1932, Zhang Tianyi published \"Big Lin and Little Lin\", the first full-length Chinese novel for children.\nThe Chinese Communist Revolution changed children's literature again. Many children's writers were denounced, but Tianyi and Ye Shengtao continued to write for children and created works that were aligned with Maoist ideology. The 1976 death of Mao Zedong provoked more changes that swept China. The work of many writers from the early part of the century became available again. In 1990 came \"General Anthology of Modern Children's Literature of China\", a fifteen-volume anthology of children's literature since the 1920s.\nBrazil.\nIn Brazil, Monteiro Lobato wrote a series of 23 books for children known as S\u00edtio do Picapau Amarelo (The Yellow Woodpecker Ranch), between 1920 and 1940. The series is considered representative of Brazilian children's literature and the Brazilian equivalent to children's classics such as C. S. Lewis, \"The Chronicles of Narnia\" and L. Frank Baum's \"The Wonderful Wizard of Oz\" series. The concept was introduced in Monteiro Lobato's 1920 short story \"A Menina do Narizinho Arrebitado\", and was later republished as the first chapter of \"Reina\u00e7\u00f5es de Narizinho\", which is the first novel of the series. The main setting is the \"S\u00edtio do Picapau Amarelo\", where a boy (Pedrinho), a girl (Narizinho) and their living and thinking anthropomorphic toys enjoy exploring adventures in fantasy, discovery and learning. On several occasions, they leave the ranch to explore other worlds such as Neverland, the mythological Ancient Greece, an underwater world known as \"Reino das \u00c1guas Claras\" (Clear Waters Kingdom), and even the outer space. The \"S\u00edtio\" is often symbolized by the character of Em\u00edlia, Lobato's most famous creation.\nIndia.\nChristian missionaries first established the Calcutta School-Book Society in the 19th century, creating a separate genre for children's literature in the country. Magazines and books for children in native languages soon appeared. In the latter half of the century, Raja Shivprasad wrote several well-known books in Hindustani. A number of respected Bengali writers began producing Bengali literature for children, including Ishwar Chandra Vidyasagar, who translated some stories and wrote others himself. Nobel Prize-winner Rabindranath Tagore wrote plays, stories, and poems for children, including one work illustrated by painter Nandalal Bose. They worked from the end of the nineteenth century into the beginning of the twentieth. Tagore's work was later translated into English, with Bose's pictures. Behari Lal Puri was the earliest writer for children in Punjabi. His stories were didactic in nature.\nThe first full-length children's book was \"Khar Khar Mahadev\" by Narain Dixit, which was serialized in one of the popular children's magazines in 1957. Other writers include Premchand, and poet Sohan Lal Dwivedi. In 1919, Sukumar Ray wrote and illustrated nonsense rhymes in the Bengali language, and children's writer and artist Abanindranath Tagore finished \"Barngtarbratn\". Bengali children's literature flourished in the later part of the twentieth century. Educator Gijubhai Badheka published over 200 books in the Children's literature in Gujarati language, and many are still popular. Other popular Gujarati children's authors were Ramanlal Soni and Jivram Joshi. In 1957, political cartoonist K. Shankar Pillai founded the Children's Book Trust publishing company. The firm became known for high quality children's books, and many of them were released in several languages. One of the most distinguished writers is Pandit Krushna Chandra Kar in Oriya literature, who wrote many good books for children, including \"Pari Raija\", \"Kuhuka Raija\", \"Panchatantra\", and \"Adi Jugara Galpa Mala\". He wrote biographies of many historical personalities, such as \"Kapila Deva\". In 1978, the firm organized a writers' competition to encourage quality children's writing. The following year, the Children's Book Trust began a writing workshop and organized the First International Children's Book Fair in New Delhi. Children's magazines, available in many languages, were widespread throughout India during this century. Ruskin Bond is also a famous Anglo-Indian writer for children.\nArgentina.\nThe origins of the Argentine children's literature tradition can be traced back to the publication of \"Leyendas Argentinas\" (\"Argentine Legends\") in 1906 by Ada Mar\u00eda Elflein, the Argentine daughter of German immigrants. Public schooling in Argentina was established in 1884 as free, compulsory and secular. With the Bible absent from schools, children's literature became an essential tool through which moral values could be taught. School reading books supported the instruction of civic morality, helping to fill the gap left by the displacing of the Catholic Church from its traditional position of imparting moral values. The commercial implications of this persisted into the 2000s, when Argentine publishing houses marketed Roald Dahl to teachers by highlighting the values which are transmitted by each of his books.\nIn 1918, Uruguayan author Horacio Quiroga published \"\" (\"Tales of the Jungle\") in Buenos Aires. A collection of short stories for children, about survival in the jungle of the Argentine Province of Misiones, bringing different types of animals into conflict or allegiance with each other and, occasionally, with humans. It was acclaimed due to the previous reputation Quiroga had obtained writing short stories for adults, particularly in \" (Tales of Love, Madness and Death)\". However, due to the lack of \"moral content\", the book was not read in schools.\nOn the other hand, Constancio C. Vigil had much more success in Argentine schools, where his more moralizing stories were frequently read. He also created Editorial Atl\u00e1ntida, an important publishing house and the country's leading magazine publisher and distributor, specially of magazines aimed to children such as \"Billiken.\" Stories written by Vigil, such as \" (The Little Travelling Ant)\" and \" (The Clockwork Monkey)\" were also read in schools in other countries of Latin America, such as Bolivia, Ecuador, Dominican Republic and Uruguay.1]\nIn the 1960s, Maria Elena Walsh started publishing children's books, she was the daughter of a railway worker of Irish descent, and she had become famous for her poetry and music. After years living in Paris, she came back to Argentina when Juan Per\u00f3n's government was overthrown in the \"Revoluci\u00f3n Libertadora\" (1955). She published the most beloved children's books in Argentina, which are read to this day, such as \"El Reino del Rev\u00e9s (The Upside Down Kingdom), Manuelita \u00bfd\u00f3nde vas?\" (\"Manuelita, Where Are You Going?\") and \"La Reina Batata (The Sweet Potato Queen).\" She also composed the famous children's song \"Manuelita.\"\nIran.\nOne of the pioneering children's writer in Persian was Mehdi Azar-Yazdi. His award-winning work, \"Good Stories for Good Children\", is a collection of stories derived from the stories in Classical Persian literature re-written for children.\nNigeria.\nOriginally, for centuries, stories were told by Africans in their native languages, many being told during social gatherings. Stories varied between mythic narratives dealing with creation and basic proverbs showcasing human wisdom. These narratives were passed down from generation to generation orally. Since its independence in 1960, Nigeria has witnessed a rise in the production of children's literature by its people, the past three decades contributing the most to the genre. Most children's books depict the African culture and lifestyle, and trace their roots to traditional folktales, riddles, and proverbs. Authors who have produced such works include Chinua Achebe, Cyprian Ekwensi, Amos Tutuola, Flora Nwapa, and Buchi Emecheta.\nAchebe's \"Chike and the River\" (1966) introduced Nigerian storytelling to a global audience, while Ekwensi's \"The Drummer Boy\" (1960) highlighted traditional storytelling's moral lessons. The Noma Award-winning \"The Missing Clock\" (1981) by Mai Nasara brought further international recognition to Nigerian children's literature. The 1980s and 1990s saw further growth, with writers such as Adaeze Atuegwu, who published multiple books as a teenager, inspiring a new wave of young Nigerian authors. Publishing companies also aided in the development of children's literature. Today, Nigerian children's literature continues to gain international recognition, blending traditional African narratives with contemporary themes.\nClassification.\nChildren's literature can be divided into categories, either according to genre or the intended age of the reader.\nMuch of children's literature is series fiction (book series).532\nBy genre.\nA literary genre is a category of literary compositions. Genres may be determined by technique, tone, content, or length. According to Anderson, there are six categories of children's literature (with some significant subgenres):\nBy age category.\nThe criteria for these divisions are vague, and books near a borderline may be classified either way. Books for younger children tend to be written in simple language, use large print, and have many illustrations. Books for older children use increasingly complex language, normal print, and fewer (if any) illustrations. The categories with an age range are these:\nIllustration.\nPictures have always accompanied children's stories. A papyrus from Byzantine Egypt, shows illustrations accompanied by the story of Hercules' labors. Modern children's books are illustrated in a way that is rarely seen in adult literature, except in graphic novels. Generally, artwork plays a greater role in books intended for younger readers (especially pre-literate children). Children's picture books often serve as an accessible source of high quality art for young children. Even after children learn to read well enough to enjoy a story without illustrations, they (like their elders) continue to appreciate the occasional drawings found in chapter books.\nAccording to Joyce Whalley in \"The International Companion Encyclopedia of Children's Literature\", \"an illustrated book differs from a book with illustrations in that a good illustrated book is one where the pictures enhance or add depth to the text.\" Using this definition, the first illustrated children's book is considered to be \"Orbis Pictus\" which was published in 1658 by the Moravian author Comenius. Acting as a kind of encyclopedia, \"Orbis Pictus\" had a picture on every page, followed by the name of the object in Latin and German. It was translated into English in 1659 and was used in homes and schools around Europe and Great Britain for many years.\nEarly children's books, such as \"Orbis Pictus\", were illustrated by woodcut, and many times the same image was repeated in a number of books regardless of how appropriate the illustration was for the story. Newer processes, including copper and steel engraving were first used in the 1830s. One of the first uses of Chromolithography (a way of making multi-colored prints) in a children's book was demonstrated in \"Struwwelpeter\", published in Germany in 1845. English illustrator Walter Crane refined its use in children's books in the late 19th century. \nAnother method of creating illustrations for children's books was etching, used by George Cruikshank in the 1850s. By the 1860s, top artists were illustrating for children, including Crane, Randolph Caldecott, Kate Greenaway, and John Tenniel. Most pictures were still black-and-white, and many color pictures were hand colored, often by children. \"The Essential Guide to Children's Books and Their Creators\" credits Caldecott with \"The concept of extending the meaning of text beyond literal visualization\".\nTwentieth-century artists such as Kay Nielson, Edmund Dulac, and Arthur Rackham produced illustrations that are still reprinted today. Developments in printing capabilities were reflected in children's books. After World War II, offset lithography became more refined, and painter-style illustrations, such as Brian Wildsmith's were common by the 1950s.\n\"Illustrators of Children's Books, 1744\u20131945\" (Horn Book, 1947), an extensively detailed four volume work by Louise Payson Latimer, Bertha E. Mahony and Beulah Folmsbee, catalogs illustrators of children's books over two centuries.\nScholarship.\nProfessional organizations, dedicated publications, individual researchers and university courses conduct scholarship on children's literature. Scholarship in children's literature is primarily conducted in three different disciplinary fields: literary studies/cultural studies (literature and language departments and humanities), library and information science, and education. (Wolf, et al., 2011).\nTypically, children's literature scholars from literature departments in universities (English, German, Spanish, etc. departments), cultural studies, or in the humanities conduct literary analysis of books. This literary criticism may focus on an author, a thematic or topical concern, genre, period, or literary device and may address issues from a variety of critical stances (poststructural, postcolonial, New Criticism, psychoanalytic, new historicism, etc.). Results of this type of research are typically published as books or as articles in scholarly journals.\nThe field of Library and Information Science has a long history of conducting research related to children's literature.\nMost educational researchers studying children's literature explore issues related to the use of children's literature in classroom settings. They may also study topics such as home use, children's out-of-school reading, or parents' use of children's books. Teachers typically use children's literature to augment classroom instruction.\nTranslation of children's literature.\nTranslation of children's literature can emerge in various forms and necessitates to have a comprehension of the children's inner worlds and developmental factors. Hollindale in 1997 takes the attention on the experimental, dynamic, imaginative, interactive, and unstable nature of childness. Considering that the translation is carried out for children consequently requires to the necessities of the youngest readers and thus, the target text can be expected to involve considering effective content, creativity, the simplest of expression, and linguistic playfulness.\nBeyond age considerations, in the translation of children's literature, the translators are supposed to comprehend the changing status and essence of youth cultures. This arises from the phenomena that works translated for children can be fictions fundamentally produced both for adults and children, consisting of genres such as romances, fables, and fairytales. Besides, adults might be present in literary works for children as the disguise of a didactic narrator or ironic asides. This can have the power to change the implicit adult-child relationship in the source text. The visuals play an important role in children's literature for younger audience and these visuals might consist of comics, graphic novels, and picture books. Therefore, the translators are required to have an understanding of typography, visual coding and stylization.\nAccordingly, comprehending the multi-medial nature of children's literature and grasping how to compose text and images for promoting active child readers are fundamental for translators to produce effective target texts. Scholars such as Oittinen suggests that translators of children's literature would benefit from having a specialized training in arts along with translation studies. Puurtinen and Kreller highlights other aspects such as of sound, narrative structure, syntactic alterations, and textual elements like repetition and rhyme and they suggest these components possess crucial roles in translating children's literature. It can be said that these suggestions are being further on through critical developments such as edited volumes, reviews, and collections in the field opening the path for future research directions.\nDistribution.\nThe US reported revenue of US$4.7 billion from children's books in 2020, followed by Germany (US$2 billion), the UK (US$508 million), Spain (US$427 million) and France (US$406 million).\nLiterary criticism.\nControversies often emerge around the content and characters of prominent children's books. Well-known classics that remain popular throughout decades commonly become criticized by critics and readers as the values of contemporary culture change. Critical analysis of children's literature is common through children's literary journals as well as published collections of essays contributed to by psychoanalysts, scholars and various literary critics such as Peter Hunt.\nDebate over controversial content.\nA widely discussed and debated topic by critics and publishers in the children's book industry is whether outdated and offensive content, specifically racial stereotypes, should be changed in new editions. Others argue instead that original content should remain but that publishers should add information to guide parents in conversations with their children about the problematic elements of the particular story. Some see racist stereotypes as cultural artifacts that should be preserved. In \"The Children's Culture Reader\", scholar Henry Jenkins references Herbert R. Kohl's essay \"Should We Burn Babar?\" which raises the debate whether children should be educated on how to think critically towards oppressive ideologies rather than ignore historical mistakes. Jenkins suggests that parents and educators should trust children to make responsible judgments.\nSome books have been altered in newer editions and significant changes can be seen, such as illustrator Richard Scarry's book \"Best Word Book Ever\". and Roald Dahl's book \"Charlie and the Chocolate Factory\". In other cases classics have been rewritten into updated versions by new authors and illustrators. Several versions of \"Little Black Sambo\" have been remade as more appropriate and without prejudice.\nStereotypes, racism and cultural bias.\nPopular classics such as \"The Secret Garden\", \"Pippi Longstocking\", \"Peter Pan\", \"The Chronicles of Narnia\" and \"Charlie and the Chocolate Factory\" have been criticized for their racial stereotyping.\nThe academic journal \"Children's Literature Review\" provides critical analysis of many well known children's books. In its 114th volume, the journal discusses the cultural stereotypes in Belgian cartoonist Herge's \"Tintin\" series in reference to its depiction of people from the Congo.\nAfter the scramble for Africa which occurred between the years of 1881 and 1914 there was a large production of children's literature which attempted to create an illusion of what life was like for those who lived on the African continent. This was a simple technique in deceiving those who only relied on stories and secondary resources. Resulting in a new age of books which put a \"gloss\" on imperialism and its teachings at the time. Thus encouraging the idea that the colonies who were part of the African continent were perceived as animals, savages and inhuman-like. Therefore, needing cultured higher class Europeans to share their knowledge and resources with the locals. Also promoting the idea that the people within these places were as exotic as the locations themselves. Examples of these books include:\n\"The Five Chinese Brothers\", written by Claire Huchet Bishop and illustrated by Kurt Wiese has been criticized for its stereotypical caricatures of Chinese people. Helen Bannerman's \"The Story of Little Black Sambo\" and Florence Kate Upton's \"The Adventures of Two Dutch Dolls and a Golliwogg\" have also been noted for their racist and controversial depictions. The term \"sambo\", a racial slur from the American South caused a widespread banning of Bannerman's book. Author Julius Lester and illustrator Jerry Pinkney revised the story as \"Sam and the Tigers: A New Telling of Little Black Sambo\", making its content more appropriate and empowering for ethnic minority children. Feminist theologian Eske Wollrad claimed Astrid Lindgren's \"Pippi Longstocking\" novels \"have colonial racist stereotypes\", urging parents to skip specific offensive passages when reading to their children. Criticisms of the 1911 novel \"The Secret Garden\" by author Frances Hodgson Burnett claim endorsement of racist attitudes toward black people through the dialogue of main character Mary Lennox. Hugh Lofting's \"The Story of Doctor Dolittle\" has been accused of \"white racial superiority\", by implying through its underlying message that an ethnic minority person is less than human.\nThe picture book \"The Snowy Day\", written and illustrated by Ezra Jack Keats was published in 1962 and is known as the first picture book to portray an African-American child as a protagonist. Middle Eastern and Central American protagonists still remain underrepresented in North American picture books. According to the Cooperative Children's Books Center (CCBC) at University of Wisconsin Madison, which has been keeping statistics on children's books since the 1980s, in 2016, out of 3,400 children's books received by the CCBC that year, only 278 were about Africans or African Americans. Additionally, only 92 of the books were written by Africans or African Americans. In his interview in the book \"Ways of Telling: Conversations on the Art of the Picture Book\", Jerry Pinkney mentioned how difficult it was to find children's books with black children as characters. In the literary journal \"The Black Scholar\", Bettye I. Latimer has criticized popular children's books for their renditions of people as almost exclusively white, and notes that \"Dr. Seuss\" books contain few ethnic minority people. The popular school readers \"Fun with Dick and Jane\" which ran from the 1930s until the 1970s, are known for their whitewashed renditions of the North American nuclear family as well as their highly gendered stereotypes. The first black family did not appear in the series until the 1960s, thirty years into its run.\nWriter Mary Renck Jalongo In \"Young Children and Picture Books\" discusses damaging stereotypes of Native Americans in children's literature, stating repeated depictions of indigenous people as living in the 1800s with feathers and face paint cause children to mistake them as fictional and not as people that still exist today. The depictions of Native American people in Laura Ingalls Wilder's \"Little House on the Prairie\" and J. M. Barrie's \"Peter Pan\" are widely discussed among critics. Wilder's novel, based on her childhood in America's midwest in the late 1800s, portrays Native Americans as racialized stereotypes and has been banned in some classrooms. In her essay, \"Somewhere Outside the Forest: Ecological Ambivalence in Neverland from The Little White Bird to Hook\", writer M. Lynn Byrd describes how the natives of Neverland in \"Peter Pan\" are depicted as \"uncivilized\", valiant fighters unafraid of death and are referred to as \"redskins\", which is now considered a racial slur.\nImperialism and colonialism.\nThe presence of empire as well as pro-colonialist and imperialist themes in children's literature have been identified in some of the most well known children's classics of the late nineteenth and early twentieth centuries.\nIn the French illustrator Jean de Brunhoff's 1931 picture book \"Histoire de Babar, le petit elephant (The Story of Babar, The Little Elephant)\", prominent themes of imperialism and colonialism have been noted and identified as propaganda. An allegory for French colonialism, Babar easily assimilates himself into the bourgeois lifestyle. It is a world where the elephants who have adapted themselves dominate the animals who have not yet been assimilated into the new and powerful civilization. H. A. Rey and Margret Rey's \"Curious George\" first published in 1941 has been criticized for its blatant slave and colonialist narratives. Critics claim the man with the yellow hat represents a colonialist poacher of European descent who kidnaps George, a monkey from Africa, and sends him on a ship to America. Details such as the man in colonialist uniform and Curious George's lack of tail are points in this argument. In an article, \"The Wall Street Journal\" interprets it as a \"barely disguised slave narrative.\" Rudyard Kipling, the author of \"Just So Stories\" and \"The Jungle Book\" has also been accused of colonial prejudice attitudes. Literary critic Jean Webb, among others, has pointed out the presence of British imperialist ideas in \"The Secret Garden\". Colonialist ideology has been identified as a prominent element in Peter Pan by critics.\nGender roles and representation of women.\nSome of the earliest children's stories that contain feminist themes are Louisa May Alcott's \"Little Women\" and Frank L. Baum's \"The Wonderful Wizard of Oz\". With many women of this period being represented in children's books as doing housework, these two books deviated from this pattern. Drawing attention to the perception of housework as oppressive is one of the earliest forms of the feminist movement. \"Little Women\", a story about four sisters, is said to show power of women in the home and is seen as both conservative and radical in nature. The character of Jo is observed as having a rather contemporary personality and has even been seen as a representation of the feminist movement. It has been suggested that the feminist themes in \"The Wonderful Wizard of Oz\" result from influence of Baum's mother-in law, Matilda Gage, an important figure in the suffragist movement. Baum's significant political commentary on capitalism, and racial oppression are also said to be part of Gage's influence. Examples made of these themes is the main protagonist, Dorothy who is punished by being made to do housework. Another example made of positive representations of women is in Finnish author Tove Jansson's Moomin series which features strong and individualized female characters. In recent years, there has been a surge in the production and availability of feminist children's literature as well as a rise in gender neutrality in children's literature.\nIn addition to perpetuating stereotypes about appropriate behavior and occupations for women and girls, children's books frequently lack female characters entirely, or include them only as minor or unimportant characters. In the book \"Boys and Girls Forever: Reflections on Children's Classics\", scholar Alison Lurie says most adventure novels of the 20th century, with few exceptions, contain boy protagonists while female characters in books such as those by Dr. Seuss, would typically be assigned the gender-specific roles of receptionists and nurses. The \"Winnie-the-Pooh\" characters written by A. A. Milne, are primarily male, with the exception of the character Kanga, who is a mother to Roo. Even animals and inanimate objects are usually identified as being male in children's books. The near-absence of significant female characters is paradoxical because of the role of women in creating children's literature. According to an article published in the \"Guardian\" in 2011, by Allison Flood, \"Looking at almost 6,000 children's books published between 1900 and 2000, the study, led by Janice McCabe, a professor of sociology at Florida State University, found that males are central characters in 57% of children's books published each year, with just 31% having female central characters. Male animals are central characters in 23% of books per year, the study found, while female animals star in only 7.5%\".\nOn the one hand \"Growing up with Dick and Jane\" highlights the heterosexual, nuclear family and also points out the gender-specific duties of the mother, father, brother and sister, while \"Young Children and Picture Books\", on the other hand, encourages readers to avoid books with women who are portrayed as inactive and unsuccessful as well as intellectually inferior and subservient to their fellow male characters to avoid children's books that have repressive and sexist stereotypes for women.\nIn her book \"Children's Literature: From the fin de si\u00e8cle to the new millennium\", professor Kimberley Reynolds claims gender division stayed in children's books prominently until the 1990s. She also says that capitalism encourages gender-specific marketing of books and toys. For example, adventure stories have been identified as being for boys and domestic fiction intended for girls. Publishers often believe that boys will not read stories about girls, but that girls will read stories about both boys and girls; therefore, a story that features male characters is expected to sell better. The interest in appealing to boys is also seen in the Caldecott awards, which tend to be presented to books that are believed to appeal to boys. Reynolds also says that both boys and girls have been presented by limited representations of appropriate behaviour, identities and careers through the illustrations and text of children's literature. She argues girls have traditionally been marketed books that prepare them for domestic jobs and motherhood. Conversely, boys are prepared for leadership roles and war. During the 20th century, more than 5,000 children's picture books were published in the U.S; during that time, male characters outnumbered female characters by more than 3 to 2, and male animals outnumbered female animals by 3 to 1. No children's picture book that featured a protagonist with an identifiable gender contained only female characters.\n\"I'm Glad I'm a Boy! I'm Glad I'm a Girl!\" (1970) by Whitney Darrow Jr. was criticized for narrow career depictions for both boys and girls. The book informs the reader that boys are doctors, policemen, pilots, and presidents while girls are nurses, meter maids, stewardesses and first ladies.\nNancy F. Cott, once said that \"gender matters; that is, it matters that human beings do not appear as neuter individuals, that they exist as male or female, although this binary is always filtered through human perception. I should add that when I say gender, I am talking about meaning. I am talking about something in which interpretation is already involved.\"\nIn her book \"La sua barba non \u00e8 poi cos\u00ec blu... Immaginario collettivo e violenza misogina nella fiaba di Perrault\" (2014, translated into Spanish \"Su barba no era tan azul\" and winner of the first international CIRSE award 2015), Angela Articoni analyzes the fairy tale Bluebeard dwelling on the sentence pronounced by the protagonist to convince herself to accept marriage, an expression that recites to repeat the women victims of violence who hope to be able to redeem their prince charming.\nEffect on early childhood development.\nBruno Bettelheim in \"The Uses of Enchantment\", uses psychoanalysis to examine the impact that fairy tales have on the developing child. Bettelheim states the unconscious mind of a child is affected by the ideas behind a story, which shape their perception and guides their development. Likewise, author and illustrator Anthony Browne contends the early viewing of an image in a picture book leaves an important and lasting impression on a child. According to research, a child's most crucial individual characteristics are developed in their first five years. Their environment and interaction with images in picture books have a profound impact on this development and are intended to inform a child about the world.\nChildren's literature critic Peter Hunt argues that no book is innocent of harbouring an ideology of the culture it comes from. Critics discuss how an author's ethnicity, gender and social class inform their work. Scholar Kimberley Reynolds suggests books can never be neutral as their nature is intended as instructional and by using its language, children are embedded with the values of that society. Claiming childhood as a culturally constructed concept, Reynolds states that it is through children's literature that a child learns how to behave and to act as a child should, according to the expectations of their culture. She also attributes capitalism, in certain societies, as a prominent means of instructing especially middle class children in how to behave. The \"image of childhood\" is said to be created and perpetuated by adults to affect children \"at their most susceptible age\". Kate Greenaway's illustrations are used as an example of imagery intended to instruct a child in the proper way to look and behave. In Roberta Seelinger Trites's book \"Disturbing the Universe: Power and Repression in Adolescent Literature\", she also argues adolescence is a social construct established by ideologies present in literature. In the study \"The First R: How Children Learn About Race and Racism\", researcher Debra Ausdale studies children in multi-ethnic daycare centres. Ausdale claims children as young as three have already entered into and begun experimenting with the race ideologies of the adult world. She asserts racist attitudes are assimilated using interactions children have with books as an example of how children internalize what they encounter in real life.\nDiversity in children's books.\nDiversity has been a key topic in children's books and publishing in recent years, with social media movements such as We Need Diverse Books bringing this issue into the public consciousness. Books by and about marginalised groups - BIPOC, LGBTQIA+, disabled, neurodivergent, religious minorities etc. - have been underrepresented in children's publishing. In the US, CCBC releases the numbers of children's and YA books by and about BIPOC published in the previous year. 2019 saw the following stats:\nIn the UK, CLPE follow a similar survey. In 2020, they found a positive increase in children's books featuring a minority ethnic character from 10% in 2019 to 15% in 2020 and up significantly from the 4% reported in the inaugural report in 2017.\nOutside the US and UK, efforts to track and promote diversity in children's literature are emerging. In Canada, the Festival of Literary Diversity (FOLD) was established in 2016 to highlight underrepresented voices in literature. In Australia, the Australian Children's Laureate Foundation has promoted cultural inclusivity through its national programs. Data collection on diversity in children's books remains limited in many non-Western countries.\nAuthors of colour are not well represented in children's authorship. In the UK, research found that:\nSubsequent reports have shown gradual improvements in representation, though disparities remain. According to the CLPE's \"Reflecting Realities\" report (2022), 20% of children's books published in the UK in 2021 featured a minority ethnic character, up from 4% in 2017. However, only 9% of children's books were created by authors or illustrators from minority ethnic backgrounds in the same year, indicating that representation within the publishing workforce has not kept pace with character diversity in books.\nBenefits of children's books.\nChildren's books are critical to child development, especially at preschool ages. Children have had limited engagement in social contexts at this age. Reading books will help them to prepare for future social interactions and real-life situations because reading helps language, cognitive, social, and emotional development.\nChildren's books increase language development by introducing new vocabulary and helping children to learn about using language in context. Children are also exposed to various words and sentence structures when reading. Moreover, children's books enhance children's cognitive development in memory, attention, and imagination. Reading allows them to relate to their experience and understanding to make meaning of the sensory message, which is how the brain understands the world around them. Children's books also benefit children's social and emotional development. Reading books help \"personal development and self-understanding by presenting situations and characters with which our own can be compared\". Children's books often present topics that children can relate to, such as love, empathy, family affection, and friendship. Reading those books helps children to understand emotion and helps them transfer their learning to social contexts.\nAwards.\nMany noted awards for children's literature exist in various countries, parts of the world, or for specific languages:\nInternational awards also exist as forms of global recognition. These include the Hans Christian Andersen Award, the Astrid Lindgren Memorial Award, Ilustrarte Bienale for illustration, and the BolognaRagazzi Award for art work and design. Additionally, bloggers with expertise on children's and young adult books give a major series of online book awards called The Cybils Awards, or Children's and Young Adult Bloggers' Literary Awards.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52851", "revid": "50609585", "url": "https://en.wikipedia.org/wiki?curid=52851", "title": "1975 Australian constitutional crisis", "text": "Dismissal of Prime Minister Gough Whitlam\nThe 1975 Australian constitutional crisis, also called the Dismissal, culminated with the dismissal of the prime minister, Gough Whitlam of the Australian Labor Party (ALP), by Sir John Kerr, the governor-general of Australia, on 11 November 1975. Kerr then commissioned the Leader of the Opposition, Malcolm Fraser of the Liberal Party, as prime minister on the condition that he advise a new election. It has been described as the greatest political and constitutional crisis in Australian history.\nThe Labor Party under Whitlam came to power in the 1972 federal election, ending 23 consecutive years of Liberal\u2013Country Coalition government. Labor won a majority in the House of Representatives of 67 seats to the Coalition's 58 seats, but faced a hostile Senate. In May 1974, after the Senate voted to reject six of Labor's bills, Whitlam advised governor-general Sir Paul Hasluck to call a double dissolution election. The election saw Labor re-elected, with its House of Representatives majority reduced from nine to five seats, although it gained seats in the Senate. With the two houses of Parliament still deadlocked, pursuant to section 57 of the Australian Constitution, Whitlam was able to narrowly secure passage of the six trigger bills of the earlier double dissolution election in a joint sitting of Parliament on 6\u20137 August 1974, the only such sitting held in Australia's history.\nWhitlam's tenure in office proved highly turbulent and controversial, and in October 1975, the Opposition under Fraser used its control of the Senate to defer passage of appropriation bills needed to finance government expenditure which had already been passed by the House of Representatives. Fraser and the Opposition stated that they would continue to block supply in the Senate unless Whitlam called a fresh election for the House of Representatives, and urged Kerr, who had been appointed governor-general on Whitlam's advice in July 1974, to dismiss Whitlam unless he acceded to their demand. Whitlam believed that Kerr would not dismiss him as prime minister, and Kerr did nothing to make Whitlam believe that he might be dismissed.\nOn 11 November 1975, the crisis came to a head as Whitlam went to seek Kerr's approval to call a half-Senate election in an attempt to break the parliamentary deadlock. Kerr did not accept Whitlam's request, and instead dismissed him as prime minister and appointed Fraser as caretaker prime minister on the understanding that he would immediately call a general election. Acting quickly before all ALP parliamentarians became aware of the change of government, Fraser and his parliamentary allies were able to secure passage of the supply bills through the Senate and advised Kerr to dissolve Parliament for a double dissolution election. Fraser and his Liberal\u2013Country Coalition were elected with a massive majority in the federal election held the following month.\nThe events of the Dismissal led to only minor constitutional change. The Senate retained its power to block supply, and the governor-general the power to dismiss government ministers; however, these powers have not since been used to force a government from office. Allegations of CIA involvement in Whitlam's dismissal have been made, but these were denied by both Kerr and Whitlam. Kerr was widely criticised by Labor supporters for his actions, resigned early as governor-general, and lived much of his remaining life abroad. \nBackground.\nConstitutional background.\nAs established by the Constitution of Australia, the Parliament of Australia is composed of two houses, the House of Representatives and the Senate, together with the monarch. The monarch is represented through the governor-general, whom the monarch appoints (and therefore may remove) on the advice of the prime minister. Formally, the governor-general may exercise all of the Commonwealth's executive power; however, in practice they are generally bound by convention to act only upon the advice of the prime minister and the government. The limited number of powers that may be exercised without advice and according to the governor-general's own discretion are known as the reserve powers. These powers are also governed by convention. For example, the appointment and dismissal of a prime minister is a reserve power, but convention dictates that ordinarily only somebody who has the confidence of the House of Representatives may be appointed.\nAs in most Westminster system parliaments, Australia's government is ordinarily formed by the party enjoying the confidence of the lower house of parliament, the House of Representatives. Australia's Parliament also has a powerful upper house, the Senate, which must pass any bill initiated by the House of Representatives if it is to become law. The composition of the Senate, in which each state has an equal number of senators regardless of that state's population, was originally designed to attract the Australian colonies into one Federation. Some at the time of Federation saw the contradiction in the Constitution between responsible government, in which the executive owes its existence to the legislature or one dominant house of the legislature, and, federations with the houses of bicameral legislatures operating independently and possibly deadlocking. Certain delegates predicted that either responsible government would result in the federation becoming a unitary state or federalism would result in an executive closer to federal theory. For instance, delegate Winthrop Hackett stated at the 1891 Convention that as a result of the combination of a strong Senate with responsible government, \"there will be one of two alternatives\u2014either responsible government will kill federation, or federation in the form in which we shall, I hope, be prepared to accept it, will kill responsible government\".\nConstitutionally, the Senate is unable to originate or amend a money bill coming from the House, although it may return the bill to the House with requests for amendment; or, as with any other bill, it may reject the bill entirely. Whether there was nevertheless a convention that the upper house should not reject money bills from the lower house was a key issue in the dispute. During and after the crisis, Whitlam argued for the existence of this convention; however previously as Leader of the Opposition he had supported the blocking of supply, stating of a budget bill: \"Let me make it clear at the outset that our opposition to this Budget is no mere formality. We intend to press our opposition by all available means on all related measures in both Houses. If the motion is defeated, we will vote against the Bills here and in the Senate. Our purpose is to destroy this Budget and destroy the Government which has sponsored it.\"\nThe Senate had never blocked supply before 1975, even when it had been controlled by the opposition. However, the Parliament of the state of Victoria had done so in 1947, in response to the federal Chifley government's attempt to nationalise the banks. The coalition-controlled upper house blocked the state budget in order to force a premature election. Labor premier John Cain called a snap election and was defeated.\nPrior to the 1975 crisis, the governor-general's power to dismiss a prime minister against the incumbent's will under section 64 of the Constitution had never been exercised. Twice since Federation, conflicts between state premiers and state governors, who perform analogous functions to the prime minister and governor-general respectively at the state level, had resulted in the departure of one or the other. In 1916, New South Wales premier William Holman was expelled from the Australian Labor Party for supporting conscription. He managed to hold on to power with the aid of opposition parties and consulted the governor, Sir Gerald Strickland, proposing to pass legislation to extend the term of the lower house of the state legislature by a year. When Strickland objected, stating that such a course was unfair to Labor, Holman had him replaced. In 1932 the New South Wales Labor premier, Jack Lang, refused to pay money owed to the federal government, which froze the state's bank accounts, causing Lang to order that payments to the state government be only in cash. The governor, Sir Philip Game, wrote to Lang to warn him that this was unlawful. Game further warned Lang that if Lang continued, he would have to sack Lang to obtain ministers who could carry on government within legal bounds. Lang replied that he would not resign, and Game dismissed his government and commissioned the leader of the opposition, Bertram Stevens, to form a caretaker government pending a new election, in which Labor was defeated.\nAmong the powers granted to the governor-general is the power to dissolve both houses of Parliament under section 57 of the Constitution in the event that the House of Representatives twice passes a bill at least three months apart and the Senate refuses to pass it. In both instances where those circumstances arose prior to the Whitlam government, in 1914 and 1951, the governor-general dissolved Parliament for a double dissolution election on the recommendation of the prime minister.\nPolitical background.\nGough Whitlam's Labor government was elected in 1972 after 23 years of rule by a coalition formed by the Liberal and Country parties. The ALP Government enjoyed a nine-seat majority in the House of Representatives, but did not control the Senate, which had been elected in 1967 and 1970 (as Senate elections were then out of synchronisation with House of Representatives elections). In accordance with pre-election promises, it instituted a large number of policy changes, and offered much legislation. The opposition, which still controlled the Senate, allowed some government bills to pass the Senate, and blocked others.\nIn April 1974, faced with attempts by the opposition under Billy Snedden to block supply (appropriation bills) in the Senate, Whitlam obtained the concurrence of the governor-general, Sir Paul Hasluck, to a double dissolution. Labor was returned at the election on 18 May with a reduced House majority of five seats. The Coalition and Labor each had 29 Senate seats, with the balance of power held by two independents. Snedden later told author Graham Freudenberg when being interviewed for the book \"A Certain Grandeur \u2013 Gough Whitlam in Politics\": \"The pressure [to block supply] was on me from [Doug] Anthony. We thought you had a chance of getting control of the Senate at the half-Senate election or at least enough to get a redistribution through. With a gerrymander, you'd be in forever.\"\nHasluck had been governor-general since 1969, and his expected term was shortly due to expire. Whitlam wanted him to remain a further two years, but Hasluck declined, citing the refusal of his wife, Alexandra, to remain at Yarralumla longer than the originally agreed five years. Whitlam offered the post to businessman Ken Myer, who turned it down. Whitlam then offered the position to his treasurer, Frank Crean, and his own deputy, Lance Barnard, neither of whom was keen to move on from parliament. Finally, Whitlam turned to his fifth choice, Sir John Kerr, the chief justice of New South Wales. Kerr was reluctant to give up the chief justiceship, in which he intended to remain another ten years, for the governor-general's post, which traditionally lasted five years. At Kerr's request, Whitlam informally agreed that if both men were still in office in five years, Kerr would remain governor-general for another five years. Whitlam also secured legislation to address Kerr's financial concerns about the position, including authorising a pension for the governor-general or his widow. The leader of the opposition, Billy Snedden, was enthusiastic about the appointment and also agreed to keep on Kerr in five years, were he prime minister at the time. Kerr then agreed to take the post, was duly appointed by Queen Elizabeth\u00a0II, and was sworn in on 11 July 1974.\nSix of the bills that had been the subject of the double dissolution were introduced in Parliament a third time and, as expected, were again rejected by the Senate. Section 57 of the Constitution provides that, after a double dissolution election, if bills that had been rejected twice by the Senate in the previous parliament were again passed by the House and again rejected by the Senate, they could then be put to a joint sitting of both houses. On 30July, Whitlam gained Kerr's agreement for a joint sitting, which was set for 6\u20137 August 1974. The joint sitting, the only one in Australia's history under section 57, passed all six bills, including the enabling legislation for Medibank.\nControversy and vacancies.\nIn December 1974, Whitlam was anxious to find new sources of money to finance his development plans. After a meeting at the prime minister's residence, The Lodge, Whitlam and three of his ministers (deputy prime minister and treasurer Jim Cairns, attorney-general Lionel Murphy, and minister for minerals and energy Rex Connor) signed a letter of authority for Connor to borrow up to US$4\u00a0billion. This letter was described by author and journalist Alan Reid as the \"death warrant of the Whitlam ALP government\".\nConnor and other ministers had made contact with a hitherto obscure Pakistani financier, Tirath Khemlani, as early as November 1974. Khemlani was said to have contacts in the newly enriched Arab oil nations. None of the efforts to secure a loan, whether through Khemlani or by other routes, bore fruit, but, as information about the \"Loans Affair\" trickled out, the government lost support.\nIn February 1975, Whitlam decided to appoint Murphy a justice of the High Court of Australia, even though Murphy's Senate seat would not be up for election if a half-Senate election were held. Under the Senate's electoral system, Labor could win three of the five New South Wales seats, but if Murphy's seat was also contested, it was most unlikely to win four out of six. Thus, appointing Murphy would almost certainly cost the ALP a Senate seat at the next half-Senate election. Whitlam appointed Murphy anyway. By convention, senators appointed by the state parliaments to fill casual vacancies were from the same political party as the former senator. The New South Wales premier, Tom Lewis, a member of the Liberal Party, argued that this convention only applied to vacancies caused by deaths or ill-health, and arranged for the legislature to elect Cleaver Bunton, former mayor of Albury and an independent.\nBy March 1975, many Liberal parliamentarians felt that Snedden was doing an inadequate job as leader of the opposition and that Whitlam was dominating him in the House of Representatives. Malcolm Fraser challenged Snedden for the leadership on 21 March, and defeated him by 37 votes to 27. At a press conference after winning the leadership, Fraser stated:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The question of supply\u2014let me deal with it this way. I generally believe if a government is elected to power in the lower House and has the numbers and can maintain the numbers in the lower House, it is entitled to expect that it will govern for the three-year term unless quite extraordinary events intervene\u00a0... Having said that\u00a0... if we do make up our minds at some stage that the Government is so reprehensible that an Opposition must use whatever power is available to it, then I'd want to find a situation in which Mr Whitlam woke up one morning finding the decision had been made and finding that he had been caught with his pants well and truly down.\nWhitlam's original deputy prime minister, Lance Barnard, had been challenged and defeated for his post by Cairns in June 1974 shortly after the May 1974 election. Whitlam then offered Barnard a diplomatic post; in early 1975 Barnard agreed to this. If the appointment went through, Barnard's resignation from the House of Representatives would trigger a by-election in his Tasmanian electorate of Bass. ALP officials felt that, given the party's weakened state, Barnard should remain in Parliament and be given no preferment if he resigned; party president and future prime minister Bob Hawke described the decision to appoint Barnard as \"an act of lunacy\". Barnard had been losing support over the last several elections, and the Liberals needed only a swing of four percent to take Bass off Labor. The Liberals had a candidate, Kevin Newman, who had been nursing the electorate; Labor had no candidate selected and a bitter preselection in the offing. Barnard resigned and was appointed the ambassador to Sweden. The election on 28 June proved a disaster for Labor, with Newman winning the seat on a swing of over 17%.\nThe next week, Whitlam fired Cairns for misleading Parliament regarding the Loans Affair amid innuendo about his relationship with his Principal Private Secretary, Junie Morosi. He was replaced as deputy by Frank Crean. At the time of Cairns' dismissal, one Senate seat was vacant, following the death on 30 June of Queensland ALP senator Bertie Milliner. The state Labor party nominated Mal Colston, who was the highest unelected candidate on the party's Queensland list in 1974. This resulted in deadlock in Brisbane; the unicameral Queensland Parliament twice voted against Colston, and the party refused to submit any alternative candidates. Queensland Country Party Premier Joh Bjelke-Petersen had evidence that Colston, a school teacher by trade, had set a school on fire during a labour dispute, though the police had refused to prosecute. After the Queensland Parliament voted Colston down a second time, Bjelke-Petersen instructed his majority in the Queensland Parliament to elect a low-level union official, Albert Field, who had contacted his office and expressed a willingness to serve. In interviews, Field made it clear he would not support Whitlam. Field was expelled from the ALP for standing against Colston, and Labor senators boycotted his swearing-in. Whitlam argued that because of the vacancies being filled as they were, the Senate was \"corrupted\" and \"tainted\", with the opposition enjoying a majority they did not win at the ballot box. When Labor learned that Field had not given the required three weeks notice to the Queensland Department of Education, it challenged his appointment in the High Court, arguing that he was still technically a public servant\u2013and thus ineligible to serve in the Senate. With Field on leave throughout the remainder of the crisis, the Coalition refused to provide a pair to account for his absence, giving it an effective majority of 30\u201329 in the Senate. Whitlam remarked that if Milliner had not died or had he been replaced by a pro-Whitlam senator, the crisis would not have happened.\nDeadlock.\nDeferral of supply.\nOn 10 October, the High Court ruled that the act passed at the joint sitting that gave the Australian Capital Territory (ACT) and the Northern Territory two senators each was valid. A half-Senate election needed to be held by June 1976; most elected senators would take their seats on 1 July, but the territorial senators and those filling Field's and Bunton's seats would take their places at once. The ruling meant that it was possible for the ALP to gain a temporary majority in the Senate, at least until 1 July 1976. To do so, the ALP would have to win Field's and Bunton's seats, and one seat in each territory, and have the second ACT seat fall to either a Labor candidate or an independent, former Liberal prime minister John Gorton, now estranged from his party. If this happened, Labor would have an effective 33\u201331 margin, would be able to pass supply if that was still an issue, and also could pass electoral redistribution laws (which had been passed by the House, though twice defeated by the Senate) that would give it an advantage at the next election.\nIn the wake of the High Court ruling, and with the appropriation bills due to be considered by the Senate on 16 October, Fraser was undecided whether to block supply. His biographer, Philip Ayres, contends that, had there been no further government scandals, he would not have done so. Khemlani, however, had alleged \u2013 contrary to government statements \u2013 that Connor had never revoked his authority to obtain loans and had been in regular contact with him even into mid-1975. On 13 October, the Melbourne \"Herald\" printed documents in support of Khemlani's allegations, and on the following day, Connor resigned. Fraser, determined to block supply, convened a shadow cabinet meeting and received the unanimous support of the Coalition frontbench. At a press conference, Fraser cited the poor state of the economy and the continuing scandals as reasons for his decision. Without the passage of fresh appropriations, supply would be exhausted on 30 November.\nOn 15 October the governor of Queensland, Sir Colin Hannah, gave a speech denigrating the Whitlam government, in violation of the convention that state governors remain neutral. Hannah held a dormant commission as Administrator of the Commonwealth to act as Governor-General in the event of Kerr's death, resignation, or absence from Australia. Whitlam immediately contacted Buckingham Palace to arrange for Hannah's dormant commission to be revoked, a process which took ten days to complete. Although Whitlam later alleged that he never contemplated dismissing Kerr during the crisis, on 16 October, while speaking with Kerr and visiting Malaysian Prime Minister Tun Abdul Razak, he told Kerr that if the crisis continued, \"It could be a question of whether I get to the Queen first for your recall, or whether you get in first with my dismissal.\" Kerr saw the statement as a threat; Whitlam later stated the comment was \"flippant\" and designed to turn the conversation to another subject.\nOn 16 and 17 October, the Senate, with the unanimous support of the Coalition majority, deferred the appropriation bills. In response to the blockage, Whitlam asserted that the Senate was acting against long-standing constitutional principles. On 16 October, the government endorsed a motion passed in the House stating that the Senate actions was \"a gross violation\" of conventions that placed the responsibility of the supply of money in the hands of the House of Representatives. The Opposition-controlled Senate rejected this contention, moving a motion that denied the existence of any such convention. \nThe Coalition took the position that Kerr could dismiss Whitlam if the Government could not secure supply. Whitlam's former solicitor-general Bob Ellicott, now a Liberal member of the House, issued a legal opinion on 16 October stating that the Governor-General had the power to dismiss Whitlam, and should do so forthwith if Whitlam could not state how he would obtain supply. Ellicott indicated that Whitlam was treating Kerr as if he had no discretion but to follow prime ministerial advice, when in fact the Governor-General could and should dismiss a ministry unable to secure supply. Ellicott stated that Kerr\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;should ask the Prime Minister if the Government is prepared to advise him to dissolve the House of Representatives and the Senate or the House of Representatives alone as a means of assuring that the disagreement between the two Houses is resolved. If the Prime Minister refuses to do either, it is then open to the Governor-General to dismiss his present Ministers and seek others who are prepared to give him the only proper advice open. This he should proceed to do.\nJournalist and author Paul Kelly, who wrote two books on the crisis, argues that Whitlam was motivated by a desire to bring about de facto constitutional change, with the House of Representatives gaining dominance over the Senate:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Whitlam intended to use the crisis triggered by Fraser to defeat the Senate in such a comprehensive manner that no future Senate would contemplate such action, and to ensure that the contradiction within the Constitution since the inauguration of the Commonwealth was finally resolved with the victory of the Representatives over the Senate and of responsible government over federalism. Whitlam would become the last of the founding fathers. He would resolve the contradiction that they had been unable to resolve.\nConsultations and negotiations.\nKerr's major confidant and secret adviser regarding the dismissal was a member of the High Court and friend of Kerr, Sir Anthony Mason whose role was not revealed until 2012 when Whitlam's biographer Jenny Hocking detailed Kerr's archival record of their extensive consultations. Kerr described Mason as playing \"a most significant part in my thinking\" and wrote of confiding in Mason \"to fortify myself for the action I was to take\". Mason's role included drafting a letter of dismissal for Kerr and he also said he had advised Kerr that he should \"as a matter of fairness\" warn Whitlam of his intention to dismiss him, which Kerr refused to do. Mason writes that his discussions with Kerr began in August 1975 and concluded on the afternoon of 11 November 1975. He declined Kerr's requests to allow his role to be publicly known. Kerr rang Whitlam on Sunday 19 October, asking permission to consult with the Chief Justice of the High Court, Sir Garfield Barwick, concerning the crisis. Whitlam advised Kerr not to do so, noting that no Governor-General had consulted with a Chief Justice under similar circumstances since 1914, when Australia was at a much earlier stage of her constitutional development. Whitlam also noted that in all of the recent unsuccessful High Court challenges to Whitlam government legislation, Barwick had been in the minority in finding against the government. On 21 October, Kerr phoned Whitlam regarding the Ellicott opinion, and asked, \"It's all bullshit, isn't it?\". Whitlam agreed with Kerr's view. Kerr then requested that the Government provide him with a written legal opinion rebutting Ellicott's views. Kerr would receive no written advice from the Government until 6 November. Paul Kelly paints this delay as a major mistake by Whitlam, given Kerr's judicial background. Kerr also asked on 21 October for Whitlam's permission to interview Fraser, which the Prime Minister readily granted, and the two men met that night. Fraser told Kerr that the Opposition were determined to block supply. Fraser indicated that the Opposition's decision to defer the appropriation bills, rather than defeating them, was a tactical decision, since then the bills would remain in the control of the Senate and could be passed at any time. He stated that the Coalition agreed with the Ellicott opinion, and proposed to continue deferring supply while it awaited events. The media were not told of the substance of the conversation, and instead reported that Kerr had reprimanded Fraser for blocking supply, causing the Governor-General's office to issue a denial.\nThroughout the crisis, Kerr did not tell Whitlam of his increasing concerns, nor did he suggest that he might dismiss Whitlam. He believed nothing he said would influence Whitlam, and feared that, if Whitlam perceived him as a possible opponent, the Prime Minister would procure his dismissal from the Queen. Accordingly, though Kerr dealt with Whitlam in an affable manner, he did not confide his thinking to the Prime Minister. Labor senator Tony Mulvihill later related that \"Whitlam would come back to each caucus meeting and say, 'I saw His Excellency\u00a0... No worry. He's got to do it his way.'\u00a0... at no time did he hint that the Governor-General was frowning.\"\nThere was intense public interest and concern at the stalemate, and Fraser and his Liberals acted to shore up support. Liberal frontbenchers worked to build unity for the tactic in state organisations. The former longtime Premier of South Australia Sir Thomas Playford was speaking out against the blocking of supply, causing South Australia senator Don Jessop to waver in his support for the tactic. Fraser was able to co-ordinate a wave of communications from party members which served to neutralise both men. Fraser sought the backing of the retired longtime Liberal Prime Minister, Sir Robert Menzies, and went to see Menzies in person, taking with him a 1947 statement by Menzies supporting the blocking of supply in the upper house of the Victorian Parliament. He did not have to use the paper; Menzies stated that he found the tactic distasteful, but in this case necessary. The former prime minister issued a statement in support of Fraser's tactics.\nKerr invited Whitlam and Minister for Labour Jim McClelland to lunch on 30October, immediately preceding an Executive Council meeting. At that meal, Kerr proposed a possible compromise. If the Opposition were to allow supply to pass, Whitlam would not advise a half-Senate election until May or June 1976, and the Senate would not convene until 1July, thus obviating the threat of a possible temporary Labor majority. Whitlam, who was determined to destroy both Fraser's leadership and the Senate's right to block supply, refused any compromise.\nDecision.\nFraser chaired a summit of leaders of the Coalition parties on 2 November. The resulting communiqu\u00e9 urged the Coalition senators to continue deferring supply. It also threatened, should Kerr grant Whitlam a half-Senate election, that the Coalition state premiers would advise their governors not to issue writs, thus blocking the election from taking place in the four states with non-Labor premiers. After the meeting, Fraser proposed a compromise: that the Opposition would concede supply if Whitlam agreed to hold a House of Representatives election at the same time as the half-Senate election. Whitlam rejected the idea.\nOn 22 October, Whitlam had asked the Attorney-General, Kep Enderby, to have a paper drafted rebutting the Ellicott opinion for presentation to Kerr. Enderby delegated this task to the Solicitor-General, Maurice Byers, and other officials. On 6 November, Enderby was to see Kerr to give him a legal opinion regarding the Government's alternative plans in case supply ran out. Vouchers were to be issued to Commonwealth employees and contractors instead of cheques, to be redeemed from banks after the crisis ended\u2014transactions which were to be rejected by major banks as \"tainted with illegality\". Enderby decided to present Kerr with the rebuttal to Ellicott. When Enderby reviewed the document, he found that, while it argued for the Government's position, it recognised both that the Senate had the constitutional right to block supply, and that the reserve powers were still extant\u2014matters with which Enderby did not agree. He presented Kerr with the rebuttal, but crossed out Byers' signature on it and told Kerr of his disagreement. Enderby told Kerr that the Byers rebuttal was \"background\" for formal written advice, to be presented by Whitlam. Later that day, Kerr met with Fraser again. The Opposition leader told him that if Kerr did not dismiss Whitlam, the Opposition planned to criticise him in Parliament for failing to carry out his duty.\nKerr concluded on 6 November that neither Government nor Opposition would yield and had received advice that day from Treasurer Bill Hayden that supply would run out on 27 November. The Governor-General decided that, as Whitlam could not secure supply, and would not resign or advise an election for the House of Representatives, he would have to sack him. As Kerr feared that Whitlam might advise the Queen to dismiss him, he considered it important that Whitlam be given no hint of the impending action. Kerr later stated that were Whitlam to seek his dismissal, it would involve the Queen in politics. Seeking confirmation of his decision, he contacted Chief Justice Barwick, met with him and asked for his views of a dismissal of Whitlam. Barwick furnished him with written advice containing his view that a governor-general could and should dismiss a prime minister who was unable to obtain supply. Barwick specified that the prime minister should also not have refused either to resign or to advise a general election, with which Kerr agreed.\nOn 9 November, Fraser contacted Whitlam and invited him to negotiations with the Coalition aimed at settling the dispute. Whitlam agreed, and a meeting was set for 9\u00a0am on Tuesday 11 November, at Parliament House. That Tuesday was also the deadline for an election to be called if it were to be held before Christmas. Both Government and Opposition leaders were in Melbourne on the night of 10 November for the Lord Mayor's banquet. To ensure the Opposition leaders could reach Canberra in time for the meeting, Whitlam brought them back in his VIP aircraft, which arrived in Canberra at midnight.\nDismissal.\nMeeting at Yarralumla.\nAt 9\u00a0am on 11 November, Whitlam, together with deputy prime minister Frank Crean and Leader of the House Fred Daly, met with Fraser and Country Party leader Doug Anthony. No compromise could be reached. Whitlam informed the Coalition leaders that he would be advising Kerr to hold a half-Senate election on 13 December, and he would not be seeking interim supply for the period before the election. Thinking it unlikely that Kerr would grant the election without supply, Fraser warned Whitlam that the Governor-General might make up his own mind about the matter. Whitlam was dismissive and after the meeting broke, telephoned Kerr to tell him that he needed an appointment to advise him to hold a half-Senate election. Both men were busy in the morning, Kerr with Remembrance Day commemorations, and Whitlam with a caucus meeting and a censure motion in the House which the Opposition had submitted. The two discussed a meeting for 1:00\u00a0pm, though Kerr's office later called Whitlam's and confirmed the time as 12:45pm. Word of this change did not reach Whitlam. Whitlam announced the request for a half-Senate election to his caucus, which approved it.\nAfter hearing from Whitlam, Kerr called Fraser. According to Fraser, Kerr asked him whether he, if commissioned prime minister, could secure supply, would immediately thereafter advise a double-dissolution election, and would refrain from new policies and investigations of the Whitlam government pending the election. Fraser stated that he agreed. Kerr denied the exchange took place via telephone, though both men agree those questions were asked later in the day before Kerr commissioned Fraser as prime minister. According to Kerr, Fraser was supposed to come to Yarralumla at 1:00\u00a0pm.\nWhitlam was delayed in leaving Parliament House, while Fraser left slightly early, with the result that Fraser arrived at Yarralumla first. He was taken into an anteroom, and his car was moved. Whitlam maintained that the purpose in moving Fraser's car was to ensure that Whitlam was not tipped off by seeing it, stating, \"Had I known Mr. Fraser was already there, I would not have set foot in Yarralumla.\" Kelly doubted Whitlam would have recognised Fraser's car, which was an ordinary Ford LTD from the car pool. According to Fraser biographer Philip Ayres, \"A white car pulled up at the front would signify nothing in particular\u2014it would simply be in the way.\"\nWhitlam arrived just before 1:00\u00a0pm and was taken to Kerr's office by an aide. He brought with him the formal letter advising a half-Senate election, and after the two men were seated, attempted to give it to Kerr. According to Kerr, he interrupted Whitlam and asked if, as a result of the failure to find a compromise between party leaders, he intended to govern without parliamentary supply, to which the Prime Minister answered, \"Yes\". In their accounts of their meeting, both men agree that Kerr then told Whitlam about the decision to withdraw his commission as prime minister under section\u00a064 of the Constitution. Kerr later wrote that at this point Whitlam got to his feet, looked at the office's phones, and stated, \"I must get in touch with the Palace at once.\" According to Kerr, this indicated that Whitlam would not try to negotiate with him about a general election but contact the Queen for his recall, which gave him the final reason to carry out the dismissal; he answered that it was too late to get in touch with the Palace because Whitlam was not prime minister any more. Whitlam, however, later disputed that such words were spoken, and stated that he asked Kerr whether he had consulted the Palace, to which Kerr replied that he did not need to, and that he had the advice of Barwick. Both accounts agree that Kerr then handed Whitlam a letter of dismissal and statement of reasons, stating that they would both have to live with this, to which Whitlam replied, \"\"You\" certainly will.\" The dismissal concluded with Kerr wishing Whitlam luck in the election, and offering his hand, which the now former prime minister took.\nKerr's statement of reasons read:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Because of the federal nature of our Constitution and because of its provisions the Senate undoubtedly has constitutional power to refuse or defer supply to the Government. Because of the principles of responsible government a Prime Minister who cannot obtain supply, including money for carrying on the ordinary services of government, must either advise a general election or resign. If he refuses to do this I have the authority and indeed the duty under the Constitution to withdraw his Commission as Prime Minister. The position in Australia is quite different from a position in the United Kingdom. Here the confidence of both Houses on supply is necessary to ensure its provision. In the United Kingdom the confidence of the House of Commons alone is necessary. But both here and in the United Kingdom the duty of the Prime Minister is the same in a most important aspect \u2013 if he cannot get supply he must resign or advise an election.\u2014\u200a\nAfter Whitlam left, Kerr called Fraser in, informed him of the dismissal, and asked if he would form a caretaker government, to which Fraser agreed. Fraser later stated that his overwhelming sensation at the news was relief. Fraser left to return to Parliament House, where he conferred with Coalition leaders, while Kerr joined the luncheon party that had been waiting for him, apologising to his guests and offering the excuse that he had been busy dismissing the Government.\nParliamentary strategy.\nWhitlam returned to The Lodge, where he had lunch. When his aides arrived, he informed them of his sacking. Whitlam drafted a resolution for the House, expressing confidence in his Government. No ALP Senate leaders were at The Lodge, nor did Whitlam and his party contact any when they drove back to Parliament House, confining their strategy to the House of Representatives.\nPrior to Whitlam's dismissal, the Labor leadership decided to introduce a motion that the Senate pass the appropriation bills. With ALP senators unaware of Whitlam's sacking, that plan went ahead. Senator Doug McClelland, manager of the ALP government in the Senate, informed Coalition Senate leader Reg Withers of Labor's intent at about 1:30\u00a0pm. Withers then attended a leadership meeting where he learned of Fraser's appointment and assured the new prime minister he could secure supply. When the Senate convened, the ALP Senate leader, Ken Wriedt, made the motion to pass the appropriation bills. As Wriedt did so, he was told that the government had been sacked, which he initially refused to believe. Authoritative word did not reach Wriedt until 2:15\u00a0pm, by which time it was too late to withdraw the motion and instead obstruct his party's appropriation bill to hinder Fraser. At 2:24\u00a0pm, Labor's appropriation bills passed the Senate, fulfilling Fraser's first promise of providing supply.\nIn the House, desultory debate on Fraser's censure motion ended with it being amended by the ALP majority into a condemnation of Fraser and passed on a party line vote. By 2:34\u00a0pm, when Fraser rose and announced that he had been commissioned as prime minister, word of the dismissal had spread through the House. Fraser announced his intent to advise a double dissolution, and moved that the House adjourn. His motion was defeated. Fraser's new government suffered repeated defeats in the House, which passed a motion of no confidence in him, and asked the Speaker, Gordon Scholes, to urge the Governor-General to recommission Whitlam. Scholes, attempting to communicate this to the Governor-General, was initially told that an appointment might not be possible that day, but after stating that he would reconvene the House and tell them of the refusal, was given an appointment with Kerr for 4:45\u00a0pm.\nDissolution.\nAfter the appropriation bills were approved by both Houses, they were sent over to Yarralumla where Kerr gave them royal assent. With supply assured, Kerr then received Fraser, who advised him that 21\u00a0bills (including the electoral redistribution bills) which had been introduced since the last election fulfilled the double dissolution provisions of section\u00a057. Fraser asked that both Houses be dissolved for an election on 13December. Kerr signed the proclamation dissolving Parliament, and sent his Official Secretary, David Smith, to proclaim the dissolution from the front steps of Parliament House.\nAt 4:45pm, Kerr received Scholes, and informed him of the dissolution. Kerr wrote that \"nothing else of relevance\" took place between the two men, but Scholes's account is that he accused Kerr of bad faith for making an appointment to receive the Speaker, and then not waiting to hear from him before dissolving Parliament. Whitlam later stated that it would have been wiser for Scholes to take the appropriation bills with him, rather than having them sent ahead. Kerr's action was based on the advice he had received from two High Court judges (Mason and Chief Justice Barwick) and the Crown Law Officers (Byers and Clarence Harders, the Secretary of the Attorney-General's Department).\nAs Scholes and Kerr spoke, Smith reached Parliament House. The dismissal was by then publicly known, and an angry crowd of ALP supporters had gathered, filling the steps and spilling over both into the roadway and into Parliament House itself. Many of the demonstrators were ALP staffers; others were from the Australian National University. Smith was forced to enter Parliament House through a side door and make his way to the steps from the inside. He read the proclamation, though the boos of the crowd drowned him out, and concluded with the traditional \"God save the Queen\". Former Prime Minister Whitlam, who had been standing behind Smith, then addressed the crowd:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nWell may we say \"God save the Queen\", because nothing will save the Governor-General! The Proclamation which you have just heard read by the Governor-General's Official Secretary was countersigned Malcolm Fraser, who will undoubtedly go down in Australian history from Remembrance Day 1975 as Kerr's cur. They won't silence the outskirts of Parliament House, even if the inside has been silenced for a few weeks\u00a0... Maintain your rage and enthusiasm for the campaign for the election now to be held and until polling day.\nAftermath.\nCampaign.\nThe news that Whitlam had been dismissed spread across Australia during the afternoon, triggering immediate protest demonstrations. On 12\u00a0November, Scholes wrote to the Queen, asking her to restore Whitlam as prime minister. The reply from her private secretary, Martin Charteris, dated 17November 1975, stated:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;As we understand the situation here, the Australian Constitution firmly places the prerogative powers of the Crown in the hands of the Governor-General as the representative of the Queen of Australia. The only person competent to commission an Australian Prime Minister is the Governor-General, and The Queen has no part in the decisions which the Governor-General must take in accordance with the Constitution. Her Majesty, as Queen of Australia, is watching events in Canberra with close interest and attention, but it would not be proper for her to intervene in person in matters which are so clearly placed within the jurisdiction of the Governor-General by the Constitution Act.\nOn 12 November 1975, the First Fraser Ministry was sworn in by Kerr. By some accounts, Kerr sought reassurance at that meeting that the Coalition senators would not have given in before supply ran out, \"The Senate would never have caved in, would it?\" According to those accounts, senator Margaret Guilfoyle laughed and said to a colleague, \"That's all he knows\". Guilfoyle later stated that, if she did make such a remark, it was not meant to imply that the Coalition senators would have broken. However, Kelly lists four Coalition senators who stated, in subsequent years, that they would have crossed the floor and voted for the appropriation bills.\nLabor believed it had a chance of winning the election, and that the dismissal would be an electoral asset for them. However, some Labor strategists believed the party was heading for a disaster, with few economic accomplishments to point to and an electorate whose emotions would have cooled before polling day. Nonetheless, Whitlam, who began campaigning almost immediately after the dismissal, was met with huge crowds wherever he went; 30,000\u00a0people overspilled the Sydney Domain for the official campaign launch on 24November. That evening, Whitlam made a major speech at Festival Hall in Melbourne before 7,500\u00a0people and a national TV audience, calling 11November \"Fraser's day of shame\u2014a day that will live in infamy\".\nPolls were released at the end of the first week of campaigning, and showed a nine-point swing against Labor. Whitlam's campaign did not believe it at first, but additional polling made it clear that the electorate was turning against the ALP. The Coalition attacked Labor for the economic conditions, and released television commercials \"The Three Dark Years\" showing images from the Whitlam government scandals. The ALP campaign, which had concentrated on the issue of Whitlam's dismissal, did not begin to address the economy until its final days. By that time Fraser, confident of victory, was content to sit back, avoid specifics and make no mistakes. There was little violence in the campaign, but three letter bombs were placed in the post; one wounded two people in Bjelke-Petersen's office, while the other two, addressed to Kerr and Fraser, were intercepted and defused.\nDuring the campaign, the Kerrs purchased a Sydney apartment, as John was prepared to resign in the event that the ALP triumphed. In the 13\u00a0December election, the Coalition won a record victory, with 91\u00a0seats in the House of Representatives to the ALP's 36 and a 35\u201327 majority in the expanded Senate.\nReactions.\nThe dismissal is considered the greatest political and constitutional crisis in Australia's history. In 1977, the Fraser government proposed four constitutional amendments via referendum, three of which passed\u2014the last time that the Australian Constitution has been amended. One of the amendments requires that a senator appointed to fill a casual vacancy be from the same party as the former senator. As of 2002[ [update]], the Senate retains the power to block supply; the governor-general retains the power to dismiss a prime minister. However, these powers have not since been used to force a government from office.\nIn the wake of the dismissal, the ALP turned its anger on Kerr. Demonstrations marked his appearances, while the remaining ALP parliamentarians boycotted his opening of the new parliament. Whitlam, now leader of the Opposition, refused all invitations to events at Yarralumla, which the Kerrs continued to extend until his refusal of an invitation during the Queen's 1977 visit caused them to feel that no further efforts need be made. Whitlam never spoke with Kerr again. Even ALP parliamentarians who had been friends of Kerr broke off their relationships, feeling Kerr had betrayed the party and had ambushed Whitlam. Lady Kerr stated that she and her husband confronted a \"new irrational scene swarming with instant enemies\".\nWhitlam repeatedly castigated Kerr for his role in the dismissal. When Kerr announced his resignation as governor-general on 14 July 1977, Whitlam commented: \"How fitting that the last of the Bourbons should bow out on Bastille Day\". After Kerr resigned as governor-general, he still sought a government position, reasoning that it had been his intent to remain for ten years as governor-general. However, Fraser's attempt to appoint Kerr as ambassador to UNESCO (a position later held by Whitlam) provoked such public outcry that the nomination was withdrawn. The Kerrs spent the next several years living in Europe, and when he died in Australia in 1991, his death was not announced until after he was buried. In 1991, Whitlam stated that no future governor-general was likely to act as Kerr did lest he also became the subject of \"contempt and isolation\". In 1997 he said that the letter of dismissal \"had the shortcomings of being \"ex tempore\", \"ex parte\", \"ad hoc\" and \"sub rosa\"\". In 2005, Whitlam called Kerr \"a contemptible person\". On the other hand, Country Party leader and deputy prime minister Doug Anthony said: \"I can't forgive Gough for crucifying him\". Sir Garfield Barwick was not spared Whitlam's invective; the former prime minister described him as \"evil\". Allegations have been made about CIA involvement in the Whitlam dismissal, although these were denied by both Kerr and Whitlam.\nWhitlam resigned as ALP leader after the party suffered its second successive electoral defeat in 1977. Fraser served over seven years as prime minister, and left the Liberal leadership after the Coalition was defeated in the 1983 election. Years later, Whitlam and Fraser put aside their differences; Whitlam wrote in 1997 that Fraser \"did not set out to deceive me\". The two campaigned together in support of the 1999 referendum that would have made Australia a republic. According to Whitlam speechwriter Graham Freudenberg, \"the residual rage over the conduct of the Queen's representative found a constructive outlet in the movement for the Australian Republic\".\nFreudenberg summed up Kerr's fate after the dismissal:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;The beneficiaries of the Dismissal scarcely bothered to defend Kerr and in the end abandoned him. In the personal sense, Sir John Kerr himself became the real victim of the Dismissal, and history has accorded a brutal if poignant truth to Whitlam's declaration on the steps of Parliament House on 11 November 1975: \"Well may we say 'God Save the Queen'\u00a0\u2013 because nothing will save the Governor-General\".\nAssessment.\nIn his 1995 survey of the events of the crisis, \"November 1975\", Kelly places blame on Fraser for initiating the crisis and on Whitlam for using the crisis to try to break Fraser and the Senate. However, he places the most blame on Kerr, for failing to be candid with Whitlam about his intentions, and for refusing to offer a clear, final warning before dismissing him. According to Kelly,\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;[Kerr] should have unflinchingly and courageously met his responsibility to the Crown and to the Constitution. He should have spoken frankly with his Prime Minister from the start. He should have warned wherever and whenever appropriate. He should have realised that, whatever his fears, there was no justification for any other behaviour.\nKerr's predecessor as governor-general, Sir Paul Hasluck, believed that the fundamental reason for the crisis was the lack of trust and confidence between Whitlam and Kerr, and that the proper role of the governor-general had been to provide counsel, advice and warning.\nFuture Labor prime minister Paul Keating, who was Minister for Northern Australia in Whitlam's ministry, called the dismissal a \"coup\" and raised the idea to \"arrest [Kerr]\" and \"lock him up\", adding that he would not have \"[taken] it lying down\" if he was prime minister, during a 2013 interview with Kerry O'Brien.\nRoyal involvement.\nNeither Whitlam nor Kerr ever suggested there had been any covert royal involvement. According to Whitlam's biographer Jenny Hocking, Kerr's papers in the National Archives of Australia reveal that he discussed with the Prince of Wales (later Charles III) his reserve powers and the possibility that he would dismiss the Whitlam government, in September 1975. Kerr asked what would happen if he dismissed Whitlam and the prime minister retaliated by dismissing him. According to Kerr, Charles had responded: \"But surely, Sir John, the Queen should not have to accept advice that you should be recalled at the very time when you were considering having to dismiss the government\". Kerr writes in his journal that Prince Charles informed the Queen's Private Secretary, Martin Charteris, of the conversation. Charteris then wrote to Kerr to say that, should the prime minister request the recall of the governor-general, the Queen \"would take most unkindly to it. There would be considerable comings and goings, but ... at the end of the road The Queen, as a Constitutional Sovereign, would have no option but to follow the advice of her Prime Minister.\" Hocking argues the letter is alarming as \"the involvement of the Queen in any discussion with Kerr about his tenure unknown to the prime minister, was manifestly improper [as] the appointment and recall of a governor-general is clearly and unquestionably a decision for the Australian prime minister alone\". She also suggests that the letter indicates that the palace approved of dismissal, quoting Professor Paul Rodan that \"Only the most obtuse of governors-general could fail to interpret [the letter] as a favourable sign\". Conversely, Paul Kelly and Troy Bramstone argues against this interpretation, stating that the reference to the \"considerable comings and goings\" referred to the fact that dismissal would require written notice, not just a phone call. They argue that the letter \"demonstrate[s] beyond question that the Queen would remove Kerr on Whitlam's advice\".\nBeginning in 2012, Hocking attempted to gain the release of correspondence between the Queen's advisors and Kerr regarding the dismissal, held by the National Archives. In 2016, Hocking launched a federal court action against the National Archives seeking the release of the \"Palace letters\", correspondence between Kerr, the Queen and Charteris held by the archives but not available for view. The action was lost in the full court, but on 29 May 2020 Hocking's appeal to the High Court succeeded: in a majority six to one decision the High Court held that the Palace letters are \"Commonwealth records\" (not personal property) and therefore available for public release under the provisions of the \"Archives Act 1983\".\nOn 14 July 2020, the letters were released online without redaction. They revealed that, although Kerr had corresponded with Charteris about whether he had the constitutional authority to dismiss Whitlam, he had not informed the Queen in advance of his decision to do so. However, the letters also revealed that Kerr had discussed the possibility of dismissing Whitlam as early as July1975. Also, on 2October 1975, Charteris confirmed in a letter that Kerr had discussed with Charles the possibility that Whitlam could ask the Queen to dismiss Kerr.\nPopular culture.\nThe 1983 miniseries \"The Dismissal\" dramatised the events of the crisis. It featured Max Phipps as Whitlam, John Meillon as Kerr and John Stanton as Fraser. A musical adaptation of the events was staged by the Sydney Theatre Company in 2023.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52853", "revid": "37024255", "url": "https://en.wikipedia.org/wiki?curid=52853", "title": "Alice's Adventures in Wonderland", "text": "1865 children's novel by Lewis Carroll\nAlice's Adventures in Wonderland (also known as Alice in Wonderland) is an 1865 English children's novel by Lewis Carroll, a mathematics don at the University of Oxford. It details the story of a girl named Alice who falls through a rabbit hole into a fantasy world of anthropomorphic creatures. It is seen as an example of the literary nonsense genre. The artist John Tenniel provided 42 wood-engraved illustrations for the book. \nIt received positive reviews upon release and is now one of the best-known works of Victorian literature; its narrative, structure, characters and imagery have had a widespread influence on popular culture and literature, especially in the fantasy genre. It is credited as helping end an era of didacticism in children's literature, inaugurating an era in which writing for children aimed to \"delight or entertain\". The tale plays with logic, giving the story lasting popularity with adults as well as with children. The titular character Alice shares her name with Alice Liddell, a girl Carroll knew\u2014scholars disagree about the extent to which the character was based upon her.\nThe book has never been out of print and has been translated into 174 languages. Its legacy includes adaptations to screen, radio, visual art, ballet, opera, and musical theatre, as well as theme parks, board games and video games. Carroll published a sequel in 1871 entitled \"Through the Looking-Glass\" and a shortened version for young children, \"The Nursery \"Alice\"\", in 1890.\nBackground.\n\"All in the golden afternoon...\".\n\"Alice's Adventures in Wonderland\" was conceived on 4 July 1862, when Lewis Carroll and the Reverend Robinson Duckworth rowed up the river Isis with the three young daughters of Carroll's friend Henry Liddell: Lorina Charlotte (aged 13; \"Prima\" in the book's prefatory verse); Alice Pleasance (aged 10; \"Secunda\" in the verse); and Edith Mary (aged 8; \"Tertia\" in the verse).\nThe journey began at Folly Bridge, Oxford, and ended upstream at Godstow, Oxfordshire. During the trip, Carroll told the girls a story that he described in his diary as \"Alice's Adventures Under Ground\", which his journal says he \"undertook to write out for Alice\". Alice Liddell recalled that she asked Carroll to write it down: unlike other stories he had told her, this one she wanted to preserve. She finally received the manuscript more than two years later.\n4 July was known as the \"golden afternoon\", prefaced in the novel as a poem. In fact, the weather around Oxford on 4 July was \"cool and rather wet\", although at least one scholar has disputed this claim. Scholars debate whether Carroll in fact came up with \"Alice\" during the \"golden afternoon\" or whether the story was developed over a longer period. \nCarroll had known the Liddell children since around March 1856, when he befriended Harry Liddell. He had met Lorina by early March as well. In June 1856, he took the children out on the river. Robert Douglas-Fairhurst, who wrote a literary biography of Carroll, suggests that Carroll favoured Alice Pleasance Liddell in particular because her name was ripe for allusion. \"Pleasance\" means pleasure and the name \"Alice\" appeared in contemporary works, including the poem \"Alice Gray\" by William Mee, of which Carroll wrote a parody; Alice is a character in \"Dream-Children: A Reverie\", a prose piece by Charles Lamb. Carroll, an amateur photographer by the late 1850s, produced many photographic portraits of the Liddell children \u2013 and especially of Alice, of which 20 survive.\nManuscript: \"Alice's Adventures Under Ground\".\nCarroll began writing the manuscript of the story the next day, although that earliest version is lost. The girls and Carroll took another boat trip a month later, when he elaborated the plot of the story to Alice, and in November, he began working on the manuscript in earnest. To add the finishing touches, he researched natural history in connection with the animals presented in the book and then had the book examined by other children\u2014particularly those of George MacDonald. Though Carroll did add his own illustrations to the original copy, on publication he was advised to find a professional illustrator so that the pictures were more appealing to his audience. He subsequently approached \"Punch\" cartoonist John Tenniel to reinterpret his visions through his own artistic eye, telling him that the story had been well-liked by the children.\nCarroll began planning a print edition of the \"Alice\" story in 1863. He wrote on 9 May 1863 that MacDonald's family had suggested he publish \"Alice\". A diary entry for 2 July says that he received a specimen page of the print edition around that date. On 26 November 1864, Carroll gave Alice the manuscript of \"Alice's Adventures Under Ground\", with illustrations by Carroll, dedicating it as \"A Christmas Gift to a Dear Child in Memory of a Summer's Day\". The published version of \"Alice's Adventures in Wonderland\" is about twice the length of \"Alice's Adventures Under Ground\" and includes episodes, such as the Mad Hatter's Tea-Party (or Mad Tea Party), that do not appear in the manuscript. The only known manuscript copy of \"Under Ground\" is held in the British Library. Macmillan published a facsimile of the manuscript in 1886.\nPlot.\nAlice, a young girl, sits bored by a riverbank and spots a White Rabbit with a pocket watch and waistcoat lamenting that he is late. Surprised, Alice follows him down a rabbit hole, which sends her into a lengthy plummet but to a safe landing. Inside a room with a table, she finds a key to a tiny door, beyond which is a garden. While pondering how to fit through the door, she discovers a bottle labelled \"Drink me\". Alice drinks some of the bottle's contents, and to her astonishment, she shrinks small enough to enter the door. However, she had left the key upon the table and cannot reach it. Alice then discovers and eats a cake labelled \"Eat me\", which causes her to grow to a tremendous size. Unhappy, Alice bursts into tears, and the passing White Rabbit flees in a panic, dropping a fan and two gloves. Alice uses the fan for herself, which causes her to shrink once more and leaves her swimming in a pool of her own tears. Within the pool, Alice meets various animals and birds, who convene on a bank and engage in a \"Caucus Race\" to dry themselves. Following the end of the race, Alice inadvertently frightens the animals away by discussing her cat.\nThe White Rabbit appears looking for the gloves and fan. Mistaking Alice for his maidservant, he orders her to go to his house and retrieve them. Alice finds another bottle and drinks from it, which causes her to grow to such an extent that she gets stuck in the house. Attempting to extract her, the White Rabbit and his neighbours eventually take to hurling pebbles that turn into small cakes. Alice eats one and shrinks herself, allowing her to flee into the forest. She meets a Caterpillar seated on a mushroom and smoking a hookah. During the Caterpillar's questioning, Alice begins to admit to her current identity crisis, compounded by her inability to remember a poem. Before crawling away, the Caterpillar says that a bite of one side of the mushroom will make her larger, while a bite from the other side will make her smaller. During a period of trial and error, Alice's neck extends between the treetops, frightening a pigeon who mistakes her for a serpent. After shrinking to an appropriate height, Alice arrives at the home of a Duchess, who owns a perpetually grinning Cheshire Cat. The Duchess's baby, whom she hands to Alice, transforms into a piglet, which Alice releases into the woods. The Cheshire Cat appears to Alice and directs her toward the Hatter and March Hare before disappearing, leaving his grin behind. Alice finds the Hatter, March Hare, and a sleepy Dormouse in the midst of a tea party. The Hatter explains that it is always 6\u00a0p.m. (tea time), claiming that time is standing still as punishment for the Hatter trying to \"kill it\". A conversation ensues around the table, and the riddle \"Why is a raven like a writing desk?\" is brought up. Alice impatiently decides to leave, calling the party stupid.\nNoticing a door on a tree, Alice passes through and finds herself back in the room from the beginning of her journey. She takes the key and uses it to open the door to the garden, which turns out to be the croquet court of the Queen of Hearts, whose guard consists of living playing cards. Alice participates in a croquet game, in which hedgehogs are used as balls, flamingos are used as mallets, and soldiers act as hoops. The Queen is short-tempered and constantly orders beheadings. When the Cheshire Cat appears as only a head, the Queen orders his beheading, only to be told that such an act is impossible. Because the cat belongs to the Duchess, Alice prompts the Queen to release the Duchess from prison to resolve the matter. When the Duchess ruminates on finding morals in everything around her, the Queen dismisses her on the threat of execution.\nAlice then meets a Gryphon and a Mock Turtle, who dance to the Lobster Quadrille while Alice recites (rather incorrectly) a poem. The Mock Turtle sings them \"Beautiful Soup\", during which the Gryphon drags Alice away for a trial, in which the Knave of Hearts stands accused of stealing the Queen's tarts. The trial is conducted by the King of Hearts, and the jury is composed of animals that Alice previously met. Alice gradually grows in size and confidence, allowing herself increasingly frequent remarks on the irrationality of the proceedings. The Queen eventually commands Alice's beheading, but Alice scoffs that the Queen's guard is only a pack of cards. Although Alice holds her own for a time, the guards soon gang up and start to swarm all over her. Alice's sister wakes her up from a dream, brushing what turns out to be leaves from Alice's face. Alice leaves her sister on the bank to imagine all the curious happenings for herself.\nCharacters.\nThe main characters in \"Alice's Adventures in Wonderland\" are the following:\nCharacter allusions.\nIn \"The Annotated Alice\", Martin Gardner provides background information for the characters. The members of the boating party that first heard Carroll's tale show up in chapter 3 (\"A Caucus-Race and a Long Tale\"). Alice Liddell is there, while Carroll is caricatured as the Dodo (Lewis Carroll was a pen name for Charles Lutwidge Dodgson; because he stuttered when he spoke, he sometimes pronounced his last name as \"Dodo-Dodgson\"). The Duck refers to Robinson Duckworth, and the Lory and Eaglet to Alice Liddell's sisters Lorina and Edith.\nBill the Lizard may be a play on the name of British Prime Minister Benjamin Disraeli. One of Tenniel's illustrations in \"Through the Looking-Glass\"\u2014the 1871 sequel to \"Alice\"\u2014depicts the character referred to as the \"Man in White Paper\" (whom Alice meets on a train) as a caricature of Disraeli, wearing a paper hat. The illustrations of the Lion and the Unicorn (also in \"Looking-Glass\") look like Tenniel's \"Punch\" illustrations of William Ewart Gladstone and Disraeli, although Gardner says there is \"no proof\" that they were intended to represent these politicians.\nGardner has suggested that the Hatter is a reference to Theophilus Carter, an Oxford furniture dealer, and that Tenniel apparently drew the Hatter to resemble Carter, on a suggestion of Carroll's. The Dormouse tells a story about three little sisters named Elsie, Lacie, and Tillie. These are the Liddell sisters: Elsie is L.C. (Lorina Charlotte); Tillie is Edith (her family nickname is Matilda); and Lacie is an anagram of Alice.\nThe Mock Turtle speaks of a drawling-master, \"an old conger eel\", who came once a week to teach \"Drawling, Stretching, and Fainting in Coils\". This is a reference to the art critic John Ruskin, who came once a week to the Liddell house to teach the children to draw, sketch, and paint in oils. The Mock Turtle sings \"Turtle Soup\", which is a parody of a song called \"Star of the Evening, Beautiful Star\", which the Liddells sang for Carroll.\nPoems and songs.\nCarroll wrote multiple poems and songs for \"Alice's Adventures in Wonderland\", including:\nWriting style and themes.\nSymbolism.\nCarroll's biographer Morton N. Cohen reads \"Alice\" as a \"roman \u00e0 clef\" populated with real figures from Carroll's life. Alice is based on Alice Liddell; the Dodo is Carroll; Wonderland is Oxford; even the Mad Hatter's Tea Party, according to Cohen, is a send-up of Alice's own birthday party. The critic Jan Susina rejects Cohen's account, arguing that Alice the character bears a tenuous relationship with Alice Liddell.\nBeyond its refashioning of Carroll's everyday life, Cohen argues, \"Alice\" critiques Victorian ideals of childhood. It is an account of \"the child's plight in Victorian upper-class society\", in which Alice's mistreatment by the creatures of Wonderland reflects Carroll's own mistreatment by older people as a child.\nIn the eighth chapter, three cards are painting the roses on a rose tree red, because they had accidentally planted a white-rose tree that the Queen of Hearts hates. According to Wilfrid Scott-Giles, the rose motif in \"Alice\" alludes to the English Wars of the Roses: red roses symbolised the House of Lancaster, and white roses the rival House of York.\nLanguage.\n\"Alice\" is full of linguistic play, puns, and parodies. According to Gillian Beer, Carroll's play with language evokes the feeling of words for new readers: they \"still have insecure edges and a nimbus of nonsense blurs the sharp focus of terms\". The literary scholar Jessica Straley, in a work about the role of evolutionary theory in Victorian children's literature, argues that Carroll's focus on language prioritises humanism over scientism by emphasising language's role in human self-conception.\nPat's \"Digging for apples\" is a cross-language pun, as \"pomme de terre\" (literally; \"apple of the earth\") means potato and \"pomme\" means apple. In the second chapter, Alice initially addresses the mouse as \"O Mouse\", based on her memory of the noun declensions \"in her brother's Latin Grammar, 'A mouse \u2013 of a mouse \u2013 to a mouse \u2013 a mouse \u2013 O mouse!'\" These words correspond to the first five of Latin's six cases, in a traditional order established by medieval grammarians: \"mus\" (nominative), \"muris\" (genitive), \"muri\" (dative), \"murem\" (accusative), \"(O) mus\" (vocative). The sixth case, \"mure\" (ablative) is absent from Alice's recitation. Nilson suggests that Alice's missing ablative is a pun on her father Henry Liddell's work on the standard \"A Greek-English Lexicon\", since ancient Greek does not have an ablative case. Further, mousa (\u03bc\u03bf\u03cd\u03c3\u03b1, meaning muse) was a standard model noun in Greek textbooks of the time in paradigms of the first declension, short-alpha noun.\nMathematics.\nMathematics and logic are central to \"Alice\". As Carroll was a mathematician at Christ Church, it has been suggested that there are many references and mathematical concepts in both this story and \"Through the Looking-Glass\". Literary scholar Melanie Bayley asserts in the \"New Scientist\" magazine that Carroll wrote \"Alice in Wonderland\" in its final form as a satire on mid-19th century mathematics.\nEating and devouring.\nCarina Garland notes how the world is \"expressed via representations of food and appetite\", naming Alice's frequent desire for consumption (of both food and words), her 'Curious Appetites'. Often, the idea of eating coincides to make gruesome images. After the riddle \"Why is a raven like a writing-desk?\", the Hatter claims that Alice might as well say, \"I see what I eat\u2026I eat what I see\" and so the riddle's solution, put forward by Boe Birns, could be that \"A raven eats worms; a writing desk is worm-eaten\"; this idea of food encapsulates idea of life feeding on life itself, for the worm is being eaten and then becomes the eater\u2014a horrific image of mortality.\nNina Auerbach discusses how the novel revolves around eating and drinking which \"motivates much of her [Alice's] behaviour\", for the story is essentially about things \"entering and leaving her mouth.\" The animals of Wonderland are of particular interest, for Alice's relation to them shifts constantly because, as Lovell-Smith states, Alice's changes in size continually reposition her in the food chain, serving as a way to make her acutely aware of the 'eat or be eaten' attitude that permeates Wonderland.\nNonsense.\n\"Alice\" is an example of the literary nonsense genre. According to Humphrey Carpenter, \"Alice\"'s brand of nonsense embraces the nihilistic and existential. Characters in nonsensical episodes such as the Mad Hatter's Tea Party, in which it is always the same time, go on posing paradoxes that are never resolved.\nRules and games.\nWonderland is a rule-bound world, but its rules are not those of our world. The literary scholar Daniel Bivona writes that \"Alice\" is characterised by \"gamelike social structures.\" She trusts in instructions from the beginning, drinking from the bottle labelled \"drink me\" after recalling, during her descent, that children who do not follow the rules often meet terrible fates. Unlike the creatures of Wonderland, who approach their world's wonders uncritically, Alice continues to look for rules as the story progresses. Gillian Beer suggests that Alice looks for rules to soothe her anxiety, while Carroll may have hunted for rules because he struggled with the implications of the non-Euclidean geometry then in development.\nIllustrations.\nThe manuscript was illustrated by Carroll, who added 37 illustrations\u2014printed in a facsimile edition in 1887. John Tenniel provided 42 wood-engraved illustrations for the 1865 published version of the book. The first print run was destroyed (or sold in the US) at Carroll's request because Tenniel was dissatisfied with the printing quality. There are only 22 known first edition copies in existence. The book was reprinted and published in 1866. Tenniel's detailed black-and-white drawings remain the definitive depiction of the characters.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Carroll's text was often light on description, and Tenniel invented his own characterisations, drawing from a vast range of sources, including fine art, natural history, heraldry, caricature and his previous work for \"Punch\". Once committed to paper, the now famous illustrations were carved into woodblocks by engravers, and electrotype copies made to be used by the publishers Macmillan for printing. The praise from critics and readers following publication was unanimous.\u2014\u200a\nTenniel's illustrations of Alice do not portray the real Alice Liddell, who had dark hair and a short fringe. In 1911, Harry Theaker, with Tenniel's approval, was commissioned by Macmillan to colour sixteen of Tenniel\u2019s plates for an \"Alice\" edition and her dress was blue \u2013 and has remained so in the popular mind ever since. \"Alice\" has provided a challenge for other illustrators, including those of 1907 by Charles Pears and the full series of colour plates and line-drawings by Harry Rountree published in the (inter-War) Children's Press (Glasgow) edition. Other significant illustrators include: Arthur Rackham (1907), Willy Pogany (1929), Mervyn Peake (1946), Ralph Steadman (1967), Salvador Dal\u00ed (1969), Graham Overden (1969), Max Ernst (1970), Peter Blake (1970), Tove Jansson (1977), Anthony Browne (1988), Helen Oxenbury (1999), and Lisbeth Zwerger (1999). To mark the 200th anniversary of Tenniel's birth, in 2020 Chris Riddell provided illustrations for a new edition of the novel.\nPublication history.\nCarroll first met Alexander Macmillan, a high-powered London publisher, on 19 October 1863. His firm, Macmillan Publishers, agreed to publish \"Alice's Adventures in Wonderland\" by sometime in 1864. Carroll financed the initial print run, possibly because it gave him more editorial authority than other financing methods. He managed publication details such as typesetting and engaged illustrators and translators.\nMacmillan had published \"The Water-Babies\", also a children's fantasy, in 1863, and suggested its design as a basis for \"Alice\"'s. Carroll saw a specimen copy in May 1865. 2,000 copies were printed by July, but Tenniel objected to their quality, and Carroll instructed Macmillan to halt publication so they could be reprinted. In August, he engaged Richard Clay as an alternative printer for a new run of 2,000. The reprint cost \u00a3600, paid entirely by Carroll. He received the first copy of Clay's edition on 9 November 1865.\nMacmillan finally published the new edition, printed by Richard Clay, in November 1865. Carroll requested a red binding, deeming it appealing to young readers. A new edition, released in December 1865 for the Christmas market but carrying an 1866 date, was quickly printed. The text blocks of the original edition were removed from the binding and sold with Carroll's permission to the New York publishing house of D. Appleton &amp; Company. The binding for the Appleton \"Alice\" was identical to the 1866 Macmillan \"Alice\", except for the publisher's name at the foot of the spine. The title page of the Appleton \"Alice\" was an insert cancelling the original Macmillan title page of 1865 and bearing the New York publisher's imprint and the date 1866.\nThe entire print run sold out quickly. \"Alice\" was a publishing sensation, beloved by children and adults alike. Oscar Wilde was a fan; Queen Victoria was also an avid reader of the book. She reportedly enjoyed \"Alice\" enough that she asked for Carroll's next book, which turned out to be a mathematical treatise; Carroll denied this. The book has never been out of print. \"Alice's Adventures in Wonderland\" has been translated into 174\u00a0languages.\nPublication timeline.\nThe following list is a timeline of major publication events related to \"Alice's Adventures in Wonderland\": \nReception.\n\"Alice\" was published to critical praise. One magazine declared it \"exquisitely wild, fantastic, [and] impossible\". In the late 19th century, Walter Besant wrote that \"Alice in Wonderland\" \"was a book of that extremely rare kind which will belong to all the generations to come until the language becomes obsolete\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;No story in English literature has intrigued me more than Lewis Carroll's \"Alice in Wonderland\". It fascinated me the first time I read it as a schoolboy.\u2014\u200a\nF. J. Harvey Darton argued in a 1932 book that \"Alice\" ended an era of didacticism in children's literature, inaugurating a new era in which writing for children aimed to \"delight or entertain\". In 2014, Robert McCrum named \"Alice\" \"one of the best loved in the English canon\" and called it \"perhaps the greatest, possibly most influential, and certainly the most world-famous Victorian English fiction\". A 2020 review in \"Time\" states: \"The book changed young people's literature. It helped to replace stiff Victorian didacticism with a looser, sillier, nonsense style that reverberated through the works of language-loving 20th-century authors as different as James Joyce, Douglas Adams and Dr. Seuss.\" Joe Sommerlad in \"The Independent\" writes that Roald Dahl \"owes a debt to the \"Drink Me\" episode in \"Alice\"\" in regard to Dahl's \"George's Marvellous Medicine\" where the grandmother drinks a potion and is blown up to the size of a farmhouse. The protagonist of the story, Alice, has been recognised as a cultural icon. In 2006, \"Alice in Wonderland\" was named among the icons of England in a public vote.\nAdaptations and influence.\nBooks for children in the \"Alice\" mould emerged as early as 1869 and continued to appear throughout the late 19th century. Released in 1903, the British silent film \"Alice in Wonderland\" was the first screen adaptation of the book.\nIn 2015, Robert Douglas-Fairhurst wrote in the \"Guardian\",\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Since the first publication of \"Alice's Adventures in Wonderland\" 150 years ago, Lewis Carroll's work has spawned a whole industry, from films and theme park rides to products such as a \"cute and sassy\" Alice costume (\"petticoat and stockings not included\"). The blank-faced little girl made famous by John Tenniel's original illustrations has become a cultural inkblot we can interpret in any way we like.\nLabelled \"a dauntless, no-nonsense heroine\" by the \"Guardian\", the character of the plucky, yet proper, Alice has proven immensely popular and inspired similar heroines in literature and pop culture, many also named Alice in homage. The book has inspired numerous film and television adaptations, which have multiplied, as the original work is now in the public domain in all jurisdictions. Musical works inspired by \"Alice\" include the Beatles's song \"Lucy in the Sky with Diamonds\", with songwriter John Lennon attributing the song's fantastical imagery to his reading of Carroll's books. Argentine prog-rock band Seru Giran used \"Alice\" as a metaphor to represent the political climate in Argentina during the 1970s in their song \"Canci\u00f3n de Alicia en el pa\u00eds\". A popular figure in Japan since the country opened up to the West in the late 19th century, Alice has been a popular subject for writers of manga and a source of inspiration for Japanese fashion, in particular Lolita fashion.\nLive performance.\nThe first full major production was \"Alice in Wonderland\", a musical play in London's West End by Henry Savile Clarke and Walter Slaughter, which premiered at the Prince of Wales Theatre in 1886. Twelve-year-old actress Phoebe Carlo (the first to play Alice) was personally selected by Carroll for the role. Carroll attended a performance on 30 December 1886, writing in his diary that he enjoyed it. The musical was frequently revived during West End Christmas seasons during the four decades after its premiere, including a London production at the Globe Theatre in 1888, with Isa Bowman as Alice.\nAs the book and its sequel are Carroll's most widely recognised works, they have also inspired numerous live performances, including plays, operas, ballets, and traditional English pantomimes. These works range from fairly faithful adaptations to those that use the story as a basis for new works. Eva Le Gallienne's stage adaptation of the \"Alice\" books premiered on 12 December 1932 and ended its run in May 1933. The production was revived in New York in 1947 and 1982. A community theatre production of \"Alice\" was Olivia de Havilland's first foray onto the stage.\nA dramatisation by Herbert M. Prentice premiered at the Shakespeare Memorial Theatre, Stratford-upon-Avon in 1947, and was in turn adapted for television by John Glyn-Jones and shown by the BBC on Christmas Day 1948. The BBC screened another adaptation of Prentice's play in 1956. Joseph Papp staged \"Alice in Concert\" at the Public Theater in New York City in 1980. Elizabeth Swados wrote the book, lyrics, and music based on both \"Alice's Adventures in Wonderland\" and \"Through the Looking-Glass\". Papp and Swados had previously produced a version of it at the New York Shakespeare Festival. Meryl Streep played Alice, the White Queen, and Humpty Dumpty. The cast also included Debbie Allen, Michael Jeter, and Mark Linn-Baker. Performed on a bare stage with the actors in modern dress, the play is a loose adaptation, with song styles ranging the globe. \nThe 1992 musical theatre production \"Alice\" used both books as its inspiration. It also employs scenes with Carroll, a young Alice Liddell, and an adult Alice Liddell, to frame the story. Paul Schmidt wrote the play, with Tom Waits and Kathleen Brennan writing the music. Although the original production in Hamburg, Germany, received only a small audience, Tom Waits released the songs as the album \"Alice\" in 2002.\nJoseph Horovitz composed an \"Alice in Wonderland\" ballet commissioned by the London Festival Ballet in 1953. It was performed frequently in England and the US. A ballet by Christopher Wheeldon and Nicholas Wright commissioned for the Royal Ballet entitled \"Alice's Adventures in Wonderland\" premiered in February 2011 at the Royal Opera House in London. The ballet was based on the novel Wheeldon grew up reading as a child and is generally faithful to the original story, although some critics claimed it may have been too faithful. \nUnsuk Chin's opera \"Alice in Wonderland\" premiered in 2007 at the Bavarian State Opera and was hailed as World Premiere of the Year by the German opera magazine \"Opernwelt\". Gerald Barry's 2016 one-act opera, \"Alice's Adventures Under Ground\", first staged in 2020 at the Royal Opera House, is a conflation of the two \"Alice\" books. In 2022, the Op\u00e9ra national du Rhin performed the ballet \"Alice\", with a score by Philip Glass, in Mulhouse, France.\nCommemoration.\nCharacters from the book are depicted in the stained glass windows of Carroll's hometown church, All Saints', in Daresbury, Cheshire, England. Another commemoration of Carroll's work in his home county of Cheshire is the granite sculpture \"The Mad Hatter's Tea Party\", located in Warrington. International works based on the book include the Alice in Wonderland statue in Central Park, New York, and the Alice statue in Rymill Park, Adelaide, Australia. \nIn 2015, \"Alice\" characters were featured on a series of UK postage stamps issued by the Royal Mail to mark the 150th anniversary of the publication of the book. In 2021, the Royal Mint issued their first \"Alice's Adventures in Wonderland\" commemorative coin collection, including a \u00a35 coin featuring Alice and the Cheshire Cat (inspired by Tenniel's original illustration).\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nWorks cited.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\n* https://\n* https://\n\"3 square blue boxes, each with 8 glass lantern slides and leaflet with abridged excerpt from 'Alice', 24 slides &amp; 3 leaflets all\""}
{"id": "52856", "revid": "24465790", "url": "https://en.wikipedia.org/wiki?curid=52856", "title": "Alice in Wonderland (disambiguation)", "text": "Alice's Adventures in Wonderland (also known as Alice in Wonderland for short) is a 1865 novel by Lewis Carroll.\nAlice in Wonderland may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "52857", "revid": "47902409", "url": "https://en.wikipedia.org/wiki?curid=52857", "title": "Marajuana", "text": ""}
{"id": "52859", "revid": "50881692", "url": "https://en.wikipedia.org/wiki?curid=52859", "title": "Pseudopodia", "text": "False leg found on slime molds, archaea, protozoans, leukocytes and certain bacteria\nA pseudopod or pseudopodium (pl.: pseudopods or pseudopodia) is a temporary arm-like projection of an eukaryotic cell membrane that is emerged in the direction of movement. Filled with cytoplasm, pseudopodia primarily consist of actin filaments and may also contain microtubules and intermediate filaments. Pseudopods are used for motility and ingestion. They are often found in amoebas.\nDifferent types of pseudopodia can be classified by their distinct appearances. Lamellipodia are broad and thin. Filopodia are slender, thread-like, and are supported largely by microfilaments. Lobopodia are bulbous and amoebic. Reticulopodia are complex structures bearing individual pseudopodia which form irregular nets. Axopodia are the phagocytosis type with long, thin pseudopods supported by complex microtubule arrays enveloped with cytoplasm; they respond rapidly to physical contact.\nGenerally, several pseudopodia arise from the surface of the body, (\"polypodial\", for example, \"Amoeba proteus\"), or a single pseudopod may form on the surface of the body (\"monopodial\", such as \"Entamoeba histolytica\").\nFormation.\nCells which make pseudopods are generally referred to as \"amoeboids\".\nVia extracellular cue.\nTo move towards a target, the cell uses chemotaxis. It senses extracellular signalling molecules, chemoattractants (e.g. cAMP for \"Dictyostelium\" cells), to extend pseudopodia at the membrane area facing the source of these molecules.\nThe chemoattractants bind to G\u00a0protein-coupled receptors, which activate GTPases of the Rho family (e.g. Cdc42, Rac) via G\u00a0proteins.\nRho GTPases are able to activate WASp which in turn activate Arp2/3 complex which serve as nucleation sites for actin polymerization. The actin polymers then push the membrane as they grow, forming the pseudopod. The pseudopodium can then adhere to a surface via its adhesion proteins (e.g. integrins), and then pull the cell's body forward via contraction of an actin-myosin complex in the pseudopod. This type of locomotion is called \"amoeboid movement\".\nRho GTPases can also activate phosphatidylinositol 3-kinase (PI3K) which recruit PIP3 to the membrane at the leading edge and detach the PIP3-degrading enzyme PTEN from the same area of the membrane. PIP3 then activate GTPases back via GEF stimulation. This serves as a feedback loop to amplify and maintain the presence of local GTPase at the leading edge.\nOtherwise, pseudopodia cannot grow on other sides of the membrane than the leading edge because myosin filaments prevent them to extend. These myosin filaments are induced by cyclic GMP in \"D. discoideum\" or Rho kinase in neutrophils for example.\nDifferent physical parameters were shown to regulate the length and time-scale of pseudopodia formation. For example, an increase in membrane tension inhibits actin assembly and protrusion formation. It was demonstrated that the lowered negative surface charge on the inner surface of the plasma membrane generates protrusions via activation of the Ras-PI3K/AKT/mTOR signalling pathway.\nWithout extracellular cue.\nIn the case there is no extracellular cue, all moving cells navigate in random directions, but they can keep the same direction for some time before turning. This feature allows cells to explore large areas for colonization or searching for a new extracellular cue.\nIn \"Dictyostelium\" cells, a pseudopodium can form either \"de novo\" as normal, or from an existing pseudopod, forming a Y-shaped pseudopodium.\nThe Y-shaped pseudopods are used by \"Dictyostelium\" to advance relatively straight forward by alternating between retraction of the left or right branch of the pseudopod. The \"de novo\" pseudopodia form at different sides than pre-existing ones, they are used by the cells to turn.\nY-shaped pseudopods are more frequent than \"de novo\" ones, which explain the preference of the cell to keep moving to the same direction. This persistence is modulated by PLA2 and cGMP signalling pathways.\nFunctions.\nThe functions of pseudopodia include locomotion and ingestion:\nMorphology.\nPseudopods can be classified into several varieties according to the number of projections (monopodia and polypodia), and according to their appearance.\nSome pseudopodial cells are able to use multiple types of pseudopodia depending on the situation. Most use a combination of lamellipodia and filopodia to migrate (e.g. metastatic cancer cells). Human foreskin fibroblasts can either use lamellipodia- or lobopodia-based migration in a 3D matrix depending on the matrix elasticity.\nLamellipodia.\nLamellipodia are broad and flat pseudopodia used in locomotion. They are supported by microfilaments which form at the leading edge, creating a mesh-like internal network.\nFilopodia.\nFilopodia (or filose pseudopods) are slender and filiform with pointed ends, consisting mainly of ectoplasm. These formations are supported by microfilaments which, unlike the filaments of lamellipodia with their net-like actin, form loose bundles by cross-linking. This formation is partly due to bundling proteins such as fimbrins and fascins.\nFilopodia are observed in some animal cells: in part of Filosa (Rhizaria), in \"Testaceafilosia\", in Vampyrellidae and Pseudosporida (Rhizaria) and in Nucleariida (Opisthokonta).\nLobopodia.\nLobopodia (or lobose pseudopods) are bulbous, short, and blunt in form. These finger-like, tubular pseudopodia contain both ectoplasm and endoplasm. They can be found in different kind of cells, notably in Lobosa and other Amoebozoa and in some Heterolobosea (Excavata).\nHigh-pressure lobopodia can also be found in human fibroblasts travelling through a complex network of 3D matrix (e.g. mammalian dermis, cell-derived matrix). Contrarily to other pseudopodia using the pressure exerted by actin polymerization on the membrane to extend, fibroblast lobopods use the nuclear piston mechanism consisting in pulling the nucleus via actomyosin contractility to push the cytoplasm that in turn push the membrane, leading to pseudopod formation. To occur, this lobopodia-based fibroblast migration needs nesprin 3, integrins, RhoA, ROCK and myosin II.\nOtherwise, lobopods are often accompanied with small lateral blebs forming along the side of the cell, probably due to the high intracellular pressure during lobopodia formation increasing the frequency of plasma membrane-cortex rupture.\nReticulopodia.\nReticulopodia (or reticulose pseudopods), are complex formations in which individual pseudopods are merged and form irregular nets. The primary function of reticulopodia, also known as myxopodia, is food ingestion, with locomotion a secondary function. Reticulopods are typical of Foraminifera, Chlorarachnea, \"Gromia\" and \"Filoreta\" (Rhizaria).\nIf a pseudopod is branched as a reticulopod is but not forming a network, it is known as a rhizopod.\nAxopodia.\nAxopodia (also known as actinopodia) are narrow pseudopodia containing complex arrays of microtubules enveloped by cytoplasm. Axopodia are mostly responsible for phagocytosis by rapidly retracting in response to physical contact. These pseudopodia are primarily food-collecting structures, but also provide a means of hydrological transportation via the expansion of their surface areas. They are observed in \"Radiolaria\" and \"Heliozoa\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52861", "revid": "394950", "url": "https://en.wikipedia.org/wiki?curid=52861", "title": "Baltic Republics", "text": ""}
{"id": "52863", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=52863", "title": "Seasoning", "text": "Process of supplementing food via herbs, salts, or spices\nSeasoning is the process of supplementing food via herbs, spices, and/or salts, intended to enhance a particular flavour.\nGeneral meaning.\nSeasonings include herbs and spices, which are themselves frequently referred to as \"seasonings\". Salt may be used to draw out water, or to magnify a natural flavor of a food making it richer or more delicate, depending on the dish. This type of procedure is akin to curing. For instance, sea salt (a coarser-grained salt) is rubbed into chicken, lamb, and beef to tenderize the meat and improve flavour. Other seasonings like black pepper and basil transfer some of their flavors to the food. A well-designed dish may combine seasonings that complement each other.\nIn addition to the choice of herbs and seasoning, the timing of when flavors are added will affect the food that is being cooked or otherwise prepared. Seasonings are usually added near the end of the cooking period, or even at the table, when the food is served. The most common table-seasonings are salt, pepper, and acids (such as lemon juice). When seasonings are used properly, they cannot be tasted; their job is to heighten the flavors of the original ingredients.\nResearchers have found traces of garlic mustard seeds in prehistoric pots that also contained traces of meat, making this the earliest recording of seasoning food.\nOil infusion.\nInfused oils are also used for seasoning. There are two methods for doing an infusion\u2014hot and cold. Olive oil makes a good infusion base for some herbs, but tends to go rancid more quickly than other oils. Infused oils should be kept refrigerated.\nEscoffier.\nIn \"Le Guide Culinaire\", Auguste Escoffier divides seasoning and condiments into the following groups:\nNon-culinary uses.\nSeasonings have also been used for non-culinary purposes throughout history. Cinnamon, for example, was widely utilized in the production of Kyphi, a perfume used in ancient Egypt. Other herbs and spices have also been used in a variety of historical medicinal treatments, such as those described in Ebers Papyrus.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52864", "revid": "44227202", "url": "https://en.wikipedia.org/wiki?curid=52864", "title": "Marination", "text": "Process of soaking foods in a seasoned, often acidic, liquid before cooking\nMarinating is the process of soaking foods in a seasoned, often acidic, liquid before cooking. This sauce, called the marinade, can be either acidic (made with ingredients such as vinegar, lemon juice, or wine), or enzymatic (made with ingredients such as pineapple, papaya, yogurt, or ginger), or have a neutral pH. In addition to these ingredients, a marinade often contains oil, salt, herbs, and spices to further flavor the food items. It is commonly used to flavor foods and to tenderize tougher cuts of meat; the process may last seconds or days.\nMarinating is similar to brining, except that brining relies on the action of salty brine rather than the action of acids or enzymes. Marinating is also similar to pickling, except that pickling is generally done for much longer periods of months or even years, primarily as a means of food preservation. Conversely, marinating is usually performed for a few hours to a day, generally as a means of enhancing the flavor of the food or tenderizing it.\nMarinades vary between different cuisines. The French word derives from the verb \"to pickle in sea brine\", and ultimately from the Latin noun \"sea\", suggesting that marinades may have evolved from an ancient brining tradition or may have initially used sea brine as an ingredient.\nTissue breakdown.\nIn meats, the acid causes the tissue to break down, which allows more moisture to be absorbed and results in a juicier end product; however, too much acid can be detrimental to the end product. A good marinade has a balance of acid, oil, and spice. If raw marinated meat is frozen, the marinade can break down the surface and turn the outer layer mushy.\nOften confused with marinating, macerating is a similar form of food preparation.\nSafety considerations.\nRaw pork, seafood, beef and poultry may contain harmful bacteria which may contaminate the marinade. Marinating should be done in the refrigerator to inhibit bacterial growth. Used marinade should not be made into a sauce unless rendered safe by boiling directly before use; otherwise, fresh or set-aside marinade that has not touched meat should be used. The container used for marinating should be glass or food safe plastic. Metal, including pottery glazes which can contain lead, reacts with the acid in the marinade and should be avoided.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52865", "revid": "1284932427", "url": "https://en.wikipedia.org/wiki?curid=52865", "title": "Brining", "text": "Food processing by treating with brine or salt\nBrining is treating food with brine or coarse salt which preserves and seasons the food while enhancing tenderness. Flavor can be further developed with additions such as herbs, spices, sugar, caramel or vinegar. Meat and fish are typically brined for less than twenty-four hours while vegetables, cheeses and fruit are brined in a much longer process known as pickling. Brining is similar to marination, except that a marinade usually includes a significant amount of acid, such as vinegar or citrus juice. Brining is also similar to curing, which usually involves significantly drying the food, and is done over a much longer time period.\nMeat.\nBrining is a food processing technique in which meat is soaked in a salt water solution \u2013 a brine \u2013 similar to marination before cooking. The brine may be seasoned with spices and herbs. Duration varies from 30 minutes to several days depending on the cut's size, thickness, and desired effect. \nDry brining.\nBrining can also be achieved by covering the meat in dry coarse salt and left to rest for several hours. The salt draws moisture from the interior of the meat to the surface, where it mixes with the salt and is then reabsorbed with the salt essentially brining the meat in its own juices. The salt rub is then rinsed off and discarded before cooking.\nFood scientists have two theories about the brining effect, but which one is correct is still under debate.\nFish.\nAs opposed to dry salting, fish brining or wet-salting is performed by immersion of fish into brine, or just sprinkling it with salt without draining the moisture. To ensure long-term preservation, the solution has to contain at least 20% of salt, a process called \"heavy salting\" in fisheries; heavy-salted fish must be desalted in cold water or milk before consumption. If less salt is used, the fish is suited for immediate consumption, but additional refrigeration is necessary for longer preservation.\nWet-salting is used for preparation of:\nVegetables.\nVegetables are immersed in brine, vinegar or vinaigrette for extended periods of time in the process of pickling, where they undergo anaerobic fermentation which affects their texture and flavor. Pickling can preserve perishable foods for months. Antimicrobial herbs and spices, such as mustard seed, garlic, cinnamon or cloves, are often added. Unlike the canning process, pickling (which includes fermentation) does not require that the food be completely sterile before it is sealed. The acidity or salinity of the solution, the temperature of fermentation, and the exclusion of oxygen determine which microorganisms dominate, and determine the flavor of the end product.\nCheese.\nBrine is used in two ways in cheese production:\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52866", "revid": "50604643", "url": "https://en.wikipedia.org/wiki?curid=52866", "title": "Cooking weights and measures", "text": "Specifications for quantities of ingredients\nIn recipes, quantities of ingredients may be specified by mass (commonly called weight), by volume, or by count.\nFor most of history, most cookbooks did not specify quantities precisely, instead talking of \"a nice leg of spring lamb\", a \"cupful\" of lentils, a piece of butter \"the size of a small apricot\", and \"sufficient\" salt. Informal measurements such as a \"pinch\", a \"drop\", or a \"hint\" (\"soup\u00e7on\") continue to be used from time to time. In the US, Fannie Farmer introduced the more exact specification of quantities by volume in her 1896 \"Boston Cooking-School Cook Book\".\nToday, most of the world prefers metric measurement by weight, though the preference for volume measurements continues among home cooks in the United States and the rest of North America. Different ingredients are measured in different ways:\nLiquid ingredients are generally measured by volume worldwide.\nDry bulk ingredients, such as sugar and flour, are measured by weight in most of the world (\"250 g flour\"), and by volume in North America (\" flour\"). Small quantities of salt and spices are generally measured by volume worldwide, as few households have sufficiently precise balances to measure by weight.\nIn most countries, meat is described by weight or count: \"a 2 kilogram chicken\"; \"four lamb chops\".\nEggs are usually specified by count. Vegetables are usually specified by weight or occasionally by count, despite the inherent imprecision of counts given the variability in the size of vegetables.\nMetric measures.\nIn most of the world, recipes use the metric system of units\u2014litres (L) and millilitres (mL), grams (g) and kilograms (kg), and degrees Celsius (\u00b0C). The official spelling \"litre\" is used in most English-speaking nations. The notable exception is the United States where the spelling \"liter\" is preferred.\nThe United States measures weight in pounds (avoirdupois). Recipes in the UK tend to include both imperial and metric measures, following the advice of the Guild of Food Writers. The United States also uses volume measures based on cooking utensils and pre-metric measures. The actual values frequently deviate from the utensils on which they were based, and there is little consistency from one country to another.\n\u2020 In South Australia, a \"pint\" of beer is traditionally 425\u00a0mL, while most other states have metricated this value to 570\u00a0mL.\n\u2021 In Canada, a cup was historically 8 imperial fluid ounces (227\u00a0mL) but could also refer to 10 imperial fl oz (284\u00a0mL), as in Britain, and even a metric cup of 250\u00a0mL. Serving sizes on nutrition labelling on food packages in Canada employ the metric cup of 250\u00a0mL, with nutrition labelling in the US using a cup of 240\u00a0mL, based on the US customary cup.\n* In Canada, a teaspoon is historically &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20446 imperial fluid ounce (4.74\u00a0mL) and a tablespoon is &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 imperial fl oz (14.21\u00a0mL). In Canada, cooking utensils commonly come in 5\u00a0mL for teaspoons and 15\u00a0mL for tablespoons.\n\u00a7 In the UK, teaspoons and tablespoons are formally and of an imperial pint (3.55\u00a0mL and 14.21\u00a0mL), respectively, with 1tbsp being equal to 2 dessert spoons or 4tsp. Cooking utensils are now commonly manufactured at 15\u00a0mL for tablespoons, and either 1 metric teaspoon (5ml) or a compromise measurement (such as 4ml) for teaspoons. Metric dessertspoons are not commonly used in the UK.\nThe volume measures here are for comparison only. See below for the definition of Gallon for more details.\nThe \"cook's cup\" above is not the same as a \"coffee cup\", which can vary anywhere from , or even smaller for espresso.\nIn Australia, since 1970, metric utensil units have been standardized by law, and imperial measures no longer have legal status. It is wise to measure the actual volume of the utensil measures, particularly the 'Australian tablespoon' (see above), since many are imported from other countries with different values. Dessertspoons are standardized as part of the metric system at 10\u00a0mL, though they are not normally used in contemporary recipes. Australia is the only metricated country with a metric tablespoon of 20\u00a0mL, unlike other countries that metricated, which have a 15\u00a0mL metric tablespoon.\nIn Europe, older recipes frequently refer to \"pounds\" (e.g. in German, in Dutch, in French). In each case, the unit refers to 500\u00a0g, about 10% more than an avoirdupois pound (454\u00a0g). Dutch recipes may also use the , which is 100\u00a0g.\nWeight of liquids.\nWith the advent of accurate electronic scales, it has become more common to weigh liquids for use in recipes, avoiding the need for accurate volumetric utensils. The most common liquids used in cooking are water and milk, milk having approximately the same density as water.\n1 mL of water weighs 1\u00a0gram, so a recipe calling for 300 mL (\u2248 &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 Imperial Pint) of water can simply be substituted with 300 g (\u2248 10 oz.) of water.\n1 fluid ounce of water weighs approximately 1 ounce, so a recipe calling for a UK pint (20 fl oz) of water can be substituted with 20 oz of water.\nMore accurate measurements become important in the large volumes used in commercial food production. Also, a home cook can use greater precision at times. Water at may be volumetrically measured then weighed to determine an unknown measuring-utensil volume without the need for a water-density adjustment.\nUnited States measures.\nThe US uses pounds and ounces (avoirdupois) for weight, and US customary units for volume. For measures used in cookbooks published in other nations navigate to the appropriate regional section in Traditional measurement systems.\nMeasures are classified as either dry measures or fluid measures. Some of the fluid and dry measures have similar names, but the actual measured volume is quite different. A recipe will generally specify which measurement is required. U.S. recipes are commonly in terms of fluid measures, even for dry ingredients. Most of these units derive from earlier English units, as applied to the U.S. gallon. Typically they follow a pattern of binary submultiples, where each larger measure consists of two units of the next-smallest measure. An exception is with the commonly used teaspoon as one-third of a tablespoon.\nBinary submultiples are fractional parts obtained by successively dividing by the number 2. Thus, one-half, one-fourth, one-eighth, one-sixteenth, and so on, are binary submultiples. The system can be traced back to the measuring systems of the Hindus and the ancient Egyptians, who subdivided the (about 4.8 litres) into parts of &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444,&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20448, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204416, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204432, and &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204464 (1 , or mouthful, or about 14.5\u00a0ml), and the similarly down to &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204432 (1 ) using hieratic notation, as early as the Fifth Dynasty of Egypt, 2494 to 2345 BC, thus making the \"English doubling system\" at least 4,300 years old.\nFrom units and tools of convenience, most of the system's history could have values vary widely. It was not until recent centuries that standardization began to take shape. The overlap with other systems\u00a0\u2013 like the apothecaries' system, and giving each &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20442 division a unique\u00a0\u2013 and often variable by context, person, place, and time\u00a0\u2013 name instead of a systematic one, can make the system seem confusing for those not accustomed to it. \nOther than the names themselves, the regular ratios make the actual measurements straightforward. In many cases, names have been deprecated in favor of fractionally denominated amounts of a few core units (such as taking gallons, cups, and teaspoons to their nearest quarters without names: nixing pottle; gill and wineglass; dram (as a culinary unit), coffeespoon, and saltspoon; respectively), or are limited to the specific or esoteric.\nIt is still a legal basis for measures in many states, such as Massachusetts, which mandates that \"Glass bottles or jars used for the sale of milk or cream to the consumer shall be of the capacity of one gallon, a multiple of the gallon, or a binary submultiple of the gallon.\"\nMetric equivalents are based upon one of two nearly equivalent systems. In the standard system the conversion is that 1\u00a0gallon = 231\u00a0cubic inches and 1\u00a0inch = 2.54\u00a0cm, which makes a gallon = 3785.411784\u00a0millilitres exactly. For nutritional labeling on food packages in the US, the teaspoon is defined as exactly 5\u00a0ml, giving 1\u00a0gallon = 3840\u00a0ml exactly. This chart uses the former.\nSuffixed asterisks on some of the \"tsp\" units in the \"Defined\" column above indicate that those teaspoon units are defined as &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20448 fl oz (4 fl dram), the old 4 tsp = 1 tbsp amount, instead of . This definition fits with \"barkeepers' teaspoon\", and is used in many cocktail recipe books. Generally the subdivisions are not so explicitly defined nor named below in general culinary. This can be verified by comparing the associated values in the \"fl oz\" column. All other \"tsp\" units in the \"Defined\" column are indeed defined as , the current 3 tsp = 1 tbsp amount.\n\u2021\u00a0Rare if not nonexistent in use by name rather than as fraction of a different unit.\n\u2020 The fluid scruple has been properly defined on its own in the apothecaries' system as &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u204424 fl oz, &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20443 fluid dram, or = 20 minims (\u2248 1.23223 ml), and also &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444 tsp. Mind that scruples and drams were pharmaceutical and intended to be specific and precise. Cooking measures tended to use what was on hand and/or actually used to consume what was being prepared, and not intended to be as formally scientific in its degree of precision.\nThe saltspoon most likely combined into the scruple over time, as a consequence of home cooks approximating standard measures with what they had at hand, much as the teaspoon was roughly \"close enough\" for a kitchen approximation to a fluid dram (= 60 minims), but not equal to the &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1+1\u20443 fl dr (80 minims) value it actually is. Especially with the variability of the \"method\" of measuring itself. Not of insignificance is the natural habit of customary measures to use a 2n dividing scheme regardless of exact definitions. This pattern is seen even with metric measuring spoons.\nConfusion comes about from teaspoon continuing to be called a \"dram\" in vernacular, despite the sizes of actual spoons creeping up quietly over time, such that &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444 of a tsp (tsp &gt; fl dr) would in fact become congruent with current &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20443 fl dr values for the scruple and saltspoon. In other words, the terminology not keeping pace with the definition. At the small scales involved this is negligible (i.e.: math can convert down to tsp \u00d710\u22129, but to what degree can it practically be meted).\nHowever, it can cause problems when accuracy is required such as medicines: \"In almost all cases the modern teacups, tablespoons, dessertspoons, and teaspoons, after careful test by the author, were found to average 25 percent greater capacity than the theoretical quantities given above, and thus the use of accurately graduated medicine glasses, which may be had now at a trifling cost, should be insisted upon.\"\nIn domestic cooking, bulk solids, notably flour and sugar, are measured by volume, often cups, though they are sold by weight at retail. Weight measures are used for meat. Butter may be measured by either weight (&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444 lb) or volume (3 tbsp) or a combination of weight and volume (&lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444 lb plus 3 tbsp). It is sold by weight but in packages marked to facilitate common divisions by eye. \nAs a sub-packaged unit, a \"stick\" of butter, at &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1\u20444 lb [113 g], is a \"de facto\" measure in the US. Some recipes may specify butter amounts called a \"pat\" (1\u20131.5 tsp) or a \"knob\" (2 tbsp).\nCookbooks in Canada use the same system, although pints and gallons would be taken as their Imperial quantities unless specified otherwise. Following the adoption of the metric system, recipes in Canada are frequently published with metric conversions.\nApproximate units.\nThere are a variety of approximate units of measures, which are frequently undefined by any official source, or which have had conflicting definitions over time, yet which are commonly used. The measurement units that are most commonly understood to be approximate are the drop, smidgen, pinch, and dash, yet nearly all of the traditional cooking measurement units lack statutory definitions, or even any definition by any organization authorized to set standards in the U.S.\nFor example, of the table above, only the fluid ounce, pint, quart, and gallon are officially defined by the NIST. All of the others appear only in conversion guides lacking statutory authority, or in now-obsolete publications of the U.S. Pharmacopeial Convention, or USP\u2014essentially, the Apothecaries' system\u2014which still has authority to define certain drug and supplement standards. The USP has long-since abandoned Apothecaries' measurements, and even now recommends against using teaspoons to measure doses of medicine.\nBritish (Imperial) measures.\nNote that measurements in this section are in imperial units.\nBritish imperial measures distinguish between weight and volume.\nWeight is measured in ounces and pounds (avoirdupois) as in the U.S.\nVolume is measured in imperial gallons, quarts, pints, fluid ounces, fluid drachms, and minims. The imperial gallon was originally defined as of water in 1824, and refined as exactly 4.54609 litres in 1985.\nTraditionally, when describing volumes, recipes commonly give measurements in the following units:\nIf the recipe is one that has been handed down in a family and gives measurements in \u2018cups\u2019, it is just as likely to refer to someone's favourite kitchen cup as to the said unit that is 6 fluid ounces.\nAll six units are the traditional British equivalents of the US customary cup and the metric cup, used in situations where a US cook would use the US customary cup and a cook using metric units the metric cup. The breakfast cup is the most similar in size to the US customary cup and the metric cup. Which of these six units is used depends on the quantity or volume of the ingredient: there is division of labour between these six units, like the tablespoon and the teaspoon. \nBritish cookery books and recipes, especially those from the days before the UK's partial metrication, commonly use two or more of the aforesaid units simultaneously. For example, the same recipe may call for a \u2018tumblerful\u2019 of one ingredient and a \u2018wineglassful\u2019 of another one. Or a \u2018breakfastcupful\u2019 or \u2018cupful\u2019 of one ingredient, a \u2018teacupful\u2019 of a second one, and a \u2018coffeecupful\u2019 of a third one. \nUnlike the US customary cup and the metric cup, a tumbler, a breakfast cup, a cup, a teacup, a coffee cup, and a wine glass are not measuring cups. They are simply everyday drinking vessels commonly found in British households and typically having the respective aforementioned capacities. Due to long-term and widespread use, they have been transformed into measurement units for cooking. There is not a British imperial unit\u2060\u2013\u2060based culinary measuring cup.\nFor smaller amounts, British recipes traditionally give measurements in the following units:\nFor even smaller amounts, the following units are used:\nAmerican cooks using British recipes, and vice versa, need to be careful with pints and fluid ounces.\nA US pint (16 US fluid ounces) is about 16.65 UK fluid ounces or 473 mL. A UK pint is 20 UK fluid ounces (about 19.21 US fluid ounces or 568 mL). A UK pint is about 20% larger than a US pint.\nA US fluid ounce is of a US pint (about 1.04 UK fluid ounces or 29.6 mL). A UK fluid ounce is of a UK pint (about 0.96 US fluid ounce or 28.4 mL).\nOn a larger scale, perhaps for institutional cookery, a UK gallon is 8 UK pints (160 UK fluid ounces; about 1.2 US gallons or 4.546 litres). The US gallon is 8 US pints (128 US fluid ounces; about 0.83 UK gallon or 3.785 litres).\nIn the 20th century, the metric system was officially adopted in the UK, for most purposes. Both imperial and metric are taught in schools and used in books. It is now mandatory for the sale of food to also show metric. However, it is not uncommon to purchase goods which are measured and labeled in metric, but the actual measure is rounded to the equivalent imperial measure (i.e., milk labeled as 568 mL / 1 pint). In September 2007, the EU deregulated prescribed metric packaging of most products, leaving only wines and spirits subject to prescribed EU-wide pre-packaging legislation. The law relating to labelling of products remaining unchanged.\nSpecial instructions.\nVolume measures of compressible ingredients have a substantial measurement uncertainty, in the case of flour of about 20%. Some volume-based recipes, therefore, attempt to improve the reproducibility by including additional instructions for measuring the correct amount of an ingredient. For example, a recipe might call for \"1 cup brown sugar, firmly packed\", or \"2 heaping cups flour\". A few of the more common special measuring methods:\nWith a spatula, a spoon, or by hand, the ingredient is pressed as tightly as possible into the measuring device.\nThe ingredient is pressed lightly into the measuring device, only tightly enough to ensure no air pockets.\nA precise measure of an ingredient, discarding all of the ingredient that rises above the rim of the measuring device. Sweeping across the top of the measure with the back of a straight knife or the blade of a spatula is a common leveling method.\nAllowing a measure of an ingredient to pile up above the rim of the measuring device naturally, into a soft, rounded shape.\nThe maximum amount of an ingredient which will stay on the measuring device.\nThis instruction may be seen in two different ways, with two different meanings: before the ingredient, as \"1 cup sifted flour\", indicates the ingredient should be sifted into the measuring device (and normally leveled), while after the ingredient, as \"1 cup flour, sifted\", denotes the sifting should occur after measurement.\nSuch special instructions are unnecessary in weight-based recipes.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52867", "revid": "26778975", "url": "https://en.wikipedia.org/wiki?curid=52867", "title": "Xylophone", "text": "Wooden keyboard percussion instrument\nThe xylophone (from grc \" ' ()\"\u00a0'wood' and \" ' ()\"\u00a0'sound, voice'; lit.\u2009'sound of wood') is a musical instrument in the percussion family that consists of wooden bars struck by mallets. Each bar is an idiophone tuned to a pitch of a musical scale, whether pentatonic or heptatonic in the case of many African and Asian instruments, diatonic in many western children's instruments, or chromatic for orchestral use.\nThe term \"xylophone\" may be used generally, to include all such instruments such as the marimba, balafon and even the semantron. However, in the orchestra, the term \"xylophone\" refers specifically to a chromatic instrument of somewhat higher pitch range and drier timbre than the marimba, and these two instruments should not be confused. A person who plays the xylophone is known as a \"xylophonist\" or simply a \"xylophone player\".\nThe term is also popularly used to refer to similar instruments of the lithophone and metallophone types. For example, the Pixiphone and many similar toys described by the makers as xylophones have bars of metal rather than of wood, and so are in organology regarded as glockenspiels rather than as xylophones.\nConstruction of xylophones.\nThe modern western xylophone has bars of rosewood, padauk, cocobolo, or various synthetic materials such as fiberglass or fiberglass-reinforced plastic which allows a louder sound. Some can be as small a range as &lt;templatestyles src=\"Fraction/styles.css\" /&gt;2+1\u20442 octaves but concert xylophones are typically &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3+1\u20442 or 4 octaves. Like the glockenspiel, the xylophone is a transposing instrument: its parts are written one octave below the sounding notes.\nConcert xylophones have tube resonators below the bars to enhance the tone and sustain. Frames are made of wood or cheap steel tubing: more expensive xylophones feature height adjustment and more stability in the stand. In other music cultures some versions have gourds that act as Helmholtz resonators. Others are \"trough\" xylophones with a single hollow body that acts as a resonator for all the bars. Old methods consisted of arranging the bars on tied bundles of straw, and, is still practiced today, placing the bars adjacent to each other in a ladder-like layout. Ancient mallets were made of willow wood with spoon-like bowls on the beaten ends.\nMallets.\nXylophones should be played with very hard rubber, polyball, or acrylic mallets. Sometimes medium to hard rubber mallets, very hard core, or yarn mallets are used for softer effects. Lighter tones can be created on xylophones by using wooden-headed mallets made from rosewood, ebony, birch, or other hard woods.\nHistory.\nThe instrument has obscure ancient origins. Nettl proposed that it originated in southeast Asia and came to Africa c. AD 500 when a group of Austronesian speaking peoples migrated to Africa, and compared East African xylophone orchestras and Javanese and Balinese gamelan orchestras. This hypothesis was challenged by ethnomusicologist and linguist Roger Blench, who posits an independent origin of the xylophone in Africa, citing, among the evidence for local invention, distinct features of African xylophones and the greater variety of xylophone types and proto-xylophone-like instruments in Africa.\nAsian xylophone.\nThe earliest evidence of a true xylophone is from the 9th century in southeast Asia, while a similar hanging wood instrument, a type of harmonicon, is said by the Vienna Symphonic Library to have existed in 2000 BC in what is now part of China. The xylophone-like ranat was used in Hindu regions (kashta tharang). In Indonesia, few regions have their own type of xylophones. In North Sumatra, The Toba Batak people use wooden xylophones known as the Garantung (spelled: \"garattung\"). Java and Bali use xylophones (called gambang, Rindik and Tingklik) in gamelan ensembles. They still have traditional significance in Malaysia, Melanesia, Indonesia, Thailand, Myanmar, and regions of the Americas. In Myanmar, the xylophone is known as Pattala and is typically made of bamboo.\nAfrican xylophone.\nThe term \"marimba\" is also applied to various traditional folk instruments such as the West Africa \"balafon\". Early forms were constructed of bars atop a gourd. The wood is first roasted around a fire before shaping the key to achieve the desired tone. The resonator is tuned to the key through careful choice of size of resonator, adjustment of the diameter of the mouth of the resonator using wasp wax and adjustment of the height of the key above the resonator. A skilled maker can produce startling amplification. The mallets used to play \"dibinda\" and \"mbila\" have heads made from natural rubber taken from a wild creeping plant. \"Interlocking\" or alternating rhythm features in Eastern African xylophone music such as that of the Makonde \"dimbila\", the Yao \"mangolongondo\" or the Shirima \"mangwilo\" in which the \"opachera\", the initial caller, is responded to by another player, the \"wakulela\". This usually doubles an already rapid rhythmic pulse that may also co-exist with a counter-rhythm.\nMbila.\nThe mbila (plural \"timbila\") is associated with the Chopi people of the Inhambane Province, in southern Mozambique. It is not to be confused with the mbira. The style of music played on it is believed to be the most sophisticated method of composition yet found among preliterate peoples. The gourd-resonated, equal-ratio heptatonic-tuned mbila of Mozambique is typically played in large ensembles in a choreographed dance, perhaps depicting a historical drama. Ensembles consist of around ten xylophones of three or four sizes. A full orchestra would have two bass instruments called with three or four wooden keys played standing up using heavy mallets with solid rubber heads, three tenor , with ten keys and played seated, and the mbila itself, which has up to nineteen keys of which up to eight may be played simultaneously. The uses gourds and the and Masala apple shells as resonators. They accompany the dance with long compositions called or and consist of about 10 pieces of music grouped into 4 separate movements, with an overture, in different tempos and styles. The ensemble leader serves as poet, composer, conductor and performer, creating a text, improvising a melody partially based on the features of the Chopi tone language and composing a second contrapuntal line. The musicians of the ensemble partially improvise their parts. The composer then consults with the choreographer of the ceremony and adjustments are made. The longest and most important of these is the \"Mzeno\" which will include a song telling of an issue of local importance or even making fun of a prominent figure in the community! Performers include Eduardo Dur\u00e3o and Venancio Mbande.\nGyil.\nThe gyil () is a pentatonic instrument common to the Gur-speaking populations in Ghana, Burkina Faso, Mali and Ivory Coast in West Africa. The Gyil is the primary traditional instrument of the Dagara people of northern Ghana and Burkina Faso, and of the Lobi of Ghana, southern Burkina Faso, and Ivory Coast. The gyil is usually played in pairs, accompanied by a calabash gourd drum called a \"kuor\". It can also be played by one person with the drum and the stick part as accompaniment, or by a soloist. Gyil duets are the traditional music of Dagara funerals. The instrument is generally played by men, who learn to play while young, however, there is no restriction on gender.\nThe Gyil's design is similar to the \"Balaba\" or Balafon used by the Mande-speaking Bambara, Dyula and Sosso peoples further west in southern Mali and western Burkina Faso, a region that shares many musical traditions with those of northern Ivory Coast and Ghana. It is made with 14 wooden keys of an African hardwood called liga attached to a wooden frame, below which hang calabash gourds. Spider web silk covers small holes in the gourds to produce a buzzing sound and antelope sinew and leather are used for the fastenings. The instrument is played with rubber-headed wooden mallets.\nSilimba.\nThe silimba is a xylophone common among the Nkoya and Lozi people of Barotseland, western Zambia. The tuned keys are tied atop resonating gourds. Known as shinjimba among the Nkoya, it is used at the Kazanga, a traditional royal ceremony of the Nkoya. The silimba is an essential part of the folk music traditions of the Lozi people and can be heard at their annual Kuomboka ceremony. The shilimba is now used in most parts of Zambia.\nAkadinda, amadinda and mbaire.\nThe akadinda and the amadinda are xylophone-like instruments originating in Buganda, in modern-day Uganda. The amadinda is made of twelve logs which are tuned in a pentatonic scale. It mainly is played by three players. Two players sit opposite of each other and play the same logs in an interlocking technique in a fast tempo. It has no gourd resonators or buzzing tone, two characteristics of many other African xylophones.\nThe amadinda was an important instrument at the royal court in Buganda, a Ugandan kingdom. A special type of notation is now used for this xylophone, consisting of numbers for and periods. as is also the case with the embaire, a type of xylophone originating in southern Uganda.\nBalo.\nThe balo (balenjeh, behlanjeh) is used among the Mandinka people of West Africa. Its keys are mounted on gourds, and struck with mallets with rubber tips. The players typically wear iron cylinders and rings attached to their hands so that they jingle as they play.\nWestern xylophone.\nThe earliest mention of a xylophone in Europe was in Arnolt Schlick's \"Spiegel der Orgelmacher und Organisten\" (1511), where it is called \"h\u00fcltze glechter\" (\"wooden clatter\"). There follow other descriptions of the instrument, though the term \"xylophone\" is not used until the 1860s. The instrument was associated largely with the folk music of Central Europe, notably Poland and eastern Germany. An early version appeared in Slovakia and the earliest reference to a similar instrument came in the 14th century.\nThe first use of a European orchestral xylophone was in Camille Saint-Sa\u00ebns' \"Danse Macabre\", in 1874. By that time, the instrument had already been popularized to some extent by Michael Josef Gusikov, whose instrument was the five-row xylophone made of 28 crude wooden bars arranged in semitones in the form of a trapezoid and resting on straw supports. There were no resonators and it was played fast with spoon-shaped sticks. According to musicologist Curt Sachs, Gusikov performed in garden concerts, variety shows, and as a novelty act at symphony concerts.\nThe western xylophone was used by early jazz bands and in vaudeville. Its bright, lively sound worked well the syncopated dance music of the 1920s and 1930s. Red Norvo, George Cary, George Hamilton Green, Teddy Brown, Harry Breuer and Harry Robbins were among the well-known players. As time passed, the xylophone was exceeded in popularity by the metal-key vibraphone, which was developed in the 1920s. A xylophone with a range extending downwards into the marimba range is called a xylorimba.\nIn orchestral scores, a xylophone can be indicated by the French \"claquebois\", German \"Holzharmonika\" (literally \"wooden harmonica\"), or Italian \"silofono\". Shostakovich was particularly fond of the instrument; it has prominent roles in much of his work, including most of his symphonies and his Cello Concerto No. 2. Modern xylophone players include Bob Becker, Evelyn Glennie and Ian Finkel.\nIn the United States, there are Zimbabwean marimba bands in particularly high concentration in the Pacific Northwest, Colorado, and New Mexico, but bands exist from the East Coast through California and even to Hawaii and Alaska. The main event for this community is ZimFest, the annual Zimbabwean Music Festival. The bands are composed of instruments from high sopranos, through to lower soprano, tenor, baritone, and bass. Resonators are usually made with holes covered by thin cellophane (similar to the balafon) to achieve the characteristic buzzing sound. The repertoires of U.S. bands tends to have a great overlap, due to the common source of the Zimbabwean musician Dumisani Maraire, who was the key person who first brought Zimbabwean music to the West, coming to the University of Washington in 1968.\nUse in elementary education.\nMany music educators use xylophones as a classroom resource to assist children's musical development. One method noted for its use of xylophones is Orff-Schulwerk, which combines the use of instruments, movement, singing and speech to develop children's musical abilities. Xylophones used in American general music classrooms are smaller, at about &lt;templatestyles src=\"Fraction/styles.css\" /&gt;1+1\u20442 octaves, than the &lt;templatestyles src=\"Fraction/styles.css\" /&gt;2+1\u20442 or more octave range of performance xylophones. The bass xylophone ranges are written from middle C to A an octave higher but sound one octave lower than written. The alto ranges are written from middle C to A an octave higher and sound as written. The soprano ranges are written from middle C to A an octave higher but sound one octave higher than written.\nAccording to Andrew Tracey, marimbas were introduced to Zimbabwe in 1960. Zimbabwean marimba based upon Shona music has also become popular in the West, which adopted the original use of these instruments to play transcriptions of mbira dzavadzimu (as well as \"nyunga nyunga\" and \"matepe\") music. The first of these transcriptions had originally been used for music education in Zimbabwe. Zimbabwean instruments are often in a diatonic C major scale, which allows them to be played with a 'western-tuned' mbira (G nyamaropa), sometimes with an added F\u266f key placed inline.\nCitations.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52869", "revid": "50598983", "url": "https://en.wikipedia.org/wiki?curid=52869", "title": "Braising", "text": "Combination-cooking method using wet and dry heat\nBraising (from the French word ) is a combination-cooking method that uses both wet and dry heats: typically, the food is first browned at a high temperature, then simmered in a covered pot in cooking liquid (such as wine, broth, coconut milk, or beer). It is similar to stewing, but braising is done with less liquid and usually used for larger cuts of meat. Braising of meat is often referred to as pot roasting, though some authors make a distinction between the two methods, based on whether additional liquid is added. Osso buco and coq au vin are well known braised meat dishes, and the technique can also be used to prepare fish, tempeh, tofu, or fruits and vegetables.\nTechniques.\nMost braises follow the same basic steps. The food to be braised (meats, vegetables, mushrooms, etc.) is first pan-seared to brown its surface and enhance its flavor (through the Maillard reaction). If the food will not produce enough liquid of its own, a certain amount of cooking liquid that often includes an acidic element (e.g., tomatoes, beer, balsamic vinegar, wine) is added to the pot, often with stock. A classic braise is done with a relatively whole cut of meat, and the braising liquid will cover two-thirds of the food in the pan. The dish is then covered and cooked with a lid or cartouche at a very low simmer until the meat becomes so tender that it can be \"cut\" with just the gentlest of pressure from a fork (versus a knife). Often the cooking liquid is finished to create a sauce or gravy as well.\nSometimes foods with high water content (particularly vegetables) can be cooked in their own juices, making the addition of liquid unnecessary.\nDespite a common misconception that braising adds moisture to meat, the opposite is true, and the appearance of moisture comes from gentle cooking breaking down connective tissue and collagen, which lubricates and tenderizes fibers.\nBraised foods.\nBraising is used extensively in the cuisines of Asia, particularly Chinese cuisine and Vietnamese cuisine, where soy sauce (or, in Vietnam, soy sauce and fish sauce) is often added to the braising liquid.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52870", "revid": "36767729", "url": "https://en.wikipedia.org/wiki?curid=52870", "title": "Broiling", "text": ""}
{"id": "52871", "revid": "39138398", "url": "https://en.wikipedia.org/wiki?curid=52871", "title": "Marimba", "text": "Wooden keyboard percussion instrument\nThe marimba ( ) is a musical instrument in the percussion family that consists of wooden bars that are struck by mallets. Below each bar is a resonator pipe that amplifies particular harmonics of its sound. Compared to the xylophone, the marimba has a lower range. Typically, the bars of a marimba are arranged chromatically, like the keys of a piano. The marimba is a type of idiophone.\nToday, the marimba is used as a solo instrument, or in ensembles like orchestras, marching bands (typically as a part of the front ensemble), percussion ensembles, brass and concert bands, and other traditional ensembles.\nEtymology and terminology.\nThe term \"marimba\" refers to both the traditional version of this instrument and its modern form. Its first documented use in the English language dates back to 1704. The term is of Bantu origin, deriving from the prefix meaning 'many' and meaning 'xylophone'. The term is akin to Kikongo and Swahili or .\nHistory.\nAncient.\nInstruments like the marimba are present throughout the entirety of sub-Saharan Africa. The instrument itself is most similar and shares its name with the marimbas of modern-day Angola and the Democratic Republic of the Congo. However, it is also similar to instruments that exist in West Africa such as the balafon of the Mandinka people, known as gyil among the Gur peoples in and around northern Ghana and Burkina Faso.\nMexico.\nThe first known marimba dates back to 1545 in the Santa Luc\u00eda hacienda, in the municipality of Jiquipilas, Chiapas. According to documentation dated October 9, 1545, the encomendero Don Pedro Gentil de Bustamante and owner of the hacienda of Santa Lucia, describes in his chronicle a marimba in a celebration of Indians; and tells us the following:.\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nIt is believed that xylophones came to America by means of Africans who had been taken to Guatemala and Mexico, although there are also records in some Mayan pyramids found in Chiapas and Guatemala. The first documented mention of the marimba in Guatemala (marimba de tecomates), dates from November 13, 1680 during the inauguration celebrations of the Santa Iglesia Catedral in Santiago de los Caballeros de Guatemala.\nThe modern double keyboard marimba was created in 1892, in Chiapas, Mexico, thanks to the innovation of Coraz\u00f3n de Jes\u00fas Borras Moreno, a native of the Municipality of Venustiano Carranza, Chiapas, Mexico. In 1897, the current model of marimba was played for the first time in the traditional park of the church of Se\u00f1or del Pozo, in the same municipality, from that moment it has gone from being a native instrument to a concert instrument. A five-octave instrument was first built, and later an 11-octave, huge instrument was built, which was played by 9 elements.\nIn Central America there are two versions of its origin. Some claim that it was brought by black slaves from Africa, while others consider it native, created by the Maya-quiche.\nHistorian David Vela says: \"We also refer to the thesis of Dr. Casta\u00f1eda Paganini on the possible invention of the marimba in Guatemala, by Africans brought as slaves in the sixteenth century; it is surprising however that the marimba appears here early among communities closed to their influence, among remote mountains, and is missing in the areas actually inhabited by the colored race.\" what is undoubted is that the ingenuity of the local countries transformed the instrument to the point of making it their own.\nSince there are records in Guatemala that in the middle of the 18th century, in the same city of Santiago de Guatemala (today Antigua Guatemala), the presbyter Joseph de Padilla developed a new version of the instrument (simple marimba), to which he extended the extension of the keyboard to 42 keys (first and only collective instrument in the world), he added a structure with 4 legs raising it from the ground, being able to play standing up.\nIn 1894 in Quetzaltenango, the master Sebasti\u00e1n Hurtado developed the first chromatic marimba or double keyboard marimba made of Hormigo wood (Plathymiscium dimorphandrum) giving it up to 6 musical scales. He inherited the marimba to his sons and they created the group Marimba Royal of the Hurtado brothers who in 1908 performed a concert in the city of Buffalo, New York, and thus introduced the marimba (with the contributions of Guatemala) in the United States, making it known to the world.\nBeing an instrument used in many countries of the Americas, on February 12, 2015, the Organization of American States (OAS) declares the marimba \"Cultural Heritage of the Americas\".\nCentral America.\nThe marimba is popular throughout Central America, with its popularity spreading from southern Mexico to Costa Rica. The first historical account in Central America is from 1550 where enslaved Africans in Guatemala are reported playing it. By 1680 accounts of Maya musicians using marimbas with gourd resonator were made in Guatemala. It became more widespread during the 18th and 19th centuries, as Maya and Ladino ensembles started using it on festivals. In 1821, the marimba was proclaimed the national instrument of Guatemala in its independence proclamation.\nSouth America.\nMarimba's second range of popularity in Latin America is in the Pacific coast of Colombia and Ecuador. The instruments were brought there via the African diaspora and their cultural significance has survived to the present day. The Afro-Latino communities that take part in preserving and playing it value its importance as a touchstone of their resilience.\nIn Colombia the most widespread marimba is the \"marimba de chonta\" (peach-palm marimba). Marimba music has been listed on UNESCO as an intangible part of Colombian culture. In recent times \"marimberos\" (marimba players) and the marimba genres as a whole have started to fade out in popularity. Nonetheless, the genre is still popular in the departments of Choc\u00f3 and Cauca.\nIn Ecuador the most widespread marimba is the \"marimba esmeralde\u00f1a\" (Esmeralda marimba). Marimbas are an important aspect of Afro-Ecuadorian culture: many religious ceremonies and songs are accompanied with marimba music along with festivals and dances. It is most popular in the province of Esmeraldas where in the 16th century Alonso de Illescas, a maroon, found a maroon settlement near the area around modern day Esmeraldas. In that province, it evokes a sense of pride for the community in which years centuries marimba music has been prohibited after government encroachment upon the Esmeraldas province.\nModern.\nMarimbas have become widely popular around the world since it was being used throughout Africa, Southeast Asia, Europe, North America, South America and Central America.\nIn 1850, Mexican marimbist Manuel Bol\u00e1n Cruz (1810\u20131863), modified the old bow marimba, by the wooden straight one, lengthening the legs so that the musicians could play in a standing mode, expanded the keyboard and replaced the gourd resonators by wooden boxes.\nIn 1892, Mexican musician Coraz\u00f3n de Jes\u00fas Borras Moreno expanded the range of the marimba to include the chromatic scale by adding another row of sound bars, akin to black keys on the piano.\nThe name \"marimba\" was later applied to the orchestra instrument inspired by the Latin American model. In the United States, companies like J.C. Deagan and the Leedy Manufacturing Company adapted the Latin American instruments for use in Western music. Metal tubes were used as resonators, fine-tuned by rotating metal discs at the bottom; lowest note tubes were U-shaped. The marimbas were first used for light music and dance, such as vaudeville theater and comedy shows. Clair Omar Musser was a chief proponent of marimba in the United States at the time.\nIn 1940, the American composer Paul Creston wrote the first composition for solo marimba (\"Concertino for Marimba and Orchestra\"). French composer Darius Milhaud also helped introduce marimbas into Western classical music with his 1947 \"Concerto for Marimba and Vibraphone\". Four-mallet grip was employed to play chords, enhancing interest for the instrument. In the late 20th century, modernist and contemporary composers found new ways to use marimba: notable examples include Leo\u0161 Jan\u00e1\u010dek (\"Jenufa\"), Carl Orff (\"Antigonae\"), Karl Amadeus Hartmann, Hans Werner Henze (\"Elegy for Young Lovers\"), Pierre Boulez (\"Le marteau sans ma\u00eetre\") and Steve Reich.\nConstruction.\nBars.\nMarimba bars may be made either of wood or a synthetic fiberglass material. For the best sound quality, rosewood is the most desirable, while padauk is a popular affordable alternative. Synthetic fiberglass bars are often sold under trade names such as Kelon (for Ludwig-Musser), Klyperon (for J.C. Deagan), or Acoustalon (for Yamaha), among others. Bars made from synthetic materials generally fall short in sound quality and generally have a longer decay in comparison to wooden bars, but they are often less expensive and yield added durability and weather resistance, making them suitable for outdoor use. For wooden bars, changes in humidity or temperature may alter the moisture levels within the wood. This may negatively affect the pitch and tonality of the bar.\nBubinga (\"Guibourtia demeusei\") and mahogany have also been cited as comparable to rosewood in quality for use as marimba bars. The specific rosewood, \"Dalbergia stevensonii\", only grows in Southern Guatemala and Belize, formerly British Honduras. This wood has a Janka rating of 2200, which is about three times harder than silver maple. The bars are wider and longer at the lowest-pitched notes, and gradually get narrower and shorter as the notes get higher. During the tuning, wood is taken from the middle underside of the bar to lower the pitch. Because of this, the bars are also thinner in the lowest pitch register and thicker in the highest pitch register. While most American marimbas are tuned to the standard A4=440\u00a0Hz, many commercial marimbas are tuned to A4=442\u00a0Hz for a brighter sound for better blend with an orchestra.\nMarimba bars produce their fullest sound when struck just off center, while striking the bar in the center produces a more articulate tone. On chromatic marimbas, the accidentals can also be played on the extreme front edge of the bar, away from the node (the place where the string goes through the bar) if necessary. Playing on the node produces a sonically weak tone, and the technique is only used when the player or composer is looking for a muted sound from the instrument.\nRange.\nThere is no standard range of the marimba, but the most common ranges are 4.3 octaves, 4.5 octaves and 5 octaves; 4, 4.6 and 5.5 octave sizes are also available.\nThe range of the marimba has been gradually expanding, with companies like Marimba One adding notes up to F above the normal high C (C7) on their 5.5 octave instrument and marimba tuners adding notes lower than the low C on the 5 octave C2. Adding lower notes is somewhat impractical; as the bars become bigger and the resonators become longer, the instrument must be taller and the mallets must be softer in order to produce a tone rather than just a percussive attack. Adding higher notes is also impractical because the hardness of the mallets required to produce the characteristic tone of a marimba are much too hard to play with in almost any other, lower range on the instrument.\nThe marimba is a non-transposing instrument with no octave displacement, unlike the xylophone, which sounds one octave higher than written, and the glockenspiel, which sounds two octaves higher than written.\nResonators.\nPart of the key to the marimba's rich sound are its resonators. These are tubes (usually aluminum) that hang below each bar.\nIn the most traditional versions, various sizes of natural gourds are attached below the keys to act as resonators; in more sophisticated versions carved wooden resonators are substituted, allowing for more precise tuning of pitch. In Central America and Mexico, a hole is often carved into the bottom of each resonator and then covered with a delicate membrane taken from the intestine of a pig to add a characteristic \"buzzing\" or \"rattling\" sound known as \"charleo\". In more contemporary-style marimbas, wood is replaced by PVC tubing. The holes in the bottoms of the tubes are covered with a thin layer of paper to produce the buzzing noise.\nThe length of the resonators varies according to the frequency that the bar produces. Vibrations from the bars resonate as they pass through the tubes, which amplify the tone in a manner very similar to the way in which the body of a guitar or cello would. In instruments exceeding &lt;templatestyles src=\"Fraction/styles.css\" /&gt;4+1\u20442 octaves, the length of tubing required for the bass notes exceeds the height of the instrument. Some manufacturers, such as DeMorrow and Malletech, compensate for this by bending the ends of the tubes. This involves soldering smaller straight sections of tubes to form \"curved\" tubes. Both DeMorrow and Malletech use brass rather than aluminium. Others, such as Adams and Yamaha, expand the tubes into large box-shaped bottoms, resulting in the necessary amount of resonating space without having to extend the tubes. This result is achieved by the custom manufacturer Marimba One by widening the resonators into an oval shape, with the lowest ones reaching nearly a foot in width, and doubling the tube up inside the lowest resonators\u2014a process known as \"Haskelling\", originally used in pipe organ resonators, and named for its inventor, William E. Haskell.\nResonator tuning involves adjusting \"stops\" in the tubes themselves to compensate for temperature and humidity conditions in the room where the instrument is stored. Some companies offer adjustment in the upper octaves only. Others do not have any adjustable stops. Still some companies (Malletech and DeMorrow) offer full-range adjustable stops.\nOn many marimbas, decorative resonators are added to fill the gaps in the accidental resonator bank. In addition to this, the resonator lengths are sometimes altered to form a decorative arch, such as in the Musser M-250. This does not affect the resonant properties, because the end plugs in the resonators are still placed at their respective lengths.\nMallets.\nThe mallet shaft is commonly made of wood, usually birch or rattan, but may also be made of fiberglass or carbon fibre. The most common diameter of the shaft is around . Shafts made of rattan have a certain elasticity to them, while birch has almost no give. Professionals use both depending on their preferences, whether they are playing with two mallets or more, and which grip they use if they are using a four-mallet grip.\nAppropriate mallets for the instrument depend on the range. The material at the end of the shaft is almost always a type of rubber, usually wrapped with yarn. Softer mallets are used at the lowest notes, and harder mallets are used at the highest notes. Mallets that are too hard will damage the instrument, and mallets that might be appropriate for the upper range could damage the notes in the lower range (especially on a padouk or rosewood instrument). On the lower notes, the bars are larger, and require a softer mallet to bring out a strong fundamental. Because of the need to use varying hardnesses of mallets, some players, when playing with four or more mallets, might use graduated mallets to match the bars that they are playing (softer on the left, harder on the right).\nSome mallets, called \"two-toned\" or \"multi-tonal\", have a hard core, loosely wrapped with yarn. These are designed to sound articulate when playing at a loud dynamic, and broader at the quieter dynamics.\nMallet technique.\nModern marimba music calls for simultaneous use of between two and four mallets (sometimes up to six or eight), granting the performer the ability to play chords or music with large interval skips more easily. Multiple mallets are held in the same hand using any of a number of techniques or \"grips\". For four mallets (two mallets in each hand), the most common grips are the Burton grip (made popular by Gary Burton), the traditional grip (or \"cross grip\") and the Musser-Stevens grip (made popular by Leigh Howard Stevens). Each grip is perceived to have its own benefits and drawbacks. For example, some marimbists feel the Musser-Stevens grip is more suitable for quick interval changes and mallet independence, while the Burton grip is more suitable for stronger playing or switching between chords and single-note melody lines. The traditional grip gives a greater dynamic range and freedom of playing. The choice of grip varies by region (the Musser-Stevens grip and the Burton grip are more popular in the United States, while the traditional grip is more popular in Japan), by instrument (the Burton grip is less likely to be used on marimba than on a vibraphone) and by the preference of the individual performer.\nSix-mallet grips consist of variations on these three grips. Six-mallet marimba grips have been used for years by Mexican and Central American marimbists, but they are generally considered non-standard in the Western classical canon. Keiko Abe has written a number of compositions for six mallets, including a section in her concerto \"Prism Rhapsody\". Other marimbists/composers using this technique include Rebecca Kite (who commissioned composer Evan Hause to write \"Circe\", a major work for six mallets, in 2001), Dean Gronemeier, Robert Paterson, and Kai Stensgaard. Paterson's grip is based on the Burton grip, and his grip and technique have been called the Paterson grip, and even the Wolverine grip. Paterson states that his technique differs from others in that there is less emphasis places on block chords on the lower bank of notes (the naturals or white notes) and more emphasis on independence, one-handed rolls, and alternations between mallets 12-3 or 1\u201323 in the left hand (or 45-6 or 4\u201356 in the right hand, respectively), and so on. Ludwig Albert published at first a work for eight mallets and demonstrated the Ludwig Albert eight-mallet grip based on the traditional grip from 1995.\nRepertoire.\nOrchestra.\nThe marimba is less used by composers than other keyboards from orchestral percussion section, although its interest increased after 1950 such as in Le marteau sans ma\u00eetre by Pierre Boulez.\nConcertos.\nThe first solo marimba concerto, Concertino for Marimba, was composed by Paul Creston in 1940, after a commission by Fr\u00e9d\u00e9rique Petrides. The Concertino for Marimba premiered on 29 April 1940 in Carnegie Hall with marimba soloist Ruth Stuber Jeanne and the Orchestrette Classique. The second concerto for the marimba, Concerto for Marimba, Vibraphone and Orchestra, was written by Darius Milhaud in 1947.\nThe Oregon Symphony Orchestra commissioned Tom\u00e1\u0161 Svoboda to compose Concerto for Marimba and Orchestra, Op. 148, in 1995. A recording of the piece by the orchestra and Niel DePonte was nominated for the 2004 Grammy Award for Best Instrumental Soloist(s) Performance (with orchestra).\nOther prominent concertos include Concerto No. 1 for Marimba and String Orchestra written in 1986 by Ney Rosauro and Concerto for Marimba and String Orchestra written in 2006 by Emmanuel S\u00e9journ\u00e9.\nSolos.\nThe marimba is the most popular solo keyboard percussion instrument in classical music. Popular marimba solos range from beginner solos such as \"Yellow After the Rain\" and \"Sea Refractions\" by Mitchell Peters to more advanced works such as \"Variations on Lost Love\" by David Maslanka, \"Rhythmic Caprice\" by Leigh Howard Stevens and \"Khan Variations\" by Alejandro Vi\u00f1ao.\nPopular music.\nTraditional marimba bands are especially popular in Guatemala, where they are the national symbol of culture, but are also strongly established in the Mexican states of Chiapas, Tabasco, and Oaxaca. They are also very popular in other Central American nations such as Honduras, El Salvador, Nicaragua, and Costa Rica, as well as among Afro-Ecuadorians and Afro-Colombians.\nThere have been numerous jazz vibraphonists who also played the marimba. Notable among them are Gary Burton, David Friedman, Stefon Harris, Bobby Hutcherson, Joe Locke, Steve Nelson, Red Norvo, Dave Pike, Gloria Parker, Dave Samuels, and Arthur Lipner.\nMarimbist and vibraphonist Julius Wechter was the leader of a popular 1960s Latin-flavored band called Baja Marimba Band. Herb Alpert and his Tijuana Brass made frequent use of the marimba.\nRuth Underwood played an electrically amplified marimba in Frank Zappa's The Mothers of Invention.\nThe Rolling Stones' 1966 song \"Under My Thumb\" prominently features a marimba, played by Brian Jones.\nA marimba solo was in the hit 1975 Starbuck song \"Moonlight Feels Right\".\nThe 1982 Toto hit \"Africa\" prominently features the marimba, played by Joe Porcaro.\nThe version of the song \"Tonight\" by David Bowie and Iggy Pop featured on Bowie's 1984 album of the same title includes a marimba.\nPeter Gabriel's 1985 soundtrack album \"Birdy\" includes the song \"Slow Marimbas.\"\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52872", "revid": "27015025", "url": "https://en.wikipedia.org/wiki?curid=52872", "title": "Vibraphone", "text": "Mallet percussion instrument\nThe vibraphone (also called the vibraharp) is a percussion instrument in the metallophone family. It consists of tuned metal bars and is typically played by using mallets to strike the bars. A person who plays the vibraphone is called a \"vibraphonist,\" \"vibraharpist,\" or \"vibist\".\nThe vibraphone resembles the steel marimba, which it superseded. One of the main differences between the vibraphone and other keyboard percussion instruments is that each bar suspends over a resonator tube containing a flat metal disc. These discs are attached together by a common axle and spin when the motor is turned on. This causes the instrument to produce its namesake tremolo or vibrato effect. The vibraphone also has a sustain pedal similar to a piano. When the pedal is up, the bars produce a muted sound; when the pedal is down, the bars sustain for several seconds or until again muted with the pedal.\nThe vibraphone is commonly used in jazz music, in which it often plays a featured role, and was a defining element of the sound of mid-20th-century \"Tiki lounge\" exotica, as popularized by Arthur Lyman. It is the second most popular solo keyboard percussion instrument in classical music, after the marimba, and is part of the standard college-level percussion performance education. It is a standard instrument in the modern percussion section for orchestras, concert bands, and in the marching arts (typically as part of the front ensemble).\nHistory.\nInvention.\nAround 1916, instrument maker Herman Winterhoff of the Leedy Manufacturing Company began experimenting with \"vox humana\" effects on a three-octave (F3 to F6) steel marimba. His original design attempted to produce this effect by raising and lowering the resonators, which caused a noticeable vibrato. In 1921, Winterhoff perfected the design by instead attaching a motor that rotated small discs underneath the bars to achieve the same effect. After sales manager George H. Way termed this instrument the \"vibraphone\", it was marketed by Leedy starting in 1924. The Leedy vibraphone managed to achieve a decent degree of popularity after it was used in the novelty recordings of \"Aloha \u02bbOe\" and \"Gypsy Love Song\" in 1924 by vaudeville performer Louis Frank Chiha.\nHowever, this instrument differed significantly from the instrument now called the \"vibraphone\". The Leedy vibraphone did not have a pedal mechanism, and it had bars made of steel rather than aluminum. The growing popularity of Leedy's instrument led competitor J. C. Deagan, Inc., the inventor of the original steel marimba on which Leedy's design was based, to ask its chief tuner, Henry Schluter, to develop a similar instrument in 1927. Instead of just copying the Leedy design, Schluter introduced several significant improvements. He made the bars from aluminum instead of steel for a mellower tone, adjusted the dimensions and tuning of the bars to eliminate the dissonant harmonics present in the Leedy design, and introduced a foot-controlled damper bar. Schluter's design became more popular than the Leedy design and has become the template for all instruments now called a \"vibraphone\".\nBoth the terms \"vibraphone\" and \"vibraharp\" were trademarked by Leedy and Deagan, respectively. Other manufacturers were forced to use the generic name \"vibes\" or devise new trade names such as \"vibraceleste\" for their instruments incorporating the newer design.\nUse.\nWhile the initial purpose of the vibraphone was as a novelty instrument for vaudeville orchestras, that use was quickly overwhelmed in the 1930s by its development in jazz music. The use of the vibraphone in jazz was popularized by Lionel Hampton, a jazz drummer from California. At one recording session with bandleader Louis Armstrong, Hampton was asked to play a vibraphone that had been left behind in the studio. This resulted in the recording of the song \"Memories of You\" in 1930, containing what is often considered to be the first instance of an improvised vibraphone solo.\nIn its early history, the vibraphone was often used in classical music to give compositions a jazz influence. The first known composer to use the vibraphone was Havergal Brian in his 1917 opera, \"The Tigers\", which called for two of them. However, since the piece was lost and did not premiere until 1983, Ferde Grof\u00e9's \"Grand Canyon Suite\", completed in 1931, is sometimes considered to be the first piece to use a vibraphone instead. Other early classical composers to use the vibraphone were Alban Berg, who used it prominently in his opera \"Lulu\" in 1935, and William Grant Still, who used it in his \"Afro-American Symphony\" that same year. While the vibraphone has not been used quite as extensively in the realm of classical music as it has with jazz, it can often be heard in theatre or film music, such as in Leonard Bernstein's \"West Side Story\".\nCharacteristics.\nRange.\nThe standard modern instrument has a range of 3 octaves, starting from the F below middle C (F3 to F6 in scientific pitch notation). Larger &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3+1\u20442 or 4 octave models from the C below middle C are also becoming more common (C3 to F6 or C7). Unlike its cousin, the glockenspiel, the vibraphone is generally a non-transposing instrument, written at concert pitch.\nMallets.\nVibraphone mallets usually consist of a rubber ball core wrapped in yarn or cord and attached to a narrow dowel, most commonly made of rattan or birch and sometimes of fiberglass or nylon. Mallets suitable for the vibraphone are also generally suitable for the marimba.\nThe mallets can have a great effect on the timbre, ranging from a bright metallic clang to a mellow ring with no obvious initial attack. Consequently, a wide array of mallets is available, offering variations in hardness, head size, weight, shaft length and flexibility.\nClassical players must carry a wide range of mallet types to accommodate the changing demands of composers who are looking for particular sounds. Jazz players, on the other hand, often make use of multi-purpose mallets to allow for improvisation.\nConstruction.\nBars.\nVibraphone bars are made from aluminum bar stock, cut into blanks of predetermined length. Holes are drilled through the width of the bars, so they can be suspended by a cord (typically paracord). To maximize the sustain of the bars, the holes are placed at approximately the nodal points of the bar (i.e., the points of minimum amplitude around which the bar vibrates). For a uniform bar, the nodal points are located 22.4% from each end of the bar.\nMaterial is ground away from the underside of the bars in an arch shape to lower the pitch. This allows the lower-pitched bars to be a manageable length. It is also the key to the mellow sound of the vibraphone (and marimba, which uses the same deep arch) compared with the brighter xylophone, which uses a shallower arch, and the glockenspiel, which has no arch at all. These rectangular bars have three primary modes of vibration. The deep arch causes these modes to align and create a consonant arrangement of intervals: a fundamental pitch, a pitch two octaves above that, and a third pitch an octave and a major third above the second. For the F3 bar that usually forms the lowest note on a vibraphone, there would be F3 as the fundamental, F5 as the first overtone, and A6 as the second overtone. As a side effect, the arch causes the nodal points of the fundamental vibration to shift closer towards the ends of the bar.\nAfter beveling or rounding the edges, fine-tuning adjustments are made. If a bar is flat, its overall pitch structure can be raised by removing material from the ends of the bar. Once this slightly sharp bar is created, the secondary and tertiary tones can be lowered by removing material from specific locations of the bar. Vibraphones are tuned to a standard of A\u00a0=\u00a0442\u00a0Hz or A\u00a0=\u00a0440\u00a0Hz, depending on the manufacturer or the customer's preference. While concert pitch is generally A\u00a0=\u00a0440\u00a0Hz, the sharper tuning of A\u00a0=\u00a0442\u00a0Hz is used to give the vibraphone a slightly brighter sound to cut through the ensemble.\nLike marimbas, professional vibraphones have bars of graduated width. Lower bars are made from wider stock, and higher notes from narrower stock, to help balance volume and tone across the range of the instrument. The bars are anodized after fine-tuning (typically in a silver or gold color) and may have a glossy or matte finish. These are cosmetic features with a negligible effect on the sound.\nThe bed for the bars is made by laying down four wooden rails onto each end of the frame. Each rail has a series of pins with rubber spacers. As the cord passes through the holes of the bar, they rest on the pins to suspend the bars. On each outer side, the ends of the cord attach together with a spring to provide tension and flex.\nResonators.\nResonators are thin-walled tubes, typically made of aluminum, but any suitably strong material can be used. They are open at one end and closed at the other. Each bar is paired with a resonator whose diameter is slightly wider than the width of the bar and whose length to the closure is one-quarter of the wavelength of the fundamental frequency of the bar. When the bar and resonator are properly in tune with each other, the vibrating air beneath the bar travels down the resonator and is reflected from the closure at the bottom, then returns to the top and is reflected back by the bar, over and over, creating a much stronger standing wave and increasing the amplitude of the fundamental frequency. The resonators, besides raising the upper end of the vibraphone's dynamic range, also affect the overall tone of the vibraphone, since they amplify the fundamental frequency, but not the upper partials.\nThere is a trade-off between the amplifying effect of the resonators and the length of sustain of a ringing bar. The energy in a ringing bar comes from the initial mallet strike, and that energy can either be used to make the bar ring louder initially, or not as loudly but for a longer period of time. This is not an issue with marimbas and xylophones, where the natural sustain time of the wooden bars is short, but vibraphone bars can ring for many seconds after being struck, and this effect is highly desirable in many circumstances. Therefore, the resonators in a vibraphone are usually tuned slightly off-pitch to create a balance between loudness and sustain.\nA unique feature of vibraphone resonators is the shaft of rotating discs, commonly called fans, across the top. When the fans are open, the resonators have full function. When the fans are closed, the resonators are partially occluded, reducing the resonance of the fundamental pitch. A drive belt connects the shafts to an electric motor beneath the playing surface and rotates the fans. This rotation of the fans creates a tremolo effect and a slight vibrato.\nOftentimes, vibraphones, and other mallet instruments, will include non-functional, decorative resonator tubes with no corresponding bar above to make the instrument look more complete.\nIn 1970, Deagan introduced the ElectraVibe, which dispensed with resonator tubes entirely and took a signal directly from the bars, adding a tremolo in a preamplifier. This sought to improve the portability of the instrument and solve the problem inherent in all tuned mallet instruments: miking the bars evenly.\nDamper mechanism.\nFor the first few years of production, the original Leedy vibraphone did not include a mechanism for damping, or stopping, the sustaining tones. In 1927, the J.C. Deagan company introduced a pedal mechanism that has not changed substantially since. A rigid bar beneath the center of the instrument is pressed upward by an adjustable spring and engages a long felt pad against the sharps and the naturals. A foot pedal lowers the bar and allows notes to ring freely; releasing the pedal engages the damper and stops any vibrating notes. One common flaw of this damping mechanism is that the bar is often supported at one point in the middle, causing it to damp the instrument unevenly in the upper and lower registers. To combat this, some manufacturers have made silicone- or liquid-filled damper pads whose fluid shape can conform evenly around the bars.\nMotor.\nVibraphones usually have an electric motor and pulley assembly mounted on one side or the other to drive the disks in the resonators. Often, especially within classical music, the vibraphone is played with the motor off. Certain models for outdoor use as part of a front ensemble have the motor removed entirely. In those cases having the motor off is the norm and is not used unless specifically called for.\nThe early vibraphones used motors that were intended to power record-player turntables and had limited to no speed-adjustment capabilities. Whatever speed adjustments were possible were made by moving the drive belt among a small number of pulleys (usually three) of varying diameters. Later, variable-speed AC motors became available at reasonable prices. These motors allow the adjustment of the rotating speed by a potentiometer mounted on a control panel near the motor. They typically support rotation rates in the range of 1\u201312\u00a0Hz.\nTechnique.\nTwo-mallet style.\nThe two-mallet approach to vibes is traditionally linear, playing like a horn rather than comping like a guitar or piano. Two-mallet players usually concentrate on playing a single melodic line and rely on other musicians to provide accompaniment. Double stops (two notes played simultaneously) are sometimes used, but mostly as a reinforcement of the main melodic line, similar to the use of double stops in solo violin music. In jazz groups, two-mallet vibraphonists are usually considered part of the \"front line\" with the horn players, contributing solos of their own but contributing very little in the way of accompaniment to other soloists.\nTwo-mallet players use several different grips, the most common being a matched grip called German grip, in which the mallets are played palms down, with the thumbs facing each other. In this grip, the mallets are held between the thumb and index finger of each hand, with the remaining three fingers of each hand supporting the shafts. This grip uses a combination of wrist movement and fingertip control to manipulate the mallet. Another popular grip is French grip, a grip also commonly used on timpani. The mallets are again held between the thumb and index fingers and controlled with the remaining three fingers, but the palms are held vertically, with the thumbs pointed upward. Most of the stroke action comes from the fingertip control of the shafts, with the wrists contributing slightly less than they do with the German grip.Passages are usually played with alternating sticking, but double strokes (playing two notes in a row with the same hand) are used when convenient to minimize crossing the hands.\nThe player must pay close attention to the damper pedal to avoid multiple notes ringing unintentionally at the same time. Because the notes ring for a considerable fraction of a second when struck with the damper pad up, and ringing bars do not stop ringing immediately when contacted by the pad, players use a technique called \"after pedaling\". In this technique, the player presses the damper pedal slightly after striking the bar\u2014shortly enough after so the recently struck note continues to ring, but long enough after so that the previous note stops ringing.\nIn another damper technique\u2014\"half pedaling\"\u2014the player depresses the pedal just enough to remove the spring pressure from the bars, but not enough to make the pad lose contact with the bars. This lets the bars ring slightly longer than with the pad fully up and can make a medium-fast passage sound more legato without pedaling every note.\nFour-mallet style.\nThe four-mallet vibraphone style is multi-linear, like a piano. In jazz groups, four-mallet vibraphonists are often considered part of the rhythm section, typically substituting for piano or guitar and providing accompaniment for other soloists in addition to soloing themselves. Furthermore, the four-mallet style has led to a significant body of unaccompanied solo vibes playing. One notable example is Gary Burton's performance of \"Chega de Saudade (No More Blues)\" from his Grammy-winning 1971 album, \"Alone at Last\".\nThe most popular four-mallet grip for vibraphone is the Burton grip, named for Gary Burton. One mallet is held between the thumb and index finger and the other is held between the index and middle fingers. The shafts cross in the middle of the palm and extend past the heel of the hand. For wide intervals, the thumb often moves in between the two mallets, and the inside mallet is held in the crook of the fingers. Unlike many other grips, the outer right mallet is the leading mallet rather than the inside two. Although some early vibes players made use of four mallets, notably Red Norvo, Adrian Rollini, and sometimes Lionel Hampton, the fully pianistic four-mallet approach to jazz on the vibraphone is almost entirely the creation of Burton.\nPractitioners of Burton grip tend to make more use of double strokes as compared to two-mallet players. This is done not only to avoid crossing the hands, but also to help minimize the motions between the two bar rows. For example, an ascending E\u266d major scale could be played by keeping the left hand on the upper bars and the right hand on the lower. For linear passages with leaps, all four mallets are often used sequentially.\nAlso popular is the Stevens grip, named for marimbist Leigh Howard Stevens. Many other grips are in use, some variations on the Burton or Stevens, others idiosyncratic creations of individual vibes players.\nDamping.\nPedaling techniques are at least as important for the four-mallet vibraphonist as for two-mallet players, but the all-or-nothing damping system of the sustain pedal presents many obstacles to multi-linear playing, since each line normally has its own damping requirements independent of the other lines. To overcome this, four-mallet players also use \"mallet damping\" and \"hand damping\". There are many benefits of being proficient in these techniques, as it allows the player to transition between chords much more smoothly and play new notes without having them affect the quality of the chord when the pedal is down.\nThe most common form of mallet damping occurs when the vibraphonist plays a note with one mallet before pressing another mallet into the ringing bar to stop it from sounding. Usually the damping mallet and the original striking mallet are held in different hands, but advanced players can, in some circumstances, use the same hand. Mallet damping also includes \"dead strokes\", where a player strikes a bar and then, instead of drawing the mallet back, directly presses the head of the mallet onto the bar, causing the ringing to stop immediately. This produces a fairly distinctive \"choked\" sound, and dead strokes are often used just for that particular sound in addition to the damping aspects.\nHand damping (also known as \"finger damping\") can be used to damp a note on the lower bars while striking a nearby upper bar. As the player strikes the upper bar with a mallet, they simultaneously press the heel of their hand or the side of their finger into the ringing lower bar, using the same hand to strike the upper bar and damp the lower one. Using both hands, it's possible to damp and strike two bars at once.\nExtended techniques.\nFive to six mallets.\nTo achieve a denser sound and richer chord voicings, some vibraphonists have experimented with three mallets per hand, either in both hands for a total of six mallets or in just the left hand for a total of five.\nBowing.\nLike many other metallophones, percussionists can use an orchestral bow on the vibraphone to achieve sustained tones that will not decay, nor have a percussive attack. This is done by bowing the bars perpendicular to their outer edges. Due to the different mode of vibration, this also changes the sound of the vibraphone by emphasizing the higher harmonics and giving it a more \"glassy\" tone. Because changing notes requires large and precise movements, fast passages are not often written for bowed vibraphone.\nPitch bend.\nBent notes can be achieved on the vibraphone by sliding a rubber or plastic mallet from the nodal point to the center of the bar. This technique is able to lower the pitch by about a half step.\nRepertoire.\nClassical.\nAs part of the standard percussion section, the use of the vibraphone in classical music has increased over the past fifty years, especially within the collegiate percussion ensemble.\nConcertos.\nSeveral concertos have been written for the vibraphone, the first of these being Darius Milhaud's Concerto for Marimba, Vibraphone and Orchestra written in 1947. Other prominent concertos for the vibraphone include Ney Rosauro's Concerto No. 1 for Vibraphone written in 1996 and Emmanuel S\u00e9journ\u00e9's Concerto for Vibraphone and Strings written in 1999.\nSolos.\nThe vibraphone is the second most popular solo keyboard percussion instrument, after the marimba. Solos may be jazz standards specifically arranged for the instrument or newly composed pieces that are either jazz-oriented or classical in nature. Some of the most performed solo literature includes \"Mirror from Another\" by David Friedman, \"Mourning Dove Sonnet\" by Christopher Deane, \"Trilogy\" by Tim Huesgen, and \"Blues for Gilbert\" by Mark Glentworth.\nManufacturers.\nThroughout the 1930s and 1940s, each manufacturer attracted its own following in various specialties, but the Deagan vibraphones were the models preferred by many of the specialist jazz players. Deagan struck endorsement deals with many of the leading players, including Lionel Hampton and Milt Jackson. However, the Deagan company went out of business in the 1980s, and its trademark and patents were purchased by Yamaha. Yamaha continues to make percussion instruments based on the Deagan designs.\nIn 1948, the Musser Mallet Company was founded by Clair Omar Musser, who had been a designer at Deagan. The Musser Mallet Company continues to manufacture vibraphones as part of the Ludwig Drum Company after their purchase in 1965. The Leedy Manufacturing Company, the original designers of the vibraphone, had already merged with Ludwig Drums in 1929 under C. G. Conn.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nFurther reading.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52873", "revid": "9929111", "url": "https://en.wikipedia.org/wiki?curid=52873", "title": "Glockenspiel", "text": "Mallet percussion instrument\nThe glockenspiel ( ; or , : bells and : play) or bells is a percussion instrument consisting of pitched aluminum or steel bars arranged in a keyboard layout. This makes the glockenspiel a type of metallophone, similar to the vibraphone. \nThe glockenspiel is played by striking the bars with mallets, often made of a hard material such as metal or plastic. Its clear, high-pitched tone is often heard in orchestras, wind ensembles, marching bands, and in popular music.\nTerminology.\nIn German, a carillon is also called a , and in French, the glockenspiel is sometimes called a . It may also be called a (lit.\u2009'set of small bells') in French, although this term may sometimes be specifically reserved for the keyboard glockenspiel. In Italian, the term (lit.\u2009'little bells') is used.\nThe glockenspiel is sometimes erroneously referred to as a xylophone. (The xylophone has wooden bars, unlike the glockenspiel which has metal bars.) The Pixiphone, a type of toy glockenspiel, was one such instrument sold as a xylophone.\nRange.\nThe glockenspiel is limited to the upper register and typically covers between &lt;templatestyles src=\"Fraction/styles.css\" /&gt;2+1\u20442 and 3 octaves, though certain professional models may reach up to &lt;templatestyles src=\"Fraction/styles.css\" /&gt;3+1\u20442 octaves. The glockenspiel is often a transposing instrument and sounds two octaves above the written pitch, though this is sometimes remedied by using an octave clef.\nHistory.\nEarly glockenspiels were percussion instruments that produced notes via small bronze bells that were tuned with a drumstick. The bells were replaced by metal sound plates in the 17th century. In the 18th century the instrument was played using a keyboard that struck the bottom of each plate with a hammer. The use of mallets evolved during the 19th century, coinciding with Romanticism.\nConstruction.\nWhen used in a marching or military band, the bars are sometimes mounted in a portable case and held vertically, sometimes in a lyre-shaped frame. However, the bars may be held horizontally, using a harness similar to that found on a marching snare. In orchestral use, the bars are mounted horizontally.\nLarger sets of glockenspiel (i.e., sets three octaves or larger) are often equipped with a sustain pedal, not unlike that of a vibraphone.\nFrom 1918 to 1932, J.C. Deagan, Inc. manufactured bells equipped with a resonator under the name Parsifal bells. Both Adams and Yamaha model their professional-grade glockenspiels on the Deagan design.\nMallets.\nThe glockenspiel is played with unwrapped mallets made of hard material, such as metal (usually brass or aluminum) or a type of polymer (usually Lexan, acrylic, phenolic, or nylon). Non-metal mallets are used for general playing, while metal mallets produce a more brilliant sound. Rubber mallets may be used for a warmer sound, although rubber that is too soft may struggle to excite the metal bars. Playing chords on a glockenspiel can be done with four mallets using a grip such as Stevens technique.\nBell-lyre.\nIn the United Kingdom, the United States, and Canada, a form of glockenspiel is called a bell lyre, bell lyra, or lyra-glockenspiel. The bell lyre is a form of glockenspiel commonly used in marching bands. \nOne variation is played vertically and has an extendable spike that is held on a strap. The player marches with the strap over one's shoulder and plays the instrument upright with a mallet. Another variation of the bell lyre exists that is supported by a strap around the shoulders and back. This variation is played horizontally with two mallets. Since the middle of the 19th century this form has been used in military and civil bands in Germany, where it is called a \"Stahlspiel\" or \"Milit\u00e4r-Glockenspiel\". \nThe all-percussion drum and lyre corps in the Philippines uses this as a main instrument. This form of glockenspiel is also popular in Colombian marching band music.\nMany marching bands stopped using bell lyres with the introduction of the front ensemble. One of the few college marching bands with a glockenspiel section is UC Berkeley's University of California Marching Band, where they are affectionately referred to as \"glocks\".\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nBibliography.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;"}
{"id": "52874", "revid": "20542576", "url": "https://en.wikipedia.org/wiki?curid=52874", "title": "People of the Book", "text": "Islamic term originally used to refer to Jews and Christians\nPeople of the Book, or Ahl al-Kit\u0101b (), is a classification in Islam for the adherents of those religions that are regarded by Muslims as having received a divine revelation from God, generally in the form of a holy scripture. The classification chiefly refers to pre-Islamic Abrahamic religions. In the Quran, they are identified as the Jews, the Christians, the Sabians, and\u2014according to some interpretations\u2014the Zoroastrians. Beginning in the 8th century, this recognition was extended to other groups, such as the Samaritans (who are closely related to the Jews), and, controversially, Hindus, Buddhists, Jains, and Sikhs, among others. In most applications, \"People of the Book\" is simply used by Muslims to refer to the followers of Judaism and Christianity, with which Islam shares many values, guidelines, and principles.\nHistorically, in countries and regions following Islamic law, the religious communities that Muslims recognized as People of the Book were subject to a legal status known as \"dhimmi\", meaning that they had the option to pay a special head tax called \"jizya\" in exchange for being granted the privilege to practice their faith and govern their community according to the rules and norms of their own religion. \"Jizya\" was levied on all mentally and physically capable adult males from these recognized non-Muslim communities. Practitioners of non-recognized religions were not always granted this privilege, although many later Islamic states, particularly those in the Indian subcontinent, amended their laws to extend the application of \"dhimmi\" status beyond the originally designated Jewish and Christian communities.\nIn the Quran, the term is used in a variety of contexts, from religious polemics to passages emphasizing the community of faith among those who possess scriptures espousing monotheism, as opposed to polytheism or any other form of belief.\nThe designation of People of the Book is also relevant to Islamic marriages: a Muslim man is only permitted to marry a non-Muslim woman if she is Jewish or Christian, and he must additionally ensure that any children produced with his Jewish or Christian wife/wives are raised in the Muslim faith. Muslim women are not permitted to marry non-Muslim men, even if they are Jewish or Christian. In the case of a Muslim\u2013Christian marriage, which is to be contracted only after permission from the Christian party, the \"Ashtiname\" of Muhammad dictates that the Muslim husband is not allowed to prevent his Christian wife from attending church for prayer and worship.\nMore recently, the term has been reappropriated by some Jews and Christians as a means of self-identification vis-\u00e0-vis Muslims.\nIn the Quran.\nMeaning of the term.\nWhen used in conjunction with a person, the term identifies the members of that person's household, including their fellow tribesmen, relatives and all those who share a family background with them. However, it may also be used with place names to refer to people living in a certain locality (e.g., in Quran 9:101, 'the people of Medina'), or with more abstract nouns, as in , 'the people of a certain or school of thought'.\nThe word , meaning 'writing' or 'book', occurs very often in the Quran, generally in the sense of a divine rather than a human activity, which consists in writing down and recording everything that is created. More than just referring to a 'book', it conveys meanings of divine knowledge, divine authority, and divine revelation.\nThe term , then, refers to those who have been given access to such knowledge and revelation: they are the people to whom God has 'sent down' (see ) his wisdom by means of a prophet, as an act of divine grace. However, the revelations given to the People of the Book, taking the form of the Torah (), the Psalms (), and the Gospel (), were all partial, and it is precisely by already being familiar with the books () previously sent down that the People of the Book were expected to be able to recognize Muhammad as a prophet, and the Quran as the final and most complete revelation.\nIdentity.\nSeveral verses in the Quran are commonly understood as identifying the Jews, the Christians, and the Sabians as People of the Book. Thus for example 5:68\u201369, which mentions these groups along with the Muslims (\"the believers\") as being safe from fear and grief:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\n 2:62 is similar to this, but there is also a verse ( 22:17) which lists the same groups in another context, that of how God will judge them on the Day of Resurrection, but now adding two more groups to the list:\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nThe last named group, \"the polytheists\" (the , lit.\u2009'those who associate'), are the opposite of the first named, \"the believers\" (the Muslims). What is less clear, however, is the status of the groups mentioned in between, who now also include the \"Magi\" (), that is to say, the Zoroastrians (who are named only once in the Quran, in this verse). This was a matter of dispute among medieval Muslim scholars, who questioned whether the Zoroastrians had a clear prophet and scripture, as well as whether their doctrines on the nature of God and creation were in accordance with those of Islam and the other religions recognized as having received a revelation. Ultimately though, most Islamic jurists granted the Zoroastrians partial status as a People of the Book, while still disagreeing on the extent to which legal privileges such as intermarriage with Muslims should be allowed.\nUsage.\nThe Quran emphasizes the community of faith between possessors of monotheistic scriptures, and occasionally pays tribute to the religious and moral virtues of communities that have received earlier revelations, calling on Muhammad to ask them for information. More often, reflecting the refusal of Jews and Christians in Muhammad's environment to accept his message, the Quran stresses their inability to comprehend the message they possess but do not put into practice and to appreciate that Muhammad's teaching fulfills that message.\nThe People of the Book are mentioned several times in the 98th chapter of the Quran, ('The Clear Proof'):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;\nAccording to Islamic studies scholar Yvonne Haddad, this short chapter condemns all those who reject the 'clear proof' () of the Prophet to the eternal fire of hell, whether they are People of the Book or disbelievers ().\nThe People of the Book are also referenced in the \"jizya\" verse (), which has received varied interpretations.\nThe Quran permits marriage between Muslim men and women who are People of the Book (Jews and Christians).\nHistory.\nMuhammad's era (610\u2013632).\nThe Ashtiname of Muhammad, a treaty purportedly made between Muhammad and the Christians of Saint Catherine's Monastery, stated that if a Muslim man wished to marry a Christian woman, marriage could only occur with her consent and she must be permitted to continue attending church to pray and worship. The Ashtiname states that Christians cannot be forced to fight in wars and that Muslims should fight on their behalf; it also states that Christian churches are to be respected and forbids stealing from them. The Ashtiname forbids Muslims to remove Christians from their jobs, including those who serve as judges or monks. Muslims are bound until the Last Judgment to adhere to the treaty or \"he would spoil God's covenant and disobey His Prophet.\" The policy of the Ottoman Sultans abided by the Ashtiname.\nRashidun Caliphate (634\u2013661).\nDuring the second caliph Umar's reign (r.\u2009634\u00a0\u2013\u00a0642), the Christian community of Najran and the Jewish community of Khaybar were deported to the newly conquered regions of Syria and Iraq. Umar set aside the Christian ban on the Jews and allowed them to pray and reside in Jerusalem. Umar signed a pact with the Christians of Jerusalem, which granted them safety in the region. He also awarded the status of the People of the Book to the Zoroastrians, although some practices contrary to Islam were prohibited.\nAt the beginning of the Muslim conquest of Mesopotamia in c.\u2009640, the leader of the Mandaeans (one of the religious groups who historically claimed to be the Sabians mentioned in the Quran), Anush bar Danqa, is said to have traveled to Baghdad in order to appear before the Muslim authorities, showing them a copy of the \"Ginza Rabba\" (the Mandaean holy book), and proclaiming the chief Mandaean prophet to be John the Baptist (known to Muslims as Yahya ibn Zakariyya). Consequently, the Muslim authorities afforded them the status of People of the Book. However, this account is likely apocryphal, and if it took place at all, it must have occurred after the founding of Baghdad in 762. The earliest source to unambiguously apply the term 'Sabian' to the Mandaeans was al-Hasan ibn Bahlul (fl.\u2009950\u20131000) citing the Abbasid vizier Abu Ali Muhammad ibn Muqla (c.\u2009885\u2013940). However, it is not clear whether the Mandaeans of this period already identified themselves as Sabians or whether the claim originated with Ibn Muqla.\nLater Islamic usage.\nWhen the Umayyad general Muhammad ibn Qasim (c.\u2009694\u2013715) conquered Brahmanabad, he is said to have granted Hindus, Buddhists, and Jains the status of People of the Book.\nIslamic scholars differ on whether Hindus are People of the Book. The Islamic conquest of India necessitated the definition be revised, as most India's inhabitants were followers of the Indian religions. Many of the Muslim clergy of India considered Hindus as people of the book, and from Muhammad bin Qasim in the Umayyad era to the Mughal ruler Aurangzeb in the 17th century, Muslim rulers were willing to consider Hindus as People of the Book.\nDhimmi.\n\"Dhimmi\" is a historical term referring to the status accorded to People of the Book living in an Islamic state. The word literally means \"protected person.\" According to scholars, dhimmis had their rights fully protected in their communities, but as citizens in the Islamic state, had certain restrictions, and it was obligatory for them to pay the jizya tax, which complemented the zakat, or alms, paid by the Muslim subjects. Dhimmis were excluded from specific duties assigned to Muslims, and did not enjoy certain political rights reserved for Muslims, but were otherwise equal under the laws of property, contract, and obligation.\nUnder sharia, the dhimmi communities were usually subjected to their own special laws, rather than some of the laws which were applicable only to the Muslim community. For example, the Jewish community in Medina was allowed to have its own Halakhic courts, and the Ottoman millet system allowed its various dhimmi communities to rule themselves under separate legal courts. These courts did not cover cases that involved religious groups outside of their own community, or capital offences. Dhimmi communities were also allowed to engage in certain practices that were usually forbidden for the Muslim community, such as the consumption of alcohol and pork.\nHistorically, dhimmi status was originally applied to Jews, Christians, and Sabians. This status later also came to be applied to Zoroastrians, Hindus, Jains and Buddhists. Moderate Muslims generally reject the dhimma system as inappropriate for the age of nation-states and democracies.\nUsage by Jews and Christians.\nIn Judaism, the term \"People of the Book\" (Hebrew: \u05e2\u05dd \u05d4\u05e1\u05e4\u05e8, \"Am HaSefer\") has been reappropriated as a term to designate the Jewish people, in reference to the Torah or to the entire Hebrew Bible. Members of some Christian denominations have also embraced the term \"People of the Book\" in reference to themselves, foremost among them the Puritans as well as the Seventh-day Adventist Church and the Baptists.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52875", "revid": "1043125", "url": "https://en.wikipedia.org/wiki?curid=52875", "title": "Celesta", "text": "Struck idiophone operated by a keyboard\nThe celesta () or celeste (), also called a bell-piano, is a struck idiophone operated by a keyboard. It looks similar to an upright piano (four- or five-octave), albeit with smaller keys and a much smaller cabinet, or a large wooden music box (three-octave). The keys connect to hammers that strike a graduated set of metal (usually steel) plates or bars suspended over wooden resonators. Four- or five-octave models usually have a damper pedal that sustains or damps the sound. The three-octave instruments do not have a pedal because of their small \"table-top\" design. One of the best-known works that uses the celesta is Pyotr Ilyich Tchaikovsky's \"Dance of the Sugar Plum Fairy\" from \"The Nutcracker\".\nThe sound of the celesta is similar to that of the glockenspiel, but with a much softer and more subtle timbre. This quality gave the instrument its name, \"celeste\", meaning \"heavenly\" in French. The celesta is often used to enhance a melody line played by another instrument or section. Its musical parts are often the duplicate of a theme played on flute, harp or piano; sometimes even a real solo part. It is also used in chamber music, but there are very few concertos written for it. The delicate, bell-like sound is not loud enough to be used in full ensemble sections.\nThe celesta is a transposing instrument; it sounds one octave higher than the written pitch. Instruments of different sizes exist with ranges of three to five and a half octaves. Its four-octave sounding range is generally considered to be C4 to C8. The fundamental frequency of 4186\u00a0Hz makes this one of the highest pitches in common use. The original French instrument had a five-octave range, but because the lowest octave was considered somewhat unsatisfactory, it was omitted from later models before eventually being added back when technology improved. The standard French four-octave instrument is gradually being replaced in symphony orchestras by a larger, five-octave German model. Although it is a member of the percussion family, in orchestral terms it is more properly considered a member of the keyboard section and usually played by a keyboardist. The celesta part is normally written on two braced staves, called a grand staff.\nHistory.\nThe celesta was invented in 1886 by the Parisian harmonium builder Auguste Mustel. His father, Charles Victor Mustel, had developed the forerunner of the celesta, the typophone, in 1860. This instrument produced sound by striking tuning forks instead of the metal plates that would be used in the celesta. The dulcitone functioned identically to the typophone and was developed concurrently in Scotland; it is unclear whether their creators were aware of one another's instrument. The typophone's and dulcitone's uses were limited by its low volume, too quiet to be heard in a full orchestra.\nPyotr Ilyich Tchaikovsky is usually cited as the first major composer to use this instrument in a work for full symphony orchestra. He first used it in his symphonic poem \"The Voyevoda\", Op. posth. 78, premiered in November 1891. The following year, he used the celesta in passages of his ballet \"The Nutcracker\" (Op. 71, 1892), most notably in the \"Variation de la F\u00e9e Drag\u00e9e\" (commonly known as the \"Dance of the Sugar Plum Fairy\"), in response to instructions from the Balletmaster Marius Petipa that the music should resemble \"...drops of water shooting out of fountains...\".\nHowever, Ernest Chausson preceded Tchaikovsky by employing the celesta in December 1888 in his incidental music, written for a small orchestra, for \"La temp\u00eate\" (a French translation by Maurice Bouchor of William Shakespeare's \"The Tempest\").\nThe celesta is also notably used in Gustav Mahler's Symphony No. 6, particularly in the 1st, 2nd and 4th movements, in his Symphony No. 8 and \"Das Lied von der Erde\". Karol Szymanowski featured it in his Symphony No. 3. Gustav Holst employed the instrument in his 1918 orchestral work \"The Planets\", particularly in the final movement, \"Neptune, the Mystic\". It also features prominently in B\u00e9la Bart\u00f3k's 1936 \"Music for Strings, Percussion and Celesta\". Ottorino Respighi included it in a number of his works, particularly the \"Roman triptych\" of tone poems. George Gershwin included a celesta solo in the score to \"An American in Paris\". Ferde Grofe also wrote an extended cadenza for the instrument in the third movement of his \"Grand Canyon Suite\". Dmitri Shostakovich included parts for celesta in seven out of his fifteen symphonies, with a notable use in the fourth symphony's coda. Erich Wolfgang Korngold featured it in many of his works, from Marietta's lied in act 1 of his opera Die tote Stadt, through his film career, to his Violin Concerto (particularly in the second movement), and beyond.\nTwentieth-century American composer Morton Feldman used the celesta in many of his large-scale chamber pieces such as \"Crippled Symmetry\" and \"For Philip Guston\", and it figured in much of his orchestral music and other pieces. In some works, such as \"Five Pianos\" one of the players doubles on celesta.\nThe celesta is used in Carl Orff's cantata \"Carmina Burana\" (1936), and in some 20th-century operas such as the Silver Rose scene in \"Der Rosenkavalier\" (1911).\nThe keyboard glockenspiel part in Mozart's \"The Magic Flute\" is nowadays often played by a celesta.\nUse in other musical genres.\nJazz.\nSince Earl Hines took it up in 1928, other jazz pianists have occasionally used the celesta as an alternative instrument. In the 1930s, Fats Waller sometimes played celesta with his right hand and piano simultaneously with his left hand. Other notable jazz pianists who occasionally played the celesta include Memphis Slim, Meade \"Lux\" Lewis, Willie \"The Lion\" Smith, Art Tatum, Duke Ellington, Thelonious Monk, Buddy Greco, Oscar Peterson, McCoy Tyner, Sun Ra, Keith Jarrett, and Herbie Hancock. A celesta provides the introduction to \"Someday You'll Be Sorry\", a song Louis Armstrong recorded for RCA, and is featured prominently throughout the piece. A celesta is used by the pianist Russ Freeman on tracks from Chet Baker Sings (such as \"My Ideal\" and \"I Get Along Without You Very Well (Except Sometimes)\"). A number of recordings Frank Sinatra made for Columbia in the 1940s feature the instrument (for instance \"I'll Never Smile Again\"), as do many of his albums recorded for Capitol in the 1950s (\"In the Wee Small Hours\", \"Close to You\" and \"Songs for Swingin' Lovers\").\nThe use of celesta in jazz rapidly declined with the advent of the vibraphone.\nRock and pop.\nNotable pop and rock songs recorded with the celesta include:\nIcelandic band Sigur R\u00f3s included celesta on their album \"Takk...\", as did lead singer J\u00f3nsi on \"Go Quiet\", the acoustic version of his solo album \"Go\". Steven Wilson also uses it on various tracks in his solo works.\nThe Italian 1970s progressive rock band Celeste was named after the instrument.\nBruce Springsteen and the E Street Band used a celesta heavily in their early days, with Danny Federici often playing a Jenco Celestette in the band's live performances throughout the 1970s and 80s.\nSheryl Crow plays celesta on her 2017 album, \"Be Myself\".\nThe band A-ha used, among other instruments, a Jenco celesta during their performances, recorded and released in 2017.\nSoundtrack.\nThe celesta has been common in cinema for decades. In addition to supplementing numerous soundtrack orchestrations for films from the 1930s through to the 1960s, the celesta has occasionally been spotlighted to invoke a whimsical air. For example, in \"Pinocchio\" (1940), a small motif on the celesta is used whenever the Blue Fairy appears out of thin air or performs magic. Celesta also provides the signature opening of \"Pure Imagination\", a song (sung by Gene Wilder) from the 1971 film \"Willy Wonka &amp; the Chocolate Factory\". Composer John Williams's scores for the first three Harry Potter films feature the instrument, particularly in the first two films' frequent statements of \"Hedwig's Theme\".\nAnother use of the celesta was in the music on the children's television series \"Mister Rogers' Neighborhood\". It was heard in the intro to the theme song of the programme, \"Won't You Be My Neighbor\", which began with a dreamy sequence on the instrument. The song was sung by Fred Rogers and played by Johnny Costa. It was also used from time to time in other music sequences throughout the programme.\nManufacturers.\nSchiedmayer and Yamaha are the only companies currently making celestas. Other known manufacturers that made celestas in the past include:\nSubstitutes.\nIf an ensemble or orchestra lacks a celesta, a piano, synthesizer, or sampler and electronic keyboards are often used as a substitute.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52876", "revid": "33924242", "url": "https://en.wikipedia.org/wiki?curid=52876", "title": "Chomsky and anti-semitism", "text": ""}
{"id": "52877", "revid": "44120587", "url": "https://en.wikipedia.org/wiki?curid=52877", "title": "St. Petersburg", "text": ""}
{"id": "52881", "revid": "1319720777", "url": "https://en.wikipedia.org/wiki?curid=52881", "title": "Gerard Kuiper", "text": "Dutch astronomer (1905\u20131973)\nGerard Peter Kuiper ( ; born Gerrit Pieter Kuiper, ; 7\u00a0December 1905 \u2013 23\u00a0December 1973) was a Dutch astronomer, planetary scientist, selenographer, author and professor. The Kuiper belt is named after him.\nKuiper is considered by many to be the father of modern planetary science.\nEarly life and education.\nKuiper, the son of a tailor in the village of Tuitjenhorn in North Holland, had an early interest in astronomy. He had extraordinarily sharp eyesight, allowing him to see with the naked eye magnitude 7.5\u00a0stars, about four times fainter than those visible to normal eyes.\nHe studied at Leiden University in 1924, where at the time a very large number of astronomers had congregated. He befriended fellow students Bart Bok and Pieter Oosterhoff, and was taught by Ejnar Hertzsprung, Antonie Pannekoek, Willem de Sitter, Jan Woltjer, Jan Oort, and the physicist Paul Ehrenfest. He received his candidate degree in Astronomy in 1927 and continued straight on with his graduate studies.\nKuiper received his PhD degree from Leiden University in the Netherlands on his thesis on binary stars with Hertzsprung in 1933.\nCareer.\nHe traveled to California to become a fellow under Robert Grant Aitken at the Lick Observatory. In 1935 he left to work at the Harvard College Observatory, where he met Sarah Parker Fuller (1913-2000), whom he married on 20\u00a0June 1936. Although he had planned to move to Java to work at the Bosscha Observatory, he took a position at Yerkes Observatory of the University of Chicago and received American citizenship in 1937.\nFrom 1947 to 1949, Kuiper served as the director of the Yerkes Observatory, as well as the McDonald Observatory in west Texas. In 1949, Kuiper initiated the Yerkes\u2013McDonald asteroid survey (1950\u20131952).\nFrom 1950-1960 he was professor at the University of Chicago, and from 1957 to 1959, Kuiper once again served as the director of the Yerkes and McDonald Observatories.\nKuiper was doctoral advisor to Carl Sagan. In 1958, the two worked on the classified military Project A119, a secret Air Force plan to detonate a nuclear warhead on the moon. In 1959, he sent J\u00fcrgen Stock to Chile, to search for suitable sites of an observatory for the Southern skies, who eventually would identify the spot for the Cerro Tololo Inter-American Observatory.\nIn 1960 Kuiper moved to Tucson, Arizona, to found the Lunar and Planetary Laboratory at the University of Arizona, serving as the laboratory's director for the rest of his life, until his death in 1973. \nDiscoveries.\nKuiper discovered two natural satellites of planets in the Solar System, namely Uranus's satellite Miranda and Neptune's satellite Nereid. In addition, he discovered carbon dioxide in the atmosphere of Mars, and the existence of a methane-laced atmosphere above Saturn's satellite Titan in 1944. Kuiper also pioneered airborne infrared observing using a Convair 990 aircraft in the 1960s.\nIn the 1950s Kuiper's interdisciplinary collaboration with the geochemist and Nobel Laureate Harold C. Urey to understand the Moon's thermal evolution descended into acrimony, as the two engaged in what became known as the \"Hot Moon, Cold Moon\" controversy. Their falling out, in part a scientific dispute, also reflected the challenge of maintaining professional relationships across overlapping but distinct scientific disciplines.\nBy 1950, Kuiper had contributed a theory for the ongoing problem of solar system origins. Kuiper claimed that gravitational instabilities would form in the solar nebula, which would then condense into protoplanets. However, Kuiper's theory failed to address the angular momentum problem, simply attributing the loss of momentum to magnetic and electric fields instead of gravity.\nIn 1951, in a paper in \"Astrophysics: A Topical Symposium\", Kuiper speculated that a large disc of small astronomical bodies formed early in the Solar System's evolution. He suggested that the disc consisted of \"remnants of original clusterings which have lost many members that became stray asteroids, much as has occurred with open galactic clusters dissolving into stars.\" In another paper, based upon a lecture Kuiper gave in 1950, also called \"On the Origin of the Solar System\", Kuiper wrote about the \"outermost region of the solar nebula, from 38 to 50 astr. units (i.e., just outside proto-Neptune)\" where \"condensation products (ices of H20, NH3, CH4, etc.) must have formed, and the flakes must have slowly collected and formed larger aggregates, estimated to range up to 1 km or more in size.\" He continued to write that \"these condensations appear to account for the comets, in size, number and composition.\" According to Kuiper \"the planet Pluto, which sweeps through the whole zone from 30 to 50 astr. units, is held responsible for having started the scattering of the comets throughout the solar system.\" It is said that Kuiper was operating on the assumption, common in his time, that Pluto was the size of Earth and had therefore scattered these bodies out toward the Oort cloud or out of the Solar System; there would not be a Kuiper belt today if this were correct. The name \"Kuiper belt\" was given to the region in the 1980s; it was first used in print by Scott Tremaine in 1988.191\nIn the 1960s, Kuiper helped identify landing sites on the Moon for the Apollo program.\nKuiper discovered several binary stars which received \"Kuiper numbers\" to identify them, such as KUI\u00a079.\nPersonal life and death.\nHe married Sarah Parker Fuller (1913-2000) on 20\u00a0June 1936. Kuiper died age 68 of a heart attack on 23\u00a0December 1973 in Mexico City, while on vacation with his wife.\nHonors.\nBesides the minor planet 1776 Kuiper, three craters (Mercurian, lunar, and Martian), Kuiper Scarp in Antarctica, and the now-decommissioned Kuiper Airborne Observatory were also named after him.\nAstronomers refer to a region of minor planets beyond Neptune as the \"Kuiper belt,\" since Kuiper had suggested that such small planets or comets may have formed there. However Kuiper himself believed that such objects would have been swept clear by planetary gravitational perturbations, so that none or few would exist there today.\nThe Kuiper Prize, named in his honor, is the most distinguished award given by the American Astronomical Society's Division for Planetary Sciences, an international society of professional planetary scientists.\nOne of the three buildings at Arizona that makes up the Lunar and Planetary Laboratory is named in his honor.\nIn Tuitjenhorn is since 2001 a statue of Gerard Kuiper, made by Gosse Dam.\nIn popular culture.\nEpisode 6 (\"The Man of a Trillion Worlds\") of the TV series \"\" featured the Kuiper\u2013Urey conflict.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52883", "revid": "28903366", "url": "https://en.wikipedia.org/wiki?curid=52883", "title": "Lavon Affair", "text": "1954 Israeli false flag operation in Egypt\nThe Lavon affair was a failed Israeli covert operation, codenamed Operation Susannah, conducted in Egypt in the summer of 1954. As part of a false flag operation, a group of Egyptian Jews were recruited by Israeli military intelligence to plant bombs inside Egyptian-, American-, and British-owned civilian targets: cinemas, libraries, and American educational centers. The bombs were timed to detonate several hours after closing time. The attacks were to be blamed on the Muslim Brotherhood, Egyptian communists, \"unspecified malcontents\", or \"local nationalists\" with the aim of creating a climate of sufficient violence and instability to induce the British government to retain its occupying troops in Egypt's Suez Canal zone. The operation caused no casualties among the population, but resulted in the deaths of four operatives. The overseer of the operation allegedly informed the Egyptians, after which 11 suspected operatives were arrested. Two died by suicide after being captured, two were executed by the Egyptian authorities, two of them were acquitted at trial, and the remaining five received prison terms ranging from 7 years to life in prison.\nThe operation ultimately became known as the \"Lavon affair\" after the Israeli defense minister Pinhas Lavon, who was forced to resign as a consequence of the incident. Before Lavon's resignation, the incident had been euphemistically referred to in Israel as the \"Unfortunate Affair\" or \"The Bad Business\" (, \"HaEsek HaBish\"). Israel publicly denied any involvement in the incident until 2005, when the surviving agents were awarded certificates of appreciation by Israeli President Moshe Katsav.\nOperation Susannah.\nAim.\nIn the early 1950s, the United States initiated a more activist policy of support for Egyptian nationalism; this aim was often in contrast with Britain's policy of maintaining its regional hegemony. Israel feared that the US policy, which encouraged Britain to withdraw its military forces from the Suez Canal, would embolden the military ambitions of Egyptian president Gamal Abdel Nasser towards Israel. Israel at first sought to influence this policy through diplomatic means, but was frustrated.\nIn the summer of 1954, Colonel Binyamin Gibli, the chief of Israel's military intelligence directorate Aman, initiated 'Operation Susannah' in order to reverse that decision. The goal of the Operation was to carry out bombings and other acts of sabotage in Egypt, with the aim of creating an atmosphere in which Anglo-American opponents of the British withdrawal from Egypt would be able to gain the upper hand and block the withdrawal.\nAccording to historian Shabtai Teveth, who wrote one of the more detailed accounts, the assignment was \"To undermine Western confidence in the existing Egyptian regime by generating public insecurity and actions to bring about arrests, demonstrations, and acts of revenge, while totally concealing the Israeli factor. The team was accordingly urged to avoid detection, so that suspicion would fall on the Muslim Brotherhood, the Communists, 'unspecified malcontents' or 'local nationalists'.\"\nSecret cell.\nThe top-secret cell, Unit 131, which was to carry out the operation, had existed since 1948 and under Aman since 1950. At the time of Operation Susannah, Unit 131 was the subject of a bitter dispute between Aman (military intelligence) and Mossad (national intelligence agency) over who should control it.\nUnit 131 operatives had been recruited several years earlier, when the Israeli intelligence officer Avraham Dar arrived in Cairo under the cover of a British citizen from Gibraltar named John Darling. He had recruited several Egyptian Jews, known as \"sayanim\" (), who had also previously been active in helping Jews flee to Israel, activities that Egypt deemed illegal, and trained them for covert operations.\nOperation commenced.\nAman decided to activate the network in the spring of 1954. On 2 July, the cell detonated bombs at a post office in Alexandria, and on 14 July, it bombed the libraries of the U.S. Information Agency in Alexandria and Cairo, and a British-owned theater. The homemade bombs, consisting of bags containing acid placed over nitroglycerine, were inserted into books and placed on the shelves of the libraries just before closing time. Several hours later, as the acid ate through the bags, the bombs would explode. They did little damage to the targets and caused no injuries or deaths.\nBefore the group began the operation, Israeli agent Avri Elad (Avraham Seidenberg) was sent to oversee the operations. Elad assumed the identity of Paul Frank, a former SS officer with Nazi underground connections. Avri Elad allegedly informed the Egyptians, resulting in the Egyptian intelligence agency following a suspect to his target, the Rio Theatre, where a fire engine was standing by. Egyptian authorities arrested this suspect, Philip Natanson, when his bomb accidentally ignited prematurely in his pocket. Having searched his apartment, they found incriminating evidence and names of accomplices to the operation.\nEleven suspects were arrested by the Egyptian State Security, including Egyptian Jews and undercover Israelis. Elad and Colonel Dar managed to escape. Two suspects, Yosef Carmon and Israeli Meir Max Bineth, died by suicide in prison.\nTrials and jail.\nThe Egyptian trial began on 11 December and lasted until 27 January 1955; two of the accused (Moshe Marzouk and Shmuel Azar) were sentenced to death by hanging, two were acquitted, and the rest received lengthy prison terms ranging from 7 years to life in prison.\nIn 1954, on behalf of both Winston Churchill and the World Jewish Congress, Maurice Orbach went to Cairo to intercede for the lives of those sentenced to death. Later, he said that Egypt's president, Nasser, had agreed to spare their lives but then reneged on this, balancing their deaths with those of members of the Muslim Brotherhood.\nThe trial was criticised in Israel as a show trial, although strict Israeli military censorship of the press at the time meant that the Israeli public was kept in the dark about the facts of the case, and in fact were led to believe that the defendants were innocent.\nAfter serving seven-year jail sentences, two of the imprisoned operatives (Meir Meyuhas and Meir Za'afran) were released in 1962. The rest were eventually freed in February 1968, including Marcelle Ninio, in a secret addendum to a prisoner-of-war exchange.\nSoon after the affair, Mossad chief Isser Harel expressed suspicion to Aman concerning the integrity of Avri Elad. Despite his concerns, Aman continued using Elad for intelligence operations until 1956, when he was caught trying to sell Israeli documents to the Egyptians. Elad was tried in Israel and sentenced to 10 years imprisonment. During his imprisonment in Ayalon Prison, the media were only able to refer to him as the \"Third Man\" or \"X\" due to government censorship. In 1976, while living in Los Angeles, Elad publicly identified himself as the \"Third Man\" from the Lavon Affair. In 1980, Harel publicly revealed evidence that Elad had been turned by the Egyptians even before Operation Susannah.\nPolitical aftermath.\nDenial and first inquiry.\nIn meetings with the prime minister Moshe Sharett, minister of defense Pinhas Lavon denied any knowledge of the operation. When intelligence chief Gibli contradicted Lavon, Sharett commissioned a board of inquiry consisting of Israeli Supreme Court Justice Isaac Olshan and the first chief of staff of the Israel Defense Forces, Yaakov Dori that was unable to find conclusive evidence that Lavon had authorized the operation. Lavon tried to fix the blame on Shimon Peres, who was the secretary general of the defense ministry, and on Gibli for insubordination and criminal negligence.\nSharett resolved the dilemma by siding with Peres (who had, along with Moshe Dayan, testified against Lavon), after which Lavon resigned on 17 February 1955. Former prime minister David Ben-Gurion succeeded Lavon as minister of defense. On 3 November 1955, Sharett (who had not known about the operation in advance, and had therefore strongly denied Israel's involvement) resigned as Prime Minister and was replaced by Ben-Gurion.\nSubsequent revelations and inquiries.\nIn April 1960, a review of minutes from the inquiry found inconsistencies and possibly a fraudulent document in Gibli's original testimony that seemed to support Lavon's account of events. During this time it came to light that Elad (the Israeli agent running Operation Susannah in Egypt) had committed perjury during the original inquiry. Elad was also suspected of betraying the group to Egyptian authorities, though the charges were never proven. He was eventually sentenced to a jail term of 10 years for trying to sell Israeli documents to the Egyptians in an unrelated matter. Ben-Gurion scheduled closed hearings with a new board of inquiry chaired by Haim Cohn, a Supreme Court justice.\nThis inquiry found that the perjury indeed had been committed, and that Lavon had not authorized the operation. Sharett and Levi Eshkol tried to issue a statement that would placate both Lavon and those who had opposed him. Ben-Gurion refused to accept the compromise, and viewed it as a divisive play within the Mapai party.\nAnother investigative committee took up the matter and sided with the Cohn inquiry. Ben-Gurion then resigned from his post as defense minister. This led to the expulsion of Lavon from the Histadrut labor union and an early call for new elections, the results of which changed the political structure in Israel. The specifics of Operation Susannah were kept secret from the Israeli public at the time of the political upheaval.\nPublic debate.\nDue to Israel's military censorship the details of the affair could originally not be openly discussed in the media. Despite this, debate occurred but with the use of code words such as the \"Senior Officer\", to refer to Gibli, and the \"unfortunate business\" to refer to the Egyptian operation.\nLegacy.\nOperation Susannah and the Lavon Affair turned out to be disastrous for Israel in several ways:\nIsrael publicly honored the surviving spies on March 30, 2005; President Moshe Katsav presented each with a certificate of appreciation for their efforts on behalf of the state, ending decades of official denial by Israel.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52886", "revid": "33077729", "url": "https://en.wikipedia.org/wiki?curid=52886", "title": "Logo (disambiguation)", "text": "A logo is a graphic used to represent an entity.\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nLogo may also refer to:\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "52887", "revid": "1257609314", "url": "https://en.wikipedia.org/wiki?curid=52887", "title": "Middle ages", "text": ""}
{"id": "52888", "revid": "21860424", "url": "https://en.wikipedia.org/wiki?curid=52888", "title": "Logo", "text": "Graphic mark, emblem, or symbol used to aid and promote public identification and recognition\nA logo (abbreviation of logotype; from grc \" \"\u03bb\u03cc\u03b3\u03bf\u03c2\" (l\u00f3gos)\"\u00a0'word, speech' and \" \"\u03c4\u03cd\u03c0\u03bf\u03c2\" (t\u00fapos)\"\u00a0'mark, imprint') is a graphic mark, emblem, or symbol used to aid and promote public identification and recognition. It may be of an abstract or figurative design or include the text of the name that it represents, as in a wordmark.\nIn the days of hot metal typesetting, a logotype was one word cast as a single piece of type (e.g. \"The\" in ATF Garamond), as opposed to a ligature, which is two or more letters joined, but not forming a word. By extension, the term was also used for a uniquely set and arranged typeface or colophon. At the level of mass communication and in common usage, a company's logo is today often synonymous with its trademark or brand.\nEtymology.\nDouglas Harper's \"Online Etymology Dictionary\" states that the first surviving written record of the term 'logo' dates back to 1937, and that the term was \"probably a shortening of logogram\".\nHistory.\nNumerous inventions and techniques have contributed to the contemporary logo, including cylinder seals (c.\u20092300 BCE), coins (c.\u2009600 BCE), trans-cultural diffusion of logographic languages, coats of arms, watermarks, silver hallmarks, and the development of printing technology.\nAs the Industrial Revolution converted western societies from agrarian to industrial in the 18th and 19th centuries, photography and lithography contributed to the boom of an advertising industry that integrated typography and imagery together on the page. Simultaneously, typography itself was undergoing a revolution of form and expression that expanded beyond the modest, serif typefaces used in books, to bold, ornamental typefaces used on broadsheet posters.\nThe arts were expanding in purpose\u2014from expression and decoration of an artistic, storytelling nature, to a differentiation of brands and products that the growing middle classes were consuming. Consultancies and trades-groups in the commercial arts were growing and organizing; by 1890, the US had 700 lithographic printing firms employing more than 8,000 people. Artistic credit tended to be assigned to the lithographic company, as opposed to the individual artists who usually performed less important jobs.\nInnovators in the visual arts and lithographic process\u2014such as French printing firm Rouchon in the 1840s, Joseph Morse of New York in the 1850s, Frederick Walker of England in the 1870s, and Jules Ch\u00e9ret of France in the 1870s\u2014developed an illustrative style that went beyond tonal, representational art to figurative imagery with sections of bright, flat colors. Playful children's books, authoritative newspapers, and conversational periodicals developed their own visual and editorial styles for unique, expanding audiences. As printing costs decreased, literacy rates increased, and visual styles changed, the Victorian decorative arts led to an expansion of typographic styles and methods of representing businesses.\nThe Arts and Crafts Movement of late-19th century, partially in response to the excesses of Victorian typography, aimed to restore an honest sense of craftsmanship to the mass-produced goods of the era. A renewal of interest in craftsmanship and quality also provided the artists and companies with a greater interest in credit, leading to the creation of unique logos and marks.\nBy the 1950s, Modernism had shed its roots as an avant-garde artistic movement in Europe to become an international, commercialized movement with adherents in the United States and elsewhere. The visual simplicity and conceptual clarity that were the hallmarks of Modernism as an artistic movement formed a powerful toolset for a new generation of graphic designers whose logos embodied Ludwig Mies van der Rohe's dictum, \"Less is more.\" Modernist-inspired logos proved successful in the era of mass visual communication ushered in by television, improvements in printing technology, and digital innovations.\nContemporary logos.\nThe current era of logo design began in the 1870s with the first abstract logo, the Bass red triangle. As of 2014[ [update]], many corporations, products, brands, services, agencies, and other entities use an ideogram (sign, icon) or an emblem (symbol) or a combination of sign and emblem as a logo. As a result, only a few of the thousands of ideograms in circulation are recognizable without a name. An effective logo may consist of both an ideogram and the company name (logotype) to emphasize the name over the graphic, and employ a unique design via the use of letters, colors, and additional graphic elements.\nIdeograms and symbols may be more effective than written names (logotypes), especially for logos translated into many alphabets in increasingly globalized markets. For instance, a name written in Arabic script might have little resonance in most European markets. By contrast, ideograms keep the general proprietary nature of a product in both markets. In non-profit areas, the Red Cross (varied as the Red Crescent in Muslim countries and as the Red Star of David in Israel) exemplifies a well-known emblem that does not need an accompanying name. The red cross and red crescent are among the best-recognized symbols in the world. National Red Cross and Red Crescent Societies and their Federation as well as the International Committee of the Red Cross include these symbols in their logos.\nBranding can aim to facilitate cross-language marketing. Consumers and potential consumers can identify the Coca-Cola name written in different alphabets because of the standard color and \"ribbon wave\" design of its logo. The text was written in Spencerian Script, which was a popular writing style when the Coca-Cola Logo was being designed.\nLogo design.\nSince a logo is the visual entity signifying an organization, logo design is an important area of graphic design. A logo is the central element of a complex identification system that must be functionally extended to all communications of an organization. Therefore, the design of logos and their incorporation in a visual identity system is one of the most difficult and important areas of graphic design. Logos fall into three classifications (which can be combined). Ideographs, such as Chase Bank, are completely abstract forms; pictographs are iconic, representational designs; logotypes (or wordmarks) depict the name or company initials. These elements can be combined in a set position and relative size in a logo lock-up, so named because elements are \"locked\" together and should not be broken apart or resized individually. Because logos are meant to represent companies' brands or corporate identities and foster their immediate customer recognition, it is counterproductive to frequently redesign logos.\nThe logo design profession has substantially increased in numbers over the years since the rise of the Modernist movement in the United States in the 1950s. Three designers are widely considered the pioneers of that movement and of logo and corporate identity design: The first is Chermayeff &amp; Geismar, which is the firm responsible for many iconic logos, such as Chase Bank (1964), Mobil Oil (1965), PBS (1984), NBC (1986), National Geographic (2003), and others. Due to the simplicity and boldness of their designs, many of their earlier logos are still in use today. The firm recently designed logos for the Library of Congress and the fashion brand Armani Exchange. Another pioneer of corporate identity design is Paul Rand, who was one of the originators of the Swiss Style of graphic design. He designed many posters and corporate identities, including the famous logos for IBM, UPS, and ABC. The third pioneer of corporate identity design is Saul Bass. Bass was responsible for several recognizable logos in North America, including both the Bell Telephone logo (1969) and successor AT&amp;T Corporation globe (1983). Other well-known designs were Continental Airlines (1968), Dixie (1969), and United Way (1972). Later, he would produce logos for a number of Japanese companies as well.\nAn important development in the documentation of logo design is the study of French trademarks by historian Edith Amiot and philosopher Jean Louis Azizollah.\nLogo color.\nColor is a key element in logo design and plays an important and potentially vital role in brand differentiation. Colors can have immense consequences on our moods. They are remarkably dominant to the point that they can psychologically manipulate perspectives, emotions, and reactions. The importance of color in this context is due to the mechanics of human visual perception wherein color and contrast play critical roles in visual detail detection. In addition, we tend to acquire various color connotations and color associations through social and cultural conditioning, and these play a role in how we decipher and evaluate logo color. While color is considered important to brand recognition and logo design, it should not conflict with logo functionality, and it needs to be remembered that color connotations and associations are not consistent across all social and cultural groups. For example, in the United States, red, white, and blue are often used in logos for companies that want to project patriotic feelings but other countries will have different sets of colors that evoke national pride.\nChoosing an organisation's logo color is an important decision because of its long term implications and its role in creating differentiation among competitors' logos. A methodology for identifying potential logo colors within an industry sector is color mapping, whereby existing logo colors are systematically identified, mapped, and evaluated (O'Connor, 2011).\nLogo design process.\nDesigning a good logo often requires involvement from a marketing team teaming with the graphic design studio. Before a logo is designed, there must be a clear definition of the concept and values of the brand as well as understanding of the consumer or target group. Broad steps in the logo design process include research, conceptualization, investigation of alternative candidates, refinement of a chosen design, testing across products, and finally adoption and production of the chosen mark.\nDynamic logos.\nIn 1898, the French tire manufacturer Michelin introduced the Michelin Man, a cartoon figure presented in many different contexts, such as eating, drinking, and playing sports. By the early 21st century, large corporations such as MTV, Nickelodeon, Google, Morton Salt, and Saks Fifth Avenue had adopted \"dynamic logos\" that change over time from setting to setting.\nInternet-compatible logos.\nA company that uses logotypes (wordmarks) may desire a logo that matches the firm's Internet address. For short logotypes consisting of two or three characters, multiple companies are found to employ the same letters. A \"CA\" logo, for example, is used by the French bank Credit Agricole, the Dutch clothing retailer C&amp;A, and the US software corporation CA Technologies, but only one can have the Internet domain name CA.com.\nIn today's digital interface adaptive world, a logo will be formatted and re-formatted from large monitors to small handheld devices. With the constant size change and re-formatting, logo designers are shifting to a more bold and simple approach, with heavy lines and shapes, and solid colors. This reduces the confusion when mingled with other logos in tight spaces and when scaled between media. Social networks like Twitter, and Google+ used such logos, and X, Facebook, and LinkedIn, still do.\nDesign protection.\nLogos and their design may be protected by copyright, via various intellectual property organisations worldwide which make available application procedures to register a design to give it protection at law. For example, in the UK, the Intellectual Property Office (United Kingdom) govern registered designs, patents, and trademarks. Ordinarily, the trademark registration will not 'make claim' to colors used, meaning it is the visual design that will be protected, even if it is reproduced in a variety of other colors or backgrounds.\nIn some countries, especially civil law countries, the threshold of originality required for copyright protection can be quite high, so a logo that contains simple geometric shapes or text might not be eligible for copyright protection although it can be protected as a trademark.\nSports.\nFor many teams, a logo or \"crest\" is an important way to recognize a team's history and can intimidate opponents.\nFor certain teams, the logo and color scheme are synonymous with the team's players. For example, Manchester United, the Toronto Maple Leafs, or New York Yankees all have a recognizable logo that can be identified by any fan of the respective sport.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nSources.\n&lt;templatestyles src=\"Refbegin/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; The dictionary definition of \"logo\" at Wiktionary"}
{"id": "52890", "revid": "22041646", "url": "https://en.wikipedia.org/wiki?curid=52890", "title": "Badger (disambiguation)", "text": "A badger is a medium-sized short-legged animal.\nBadger may also refer to:\n&lt;templatestyles src=\"Template:TOC_right/styles.css\" /&gt;\nSee also.\nTopics referred to by the same term\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n This page lists associated with the title ."}
{"id": "52892", "revid": "21112944", "url": "https://en.wikipedia.org/wiki?curid=52892", "title": "Modern pentathlon", "text": "Five-event Olympic sport\nThe modern pentathlon is an Olympic multisport that consists of five events: fencing (one-touch \u00e9p\u00e9e followed by direct elimination), freestyle swimming, obstacle course racing, laser pistol shooting, and cross country running.\nThe sport was first held in 1912, inspired by the traditional pentathlon held during the ancient Olympics, and designed to model skills needed by a soldier of that time. It has been a continuous part of the Summer Olympics since 1912, and a world championship has been held annually since 1949.\nThe rules of the modern pentathlon have changed several times, especially in recent decades. Most notably, equestrian show jumping was one of the five events for more than 100 years, but was replaced by obstacle course racing in senior competitions as of 2025. The event has been condensed from five days to one day, and further down to two hours. The latest structure, as of the 2024 Olympics, consisted of separate events for fencing, swimming, and equestrian, points from which determine each athlete's starting time in the final event, a combined laser-run. Egypt has achieved consistent success across multiple age-group world championships, culminating in Ahmed El-Gendy winning the first Olympic gold medal by an African pentathlete at the 2024 Summer Olympics. Hungary has won the most Olympic gold medals after Michelle Gulyas became its second women\u2019s Olympic champion at Paris 2024. \u00a0\nThe initial program of the 2028 Olympics did not include modern pentathlon, but the 141st International Olympic Committee Session in Mumbai, India, voted to approve the inclusion of the sport with its new format where obstacle racing replaces equestrian.\nModern pentathlon's governing body, Union Internationale de Pentathlon Moderne (UIPM), administers the international sport with member federations in more than 130 countries.\nFormat.\nThe format of the modern pentathlon has changed frequently through the sport's history. Obstacle course racing will make its debut in the 2028 Los Angeles Olympics as part of the modern pentathlon, replacing the equestrian show jumping event at the Olympics. This shift aims to modernize the sport and make it more accessible and relatable. Described below is the format that will be used:\nAt the 2024 Olympics, the event was run twice for each gender. The first, the semifinals, determined which athletes could participate in the finals. The finals then determines the medallists. However, the fencing ranking round was only run once and its results were used for both the semifinals and finals. \nHistory.\nCreation.\nMost sources state that the creator of the modern pentathlon was Baron Pierre de Coubertin, the founder of the modern Olympic Games. One alternative view is provided by researcher Sandra Heck, who concluded that Viktor Balck, the President of the Organizing Committee for the 1912 Games, made use of the long tradition of Swedish military multi-sports events to create the modern pentathlon.\nThe name derives from the Greek \u03c0\u03ad\u03bd\u03c4\u03b1\u03b8\u03bb\u03bf\u03bd (\"p\u00e9ntathlon\") \"contest of five [events]\". The addition of \"modern\" to the name distinguishes it from the original pentathlon of the ancient Olympic Games, which consisted of the \"stadion\" foot race, wrestling, long jump, javelin, and discus. The location of the first Olympic Games was Olympia in 708 BCE. As the events of the ancient pentathlon were modelled on the skills of the ideal soldier to defend a fortification of that time, Coubertin created the contest to simulate the experience of a 19th-century cavalry soldier behind enemy lines: he must ride an unfamiliar horse, fight enemies with pistol and sword, swim, and run to return to his own soldiers.\nOlympic Games.\nThe event was first held at the 1912 Olympic Games and has been on the Olympic program continuously ever since. It was a male-only event until the 2000 Games, when an event for women was added. This enabled the sport to achieve gender parity 24 years before the Olympic Games managed this as a whole.\nA men's team event was added to the Olympic Games in 1952, and was included in all Summer Olympics until its last appearance in 1992.\nOriginally, the competition took place over four or five days. In 1996, a one-day format was adopted in a major shift towards the sport's more audience-friendly future. The switch to a one-day format was criticised for changing the steady character of modern pentathlon to a more fast-paced competition. To further enhance the experience for spectators, the UIPM proposed that all five events should be held in a single venue. This was planned for the 2016 Summer Olympics but held for the first time at the 2020 Summer Olympics. For the 2024 Summer Olympics, the format is further condensed into two hours. Further innovation and streamlining to maximise the sport's appeal, including changes to the fencing event, is planned for the\u00a02028 Summer Olympics in Los Angeles.\nModern pentathlon is also part of the Youth Olympic Games since 2010.\nModern pentathlon, despite its long Olympic history, has had to justify its inclusion in the modern Olympic Games several times. On February 11, 2013, in Lausanne, the IOC confirmed modern pentathlon once again as one of the 25 core sports of the Olympic program through to 2020. Nine years later, the IOC confirmed its place on the program for the 2028 Summer Olympics in Los Angeles.\nGovernance.\nUntil 1948 there was no official international federation for modern pentathlon, so an IOC committee was set up for the sport making use of the expertise of IOC members. The governing body, Union Internationale de Pentathlon Moderne (UIPM) was founded in 1948 in Sandhurst, England during the London 1948 Olympic Games.\nInternational competitions.\nA world championship has been held every year since 1949. The competitions now include men and women's individual and team events together with relay events for men and women and, since 2010, a mixed relay event. After much lobby work of the president of the German Modern Pentathlon Federation, Wilhelm Henze, women were for the first time admitted at the world championships in 1977, and at the official world championships in 1981.\nThe Modern Pentathlon World Cup is an annual series of modern pentathlon competitions, with four events taking place in the regular season and the top 36 female and top 36 male athletes qualifying to compete in the World Cup Final. It was first held in 1999.\nFormat changes over time.\nModern pentathlon has been the subject of numerous changes since its creation.\nFencing.\nIn 2015 \u2014 and for the first time in the 2016 Summer Olympics \u2014 a system of an additional bonus round was added to \u00e9p\u00e9e fencing in international competitions. Before that, there was only the round-robin format.\nSwimming.\nUntil the 2000 Olympics, the distance for swimming was 300\u00a0metres; at that time it was changed to 200\u00a0metres.\nRiding.\nThe distance of the cross-country riding event was reduced from 5\u00a0km to 4\u00a0km in 1972. For the 1988 Summer Olympics cross-country riding was changed to show jumping.\nShooting and running.\nFrom 1912 to 1988 regular pistols or later sport pistols were used for shooting. From 1989 until 2009, the shooting discipline involved firing a 4.5\u00a0mm (.177 cal) air pistol in the standing position from 10 metres distance at a stationary target. The format was that of the 10 metre air pistol competition: each competitor had 20\u00a0shots, with 40\u00a0seconds allowed for each shot. Beginning with the World Cup events in 2011, in a move designed to improve the safety and sustainability of the sport, laser pistols were used instead of pistols with actual projectiles. At the same time, unlimited shots were allowed for each timed shooting round. There is a slight delay between the trigger pull and the laser firing, simulating the time it would take for a pellet to clear the muzzle. Air pistols with laser transmitters were introduced during the transitional period and are still in use. Purpose-built laser pistols are developed and commonly used since the middle of the 2010s. Laser pistols and targets have to be certified by the UIPM. The standard target dimension is a 250 mm diameter circle, with a target valid zone of 59.5 mm.\nUntil 2000, the running distance was 4\u00a0kilometres. At the 2000 Olympics, the running discipline was shortened to a 3\u00a0km cross-country run.\nIn 2008, the UIPM Congress passed a motion to combine the shoot and run disciplines. This is now known as the \u201ccombined event\u201d and is the final event of the competition. In 2009, the combined event consisted of three 1000\u00a0m laps, each preceded by laser shooting at five targets in 70\u00a0seconds or less. From the start of the 2013 season, the laser-run (term coined in 2016) was changed to consist of four 800\u00a0m laps (increasing the distance to 3.2\u00a0kilometres) each preceded by laser shooting at five targets in 50\u00a0seconds or less. This change was intended to restore some of the importance of the shooting skill felt to have been lost in the original 2009 combined event. After the 2020 Summer Olympics (postponed to 2021), the run was further modified to a new model of five 600 m laps. \nThe laser run is organized as a pursuit race: athletes start with a handicap based on the summed points gathered in the previous disciplines; as such it determines the overall outcome of the modern pentathlon event. The rest of the field face a one-second handicap for each pentathlon point by which they trail the leader. This ensures that the first person to cross the finish line wins the Gold medal. \nThe laser-run has been criticized as altering too radically the nature of the skills required by athletes. \"The New York Times\" asked whether the name ought to be changed to \"tetrathlon\" given that two of the five disciplines had been combined into a single event. Laser-run has also become a sport in its own right with para athlete participation and world championships of its own. It is the summer equivalent of the biathlon winter sport, which involves skiing and shooting.\nOverall scoring and operation.\nScoring was originally done by a points-for-place system with the lowest score winning. Since the 1954 World Cup points tables are used for each of the five events and points are added for the final score. This scoring was first used in the 1956 Summer Olympics. The five disciplines were held on a single day \u2014 instead of four to six \u2014 from the 1996 Summer Olympics onwards. In the 2024 Olympics, all five disciplines \u2013 other than the fencing ranking round \u2013 will all take place in the same venue within 90 minutes.\nReplacement of riding with obstacle course racing.\nThe riding discipline attracted criticism during the 2020 Summer Olympics after multiple athletes in the women's event struggled to control their randomly-assigned horses. This culminated in the German team's coach, Kim Raisner, being removed from the event after striking a horse with her fist. Following the Games, in November 2021 it was reported that the UIPM was opening consultations on the proposed replacement of riding with another discipline. The decision was ratified during the UIPM's Congress on 27 November 2021, with the changes intended to be implemented for the 2028 Summer Olympics. According to critics of the decision, the UIPM voted for the change without consulting athletes, claiming \"force majeure\".\nThe decision was met with criticism from various athletes and bodies, who considered riding to be integral to modern pentathlon. Some also accused the UIPM of hindering debate in favor of riding during the congress. More than 650 modern pentathletes signed a letter calling for the UIPM executive board to resign in November 2021. A group known as \"Pentathlon United\" called for the IOC to investigate the UIPM's governance, and proposed a plan to maintain riding with rule changes to bring them in line with those of the International Federation for Equestrian Sports (FEI), and a focus on animal welfare.\nIn May 2022, the UIPM announced it would hold an obstacle racing test event alongside the 2022 Modern Pentathlon World Cup final in Ankara, citing that it had received the most support out of the over 60 disciplines proposed, was more cost-effective, would help make the event more attractive to a younger audience, and was \"compatible with the DNA of modern pentathlon\". The competition course was developed with input from World Obstacle and Japanese broadcaster TBS (producer of the sports competition series \"Sasuke\", whose format has been widely exported under the title \"Ninja Warrior\"), and the event featured a mix of athletes from both the obstacle racing and modern pentathlon communities. Australian gymnast Olivia Vivian\u2014a grand finalist of \"Australian Ninja Warrior\"\u2014won the gold in the women's competition.\nOn 9 July 2022, Pentathlon United shared a survey of 213 responses from 40 countries, claiming that 68.5% of the respondents were current athletes, that indicated more than 92% of current modern pentathlon participants wanted to preserve the equestrian discipline as part of the sport. The group stated, \"A total of 74.18% chose the reformed version of equestrian, which puts horse welfare among the central themes, while concern over the cost and accessibility of the equestrian discipline is also acknowledged in the 16-point plan.\" Of those polled, Pentathlon United claimed that only athletes from the United Kingdom showed any support for an obstacle race, with athletes from the United States overwhelmingly voting for a reformed version of equestrian sport.\nIn October 2022, modern pentathlon's elected Athletes Committee launched a campaign entitled #OurFuture, highlighting the views of pentathletes in favour of the change. Athletes such as Olympic silver medallists Elodie Clouvel (France) and Ahmed Elgendy (Egypt) supported the transition when participating in a media conference at UIPM Headquarters in Monaco. They were joined by Athletes Committee representatives including the group's Chair, Yasser Hefny OLY (Egypt), Jamie Cooke (Great Britain) and Natalya Coyle OLY (Ireland), as well as former Pan American champion Tamara Vega (Mexico).\nIn November 2022, the UIPM Congress voted 69\u201311 in favor of replacing riding with obstacle course racing; an associated motion established that the changes would take effect for junior competition in 2023. The 2023 and 2024 junior world championships duly took place with obstacle in place of equestrian. The new format's implementation at the senior level will be formalised after the 2024 Summer Olympics.\nOn 22 June 2023, the UIPM shared a poll of 1,500 Americans by YouGov that they commissioned in support of their decision to replace riding with obstacle course racing, citing that the survey showed that \"45% of Gen Z and 41% of Millennials more likely to watch the Olympics on television if it featured a ninja-style obstacle race...taken as a percentage of the U.S. population, this would equate to nearly 45 million more people watching the Games\". The UIPM also stated, \"More than two-thirds (37%) of survey respondents said they would be more likely to watch the new-look Modern Pentathlon at the Olympic Games, and 46% of those cited enjoying ninja-style obstacle races as the reason, with 34% describing the reason for their answer: 'I think the Modern Pentathlon needs to embrace change'.\" The article also indirectly referenced the popular TV show \"American Ninja Warrior\".\n\u0406n August 2023 during the 2023 UIPM Pentathlon and Laser Run World Championships, the UIPM signed a memorandum of understanding with World Obstacle to collaborate on the integration of obstacle racing into the modern pentathlon at the senior level; UIPM president Klaus Schormann stated that the federation was \"want[ing] to bring a different challenge to the Olympic Movement, to be more urban and provide something that young generations will love.\" The MoU was criticised by Pentathlon United, who questioned World Obstacle's finances (in particular, being funded solely by one person with no other commercial revenue). In October 2023, during the 141st IOC Session in Mumbai, the IOC voted to reinstate modern pentathlon with its new format for the 2028 Summer Olympics.\nPopularity.\nIn 2021, modern pentathlon consistently had the least TV viewers of all Olympic sports, and also ranked at the bottom for internal Olympic measurements of social engagement. The Greek modern pentathlon coach said, \"We are an Olympic sport that is on the edge... We're very, very low down, if not bottom, in a lot of ratings like ticket sales, viewership, and participation\". Sports academic J\u00f6rg Krieger wrote in 2022 that the sport \"suffered from a lack of participation in the sport, as well as [having] limited public interest\". However, KXAS-TV reporter Stephanie de Lancey called the compressed 90-minute format used at the 2024 Olympics \"fast and action-packed\" and said the replacement of show jumping for 2028 was \"a way for the sport to evolve in the 21st century.\"\nA 2021 study by Quartz concluded that modern pentathlon (in the form that included equestrian) was the most expensive Olympic sport for entry-level costs. It found that to start modern pentathlon cost US$13,580 for equipment and facilities. Most other Olympic sports examined cost less than $500 to start in.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;\nExternal links.\n&lt;templatestyles src=\"Sister-inline/styles.css\"/&gt; Media related to at Wikimedia Commons"}
{"id": "52893", "revid": "50216599", "url": "https://en.wikipedia.org/wiki?curid=52893", "title": "French Equatorial Africa", "text": "Federation of French colonies in central Africa (1910\u201358)\nFrench Equatorial Africa (, or AEF) was a federation of French colonial territories in Equatorial Africa which consisted of Gabon, French Congo, Ubangi-Shari, and Chad. It existed from 1910 to 1958 and its administration was based in Brazzaville.\nHistory.\nEstablished in 1910, the Federation contained four colonial possessions: French Gabon, French Congo, Ubangi-Shari and French Chad. The Governor-General was based in Brazzaville with deputies in each territory.\nIn 1911, France ceded parts of the territory to German Kamerun as a result of the Agadir Crisis. The territory was returned after Germany's defeat in World War I, while most of Cameroon proper became a French League of Nations mandate not integrated into the AEF.\nFrench Equatorial Africa, especially the region of Ubangi-Shari, had a similar concession system as the Congo Free State and similar atrocities were also committed there. Writer Andr\u00e9 Gide traveled to Ubangi-Shari and was told by inhabitants about atrocities including mutilations, dismemberments, executions, the burning of children, and villagers being forcibly bound to large beams and made to walk until dropping from exhaustion and thirst. Gide's book \"Travels in the Congo\", published in 1927, was fiercely critical of the system of the concession companies in French Equatorial Africa. The book had an important impact on the anti-colonialist movement in France. The number of victims under the French concession system in Ubangi-Shari and other parts of French Equatorial Africa remains unknown. Adam Hochschild estimates a population decrease of half in the French Congo and Gabon, similar to his estimate of the population decline in the Congo Free State.\nIn French Equatorial Africa, the French authorities long tolerated indigenous slavery, but finally acted against the slave trade of the Sultan of Dar Kuti in 1908, and took action against his slave raids in 1911, declaring the slaves in Dar al Kuti free and annexing the territory in 1912. \nDuring the late 1920s and early 1930s an anti-colonial movement \"Soci\u00e9t\u00e9 Amicale des Originaires de l'A.E.F.\" was established by Andr\u00e9 Matsoua, seeking French citizenship for the territory's inhabitants.\nDuring World War II, French Cameroun and the entirety of the AEF except for Gabon rallied to the Free French Forces in August 1940, Gabon instead remained loyal to Vichy France until 12 November 1940 when the Vichy administration withdrew following the Battle of Gabon. The federation became the strategic centre of Free French activities in Africa. F\u00e9lix Ebou\u00e9 was installed as Governor-General of AEF. A separate administrative structure was established under the auspices of Free French Africa grouping both AEF and Cameroun.\nUnder the Fourth Republic (1946\u201358), the federation was represented in the French parliament. When the territories voted in the September 1958 referendum to become autonomous within the French Community, the federation was dissolved. In 1959 the new republics formed an interim association called the Union of Central African Republics, before becoming fully independent in August 1960.\nAdministration.\nFrench Equatorial Africa began with the concept of association, which was implemented through treaties promising French protection by the Italian-French explorer Pierre Savorgnan de Brazza during the mid-1800s, who convinced indigenous communities to cooperate with the French in exchange for greater trade opportunities. This association eventually led to French indirect rule in the region. However, France's attempts at indirect rule faced consistent resistance from local leaders.\nThe AEF was perceived by France as an unstable colony. Therefore, France granted private companies contracts for the exploitation of natural resources like ivory and rubber, rather than sustainable investment. Private companies implemented heavy taxation with little to no pay and cruel treatment towards workers and the local communities.\nIn 1908 French Equatorial Africa was divided into four colonies in hopes of strengthening French authority within the region. Until 1934, French Equatorial Africa was a federation of French colonies like French West Africa. That year, however, the AEF became a unitary entity, its constituent colonies becoming known as regions, and later became known as territories in 1937. There was a single budget for the unified colony; prior to unification, each member had had its own finances. \nAs of 1942, the AEF was administered by a governor-general, who had \"the supreme direction of all services, both civil and military.\" However, the difference in numbers between administrators and the local populace made it difficult for the French to exercise power outside of their headquarters without voluntary or involuntary indigenous cooperation. Additionally, the governor-general's power was limited in practice by France's centralizing colonial policy. \"Most important legislation is enacted in Paris,\" wrote the authors of the 1942 British naval intelligence handbook for the colony, \"whilst the governor-general fills in minor details and penalties.\" The governor-general was assisted by a consultative council of administration (\"Conseil d'Administration\") composed of important local officials and some members, both African and European, elected indirectly. All major administration positions were appointed by French government and were not accountable to officials elected by the African people. Additionally, France held complete control over diplomacy, defense, and politics.\nUnder the unified colony, three of the constituent territories, Chad, Gabon, and Ubangi-Shari, were administered by a governor, while Moyen-Congo was under the purview of the governor-general. Each had a council of local interests (\"Conseil des Int\u00e9r\u00eats Locaux\") similar to the council of administration. Locally, the territories were subdivided into \"d\u00e9partements\" and subdivisions overseen by appointed officials. The only municipalities were the capitals of the territories, which were classified as \"communes mixtes\" as opposed to Senegal's \"communes de plein exercice\", which had democratically elected councils. Although these municipalities possessed certain powers of local self-government, their mayors and councils\u2014which included African representatives\u2014were appointed.\nGeography.\nAccounting for a little less than an eighth of Africa, across modern day Central African Republic, Republic of Chad, Republic of the Congo, Republic of Gabon, and most of Cameroon, the greater part of French Equatorial Africa extended over a granite plateau, framed by the Tibesti, Ouada\u00ef, and Fertit massifs to the northeast, Darfur to the east and the Crystal mountains and Mayombe in the southwest. Two basins occupied the central and southern parts of the territory: the basin of Chad, a former inland sea of which Lake Chad is a remnant, and the basin of Congo, traversed by the river of the same name and its main tributaries (Oubangui River, Sangha River, and Alima River). A coastal plain stretched from mainland Spanish Guinea (now Equatorial Guinea) to the Congo River. The highest point in French Equatorial Africa was Mount Emi Koussi (3,415 meters) in Tibesti.\nDue to the very size of the territory, the climate varied extremely from one point to another, going from a particularly arid Saharan climate in the north to a humid tropical climate in the southern part. The vegetation was affected by these differences: in the north, the virtual absence of rain made it nearly impossible for vegetation to develop, apart from a few thorny shrubs; in the center lay the domain of the savannahs, where millet, peanuts and cassava were grown; finally to the south were the humid tropical forests, from which various species such as ebony and okoum\u00e9 were taken. In the coastal regions, vanilla, cocoa and coffee trees were grown. \nFrench Equatorial Africa was bounded by British Nigeria, French West Africa, Italian Libya, Anglo-Egyptian Sudan and the Belgian Congo. To the west, it bordered the Atlantic Ocean.\nTerritories:\nPostage stamps.\nThe postal administrations of the four territories were separate until 1936, each issuing its own stamps. In that year, stamps of Gabon and Middle Congo were overprinted . A definitive series for the colony followed in 1937, featuring local scenes and key French figures in the formation of the colony, with various color and value changes each year through 1940.\nThe 1937 series was overprinted or just in 1940 by the Free French, and in 1941 they issued a series depicting a phoenix rising from the flames.\nA new definitive series, featuring local scenery and people, was issued in 1946, and another twenty-odd stamps came out during the 1950s, with the last being the omnibus Human Rights issue on 10 December 1958.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52896", "revid": "1066131495", "url": "https://en.wikipedia.org/wiki?curid=52896", "title": "Partitions of unity", "text": ""}
{"id": "52897", "revid": "46264695", "url": "https://en.wikipedia.org/wiki?curid=52897", "title": "Stone\u2013\u010cech compactification", "text": "Concept in topology\nAn important problem in topology is how to enlarge a space by adding \"ideal points\" so that certain kinds of limits exist. The Stone\u2013\u010cech compactification of a space provides the most extensive such enlargement: it adds enough ideal points to ensure the existence of all generalized limits, including those detected by nets or ultrafilters rather than ordinary sequences.\nFor a topological space \"X\", its Stone\u2013\u010cech compactification is a compact space \u03b2X containing \"X\" as a dense subspace together with all the ideal points needed to obtain these limits. A key property of \"\u03b2X\" is that every \"bounded\" continuous function on \"X\" extends uniquely to a continuous function on \"\u03b2X\", and this universal extension property characterizes the Stone\u2013\u010cech compactification. In this way, bounded continuous functions on \"X\" correspond naturally to continuous functions on a compact Hausdorff space \"\u03b2X\". The Stone\u2013\u010cech compactification appears implicitly in a paper by Andrey Nikolayevich Tychonoff\u00a0(1930) and was described explicitly by Marshall Stone\u00a0(1937) and Eduard \u010cech\u00a0(1937).\nFor many relatively simple spaces, such as infinite discrete spaces, no (constructive) concrete description of \"\u03b2X\" is possible. The existence of the Stone\u2013\u010cech compactification in full generality requires a form of the axiom of choice.\nHistory.\nAndrey Nikolayevich Tikhonov introduced completely regular spaces in 1930 in order to avoid the pathological situation of Hausdorff spaces whose only continuous real-valued functions are constant maps.\nIn the same 1930 article where Tychonoff defined completely regular spaces, he also proved that every Tychonoff space (i.e. Hausdorff completely regular space) has a Hausdorff compactification (in this same article, he also proved Tychonoff's theorem). \nIn 1937, \u010cech extended Tychonoff's technique and introduced the notation \"\u03b2X\" for this compactification. \nStone also constructed \"\u03b2X\" in a 1937 article, although using a very different method. \nDespite Tychonoff's article being the first work on the subject of the Stone\u2013\u010cech compactification and despite Tychonoff's article being referenced by both Stone and \u010cech, Tychonoff's name is rarely associated with \"\u03b2X\".\nUniversal property and functoriality.\nThe Stone\u2013\u010cech compactification of the topological space \"X\" is a compact Hausdorff space \"\u03b2X\" together with a continuous map \"iX\" : \"X\" \u2192 \"\u03b2X\" that has the following universal property: any continuous map \"f\" : \"X\" \u2192 \"K\", where \"K\" is a compact Hausdorff space, extends uniquely to a continuous map \"\u03b2f\" : \"\u03b2X\" \u2192 \"K\", i.e. (\"\u03b2f\")\"iX\" = \"f\".\nAs is usual for universal properties, this universal property characterizes \"\u03b2X\" up to homeomorphism.\nAs is outlined in , below, one can prove (using the axiom of choice) that such a Stone\u2013\u010cech compactification \"iX\" : \"X\" \u2192 \"\u03b2X\" exists for every topological space \"X\". Furthermore, the image \"iX\"(\"X\") is dense in \"\u03b2X\".\nSome authors add the assumption that the starting space \"X\" be Tychonoff (or even locally compact Hausdorff), for the following reasons:\nThe Stone\u2013\u010cech construction can be performed for more general spaces \"X\", but in that case the map \"X\" \u2192 \"\u03b2X\" need not be a homeomorphism to the image of \"X\" (and sometimes is not even injective).\nAs is usual for universal constructions like this, the extension property makes \"\u03b2\" a functor from Top (the category of topological spaces) to CHaus (the category of compact Hausdorff spaces). Further, if we let \"U\" be the inclusion functor from CHaus into Top, maps from \"\u03b2X\" to \"K\" (for \"K\" in CHaus) correspond bijectively to maps from \"X\" to \"UK\" (by considering their restriction to \"X\" and using the universal property of \"\u03b2X\"). i.e. \nHom(\"\u03b2X\", \"K\") \u2245 Hom(\"X\", \"UK\"), \nwhich means that \"\u03b2\" is left adjoint to \"U\". This implies that CHaus is a reflective subcategory of Top with reflector \"\u03b2\".\nExamples.\nIf \"X\" is a compact Hausdorff space, then it coincides with its Stone\u2013\u010cech compactification.\nThe Stone\u2013\u010cech compactification of the first uncountable ordinal formula_1, with the order topology, is the ordinal formula_2. The Stone\u2013\u010cech compactification of the deleted Tychonoff plank is the Tychonoff plank. These examples do not require the axiom of choice.\nConstructions.\nConstruction using products.\nOne attempt to construct the Stone\u2013\u010cech compactification of \"X\" is to take the closure of the image of \"X\" in\nformula_3\nwhere the product is over all maps from \"X\" to compact Hausdorff spaces \"K\" (or, equivalently, the image of \"X\" by the right Kan extension of the identity functor of the category \"CHaus\" of compact Hausdorff spaces along the inclusion functor of \"CHaus\" into the category \"Top\" of general topological spaces). By Tychonoff's theorem this product of compact spaces is compact, and the closure of \"X\" in this space is therefore also compact. This works intuitively but fails for the technical reason that the collection of all such maps is a proper class rather than a set. There are several ways to modify this idea to make it work; for example, one can restrict the compact Hausdorff spaces \"K\" to have underlying set \"P\"(\"P\"(\"X\")) (the power set of the power set of \"X\"), which is sufficiently large that it has cardinality at least equal to that of every compact Hausdorff space to which \"X\" can be mapped with dense image.\nConstruction using the unit interval.\nOne way of constructing \"\u03b2X\" is to let \"C\" be the set of all continuous functions from \"X\" into [0, 1] and consider the map formula_4 where \nformula_5\nThis may be seen to be a continuous map onto its image, if [0, 1]\"C\" is given the product topology. By Tychonoff's theorem we have that [0, 1]\"C\" is compact since [0, 1] is. Consequently, the closure of \"X\" in [0, 1]\"C\" is a compactification of \"X\".\nIn fact, this closure is the Stone\u2013\u010cech compactification. To verify this, we just need to verify that the closure satisfies the appropriate universal property. We do this first for \"K\" = [0, 1], where the desired extension of \"f\" : \"X\" \u2192 [0, 1] is just the projection onto the \"f\" coordinate in [0, 1]\"C\". In order to then get this for general compact Hausdorff \"K\" we use the above to note that \"K\" can be embedded in some cube, extend each of the coordinate functions and then take the product of these extensions.\nThe special property of the unit interval needed for this construction to work is that it is a \"cogenerator\" of the category of compact Hausdorff spaces: this means that if \"A\" and \"B\" are compact Hausdorff spaces, and \"f\" and \"g\" are distinct maps from \"A\" to \"B\", then there is a map \"h\" : \"B\" \u2192 [0, 1] such that \"hf\" and \"hg\" are distinct. Any other cogenerator (or cogenerating set) can be used in this construction.\nConstruction using ultrafilters.\nAlternatively, if X is discrete, then it is possible to construct formula_6 as the set of all ultrafilters on X, with the elements of X corresponding to the principal ultrafilters. The topology on the set of ultrafilters, known as the , is generated by sets of the form formula_7 for U a subset of X.\nAgain we verify the universal property: For formula_8 with K compact Hausdorff and F an ultrafilter on X we have an ultrafilter base formula_9 on K, the pushforward of F. This has a unique limit because K is compact Hausdorff, say x, and we define formula_10 This may be verified to be a continuous extension of f.\nEquivalently, one can take the Stone space of the complete Boolean algebra of all subsets of X as the Stone\u2013\u010cech compactification. This is really the same construction, as the Stone space of this Boolean algebra is the set of ultrafilters (or equivalently prime ideals, or homomorphisms to the 2-element Boolean algebra) of the Boolean algebra, which is the same as the set of ultrafilters on X.\nThe construction can be generalized to arbitrary Tychonoff spaces by using maximal filters of zero sets instead of ultrafilters. (Filters of closed sets suffice if the space is normal.)\nConstruction using C*-algebras.\nThe Stone\u2013\u010cech compactification is naturally homeomorphic to the spectrum of Cb(\"X\"). Here Cb(\"X\") denotes the C*-algebra of all continuous bounded complex-valued functions on \"X\" with sup-norm. Notice that Cb(\"X\") is canonically isomorphic to the multiplier algebra of C0(\"X\").\nThe Stone\u2013\u010cech compactification of the natural numbers.\nIn the case where \"X\" is locally compact, e.g. N or R, the image of \"X\" forms an open subset of \"\u03b2X\", or indeed of any compactification, (this is also a necessary condition, as an open subset of a compact Hausdorff space is locally compact). In this case one often studies the remainder of the space, \"\u03b2X\" &amp;setminus; \"X\". This is a closed subset of \"\u03b2X\", and so is compact. We consider N with its discrete topology and write \"\u03b2\"N &amp;setminus; N \n N* (but this does not appear to be standard notation for general \"X\").\nAs explained above, one can view \"\u03b2\"N as the set of ultrafilters on N, with the topology generated by sets of the form formula_7 for \"U\" a subset of N. The set N corresponds to the set of principal ultrafilters, and the set N* to the set of free ultrafilters.\nThe study of \"\u03b2\"N, and in particular N*, is a major area of modern set-theoretic topology. The major results motivating this are Parovicenko's theorems, essentially characterising its behaviour under the assumption of the continuum hypothesis.\nThese state:\nThese were originally proved by considering Boolean algebras and applying Stone duality.\nJan van Mill has described \"\u03b2N as a \"three headed monster\"\u2014the three heads being a smiling and friendly head (the behaviour under the assumption of the continuum hypothesis), the ugly head of independence which constantly tries to confuse you (determining what behaviour is possible in different models of set theory), and the third head is the smallest of all (what you can prove about it in ZFC). It has relatively recently been observed that this characterisation isn't quite right\u2014there is in fact a fourth head of \"\u03b2N, in which forcing axioms and Ramsey type axioms give properties of \"\u03b2\"N almost diametrically opposed to those under the continuum hypothesis, giving very few maps from N* indeed. Examples of these axioms include the combination of Martin's axiom and the Open colouring axiom which, for example, prove that (N*)2 \u2260 N*, while the continuum hypothesis implies the opposite.\nAn application: the dual space of the space of bounded sequences of reals.\nThe Stone\u2013\u010cech compactification \"\u03b2\"N can be used to characterize formula_13 (the Banach space of all bounded sequences in the scalar field R or C, with supremum norm) and its dual space.\nGiven a bounded sequence formula_14 there exists a closed ball \"B\" in the scalar field that contains the image of a. a is then a function from N to \"B\". Since N is discrete and \"B\" is compact and Hausdorff, \"a\" is continuous. According to the universal property, there exists a unique extension \"\u03b2a\" : \"\u03b2\"N \u2192 \"B\". This extension does not depend on the ball \"B\" we consider.\nWe have defined an extension map from the space of bounded scalar valued sequences to the space of continuous functions over \"\u03b2\"N.\nformula_15\nThis map is bijective since every function in \"C\"(\"\u03b2\"N) must be bounded and can then be restricted to a bounded scalar sequence.\nIf we further consider both spaces with the sup norm the extension map becomes an isometry. Indeed, if in the construction above we take the smallest possible ball \"B\", we see that the sup norm of the extended sequence does not grow (although the image of the extended function can be bigger).\nThus, formula_13 can be identified with \"C\"(\"\u03b2N). This allows us to use the Riesz representation theorem and find that the dual space of formula_13 can be identified with the space of finite Borel measures on \"\u03b2N.\nFinally, it should be noticed that this technique generalizes to the \"L\"\u221e space of an arbitrary measure space \"X\". However, instead of simply considering the space \"\u03b2X\" of ultrafilters on \"X\", the right way to generalize this construction is to consider the Stone space \"Y\" of the measure algebra of \"X\": the spaces \"C\"(\"Y\") and \"L\"\u221e(\"X\") are isomorphic as C*-algebras as long as \"X\" satisfies a reasonable finiteness condition (that any set of positive measure contains a subset of finite positive measure).\nA monoid operation on the Stone\u2013\u010cech compactification of the naturals.\nThe natural numbers form a monoid under addition. It turns out that this operation can be extended (generally in more than one way, but uniquely under a further condition) to \"\u03b2\"N, turning this space also into a monoid, though rather surprisingly a non-commutative one.\nFor any subset, \"A\", of N and a positive integer \"n\" in N, we define\nformula_18\nGiven two ultrafilters \"F\" and \"G\" on N, we define their sum by \nformula_19\nit can be checked that this is again an ultrafilter, and that the operation + is associative (but not commutative) on \u03b2N and extends the addition on N; 0 serves as a neutral element for the operation + on \"\u03b2\"N. The operation is also right-continuous, in the sense that for every ultrafilter \"F\", the map\nformula_20\nis continuous.\nMore generally, if \"S\" is a semigroup with the discrete topology, the operation of \"S\" can be extended to \"\u03b2S\", getting a right-continuous associative operation.\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52898", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=52898", "title": "Completely regular space", "text": ""}
{"id": "52900", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=52900", "title": "Spread betting", "text": "Type of wagering where the pay-off is based on the accuracy of the wager\nSpread betting is any of various types of wagering on the outcome of an event where the pay-off is based on the accuracy of the wager, rather than a simple \"win or lose\" outcome, such as fixed-odds (or money-line) betting or parimutuel betting.\nA point spread is a range of outcomes and the bet is whether the outcome will be above or below the spread. As of 2006[ [update]], spread betting was a major growth market in the UK, with the number of gamblers heading towards one million. Financial spread betting (see below) can carry a high level of risk if there is no \"stop\". In the UK, financial spread betting is regulated by the Financial Conduct Authority rather than the Gambling Commission who regulate spread betting on sports.\nPurpose.\nThe general purpose of spread betting is to create an active market for both sides of a binary wager, even if the outcome of an event may appear \"prima facie\" to be biased towards one side or the other. In sports, almost every contest has a \"favorite\" and an \"underdog\", most obviously when a historically strong team is playing a weaker team. If the wager is simply \"Will the favorite win?\", more bets are likely to be made for the favorite, possibly to such an extent that there would be very few betters willing to take the underdog.\nThe point spread is essentially a handicap towards the underdog. The wager becomes \"Will the favorite win by more than the point spread?\" The point spread can be moved to any level to create an equal number of participants on each side of the wager. This allows a bookmaker to act as a market maker by accepting wagers on both sides of the spread. The bookmaker charges a commission, or \"vigorish\", and acts as the counterparty for each participant. As long as the total amount wagered on each side is roughly equal, the bookmaker is unconcerned with the actual outcome; profits instead come from the commissions.\nBecause the spread is intended to create an equal number of wagers on either side, the implied probability is 50% for both sides of the wager. To profit, the bookmaker must pay one side (or both sides) less than this notional amount. In practice, spreads may be perceived as slightly favoring one side, and bookmakers often revise their odds to manage their event risk.\nOne important assumption is that to be credited with a win, either team only needs to win by the minimum of the rules of the game (\"i.e.\", 1 point), without regard to the margin of victory. This presumes that winning teams never unnecessarily extend a winning margin\u2014and losing teams never uselessly narrow an inevitable loss. In other words, each team is only playing to win rather than to beat the point spread.\nThis assumption does not necessarily hold in all situations. For example, at the end of a season, the total points scored by a team can affect future events such as playoff seeding and positioning for the amateur draft; winning teams may \"run up\" the score, and losing teams may bench their starters in favor of developing less-experienced players for the future. \nIn virtually all sports, players and other on-field contributors are forbidden from being involved in sports betting and thus have no incentive to consider the point spread during play; any attempt to manipulate the outcome of a game for gambling purposes would be considered match fixing. The lack of tolerance for athletes and coaching staff engaging in this practice is so serious that the penalty is typically a lifetime banishment from the sport.\nSpreads in sports wagering (U.S.).\nSpread betting was invented by Charles K. McNeil, a mathematics teacher from Connecticut who became a bookmaker in Chicago in the 1940s. In North America, the gambler usually wagers that the difference between the scores of two teams will be less than or greater than the value specified by the bookmaker, with even money for either option. An example:\nSpreads are frequently, though not always, specified in half-point fractions to eliminate the possibility of a tie, known as a \"push\". In the event of a push, the game is considered \"no action\", and no money is won or lost. However, this is not a desirable outcome for the sports book, as they are forced to refund every bet, and although both the book and its bettors will be even, if the cost of overhead is taken into account, the book has actually lost money by taking bets on the event. Sports books are generally permitted to state \"ties win\" or \"ties lose\" to avoid the necessity of refunding every bet.\nBetting on sporting events has long been the most popular form of spread betting. Whilst most bets the casino offers to players have a built in house edge, betting on the spread offers an opportunity for the astute gambler. When a casino accepts a spread bet, it gives the player the odds of 10 to 11, or -110. That means that for every 11 dollars the player wagers, the player will win 10, slightly lower than an even money bet. If team A is playing team B, the casino is not concerned with who wins the game; they are only concerned with taking an equal amount of money of both sides. For example, if one player takes team A and the other takes team B and each wager $110 to win $100, it doesn't matter what team wins; the casino makes money. They take $100 of the $110 from the losing bet and pay the winner, keeping the extra $10 for themselves. This is the house edge. The goal of the casino is to set a line that encourages an equal amount of action on both sides, thereby guaranteeing a profit. This also explains how money can be made by the astute gambler. If casinos set lines to encourage an equal amount of money on both sides, it sets them based on the public perception of the team, not necessarily the real strength of the teams. Many things can affect public perception, which moves the line away from what the real line should be. This gap between the Vegas line, the real line, and differences between other sports books betting lines and spreads is where value can be found.\nA \"teaser\" is a bet that alters the spread in the gambler's favor by a predetermined margin \u2013 in American football the teaser margin is often six points. For example, if the line is 3.5 points and bettors want to place a teaser bet on the underdog, they take 9.5 points instead; a teaser bet on the favorite would mean that the gambler takes 2.5 points instead of having to give the 3.5. In return for the additional points, the payout if the gambler wins is less than even money, or the gambler must wager on more than one event and both events must win. In this way it is very similar to a parlay. At some establishments, the \"reverse teaser\" also exists, which alters the spread against the gambler, who gets paid at more than evens if the bet wins.\nSports spread betting.\nIn the United Kingdom, sports spread betting became popular in the late 1980s by offering an alternative form of sports wagering to traditional fixed odds, or fixed-risk, betting. With fixed odds betting, a gambler places a fixed-risk stake on stated fractional or decimal odds on the outcome of a sporting event that would give a known return for that outcome occurring or a known loss if that outcome doesn't occur (the initial stake). With sports spread betting, gamblers are instead betting on whether a specified outcome in a sports event will end up being above or below a \u2018spread\u2019 offered by a sports spread betting firm, with profits or losses determined by how much above or below the spread the final outcome finishes at.\nThe spread on offer will refer to the betting firm's prediction on the range of a final outcome for a particular occurrence in a sports event, e.g., the total number of goals to be scored in a football (US: soccer) match, the number of runs to be scored by a team in a cricket match or the number of lengths between the winner and second-placed finisher in a horse race.\nThe gambler can elect to \u2018buy\u2019 or \u2018sell\u2019 on the spread depending on whether they think the final outcome will be higher than the top end of the spread on offer, or lower than the bottom end of the spread. The more right the gambler is then the more they will win, but the more wrong the byy are then the more they can lose.\nThe level of the gambler's profit or loss will be determined by the stake size selected for the bet, multiplied by the number of unit points above or below the gambler's bet level. This reflects the fundamental difference between sports spread betting and fixed odds sports betting in that both the level of winnings and level of losses are not fixed and can end up being many multiples of the original stake size selected.\nFor example, in a cricket match a sports spread betting firm may list the spread of a team's predicted runs at 340 \u2013 350. The gambler can elect to \u2018buy\u2019 at 350 if they think the team will score more than 350 runs in total, or sell at 340 if they think the team will score less than 340. If the gambler elects to buy at 350 and the team scores 400 runs in total, the gambler will have won 50 unit points multiplied by their initial stake. But if the team only scores 300 runs then the gambler will have lost 50 unit points multiplied by their initial stake.\nIt is important to note the difference between spreads in sports wagering in the U.S. and sports spread betting in the UK. In the U.S. betting on the spread is effectively still a fixed risk bet on a line offered by the bookmaker with a known return if the gambler correctly bets with either the underdog or the favourite on the line offered and a known loss if the gambler incorrectly bets on the line. In the UK betting above or below the spread does not have a known final profit or loss, with these figures determined by the number of unit points the level of the final outcome ends up being either above or below the spread, multiplied by the stake chosen by the gambler.\nFor UK spread betting firms, any final outcome that finishes in the middle of the spread will result in profits from both sides of the book as both buyers and sellers will have ended up making unit point losses. So in the example above, if the cricket team ended up scoring 345 runs both buyers at 350 and sellers at 340 would have ended up with losses of five unit points multiplied by their stake.\nBets on the total (over/under).\nIn addition to the spread bet, a very common \"side bet\" on an event is the \"total\" (commonly called the \"over/under\" or \"O/U\") bet. This is a bet on the total number of points scored by both teams. Suppose team A is playing team B and the total is set at 44.5 points. If the final score is team A 24, team B 17, the total is 41 and bettors who took the \"under\" will win. If the final score is team A 30, team B 31, the total is 61 and bettors who took the \"over\" will win. The total is popular because it allows gamblers to bet on their overall perception of the game (e.g., a high-scoring offensive show or a defensive battle) without needing to pick the actual winner.\nIn the UK, these bets are sometimes called spread bets, but rather than a simple win/loss, the bet pays more or less depending on how far from the spread the final result is.\nExample: In a football match the bookmaker believes that 12 or 13 corners will occur, thus the spread is set at 12\u201313.\nIn North American sports betting many of these wagers would be classified as \"over-under\" (or, more commonly today, \"total\") bets rather than spread bets. However, these are for one side or another of a total only, and do not increase the amount won or lost as the actual moves away from the bookmaker's prediction. Instead, over-under or total bets are handled much like \"point-spread\" bets on a team, with the usual 10/11 (4.55%) commission applied. Many Nevada sports books allow these bets in parlays, just like team point spread bets. This makes it possible to bet, for instance, \"team A and the over\", and be paid if \"both\" \n team A \"covers\" the point spread (wins by that amount or more) \n\"and\" \n the total score is higher than the book's prediction.\nMathematics.\nThe mathematical analysis of spreads and spread betting is a large and growing subject. For example, sports that have simple 1-point scoring systems (\"e.g.,\" baseball, hockey, and soccer) may be analysed using Poisson and Skellam statistics.\nFinancial spread betting.\nBy far the largest part of the official market in the UK concerns financial instruments; the leading spread-betting companies make most of their revenues from financial markets, their sports operations being much less significant. Financial spread betting in the United Kingdom closely resembles the futures and options markets, the major differences being\nFinancial spread betting is a way to speculate on financial markets in the same way as trading a number of derivatives. In particular, the financial derivative contract for difference (CFD) mirrors the spread bet in many ways. In fact, a number of offer both financial spread bets and CFDs in parallel using the same trading platform.\nUnlike fixed-odds betting, the amount won or lost can be unlimited as there is no single stake to limit any loss. However, it is usually possible to negotiate limits with the bookmaker:\nSpread betting has moved outside the ambit of sport and financial markets (that is, those dealing solely with share, bonds and derivatives), to cover a wide range of markets, such as house prices. \nTax treatment.\nIn the UK and some other European countries the profit from spread betting is free from tax. The tax authorities of these countries designate financial spread betting as gambling and not investing, meaning it is free from capital gains tax and stamp duty, despite the fact that it is regulated as a financial product by the Financial Conduct Authority in the UK. Most traders are also not liable for income tax unless they rely solely on their profits from financial spread betting to support themselves. The popularity of financial spread betting in the UK and some other European countries, compared to trading other speculative financial instruments such as CFDs and futures is partly due to this tax advantage. However, this also means any losses cannot be offset against future earnings for tax calculations.\nConversely, in most other countries financial spread betting income is considered taxable. For example, the Australian Taxation Office issued a decision in March 2010 saying \"Yes, the gains from financial spread betting are assessable income under section 6-5 or section 15-15 of the ITAA 1997\". Similarly, any losses on the spread betting contracts are deductible. This has resulted in a much lower interest in financial spread betting in those countries.\nFinancial spread bet example.\nSuppose Lloyds Bank is trading on the market at 410p bid, and 411p offer. A spread-betting company is also offering 410-411p. We use cash bets with no definite expiry, or \"rolling daily bets\" as they are referred to by the spread betting companies.\nIf I think the share price is going to go up, I might bet \u00a310 a point (\"i.e.,\" \u00a310 per penny the shares moves) at 411p. We use the offer price since I am \"buying\" the share (betting on its increase). Note that my total loss (if Lloyds Bank went to 0p) could be up to \u00a34110, so this is as risky as buying 1000 of the shares normally.\nIf a bet goes overnight, the bettor is charged a financing cost (or receives it, if the bettor is shorting the stock). This might be set at LIBOR + a certain percentage, usually around 2-3%.\nThus, in the example, if Lloyds Bank are trading at 411p, then for every day I keep the bet open I am charged [taking finance cost to be 7%] ((411p x 10) * 7% / 365 ) = \u00a30.78821 (or 78.8p)\nOn top of this, the bettor needs an amount as collateral in the spread-betting account to cover potential losses. Usually this is either 5 or 10% of the total exposure you are taking on but can go up to 100% on illiquid stocks. In this case \u00a34110 * 0.1 or 0.05 = \u00a3411.00 or \u00a3205.50\nIf at the end of the bet Lloyds Bank traded at 400-401p, I need to cover that \u00a34110 \u2013 \u00a3400*10 (\u00a34000) = \u00a3110 difference by putting extra deposit (or collateral) into the account.\nThe punter usually receives all dividends and other corporate adjustments in the financing charge each night. For example, suppose Lloyds Bank goes ex-dividend with dividend of 23.5p. The bettor receives that amount. The exact amount received varies depending on the rules and policies of the spread betting company, and the taxes that are normally charged in the home tax country of the shares.\nHigh of day (the highest price the market traded at for the day).\nA trader who does not hold positions overnight, opening and closing positions within the same trading day.\nLow of day (the lowest price the market traded at for the day).\nThe time when markets subtly change direction between 12:15 and 13:15 GMT with a regularity that is more than coincidental.\nThe time of day that is governed mostly by the regional stock markets. Times vary from broker to broker, but the following are typical: Asian session (22:30 to 08:45 GMT), European session (06:45 to 16:45 GMT), US session (13:00 to 21:30 GMT).\nThe difference between the ask and bid prices, which may vary between markets and between brokers substantially.\nDangers of financial spread betting.\nAccording to an article in \"The Times\" dated 10 April 2009, approximately 30,000 spread bet accounts were opened in the previous year, and that the largest study of gambling in the UK on behalf of the Gambling Commission found that serious problems developed in almost 15% of spread betters compared to 1% of other gambling. A report from Cass Business School found that only 1 in 5 gamblers ends up a winner. As noted in the report, this corresponds to the same ratio of successful gamblers in regular trading. Evidence from spread betting firms through an analysis of their risk warnings in October 2024 actually put this closer to being 2 in 10 traders as being profitable.\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nNotes.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52901", "revid": "5062955", "url": "https://en.wikipedia.org/wiki?curid=52901", "title": "Brahma Creator God", "text": ""}
{"id": "52902", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=52902", "title": "Marvel comic", "text": ""}
{"id": "52903", "revid": "966401327", "url": "https://en.wikipedia.org/wiki?curid=52903", "title": "Injective", "text": ""}
{"id": "52904", "revid": "9182658", "url": "https://en.wikipedia.org/wiki?curid=52904", "title": "Israel Putnam", "text": "American military officer and landowner (1718\u20131790)\nIsrael Putnam (January 7, 1718 \u2013 May 29, 1790), popularly known as \"Old Put\", was an American military officer and landowner who served in the French and Indian War and American Revolutionary War. He was an officer in Rogers' Rangers during the French and Indian War, during which Putnam was captured by Mohawk warriors. He was saved from the ritual burning given to enemies by the intervention of French officer Molang, with whom the Mohawks were allied. Putnam's exploits became known far beyond his home of Connecticut's borders through the circulation of folk legends in the American colonies and states celebrating his exploits.\nEarly life.\nPutnam was born in 1718 in Salem Village, Massachusetts (now Danvers) to Joseph and Elizabeth (Porter) Putnam, a prosperous farming Putnam family. His parents had opposed the Salem witch trials in the 1690s.\nPutnam moved west in 1740 at age 22 to Mortlake, Connecticut (today Brooklyn) where land was cheaper. While living in Connecticut, Putnam purchased several Black slaves to work on his lands. He killed a wolf in 1743 with the help of a group of farmers from Mortlake seeking to safeguard their sheep. They tracked the wolf to its den and tried sending in their dogs, but all the dogs returned frightened or injured by the wolf. They tried smoking out the wolf and burning sulfur at the mouth of the cave, all to no avail. After Putnam arrived, he tried getting his dog to enter the den, with no luck. He also tried to get his servant to enter with a torch and gun to shoot the wolf. His servant refused, as did all the other farmers. Putnam then reportedly crawled into the den with a torch, a musket loaded with buckshot, and his feet secured with rope to be quickly pulled out. While in the den, he killed the wolf.\nIn celebration of the event, Putnam was carried in a torch-lit procession through Pomfret in a celebration that lasted until about midnight. He earned the nicknames \"Wolf Putnam\" and \"Old Wolf Put\", which stayed with him for decades afterward. A section of Mashamoquet Brook State Park in Pomfret is named \"Israel Putnam Wolf Den\" where the den was located. The name \"Wolf Den Road\" in adjacent Brooklyn also attests to the days of wolves.\nPutnam married Hannah Pope in 1739, the mother of his children. She died in 1765, and he married Deborah Lothrop two years later.\nEarly military service.\nPutnam was one of the first men in Connecticut in 1755 to sign up to serve as a private in the militia in the French and Indian War at age 37. Over the course of the war, he was promoted to second lieutenant, captain, major, lieutenant colonel, and colonel. He served with Robert Rogers, who gained fame as the commander of Rogers' Rangers, and the two of them had various exploits together, in one of which Putnam saved Rogers' life. Putnam's reputation for courage was made famous by his participation in the war. It was said that \"Rogers always sent, but Putnam led his men to action.\"\nIn 1757, the Rangers were stationed on an island off Fort Edward. The following February, Putnam and his Rangers were still on Roger's Island when fire broke out in the row of barracks nearest the magazine. The danger of an explosion was imminent, but Putnam took a position on the roof and poured bucket after bucket of water upon the flames, only descending when the buildings fell only a few feet from the magazine. In spite of his severe wounds, he continued to fight the fire, dashing water upon the magazine until the fire was under control. He was laid up for a month due to burns and exposure.\nPutnam was captured on August 8, 1758, by Kahnawake Indians from a mission settlement south of Montreal during a military campaign near Crown Point in New York. He was saved from being ritually burned alive by a rainstorm and the last-minute intervention of a French officer.\nIn 1759, Putnam led a regiment into The Valley of Death in the attack on Fort Carillon and he was with the British army that marched on Montreal in 1760. In 1762, he survived a shipwreck during the British expedition against Cuba that led to the capture of Havana. Putnam is believed to have brought back Cuban tobacco seeds to New England, which he planted in the Hartford area. This reportedly resulted in the development of the renowned Connecticut Wrapper. In 1763, during Pontiac's Rebellion, Putnam was sent with reinforcements to relieve Chief Pontiac's siege of Fort Detroit.\nAfter the war, he returned to his homestead, a remnant of which exists today as Putnam Farm in Brooklyn, Connecticut. Putnam publicly professed his Christian faith following the Seven Years' War in 1765 and joined the Congregational Church in his town. He was among those who objected to British tax action policies. Around the time of the Stamp Act crisis in 1766, he was elected to the Connecticut General Assembly and was one of the founders of the state's chapter of the Sons of Liberty. In the fall of 1765, he threatened Governor Thomas Fitch over this issue. He said that Fitch's house \"will be leveled with the dust in five minutes\" if Fitch did not turn over the stamp tax paper to the Sons of Liberty.\nAmerican Revolutionary War.\nBattle of Bunker Hill.\nBy the eve of the American Revolution, Putnam had become a relatively prosperous farmer and tavern keeper, with more than a local reputation for his previous exploits. He received news of the Battles of Lexington and Concord in April 1775 while he was plowing one of his fields with his son. He literally \"came off the plow\", leaving it in the field and riding in eight hours, reaching Cambridge the next day to offer his services to the Patriot cause. He was made a major general, putting him second in rank to General Artemas Ward in the Army of Observation which preceded the founding of the Continental Army.\nPutnam was one of the primary figures at the Battle of Bunker Hill in June 1775, both in its planning and on the battlefield. During the battle, he may have ordered William Prescott to tell his troops, \"Don't fire until you see the whites of their eyes.\" It is debated who said these words first; they are attributed to a number of officers. This command has since become one of the American Revolution's notable quotations. It was given to make the best use of the low ammunition stocks that the troops had.\nIn the planning for the Battle of Bunker Hill, Putnam was likely the one who argued in favor of also fortifying the adjacent hill, which later became known as \"Breed's Hill\". This hill was closer to Boston so that cannons could fire on the British forces in town, forcing them to come out and attack the hill. The British suffered heavy casualties as they marched toward the American fortifications. However, the Americans ran out of powder and were eventually forced to retreat. American casualties were 449, while British casualties were 1,054. By the standard of the day the Americans lost, since they gave up the ground. However, Continental Army Brigadier General Nathanael Greene wrote to his brother that \"I wish we could sell them another hill, at the same price.\"\nYears after the battle, and after Putnam's death, he was accused by Henry Dearborn of failing to supply reinforcements and even of cowardice during the battle. The accusations created a long-standing controversy among veterans, family, friends, and historians. People were shocked by the rancor of the attack, and this prompted a forceful response from defenders of Putnam, including such notables as John and Abigail Adams. Historian Harold Murdock wrote that Dearborn's account \"abounds in absurd misstatements and amazing flights of imagination.\" The Dearborn attack received considerable attention because at the time he was in the middle of controversy himself. He had been relieved of one of the top commands in the War of 1812 due to his mistakes. He had also been nominated to serve as U.S. Secretary of War by President James Monroe, but was rejected by the United States Senate (which was the first time that the Senate had voted against confirming a presidential cabinet choice).\nLong Island and later service.\nThe Continental Congress voted to create the Continental Army on June 14, 1775. They appointed George Washington as Commander-in-Chief, with Putnam and three others appointed as major generals under him. Only the votes for Washington and Putnam were unanimous.\nAfter Bunker Hill, Washington arrived and Putnam served under him in the Siege of Boston. The British were forced to abandon Boston due largely to the efforts of Henry Knox and Putnam's cousin Rufus Putnam in moving 60 tons of artillery from Fort Ticonderoga over 300 miles of snow-covered terrain to Boston. Those cannon, placed on Dorchester Heights, forced the British to sail out of Boston.\nPutnam subsequently served as temporary commander of the American forces in New York while waiting for Washington's arrival there on April 13, 1776. Putnam's fortunes declined at the Battle of Long Island in August 1776, where he was forced to effect a hasty retreat from the British. Some in the Second Continental Congress blamed him for the defeat, but Washington witnessed the battle and did not lay blame on him.\nIt is possible that Putnam's efforts saved Washington's life or prevented his capture. As Senator Daniel Patrick Moynihan described it, \"it could be argued that we owe our national existence to the fortifications which General Israel Putnam threw up in April 1776 on the Buttermilk Channel side [of Governors Island, New York.\" British troops landed on Long Island and headed for Washington and his army. He had to flee, and he made it because Putnam's artillery firing on Brooklyn Heights held Howe back just long enough for Washington to escape to Manhattan.\nPutnam was fooled in October 1777 by a feint executed by British troops under the command of General Henry Clinton, making way for Clinton's capture of Fort Montgomery and Fort Clinton. As was standard procedure, Putnam was relieved of command and brought before a court of inquiry for these losses. The court determined that the loss was the result of a lack of men, not of the fault of any commander, and he was exonerated of any wrongdoing.\nPutnam had personal friendships and deep respect for many of his British former comrades in arms in the French and Indian War, who were now his enemies. While in command in New York, there were several occasions on which he showed personal courtesies, such as providing newspapers to read or medical attention to British officers who had become his prisoners of war. This offended many New Yorkers. He also showed an \"unconquerable aversion\" to many of those who were entrusted with the disposal of Tory property; Putnam felt that they were instead embezzling the funds. This also led to Putnam becoming unpopular with many influential New Yorkers, who complained to Washington.\nWashington had also lost some of his faith in Putnam due to an incident in which Putnam delayed in forwarding troops to Washington when ordered to do so. Washington felt that he could not have Putnam in charge of troops in New York without the support of that state, and transferred him to recruiting duties in Connecticut after the court of inquiry finished its investigation. Putnam was later put in command of the Eastern Division, consisting of three brigades of New Hampshire and Connecticut troops. In 1779, he was put in command of the right wing of the army, which included the Virginia, Maryland, and Pennsylvania divisions.\nDuring the winter of 1778\u20131779, Putnam and his troops were encamped at the site now preserved as the Putnam Memorial State Park in Redding, Connecticut. On February 26, 1779, Putnam escaped from the British, riding down a steep slope in Greenwich, Connecticut for which he became famous. A statue commemorating this escape was erected at Putnam Memorial State Park. In December 1779, Putnam suffered a paralyzing stroke which ended his military service.\nPersonality and characteristics.\nIsrael Putnam did not fit the stereotype of the taciturn New Englander. He was a gregarious tavern-keeper, a very industrious farmer, and an aggressive soldier, always looking for an excuse to discipline his soldiers. His farm was one of the most productive in the area; he bought out his partner and paid off his mortgage after only two years. In battle, he would lead from the front, not from behind. After hours, he would lead his comrades in singing the popular drinking songs of the day.\nPutnam served as Washington's second in command, and the two shared some key characteristics that other general officers of the time did not. Neither of them had as much education as some of their peers, and certainly not as elite as their British counterparts. Putnam's lack of education and unsophisticated manner prompted a captured Hessian officer to comment, \"This old gray-beard may be a good honest man, but nobody but the rebels would have made him a general.\" Some of America's proper Philadelphians agreed. However, the common soldier admired Putnam's courage and could see from his many visible battle scars that he knew what it was like to be on the front lines. They knew that he had achieved his position through first-hand experience, rather than just education or family connections. Historian Nathaniel Philbrick says flatly that \"Israel Putnam was the provincial army's most beloved officer.\"\nPutnam's spelling was a language all its own, yet he still had a way with words. Both Washington and Putnam had to use their powers of persuasion to put down mutinies from their long-suffering, disgruntled troops. Biographer David Humphreys witnessed the Putnam event:\n\"The troops who had been badly fed, badly cloathed and worse paid ... formed the design of marching to Hartford, where the General Assembly was then in session, and of demanding redress at the point of the bayonet. Word having been brought to General Putnam that the second Brigade was under arms for this purpose, he mounted his horse, galloped to the Cantonment and thus addressed them:\n\"'My brave lads, whither are you going? Do you intend to desert your Officers and to invite the enemy to follow you into the country? Whose cause have you been fighting and suffering so long in, is it not your own? Have you no property, no parents, wives or children? You have behaved like men so far \u2013 all the world is full of your praises \u2013 and posterity will stand astonished at your deeds: but not if you spoil all at last. Don't you consider how much the country is distressed by the war, and that your officers have not been any better paid than yourselves? But we all expect better times and that the Country will do us ample justice. Let us all stand by one another then and fight it out like brave Soldiers. Think what a shame it would be for Connecticut men to run away from their officers.'\"\nPutnam's speech worked. After he finished, \"he directed the acting Major of Brigade to give the word for them to shoulder, march to their Regimental parades, and lodge arms. All of which they executed with promptitude and apparent good humor.\"\nAfter hearing of the mutiny, Washington wrote to Putnam commending him for his success in quelling it. Putnam wrote to Washington that the incident had \"not been repeated, or attended with any farther ill consequences.\".\nBoth Washington and Putnam were aggressive by nature and did not hesitate to put themselves in harm's way if that was what was called for in battle. Both were able to function calmly while bullets whizzed around them. Yet, each was nevertheless able to calculate risk and make decisions accordingly. After leading inexperienced men in a successful engagement while being bombarded with cannonballs, Putnam commented, \"I wish we could have something of the kind to do every day; it would teach our men how little danger there is from cannon balls, for though they have sent a great many at us, nobody has been hurt by them.\"\nPutnam has been criticized by historians as having not been a great strategic thinker. He once grew tired of the endless discussion during one of the planning sessions during the siege of Boston with Washington and his senior officers, so he went to the window and started observing the British. Washington invited him back to the planning table, and Putnam responded, \"Oh, my dear General, you may plan the battle to suit yourself, and I will fight it.\"\nHowever, Putnam did have the ability to see both effective battlefield strategy and the big picture. He ordered his men to aim for the British officers, knowing the crippling effect that it would have. He knew the value of inoculating the American troops against small pox, and the tendency of nervous soldiers to fire too soon and aim too high\u2014thus the orders to not fire until \"you see the whites of their eyes\" and to \"take aim at the waistbands\". \nPutnam had a feel for the common soldier and how to make good use of him. He knew that a soldier was not worried about his head, but if his body was protected with earthworks, he would \"fight forever.\" Putnam also understood that a retreat could be a very effective tactic. \"Let me pick my officers, and I would not fear to meet [the enemy] with half the number... I would fight them on the retreat, and every stone wall we passed should be lined with their dead ... our men are lighter of foot, they understand their grounds and how to take advantage of them.\"\nIn some instances, he was more prescient than his fellow generals. Putnam advocated aggressive action against the British in discussion with Joseph Warren and General Artemas Ward before the Battle of Bunker Hill. Ward replied, \"As peace and reconciliation is what we seek for, would it not be better to act only on the defensive and give no unnecessary provocation?\" Putnam turned to Warren and said with emphasis, \"You know, Dr. Warren, we shall have no peace worth anything, till we gain it by the sword.\"\nShortly after Washington took command at Cambridge in 1775, he and the other generals hoped for a speedy resolution of the war. On one occasion with them gathered around his dinner table, Washington offered a toast: \"A speedy and honorable peace.\" A few days later, Putnam offered a different one: \"A long and moderate war.\" The sober and seldom-smiling Washington laughed out loud and replied, \"You are the last man, General Putnam, from whom I should have expected such a toast, you who are always urging vigorous measures, to plead now for a long, and what is still more extraordinary, a moderate, war, seems strange indeed.\" Putnam replied that a false peace would divide Americans and not be long-lasting. \"I expect nothing but a long war, and I would have it a moderate one, that we may hold out till the mother country becomes willing to cast us off forever.\"\nThe Revolutionary War dragged on for eight and a half years, the longest in United States history until the Vietnam War. Washington did not forget Putnam's prescient toast; he more than once reminded Putnam of it.\nBurial.\nPutnam died in Brooklyn, Connecticut in 1790. He was buried in an above-ground tomb in the town's South Cemetery. He is honored with an equestrian monument near his original burial site on Canterbury Road (Route 169).\nOver the years, souvenir hunters removed fragments of the headstone of his tomb. The marble marker eventually became badly mutilated, and the overall condition of the tomb was deemed unsuitable for General Putnam's remains; it was removed for safekeeping to the Connecticut State Capitol in Hartford. Sculptor Karl Gerhardt designed the Soldiers' and Sailors' Monument in Hartford, as well as Civil War monuments in New York and New Jersey, and he was chosen to create a monument to house Putnam's remains. In 1888, Putnam's remains were removed from the Brooklyn cemetery and reinterred in a sarcophagus in the base of that monument, and the original headstone inscription was recreated.\nLegacy, namesakes, and honors.\nPutnam's birthplace in Danvers, Massachusetts is now known as the Putnam House, designated and preserved as a historic structure. His Connecticut farmhouse on Putnam Farm still stands and is listed on the National Register of Historic Places. A statue of Israel Putnam stands in Hartford's Bushnell Park, near the Connecticut State Capitol. It was sculpted by John Quincy Adams Ward in 1873 and presented to the city in 1874.\nNumerous places bear his name, including eight counties, starting with Putnam County, New York, which embraces the east bank of the Hudson Highlands where he once held command. Towns in New York and Connecticut are also named for him. His many namesakes include:\nIn the 1992 film My Cousin Vinny, the protagonist and his paramour stay in the General Putnam Motel in Eatonton, GA.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52906", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=52906", "title": "Brunch", "text": "Meal that combines breakfast and lunch\nBrunch () is a meal, often accompanied by \"signature morning cocktails\" such as mimosas, bloody marys, espresso martinis, and bellinis, taken sometime in the late morning or early afternoon \u2013 some sources mention 11am\u20132pm, though modern brunch often extends as late as 3pm. The meal originated in the British hunt breakfast. The word \"brunch\" is a portmanteau of \"breakfast\" and \"lunch\". The word originated in England in the late 19th century, and became popular in the United States in the 1930s.\nOrigin of the word.\nThe 1896 supplement to the \"Oxford English Dictionary\" cites \"Punch\" magazine, which wrote that the term was coined in Britain in 1895 to describe a Sunday meal for \"Saturday-night carousers\" in the writer Guy Beringer's article \"Brunch: A Plea\" in \"Hunter's Weekly\".\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Instead of England's early Sunday dinner, a postchurch ordeal of heavy meats and savory pies, the author wrote, why not a new meal, served around noon, that starts with tea or coffee, marmalade and other breakfast fixtures before moving along to the heavier fareBy eliminating the need to get up early on Sunday, brunch would make life brighter for Saturday-night carousers. It would promote human happiness in other ways as well.\"Brunch is cheerful, sociable and inciting\", Beringer wrote. \"It is talk-compelling. It puts you in a good temper, it makes you satisfied with yourself and your fellow beings, it sweeps away the worries and cobwebs of the week.\"\u2014\u200a\nDespite the substantially later date it has also been claimed that the term was possibly coined by reporter Frank Ward O'Malley, who wrote in the early 20th century for the New York City newspaper, \"The Sun\" from 1906 until 1919. It is thought that he may have come up with the term after observing the typical mid-day eating habits of his colleagues at the newspaper.\nServing locations.\nColleges and hotels.\nSome colleges and hotels serve brunch, often serve-yourself buffets, although menu-ordered meals may be available as well. The meal usually consists of standard breakfast foods such as eggs, sausages, bacon, ham, fruits, pastries, pancakes, waffles, cereals, and scones.\nMilitary.\nThe United States, Canada and United Kingdom militaries often serve weekend brunch in their messes. They offer breakfast and lunch options, and usually are open from 09:00\u201312:00.\nDim Sum brunch.\nYum cha, a Cantonese dim sum brunch, is popular in Chinese restaurants worldwide. It consists of a variety of stuffed buns, dumplings, and other savory or sweet foods that have been steamed, deep-fried, or baked. Customers select small portions from passing carts, as the kitchen continuously produces and sends out freshly prepared dishes. Dim sum is usually eaten at a mid-morning, midday, or mid-afternoon teatime.\nSpecial occasions.\nBrunch is prepared by restaurants and hotels for special occasions and holidays, such as weddings, Valentine's Day, St. Patrick's Day, Mother's Day, Father's Day, Halloween, Thanksgiving, Christmas, New Year, and Easter. \nIn other languages.\nChinese.\nThe Chinese word \"\u65e9\u5348\u996d\" () is defined as brunch, with \"\u65e9\u996d\" (; \u65e9: morning, \u996d: meal) meaning breakfast; and \"\u5348\u996d\" (; \u5348: noon, \u996d: meal) meaning lunch. The combination of \"\u65e9\u996d\" and \"\u5348\u996d\" is thus \"\u65e9\u5348\u996d\", brunch.\nFrench.\nThe Office qu\u00e9b\u00e9cois de la langue fran\u00e7aise accepts 'brunch' as a valid word but also provides a synonym \"d\u00e9jeuner-buffet\". Note that, however, in Quebec, \"d\u00e9jeuner\" alone (even without the qualifying adjective \"petit\") means 'breakfast'. In Quebec, the word\u2014when francized\u2014is pronounced . The common pronunciation in France is .\nItalian.\nIn Italian, the English loanword 'brunch' is generally used, though the neologism/calque is increasingly popular, being derived from (breakfast) and (lunch). Even less common but occasionally used are and , both derived from the same sources.\nThe usage of these terms varies in Italy, as different regions have different cultural definitions of mealtimes and their names. Traditional usage, particularly in northern Italy, included calling the first meal of the day (first ), and the second meal either or (second ), as distinguished from , the evening meal (now generally used as the term for the midday meal). In this scheme, a separate term for 'brunch' would not be necessary, as could be used as a general term for any meal taken in the morning or early afternoon. Although Italian meal terminologies have generally shifted since widespread use of this naming scheme, the concept of a distinct mid-morning meal combining features of breakfast and lunch is largely one imported from the UK and North America in the last century, so the Anglicism 'brunch' is predominant.\nOther places.\nCanada.\nThe area now known as Leslieville neighbourhood is sometimes called the brunch capital of Toronto, as many renowned establishments serve brunch there. Brunch buffets also exist in other parts of Southern Ontario, including Kitchener-Waterloo.\nIn Canada, brunch is served in private homes and in restaurants. In both cases, brunch typically consists of the same dishes as would be standard in an American brunch, namely, coffee, tea, fruit juices, breakfast foods, including pancakes, waffles, and french toast; meats such as ham, bacon, and sausages; egg dishes such as scrambled eggs, omelettes, and eggs Benedict; bread products, such as toast, bagels or croissants; pastries or cakes, such as cinnamon rolls and coffee cake; and fresh cut fruit or fruit salad. Brunches may also include foods not typically associated with breakfast, such as roasted meats, quiche, soup, smoked salmon, sandwiches, and salads, such as Cobb salad.\nWhen served at home or in a restaurant, a brunch may be offered buffet style, in which trays of foods and beverages are available and guests may serve themselves and select the items they want, often in an \"all-you-can-eat\" fashion. Restaurant brunches may also be served from a menu, in which case guests select specific items that are served by waitstaff. Restaurant brunch meals range from relatively inexpensive brunches available at diners and family restaurants to expensive brunches served at high-end restaurants and bistros.\nPhilippines.\nBrunch in the Philippines is served between 9:00\u00a0am and noon. Contrary to what is observed in other countries, brunch in the afternoon, between 3:00 and 4:00\u00a0pm, is called merienda, a traditional snack carried over from Spanish colonialism.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52907", "revid": "8377723", "url": "https://en.wikipedia.org/wiki?curid=52907", "title": "Nassau County", "text": "Nassau County may refer to:\nSee also.\n&lt;templatestyles src=\"Dmbox/styles.css\" /&gt;\n Topics referred to by the same termThis page lists articles about distinct geographical locations with the same name. "}
{"id": "52908", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=52908", "title": "Manilius", "text": ""}
{"id": "52909", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=52909", "title": "Piet Hein Tunnel", "text": "The Piet Hein Tunnel () is a 1.9\u00a0km long tunnel under the IJ in Amsterdam, the Netherlands. It provides a road link running east\u2013west between the city center and the A10 ring-road, and since May 2005 also provides a tram link between the Amsterdam Centraal railway station and Haveneiland, IJburg. Completed in 1997, the tunnel, approaches and related buildings were designed by the hypermodernist Dutch architectural firm Van Berkel + Bos, and was named after the Dutch naval hero Piet Hein."}
{"id": "52910", "revid": "274535", "url": "https://en.wikipedia.org/wiki?curid=52910", "title": "Zuiderzee", "text": "Former inland sea in the Netherlands, now the IJsselmeer\nThe Zuiderzee or Zuider Zee (; old spelling \"Zuyderzee\" or \"Zuyder Zee\"), historically called Lake Almere and Lake Flevo, was a shallow bay of the North Sea in the northwest of the Netherlands. It extended about inland and at most wide, with an overall depth of about and a coastline of about . It covered . Its name is Dutch for \"southern sea\", indicating that the name originates in Friesland, to the north of the Zuiderzee (cf. North Sea).\nIt is generally acknowledged that the Zuiderzee existed from roughly 1170, following the devastating All Saints' Flood, until 1932, when the Afsluitdijk was completed. The majority of the Zuiderzee was closed off from the North Sea, leaving the mouth of the inlet to become part of the Wadden Sea. The salt water inlet changed into a fresh water lake now called the IJsselmeer (IJssel Lake) after the river that drains into it, and by means of drainage and polders, an area of some was reclaimed as land. This land eventually became the province of Flevoland. Part of the IJsselmeer was also divided into the Markermeer.\nHistory.\nLake Flevo.\nIn classical times the body of water at this location was called Lake Flevo (Flevo Lacus) by Roman authors. This was the central and largest lake in a region filled with a mixture of lowland and freshwater lakes occupying the area later filled by the Zuiderzee. It was separated from the sea by a belt of marsh and fen; at that time, the coastline ran along the line of the Frisian Islands. A number of streams, including the Vecht, Eem, and Ysel, fed into the lake. The lake itself fed out into the North Sea through the Vlie (). It existed in Roman times and the early Middle Ages.\nFrom the Indo-European root \"*plew-\" \"flow\", the name was transmitted by the Roman geographer Pomponius Mela in describing this region. In his treatise on geography of 44 AD, Pomponius speaks of a . He writes: \"The northern branch of the Rhine widens as Lake Flevo, and encloses an island of the same name, and then as a normal river flows to the sea\". Other sources rather speak of Flevum, which could be related to today's Vlie (Vliestroom), i.e. the seaway between the Dutch islands of Vlieland and Terschelling. This last name is grammatically more probable for a geographical indication, which is why it is assumed that Pomponius confused the declension of the word giving the name Flevo. In fact the Vlie formed outfall from the lake into the North Sea.\nIn the second half of the twentieth century the Flevopolders and a new province, Flevoland, took the name of the body of water which lay there long ago.\nOver time these lakes gradually eroded their soft peat shores and spread (a process known as waterwolf). Some part of this area of water was later called the \"Vlie\"; it probably flowed into the sea through what is now the Vliestroom channel between the islands of Vlieland and Terschelling.\nDuring a period of rising sea level between 250 and 600 CE, the connection to the sea and the lake were significantly enlarged. A period of lower sea levels followed.\nAlmere.\nLake Almere is mentioned among others in a life of saints written by Anglo-Saxon Bishop Saint Boniface in 753, and a deed of gift from the town of Urk. Its etymology may be eels, in Dutch or , so: = \"eel lake\". Presumably, the water of Lake Almere at that time was fresh water or slightly brackish. The name of the new town of Almere in Flevoland was given in 1984 in memory of this body of water.\nA number of occurrences during the Middle Ages led to the transformation of the lake to an inland sea that would be called the Zuiderzee, which are:\nThe Marsdiep between Den Helder and Texel was once a river () which may have been a distributary of the Vlie. During the early Middle Ages this began to change as rising sea levels and storms started to eat away at the coastal areas which consisted mainly of peatlands. In this period the inlet was referred to as the Almere, indicating it was still more of a lake, but the mouth and size of the inlet were much widened in the 12th century and especially after the disastrous All Saints' Flood (1170) and subsequent floods broke through the barrier dunes near Texel and The land between Stavoren, Texel, and Medemblik was washed away around 1170. The disaster marked the rise of Amsterdam on the southwestern end of the bay, since traders from the Hanseatic cities could now reach the area.\nZuiderzee.\nThe formation of the Zuiderzee was a gradual process, influenced by several storm surges in 1163/64, 1170, 1173, and especially the Saint Nicholas' Flood of 1196, which completed much of what the earlier floods had set in motion. Human activities \u2013 particularly agriculture and peat extraction \u2013 are regarded as the primary drivers of the change, as they caused land subsidence through peat oxidation and erosion. In the 13th century, additional storm surges (1214, 1219, 1220, 1221, 1246, 1248) further shaped the region, which developed into an extensive tidal-flat area with Texel, Wieringen, Huisduinen, and Callantsoog as islands. Around 1400, the Zuiderzee had reached its full extent, although it was still only two to three meters deep. In the south and east, the devastation was halted by the high sandy shores of the Gooi, the Veluwe, Voorst, and Gaasterland.\nThe size of this inland sea remained largely stable from the 15th century onwards due to improvements in dikes, but when storms pushed North Sea water into the inlet, the Zuiderzee became a volatile cauldron of water, frequently resulting in flooding and the loss of ships. For example, on 18 November 1421, a seawall at the Zuiderzee dike broke, which flooded 72 villages and killed about 10,000 people. This was the Second St. Elizabeth's flood.\nThe process of creating polders had developed to a point by 1667 that the damming of the Zuiderzee was proposed, although a feasible method did not appear until the 20th century.\nThe Netherlands was part of the First French Empire between 1810 and 1813. A d\u00e9partement was formed in 1811 and named as Zuyderz\u00e9e after the Zuiderzee, whose territory roughly corresponded to the present provinces of North Holland and Utrecht.\nIn 1928, the 6-meter and 8-meter \nsailing events for the Amsterdam Summer Olympics were held on the Zuiderzee.\nZuiderzee Works.\nThe construction between 1927 and 1932 of a 19-mile long dam (the Afsluitdijk), under plans originating from Cornelius Lely, enclosed the Zuiderzee. The creation of this dam was hastened by the Flood of January 1916. Plans for closing the Zuiderzee had been made over thirty years earlier but had not yet passed in parliament. With the completion of the Afsluitdijk in 1932, the Zuiderzee became the IJsselmeer, and the outer portion of the Zuiderzee became the Wadden Sea. Large areas of land, mainly for agricultural use, were subsequently reclaimed from the water through the construction of polders with dams, pumping, and other hydrological technology. Four had been built by the early 1980s. They were the Wieringermeer Polder built in 1930; the Northeast (Noordoost) Polder, built in 1942; the East (Oostelijk) Flevoland Polder, built in 1957; and the South (Zuidelijk) Flevoland Polder, completed in 1968. A fifth, Markerwaard, began construction in 1963, and became partially complete, but was abandoned in the mid-1980s. Collectively, this system of dams, dikes, and polders is called the Zuiderzee Works.\nGeography.\nAround the Zuiderzee many fishing villages grew up and several developed into walled towns with extensive trade connections, in particular Kampen, a town in Overijssel, and later also towns in Holland such as Amsterdam, Hoorn, and Enkhuizen. These towns traded at first with ports on the Baltic Sea, in England, and in the Hanseatic League, but later also with the rest of the world when the Netherlands established its colonial empire. When that lucrative trade diminished, most of the towns fell back on fishing and some industry until the 20th century when tourism became the major source of income.\nContained within the Zuiderzee were five small islands, the remains of what were once larger islands, peninsulas connected to the mainland, or in the case of Pampus, an artificial island. These were Wieringen, Urk, Schokland, Pampus and Marken. The inhabitants of these islands also subsisted mainly on fishing and related industries and still do in the case of Urk and Wieringen. All of these islands, except for Pampus, are now part of the mainland or connected to it.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52911", "revid": "51052790", "url": "https://en.wikipedia.org/wiki?curid=52911", "title": "Town", "text": "Type of human settlement\nA town is a type of a human settlement, generally larger than a village but smaller than a city.\nThe criteria for distinguishing a town vary globally, often depending on factors such as population size, economic character, administrative status, or historical significance. In some regions, towns are formally defined by legal charters or government designations, while in others, the term is used informally. Towns typically feature centralized services, infrastructure, and governance, such as municipal authorities, and serve as hubs for commerce, education, and cultural activities within their regions.\nThe concept of a town varies culturally and legally. For example, in the United Kingdom, a town may historically derive its status from a market town designation or royal charter, while in the United States, the term is often loosely applied to incorporated municipalities. In some countries, such as Australia, New Zealand, and Canada, distinctions between towns, cities, and rural areas are based on population thresholds. Globally, towns play diverse roles, ranging from agricultural service centers to suburban communities within metropolitan areas.\nEtymology.\nThe word \"town\" shares an origin with the German word (\"fence\"), the Dutch word (\"garden, yard; fence, enclosure\"), and the Old Norse (\"enclosure, as for a homestead\"). The original Proto-Germanic word, , is thought to be an early borrowing from (cf. Old Irish , Welsh ).\nThe original sense of the word in both Germanic and Celtic was that of a fortress or an enclosure. Cognates of the English word \"town\" in many modern Germanic languages designate a \"fence\" or a \"hedge\". In English and Dutch, the meaning of the word took on the sense of the space which these fences enclosed, and through which a track must run. In England, a \"town\" was a small community that could not afford or was not allowed to build walls or other larger fortifications, and built a palisade or stockade instead. In the Netherlands, this space was a garden, more specifically those of the wealthy, which had a high fence or a wall around them (like the garden of the palace of Het Loo in Apeldoorn, which was the model for the privy garden of William III and Mary II at Hampton Court). In Old Norse means a (grassy) place between farmhouses, and the word is still used with a similar meaning in modern Norwegian.\nOld English became a common place-name suffix in England and southeastern Scotland during the Anglo-Saxon settlement period. In Old English and Early and Middle Scots, the words \"ton\", \"toun\", etc. could refer to diverse kinds of settlements from agricultural estates and holdings, partly picking up the Norse sense (as in the Scots word ) at one end of the scale, to fortified municipalities. Other common Anglo-Saxon suffixes included \"ham\" 'home', \"stede\" 'stead', and \"burh\" 'bury, borough, burgh'.\nIn toponymic terminology, names of individual towns and cities are called \"astyonyms\" or \"astionyms\" (from Ancient Greek 'town, city', and 'name').\nMeaning.\nIn some cases, \"town\" is an alternative name for \"city\" or \"village\" (especially a small city or large village; and occasionally even hamlets). Sometimes, the word \"town\" is short for \"township\". In general, today towns can be differentiated from townships, villages, or hamlets on the basis of their economic character, in that most of a town's population will tend to derive their living from manufacturing industry, commerce, and public services rather than primary sector industries such as agriculture or related activities.\nA place's population size does not define its urban character. In many areas of the world, e.g. in India at least until recent times, a large village might contain several times as many people as a small town. In the United Kingdom, there are historical cities that are far smaller than the larger towns.\nThe modern phenomenon of extensive suburban growth, satellite urban development, and migration of city dwellers to villages has further complicated the definition of towns, creating communities urban in their economic and cultural characteristics but lacking other characteristics of urban localities.\nSome forms of non-rural settlement, such as temporary mining locations, may be clearly non-rural, but have at best a questionable claim to be called a town.\nTowns often exist as distinct governmental units, with legally defined borders and some or all of the appurtenances of local government (e.g. a police force). In the United States these are referred to as \"incorporated towns\". In other cases the town lacks its own governance and is said to be \"unincorporated\". The existence of an unincorporated town may be legally set out by other means, e.g. zoning districts. In the case of some planned communities, the town exists legally in the form of covenants on the properties within the town. The United States census identifies many census-designated places (CDPs) by the names of unincorporated towns which lie within them; however, those CDPs typically include rural and suburban areas and even surrounding villages and other towns.\nThe distinction between a town and a city similarly depends on the approach: a city may strictly be an administrative entity which has been granted that designation by law, but in informal usage, the term is also used to denote an urban locality of a particular size or importance: whereas a medieval city may have possessed as few as 10,000 inhabitants, today some consider an urban place of fewer than 100,000 as a town, even though there are many officially designated cities that are much smaller than that.\nStarting in March 2021, the then-193 member states of the United Nations have been involved in an effort led by EU aparatusses to agree on a common statistical definition of cities, towns and rural areas.\nAge of towns scheme.\nAustralian geographer Thomas Griffith Taylor proposed a classification of towns based on their age and pattern of land use. He identified five types of towns:\nHistory.\nThrough different periods of recorded history, many towns have grown into sizeable settlements, with the development of properties, centres of culture, and specialized economies.\nNeolithic.\n\u00c7atalh\u00f6y\u00fck, currently an archaeological site, was considered to be the oldest inhabited town, or proto-city, that existed from around 7500 BC. Inscribed as a World Heritage Site, it remains a depopulated town with a complex of ruins.\nRoman era.\nIn Roman times, a villa was a rural settlement formed by a main residential building and another series of secondary buildings. It constituted the center from which an agricultural holding was administered. Subsequently, it lost its agricultural functions and reduced its activity to residential. With the consolidation of large estates during the Roman Empire, the town became the center of large farms.\nA distinction was created between rustic and urban settlements:\nBy country.\nAfghanistan.\nIn Afghanistan, a city and a town are both referred to as \"sh\u0101r\" (; ). The capital of each of its 34 provinces may include a major city such as Kabul whose population is over five million people or a town such as Parun, the capital of Nuristan Province, whose population is less than 20,000 people.\nAlbania.\nIn Albania means 'town', which is very similar to the word for city (), although there is no official use of the term for any settlement.\nIn Albanian, means 'small city' or 'new city', while in ancient times it referred to a small residential center within the walls of a castle.\nAustralia.\nIn Australia, most rural and regional centres of population can be called towns; many small towns have populations of less than 200. The smallest may be described as townships.\nIn addition, some local government entities are officially styled as towns in Queensland, South Australia, Western Australia and the Northern Territory, and formerly also (till the 1990s) in Victoria.\nAustria.\nThe Austrian legal system does not distinguish between villages, towns, and cities. The country is partitioned into 2098 municipalities () of fundamentally equal rank. Larger municipalities are designated as market towns () or cities (), but these distinctions are purely symbolic and do not confer additional legal responsibilities. There is a number of smaller communities that are labelled cities because they used to be regional population centers in the distant past. The city of Rattenberg for example has about 400 inhabitants. The city of Hardegg has about 1200 inhabitants.\nThere are no unincorporated areas.\nOf the 201 cities in Austria, 15 are statutory cities (). A statutory city is a city that is vested, in addition to its purview as a municipality, with the duties of a district administrative authority. The status does not come with any additional autonomy: district administrative authorities are essentially just service centers that citizens use to interact with the national government, for example to apply for driver licenses or passports. The national government generally uses the provinces to run these points of contact on its behalf; in the case of statutory cities, the municipality gets to step up.\nBrazil.\nIn Brazil, since 1938, it was defined that the seat of the municipalities would pass to the category of city and give it the name and the districts would be designated by the name of their respective seats, and if they were not municipal seats, they would have the category of town.\nBulgaria.\nBulgarians do not, in general, differentiate between 'city' and 'town'. However, in everyday language and media the terms \"large towns\" and \"small towns\" are in use. \"Large towns\" usually refers to Sofia, Plovdiv, Varna and Burgas, which have population over 200,000. Ruse and Stara Zagora are often included as well due to presence of relatively developed infrastructure and population over 100,000 threshold. It is difficult to call the remaining provincial capitals \"large towns\" as, in general, they are less developed and have shrinking population, some with as few as 30,000 inhabitants.\nIn Bulgaria the Council of Ministers defines what constitutes a settlement, while the President of Bulgaria grants each settlement its title. In 2005 the requirement that villages that wish to classify themselves as town must have a social and technical infrastructure, as well as a population of no fewer than 3500 people. For resort settlements the requirements are lower with the population needing to be no fewer than 1000 people but infrastructure requirements remain.\nCanada.\nThe legal definition of a town in Canada varies by province or territory, as each has jurisdiction over defining and legislating towns, cities and other types of municipal organization within its own boundaries.\nThe province of Quebec is unique in that it makes no distinction under law between towns and cities. There is no intermediate level in French between and (\"municipality\" is an administrative term usually applied to a legal, not geographical entity), so both are combined under the single legal status of \"ville\". While an informal preference may exist among English speakers as to whether any individual is commonly referred to as a city or as a town, no distinction and no objective legal criteria exist to make such a distinction under law.\nOntario allows municipalities to select whichever administrative term they like with no legal distinction existing between towns, townships, cities, and villages. Instead all municipalities, with the exception of Toronto and Ottawa, fall into one of three legal categories under the Municipalities Act: Single-tier (I.e. towns that are located within a region or county but that are considered separate for municipal purposes such as Hamilton), lower-tier (i.e. municipalities that are part of a region or county such as St. Catharines), or upper-tier (i.e. regional municipalities such as Niagara). Accordingly, many larger municipalities continue to use the title of town due to it better reflecting the character of the municipality. For example, Oakville (2021 Population: 213,759) is the largest municipality to use the title of town to reflect its largely suburban character while other municipalities such as Richmond Hill (2021 Population: 202,022) have opted to change their status from \"town\" to \"city\" to encourage investment.\nChile.\nIn Chile, towns (Spanish: ) are defined by the National Statistics Institute (INE) as an urban entity with a population from 2001 to 5000 or an area with a population from 1001 to 2000 and an established economic activity.\nCzechia.\nIn Czechia, a municipality can obtain the title of a city (), town () or market town (). The title is granted by law.\nStatutory cities (in English usually called just \"cities\"), which are defined by law no. 128/2000 Coll., can define their own self-governing municipal districts. There are 26 such cities, in addition to Prague, which is a \"de facto\" statutory city. All the Czech municipalities with more than 40,000 inhabitants are cities.\nTown and market town are above all ceremonious honorary degrees, referring to population, history and regional significance of a municipality. As the statistics of Czech municipalities shows, towns usually have between 1,000 and 35,000 inhabitants, with median around 4,000 and average around 6,500. Nowadays a municipality must have at least 3,000 inhabitants to have the right to request the town title. Market towns usually have between 500 and 4,000 inhabitants, with median and average both around 1,000.\nDenmark.\nIn Denmark, in many contexts no distinction is made between \"city\", \"town\" and \"village\"; all three translate as . In more specific use, for small villages and hamlets the word (meaning 'country town') is used, while the Danish equivalent of English \"city\" is (meaning 'large town'). For formal purposes, urban areas having at least 200 inhabitants are considered .\nHistorically some towns held various privileges, the most important of which was the right to hold market. They were administered separately from the rural areas in both fiscal, military and legal matters. Such towns are known as (roughly the same meaning as \"borough\" albeit deriving from a different etymology) and they retain the exclusive right to the title even after the last vestiges of their privileges vanished through the reform of the local administration carried through in 1970.\nEstonia.\nIn Estonia, there is no distinction between a town and a city as the word is used for both bigger and smaller settlements, which are bigger than villages and boroughs. There are 30 municipal towns () in Estonia and a further 17 towns, which have merged with a municipal parish ().\nFinland.\nIn Finland, there is no distinction between a town and a city as the word is used for both bigger and smaller settlements, which are bigger than villages and boroughs; although when talking about the word \"town\", the word is used ( means 'little' or 'small'). There are over one hundred municipal towns in Finland.\nFrance.\nFrom an administrative standpoint, the smallest level of local authorities are all called \"communes\". They can have anywhere from a handful to millions of inhabitants, and France has 36,000 of them. The French term for \"town\" is \"bourg\" but French laws generally do not distinguish between towns and cities which are all commonly called . However, some laws do treat these authorities differently based on the population and different rules apply to the three big cities Paris, Lyon and Marseille. For historical reasons, six communes in the Meuse d\u00e9partement exist as independent administrative entities despite having no inhabitants at all.\nFor statistical purposes, the national statistical institute (INSEE) operates a distinction between urban areas with fewer than 2,000 inhabitants and bigger communes, the latter being called . Smaller settlements are usually called .\nGermany.\nGermans do not, in general, differentiate between 'city' and 'town'. The German word for both is , as it is the case in many other languages that do not differentiate between these concepts. The word for a 'village', as a smaller settlement, is . However, the International Statistics Conference of 1887 defined different sizes of , based on their population size, as follows: ('country town'; under 5,000), ('small town'; 5,000 to 20,000), ('middle town'; between 20,000 and 100,000) and (\"large town\"; 100,000 to 1,000,000). The term may be translated as 'city'. In addition, Germans may speak of a , a city with anywhere between one and five million inhabitants (such as Cologne, Munich, Hamburg and Berlin). Also, a city with more than five million inhabitants is often referred to as a (commonly translated as megacity).\nHistorically, many settlements became a by being awarded a \"Stadtrecht\" in medieval times. In modern German language use, the historical importance, the existence of central functions (education, retail etc.) and the population density of an urban place might also be taken as characteristics of a . The modern local government organisation is subject to the laws of each state and refers to a (municipality), regardless of its historic title. While most form part of a (district) on a higher tier of local government, larger towns and cities may have the status of a , combining both the powers of a municipality and a district.\nDesignations in different states are as diverse as e.g. in Australian States and Territories, and differ from state to state. In some German states, the words ('market'), (both used in southern Germany) or ('spot'; northern Germany e.g. in Lower Saxony) designate a town-like residential community between and with special importance to its outer conurbation area. Historically those had (market right) but not full town privileges; see Market town. The legal denomination of a specific settlement may differ from its common designation (e.g. \u2013 a legal term in Lower Saxony for a group of villages [, pl. ] with common local government created by combining municipalities [, pl. ]).\nGreece and Cyprus.\nIn ordinary speech, Greeks use the word ('village') to refer to smaller settlements and the word or ('city') to refer to larger ones. Careful speakers may also use the word to refer to towns with a population of 2,000\u20139,999.\nIn Greek administrative law there used to be a distinction between , i.e. municipalities with more than 10,000 inhabitants or considered important for some other geographical (county seats), historical or ecclesiastical (bishops' seats) reason, and \u03ba\u03bf\u03b9\u03bd\u03cc\u03c4\u03b7\u03c4\u03b5\u03c2, referring to smaller self-governing units, mostly villages. A sweeping reform, carried out in two stages early in the 21st century, merged most with the nearest , dividing the whole country into 325 self-governing . The former municipalities survive as administrative subdivisions (, ).\nCyprus, including the Turkish-occupied areas, is also divided into 39 (in principle, with at least 5,000 inhabitants, though there are exceptions) and 576 .\nHong Kong.\nHong Kong started developing new towns in the 1950s, to accommodate exponential population increase. The first new towns included Tsuen Wan and Kwun Tong. In the late 1960s and the 1970s, another stage of new town developments was launched. Nine new towns have been developed so far. Land use is carefully planned and development provides plenty of room for public housing projects. Rail transport is usually available at a later stage. The first towns are Sha Tin, Tsuen Wan, Tuen Mun and Tseung Kwan O. Tuen Mun was intended to be self-reliant, but was not successful and turned into a bedroom community like the other new towns. More recent developments are Tin Shui Wai and North Lantau (Tung Chung-Tai Ho).\nHungary.\nIn Hungary there is no official distinction between a city and a town (the word for both in Hungarian is ). Nevertheless, the expressions formed by adding the adjectives ('small') and ('large') to the beginning of the root word (e.g. ) have been normalized to differentiate between cities and towns (towns being smaller, therefore bearing the name .) In Hungary, a village can gain the status of ('town'), if it meets a set of diverse conditions for quality of life and development of certain public services and utilities (e.g. having a local secondary school or installing full-area sewage collection pipe network). Every year the Minister of Internal Affairs selects candidates from a committee-screened list of applicants, whom the President of Republic usually affirms by issuing a bill of town's rank to them. Since being a town carries extra fiscal support from the government, many relatively small villages try to win the status of ('town rank') nowadays.\nBefore the fall of communism in 1990, Hungarian villages with fewer than 10,000 residents were not allowed to become towns. Recently some settlements as small as 2,500 people have received the rank of town (e.g. Visegr\u00e1d, Zalakaros or G\u00f6nc) and meeting the conditions of development is often disregarded to quickly elevate larger villages into towns. As of middle 2013, there are 346 towns in Hungary, encompassing some 69% of the entire population.\nTowns of more than 50,000 people are able to gain the status of (town with the rights of a county), which allows them to maintain a higher degree of services. (There are a few exceptions, when towns of fewer than 50,000 people gained the status: \u00c9rd, H\u00f3dmez\u0151v\u00e1s\u00e1rhely, Salg\u00f3tarj\u00e1n and Szeksz\u00e1rd) As of middle 2013, there are only 23 such towns in Hungary.\nIndia.\nThe 2011 Census of India defines towns of two types: statutory town and census town. Statutory town is defined as all places with a municipality, corporation, cantonment board or notified town area committee. Census towns are defined as places that satisfy the following criteria:\nAll the statutory towns, census towns and out growths are considered as urban settlements, as opposed to rural areas.\nTowns in India usually have basic infrastructure like shops, electricity, bitumenised roads, post offices, banks, telephone facilities, high schools and sometimes a few government offices. The human population living in these towns may be a few thousand. There are some towns which can be labelled as Main road town.\nIn state of Karnataka, towns are known as or in the Kannada language. Sometimes the terms ('city') or , which generally means 'place', are used for towns. The administrative council which governs these towns is known as or in Kannada depending on the number of people living within the town's boundaries.\nIran.\nIn contemporary Persian texts, no distinction is made between \"city\" and \"town\"; both translate as (). In older Persian texts (until the first half of the 20th century), the Arabic word () was used for a town. However, in the past 50 years, this word has become obsolete.\nThere is a word in Persian which is used for special sort of satellite townships and city neighborhoods. It is (), (lit.: 'small city').\nAnother smaller type of town or neighborhood in a big city is called (). and each have different legal definitions.\nLarge cities such as Tehran, Mashhad, Isfahan, Tabriz, etc. which have millions inhabitants are referred to as (), metropole.\nThe pace in which different large villages have gained city status in Iran shows a dramatic increase in the last two decades.\nBigger cities and towns usually are centers of a township (in Persian: (). itself is a subdivision of (), 'province'.\nIraq.\nThe word () is used to describe villages, the word () to describe towns, and the word () to describe cities.\nIreland.\nThe Local Government act 2001 provides that from 1 January 2002 (section 10 subsection (3)):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Within the county in which they are situated and of which they form part, there continue to be such other local government areas as are set out in Schedule 6 which \u2013\nshall be known as towns, and in this Act a reference to a town shall include a reference to a borough.\nThese provisions affect the replacement of the boroughs, towns and urban districts which existed before then. Similar reforms in the nomenclature of local authorities (but not their functions) are affected by section 11 part 17 of the act includes provision (section 185(2))\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;Qualified electors of a town having a population of at least 7,500 as ascertained at the last preceding census or such other figure as the Minister may from time to time prescribe by regulations, and not having a town council, may make a proposal in accordance with paragraph (b) for the establishment of such a council\nand contains provisions enabling the establishment of new town councils and provisions enabling the dissolution of existing or new town councils in certain circumstances\nThe reference to \"town having a population of at least 7,500 as ascertained at the last preceding census\" hands much of the power relating to defining what is in fact a town over to the Central Statistics Office and their criteria are published as part of each census.\nPlanning and Development Act 2000.\nAnother reference to the Census and its role in determining what is or is not a town for some administrative purpose is in the Planning and Development act 2000 (part II chapter I which provides for Local area plans):\n&lt;templatestyles src=\"Template:Blockquote/styles.css\" /&gt;A local area plan shall be made in respect of an area which\u2014\nCentral Statistics Office criteria.\nThese are set out in full at http://.\nIn short they speak of \"towns with legally defined boundaries\" (i.e. those established by the Local Government Act 2001) and the remaining 664 as \"census towns\", defined by themselves since 1971 as \"a cluster of 50 or more occupied dwellings in which within a distance of 800 meters there is a nucleus of 30 occupied houses on both sides of the road or twenty occupied Houses on one side of the road\". There is also a \"200 meter criterion\" for determining whether a house is part of a census town.\nIsle of Man.\nThere are four settlements which are historically and officially designated as towns (Douglas, Ramsey, Peel, Castletown); however\nIsrael.\nModern Hebrew does provide a word for the concept of a town: (), derived from (), the biblical word for 'city'. However, the term is normally used only to describe towns in foreign countries, i.e. urban areas of limited population, particularly when the speaker is attempting to evoke nostalgic or romantic attitudes. The term is also used to describe a shtetl, a pre-Holocaust Eastern European Jewish town.\nWithin Israel, established urban areas are always referred to as cities (with one notable exception explained below) regardless of their actual size. Israeli law does not define any nomenclature for distinction between urban areas based on size or any other factor \u2013 meaning that all urban settlements in Israel are legally referred to as \"cities\".\nThe exception to the above is the term (, lit. 'Development Town') which is applied to certain cities in Israel based on the reasons for their establishment. These cities, created during the earlier decades of Israeli independence (1950s and 1960s, generally), were designed primarily to serve as commercial and transportation hubs, connecting smaller agricultural settlements in the northern and southern regions of the country (the \"Periphery\") to the major urban areas of the coastal and central regions. Some of these development towns have since grown to a comparatively large size, and yet are still referred to as development towns, particularly when the speaker wishes to emphasize their (often low) socio-economic status. Nonetheless, they are rarely (if ever) referred to simply as towns; when referring to one directly, it will be called either a development town or a city, depending on context.\nItaly.\nAlthough Italian provides different words for city (), town () and village (, old-fashioned, or , most common), no legal definitions exist as to how settlements must be classified. Administratively, both towns and cities are ruled as comuni/comunes, while villages might be subdivisions of the former.\nGenerally, in everyday speech, a town is larger or more populated than a village and smaller than a city. Various cities and towns together may form a metropolitan area (). A city can also be a culturally, economically, or politically prominent community with respect to surrounding towns. Moreover, a city can be such by Presidential decree. A town, in contrast, can be an inhabited place which would elsewhere be styled a city, but has not received any official recognition.\nRemarkable exceptions do exist: for instance, Bassano del Grappa, was given the status of in 1760 by Francesco Loredan's dogal decree and has since then carried this title. Also, the Italian word for 'town' ( with lowercase P) must not be confused with the Italian word for 'country/nation' ( usually with uppercase P).\nJapan.\nIn Japan, city status (\u5e02 \"shi\") was traditionally reserved for only a few particularly large settlements. Over time however the necessary conditions to be a city have been watered down and today the only loose rules that apply are having a population over 50,000 and over 60% of the population in a \"city centre\". In recent times many small villages and towns have merged in order to form a city despite seeming geographically to be just a collection of villages.\nThe distinction between towns (\u753a \"machi/ch\u014d\") and villages (\u6751 \"mura/son\") is largely unwritten and purely one of population size when the settlement was founded with villages having under 10,000 and towns 10,000\u201350,000.\nKorea.\nIn both of South Korea and North Korea, towns are called \"eup\" (). Most cities in North Korea are built around a central square. Perhaps it is to symbolize the importance of the society over the individual, or just a handy place for mass gatherings and celebrations.\nLatvia.\nIn Latvia, towns and cities are indiscriminately called in singular form. The name is a contraction of two Latvian words: ('castle') and ('fence'), making it very obvious what is meant by the word \u2013 what is situated between the castle and the castle fence. However, a city can be called (big city) or \"mazpils\u0113ta\" (small city/town) in reference to its size. Latvia also has administrative units such as state cities(valstspils\u0113ta) A village is called or in Latvian.\nLithuania.\nIn Lithuanian, a city is called \"miestas\" and a town is called \"miestelis\" (literally 'small '). Metropolises are called \"didmiestis\" (literally 'big ').\nMalaysia.\nIn Malaysia, a town ( or \"kota\") is the area administered by a municipal council ().\nNew Zealand.\nIn New Zealand, the term \"town\" has no current statutory meaning. Certain towns are regionally part of cities.\nNetherlands.\nBefore 1848 there was a legal distinction between and non- parts of the country, but the word no longer has any legal significance. About 220 places were granted ('city rights') and are still so called for historical and traditional reasons, though the word is also used for large urban areas that never obtained such rights. Because of this, in the Netherlands, no distinction is made between \"city\" and \"town\"; both translate as . A hamlet () usually has fewer than 1,000 inhabitants, a village () ranges from 1,000 up to 25,000 inhabitants, and a place above 25,000 can call itself either village or city, mostly depending on historic reasons or size of the place. As an example, The Hague never gained city rights, but because of its size \u2013 more than half a million inhabitants \u2013 it is regarded as a city. Staverden, with only 40 inhabitants, would be a hamlet, but because of its city rights it may call itself a city.\nFor statistical purposes, the Netherlands has three sorts of cities:\nOnly Amsterdam, Rotterdam, The Hague and Utrecht are regarded as a .\nNorway.\nIn Norway, \"city\" and \"town\" both translate to \"by\", even if a city may be referred to as ('large town'). They are all part of and administered as a \"kommune\" ('municipality').\nNorway has had inland the northernmost city in the world: Hammerfest. Now the record is held by New \u00c5lesund on the Norwegian island Svalbard.\nThe oldest town in Norway is T\u00f8nsberg, founded during the Viking Age. The year when the town was founded and which person who founded it is unknown, but Snorri Sturluson says in the Saga of Harald Fairhair that the market town existed before the Battle of Hafrsfjord in the year 872. Nowadays T\u00f8nsberg is considered a city ().\nPhilippines.\nIn the Philippines, the local official equivalent of the town is the municipality (Filipino: ). Every municipality, or town, in the country has a mayor () and a vice mayor () as well as local town officials (Sangguniang Bayan). Philippine towns, otherwise called municipalities, are composed of a number of villages and communities called \"barangays\" with one (or a few cluster of) (s) serving as the town center or \"poblacion\".\nUnique in Philippine towns is that they have fixed budget, population and land requirements to become as such, i.e. from a , or a cluster of such, to a town, or to become cities, i.e. from town to a city. Respectively, examples of these are the town of B. E. Dujali in Davao del Norte province, which was formed in 1998 from a cluster of five , and the city of El Salvador, which was converted from a town to a city in 2007. Each town in the Philippines was classified by its annual income and budget.\nA sharp, hierarchical distinction exists between Philippine cities ( or ) and towns, as towns in the country are juridically separate from cities, which are typically larger and more populous (some smaller and less populated) and which political and economic status are above those of towns. This was further supported and indicated by the income classification system implemented by the National Department of Finance, to which both cities and towns fell into their respective categories that indicate they are such as stated under Philippine law. However, both towns and cities equally share the status as local government units (LGUs) grouped under and belong to provinces and regions; both each are composed of and are governed by a mayor and a vice mayor supplemented by their respective LGU legislative councils. However, despite this some towns in the Philippines are significantly larger than some cities in the Philippines such as Rodriguez, Rizal, Santa Maria, Bulacan and Minglanilla, Cebu are actually bigger than some regional centers.\nPoland.\nIn the Polish language, there is no linguistic distinction between a city and a town, both translated . The word for both is , as a form of settlement distinct from types of rural settlements: village (), \"przysi\u00f3\u0142ek\", ', or ', see Classification of localities and their parts in Poland. Cities are the biggest municipalities, distinguished through being managed by a city mayor (, literally translated city president) instead of a town mayor () as the head of the city executive, thus being informally called \"miasto prezydenckie\", with such privilege automatically awarded to municipalities either inhabited by more than 100,000 residents (currently 37) or those enjoying the status of a city with powiat rights (currently 66). As of 2022, all of the former group fit into the latter, though it was not always the case in the past. There is, however, a number of exemptions due to historic or political reasons, when a municipality meets neither of these two conditions but nevertheless has the city status, including the only 3 capitals of the former voivodeships of Poland (1975\u20131998) not meeting the abovementioned criteria, as well as further 38 municipalities which do not fit into any of the mentioned categories but have nevertheless been allowed to keep the earlier awarded status due to unspecified historical reasons. Towns may sometimes be called , a diminutive colloquially used for localities with a few thousand residents. Such localities have a town mayor () as the head of the town executive.\nTown/city rights are conferred by government legislation; new towns/cities are designated by the government in an annual regulation effective from the first day of the year. Some settlements tend to remain villages even though they have a larger population than many smaller towns, primarily in order not to lose eligibility for the European Agricultural Fund for Rural Development. As of 30 April 2022, there are altogether 2477 municipalities (gmina) in Poland, including 1513 rural gminas, while the remaining 968 ones contain cities and towns. Among them, 666 towns are part of an urban-rural gmina while 302 cities and towns are standalone as an urban gmina. The latter group includes 107 cities (governed by a \"prezydent miasta\"), including 66 cities with powiat rights. 37 cities among the latter group are over 100,000, including 18 cities serving as a seat for voivode or voivodeship sejmik, informally called voivodeship cities.\nPortugal.\nLike other Latin cultures, in Portugal a town () is a populated place larger than a village ( and smaller than a city (). Similarly, although these places are not defined under the Portuguese Constitution and have no political and administrative functions (with associated organs), they are defined by law, and a town must have:\nIn special cases, villages can receive the status of town if they possess historical, cultural or architectonic importance.\nA Portuguese town or city is so merely an urban settlement located in the area of a municipality, in comparison to the North American context, where they have political functions.\nA town can be enterily located inside the area of a single freguesia (subdivion of a municipality) or can occupy several freguesias.\nPortuguese local governments heraldry reflects if the seat of the respective freguesia or municipality is a city, town or another type of settlement. The coat of arms of a local government with a seat in a town bears a mural crown with four towers, while the coat of arms of a local government with a set in a city bears a crown with five towers.\nThis difference between towns and cities is still in use in other Portuguese-speaking countries. In Brazil, since the beginning of the 20th century, all municipal seats receive the status of city.\nRomania.\nIn Romania there is no official distinction between a city and a town (the word for both in Romanian is ). Cities and towns in Romania can have the status either of , conferred to large urban areas, or only to smaller urban localities. Some settlements remain villages () even though they have a larger population than other smaller towns.\nRussia.\nUnlike English, the Russian language does not distinguish the terms \"city\" and \"town\"\u2014both are translated as (). Occasionally the term is applied to urban-type settlements as well, even though the status of those is not the same as that of a city/town proper.\nIn Russia, the criteria an inhabited locality needs to meet in order to be granted city/town () status vary in different federal subjects. In general, to qualify for this status, an inhabited locality should have more than 12,000 inhabitants and the occupation of no less than 85% of inhabitants must be other than agriculture. However, inhabited localities which were previously granted the city/town status but no longer meet the criteria can still retain the status for historical reasons.\nSingapore.\nIn Singapore, towns are large-scale satellite housing developments which are designed to be self-contained. It includes public housing units, a town centre and other amenities. Helmed by a hierarchy of commercial developments, ranging from a town centre to precinct-level outlets, there is no need to venture out of town to meet the most common needs of residences. Employment can be found in industrial estates located within several towns. Educational, health care, and recreational needs are also taken care of with the provision of schools, hospitals, parks, sports complexes, and so on. The most populous town in the country is Bedok.\nSouth Africa.\nIn South Africa the Afrikaans term is used interchangeably with the English equivalent \"town\". A town is a settlement that has a size that is smaller than that of a city.\nSpain.\nIn Spain, the equivalent of town would be , a population unit between a village () and a city (), and is not defined by the number of inhabitants, but by some historical rights and privileges dating from the Middle Ages, such as the right to hold a market or fair. For instance, while Madrid is technically a , Barcelona, with a smaller population, is known as a city.\nSweden.\nThe Swedish language does not differentiate between towns and cities in the English sense of the words; both words are commonly translated as , a term which has no legal significance today. The term is used for an urban area or a locality, which however is a statistical rather than an administrative concept and encompasses densely settled villages with only 200 inhabitants as well as the major cities. The word \"k\u00f6ping\" corresponds to an English \"market town\" \"(chipping)\" or German \"Markt\" but is mainly of historical significance, as the term is not used today and only survives in some toponyms. Some towns with names ending in are cities with over 100,000 inhabitants today, e.g. Link\u00f6ping.\nBefore 1971, 132 larger municipalities in Sweden enjoyed special royal charters as instead of \"kommun\" (which is similar to a US county). However, since 1971 all municipalities are officially defined as , thus making no legal difference between, for instance, Stockholm and a small countryside municipality. Every urban area that was a before 1971 is still often referred to as a in daily speech. Since the 1980s, 14 of these municipalities have branded themselves as again, although this has no legal or administrative significance, as they still have to refer to themselves as in all legal documentation.\nFor statistical purposes, Statistics Sweden officially defines a as an urban area of at least 10,000 inhabitants. Since 2017 it also defines a (literally 'big town') as a municipality with a population of at least 200,000 of which at least 200,000 are in its largest . This means that Stockholm, Gothenburg and Malm\u00f6 are , i.e. 'major cities', while Uppsala, with a population of approximately 230,000 in the municipality, which covers an unusually large area, almost three times larger than the combined land area of the municipalities of Stockholm, Gothenburg and Malm\u00f6, is not. The largest contiguous urban area within Uppsala municipality has a population of well below 200,000, while the population of both Malm\u00f6 municipality, with a land area only 1/14 the size of Uppsala municipality, and Malm\u00f6 , i.e. contiguous urban area, is well over 300,000, and the population of the Malm\u00f6 Metropolitan Area, with a land area only slightly larger than Uppsala Municipality, is well over 700,000. A difference in the size and population of the urban area between Uppsala and the smallest in Sweden, Malm\u00f6, is the reason Statistics Sweden changed the definition of in 2017.\nUkraine.\nIn Ukraine the term \"town\" (, ) existed from the Medieval period until 1925, when it was replaced by the Soviet government with \"urban type settlement\". Historically, a town in the Ukrainian lands was a smaller populated place that was chartered under the German town law and had a market square (see Market town).\nUnited Kingdom.\nEngland and Wales.\nIn England and Wales, a town traditionally was a settlement which had a charter to hold a market or fair and therefore became a \"market town\". Market towns were distinguished from villages in that they were the economic hub of a surrounding area, and were usually larger and had more facilities.\nIn parallel with popular usage, however, there are many technical and official definitions of what constitutes a town, to which various interested parties cling.\nIn modern official usage the term \"town\" is employed either for old market towns, or for settlements which have a town council, or for settlements which elsewhere would be classed a city, but which do not have the legal right to call themselves such. Any parish council can decide to describe itself as a town council, but this will usually only apply to the smallest \"towns\" (because larger towns will be larger than a single civil parish).\nNot all settlements which are commonly described as towns have a town council or borough council. In fact, because of many successive changes to the structure of local government, there are now few large towns which are represented by a body closely related to their historic borough council. These days, a smaller town will usually be part of a local authority which covers several towns. And where a larger town \"is\" the seat of a local authority, the authority will usually cover a much wider area than the town itself (either a large rural hinterland, or several other, smaller towns).\nAdditionally, there are \"new towns\" which were created during the 20th century, such as Basildon, Redditch and Telford.\nSome settlements which describe themselves as towns (e.g. Shipston-on-Stour, Warwickshire) are smaller than some large villages (e.g. Kidlington, Oxfordshire).\nThe status of a \"city\" is reserved for places that have letters patent entitling them to the name, historically associated with the possession of a cathedral. Some large municipalities (such as Northampton and Bournemouth) are legally boroughs but not cities, whereas some cities are quite small \u2014 such as Ely or St David's. The city of Brighton and Hove was created from the two former towns and some surrounding villages, and within the city the correct term for the former distinct entities is somewhat unclear.\nIt appears that a city may become a town, though perhaps only through administrative error: Rochester in Kent had been a city for centuries but, when in 1998 the Medway district was created, a bureaucratic blunder meant that Rochester lost its official city status and is now technically a town.\nIt is often thought that towns with bishops' seats rank automatically as cities: however, Chelmsford was a town until 5 June 2012 despite being the seat of the diocese of Chelmsford, created in 1914. St Asaph, which is the seat of the diocese of St Asaph, only became a city on 1 June 2012 though the diocese was founded in the mid-sixth century. In reality, the pre-qualification of having a cathedral of the established Church of England, and the formerly established Church in Wales or Church of Ireland, ceased to apply from 1888.\nThe word \"town\" can also be used as a general term for urban areas, including cities and in a few cases, districts within cities. In this usage, a city is a type of town; a large one, with a certain status. For example, central Greater London is sometimes referred to colloquially as \"London town\". (The \"City of London\" is the historical nucleus, informally known as the \"Square Mile\", and is administratively separate from the rest of Greater London, while the City of Westminster is also technically a city and is also a London borough.) Camden Town and Somers Town are districts of London, as New Town is a district of Edinburgh \u2013 actually the Georgian centre.\nIn recent years the division between cities and towns has grown, leading to the establishment of groups like the Centre for Towns, who work to highlight the issues facing many towns. Towns also became a significant issue in the 2020 Labour Party leadership election, with Lisa Nandy making significant reference to Labour needing to win back smaller towns which have swung away from the party.\nScotland.\nIn Scotland the word \"town\" has no specific legal meaning and (especially in areas which were or are still Gaelic-speaking) can refer to a mere collection of buildings (e.g. a \"farm-town\" or in Scots ), not all of which might be inhabited, or to an inhabited area of any size which is not otherwise described in terms such as city, burgh, etc. Many locations of greatly different size will be encountered with a name ending with \"-town\", \"-ton\", \"-toun\" etc. (or beginning with the Gaelic equivalent etc.).\n\"Burgh\" (pronounced \"burruh\") is the Scots term for a town or a municipality. They were highly autonomous units of local government from at least the 12th century until their abolition in 1975, when a new regional structure of local government was introduced across the country. Usually based upon a town, they had a municipal corporation and certain rights, such as a degree of self-governance and representation in the sovereign Parliament of Scotland adjourned in 1707.\nThe term no longer describes units of local government, although various claims are made from time to time that the legislation used was not competent to change the status of the Royal Burghs described below. The status is now chiefly ceremonial but various functions have been inherited by current councils (e.g. the application of various endowments providing for public benefit) which might only apply within the area previously served by a burgh; in consequence a burgh can still exist (if only as a defined geographical area) and might still be signed as such by the current local authority. The word 'burgh' is generally not used as a synonym for 'town' or 'city' in everyday speech, but is reserved mostly for government and administrative purposes.\nHistorically, the most important burghs were royal burghs, followed by burghs of regality and burghs of barony. Some newer settlements were only designated as police burghs from the 19th century onward, a classification which also applies to most of the older burghs.\nUnited States.\nIn the United States, the meaning of the term town is different in each state. In some states, a town is a town if the state says it is. In other states, like Wisconsin, a town is a subdivision of a county. In other states, like Michigan, the name \"town\" has no official meaning. People use it to describe any place where many people live. In the six New England states, a town is a kind of municipality that is like a city, but smaller. For example, in Pennsylvania, a town is a specific type of incorporated municipality, distinct from townships and boroughs, with only one town, Bloomsburg, officially designated as such under state law. They're originally based around a population center and in most cases correspond to the geographical designations used by the United States Census Bureau for reporting of housing and population statistics. Municipalities vary greatly in size, from the millions of residents of New York City and Los Angeles to the few hundred people who live in Jenkins, Minnesota. In some instances, the term \"town\" refers to a small incorporated municipality of less than a population threshold specified by state statute, while in others a town can be significantly larger. Some states do not use the term \"town\" at all, while in others the term has no official meaning and is used informally to refer to a populated place, of any size, whether incorporated or unincorporated. In some other states, the words \"town\" and \"city\" are legally interchangeable. The Census of Governments treats jurisdictions called towns in the New England states, Minnesota, New York, and Wisconsin as townships rather than municipalities.\nSmall-town life has been a major theme in American literature, especially stories of rejection by young people leaving for the metropolis.\nSince the use of the term varies considerably by state, individual usages are presented in the following sections:\nAlabama.\nIn Alabama, the legal use of the terms \"town\" and \"city\" is based on population. A municipality with a population of 2,000 or more is a city, while less than 2,000 is a town (Code of Alabama 1975, https://). For legislative purposes, municipalities are divided into eight classes based on population. Class 8 includes all towns, plus cities with populations of less than 6,000 (Code of Alabama 1975, https://).\nArizona.\nIn Arizona, the terms \"town\" and \"city\" are largely interchangeable. A community may incorporate under either a town or a city organization with no regard to population or other restrictions according to Arizona law (see Arizona Revised Statutes, Title 9). Cities may function under slightly differing governmental systems, such as the option to organize a district system for city governments, but largely retain the same powers as towns. Arizona law also allows for the consolidation of neighboring towns and the unification of a city and a town, but makes no provision for the joining of two adjacent cities.\nCalifornia.\nIn California, the words \"town\" and \"city\" are synonymous by law (see Cal. Govt. Code \u00a7\u00a7 34500\u201334504). There are two types of cities in California: charter and general law. Cities organized as charter cities derive their authority from a charter that they draft and file with the state, and which, among other things, states the municipality's name as \"City of (Name)\" or \"Town of (Name).\" Government Code \u00a7\u00a7 34500\u201334504 apply to cities organized as general law cities, which differ from charter cities in that they do not have charters but instead operate with the powers conferred them by the pertinent sections of the Government Code. Like charter cities, general law cities may incorporate as \"City of (Name)\" or \"Town of (Name).\"\nSome cities change what they are referred to as. The sign in front of the municipal offices in Los Gatos, California, for example, reads \"City of Los Gatos\", but the words engraved on the building above the front entrance when the city hall was built read \"Town of Los Gatos.\" There are also signs at the municipal corporation limit, some of which welcome visitors to the \"City of Los Gatos\" while older, adjacent signs welcome people to the \"Town of Los Gatos.\" Meanwhile, the village does not exist in California as a municipal corporation. Instead, the word \"town\" is commonly used to indicate any unincorporated community that might otherwise be known as an unincorporated village. Additionally, some people may still use the word \"town\" as shorthand for \"township\", which is not an incorporated municipality but an administrative division of a county.\nGeorgia.\nGeorgia is divided into 159 counties and contains 535 municipalities consisting of cities, towns, consolidated city-counties, and consolidated cities. There is no legal difference in Georgia between cities and towns.\nHawaii.\nIn Hawaii, the Department of Business, Economic Development, and Tourism has the statutory authority to establish, modify, or abolish the statistical boundaries for cities, town, and. villages. However, the only municipal government in Hawaii is the City and County of Honolulu.\nIllinois.\nIn Illinois, the word \"town\" has been used both to denote a subdivision of a county called a township, and to denote a form of municipality similar to a village, in that it is generally governed by a president and trustees rather than a mayor. In some areas a town may be incorporated legally as a village (meaning it has at large trustees) or a city (meaning it has aldermen from districts) and absorb the duties of the township it is coterminous with (maintenance of birth records, certain welfare items). Evanston, Berwyn and Cicero are examples of towns in this manner. Under the current Illinois Municipal Code, an incorporated or unincorporated town may choose to incorporate as a city or as a village, but other forms of incorporation are no longer allowed.\nIndiana.\nIn Indiana, a \"town\" is differentiated from a \"city\" in that a town can not become a city until it has a population of at least 2,000. The form of government is also different from that of a city in that the town council is both the legislative and executive branches of government. The mayor is selected by the council from within its ranks and operates as a first among equals.\nLouisiana.\nIn Louisiana, a town is defined as being a municipal government having a population of 1,001 to 4,999 inhabitants.\nMaryland.\nWhile a town is generally considered a smaller entity than a city, the two terms are legally interchangeable in Maryland. The only exception is the independent city of Baltimore, which is a special case, as it was created by the Constitution of Maryland.\nMississippi.\nMunicipalities in Mississippi are classified according to population size. At time of incorporation, municipalities with populations of more than 2,000 are classified as cities, municipalities containing between 301 and 2000 persons are classified as towns, and municipalities between 100 and 300 persons are classified as villages. Places may be incorporated to become a city, town, or village through a petition signed by two-thirds of the qualified voters who reside in the proposed municipality. The major function of municipal governments are to provide services for its citizens such as maintaining roads and bridges, providing law, fire protection, and health and sanitation services.\nNevada.\nIn Nevada, a town has a form of government, but is not considered to be incorporated. It generally provides a limited range of services, such as Land-use planning and recreation, while leaving most services to the county. Many communities have found this \"semi-incorporated\" status attractive; the state has only 20 incorporated cities, and towns as large as Paradise (186,020 in 2000 Census), home of the Las Vegas Strip. Most county seats are also towns, not cities.\nNew England.\nIn the six New England states, a town is the most prevalent minor civil division, and in most cases, are a more important form of government than the county. In Connecticut, Rhode Island and seven out of fourteen counties in Massachusetts, in fact, counties only exist as boundaries for state services and chambers of commerce at most, and have no independent legal functions. In New Hampshire, Maine, and Vermont, counties function at a limited scope, and are still not as important in northern New England as they are outside of the northeast. In all six states, towns perform functions that in most states would be county functions. The defining feature of a New England town, as opposed to a city, is that a town meeting and a board of selectmen serve as the main form of government for a town, while cities are run by a mayor and a city council. For example, Brookline, Massachusetts is a town, even though it is fairly urban, because of its form of government. In the three southern New England states, the entire land area is divided into towns and cities, while the three northern states have small areas that are unincorporated. In Vermont and New Hampshire, the population of these areas is practically nonexistent, while in Maine, unincorporated areas make up roughly half of the state's area but only one percent of the state's population.\nThough the U.S. Census Bureau defines New England towns as \"minor civil divisions\" for statistical purposes, all New England towns are municipal corporations equivalent to cities in all legal respects, except for form of government. For statistical purposes, the Census Bureau uses census-designated places for the built-up population centers within towns, though these have no legal or social recognition for residents of those towns. Similarly, the Census Bureau uses a special designation for urban areas within New England, the New England city and town area, instead of the metropolitan statistical area it uses in the rest of the country.\nNew Jersey.\nA \"town\" in the context of New Jersey local government refers to one of five types and one of eleven forms of municipal government. While \"town\" is often used as a shorthand to refer to a township, the two are not the same. The Town Act of 1895 allowed any municipality or area with a population exceeding 5,000 to become a Town through a petition and referendum process. Under the 1895 Act, a newly incorporated town was divided into at least three wards, with two councilmen per ward serving staggered two-year terms, and one councilman at large, who also served a two-year term. The councilman at large served as chairman of the town council. The Town Act of 1988 completely revised the town form of government and applied to all towns incorporated under the Town Act of 1895 and to those incorporated by a special charter granted by the Legislature prior to 1875.\nUnder the 1988 Act, the mayor is also the councilman at large, serving a term of two years, unless increased to three years by a petition and referendum process. The council under the Town Act of 1988 consists of eight members serving staggered two-year terms with two elected from each of four wards. One council member from each ward is up for election each year. Towns with different structures predating the 1988 Act may retain those features unless changed by a petition and referendum process. Two new provisions were added in 1991 to the statutes governing towns. First, a petition and referendum process was created whereby the voters can require that the mayor and town council be elected to four-year terms of office. The second new provision defines the election procedure in towns with wards. The mayor in a town chairs the town council and heads the municipal government. The mayor may both vote on legislation before council and veto ordinances. A veto may be overridden by a vote of two-thirds of all the members of the council. The council may enact an ordinance to delegate all or a portion of the executive responsibilities of the town to a municipal administrator. Fifteen New Jersey municipalities currently have a type of town, nine of which operate under the town form of government.\nNew York.\nIn New York, a town is a division of the county that possesses home rule powers, but generally with fewer functions than towns in New England. A town provides a closer level of governance than its enclosing county, providing almost all municipal services to unincorporated communities, called hamlets, and selected services to incorporated areas, called villages. In New York, a town typically contains a number of such hamlets and villages. However, due to their independent nature, incorporated villages may exist in two towns or even two counties (example: Almond (village), New York). Everyone in New York who does not live in a city or Indian reservation lives in a town and possibly in one of the town's hamlets or villages. New York City and Geneva are the only two cities that span county boundaries. The only part of Geneva in Seneca County is water; each of the boroughs of New York City is a county.\nNorth Carolina.\nIn North Carolina, all cities, towns, and villages are incorporated as municipalities. According to the North Carolina League of Municipalities, there is no legal distinction among a city, town, or village\u2014it is a matter of preference of the local government. Some North Carolina cities have populations as small as 1,000 residents, while some towns, such as Cary, have populations of greater than 100,000.\nOklahoma.\nIn Oklahoma, according to the state's municipal code, \"city\" means a municipality which has incorporated as a city in accordance with the laws of the state, whereas \"town\" means a municipality which has incorporated as a town in accordance with the laws of the state, and \"municipality\" means any incorporated city or town. The term \"village\" is not defined or used in the act. Any community of people residing in compact form may become incorporated as a town; however, if the resident population is one thousand or more, a town or community of people residing in compact form may become incorporated as a city.\nPennsylvania.\nIn Pennsylvania, the incorporated divisions are townships, boroughs, and cities, of which boroughs are equivalent to towns (example: State College is a borough). However, one borough is incorporated as a town: Bloomsburg.\nSouth Carolina.\nAt incorporation, municipalities may choose to be named either \"City of\" or \"Town of\", however there is no legal difference between the two. All municipalities are responsible for providing local service including law enforcement, fire protection, waste and water management, planning and zoning, recreational facilities, and street lighting. Municipalities may incorporate with one of three forms of government: 141 chose mayor\u2013council, 95 chose council, and 33 chose council\u2013manager.\nTennessee.\nSome Tennessee municipalities are called \"cities\" and others are called \"towns.\" These terms do not have legal significance in Tennessee and are not related to population, date of establishment, or type of municipal charter.\nTexas.\nIn Texas, although some municipalities refer to themselves as \"towns\" or \"villages\" (to market themselves as an attractive place to live), these names have no specific designation in Texas law; legally all incorporated places are considered cities.\nUtah.\nIn Utah, the legal use of the terms \"town\" and \"city\" is based on population. A municipality with a population of 1,000 or more is a city, while less than 1,000 is a town. In addition, cities are divided into five separate classes based on the population.\nVirginia.\nIn Virginia, a town is an incorporated municipality similar to a city (though with a smaller required minimum population). But while cities are by Virginia law independent of counties, towns are contained within counties.\nWashington.\nA town in the state of Washington is a municipality that has a population of less than 1,500 at incorporation, however an existing town can reorganize as a code city. Town government authority is limited relative to cities, the other main classification of municipalities in the state. As of 2012,[ [update]] most municipalities in Washington are cities (see: List of towns in Washington).\nWisconsin.\nWisconsin has towns which are areas outside of incorporated cities and villages. These towns retain the name of the civil township from which they evolved and are often the same name as a neighboring city. Some towns, especially those in urban areas, have services similar to those of incorporated cities, such as police departments. These towns will, from time to time, incorporate into cities, such as Fox Crossing in 2016 from the former town of Menasha. Often this is to avoid annexation into neighboring cities and villages.\nWyoming.\nA Wyoming statute indicates towns are incorporated municipalities with populations of less than 4,000. Municipalities of 4,000 or more residents are considered \"first-class cities\".\nSome examples are Moorcroft, Wyoming and Sundance, Wyoming.\nVietnam.\nIn Vietnam, a district-level town () is the second subdivision, below a province () or municipality (). A commune-level town () a third-level (commune-level) subdivision, below a district ().\nSee also.\n&lt;templatestyles src=\"Div col/styles.css\"/&gt;\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52912", "revid": "50515789", "url": "https://en.wikipedia.org/wiki?curid=52912", "title": "Gervasio Antonio de Posadas", "text": "1st Supreme Director of the United Provinces of the R\u00edo de la Plata (1757\u20131833)\nGervasio Antonio de Posadas y D\u00e1vila (18 June 1757 \u2013 2 July 1833) was an Argentine lawyer and statesman who served as the first \"Supreme Director\" of the United Provinces of the R\u00edo de la Plata from 31 January 1814 to 9 January 1815, after having been a member of the Second Triumvirate in 1813\u20131814.\nEarly life and legal career.\nPosadas studied at the Franciscan convent school in Buenos Aires and later trained in law under Manuel Jos\u00e9 de Lavard\u00e9n. In 1789 he was appointed \"escribano mayor\" (notary general) of the bishopric, a post he held until the events of May 1810. He briefly served as \"procurador\" (solicitor) of Buenos Aires in mid-1810.\nPolitical rise and the Second Triumvirate.\nOn 19 August 1813 Posadas joined the Second Triumvirate, replacing Antonio \u00c1lvarez Jonte; he served until the Assembly concentrated executive power in a single person in January 1814. On 31 January 1814 he took office as \"Supreme Director\" of the United Provinces.\nSupreme Director (1814\u20131815).\nNaval campaign and the fall of Montevideo.\nUnder Posadas, the revolutionary fleet commanded by Guillermo Brown won decisive actions in 1814 (notably the Battle of Buceo), which led to the capitulation of Montevideo on 23 June 1814 and the end of royalist control of the principal naval base in the estuary.\nConflict with Artigas and the Federal League.\nShortly after assuming office Posadas issued a decree on 11 February 1814 declaring Jos\u00e9 Gervasio Artigas \"infamous, deprived of his posts, outside the law and an enemy of the fatherland\", and offering a reward of 6,000 pesos for his capture, dead or alive. The measure deepened the conflict between the central government and the Liga Federal.\nAdministrative measures.\nOn 10 September 1814 Posadas decreed the separation of the territories of Entre R\u00edos and Corrientes from the Buenos Aires intendancy, establishing them as provinces of the state and fixing their boundaries (including the annexation of the Misiones pueblos to Corrientes). The full text of the decree survives.\nAppointments and organization.\nDuring his one-year term Posadas appointed Jos\u00e9 de San Mart\u00edn Governor-Intendant of Cuyo (10 August 1814), a post from which San Mart\u00edn organized the Army of the Andes. He also promoted the creation and equipping of a riverine fleet, a key factor in the 1814 campaign.\nInternational context.\nIn Europe Ferdinand VII of Spain was restored to the throne in 1814, returning to Madrid in May and re-establishing absolutist rule, developments that reshaped metropolitan policy toward Spanish America.\nResignation.\nAmid military tensions with the \"Ej\u00e9rcito del Norte\" and intensifying internal conflict in the Littoral, Posadas resigned on 9 January 1815; he was succeeded by his nephew Carlos Mar\u00eda de Alvear.\nImprisonment and later life.\nAfter Alvear's fall in April 1815 Posadas was imprisoned and confined in multiple locations. In his \"Autobiograf\u00eda\" he recalled having occupied \"22 different jails\" over six years before being released around mid-1821. He began drafting his memoirs in 1829; a later edition of his \"Memorias\" was published in 1920. Posadas died in Buenos Aires on 2 July 1833.\nLegacy.\nIn 1879 the city of Posadas was named in his honor.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52921", "revid": "14672439", "url": "https://en.wikipedia.org/wiki?curid=52921", "title": "Wah-wah (music)", "text": "Musical effect\nWah-wah (or wa-wa) is an imitative word (or onomatopoeia) for the sound of altering the resonance of musical notes to extend expressiveness, sounding much like a human voice saying the syllable \"wah\". The wah-wah effect is a spectral glide, a \"modification of the vowel quality of a tone\".\n\"Ultimate-Guitar\" opined that the effect is \"one of the most original and easily identified guitar effects in the world.\"\nEtymology.\nThe word is derived from the sound of the effect itself; an imitative or onomatopoeia word. The effect's \"wa-wa\" sound was noted by jazz player Barney Bigard when he heard Tricky Sam Nanton use the effect on his trombone in the early 1920s.\nHistory.\nAcoustic.\nThe wah-wah effect is believed to have originated in the 1920s, with brass instrument players finding they could produce an expressive crying tone by moving a mute, or plunger, in and out of the instrument's bell. In 1921, trumpet player Johnny Dunn's use of this style inspired Tricky Sam Nanton to use the mute with the trombone.\nElectronic.\nBy the early 1960s, the sound of the acoustic technique had been emulated with electronic circuitry. For electric guitar the wah-wah pedal was invented.\nTechnique.\nThe method of production varies from one type of instrument to another. On brass instruments, it is usually created by means of a mute, particularly with the harmon (also called a \"wa-wa\" mute) or plunger mute. Woodwind instruments may use \"false fingerings\" to produce the effect.\nAny electrified instrument may use an auxiliary signal-processing device, or pedal. Often it is controlled by movement of the player's foot on a rocking pedal connected to a potentiometer. An alternative to players directly controlling the amount of effect is an 'auto-wah'. These devices, usually make harder hit notes more trembly with a more prominent wah wah effect. Wah-wah effects are often used for soloing or for creating a \"wacka-wacka\" funk rhythm on guitar. Although these electronic means are most often on electric guitar, they are also often used on electric piano.\nTheory.\nThe wah-wah effect is produced by periodically bringing in and out of play treble frequencies while a note is sustained. Therefore, the effect is a type of spectral glide, a \"modification of the vowel quality of a tone\".\nThe Electronic wah-wah effects are produced by controlling tone filters with a pedal. An envelope follower circuit is used in the 'auto-wah'. Subtractive synthesis can produce a similar effect.\nNotable uses.\nTricky Sam Nanton's wah-wah on trombone in Duke Ellington's Orchestra became well known as part of the so-called \"jungle\" effects of the band in the late 1920s. This technique has been used in contemporary music. Karlheinz Stockhausen notates the use of the wah-wah mute in his \"Punkte\" (1952/1962) in terms of transitions between open to close using open and closed circles connected by a line. Although the most common method of producing wah-wah on brass instruments is with a mute, some players have used electronic filtering, notably Miles Davis on trumpet.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
{"id": "52924", "revid": "33164707", "url": "https://en.wikipedia.org/wiki?curid=52924", "title": "East of England", "text": "Region of England\nThe East of England is one of nine official regions of England at the first level of ITL for statistical purposes. It consists of the ceremonial counties of Bedfordshire, Cambridgeshire, Essex, Hertfordshire, Norfolk and Suffolk. The northern part of the region, consisting of Norfolk, Suffolk and Cambridgeshire, is known as East Anglia. The latter region has been considered an informal region in its own right due to its differing cultural identity.\nThe population of the East of England in 2024 was 6,576,306. Bedford, Luton, Basildon, Peterborough, Southend-on-Sea, Norwich, Ipswich, Colchester, Chelmsford and Cambridge are the most populous settlements. Peterborough is the largest city in the East of England at 215,000. The southern part of the region lies in the London commuter belt.\nGeography.\nThe East of England has the lowest elevation range in the UK. Twenty per cent of the region is below mean sea level, most of this in North Cambridgeshire, Norfolk and on the Essex Coast. Most of the remaining area is of low elevation, with extensive glacial deposits. The Fens, a large area of reclaimed marshland, are mostly in North Cambridgeshire. The Fens include the lowest point in the country in the village of Holme: 2.75 metres (9.0\u00a0ft) below mean sea level. This area formerly included the body of open water known as Whittlesey Mere. The highest point in the region is at Clipper Down at 817\u00a0ft (249 m) above mean sea level, in the far southwestern corner of the region in the Ivinghoe Hills.\nCommunities known as New Towns, responses to urban congestion and World War II destruction, appeared in Basildon and Harlow (Essex), as well as in Stevenage and Hemel Hempstead (Hertfordshire), in the 1950s and 1960s. In the late 1960s, the Roskill Commission considered Cublington in Buckinghamshire, Thurleigh in Bedfordshire, Nuthampstead in Hertfordshire and Foulness in Essex as locations for a possible third airport for London. A new airport was not built, but a former Royal Air Force base at Stansted, which had previously been converted to civilian use redeveloped and expanded in the following decades.\nHistorical use.\nThe East of England succeeded the standard statistical region East Anglia (which excluded Essex, Hertfordshire and Bedfordshire, then in the South East). The East of England civil defence region was identical to today's region.\nEast Anglia with Home Counties.\nEssex, despite meaning East-Saxons, previously formed part of the South East England administrative region, along with Bedfordshire and Hertfordshire, a mixture of definite and debatable Home counties. The earliest use of the term is from 1695. Charles Davenant, in \"An essay upon ways and means of supplying the war\", wrote, \"The Eleven Home Counties, which are thought in Land Taxes to pay more than their proportion...\" then cited a list including these four. The term does not appear to have been used in taxation since the 18th century.\nClimate.\nEast Anglia is one of the driest parts of the United Kingdom, with average rainfall ranging from . The area receives such low rainfall amounts because low pressure systems and weather fronts from the Atlantic lose a lot of moisture over land (and therefore are usually much weaker) by the time they reach Eastern England.\nWinter (mid-November \u2013 mid-March) is mostly cool, but non-prevailing cold easterly winds can affect the area from the continent. These can bring heavy snowfall if the winds interact with a low-pressure system over the Atlantic or France. Northerly winds also can be cold but are not usually as cold as easterly winds. Westerly winds bring milder and, typically, wetter weather. Southerly winds usually bring mild air (if from the Atlantic or North Africa) but chill if coming from further east than Spain.\nSpring (mid-March \u2013 May) is a transitional season that initially can be chilly but is usually warm by late-April/May. The weather at this time is often changeable (within each day) and occasionally showery.\nSummer (June \u2013 mid-September) is usually warm. Continental air from mainland Europe or the Azores High usually leads to at least a few weeks of hot, balmy weather with prolonged warm to hot temperatures. The number of summer storms from the Atlantic, such as the remnants of a tropical storm, usually coincides with the location of the jet stream. The East tends to receive much less rain than the other regions.\nAutumn (mid-September \u2013 mid-November) is usually mild with some days being very unsettled and rainy and others warm. At least part of September and early October in the East have warm and settled weather, but only in rare years is there an Indian summer where fine weather marks the entire traditional harvest season.\nDust devils were reported in Essex and Cambridgeshire on 17 August 2024, causing minor injuries and some disruption. These small whirlwinds, which form from the ground up, are less powerful than tornadoes. In Essex, they caused tents and gazebos to be lifted during a local event, resulting in minor injuries. Witnesses described the event as unexpected, noting that such phenomena are rare in the area.\nPolitics.\nElections.\nIn the 2015 general election there was an overall swing of 0.25% from the Conservatives to Labour and the Liberal Democrats lost 16% of its vote. All of Hertfordshire and Suffolk became Conservative. The region's electorate voted 49% Conservative, 22% Labour, 16% UKIP, 8% Liberal Democrat and 4% Green. Like other regions, the division of seats favours the dominant party in the region and the Conservatives had 52, Labour 4 (Cambridge, Luton South, Luton North and Norwich South), UKIP 1 (Clacton) and 1 Liberal Democrat (North Norfolk).\nIn the 2019 United Kingdom general election, the Conservatives gained Peterborough and Ipswich from Labour. They also gained North Norfolk from the Liberal Democrats but lost St Albans to Daisy Cooper.\nGovernance and regions.\nEast of England Plan.\nThe East of England Plan, a revision of the Regional Spatial Strategy for the East of England, was published on 12 May 2008. It was revoked on 3 January 2013.\nLocal government.\nThe official region consists of the following subdivisions:\nEurostat NUTS.\nIn the Eurostat Nomenclature of Territorial Units for Statistics (NUTS), the East of England was a level-1 NUTS region, coded \"UKH\", which was subdivided as follows:\nAfter the UK's departure from the EU, the UK NUTS regions were renamed as International Territorial Level regions in 2021.\nHistory.\nCivil War and the Protectorate.\nThe East of England was a major force and resource for Parliament and, in particular, in the form of the Eastern Association. Oliver Cromwell came from Huntingdon.\nSecond World War.\nNorfolk, Suffolk and Essex played host to the American VIII Bomber Command and Ninth Air Force. The Imperial War Museum at Duxford has an exhibition, commemorating their participation and sacrifice, near to the M11 south of Cambridge.\nStansted Airport was RAF Stansted Mountfitchet, home to the 344th Bombardment Group. The de Havilland Mosquito was mainly assembled at Hatfield and Leavesden, although much of the innovative wooden structure originated outside the region from the furniture industry of High Wycombe; the Mosquito entered service in 1942 with 105 Sqn at RAF Horsham St Faith. RAF Tempsford in Bedford is the airfield from where SOE secret agents for Europe took off, with 138 Sqn which parachuted agents and equipment and 161 Sqn which landed and retrieved agents. 19 Sqn at Duxford was the first to be equipped with the Spitfire on 4 August 1938.\nCold War.\nThe 81st Tactical Fighter Wing was at RAF Bentwaters from January 1952 and also at RAF Woodbridge; in the late 1980s some of the aircraft went to RAF Alconbury. Alconbury closed in 1992 and Bentwaters closed in 1993, with the American air forces being in the area for 42 years; the USAF aircraft subsequently moved to Spangdahlem Air Base in Rhineland-Palatinate, Germany.\nAt RAF Marham in west Norfolk, 214 Sqn with the Vickers Valiant developed the RAF's refuelling system; later the squadron would be equipped with the Handley Page Victor. Work on refuelling had also taken place at RAF Tarrant Rushton in Dorset.\nFrom the 1950s, RAF Wyton was an important reconnaissance base for the RAF, mainly 543 Sqn. The base is now home of the Defence Intelligence Fusion Centre, previously known as JARIC, or the Joint Air Reconnaissance Intelligence Centre from 1956.\nOfficial region.\nThe East of England region was officially created in 1994 and was adopted for statistics purposes from 1999.\nHealthcare.\nNHS East of England, which was the strategic health authority for the area until the abolition of these areas in 2013, is on Capital Park, next to Fulbourn Tesco, Fulbourn Hospital, and the Cambridge-Ipswich railway, on the eastern edge of Cambridge. The East of England Ambulance Service is on Cambourne Business Park on Cambourne, of the A428 (the former A45) west of Cambridge. The East Anglian Air Ambulance operates from Cambridge Airport and Norwich Airport; Essex Air Ambulance operates from Boreham.\nEconomy.\nThe former electricity company for the area, Eastern Electricity, has the area's distribution now looked after by UK Power Networks at Fore Hamlet in Ipswich. UK Power Networks also looks after London and most of the South-East. Business Link in the East of England is near to the headquarters of Ocado in Hatfield, at the roundabout of the A1057 and the A1001 on the Bishops Square Business Park. The region's Manufacturing Advisory Service is at Melbourn in Cambridgeshire, off the A10 and north of Royston. UK Trade &amp; Investment for the region is in Histon with its international trade team based next to Magdalene College.\nHertfordshire.\nThe Greater Watford area is home to British Waterways, Vinci (which bought Taylor Woodrow in 2008), the UK of the international firm Total Oil, retailers TK Maxx, Bathstore, Majestic Wine, Mothercare, Costco and Smiths Detection, Iveco, BrightHouse (at Abbots Langley), Leavesden Film Studios, Sanyo, Europcar, Olympus, Kenwood and Beko electronic goods manufacturers, Wetherspoons pub chains, the European HQ of the Hilton hotel group and Nestl\u00e9 Waters; in Garston is the UK headquarters of the Seventh-day Adventist Church, on the A412 and the Building Research Establishment. Comet was previously, and Camelot Group (owners of the National Lottery) currently is, on the A4145, are in Rickmansworth. Ferrero (maker of Nutella and Kinder Chocolate) is in Croxley Green. Renault and Skanska (construction) are in Maple Cross.\nBedfordshire.\nMoto Hospitality has its headquarters at Toddington in Bedfordshire (at the Toddington services).\nLuton is home to EasyJet,(based at the airport), Hain Celestial Group (which makes Linda McCartney Foods and is based on the B579 in Biscot), Eurolines (UK office), Thomson Holidays (based at Wigmore on the eastern edge of the town) and Chevrolet (at Griffin House, the Vauxhall head office). At the 85-acre Capability Green off the A1081 and junction 10a of the M1, is the Stonegate Pub Company (owner of Scream Pubs, Yates's, Slug and Lettuce and Hogshead), InBev UK (which bought most of Whitbread's beer brands), Chargemaster (electric vehicle network under the POLAR brand), AstraZeneca's UK Marketing Company division and Alexon Group (ladies clothing). Vauxhall produced its last Vectra in March 2002 at its Luton plant near the A6/A505 roundabout. Since then, the company has focused on van production, primarily the Vivaro (also sold as the Renault Trafic and other variants), at the former Bedford Vehicles site in the north of the town.\nEast Anglia.\nThe economy in Norfolk, Cambridgeshire and Suffolk is traditionally mostly agricultural. Norfolk is the UK's biggest producer of potatoes. Nationally known companies include the RAC, Archant (publishing), Virgin Money and Aviva (formerly Norwich Union) in Norwich. In Carrow, to the east of the city, Colman's makes a wide range of mustards, and Britvic makes Robinsons squash, which was owned by Colman's until 1995. Across the River Yare near the A47/A146 junction in Trowse with Newton is May Gurney, the construction company. Bernard Matthews Farms has a large turkey farm on the former RAF Attlebridge in Weston Longville. Campbell Soup was made in Kings Lynn until 2008, and on the Hardwick Industrial Estate at the A47/A149 junction is PinguinLutosa the UK, which packs frozen vegetables, and Caithness Crystal.\nFoster Refrigerator is the UK's leading manufacturer of commercial refrigerators and blast chillers, owned by Illinois Tool Works, based on the industrial estate; with Multitone Electronics, which has a manufacturing plant there, and which invented the pager in 1956, for St Thomas' Hospital; and Snap-on Diagnostics makes diagnostic tools for garages. British Sugar's Wissington is the world's largest sugar beet factory in Methwold, on the B1160 near the River Wissey. Lotus Cars and Team Lotus are on the eastern edge of the former RAF Hethel, east of Wymondham (A11) at Hethel (Bracon Ash). Jeyes Group makes household chemicals in Thetford, off the A134; Multiyork makes furniture and Baxter Healthcare has a manufacturing plant in the south of the town. Aunt Bessie vegetable products (roast potatoes) are made by Heinz at Westwick, in a factory built by Ross Group.\nAround Cambridge on numerous science parks, are high technology (electronics and biochemistry) companies, such as ARM Holdings on Peterhouse Technology Park in the south-east of the town, Adder Technology (KVM switches) at Bar Hill at the A14/B1050 junction north of the town, Monsanto, Play.com on the Cambridge Business Centre. The Wellcome Trust Genome Campus has the European Bioinformatics Institute at Hinxton east of Duxford near the M11 spur for the A11. These form the so-called Silicon Fen. Marshall Aerospace is at Cambridge Airport on the A1303 in the east of the town, towards Teversham. South of the airport, Carl Zeiss NTS makes scanning electron microscopes in Cherry Hinton. Syngenta is to the east of Cambridge, on Capital Park at Fulbourn. Premier Foods has a large plant in Histon making Robertson's and Hartley's jam, Gale's honey, Smash instant potato, and Rose's marmalade. Addenbrooke's Hospital is a pioneering hospital in the UK, based at Cambridge Biomedical Campus.\nUniversities.\nThe most famous university in the region is the University of Cambridge. The university has been officially rated as the best in the world in 2010. It has the second-best medicine course in the world, and in 2010 became the only university outside of the US to raise over \u00a31 billion in charitable donations.\nThere are eight universities in the region. Cambridge hosts two universities: the University of Cambridge and Anglia Ruskin University. It is also the home of the Open University's East of England branch. Norwich also hosts two universities: the University of East Anglia and Norwich University of the Arts. There are also other towns and cities in the region which have universities including Bedford and Luton (University of Bedfordshire), Colchester (University of Essex) and Hatfield (University of Hertfordshire). Other higher education centres in the region include University Centre Peterborough, University of Suffolk and Writtle College.\nThe University of Cambridge receives almost three times as much funding as any other university in the region, due to its huge research grant\u2014the largest in England (and the UK). The next largest, by funding, is UEA in Norwich. The University of Essex and Cranfield University also have moderately large research grants, but no other universities in the region do. The largest university by student numbers is ARU, and the next biggest is Cambridge. The smallest is Essex.\nFor total income to universities, Cambridge receives around \u00a31 billion\u2014around six times larger than any other university in the region. The University of Bedfordshire receives the least income. Cambridge has the lowest drop-out (discontinuation) rate in the region. Once graduated, over 50% of students stay in the region, with 25% going to London and 10% going to the South East. Very few go elsewhere\u2014especially the North of England.\nSport.\nFootball.\nDuring the nineteenth century, several formulations of the laws of football, known as the Cambridge rules, were created by students at the University. One of these codes, dating from 1863, had a significant influence on the creation of the original laws of The Football Association.\nEast of England's top representatives in the English football league system today are Ipswich Town, Norwich City, Watford and Luton Town, who have competed in the top flight at various points. Alongside teams Peterborough United, and Cambridge United.\nNetball.\nLondon Mavericks, previously Hertfordshire Mavericks and Saracens Mavericks, have competed in the Netball Super League since 2005. The franchise represents the East region and plays a number of home fixtures at the University of Hertfordshire sports village and the Brentwood Centre. Mavericks have appeared in the Netball Super League Grand Final seven times, winning the title in both 2008 and 2011.\nTurnford Netball Club, Norfolk United Netball Club and Hatfield Netball Club are all teams from the East region which play in the England Netball Premier League, the highest level of club/amateur netball in the country.\nLiterature.\nChildren's author Dodie Smith lived near the town of Sudbury in Suffolk, and part of her famous novel The Hundred and One Dalmatians which inspired the Disney animated film of the same name takes place in the town at St Peter's Church.\nMedia.\nTelevision.\nMuch of the region receives the BBC East and ITV Anglia television services, both based in Norwich (the BBC moving from All Saints' Green to The Forum in 2003, and Anglia remaining at its original base, Angia House.) These services broadcast from the Sandy Heath, Sudbury and Tacolneston transmitter groups. Some areas in close proximity to London, including Luton and south Essex, may receive their service from BBC London and ITV London; in addition, the Hemel Hempstead relay transmitter is a relay of the London services from Crystal Palace, bringing London television into parts of Hertfordshire. Northwestern parts of Norfolk including Kings Lynn receive a better TV signal from the Belmont transmitter that broadcast BBC East Yorkshire and Lincolnshire and ITV Calendar. Some editions of \"Look East\" and \"ITV News Anglia\" broadcast split news programming for the West (Home Counties) and East (East Anglia/Essex) of the region, with the West subregions broadcasting from Sandy Heath; the BBC's Western opt-outs are broadcast from studios in Cambridge, also the base of BBC Radio Cambridgeshire, whilst both versions of the ITV Anglia output have broadcast from Anglia House in Norwich since the split service was introduced in 1990.\nReferences.\n&lt;templatestyles src=\"Reflist/styles.css\" /&gt;"}
